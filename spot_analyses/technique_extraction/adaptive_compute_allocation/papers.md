- [2502.04404](https://arxiv.org/abs/2502.04404): [Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models](../../../ml_research_analysis_2025/2502.04404_step-back-to-leap-forward-self-backtracking-for-boosting-reasoning-of-language-models_20260210_132612.md)
- [2502.06703](https://arxiv.org/abs/2502.06703): [Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling](../../../ml_research_analysis_2025/2502.06703_can-1b-llm-surpass-405b-llm-rethinking-compute-optimal-test-time-scaling_20260208_132551.md)
- [2502.10954](https://arxiv.org/abs/2502.10954): [Learning to Stop Overthinking at Test Time](../../../ml_research_analysis_2025/2502.10954_learning-to-stop-overthinking-at-test-time_20260208_125342.md)
- [2503.07572](https://arxiv.org/abs/2503.07572): [Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning](../../../ml_research_analysis_2025/2503.07572_optimizing-test-time-compute-via-meta-reinforcement-fine-tuning_20260208_125434.md)
- [2504.06514](https://arxiv.org/abs/2504.06514): [Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?](../../../ml_research_analysis_2025/2504.06514_missing-premise-exacerbates-overthinking-are-reasoning-models-losing-critical-thinking-skill_20260210_155049.md)
- [2504.21370](https://arxiv.org/abs/2504.21370): [ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning](../../../ml_research_analysis_2025/2504.21370_shorterbetter-guiding-reasoning-models-to-find-optimal-inference-length-for-efficient-reasoning_20260210_144112.md)
- [2505.09388](https://arxiv.org/abs/2505.09388): [Qwen3 Technical Report](../../../ml_research_analysis_2025/2505.09388_qwen3-technical-report_20260209_233834.md)
- [2505.17454](https://arxiv.org/abs/2505.17454): [Self-Training Large Language Models with Confident Reasoning](../../../ml_research_analysis_2025/2505.17454_self-training-large-language-models-with-confident-reasoning_20260210_042831.md)
- [2505.17813](https://arxiv.org/abs/2505.17813): [Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning](../../../ml_research_analysis_2025/2505.17813_don-t-overthink-it-preferring-shorter-thinking-chains-for-improved-llm-reasoning_20260210_143518.md)
- [2505.18065](https://arxiv.org/abs/2505.18065): [Reward Model Generalization for Compute-Aware Test-Time Reasoning](../../../ml_research_analysis_2025/2505.18065_reward-model-generalization-for-compute-aware-test-time-reasoning_20260210_114320.md)
- [2505.20643](https://arxiv.org/abs/2505.20643): [Can Past Experience Accelerate LLM Reasoning?](../../../ml_research_analysis_2025/2505.20643_can-past-experience-accelerate-llm-reasoning_20260210_065059.md)
- [2505.22662](https://arxiv.org/abs/2505.22662): [AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models](../../../ml_research_analysis_2025/2505.22662_autol2s-auto-long-short-reasoning-for-efficient-large-language-models_20260210_103909.md)
- [2506.00189](https://arxiv.org/abs/2506.00189): [Control-R: Towards controllable test-time scaling](../../../ml_research_analysis_2025/2506.00189_control-r-towards-controllable-test-time-scaling_20260211_013033.md)
- [2506.10716](https://arxiv.org/abs/2506.10716): [PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models](../../../ml_research_analysis_2025/2506.10716_premise-scalable-and-strategic-prompt-optimization-for-efficient-mathematical-reasoning-in-large-models_20260210_145956.md)
- [2506.12721](https://arxiv.org/abs/2506.12721): [Strategic Scaling of Test-Time Compute: A Bandit Learning Approach](../../../ml_research_analysis_2025/2506.12721_strategic-scaling-of-test-time-compute-a-bandit-learning-approach_20260210_123446.md)
- [2506.13102](https://arxiv.org/abs/2506.13102): [Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs](../../../ml_research_analysis_2025/2506.13102_rethinking-test-time-scaling-for-medical-ai-model-and-task-aware-strategies-for-llms-and-vlms_20260210_163354.md)
- [2506.15733](https://arxiv.org/abs/2506.15733): [$\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts](../../../ml_research_analysis_2025/2506.15733_texttt-specs-faster-test-time-scaling-through-speculative-drafts_20260210_081554.md)
- [2507.02076](https://arxiv.org/abs/2507.02076): [Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs](../../../ml_research_analysis_2025/2507.02076_reasoning-on-a-budget-a-survey-of-adaptive-and-controllable-test-time-compute-in-llms_20260210_131254.md)
- [2507.14958](https://arxiv.org/abs/2507.14958): [MUR: Momentum Uncertainty guided Reasoning for Large Language Models](../../../ml_research_analysis_2025/2507.14958_mur-momentum-uncertainty-guided-reasoning-for-large-language-models_20260210_115320.md)
- [2508.03293](https://arxiv.org/abs/2508.03293): [Enhancing Joint Human-AI Inference in Robot Missions: A Confidence-Based Approach](../../../ml_research_analysis_2025/2508.03293_enhancing-joint-human-ai-inference-in-robot-missions-a-confidence-based-approach_20260209_181303.md)
- [2508.12604](https://arxiv.org/abs/2508.12604): [SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression](../../../ml_research_analysis_2025/2508.12604_sspo-self-traced-step-wise-preference-optimization-for-process-supervision-and-reasoning-compression_20260210_145219.md)
- [2508.15050](https://arxiv.org/abs/2508.15050): [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](../../../ml_research_analysis_2025/2508.15050_don-t-think-twice-over-reasoning-impairs-confidence-calibration_20260210_170805.md)
- [2508.17627](https://arxiv.org/abs/2508.17627): [The Evolution of Thought: Tracking LLM Overthinking via Reasoning Dynamics Analysis](../../../ml_research_analysis_2025/2508.17627_the-evolution-of-thought-tracking-llm-overthinking-via-reasoning-dynamics-analysis_20260210_143524.md)
- [2509.00125](https://arxiv.org/abs/2509.00125): [Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning](../../../ml_research_analysis_2025/2509.00125_know-when-to-explore-difficulty-aware-certainty-as-a-guide-for-llm-reinforcement-learning_20260210_013916.md)
- [2509.05226](https://arxiv.org/abs/2509.05226): [Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware Chain-of-Thought Distillation](../../../ml_research_analysis_2025/2509.05226_less-is-more-tokens-efficient-math-reasoning-via-difficulty-aware-chain-of-thought-distillation_20260210_160913.md)
- [2509.06174](https://arxiv.org/abs/2509.06174): [From Long to Short: LLMs Excel at Trimming Own Reasoning Chains](../../../ml_research_analysis_2025/2509.06174_from-long-to-short-llms-excel-at-trimming-own-reasoning-chains_20260210_235036.md)
- [2509.07820](https://arxiv.org/abs/2509.07820): [Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach](../../../ml_research_analysis_2025/2509.07820_certainty-guided-reasoning-in-large-language-models-a-dynamic-thinking-budget-approach_20260210_055918.md)
- [2509.09864](https://arxiv.org/abs/2509.09864): [Latency and Token-Aware Test-Time Compute](../../../ml_research_analysis_2025/2509.09864_latency-and-token-aware-test-time-compute_20260210_005039.md)
- [2509.19645](https://arxiv.org/abs/2509.19645): [Are We Scaling the Right Thing? A System Perspective on Test-Time Scaling](../../../ml_research_analysis_2025/2509.19645_are-we-scaling-the-right-thing-a-system-perspective-on-test-time-scaling_20260210_011405.md)
- [2509.25176](https://arxiv.org/abs/2509.25176): [SIRI: Scaling Iterative Reinforcement Learning with Interleaved Compression](../../../ml_research_analysis_2025/2509.25176_siri-scaling-iterative-reinforcement-learning-with-interleaved-compression_20260210_094157.md)
- [2509.25420](https://arxiv.org/abs/2509.25420): [Adaptive Test-Time Reasoning via Reward-Guided Dual-Phase Search](../../../ml_research_analysis_2025/2509.25420_adaptive-test-time-reasoning-via-reward-guided-dual-phase-search_20260210_181930.md)
- [2509.26522](https://arxiv.org/abs/2509.26522): [Entropy After $\langle \texttt{/Think} \rangle$ for reasoning model early exiting](../../../ml_research_analysis_2025/2509.26522_entropy-after-langle-texttt-think-rangle-for-reasoning-model-early-exiting_20260211_001414.md)
- [2510.01394](https://arxiv.org/abs/2510.01394): [Optimal Stopping vs Best-of-$N$ for Inference Time Optimization](../../../ml_research_analysis_2025/2510.01394_optimal-stopping-vs-best-of-n-for-inference-time-optimization_20260210_074907.md)
- [2510.02228](https://arxiv.org/abs/2510.02228): [xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity](../../../ml_research_analysis_2025/2510.02228_xlstm-scaling-laws-competitive-performance-with-linear-time-complexity_20260209_052135.md)
- [2510.05593](https://arxiv.org/abs/2510.05593): [Improving Chain-of-Thought Efficiency for Autoregressive Image Generation](../../../ml_research_analysis_2025/2510.05593_improving-chain-of-thought-efficiency-for-autoregressive-image-generation_20260210_153750.md)
- [2510.10103](https://arxiv.org/abs/2510.10103): [Stop When Enough: Adaptive Early-Stopping for Chain-of-Thought Reasoning](../../../ml_research_analysis_2025/2510.10103_stop-when-enough-adaptive-early-stopping-for-chain-of-thought-reasoning_20260211_002018.md)
- [2510.21067](https://arxiv.org/abs/2510.21067): [The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning](../../../ml_research_analysis_2025/2510.21067_the-virtues-of-brevity-avoid-overthinking-in-parallel-test-time-reasoning_20260210_164325.md)
- [2511.00086](https://arxiv.org/abs/2511.00086): [Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph](../../../ml_research_analysis_2025/2511.00086_generalizing-test-time-compute-optimal-scaling-as-an-optimizable-graph_20260210_094525.md)
- [2511.04108](https://arxiv.org/abs/2511.04108): [Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models](../../../ml_research_analysis_2025/2511.04108_batch-prompting-suppresses-overthinking-reasoning-under-constraint-how-batch-prompting-suppresses-overthinking-in-reasoning-models_20260210_122136.md)
- [2511.11233](https://arxiv.org/abs/2511.11233): [STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models](../../../ml_research_analysis_2025/2511.11233_star-towards-cognitive-table-reasoning-via-slow-thinking-large-language-models_20260211_000221.md)
- [2511.17006](https://arxiv.org/abs/2511.17006): [Budget-Aware Tool-Use Enables Effective Agent Scaling](../../../ml_research_analysis_2025/2511.17006_budget-aware-tool-use-enables-effective-agent-scaling_20260211_022939.md)
- [2511.20906](https://arxiv.org/abs/2511.20906): [Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy](../../../ml_research_analysis_2025/2511.20906_dynamic-test-time-compute-scaling-in-control-policy-difficulty-aware-stochastic-interpolant-policy_20260210_023702.md)
- [2512.00466](https://arxiv.org/abs/2512.00466): [SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling](../../../ml_research_analysis_2025/2512.00466_scale-selective-resource-allocation-for-overcoming-performance-bottlenecks-in-mathematical-test-time-scaling_20260210_162212.md)
- [2512.11213](https://arxiv.org/abs/2512.11213): [FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration](../../../ml_research_analysis_2025/2512.11213_futureweaver-planning-test-time-compute-for-multi-agent-systems-with-modularized-collaboration_20260210_122812.md)
- [2512.21884](https://arxiv.org/abs/2512.21884): [Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models](../../../ml_research_analysis_2025/2512.21884_optimizing-resource-allocation-for-geographically-distributed-inference-by-large-language-models_20260210_022458.md)
- [2512.24776](https://arxiv.org/abs/2512.24776): [Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models](../../../ml_research_analysis_2025/2512.24776_compute-accuracy-pareto-frontiers-for-open-source-reasoning-large-language-models_20260209_142714.md)
- [2601.14224](https://arxiv.org/abs/2601.14224): [Rerank Before You Reason: Analyzing Reranking Tradeoffs through Effective Token Cost in Deep Search Agents](../../../ml_research_analysis_2025/2601.14224_rerank-before-you-reason-analyzing-reranking-tradeoffs-through-effective-token-cost-in-deep-search-agents_20260210_100726.md)
- [2601.18987](https://arxiv.org/abs/2601.18987): [LLMs versus the Halting Problem: Revisiting Program Termination Prediction](../../../ml_research_analysis_2025/2601.18987_llms-versus-the-halting-problem-revisiting-program-termination-prediction_20260210_123132.md)
- [2602.01120](https://arxiv.org/abs/2602.01120): [MarkovScale: Towards Optimal Sequential Scaling at Inference Time](../../../ml_research_analysis_2025/2602.01120_markovscale-towards-optimal-sequential-scaling-at-inference-time_20260210_074618.md)
- [2602.01237](https://arxiv.org/abs/2602.01237): [Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models](../../../ml_research_analysis_2025/2602.01237_predictive-scheduling-for-efficient-inference-time-reasoning-in-large-language-models_20260209_202721.md)
- [2602.01842](https://arxiv.org/abs/2602.01842): [Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models](../../../ml_research_analysis_2025/2602.01842_prism-efficient-test-time-scaling-via-hierarchical-search-and-self-verification-for-discrete-diffusion-language-models_20260210_153525.md)
