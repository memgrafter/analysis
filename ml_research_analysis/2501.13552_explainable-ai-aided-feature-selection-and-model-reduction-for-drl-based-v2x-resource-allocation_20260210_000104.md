---
ver: rpa2
title: Explainable AI-aided Feature Selection and Model Reduction for DRL-based V2X
  Resource Allocation
arxiv_id: '2501.13552'
source_url: https://arxiv.org/abs/2501.13552
tags:
- feature
- state
- network
- performance
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an explainable AI (XAI)-based framework for
  feature selection and model reduction in deep reinforcement learning (DRL) agents
  applied to vehicle-to-everything (V2X) communications. The method employs SHAP-based
  feature importance rankings to systematically identify and remove non-influential
  state features, thereby simplifying the model without significant performance loss.
---

# Explainable AI-aided Feature Selection and Model Reduction for DRL-based V2X Resource Allocation

## Quick Facts
- arXiv ID: 2501.13552
- Source URL: https://arxiv.org/abs/2501.13552
- Authors: Nasir Khan; Asmaa Abdallah; Abdulkadir Celik; Ahmed M. Eltawil; Sinem Coleri
- Reference count: 40
- One-line primary result: Achieves 97% of original sum-rate performance with 28% fewer state features and 46% fewer trainable parameters

## Executive Summary
This paper presents an explainable AI (XAI)-based framework for feature selection and model reduction in deep reinforcement learning (DRL) agents for vehicle-to-everything (V2X) communications. The method employs SHAP-based feature importance rankings to systematically identify and remove non-influential state features, thereby simplifying the model without significant performance loss. Applied to a multi-agent DRL setting for joint sub-band assignment and power allocation in cellular V2X communications, the approach achieves 97% of the original sum-rate performance while reducing optimal state features by 28%, average training time by 11%, and trainable weight parameters by 46% in a network with eight vehicular pairs. The framework provides a model-agnostic, post-hoc explainability pipeline that enhances understanding of DRL agent inferences and enables efficient model simplification.

## Method Summary
The method involves training a multi-agent DRL system for V2X resource allocation, then applying SHAP-based explainability to identify and remove non-critical state features. The approach uses centralized training with decentralized execution (CTDE) where a central entity trains DQN agents using shared experience replay. After training convergence, SHAP values are computed using a background dataset (1% K-means summary of training data) and a hold-out test set (10% K-means summary). An iterative masking algorithm then removes the least important features while monitoring performance degradation against a precision threshold. The simplified model is retrained from scratch with reduced input dimensions, resulting in fewer trainable parameters and faster convergence.

## Key Results
- Achieves 97% of original sum-rate performance with 28% reduction in state features
- Reduces trainable weight parameters by 46% through input dimension reduction
- Decreases average training time by 11% for the simplified model
- Successfully demonstrates model simplification without significant performance degradation in multi-agent V2X scenarios

## Why This Works (Mechanism)

### Mechanism 1: Redundancy Elimination via Global Importance Aggregation
The method calculates Shapley values for every input feature across multiple data instances, then aggregates these "local" explanations into a "global" ranking by taking the mean absolute value. By eliminating features that consistently contribute little to the output variance, the model dimensionality is reduced. The core assumption is that feature contribution to Q-value prediction correlates strongly with necessity for maximizing reward.

### Mechanism 2: Iterative Pruning with Performance Guardrails
An iterative masking strategy identifies the minimal viable feature set by linking feature removal directly to a precision threshold (Δ). The algorithm iteratively masks the p least important features and re-evaluates network performance. If performance drops below the threshold Δ, masking is reversed or halted, ensuring the model doesn't cross a "performance cliff" due to cumulative small errors in feature ranking.

### Mechanism 3: Architectural Contraction via Input Dimension Reduction
Reducing the input state space dimension directly reduces the number of trainable weights in hidden layers, leading to faster training and inference. The DQN architecture uses fully connected layers where input dimension L dictates the size of the first hidden layer and subsequent weight matrices. By reducing L, the number of weights decreases non-linearly, observed as a ~46% reduction.

## Foundational Learning

- **Concept: Shapley Additive exPlanations (SHAP)**
  - Why needed here: Core mathematical tool used to assign "importance" values to input features
  - Quick check question: Does a negative SHAP value indicate a feature is "unimportant," or does it indicate the feature pushes the prediction lower than the baseline?

- **Concept: Multi-Agent Deep Reinforcement Learning (MADRL)**
  - Why needed here: Context is a network where multiple V2V pairs act as independent agents
  - Quick check question: In the CTDE framework, does the vehicle (agent) need to calculate SHAP values during real-time execution?

- **Concept: Finite Blocklength Regime (URLLC)**
  - Why needed here: Paper optimizes for V2V links using specific rate formula rather than standard Shannon capacity
  - Quick check question: Why does the standard Shannon capacity formula fail to capture reliability requirements of V2V safety messages in this paper?

## Architecture Onboarding

- **Component map:** Environment -> Original-MADRL Trainer -> Deep-SHAP Explainer -> Iterative Pruner -> Simplified-MADRL Builder
- **Critical path:** Train full MADRL model to convergence -> Generate Background Dataset (1% K-means summary) -> Execute iterative masking loop (Algorithm 2) -> Retrain model from scratch using only selected features
- **Design tradeoffs:** Precision Threshold (Δ) - higher allows more aggressive pruning but risks reliability constraints; Background Data Size - 1% K-means summary balances computational complexity vs. explanation accuracy
- **Failure signatures:** Performance Cliff - metric stays flat then suddenly crashes suggesting critical conditional dependencies were discarded; High Variance in SHAP - values fluctuate wildly leading to inconsistent pruning results
- **First 3 experiments:** Baseline Convergence - run Original-MADRL with full state space; SHAP Sensitivity - compute SHAP values and visualize feature importance; Ablation Study - implement Algorithm 2 with varying Δ (1%, 2%, 5%) and plot retained features vs. sum rate

## Open Questions the Paper Calls Out

### Open Question 1
How can the proposed XAI-based feature selection methodology be adapted for digital twin systems to maintain synchronization between the virtual representation and the real-world V2X network? The current work focuses on resource allocation in the physical layer but hasn't explored how interpreting model actions via environment semantics scales to the complex, dual-state nature of digital twins.

### Open Question 2
Can the model-agnostic XAI framework be generalized to other wireless resource allocation problems with different constraint types, such as network slicing or MIMO beamforming? The current study validates the method only on a joint sub-band assignment and power allocation problem using MADRL; it's unproven whether the iterative feature masking strategy works for problems with vastly larger or continuous action spaces.

### Open Question 3
How robust is the Deep-SHAP feature ranking when the background dataset summarization ratio is varied or the environment statistics drift significantly over time? The use of 1% K-means summary for background dataset balances computational complexity but doesn't analyze sensitivity of feature rankings to this specific compression ratio or dataset staleness.

## Limitations
- Performance reduction trade-off assumes uniform importance of features across operational state space, which may not hold for rare but critical events under-represented in background dataset
- SHAP-based feature importance is computationally intensive even with K-means summarization, limiting real-time explainability applications
- Study validates only one specific DRL architecture (DQN) and V2X scenario; generalization to other RL algorithms or network configurations remains untested

## Confidence

**High Confidence:** Mathematical framework of SHAP value computation and iterative pruning (Algorithm 2) is sound and well-specified

**Medium Confidence:** 28% feature reduction with 97% performance retention is specific to tested configuration; different network densities or mobility patterns may yield different results

**Medium Confidence:** 46% parameter reduction claim depends on specific network architecture; different hidden layer configurations would alter scaling relationship

## Next Checks
1. **Robustness Test:** Apply pruning algorithm to datasets with artificially injected rare interference events to verify model doesn't discard critical edge-case features
2. **Cross-Architecture Validation:** Implement same framework using PPO or SAC algorithms to test algorithm-agnostic performance of feature selection approach
3. **Generalization Test:** Scale network beyond 8 vehicular pairs (e.g., 16-32 pairs) to evaluate how feature reduction percentages and performance retention scale with network complexity