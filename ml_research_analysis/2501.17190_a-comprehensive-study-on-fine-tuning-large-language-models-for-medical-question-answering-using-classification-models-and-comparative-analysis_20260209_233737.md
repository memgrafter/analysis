---
ver: rpa2
title: A Comprehensive Study on Fine-Tuning Large Language Models for Medical Question
  Answering Using Classification Models and Comparative Analysis
arxiv_id: '2501.17190'
source_url: https://arxiv.org/abs/2501.17190
tags:
- medical
- performance
- large
- bert
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated four fine-tuned language models (LoRA Roberta-large,
  Roberta-base, Bert Uncased, and Bert Large Uncased) for classifying medical questions
  using a 5-fold cross-validation approach. The models were trained on a dataset of
  6,800 samples scraped from Healthline.com with synthetic augmentation.
---

# A Comprehensive Study on Fine-Tuning Large Language Models for Medical Question Answering Using Classification Models and Comparative Analysis

## Quick Facts
- arXiv ID: 2501.17190
- Source URL: https://arxiv.org/abs/2501.17190
- Reference count: 23
- Primary result: BERT Large Uncased achieved perfect 100% accuracy on medical question classification task

## Executive Summary
This study evaluates four fine-tuned language models (LoRA Roberta-large, Roberta-base, Bert Uncased, and Bert Large Uncased) for classifying medical questions using a 5-fold cross-validation approach. The models were trained on a dataset of 6,800 samples scraped from Healthline.com with synthetic augmentation. The results demonstrate that fine-tuning large language models can significantly improve medical question-answering capabilities, with BERT-based models showing superior performance. The classification-based approach aims to reduce hallucination risks compared to generative models by mapping questions to predefined labels and static answers.

## Method Summary
The study fine-tuned four transformer-based models on a medical question classification task using 6,800 samples from Healthline.com with synthetic augmentation. Models evaluated include Roberta-base, Roberta-large with LoRA, Bert Uncased, and Bert Large Uncased. Training employed 5-fold cross-validation with 10 epochs per fold on a Google Colab T4 GPU. The approach maps open-ended medical questions to discrete classification labels, then retrieves predefined answers, decoupling understanding from answer generation to mitigate hallucination risks.

## Key Results
- Bert Large Uncased achieved perfect performance (100% accuracy, precision, recall, and F1 score)
- Roberta-base showed near-perfect results (99.87%, 99.81%, 99.86%, 99.82%)
- Bert Uncased achieved strong performance (95.85%, 94.42%, 95.58%, 94.72%)
- LoRA Roberta-large showed moderate results (78.47%, 72.91%, 76.95%, 73.56%)

## Why This Works (Mechanism)

### Mechanism 1: Label-Bounded Output Constraint
Mapping open-ended medical questions to discrete classification labels reduces hallucination compared to generative decoding. The system decouples the "understanding" phase from the "answer" phase, ensuring final answers are human-verified rather than generated, avoiding factual drift common in generative LLMs.

### Mechanism 2: Domain-Specific Representation Alignment
Fine-tuning transformer encoders on domain data shifts embedding space to prioritize medical semantic relationships. Pre-trained models possess general language understanding, but domain exposure optimizes attention mechanisms to recognize specific symptom-to-disease correlations required for classification.

### Mechanism 3: Parameter-Efficient Fine-Tuning (PEFT) Trade-offs
LoRA enables training larger backbones with limited compute by freezing pre-trained weights and injecting trainable rank decomposition matrices. This reduces memory usage but limits expressiveness to the rank dimension, potentially causing underfitting on complex tasks.

## Foundational Learning

**Encoder-Only Architectures (BERT/RoBERTa)**
- Why needed: Designed to produce contextual embeddings ideal for classification via `[CLS]` token rather than text generation
- Quick check: Can you explain why a masked language model is generally more parameter-efficient for classification than an autoregressive decoder model?

**Cross-Validation Strategy**
- Why needed: 5-fold cross-validation mitigates high variance from training on relatively small dataset (6,800 samples)
- Quick check: If a model achieves 100% accuracy on one fold but 80% on another, what does this imply about data distribution or model stability?

**The Accuracy vs. Efficiency Trade-off**
- Why needed: Study compares full fine-tuning (high accuracy, high compute) against LoRA (lower accuracy, lower compute)
- Quick check: Why might a "perfect" 100% accuracy score in a validation set be suspicious?

## Architecture Onboarding

**Component map:**
Raw medical query text -> Tokenizer -> Backbone (Transformer Encoder) -> Adapter (LoRA optional) -> Classification Head -> Retrieval (Label -> Predefined Answer)

**Critical path:**
Tokenizer -> Backbone -> Classification Head determines latency and accuracy

**Design tradeoffs:**
Base vs. Large: Base offers better speed/accuracy balance than Large given overfitting risk
Full vs. LoRA: Full fine-tuning significantly outperformed LoRA, suggesting low-rank constraints were too restrictive

**Failure signatures:**
"Perfect" Scores: BERT Large Uncased's 100% metrics usually signal data leakage, insufficient validation diversity, or memorization
LoRA Underperformance: Significant gap suggests low-rank constraints were too restrictive for this classification boundary

**First 3 experiments:**
1. Baseline Reproduction: Implement Roberta-base fine-tuning to verify 99.87% accuracy claim
2. Overfitting Stress Test: Test "perfect" BERT Large against adversarial examples to verify 100% accuracy
3. LoRA Rank Sweep: Increase rank in LoRA configuration to determine if 78% accuracy was due to bottleneck

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: Does BERT Large Uncased model's reported 100% accuracy stem from overfitting or data leakage rather than genuine generalization?
- Basis: Page 12 states perfect scores "warrant cautious interpretation as they could indicate potential overfitting," and Page 16 calls for "further validation to ensure generalizability"
- Why unresolved: Study relied solely on cross-validation on single dataset without external testing
- Evidence needed: Performance on external medical benchmark or analysis of data leakage

**Open Question 2**
- Question: Would replacing static "label-to-answer" classification with dynamic answer generation improve performance on complex medical inquiries?
- Basis: Page 16 notes approach is "constrained by predefined labels," and future work should focus on "incorporating dynamic answer generation"
- Why unresolved: Current architecture only classifies questions to map them to existing static answers
- Evidence needed: Comparative study against generative model on complex medical questions

**Open Question 3**
- Question: How robust are these fine-tuned models against adversarial attacks and demographic biases?
- Basis: Page 17 acknowledges "resilience to adversarial attacks, and potential biases, were not adequately addressed"
- Why unresolved: Evaluation relied exclusively on standard classification metrics rather than robustness or fairness checks
- Evidence needed: Adversarial stress tests and fairness audits

## Limitations

**Data Source & Representativeness**
Relies on 6,800 samples scraped from Healthline.com with unverified synthetic augmentation, lacking class distribution or diversity metrics

**Perfect Performance Suspicion**
BERT Large Uncased achieving 100% accuracy across all metrics raises red flags for data leakage, insufficient validation set diversity, or memorization

**Limited Clinical Context**
Classification-only approach restricts answers to predefined responses, insufficient for complex queries requiring nuanced reasoning or multi-step diagnosis

## Confidence

**High Confidence Claims**
- Classification-based approaches reduce hallucination risk (supported by methodology and corpus validation)
- Fine-tuning transformer encoders on domain data improves performance (basic ML principle, confirmed by results)

**Medium Confidence Claims**
- BERT models outperform Roberta for this task (experimental results show this, but 100% accuracy raises validity concerns)
- LoRA underperforms full fine-tuning (results support this, but LoRA configuration details missing)

**Low Confidence Claims**
- 100% accuracy of BERT Large Uncased represents true generalization (unrealistic in medical domain, likely indicates overfitting)
- Synthetic data augmentation effectively improves performance (no analysis of synthetic sample quality)

## Next Checks

1. **Adversarial Testing Protocol**
Design test suite of paraphrased medical questions, synonym substitutions, and compound queries to evaluate whether "perfect" BERT Large model maintains performance below 95% on adversarial examples

2. **Cross-Dataset Generalization Study**
Test fine-tuned models on independent medical QA dataset to assess real-world generalization and quantify domain-specific overfitting

3. **LoRA Configuration Optimization**
Systematically sweep LoRA ranks (r=2, 4, 8, 16, 32) and learning rates to identify optimal configuration and determine if 78.47% accuracy was due to suboptimal hyperparameters or fundamental limitations