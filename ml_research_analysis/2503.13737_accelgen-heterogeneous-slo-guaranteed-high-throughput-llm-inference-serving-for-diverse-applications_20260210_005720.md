---
ver: rpa2
title: 'AccelGen: Heterogeneous SLO-Guaranteed High-Throughput LLM Inference Serving
  for Diverse Applications'
arxiv_id: '2503.13737'
source_url: https://arxiv.org/abs/2503.13737
tags:
- requests
- accel
- time
- utilization
- batch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'AccelGen is a high-throughput LLM inference serving system designed
  to handle diverse applications with both short and long prompts while meeting heterogeneous
  SLOs for iteration time. It introduces four core components: SLO-guaranteed dynamic
  chunking, which dynamically adjusts chunk sizes to maximize GPU compute utilization
  while meeting iteration-level SLOs; Iteration-level SLO-based task prioritization,
  which prioritizes tight-SLO requests and batches requests with similar SLOs; Multi-resource-aware
  batching, which selects queued requests to maximize the utilizations of both GPU
  compute resource and key-value cache (KVC).'
---

# AccelGen: Heterogeneous SLO-Guaranteed High-Throughput LLM Inference Serving for Diverse Applications

## Quick Facts
- arXiv ID: 2503.13737
- Source URL: https://arxiv.org/abs/2503.13737
- Authors: Haiying Shen; Tanmoy Sen
- Reference count: 40
- Primary result: Achieves 1.42-11.21X higher throughput, 1.43-13.71X higher goodput, 37-90% higher SLO attainment, and 1.61-12.22X lower response latency compared to state-of-the-art approaches

## Executive Summary
AccelGen is a high-throughput LLM inference serving system designed to handle diverse applications with both short and long prompts while meeting heterogeneous Service Level Objectives (SLOs) for iteration time. The system introduces four core components that work together to optimize GPU compute utilization and key-value cache usage while guaranteeing SLO compliance. Trace-driven real experiments demonstrate that AccelGen significantly outperforms existing approaches across multiple performance metrics.

## Method Summary
AccelGen implements a comprehensive system for LLM inference serving that addresses the challenges of heterogeneous workloads with varying SLO requirements. The system dynamically adjusts chunk sizes to maximize GPU utilization while meeting iteration-level SLOs, prioritizes requests based on their SLO tightness, and performs multi-resource-aware batching that considers both GPU compute and KV cache constraints. The approach is validated through trace-driven experiments comparing against state-of-the-art methods and an Oracle baseline.

## Key Results
- Achieves 1.42-11.21X higher throughput compared to state-of-the-art approaches
- Demonstrates 37-90% higher SLO attainment rates
- Reduces response latency by 1.61-12.22X
- Performs near Oracle-optimal levels for goodput maximization

## Why This Works (Mechanism)
The system works by implementing four coordinated mechanisms that address the fundamental tension between maximizing throughput and meeting diverse SLO requirements. Dynamic chunking adjusts inference chunk sizes in real-time to balance GPU utilization against iteration time constraints. Task prioritization ensures tight-SLO requests receive preferential treatment while batching similar SLO requests together. Multi-resource-aware batching intelligently selects requests to optimize both GPU compute and KV cache utilization simultaneously. Together, these components create a system that can adapt to workload heterogeneity while maintaining SLO guarantees.

## Foundational Learning
- **Dynamic Chunking**: Adjusting chunk sizes during inference to balance GPU utilization and iteration time - needed to handle the variability in prompt lengths and maintain SLOs; quick check: monitor GPU utilization vs iteration completion times
- **Iteration-level SLO Prioritization**: Prioritizing requests based on their SLO tightness at the iteration level - needed to ensure critical requests meet their deadlines; quick check: track SLO attainment rates across different priority levels
- **Multi-resource-aware Batching**: Selecting requests that optimize both GPU compute and KV cache utilization - needed to prevent resource bottlenecks and maximize throughput; quick check: measure resource utilization patterns during batching
- **Heterogeneous Workload Management**: Handling diverse applications with varying prompt lengths and SLO requirements - needed to serve real-world LLM inference scenarios; quick check: analyze performance across different workload mixes

## Architecture Onboarding

**Component Map**: SLO-guaranteed dynamic chunking -> Iteration-level SLO-based task prioritization -> Multi-resource-aware batching -> SLO guarantee enforcement

**Critical Path**: Request arrival -> Priority assignment -> Batching selection -> Dynamic chunking adjustment -> GPU execution -> SLO validation

**Design Tradeoffs**: The system trades optimal GPU utilization for SLO guarantees by potentially leaving some GPU cycles unused when tight SLOs require smaller chunk sizes. It also prioritizes KV cache efficiency over pure compute throughput when memory-bound scenarios are detected.

**Failure Signatures**: SLO violations indicate either insufficient dynamic chunking adjustments or batching selections that don't properly account for iteration-level constraints. Low throughput despite high GPU utilization suggests batching decisions that don't optimize KV cache usage.

**First 3 Experiments**:
1. Baseline performance measurement with static chunk sizes and no prioritization
2. Ablation study isolating each component (dynamic chunking, prioritization, batching) to measure individual contributions
3. Stress test with mixed tight and loose SLO workloads to validate system behavior under pressure

## Open Questions the Paper Calls Out
None

## Limitations
- Comparison with "state-of-the-art approaches" lacks specificity about exact baseline methods
- Oracle baseline represents idealized optimal scheduling, making "near Oracle" claims difficult to validate
- Real-world deployment scenarios beyond trace-driven experiments remain unclear
- Resource utilization trade-offs across different hardware configurations not fully explored

## Confidence

**High confidence**: Core system design principles and four-component architecture (dynamic chunking, task prioritization, multi-resource batching, SLO guarantees)

**Medium confidence**: Quantitative performance improvements (1.42-11.21X throughput gains, 37-90% SLO attainment improvements) given comparison methodology limitations

**Medium confidence**: "Near Oracle" performance claim due to idealized nature of Oracle baseline

## Next Checks

1. Conduct ablation studies isolating each of the four core components to quantify their individual contributions to overall performance

2. Test the system across diverse hardware configurations (different GPU types, memory capacities) to validate generalization of the multi-resource-aware batching approach

3. Evaluate performance with real-world, production LLM serving workloads rather than trace-driven experiments to validate practical applicability