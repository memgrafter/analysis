---
ver: rpa2
title: 'TopoReformer: Mitigating Adversarial Attacks Using Topological Purification
  in OCR Models'
arxiv_id: '2511.15807'
source_url: https://arxiv.org/abs/2511.15807
tags:
- adversarial
- attacks
- topological
- defense
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TopoReformer introduces a model-agnostic adversarial defense for
  OCR systems by integrating topological purification with a lightweight reformer.
  It uses a topological autoencoder to preserve the global structure of text images,
  removing adversarial perturbations without requiring adversarial training or affecting
  clean-input performance.
---

# TopoReformer: Mitigating Adversarial Attacks Using Topological Purification in OCR Models

## Quick Facts
- arXiv ID: 2511.15807
- Source URL: https://arxiv.org/abs/2511.15807
- Reference count: 10
- TopoReformer introduces a model-agnostic adversarial defense for OCR systems by integrating topological purification with a lightweight reformer

## Executive Summary
TopoReformer addresses the vulnerability of OCR systems to adversarial attacks by introducing a novel defense mechanism that leverages topological purification. The approach combines a topological autoencoder with a lightweight reformer to preserve the global structure of text images while removing adversarial perturbations. Unlike traditional methods requiring adversarial training, TopoReformer maintains high performance on clean inputs while significantly reducing attack success rates across various attack scenarios.

## Method Summary
TopoReformer implements a model-agnostic adversarial defense for OCR systems through topological purification. The method integrates a topological autoencoder that captures and preserves the global structure of text images, effectively removing adversarial perturbations without compromising clean-input performance. This lightweight reformer approach operates independently of the underlying OCR architecture, eliminating the need for adversarial training while maintaining robust defense capabilities against standard, adaptive, and OCR-specific attacks.

## Key Results
- Reduces attack success rates across standard attacks (FGSM, PGD, C&W), adaptive attacks (EOT, BPDA), and OCR-specific watermark attacks (FAWA)
- Improves classification F1-scores and precision under adversarial conditions while maintaining over 94% accuracy on clean inputs
- Grad-CAM visualizations confirm more focused, confident predictions on purified inputs

## Why This Works (Mechanism)
TopoReformer leverages topological data analysis to identify and preserve the essential structural features of text images. By focusing on the global topology rather than pixel-level details, the method can effectively distinguish between legitimate variations in text appearance and adversarial perturbations. The topological autoencoder learns to encode these structural invariants, while the reformer component ensures that the purification process doesn't introduce artifacts that could confuse the OCR system. This approach is particularly effective because adversarial attacks often target local features that are less topologically significant, allowing the method to filter out noise while preserving the semantic content of the text.

## Foundational Learning
- Topological Data Analysis (TDA): Analyzes the shape and structure of data
  - Why needed: To capture global structural invariants that are robust to local perturbations
  - Quick check: Verify that topological features remain stable across different text fonts and styles
- Autoencoder Architecture: Neural network for learning compressed data representations
  - Why needed: To learn the topological structure of clean text images
  - Quick check: Ensure the autoencoder can reconstruct clean images with minimal loss
- Reformer Models: Efficient transformer architectures for sequence processing
  - Why needed: To provide lightweight, model-agnostic purification without heavy computational overhead
  - Quick check: Validate that the reformer doesn't introduce significant latency
- Grad-CAM Visualization: Technique for visualizing model attention
  - Why needed: To confirm that purified inputs lead to more focused predictions
  - Quick check: Compare attention maps between clean, attacked, and purified inputs
- Adversarial Attack Taxonomy: Classification of attack methods
  - Why needed: To systematically evaluate defense against various threat models
  - Quick check: Test against both white-box and black-box attack scenarios
- OCR System Vulnerabilities: Understanding attack surfaces in text recognition
  - Why needed: To tailor the defense to specific OCR failure modes
  - Quick check: Identify which OCR components are most susceptible to topological attacks

## Architecture Onboarding

Component map: Input Image -> Topological Autoencoder -> Reformer Purification -> OCR Model

Critical path: The topological autoencoder must successfully learn the structural invariants of clean text before the reformer can effectively filter adversarial perturbations. The purification step must be fast enough to maintain real-time processing requirements.

Design tradeoffs: The method balances between aggressive purification (which might remove legitimate variations) and conservative filtering (which might allow some adversarial noise). The topological approach provides a middle ground by focusing on structural features rather than pixel-perfect reconstruction.

Failure signatures: Poor topological feature extraction would result in either over-purification (removing legitimate text features) or under-purification (failing to remove adversarial noise). The Grad-CAM visualizations should show diffuse attention patterns when purification fails.

First experiments:
1. Test topological feature extraction on clean text samples with varying fonts and styles
2. Evaluate purification effectiveness on simple adversarial examples (e.g., FGSM with small epsilon)
3. Measure clean-input accuracy preservation after adding the purification layer

## Open Questions the Paper Calls Out
None

## Limitations
- Performance on real-world OCR datasets beyond synthetic word-based datasets remains unverified
- Computational overhead during inference requires detailed runtime analysis
- The model-agnostic claim needs validation across diverse OCR architectures, particularly non-convolutional or transformer-based models

## Confidence

High confidence in the method's effectiveness against standard and adaptive attacks on tested datasets
Medium confidence in the model-agnostic claim due to limited architectural diversity in validation
Medium confidence in the computational efficiency claim without detailed runtime analysis
Low confidence in the generalizability to complex, real-world OCR scenarios without additional testing

## Next Checks
1. Evaluate TopoReformer on a large-scale, real-world OCR dataset (e.g., ICDAR, Street View Text) to assess practical applicability
2. Conduct runtime and memory overhead analysis across different hardware configurations to quantify deployment feasibility
3. Test the defense against adaptive attacks specifically designed to bypass the topological purification mechanism, such as attacks that preserve topological features while introducing semantic distortions