---
ver: rpa2
title: Large Language Models as Common-Sense Heuristics
arxiv_id: '2501.18816'
source_url: https://arxiv.org/abs/2501.18816
tags:
- walk
- action
- actions
- language
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel method that uses large language models
  (LLMs) to guide local search for planning tasks in a virtual household environment.
  The approach leverages the LLM's world knowledge by using its output as a heuristic
  for Hill-Climbing Search, enhanced with solution estimates to guide the search.
---

# Large Language Models as Common-Sense Heuristics
## Quick Facts
- arXiv ID: 2501.18816
- Source URL: https://arxiv.org/abs/2501.18816
- Reference count: 20
- Primary result: 22 percentage point improvement in task success rate using LLM-guided Hill-Climbing Search for virtual household planning

## Executive Summary
This paper presents a novel approach that leverages large language models as common-sense heuristics to guide local search algorithms for planning tasks in virtual household environments. The method uses LLM-generated world knowledge directly as heuristics for Hill-Climbing Search, enhanced with solution estimates to improve search efficiency. The approach demonstrates significant performance gains, achieving a 22 percentage point improvement in task success rate over similar systems while producing consistently executable plans without requiring intermediate translation steps.

## Method Summary
The approach integrates LLMs into the planning process by using their output as heuristics for local search algorithms. The system operates directly in the VirtualHome language, eliminating the need for intermediate translation. Hill-Climbing Search is enhanced with solution estimates derived from LLM outputs, allowing the search to be guided by the model's common-sense understanding of household tasks and object relationships. This direct integration enables more efficient exploration of the solution space while maintaining plan executability.

## Key Results
- Achieves 22 percentage point improvement in task success rate over similar systems
- Generates consistently executable plans without intermediate translation steps
- Demonstrates effective use of LLM world knowledge for guiding local search in complex environments

## Why This Works (Mechanism)
The approach works by leveraging the LLM's extensive world knowledge to provide common-sense heuristics that guide local search algorithms. The LLM's understanding of household tasks, object relationships, and typical action sequences informs the search process, helping it avoid dead ends and inefficient paths. By operating directly in the VirtualHome language, the method preserves the semantic richness of the LLM's output while eliminating potential errors from translation steps. The solution estimates component helps prioritize promising search directions, making the Hill-Climbing Search more effective at finding complete solutions.

## Foundational Learning
- VirtualHome language: Understanding the domain-specific language for household tasks and object interactions; needed for direct LLM integration; quick check: verify LLM outputs are valid VirtualHome commands
- Hill-Climbing Search: Local search algorithm that iteratively improves solutions; needed for efficient exploration; quick check: confirm search converges to valid plans
- Heuristic guidance: Using estimated solution quality to guide search direction; needed for efficient navigation of solution space; quick check: validate heuristics correlate with actual solution quality
- Solution estimates: Quantitative predictions of solution likelihood; needed for prioritizing search paths; quick check: verify estimates improve search efficiency
- Common-sense reasoning: LLM's ability to understand typical household task sequences; needed for generating useful heuristics; quick check: test LLM on household task comprehension
- Direct language integration: Bypassing translation layers; needed for preserving semantic information; quick check: compare performance with/without translation

## Architecture Onboarding
- Component map: LLM output generator -> Heuristic processor -> Hill-Climbing Search -> Solution validator
- Critical path: LLM description generation → Heuristic extraction → Search state evaluation → Plan execution
- Design tradeoffs: Direct VirtualHome integration vs. translation accuracy vs. computational overhead
- Failure signatures: Poor LLM descriptions → invalid heuristics → search failure; overly optimistic solution estimates → premature convergence; insufficient world knowledge → incomplete plans
- First experiments:
  1. Test LLM's ability to generate valid VirtualHome commands for basic household tasks
  2. Evaluate heuristic quality by comparing LLM-generated estimates against ground truth solution difficulty
  3. Measure search efficiency gains from solution estimates vs. standard Hill-Climbing

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single virtual household environment, limiting generalizability
- Performance dependent on LLM's common-sense knowledge quality and potential cultural biases
- Assumes deterministic environment behavior, which may not hold in real-world settings
- Baseline comparison lacks specification of selection criteria and state-of-the-art alternatives

## Confidence
- High confidence: Core methodology of using LLM outputs as heuristics for local search is sound and well-implemented
- Medium confidence: Reported performance improvements are valid for tested environment but may not generalize
- Low confidence: Claims about eliminating intermediate translation steps being universally beneficial lack broader validation

## Next Checks
1. Test the approach across multiple household simulation environments with varying layouts and object configurations to assess robustness
2. Evaluate performance degradation when using LLMs with different sizes or knowledge bases to understand sensitivity
3. Conduct ablation studies removing the solution estimates component to quantify its specific contribution to the 22 percentage point improvement