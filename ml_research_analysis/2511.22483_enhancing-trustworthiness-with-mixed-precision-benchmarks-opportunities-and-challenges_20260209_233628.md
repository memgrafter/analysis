---
ver: rpa2
title: 'Enhancing Trustworthiness with Mixed Precision: Benchmarks, Opportunities,
  and Challenges'
arxiv_id: '2511.22483'
source_url: https://arxiv.org/abs/2511.22483
tags:
- quantization
- trustworthiness
- dense
- arxiv
- metrics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work evaluates how low-precision quantization affects LLM
  trustworthiness, identifying instability in performance on metrics like adversarial
  robustness and fairness. It introduces a precision-ensemble voting approach that
  aggregates predictions from multiple bit-width variants of the same model, reducing
  refusal rates and improving robustness.
---

# Enhancing Trustworthiness with Mixed Precision: Benchmarks, Opportunities, and Challenges

## Quick Facts
- arXiv ID: 2511.22483
- Source URL: https://arxiv.org/abs/2511.22483
- Reference count: 40
- Key outcome: Precision-ensemble voting improves trustworthiness by up to 5.8% while maintaining accuracy

## Executive Summary
This work evaluates how low-precision quantization affects large language model trustworthiness across four dimensions: adversarial robustness, fairness, machine ethics, and out-of-distribution robustness. The authors find that low-bit quantization degrades trustworthiness more severely than standard accuracy, with GPTQ particularly prone to high refusal rates at 3-4 bits. To address this, they introduce a precision-ensemble voting approach that aggregates predictions from multiple bit-width variants of the same model. This ensemble method consistently improves trustworthiness performance by up to 5.8% over dense baselines while maintaining multi-domain accuracy. Results emphasize the need to evaluate trustworthiness under model compression and highlight opportunities for joint compression and trust-aware optimization, especially in multi-modal and safety-critical contexts.

## Method Summary
The approach applies AWQ and GPTQ post-training quantization at 3-, 4-, and 8-bit to LLaMA-2-Chat models. The precision-ensemble voting method generates responses in parallel from each quantized variant, filters refusals and invalid outputs based on task type, then applies unweighted majority voting with tie-breaking by highest precision. The method is evaluated across five benchmarks: MMLU (57 tasks), AdvGLUE++ (SST-2, QQP, MNLI), Adult dataset (fairness), ETHICS dataset (2,109 samples, machine ethics), and OOD robustness tasks. Accuracy and trustworthiness scores (0-100 scale per DecodingTrust framework) are measured for each quantized variant and the ensemble, with comparisons to dense baselines.

## Key Results
- Low-bit quantization (3-4 bit) degrades trustworthiness metrics more severely than standard accuracy
- GPTQ quantization shows higher refusal rates than AWQ at low bit-widths due to degraded in-context learning
- Precision-ensemble voting improves trustworthiness by up to 5.8% over dense baselines
- The approach maintains multi-domain accuracy while reducing variance across bit-widths
- AWQ is more robust than GPTQ at 3-4 bit for few-shot and instruction-following tasks

## Why This Works (Mechanism)

### Mechanism 1: Precision-Ensemble Voting
- Claim: Aggregating predictions from multiple precision variants improves trustworthiness metrics
- Mechanism: Runs 3-bit, 4-bit, and 8-bit quantized versions in parallel, filters invalid/refusal outputs, then applies unweighted majority voting
- Core assumption: Quantization-induced errors are partially independent across precision levels
- Evidence anchors: [abstract] "precision-ensemble voting approach...improves performance by up to 5.8%"; [section IV-C] "unweighted majority voting improves stability by reducing variance across bit-widths"
- Break condition: If errors become correlated across precisions, voting provides no benefit

### Mechanism 2: Refusal Filtering Before Aggregation
- Claim: Removing refusal responses before voting lowers measured refusal rates
- Mechanism: Discards empty, unparseable, or explicit refusal outputs before aggregation
- Core assumption: Refusals represent uncertainty or failure modes rather than correct behavior for standard tasks
- Evidence anchors: [section IV-B] "Filter refused candidates...for standard classification metrics, refusals are removed"
- Break condition: If refusals encode correct safety behavior, filtering may remove valid signals

### Mechanism 3: Differential Quantization Sensitivity
- Claim: Different trustworthiness metrics exhibit different degradation patterns under quantization
- Mechanism: AWQ preserves activation-salient channels, maintaining in-context learning at low bit-widths
- Core assumption: Trustworthiness metrics depend on capabilities differentially sensitive to quantization method
- Evidence anchors: [section III-C.4] "low-bit GPTQ-quantized models frequently produce invalid or abstaining outputs"; [section III-C.6] "AWQ is more robust at 4- and 3-bit"
- Break condition: For models where few-shot capability is less critical, AWQ vs GPTQ gap may narrow

## Foundational Learning

- Concept: Post-Training Quantization (PTQ) vs. Quantization-Aware Training (QAT)
  - Why needed here: The paper evaluates PTQ methods that compress without retraining
  - Quick check question: Why might PTQ preserve perplexity but degrade trustworthiness metrics requiring in-context learning?

- Concept: Trustworthiness Dimensions in LLMs
  - Why needed here: Each dimension responds differently to quantization and requires separate validation
  - Quick check question: If a model scores high on fairness but low on adversarial robustness, would you deploy it in safety-critical domains?

- Concept: Refusal Rate as a Trustworthiness Signal
  - Why needed here: High refusal rates can indicate either appropriate safety boundaries or degraded capability
  - Quick check question: Under what conditions should high refusal rates be interpreted as a feature rather than a bug?

## Architecture Onboarding

- Component map: Dense backbone -> Quantization module (3/4/8-bit) -> Parallel generation -> Filtering stage -> Voting aggregator
- Critical path: 1) Quantize dense model to target precisions (offline) 2) At inference, route prompt to all precision variants in parallel 3) Map outputs to discrete labels 4) Filter based on refusal detection 5) Aggregate via majority vote
- Design tradeoffs: Latency vs. trustworthiness (3x inference compute); memory (store multiple quantized variants); refusal handling (filtering improves accuracy but may remove valid safety refusals)
- Failure signatures: Correlated errors across precisions (voting provides no benefit); excessive refusals (ensemble returns REFUSED); tie with no clear majority (falls back to highest-precision prediction)
- First 3 experiments: 1) Replicate MMLU and trustworthiness benchmark results for LLaMA-2-13B with AWQ/GPTQ at 3/4/8-bit 2) Implement precision-ensemble voting on adversarial robustness and measure improvement 3) Ablate filtering stage: run voting with and without refusal filtering on machine ethics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can modality-aware mixed-precision quantization be designed for multi-modal LLMs?
- Basis in paper: [explicit] Section V-A identifies multi-modal trustworthiness as a challenge
- Why unresolved: This paper evaluates only text-only LLMs; cross-modal reasoning introduces additional complexity
- What evidence would resolve it: Benchmarks showing trustworthiness metrics across modalities under different precision schedules

### Open Question 2
- Question: Can trust-aware auto-compression pipelines jointly tune bit-width, sparsity, and decomposition rank while optimizing trustworthiness?
- Basis in paper: [explicit] Section V-B proposes automated sparsity search with trustworthiness in the objective
- Why unresolved: Current compression methods optimize for perplexity or accuracy; combining techniques with trustworthiness constraints remains unexplored
- What evidence would resolve it: A compression framework producing Pareto-optimal models on both efficiency and trustworthiness metrics

### Open Question 3
- Question: How can precision-ensemble voting be adapted for fairness metrics measuring inter-group disparities?
- Basis in paper: [inferred] Section IV-C explicitly excludes fairness from ensemble evaluation due to group-level measurement
- Why unresolved: Majority voting assumes per-instance correctness; fairness requires aggregate distributional properties
- What evidence would resolve it: An ensemble aggregation rule improving demographic parity and equalized odds scores

### Open Question 4
- Question: What are the latency-throughput trade-offs of precision-ensemble voting in latency-constrained deployment?
- Basis in paper: [inferred] The approach runs multiple models in parallel; Section V-C notes scheduling challenges
- Why unresolved: The paper reports accuracy gains but does not quantify inference overhead or optimal parallelization strategies
- What evidence would resolve it: End-to-end latency measurements under batched inference with single-model baseline comparisons

## Limitations
- Relies on post-hoc quantization without joint training, bounding improvements by base-model capabilities
- Assumes quantization errors are independent across bit-widths - a critical but untested assumption
- Treats refusals as uniformly undesirable, which may not hold in safety-critical domains
- Focuses on classification-style trustworthiness tasks; results may not generalize to generation or reasoning-heavy use cases
- 5.8% improvement represents best-case scenario; performance varies substantially across metrics and models

## Confidence
- **High confidence**: Low-bit quantization degrades trustworthiness metrics more severely than standard accuracy, particularly for GPTQ at 3-4 bits
- **Medium confidence**: Precision-ensemble voting mechanism improves trustworthiness by up to 5.8% with clear methodology but untested independence assumptions
- **Low confidence**: Claims of generalization to multi-modal or safety-critical contexts without supporting evaluation

## Next Checks
1. **Error correlation analysis**: Compute pairwise agreement matrix across 3-bit, 4-bit, and 8-bit predictions to test independence assumption
2. **Refusal behavior ablation**: Run ETHICS and OOD benchmarks with three variants (ensemble with filtering, ensemble treating refusals as valid labels, single-precision with refusals retained) to isolate filtering's contribution
3. **Cross-model generalization**: Apply precision-ensemble approach to Mistral-7B or Qwen-7B with different quantization method and compare improvement profile to LLaMA-2-13B