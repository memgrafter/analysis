---
ver: rpa2
title: Are Time Series Foundation Models Susceptible to Catastrophic Forgetting?
arxiv_id: '2510.00809'
source_url: https://arxiv.org/abs/2510.00809
tags:
- forgetting
- time
- learning
- series
- catastrophic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates catastrophic forgetting in Time Series
  Foundation Models (TSFMs), specifically focusing on the TimesFM model. The authors
  evaluate TimesFM's ability to retain knowledge when fine-tuned sequentially on multiple
  synthetic time series datasets with varying periodic structures.
---

# Are Time Series Foundation Models Susceptible to Catastrophic Forgetting?

## Quick Facts
- arXiv ID: 2510.00809
- Source URL: https://arxiv.org/abs/2510.00809
- Reference count: 26
- Primary result: TSFMs exhibit significant catastrophic forgetting when fine-tuned sequentially on time series tasks

## Executive Summary
This paper investigates catastrophic forgetting in Time Series Foundation Models (TSFMs), specifically focusing on the TimesFM model. The authors evaluate TimesFM's ability to retain knowledge when fine-tuned sequentially on multiple synthetic time series datasets with varying periodic structures. Using a two-stage continual learning setup, they measure performance degradation on previously learned tasks after fine-tuning on new tasks. Results show significant catastrophic forgetting, with Mean Absolute Error (MAE) on D1 increasing from 0.15 to 1.60 after fine-tuning on D2. The study reveals a fundamental stability-plasticity dilemma, where adaptation to new data comes at the cost of erasing prior knowledge.

## Method Summary
The authors evaluate TimesFM's performance across four synthetic time series datasets (D1, D2, D3, D4) with varying periodic structures. They employ a two-stage continual learning setup: first, the model is trained on D1 and D3 separately, then fine-tuned sequentially on D2 and D4. Performance is measured using Mean Absolute Error (MAE) on both new and previously learned tasks. The study systematically varies learning rates (10^-6 to 10^-3) and fine-tuning epochs (1-20) to analyze the stability-plasticity trade-off.

## Key Results
- TimesFM exhibits significant catastrophic forgetting when fine-tuned sequentially on new time series tasks
- MAE on previously learned task D1 increased from 0.15 to 1.60 after fine-tuning on D2
- Intermediate fine-tuning settings (10^-5 learning rate, 5-10 epochs) offer the best balance between stability and plasticity

## Why This Works (Mechanism)
The catastrophic forgetting observed in TSFMs stems from the fundamental tension between retaining previously learned patterns and adapting to new data distributions. When fine-tuned on new tasks, the model's parameters are updated to optimize performance on current data, which inadvertently degrades performance on earlier tasks. This stability-plasticity dilemma is particularly pronounced in TSFMs due to their complex architecture and the sequential nature of time series data.

## Foundational Learning
- Continual Learning: Why needed - to enable models to learn from evolving data streams without losing previous knowledge; Quick check - measure performance degradation on previous tasks after sequential fine-tuning
- Catastrophic Forgetting: Why needed - understanding when and how models lose previously acquired knowledge; Quick check - compare performance on old tasks before and after fine-tuning on new tasks
- Stability-Plasticity Trade-off: Why needed - balancing between retaining old knowledge and learning new patterns; Quick check - vary learning rates and epochs to find optimal balance

## Architecture Onboarding
Component map: Input Time Series -> TimesFM Encoder -> Task-specific Head -> Output Predictions
Critical path: The encoder-decoder architecture is crucial for maintaining temporal dependencies while allowing task-specific adaptations
Design tradeoffs: Larger models offer better performance but are more prone to catastrophic forgetting due to increased parameter space
Failure signatures: Sharp increase in MAE on previously learned tasks when fine-tuning on new data
First experiments: 1) Test on real-world time series datasets, 2) Evaluate across multiple TSFM architectures, 3) Investigate impact of task sequencing strategies

## Open Questions the Paper Calls Out
The paper does not explicitly call out any open questions in the provided content.

## Limitations
- Experiments focus exclusively on synthetic time series data with controlled periodic structures
- Evaluation uses a specific TSFM model (TimesFM) and particular task sequence
- Catastrophic forgetting is measured using MAE on synthetic datasets, which may not reflect practical applications

## Confidence
- High confidence in demonstrating catastrophic forgetting in TSFMs under sequential fine-tuning conditions
- Medium confidence in stability-plasticity trade-off characterization based on limited hyperparameter range
- Medium confidence in proposed intermediate fine-tuning settings as optimal

## Next Checks
1. Evaluate catastrophic forgetting on real-world time series datasets with diverse characteristics
2. Test the phenomenon across multiple TSFM architectures to determine generalizability
3. Investigate the impact of different task sequencing strategies and task similarity on catastrophic forgetting severity