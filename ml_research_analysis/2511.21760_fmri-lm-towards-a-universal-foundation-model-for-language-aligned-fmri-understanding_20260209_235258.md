---
ver: rpa2
title: 'fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding'
arxiv_id: '2511.21760'
source_url: https://arxiv.org/abs/2511.21760
tags:
- fmri
- text
- fmri-lm
- language
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: fMRI-LM introduces a foundational model for bridging fMRI and language
  through a three-stage framework. It employs a neural tokenizer to map fMRI into
  discrete tokens aligned with LLM embeddings, then adapts a pretrained LLM to jointly
  model fMRI tokens and synthetic fMRI-text pairs derived from imaging-based features
  (functional connectivity, gradients, ICA, graph metrics).
---

# fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding

## Quick Facts
- arXiv ID: 2511.21760
- Source URL: https://arxiv.org/abs/2511.21760
- Reference count: 40
- Primary result: fMRI-LM achieves strong zero-shot and few-shot performance across seven datasets, significantly outperforming supervised and foundation baselines in classification and regression tasks

## Executive Summary
fMRI-LM introduces a foundational model for bridging fMRI and language through a three-stage framework. It employs a neural tokenizer to map fMRI into discrete tokens aligned with LLM embeddings, then adapts a pretrained LLM to jointly model fMRI tokens and synthetic fMRI-text pairs derived from imaging-based features (functional connectivity, gradients, ICA, graph metrics). Finally, multi-task, multi-paradigm instruction tuning enables diverse downstream applications. Across seven datasets, fMRI-LM achieves strong zero-shot and few-shot performance, significantly outperforming supervised and foundation baselines in classification (e.g., up to 94.9% accuracy for sex prediction) and regression tasks, while demonstrating efficient adaptation with LoRA and robust generalization across tasks and datasets.

## Method Summary
fMRI-LM employs a three-stage framework to create a universal foundation model for fMRI-language alignment. First, a neural tokenizer maps continuous fMRI data into discrete tokens aligned with LLM embeddings. Second, a pretrained LLM is adapted to jointly model these fMRI tokens and synthetic fMRI-text pairs generated from imaging-derived features like functional connectivity and graph metrics. Third, multi-task, multi-paradigm instruction tuning enables flexible downstream applications. The model demonstrates strong zero-shot and few-shot performance across seven datasets, leveraging efficient adaptation through LoRA and showing robust generalization across tasks and datasets.

## Key Results
- fMRI-LM achieves strong zero-shot and few-shot performance across seven datasets
- Outperforms supervised and foundation baselines in classification and regression tasks
- Demonstrates efficient adaptation with LoRA and robust generalization across tasks and datasets

## Why This Works (Mechanism)
fMRI-LM leverages a neural tokenizer to convert continuous fMRI data into discrete tokens aligned with LLM embeddings, enabling joint modeling of brain activity and language. By incorporating synthetic fMRI-text pairs derived from imaging-based features, the model learns rich representations that bridge neural signals and linguistic concepts. Multi-task, multi-paradigm instruction tuning further enhances the model's flexibility, allowing it to adapt to diverse downstream applications. The use of LoRA enables efficient adaptation, while the model's design promotes generalization across tasks and datasets.

## Foundational Learning
- **fMRI preprocessing and feature extraction**: Converting raw brain scans into analyzable signals; needed for consistent input to the model; quick check: verify signal quality and noise reduction
- **Functional connectivity analysis**: Measuring correlations between brain regions; needed to capture network-level brain activity; quick check: assess network stability across subjects
- **Tokenization of continuous data**: Mapping continuous fMRI signals to discrete tokens; needed for integration with LLMs; quick check: validate token stability across subjects
- **Synthetic data generation**: Creating algorithmically generated fMRI-text pairs; needed to augment training data; quick check: evaluate synthetic-real data alignment
- **Multi-task learning**: Training on multiple tasks simultaneously; needed for generalization; quick check: monitor task-specific performance during training
- **LoRA adaptation**: Parameter-efficient fine-tuning; needed for efficient model adaptation; quick check: compare performance with and without LoRA

## Architecture Onboarding

**Component Map**
fMRI data -> Neural Tokenizer -> Discrete fMRI Tokens -> LLM Backbone -> Synthetic fMRI-Text Pairs -> Multi-Task Tuning -> Downstream Tasks

**Critical Path**
The critical path involves converting fMRI data to tokens, aligning them with LLM embeddings, incorporating synthetic pairs, and performing multi-task instruction tuning for downstream applications.

**Design Tradeoffs**
- Synthetic data generation vs. real fMRI-text alignment: Synthetic pairs enable pre-training but may not fully capture real brain-language relationships
- Tokenization granularity: Affects model's ability to capture fine-grained brain activity vs. computational efficiency
- Multi-task vs. task-specific training: Multi-task learning promotes generalization but may dilute task-specific performance

**Failure Signatures**
- Poor generalization across datasets or tasks
- Overfitting to synthetic data rather than real fMRI-language alignment
- Tokenization instability leading to inconsistent representations

**3 First Experiments**
1. Validate tokenization stability across subjects and datasets
2. Test zero-shot performance on a held-out dataset
3. Compare performance with and without synthetic fMRI-text pairs

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation restricted to seven datasets, limiting generalizability to other brain imaging paradigms or languages
- Reliance on synthetic fMRI-text pairs raises questions about ecological validity and real-world generalization
- High reported accuracies may reflect dataset-specific confounds rather than robust, generalizable features
- Cross-subject and cross-dataset generalization not exhaustively tested, and domain shifts or scanner/site variability not addressed
- Interpretability of model decisions not deeply explored, limiting understanding of brain-language relationships learned by the model

## Confidence
- **High**: Zero-shot and few-shot performance claims across multiple tasks and datasets; technical implementation details (pre-training, LoRA adaptation, multi-task tuning)
- **Medium**: Claims about generalization to unseen tasks and datasets; utility of synthetic fMRI-text pairs for pre-training
- **Low**: Claims about model's ability to capture genuine brain-language alignment or interpretability; robustness to real-world data variability

## Next Checks
1. Test fMRI-LM on additional, diverse fMRI datasets, including non-English languages and different imaging modalities, to assess true cross-dataset generalization
2. Conduct ablation studies removing synthetic fMRI-text pairs to quantify their actual contribution versus real fMRI-text alignment
3. Perform robustness testing across different MRI scanners, sites, and acquisition protocols to evaluate domain generalization and potential confounds