---
ver: rpa2
title: AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations
arxiv_id: '2601.12727'
source_url: https://arxiv.org/abs/2601.12727
tags:
- self-concept
- personality
- traits
- alignment
- conversation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates whether AI personality traits influence\
  \ users\u2019 self-concept during conversation. A randomized experiment (N=92) compared\
  \ conversations on personal versus non-personal topics with an LLM-based AI chatbot\
  \ (GPT-4o default personality)."
---

# AI-exhibited Personality Traits Can Shape Human Self-concept through Conversations

## Quick Facts
- arXiv ID: 2601.12727
- Source URL: https://arxiv.org/abs/2601.12727
- Reference count: 40
- Single LLM conversation can align human self-concept with AI personality traits

## Executive Summary
This study reveals that conversations with AI chatbots can significantly influence human self-concept, particularly when discussing personal topics. Using GPT-4o as the conversational partner, researchers found that participants' self-concepts aligned with the AI's personality traits after personal-topic conversations, with longer conversations producing stronger alignment effects. The study demonstrates a serial mediation pathway where perceived accuracy of AI responses and shared reality experiences lead to greater enjoyment and deeper personality alignment.

## Method Summary
The researchers conducted a randomized experiment with 92 participants who engaged in conversations with GPT-4o about either personal or non-personal topics. Participants' Big Five personality traits were measured before and after conversations, along with their perceptions of the AI's personality. The study tracked conversation length and collected measures of perceived accuracy and shared reality experience to test the proposed mediation pathway. All data collection and analysis followed pre-registered protocols to ensure methodological rigor.

## Key Results
- Participants' self-concepts aligned with AI personality traits after personal-topic conversations
- Alignment effect strengthened with longer conversation duration
- Shared reality experience and perceived accuracy mediated enjoyment and alignment effects

## Why This Works (Mechanism)
The mechanism operates through conversational dynamics where users develop perceived accuracy of AI responses and shared reality experiences during personal discussions. These factors increase conversation enjoyment, which reinforces the alignment between human and AI personality traits. The effect is amplified when conversations extend over longer durations, allowing more opportunities for personality convergence.

## Foundational Learning

**Self-concept**: An individual's understanding of their own personality and traits. Needed to measure the primary outcome of personality alignment. Quick check: Pre-post conversation personality assessments should show measurable changes.

**Shared reality experience**: The sense of mutual understanding and agreement during conversation. Critical for understanding the mediation pathway. Quick check: Measured through agreement and validation indicators during conversation.

**Perceived accuracy**: Users' evaluation of how well the AI understands and responds to them. Fundamental to the enjoyment-mediation pathway. Quick check: Correlates with conversation length and topic depth.

## Architecture Onboarding

**Component map**: Human self-concept -> AI personality exposure -> Conversation dynamics (accuracy, shared reality) -> Enjoyment -> Self-concept alignment

**Critical path**: Personal topic conversation -> Perceived accuracy -> Shared reality experience -> Enjoyment -> Personality alignment

**Design tradeoffs**: Balancing conversation engagement with ethical concerns about personality influence. The study prioritizes understanding influence mechanisms while acknowledging risks.

**Failure signatures**: Absence of alignment effects in non-personal conversations, reduced effects with shorter conversations, or lack of mediation through accuracy and shared reality.

**First experiments**: 
1. Test personality alignment with different AI models and custom personalities
2. Examine resistance mechanisms in extended conversation scenarios
3. Compare AI influence effects with human conversation controls

## Open Questions the Paper Calls Out
None

## Limitations
- Single AI model (GPT-4o) used, limiting generalizability to other systems
- No human conversation control group for comparison
- Small sample size and single-session duration restrict understanding of long-term effects

## Confidence

**High confidence**: Immediate personality alignment effects during personal-topic conversations
**Medium confidence**: Mediation pathway through accuracy and shared reality experience
**Medium confidence**: Relationship between conversation length and alignment strength

## Next Checks

1. Replicate with multiple AI models and custom personalities to test robustness across different system designs
2. Conduct longitudinal studies tracking self-concept stability and resistance mechanisms beyond single-session interactions
3. Compare AI influence effects with human-to-human conversation controls to establish whether observed alignment is unique to AI interactions or represents general conversational influence