---
ver: rpa2
title: 'RAG Meets Temporal Graphs: Time-Sensitive Modeling and Retrieval for Evolving
  Knowledge'
arxiv_id: '2510.13590'
source_url: https://arxiv.org/abs/2510.13590
tags:
- temporal
- time
- retrieval
- answer
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper
---

# RAG Meets Temporal Graphs: Time-Sensitive Modeling and Retrieval for Evolving Knowledge

## Quick Facts
- arXiv ID: 2510.13590
- Source URL: https://arxiv.org/abs/2510.13590
- Reference count: 40
- Primary result: TG-RAG achieves 0.599 Correct score on ECT-QA, outperforming static RAG baselines by 0.217

## Executive Summary
TG-RAG addresses the challenge of retrieving time-sensitive information from evolving knowledge sources by representing facts as timestamped edges in a temporal graph. The system builds a bi-level index combining a temporal knowledge graph (TK graph) with a hierarchical time graph, enabling efficient updates and precise retrieval of facts at specific time points. Experiments on the ECT-QA dataset demonstrate significant improvements in accuracy for both specific factual queries and abstract trend summarization, with update costs reduced by approximately 20x compared to full re-indexing.

## Method Summary
TG-RAG indexes evolving knowledge by extracting temporal quadruples (entity₁, entity₂, relation, timestamp) from document chunks and organizing them into a bi-level graph structure. The Temporal Knowledge Graph captures relationships between entities with time annotations, while the Time Hierarchy Graph organizes time nodes (year → quarter → month → day) to enable efficient report generation and updates. During retrieval, the system identifies the temporal scope of queries, performs personalized PageRank (PPR) on the time-filtered subgraph for local retrieval, or uses hierarchical time summaries for global retrieval of trends. The approach relies on LLM-based extraction, embedding similarity for graph positioning, and LLM synthesis for answering.

## Key Results
- TG-RAG achieves 0.599 Correct score on ECT-QA, compared to 0.382 for static RAG baselines
- Update cost reduced from 30.0M/7.8M tokens (full re-indexing) to 1.6M/2.0M tokens (incremental updates)
- Temporal Coverage of 0.808 for abstract trend queries, outperforming baseline methods
- Refusal rate of 0.001, significantly lower than static RAG approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representing facts as timestamped edges disambiguates semantically similar but temporally distinct information.
- Mechanism: The system extracts temporal quadruples (entity₁, entity₂, relation, τ) rather than static triples. Multiple facts between the same entity pair at different times become parallel edges, each anchored to a time node in the hierarchy. This bypasses vector embedding similarity limitations where "Revenue in 2021" and "Revenue in 2022" cluster indistinguishably.
- Core assumption: The extraction LLM can accurately identify and normalize temporal expressions (e.g., "Q3 2020" → "2020-Q3") from unstructured text.
- Evidence anchors:
  - [abstract]: "The temporal graph explicitly represents identical facts at different times as distinct edges to avoid ambiguity"
  - [section III-A-2]: "Multiple facts between the same entity pair at different times are kept as parallel temporal edges"
  - [corpus]: Related work (T-GRAG, DyG-RAG) addresses temporal conflicts but this specific quadruple+edge approach is not directly validated externally
- Break condition: If temporal expressions in documents are ambiguous, inconsistent, or outside LLM's normalization capability, edge disambiguation fails.

### Mechanism 2
- Claim: Hierarchical time summaries with incremental propagation enable efficient updates without full re-indexing.
- Mechanism: Time nodes form a hierarchy (year → quarter → month → day). When new documents arrive, only new leaf nodes and their ancestors regenerate reports. Unaffected branches remain unchanged. This constrains update cost to O(log depth) along affected paths rather than O(corpus size).
- Core assumption: New knowledge primarily creates new time nodes rather than retroactively modifying historical summaries.
- Evidence anchors:
  - [abstract]: "The time hierarchy graph allows only generating reports for new leaf time nodes and their ancestors, ensuring effective and efficient updates"
  - [Table IV]: Update cost reduced from 30.0M/7.8M tokens (GraphRAG full regeneration) to 1.6M/2.0M tokens (TG-RAG incremental)
  - [corpus]: No external validation; comparable systems in corpus not evaluated on incremental update cost
- Break condition: If updates frequently require backfilling historical nodes or restructuring the time hierarchy, incremental benefits diminish.

### Mechanism 3
- Claim: Temporal scoping via query-centric time identification + PPR ranking improves retrieval precision.
- Mechanism: First, LLM extracts temporal expressions from query and aligns to time nodes T_q. Second, PPR propagates relevance from temporally-filtered seed entities across the subgraph. Edge scores zero out if timestamp falls outside T_q. This two-stage filter (semantic → temporal) reduces noise from temporally irrelevant but semantically similar chunks.
- Core assumption: Queries contain extractable temporal constraints; PPR correctly identifies entity relevance within the subgraph.
- Evidence anchors:
  - [Table VII]: Removing temporal retrieval drops Correct score from 0.599 to 0.382 and spikes Refusal rate to 0.423
  - [section III-B-3]: "edges with τ ∉ T_q receive zero score"
  - [corpus]: HippoRAG2 also uses PPR but lacks temporal filtering; direct mechanism comparison unavailable
- Break condition: If query temporal scope is implicit or requires multi-hop inference to determine, time identification fails and retrieval degrades to non-temporal baseline.

## Foundational Learning

- Concept: **Temporal Knowledge Graphs (TKGs)**
  - Why needed here: TG-RAG extends static KGs by timestamping edges. Understanding how TKGs differ from static KGs (where triples lack time) clarifies why conventional RAG conflates facts across time.
  - Quick check question: Given triples (Company, revenue, $10M) and (Company, revenue, $15M), can you determine which year each applies to? (Answer: No—static KGs lose this information.)

- Concept: **Personalized PageRank (PPR)**
  - Why needed here: Local retrieval uses PPR with seed entities to propagate relevance scores. Without understanding PPR, the scoring function s(ε) = 1[τ∈T_q](s(v₁) + s(v₂)) is opaque.
  - Quick check question: If seed set V_q^t contains entity "Western Digital" and graph has edges to "Revenue" and "EPS", which entity receives higher PPR score if both edges connect to query-relevant time nodes? (Answer: Depends on graph structure and edge weights; PPR spreads preference from seeds through random walks.)

- Concept: **Incremental Indexing vs. Full Re-indexing**
  - Why needed here: The paper's efficiency claim hinges on updating only affected time nodes. Distinguishing incremental (append-only, localized updates) from full re-indexing (rebuild entire structure) is essential for evaluating cost claims.
  - Quick check question: If a document from 2022 is corrected in 2025, does TG-RAG's incremental update handle this efficiently? (Answer: No—corrections to historical nodes would require regenerating ancestor summaries, potentially many paths. Design assumes forward-time growth.)

## Architecture Onboarding

- Component map:
```
[Incoming Corpus] → Chunking → Temporal Quadruple Extraction (LLM)
                                        ↓
                            [Temporal Knowledge Graph G_K] ← entities, timestamped edges
                                        ↕ (cross-layer edges)
                            [Time Hierarchy Graph G_T] ← year/quarter/month/day nodes
                                        ↓
                            Time Report Generation (LLM, bottom-up)
                                        ↓
                            [Bi-Level Temporal Graph Index]
                                        ↓
[User Query] → Query-Centric Time Identification (LLM) → T_q
                                        ↓
              Dynamic Subgraph Positioning (embedding similarity, top-K edges)
                                        ↓
              ┌─────────────────┬─────────────────┐
              ↓                 ↓                 ↓
        Local Retrieval   Global Retrieval   (both modes available)
        (PPR + chunk      (time reports +
         scoring)          point extraction)
              └─────────────────┴─────────────────┘
                              ↓
                    Answer Generation (LLM)
```

- Critical path:
1. **Indexing**: Temporal quadruple extraction accuracy directly determines graph quality—if timestamps are wrong or missed, retrieval fails downstream.
2. **Query time**: Time identification must correctly map query temporal expressions to T_q nodes; misalignment causes edge zeroing or missed evidence.
3. **Retrieval**: PPR seed set V_q^t must contain relevant entities; empty or wrong seeds produce low scores across board.

- Design tradeoffs:
1. **Time granularity vs. storage**: Finer granularity (day-level) increases time nodes and report generation cost but improves precision for day-specific queries. Paper uses quarter-level for ECT-QA.
2. **Local vs. global retrieval**: Local retrieval excels at specific factual queries (Correct: 0.599); global retrieval targets abstract trend questions. Choosing wrong mode degrades performance.
3. **LLM dependency**: Quadruple extraction, time identification, and report generation all rely on LLM accuracy. Latency and cost scale with corpus size and query complexity.

- Failure signatures:
1. **Temporal extraction failure**: If LLM extracts wrong timestamps (e.g., "Q3 2023" → "2023-Q2"), edges connect to wrong time nodes, retrieval returns wrong-year facts.
2. **Query time identification failure**: Query "revenue before the acquisition" requires inferring implicit time boundary; if LLM fails, T_q is empty or wrong, edge scores zero out incorrectly.
3. **PPR seed sparsity**: If semantically similar edges don't connect to query entities, V_q^t is sparse, PPR scores low, retrieval returns empty or weak context.
4. **Update backfill cascade**: Correcting historical documents triggers ancestor report regeneration up to root; large corrections become near-full re-indexing.

- First 3 experiments:
1. **Sanity check—temporal quadruple extraction**: Take 10 document chunks with known temporal facts. Run extraction prompt. Manually verify (entity₁, entity₂, relation, τ) accuracy. Target: >90% timestamp normalization correct.
2. **Retrieval mode ablation**: Run 20 specific queries and 20 abstract queries. Compare local-only, global-only, and combined retrieval. Confirm local wins on specific (Correct >0.5), global wins on abstract (Temporal Coverage >0.8 vs baselines).
3. **Incremental update stress test**: Index base corpus (2020-2023). Inject 2024 documents. Measure token cost and compare to full re-indexing baseline. Verify cost reduction matches paper's ~20x improvement (30M → 1.6M prompt tokens).

## Open Questions the Paper Calls Out

- **Question**: How does TG-RAG perform on datasets with implicit or relative temporal markers compared to the explicit timestamps found in financial transcripts?
- **Basis in paper**: [explicit] The paper introduces ECT-QA derived from earnings calls which contain structured financial timestamps, and notes that retrieval on generic datasets required removing temporal filtering when no time scope was found.
- **Why unresolved**: The framework is optimized for explicit extraction ("2023 Q1"). It is unclear if the LLM-based extraction module can robustly handle vague temporal cues (e.g., "last year," "recently") without normalized timestamps, which limits its applicability to less structured domains.
- **What evidence would resolve it**: Evaluation results on a dataset specifically curated with relative temporal expressions requiring complex resolution to absolute timestamps.

## Limitations
- Temporal extraction accuracy heavily depends on LLM's ability to normalize diverse temporal expressions, which may fail on ambiguous or relative time references
- The time hierarchy granularity (quarter-level) may not generalize to domains requiring finer temporal resolution (day-level or event-level)
- PPR-based retrieval assumes seed entities connect to temporally relevant edges, which may fail for implicit or multi-hop temporal reasoning queries
- Incremental update benefits assume primarily forward-time knowledge additions; historical corrections trigger costly ancestor regeneration cascades

## Confidence
- **High confidence**: Temporal graph structure effectively disambiguates same-entity facts across different times (validated by correct score improvement from 0.382 to 0.599)
- **Medium confidence**: Local PPR retrieval with temporal scoping improves precision for specific factual queries (depends on LLM temporal extraction quality)
- **Medium confidence**: Incremental updates provide significant efficiency gains (measured token reduction shows ~20x improvement, but assumes mostly forward-time additions)

## Next Checks
1. **Temporal extraction robustness**: Test extraction accuracy across diverse temporal expressions (relative times, fiscal vs calendar years, ambiguous formats) to quantify LLM dependency risk
2. **Cross-domain generalizability**: Apply TG-RAG to a non-financial corpus with different temporal patterns (e.g., news events with day-level resolution) to assess granularity limitations
3. **Historical update stress test**: Simulate document corrections spanning multiple years to measure actual vs. claimed incremental update efficiency under backfill conditions