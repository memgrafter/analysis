---
ver: rpa2
title: Improving Image Captioning by Mimicking Human Reformulation Feedback at Inference-time
arxiv_id: '2501.04513'
source_url: https://arxiv.org/abs/2501.04513
tags:
- feedback
- captions
- reformulation
- image
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach for improving generative
  models by using human reformulation feedback at inference time, specifically for
  image captioning. The authors collect a dataset of human-written reformulations
  that correct errors in model-generated captions, training models to mimic this feedback.
---

# Improving Image Captioning by Mimicking Human Reformulation Feedback at Inference-time

## Quick Facts
- arXiv ID: 2501.04513
- Source URL: https://arxiv.org/abs/2501.04513
- Reference count: 26
- Authors: Uri Berger; Omri Abend; Lea Frermann; Gabriel Stanovsky
- Primary result: Achieves state-of-the-art performance on German image captioning and style transfer tasks using inference-time reformulation models trained on human feedback

## Executive Summary
This paper introduces a novel approach for improving generative models by using human reformulation feedback at inference time, specifically for image captioning. The authors collect a dataset of human-written reformulations that correct errors in model-generated captions, training models to mimic this feedback. They demonstrate that applying these reformulation models to existing captioning systems results in improved captions, especially for weaker models or in low-resource languages like German. The approach achieves state-of-the-art performance on German image captioning and style transfer tasks, validated through both automatic metrics and detailed human evaluation.

## Method Summary
The method involves fine-tuning a pre-trained multimodal model (mPLUG) on human-written reformulation data, where annotators correct errors in existing captions while preserving their structure. During inference, the reformulated model takes both the image and the original caption as input, generating a corrected version. This approach doesn't require training the base captioning model itself, instead adding a separate reformulation step that acts as an inference-time "refiner" rather than a generator.

## Key Results
- The reformulation model improves captions for weak base models (e.g., vit_gpt2) but shows mixed results for strong models (e.g., BLIP)
- Significant improvements in German captioning through a translate-reformulate-translate pipeline
- Human evaluation shows the method increases faithfulness and accuracy while preserving style similarity
- Achieves state-of-the-art performance on German image captioning and FlickrStyle style transfer tasks

## Why This Works (Mechanism)

### Mechanism 1: Conditional Refinement via Dual-Input Attention
The reformulation model improves captions by conditioning on both visual input and linguistic input to predict corrections. The model acts as a "fixer" rather than a "generator," attending to specific errors while grounding corrections in image evidence. The core assumption is that the model can learn to distinguish between necessary corrections (grounded in the image) and unnecessary changes, maintaining semantic structure where possible.

### Mechanism 2: Asymmetric Skill Transfer (Correction vs. Generation)
Learning to correct errors in existing captions is computationally cheaper and data-efficient than learning to generate perfect captions from pixels alone. The refiner "piggybacks" on the generator's ability to produce syntax and general scene descriptions, focusing on specific error modes. The core assumption is that the base captioning model produces output that is "good enough" structurally to be editable.

### Mechanism 3: Cross-Lingual Anchoring via Pivot Translation
In low-resource settings like German captioning, the reformulation mechanism leverages superior English model performance to correct translations. The pipeline uses high-quality English reformulation space to scrub errors introduced by weaker non-English base models. The core assumption is that translation models preserve the intent of corrections during back-translation.

## Foundational Learning

- **Concept: Sequence-to-Sequence (Seq2Seq) with Multimodal Conditioning**
  - Why needed here: The reformulation model is technically a multimodal Seq2Seq model (mPLUG) that conditions on both image embeddings and text prefixes
  - Quick check question: If you input an image and a text caption, does the model generate text based on the image alone, the text alone, or a fused representation of both?

- **Concept: Inference-Time Intervention (vs. Training-Time Fine-Tuning)**
  - Why needed here: The core novelty is freezing the base model and intervening at inference, distinguishing between training a reward model and training a refiner model
  - Quick check question: Why does this method not require updating the weights of the initial captioning model (e.g., BLIP or ClipCap)?

- **Concept: Levenshtein Distance and Edit Operations**
  - Why needed here: The paper analyzes performance based on "minimal changes," measuring distance between original and reformulated text to evaluate the "style preservation" vs. "correction" tradeoff
  - Quick check question: If the Levenshtein distance between the original and reformulated caption is 0, what does that imply about the base model's output for that sample?

## Architecture Onboarding

- **Component map:** Image + Base Caption -> Reformulation Model -> Final Caption
- **Critical path:** 1) Collect dataset of (Image, Bad Caption, Good Caption) triplets 2) Fine-tune mPLUG on triplets 3) Run inference: Base Model -> Raw Caption + Image -> Reformulation Model -> Final Caption
- **Design tradeoffs:** Using a separate reformulator adds latency to inference but saves massive training compute; relies on quality of human annotations
- **Failure signatures:** Strong base degradation where reformulator introduces noise to correct captions; translation drift in cross-lingual pipelines
- **First 3 experiments:**
  1. Ablation on input: Compare reformulator performance with (Image + Empty String) vs. (Image + Base Caption)
  2. Error analysis by base model strength: Compare performance gains across weak (vit_gpt2) vs. strong (BLIP) models
  3. Style transfer injection: Train reformulator on FlickrStyle dataset to verify tone changes without altering factual content

## Open Questions the Paper Calls Out
1. Does training a reformulation model natively in a non-English language yield better factual improvements than the translate-reformulate-translate pipeline?
2. Can the reformulation framework effectively improve factuality in specialized "challenge domains" like medical imaging?
3. How does the performance of the inference-time reformulation method compare to directly fine-tuning the base captioning model on the same human correction data?

## Limitations
- Cross-lingual results depend on translation pipeline quality, which introduces uncontrolled variables
- Small dataset size (1,405 samples) raises questions about generalization beyond curated error types
- Computational efficiency claim assumes base model is already trained, not addressing human data collection costs

## Confidence
- **High Confidence:** Core mechanism of inference-time reformulation using human feedback is technically sound and well-validated on English datasets
- **Medium Confidence:** German captioning performance gains depend on translation pipeline quality not fully characterized
- **Medium Confidence:** Computational efficiency claims assume pre-trained base model, not addressing data collection costs

## Next Checks
1. Cross-Lingual Robustness Test: Apply reformulation pipeline to German captions using German reformulator trained directly on German data to isolate gains from mechanism vs. translation
2. Base Model Strength Sweep: Systematically test reformulation across broader range of base model qualities to map boundary where reformulation becomes harmful
3. Error Type Attribution: Analyze which specific error types (hallucinations, missing attributes, style mismatches) reformulator actually corrects vs. introduces using human evaluation data