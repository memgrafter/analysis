---
ver: rpa2
title: 'CopyQNN: Quantum Neural Network Extraction Attack under Varying Quantum Noise'
arxiv_id: '2504.00366'
source_url: https://arxiv.org/abs/2504.00366
tags:
- quantum
- data
- learning
- training
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of model extraction attacks
  on Quantum Neural Networks (QNNs) deployed via QNN-as-a-Service (QNNaaS) platforms
  on noisy intermediate-scale quantum (NISQ) computers. The core method, CopyQNN,
  introduces a three-step data cleaning pipeline to filter noisy data based on variance
  across multiple query rounds, followed by a novel integration of quantum contrastive
  learning and transfer learning to train accurate substitute QNNs with limited data.
---

# CopyQNN: Quantum Neural Network Extraction Attack under Varying Quantum Noise

## Quick Facts
- **arXiv ID:** 2504.00366
- **Source URL:** https://arxiv.org/abs/2504.00366
- **Reference count:** 32
- **Primary result:** CopyQNN achieves 8.73% average performance improvement and 90× query reduction in QNN extraction attacks under varying quantum noise

## Executive Summary
This paper presents CopyQNN, a novel framework for extracting quantum neural network (QNN) models deployed on noisy intermediate-scale quantum (NISQ) computers. The framework addresses the challenge of varying quantum noise in QNN-as-a-Service (QNNaaS) platforms by introducing a three-step data cleaning pipeline and integrating quantum contrastive learning with transfer learning. CopyQNN effectively filters noisy data based on variance across multiple query rounds and trains accurate substitute QNNs with significantly reduced query requirements.

## Method Summary
CopyQNN introduces a comprehensive approach to QNN extraction that combines data cleaning, quantum contrastive learning, and transfer learning. The method begins with a variance-based data cleaning pipeline that filters noisy data by querying multiple rounds and selecting instances with consistent variance. This is followed by quantum contrastive learning to learn better representations from limited data, and transfer learning to leverage pre-trained models for improved accuracy. The framework is specifically designed to handle the varying noise characteristics of NISQ computers while maintaining attack stealth.

## Key Results
- Achieves 8.73% average performance improvement across all tasks compared to state-of-the-art QLeak
- Reduces required queries by 90× while maintaining extraction accuracy
- Effectively handles varying quantum noise on IBM_Brisbane NISQ computer

## Why This Works (Mechanism)
CopyQNN works by addressing the fundamental challenge of quantum noise in QNN extraction attacks. The variance-based data cleaning pipeline identifies and removes noisy data points that would otherwise degrade model accuracy. Quantum contrastive learning helps the substitute model learn robust representations despite limited training data, while transfer learning accelerates convergence and improves performance. The integration of these components creates a synergistic effect that enables accurate model extraction with fewer queries under realistic noise conditions.

## Foundational Learning

### Quantum Noise in NISQ Computers
- **Why needed:** Understanding how quantum noise affects measurement outcomes and model predictions
- **Quick check:** Compare measurement distributions with and without noise on simple quantum circuits

### Quantum Contrastive Learning
- **Why needed:** Enables representation learning from limited data in quantum feature spaces
- **Quick check:** Train a contrastive model on synthetic quantum data and measure embedding quality

### Transfer Learning in Quantum Context
- **Why needed:** Leverages pre-trained quantum models to improve convergence on target tasks
- **Quick check:** Fine-tune a pre-trained QNN on a related task and measure performance gain

## Architecture Onboarding

### Component Map
QNNaaS platform -> Query interface -> Data cleaning pipeline -> Quantum contrastive learning -> Transfer learning -> Substitute QNN

### Critical Path
1. Query generation and execution on NISQ device
2. Data cleaning based on variance analysis
3. Quantum contrastive learning training
4. Transfer learning fine-tuning
5. Substitute QNN evaluation

### Design Tradeoffs
- Query efficiency vs. data quality: More queries improve cleaning but increase detection risk
- Cleaning threshold selection: Balancing noise removal with data retention
- Pre-trained model selection: Task similarity vs. model complexity

### Failure Signatures
- High variance in cleaned data indicates ineffective noise filtering
- Poor convergence in contrastive learning suggests insufficient data quality
- Low transfer learning performance indicates poor pre-trained model-task alignment

### First Experiments to Run
1. Baseline QLeak extraction without data cleaning on varying noise conditions
2. Data cleaning pipeline validation with synthetic noisy data
3. Quantum contrastive learning performance with limited training samples

## Open Questions the Paper Calls Out

## Limitations
- Results are limited to single NISQ device (IBM_Brisbane), limiting generalizability
- Performance improvements lack confidence intervals for statistical significance assessment
- "Attack stealth" claims are qualitative without quantitative detection probability measures
- Framework scalability to larger QNN architectures remains untested

## Confidence

| Claim | Confidence |
|-------|------------|
| 8.73% average performance improvement | Medium |
| 90× query reduction | Medium |
| Stealth maintenance | Low |
| Generalizability across hardware | Medium-Low |

## Next Checks
1. Test CopyQNN across multiple NISQ devices with varying noise characteristics to assess hardware dependence
2. Conduct statistical significance testing with confidence intervals on performance improvements
3. Implement and test against quantum adversarial detection mechanisms to quantify actual stealth capabilities