---
ver: rpa2
title: Automated Neuron Labelling Enables Generative Steering and Interpretability
  in Protein Language Models
arxiv_id: '2507.06458'
source_url: https://arxiv.org/abs/2507.06458
tags:
- protein
- neuron
- features
- neurons
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first automated framework for labeling
  every neuron in a protein language model with biologically grounded natural language
  descriptions. Unlike prior approaches relying on sparse autoencoders or manual annotation,
  the method scales to hundreds of thousands of neurons, revealing that individual
  neurons are selectively sensitive to diverse biochemical and structural properties.
---

# Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models

## Quick Facts
- arXiv ID: 2507.06458
- Source URL: https://arxiv.org/abs/2507.06458
- Authors: Arjun Banerjee; David Martinez; Camille Dang; Ethan Tam
- Reference count: 30
- Key outcome: First automated framework for labeling every neuron in a protein language model with biologically grounded natural language descriptions, enabling targeted protein generation

## Executive Summary
This work introduces the first automated framework for labeling every neuron in a protein language model (PLM) with biologically grounded natural language descriptions. Unlike prior approaches relying on sparse autoencoders or manual annotation, the method scales to hundreds of thousands of neurons, revealing that individual neurons are selectively sensitive to diverse biochemical and structural properties. The authors then develop a novel neuron activation-guided steering method to generate proteins with desired traits, enabling convergence to target biochemical properties like molecular weight and instability index as well as secondary and tertiary structural motifs, including alpha helices and canonical Zinc Fingers. Analysis of labeled neurons across different model sizes reveals PLM scaling laws and a structured neuron space distribution.

## Method Summary
The framework combines three components: an Explainer model (GPT-4.1-nano) that generates candidate natural language descriptions for neurons based on top-activating protein sequences, a Simulator model (fine-tuned Longformer) that validates these descriptions by predicting activation scores from text, and a steering mechanism that applies affine transformations to neuron activations during iterative masked inpainting generation. The method first collects neuron activations from ESM-2 on 500K UniProt sequences, then uses the simulator to identify the most correlated natural language description for each neuron, and finally applies targeted interventions to guide protein generation toward desired biochemical and structural properties.

## Key Results
- Automated labeling achieves high correlation between simulator predictions and actual activations, validating biological interpretability of individual neurons
- Steering method successfully shifts scalar properties (molecular weight, GRAVY, instability index) in predictable directions
- Structural motif steering produces alpha helices and C2H2 zinc fingers, though generated proteins exhibit unrealistic folding energies (ΔG > 100 kCal/mol vs. typical 5-15 kCal/mol)

## Why This Works (Mechanism)

### Mechanism 1: Simulation-Grounded Hypothesis Verification
The framework identifies biologically meaningful neurons by validating natural language hypotheses against actual activation patterns. An Explainer model generates candidate text descriptions, and a Simulator model predicts activation scores for held-out sequences given these descriptions. The hypothesis yielding the highest Pearson correlation between predicted and actual activations is selected, filtering out spurious correlations.

### Mechanism 2: Activation-Space Intervention via Affine Transformation
Modulating neuron activations with an affine transformation (Ax + B) during the forward pass shifts the output distribution to express targeted biological properties. During iterative masked inpainting generation, the method identifies neurons labeled with the desired trait and applies scaling and bias to force the model's internal state toward representations consistent with the target property.

### Mechanism 3: Hierarchical Feature Localization
Biological features are structured hierarchically by layer depth, allowing for targeted interventions depending on the complexity of the desired trait. Local biochemical properties peak in early layers, structural motifs in middle layers, and functional roles in later layers, enabling layer-specific steering for different types of properties.

## Foundational Learning

- **Protein Language Models (PLMs) & Masked Language Modeling (MLM)**: PLMs like ESM-2 are trained to predict missing amino acids from context. Understanding this is crucial because the generator uses iterative "masked inpainting" - without this knowledge, the mechanism of "steering via resampling masked tokens" is opaque. Quick check: If you mask a residue in the middle of a sequence and change the hidden state of a "zinc finger" neuron, how does the model decide which amino acid to fill in?

- **Mechanistic Interpretability (Polysemanticity)**: The paper argues against the "superposition" hypothesis by assuming neurons are individually labelable. Understanding that neurons often encode multiple features (polysemantic) is crucial to evaluating why the authors need a "Simulator" to disentangle valid labels from noise. Quick check: Why might a single neuron activate for both "high hydrophobicity" and "zinc fingers"? Does the paper's method account for this?

- **Forward Hooks & Activation Steering**: The core technical intervention modifies hidden states during a forward pass. In PyTorch, this involves intercepting the output of a specific linear layer, modifying it by Ax+B, and ensuring the rest of the model uses the modified value. Quick check: How would you implement this in PyTorch to intercept and modify a specific layer's output?

## Architecture Onboarding

- **Component map**: UniProt sequences + BioPython features -> ESM-2 (Target PLM) -> Activation Logs -> GPT-4.1-nano (Explainer) -> Longformer (Simulator) -> Validated Labels; Random Sequence -> ESM-2 (with Forward Hooks) -> Affine Transformation on Target Neurons -> Resample Masked Tokens

- **Critical path**: The fidelity of the Simulator is the bottleneck. If the correlation between the simulator's prediction and actual activations is weak, the labels are noise, and steering will fail (random behavior).

- **Design tradeoffs**: The authors trade the decomposition power of Sparse Autoencoders (SAEs) for direct interpretability of the neuron basis to avoid training additional models which can have optimization instability. The method uses iterative decoding (gradient-free on weights) rather than backpropagation on sequence embeddings, prioritizing stability and discrete sequence constraints over optimization speed.

- **Failure signatures**: High ΔG values indicate structurally invalid proteins; label oversimplification may produce generic descriptions that fail to differentiate specific structural nuances; simulator failure leads to random steering behavior.

- **First 3 experiments**: 1) Verify Simulator Correlation by checking Pearson correlation on held-out test set; 2) Sanity Check Steering with scalar properties like "High Molecular Weight" vs. "Low Molecular Weight"; 3) Layer Ablation by applying steering only to middle layers when generating "Alpha Helix" and comparing to global application.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating a reinforcement learning loop with a structural prediction oracle (e.g., AlphaFold2) resolve the low foldability of generated proteins?
- Basis in paper: The authors note in "Limitations and Future Work" that generated proteins currently exhibit unrealistic ΔG values and propose using a structure prediction model as an oracle to provide reward signals for foldability.
- Why unresolved: Current steering methods successfully generate target motifs but result in thermodynamically unstable sequences with ΔG scores far outside the viable 5–15 kCal/mol range.
- What evidence would resolve it: Demonstration of generated proteins with desired motifs that simultaneously possess ΔG scores within the thermodynamically stable range.

### Open Question 2
- Question: Can models be compressed via label-based pruning without losing functional capacity?
- Basis in paper: The "Model Pruning" subsection of "Looking Forwards" asks if neurons with low specificity can be removed to create a smaller, condensed ESM variant with equivalent performance.
- Why unresolved: While the authors map functional neurons, the redundancy of these neurons and the model's tolerance for removing "low specificity" units remain untested.
- What evidence would resolve it: Retention of benchmark performance (e.g., structure prediction accuracy) in a pruned model where neurons identified as redundant are ablated.

### Open Question 3
- Question: How can the quality and faithfulness of automated neuron descriptions be rigorously evaluated against human judgment?
- Basis in paper: The authors identify "LLM Oversimplification" as a limitation and state the need to "generate an evaluation rubric and benchmark for descriptions and then have humans assess the quality."
- Why unresolved: The current method relies on automated simulator correlation, which may not capture semantic hallucinations or oversimplifications made by the explainer model.
- What evidence would resolve it: A standardized benchmark dataset where automated labels show high statistical correlation with labels assigned by human biology experts.

## Limitations

- Generated proteins exhibit unrealistic folding energies (ΔG values of 99-172 kCal/mol versus typical 5-15 kCal/mol), indicating structural infeasibility despite successful property steering
- The simulator's correlation quality is critical but not fully validated on held-out neurons, creating uncertainty about label reliability
- The method relies on automated text generation which may oversimplify or hallucinate features not present in the sequence data

## Confidence

**High Confidence**: The labeling framework successfully produces natural language descriptions for neurons at scale with clear correlation-based validation.

**Medium Confidence**: The affine transformation steering approach can shift target biochemical properties (molecular weight, GRAVY, instability index) in predictable directions with monotonic divergence.

**Low Confidence**: Steering for structural properties produces desired motifs but with unrealistic folding energies, suggesting the method identifies patterns without maintaining biophysical constraints necessary for stable protein folding.

## Next Checks

1. **Simulator Validation**: Measure Pearson correlation between simulator predictions and actual activations on a held-out test set of 50 neurons. If correlation falls below 0.3, the labeling framework cannot be trusted.

2. **Structural Validity Assessment**: Compute folding energy (ΔG) for proteins generated through biochemical steering experiments. If ΔG remains above 50 kCal/mol, the method successfully shifts properties but produces structurally infeasible proteins.

3. **Layer-Specific Steering Ablation**: When steering for alpha helices, apply the affine intervention only to middle layers versus applying it globally. Compare structural motif accuracy and biochemical property divergence to determine whether hierarchical feature localization holds.