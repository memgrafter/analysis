---
ver: rpa2
title: 'FLAT: Latent-Driven Arbitrary-Target Backdoor Attacks in Federated Learning'
arxiv_id: '2508.04064'
source_url: https://arxiv.org/abs/2508.04064
tags:
- flat
- attack
- attacks
- backdoor
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FLAT addresses the limitation of existing FL backdoor attacks,
  which are constrained by fixed, single-target triggers that are easily detected.
  The core innovation is a latent-driven conditional autoencoder that generates diverse,
  target-specific perturbations.
---

# FLAT: Latent-Driven Arbitrary-Target Backdoor Attacks in Federated Learning

## Quick Facts
- arXiv ID: 2508.04064
- Source URL: https://arxiv.org/abs/2508.04064
- Authors: Tuan Nguyen; Khoa D Doan; Kok-Seng Wong
- Reference count: 24
- Primary result: FLAT achieves up to 94.7% ASR on CIFAR-10 with superior defense resilience

## Executive Summary
FLAT addresses the limitation of existing federated learning (FL) backdoor attacks, which are constrained by fixed, single-target triggers that are easily detected. The core innovation is a latent-driven conditional autoencoder that generates diverse, target-specific perturbations. By sampling from a latent space, FLAT creates a unique, visually adaptive trigger for any chosen target class, enabling arbitrary target selection without retraining. Extensive experiments across four datasets show FLAT achieves the highest attack success rate (up to 94.7% ASR on CIFAR-10) while maintaining competitive clean accuracy (82.1% ACC) and demonstrating superior resilience against advanced FL defenses compared to prior art.

## Method Summary
FLAT introduces a novel approach to backdoor attacks in federated learning by leveraging a latent-driven conditional autoencoder. The method generates diverse, target-specific triggers by sampling from a latent space, allowing for arbitrary target selection without the need for retraining. This approach overcomes the limitations of existing attacks that rely on fixed, single-target triggers, which are both detectable and inflexible. The attack is evaluated across multiple datasets, demonstrating high attack success rates and robustness against advanced FL defenses.

## Key Results
- FLAT achieves up to 94.7% attack success rate (ASR) on CIFAR-10.
- Maintains competitive clean accuracy at 82.1% while under attack.
- Demonstrates superior resilience against advanced federated learning defenses compared to prior art.

## Why This Works (Mechanism)
FLAT's effectiveness stems from its ability to generate diverse, target-specific triggers using a latent-driven conditional autoencoder. By sampling from a latent space, the method creates unique, visually adaptive perturbations for any chosen target class. This flexibility allows FLAT to evade detection by standard defenses, which often rely on identifying fixed or repetitive trigger patterns. The conditional autoencoder ensures that each trigger is tailored to the specific target, enhancing both the attack's stealth and success rate.

## Foundational Learning
- **Federated Learning (FL):** A decentralized machine learning approach where multiple clients collaboratively train a model under the coordination of a central server. *Why needed:* Understanding FL is crucial as FLAT exploits vulnerabilities in this collaborative training process.
- **Backdoor Attacks:** Malicious modifications to a model that cause it to behave incorrectly for specific inputs. *Why needed:* FLAT is a backdoor attack, so understanding its mechanics and goals is essential.
- **Conditional Autoencoders:** Neural networks that learn to generate outputs conditioned on specific inputs, often used for generating diverse data samples. *Why needed:* FLAT uses a conditional autoencoder to generate diverse, target-specific triggers.
- **Latent Space Sampling:** The process of drawing samples from a learned latent space to generate varied outputs. *Why needed:* FLAT leverages latent space sampling to create unique triggers for each target class.

## Architecture Onboarding
- **Component Map:** Input Data -> Latent-Driven Conditional Autoencoder -> Generated Triggers -> Federated Learning Model
- **Critical Path:** The latent-driven conditional autoencoder generates target-specific triggers, which are then injected into the training process to corrupt the federated learning model.
- **Design Tradeoffs:** FLAT trades off some computational complexity for increased attack flexibility and stealth, allowing for arbitrary target selection without retraining.
- **Failure Signatures:** If the latent space is not well-optimized, triggers may become detectable or fail to consistently target the intended class.
- **First Experiments:** 1) Test trigger generation on CIFAR-10 to verify diversity and adaptability. 2) Evaluate attack success rate on a small FL setup. 3) Assess resilience against basic defense mechanisms.

## Open Questions the Paper Calls Out
- None

## Limitations
- The robustness of FLAT under realistic, non-ideal FL conditions (e.g., data heterogeneity, non-IID data, or partial participation) is not thoroughly validated.
- The scalability and adaptability of the latent-driven autoencoder to more complex or diverse datasets remain unclear.
- The generation and optimization of the latent space for trigger creation is noted as a challenge, with uncertainty about reproducibility and generalizability.

## Confidence
- Experimental results are promising and well-documented within the scope of tested conditions: High
- Broader applicability and resilience in more complex FL environments are not fully established: Medium

## Next Checks
1. Test FLAT under more realistic FL settings, including non-IID data, partial device participation, and heterogeneous data distributions, to assess attack effectiveness and scalability.
2. Evaluate the approach on larger, more complex datasets (e.g., ImageNet) and non-image modalities to determine generalizability and adaptability of the latent-driven autoencoder.
3. Investigate whether new, adaptive defenses can be developed to detect or mitigate FLAT's diverse, latent-driven triggers, especially under advanced FL defense mechanisms.