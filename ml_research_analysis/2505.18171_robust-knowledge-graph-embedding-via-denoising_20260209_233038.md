---
ver: rpa2
title: Robust Knowledge Graph Embedding via Denoising
arxiv_id: '2505.18171'
source_url: https://arxiv.org/abs/2505.18171
tags:
- robustness
- embedding
- robust
- knowledge
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RKGE-D, a denoising framework that improves
  the robustness of knowledge graph embedding (KGE) models against embedding perturbations.
  The approach treats KGE methods as energy-based models and leverages denoising autoencoders
  with score matching to learn robust embeddings under noise.
---

# Robust Knowledge Graph Embedding via Denoising

## Quick Facts
- **arXiv ID:** 2505.18171
- **Source URL:** https://arxiv.org/abs/2505.18171
- **Reference count:** 8
- **Primary result:** Introduces RKGE-D, a denoising framework that improves KGE robustness against embedding perturbations, outperforming state-of-the-art models in link prediction and multi-hop reasoning under noise.

## Executive Summary
This paper introduces RKGE-D, a denoising framework that improves the robustness of knowledge graph embedding (KGE) models against embedding perturbations. The approach treats KGE methods as energy-based models and leverages denoising autoencoders with score matching to learn robust embeddings under noise. A certified robustness evaluation using randomized smoothing is also proposed to measure model resilience. Experiments on FB15k-237 show that RKGE-D consistently outperforms state-of-the-art models in link prediction and multi-hop reasoning under perturbed embeddings, with improved robustness metrics like ACR/σ and CA. The framework particularly benefits deep learning-based models, demonstrating the effectiveness of denoising strategies for enhancing KGE robustness.

## Method Summary
RKGE-D is a denoising framework for robust KGE that treats models as energy-based systems. During training, entity embeddings are perturbed with Gaussian noise, and the model learns to denoise by predicting this noise through gradient-based score matching. The method jointly optimizes the original KGE loss and a denoising loss, where the denoising target is the gradient of the energy function with respect to the noisy embedding. For evaluation, certified robustness is measured using randomized smoothing, which provides provable guarantees on prediction stability under perturbations. The framework is tested on FB15k-237 for link prediction and multi-hop reasoning tasks.

## Key Results
- RKGE-D consistently outperforms state-of-the-art models in link prediction under embedding perturbations
- Achieves improved robustness metrics (ACR/σ and CA) through certified evaluation
- Particularly benefits deep learning-based KGE models, showing significant robustness gains
- Maintains near-identical performance on unperturbed data (+0.4% improvement)

## Why This Works (Mechanism)

### Mechanism 1: Energy-Based Denoising via Score Matching
- **Claim:** Treating KGE models as energy-based models enables a principled connection to denoising autoencoders through score matching.
- **Mechanism:** The framework defines an energy function E(h,r,t) = -f_r(h,t) where lower energy indicates higher plausibility. By perturbing entity embeddings with Gaussian noise (ẽ_i = e_i + αϵ_i) and training the model to predict this noise, the denoising objective aligns with learning the gradient of the energy function directly from perturbed representations: L_d = ||n - n̂||² where n̂ = -∇_h̃ E(h̃,r,t).
- **Core assumption:** The gradient of the log noise distribution can be approximated by the empirical energy gradient, which assumes the energy function captures meaningful structure in the embedding space.
- **Evidence anchors:**
  - [abstract] "By treating KGE methods as energy-based models, we leverage the established connection between denoising and score matching"
  - [section 3.2] "we leverage the established link between denoising autoencoders and score matching... the denoising objective aligns with learning the energy gradient directly"
  - [corpus] No direct corpus support for this specific mechanism; related KGE work focuses on structural embedding rather than robustness.
- **Break condition:** If the energy landscape is poorly structured (flat or highly irregular), the gradient signal becomes uninformative, and denoising fails to improve robustness.

### Mechanism 2: Joint Loss Optimization for Robustness-Utility Tradeoff
- **Claim:** Combining the original KGE loss with a denoising auxiliary loss (L = L_o + λL_d) improves robustness while maintaining link prediction performance.
- **Mechanism:** The joint optimization forces the model to simultaneously minimize prediction error on clean data (L_o) and learn to recover from perturbations (L_d). The hyperparameter λ controls the tradeoff between standard performance and robustness.
- **Core assumption:** The two objectives are not fundamentally conflicting—that learning to denoise does not significantly degrade the model's ability to capture relational patterns.
- **Evidence anchors:**
  - [section 3.2] "the optimization goal of the model is defined as the joint loss function of the original model loss and the de-noising loss"
  - [section 4.2] Table 1 shows TuckER-D achieves .294 MRR vs .255 for baseline under α=2 perturbation
  - [corpus] Neighbor papers discuss negative sampling and embedding quality but not robustness tradeoffs explicitly.
- **Break condition:** Excessive λ values cause the model to over-prioritize noise recovery at the expense of learning meaningful relational structure; the paper shows α=0 or λ=0 reduces robustness (Figure 2).

### Mechanism 3: Certified Robustness via Randomized Smoothing
- **Claim:** Randomized smoothing provides provable robustness guarantees by constructing a smoothed classifier from multiple noisy evaluations.
- **Mechanism:** For a query q, the model is evaluated under n_0 Gaussian noise perturbations. If the model correctly predicts entity e_T with probability lower bound p_T at confidence C, then the certified radius CR = σΦ⁻¹(p_T) guarantees correct prediction for any perturbation ||δ||₂ < CR. This is adapted from computer vision (Cohen et al., 2019) to link prediction.
- **Core assumption:** Link prediction can be treated as binary classification (correct/incorrect entity) and that the smoothed classifier's robustness transfers to the base classifier at high confidence.
- **Evidence anchors:**
  - [section 3.3] "We adopt ACR (Average Certified Radius) and CA (Certified Accuracy)... to evaluate the robustness of the model"
  - [section 3.3.1] Definition 1 formalizes CR for KGE link prediction
  - [corpus] No corpus papers address certified robustness; this appears novel to KGE.
- **Break condition:** If the base model has very low accuracy (p_T near 0.5), the certified radius collapses; also requires n_0 sufficiently large for reliable probability estimation.

## Foundational Learning

- **Concept: Energy-Based Models (EBMs)**
  - Why needed here: The entire RKGE-D framework depends on interpreting KGE scoring functions as energy functions and exploiting their gradients for denoising.
  - Quick check question: Given an energy function E(x), what does ∇_x E(x) represent, and why would minimizing it lead to more plausible samples?

- **Concept: Denoising Autoencoders and Score Matching**
  - Why needed here: The theoretical justification for using denoising as a robustness mechanism comes from Vincent (2011)'s connection between denoising and score matching.
  - Quick check question: If you corrupt input x to get x̃ = x + noise, what should the model learn to output, and how does this relate to the score (gradient of log density)?

- **Concept: Certified Robustness and Randomized Smoothing**
  - Why needed here: Evaluating robustness requires understanding how randomized smoothing provides provable guarantees rather than just empirical robustness.
  - Quick check question: Why does adding noise during evaluation (not just training) provide certification, and what is the tradeoff between certified radius and accuracy?

## Architecture Onboarding

- **Component map:**
  - Backbone KGE model (e.g., TuckER, HousE) -> Perturbation module -> Denoising head -> Joint loss -> Certification module

- **Critical path:**
  1. Select backbone KGE model -> 2. Implement noise injection with adaptive σ (99.73% quantile of |e_i|) -> 3. Add denoising loss term computing energy gradient -> 4. Tune α (noise scale) and λ (loss weight) via grid search -> 5. Evaluate using both standard metrics and certified robustness (ACR/σ, CA)

- **Design tradeoffs:**
  - Higher α improves robustness but may harm clean performance (paper notes only ~0.4% improvement on unperturbed data)
  - Deep learning models (ConvE, GNNs) benefit more from RKGE-D but are more vulnerable baseline
  - Certification requires n_0=1000 evaluations per sample—computationally expensive for large-scale testing

- **Failure signatures:**
  - If ACR/σ remains low despite training: noise scale α may be mismatched to embedding magnitudes
  - If clean performance degrades severely: λ is too high relative to L_o
  - If certification fails (CA near 0): base model accuracy is insufficient; improve backbone first

- **First 3 experiments:**
  1. **Baseline robustness assessment**: Apply Gaussian noise at scales α∈{0.5,1,2,5} to entity embeddings of standard KGE models (TransE, RotatE, ConvE) and measure Hit@10 degradation on FB15k-237
  2. **Denoising loss ablation**: Train TuckER-D with λ∈{0,0.1,0.5,1.0} while fixing α=1.0; plot both clean MRR and perturbed MRR (α=2) to find optimal tradeoff
  3. **Certification validation**: For a subset of 100 test triples, compute certified radius with n_0=1000, C=99.9%; verify that adversarial perturbations within CR indeed preserve correct predictions

## Open Questions the Paper Calls Out

- **Adaptive noise management**: The authors note that while RKGE-D improves robustness, the improvement on clean data is limited (+0.4%). They propose adaptive noise management as a future direction to address this tradeoff, suggesting dynamic noise scales could improve both robustness and standard performance.

## Limitations
- The improvement on unperturbed data is limited (+0.4%), indicating a robustness-accuracy tradeoff
- Certified robustness evaluation relies on treating link prediction as binary classification, which lacks validation in KGE literature
- The framework particularly benefits deep learning models but the analysis of why traditional methods are less sensitive to perturbations is incomplete

## Confidence
- **High confidence**: The denoising mechanism works through joint loss optimization (L = L_o + λL_d) and improves empirical robustness metrics under perturbation
- **Medium confidence**: The theoretical connection between denoising autoencoders and score matching applies to KGE, though direct corpus support is lacking
- **Medium confidence**: Certified robustness via randomized smoothing provides meaningful guarantees, but the binary classification assumption for link prediction needs further validation

## Next Checks
1. Verify that adversarial perturbations within the certified radius CR indeed preserve correct predictions on a held-out validation set to confirm the certification methodology
2. Test RKGE-D with different noise distributions (Laplacian, uniform) to determine whether Gaussian noise is essential to the robustness gains
3. Analyze the learned embedding geometry under RKGE-D to confirm that denoising creates smoother energy landscapes rather than just masking perturbation effects