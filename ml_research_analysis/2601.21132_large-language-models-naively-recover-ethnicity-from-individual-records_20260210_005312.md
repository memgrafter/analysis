---
ver: rpa2
title: Large Language Models Naively Recover Ethnicity from Individual Records
arxiv_id: '2601.21132'
source_url: https://arxiv.org/abs/2601.21132
tags:
- accuracy
- bisg
- gemini
- data
- name
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper demonstrates that large language models can infer ethnicity
  from names with accuracy exceeding Bayesian Improved Surname Geocoding (BISG) without
  additional training data. Using Florida and North Carolina voter files, LLM-based
  classification achieved up to 84.7% accuracy compared to BISG's 68.2%, with notable
  improvements for Black and Hispanic voters.
---

# Large Language Models Naively Recover Ethnicity from Individual Records

## Quick Facts
- arXiv ID: 2601.21132
- Source URL: https://arxiv.org/abs/2601.21132
- Authors: Noah Dasanaike
- Reference count: 2
- Key outcome: LLM-based classification achieves up to 84.7% accuracy vs BISG's 68.2% for ethnicity inference from names

## Executive Summary
This paper demonstrates that large language models can infer ethnicity from names with accuracy exceeding Bayesian Improved Surname Geocoding (BISG) without additional training data. Using Florida and North Carolina voter files, LLM-based classification achieved up to 84.7% accuracy compared to BISG's 68.2%, with notable improvements for Black and Hispanic voters. The approach extends beyond the United States, successfully classifying religious sects in Lebanon (64.3%), caste in India (74.0%), and recovering known population distributions across six countries. Including metadata like party registration improved accuracy to 86.7%. The method overcomes BISG's limitations of requiring labeled training data and being restricted to predefined categories, while also reducing income-based classification bias. Small transformer models fine-tuned on LLM labels can achieve BISG-level accuracy for local deployment.

## Method Summary
The study uses zero-shot classification with LLMs to infer ethnicity from names, comparing results against BISG baseline. The method prompts LLMs with names and optional geographic/metadata context, extracting deterministic category outputs. Validation uses stratified samples from Florida and North Carolina voter files (10,000 records each, 2,500 per racial category), Lebanon voter rolls (3,500 records), Indian MPs from reserved constituencies (n=130), and Lee & Velez replication data (n=1,000). The approach tests multiple countries and contexts, including knowledge distillation where small transformer models are fine-tuned on LLM-generated labels using LoRA.

## Key Results
- LLM-based classification achieved 84.7% accuracy versus BISG's 68.2% on Florida/NC voter data
- Accuracy improves to 86.7% when including party registration metadata
- Successfully classifies non-US contexts: Lebanon religious sects (64.3%), Indian caste (74.0%)
- Small transformer models fine-tuned on LLM labels can achieve BISG-level accuracy for local deployment
- Reduces income-based classification bias compared to BISG, particularly for Asian voters

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs infer ethnicity via zero-shot classification by leveraging implicit statistical associations between names and demographic groups learned during pre-training.
- **Mechanism:** During training on massive text corpora, the model develops high-dimensional representations where names co-occur with ethnic, religious, or national identifiers. By prompting with a name and target categories, the model retrieves the most probable association from its latent space without task-specific gradient updates.
- **Core assumption:** Training data contained sufficient co-occurrences of specific names and ethnic labels to form statistically recoverable patterns that generalize to inference context.
- **Evidence anchors:** [abstract] "Large language models can infer ethnicity... without additional training data... implicitly learn associations." [Page 2] "Books, news and research articles... frequently mention individuals by name alongside ethnic, religious, or national identifiers."

### Mechanism 2
- **Claim:** Accuracy improves when non-name metadata is injected into the prompt, allowing the model to condition probability estimates on auxiliary correlations.
- **Mechanism:** LLMs function as universal function approximators for text. When metadata is provided, the model applies context-dependent prior, weighting probability of name association higher if geographic location has known demographic skew.
- **Core assumption:** Model has learned correlation between metadata (e.g., "North Carolina," "Party X") and target classes during pre-training.
- **Evidence anchors:** [Page 12] "Party registration provides the largest improvement (+2.0pp)... LLMs can leverage metadata that BISG cannot incorporate." [Page 5] Ablation studies show removing first names reduces accuracy by 8.7pp.

### Mechanism 3
- **Claim:** Knowledge distillation transfers zero-shot capability of large models into smaller, locally deployable transformers.
- **Mechanism:** Large "teacher" model generates probabilistic labels for dataset. Smaller "student" model is fine-tuned on these soft labels, learning to mimic teacher's decision boundaries and compressing relevant capability into smaller parameter space.
- **Core assumption:** Teacher predictions are accurate enough to serve as ground truth, and student model has sufficient capacity to approximate required decision boundary.
- **Evidence anchors:** [Page 13] "Small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment." [Page 13, Table 9] Shows Qwen3-1.7B jumping from 60.3% to 79.7% accuracy.

## Foundational Learning

- **Concept:** Bayesian Improved Surname Geocoding (BISG)
  - **Why needed here:** Baseline "state-of-the-art" the paper attempts to outperform. Understanding BISG explains why LLM approach is novel (removing need for Census training data).
  - **Quick check question:** How does BISG traditionally combine surname lists and geographic location to predict race, and what data requirement does LLM method eliminate?

- **Concept:** Zero-Shot Classification
  - **Why needed here:** Core claim is that LLMs do this "naively" (without training). Must understand model uses pre-existing knowledge rather than learning from provided voter files.
  - **Quick check question:** If model has never seen Florida voter file, how does it correctly classify the names?

- **Concept:** Stratified Sampling & Recall
  - **Why needed here:** Paper uses stratified samples (2,500 per category) rather than random samples. Explains why BISG accuracy appears lower than usual (BISG relies on majority-class prevalence which is removed in stratified sets).
  - **Quick check question:** Why does author use stratified sampling (equalizing racial categories) rather than random sample to benchmark performance against BISG?

## Architecture Onboarding

- **Component map:** Voter records (First Name, Surname, optional Geography/Metadata) -> Prompt Constructor -> Inference Engine (Gemini API/Local Transformer) -> Output Parser (Temperature=0)
- **Critical path:** Performance depends heavily on First Name + Surname combination. Ablation studies show dropping first names causes 8.7pp accuracy drop. Do not discard first names.
- **Design tradeoffs:**
  - Gemini 3 Flash: Best accuracy (83.8%), low cost, but data must leave premise (external API)
  - Local Fine-tuned Qwen: slightly lower accuracy (~79%), but zero marginal cost and preserves data privacy
  - Reasoning Mode: Inconsistent gains (+3.4pp for small models, mixed for large) for 2.8x-5x latency increase. Generally not recommended for large-scale batch processing.
- **Failure signatures:**
  - Majority Collapse: Watch for "implausible concentrations in a single category" (Page 17), indicating model lacks specific knowledge for context
  - Script Limitations: Smaller models fail significantly on non-Latin scripts or specific dialects, often defaulting to majority class or hallucinating
- **First 3 experiments:**
  1. **US Baseline Validation:** Run BISG vs. LLM (Gemini/GPT-4o) on stratified sample of 1,000 records to confirm 15-16pp accuracy lift
  2. **Ablation Study:** Test "Full Name + Geo" vs. "Surname Only" on subset to quantify first name contribution (~8.7pp delta)
  3. **Distillation Viability:** Generate labels for 1,200 records using Gemini, fine-tune Qwen3-1.7B using LoRA, verify accuracy holds (>75%)

## Open Questions the Paper Calls Out

- **Open Question 1:** Why does extended reasoning improve classification accuracy in some contexts (+1.0 to +3.4pp for Florida) but reduce it in others (-0.3 to -1.3pp for North Carolina)? Authors document pattern but don't investigate whether it stems from naming convention differences, demographic composition, or model-specific factors.

- **Open Question 2:** What explains large accuracy gap between Bihar land records (74.0%) and Rajasthan sarpanch data (57.0%) for four-way caste classification? Authors hypothesize Bihar names include explicit caste surnames while Rajasthan lacks consistent markers, but don't test this.

- **Open Question 3:** How do societal biases encoded in LLM training data affect individuals with atypical names for their ethnic group? Discussion notes "LLMs may encode societal biases about name-ethnicity associations learned from training data, which may disadvantage individuals with atypical names for their group" but provides no empirical test.

- **Open Question 4:** Why does income-related classification bias decrease for Asian voters but increase for Hispanic voters in both BISG and LLM methods? Authors only analyze Black voters in detail and note Asian/Hispanic patterns without explanation.

## Limitations

- Data access limitations: Paper relies on voter files from Florida and North Carolina that require formal requests, plus proprietary LLM API access (Gemini, GPT-4o)
- Exact prompt formulations not provided: Only "typical" examples given across different contexts, leaving room for performance variation based on prompt engineering
- Distillation results limited external validation: Paper doesn't demonstrate generalization beyond tested Qwen models or provide public checkpoints

## Confidence

- **High Confidence:** LLM mechanism itself (zero-shot classification via learned associations) is well-established and ablation study showing first names contribute 8.7pp accuracy is methodologically sound and internally consistent
- **Medium Confidence:** Accuracy comparisons are credible given methodology, but depend heavily on specific voter files and LLM API versions which may have changed since study
- **Low Confidence:** Distillation results for small transformer models are promising but have limited external validation

## Next Checks

1. **API Version Validation:** Test current Gemini Flash and GPT-4o-mini APIs on stratified sample of publicly available North Carolina voter data to verify if they still achieve ~83-84% accuracy range claimed, controlling for API version drift.

2. **Prompt Engineering Sensitivity:** Systematically vary prompt structure (different category list orders, inclusion/exclusion of geographic metadata) on subset of 500 records to quantify how much performance varies with prompt formulation.

3. **Cross-Dataset Generalization:** Apply LLM classification method to different publicly available dataset with ground truth (e.g., census surname lists with self-reported race) to test whether claimed accuracy advantage over BISG holds outside original voter file context.