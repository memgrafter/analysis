---
ver: rpa2
title: 'Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional
  Analysis'
arxiv_id: '2505.17636'
source_url: https://arxiv.org/abs/2505.17636
tags:
- safety
- benchmarks
- harm
- while
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study employed UMAP dimensionality reduction and k-means clustering
  to analyze five open-source AI safety benchmarks, identifying six primary harm categories
  with a silhouette score of 0.470. The analysis revealed distinct semantic clusters
  and coverage gaps, with GretelAI focusing on privacy concerns and WildGuardMix emphasizing
  self-harm scenarios.
---

# Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional Analysis

## Quick Facts
- arXiv ID: 2505.17636
- Source URL: https://arxiv.org/abs/2505.17636
- Reference count: 40
- Primary result: Identified six primary harm categories across five AI safety benchmarks using UMAP clustering with silhouette score of 0.470

## Executive Summary
This study analyzes five open-source AI safety benchmarks to quantify semantic orthogonality and identify coverage gaps. Using UMAP dimensionality reduction and k-means clustering, the researchers discovered distinct semantic clusters corresponding to different harm categories. The methodology reveals that benchmarks like GretelAI focus on privacy concerns while WildGuardMix emphasizes self-harm scenarios, with significant differences in prompt length distributions suggesting potential confounds in data collection. The framework provides a quantitative approach to developing targeted datasets that comprehensively address evolving AI harms while highlighting transparency in coverage gaps.

## Method Summary
The researchers employed MiniLM embeddings to convert prompts from five benchmarks (AEGIS 2.0, WildGuardMix, BeaverTails, GretelAI, AILuminate) into vector representations. They applied UMAP dimensionality reduction (n_neighbors=15, min_dist=0.1) to project high-dimensional embeddings into 2D space, then used k-means clustering (k=6) to partition the space into harm categories. GPT-4 labeled cluster centroids using the Aegis 2.0 taxonomy. The analysis included z-score outlier removal (3 standard deviations) and computed silhouette scores to validate cluster quality, achieving 0.470 on Nvidia Tesla T4 GPU.

## Key Results
- Identified six primary harm categories across benchmarks with silhouette score of 0.470
- Discovered distinct semantic clusters with GretelAI focusing on privacy concerns and WildGuardMix emphasizing self-harm scenarios
- Revealed significant prompt length distribution differences (55-136 chars vs >700 chars) suggesting collection methodology confounds

## Why This Works (Mechanism)

### Mechanism 1: Embedding Space Reveals Semantic Structure
- Embedding models convert prompt text into vector representations where semantic similarity correlates with spatial proximity, enabling unsupervised discovery of harm categories.
- MiniLM/MPNet maps each prompt to high-dimensional vector; distance metrics quantify similarity; k-means partitions space into harm clusters.
- Core assumption: Embedding model's semantic space aligns with human-interpretable harm categories.
- Evidence: Distinct semantic clusters using UMAP and k-means (silhouette score: 0.470); MiniLM provides fast, efficient embeddings with quality representation.

### Mechanism 2: Dimensionality Reduction Preserves Cluster Geometry
- UMAP preserves both local and global structure better than t-SNE for this task, maintaining meaningful cluster boundaries while enabling visualization.
- UMAP projects high-dimensional embeddings to 2D by optimizing topological representation; n_neighbors balances structure preservation; min_dist controls cluster tightness.
- Core assumption: Intrinsic dimensionality of harm semantics is low enough that 2D projection preserves discriminative structure.
- Evidence: UMAP preserves both local and global structure while scaling efficiently; MiniLM with Euclidean distance and UMAP reduction achieves highest silhouette scores.

### Mechanism 3: Prompt Length Distribution Signals Collection Bias
- Systematic differences in prompt length across benchmarks reveal divergent data collection strategies that confound cross-benchmark comparisons.
- Shorter prompts (medians 55-136 chars) target specific vulnerabilities; longer prompts (medians >700 chars) evaluate nuanced real-world scenarios.
- Core assumption: Prompt length is proxy for scenario complexity reflecting intentional design choices.
- Evidence: Significant differences in prompt length distribution suggests confounds; GretelAI and WildGuardMix utilize substantially longer prompts.

## Foundational Learning

- **Concept: Silhouette Score**
  - Why needed: Quantifies cluster quality by comparing intra-cluster distance to nearest-cluster distance.
  - Quick check: If silhouette score is 0.15, would you trust the clusters? What about 0.85?

- **Concept: UMAP vs. t-SNE**
  - Why needed: Both reduce dimensionality for visualization, but UMAP preserves global structure and scales better.
  - Quick check: You have 100K prompts and need to preserve both cluster boundaries and inter-cluster relationships. Which method do you choose?

- **Concept: Mahalanobis Distance**
  - Why needed: Accounts for covariance in embedding dimensions, normalizing anisotropic clusters.
  - Quick check: If your embedding dimensions are uncorrelated and have equal variance, is Mahalanobis distance meaningfully different from Euclidean?

## Architecture Onboarding

- **Component map**: Raw prompt → Embedding (MiniLM) → Z-score outlier removal → UMAP (n_neighbors=15, min_dist=0.1) → K-means (k=6) → Centroid extraction → GPT-4 labeling
- **Critical path**: Raw prompt → Embedding → Z-score outlier removal → UMAP → K-means → Centroid extraction → LLM labeling
- **Design tradeoffs**: 85% confidence level increases Type I error risk but enables inclusion of smaller benchmarks; Z-score outlier removal preserves long-tail prompts; k=6 chosen over k=5 to align with taxonomy expectations
- **Failure signatures**: Silhouette score < 0.3 indicates embeddings or k selection not capturing meaningful structure; all prompts cluster into 1-2 groups suggests n_neighbors too high; cluster labels incoherent suggests centroid extraction or labeling step failing
- **First 3 experiments**: 1) Reproduce clustering on single benchmark to verify pipeline, 2) Ablate embedding model: compare MiniLM vs MPNet silhouette scores, 3) Control for prompt length: stratify sampling by length quartiles and re-cluster

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does inclusion of benchmarks from diverse cultural contexts alter identified harm categories and semantic cluster structure?
- Basis: Future work should expand framework to include benchmarks from more diverse cultural contexts because implicit Western views of harm may skew category definitions.
- Resolution: Replicating methodology on dataset including non-Western safety benchmarks to observe shifts in cluster boundaries or silhouette scores.

### Open Question 2
- Question: Does semantic orthogonality observed in prompt-only analysis persist when evaluating prompt-response pairs in adversarial settings?
- Basis: Need to explore prompt-response relationships in adversarial settings as necessary extension.
- Resolution: Comparative study extending embedding analysis to include response tokens and measuring cluster stability when adversarial responses are introduced.

### Open Question 3
- Question: To what extent does choice of embedding model (MiniLM vs MPNet) propagate bias into semantic clustering results?
- Basis: Embedding model selection imposes representational constraints; future work should evaluate embedding bias propagation.
- Resolution: Sensitivity analysis comparing cluster assignments across multiple embedding architectures against ground-truth taxonomy.

## Limitations

- Reliance on embedding models introduces representational constraints that may not fully capture evolving AI harms
- Silhouette score of 0.470 indicates moderate cluster separation that could be improved
- Prompt length distributions differ significantly across benchmarks (55-136 chars vs >700 chars), creating potential confounds

## Confidence

- **High Confidence**: Methodology for quantifying benchmark orthogonality and identifying coverage gaps through clustering is sound and reproducible
- **Medium Confidence**: Six primary harm categories identified are plausible but depend on embedding model quality and clustering parameters
- **Low Confidence**: Interpretation of clusters as definitive harm categories without accounting for cultural variations and potential embedding biases

## Next Checks

1. Replicate clustering on a held-out benchmark to verify identified harm categories generalize beyond training set
2. Control for prompt length by stratifying sampling across length quartiles and re-clustering to quantify length confound
3. Conduct cross-cultural validation by having safety experts from diverse backgrounds label same cluster centroids