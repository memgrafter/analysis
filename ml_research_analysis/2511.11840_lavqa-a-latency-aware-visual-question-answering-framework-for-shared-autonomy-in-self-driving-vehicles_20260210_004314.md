---
ver: rpa2
title: 'LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy
  in Self-Driving Vehicles'
arxiv_id: '2511.11840'
source_url: https://arxiv.org/abs/2511.11840
tags:
- collision
- latency
- risk
- vehicle
- decision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of safe decision-making in autonomous
  driving under high uncertainty and variable network-induced latency. It proposes
  LA VQA, a shared autonomy framework that integrates Visual Question Answering (VQA)
  with spatiotemporal risk visualization.
---

# LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles

## Quick Facts
- arXiv ID: 2511.11840
- Source URL: https://arxiv.org/abs/2511.11840
- Reference count: 0
- Proposed LA VQA framework integrates Visual Question Answering (VQA) with spatiotemporal risk visualization for shared autonomy in self-driving vehicles

## Executive Summary
This paper addresses the challenge of safe decision-making in autonomous driving under high uncertainty and variable network-induced latency. It proposes LA VQA, a shared autonomy framework that integrates Visual Question Answering (VQA) with spatiotemporal risk visualization. The core innovation is the Latency-Induced Collision Map (LICOM), which dynamically represents how collision risk evolves with response delay, enabling remote operators to make spatially and temporally informed decisions. The framework augments VQA queries with visual overlays of time-varying safe regions derived from motion prediction and collision probability estimation.

Evaluated in CARLA closed-loop simulation across three traffic scenarios (merge, right turn, left turn), LA VQA reduced collision rates by up to 8.98x compared to a latency-agnostic baseline, particularly at lower latencies (200ms). The results demonstrate that visualizing latency-induced risk improves operator decision-making and enhances driving safety in dynamic environments.

## Method Summary
The LA VQA framework combines Visual Question Answering with latency-aware risk visualization to enable shared autonomy in self-driving vehicles. The core component is the Latency-Induced Collision Map (LICOM), which models how collision risk varies with network response delay. The system uses motion prediction algorithms to estimate future trajectories of surrounding vehicles and calculates collision probabilities over time. These spatiotemporal risk assessments are then visualized as overlays on the VQA interface, highlighting safe regions that evolve dynamically with latency. The framework integrates this visualization directly into the decision-making pipeline, allowing remote operators to account for both current environmental conditions and network-induced temporal uncertainties when making control decisions.

## Key Results
- Collision rates reduced by up to 8.98x compared to latency-agnostic baseline
- Performance gains most pronounced at lower latencies (200ms)
- Framework demonstrates effectiveness across three traffic scenarios: merge, right turn, left turn

## Why This Works (Mechanism)
The framework works by explicitly modeling and visualizing how network latency transforms spatial risk into temporal risk. By representing collision probability as a function of both space and time, LICOM enables operators to make decisions that account for when their commands will actually execute relative to the dynamic environment. This spatiotemporal risk visualization bridges the gap between remote perception and local execution, allowing operators to compensate for network delays by choosing actions with appropriate temporal margins.

## Foundational Learning
- Motion Prediction: Required to estimate future trajectories of surrounding vehicles; quick check: validate prediction accuracy against ground truth in simulation
- Collision Probability Estimation: Needed to quantify risk across spatiotemporal dimensions; quick check: compare estimated vs. actual collision rates
- Latency Modeling: Essential for understanding how network delay affects risk evolution; quick check: measure correlation between predicted and observed latency effects

## Architecture Onboarding

**Component Map:**
VQA Engine -> Motion Predictor -> Collision Estimator -> LICOM Visualizer -> Operator Interface

**Critical Path:**
Motion Predictor -> Collision Estimator -> LICOM Visualizer -> Operator Decision -> Command Transmission

**Design Tradeoffs:**
- Visualization complexity vs. operator cognitive load
- Prediction horizon length vs. computational latency
- Risk granularity vs. real-time performance requirements

**Failure Signatures:**
- Overconfidence in predictions leading to insufficient safety margins
- Visualization clutter obscuring critical risk information
- Prediction errors propagating through collision estimation

**First 3 Experiments:**
1. Baseline comparison without LICOM visualization across all traffic scenarios
2. Sensitivity analysis of prediction horizon length on collision avoidance performance
3. User study measuring decision accuracy with varying visualization complexity levels

## Open Questions the Paper Calls Out
None

## Limitations
- CARLA simulation environment may not capture full complexity of real-world driving
- Evaluation limited to three specific traffic scenarios (merge, right turn, left turn)
- Performance dependent on accuracy of motion prediction and collision probability estimation components

## Confidence
High: Core finding that latency-aware risk visualization improves operator decision-making in controlled scenarios
Medium: Scalability of results to more complex driving environments and longer operational timeframes
Low: Framework's performance under degraded network conditions, extreme weather, or with untrained operators

## Next Checks
1. Real-world pilot testing with actual remote operators in varied traffic conditions
2. Ablation studies isolating the contribution of LICOM visualization from other framework components
3. Analysis of operator cognitive load and decision time across different visualization complexities