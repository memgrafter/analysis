---
ver: rpa2
title: 'Programming by Examples Meets Historical Linguistics: A Large Language Model
  Based Approach to Sound Law Induction'
arxiv_id: '2501.16524'
source_url: https://arxiv.org/abs/2501.16524
tags:
- lambda
- sound
- data
- change
- basicaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a programming by examples (PBE) formulation
  of sound law induction (SLI), applying large language models (LLMs) to automate
  the conversion of reconstructed words in ancestral languages into their attested
  descendants via ordered string rewrite functions. The authors investigate the impact
  of structure versus substance in synthetic data generation, creating four synthetic
  data conditions with varying degrees of inductive bias.
---

# Programming by Examples Meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction

## Quick Facts
- **arXiv ID**: 2501.16524
- **Source URL**: https://arxiv.org/abs/2501.16524
- **Reference count**: 14
- **Primary result**: PySLICoder achieves 6% higher pass rate than previous best open-source LLM for sound law induction using one-third of the parameters

## Executive Summary
This paper presents a novel approach to sound law induction (SLI) by framing it as a programming by examples (PBE) problem and applying large language models (LLMs) to automate the conversion of ancestral language words into their attested descendants. The authors investigate how synthetic data generation strategies affect model performance, creating four conditions with varying degrees of inductive bias. Their proposed model PySLICoder, trained on the optimal synthetic data condition, achieves state-of-the-art performance on SLI as PBE, outperforming previous approaches while using significantly fewer parameters.

## Method Summary
The authors formulate SLI as a PBE problem where the goal is to learn string rewrite functions that convert reconstructed ancestral words into attested descendant forms. They generate synthetic training data with controlled characteristics, varying the realism of input words and the diversity of transformation programs. Four synthetic data conditions are created: two with realistic-looking input words (one with diverse programs, one with simple programs) and two with unrealistic input words (again varying program complexity). The best-performing model, PySLICoder, is fine-tuned on the condition combining realistic inputs with program diversity, then evaluated against previous approaches on benchmark SLI tasks.

## Key Results
- PySLICoder achieves 6% higher pass rate than previous best open-source LLM for sound law induction
- The model uses only one-third of the parameters compared to previous approaches
- Fine-tuning works best when input distribution resembles real language words while maintaining high program diversity
- Program diversity in synthetic data is crucial for generalization to unseen sound change patterns

## Why This Works (Mechanism)
The success of this approach stems from leveraging the strong pattern-matching capabilities of LLMs while carefully structuring the training data to capture the essential characteristics of historical sound changes. By framing SLI as PBE, the model learns to generalize from specific examples to broader transformation rules. The synthetic data generation strategy ensures that the model encounters diverse transformation patterns while maintaining linguistic plausibility in the input words, allowing it to develop robust inductive biases for sound change patterns.

## Foundational Learning
- **Sound Law Induction**: The process of automatically inferring phonological rules that describe how words change between related languages over time. *Why needed*: Forms the core problem being addressed. *Quick check*: Can identify systematic sound correspondences between related languages.
- **Programming by Examples (PBE)**: A paradigm where programs are learned from input-output examples rather than explicit specifications. *Why needed*: Provides the framework for framing SLI as a learnable task. *Quick check*: Can generate correct programs for novel input-output pairs.
- **Synthetic Data Generation**: Creating artificial training data with controlled characteristics to study model behavior. *Why needed*: Allows systematic investigation of how data properties affect learning. *Quick check*: Generated data should capture essential patterns while allowing controlled variation.
- **Inductive Bias**: The set of assumptions that guide learning toward certain solutions over others. *Why needed*: Critical for ensuring models generalize appropriately to new linguistic patterns. *Quick check*: Model should perform well on held-out data with similar but distinct patterns.

## Architecture Onboarding

**Component Map**: Input words -> LLM with PBE formulation -> String rewrite programs -> Output descendant words

**Critical Path**: Synthetic data generation → Fine-tuning LLMs → Evaluation on benchmark tasks → Performance analysis

**Design Tradeoffs**: The paper trades model size for performance by using smaller LLMs with carefully curated synthetic data rather than larger models with less structured training. This approach achieves better results with fewer parameters but requires more sophisticated data generation.

**Failure Signatures**: Models trained on unrealistic input words or lacking program diversity fail to generalize to real linguistic patterns. Performance degrades when encountering rare or complex sound changes not well-represented in training data.

**First Experiments**: 1) Ablation study removing program diversity from synthetic data, 2) Testing model on increasingly rare sound change patterns, 3) Cross-linguistic validation on non-Indo-European language families

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation framework relies on synthetic data that may not fully capture real historical linguistic complexity
- The approach requires substantial computational resources for fine-tuning large language models
- Focus on Indo-European languages may limit generalizability to other language families
- Unclear how the model handles extremely rare or complex sound change patterns

## Confidence
**High Confidence**: The core methodology of framing SLI as PBE is sound and well-established in the literature; the experimental design with controlled synthetic data conditions is methodologically rigorous; the observation that program diversity and realistic input distribution are important for fine-tuning success

**Medium Confidence**: The state-of-the-art performance claims relative to previous models; the effectiveness of the proposed data generation approach; the general applicability of the approach to historical linguistics

**Low Confidence**: The direct applicability to real historical linguistic data; the long-term stability of the fine-tuned models; the ability to handle extremely rare or complex sound change patterns

## Next Checks
1. **Real Data Validation**: Apply the trained model to actual historical linguistic datasets from multiple language families beyond Indo-European to assess generalizability and identify any systematic biases or failures in real-world applications.

2. **Robustness Testing**: Systematically vary the complexity and rarity of sound changes in synthetic test sets to evaluate model performance across different difficulty levels and identify specific failure modes.

3. **Efficiency Analysis**: Conduct detailed benchmarking of computational requirements for fine-tuning and inference, including memory usage and processing time, to better understand the practical constraints of deploying this approach in research settings.