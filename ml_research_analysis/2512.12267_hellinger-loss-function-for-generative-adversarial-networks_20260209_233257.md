---
ver: rpa2
title: Hellinger loss function for Generative Adversarial Networks
arxiv_id: '2512.12267'
source_url: https://arxiv.org/abs/2512.12267
tags:
- loss
- function
- hellinger
- page
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel Hellinger-type loss function for
  Generative Adversarial Networks (GANs) motivated by the boundedness, symmetry, and
  robustness properties of the Hellinger distance. The authors develop a comprehensive
  theoretical framework for this new loss, establishing the existence, uniqueness,
  consistency, and joint asymptotic normality of the estimators for both generator
  and discriminator parameters.
---

# Hellinger loss function for Generative Adversarial Networks

## Quick Facts
- arXiv ID: 2512.12267
- Source URL: https://arxiv.org/abs/2512.12267
- Reference count: 40
- Key outcome: Introduces Hellinger-type loss for GANs with improved robustness and estimation accuracy

## Executive Summary
This paper introduces a novel Hellinger-type loss function for Generative Adversarial Networks motivated by the boundedness, symmetry, and robustness properties of the Hellinger distance. The authors develop a comprehensive theoretical framework establishing existence, uniqueness, consistency, and joint asymptotic normality of estimators for both generator and discriminator parameters. The method demonstrates improved estimation accuracy and robustness against data contamination compared to standard GAN losses, particularly maintaining stable performance under 20% contamination.

## Method Summary
The proposed approach replaces the traditional Jensen-Shannon divergence in GAN training with Hellinger-type losses that incorporate bounded, symmetric, and robust properties. The theoretical framework establishes conditions for the existence and uniqueness of optimal parameters, proves consistency of the estimators, and derives their joint asymptotic normality. The authors also analyze robustness through influence function analysis and validate their approach through controlled experiments on Gaussian mixtures and the Fashion-MNIST dataset, comparing performance against standard GAN implementations.

## Key Results
- Hellinger-type losses achieve improved estimation accuracy compared to classic GAN loss in controlled Gaussian settings
- The proposed losses maintain stable performance with up to 20% data contamination while standard GANs show significant degradation
- Experiments on Fashion-MNIST show comparable visual sample quality to standard GANs without sacrificing robustness

## Why This Works (Mechanism)
The Hellinger distance provides bounded and symmetric divergence measurement between probability distributions, which helps stabilize GAN training and improves robustness to outliers. Unlike KL divergence used in standard GANs, the Hellinger distance treats both distributions symmetrically and has bounded gradients, preventing the exploding or vanishing gradient problems that can occur with extreme probability values. The boundedness property also provides natural protection against adversarial examples and data contamination, as the loss contribution from outliers is naturally limited.

## Foundational Learning

**Hellinger Distance**: A symmetric divergence measure between probability distributions that is bounded between 0 and 1, providing stable gradient signals during training. Needed for robust comparison of generated and real distributions. Quick check: Verify Hellinger distance values remain bounded in [0,1] for extreme probability pairs.

**Influence Function**: A tool for analyzing the sensitivity of estimators to small perturbations in the data distribution, used to quantify robustness. Needed to theoretically establish contamination resistance. Quick check: Compute influence function for a simple contamination scenario to verify boundedness.

**Asymptotic Normality**: The property that estimators converge to a normal distribution as sample size increases, enabling statistical inference. Needed for establishing theoretical guarantees. Quick check: Verify sample estimator distributions approximate normality in simulation studies.

## Architecture Onboarding

**Component Map**: Real Data -> Discriminator -> Hellinger Loss -> Generator -> Generated Data -> Discriminator

**Critical Path**: Generator parameters → Generated samples → Discriminator output → Hellinger loss → Parameter updates (bidirectional flow between generator and discriminator)

**Design Tradeoffs**: Bounded Hellinger loss provides robustness but may reduce sensitivity to subtle distribution differences compared to unbounded divergences; symmetric treatment prevents mode collapse but requires careful calibration of discriminator capacity.

**Failure Signatures**: Underfitting manifests as both real and generated data having similar Hellinger distances to intermediate distributions; overfitting shows discriminator achieving near-zero Hellinger loss while generator fails to improve; contamination sensitivity appears as unstable loss values when outliers are present.

**First Experiments**: 1) Test Hellinger loss on simple Gaussian mixture with known contamination levels, 2) Compare gradient norms and stability during training versus standard GAN, 3) Evaluate sample diversity using coverage metrics on synthetic distributions.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical framework assumes true data distribution lies within the model family, which is restrictive for real-world applications
- Influence function analysis provides only local approximations valid for small contamination levels
- Experimental validation uses controlled Gaussian mixtures that may not generalize to complex real-world data distributions

## Confidence

**Major claim confidence:**
- Theoretical properties (existence, consistency): High
- Robustness against contamination: Medium
- Practical performance on real datasets: Medium

## Next Checks

1. Evaluate performance on diverse real-world datasets beyond Fashion-MNIST, including CIFAR-10 and LSUN, with quantitative metrics (FID, Inception Score)
2. Test the method under various contamination types beyond symmetric noise (outliers, label noise, structured corruption)
3. Investigate computational overhead compared to standard GAN training, including convergence speed and memory requirements