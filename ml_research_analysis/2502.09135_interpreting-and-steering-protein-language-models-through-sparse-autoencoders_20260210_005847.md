---
ver: rpa2
title: Interpreting and Steering Protein Language Models through Sparse Autoencoders
arxiv_id: '2502.09135'
source_url: https://arxiv.org/abs/2502.09135
tags:
- uni00000013
- uni00000011
- uni00000014
- protein
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper applies sparse autoencoders to interpret and steer the
  ESM-2 8M protein language model. It identifies latent components linked to protein
  annotations such as transmembrane regions, binding sites, and zinc finger motifs
  by measuring precision and recall.
---

# Interpreting and Steering Protein Language Models through Sparse Autoencoders

## Quick Facts
- **arXiv ID**: 2502.09135
- **Source URL**: https://arxiv.org/abs/2502.09135
- **Reference count**: 13
- **Primary result**: SAEs identify interpretable latents in ESM-2 8M and enable controllable sequence generation of zinc finger domains

## Executive Summary
This paper applies sparse autoencoders to interpret and steer the ESM-2 8M protein language model by identifying latent components linked to protein annotations like transmembrane regions, binding sites, and zinc finger motifs. The method uses precision and recall metrics to associate latents with features, then steers sequence generation by artificially amplifying target latents. The study successfully demonstrates controlled generation of zinc finger domains and shows that SAEs can disentangle polysemantic representations in protein models for controllable sequence design.

## Method Summary
The authors train SAEs on activations from ESM-2 layer 3 (selected via intrinsic dimension plateau) using a 10× expansion factor. They extract activations from ~15k non-redundant protein sequences and train the SAE with L1 regularization to achieve sparse representations. Latent-feature associations are identified using precision/recall thresholds (≥0.80), and steering is performed by scaling target latents during inference. The steering pipeline involves intervening on latents post-encoder, reconstructing embeddings, and continuing the forward pass through remaining layers.

## Key Results
- SAE successfully identifies latent components associated with specific protein features using precision/recall thresholding
- Artificially amplifying zinc finger-associated latents during generation produces matching zinc finger domains in 13% of sequences (24/180)
- Single latent steering yields 3 matches while dual-latent steering achieves 24 matches, demonstrating combinatorial effects

## Why This Works (Mechanism)

### Mechanism 1: Sparse Decomposition of Superposed Representations
SAEs extract monosemantic features from polysemantic neurons by learning an overcomplete sparse basis through L1 regularization in a higher-dimensional latent space, with unit-norm decoder weight normalization preventing trivial sparsity.

### Mechanism 2: Statistical Association via Precision/Recall Thresholding
Latent-feature mappings are identified by measuring precision (P(φ+|k+)) and recall (P(k+|φ+)) across tokens, with latents exceeding 0.80 thresholds considered associated with features.

### Mechanism 3: Inference-Time Activation Steering
Steering is achieved by scaling target latents during generation (z*_k = a·z_k + b), reconstructing embeddings, and continuing forward pass, with 100 refinement iterations per sequence.

## Foundational Learning

- **Superposition in neural representations**: Explains why single neurons are polysemantic and why sparse expansion is required for interpretability. *Quick check*: Can you explain why a 320-dim embedding can encode more than 320 features?

- **Masked Language Modeling (MLM) objective**: ESM-2 is trained via MLM; features it learns are those useful for predicting masked tokens, which may not align with human annotations. *Quick check*: What pressure does MLM place on learning local vs. global sequence features?

- **Intrinsic dimension estimation**: Used as a heuristic to select which transformer layer's activations to extract (plateau = abstract features). *Quick check*: Why might mid-layers encode more "abstract" features than early or final layers?

## Architecture Onboarding

- **Component map**: ESM-2 8M (6 layers, 320 hidden dim) → extract activations at layer 3 (intrinsic dimension plateau) → SAE: encoder (ReLU(W_enc(x - b_dec) + b_enc)), decoder (W_dec·z + b_dec), hidden size 10× expansion (320→3200) → Steering hook: intervene on z_k post-encoder, pre-decoder

- **Critical path**: 1) Forward pass through ESM-2 layers 0-2, 2) Extract activation x at layer 3, 3) Encode: z = f_enc(x), 4) Intervene: z*_k = a·z_k + b (inference-time only), 5) Decode: x* = f_dec(z*) + x_err, 6) Continue through layers 3-5 → logits → sample

- **Design tradeoffs**: Sparsity (L0) vs. reconstruction quality (CE increase): selected model at L0≈18, CE increase≈0.10; Single vs. multi-latent steering: dual-latent intervention produced 24 zinc finger matches vs. 3 for single latent; Expansion factor: 10× chosen; higher expansion increases feature resolution but training cost and dead latents

- **Failure signatures**: Dead latents (>500 in trained model): latents that never activate; mitigated via periodic re-initialization; High CE increase (>0.2): SAE fails to reconstruct model's functional state; Low steering success rate: 24/180 = 13% for zinc fingers; indicates parameter sweep needed

- **First 3 experiments**: 1) Validate reconstruction: substitute SAE-decoded activations at layer 3, measure CE increase on held-out sequences. Confirm <0.15 before proceeding, 2) Audit latent-annotation pairs: for a known feature (e.g., transmembrane region), visualize activation patterns across annotated sequences. Check P(k+|φ+) vs. P(k+|φ−) separation, 3) Steering ablation: for a single target feature, run (a) no intervention, (b) random latent intervention, (c) target latent intervention. Measure feature presence in generated sequences using independent annotation tool

## Open Questions the Paper Calls Out

- **Open Question 1**: Will sparse autoencoder-based interpretation and steering methods scale effectively to larger protein language models (e.g., ESM-2 650M or ESMFold-scale models)? The study only examined the 8M parameter ESM-2 model, and scaling behavior is unknown.

- **Open Question 2**: Can the sequence generation success rate be improved through automated parameter optimization, and what heuristics would enable efficient search of the intervention parameter space? The authors note the process requires parameter fine-tuning and can be automated.

- **Open Question 3**: How robust are latent-feature associations across different activation thresholds, and what determines the optimal threshold for identifying biologically meaningful latents? The paper demonstrates threshold choice affects associations but doesn't establish principled criteria.

- **Open Question 4**: Can steering toward multiple simultaneous structural features be achieved, and how do interventions on multiple latents interact? The study focused on a single structural motif with limited exploration of multi-feature steering.

## Limitations

- The 13% success rate (24/180 sequences) suggests significant parameter sensitivity or potential limitations in the underlying representation
- The association methodology assumes UniProt annotations capture the same features as the PLM's learned representations without validation
- The causal efficacy of steering remains uncertain as the mechanism relies on monotonic latent-logit relationships that aren't empirically validated

## Confidence

- **High confidence**: SAE can identify latent components associated with protein annotations via precision/recall thresholding. The reconstruction capability (CE increase≈0.10) and dead latent management are technically sound.
- **Medium confidence**: Latent components can steer sequence generation toward target features. The zinc finger results demonstrate proof-of-concept but with limited success rate and unclear generalizability.
- **Low confidence**: The latent-annotation associations reflect the same biological features. The paper doesn't validate whether high-precision latents encode the same concepts as UniProt annotations.

## Next Checks

1. **Causal validation of steering**: Run ablation studies comparing (a) no intervention, (b) random latent intervention, (c) target latent intervention across multiple features. Use independent annotation tools to verify feature presence and measure effect sizes.

2. **Representation alignment validation**: For top latent-annotation pairs, compare the model's internal feature representations against the semantic content of UniProt annotations. This could involve visualizing activation patterns or checking for hierarchical relationships.

3. **Steering robustness check**: Systematically vary steering parameters (a, b) across a wider range and measure feature generation success rates. Determine whether the 13% zinc finger success rate represents a fundamental limitation or parameter sensitivity.