---
ver: rpa2
title: 'Code-Driven Inductive Synthesis: Enhancing Reasoning Abilities of Large Language
  Models with Sequences'
arxiv_id: '2503.13109'
source_url: https://arxiv.org/abs/2503.13109
tags:
- code
- slot
- reasoning
- data
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel method to enhance inductive reasoning
  in large language models (LLMs) by using number sequences as training data. It constructs
  a synthetic dataset, CodeSeq, by converting sequences into algorithmic problems
  with code solutions and unit tests to inject case-based supervision signals.
---

# Code-Driven Inductive Synthesis: Enhancing Reasoning Abilities of Large Language Models with Sequences

## Quick Facts
- arXiv ID: 2503.13109
- Source URL: https://arxiv.org/abs/2503.13109
- Reference count: 26
- Key outcome: Qwen2.5-7B achieves near Claude-3.5-Sonnet-level accuracy on next number prediction after training with CodeSeq

## Executive Summary
This paper introduces CodeSeq, a novel method for enhancing inductive reasoning in large language models by converting number sequences from the OEIS database into algorithmic problems with code solutions and unit tests. The approach uses a three-stage pipeline with two different LLM agents to generate and verify synthetic training data, then fine-tunes models like LLaMA3-8B and Qwen2.5-7B. The resulting models show significant improvements on both code benchmarks (Humaneval, MBPP) and comprehensive reasoning benchmarks (MMLU, BBH, GaoKaoBench), with Qwen2.5-7B achieving near state-of-the-art performance on sequence prediction tasks.

## Method Summary
The paper presents a code-driven inductive synthesis approach that transforms number sequences from the OEIS database into algorithmic problems with executable code solutions. The method uses a three-stage pipeline: first filtering sequences for quality using a working agent, then generating problem descriptions with test cases, and finally synthesizing code solutions with iterative correction through a sandbox environment. The synthetic dataset (CodeSeq) is mixed with filtered Tulu3 data and used to fine-tune LLaMA3-8B and Qwen2.5-7B models, resulting in improved performance across multiple reasoning benchmarks while maintaining general capability through careful data mixing.

## Key Results
- LLaMA3-8B shows +8.82 improvement on MMLU after CodeSeq fine-tuning
- Qwen2.5-7B achieves near Claude-3.5-Sonnet-level accuracy on next number prediction
- Significant gains across code benchmarks (Humaneval, MBPP) and reasoning benchmarks (MMLU, BBH, GaoKaoBench)
- CodeSeq successfully enhances inductive reasoning while avoiding catastrophic forgetting when mixed with Tulu3

## Why This Works (Mechanism)
The approach works by injecting case-based supervision signals through code execution and unit tests, forcing the model to learn the underlying patterns and logic of number sequences rather than memorizing solutions. By converting abstract sequence patterns into concrete algorithmic problems with verifiable test cases, the model develops stronger inductive reasoning capabilities that generalize to other domains. The iterative correction loop ensures high-quality synthetic data, while the mixing with general instruction data prevents catastrophic forgetting of broader capabilities.

## Foundational Learning
- **OEIS Database**: Repository of integer sequences containing over 360,000 entries; needed for diverse pattern learning, quick check: verify sequence diversity and density metrics
- **Algorithmic Problem Generation**: Converting sequences into code problems with test cases; needed to create executable supervision signals, quick check: validate generated problems solve original sequences
- **Sandbox Execution**: Isolated environment for code testing with restricted built-ins; needed to safely verify solutions without security risks, quick check: ensure sandbox prevents file access and system calls
- **Iterative Correction**: Multi-round refinement of code solutions using agent feedback; needed to achieve high-quality synthetic data, quick check: measure success rate within max correction rounds
- **Data Mixing Strategy**: Combining specialized CodeSeq with general Tulu3 data; needed to prevent catastrophic forgetting, quick check: monitor performance drop on non-reasoning tasks

## Architecture Onboarding

### Component Map
DeepSeek-V3 (Working Agent) -> OEIS Filter -> DeepSeek-V3 (Problem Generator) -> o1-preview (Verifier) -> DeepSeek-V3 (Code Generator) -> Sandbox Execution -> o1-preview (Error Analysis) -> DeepSeek-V3 (Corrector) -> Final Code + Tests

### Critical Path
Filter -> Problem Generation -> Code Generation -> Sandbox Testing -> Iterative Correction (max 5 rounds) -> Data Formatting -> Model Fine-Tuning

### Design Tradeoffs
- **Agent Selection**: Uses two different proprietary models (DeepSeek-V3 for generation, o1-preview for verification) to leverage complementary strengths; tradeoff is dependency on closed models
- **Correction Rounds**: Limits to 5 rounds to prevent infinite loops; tradeoff is potentially discarding sequences that need more refinement
- **Data Mixing**: 5:1 ratio with Tulu3 to prevent catastrophic forgetting; tradeoff is potentially diluting the specialized reasoning signals

### Failure Signatures
- **Catastrophic Forgetting**: General instruction following capability drops significantly, indicating insufficient Tulu3 presence
- **Data Generation Loop**: Working agent fails to pass tests within 5 correction rounds, suggesting sequence complexity exceeds generation capability
- **Sandbox Breakout**: Generated code causes side effects or crashes, indicating inadequate built-in restrictions

### Three First Experiments
1. Test sandbox environment with various code patterns to verify security restrictions and stdout/stderr capture
2. Run a small batch of sequence generation to measure success rate and identify common failure modes
3. Experiment with different CodeSeq:Tulu3 mixing ratios (1:5, 1:1, 5:1) to find optimal balance for reasoning gains vs. general capability retention

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on proprietary models (DeepSeek-V3, o1-preview) for data generation creates reproducibility barriers
- Incomplete specifications for sandbox implementation and Tulu3 filtering criteria
- No error analysis on the 82% of sequences that failed during generation
- Mixing ratio direction ambiguity (whether Tulu3:CodeSeq is 5:1 or 1:5)

## Confidence

### Confidence Assessment
**High Confidence** in the core methodology: The three-stage pipeline and use of code execution as supervision is theoretically sound and well-defined.

**Medium Confidence** in performance claims: Results depend heavily on proprietary models and specific filtering approaches that are not fully specified.

**Low Confidence** in exact reproduction: Mixing ratio ambiguity, incomplete sandbox specifications, and reliance on closed models make exact replication challenging.

## Next Checks

### Three Concrete Next Validation Checks
1. **Mixing Ratio Sensitivity Analysis**: Systematically test CodeSeq:Tulu3 ratios of 1:5, 1:1, and 5:1 to empirically determine the optimal weighting for balancing inductive reasoning gains with general capability retention.

2. **Sandbox Security Audit**: Implement and test the sandbox environment with comprehensive coverage of potential escape vectors and verify that stdout/stderr capture works reliably across different Python versions and code patterns.

3. **Failed Sequence Analysis**: Generate a sample of the 82% of sequences that failed during the correction rounds and categorize the failure modes to identify whether specific sequence patterns or generation strategies need adjustment.