---
ver: rpa2
title: 'SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language
  Models'
arxiv_id: '2601.20856'
source_url: https://arxiv.org/abs/2601.20856
tags:
- planning
- sokoban
- problem
- reasoning
- pddl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SokoBench, a benchmark designed to evaluate
  the long-horizon planning and reasoning capabilities of large language models (LLMs)
  using simplified Sokoban puzzles. The benchmark isolates long-horizon planning from
  state persistence by using linear corridors with minimal branching, where the only
  challenge is maintaining correct counting and state representation over extended
  sequences of actions.
---

# SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models

## Quick Facts
- arXiv ID: 2601.20856
- Source URL: https://arxiv.org/abs/2601.20856
- Reference count: 17
- Key outcome: SokoBench reveals that even advanced reasoning models degrade consistently beyond 25 moves in long-horizon planning tasks, with external PDDL tools providing only modest improvements.

## Executive Summary
This paper introduces SokoBench, a benchmark designed to evaluate the long-horizon planning and reasoning capabilities of large language models (LLMs) using simplified Sokoban puzzles. The benchmark isolates long-horizon planning from state persistence by using linear corridors with minimal branching, where the only challenge is maintaining correct counting and state representation over extended sequences of actions. The study tests both reasoning models alone and models augmented with PDDL planning tools (LLM-modulo setting). Results show that even advanced reasoning models exhibit consistent performance degradation when more than 25 moves are required, indicating fundamental architectural limitations in forward planning capacity. While providing PDDL parsing, validation, and solving tools yields modest improvements, the core limitation of maintaining accurate internal state representations persists. The findings suggest that test-time scaling approaches alone cannot overcome these structural limitations without architectural innovations or explicit symbolic grounding.

## Method Summary
SokoBench uses simplified Sokoban puzzles with linear corridors of varying lengths (5-100 moves) and minimal branching to isolate long-horizon planning challenges. The benchmark tests two settings: reasoning-only models (1-shot ASCII map to LURD action sequence) and LLM-modulo models (ASCII map to PDDL problem, then to solver for optimal plan). Multiple state-of-the-art reasoning models are evaluated across corridor orientations (horizontal/vertical) to identify spatial encoding biases. Performance is measured by plan accuracy, with particular attention to the critical transition point where success rates drop precipitously.

## Key Results
- Models show consistent performance degradation beyond 25 moves, with success rates following an exponential decay pattern ~(1-p_w)^ℓ
- LLM-modulo setting with PDDL tools provides only modest improvements over reasoning-only models
- Models exhibit orientation-dependent performance biases between horizontal and vertical corridor representations
- Repetitive looping and token exhaustion emerge as failure modes rather than systematic state-space search

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Small per-step state-tracking errors compound exponentially in long-horizon planning, causing performance collapse beyond a critical sequence length.
- Mechanism: Linear corridors minimize branching but require accurate counting across many sequential steps. Per-step probability p_w of miscounting map dimensions produces success probability ~(1-p_w)^ℓ, creating three observed performance regimes: short corridors tolerate drift, intermediate lengths show exponential decay, and long corridors see near-total collapse.
- Core assumption: Models rely on implicit counting without explicit state-maintenance mechanisms.
- Evidence anchors:
  - [Section 4.1]: "corridors are deep but narrow problems...a small per-step probability p_w of miscounting the size of the map compounds exponentially, yielding success probability ~(1-p_w)^ℓ"
  - [Abstract]: "consistent degradation in planning performance when more than 25 moves are required"
  - [Corpus]: Limited direct corpus support for this specific counting mechanism; related work (R-Horizon) discusses depth/breadth limits but not counting drift explicitly.
- Break condition: Explicit external memory or step-by-step state validation would interrupt compounding errors.

### Mechanism 2
- Claim: LRMs lack visited-state tracking, causing repetitive looping and token exhaustion rather than systematic search.
- Mechanism: Without maintaining a mental tape of explored configurations, models repeatedly propose identical moves without recognizing cycles. This manifests as "wandering" exploration rather than systematic pruning, eventually hitting token limits.
- Core assumption: Transformer architectures lack architectural support for persistent visited-state sets across long reasoning traces.
- Evidence anchors:
  - [Section 4.1]: "models get stuck in repeating the same action or reasoning frame over and over until they reach the token limit"
  - [Section 4.1]: "This repetitive looping behavior exemplifies what Lu et al. classify as unnecessary exploration and failure to maintain a visited-state set"
  - [Corpus]: ReasoningFlow paper analyzes complex traces with backtracking/verification but doesn't address visited-state maintenance as a structural limitation.
- Break condition: External state-tracking tools or architectural modifications for explicit working memory.

### Mechanism 3
- Claim: PDDL tool augmentation improves accuracy modestly but cannot compensate for unfaithful spatial representation in problem formulation.
- Mechanism: LLM-modulo pipelines eliminate invalid transitions via solver constraints, but the model must still correctly encode spatial dimensions. If corridor length is misrepresented in the PDDL problem, the solver produces formally valid but task-incorrect solutions.
- Core assumption: The bottleneck shifts from state maintenance during planning to accurate spatial encoding during problem formulation.
- Evidence anchors:
  - [Section 4.2]: "primary challenge for these models lies in maintaining a consistent internal representation of the spatial environment"
  - [Section 4.2]: "difficulty may stem from a fundamental limitation in the models' ability to precisely quantify the dimensions of the map"
  - [Corpus]: LLM+MAP shows PDDL integration for robotic planning but doesn't isolate spatial encoding as a failure mode.
- Break condition: Grounded spatial representations (e.g., coordinate-based encodings) or external dimension verification.

## Foundational Learning

- Concept: Planning Domain Definition Language (PDDL)
  - Why needed here: Essential for understanding the LLM-modulo approach where models generate PDDL problems for symbolic solvers.
  - Quick check question: Can you explain the difference between a PDDL domain (action schemas, predicates) and a PDDL problem (objects, initial state, goal)?

- Concept: State-space search and branching factor
  - Why needed here: The benchmark intentionally minimizes branching to isolate depth-related failures from complexity-related failures.
  - Quick check question: Why does a linear corridor with branching factor ~1 still present planning difficulty?

- Concept: Working memory in sequential reasoning
  - Why needed here: The paper's findings implicate implicit working memory limitations as the root cause of counting drift and state-tracking failures.
  - Quick check question: How does maintaining a "visited-state set" differ from autoregressive token prediction?

## Architecture Onboarding

- Component map: ASCII map -> LRM (internal reasoning only) -> LURD action sequence
  LLM-modulo setting: ASCII map -> LRM -> PDDL problem -> Domain/Problem parsers -> Solver (Fast-Downward/PyperPlan) -> LURD plan

- Critical path: Accurate corridor length encoding -> correct PDDL problem formulation -> valid solver execution -> optimal plan extraction. Failure at encoding stage propagates through entire pipeline.

- Design tradeoffs: Reasoning-only (faster, cheaper, ~25-move horizon limit) vs. LLM-modulo (slower, costlier, modest accuracy improvement, same fundamental limitation). Tool use adds ~75 minutes per evaluation batch vs. seconds for reasoning-only.

- Failure signatures:
  - Token exhaustion from repetitive loops (wandering)
  - Invalid transitions: teleporting through walls/boxes
  - Asymmetric performance across rotations (vertical vs. horizontal corridors)
  - Prefix accuracy >> full accuracy (partial trajectories correct, final steps wrong)

- First 3 experiments:
  1. Replicate the corridor length sweep (ℓ=5-100) with a single model to observe the 25-move degradation threshold and three-region performance curve.
  2. Compare horizontal (0°/180°) vs. vertical (90°/270°) corridor performance to identify orientation bias in spatial encoding.
  3. Implement a simple PDDL validation layer that checks dimension consistency before solver invocation to quantify how often spatial encoding fails vs. other error types.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural innovations could enable LLMs to maintain accurate internal state representations over extended action sequences beyond the observed ~25-move threshold?
- Basis in paper: [explicit] The conclusion states that "test-time scaling approaches alone cannot overcome these structural limitations without architectural innovations or explicit symbolic grounding."
- Why unresolved: The paper identifies the limitation but does not propose or test architectural solutions; it only demonstrates that external PDDL tools provide modest improvements without solving the core state-tracking problem.
- What evidence would resolve it: Systematic evaluation of LLM variants with explicit working memory modules, recurrent state representations, or hybrid neuro-symbolic architectures on SokoBench at corridor lengths exceeding 50 moves.

### Open Question 2
- Question: Can alternative spatial encodings (e.g., row/column numbered grids or coordinate-based representations) reduce the orientation-dependent performance gap between horizontal and vertical corridors?
- Basis in paper: [explicit] Section 5.1 states that "alternative encodings, such as row/column numbered grids or other textual cues, may reduce this issue" regarding orientation-related effects.
- Why unresolved: The current ASCII representation shows sensitivity to map rotation (Figure 8), but no alternative encodings were tested.
- What evidence would resolve it: Comparative experiments using coordinate-based or grid-numbered input formats across all four corridor rotations, measuring accuracy parity between orientations.

### Open Question 3
- Question: Does the counting-based failure mode observed in linear corridors predict LRM performance degradation in more complex planning domains with branching, obstacles, and deadlocks?
- Basis in paper: [explicit] Section 5.1 acknowledges that "corridor tasks have limited external validity, since success or failure may not transfer to richer planning domains" and mentions planned follow-up experiments.
- Why unresolved: The benchmark intentionally isolates long-horizon counting from other complexity factors; the relationship to general planning ability remains untested.
- What evidence would resolve it: Correlation analysis between SokoBench performance and success rates on multi-box Sokoban variants, BlocksWorld, or PDDL planning benchmarks with equivalent horizon lengths.

### Open Question 4
- Question: What mechanistic interventions could convert LRM "wandering" exploration into systematic state-space search with visited-state tracking?
- Basis in paper: [inferred] The paper characterizes LRM behavior as "wandering" rather than systematic (Lu et al. 2025 framework) and notes repetitive looping until token limits, but does not test interventions.
- Why unresolved: The paper documents the wandering behavior but stops short of proposing or evaluating methods to enforce visited-state tracking.
- What evidence would resolve it: Experiments with prompting strategies or fine-tuning that explicitly require models to maintain and reference a "visited states" list during solution generation.

## Limitations
- The benchmark's intentional simplicity (linear corridors with minimal branching) may not generalize to domains requiring rich spatial reasoning, obstacle navigation, or multi-agent coordination.
- The observed 25-move performance collapse appears robust but may vary with problem complexity, prompting strategy, or specific architectural choices.
- The study focuses on ASCII-based spatial encoding, which may not reflect how LLMs process more structured spatial representations like grids or coordinate systems.

## Confidence
- High Confidence: The finding that LLMs exhibit consistent performance degradation beyond 25 moves in linear corridor planning. This is supported by systematic experiments across multiple model families and the clear exponential decay pattern in success rates.
- Medium Confidence: The claim that PDDL tool augmentation provides only modest improvements. While the experimental results show small gains, the paper doesn't explore whether different solver configurations, domain formulations, or post-processing strategies could yield more substantial benefits.
- Medium Confidence: The interpretation that compounding counting errors drive the observed performance limits. The mathematical model (1-p_w)^ℓ is plausible, but direct evidence of per-step miscounting behavior would strengthen this causal claim.

## Next Checks
1. **Cross-domain generalization test**: Apply the SokoBench methodology to a non-linear planning task (e.g., maze navigation with multiple decision points) to determine whether the 25-move limit is specific to linear corridors or represents a more general architectural constraint.

2. **Spatial encoding ablation**: Compare performance using ASCII representations versus explicit coordinate-based encodings or visual input to determine whether the encoding format contributes to the observed counting/dimension errors.

3. **External memory intervention**: Implement a simple visited-state tracking mechanism (e.g., maintaining a set of explored configurations) and measure whether this eliminates the repetitive looping behavior and extends the effective planning horizon.