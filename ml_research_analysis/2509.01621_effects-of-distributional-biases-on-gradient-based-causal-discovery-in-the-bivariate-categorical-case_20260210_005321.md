---
ver: rpa2
title: Effects of Distributional Biases on Gradient-Based Causal Discovery in the
  Bivariate Categorical Case
arxiv_id: '2509.01621'
source_url: https://arxiv.org/abs/2509.01621
tags:
- causal
- distribution
- learning
- case
- interventions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how distributional biases affect gradient-based
  causal discovery in the bivariate categorical case. The authors identify two key
  biases: Marginal Distribution Asymmetry (differences in entropy between marginal
  distributions) and Marginal Distribution Shift Asymmetry (unequal distribution shifts
  during interventions).'
---

# Effects of Distributional Biases on Gradient-Based Causal Discovery in the Bivariate Categorical Case

## Quick Facts
- **arXiv ID**: 2509.01621
- **Source URL**: https://arxiv.org/abs/2509.01621
- **Reference count**: 33
- **Primary result**: Gradient-based causal discovery in bivariate categorical settings is susceptible to two distributional biases—entropy asymmetry and intervention-rate asymmetry—that can steer models toward incorrect causal directions.

## Executive Summary
This paper investigates how distributional biases affect gradient-based causal discovery in the bivariate categorical case. The authors identify two key biases: Marginal Distribution Asymmetry (differences in entropy between marginal distributions) and Marginal Distribution Shift Asymmetry (unequal distribution shifts during interventions). Through controlled experiments with two simple models, they demonstrate that gradient-based methods can be steered toward incorrect causal directions by these biases. Notably, the ENCO model is found to be robust to both biases due to its approach of analyzing causal dependencies separately for each variable. The work highlights the importance of considering distributional biases when designing causal discovery methods.

## Method Summary
The study uses synthetic bivariate categorical data generated from Dirichlet priors, where ε controls marginal distribution entropy asymmetry and λ controls intervention rate asymmetry. Two models are tested: a Marginal Model (MM) that learns marginals only, and a Conditional Model (CM) that learns conditional distributions via a matrix W. Both use Gumbel-Softmax for structural parameters representing causal direction. Training uses cross-entropy loss with Adam optimizer, and experiments are run across 100 seeds for each configuration to ensure robust conclusions about bias effects.

## Key Results
- Gradient-based causal discovery models can be steered by Marginal Distribution Asymmetry, converging toward predicting lower-entropy variables as independent
- Marginal Distribution Shift Asymmetry can fully reverse the direction of causal inference, with intervention rates controlling the bias strength
- The ENCO model demonstrates robustness to both biases due to its separate analysis of causal edges rather than competing factorizations
- Balanced interventions require λ≈0.3-0.4 (not 0.5) to achieve zero distributional shift asymmetry

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Differences in entropy between marginal distributions create asymmetric learning signals that steer models toward predicting lower-entropy variables as independent.
- Mechanism: When ∆H₁,₂ = H(X₁) - H(X₂) ≠ 0, gradient-based models converge to the factorization where the lower-entropy variable is predicted. The "spikier" distribution is easier to learn, creating preferential convergence. The paper controls this via Dirichlet prior parameter ε, where ε=1 yields symmetric marginals (BDe prior), ε>1 gives X₁ higher entropy, and ε<1 gives X₂ higher entropy.
- Core assumption: Causal relationships between variables manifest as asymmetries in marginal distributions even in observational data.
- Evidence anchors:
  - [abstract]: "Marginal Distribution Asymmetry, where differences in entropy skew causal learning toward certain factorizations"
  - [section 5.1, Figure 4]: Shows both MM and CM converge to c₁=0 for ε<1 (predicting X₁) and c₁=1 for ε>1 (predicting X₂), with no convergence at ε=1
  - [corpus]: Limited corpus evidence; related work (Reisach et al. 2021) on varsortability shows similar distribution-based artifacts in continuous settings
- Break condition: ε=1 (BDe prior) eliminates bias by ensuring E[∆H₁,₂]=0

### Mechanism 2
- Claim: Asymmetric distribution shifts during interventions—measured via KL divergence—can fully reverse the direction of causal inference, even when entropy differences are controlled.
- Mechanism: When interventions cause faster shifts in one variable (∆S₁,₂ ≠ 0), the model perceives the faster-changing variable as independent. The intervention rate parameter λ controls this bias: λ=0 (interventions only on X₁) yields ∆S₁,₂>0 and convergence to X₁→X₂; λ=1 (interventions only on X₂) reverses this. The paper proves (Theorem 1, Appendix A.2) that intervening on the cause variable cannot shift the effect's marginal more than the cause's marginal: D_KL(P'(X₂)||P(X₂)) ≤ D_KL(P'(X₁)||P(X₁)).
- Core assumption: Interventions momentarily break causal dependencies, and the rate of distribution recovery differs between cause and effect variables.
- Evidence anchors:
  - [abstract]: "Marginal Distribution Shift Asymmetry, where repeated interventions cause faster shifts in some variables than in others"
  - [section 5.2, Figure 6]: Shows gradual transition from c₁≈1 (low λ) to c₁≈0 (high λ) for both MM and CM, closely tracking ∆S₁,₂ changes
  - [corpus]: No corpus papers directly address intervention-rate-based distribution shift asymmetries
- Break condition: Balanced intervention rates achieving ∆S₁,₂≈0 (empirically requires more interventions on X₁ than X₂)

### Mechanism 3
- Claim: Eliminating direct competition between factorizations by evaluating causal edges independently provides robustness to both distributional biases.
- Mechanism: ENCO (Lippe et al. 2022) separates structural parameters into edge existence (γ) and edge direction (θ), computing gradients that compare a variable's likelihood with vs. without an edge—rather than comparing likelihoods between competing factorizations. For θ₁₂, the gradient has two components: (1) interventions on X₁ provide direct causal signal via L(X₁→X₂), and (2) interventions on X₂ provide invariance signal via L(X₂↛X₁). At least one component always supports the correct direction, never contradicting.
- Core assumption: Correct causal edges should improve likelihood of the dependent variable when added to the model.
- Evidence anchors:
  - [abstract]: "An empirical evaluation of two related, existing approaches indicates that eliminating competition between possible causal factorizations can make models robust"
  - [section 5.3, Equations 12-13]: Gradients for γ₁₂ and θ₁₂ don't compare likelihoods of variables themselves (susceptible to Bias 1) but compare likelihoods with/without edges
  - [corpus]: No corpus papers analyze ENCO's bias robustness properties
- Break condition: None identified within tested parameters; ENCO maintains σ(θ₁₂)≈1 and σ(γ₁₂)>0.5 across all λ and ε values

## Foundational Learning

- Concept: **Entropy and Conditional Entropy**
  - Why needed here: Bias 1 is quantified as entropy difference ∆H₁,₂ between marginal distributions. Understanding how entropy measures distribution "spikiness" is essential for diagnosing and controlling this bias.
  - Quick check question: Given P(X₁)=[0.7,0.3] and P(X₂)=[0.5,0.5], which distribution has higher entropy and which direction would Bias 1 favor?

- Concept: **Kullback-Leibler Divergence**
  - Why needed here: Bias 2 is measured using KL divergence to quantify how much distributions shift before vs. after interventions. The data processing inequality (Theorem 1) bounds this shift.
  - Quick check question: If D_KL(P'(X₁)||P(X₁))=2.0 and D_KL(P'(X₂)||P(X₂))=0.5 for an intervention on X₁, is this consistent with X₁→X₂ causality?

- Concept: **Structural Causal Models and Factorizations**
  - Why needed here: The paper compares competing factorizations P(X₁)P(X₂|X₁) vs. P(X₂)P(X₁|X₂) and how biases influence which factorization models learn.
  - Quick check question: In a bivariate SCM with X₁→X₂, what happens to P(X₂|X₁) when intervening on X₂?

## Architecture Onboarding

- Component map:
  - Data Generation: Dirichlet(α₁) → P(X₁), Dirichlet(α₂) → P(X₂|X₁=x₁), with α₁=1/K, α₂=1/(εK)·1_K
  - Bias Controllers: ε (entropy asymmetry via BDe deviation), λ (intervention rate on X₂, where λ∈[0,1])
  - Marginal Model (MM): Learnable vector i∈R^K, predictions via ĥ₁=c₂i, ĥ₂=c₁i
  - Conditional Model (CM): Learnable matrix W∈R^(K×K), predictions via ĥ₁=c₂W·e_{x₂}, ĥ₂=c₁W·e_{x₁}
  - Structural Parameters: Logits z₁,z₂ → Gumbel-Softmax(z₁,z₂;τ=2) → weights c₁,c₂ encoding causal direction (c₁>0.5: X₁→X₂)
  - Training: Cross-entropy loss, Adam optimizer (lr=0.1), 300 epochs, batch size 128

- Critical path:
  1. Initialize: z₁=z₂=0.5, W/i random, set ε (Bias 1), λ (Bias 2), K=5
  2. Generate data: Sample Dirichlet distributions, apply ancestral sampling, intervene at rate λ in random order
  3. Forward pass: Compute predictions (ĥ₁,ĥ₂) via MM or CM equations
  4. Compute loss: Cross-entropy between one-hot labels and softmax predictions
  5. Backward pass: Update structural parameters (z₁,z₂) and distribution parameters (W or i)
  6. Monitor: Track c₁ convergence (should stabilize near 0 or 1 if bias present, fluctuate around 0.5 if unbiased)

- Design tradeoffs:
  - **MM vs CM**: MM exploits asymmetries more effectively (mean c₁ closely tracks ∆S₁,₂), but CM follows similar trends with flatter curves—choice depends on whether you want to study marginal vs conditional distribution learning
  - **ε=1 vs asymmetric**: ε=1 ensures unbiased observational distributions but may not reflect real-world entropy asymmetries; asymmetric ε tests robustness
  - **λ balance**: Requires λ≈0.3-0.4 to achieve ∆S₁,₂≈0 (not 0.5), since intervening on cause shifts effect less than intervening on effect shifts recovery

- Failure signatures:
  - **Wrong direction with balanced interventions**: If λ≈0.5 but c₁→0 when ground truth is X₁→X₂, check ε (Bias 1 contamination)
  - **No convergence at ε=1, λ=0.5**: Expected behavior (no bias), but verify with longer training or check if model capacity is sufficient
  - **High variance in c₁ across runs**: Model may be switching between competing factorizations; increase Gumbel-Softmax noise or check intervention order randomization
  - **Convergence speed differs between MM/CM**: MM converges faster when exploiting asymmetry; CM requires more epochs when conditional distributions are complex

- First 3 experiments:
  1. **Validate Bias 1 isolation**: Set λ=0 (no interventions), sweep ε∈{0.1,0.5,1.0,2.0,5.0,10.0}, run 100 seeds each with MM. Verify: c₁<0.5 for ε<1, c₁≈0.5 for ε=1, c₁>0.5 for ε>1. Plot c₁ vs ε on log scale (should match Figure 4).
  2. **Validate Bias 2 isolation**: Set ε=1 (no entropy asymmetry), sweep λ∈{0,0.2,0.4,0.6,0.8,1.0}, run 100 seeds each with both MM and CM. Verify: c₁≈1 for λ<0.3, gradual transition, c₁≈0 for λ>0.7. Compute empirical ∆S₁,₂ for each λ and correlate with c₁ (should match Figure 6).
  3. **Test ENCO robustness replication**: Implement ENCO edge parameters (γ₁₂, θ₁₂) with gradients per Equations 12-13. Repeat λ and ε sweeps from experiments 1-2. Expected: σ(θ₁₂)≈1 for all conditions, σ(γ₁₂)>0.5 for λ<1. If σ(θ₁₂) varies significantly, check gradient suppression for intervened variables.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do Marginal Distribution Asymmetry and Marginal Distribution Shift Asymmetry affect convergence in multivariate causal discovery settings ($n > 2$)?
- Basis in paper: [explicit] The study is explicitly restricted to the "bivariate categorical case" in the title and methodology.
- Why unresolved: The paper notes that extending bivariate work to multivariate settings is standard (e.g., SDI), but the propagation of these specific biases through larger, more complex DAGs remains untested.
- What evidence would resolve it: Empirical evaluation of the simple models (MM and CM) on synthetic datasets with $n > 2$ variables under varying $\epsilon$ and $\lambda$.

### Open Question 2
- Question: Do the identified biases influence causal discovery in continuous variable domains using differentiable score functions?
- Basis in paper: [explicit] The methodology relies on categorical distributions with Dirichlet priors, explicitly excluding continuous data types.
- Why unresolved: Bias 1 relies on discrete entropy definitions; it is unclear if the "spikiness" or distribution shift asymmetries translate similarly to density estimation errors in continuous models.
- What evidence would resolve it: Testing gradient-based structure learning on continuous synthetic data (e.g., Gaussian processes) while manipulating the variance/entropy ratios of the marginals.

### Open Question 3
- Question: How do Bias 1 and Bias 2 interact when they compete to influence the convergence direction?
- Basis in paper: [inferred] The authors isolate the biases for clarity (e.g., setting $\epsilon=1$ to study $\lambda$), leaving scenarios where both biases are present and contradictory unanalyzed.
- Why unresolved: In practical settings, models likely face simultaneous entropic asymmetries and intervention rate imbalances, potentially complicating the linear convergence trends observed in isolation.
- What evidence would resolve it: Experiments where $\epsilon$ and $\lambda$ are varied simultaneously to determine which bias dominates the gradient signal or if they cancel out.

## Limitations

- Limited external validation: Only two simple synthetic models (MM, CM) tested; performance on real-world causal discovery benchmarks unknown
- Bias 2 mechanism assumption: The data processing inequality bound assumes interventions momentarily break dependencies, but empirical validation of distribution recovery dynamics remains sparse
- ENCO robustness attribution: The claim that ENCO's separate edge analysis prevents bias is theoretically plausible but lacks ablation studies isolating the critical mechanism

## Confidence

- **High**: Bias 1 (entropy asymmetry) effects on gradient-based causal discovery are clearly demonstrated through controlled experiments
- **Medium**: Bias 2 (intervention-rate asymmetry) can reverse causal inference direction, though real-world applicability depends on intervention protocols
- **Medium**: ENCO's robustness to both biases is empirically shown, but theoretical understanding of why remains incomplete

## Next Checks

1. **Real-world validation**: Apply MM and CM models to benchmark causal discovery datasets (e.g., Tübingen Cause-Effect Pairs) to test whether Bias 1 artifacts appear in practice
2. **Intervention protocol analysis**: Systematically vary intervention duration, recovery time, and target selection to map the full space of Bias 2 effects
3. **ENCO mechanism isolation**: Create ablations of ENCO that remove either the separate edge analysis or the Gumbel-Softmax sampling to identify which component provides bias robustness