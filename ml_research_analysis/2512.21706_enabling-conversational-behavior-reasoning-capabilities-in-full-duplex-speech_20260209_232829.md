---
ver: rpa2
title: Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech
arxiv_id: '2512.21706'
source_url: https://arxiv.org/abs/2512.21706
tags:
- speech
- audio
- reasoning
- text
- conversational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of enabling natural full-duplex
  conversational systems by shifting from black-box prediction to explicit reasoning
  over conversational behaviors. The core method introduces a hierarchical conversational
  behavior detection system that perceives high-level communicative intents and low-level
  speech acts, followed by a Graph-of-Thoughts framework that performs causal inference
  over these behaviors to predict next actions and generate interpretable rationales.
---

# Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech

## Quick Facts
- arXiv ID: 2512.21706
- Source URL: https://arxiv.org/abs/2512.21706
- Authors: Shuchang Pan; Siddharth Banerjee; Dhruv Hebbar; Siddhant Patel; Akshaj Gupta; Kan Jen Cheng; Hanjo Kim; Zeyi Austin Li; Martin Q. Ma; Tingle Li; Gopala Anumanchipalli; Jiachen Lian
- Reference count: 40
- One-line primary result: Hierarchical conversational behavior detection + Graph-of-Thoughts reasoning achieves AUC 0.78-0.95 and F1 0.47-0.88 on synthetic data, maintaining strong performance on real dialogue with interpretable rationale generation.

## Executive Summary
This paper addresses the challenge of enabling natural full-duplex conversational systems by shifting from black-box prediction to explicit reasoning over conversational behaviors. The core method introduces a hierarchical conversational behavior detection system that perceives high-level communicative intents and low-level speech acts, followed by a Graph-of-Thoughts framework that performs causal inference over these behaviors to predict next actions and generate interpretable rationales. Experiments show the framework achieves strong behavior detection performance on synthetic data and maintains high AUC scores on real dialogue data, while producing plausible rationales and demonstrating effective transfer from simulated to real audio.

## Method Summary
The method employs a two-stage approach: first, a hierarchical speech act perception module processes 16kHz stereo audio through HuBERT and Whisper/T5 encoders with gated fusion, using a causal Transformer to predict high-level (constative, directive, commissive, acknowledgment) and low-level (turn-taking, backchannel, interruption, continuation) speech acts per 1-second chunk. Second, a Graph-of-Thoughts reasoning module constructs a directed graph from OpenIE triples and predicted speech acts, encodes it with a GAT, and uses a T5 decoder to generate autoregressive rationales. The system is trained on a hybrid corpus combining controllable synthetic dialogues with human-annotated real data, using class-weighted losses and frozen encoders in both stages.

## Key Results
- Detection performance: AUC 0.78-0.95, F1 0.47-0.88 on synthetic data; AUC 0.70-0.80 on real CANDOR dialogue
- Rationale quality: BLEU-1 scores of 0.48-0.58 with +0.07-0.14 semantic similarity gains when transferring from synthetic to real data
- Synthetic-to-real transfer: Improved rationale generation metrics and maintained detection performance despite different micro-rhythms (shorter overlaps, higher IPU counts)
- Human evaluation: High plausibility ratings for generated rationales on real audio conversations

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Speech Act Perception
Decomposing conversational behavior into high-level communicative intents and low-level speech acts provides a structured, interpretable representation that improves downstream reasoning. A dual-branch classifier processes fused HuBERT audio embeddings and Whisper-derived T5 text embeddings through a causal Transformer, producing parallel high-level and low-level predictions per 1-second chunk, allowing the system to model their dependencies.

### Mechanism 2: Graph-of-Thoughts Causal Inference
Structuring streaming predictions as an evolving Graph-of-Thoughts enables the model to perform causal inference over behavior sequences and generate interpretable rationales. The GoT framework constructs a dynamic, directed graph where nodes are semantic entities from OpenIE triples and predicted speech-act labels, which a GAT encodes and fuses with multimodal representations for T5 decoder-based rationale generation.

### Mechanism 3: Synthetic-to-Real Transfer via Hybrid Corpus
Training on a hybrid corpus of controllable, event-rich synthetic dialogues and human-annotated real data enables effective transfer of reasoning capabilities to real-world audio. The system leverages dense supervision from synthetic data for rare events while maintaining natural conversational patterns from real dialogue, achieving improved rationale generation metrics and robust detection performance.

## Foundational Learning

- **Concept: Full-Duplex vs. Half-Duplex Dialogue**
  - Why needed here: The paper's core contribution is a full-duplex system that processes simultaneous listening and speaking, unlike traditional turn-based systems. Understanding this distinction is crucial for grasping the problem's constraints (e.g., overlapping speech, real-time latency) and the paper's proposed solution.
  - Quick check question: Can a half-duplex model handle interruptions or backchannels without an explicit end-of-turn signal?

- **Concept: Graph Attention Networks (GAT)**
  - Why needed here: The GoT framework uses a GAT to encode the graph of thoughts. Understanding how GAT computes node embeddings by attending to neighbors is essential for following the system's multimodal fusion and reasoning pipeline.
  - Quick check question: How does GAT differ from a standard Transformer in its handling of input structure?

- **Concept: Causal vs. Non-Causal Modeling**
  - Why needed here: The system is designed to be strictly causal (no future information) for streaming inference. The paper explicitly contrasts this with non-causal approaches and studies the impact of look-ahead (`L`) and window size (`W`). This is critical for implementation and deployment.
  - Quick check question: What is the impact of adding a small look-ahead (e.g., L=5s) on model performance and system latency?

## Architecture Onboarding

- **Component map:** Input (16kHz stereo audio) -> Segmentation (1s chunks) -> Perception (HuBERT + Whisper/T5 encoders → gated fusion → causal Transformer → dual classification heads) -> Graph Construction (OpenIE + speech acts) -> Reasoning (GAT encoder + multimodal fusion) -> Generation (T5 decoder for rationales)

- **Critical path:** The causal, streaming inference loop requires: 1) Running perception model for speech act labels, 2) Running incremental ASR and OpenIE to update context graph, 3) Fusing all modalities through GoT reasoning model, 4) Generating rationale and updating GoT state. Latency in any component (especially ASR/OpenIE) breaks the real-time constraint.

- **Design tradeoffs:** Causality vs. Performance (strictly causal lower performance but deployable; look-ahead improves results but adds latency), Modality Fusion (ASR noise can hurt performance requiring conservative gating), Synthetic vs. Real Data (synthetic provides dense supervision but different micro-rhythms).

- **Failure signatures:** ASR errors leading to poor OpenIE triple extraction and corrupted GoT graphs, class imbalance causing inconsistent performance on rare behaviors, sim-to-real gap if synthetic data's conversational dynamics diverge significantly from real human speech.

- **First 3 experiments:**
  1. Ablate Input Modalities: Run GoT reasoning model with Audio-only, Audio+Text, and Audio+Text+Graph on real dialogue; measure BLEU/ROUGE scores for generated rationales.
  2. Sensitivity to ASR Noise: Inject synthetic noise into ASR transcripts (WER 5%-30%) and measure degradation in rationale quality and graph coherence.
  3. Causal Window Analysis: Test perception model with different causal window sizes (W=10,20,30,40s) and look-ahead values (L=0,5,10s) on CANDOR dataset; plot tradeoff between performance and latency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can full-duplex reasoning models move beyond discrete speech-act labels to represent ambiguous or continuous conversational cues?
- Basis in paper: The authors state in the Conclusion and Limitations that "real-world conversational cues are often ambiguous and continuous," making the current use of discrete labels a primary challenge.
- Why unresolved: The current framework relies on hard classifications (e.g., constative, directive), which struggle to capture the fluidity and blended nature of human intent.
- What evidence would resolve it: A model using probabilistic or fuzzy set membership for speech acts that shows higher correlation with human ambiguity ratings in edge-case conversations.

### Open Question 2
- Question: How can the Graph-of-Thoughts pipeline be insulated against error propagation from upstream ASR systems in noisy environments?
- Basis in paper: The authors acknowledge that "system performance is sensitive to upstream errors from ASR" and identify improving robustness in noisy conditions as a critical next step.
- Why unresolved: The GoT construction relies on text transcripts (via OpenIE) to build context nodes; therefore, ASR hallucinations or errors directly corrupt the graph structure and subsequent reasoning.
- What evidence would resolve it: A benchmark evaluating the reasoning pipeline under varying Signal-to-Noise Ratios (SNR) showing stable graph construction when utilizing robust audio features over text transcripts.

### Open Question 3
- Question: Can synthetic training data capture the cultural and stylistic diversity necessary for generalizable conversational reasoning?
- Basis in paper: The authors note that while effective, their synthetic data "may not capture the full diversity of speaking styles, accents, or cultural norms present in human dialogue."
- Why unresolved: The simulation pipeline relies on narrative prompts and specific timbre references (LibriSpeech), which may lack the organic variance found in real-world global populations.
- What evidence would resolve it: Cross-cultural validation showing the model maintains high rationale plausibility and detection AUC when applied to spontaneous dialogue datasets outside the training distribution.

## Limitations

- The causal graph structure assumes pre-defined dependencies between conversational behaviors rather than learning them from data, with no validation of whether these assumed edges reflect true causal relationships.
- The synthetic-to-real transfer relies on the assumption that controllable synthetic dialogues accurately simulate real conversational dynamics, but analysis shows significant differences in micro-rhythms (shorter overlaps, higher IPU counts).
- Performance on rare behaviors (interruption, backchannel) remains limited with F1 scores of 0.47-0.54 despite data enrichment, indicating unreliable handling of critical full-duplex scenarios.

## Confidence

- **High confidence**: Hierarchical speech act detection performance metrics (AUC 0.78-0.95, F1 0.47-0.88) on both synthetic and real data, as these are directly measured on held-out test sets with clear ground truth.
- **Medium confidence**: Rationale generation quality (BLEU-1 0.48-0.58, semantic similarity gains +0.07-0.14) and transfer effectiveness from synthetic to real data, as these depend on the quality of OpenIE extraction and the assumption that synthetic dialogue patterns generalize.
- **Low confidence**: The causal inference claims of the Graph-of-Thoughts framework, as the paper does not validate that the assumed graph edges represent true causal relationships or that the framework actually learns causal reasoning versus pattern matching.

## Next Checks

1. **Ablate the graph structure**: Remove the GoT graph component and test the reasoning model with only multimodal fusion (audio + text + predicted behaviors). Compare rationale quality (BLEU, semantic similarity) to determine if the graph structure adds meaningful causal reasoning or just computational complexity.

2. **Test causal assumption validity**: Design an experiment where you systematically manipulate the graph edge structure (e.g., randomize edges, remove certain dependency types) and measure the impact on rationale plausibility and prediction accuracy. This would validate whether the assumed causal relationships are actually beneficial.

3. **Stress-test with ASR noise**: Implement a controlled experiment where you inject varying levels of word error rates (5%, 15%, 30%) into the ASR transcripts and measure the degradation in OpenIE triple quality, graph coherence, and ultimately rationale generation performance. This quantifies the system's robustness to a critical real-world failure mode.