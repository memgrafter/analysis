---
ver: rpa2
title: 'Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating
  Deliberation'
arxiv_id: '2601.16863'
source_url: https://arxiv.org/abs/2601.16863
tags:
- nsed
- agent
- agents
- round
- consensus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a method for combining multiple small language
  models to achieve performance comparable to much larger models. The approach, called
  N-Way Self-Evaluating Deliberation (NSED), treats model selection as a runtime optimization
  problem and formalizes deliberation as a recurrent process where consensus is refined
  over multiple rounds.
---

# Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation

## Quick Facts
- arXiv ID: 2601.16863
- Source URL: https://arxiv.org/abs/2601.16863
- Reference count: 40
- Primary result: Small language model ensembles (under 20B parameters) achieve performance matching 100B+ parameter models on mathematical and coding benchmarks through N-Way Self-Evaluating Deliberation

## Executive Summary
The paper introduces N-Way Self-Evaluating Deliberation (NSED), a method that unifies heterogeneous small language models to achieve performance comparable to much larger models. By treating model selection as a runtime optimization problem and formalizing deliberation as a recurrent consensus-refinement process, the approach enables ensembles of models under 20B parameters to match or exceed state-of-the-art 100B+ parameter models on challenging benchmarks. The method incorporates novel architectural elements including trustless topology with identity masking, diagonal voting masks to prevent sycophancy, and a Quadratic Voting activation function for non-linear consensus.

## Method Summary
NSED treats model selection as a runtime optimization problem where multiple heterogeneous agents engage in iterative deliberation. The process formalizes consensus refinement over multiple rounds through a recurrent voting mechanism. Key architectural innovations include diagonal voting masks that prevent models from influencing themselves (eliminating sycophancy), a trustless topology with identity masking to ensure fair evaluation, and a Quadratic Voting activation function that enables non-linear consensus aggregation. The method was validated using ensembles of small language models (under 20B parameters) on mathematical reasoning benchmarks (AIME 2025) and coding challenges (LiveCodeBench).

## Key Results
- Ensembles of small models (<20B parameters) achieved performance matching or exceeding 100B+ parameter state-of-the-art models on AIME 2025 and LiveCodeBench benchmarks
- The protocol demonstrated intrinsic alignment properties, reducing sycophancy scores below that of any individual agent when tested on DarkBench safety suite
- Mathematical and coding task performance showed consistent improvement through the deliberation process

## Why This Works (Mechanism)
NSED works by transforming heterogeneous model capabilities into a unified deliberative system. The trustless topology ensures that no single model can dominate or manipulate the consensus process through identity masking and diagonal voting. The recurrent nature of deliberation allows initial disagreements to be progressively refined into stronger consensus. The Quadratic Voting activation function enables the system to weight confident agreements more heavily than simple majority voting would allow, while the runtime optimization approach dynamically selects the most appropriate model combinations for each task.

## Foundational Learning
- Deliberation as consensus refinement: Understanding how iterative voting processes can improve collective decision-making is crucial for implementing NSED effectively. Quick check: Verify that multiple deliberation rounds consistently improve output quality.
- Trustless topology design: The diagonal voting mask and identity masking mechanisms prevent self-influence and manipulation. Quick check: Test that removing diagonal masks increases sycophancy scores.
- Runtime model selection: Treating model combination as an optimization problem rather than a fixed ensemble requires understanding dynamic resource allocation. Quick check: Measure performance degradation when using suboptimal model combinations.

## Architecture Onboarding
Component map: Input Prompt -> Model Ensemble (N agents) -> Diagonal Voting Mask -> Quadratic Voting Aggregation -> Deliberation Round (t) -> Consensus Output
Critical path: Prompt → Individual model responses → Diagonal voting → Quadratic aggregation → Consensus refinement over multiple rounds
Design tradeoffs: The trustless topology prevents manipulation but may reduce potential synergies between highly compatible models. The quadratic voting function better captures confidence but requires additional computation.
Failure signatures: Performance degradation when diagonal masks are removed (increased sycophancy), poor results with insufficient deliberation rounds, and suboptimal model selection for specific task types.
First experiments: 1) Test individual model performance vs ensemble performance on AIME problems, 2) Remove diagonal voting masks and measure sycophancy increase, 3) Vary number of deliberation rounds to find optimal consensus refinement depth

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the generalizability of NSED beyond mathematical and coding tasks, the computational overhead introduced by runtime optimization, and the need for larger-scale safety evaluations. It also notes the potential for extending the deliberation framework to other domains and the question of optimal ensemble sizing for different task categories.

## Limitations
- Focus on mathematical and coding tasks may not generalize to broader domains like commonsense reasoning or creative tasks
- Limited evaluation of computational overhead during runtime optimization could impact practical deployment
- Small sample size in safety evaluations (100 examples) may not capture full range of potential failure modes
- Potential cherry-picking in benchmark selection that favors deliberative approaches

## Confidence
- Performance claims: High (supported by specific benchmark results on AIME 2025 and LiveCodeBench)
- Safety/alignment claims: Medium (limited sample size, need independent verification)
- Architectural innovations: High (clear mathematical formulation and implementation details)

## Next Checks
1. Test the NSED protocol on non-mathematical, non-coding benchmarks (e.g., MMLU, HellaSwag) to assess domain generalization
2. Measure and report the computational overhead and latency introduced by the runtime optimization process
3. Conduct a larger-scale safety evaluation with diverse prompts and adversarial testing to verify the alignment claims