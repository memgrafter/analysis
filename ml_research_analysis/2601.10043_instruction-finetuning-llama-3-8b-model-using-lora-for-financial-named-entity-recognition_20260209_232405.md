---
ver: rpa2
title: Instruction Finetuning LLaMA-3-8B Model Using LoRA for Financial Named Entity
  Recognition
arxiv_id: '2601.10043'
source_url: https://arxiv.org/abs/2601.10043
tags:
- instruction
- financial
- lora
- entity
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach to financial named entity
  recognition (NER) using Llama 3 8B with instruction fine-tuning and LoRA. The method
  converts annotated sentences into instruction-input-output triples and fine-tunes
  only low-rank matrices, achieving a micro-F1 score of 0.894.
---

# Instruction Finetuning LLaMA-3-8B Model Using LoRA for Financial Named Entity Recognition

## Quick Facts
- arXiv ID: 2601.10043
- Source URL: https://arxiv.org/abs/2601.10043
- Reference count: 0
- Primary result: Achieved 0.894 micro-F1 score on financial NER using Llama 3 8B with LoRA-based instruction fine-tuning

## Executive Summary
This paper presents a novel approach to financial named entity recognition (NER) using Llama 3 8B with instruction fine-tuning and LoRA. The method converts annotated sentences into instruction-input-output triples and fine-tunes only low-rank matrices, achieving a micro-F1 score of 0.894. This outperforms strong baselines including Qwen3-8B and Baichuan2-7B by about 6 percentage points. The approach demonstrates that combining instruction tuning with parameter-efficient fine-tuning enables state-of-the-art performance on domain-sensitive NER while maintaining computational efficiency.

## Method Summary
The paper proposes a parameter-efficient fine-tuning approach that combines instruction tuning with Low-Rank Adaptation (LoRA) for financial NER. The method converts annotated sentences into instruction-input-output triples and applies LoRA to fine-tune only low-rank matrices while keeping the original model parameters frozen. This approach enables effective domain adaptation for financial NER while minimizing computational costs compared to full fine-tuning. The instruction format allows the model to better understand the NER task through explicit task descriptions.

## Key Results
- Achieved micro-F1 score of 0.894 on financial NER task
- Outperformed Qwen3-8B and Baichuan2-7B baselines by approximately 6 percentage points
- Demonstrated effectiveness of instruction fine-tuning combined with LoRA for domain-specific NER
- Showed that parameter-efficient fine-tuning can achieve state-of-the-art performance on financial NER

## Why This Works (Mechanism)
The approach leverages the strong pre-training of Llama 3 8B as a foundation and adapts it to the financial domain through instruction fine-tuning. By converting annotated sentences into instruction-input-output triples, the model receives explicit guidance about the NER task, which helps it better understand domain-specific entity types. LoRA enables efficient adaptation by modifying only low-rank matrices, reducing the number of trainable parameters while maintaining the knowledge learned during pre-training. This combination allows the model to leverage its general language understanding capabilities while acquiring domain-specific NER skills.

## Foundational Learning

1. **Low-Rank Adaptation (LoRA)**: A parameter-efficient fine-tuning method that approximates weight updates using low-rank matrices, reducing the number of trainable parameters.
   - Why needed: Enables efficient adaptation of large models without full fine-tuning, reducing computational costs
   - Quick check: Verify that only a small fraction of total parameters are updated during fine-tuning

2. **Instruction Fine-Tuning**: A technique where models are fine-tuned on instruction-input-output pairs to improve task performance and generalization.
   - Why needed: Helps models understand task requirements through explicit instructions rather than implicit patterns
   - Quick check: Compare performance with and without instruction formatting

3. **Named Entity Recognition (NER)**: A sequence labeling task that identifies and classifies named entities in text into predefined categories.
   - Why needed: Core task for information extraction in financial documents and domain-specific applications
   - Quick check: Ensure entity labels align with financial domain requirements

## Architecture Onboarding

Component Map: Pre-trained Llama 3 8B -> Instruction-formatted data -> LoRA adapter layers -> Fine-tuned model

Critical Path: Data preprocessing (instruction conversion) -> LoRA initialization -> Parameter-efficient fine-tuning -> Evaluation

Design Tradeoffs: 
- Full fine-tuning vs. LoRA: Computational efficiency vs. potential performance
- Instruction format vs. standard format: Task clarity vs. data preparation complexity
- Model size vs. efficiency: Performance vs. deployment constraints

Failure Signatures:
- Poor generalization if instruction format doesn't capture task nuances
- Overfitting to training data if LoRA rank is too high
- Suboptimal performance if pre-training knowledge conflicts with domain-specific patterns

First Experiments:
1. Compare LoRA rank configurations to find optimal parameter efficiency vs. performance tradeoff
2. Evaluate different instruction formulations to determine most effective task description
3. Test model performance on out-of-distribution financial text to assess generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Single dataset evaluation without comparison to established NER benchmarks like CoNLL or OntoNotes
- Lack of statistical significance testing and confidence intervals for reported performance metrics
- No quantitative analysis of computational efficiency improvements or parameter counts
- Limited evaluation across different financial sub-domains (banking, insurance, trading)

## Confidence

Performance improvement claims (Medium): The 6 percentage point improvement over baselines is reported but lacks statistical validation and comparative analysis across multiple datasets.

Methodology novelty (Medium): The instruction-tuning approach is reasonable but not clearly differentiated from existing LoRA applications in NER.

Computational efficiency claims (Low): No quantitative evidence provided to support efficiency assertions.

## Next Checks

1. Conduct statistical significance testing with confidence intervals across multiple runs and financial NER datasets to verify the robustness of the 0.894 micro-F1 score.

2. Perform ablation studies comparing different instruction formulations and LoRA rank configurations to quantify their individual contributions to performance gains.

3. Evaluate the model's performance across diverse financial sub-domains and compare against established NER benchmarks to assess generalizability beyond the specific dataset used.