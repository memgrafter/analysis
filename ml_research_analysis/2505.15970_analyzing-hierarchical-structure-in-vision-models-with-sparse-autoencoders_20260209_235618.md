---
ver: rpa2
title: Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders
arxiv_id: '2505.15970'
source_url: https://arxiv.org/abs/2505.15970
tags:
- saes
- hierarchical
- vision
- imagenet
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the question of whether deep vision models
  encode hierarchical relationships found in the ImageNet taxonomy. To investigate
  this, the authors apply Sparse Autoencoders (SAEs) to the DINOv2 vision foundation
  model, treating SAEs as a probe to extract semantically meaningful, sparse features
  from model activations.
---

# Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders

## Quick Facts
- **arXiv ID:** 2505.15970
- **Source URL:** https://arxiv.org/abs/2505.15970
- **Reference count:** 17
- **Primary result:** SAEs reveal hierarchical semantic features in later layers of DINOv2, aligning with ImageNet taxonomy.

## Executive Summary
This study investigates whether deep vision models encode hierarchical relationships from the ImageNet taxonomy by applying Sparse Autoencoders (SAEs) to the DINOv2 vision foundation model. SAEs are used as probes to extract semantically meaningful, sparse features from model activations. The authors define metrics such as Lowest Common Hypernym (LCH) Height and Ontological Coverage to quantify the alignment between extracted features and WordNet-based ImageNet class hierarchies. Results show that later layers of DINOv2 progressively encode hierarchical concepts, with layer 36 exhibiting strong taxonomic alignment. Relevancy maps confirm that SAE-identified features focus on semantically relevant image regions, demonstrating SAEs as an effective tool for revealing hierarchical semantic structure in vision models.

## Method Summary
The authors apply Sparse Autoencoders (SAEs) to the DINOv2 vision foundation model, treating SAEs as probes to extract semantically meaningful, sparse features from model activations. They define metrics—Lowest Common Hypernym (LCH) Height and Ontological Coverage—to quantify the degree to which extracted features correspond to hierarchical groupings in WordNet-based ImageNet classes. The analysis focuses on different layers of DINOv2, assessing the emergence of hierarchical structure across the model's depth. Relevancy maps are used to validate that SAE-identified features focus on semantically relevant image regions.

## Key Results
- Early layers of DINOv2 contain little informative class-related structure.
- Later layers, especially layer 36, progressively encode hierarchical concepts, with numerous SAE heads activating on coherent, higher-order groups such as whales, sharks, or woodwind instruments.
- Relevancy maps confirm that SAE-identified features focus on semantically relevant image regions.

## Why This Works (Mechanism)
SAEs act as probes to extract sparse, semantically meaningful features from model activations, revealing hierarchical relationships encoded in later layers of DINOv2. By aligning these features with WordNet-based ImageNet classes, the study quantifies the model's understanding of taxonomic structure.

## Foundational Learning
- **Sparse Autoencoders (SAEs):** Used to extract sparse, interpretable features from model activations. *Why needed:* To identify semantically meaningful representations. *Quick check:* Verify SAE sparsity and interpretability.
- **WordNet Taxonomy:** Provides hierarchical class groupings for evaluation. *Why needed:* To measure alignment between model features and known hierarchies. *Quick check:* Confirm WordNet hierarchy accuracy.
- **Ontological Coverage:** Metric to quantify how well extracted features cover hierarchical classes. *Why needed:* To assess the breadth of hierarchical understanding. *Quick check:* Validate metric computation.

## Architecture Onboarding
- **Component Map:** DINOv2 -> SAEs -> Feature Extraction -> Ontological Metrics
- **Critical Path:** Model activations → SAE decomposition → Hierarchical feature alignment → Relevancy map validation
- **Design Tradeoffs:** SAE sparsity vs. feature richness; WordNet-based evaluation vs. emergent concepts
- **Failure Signatures:** Lack of hierarchical structure in early layers; misalignment with WordNet classes
- **First Experiments:**
  1. Apply SAEs to early vs. late DINOv2 layers to confirm hierarchical emergence.
  2. Validate SAE feature sparsity and interpretability.
  3. Compute Ontological Coverage for different SAE heads.

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis is confined to a single vision foundation model (DINOv2), limiting generalizability.
- Results may not extend to other architectures or training regimes.
- Reliance on WordNet-based ImageNet taxonomy may not capture nuanced or emergent concepts.

## Confidence
- **High:** SAEs reveal meaningful hierarchical features in later DINOv2 layers; SAE-identified features focus on semantically relevant image regions.
- **Medium:** Early layers contain little class-related structure; layer 36 exhibits strong taxonomic alignment.
- **Low:** Generalizability to other models or taxonomies; causal role of SAE features in model decisions.

## Next Checks
1. Replicate the analysis across diverse vision models (e.g., CLIP, MAE) to assess generalizability.
2. Conduct ablation studies to determine if SAE-extracted features are causally linked to model predictions.
3. Expand the taxonomy evaluation to include non-WordNet hierarchies or emergent semantic clusters.