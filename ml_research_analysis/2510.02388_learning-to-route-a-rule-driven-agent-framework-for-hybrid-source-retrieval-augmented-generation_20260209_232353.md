---
ver: rpa2
title: 'Learning to Route: A Rule-Driven Agent Framework for Hybrid-Source Retrieval-Augmented
  Generation'
arxiv_id: '2510.02388'
source_url: https://arxiv.org/abs/2510.02388
tags:
- routing
- agent
- accuracy
- rule
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a rule-driven routing framework for hybrid-source
  retrieval-augmented generation (RAG) that dynamically selects between relational
  databases and unstructured documents based on query characteristics. The framework
  addresses the limitation of existing RAG systems that either rely solely on unstructured
  documents or naively combine both sources, which can lead to noise and inefficiency.
---

# Learning to Route: A Rule-Driven Agent Framework for Hybrid-Source Retrieval-Augmented Generation

## Quick Facts
- **arXiv ID**: 2510.02388
- **Source URL**: https://arxiv.org/abs/2510.02388
- **Reference count**: 40
- **Key outcome**: Dynamic routing between relational databases and unstructured documents improves accuracy while maintaining moderate computational cost

## Executive Summary
This paper introduces a rule-driven routing framework for hybrid-source retrieval-augmented generation (RAG) that addresses the limitations of existing systems that either rely solely on unstructured documents or naively combine both structured and unstructured sources. The proposed framework dynamically selects between relational databases and unstructured documents based on query characteristics, using a rule-driven routing agent that scores candidate paths with interpretable rules. The method includes a rule-making expert agent for refining rules based on feedback and a path-level meta-cache for reusing routing decisions. Experiments on three QA benchmarks demonstrate consistent improvements over static strategies and learned routing baselines, achieving higher accuracy while maintaining moderate computational cost.

## Method Summary
The framework consists of three main components: a rule-driven routing agent that dynamically selects knowledge sources based on query characteristics, a rule-making expert agent that refines routing rules through feedback, and a path-level meta-cache that stores and reuses routing decisions. The routing agent scores candidate paths using interpretable rules designed to capture different query types and their optimal knowledge sources. The rule-making expert agent iteratively improves these rules based on retrieval and generation outcomes, while the meta-cache enables computational efficiency by avoiding redundant routing decisions for similar queries.

## Key Results
- Consistent improvements over static strategies and learned routing baselines on three QA benchmarks
- Higher accuracy achieved through dynamic source selection between relational databases and unstructured documents
- Moderate computational cost maintained through path-level meta-caching of routing decisions

## Why This Works (Mechanism)
The framework leverages the complementary strengths of structured and unstructured knowledge sources by routing queries to the most appropriate source type. Structured databases excel at handling queries requiring precise, relational information, while unstructured documents are better suited for context-rich, natural language queries. By dynamically selecting between these sources based on query characteristics, the system can provide more accurate answers while avoiding the noise introduced by naive source combination.

## Foundational Learning
- **Hybrid Retrieval-Augmented Generation**: Combining structured and unstructured knowledge sources to improve answer quality - needed to address limitations of single-source RAG systems; quick check: verify source complementarity through ablation studies
- **Rule-Driven Routing**: Using interpretable rules to guide source selection rather than learned policies - needed for transparency and control; quick check: test rule interpretability and consistency
- **Meta-Caching**: Storing and reusing routing decisions to improve efficiency - needed to maintain moderate computational cost; quick check: measure cache hit rates and efficiency gains

## Architecture Onboarding

**Component Map**: Query -> Rule-Driven Routing Agent -> Source Selection (DB/Docs) -> Retrieval -> Generation -> Feedback -> Rule-Making Expert Agent -> Updated Rules

**Critical Path**: Query analysis and routing decision → Source-specific retrieval → Answer generation → Performance evaluation → Rule refinement (if needed)

**Design Tradeoffs**: The framework prioritizes interpretability and control through rule-driven routing over the potential performance gains of fully learned policies. This choice enables better understanding of routing decisions but may limit adaptability to complex or ambiguous queries.

**Failure Signatures**: Poor routing decisions occur when queries don't fit cleanly into rule categories, leading to suboptimal source selection. The framework may struggle with queries that require information from both sources or with ambiguous queries that could be answered by either source type.

**First 3 Experiments**:
1. Compare routing accuracy between rule-driven and learned routing baselines across query types
2. Measure computational overhead with and without meta-caching across different query loads
3. Evaluate end-to-end QA performance when using single-source vs. hybrid-source approaches

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains may not generalize beyond the three QA benchmarks tested
- Reliance on predefined rules may limit adaptability to nuanced or ambiguous queries
- Computational cost claims of "moderate" lack precise quantitative benchmarks

## Confidence

*Hybrid Source Integration Effectiveness* (Medium Confidence): Supported by experimental results but may be dataset-dependent
*Rule-Driven Routing Superiority* (Medium Confidence): Validated on specific benchmarks but relative advantage may vary with different characteristics
*Efficiency-Cost Trade-off* (Low Confidence): Lacks precise quantitative benchmarks and comprehensive ablation studies

## Next Checks
1. **Cross-Domain Generalization Test**: Evaluate framework performance on datasets from different domains (biomedical, legal, technical) to assess effectiveness beyond original QA benchmarks
2. **Rule Robustness Analysis**: Conduct controlled experiments varying rule complexity and coverage to determine framework sensitivity to rule quality
3. **Real-World Deployment Simulation**: Implement scaled-up version with realistic query loads and heterogeneous data sources to measure actual computational overhead and identify bottlenecks