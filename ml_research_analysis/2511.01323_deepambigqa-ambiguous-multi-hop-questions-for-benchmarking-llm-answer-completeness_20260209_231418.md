---
ver: rpa2
title: 'DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness'
arxiv_id: '2511.01323'
source_url: https://arxiv.org/abs/2511.01323
tags:
- question
- reasoning
- answer
- query
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DEEPAMBIGQA addresses the challenge of evaluating large language
  models on complex, ambiguous multi-hop questions that require both entity disambiguation
  and comprehensive evidence retrieval. The authors introduce DEEPAMBIGQAGEN, an automatic
  pipeline that synthesizes such questions using knowledge graphs aligned with text
  corpora, generating structured reasoning plans that can be executed to produce verifiable
  answers.
---

# DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness

## Quick Facts
- arXiv ID: 2511.01323
- Source URL: https://arxiv.org/abs/2511.01323
- Reference count: 40
- Primary result: GPT-5 achieves only 0.13 exact match on ambiguous questions requiring multi-hop reasoning

## Executive Summary
DEEPAMBIGQA introduces a synthetic question generation pipeline to create ambiguous multi-hop QA questions that test LLM answer completeness. The dataset contains 3,600 questions requiring at least two reasoning steps, with half featuring explicit name ambiguity leading to multiple valid reasoning paths. Experiments reveal that even state-of-the-art models struggle with answer completeness, achieving only 0.13 exact match on ambiguous questions, highlighting the gap between current QA systems and the need for exhaustive information gathering.

## Method Summary
The DEEPAMBIGQAGen pipeline operates in three stages: (1) seed entity and relation collection from Wikidata schema, (2) execution plan synthesis using 7 operations (Atomic, Join, Filter, Union, Difference, Intersection, GroupBy) to traverse knowledge graphs and collect answers, and (3) LLM-based question translation (GPT-5-mini) with heuristic and LLM filtering to produce natural questions. The pipeline generates verifiable QA pairs by executing reasoning plans against Wikidata, then translating them to natural language while filtering semantically invalid questions.

## Key Results
- GPT-5 achieves only 0.13 exact match on ambiguous questions vs. 0.21 on non-ambiguous
- Models show high precision (~0.90) but low recall (~0.50), finding partial answers but missing exhaustive retrieval
- Adding Wiki-SPARQL tool caused performance drops due to incorrect query generation
- Human evaluation shows 2.86-2.91/3 naturalness and 91.2-91.6% correctness for generated questions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grounding question generation in executable knowledge-graph operations produces verifiable multi-hop reasoning chains.
- Mechanism: The pipeline constructs reasoning plans as sequences of typed operations that traverse entity-relation graphs, directly executable against Wikidata for deterministic ground truth.
- Core assumption: Knowledge graph relations accurately reflect real-world entity connections and are sufficiently complete.
- Evidence anchors: Abstract states "verifiable questions that systematically embed name ambiguity"; section 3.2 describes executable operations guaranteeing "answer correctness and completeness."

### Mechanism 2
- Claim: Re-executing the same reasoning plan across multiple entity interpretations captures ambiguity-induced answer divergence.
- Mechanism: For ambiguous entity names, the pipeline identifies all distinct entities sharing that name and runs the same execution plan separately for each, producing distinct answer sets.
- Core assumption: Wikipedia disambiguation pages comprehensively cover plausible entity interpretations.
- Evidence anchors: Abstract mentions "half of them explicit name ambiguity resolving"; section 3.2 describes deriving "unique answer sets for each reasoning branch."

### Mechanism 3
- Claim: LLM-based translation from execution plans to natural language preserves reasoning intent while achieving human-like phrasing.
- Mechanism: GPT-5-mini receives structured execution plans and answer sets, generates natural-language questions, with filtering steps removing semantically invalid questions.
- Core assumption: The LLM can reliably map formal operations to natural phrasing without semantic drift.
- Evidence anchors: Section 3.3 describes LLM validity filter assessing "logical validity of execution plans"; human evaluation shows 2.86-2.91/3 naturalness scores.

## Foundational Learning

- **Knowledge Graph Traversal (SPARQL/Wikidata)**
  - Why needed here: Pipeline relies on understanding entity types, relations, and multi-hop paths that mirror SPARQL patterns
  - Quick check question: Given Wikidata entities Q1 (a film) and Q2 (an actor), write a SPARQL query to find all directors who worked with Q2 on films released after 2010

- **Set-Based Reasoning Operations**
  - Why needed here: Pipeline composes operations like Union, Intersection, and GroupBy requiring understanding of intermediate answer set combinations
  - Quick check question: If step 1 returns {A, B, C} and step 2 returns {B, C, D}, what does an Intersection operation yield?

- **Entity Disambiguation via Surface Forms**
  - Why needed here: Ambiguous subset depends on identifying when a string maps to multiple distinct entities
  - Quick check question: How would you determine whether "Apple" in a query refers to the fruit or the company using only Wikipedia structure?

## Architecture Onboarding

- **Component map:** Seed Collection -> Plan Synthesis -> Translation
- **Critical path:** Execution plan synthesis is the bottleneckâ€”if plans produce empty answer sets, the entire QA pair is discarded
- **Design tradeoffs:** Synthetic generation trades annotation cost for potential KG coverage gaps; KG-grounded answers ensure verifiability but may miss recent information; ambiguous questions test different capabilities (fewer steps, more branches)
- **Failure signatures:** Incomplete information extraction (71% of GPT-5 errors), incorrect SPARQL generation when adding KG tool, high precision (~0.90) but low recall (~0.50)
- **First 3 experiments:** 1) Reproduce baseline retrieval + LLM pipeline on 100-question subset, 2) Implement query expansion module and measure recall improvement on ambiguous questions, 3) Test smaller model (Qwen3-4B) with and without evidence extraction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the DeepAmbigQAGen pipeline be extended to integrate open-web text and heterogeneous knowledge graphs to mitigate temporal lag and coverage gaps?
- Basis in paper: Section 7 states authors plan to "extend the current framework to integrate information from the web and other complementary knowledge graphs."
- Why unresolved: Current implementation relies solely on static Wikipedia/Wikidata snapshot missing recent entities or those not in structured graph
- What evidence would resolve it: Modified pipeline synthesizing questions involving recent events or "long-tail" entities found only in unstructured web text

### Open Question 2
- Question: Can the synthesis pipeline's operational schema be generalized to capture ambiguity dimensions beyond name collision, specifically temporal or intentional ambiguity?
- Basis in paper: Section 7 notes dataset "does not yet cover all potential real-world ambiguities (e.g., temporal or intention ambiguities)" and suggests future extensions
- Why unresolved: Current operations designed for entity disambiguation lack primitives for modeling time-dependent or user-intent-dependent variations
- What evidence would resolve it: Successful generation of dataset subset where answers diverge based on valid temporal interpretations

### Open Question 3
- Question: What specific training or prompting strategies are required to enable LLMs to reliably utilize structured Knowledge Graph tools for complex, ambiguous reasoning?
- Basis in paper: Section 5.3 reports adding Wiki-SPARQL tool caused performance drop because models failed to generate correct, executable queries
- Why unresolved: State-of-the-art models struggle to translate natural language ambiguous queries into precise formal syntax and entity identifiers
- What evidence would resolve it: LLM agent that, when provided with KG tool, matches or exceeds text-retrieval-only baselines on DeepAmbigQA benchmark

## Limitations

- KG completeness and disambiguation page coverage limitations affect generated question quality
- Synthetic generation may produce questions with different difficulty distribution than naturally occurring ambiguous multi-hop questions
- GPT-5-mini filtering step lacks transparency in prompt engineering and evaluation criteria

## Confidence

- **High confidence**: Core mechanism of using executable KG operations to generate verifiable answers is well-specified and technically sound
- **Medium confidence**: LLM-based translation and filtering pipeline achieves good human evaluation scores but lacks detailed reproducibility specifications
- **Low confidence**: Assumption that Wikipedia disambiguation pages comprehensively capture all valid entity interpretations for ambiguous names is untested

## Next Checks

1. **Coverage validation**: Measure proportion of ambiguous names where Wikidata+Wikipedia coverage is complete vs. partial/missing; identify failure patterns for underrepresented entities
2. **Difficulty transfer**: Compare model performance on DEEPAMBIGQA versus human-annotated ambiguous multi-hop questions to assess whether synthetic generation captures real-world complexity
3. **Ablation study**: Test whether GPT-5-mini filtering steps actually improve question quality beyond simple heuristic filtering using blind human evaluation on filtered vs. unfiltered subsets