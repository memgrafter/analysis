---
ver: rpa2
title: 'Contextual Candor: Enhancing LLM Trustworthiness Through Hierarchical Unanswerability
  Detection'
arxiv_id: '2506.01104'
source_url: https://arxiv.org/abs/2506.01104
tags:
- unanswerability
- refusal
- unanswerable
- questions
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Reinforced Unanswerability Learning (RUL),\
  \ a novel training paradigm designed to imbue large language models (LLMs) with\
  \ the intrinsic capability to accurately detect unanswerable questions and generate\
  \ appropriately reliable responses. RUL integrates a discriminative unanswerability\
  \ prediction head with the LLM\u2019s generative core, trained through a two-stage\
  \ process: supervised fine-tuning on a novel Enhanced-CAsT-Answerability (ECA) dataset\
  \ with hierarchical answerability labels and ground-truth refusal responses, followed\
  \ by reinforcement learning with human feedback (RLHF) to refine the helpfulness\
  \ and informativeness of refusal responses."
---

# Contextual Candor: Enhancing LLM Trustworthiness Through Hierarchical Unanswerability Detection

## Quick Facts
- arXiv ID: 2506.01104
- Source URL: https://arxiv.org/abs/2506.01104
- Reference count: 37
- Primary result: Novel RUL framework improves unanswerability detection and refusal generation in LLMs via SFT + RLHF on ECA dataset

## Executive Summary
This paper introduces Reinforced Unanswerability Learning (RUL), a two-stage training paradigm designed to equip large language models with the ability to accurately detect unanswerable questions and generate reliable refusal responses. RUL combines supervised fine-tuning on a newly constructed Enhanced-CAsT-Answerability (ECA) dataset with hierarchical answerability labels, followed by reinforcement learning with human feedback to refine refusal quality. The approach integrates a discriminative unanswerability prediction head with the generative core, enabling joint training for both detection and response generation. Empirical results show substantial improvements over strong baselines in unanswerability detection accuracy and refusal generation, with human evaluations confirming enhanced perceived helpfulness and trustworthiness.

## Method Summary
RUL employs a two-stage training process: first, supervised fine-tuning on the ECA dataset, which provides hierarchical answerability labels (sentence, paragraph, and ranking levels) and ground-truth refusal responses; second, reinforcement learning with human feedback (RLHF) to further refine the helpfulness and informativeness of refusal responses. A discriminative unanswerability prediction head is integrated with the LLM's generative core, trained jointly to optimize both detection and response generation. The ECA dataset is specifically constructed to support this hierarchical labeling and includes unanswerable queries with appropriate refusal responses. This design enables the model to learn both when to refuse and how to refuse informatively.

## Key Results
- RUL achieves substantially higher unanswerability detection accuracy across sentence, paragraph, and ranking levels compared to strong baselines.
- The model significantly increases the generation of appropriate refusals for unanswerable queries.
- Human evaluations confirm marked improvements in perceived helpfulness and trustworthiness of RUL's refusal responses.

## Why This Works (Mechanism)
RUL's effectiveness stems from its two-stage training pipeline that first grounds the model in labeled data (SFT) and then refines its refusal behavior with human preferences (RLHF). The discriminative unanswerability head allows the model to explicitly reason about whether a question is answerable, while the generative core learns to produce appropriate refusal responses. By training these components jointly, the model develops an intrinsic capability to detect and respond to unanswerable queries in a trustworthy manner.

## Foundational Learning
- **Supervised Fine-Tuning (SFT)**: Why needed - To ground the model in labeled examples of unanswerable questions and correct refusal responses. Quick check - Verify the ECA dataset contains sufficient diversity in unanswerable query types.
- **Reinforcement Learning with Human Feedback (RLHF)**: Why needed - To align refusal responses with human notions of helpfulness and informativeness. Quick check - Ensure human evaluators are calibrated and representative.
- **Hierarchical Answerability Labels**: Why needed - To capture unanswerability at multiple granularities (sentence, paragraph, ranking). Quick check - Confirm label consistency across hierarchy levels.
- **Discriminative Prediction Head**: Why needed - To enable explicit reasoning about unanswerability before generating a response. Quick check - Validate that the head's predictions correlate with final refusal decisions.
- **Joint Training of Detection and Generation**: Why needed - To ensure the model's refusal behavior is consistent with its unanswerability judgments. Quick check - Monitor for misalignment between detection scores and refusal outputs.

## Architecture Onboarding
- **Component Map**: LLM Encoder-Decoder -> Discriminative Unanswerability Head + Generative Core -> Output
- **Critical Path**: Input question → Unanswerability prediction head → (Refuse or Generate) → Output response
- **Design Tradeoffs**: Joint training of detection and generation increases model complexity but improves coherence; hierarchical labels provide richer supervision but require careful annotation; RLHF improves refusal quality but is resource-intensive.
- **Failure Signatures**: Over-refusal (refusing answerable questions), under-refusal (answering unanswerable questions), vague or unhelpful refusals, inconsistent refusal behavior across similar questions.
- **Three First Experiments**:
  1. Evaluate unanswerability detection accuracy on ECA test set at sentence, paragraph, and ranking levels.
  2. Measure refusal generation quality using automated metrics (e.g., relevance, coherence) and human evaluation.
  3. Conduct ablation study comparing RUL with variants: SFT-only, RLHF-only, and baseline models.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements are based on a single newly constructed dataset (ECA), raising concerns about generalization to other domains or annotation styles.
- The claim of "intrinsic capability" for unanswerability detection may overstate robustness without cross-dataset validation.
- The relative contributions of SFT versus RLHF to final performance are not fully isolated or explained.

## Confidence
- **High Confidence**: The two-stage training pipeline (SFT + RLHF) is methodologically sound and clearly described.
- **Medium Confidence**: Quantitative improvements over baselines are likely real but may be dataset-specific; human evaluation is appropriate but lacks detailed methodology.
- **Low Confidence**: The claim of "intrinsic capability" for unanswerability detection is not fully substantiated without broader validation or ablation studies.

## Next Checks
1. Evaluate RUL on at least two publicly available, independently constructed unanswerability detection benchmarks to test generalization beyond the ECA dataset.
2. Conduct an ablation study isolating the impact of RLHF from SFT by comparing models trained with only SFT, only RLHF, and the full RUL pipeline.
3. Perform a detailed error analysis on failure cases, categorizing mistakes by type (e.g., false positives, false negatives, partial refusals) and assessing whether errors are systematic or random.