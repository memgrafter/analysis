---
ver: rpa2
title: What LLMs Think When You Don't Tell Them What to Think About?
arxiv_id: '2602.01689'
source_url: https://arxiv.org/abs/2602.01689
tags:
- text
- figure
- qwen
- gpt-oss
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Large language models were studied under minimal, topic-neutral
  prompts to reveal unconstrained generative behaviors. Across 256,000 samples from
  16 models, outputs spanned a broad semantic space even without explicit topics,
  with each model family showing systematic topical preferences: GPT-OSS predominantly
  generated programming (27.1%) and math content (24.6%), Llama favored literary content
  (9.1%), DeepSeek often produced religious content, and Qwen frequently generated
  multiple-choice questions.'
---

# What LLMs Think When You Don't Tell Them What to Think About?

## Quick Facts
- **arXiv ID**: 2602.01689
- **Source URL**: https://arxiv.org/abs/2602.01689
- **Reference count**: 40
- **Primary result**: Large language models show systematic topic preferences and generate diverse content even under minimal, topic-neutral prompts, revealing unconstrained generative behaviors relevant to AI monitoring and safety.

## Executive Summary
This study investigates how large language models behave when given minimal, topic-neutral prompts, revealing that models generate diverse content across a broad semantic space even without explicit guidance. The research finds systematic topical preferences across different model families: GPT-OSS favors programming and math, Llama leans toward literary content, DeepSeek produces religious content, and Qwen generates multiple-choice questions. The study also demonstrates that GPT-OSS produces more technically advanced content than other models, while degenerate text patterns vary systematically across families. These findings highlight how minimally conditioned generation can effectively reveal model tendencies important for AI monitoring and safety applications.

## Method Summary
The researchers analyzed 256,000 samples from 16 different language models using the simple prompt "You are a helpful assistant. What would you like to talk about?" They employed automated categorization tools and deduplication methods to classify the generated content into topical categories and analyze patterns across model families. The study examined both the semantic diversity of outputs and the technical depth of content produced, while also characterizing degenerate text patterns unique to different model families.

## Key Results
- Large language models generate diverse content spanning broad semantic space even under minimal, topic-neutral prompts
- Different model families show systematic topical preferences: GPT-OSS (programming 27.1%, math 24.6%), Llama (literary 9.1%), DeepSeek (religious), and Qwen (multiple-choice questions)
- GPT-OSS produces more technically advanced content than other models, with variations in degenerate text patterns across families (formatting artifacts, URLs to personal accounts)

## Why This Works (Mechanism)
When large language models are given minimal prompts without explicit topical guidance, they draw from their learned distributions to generate content. The models' training data composition and architectural biases influence their tendency to gravitate toward certain topics. Without external constraints, the internal representations and probability distributions learned during training surface more prominently, revealing systematic preferences that may not be apparent under task-specific prompting. The lack of explicit constraints allows the models' inherent tendencies to manifest more clearly.

## Foundational Learning
- **Semantic space exploration**: Understanding how models navigate and sample from their learned semantic distributions is crucial for characterizing unconstrained behavior. Quick check: Visualize topic distributions using dimensionality reduction techniques.
- **Model family characteristics**: Different architectures and training approaches lead to distinct generative tendencies. Quick check: Compare cross-family topic distributions using statistical tests.
- **Technical depth measurement**: Quantifying the sophistication of generated content requires systematic analysis of subcategory complexity. Quick check: Validate depth metrics against human expert ratings.
- **Degenerate pattern detection**: Identifying abnormal or low-quality text patterns requires robust automated detection methods. Quick check: Manually review samples flagged as degenerate to assess false positive rates.

## Architecture Onboarding

**Component Map**: User Input -> Prompt Processing -> Context Window -> Attention Mechanism -> Output Generation -> Content Categorization -> Analysis Pipeline

**Critical Path**: Prompt Reception → Token Generation → Semantic Classification → Topic Assignment → Pattern Analysis

**Design Tradeoffs**: The study balances automation (speed and scale) against accuracy (potential for misclassification), and simplicity (minimal prompts) against representativeness (potential bias from prompt choice). The cross-sectional design provides breadth but sacrifices temporal depth.

**Failure Signatures**: Potential failures include prompt-induced bias limiting topic diversity, proprietary categorization tools introducing systematic errors, and automated methods underestimating the full range of degenerate behaviors. Cross-sectional design may miss temporal evolution of generative patterns.

**First Experiments**:
1. Test multiple prompt variations to assess sensitivity to initial conditions
2. Validate automated categorization against human expert classification
3. Compare degenerate pattern detection methods to identify false positive/negative rates

## Open Questions the Paper Calls Out
None

## Limitations
- Simple prompt "You are a helpful assistant. What would you like to talk about?" may not fully capture unconstrained behavior and could bias responses
- Proprietary categorization and deduplication tools introduce potential biases and errors that are difficult to fully characterize
- Cross-sectional design limits understanding of how generative behaviors evolve over time or in response to different contexts

## Confidence
- GPT-OSS generates most technically advanced content: High confidence (well-supported by systematic analysis across multiple subcategories and depth metrics)
- Systematic family-level preferences: High confidence (robustly demonstrated through consistent patterns across all 16 models)
- Characterization of degenerate text patterns: Medium confidence (credible but may underestimate full range due to specific detection methods)

## Next Checks
1. Replicate the study using multiple prompt variations to assess sensitivity to initial conditions and identify whether observed patterns are robust across different minimal prompts
2. Conduct human evaluation studies to validate automated categorization accuracy and assess whether identified topical preferences align with human judgments of content
3. Perform longitudinal tracking of the same models over time to determine whether observed generative behaviors are stable or evolve with model updates and additional training