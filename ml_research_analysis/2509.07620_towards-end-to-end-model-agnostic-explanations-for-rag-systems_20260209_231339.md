---
ver: rpa2
title: Towards End-to-End Model-Agnostic Explanations for RAG Systems
arxiv_id: '2509.07620'
source_url: https://arxiv.org/abs/2509.07620
tags:
- explanations
- generator
- systems
- framework
- retriever
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a model-agnostic framework for explaining Retrieval-Augmented
  Generation (RAG) systems through perturbation-based techniques. The approach provides
  explanations for both the retrieval and generation processes by decomposing inputs
  (documents or prompts) into features, perturbing them, and measuring their impact
  on model outputs.
---

# Towards End-to-End Model-Agnostic Explanations for RAG Systems

## Quick Facts
- arXiv ID: 2509.07620
- Source URL: https://arxiv.org/abs/2509.07620
- Reference count: 8
- Presents model-agnostic framework for explaining both retrieval and generation in RAG systems through perturbation techniques

## Executive Summary
This paper introduces a model-agnostic framework for explaining Retrieval-Augmented Generation (RAG) systems through perturbation-based techniques. The approach provides explanations for both retrieval and generation processes by decomposing inputs into features, perturbing them, and measuring their impact on model outputs. The framework demonstrates that models generating more accurate answers tend to focus on the most relevant context portions. Despite scoring slightly lower than model-intrinsic approaches in user satisfaction, the model-agnostic nature offers flexibility across both open-source and proprietary models, making it particularly valuable for end-users of RAG systems.

## Method Summary
The framework employs a perturbation-based approach where inputs (documents or prompts) are decomposed into features at different granularities - word-level for retriever explanations and sentence-level for generator explanations. A "leave one feature out" perturbation strategy is used, where each feature is systematically removed and the impact on model outputs is measured. For the retriever, explanations show which documents are most relevant to a query, while for the generator, explanations reveal which context portions most influence the final answer. The framework was validated through user studies where participants evaluated the completeness and accuracy of explanations against human annotations.

## Key Results
- Retriever explanations achieved 64.7% completeness in user studies
- Generator explanations reached an F1 score of 76.9% against human annotations
- User satisfaction scores showed the framework scored 3.42 (completeness) and 3.98 for model-intrinsic approaches

## Why This Works (Mechanism)
The framework works by systematically perturbing individual features of the input and measuring their impact on the final output. By removing one feature at a time and observing changes in retrieval scores or generated answers, the approach identifies which features are most influential. This perturbation-based methodology allows for model-agnostic explanations that don't require access to model internals, making it applicable across different RAG architectures and both open-source and proprietary models.

## Foundational Learning
- **Perturbation-based explanations**: Systematically modifying inputs to measure impact on outputs; needed to understand how individual features influence model decisions; quick check: verify that removing key features significantly changes output
- **Feature decomposition**: Breaking down inputs into analyzable components (words/sentences); needed to identify which specific elements drive model behavior; quick check: ensure features capture meaningful semantic units
- **Model-agnostic vs model-intrinsic approaches**: Different methods for generating explanations that either work across models or require model-specific access; needed to understand trade-offs between flexibility and accuracy; quick check: compare explanation quality across different model types
- **Granularity selection**: Choosing appropriate feature sizes (word vs sentence level); needed to balance explanation precision with computational efficiency; quick check: validate that chosen granularity captures relevant semantic information
- **User study validation**: Using human evaluators to assess explanation quality; needed to establish real-world usefulness of generated explanations; quick check: ensure diverse participant pool and clear evaluation criteria

## Architecture Onboarding

Component map: Input Document/Query -> Feature Decomposition -> Perturbation Engine -> Impact Measurement -> Explanation Generation -> User Interface

Critical path: The perturbation engine forms the critical path, as it systematically removes each feature and measures the impact on both retrieval scores and generation outputs. This process directly determines the quality and completeness of the final explanations.

Design tradeoffs: The framework trades computational efficiency for model-agnostic flexibility. While model-intrinsic approaches may provide more accurate explanations, they require access to model internals. The perturbation approach works universally but requires multiple inference passes (one per feature), making it computationally expensive for large documents.

Failure signatures: Explanations may miss important feature interactions since the "leave one feature out" approach doesn't capture synergistic effects between features. Additionally, the framework may generate incomplete explanations if the perturbation strategy doesn't adequately represent all relevant semantic relationships.

First experiments:
1. Apply the framework to a simple RAG system with known ground truth to verify explanation accuracy
2. Compare explanation quality between word-level and sentence-level granularities on the same dataset
3. Measure computational overhead when processing documents of increasing length

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- The perturbation strategy may miss important interactions between features due to the "leave one feature out" approach
- Word-level granularity for retriever explanations and sentence-level granularity for generator explanations may not capture nuanced semantic relationships
- The study does not address computational efficiency or scalability concerns when applying perturbation techniques to large document collections

## Confidence
High: Model-agnostic framework provides flexibility across different RAG architectures
Medium: User study results show reasonable performance but lack objective benchmarks
Medium: Finding that more accurate models focus on relevant context portions needs larger-scale verification

## Next Checks
1. Evaluate the framework's performance across multiple RAG architectures including both open-source and proprietary models
2. Assess computational overhead and scalability when processing large document collections
3. Validate explanation quality using objective performance metrics beyond user studies, such as retrieval accuracy improvements and generation quality gains