---
ver: rpa2
title: Few-shot Continual Relation Extraction via Open Information Extraction
arxiv_id: '2502.16648'
source_url: https://arxiv.org/abs/2502.16648
tags:
- relation
- relations
- extraction
- undetermined
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method to address Few-shot Continual Relation
  Extraction (FCRE) by integrating Open Information Extraction (OIE) to handle undetermined
  relations. The approach constructs an open dataset with all possible entity pairs
  and uses OIE to generate candidate relation descriptions, enriching the training
  data.
---

# Few-shot Continual Relation Extraction via Open Information Extraction

## Quick Facts
- arXiv ID: 2502.16648
- Source URL: https://arxiv.org/abs/2502.16648
- Reference count: 25
- FewRel T8 F1: 67.62% (without UR), 43.11% (with UR)

## Executive Summary
This paper addresses Few-shot Continual Relation Extraction (FCRE) by integrating Open Information Extraction (OIE) to handle undetermined relations. The method constructs an open dataset with all possible entity pairs and uses OIE to generate candidate relation descriptions, enriching the training data. Through a combination of Weighted Mutual Information Loss and Hard Soft Margin Triplet Loss, the approach aligns sample and description embeddings while handling class imbalance from undetermined relations. Experiments show the method outperforms state-of-the-art FCRE baselines on FewRel and TACRED datasets, achieving up to 43.11% F1 score on FewRel when tested with undetermined relations.

## Method Summary
The approach uses BERT with soft prompts as the backbone, enhanced by NER to extract all entities and create an augmented dataset containing both determined and undetermined relations. OIE (via ChatGPT-4o-mini) generates candidate triplets and descriptions for undetermined relations. The model employs three loss functions: Hard Soft Margin Triplet Loss for discriminative power, and two Weighted Mutual Information losses for aligning samples with raw and candidate descriptions. Memory-based continual learning stores representative samples per relation to prevent catastrophic forgetting. Inference uses Nearest-Class-Mean classification with optional OIE filtering for undetermined relations.

## Key Results
- Achieves 67.62% F1 on FewRel T8 without undetermined relations
- Achieves 43.11% F1 on FewRel T8 with undetermined relations (43.11% vs 37.06% with OIE filtering)
- Achieves 37.79% F1 on TACRED T8 with undetermined relations
- OIE filtering improves UR handling by 6.05 percentage points on FewRel

## Why This Works (Mechanism)

### Mechanism 1
Expanding training data to include all entity pair combinations with undetermined relation labels improves robustness to unseen relations at inference time. A Named Entity Recognition (NER) module extracts all entities from each sentence, labeling matching pairs as determined relations (DR) and others as undetermined relations (UR). This creates an augmented dataset substantially increasing size (FewRel train: 1,350 DR samples vs. 7,431 UR samples).

### Mechanism 2
Aligning sample embeddings with both original and OIE-generated candidate descriptions via weighted mutual information improves representation quality under class imbalance. Two description types are used—raw (dataset-provided) and candidate (OIE-generated via ChatGPT-4o-mini). A weighted InfoNCE-based mutual information loss maximizes alignment between sample embeddings and description embeddings, with class-balanced weights compensating for UR label dominance.

### Mechanism 3
Hard Soft Margin Triplet Loss (HSMT) improves discriminative power by maximizing separation between hardest positive and hardest negative pairs with adaptive margin flexibility. The loss integrates hard mining (selecting most challenging positive/negative within a batch) with a soft, log-based margin (no fixed margin hyperparameter), pushing apart semantically similar relations while allowing adaptive flexibility.

## Foundational Learning

- **Few-shot Continual Learning (N-way-K-shot paradigm)**: The model must learn new relations from only K=5 examples per relation while retaining all previously learned relations across sequential tasks. *Why needed*: Standard fine-tuning fails catastrophically in this setting due to catastrophic forgetting.
- **Contrastive Learning and Mutual Information Maximization**: The HSMT and weighted MI losses are contrastive objectives that shape the embedding space to separate relation classes and align samples with descriptions. *Why needed*: These losses provide semantic anchors that help the model distinguish relations even when batch composition is dominated by undetermined relation samples.
- **Open Information Extraction (OIE)**: OIE enables extraction of relations without predefined schemas, generating candidate triplets and descriptions for undetermined or unseen relations. *Why needed*: This provides flexibility to handle relations not present in the training set while creating negative examples for training.

## Architecture Onboarding

- **Component map**: NER Module -> Open Dataset Constructor -> OIE Module -> Description Augmenter -> BERT Encoder -> Training Loss Combiner -> Memory Buffer -> Inference Classifier
- **Critical path**: Input sentence → NER → entity pairs → label (DR/UR) → OIE → candidate triplet + description → augmented descriptions → BERT encoder → embeddings → HSMT + weighted MI losses → update model → store L samples per relation → OIE filter (optional) → NCM classification
- **Design tradeoffs**: K=5 optimally balances diversity and noise for augmented descriptions; with vs. without OIE filtering at inference improves UR handling but adds LLM inference cost; memory size L impacts retention vs. footprint
- **Failure signatures**: High UR misclassification if true relations are incorrectly labeled as UR; catastrophic forgetting on later tasks if memory buffer is undersized; OIE hallucination if LLM generates spurious relations
- **First 3 experiments**: 1) Baseline replication on FewRel without UR labels to validate implementation; 2) Ablation on K (1,3,5,7,10) for augmented descriptions to confirm K=5 optimum; 3) UR sensitivity test with varying UR:DR ratios to assess robustness to class imbalance

## Open Questions the Paper Calls Out

1. **Computational efficiency optimization**: The paper identifies training and testing with many undetermined relations as computationally expensive and time-consuming, calling for optimized processes.
2. **Latent valid relations in UR set**: The authors note that UR samples may contain instances aligning with predefined relation types but cannot verify due to scope limitations.
3. **Dynamic loss weighting strategies**: The paper suggests dynamic loss weighting and reinforcement learning to prioritize underperforming components as future work, moving beyond current static hyperparameters.

## Limitations

- Computational expense from training and testing with large numbers of undetermined relations
- Potential label noise from latent valid relations incorrectly assigned to UR category
- Dependence on OIE quality and LLM reliability for candidate description generation
- Memory management opacity with unspecified buffer size L per relation

## Confidence

**High Confidence** (Multiple supporting evidences, clear mechanism):
- HSMT loss improves discriminative power through adaptive margin flexibility
- Weighted MI loss effectively handles class imbalance from UR dominance
- Memory replay prevents catastrophic forgetting across sequential tasks

**Medium Confidence** (Evidence exists but with gaps):
- OIE-generated descriptions improve UR handling (assumes OIE quality is sufficient)
- Dataset augmentation with all entity pairs improves robustness to unseen relations (assumes UR labels are clean)
- Weighted MI alignment between samples and descriptions improves representation quality (assumes description embeddings are semantically meaningful)

**Low Confidence** (Limited evidence, single results):
- Method supports Knowledge Graph Construction in continual learning settings (only mentioned as potential application)
- Approach generalizes to real-world scenarios with unlimited entity pairs (only evaluated on FewRel and TACRED benchmarks)

## Next Checks

1. Implement ablation study varying K (1, 3, 5, 7, 10) for augmented descriptions across all tasks and plot F1 scores for T4 and T8 to verify K=5 optimum.
2. Perform UR sensitivity analysis by training with different UR:DR ratios (1:1, 2:1, 5:1, 10:1), monitoring per-class loss weights via Eq. 7 and overall F1 to quantify robustness to class imbalance.
3. Conduct OIE quality assessment by manually validating 100 randomly sampled candidate descriptions from ChatGPT-4o-mini and computing precision/recall against ground truth relations to determine whether OIE noise limits effectiveness.