---
ver: rpa2
title: 'MORE: Multi-Objective Adversarial Attacks on Speech Recognition'
arxiv_id: '2601.01852'
source_url: https://arxiv.org/abs/2601.01852
tags:
- more
- adversarial
- accuracy
- efficiency
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MORE, the first unified adversarial attack
  method that simultaneously targets both accuracy and efficiency in large-scale automatic
  speech recognition (ASR) models like Whisper. MORE uses a hierarchical two-stage
  strategy combining a repulsion stage for accuracy degradation with an anchoring
  stage that employs a novel repetitive encouragement doubling objective (REDO) to
  induce long, structured repetitions in transcriptions.
---

# MORE: Multi-Objective Adversarial Attacks on Speech Recognition

## Quick Facts
- arXiv ID: 2601.01852
- Source URL: https://arxiv.org/abs/2601.01852
- Reference count: 40
- Key outcome: MORE achieves 10-14× output length increase while maintaining >70% WER across Whisper models

## Executive Summary
This paper introduces MORE, the first unified adversarial attack method that simultaneously targets both accuracy and efficiency in large-scale automatic speech recognition (ASR) models like Whisper. MORE uses a hierarchical two-stage strategy combining a repulsion stage for accuracy degradation with an anchoring stage that employs a novel repetitive encouragement doubling objective (REDO) to induce long, structured repetitions in transcriptions. Experiments on LibriSpeech and LJ-Speech datasets show that MORE consistently generates transcriptions 10-14 times longer than baseline attacks while maintaining high word error rates, effectively revealing dual vulnerabilities in ASR models. Across Whisper model sizes, MORE increases inference FLOPs by 9-14× compared to normal outputs, quantifying a significant efficiency vulnerability beyond accuracy degradation.

## Method Summary
MORE implements a hierarchical two-stage adversarial attack on Whisper ASR models. Stage 1 (Repulsion) uses 50 PGD steps to maximize WER via negative cross-entropy loss. Stage 2 (Anchoring) employs a novel repetitive encouragement doubling objective (REDO) that periodically doubles predicted sequences to induce long repetitions. The attack uses ℓ∞ constraints with ε=0.002 (35 dB SNR) or 0.0035 (30 dB SNR), evaluated on Whisper tiny/base/small/medium/large models using LibriSpeech and LJ-Speech datasets.

## Key Results
- MORE increases Whisper transcription length by 10-14× while maintaining WER >70%
- Across Whisper sizes, MORE increases inference FLOPs by 9-14× compared to normal outputs
- MORE outperforms single-objective baselines in both WER and efficiency metrics simultaneously
- Hierarchical approach resolves gradient competition between accuracy and efficiency objectives

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Two-Stage Optimization
Separating accuracy and efficiency objectives into sequential stages avoids gradient competition that destabilizes simultaneous multi-objective optimization. The repulsion stage first maximizes WER using negative cross-entropy as a proxy. The anchoring stage then exploits remaining degrees of freedom to extend decoding, using the high-error state as a starting point.

### Mechanism 2: Repetitive Encouragement Doubling Objective (REDO)
Periodic construction of doubled target sequences creates self-reinforcing repetition loops that reliably extend output length. Every D steps, REDO greedy-decodes the perturbed input, strips EOS, and constructs a doubled target. Cross-entropy loss then trains the model to reproduce this extended sequence.

### Mechanism 3: Dual EOS Suppression with Competing Token Boost
Simultaneously penalizing EOS probability while boosting the second-best token creates stronger continuation pressure than EOS suppression alone. L_EOS = P_EOS^L - P_z^L reduces EOS dominance while nudging toward the alternative continuation token z.

## Foundational Learning

- Concept: Autoregressive decoding dynamics
  - Why needed here: MORE exploits the sequential dependency where each predicted token conditions all future predictions; EOS sensitivity is the key attack surface.
  - Quick check question: If you modify logits only at position L (final position), what is the gradient path back to earlier positions?

- Concept: Multi-objective gradient conflict
  - Why needed here: The paper explicitly avoids joint optimization because accuracy and efficiency objectives have mismatched gradient scales and spatial concentration.
  - Quick check question: When summing two loss terms with different gradient magnitudes, what happens to the smaller-gradient objective?

- Concept: Perturbation imperceptibility constraints
  - Why needed here: SNR bounds overall perturbation energy while ℓ∞ bounds peak amplitude, jointly ensuring psychoacoustic masking.
  - Quick check question: Why does constraining SNR alone still permit perceptible "spike" artifacts?

## Architecture Onboarding

- Component map: Raw speech X → Perturbation δ → Whisper model → Transcription Y
- Critical path:
  1. Initialize δ = 0, clip to [-ε, ε]
  2. For i = 1 to K_a: compute L_acc, update δ via signed gradient
  3. For i = K_a+1 to K: if (i-K_a-1) mod D = 0, greedy decode and rebuild doubled target; compute L_EOS + L_REDO, update δ
  4. Return final δ

- Design tradeoffs:
  - K_a vs. (K - K_a): More repulsion steps → higher WER but less efficiency amplification capacity
  - Doubling period D: Smaller D → more frequent target updates (potentially better loops) but higher greedy-decoding overhead
  - SNR threshold: Lower SNR (e.g., 30 dB) → stronger attacks but risk of perceptibility

- Failure signatures:
  - WER < 70%: Repulsion stage failed (check gradient flow on L_acc)
  - Output length < 100 tokens: Anchoring stage failed (verify REDO target construction, check if greedy decode produces valid segments)
  - Random output without structured repetition: REDO not forming loops (inspect if doubled targets are being used correctly)
  - Attack-time FLOPs explode: REDO causing unbounded L_m growth (check for L_max cap implementation)

- First 3 experiments:
  1. Ablation study: Run MORE with L_EOS removed, L_REDO removed, and both removed to quantify each component's contribution
  2. Hyperparameter sweep: Vary D ∈ {5, 10, 15, 20} and K_a ∈ {30, 50, 70} to find the Pareto frontier of WER vs. output length
  3. Cross-model transfer: Craft δ on Whisper-tiny, evaluate on Whisper-large to assess transferability

## Open Questions the Paper Calls Out

### Open Question 1
What defense mechanisms can effectively mitigate MORE-style multi-objective attacks while preserving ASR model utility? The paper suggests potential defenses including decoding-time safeguards such as repetition/loop detectors; input-time defenses such as band-limiting; and training-time strategies such as adversarial training focused on EOS/repetition pathologies.

### Open Question 2
How transferable are MORE-generated adversarial perturbations across different ASR model architectures beyond the Whisper family? All experiments evaluate only on five Whisper-family models, leaving cross-architecture transferability unexplored.

### Open Question 3
How robust is MORE under black-box attack scenarios where the adversary lacks full model access? The paper focuses exclusively on white-box attacks with full access to model parameters and gradients.

## Limitations

- Specification gaps exist for critical hyperparameters including total PGD steps, doubling period, and step size
- Experiments focus exclusively on white-box attacks against Whisper variants without evaluating black-box transferability
- Hierarchical approach requires multiple greedy decoding passes during attack generation, increasing computational overhead

## Confidence

- High Confidence: The hierarchical two-stage optimization approach demonstrably achieves both high WER (>70%) and substantial length amplification (10-14×)
- Medium Confidence: The specific mechanisms (REDO, dual EOS suppression) contribute to the attack's effectiveness, but isolating individual contributions is challenging
- Low Confidence: Claims about the fundamental nature of the ASR efficiency vulnerability and its distinction from accuracy attacks are speculative

## Next Checks

1. Reproduce the attack with K=100 total steps, K_a=50 repulsion steps, D=10 doubling period, and α=0.0003 step size. Systematically remove L_REDO, L_EOS, and both to quantify individual contributions.

2. Craft adversarial perturbations on Whisper-tiny and evaluate them against Whisper-base, medium, and large models to determine cross-model transferability of both WER and length amplification vulnerabilities.

3. Measure wall-clock time to generate adversarial examples for 10-second audio clips using the full MORE attack versus single-stage baselines, comparing against real-time requirements (10× real-time for 10-second audio).