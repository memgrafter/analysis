---
ver: rpa2
title: Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge
  Distillation
arxiv_id: '2602.01956'
source_url: https://arxiv.org/abs/2602.01956
tags:
- uncertainty
- draft
- target
- estimation
- epistemic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel framework for efficient epistemic
  uncertainty estimation in large language models by leveraging small draft models
  used in speculative decoding. The method decomposes uncertainty into a variance
  proxy (Jensen-Shannon divergence among draft models) and a bias proxy (KL divergence
  between draft mixture and target), eliminating the need for expensive ensemble passes.
---

# Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation

## Quick Facts
- **arXiv ID**: 2602.01956
- **Source URL**: https://arxiv.org/abs/2602.01956
- **Authors**: Seonghyeon Park; Jewon Yeom; Jaewon Sok; Jeongjae Park; Heejun Kim; Taesup Kim
- **Reference count**: 18
- **Primary result**: Reduces RMSE of epistemic uncertainty estimates by up to 37.67% on GSM8K while matching hallucination detection performance of heavy perturbation baselines at 42% lower computational cost.

## Executive Summary
This work introduces a novel framework for efficient epistemic uncertainty estimation in large language models by leveraging small draft models used in speculative decoding. The method decomposes uncertainty into a variance proxy (Jensen-Shannon divergence among draft models) and a bias proxy (KL divergence between draft mixture and target), eliminating the need for expensive ensemble passes. To ensure effective approximation, the authors introduce Online Stochastic Distillation (OSD) and Data-Diverse Drafts (DDD) training, which promote posterior diversity across drafts. Experiments on GSM8K show up to 37.67% reduction in RMSE compared to baselines. For hallucination detection, the method matches the performance of heavy perturbation-based approaches like TokUR while reducing inference costs by up to 42%.

## Method Summary
The approach leverages small draft models from speculative decoding to estimate epistemic uncertainty efficiently. The key insight is decomposing uncertainty into variance (JSD among draft models) and bias (KL between draft mixture and target) components. The authors introduce Online Stochastic Distillation (OSD) to train a proxy mixture model that approximates the Bayesian Model Average, and Data-Diverse Drafts (DDD) to train multiple drafts on disjoint data partitions to ensure posterior diversity. At inference, token-level EU is computed as JSD(drafts) + KL(qmix||pmix), avoiding costly ensemble passes through the target model.

## Key Results
- Up to 37.67% reduction in RMSE for epistemic uncertainty estimation compared to baseline methods on GSM8K
- Matches TokUR performance for hallucination detection while reducing computational cost by 42%
- Demonstrates effective calibration with improved AUROC and reduced ECE/Brier scores for detection tasks

## Why This Works (Mechanism)
The method works by exploiting the parallel inference capability of speculative decoding. By training multiple small draft models to approximate the posterior distribution of the target LLM, the framework can estimate both variance (through disagreement among drafts) and bias (through distance from target) without expensive ensemble inference. The OSD and DDD training methods ensure that the drafts capture meaningful diversity in the target's posterior distribution, making the JSD proxy an effective variance estimator.

## Foundational Learning
- **Epistemic uncertainty**: Uncertainty due to limited training data; needed to quantify model confidence and detect hallucinations
- **Jensen-Shannon divergence**: Symmetric divergence measure between probability distributions; quick check: JSD(p,q) = 0.5*KL(p||m) + 0.5*KL(q||m) where m = 0.5*(p+q)
- **KL divergence**: Asymmetric measure of difference between distributions; quick check: KL(P||Q) ≥ 0 with equality iff P=Q almost everywhere
- **Speculative decoding**: Inference optimization using draft models; needed to reduce computational cost of LLM inference
- **Bayesian Model Average**: Weighted combination of model predictions weighted by posterior probability; quick check: BMA(x) = ∫ p(y|x,θ)p(θ|D)dθ
- **Low-rank Gaussian noise injection**: Technique for posterior sampling; needed to generate diverse outputs from target model

## Architecture Onboarding

**Component map**: GSM8K queries -> Target LLM (perturbed) -> Draft ensemble (6 models) -> Proxy mixture (pmix) -> Token-level EU

**Critical path**: Input generation → Posterior sampling → Draft training → EU computation at inference

**Design tradeoffs**: Uses existing speculative decoding infrastructure vs. custom ensemble approaches; sacrifices some accuracy for significant computational savings

**Failure signatures**: Draft models collapse (JSD→0), poor calibration despite low RMSE, computational savings not realized

**Exactly 3 first experiments**:
1. Generate training data by sampling 4 responses per GSM8K query from perturbed target models
2. Train proxy pmix with OSD using Forward KL objective for 12 epochs
3. Train 6 draft models using DDD approach with 2×3 data partitioning configuration

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to GSM8K dataset without demonstrated generalization to other domains
- Ground truth EU estimation relies on assumptions about posterior representation that aren't rigorously validated
- Claims of matching TokUR performance are qualified by noting only marginal improvements and slightly worse Brier scores
- Computational cost savings comparison lacks benchmarking against other lightweight uncertainty methods

## Confidence

**High confidence**: Theoretical framework for EU decomposition and use of JSD/KL proxies are internally consistent and mathematically justified

**Medium confidence**: Experimental results on GSM8K are reproducible given detailed setup, but generalization claims aren't fully supported

**Low confidence**: Hallucination detection claims are plausible but under-specified; methodology for extracting answers and exact logistic regression setup are unclear

## Next Checks

1. Validate ground-truth EU estimation by testing sensitivity to noise injection rank, distribution, and number of posterior samples; confirm KL(p_θ||p_T) stabilizes as N increases

2. Test domain generalization by applying trained model to non-mathematical dataset (e.g., summarization or sentiment analysis) and report EU calibration and detection performance

3. Benchmark against lightweight alternative (e.g., Monte Carlo dropout with reduced dropout rate) to isolate contribution of draft-based approach versus other efficiency gains