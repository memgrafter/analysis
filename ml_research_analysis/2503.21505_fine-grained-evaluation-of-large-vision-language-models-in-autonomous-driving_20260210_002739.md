---
ver: rpa2
title: Fine-Grained Evaluation of Large Vision-Language Models in Autonomous Driving
arxiv_id: '2503.21505'
source_url: https://arxiv.org/abs/2503.21505
tags:
- traffic
- vehicle
- lane
- driving
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "VLADBench introduces a fine-grained benchmark for evaluating large\
  \ vision-language models in autonomous driving, addressing limitations in existing\
  \ coarse-grained datasets. It spans 5 key domains\u2014Traffic Knowledge Understanding,\
  \ General Element Recognition, Traffic Graph Generation, Target Attribute Comprehension,\
  \ and Ego Decision-Making and Planning\u2014with 29 detailed tasks."
---

# Fine-Grained Evaluation of Large Vision-Language Models in Autonomous Driving

## Quick Facts
- **arXiv ID**: 2503.21505
- **Source URL**: https://arxiv.org/abs/2503.21505
- **Reference count**: 40
- **Primary result**: VLADBench evaluates 20 VLMs across 29 fine-grained driving tasks, finding top models achieve <60% accuracy and highlighting generalization challenges.

## Executive Summary
VLADBench introduces a comprehensive benchmark for evaluating large vision-language models in autonomous driving contexts, addressing the limitations of existing coarse-grained datasets. The benchmark spans 5 key domains—Traffic Knowledge Understanding, General Element Recognition, Traffic Graph Generation, Target Attribute Comprehension, and Ego Decision-Making and Planning—with 29 detailed tasks. Through evaluation of 20 VLM models, including open-source, closed-source, and domain-specific variants, the study reveals significant performance gaps even among state-of-the-art models like Qwen2.5-VL-72B, which achieve less than 60% accuracy. The research also demonstrates that while domain-specific data enhances specialized capabilities, it may reduce generalization, and that synergy among domains improves overall performance.

## Method Summary
The study introduces VLADBench, a fine-grained evaluation framework for VLMs in autonomous driving, comprising 5,000 scenes (2,000 static, 3,000 dynamic) from 12 diverse sources with 12,000 close-form questions across 29 tasks. The evaluation protocol measures accuracy, instruction compliance, IoU for detection, and trajectory metrics. Additionally, the authors train a domain-specific model (InternVL2-4B) by fine-tuning on 2.7M QA pairs (1.4M AD-specific + 1.3M general) using full-parameter fine-tuning over 2 epochs with a batch size of 1 and learning rate of 1e-5 on 128 V100 GPUs. The study systematically evaluates 20 VLM models across the benchmark, analyzing performance patterns across domains and the impact of domain-specific training on generalization.

## Key Results
- Even top-performing models (Qwen2.5-VL-72B) achieve less than 60% accuracy on VLADBench, highlighting significant performance gaps.
- Domain-specific data enhances specialized capabilities but may reduce generalization, with negative performance impacts observed in Traffic Graph Generation when trained on GER/EDP data.
- Synergy among the five key domains improves overall performance, with models trained on domain-specific data showing domain-specific gains but suffering in cross-domain generalization.

## Why This Works (Mechanism)
VLADBench succeeds by providing a fine-grained, multi-domain evaluation framework that exposes the limitations of current VLMs in autonomous driving contexts. The benchmark's detailed task decomposition reveals specific weaknesses in model reasoning and generalization that coarse-grained evaluations miss. The domain-specific training approach demonstrates that while targeted data improves specialized performance, it comes at the cost of broader applicability, highlighting the fundamental trade-off between specialization and generalization in VLM training.

## Foundational Learning
- **Autonomous Driving Perception**: Understanding how VLMs process visual information for driving tasks is essential because driving requires interpreting complex scenes with multiple objects and relationships.
- **Vision-Language Alignment**: Models must align visual features with language understanding to answer questions about driving scenes, requiring joint training of vision and language components.
- **Domain Adaptation**: The ability to specialize models for specific domains (like autonomous driving) while maintaining generalization is crucial for practical deployment.
- **Fine-grained Evaluation**: Breaking down complex tasks into detailed subtasks reveals specific model weaknesses that aggregate metrics might miss.
- **Multi-modal Reasoning**: Autonomous driving requires reasoning across visual, spatial, and linguistic modalities simultaneously, which is a key challenge for VLMs.
- **Generalization vs. Specialization**: There's an inherent trade-off between training models for specific domains and maintaining broad applicability across diverse tasks.

## Architecture Onboarding

**Component Map**: Input Scenes → VLM Backbone → Multi-domain Task Processor → Output Answers

**Critical Path**: Scene Input → Visual Feature Extraction → Language Understanding → Domain-specific Reasoning → Answer Generation

**Design Tradeoffs**: Full-parameter fine-tuning vs. adapter-based approaches for domain adaptation; single-view vs. multi-view inputs for spatial reasoning; breadth of task coverage vs. depth of specialization.

**Failure Signatures**: Low accuracy on Traffic Graph Generation indicates weak relational reasoning; poor instruction compliance suggests output format issues; generalization drops reveal catastrophic forgetting from domain-specific training.

**Three First Experiments**:
1. Evaluate baseline models on individual VLADBench tasks to identify specific weakness patterns.
2. Test different ratios of general to domain-specific training data to optimize the specialization-generalization tradeoff.
3. Compare full-parameter fine-tuning against adapter-based approaches for domain adaptation efficiency.

## Open Questions the Paper Calls Out
- How does the integration of multi-view inputs influence the 3D spatial perception and reasoning capabilities of VLMs compared to the single-view approach utilized in VLADBench?
- What specific data sampling strategies or curriculum learning methods can optimize the synergy between the five key domains while preventing the loss of generalization?
- Is elevating the vision encoder strictly more effective than scaling the language model for high-level relational reasoning tasks like Traffic Graph Generation?

## Limitations
- The benchmark relies on single-view inputs, limiting assessment of 3D spatial perception and surround awareness capabilities critical for autonomous driving.
- The exact composition of the 1.3M general QA pairs used in domain-specific training is not fully disclosed, making it difficult to assess potential domain shift artifacts.
- Statistical significance of performance differences across domains is not established, limiting causal interpretation of observed patterns.

## Confidence

**High Confidence**: Benchmark design (29 tasks across 5 domains) is well-justified; overall evaluation methodology is transparent; finding that top models achieve <60% accuracy is robust and clearly demonstrated.

**Medium Confidence**: Domain-specific training results showing reduced generalization are plausible but require more rigorous statistical validation; inference that synergy among domains improves performance is supported by correlation patterns but lacks controlled ablation studies.

**Low Confidence**: Exact mechanisms behind catastrophic forgetting when mixing general and AD-specific data are not explored; paper does not address potential dataset biases in the curated 2.7M QA pairs.

## Next Checks
1. **Statistical Significance Testing**: Perform paired t-tests or bootstrapping on model performance across domains to determine if observed differences are statistically significant rather than random variation.
2. **Ablation on QA Composition**: Systematically vary the ratio of general to AD-specific QAs in training (e.g., 0%, 50%, 100% AD-specific) and measure performance trade-offs to quantify the generalization-cost relationship.
3. **Filter Bias Analysis**: Implement and compare multiple answer-format filtering strategies (e.g., strict vs. lenient token matching) to assess how preprocessing choices impact accuracy metrics and whether they systematically favor certain model types.