---
ver: rpa2
title: Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed
  Conformal Prediction
arxiv_id: '2510.15233'
source_url: https://arxiv.org/abs/2510.15233
tags:
- uncertainty
- coverage
- prediction
- intervals
- tessera
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces TESSERA, a novel uncertainty quantification
  method for protein-ligand affinity prediction that combines Mixture-of-Experts (MoE)
  uncertainty decomposition with conformal prediction calibration. TESSERA addresses
  the challenge of providing reliable, adaptive, and informative per-sample uncertainty
  in drug discovery, where assay noise is heterogeneous, chemical space is imbalanced,
  and distribution shifts are common.
---

# Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction

## Quick Facts
- arXiv ID: 2510.15233
- Source URL: https://arxiv.org/abs/2510.15233
- Authors: Amitesh Badkul; Lei Xie
- Reference count: 40
- Primary result: Novel uncertainty quantification method combining MoE uncertainty decomposition with conformal prediction for reliable protein-ligand affinity prediction

## Executive Summary
This work introduces TESSERA, a novel uncertainty quantification method for protein-ligand affinity prediction that combines Mixture-of-Experts (MoE) uncertainty decomposition with conformal prediction calibration. TESSERA addresses the challenge of providing reliable, adaptive, and informative per-sample uncertainty in drug discovery, where assay noise is heterogeneous, chemical space is imbalanced, and distribution shifts are common. The method decomposes uncertainty into epistemic (expert disagreement) and aleatoric (per-expert variance) components, then applies split conformal calibration to produce prediction intervals with finite-sample coverage guarantees.

Evaluated on protein-ligand binding affinity prediction under both i.i.d. and scaffold-based out-of-distribution splits, TESSERA achieves near-nominal coverage (PICP ≈ 0.91 at 1-α = 0.90), competitive interval efficiency (MPIW = 4.03, NMPIW = 0.17), and strong adaptivity (AUSE = 0.64), outperforming baselines including MC Dropout, RIO-GP, and eMOSAIC. The method maintains performance across different molecular encoders and demonstrates reliable, right-sized intervals that increase under data scarcity or noise and remain tight when predictions are reliable.

## Method Summary
TESSERA combines Mixture-of-Experts (MoE) architecture with conformal prediction to provide adaptive uncertainty quantification for protein-ligand affinity prediction. The method decomposes total uncertainty into epistemic uncertainty (variance across expert predictions) and aleatoric uncertainty (mean of individual expert variances), then applies split conformal calibration to produce prediction intervals with guaranteed coverage. This approach addresses the challenge of heterogeneous assay noise and distribution shifts in drug discovery by providing sample-specific uncertainty estimates that adapt to data scarcity and noise levels.

## Key Results
- Achieves near-nominal coverage with PICP ≈ 0.91 at target 1-α = 0.90
- Competitive interval efficiency with MPIW = 4.03 and NMPIW = 0.17
- Strong adaptivity with AUSE = 0.64, outperforming MC Dropout, RIO-GP, and eMOSAIC baselines

## Why This Works (Mechanism)
The method works by leveraging the inherent uncertainty decomposition in MoE architectures: expert disagreement captures epistemic uncertainty about which expert is correct, while per-expert variance captures aleatoric uncertainty about the inherent noise in each expert's predictions. Conformal calibration then provides finite-sample coverage guarantees by adjusting intervals based on calibration data. This combination allows the method to produce adaptive, right-sized intervals that are tight when predictions are reliable and expand under uncertainty or data scarcity.

## Foundational Learning
- **Conformal Prediction**: Non-parametric uncertainty quantification providing finite-sample coverage guarantees. Needed because traditional confidence intervals may not achieve desired coverage in finite samples, especially under distribution shift.
- **Mixture-of-Experts (MoE)**: Ensemble architecture where gating network routes inputs to specialized experts. Quick check: verify that gating mechanism effectively partitions input space and that experts learn complementary representations.
- **Epistemic vs Aleatoric Uncertainty**: Epistemic uncertainty (reducible with more data) vs aleatoric uncertainty (irreducible inherent noise). Needed because different sources of uncertainty require different treatment strategies.
- **Scaffold-Based Evaluation**: Chemical structure-based split testing model generalization to unseen molecular scaffolds. Quick check: ensure scaffold splits are truly OOD by measuring Tanimoto similarity between train/test scaffolds.
- **Calibration Error Metrics**: Metrics like PICP, MPIW, and AUSE that evaluate both coverage and interval efficiency. Needed because coverage alone is insufficient - intervals must also be informative.

## Architecture Onboarding
- **Component Map**: Molecular Encoder -> MoE Layer (Gating + N Experts) -> Uncertainty Decomposition -> Conformal Calibration -> Prediction Interval
- **Critical Path**: Input molecule → Molecular encoder → MoE gating → Expert predictions → Uncertainty decomposition → Conformal calibration → Final prediction interval
- **Design Tradeoffs**: MoE provides uncertainty decomposition but adds complexity; conformal calibration provides guarantees but requires calibration data; tradeoff between interval width and coverage.
- **Failure Signatures**: Poor coverage indicates conformal calibration failure or inappropriate uncertainty decomposition; overly wide intervals suggest miscalibration or excessive uncertainty; inconsistent intervals across similar samples indicate gating problems.
- **3 First Experiments**:
  1. Verify MoE gating learns meaningful input partitioning by visualizing expert activation patterns
  2. Test uncertainty decomposition by measuring correlation between epistemic/aleatoric components and prediction accuracy
  3. Validate conformal calibration coverage on held-out calibration set before full evaluation

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical justification for uncertainty decomposition approach remains underdeveloped
- Performance evaluation limited to protein-ligand binding affinity prediction domain
- Computational overhead for large-scale screening campaigns not fully characterized

## Confidence
- **High confidence** in empirical evaluation results and experimental design
- **Medium confidence** in theoretical foundations of uncertainty decomposition approach
- **Low confidence** in scalability and computational efficiency for industrial applications

## Next Checks
1. Evaluate TESSERA on additional molecular property prediction tasks (solubility, toxicity, ADMET) to assess generalizability across different chemical space regions and property types.
2. Conduct ablation studies to quantify individual contributions of MoE uncertainty decomposition versus conformal calibration, and test alternative uncertainty decomposition strategies.
3. Perform extensive computational profiling to measure wall-clock time, memory usage, and energy consumption compared to baselines for large-scale virtual screening campaigns.