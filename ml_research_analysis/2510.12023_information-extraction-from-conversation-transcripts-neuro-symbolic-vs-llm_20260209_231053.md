---
ver: rpa2
title: 'Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM'
arxiv_id: '2510.12023'
source_url: https://arxiv.org/abs/2510.12023
tags:
- system
- information
- extraction
- llm-based
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares a neuro-symbolic (NS) and an LLM-based system
  for extracting structured information from agricultural interview transcripts across
  pork, dairy, and crop domains. The NS system uses rule-based extraction with syntactic
  parsing and embedding-based ontology grounding, while the LLM approach employs topic
  segmentation, in-context learning, and hallucination filtering.
---

# Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM

## Quick Facts
- **arXiv ID:** 2510.12023
- **Source URL:** https://arxiv.org/abs/2510.12023
- **Reference count:** 21
- **Primary result:** LLM-based system outperforms neuro-symbolic system (F1 total: 69.4 vs. 52.7; core: 63.0 vs. 47.2) with better recall but slower runtime.

## Executive Summary
This paper compares a neuro-symbolic (NS) and an LLM-based system for extracting structured information from agricultural interview transcripts across pork, dairy, and crop domains. The NS system uses rule-based extraction with syntactic parsing and embedding-based ontology grounding, while the LLM approach employs topic segmentation, in-context learning, and hallucination filtering. Evaluated on nine interviews, the LLM-based system achieved higher performance with better recall but slower runtime. The NS system was faster, more controllable, and precise for context-free tasks but struggled with generalization and contextual nuances. The study highlights trade-offs between performance, efficiency, and control in real-world IE system deployment.

## Method Summary
The paper evaluates two approaches for structured information extraction from agricultural interview transcripts. The shared pipeline includes rev.ai ASR, transcript correction, and filler removal. The neuro-symbolic system uses a multi-task encoder for syntactic parsing, Odin rules for fragment extraction, dialogue management for context assembly, and embedding-based grounding. The LLM system uses keyword segmentation, OpenChat 3.5 with in-context learning via Pydantic dataclasses, JSON schema validation, and hallucination filtering through string overlap verification. Both systems target identifier-value pair extraction with ontology grounding.

## Key Results
- LLM-based system achieved higher F1 scores (Total: 69.4 vs 52.7; Core: 63.0 vs 47.2)
- LLM showed better recall but slower runtime (22,987s vs 69s on CPU)
- NS system was faster and more controllable but had lower recall
- Neither system fully solved the extraction problem

## Why This Works (Mechanism)

### Mechanism 1
Structured extraction from noisy dialogue is improved by constraining LLM outputs via explicit schema definitions provided in-context. The system defines target fields using Pydantic dataclasses, which are serialized into JSON schemas within the prompt. This forces the model to generate valid JSON that maps directly to the ontology structure, reducing parsing errors and structure drift.

### Mechanism 2
Hallucination rates in extraction tasks are reduced by cross-referencing generated outputs against the source text. The system implements a verification filter that checks if extracted string values have at least partial overlap with the input segment. If an extraction has zero word overlap with the source, it is discarded as a hallucination.

### Mechanism 3
Processing long conversational contexts improves when the input is segmented by topic before extraction. Rather than feeding an entire long transcript into the model, the system splits interviews into smaller blocks based on keyword triggers. This narrows the expected information scope for each inference call.

## Foundational Learning

- **Concept: Ontology Grounding**
  - Why needed: Both systems extract raw text, but the final goal is to map messy natural language to a standardized ID in a knowledge base.
  - Quick check: How does the system handle synonymy where two different phrases map to the same ontology node?

- **Concept: Dialogue Management (The "Context Gap")**
  - Why needed: In interviews, a question and its answer are often separated by multiple turns or sentences. A simple sentence-level extractor fails here.
  - Quick check: In the Neuro-Symbolic system, what heuristic is used to link a value extracted in turn N to an identifier asked in turn N-3?

- **Concept: Hallucination vs. ASR Error**
  - Why needed: The system must distinguish between the LLM inventing facts (hallucination) and the LLM correctly extracting a fact that was transcribed wrongly by the ASR.
  - Quick check: Does the verification layer filter out a correct extraction if the ASR transcript contains a typo not present in the LLM's correction?

## Architecture Onboarding

- **Component map:** Audio → ASR (rev.ai) → Raw Transcript → Preprocessing → Divergence → NS Path: Encoder → Odin Rules → Dialogue Manager → Embedding Grounding OR LLM Path: Keyword Segmentation → LLM → JSON Validation → Overlap Filter → CSV Grounding

- **Critical path:** The LLM Verification Layer is the critical safety net. Without this, the higher recall of the LLM comes with unacceptably high hallucination rates. The Topic Segmentation is the critical context manager.

- **Design tradeoffs:**
  - Control vs. Recall: NS offers control and precision in context-free tasks while LLMs provide generalization
  - Speed: NS is ~330x faster on CPU (69s vs 22,987s). Use NS for real-time/edge applications; use LLM for batch processing where accuracy is paramount.

- **Failure signatures:**
  - ASR Cascade: "South" extracted instead of "sows" (NS fails if rule relies on exact string; LLM might infer context but filtered if strict overlap required)
  - Unit-less values: NS fails hard here; LLM is more flexible but prone to hallucinating units
  - Segmentation bleed: If topic segmentation fails, the LLM extracts "barn" info while looking at "crop" segments

- **First 3 experiments:**
  1. Ablate the Hallucination Filter: Run the LLM pipeline without the string-overlap check to quantify the precision drop
  2. Stress Test Dialogue Management: Feed the NS system transcripts with increasing distance between Identifier and Value to find the breaking point
  3. Domain Transfer: Apply the existing LLM prompt (Zero-shot) to a held-out 10th interview from a slightly different agricultural subdomain

## Open Questions the Paper Calls Out

- Would a hybrid system combining NS precision with LLM generalization capabilities outperform either approach alone for dialogue-based IE?
- Do these findings generalize to other domains and IE tasks beyond agricultural interviews?
- Can statistical topic segmentation methods improve LLM-based extraction accuracy compared to the keyword-based approach used in this study?
- Can semi-automated rule learning reduce NS development overhead while maintaining precision advantages?

## Limitations

- Evaluation constrained to nine interviews within a narrow agricultural domain, limiting generalizability
- Neuro-symbolic system's performance heavily dependent on manually crafted rules and unspecified encoder backbone
- Hallucination filter has documented blind spots for numeric/boolean fields and paraphrased content
- Claims about "better controllability" and "better precision" lack comparative quantitative support beyond aggregate F1 scores

## Confidence

- **High Confidence:** LLM achieves superior recall while NS maintains significant speed advantages
- **Medium Confidence:** LLM's structured generation via JSON schema and topic segmentation effectiveness are logically sound but need ablation studies
- **Low Confidence:** Claims about NS "better controllability" and LLM "better precision" lack quantitative comparative support

## Next Checks

1. Ablate the Hallucination Filter: Run the LLM pipeline without the string-overlap check to quantify the precision drop and establish the true "hidden cost" of its higher recall
2. Stress Test Dialogue Management: Systematically vary the turn distance between identifiers and values in test transcripts to find the breaking point of the neuro-symbolic system's context window heuristics
3. Domain Transfer Evaluation: Apply the existing LLM prompt (zero-shot) to a held-out 10th interview from a different agricultural subdomain to empirically test the generalization claims versus the neuro-symbolic system which would require manual rule updates