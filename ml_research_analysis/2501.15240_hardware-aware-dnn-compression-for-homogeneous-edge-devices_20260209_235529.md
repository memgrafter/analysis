---
ver: rpa2
title: Hardware-Aware DNN Compression for Homogeneous Edge Devices
arxiv_id: '2501.15240'
source_url: https://arxiv.org/abs/2501.15240
tags:
- devices
- hdap
- evaluation
- edge
- homogeneous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HDAP addresses the challenge of hardware-aware DNN compression
  across homogeneous edge device clusters, where prior methods assume identical performance
  that does not hold in practice due to manufacturing variances and environmental
  factors. The method clusters devices by performance similarity using DBSCAN and
  employs surrogate models for latency prediction, reducing evaluation overhead from
  thousands of devices to a few representative clusters.
---

# Hardware-Aware DNN Compression for Homogeneous Edge Devices
## Quick Facts
- arXiv ID: 2501.15240
- Source URL: https://arxiv.org/abs/2501.15240
- Authors: Kunlong Zhang; Guiying Li; Ning Lu; Peng Yang; Ke Tang
- Reference count: 32
- Primary result: HDAP achieves 2.86× and 1.67× latency speedups for ResNet50 and MobileNetV1 respectively while maintaining accuracy

## Executive Summary
HDAP addresses the challenge of hardware-aware DNN compression across homogeneous edge device clusters, where prior methods assume identical performance that does not hold in practice due to manufacturing variances and environmental factors. The method clusters devices by performance similarity using DBSCAN and employs surrogate models for latency prediction, reducing evaluation overhead from thousands of devices to a few representative clusters. HDAP uses a derivative-free evolutionary algorithm (NCS) to iteratively prune and fine-tune DNN models while maintaining accuracy constraints.

Experiments on ImageNet with ResNet50 and MobileNetV1 demonstrate HDAP achieves 2.86× and 1.67× latency speedups respectively while maintaining competitive accuracy, with consistent performance across device clusters. The approach enables efficient, scalable DNN deployment on large homogeneous edge device populations.

## Method Summary
HDAP addresses hardware heterogeneity in homogeneous edge device clusters by first clustering devices based on performance similarity using DBSCAN, then employing surrogate models to predict latency across device clusters rather than individual devices. The method uses a derivative-free evolutionary algorithm called NCS (Neural Architecture Search with Crossover and Selection) to iteratively prune and fine-tune DNN models while maintaining accuracy constraints. The approach significantly reduces the computational overhead of evaluating thousands of device-latency pairs by focusing on representative clusters, enabling efficient deployment of compressed DNNs across large homogeneous device populations while accounting for real-world performance variations.

## Key Results
- Achieved 2.86× latency speedup for ResNet50 on ImageNet
- Achieved 1.67× latency speedup for MobileNetV1 on ImageNet
- Maintained competitive accuracy across all device clusters
- Reduced evaluation overhead by clustering devices rather than evaluating each individually

## Why This Works (Mechanism)
HDAP works by recognizing that manufacturing variances and environmental factors create performance heterogeneity even among devices labeled as "homogeneous." By clustering devices using DBSCAN based on their actual performance characteristics, the method creates representative groups that share similar latency profiles. The surrogate model then predicts latency for entire clusters rather than individual devices, dramatically reducing computational overhead. The NCS evolutionary algorithm iteratively explores the design space of model compression parameters while maintaining accuracy constraints, using the clustered device information to optimize for realistic deployment scenarios rather than idealized homogeneous performance.

## Foundational Learning
- **DBSCAN clustering**: Needed to group devices by performance similarity rather than treating all devices as identical; quick check: verify cluster quality using silhouette scores
- **Surrogate modeling**: Required to predict latency across device clusters without exhaustive testing; quick check: validate prediction accuracy against ground truth measurements
- **NCS evolutionary algorithm**: Essential for derivative-free optimization of model compression parameters; quick check: monitor convergence speed and solution quality across generations
- **Hardware-aware pruning**: Necessary to balance accuracy and latency across heterogeneous devices; quick check: track accuracy-latency tradeoff curves
- **Cross-cluster validation**: Important to ensure compressed models work across all device clusters; quick check: test compressed models on representative devices from each cluster

## Architecture Onboarding
**Component map**: DBSCAN clustering -> Surrogate latency model -> NCS optimization -> Model compression and fine-tuning

**Critical path**: The most time-sensitive sequence is DBSCAN clustering (initial setup) → Surrogate model training (latency prediction) → NCS optimization (model compression) → Cross-cluster validation (deployment verification)

**Design tradeoffs**: The method trades computational overhead during optimization for reduced deployment complexity. While DBSCAN and surrogate modeling add upfront costs, they eliminate the need to evaluate each device individually, making large-scale deployment feasible.

**Failure signatures**: Common failure modes include poor clustering quality leading to suboptimal latency predictions, surrogate model overfitting to training data, NCS getting stuck in local optima, and compressed models failing to generalize across device clusters.

**First experiments**:
1. Validate DBSCAN clustering quality using silhouette scores and visual inspection of device latency distributions
2. Test surrogate model prediction accuracy against ground truth latency measurements on held-out device clusters
3. Evaluate NCS convergence behavior and solution quality across multiple optimization runs

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability of DBSCAN clustering to extremely large device populations remains uncertain
- Generalizability of surrogate models across diverse hardware architectures is not fully established
- Performance variance assumptions within homogeneous clusters may not hold in all deployment scenarios
- Computational overhead of NCS algorithm during optimization phase could impact real-world deployment timelines

## Confidence
- **High**: The core premise that homogeneous devices exhibit performance heterogeneity and that clustering approaches can effectively address this issue
- **Medium**: The effectiveness of the surrogate model for latency prediction across different device clusters
- **Medium**: The generalizability of the NCS algorithm to other DNN architectures beyond ResNet50 and MobileNetV1

## Next Checks
1. Test HDAP's performance across heterogeneous device clusters to evaluate its robustness beyond homogeneous environments
2. Conduct long-term stability analysis to assess how device performance drift over time affects the clustering accuracy and model optimization
3. Evaluate the computational overhead of the NCS algorithm during deployment and its impact on real-world edge computing scenarios