---
ver: rpa2
title: Sentiment Analysis in Learning Management Systems Understanding Student Feedback
  at Scale
arxiv_id: '2506.05490'
source_url: https://arxiv.org/abs/2506.05490
tags:
- feedback
- sentiment
- learning
- student
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The research integrated sentiment analysis into Learning Management
  Systems (LMS) to address communication gaps in online education, particularly the
  absence of non-verbal cues. A deep neural network model incorporating word embedding,
  LSTM, and attention mechanisms was developed and compared against a logistic regression
  baseline using the RateMyProfessor dataset.
---

# Sentiment Analysis in Learning Management Systems Understanding Student Feedback at Scale

## Quick Facts
- arXiv ID: 2506.05490
- Source URL: https://arxiv.org/abs/2506.05490
- Reference count: 18
- Key outcome: RNN model achieved 80% accuracy, 83% precision, 85% recall, and 0.84 F1-score on student feedback sentiment classification

## Executive Summary
This research addresses communication challenges in online education by integrating sentiment analysis into Learning Management Systems to interpret student feedback at scale. The study develops a deep neural network model combining word embedding, bidirectional LSTM, and attention mechanisms to capture sequential dependencies and sentiment-indicative words in student comments. Tested on the RateMyProfessor dataset, the RNN model significantly outperformed a logistic regression baseline across all evaluation metrics, demonstrating the effectiveness of sequential modeling for sentiment classification in educational contexts.

## Method Summary
The study utilized the RateMyProfessor dataset containing 19,993 student comments with star ratings. Comments were preprocessed through stopword removal and lemmatization, then converted to TF-IDF vectors with chi-squared feature selection (5,000-word vocabulary). A binary classification approach was employed with ratings ≥3.5 classified as positive and <2.5 as negative. The proposed RNN model incorporated word embeddings, bidirectional LSTM for sequential dependency capture, and an attention mechanism to weight sentiment-relevant words. SMOTE oversampling addressed class imbalance. The model was compared against a logistic regression baseline using standard metrics including accuracy, precision, recall, F1-score, and AUC.

## Key Results
- RNN model achieved 80% accuracy compared to 77% for logistic regression baseline
- Precision improved from 77% to 83% and recall from 75% to 85% with the RNN approach
- F1-score reached 0.84 with the RNN model versus 0.77 for the baseline
- The model successfully classified 81% of negative comments and 79% of positive comments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequential dependency capture via bidirectional LSTM improves sentiment classification over non-sequential baselines.
- Mechanism: The LSTM processes feedback text both forwards and backwards, maintaining memory gates that retain information from earlier tokens when interpreting later ones. This allows the model to recognize that "not engaging but informative" carries different sentiment weight than the words in isolation.
- Core assumption: Student feedback contains sentiment signals distributed across token sequences, not just in individual keywords.
- Evidence anchors:
  - [abstract]: "development of a deep neural network model encompassing word embedding, LSTM, and attention mechanisms"
  - [section 2.7]: "Given that student feedback can be lengthy, we utilize LSTM, a type of recurrent neural network (RNN), to capture long-range dependencies within the data. The LSTM layer operates bidirectionally, enabling it to process feedback sentences both forwards and backwards."
  - [corpus]: Related work on student feedback analysis using transformers (DistilBERT) in OBE contexts supports sequence-based approaches, though direct LSTM comparisons are limited.
- Break condition: If feedback texts are very short (e.g., single-word responses) or if sentiment is primarily carried by isolated keywords rather than phrasal patterns, LSTM's sequential modeling provides diminishing returns over simpler baselines.

### Mechanism 2
- Claim: Attention mechanisms improve sentiment detection by weighting sentiment-indicative words more heavily than neutral context.
- Mechanism: After LSTM encoding, the attention layer assigns learned weights to each token representation. Tokens with higher attention scores contribute more to the final classification, allowing the model to prioritize words like "engaging" or "frustrating" over generic academic vocabulary.
- Core assumption: Sentiment signals are unevenly distributed across feedback tokens; some words are more predictive than others.
- Evidence anchors:
  - [section 2.7]: "The critical function of the attention layer is to focus on words that are more indicative of sentiment than others."
  - [section 3.1]: "This enhancement in the RNN model's performance is attributed to its ability to capture sequential word dependencies in sentences, which is crucial for understanding the contribution of each word to the overall meaning in sentiment feedback analysis."
  - [corpus]: Weak—no specific corpus evidence validates attention mechanisms in educational sentiment analysis; this remains an assumption based on general NLP literature.
- Break condition: If attention weights become uniform (no token prioritization) or if the model attends to spurious correlations (e.g., course names rather than sentiment words), the mechanism degrades to equivalent performance without attention.

### Mechanism 3
- Claim: TF-IDF vectorization with chi-squared feature selection reduces noise by emphasizing sentiment-discriminative vocabulary.
- Mechanism: TF-IDF downweights ubiquitous terms while emphasizing rare but informative ones. Chi-squared tests then rank features by statistical dependence with sentiment labels, selecting the top 5,000 words from a 17,583-word vocabulary.
- Core assumption: Words with high chi-squared scores relative to sentiment labels are causally relevant to classification, not just coincidentally correlated.
- Evidence anchors:
  - [section 2.2]: "The chi-squared statistics suggest a steady impact when considering a vocabulary of 5000 words, as per the chi-square scores."
  - [section 2.2]: "Employing TF-IDF is an optimal approach as we seek to elevate the importance of terms appearing exclusively in one class (negative or positive)."
  - [corpus]: No corpus evidence directly validates chi-squared feature selection for LMS sentiment; this is a methodological choice based on standard NLP practice.
- Break condition: If the dataset contains class-specific jargon unrelated to sentiment (e.g., department names that correlate with rating patterns), chi-squared may select spurious features that fail to generalize.

## Foundational Learning

- Concept: **Word Embeddings (Dense Vector Representations)**
  - Why needed here: The model's first layer transforms discrete tokens into continuous vectors, enabling semantic similarity computation. Without understanding embeddings, the LSTM input is opaque.
  - Quick check question: Given two feedback sentences—"The lecture was engaging" and "The class was captivating"—would an embedding layer produce similar vector representations for "engaging" and "captivating"? Why?

- Concept: **Recurrent Neural Networks and LSTM Memory Gates**
  - Why needed here: The paper's core architectural choice assumes LSTM can retain information across long sequences. Understanding gating mechanisms (input, forget, output) explains why LSTM outperforms logistic regression on sequential data.
  - Quick check question: In the sentence "The professor was not helpful at first, but improved significantly," how would an LSTM's forget gate potentially behave differently when processing "but" versus a standard RNN?

- Concept: **Class Imbalance and SMOTE Oversampling**
  - Why needed here: The paper reports using SMOTE to address imbalanced sentiment classes. Without understanding oversampling, the improved recall metrics may be misinterpreted as pure architectural gains.
  - Quick check question: If a dataset has 80% positive and 20% negative samples, and you apply SMOTE to the minority class, what is the potential risk of evaluating on synthetic test data?

## Architecture Onboarding

- Component map:
  Input: Raw student comment text (string) → Preprocessing: Stopword removal → Lemmatization (NLTK WordNetLemmatizer) → Vectorization: TF-IDF with chi-squared feature selection (5,000-word vocabulary) → Embedding Layer: Dense vector transformation → Bidirectional LSTM: Sequence encoding → Attention Layer: Learned weighting of LSTM outputs → Output Layer: Sigmoid activation → Binary prediction (Positive/Negative)

- Critical path:
  1. Data quality check: Ensure comments are non-null and properly labeled via star_rating thresholds (3.5–5.0 = positive, 1.0–2.4 = negative)
  2. Preprocessing pipeline validation: Verify lemmatization reduces vocabulary without collapsing sentiment distinctions (e.g., "worst" and "worse" should remain distinct)
  3. SMOTE application: Apply only to training split to prevent data leakage
  4. Model training: Monitor for overfitting on synthetic SMOTE samples
  5. Evaluation: Use F1-score and AUC-ROC, not just accuracy, due to residual class imbalance concerns

- Design tradeoffs:
  - TF-IDF vs. learned embeddings: TF-IDF is computationally cheaper but static; learned embeddings could capture domain-specific semantics but require more data
  - Binary vs. ternary classification: Paper mentions neutral class but results focus on binary; neutral samples may have been excluded or absorbed
  - LSTM vs. Transformer: Paper acknowledges transformers (e.g., contextual embeddings) as future work; current choice trades contextual nuance for training efficiency
  - Logistic regression baseline: Simple but lacks sequential modeling; serves as weak baseline rather than state-of-the-art comparison

- Failure signatures:
  - High accuracy, low recall: Model biased toward majority class (positive); check SMOTE application and class distribution in test set
  - Attention weights uniform: Attention layer not learning; check gradient flow and consider increasing attention hidden size
  - Poor performance on negation (e.g., "not engaging"): LSTM fails to propagate negation scope; paper documents this failure in Sentence 8 analysis
  - Overfitting on SMOTE samples: Validation loss diverges from training loss; reduce SMOTE ratio or add dropout

- First 3 experiments:
  1. **Baseline replication**: Implement logistic regression with TF-IDF features on the RateMyProfessor dataset (80/20 split) to verify reported 77% accuracy and 0.77 F1-score.
  2. **Ablation study**: Train the RNN model without the attention layer and compare F1-scores. This isolates the attention mechanism's contribution from LSTM's sequential modeling.
  3. **Negation robustness test**: Construct a synthetic test set with controlled negation patterns (e.g., "not [adjective]" for various sentiment words) to quantify the failure mode identified in the paper's qualitative analysis.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent would incorporating transformer-based models with contextual embeddings improve sentiment classification accuracy compared to the current LSTM architecture?
- Basis in paper: [explicit] The authors state in the conclusion that to enhance capabilities, they propose incorporating transformer models to create continuous representations and better recognize word meanings in different contexts.
- Why unresolved: The current study utilizes LSTM and attention mechanisms, which may not capture context as effectively as modern transformer architectures.
- What evidence would resolve it: A comparative study benchmarking the existing LSTM model against a transformer-based model (e.g., BERT) using the same dataset and metrics.

### Open Question 2
- Question: How can the model be refined to accurately handle negation scoping when negative modifiers apply to multiple subsequent attributes?
- Basis in paper: [inferred] The qualitative analysis highlights a specific failure where the sentence "The lecture was not engaging and informative" was misclassified as positive, suggesting the model struggles to transfer negation to subsequent words.
- Why unresolved: Both the proposed RNN and the baseline failed to identify the negative sentiment in this specific structure, indicating a gap in the model's syntactic understanding.
- What evidence would resolve it: successful classification of test cases containing complex negation patterns (e.g., "not X and Y") that currently confuse the model.

### Open Question 3
- Question: Does the model's performance on the RateMyProfessor dataset generalize to actual feedback found within institutional Learning Management Systems?
- Basis in paper: [inferred] The authors utilized a public dataset as a "proxy" because LMS data is restricted, acknowledging that the data source is distinct from the target deployment environment.
- Why unresolved: Student feedback on public platforms may differ in tone, vocabulary, and intent from private feedback submitted directly within an LMS.
- What evidence would resolve it: Validation of the trained model on a blinded dataset of actual LMS student comments to verify real-world efficacy.

## Limitations

- The study lacks complete architectural specification, particularly regarding embedding layer configuration and attention mechanism details.
- Binary classification approach excludes the neutral sentiment class despite mentioning its existence, raising questions about rating threshold determination.
- Logistic regression baseline represents a weak state-of-the-art benchmark rather than testing against more advanced NLP approaches like transformers or ensemble methods.

## Confidence

**High Confidence**: The RNN model's superior performance metrics (80% accuracy, 83% precision, 85% recall, 0.84 F1-score) compared to the logistic regression baseline are well-supported by the experimental results and the sequential modeling advantages of LSTM are theoretically sound.

**Medium Confidence**: The attention mechanism's contribution to improved sentiment detection is supported by the performance gains but lacks direct corpus evidence specific to educational feedback contexts. The mechanism's effectiveness depends on learned attention weights, which are not reported.

**Low Confidence**: The chi-squared feature selection's effectiveness for sentiment analysis in educational contexts is assumed based on general NLP practice rather than validated with corpus-specific evidence. The neutral class handling and rating threshold determination also carry significant uncertainty.

## Next Checks

1. **Ablation study on attention mechanism**: Train the RNN model without the attention layer and compare F1-scores to isolate the attention mechanism's specific contribution versus LSTM's sequential modeling capabilities.

2. **Cross-dataset generalization test**: Evaluate the trained model on a different student feedback dataset (e.g., course evaluations from another LMS) to assess whether performance gains generalize beyond the RateMyProfessor domain.

3. **Negation pattern robustness test**: Construct a synthetic test set with controlled negation patterns (e.g., "not engaging," "not helpful") to quantify the failure mode identified in the qualitative analysis and measure model robustness to common sentiment-modifying constructs.