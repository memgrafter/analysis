---
ver: rpa2
title: 'The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs
  with Camlang'
arxiv_id: '2509.00425'
source_url: https://arxiv.org/abs/2509.00425
tags:
- camlang
- language
- reasoning
- grammar
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Camlang, a constructed language with explicit
  grammar rules and a bilingual dictionary, to evaluate whether large language models
  (LLMs) can acquire and apply linguistic competence through metalinguistic reasoning.
  Camlang is designed to be typologically plausible yet unattested, ensuring novelty
  and preventing reliance on pre-trained patterns.
---

# The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang

## Quick Facts
- **arXiv ID:** 2509.00425
- **Source URL:** https://arxiv.org/abs/2509.00425
- **Reference count:** 40
- **Primary result:** LLMs show sharp performance drop (21-47%) on Camlang tasks versus English (85-98%), while humans achieve 87%, revealing gaps in metalinguistic competence.

## Executive Summary
This paper introduces Camlang, a constructed language designed to test whether large language models can acquire and apply linguistic competence through metalinguistic reasoning. Camlang features explicit grammar rules and a bilingual dictionary, making it typologically plausible yet unattested to prevent reliance on pre-trained patterns. The evaluation reveals that while LLMs perform well on English tasks (85-98% accuracy), their performance on Camlang tasks drops sharply to 21-47%, significantly below human performance at 87%. Human verification indicates that most model successes stem from shallow lexical alignment rather than systematic grammatical mastery, establishing Camlang as a cognitively grounded evaluation paradigm.

## Method Summary
The researchers constructed Camlang with explicit grammar rules and a bilingual dictionary, ensuring typological plausibility while maintaining novelty. They designed tasks that require systematic grammatical understanding rather than pattern matching. The evaluation compares LLM performance across English and Camlang tasks, with human benchmarks providing reference points. Human verification was used to distinguish between genuine grammatical understanding and superficial pattern recognition in model outputs.

## Key Results
- LLMs achieve 85-98% accuracy on English tasks but only 21-47% on Camlang tasks
- Human performance on Camlang tasks reaches 87% accuracy
- Human verification reveals most LLM successes rely on shallow lexical alignment rather than systematic grammatical mastery
- Performance gap persists across multiple model sizes and types

## Why This Works (Mechanism)
Camlang's design isolates metalinguistic reasoning by presenting an unattested language with explicit grammatical rules. The bilingual dictionary provides clear mappings while the novel grammatical structures prevent reliance on pre-existing language patterns. This forces models to demonstrate genuine rule application rather than pattern matching. The systematic design allows clear differentiation between surface-level lexical matching and deeper grammatical understanding.

## Foundational Learning
- **Metalinguistic reasoning**: The ability to consciously reflect on and manipulate language rules - needed because the study aims to distinguish between pattern matching and genuine grammatical understanding
- **Typological plausibility**: Language features that could exist in natural languages but don't - needed to ensure the constructed language tests genuine linguistic competence rather than artificial constructs
- **Lexical alignment**: Matching words between languages based on surface similarity - needed to explain why models might succeed without true grammatical understanding
- **Grammatical mastery**: Systematic understanding and application of language rules - needed as the benchmark for human-like linguistic competence

## Architecture Onboarding
**Component map:** Camlang design -> Task creation -> LLM evaluation -> Human verification -> Performance comparison
**Critical path:** Constructed language development → Task formulation → Model testing → Human benchmarking → Analysis of shallow vs. deep understanding
**Design tradeoffs:** Novel language prevents pattern matching but may increase task difficulty; explicit grammar rules enable clear evaluation but might not capture all aspects of natural language acquisition
**Failure signatures:** High performance on lexical tasks but low performance on grammatical transformations; success patterns that match surface features rather than underlying rules
**First experiments:**
1. Test model performance on controlled grammatical transformations versus lexical matching tasks
2. Compare performance across languages with varying typological distances from English
3. Evaluate fine-tuned versus zero-shot performance on Camlang tasks

## Open Questions the Paper Calls Out
None

## Limitations
- The performance gap might reflect task difficulty differences rather than fundamental metalinguistic limitations
- The evaluation may not fully isolate grammatical competence from other linguistic abilities
- Camlang's design, while novel, may still allow for some pattern-matching strategies

## Confidence
- **High confidence:** The relative performance drop from English to Camlang is robust and consistently observed across multiple model sizes and types
- **Medium confidence:** The claim that human-like metalinguistic competence requires systematic grammatical mastery is well-supported but not definitively proven by these results alone
- **Low confidence:** The assertion that Camlang provides a "pure" measure of metalinguistic reasoning, uncontaminated by other linguistic abilities, given the complexity of language processing

## Next Checks
1. Conduct ablation studies varying specific Camlang features (e.g., word order flexibility, case marking) to identify which grammatical aspects most challenge LLMs versus humans
2. Test whether fine-tuning on synthetic languages with different properties changes Camlang performance, distinguishing between pattern learning and genuine metalinguistic generalization
3. Compare Camlang performance against human learners with varying linguistic backgrounds to better calibrate the difficulty and isolate what constitutes true metalinguistic competence