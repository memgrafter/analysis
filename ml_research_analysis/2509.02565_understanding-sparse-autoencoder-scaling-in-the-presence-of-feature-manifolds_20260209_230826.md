---
ver: rpa2
title: Understanding sparse autoencoder scaling in the presence of feature manifolds
arxiv_id: '2509.02565'
source_url: https://arxiv.org/abs/2509.02565
tags:
- feature
- scaling
- latents
- saes
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies how sparse autoencoders (SAEs) scale when neural
  activations contain multi-dimensional features (feature manifolds). The authors
  adapt a capacity-allocation model from neural scaling theory to understand SAE scaling
  behavior.
---

# Understanding sparse autoencoder scaling in the presence of feature manifolds

## Quick Facts
- **arXiv ID:** 2509.02565
- **Source URL:** https://arxiv.org/abs/2509.02565
- **Reference count:** 40
- **Primary result:** SAEs may scale pathologically by tiling common feature manifolds rather than discovering rarer features when feature frequency decay (α) exceeds per-feature loss decay (β)

## Executive Summary
This work investigates how sparse autoencoders (SAEs) scale when neural activations contain multi-dimensional features (feature manifolds). The authors adapt capacity-allocation models from neural scaling theory to analyze SAE behavior, revealing a critical threshold where SAEs optimally allocate latents to common manifolds rather than discovering rare features. Through synthetic manifold experiments, they demonstrate that SAEs can reduce loss by tiling certain manifold geometries, though realistic features with radial variation resist this behavior. The paper raises important questions about whether this pathological regime exists in practice and how to determine relevant scaling parameters from real data.

## Method Summary
The authors adapt a capacity-allocation model from neural scaling theory to analyze SAE scaling behavior. They assume feature-specific latents in orthogonal subspaces, reducing the SAE optimization to allocating N latents across features to minimize expected loss. Synthetic experiments use hyperspheres $S^d$ and spherical shells $\{x : 0.5 < |x| < 2\}$ with uniform sampling. SAEs are trained with ReLU (L1 penalty λ=0.1) and JumpReLU (tanh loss with c=0.1, λs=1.0) architectures using Adam optimizer (LR=10^-3, Batch Size=2048, Steps=12,000). The L1-decoder-norm trick prevents shrinkage. Loss scaling exponents β are measured across varying widths N to identify tiling behavior.

## Key Results
- A critical threshold exists: when β < α, SAEs enter pathological scaling where feature discovery grows sublinearly with SAE width
- On hollow hyperspheres, SAEs can gradually reduce loss by allocating many latents (β small), demonstrating tiling behavior
- Realistic features with radial variation quickly plateau at nᵢ ≈ 2dᵢ (β large), preventing pathological accumulation
- The optimal allocation becomes D(N) ∝ N^((1+β)/(1+α)) rather than D(N) ∝ N when β < α

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SAE optimization can be reduced to a latent allocation problem where latents are assigned to specific features.
- **Mechanism:** Under assumptions of feature-specific latents and orthogonal feature subspaces, the total expected SAE loss decomposes into a sum over per-feature losses: E[L] = Σᵢ pᵢLᵢ(nᵢ), where pᵢ is feature frequency and nᵢ is latents allocated to feature i. The optimization problem becomes choosing nᵢ to minimize this sum subject to Σᵢ nᵢ = N.
- **Core assumption:** Features live in orthogonal subspaces, and each latent fires only when its associated feature is active. Feature absorption and non-orthogonality in practice violate this.
- **Evidence anchors:** [abstract] "we adapt a capacity-allocation model from the neural scaling literature (Brill, 2024)"; [section 2.2] "we reduce the SAE optimization problem to the problem of choosing how many latents nᵢ to allocate to each feature i"

### Mechanism 2
- **Claim:** A critical threshold exists: when the per-feature loss decay rate (β) is less than the feature frequency decay rate (α), SAEs enter a pathological scaling regime where feature discovery grows sublinearly with SAE width.
- **Mechanism:** With power-law feature frequencies pᵢ ∝ i^(-(1+α)) and per-feature loss L(n) ∝ n^(-β): when β < α, optimal allocation puts many latents on common features (manifolds), yielding D(N) ∝ N^((1+β)/(1+α)) rather than D(N) ∝ N. The SAE "tiles" common manifolds instead of discovering rare features.
- **Core assumption:** Both feature frequencies and per-feature loss curves follow power laws with consistent exponents across features.
- **Evidence anchors:** [abstract] "when the rate at which loss decreases on common feature manifolds (β) is less than the rate at which feature frequencies decay (α), SAEs can optimally allocate most latents to tiling these common manifolds"; [section 2.5] "when β < α, then L(N) ∝ N^(-β) and D(N) ∝ N^((1+β)/(1+α))"

### Mechanism 3
- **Claim:** Manifold geometry determines whether SAEs can reduce loss by "tiling" with many latents or quickly plateau at a basis solution.
- **Mechanism:** On hollow hyperspheres, SAEs can gradually reduce loss by allocating many latents (L(n) scales gradually). However, when manifolds have radial variation (realistic feature intensity variation), loss plateaus quickly at nᵢ ≈ 2dᵢ (learning a signed basis), preventing pathological accumulation.
- **Core assumption:** Real neural features exhibit radial variation in intensity, as observed in prior work [22, 29].
- **Evidence anchors:** [abstract] "SAEs can indeed reduce loss by tiling certain manifold geometries, though they do not necessarily do this in more realistic settings with radial variation"; [section 3 / Figure 3] Shows different L(n) curves for hyperspheres vs. spherical shells

## Foundational Learning

- **Power law distributions and scaling exponents (α, β):**
  - Why needed here: The entire pathological scaling prediction hinges on comparing two power-law exponents—feature frequency decay (α) and per-feature loss decay (β). Without understanding power-law scaling, the threshold analysis is opaque.
  - Quick check question: Given pᵢ ∝ i^(-1.5) and L(n) ∝ n^(-0.3), which regime is the SAE in?

- **Latent allocation as an optimization problem:**
  - Why needed here: The paper reframes SAE training from "learning features" to "allocating capacity"—this is the core conceptual shift needed to apply Brill's neural scaling model.
  - Quick check question: If you have 1000 latents and 100 features with varying frequencies, how would you optimally distribute latents if all features are discrete?

- **Manifold geometry basics (dimensionality, radial vs. hollow):**
  - Why needed here: The key empirical finding is that radial variation in feature manifolds prevents pathological tiling—understanding why requires knowing how manifolds embed in activation space.
  - Quick check question: Why might an SAE allocate more latents to a hollow sphere than a solid spherical shell?

## Architecture Onboarding

- **Component map:** Neural activations x ∈ Rᵈ generated as x = Σᵢ Sᵢfᵢ → SAE encoder f̂ = σ(Wₑx + bₑ) with sparsity penalty λS(f̂) → SAE decoder x̂ = Wₐf̂ + bₐ → Loss decomposition L = Σᵢ pᵢLᵢ(nᵢ) under orthogonality assumptions → Latents distributed to minimize expected loss given power-law constraints

- **Critical path:**
  1. Identify feature frequency distribution (estimate α from activation data)
  2. Measure per-feature loss curves Lᵢ(n) for representative features (estimate β)
  3. Compare α vs. β to determine if pathological regime is possible
  4. Check for manifold geometry indicators (radial variation, high decoder cosine similarity)

- **Design tradeoffs:**
  - **L1 penalty strength (λ):** Higher λ increases sparsity but may push SAE toward tiling solutions on manifolds
  - **SAE width (N):** In pathological regime (β < α), more latents don't proportionally increase feature discovery
  - **Architecture choice (ReLU vs JumpReLU):** Paper shows similar scaling behavior across architectures on synthetic manifolds (Figure 6)

- **Failure signatures:**
  - **Sublinear feature discovery:** D(N) growing slower than N at large widths (Section 2.5, Figure 2 right)
  - **High decoder cosine similarity:** Many latents with nearest-neighbor cosine similarity > 0.97 may indicate tiling (Appendix E)
  - **Dead latents adjacent to similar live latents:** Suggested by Gemma Scope analysis showing dead neighbors for high-similarity latents

- **First 3 experiments:**
  1. **Measure α on target model:** Train SAE at moderate width, sort latents by firing frequency, fit power-law exponent to estimate α (replicate Figure 4 methodology on your model)
  2. **Estimate β on synthetic manifolds:** Train SAEs of varying widths on toy manifolds matching suspected feature geometries, measure L(n) curves to estimate β (follow Figure 3 protocol)
  3. **Check decoder cosine similarity distribution:** For existing SAEs, compute pairwise decoder similarities—look for excess mass at high similarity (>0.95) that may indicate tiling behavior (replicate Figure 7/8 analysis)

## Open Questions the Paper Calls Out

- **Open Question 1:** Do SAEs trained on real-world neural networks operate in the pathological scaling regime where β < α?
  - Basis in paper: [explicit] The authors state, "Unfortunately, we do not resolve the question of whether SAEs are in this pathological scaling regime in practice."
  - Why unresolved: The distribution of true feature frequencies (determining α) and the geometry of real feature manifolds (determining β) in models like LLMs remain unknown.
  - What evidence would resolve it: Empirical measurement of the feature frequency power law exponent (α) and the per-feature loss-scaling exponent (β) in large-scale models to see if the β < α condition holds.

- **Open Question 2:** How do "ripples" in feature manifolds affect SAE scaling and tiling behavior?
  - Basis in paper: [explicit] The authors note, "We are unsure how 'ripples' [29] in feature manifolds could affect SAE scaling on them."
  - Why unresolved: The paper's synthetic experiments were limited to hyperspheres and spherical shells; real features may be low-dimensional but curved through higher-dimensional spaces.
  - What evidence would resolve it: Experiments training SAEs on synthetic manifolds with controlled ripple topologies to observe if they induce pathological tiling or if SAEs learn efficient basis solutions.

- **Open Question 3:** Are the high cosine similarities observed in vision model SAEs caused by manifold tiling or latent duplication?
  - Basis in paper: [inferred] Appendix E.2 observes high cosine similarity in Inception-v1 SAEs but cautions this "could be due to latents being duplicated... rather than tiling."
  - Why unresolved: While high similarity suggests latents align on a manifold, the L1 loss does not strongly disincentivize dead or duplicated latents, creating ambiguity in the data.
  - What evidence would resolve it: Analyzing the activation patterns of high-similarity latent pairs to distinguish between identical firing (duplication) and adjacent firing on a manifold (tiling).

## Limitations

- The theoretical analysis assumes feature-specific latents in orthogonal subspaces, which may not hold in practice due to feature absorption and non-orthogonality
- Synthetic manifold experiments are limited to simple geometries (hyperspheres and spherical shells) and may not capture the complexity of real feature manifolds
- The paper does not resolve whether the pathological scaling regime actually exists in practical SAE applications on real neural activations

## Confidence

- **High Confidence:** The theoretical framework for analyzing SAE capacity allocation under orthogonality assumptions is sound and mathematically rigorous
- **Medium Confidence:** The synthetic manifold experiments successfully demonstrate the tiling mechanism and threshold behavior predicted by theory
- **Low Confidence:** Whether the pathological scaling regime (β < α) actually exists in practical SAE applications on real neural activations

## Next Checks

1. **Empirical α measurement:** Apply the paper's methodology to measure feature frequency exponents on existing SAEs from major models to determine if α > β in practice
2. **Real feature manifold analysis:** Examine whether neural features exhibit radial variation patterns similar to those that prevent pathological tiling in synthetic experiments
3. **Decoder similarity analysis:** Compute decoder cosine similarity distributions across SAEs of varying widths to identify potential tiling behavior through high-similarity latents