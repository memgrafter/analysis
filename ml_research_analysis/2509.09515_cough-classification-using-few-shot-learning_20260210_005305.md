---
ver: rpa2
title: Cough Classification using Few-Shot Learning
arxiv_id: '2509.09515'
source_url: https://arxiv.org/abs/2509.09515
tags:
- learning
- classification
- few-shot
- accuracy
- multi-class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores the use of few-shot learning for cough-based
  respiratory illness classification, focusing on COVID-19, Flu, and healthy conditions.
  Using Prototypical Networks and Mel-spectrograms from three public datasets, the
  model achieves 74.87% accuracy in 3-way classification with only 15 support examples
  per class.
---

# Cough Classification using Few-Shot Learning

## Quick Facts
- arXiv ID: 2509.09515
- Source URL: https://arxiv.org/abs/2509.09515
- Reference count: 40
- Primary result: Prototypical Networks achieve 74.87% accuracy in 3-way cough classification with only 15 labeled examples per class

## Executive Summary
This study demonstrates that few-shot learning can effectively classify respiratory illnesses from cough sounds using minimal labeled data. By converting cough audio to Mel-spectrograms and applying Prototypical Networks with a modified ResNet-18 backbone, the model distinguishes COVID-19, Flu, and healthy coughs with 74.87% accuracy in 3-way classification using only 15 support examples per class. Binary classification models achieve even higher accuracy, with Flu vs. COVID-19 reaching 93.50%. The Healthy class proved most challenging to classify due to acoustic variability, while Flu was the most distinguishable. Statistical equivalence tests confirm that multi-class performance is comparable to binary models within a 15% margin.

## Method Summary
The methodology converts raw cough audio from three public datasets into 128-band Mel-spectrograms using Librosa, resampled to 22.05 kHz and trimmed to 1-second duration. These spectrograms are resized to 224×224 tensors and fed into a modified ResNet-18 with single-channel input, initialized with ImageNet-pretrained weights. Prototypical Networks train episodically using N-way K-shot episodes, where class prototypes are computed as the mean of support set embeddings. Classification is performed by assigning query samples to the nearest class prototype using Euclidean distance. The model is evaluated across 100 random episodes for K ∈ {1, 5, 10, 15} in both multi-class (3-way) and binary classification tasks.

## Key Results
- 3-way classification achieves 74.87% accuracy with 15 support examples per class
- Binary classification accuracy exceeds 70% across all class pairs
- Flu vs. COVID-19 classification achieves highest binary accuracy at 93.50%
- Statistical equivalence tests confirm multi-class performance comparable to binary models within 15% margin
- Healthy class accuracy (62.6% at 15-shot) lags significantly behind Flu (96.8%)

## Why This Works (Mechanism)

### Mechanism 1: Prototype-Based Metric Learning for Low-Data Regimes
Prototypical Networks enable cough classification by embedding samples into a space where class membership is determined by distance to learned class prototypes. During each episode, support set embeddings are averaged per class to form prototypes. Query samples are classified based on Euclidean distance to the nearest prototype, bypassing the need for thousands of labeled examples per class. This approach assumes classes form compact, separable clusters in the learned embedding space. The method is supported by its successful application in medical FSL, though cross-domain evidence from imaging to audio is indirect.

### Mechanism 2: Audio-to-Visual Transduction via Mel-Spectrograms
Converting raw cough audio to Mel-spectrograms enables reuse of vision-based CNN architectures for audio classification. Audio recordings are resampled to 22.05 kHz, trimmed/padded to 1 second, transformed into 128-band Mel-spectrograms using Librosa, resized to 224×224, and fed into a modified ResNet-18 with single-channel input. This preserves time-frequency patterns critical for distinguishing respiratory conditions. The approach assumes disease-specific acoustic signatures are captured by Mel-spectrograms and are discriminative across Flu, COVID-19, and Healthy coughs.

### Mechanism 3: Transfer Learning from ImageNet to Audio Spectrograms
ImageNet-pretrained ResNet-18 weights provide useful initialization for spectrogram classification despite domain shift. The first convolutional layer is modified to accept single-channel input while remaining layers retain ImageNet weights. Transfer learning accelerates convergence and improves feature quality with limited medical audio data. This approach assumes low-level visual features learned from natural images transfer meaningfully to spectrogram patterns, though the domain gap's bridgeability remains partially unverified.

## Foundational Learning

- **Few-Shot Learning (FSL) and Episodic Training**: Understanding support/query splits and episode-based evaluation is critical since the methodology hinges on training with N-way K-shot episodes rather than standard batch training. Quick check: Given a 3-way 5-shot task with 5 query samples per class, how many total samples are in one episode? (Answer: 3 × 5 support + 3 × 5 query = 30)

- **Mel-Spectrograms and Audio Feature Extraction**: The paper relies on Librosa-based spectrogram generation. Understanding frequency bands, temporal resolution, and normalization is critical for debugging preprocessing failures. Quick check: Why might a 1-second audio clip lose discriminative information compared to longer clips for cough classification?

- **Metric Learning and Distance-Based Classification**: Prototypical Networks use Euclidean distance in embedding space. Understanding why distance-based methods suit few-shot tasks (vs. softmax classifiers) clarifies design choices. Quick check: What happens to prototype-based classification if one class has high intra-class variance while others are compact?

## Architecture Onboarding

- **Component map**: Raw Audio -> Preprocessing (resample 22.05kHz, trim/pad 1s, normalize) -> Mel-Spectrogram Extraction (Librosa, 128 bands) -> Tensor Conversion + Resize (224×224, single-channel) -> ResNet-18 Backbone (modified conv1, ImageNet pretrained) -> Embedding Vectors (512-dim before final layer removal) -> Prototype Computation (mean of support embeddings per class) -> Classification (Euclidean distance to prototypes)

- **Critical path**: Audio quality -> Spectrogram fidelity -> Embedding separability -> Prototype distinctiveness -> Query accuracy. The most fragile link is Healthy class embedding quality (62.6% accuracy at 15-shot vs. 96.8% for Flu).

- **Design tradeoffs**: Higher K-shot improves accuracy but requires more labeled data (diminishing returns after K=10). Binary vs. multi-class: Binary models outperform (up to 93.5% for Flu vs. COVID-19), but multi-class (74.87%) is more practical for triage. ResNet-18 vs. deeper backbones: Lighter backbone reduces computation but may limit feature capacity; paper reports ~6 hours training on Colab GPU.

- **Failure signatures**: Healthy class consistently underperforms (35.0% at 1-shot → 62.6% at 15-shot) due to high variability and overlap with COVID-19 embeddings (confirmed by t-SNE). Extreme low-shot (K=1) yields unstable performance (60.67% multi-class) — avoid deployment below K=5. Self-reported labels in source datasets introduce potential noise; verification is impossible post-hoc.

- **First 3 experiments**:
  1. Reproduce binary Flu vs. COVID-19 classification at K=15: Expect ~93.5% accuracy; validate data pipeline and episode sampling.
  2. Ablate ImageNet pretraining: Train ResNet-18 backbone from scratch and compare multi-class accuracy at K=10 to quantify transfer learning contribution.
  3. Visualize embeddings with t-SNE for K=5 vs. K=15: Confirm that Flu clusters tighten with more support examples while Healthy remains diffuse; this diagnoses class-specific failures.

## Open Questions the Paper Calls Out

- **Can MAML-based or transformer-backed meta-learners yield improved generalization compared to Prototypical Networks for cough classification?**: The authors explicitly state that future studies could investigate whether MAML-based or transformer-backed meta-learners yield improved generalization for cough classification. This study exclusively utilized Prototypical Networks with a ResNet-18 backbone, leaving alternative architectures untested.

- **Does self-supervised pretraining enhance feature robustness and discrimination for the "Healthy" class?**: The authors suggest exploring self-supervised pretraining to enhance feature robustness and identify the Healthy class as the most challenging due to acoustic variability. The current model relies on ImageNet transfer learning, which may not capture the specific nuances of non-pathological cough sounds.

- **Can novel embedding strategies overcome the performance limitations observed in extreme low-shot settings (K=1)?**: The discussion notes that performance in extreme low-shot settings (e.g., K=1) remains limited, suggesting that there is room for improving the current embedding strategies. The 1-shot multi-class accuracy (60.67%) was significantly lower than 15-shot (72.07%), indicating current embeddings are insufficient for minimal data.

## Limitations

- Domain mismatch uncertainty between ImageNet-pretrained vision features and Mel-spectrogram patterns could limit transfer learning effectiveness
- Self-reported labels in source datasets introduce unverifiable label noise that may affect model reliability
- Healthy class's consistently poor performance (62.6% at 15-shot) suggests fundamental embedding separability challenges that may persist even with more data

## Confidence

- **High Confidence**: Binary classification results (Flu vs. COVID-19 at 93.50%) and overall methodology (Prototypical Networks + Mel-spectrograms) are well-supported by experimental data
- **Medium Confidence**: Multi-class accuracy (74.87% at 15-shot) is statistically equivalent to binary models within 15% margin, but this equivalence relies on specific statistical tests whose assumptions may not fully hold
- **Low Confidence**: Transfer learning effectiveness from ImageNet to audio spectrograms lacks direct empirical validation in the paper; the assumption remains theoretically plausible but untested

## Next Checks

1. **Ablate Pretraining**: Train the ResNet-18 backbone from scratch (no ImageNet weights) and compare multi-class accuracy at K=10 to quantify transfer learning contribution

2. **Class Embedding Analysis**: Visualize t-SNE embeddings for all classes at K=5 and K=15 to confirm that Flu clusters tighten with more support while Healthy remains diffuse

3. **Cross-Validation**: Repeat the entire experimental pipeline using 5-fold cross-validation instead of single 80/20 splits to assess result stability across different data partitions