---
ver: rpa2
title: Co-Creative Learning via Metropolis-Hastings Interaction between Humans and
  AI
arxiv_id: '2506.15468'
source_url: https://arxiv.org/abs/2506.15468
tags:
- human
- learning
- agent
- data
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes and tests co-creative learning, where humans
  and AI integrate their partial information through interaction to build shared representations.
  The study uses the Metropolis-Hastings Naming Game (MHNG), a decentralized Bayesian
  inference mechanism, within a joint attention naming game (JA-NG) task.
---

# Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI

## Quick Facts
- **arXiv ID**: 2506.15468
- **Source URL**: https://arxiv.org/abs/2506.15468
- **Reference count**: 31
- **Key outcome**: MH-based human-AI interaction achieves significantly higher categorization accuracy (ARI up to 0.609) than control conditions in joint attention naming games

## Executive Summary
This paper introduces co-creative learning, where humans and AI integrate partial information through interaction to build shared representations. The authors implement the Metropolis-Hastings Naming Game (MHNG), a decentralized Bayesian inference mechanism, within a joint attention naming game (JA-NG) task. In an online experiment with 69 participants, human-AI pairs played JA-NG under partial observability with three agent types: MH-based, always-accept, and always-reject. Results demonstrate that MH-based agents significantly improved categorization accuracy and convergence toward shared sign systems compared to controls, with human acceptance behavior closely matching MH-derived acceptance probabilities. This provides the first empirical evidence that MHNG-based interaction enables co-creative learning in human-AI dyads.

## Method Summary
The study employed a joint attention naming game (JA-NG) task where human-AI pairs had partial information about object categories. Participants viewed geometric shapes (circles with notches) and attempted to name them. The AI agents used three strategies: MH-based agents calculated acceptance probabilities using Bayesian inference with Metropolis-Hastings sampling, always-accept agents agreed to all human proposals, and always-reject agents disagreed with all proposals. The MH-based agents calculated acceptance probabilities based on the posterior distribution of object categories given the current sign system, rejecting proposals when the posterior probability was low. This mechanism allowed both agents to maintain and update their own internal category representations while converging toward shared symbol systems.

## Key Results
- MH-based agent pairs achieved significantly higher adjusted Rand index (ARI) scores (up to 0.609) compared to control conditions
- Human acceptance behavior closely aligned with MH-derived acceptance probabilities (R² = 0.89, p < 0.001)
- MH-based agents demonstrated superior convergence toward shared sign systems compared to always-accept and always-reject agents

## Why This Works (Mechanism)
The co-creative learning mechanism works by enabling decentralized Bayesian inference through iterative interaction. When humans and AI share partial observations and propose category names, the MH-based agent uses the Metropolis-Hastings algorithm to probabilistically accept or reject proposals based on how well they fit the current internal model. This creates a natural selection process where both agents gradually align their internal representations while maintaining individual perspectives. The acceptance probability calculation ensures that proposals that improve the shared understanding are more likely to be accepted, while poor proposals are rejected, leading to convergence on effective category systems.

## Foundational Learning
- **Metropolis-Hastings algorithm**: A Markov Chain Monte Carlo method for sampling from probability distributions; needed for probabilistic decision-making under uncertainty; quick check: can generate samples from arbitrary target distributions
- **Bayesian inference**: Updating beliefs based on evidence; needed for agents to maintain and update internal category representations; quick check: can compute posterior probabilities given prior and likelihood
- **Joint attention**: Coordinated focus on shared objects; needed for establishing common ground in communication; quick check: can verify both agents observe same object simultaneously
- **Free energy minimization**: Principle for optimizing system organization; needed for understanding convergence dynamics; quick check: can measure system-wide information integration
- **Adjusted Rand Index (ARI)**: Measure of similarity between clustering solutions; needed for quantifying convergence quality; quick check: can compute similarity between human and AI category assignments
- **Partial observability**: Limited information access; needed to create realistic interaction constraints; quick check: can simulate scenarios where agents have incomplete information

## Architecture Onboarding

### Component Map
MHNG Agent -> Human User -> Shared Sign System <- MHNG Agent (symmetric interaction)

### Critical Path
Human proposal → MHNG acceptance probability calculation → Acceptance/rejection decision → Category update → Next proposal cycle

### Design Tradeoffs
- Decentralized vs centralized learning: Enables individual agency but requires coordination mechanisms
- Computational complexity vs real-time interaction: MH calculations must be fast enough for human interaction
- Partial observability vs complete information: Creates realistic constraints but increases difficulty
- Acceptance probability vs deterministic rules: Allows probabilistic learning but may seem less intuitive

### Failure Signatures
- Failure to converge on shared categories (low ARI scores)
- Mismatch between human and AI acceptance patterns
- Oscillating between different category systems without convergence
- Complete rejection of all proposals leading to stalemate

### First 3 Experiments
1. Test MH-based agent with different proposal acceptance thresholds to find optimal balance
2. Compare convergence rates with varying levels of partial observability
3. Evaluate performance with more complex category structures (non-linear boundaries)

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the co-creative learning mechanism demonstrated with simple visual stimuli generalize to complex, real-world tasks involving richer semantics, such as those required for Large Language Models (LLMs)?
- Basis in paper: The Discussion section explicitly lists the limitation that the study used "relatively simple, artificially generated visual stimuli" and states this limits generalizability to "real-world tasks... such as those debated in the context of Large Language Models (LLMs)."
- Why unresolved: The current experimental validation relies on low-dimensional, artificial categories (circles with notches), whereas real-world semantics and LLM interactions involve high-dimensional, noisy, and complex linguistic or multimodal data.
- What evidence would resolve it: Empirical studies showing that human-AI dyads using MHNG-based interaction can achieve similar convergence and integration of heterogeneous information in complex linguistic tasks or open-world environments.

### Open Question 2
- Question: How does the failure of joint attention impact the efficacy of MHNG-based co-creative learning, and can agents learn to align or control attention dynamically?
- Basis in paper: The Discussion section identifies the assumption of "perfect joint attention" as a limitation and states that "making the study of mechanisms to align, control, or learn attention itself a necessary future step."
- Why unresolved: The current JA-NG paradigm strictly enforces that both agents attend to the exact same object simultaneously; real-world interaction often involves ambiguity regarding the focus of attention.
- What evidence would resolve it: Experiments where the reference object is ambiguous or potentially misaligned, testing if the dyad can successfully resolve attentional conflicts to maintain co-creative learning.

### Open Question 3
- Question: Can the co-creative learning framework scale effectively from dyadic human-AI pairs to larger, multi-agent human-AI ecosystems without suffering from instability or failure?
- Basis in paper: The Discussion section mentions that the dyadic model is a "fundamental building block of a larger human-AI ecosystem" and cites the need to model such ecosystems to understand "abrupt systemic changes."
- Why unresolved: The study only validated the mechanism on 1-to-1 pairs; it is unknown if the decentralized Bayesian inference mechanism holds or degrades in many-to-many networks (e.g., crowdsourcing or multi-robot teams).
- What evidence would resolve it: Theoretical modeling or simulations of multi-agent networks (N > 2) showing that the collective free energy minimization property persists and facilitates symbol emergence across larger groups.

### Open Question 4
- Question: Does the alignment between human acceptance behavior and the theoretical Metropolis-Hastings probability hold when the computational cost or cognitive load of the categorization task increases?
- Basis in paper: The study infers human acceptance behavior using a constrained linear Bernoulli model. While the fit was good, the paper does not explore how cognitive fatigue or task difficulty affects the fidelity of human adherence to the MH rule.
- Why unresolved: The "cognitive boundaries" mentioned in the paper respect internal states, but the model assumes humans can calculate acceptance probabilities (intuitively or explicitly) effectively regardless of difficulty.
- What evidence would resolve it: Varying the difficulty of the categorization task (e.g., increasing dimensionality or category overlap) and observing if the correlation between human acceptance rates and theoretical MH probabilities weakens.

## Limitations
- Small sample size (N=69 participants) limits generalizability to broader populations
- Simple geometric stimuli used may not translate to complex real-world co-creative tasks
- Task design constrains AI to binary acceptance/rejection without creative contribution capabilities
- Focus on categorization tasks rather than open-ended creative domains

## Confidence
- **High confidence**: The empirical demonstration that MH-based agents improve convergence rates and accuracy compared to control conditions
- **Medium confidence**: The interpretation that these results represent genuine "co-creative learning" rather than improved coordination mechanisms
- **Low confidence**: Claims about scalability to open-ended creative domains or real-world applications

## Next Checks
1. Test the MHNG mechanism with larger, more diverse participant pools (N>200) across multiple creative task types
2. Evaluate performance in open-ended creative domains (story generation, visual art creation) rather than constrained categorization tasks
3. Implement multi-turn interaction sequences where AI can contribute creative elements, not just accept/reject human proposals