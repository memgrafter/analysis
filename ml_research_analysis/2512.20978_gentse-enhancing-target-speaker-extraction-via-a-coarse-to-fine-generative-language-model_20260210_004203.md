---
ver: rpa2
title: 'GenTSE: Enhancing Target Speaker Extraction via a Coarse-to-Fine Generative
  Language Model'
arxiv_id: '2512.20978'
source_url: https://arxiv.org/abs/2512.20978
tags:
- speech
- arxiv
- speaker
- target
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GenTSE addresses target speaker extraction (TSE) by proposing a
  fully generative two-stage decoder-only language model. Stage-1 generates coarse
  semantic tokens, and Stage-2 generates fine acoustic tokens conditioned on those
  predictions.
---

# GenTSE: Enhancing Target Speaker Extraction via a Coarse-to-Fine Generative Language Model

## Quick Facts
- arXiv ID: 2512.20978
- Source URL: https://arxiv.org/abs/2512.20978
- Reference count: 0
- Achieves state-of-the-art perceptual quality and speaker consistency in target speaker extraction on Libri2Mix

## Executive Summary
GenTSE introduces a fully generative two-stage decoder-only language model for target speaker extraction (TSE), addressing limitations of prior models in speaker consistency and perceptual quality. The method uses a coarse-to-fine generation approach, with Stage-1 generating coarse semantic tokens and Stage-2 refining these into fine acoustic tokens, both conditioned on continuous embeddings. To mitigate exposure bias, GenTSE employs Frozen-LM Conditioning (FLC) during training, and uses Direct Preference Optimization (DPO) to align outputs with human perceptual preferences. Evaluated on Libri2Mix, GenTSE outperforms existing LM-based TSE systems in speech quality, intelligibility, and speaker consistency.

## Method Summary
GenTSE is a fully generative TSE system that employs a two-stage decoder-only language model. Stage-1 generates coarse semantic tokens, and Stage-2 generates fine acoustic tokens conditioned on the coarse predictions. Both stages use continuous SSL or codec embeddings and are trained with Frozen-LM Conditioning (FLC) to reduce exposure bias. Direct Preference Optimization (DPO) is applied to align model outputs with human preferences. The system is evaluated on Libri2Mix, showing state-of-the-art performance in perceptual quality and speaker consistency.

## Key Results
- Achieves UTMOS of 4.135, NISQA of 3.399, and SECS of 0.927 on Libri2Mix, surpassing prior LM-based systems.
- Outperforms LLaSE-G1, Metis, and USEF-SepFormer in speech quality, intelligibility, and speaker consistency.
- Demonstrates effective coarse-to-fine generation with frozen LLM conditioning and DPO.

## Why This Works (Mechanism)
The coarse-to-fine generative approach allows the model to first capture high-level semantic content before refining into fine acoustic details, improving both quality and speaker consistency. Frozen-LM Conditioning reduces exposure bias by anchoring early-stage predictions to a robust language model, while DPO aligns outputs with human perceptual preferences, enhancing subjective quality.

## Foundational Learning
- **Target Speaker Extraction (TSE)**: Isolating a specific speaker's voice from a mixture. Needed to focus on one speaker in multi-talker environments.
- **Coarse-to-Fine Generation**: First generating rough semantic tokens, then refining into fine acoustic tokens. Needed to balance efficiency and detail.
- **Frozen-LM Conditioning (FLC)**: Using a frozen language model during training to reduce exposure bias. Needed to stabilize early predictions and improve consistency.
- **Direct Preference Optimization (DPO)**: Aligning model outputs with human preferences. Needed to improve perceptual quality and subjective metrics.
- **Continuous SSL/Codec Embeddings**: Representing audio as continuous tokens. Needed for efficient generative modeling of speech.
- **Exposure Bias**: The discrepancy between training and inference when using generated data as input. Needed to be addressed for stable generation.

## Architecture Onboarding

**Component Map**
SepFormer encoder -> Stage-1 coarse semantic token generation -> Stage-2 fine acoustic token generation -> Output reconstruction

**Critical Path**
The SepFormer encoder extracts features, which Stage-1 uses to generate coarse tokens; Stage-2 conditions on these tokens to produce fine acoustic tokens, which are then decoded into the final speaker-extracted waveform.

**Design Tradeoffs**
- Coarse-to-fine increases inference steps but improves quality and consistency.
- Frozen LLM conditioning stabilizes training but may introduce domain mismatch.
- DPO improves subjective metrics but requires preference data and careful tuning.

**Failure Signatures**
- Degraded speaker consistency if coarse tokens are noisy or Stage-2 conditioning is weak.
- Exposure bias issues if FLC is insufficient.
- Suboptimal perceptual quality if DPO is undertuned or preference data is limited.

**First Experiments**
1. Test the impact of varying the soft token target range (120-220) on generation quality.
2. Compare performance with and without DPO to quantify its contribution.
3. Evaluate speaker consistency with and without FLC to isolate its effect.

## Open Questions the Paper Calls Out
None

## Limitations
- Ablation study is incomplete; lacks isolated analysis of DPO, FLC, and coarse-to-fine stages.
- No perceptual listening study or speaker verification to confirm speaker consistency claims.
- Soft token target range is loosely constrained, potentially affecting model behavior.
- Frozen LLM conditioning may introduce domain mismatch between general language and speech.

## Confidence
- **High confidence**: System architecture and training setup (SepFormer encoder, two-stage LM, DPO, FLC).
- **Medium confidence**: Perceptual metric superiority claims (UTMOS, NISQA, SECS) — strong on paper, but no human evaluation.
- **Medium confidence**: Speaker consistency claims — metrics support it, but verification is indirect.

## Next Checks
1. Conduct ablation studies isolating DPO, FLC, and the coarse-to-fine stages to quantify each contribution.
2. Run speaker verification tests on extracted utterances to empirically confirm speaker consistency.
3. Compare against a version trained with a frozen LLM from a speech-specific pretraining corpus to assess domain mismatch effects.