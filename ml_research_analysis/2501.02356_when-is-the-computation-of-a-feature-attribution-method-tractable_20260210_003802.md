---
ver: rpa2
title: When is the Computation of a Feature Attribution Method Tractable?
arxiv_id: '2501.02356'
source_url: https://arxiv.org/abs/2501.02356
tags:
- indices
- power
- values
- computation
- expected
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work analyzes the computational complexity of feature attribution
  methods beyond the well-studied SHAP values. The authors study power indices from
  cooperative game theory, including Shapley and Banzhaf values, which measure feature
  contributions to model predictions.
---

# When is the Computation of a Feature Attribution Method Tractable?

## Quick Facts
- arXiv ID: 2501.02356
- Source URL: https://arxiv.org/abs/2501.02356
- Reference count: 6
- This work analyzes the computational complexity of feature attribution methods beyond SHAP values, showing conditions for efficient computation of power indices.

## Executive Summary
This paper investigates when feature attribution methods from cooperative game theory can be computed efficiently. The authors analyze power indices like Shapley and Banzhaf values, establishing conditions under which these indices can be computed via polynomial interpolation over expected values. They introduce Bernoulli power indices that require only two expected value evaluations, and explore interaction power indices for feature subsets. The work establishes polynomial equivalence between computing these indices and evaluating expected values for certain model classes, while identifying cases where index computation can be simpler than expected value computation.

## Method Summary
The authors analyze the computational complexity of feature attribution methods by establishing polynomial-time algorithms for computing power indices through polynomial interpolation techniques. They introduce Bernoulli power indices as a special case that reduces computation to just two expected value evaluations. The framework connects the complexity of computing attribution values to the complexity of evaluating expected values under different distributions, providing a systematic approach to determining when attribution computation is tractable.

## Key Results
- Bernoulli power indices can be computed with only two expected value evaluations
- Polynomial interpolation enables efficient computation of many simple power indices
- Computational complexity of interaction power indices mirrors that of individual features
- Polynomial equivalence established between power index computation and expected value evaluation for certain model classes

## Why This Works (Mechanism)
The tractability results stem from the mathematical structure of power indices as polynomial functions of expected values. By leveraging polynomial interpolation, the authors show that many power indices can be computed efficiently when the underlying expected values have specific structural properties. The Bernoulli power indices work because they depend only on extremal cases of feature inclusion, reducing the computational burden to minimal expected value evaluations.

## Foundational Learning
- **Cooperative Game Theory**: Why needed - Provides the mathematical foundation for power indices and feature attribution. Quick check - Verify understanding of characteristic functions and the Shapley value formula.
- **Polynomial Interpolation**: Why needed - Enables efficient computation of power indices from expected values. Quick check - Confirm ability to reconstruct polynomials from point evaluations.
- **Computational Complexity**: Why needed - Establishes the theoretical bounds for tractability. Quick check - Review P vs NP and polynomial-time reducibility concepts.
- **Expected Value Computation**: Why needed - Central to both power indices and their tractability. Quick check - Understand Monte Carlo estimation and exact computation methods.
- **Feature Attribution Methods**: Why needed - The practical motivation and application domain. Quick check - Compare different attribution methods like SHAP, LIME, and Integrated Gradients.
- **Model Independence**: Why needed - Many results apply regardless of specific model architecture. Quick check - Identify which assumptions about models are necessary vs sufficient.

## Architecture Onboarding

Component Map:
Power Indices -> Polynomial Interpolation -> Expected Value Computation
Attribution Method -> Model Evaluation -> Tractability Analysis

Critical Path:
Model evaluation → Expected value computation → Power index calculation → Tractability determination

Design Tradeoffs:
- Precision vs. computational efficiency in polynomial interpolation
- Generality of results vs. practical applicability to specific model architectures
- Number of expected value evaluations vs. accuracy of power index approximation
- Binary vs. continuous feature space representations

Failure Signatures:
- High variance in Monte Carlo expected value estimates leading to inaccurate power indices
- Polynomial interpolation errors when expected values don't follow the assumed structure
- Tractability results not holding for models with complex feature dependencies
- Computational bottlenecks when scaling to high-dimensional feature spaces

First Experiments:
1. Implement Bernoulli power index computation on simple linear models to verify the two-evaluation claim
2. Apply polynomial interpolation to compute Shapley values on a small dataset with known ground truth
3. Benchmark tractability results on diverse model architectures including neural networks and tree ensembles

## Open Questions the Paper Calls Out
None

## Limitations
- Results heavily depend on theoretical bounds and specific model structure assumptions
- Practical applicability may vary significantly across real-world models and datasets
- Focus on binary feature spaces may not capture complexity of continuous or high-dimensional features
- Potential numerical stability issues with polynomial interpolation for large feature spaces

## Confidence

High confidence:
- Theoretical bounds on computational complexity for Bernoulli power indices
- Polynomial-time algorithms for specific model classes
- Equivalence between power index computation and expected value evaluation under stated conditions

Medium confidence:
- Practical applicability of tractability results to real-world machine learning models
- Generalization of results to continuous feature spaces and non-binary interactions
- Numerical stability of polynomial interpolation methods in practice

Low confidence:
- Impact of feature correlations on tractability bounds
- Performance on models with complex non-linear feature interactions
- Scalability to very high-dimensional feature spaces

## Next Checks

1. Implement and benchmark the proposed algorithms on diverse real-world datasets to assess practical tractability and computational efficiency.

2. Extend the theoretical analysis to continuous feature spaces and non-binary feature interactions to evaluate the generalizability of the results.

3. Investigate the impact of feature correlations and conditional independence assumptions on the tractability bounds and algorithm performance.