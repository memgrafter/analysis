---
ver: rpa2
title: Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User
  Response Prediction
arxiv_id: '2602.01775'
source_url: https://arxiv.org/abs/2602.01775
tags:
- uni00000013
- uni00000011
- knowledge
- teacher
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses high model switching costs in large-scale
  user response prediction systems, where deploying new architectures requires expensive
  retraining and suffers performance degradation due to data retention constraints.
  The proposed CrossAdapt framework solves this through a two-stage approach: offline
  cross-architecture transfer using dimension-adaptive embedding projections and progressive
  network distillation, combined with strategic sampling to reduce computational cost;
  and online adaptive co-distillation with asymmetric teacher-student updates and
  distribution-aware historical knowledge preservation.'
---

# Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction

## Quick Facts
- arXiv ID: 2602.01775
- Source URL: https://arxiv.org/abs/2602.01775
- Reference count: 40
- Primary result: CrossAdapt framework improves AUC by 0.27-0.43% while reducing training time by 43-71% on public datasets and significantly reduces AUC degradation and prediction bias in large-scale production deployment.

## Executive Summary
This paper addresses the high cost of deploying new model architectures in large-scale user response prediction systems. The proposed CrossAdapt framework enables efficient cross-architecture knowledge transfer through a two-stage approach combining offline dimension-adaptive embedding projections with progressive network distillation, and online adaptive co-distillation with asymmetric teacher-student updates. Experiments demonstrate significant performance improvements while dramatically reducing training time and model switching costs.

## Method Summary
CrossAdapt employs a two-stage transfer process. Offline, it projects teacher embeddings to student dimensions using PCA (for reduction) or QR decomposition (for expansion), then progressively distills knowledge by first training the student network with frozen embeddings before joint fine-tuning. Online, it implements asymmetric co-distillation where the student updates continuously while the teacher updates every 10 steps, with adaptive historical knowledge preservation based on distribution shift detection. The framework also includes unclicked sample augmentation to expand training space.

## Key Results
- 0.27-0.43% AUC improvements on public datasets (Criteo, Avazu, Criteo1T)
- 43-71% reduction in training time compared to standard training
- Large-scale deployment on Tencent WeChat Channels (10M daily samples) shows significant reductions in AUC degradation, LogLoss increase, and prediction bias
- Progressive distillation prevents gradient interference that destroys transferred embedding structure

## Why This Works (Mechanism)

### Mechanism 1: Dimension-Adaptive Embedding Projection
Mapping embeddings mathematically (rather than training them) preserves relational geometry, bypassing the prohibitive cost of retraining massive tables. PCA reduces dimensions while minimizing distortion of pairwise inner products, while QR decomposition extends embeddings orthogonally while preserving original inner products exactly. The semantic value of categorical features is primarily encoded in their geometric relationships rather than specific axis values.

### Mechanism 2: Progressive Interaction Network Distillation
Decoupling the optimization of interaction networks from embeddings prevents gradient interference where a randomly initialized network destroys the transferred embedding structure. By freezing projected embeddings initially, the framework prevents the "cold start" state of a student network from producing high-variance, destructive gradients that destabilize static knowledge bases.

### Mechanism 3: Asymmetric Teacher-Student Co-evolution
Separating update frequencies stabilizes supervision, allowing the student to adapt rapidly while the teacher serves as a knowledge anchor. In non-stationary online environments, fully synchronized updates lead to unstable supervision, while a static teacher becomes obsolete. The asymmetric approach balances stability with adaptability.

## Foundational Learning

- **Knowledge Distillation (KD) Loss:** Why needed here - the framework relies on transferring "soft labels" or internal states, not just hard labels. Quick check: Can you distinguish between hard label cross-entropy and knowledge distillation loss, and explain why KD might contain more information per sample?

- **Gram Matrix / Inner Product Preservation:** Why needed here - the theoretical guarantee for embedding projection rests on minimizing distortion in the Gram matrix. Quick check: If you have two vectors u and v, what does their dot product represent geometrically, and why would preserving these values be critical for recommendation systems?

- **Distribution Shift Detection:** Why needed here - the online stage dynamically adjusts training based on detected shifts (Jensen-Shannon divergence). Quick check: How would you detect if the user behavior distribution has changed significantly between time window W_i and W_{i+1}?

## Architecture Onboarding

- **Component map:** Teacher Model (f_T) -> Projection Layer (PCA/QR) -> Student Model (f_S) -> Shift Detector
- **Critical path:** Projection (Sec 3.1.1) -> Phase 1 Training (Freeze E_S) -> Phase 2 Training (Unfreeze) -> Online Co-distillation (Asymmetric updates)
- **Design tradeoffs:** Aggressive reduction (d_S << d_T) saves memory but risks information loss; expansion adds capacity but requires careful initialization. Low sampling ratio speeds up offline training but may miss long-tail patterns.
- **Failure signatures:** Collapsed Embeddings if Phase 1 is skipped; Oscillating Loss if teacher updates too frequently.
- **First 3 experiments:** 1) Projection Validity - measure correlation between teacher's and student's predictions before network training; 2) Progressive Ablation - compare end-to-end vs. progressive training to isolate gradient interference; 3) Asymmetry Tuning - vary teacher update interval τ to find stability/adaptability sweet spot.

## Open Questions the Paper Calls Out

1. Does the adaptive historical knowledge preservation module maintain its offline efficacy when deployed in a live production environment with strict latency constraints? The paper notes this module "currently faces infrastructure limitations... and cannot be deployed at this stage."

2. How robust is the Unclicked Sample Augmentation strategy against propagation of systematic biases from the teacher model? If the teacher exhibits significant prediction bias, the student may inherit and amplify these errors.

3. Is an embedding projection optimized for inner product preservation theoretically optimal for student architectures that utilize complex interaction mechanisms like bilinear pooling or attention? The theoretical guarantee focuses on dot-product similarity, leaving open whether alternative projections could better preserve semantic structures for non-dot-product operations.

## Limitations

- The framework assumes the teacher model is well-trained and that offline data is representative of future streaming data; poor teacher training or stale data can propagate errors.
- Aggressive dimension reduction can discard critical variance, especially for sparse categorical features with only 8-16 dimensions for high-cardinality features.
- Online stability depends heavily on careful tuning of the teacher update interval τ, which may not generalize to all data rates or shift intensities.

## Confidence

- **High Confidence:** Mathematical formulation of embedding projection (PCA/QR) and theoretical guarantee (Theorem 1) are well-defined and sound. Ablation study validating progressive vs. standard distillation is strong.
- **Medium Confidence:** Online co-distillation mechanism and adaptive historical sampling are based on reasonable assumptions but effectiveness depends heavily on specific choices of τ and JS divergence threshold.
- **Low Confidence:** Paper lacks detailed implementation specifics for JS divergence calculation on high-cardinality categorical features, a critical component of the online stage.

## Next Checks

1. **Offline Projection Ablation:** Systematically vary dimension reduction ratio (e.g., d_S/d_T = 0.5, 0.25, 0.1) on Criteo to measure trade-off between AUC and embedding table size.

2. **Online Asymmetry Sweep:** Run online co-distillation with τ in {1, 5, 10, 50, 100} on simulated distribution shift to find optimal balance between stability and adaptability.

3. **Cross-Dataset Generalization:** Apply CrossAdapt framework to a non-advertising dataset (e.g., large-scale e-commerce or social media) to test robustness to different feature distributions and user behavior patterns.