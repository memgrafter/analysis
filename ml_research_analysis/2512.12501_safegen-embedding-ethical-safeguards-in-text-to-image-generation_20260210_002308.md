---
ver: rpa2
title: 'SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation'
arxiv_id: '2512.12501'
source_url: https://arxiv.org/abs/2512.12501
tags:
- safegen
- ethical
- text-to-image
- generation
- academic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces SafeGen, a framework that embeds ethical
  safeguards directly into the text-to-image generation pipeline, grounding its design
  in established principles for Trustworthy AI. SafeGen integrates two complementary
  components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading
  prompts, and Hyper-SD, an optimized diffusion model that produces high-fidelity,
  semantically aligned images.'
---

# SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation

## Quick Facts
- arXiv ID: 2512.12501
- Source URL: https://arxiv.org/abs/2512.12501
- Reference count: 28
- Key outcome: SafeGen integrates ethical safeguards into text-to-image generation, achieving IS = 3.52, FID = 22.08, SSIM = 0.79, and BGE-M3 F1-Score = 0.81, demonstrating reconciliation of creative freedom and ethical responsibility.

## Executive Summary
SafeGen is a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established principles for Trustworthy AI. It integrates two complementary components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading prompts, and Hyper-SD, an optimized diffusion model that produces high-fidelity, semantically aligned images. Built on a curated multilingual (English-Vietnamese) dataset and a fairness-aware training process, SafeGen demonstrates that creative freedom and ethical responsibility can be reconciled within a single workflow.

Quantitative evaluations confirm its effectiveness, with Hyper-SD achieving IS = 3.52, FID = 22.08, and SSIM = 0.79, while BGE-M3 reaches an F1-Score of 0.81. An ablation study further validates the importance of domain-specific fine-tuning for both modules. Case studies illustrate SafeGen's practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

## Method Summary
SafeGen integrates ethical safeguards into text-to-image generation by combining a fine-tuned text classifier (BGE-M3) with an optimized diffusion model (Hyper-SD). The framework leverages a curated multilingual dataset and a fairness-aware training process to balance creative freedom with ethical responsibility. The text classifier filters harmful or misleading prompts, while the diffusion model generates high-fidelity, semantically aligned images. Both components are domain-specific and fine-tuned for optimal performance, with an ablation study confirming the importance of this approach.

## Key Results
- SafeGen achieves IS = 3.52, FID = 22.08, and SSIM = 0.79 for image quality, and BGE-M3 F1-Score = 0.81 for safety classification.
- The framework demonstrates effective reconciliation of creative freedom and ethical responsibility in text-to-image generation.
- Case studies show practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

## Why This Works (Mechanism)
SafeGen works by embedding ethical safeguards directly into the text-to-image generation pipeline, ensuring that harmful or misleading prompts are filtered before image generation, while maintaining high-fidelity output. The integration of BGE-M3 and Hyper-SD allows for both safety and quality to be addressed within a single, cohesive workflow. The use of a curated multilingual dataset and fairness-aware training ensures broad applicability and inclusivity, while domain-specific fine-tuning optimizes performance for both safety and image generation tasks.

## Foundational Learning
- **Multilingual Dataset Curation**: Essential for broad applicability and inclusivity across languages; quick check: verify dataset coverage and balance across English and Vietnamese.
- **Fairness-Aware Training**: Needed to mitigate biases and ensure equitable treatment of diverse prompts; quick check: assess bias metrics across demographic groups.
- **Diffusion Model Optimization**: Critical for achieving high-fidelity, semantically aligned images; quick check: compare generated image quality using IS, FID, and SSIM metrics.
- **Text Classifier Fine-Tuning**: Important for accurately identifying harmful or misleading prompts; quick check: evaluate F1-Score and recall on safety-related prompts.
- **Ablation Study Design**: Validates the importance of domain-specific fine-tuning for both safety and image generation components; quick check: compare performance with and without fine-tuning.

## Architecture Onboarding

**Component Map**: BGE-M3 (text classifier) -> Hyper-SD (diffusion model) -> Image Output

**Critical Path**: Prompt Input -> BGE-M3 Filtering -> Hyper-SD Generation -> Safe Image Output

**Design Tradeoffs**: Balancing safety (strict filtering) with creative freedom (minimal over-blocking) and image quality (high fidelity vs. speed).

**Failure Signatures**: 
- False negatives: Harmful prompts slip through BGE-M3, resulting in unsafe images.
- False positives: Benign prompts are blocked, limiting creative freedom.
- Image artifacts: Hyper-SD fails to generate semantically aligned images despite safe prompts.

**First Experiments**:
1. Test BGE-M3's ability to block a range of harmful prompts (e.g., violence, misinformation) while allowing safe, creative ones.
2. Evaluate Hyper-SD's image quality and semantic alignment on a diverse set of safe prompts.
3. Conduct an ablation study to compare performance with and without domain-specific fine-tuning for both components.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation relies on quantitative metrics that do not directly measure real-world harm prevention or user perception of safety.
- The dataset curation process is not fully detailed, raising potential concerns about biases or blind spots.
- The bilingual scope may not generalize to other languages or cultural contexts without additional adaptation.

## Confidence
- Technical implementation and quantitative results: **High**
- Integration of ethical principles into model design: **Medium**
- Generalizability and real-world harm prevention: **Low**
- Reconciliation of creative freedom with ethical responsibility: **Medium**

## Next Checks
1. Conduct user studies with diverse populations to assess perceived safety, inclusivity, and creative satisfaction when using SafeGen.
2. Test SafeGen's robustness against adversarial or out-of-distribution prompts to identify potential bypasses of safety filters.
3. Expand evaluation to additional languages and cultural contexts to verify generalizability beyond the current bilingual dataset.