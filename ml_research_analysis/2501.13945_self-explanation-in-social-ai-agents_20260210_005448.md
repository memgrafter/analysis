---
ver: rpa2
title: Self-Explanation in Social AI Agents
arxiv_id: '2501.13945'
source_url: https://arxiv.org/abs/2501.13945
tags:
- sami
- self-explanation
- social
- questions
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a computational technique for self-explanation
  in social AI agents, specifically SAMI (Social Agent Mediated Interaction), which
  helps students in online classes form social connections. The method combines generative
  AI with knowledge-based AI by using a Task-Method-Knowledge (TMK) framework as a
  self-model and Chain of Thought reasoning with ChatGPT to generate explanations.
---

# Self-Explanation in Social AI Agents

## Quick Facts
- **arXiv ID**: 2501.13945
- **Source URL**: https://arxiv.org/abs/2501.13945
- **Reference count**: 28
- **Primary result**: 49/66 questions answered correctly with self-explanation framework combining TMK models and Chain of Thought reasoning

## Executive Summary
This paper presents a computational technique for self-explanation in social AI agents, specifically for SAMI (Social Agent Mediated Interaction), which helps students in online classes form social connections. The approach combines generative AI with knowledge-based AI by using a Task-Method-Knowledge (TMK) framework as a self-model and Chain of Thought reasoning with ChatGPT to generate explanations. The system aims to enhance transparency and trust in social AI assistants through introspection over structured self-models.

## Method Summary
The method implements self-explanation through a hybrid architecture combining a TMK framework as a structured self-model with Chain of Thought reasoning powered by ChatGPT. When users ask questions about the AI agent's functioning, the system uses the TMK model to introspect on its own knowledge and reasoning processes, then generates explanations through a reasoning chain. The approach was evaluated on 66 questions, with precision tests confirming consistent responses across multiple queries, and an ablation study demonstrating that information from the self-model significantly improves answer quality.

## Key Results
- 49 out of 66 questions answered correctly (37 complete answers)
- Initial deployment showed students found explanations clear and helpful for understanding SAMI's functioning
- Ablation study confirmed self-model information improves answer quality
- Precision tests indicated consistent responses across multiple queries

## Why This Works (Mechanism)
The approach works by combining structured knowledge representation (TMK framework) with the reasoning capabilities of large language models. The TMK framework provides a coherent self-model that captures the agent's tasks, methods, and knowledge, while Chain of Thought reasoning enables step-by-step explanation generation. This hybrid approach leverages the structured reasoning of knowledge-based AI with the natural language generation capabilities of generative AI, allowing the system to introspect on its own functioning and generate coherent explanations that enhance transparency and trust.

## Foundational Learning
- **Task-Method-Knowledge (TMK) Framework**: A structured modeling approach for representing AI systems' components; needed to provide coherent self-model for introspection, quick check is whether the model captures all essential aspects of the agent's functionality
- **Chain of Thought Reasoning**: A prompting technique that guides LLMs through step-by-step reasoning; needed to generate coherent explanations from the self-model, quick check is whether the reasoning chain follows logical progression
- **Knowledge-Based AI**: AI approaches that use structured knowledge representations; needed to provide the formal framework for self-modeling, quick check is whether the knowledge representation supports effective introspection
- **Generative AI Integration**: Combining structured knowledge with LLMs; needed to bridge formal models with natural language explanations, quick check is whether explanations maintain accuracy while being comprehensible

## Architecture Onboarding

**Component Map**: User Question -> TMK Self-Model -> Chain of Thought Reasoning (ChatGPT) -> Explanation Output

**Critical Path**: The critical path flows from user questions through the TMK self-model to generate context, then through Chain of Thought reasoning to produce explanations. The TMK model provides the structured knowledge needed for meaningful introspection, while the reasoning chain ensures coherent explanation generation.

**Design Tradeoffs**: The system trades off between the precision and consistency of knowledge-based AI with the flexibility and natural language capabilities of generative AI. Using ChatGPT for explanation generation introduces potential for hallucinations but provides superior natural language output compared to purely rule-based systems.

**Failure Signatures**: Potential failures include explanations that are technically correct but difficult to understand, incomplete introspection due to limitations in the TMK model, and hallucinations or irrelevant content from the generative component. The ablation study showed that without the self-model, answer quality degrades significantly.

**First 3 Experiments**:
1. Test the system with a diverse set of 100+ questions spanning different domains to assess robustness
2. Conduct A/B testing comparing student understanding with and without self-explanations
3. Implement real-time feedback collection to measure explanation quality and relevance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas for future research are implied, including systematic evaluation of the impact on learning outcomes, testing across diverse question domains, and longitudinal studies of user trust development.

## Limitations
- Limited evaluation scope with 66 questions may not represent diverse real-world scenarios
- Initial deployment feedback based on subjective impressions rather than rigorous outcome measures
- Reliance on ChatGPT introduces potential vulnerabilities to hallucinations or irrelevant content
- No longitudinal studies to validate claims about trust and transparency development

## Confidence

- **High confidence**: The technical implementation of the self-explanation framework combining TMK models with Chain of Thought reasoning is sound and well-described.
- **Medium confidence**: The ablation study results showing improved answer quality with the self-model are valid but may not generalize to all question types.
- **Medium confidence**: Initial deployment feedback indicates positive reception, but lacks rigorous evaluation of actual impact on learning or social connections.
- **Low confidence**: The claim that this approach "enables transparency and trust" is supported by initial positive feedback but not yet validated through longitudinal studies or objective measures of user trust.

## Next Checks

1. Conduct a controlled study comparing learning outcomes and social connection formation between students using SAMI with self-explanations versus those without this feature.

2. Perform systematic testing across diverse question domains to assess the robustness of explanations and identify potential failure modes in the Chain of Thought reasoning process.

3. Implement and evaluate a feedback mechanism where students can rate explanation quality and relevance in real-time, using this data to iteratively improve the self-model and explanation generation process.