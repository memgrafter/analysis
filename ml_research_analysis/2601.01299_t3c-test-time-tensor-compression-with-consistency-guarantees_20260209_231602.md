---
ver: rpa2
title: 'T3C: Test-Time Tensor Compression with Consistency Guarantees'
arxiv_id: '2601.01299'
source_url: https://arxiv.org/abs/2601.01299
tags:
- arxiv
- latency
- budget
- https
- rank
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: T3C introduces a train-once, test-time compression framework that
  enables dynamic rank and precision adjustment via a lightweight controller and fast
  consistency certificate. It maintains elastic tensor factorizations up to a maximal
  rank, couples rank with rank-tied mixed-precision quantization, and snaps per-layer
  assignments to hardware-aligned profiles for monotone, device-aware trade-offs.
---

# T3C: Test-Time Tensor Compression with Consistency Guarantees

## Quick Facts
- arXiv ID: 2601.01299
- Source URL: https://arxiv.org/abs/2601.01299
- Reference count: 40
- Primary result: Single checkpoint delivers predictable, certificate-backed accuracy-latency-size curves across devices with zero budget violations

## Executive Summary
T3C introduces a train-once, test-time compression framework that enables dynamic rank and precision adjustment via a lightweight controller and fast consistency certificate. It maintains elastic tensor factorizations up to a maximal rank, couples rank with rank-tied mixed-precision quantization, and snaps per-layer assignments to hardware-aligned profiles for monotone, device-aware trade-offs. The certificate upper-bounds logit drift using spectral proxies and activation statistics, allowing regularization during training and risk-aware deployment reporting. On ImageNet-1k, T3C achieves matched accuracy with lower latency and smaller model size than strong PTQ/QAT baselines.

## Method Summary
T3C proposes a novel approach to tensor compression that decouples training from deployment optimization. The method trains a single model with elastic tensor factorizations, then uses a lightweight controller at test time to adjust both tensor rank and precision based on device constraints. The framework introduces a consistency certificate that provides theoretical guarantees on accuracy degradation, computed efficiently using spectral-norm proxies and activation statistics. By coupling rank selection with mixed-precision quantization and aligning assignments to hardware profiles, T3C achieves monotonic accuracy-latency-size trade-offs across different deployment scenarios.

## Key Results
- ResNet-50: 1.18ms p50 latency, 38MB size, <0.5% accuracy drop vs. PTQ-8b (1.44ms, 88MB)
- Single checkpoint delivers predictable, certificate-backed accuracy-latency-size curves across devices
- Zero budget violations achieved across vision and language models

## Why This Works (Mechanism)
T3C's effectiveness stems from its unified approach to rank and precision control during inference. By training with elastic tensor factorizations, the model learns representations that remain robust across different compression levels. The controller uses real-time device feedback to make optimal trade-offs between accuracy, latency, and memory. The consistency certificate provides a safety net by bounding potential accuracy degradation, enabling aggressive compression while maintaining reliability. The hardware-aware snapping mechanism ensures that compression decisions map directly to achievable performance on target devices.

## Foundational Learning
- **Elastic tensor factorizations**: Allow models to maintain performance across different compression levels by training with variable-rank representations
- **Consistency certificates**: Provide theoretical bounds on accuracy degradation using spectral proxies and activation statistics
- **Rank-tied mixed-precision quantization**: Couples tensor rank selection with precision control for coherent compression decisions
- **Hardware profile alignment**: Maps compression choices to actual achievable performance on target devices
- **Monotonic trade-off curves**: Ensure that improvements in one metric (latency) don't cause unexpected degradations in others

## Architecture Onboarding
**Component Map**: Controller -> Rank Selector -> Precision Quantizer -> Hardware Profile Snapper -> Model Execution
**Critical Path**: Inference request → Device profiling → Controller decision → Rank/precision assignment → Execution
**Design Tradeoffs**: Flexibility vs. overhead (controller complexity), theoretical guarantees vs. practical performance, hardware specificity vs. generalization
**Failure Signatures**: Controller instability on tiny datasets, certificate looseness for unbounded activations, rank-tied quantization coupling artifacts
**Three First Experiments**: 
1. Profile baseline latency/memory on target hardware
2. Validate certificate bounds on validation set with known perturbations
3. Test controller convergence across different temperature schedules

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the consistency certificate be tightened for highly non-Lipschitz components or under distribution shift?
- Basis in paper: [explicit] Section 7 states future work will focus on "tightening and stress-testing the certificate under distribution shift and highly non-Lipschitz components."
- Why unresolved: Section 6.5 notes the certificate relies on spectral-norm proxies which can loosen for unbounded activations or aggressive normalization.
- What evidence would resolve it: A modified certificate formulation (e.g., non-linear bounds) demonstrating reduced looseness (smaller $\epsilon$ gap) on adversarial or shifted datasets compared to the current spectral proxy.

### Open Question 2
- Question: Can controller robustness be guaranteed in extreme-budget or low-data regimes without manual curriculum?
- Basis in paper: [explicit] Section 6.5 lists "controller instability on tiny datasets" as a limitation, and Section 7 lists "improving controller robustness in extreme-budget and low-data regimes" as future work.
- Why unresolved: The current method relies on temperature schedules and budget curricula which are sensitive to initialization and data volume.
- What evidence would resolve it: An ablation study showing stable policy convergence and maintained accuracy on few-shot datasets (e.g., <1k samples) using a modified training objective.

### Open Question 3
- Question: Can the control plane be extended to incorporate structured sparsity while preserving monotonicity guarantees?
- Basis in paper: [explicit] Section 7 proposes "extending the control plane to incorporate structured sparsity... while preserving monotonic budget guarantees."
- Why unresolved: Current T3C focuses on rank and precision; adding sparsity introduces kernel availability constraints (noted in Sec 6.5) that may conflict with monotone budget behavior.
- What evidence would resolve it: A unified T3C implementation including pruning masks that demonstrates zero monotonicity violations across budget increments on hardware supporting structured sparsity.

## Limitations
- Consistency certificate reliability under distribution shift and non-Lipschitz activations
- Controller instability on tiny datasets without manual curriculum
- Hardware profile specificity may limit generalization beyond tested devices

## Confidence
- **High Confidence**: Empirical latency, memory, and accuracy measurements on ImageNet-1k; reproducibility of per-layer hardware alignment; monotonicity of accuracy-latency curves
- **Medium Confidence**: Generalization claims across vision and language models; consistency certificate bounds under varying activation distributions; zero-budget-violation assertion
- **Low Confidence**: Scalability to trillion-parameter models; behavior under severe resource constraints; robustness to non-IID test distributions

## Next Checks
1. Stress-test the consistency certificate on adversarially perturbed inputs across multiple model families to verify spectral proxy reliability
2. Profile T3C-compressed models on edge devices (mobile SoCs, microcontrollers) to validate hardware alignment claims beyond server-class GPUs/CPUs
3. Conduct ablation studies isolating rank-tied quantization effects by comparing against independent rank and precision optimization baselines on transformer architectures