---
ver: rpa2
title: 'Query Decomposition for RAG: Balancing Exploration-Exploitation'
arxiv_id: '2510.18633'
source_url: https://arxiv.org/abs/2510.18633
tags:
- documents
- query
- retrieval
- document
- relevance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of efficiently selecting relevant
  documents in retrieval-augmented generation (RAG) systems when handling complex
  queries. The authors formulate query decomposition and document retrieval as an
  exploitation-exploration problem using a multi-armed bandit framework, where each
  sub-query is treated as an arm and document relevance observations build beliefs
  about sub-query utility.
---

# Query Decomposition for RAG: Balancing Exploration-Exploitation

## Quick Facts
- arXiv ID: 2510.18633
- Source URL: https://arxiv.org/abs/2510.18633
- Reference count: 25
- Primary result: 35% gain in document-level precision with rank-aware bandit policy

## Executive Summary
This paper addresses the challenge of efficiently selecting relevant documents in retrieval-augmented generation (RAG) systems when handling complex queries. The authors formulate query decomposition and document retrieval as an exploitation-exploration problem using a multi-armed bandit framework, where each sub-query is treated as an arm and document relevance observations build beliefs about sub-query utility. They propose a rank-aware top-k Bernoulli policy with upper confidence bounds and diversity constraints that dynamically selects the most informative sub-queries under a fixed budget.

## Method Summary
The framework treats query decomposition as a sequential decision-making problem where sub-queries compete for limited retrieval resources. Each sub-query represents an "arm" in a multi-armed bandit setup, with document relevance serving as stochastic rewards. The rank-aware top-k Bernoulli policy maintains belief distributions over sub-query utilities using upper confidence bounds, balancing exploitation of known high-performing sub-queries with exploration of potentially useful but untested ones. Diversity constraints prevent redundancy in retrieved documents. The approach extends to hierarchical decomposition, where sub-queries can themselves be decomposed into finer-grained components.

## Key Results
- 35% gain in document-level precision over baseline methods
- 15% increase in α-nDCG metric for retrieval effectiveness
- 6.0–9.9% higher citation support in downstream long-form generation
- 6.7–8.5% better nugget coverage in generated outputs
- 7.3–9.6% stronger sentence support compared to baselines

## Why This Works (Mechanism)
The method works by treating query decomposition as an active learning problem where the system must allocate limited retrieval budget across multiple sub-queries. The bandit framework naturally captures the exploration-exploitation trade-off: early iterations explore different sub-queries to build relevance estimates, while later iterations exploit the best-performing ones. The rank-aware component ensures that retrieval quality is considered, not just binary relevance. Diversity constraints prevent the system from over-focusing on similar sub-queries that might retrieve redundant documents.

## Foundational Learning

**Multi-armed bandit algorithms** - why needed: To balance exploration of new sub-queries with exploitation of known good ones under budget constraints. quick check: Can the policy converge to optimal sub-query selection over time?

**Bernoulli reward modeling** - why needed: To handle the binary nature of document relevance judgments in retrieval tasks. quick check: Are relevance scores well-modeled as independent Bernoulli trials?

**Upper confidence bound (UCB) methods** - why needed: To maintain uncertainty estimates that encourage exploration of under-sampled sub-queries. quick check: Does the confidence bound appropriately scale with sample size?

**Query decomposition strategies** - why needed: To break complex queries into manageable sub-components that can be retrieved independently. quick check: Are decomposed sub-queries semantically meaningful and non-redundant?

**Diversity constraints in retrieval** - why needed: To prevent redundancy and ensure broad coverage of relevant documents. quick check: Do diversity constraints improve downstream generation quality?

**Hierarchical decomposition** - why needed: To handle extremely complex queries that benefit from multi-level decomposition. quick check: Does hierarchical decomposition outperform flat approaches for complex queries?

## Architecture Onboarding

**Component map**: Query decomposition -> Bandit policy -> Document retrieval -> Relevance feedback -> Utility update

**Critical path**: Complex query → Decomposition engine → Sub-query pool → Bandit selector → Retrieval module → Relevance assessment → Policy update

**Design tradeoffs**: Fixed budget vs. adaptive allocation; exploration vs. exploitation; diversity vs. relevance; hierarchical vs. flat decomposition

**Failure signatures**: Over-exploration leading to poor precision; premature exploitation missing useful sub-queries; diversity constraints too strict causing coverage gaps; hierarchical decomposition creating semantically incoherent sub-queries

**First experiments**:
1. Compare simple greedy selection vs. bandit policy on synthetic query decompositions
2. Evaluate impact of different exploration parameters (temperature, confidence bounds)
3. Test hierarchical vs. flat decomposition on queries of varying complexity

## Open Questions the Paper Calls Out
None

## Limitations
The reported gains rely heavily on simulated ground-truth relevance judgments for sub-queries, which may not reflect real-world noise in actual RAG deployments where relevance feedback is ambiguous. The bandit policy assumes independence between sub-queries, but in practice overlapping or semantically related sub-queries could violate this assumption and reduce policy effectiveness. The experiments focus on Wikipedia-based datasets, limiting generalizability to domains with different document structures or query distributions. The fixed budget assumption may not hold in latency-sensitive applications where query processing time varies significantly across sub-queries.

## Confidence
- Document-level precision improvements (35% gain): High - backed by multiple evaluation metrics and ablation studies
- Rank-aware policy effectiveness: Medium - depends on assumed relevance independence
- Hierarchical decomposition benefits (30% gain): Medium - limited to synthetic query trees in evaluation

## Next Checks
1. Test the policy with realistic noisy relevance feedback from human annotators rather than simulated ground truth
2. Evaluate performance on non-Wikipedia corpora with different document lengths and query distributions
3. Measure end-to-end latency impact when integrating the decomposition framework into real-time RAG systems