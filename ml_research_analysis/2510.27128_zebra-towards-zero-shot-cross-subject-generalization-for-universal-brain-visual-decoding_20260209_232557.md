---
ver: rpa2
title: 'ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain
  Visual Decoding'
arxiv_id: '2510.27128'
source_url: https://arxiv.org/abs/2510.27128
tags:
- subjects
- should
- brain
- data
- fmri
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ZEBRA introduces the first zero-shot cross-subject fMRI-to-image
  reconstruction framework. It disentangles brain representations into subject-invariant
  and semantic-specific components using adversarial training and residual decomposition.
---

# ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding

## Quick Facts
- arXiv ID: 2510.27128
- Source URL: https://arxiv.org/abs/2510.27128
- Reference count: 40
- Introduces first zero-shot cross-subject fMRI-to-image reconstruction framework

## Executive Summary
ZEBRA addresses the challenge of generalizing brain visual decoding models across subjects without requiring subject-specific fine-tuning. The method achieves this by disentangling brain representations into subject-invariant and semantic-specific components through adversarial training and residual decomposition. This enables direct application to unseen subjects while maintaining semantic fidelity in reconstructed images. ZEBRA demonstrates significant performance improvements over zero-shot baselines while approaching the accuracy of fully fine-tuned models.

## Method Summary
The ZEBRA framework employs adversarial training to extract subject-invariant features from fMRI data while simultaneously learning semantic-specific representations. It uses residual decomposition to separate subject-specific anatomical and physiological variations from the underlying semantic content of visual stimuli. The model architecture consists of an encoder that processes fMRI data, a disentanglement module that separates invariant and specific features, and a decoder that reconstructs images from the semantic components. This approach allows the model to generalize directly to new subjects without additional training.

## Key Results
- Achieves 0.153 PixCorr, 0.384 SSIM, and 81.8% AlexNet(5) accuracy
- Outperforms zero-shot baselines while approaching fully fine-tuned performance
- Demonstrates preservation of semantic fidelity while filtering subject-specific noise

## Why This Works (Mechanism)
The method works by leveraging adversarial training to create subject-invariant feature representations that capture universal neural patterns across individuals. The residual decomposition strategy effectively separates anatomical and physiological variations from semantic content, allowing the model to focus on task-relevant information. This disentanglement enables the model to generalize across subjects by learning representations that are robust to individual differences in brain structure and function.

## Foundational Learning

**Adversarial training**: A technique where a generator and discriminator compete, with the discriminator learning to distinguish between subject-specific and subject-invariant features. Needed to extract features that generalize across subjects. Quick check: Verify that the discriminator successfully identifies subject-specific variations.

**Residual decomposition**: A method for separating combined signals into constituent components. Required to isolate semantic features from subject-specific noise. Quick check: Confirm that residual components capture meaningful anatomical variations.

**fMRI-to-image reconstruction**: The process of generating visual stimuli from brain activity patterns. Essential for evaluating the quality of semantic feature extraction. Quick check: Validate that reconstructed images preserve original semantic content.

**Subject-invariant feature learning**: The process of identifying neural patterns that remain consistent across individuals. Critical for enabling zero-shot generalization. Quick check: Test feature similarity across different subjects.

**Semantic fidelity preservation**: Ensuring that reconstructed outputs maintain the meaning and content of original stimuli. Important for validating the quality of the disentanglement process. Quick check: Compare semantic similarity between original and reconstructed images.

## Architecture Onboarding

**Component map**: fMRI input -> Encoder -> Disentanglement Module -> Decoder -> Reconstructed Images

**Critical path**: The adversarial training loop between the encoder/disentanglement module and the discriminator represents the critical path, as it directly determines the quality of subject-invariant feature extraction.

**Design tradeoffs**: The framework trades computational complexity for generalization capability. The adversarial training adds overhead but enables zero-shot performance, while residual decomposition adds architectural complexity but improves semantic preservation.

**Failure signatures**: Poor subject-invariant feature extraction manifests as degraded performance on unseen subjects, while inadequate semantic preservation results in loss of image content and meaning in reconstructions.

**First experiments**:
1. Validate adversarial training by testing discriminator accuracy on subject-specific vs. invariant features
2. Test residual decomposition by analyzing the correlation between separated components and known anatomical variations
3. Evaluate zero-shot generalization by applying the model to subjects not in the training set

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gap remains compared to fully fine-tuned models, suggesting some task-specific information may be lost in the disentanglement process
- Computational complexity of adversarial training may limit practical deployment in resource-constrained settings
- Evaluation primarily focuses on visual scene reconstruction, raising questions about applicability to other cognitive domains

## Confidence

| Claim | Confidence |
|-------|------------|
| Effectiveness of adversarial training for subject-invariant features | Medium |
| Quantitative performance improvements over zero-shot baselines | High |
| Robustness across diverse brain regions and cognitive tasks | Low |

## Next Checks

1. Test ZEBRA's generalization capability on a larger, more diverse dataset with subjects from different age groups, cultures, and neurological conditions to assess robustness of subject-invariant feature extraction

2. Apply the framework to non-visual cognitive tasks (e.g., auditory processing, working memory) to evaluate cross-domain applicability of the disentanglement approach

3. Conduct ablation studies systematically removing components of the adversarial training framework to quantify the specific contribution of each element to zero-shot performance