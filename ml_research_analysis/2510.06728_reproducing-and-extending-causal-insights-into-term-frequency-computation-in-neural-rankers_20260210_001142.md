---
ver: rpa2
title: Reproducing and Extending Causal Insights Into Term Frequency Computation in
  Neural Rankers
arxiv_id: '2510.06728'
source_url: https://arxiv.org/abs/2510.06728
tags:
- term
- query
- document
- neural
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study reproduces and extends causal interpretability research
  on neural ranking models, validating that TAS-B encodes term-frequency information
  consistent with IR axioms. Using activation patching on Passage-Retrieval MS-MARCO,
  the authors localize term-frequency tracking to specific attention heads (0.9, 1.6,
  2.3) rather than the four heads identified in the original study.
---

# Reproducing and Extending Causal Insights Into Term Frequency Computation in Neural Rankers

## Quick Facts
- **arXiv ID**: 2510.06728
- **Source URL**: https://arxiv.org/abs/2510.06728
- **Reference count**: 40
- **Primary result**: Activation patching reveals specific attention heads encode term-frequency information in TAS-B, extending TFC1 validation to TFC2 with diminishing returns observed for K ≤ 5

## Executive Summary
This study reproduces and extends causal interpretability research on neural ranking models by validating that TAS-B encodes term-frequency information consistent with IR axioms. Using activation patching on Passage-Retrieval MS-MARCO, the authors localize term-frequency tracking to specific attention heads (0.9, 1.6, 2.3) rather than the four heads identified in the original study. They extend the framework to examine TFC2 axiom, which describes diminishing returns of query term frequency on ranking. Experiments reveal that while the model tracks frequency information, it doesn't consistently adhere to TFC1 axiom when terms are repeatedly appended. For TFC2, attention heads 1.0, 1.9, 1.6, and 0.9 show sublinear behavior for K ≤ 5, with the heads demonstrating logarithmic relationships between frequency and impact. The findings demonstrate that neural ranking models' behavior is more complex than axiomatic properties suggest, highlighting the need for continued research into model transparency.

## Method Summary
The study employs activation patching to localize term-frequency computation in TAS-B neural rankers. The methodology involves three forward passes: baseline (original document), perturbed (document with appended query terms), and patched (replacing activations from perturbed with baseline). The diagnostic datasets use filler token "a" to equalize document lengths across conditions. The authors examine TFC1 axiom (term frequency effects) through append/prepend operations and extend to TFC2 axiom (diminishing returns for repeated query terms). Head-level patching localizes the computation to specific attention heads, with residual stream, attention outputs, and MLP outputs analyzed across layers and token classes. Normalized ranking score recovery measures the effectiveness of patching, with values ranging from 1 (full recovery) to 0 (no effect).

## Key Results
- Activation patching localizes term-frequency tracking to heads 0.9, 1.6, and 2.3 (vs. 4 heads in original study)
- TAS-B does not consistently adhere to TFC1 axiom when query terms are repeatedly appended
- TFC2 analysis reveals sublinear behavior for K ≤ 5 with logarithmic relationships between frequency and impact
- Attention heads 1.0, 1.9, 1.6, and 0.9 show TFC2 effects with R² fit values confirming sublinearity

## Why This Works (Mechanism)
None provided in source material.

## Foundational Learning
- **Activation Patching**: A causal interpretability technique that isolates the effect of specific neural activations by replacing them between forward passes; needed to identify which components compute term frequency, verified by observing score changes when patching specific heads.
- **IR Axioms (TFC1, TFC2)**: Theoretical properties describing how term frequency should affect retrieval rankings; needed as validation targets for model behavior, verified by checking if model outputs follow predicted patterns.
- **Attention Heads**: Individual components in transformer architectures that process different aspects of input; needed as localization targets for term-frequency computation, verified by measuring their contribution to score changes.
- **Normalized Score Recovery**: Metric measuring the effectiveness of activation replacement (1 = full recovery, 0 = no effect); needed to quantify the importance of specific activations, verified by comparing patched vs. baseline/perturbed scores.
- **Sublinear Trend Analysis**: Statistical fitting to verify diminishing returns patterns; needed to confirm TFC2 axiom adherence, verified by R² values of logarithmic fits.
- **Diagnostic Dataset Construction**: Creating controlled input pairs with systematic perturbations; needed to test specific axiomatic properties, verified by ensuring proper filler token placement and length equalization.

## Architecture Onboarding
- **Component Map**: Input Documents → TAS-B Embedding → Top-100 Retrieval → Diagnostic Dataset (TFC1-I, TFC2-K1-10) → Activation Patching (Residual Stream, Attention, MLP) → Score Recovery Analysis → Head Localization
- **Critical Path**: Query → Retrieval → Diagnostic Dataset Construction → Three-Pass Patching → Score Recovery Computation → Head-Level Analysis → Axiom Validation
- **Design Tradeoffs**: Using single filler token "a" simplifies length equalization but may introduce tokenization artifacts; limiting K to 10 controls computational cost but may miss asymptotic behaviors; selecting top-100 documents balances coverage vs. noise.
- **Failure Signatures**: Incorrect filler placement causes baseline/perturbed length mismatches; low query-term occurrence leads to noisy TFC1-R results; numerical instability occurs when perturbed-baseline differences approach zero.
- **First Experiments**: 1) Verify retrieval procedure produces consistent top-100 documents across runs; 2) Test activation patching on simple synthetic examples to confirm score recovery mechanics; 3) Validate head localization by disabling identified heads and measuring performance degradation.

## Open Questions the Paper Calls Out
None provided in source material.

## Limitations
- The study's causal interpretability claims depend critically on underspecified implementation details of the activation patching methodology.
- The identification of specific attention heads appears sensitive to experimental setup details including retrieval procedure and tokenization handling.
- The claim that TAS-B doesn't consistently adhere to TFC1 axiom requires careful interpretation as effects could stem from scoring mechanism or retrieval process itself.
- Using a single filler token and specific filtering criteria may introduce artifacts affecting generalizability.

## Confidence
- **High Confidence**: The experimental framework and activation patching methodology are valid approaches for localizing term-frequency computation in neural rankers.
- **Medium Confidence**: The localization of term-frequency tracking to specific attention heads is reproducible, though exact head numbers may vary with implementation details.
- **Medium Confidence**: The observation of sublinear behavior for TFC2 with K ≤ 5 is methodologically sound, but logarithmic relationship claims require more rigorous validation.
- **Low Confidence**: The broader claim that neural ranking models' behavior is "more complex than axiomatic properties suggest" overgeneralizes from limited experimental conditions.

## Next Checks
1. Replicate activation patching experiments with multiple filler tokens and verify consistency of head localization results across different token choices.
2. Conduct ablation studies by masking or disabling identified attention heads to measure their individual contribution to TFC1 and TFC2 behaviors.
3. Extend analysis to additional neural ranking architectures to assess whether observed head-level behaviors are model-specific or represent broader architectural patterns.