---
ver: rpa2
title: 'Dictionary Learning: The Complexity of Learning Sparse Superposed Features
  with Feedback'
arxiv_id: '2502.05407'
source_url: https://arxiv.org/abs/2502.05407
tags:
- feedback
- sparse
- learning
- feature
- matrix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of learning sparse superposed features
  (e.g., dictionaries) from feedback in the form of relative triplet comparisons.
  The core method involves an agent providing feedback on sparse combinations of atomic
  features, which a learner uses to recover the underlying feature matrix up to normal
  transformation.
---

# Dictionary Learning: The Complexity of Learning Sparse Superposed Features with Feedback

## Quick Facts
- arXiv ID: 2502.05407
- Source URL: https://arxiv.org/abs/2502.05407
- Reference count: 40
- This paper establishes tight feedback complexity bounds for learning sparse superposed features (dictionaries) from relative triplet comparisons.

## Executive Summary
This paper analyzes the feedback complexity of learning sparse feature matrices (dictionaries) through relative triplet comparisons from an agent. The work establishes tight bounds for both constructive settings (where agents can construct activations) and distributional settings (where activations are sampled). For general activations, the complexity is Θ(r(r+1)/2 + (p-r)) where r is the rank and p is the dimension. For sparse activations, the bound is O(p²(2/(p²s) log 2/δ)^(1/p²)). Experiments validate these bounds on feature recovery from Recursive Feature Machines and dictionary extraction from sparse autoencoders in large language models.

## Method Summary
The method involves an agent providing feedback on sparse combinations of atomic features through relative triplet comparisons. The learner converts these triplet inequality constraints into pairwise equality constraints through rescaling. The core approach uses version space learning where the learner selects from all matrices satisfying the feedback constraints. Four feedback mechanisms are explored: Eigendecomposition (leveraging low-rank structure), Sparse Constructive (2-sparse basis), Random Sampling, and Sparse Sampling. Optimization is performed via gradient descent with MSE loss and regularization, or directly solving constraint systems for small dimensions.

## Key Results
- Tight feedback complexity bounds established: Θ(r(r+1)/2 + (p-r)) for low-rank constructive feedback, O(p²(2/(p²s) log 2/δ)^(1/p²)) for sparse sampling
- Theoretical bounds align well with empirical performance on RFM feature recovery and SAE dictionary extraction
- Sparse constructive feedback requires O(p²) samples regardless of rank, while low-rank feedback exploits structure for substantial savings
- Practical implementation validated on Pythia-70M (512×32768) and ChessGPT/OthelloGPT (512×4096) dictionaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feature matrices can be recovered up to normal transformation using relative triplet comparisons from an agent.
- Mechanism: The system converts triplet inequality constraints (α, β, ζ) into pairwise equality constraints through rescaling. Given feedback pairs satisfying ⟨Φ, yy^⊤ − zz^⊤⟩ = 0, the learner identifies matrices that annihilate the orthogonal complement O_Φ* of the target feature matrix.
- Core assumption: The agent can provide consistent feedback following the ground truth feature matrix Φ* with the relation sgn(∥D(α−β)∥ − ∥D(α−ζ)∥) = ℓ.
- Evidence anchors:
  - [abstract]: "We analyze the feedback complexity associated with learning a feature matrix in sparse settings. Our results establish tight bounds when the agent is permitted to construct activations..."
  - [section 4, Lemma 2]: Proves that triplet feedback sets can be reduced to pairwise feedback sets while preserving feature equivalence.
  - [corpus]: Related work on sparse autoencoders (arXiv:2506.15963) confirms sparse feature recovery is achievable but doesn't address feedback-based learning.
- Break condition: If the feature matrix Φ* is degenerate (rank 0) or the feedback contains contradictions, the version space becomes empty or unbounded.

### Mechanism 2
- Claim: Low-rank feature matrices require substantially fewer feedbacks than full-rank matrices.
- Mechanism: The feedback problem decomposes into teaching the kernel (eigenspace with non-zero eigenvalues) and the null space separately. The kernel requires r(r+1)/2 − 1 constraints, while the null space requires (p−r) basis extensions.
- Core assumption: The agent knows or can construct activations in both the eigenspace and null space directions of Φ*.
- Evidence anchors:
  - [section 4.2, Theorem 1]: "the feedback complexity has a tight bound of Θ(r(r+1)/2 + (p−r)−1)" for rank-r matrices.
  - [section 6, Figure 1]: Empirical validation on RFM with rank-4 matrix in 10-dimensional space shows convergence at ~38 feedbacks (matching theoretical bound).
  - [corpus]: No direct corpus evidence on rank-aware feedback complexity; this appears novel.
- Break condition: If the assumed rank r is incorrect (underestimated), the feedback set will be insufficient to uniquely identify Φ*.

### Mechanism 3
- Claim: Sparse sampling from distributions can achieve feature recovery with high probability, but requires more samples as sparsity increases.
- Mechanism: Sample activations from a sparse distribution, construct rescaled pairs that satisfy equality constraints, and rely on the probability that sampled activations span the necessary basis. The bound O(p²(2/(p²_s)log(2/δ))^(1/p²)) emerges from Hoeffding's inequality over random subset selection.
- Core assumption: Activations are sampled i.i.d. from a distribution where each index is non-zero with probability p_nz < 1, and non-zero values follow a Lebesgue distribution.
- Evidence anchors:
  - [section 5, Theorem 4]: Establishes the probabilistic bound for sparse sampled activations with explicit dependence on sparsity parameter s.
  - [section 6, Figure 2]: Shows that higher sparsity (μ = 0.97) requires more feedback samples to approach target MSE compared to lower sparsity (μ = 0.9).
  - [corpus]: Dimensional Collapse paper (arXiv:2508.16929) notes attention outputs occupy low-dimensional subspaces, potentially reducing effective p in practice.
- Break condition: If sparsity is too extreme (p_nz → 0), the probability of sampling a spanning set drops exponentially, making the bound vacuous.

## Foundational Learning

- **Concept**: Symmetric positive semi-definite (PSD) matrices and their eigendecomposition
  - Why needed here: Feature matrices Φ = DD^⊤ are PSD by construction. Understanding that PSD matrices admit eigendecomposition with non-negative eigenvalues is essential for the rank-based complexity reduction.
  - Quick check question: Given a 3×3 symmetric matrix with eigenvalues [2, 0, 0], what is its rank and how many degrees of freedom does it have?

- **Concept**: Version space learning and constraint satisfaction
  - Why needed here: The "oblivious learner" framework assumes the learner selects arbitrarily from all matrices satisfying the feedback constraints. Understanding version spaces clarifies why sufficient spanning of the orthogonal complement O_Φ* guarantees unique recovery.
  - Quick check question: If feedback constraints reduce the version space to a single equivalence class, what does this imply about the learner's output?

- **Concept**: Sparse signal representations and incoherence
  - Why needed here: The paper builds on dictionary learning where activations α are sparse. Mutual incoherence conditions determine when dictionary recovery is possible up to linear transformations.
  - Quick check question: Why does sparsity in activations not directly translate to reduced feedback complexity in the worst case?

## Architecture Onboarding

- Component map: Agent (teacher) → Triplet/Pair Construction → Feedback Set F → Learner ← Constraint Equations ← Rescaling (if sampled) → Matrix Recovery: Solve {⟨Φ, yy^⊤ − zz^⊤⟩ = 0 for all (y,z) ∈ F} → Output: Φ̂ such that Φ̂ = λΦ* for some λ > 0

- Critical path:
  1. Determine the feedback setting (constructive vs. sampled; sparse vs. dense)
  2. Construct or receive activation vectors from the appropriate distribution
  3. Generate rescaled pairs satisfying equality constraints (Algorithm 2)
  4. Solve the linear system or use gradient descent for large-scale problems (Algorithm 3)
  5. Verify recovery via Pearson correlation against ground truth (if available)

- Design tradeoffs:
  - **Eigendecomposition feedback**: Minimal feedback (r(r+1)/2 + p−r) but requires knowledge of Φ*'s structure. Use when you control the agent.
  - **Sparse constructive feedback**: Fixed O(p²) regardless of rank, but only requires 2-sparse activations. Use for worst-case guarantees.
  - **Sparse sampling feedback**: No control over activations, but requires substantially more samples. Use for passive learning scenarios.
  - **Memory vs. batch size**: For p > 500, storing p(p+1)/2 constraints directly is infeasible; gradient descent (Algorithm 3) trades exactness for tractability.

- Failure signatures:
  - **Non-converging PCC**: Feedback set may not span the orthogonal complement. Increase sample count or check distributional assumptions.
  - **Negative eigenvalues in recovered Φ̂**: Numerical issues in constraint solving or insufficient regularization. Increase λ in Algorithm 3.
  - **Rank mismatch**: If recovered rank differs from assumed rank, the eigendecomposition strategy fails. Fall back to sparse constructive or sampling methods.
  - **Memory overflow**: Constraint matrices exceed available memory. Switch to batch-wise gradient descent with sparsity limits.

- First 3 experiments:
  1. **Synthetic validation on low-rank RFM**: Replicate Figure 1 with a known rank-r feature matrix. Verify that eigendecomposition feedback converges at exactly r(r+1)/2 + p−r samples and compare MSE across methods.
  2. **Scaling test on SAE dictionaries**: Train or load an SAE dictionary from a small LLM (e.g., Pythia-70M, p=512). Measure PCC vs. feedback count for sparse sampling with varying sparsity parameters (μ ∈ {0.8, 0.9, 0.95}). Confirm the log(1/δ) dependence.
  3. **Ablation on rank assumption**: Intentionally mis-specify the rank (use r' = r/2 or r' = 2r) in eigendecomposition feedback. Quantify the degradation in recovery quality to establish sensitivity bounds.

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the feedback complexity for ε-approximate feature recovery (in Frobenius norm) rather than exact recovery up to feature equivalence?
  - Basis in paper: [explicit] "A natural next step is to relax exact feature equivalence and ask instead for an ε-accurate approximation in Frobenius norm."
  - Why unresolved: All bounds in the paper address exact recovery; the authors note that extending to approximate recovery is a natural but unexplored direction.
  - What evidence would resolve it: Theoretical bounds on feedback complexity as a function of ε, p, and r, validated empirically.

- **Open Question 2**: Can the gap between theoretical complexity bounds and practical sample requirements be tightened using structural insights from this work?
  - Basis in paper: [explicit] "...an intriguing open question is whether the gap between these bounds and practical sample requirements can be tightened, perhaps by exploiting the structural insights developed in this work."
  - Why unresolved: The paper establishes theoretical bounds but practical experiments may require different sample sizes; bridging this gap remains open.
  - What evidence would resolve it: Refined bounds that more closely match empirical feedback requirements across diverse architectures and tasks.

- **Open Question 3**: Can full dictionary recovery (beyond normal transformation) be achieved without strong coherence assumptions?
  - Basis in paper: [explicit] "...except under strong coherence assumptions (Lemma 1)—full recovery of the underlying dictionary remains open."
  - Why unresolved: Current results only guarantee recovery up to normal transformation; recovering the exact dictionary requires orthogonal rows (strong incoherence), which may not hold in practice.
  - What evidence would resolve it: Recovery guarantees under weaker incoherence conditions, or impossibility results showing such recovery requires additional information.

## Limitations

- The theoretical framework assumes perfect, consistent feedback from agents, which may not hold in practice with noisy or biased human or model-based feedback
- The sparse sampling bounds depend on specific distributional assumptions about activation sparsity that may not generalize to all real-world data distributions
- Current results only guarantee recovery up to normal transformation, not full dictionary recovery, except under strong coherence assumptions

## Confidence

- **High Confidence**: The equivalence between triplet and pairwise feedback reduction (Mechanism 1), and the basic version space learning framework
- **Medium Confidence**: The rank-based complexity bounds (Mechanism 2) and sparse sampling bounds (Mechanism 3)
- **Low Confidence**: The scalability claims for large p (>500) using gradient descent with low-rank decomposition

## Next Checks

1. **Robustness to Noisy Feedback**: Add Gaussian noise to the feedback constraints and measure how PCC degrades as a function of noise level to establish practical limits when agent feedback is imperfect.

2. **Unknown Rank Recovery**: Design experiments where the true rank r* is unknown and test whether the algorithm can detect it (e.g., through eigenvalue thresholding) or whether rank mis-specification severely impacts recovery quality.

3. **Distributional Robustness**: Test the sparse sampling method across different activation distributions (not just sparse Bernoulli with Lebesgue non-zero values) to compare performance on heavy-tailed distributions, clustered activations, or structured sparsity patterns commonly found in real neural network representations.