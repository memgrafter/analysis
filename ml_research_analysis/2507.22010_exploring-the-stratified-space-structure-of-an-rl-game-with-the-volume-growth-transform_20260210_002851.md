---
ver: rpa2
title: Exploring the Stratified Space Structure of an RL Game with the Volume Growth
  Transform
arxiv_id: '2507.22010'
source_url: https://arxiv.org/abs/2507.22010
tags:
- space
- dimension
- agent
- local
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work adapts the volume growth transform (VGT) method to analyze
  the latent space structure of a transformer-based PPO model trained to play a visual
  RL game. By estimating local dimension via log-volume growth curves, the study finds
  that the token embedding space is not a manifold but a stratified space with varying
  local dimensions.
---

# Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform

## Quick Facts
- arXiv ID: 2507.22010
- Source URL: https://arxiv.org/abs/2507.22010
- Reference count: 27
- Key outcome: The study finds that transformer-based PPO agent token embeddings form a stratified space with local dimensions ranging from 6-21, clustering around goal states and complex environmental situations.

## Executive Summary
This work applies the Volume Growth Transform (VGT) method to analyze the latent space structure of a transformer-based PPO model trained to play a visual reinforcement learning game. By estimating local dimension via log-volume growth curves, the authors discover that the token embedding space is not a manifold but a stratified space with varying local dimensions. The analysis reveals that RL agents' latent representations alternate between low-dimension sub-strategies and high-dimension goal-or complexity-driven states, providing geometric indicators of game complexity and decision-making processes.

## Method Summary
The method involves training a Transformer-XL PPO agent on a modified "Searing Spotlights" RL game where the agent must collect two coins while avoiding dimming spotlights. After training, the 256-dimensional token embeddings from the transformer encoder are analyzed using VGT to estimate local dimension. For each token, pairwise Euclidean distances to all other tokens are computed, and a least-squares fit is applied to log(volume) vs. log(radius) data within a volume-bounded interval [50, 90]. The resulting local dimension distribution is then correlated with game events to identify patterns.

## Key Results
- Local dimension of token embeddings clusters around 6-21, not uniform across space
- Dimension spikes correlate with complex environmental states and near-goal achievement
- VGT analysis reveals non-manifold "flare" structures inconsistent with fiber bundle hypothesis
- Authors prove arbitrary VGT curves can be realized by stratified spaces, validating methodology

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The local dimension of a token embedding corresponds to the complexity of the agent's decision state.
- **Mechanism:** The network allocates higher-dimensional strata in the latent space to represent states requiring the integration of multiple variables (e.g., goal location plus obstacle avoidance). Routine states (e.g., moving in a fixed direction) collapse onto lower-dimensional sub-manifolds.
- **Core assumption:** The neural network learns a geometrically efficient representation where degrees of freedom in the latent space correlate with behavioral degrees of freedom.
- **Evidence anchors:**
  - [abstract] "local dimension fluctuates... suggesting higher dimensions occur near goal states and complex environmental situations."
  - [section 3.2] "spikes in the local dimension function generally occur before the agent reaches a goal state... or where the environmental complexity increases."
  - [corpus] "Unraveling the Localized Latents..." supports the general hypothesis that embedding spaces exhibit complex local manifold structures relevant to the data.
- **Break condition:** If local dimension spikes appeared randomly or correlated solely with visual noise (e.g., static) rather than game events, the complexity hypothesis would be invalid.

### Mechanism 2
- **Claim:** Volume Growth Transform (VGT) slope deviations identify non-manifold "flare" structures in latent space.
- **Mechanism:** On a smooth manifold or fiber bundle, the log-volume growth curve slope can only decrease or stay constant as the radius increases. A sharp *increase* in slope indicates a "flare"â€”a lower-dimensional region jutting out from a higher-dimensional bulk.
- **Core assumption:** The "fiber bundle hypothesis" (noise appended to a manifold) is the null hypothesis; deviations must be structurally significant.
- **Evidence anchors:**
  - [abstract] "...token embedding space... is better modeled as a stratified space, where local dimension can vary from point to point."
  - [section 2] "...sharp increase in growth... is inconsistent with the fiber bundle hypothesis and suggests that the token x is lying on a lower-dimensional 'flare'."
  - [corpus] Corpus signals regarding "Learning Beyond Euclid" highlight the importance of curvature and non-standard geometries, providing context for why manifold assumptions fail.
- **Break condition:** If the observed slope increases were artifacts of insufficient sampling density (sparse points at large radii), the stratified space claim would be weakened.

### Mechanism 3
- **Claim:** Stratified spaces are necessary to model the "polysemy" of agent states where multiple trajectories intersect.
- **Mechanism:** Just as words with multiple meanings form singularities in LLM spaces, RL states where an agent must choose between distinct strategies (e.g., flee vs. pursue) form intersection points between different behavioral strata.
- **Core assumption:** Distinct strategies map to distinct geometric substructures (strata) in the embedding space.
- **Evidence anchors:**
  - [section 4] "...distinct strata in the latent space correspond to different state-action trajectories, with increases in local dimension occurring when the agent is in a region where strata intersect."
  - [section 1] References Jakubowski et al. [8] regarding polysemy in word embeddings as a structural parallel.
  - [corpus] "Towards Understanding the Shape of Representations..." emphasizes geometric analysis of representations, supporting the utility of topological methods.
- **Break condition:** If dimension spikes were observed only in untrained or randomly initialized networks, the mechanism would not be learned but inherent to noise.

## Foundational Learning

- **Concept:** Stratified Spaces vs. Manifolds
  - **Why needed here:** The core finding rejects the "manifold hypothesis" (uniform dimension). You must understand that a stratified space is a union of manifolds of varying dimensions (e.g., a sheet attached to a line).
  - **Quick check question:** Can a 2D manifold contain a point with a local dimension of 1? (Answer: No, but a stratified space can).

- **Concept:** Volume Growth Transform (VGT)
  - **Why needed here:** This is the primary tool used to estimate local dimension without ground truth labels.
  - **Quick check question:** In a 3D Euclidean space, if you triple the radius of a ball, by what factor does the volume increase? (Answer: $3^3 = 27$. This cubic growth defines the dimension).

- **Concept:** PPO (Proximal Policy Optimization) with Transformer-XL
  - **Why needed here:** The analysis targets the embeddings of a specific architecture (Transformer-XL) trained via PPO.
  - **Quick check question:** Why is the "memory window" (length 16 in the paper) critical for the agent's performance in the Searing Spotlight game? (Answer: The lights dim, requiring memory of the initial state to navigate).

## Architecture Onboarding

- **Component map:** Input (84x84 RGB frame) -> CNN Encoder -> 256-dim vector -> 2-layer Transformer-XL (Memory Window 16) -> Policy and Value Heads
- **Critical path:**
  1. Train agent to convergence on the "Two-Coin" environment
  2. Collect 4500+ observation tokens (frames) from successful trajectories
  3. Compute pairwise Euclidean distances for all tokens
  4. For each token, fit the VGT least-squares model (Eq. 5) to estimate local dimension $n_x$
  5. Correlate $n_x$ spikes with visual game events (coin collection, spotlight avoidance)
- **Design tradeoffs:**
  - **Radius vs. Volume Intervals:** The paper notes that bounding the *volume* (interval [50, 90]) yields more consistent dimension estimates than bounding the *radius* (interval [40, 60]). Radii can include varying densities of points, whereas fixed volume ensures sufficient data for the least-squares fit.
  - **Memory Window:** Increasing the memory window improves game performance but increases the computational cost of analyzing the sequential dependencies in the latent space.
- **Failure signatures:**
  - **"Zero" Dimension:** Indicates insufficient neighboring tokens to solve the least squares problem (isolated point)
  - **Non-linear Log-Log Plots:** If the volume growth curve cannot be approximated by piecewise linear segments, the stratified space model may not apply, or the data is too noisy
- **First 3 experiments:**
  1. **Dimension Histogram Generation:** Generate the histogram of local dimensions (as in Fig 3) to verify the distribution is multi-modal (clusters at [6,8], [9,10], etc.) rather than Gaussian
  2. **Trajectory Trace:** Select a successful episode and plot local dimension vs. time. Manually verify that spikes align with coin collection or spotlight appearances (Fig 6)
  3. **Token Retrieval:** Extract tokens from the highest and lowest dimension clusters. Visually inspect them to confirm high-dim = "complex scene" and low-dim = "simple/empty scene" (Fig 4)

## Open Questions the Paper Calls Out
None

## Limitations
- The correlation between local dimension and environmental complexity is indirect, based on geometric analysis rather than direct measurement of decision entropy
- Analysis is limited to a single architecture (Transformer-XL PPO) and environment (modified Searing Spotlights), limiting generalizability
- The interpretation that higher local dimension indicates "complexity" assumes the network learns geometrically efficient representations without directly measuring behavioral degrees of freedom

## Confidence

**High confidence:** The empirical observation that log-volume growth curves show non-monotonic slope changes inconsistent with fiber bundles. The mathematical proof that arbitrary VGT curves can be realized by stratified spaces is sound.

**Medium confidence:** The interpretation that dimension spikes correlate with game complexity events (coin collection, spotlight avoidance). While visually apparent in trajectory plots, alternative explanations (e.g., visual saliency, memory retrieval) cannot be ruled out.

**Low confidence:** The generalization that all RL agent latent spaces will exhibit stratified structure. This analysis is based on a single architecture (Transformer-XL PPO) in a single environment (modified Searing Spotlights).

## Next Checks
1. **Cross-architecture comparison:** Apply VGT analysis to latent spaces from different RL architectures (CNN-only, LSTM-based) in the same environment. If dimension spikes persist across architectures, it strengthens the environmental complexity hypothesis.

2. **Controlled ablation study:** Train agents with modified reward structures (e.g., remove spotlight penalty, increase coin value) and verify whether dimension spike locations shift correspondingly. This would test whether the stratified structure reflects learned strategy rather than environmental features.

3. **Ground truth complexity measure:** Correlate local dimension with a direct measure of decision complexity (e.g., entropy of action distribution at each state) to validate that dimension truly reflects behavioral complexity rather than geometric artifacts.