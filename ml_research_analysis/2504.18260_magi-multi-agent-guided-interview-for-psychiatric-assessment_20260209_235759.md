---
ver: rpa2
title: 'MAGI: Multi-Agent Guided Interview for Psychiatric Assessment'
arxiv_id: '2504.18260'
source_url: https://arxiv.org/abs/2504.18260
tags:
- symptom
- psycot
- anxiety
- mark
- diagnostic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MAGI introduces a multi-agent framework that transforms the MINI
  structured psychiatric interview into automated workflows, addressing the challenge
  of aligning LLM-based mental health assessment with clinical diagnostic protocols.
  The system uses four specialized agents to manage interview navigation, generate
  adaptive questions, validate symptom responses, and produce transparent DSM-5 compliant
  diagnoses through Psychometric Chain-of-Thought reasoning.
---

# MAGI: Multi-Agent Guided Interview for Psychiatric Assessment

## Quick Facts
- arXiv ID: 2504.18260
- Source URL: https://arxiv.org/abs/2504.18260
- Reference count: 40
- 32% improvement in diagnostic agreement with expert clinicians compared to single-agent LLM baselines

## Executive Summary
MAGI introduces a multi-agent framework that transforms the MINI structured psychiatric interview into automated workflows, addressing the challenge of aligning LLM-based mental health assessment with clinical diagnostic protocols. The system uses four specialized agents to manage interview navigation, generate adaptive questions, validate symptom responses, and produce transparent DSM-5 compliant diagnoses through Psychometric Chain-of-Thought reasoning. Evaluation on 1,002 real-world cases showed MAGI achieved 32% improvement in diagnostic agreement with expert clinicians compared to single-agent LLM baselines, with Cohen's kappa values reaching 0.839-0.942 for suicide risk detection and 0.615-0.616 for depression assessment, while maintaining natural conversational flow.

## Method Summary
MAGI implements four coordinated agents: Navigation Agent manages MINI tree traversal, Question Agent generates context-adaptive utterances (probing/explaining/empathy), Judgment Agent validates responses against DSM-5 criteria with 5-turn ambiguity threshold and forced-choice fallback, and Diagnosis Agent produces PsyCoT traces mapping symptoms to diagnoses. The system was evaluated on 1,002 simulated interview sessions against dual-expert annotations from licensed psychologists, comparing performance to single-agent LLM baselines using Macro-F1, Case/Control F1, accuracy, and Cohen's kappa metrics.

## Key Results
- 32% improvement in diagnostic agreement with expert clinicians versus single-agent LLM baselines
- Cohen's kappa values: 0.839-0.942 for suicide risk detection, 0.615-0.616 for depression assessment
- Achieved human-like competency through orchestration of structured protocol adherence, adaptive interaction, and expert-knowledge integration

## Why This Works (Mechanism)

### Mechanism 1: Task-Decomposed Agent Specialization
- Claim: Separating clinical interview functions into specialized agents improves diagnostic accuracy over monolithic LLM approaches.
- Mechanism: Four agents handle distinct responsibilities—navigation enforces MINI branching logic, question generation adapts phrasing while preserving diagnostic intent, judgment validates symptom criteria, and diagnosis produces structured reasoning traces. This decomposition prevents the "rigid interaction patterns" and "diagnostic framework deviation" the authors identify in single-agent systems.
- Core assumption: The MINI protocol's procedural logic can be cleanly decomposed into modular functions without losing clinical validity.
- Evidence anchors:
  - [abstract] "32% improvement in diagnostic agreement with expert clinicians compared to single-agent LLM baselines"
  - [section 4.1.2] "MAGI's orchestration of structured protocol adherence, adaptive interaction, and expert-knowledge integration achieves human-like competency"
  - [corpus] MoodAngels paper validates multi-agent architectures for psychiatry diagnosis, suggesting the pattern generalizes.

### Mechanism 2: Psychometric Chain-of-Thought (PsyCoT)
- Claim: Structured reasoning traces that explicitly map symptoms to DSM-5 criteria improve diagnostic transparency and reliability.
- Mechanism: PsyCoT enforces three interpretable phases: (1) Symptom Anchoring translates textual criteria into validation logic with temporal verification; (2) Syndromal Validation confirms symptom profiles meet DSM-5 requirements; (3) Evidence Binding creates audit trails linking conclusions to dialogue evidence.
- Core assumption: LLMs can reliably execute structured reasoning schemas when properly prompted with domain-specific templates.
- Evidence anchors:
  - [abstract] "PsyCoT traces that explicitly map symptoms to clinical criteria"
  - [section 5.2/Table 4] Case study shows symptom validation through "multi-turn temporal verification" and "clinical equivalence" reasoning
  - [corpus] Limited direct corpus validation of PsyCoT specifically; related papers focus on broader multi-agent frameworks.

### Mechanism 3: Forced-Choice Constraints with Adaptive Recovery
- Claim: Combining strict protocol adherence with adaptive clarification improves completeness without sacrificing validity.
- Mechanism: The judgment agent applies three decision thresholds (direct matching, semantic comprehension, ambiguity resolution after 5 unproductive turns). Persistent ambiguity triggers forced-choice binary options from MINI protocol, while navigation agent redirects when participants attempt topic changes.
- Core assumption: Participants will eventually provide scorable responses when given structured options.
- Evidence anchors:
  - [section 3.3] "forced-choice mechanism activates upon persistent ambiguity, presenting binary MINI-compliant options"
  - [section 4.1.2] Judgment agent's "forced conclusive symptom matching" and navigation agent's "state-aware questioning strategy work synergistically to exhaustively cover required diagnostic criteria"
  - [corpus] Assumption: Limited corpus evidence on forced-choice effectiveness specifically in psychiatric AI.

## Foundational Learning

- Concept: MINI (Mini International Neuropsychiatric Interview) branching decision tree
  - Why needed here: The entire MAGI architecture is built to operationalize MINI's protocol. Without understanding how MINI routes from screening questions to deeper assessment nodes based on responses, the navigation agent's purpose is unclear.
  - Quick check question: Can you trace how a "yes" response to a depression screening question changes the subsequent question path versus a "no" response?

- Concept: DSM-5 diagnostic criteria and polythetic rules
  - Why needed here: PsyCoT's symptom anchoring and syndromal validation phases require understanding DSM-5's threshold requirements (e.g., "≥5 symptoms over two weeks" for depression, with core symptom requirements).
  - Quick check question: For a depression diagnosis, what distinguishes a core symptom from a secondary symptom, and how many of each type are required?

- Concept: Multi-agent orchestration patterns (control flow vs. data flow)
  - Why needed here: MAGI agents interact through "clinically constrained data flows" with navigation governing control and judgment triggering state transitions. Understanding separation of concerns is critical for debugging.
  - Quick check question: Which agent decides when to move to the next interview node, and what input does it require to make that decision?

## Architecture Onboarding

- Component map:
```
Navigation Agent (control layer)
    ├── Maintains MINI tree position
    ├── Receives: judgment results from Judgment Agent
    └── Outputs: current node, next node instruction → Question Agent

Question Agent (generation layer)
    ├── Strategies: probing / explaining / empathy
    ├── Receives: node context, conversation history
    └── Outputs: adaptive questions → Participant

Judgment Agent (validation layer)
    ├── Thresholds: direct match / semantic equivalence / ambiguity
    ├── Receives: participant responses, MINI criteria for current node
    └── Outputs: satisfaction status → Navigation Agent

Diagnosis Agent (synthesis layer)
    ├── PsyCoT phases: anchoring → validation → binding
    ├── Receives: accumulated evidence across interview
    └── Outputs: DSM-5 compliant diagnosis with reasoning trace
```

- Critical path: Participant response → Judgment Agent validation → Navigation Agent state update → Question Agent next question. The Judgment→Navigation handoff determines interview progression; errors here cascade into incomplete assessments.

- Design tradeoffs:
  - Accuracy vs. engagement: Section 4.1.2 notes MAGI "slightly trails the knowledge baseline in accuracy" because judgment agent "occasionally prioritizes participant comfort over forcing definitive answers."
  - Rigidity vs. completeness: Navigation agent enforces MINI structure strictly, which prevents skipping but may feel mechanical. Question agent's adaptive strategies partially mitigate this.
  - Transparency vs. complexity: PsyCoT traces add interpretability but require more LLM calls per diagnosis.

- Failure signatures:
  - Stuck in loop: Judgment agent repeatedly returns "unsatisfied" for same node (>5 turns should trigger forced-choice)
  - Premature termination: Navigation agent advances before judgment confirms criterion met
  - Reasoning drift: PsyCoT traces that don't map to actual dialogue evidence (audit trail broken)

- First 3 experiments:
  1. Trace validation: Run 20 simulated interviews with known symptom profiles; verify each PsyCoT trace correctly cites dialogue segments that support each symptom determination.
  2. Agent ablation: Disable judgment agent's forced-choice mechanism; measure completeness score drop on ambiguous-response test cases.
  3. Boundary test: Feed edge-case responses (e.g., "I don't know," contradictory statements across turns) and verify forced-choice triggers correctly without participant disengagement signals.

## Open Questions the Paper Calls Out
- How can the PsyCoT reasoning framework be enhanced to accurately model complex comorbidity patterns where symptoms (e.g., sleep disturbance) overlap across multiple diagnostic criteria?
- Does MAGI’s diagnostic agreement with expert clinicians persist in longitudinal studies involving diverse demographic populations outside of a university setting?
- What is the impact of the Judgment Agent's "forced-choice" threshold on participant retention and the therapeutic alliance?

## Limitations
- Evaluation on simulated participants rather than real clinical interactions introduces potential domain gap
- Agent coordination overhead and inter-agent communication protocols are described but not fully specified
- The forced-choice mechanism's effectiveness on genuine high-distress populations remains unverified

## Confidence
- Multi-agent framework improving diagnostic accuracy: High confidence
- PsyCoT reasoning transparency: Medium confidence
- Natural conversational flow maintenance: Low confidence

## Next Checks
1. Run PsyCoT trace audit: Select 50 diagnosis cases and verify that each symptom determination explicitly cites dialogue evidence segments that support the conclusion
2. Agent ablation stress test: Systematically disable each specialized agent function and measure degradation in diagnostic accuracy, protocol adherence, and completion rates
3. Edge case boundary validation: Test system response to contradictory statements across interview turns, severely atypical symptom presentations, and high distress markers to verify forced-choice triggers and safety protocol adherence