---
ver: rpa2
title: Mechanistic Interpretability of Antibody Language Models Using SAEs
arxiv_id: '2512.05794'
source_url: https://arxiv.org/abs/2512.05794
tags:
- features
- saes
- antibody
- latents
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies sparse autoencoders (SAEs) to an antibody language
  model (p-IgGen) to interpret and steer its generation. It trains both TopK and Ordered
  SAEs on hidden layer activations, identifying latent features corresponding to biologically
  meaningful concepts such as CDR identity and germline gene identity.
---

# Mechanistic Interpretability of Antibody Language Models Using SAEs

## Quick Facts
- **arXiv ID**: 2512.05794
- **Source URL**: https://arxiv.org/abs/2512.05794
- **Reference count**: 38
- **Primary result**: Sparse autoencoders (SAEs) identify interpretable, biologically meaningful features in antibody language models and enable targeted steering of germline gene usage.

## Executive Summary
This paper applies sparse autoencoders (SAEs) to interpret and steer an antibody language model (p-IgGen). The authors train both TopK and Ordered SAEs on hidden layer activations to identify latent features corresponding to antibody-specific concepts like CDR identity and germline gene identity. While TopK SAEs reveal interpretable features, they fail to provide reliable steering capability. Ordered SAEs, with their hierarchical structure, successfully enable predictable steering of specific germline gene usage (IGHJ4), demonstrating that SAEs can be used for mechanistic interpretability and targeted generation in protein language models.

## Method Summary
The authors applied sparse autoencoders (SAEs) to interpret and steer an antibody language model (p-IgGen). They trained both TopK and Ordered SAEs on hidden layer activations to identify latent features corresponding to antibody-specific concepts. The method involved correlating SAE features with biologically meaningful concepts like CDR identity and germline gene identity. Steering experiments were conducted by modifying feature activations to observe changes in generated antibody sequences. The study compared the interpretability and steering effectiveness of TopK versus Ordered SAE architectures.

## Key Results
- TopK SAEs reveal interpretable, antibody-specific features but lack reliable steering capability despite high feature-concept correlation
- Ordered SAEs successfully enable predictable increases/decreases in specific germline gene usage (IGHJ4) through targeted steering
- While TopK SAEs suffice for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required

## Why This Works (Mechanism)
SAEs work by decomposing high-dimensional hidden activations into sparse, interpretable feature vectors. The sparsity constraint forces the model to learn compact representations that correspond to meaningful biological concepts. Ordered SAEs add a hierarchical structure that enables more precise control over feature activation patterns, which translates to more predictable steering outcomes. The difference in steering capability between TopK and Ordered SAEs stems from how they handle feature interactions and activation hierarchies.

## Foundational Learning

**Sparse Autoencoders (SAEs)**
- *Why needed*: To decompose complex neural activations into interpretable, sparse features
- *Quick check*: Features should correspond to known biological concepts when correlated with antibody properties

**TopK SAEs**
- *Why needed*: To identify the most active features in each activation vector
- *Quick check*: Should reveal interpretable features even if steering is limited

**Ordered SAEs**
- *Why needed*: To provide hierarchical feature activation that enables precise steering
- *Quick check*: Should allow predictable control over specific antibody properties

## Architecture Onboarding

**Component Map**
Input Activations -> SAE Encoder -> Sparse Features -> SAE Decoder -> Reconstructed Activations

**Critical Path**
Hidden layer activations → SAE encoding → Feature interpretation/correction → Steering signal generation

**Design Tradeoffs**
TopK SAEs prioritize interpretability over steering control; Ordered SAEs sacrifice some interpretability simplicity for precise generative control

**Failure Signatures**
High feature-concept correlation without steering capability indicates TopK SAEs; successful steering indicates Ordered SAEs are working as intended

**3 First Experiments**
1. Correlate SAE features with known antibody properties to validate interpretability
2. Test steering capability by modifying specific feature activations and observing output changes
3. Compare steering effectiveness between TopK and Ordered SAE architectures

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Single model testing (p-IgGen) without generalizability assessment to other protein language models
- Binary feature-activation thresholding may oversimplify continuous latent representations
- Steering experiments limited in scope, focusing only on single feature control (IGHJ4)

## Confidence

**High confidence**: SAEs can identify interpretable, biologically relevant features in antibody language models (supported by consistent feature-concept correlations and visualization)

**Medium confidence**: Ordered SAEs enable more effective steering than TopK SAEs (demonstrated for IGHJ4 but limited to single feature steering experiments)

**Low confidence**: SAE-based steering will generalize to complex, multi-property antibody design tasks (not yet demonstrated beyond single gene family steering)

## Next Checks
1. Test SAE interpretability and steering across multiple antibody language models and protein-specific architectures to assess generalizability
2. Conduct steering experiments targeting multiple CDR regions and structural motifs simultaneously to evaluate multi-property control capability
3. Validate steered antibody sequences through computational folding predictions and binding affinity calculations to ensure functional integrity post-steering