---
ver: rpa2
title: Training Feature Attribution for Vision Models
arxiv_id: '2510.09135'
source_url: https://arxiv.org/abs/2510.09135
tags:
- training
- test
- image
- attribution
- influence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces training feature attribution (TFA), a framework
  that combines training data attribution (TDA) with feature attribution (FA) to link
  test predictions to specific regions of specific training images. The approach applies
  gradient-based FA to TDA scores, identifying which parts of influential training
  examples drive a given prediction.
---

# Training Feature Attribution for Vision Models

## Quick Facts
- **arXiv ID:** 2510.09135
- **Source URL:** https://arxiv.org/abs/2510.09135
- **Reference count:** 27
- **Primary result:** TFA links test predictions to specific training image regions, revealing both correct attributions and spurious correlations.

## Executive Summary
This paper introduces Training Feature Attribution (TFA), a framework that bridges training data attribution (TDA) with feature attribution (FA) to create fine-grained, test-specific explanations for vision models. By applying gradient-based FA to TDA scores, TFA identifies which parts of influential training examples drive a given prediction. Experiments on CIFAR-10 and Pascal VOC demonstrate that TFA generates interpretable heatmaps, correctly identifies influential training pixels through quantitative insertion tests, and reveals spurious correlations that conventional attribution methods miss. The method provides deeper insights into model behavior compared to using FA or TDA alone.

## Method Summary
TFA combines gradient-based feature attribution with training data attribution by computing the gradient of a TDA score (specifically Gradient Cosine Similarity between test and train gradients) with respect to training image pixels. This produces saliency maps highlighting influential regions in training data for specific test predictions. The approach uses SmoothGrad for noise reduction and is validated through insertion tests where masking top-k TFA-identified pixels causes larger test loss increases than random pixel masking. The method is applied to ResNet-18 models trained on vision datasets, with quantitative validation on CIFAR-10 and qualitative analysis on Pascal VOC.

## Key Results
- TFA saliency maps correctly identify influential training pixels, with top-k insertions yielding more negative test-loss changes than random controls
- TFA reveals spurious correlations (e.g., patch-based shortcuts) that conventional attribution methods miss
- TFA explains misclassifications by identifying harmful training examples and localizing decision-relevant regions

## Why This Works (Mechanism)
TFA works by leveraging the relationship between model parameters and training data through gradient-based influence. The method computes how sensitive the model's behavior on a test example is to changes in training data by measuring gradient similarity. By taking a second-order gradient (gradient of the influence score with respect to input pixels), TFA traces back which specific regions in training images are most influential for the current prediction. This creates a direct link between test-time behavior and training data regions, going beyond traditional feature attribution that only considers input-output relationships.

## Foundational Learning

**Gradient Cosine Similarity (Grad-Cos)**
- Why needed: Measures similarity between test and training gradients to identify influential examples
- Quick check: Verify Grad-Cos scores are higher for semantically similar examples than random ones

**Second-order gradients**
- Why needed: TFA requires differentiating an influence score (function of model params) w.r.t input pixels
- Quick check: Test on simple linear model where analytical second-order gradients can be computed

**SmoothGrad**
- Why needed: Reduces noise in second-order gradient computations for stable saliency maps
- Quick check: Compare TFA maps with and without SmoothGrad; noise reduction should be visible

## Architecture Onboarding

**Component map:** Test image -> Model predictions -> Grad-Cos with training images -> TFA gradients w.r.t training pixels -> Saliency map

**Critical path:** The core computation path involves: (1) forward pass on test image, (2) compute gradients w.r.t model parameters, (3) compute Grad-Cos similarity with training image gradients, (4) compute TFA gradient w.r.t training image pixels, (5) generate saliency map

**Design tradeoffs:** TFA trades computational efficiency (second-order gradients are expensive) for explanatory power (pixel-level attribution to training data). The method assumes linear approximation validity and depends heavily on the quality of the TDA method.

**Failure signatures:** Noisy heatmaps indicate SmoothGrad implementation issues; poor quantitative results suggest TDA method problems; high variance in insertion tests indicates implementation bugs in gradient computation

**First experiments:**
1. Verify Grad-Cos correctly identifies semantically similar training examples
2. Test TFA on a simple linear regression model with known influential training points
3. Compare TFA maps with and without SmoothGrad on a single test-training pair

## Open Questions the Paper Calls Out

**Higher-level semantic concepts:** How can TFA be extended from pixel-level attributions to higher-level, human-interpretable semantic concepts rather than raw pixels? The current method lacks semantic meaning required for high-level debugging.

**TDA method robustness:** How robust is TFA to different TDA methods, particularly given that Influence Functions performed poorly while Grad-Cos succeeded? A comparative analysis with diverse TDA backends could reveal method dependencies.

**Long-term influence persistence:** Does the influence of specific training pixels identified by TFA persist throughout full training, or is it limited to local optimization states? The current validation uses single gradient steps rather than full training cycles.

## Limitations

- TFA requires computationally expensive second-order gradient computations
- Results depend heavily on the quality of the TDA method (Grad-Cos) and may inherit its limitations
- The approach assumes linear approximation validity for gradient-based attributions

## Confidence

**High:** TFA methodology combining TDA gradients with FA is well-defined and reproducible
**Medium:** Quantitative results on CIFAR-10 depend on the unknown lightweight CNN architecture
**Medium:** Qualitative results on Pascal VOC are reproducible with the specified ResNet-18 setup

## Next Checks

1. Implement and verify SmoothGrad with $n=30$ samples and $\sigma=0.05-0.1$ noise to ensure TFA maps are interpretable and not dominated by gradient noise

2. Confirm correct implementation of second-order gradient computation by testing on a simple linear model where analytical gradients can be computed and compared

3. For the CIFAR-10 experiment, either identify the specific lightweight CNN architecture from the paper or implement a reasonable alternative (e.g., a shallow CNN with 3-4 convolutional layers) to reproduce the quantitative results