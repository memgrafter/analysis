---
ver: rpa2
title: 'Accessible and Pedagogically-Grounded Explainability for Human-Robot Interaction:
  A Framework Based on UDL and Symbolic Interfaces'
arxiv_id: '2504.06189'
source_url: https://arxiv.org/abs/2504.06189
tags:
- robot
- explanation
- design
- user
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of making robot explainability
  accessible to users with diverse cognitive, communicative, and learning needs by
  integrating Universal Design for Learning (UDL) principles with symbolic communication
  strategies. The authors propose a multimodal explanation framework using Asterics
  Grid and ARASAAC pictograms, implemented through a lightweight HTTP-to-ROS 2 bridge
  for real-time interaction.
---

# Accessible and Pedagogically-Grounded Explainability for Human-Robot Interaction: A Framework Based on UDL and Symbolic Interfaces

## Quick Facts
- arXiv ID: 2504.06189
- Source URL: https://arxiv.org/abs/2504.06189
- Reference count: 16
- Primary result: Framework integrating UDL principles with symbolic interfaces for accessible robot explainability

## Executive Summary
This paper presents a novel framework for robot explainability that integrates Universal Design for Learning (UDL) principles with symbolic communication strategies to serve users with diverse cognitive and communicative needs. The approach combines Asterics Grid and ARASAAC pictograms with a lightweight HTTP-to-ROS 2 bridge, enabling real-time multimodal explanations through bidirectional communication. The framework emphasizes shared understanding between robots and users, often mediated by teachers or other human facilitators, with the goal of improving mental model alignment in educational and assistive contexts.

## Method Summary
The authors developed a multimodal explanation framework that combines UDL principles with symbolic communication through Asterics Grid and ARASAAC pictogram systems. The technical implementation uses a lightweight HTTP-to-ROS 2 bridge to enable real-time interaction between symbolic interfaces and robotic systems. The framework supports bidirectional explainability where both robot transparency and user understanding are actively aligned, with human mediators facilitating the communication process. Practical examples demonstrate customizable communication boards designed for shared understanding.

## Key Results
- Integration of UDL principles with symbolic communication strategies for accessible robot explanations
- Implementation of bidirectional explainability framework using HTTP-to-ROS 2 bridge
- Practical examples of customizable communication boards supporting shared understanding
- Framework validated through illustrative examples showing potential for mental model alignment

## Why This Works (Mechanism)
The framework works by aligning robot transparency with human cognitive diversity through multiple representation modes. UDL principles ensure that explanations are accessible through different sensory channels (visual, auditory, symbolic), while the bidirectional nature allows for continuous feedback and adjustment. The symbolic interface using pictograms provides concrete, unambiguous representations that can be understood across language barriers and cognitive differences, while the HTTP-to-ROS 2 bridge enables seamless real-time integration with robotic systems.

## Foundational Learning
- Universal Design for Learning (UDL): Educational framework ensuring accessibility through multiple means of representation, engagement, and expression; needed to address diverse cognitive and learning needs; quick check: verify explanations work across visual, auditory, and symbolic channels
- Symbolic Communication Systems: Pictographic languages like ARASAAC that provide concrete, unambiguous representations; needed for users with language barriers or cognitive differences; quick check: ensure pictograms are culturally appropriate and universally recognizable
- HTTP-to-ROS 2 Bridge: Middleware enabling web-based interfaces to communicate with robotic systems; needed for real-time multimodal interaction; quick check: verify latency remains under 100ms for interactive use

## Architecture Onboarding

Component Map: User Interface -> HTTP-to-ROS 2 Bridge -> ROS 2 Nodes -> Robot Actions

Critical Path: The critical execution path flows from user interaction through the symbolic interface, via the HTTP bridge to ROS 2, where explanation content is processed and delivered to the robot for appropriate response or action. This must maintain low latency for real-time bidirectional communication.

Design Tradeoffs: The framework prioritizes accessibility and multimodal representation over computational efficiency, accepting potential performance overhead from symbolic processing and multiple interface layers. The choice of pictographic systems enables universal comprehension but may limit expressiveness for complex concepts. Human mediation support improves effectiveness but introduces dependency on facilitator availability.

Failure Signatures: System failures typically manifest as delayed or incorrect explanations, pictogram loading errors, or bridge communication timeouts. Most failures are detectable through user feedback mechanisms built into the bidirectional design, allowing for graceful degradation or fallback to simpler explanation modes.

First Experiments:
1. Verify HTTP-to-ROS 2 bridge latency remains under 100ms with basic symbolic commands
2. Test pictogram loading and display across different device types and screen sizes
3. Validate bidirectional communication by implementing a simple command-response loop with user feedback

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Validation relies on illustrative examples rather than empirical user studies with diverse populations
- Effectiveness for users with different cognitive or communicative needs remains unproven without quantitative evidence
- Reliance on human mediators introduces variability that isn't fully characterized
- Scalability to complex robotic tasks beyond basic educational scenarios is unclear

## Confidence
- High: Technical implementation details (HTTP-to-ROS 2 bridge, pictogram system integration) are well-documented and clearly explained
- Medium: Claims about improved mental model alignment and bidirectional explainability are conceptually sound but not empirically validated
- Low: Claims about accessibility outcomes and user experience benefits remain hypothetical without user testing data

## Next Checks
1. Conduct user studies with diverse populations (different ages, cognitive abilities, communication needs) to measure comprehension gains and usability of the symbolic explanation system
2. Implement A/B testing comparing the multimodal UDL-based interface against traditional text-based or speech-only robot explanations in controlled tasks
3. Test the framework's performance and effectiveness across multiple robot platforms and task complexities to assess generalizability beyond educational use cases