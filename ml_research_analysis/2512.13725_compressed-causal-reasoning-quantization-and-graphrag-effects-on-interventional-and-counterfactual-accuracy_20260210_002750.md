---
ver: rpa2
title: 'Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional
  and Counterfactual Accuracy'
arxiv_id: '2512.13725'
source_url: https://arxiv.org/abs/2512.13725
tags:
- causal
- reasoning
- quantization
- counterfactual
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study systematically evaluates how low-precision quantization\
  \ and graph-structured retrieval augmentation affect causal reasoning in large language\
  \ models across Pearl\u2019s three causal levels: association, intervention, and\
  \ counterfactual inference. Using Llama-3-8B and a 3,000-sample stratified causal\
  \ benchmark, we find that overall causal reasoning accuracy remains stable under\
  \ NF4 quantization with less than 1% degradation, though interventional reasoning\
  \ shows the highest sensitivity to precision loss."
---

# Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy

## Quick Facts
- **arXiv ID**: 2512.13725
- **Source URL**: https://arxiv.org/abs/2512.13725
- **Reference count**: 23
- **Primary result**: NF4 quantization maintains causal reasoning accuracy within 1% degradation across association and counterfactual levels

## Executive Summary
This study systematically evaluates how low-precision quantization and graph-structured retrieval augmentation affect causal reasoning in large language models across Pearl's three causal levels: association, intervention, and counterfactual inference. Using Llama-3-8B and a 3,000-sample stratified causal benchmark, the authors find that overall causal reasoning accuracy remains stable under NF4 quantization with minimal degradation. GraphRAG using ground-truth causal facts improves NF4 interventional accuracy by 1.7%, partially offsetting compression-related degradation. The study reveals that counterfactual benchmarks like CRASS show no sensitivity to quantization, suggesting limited diagnostic power for causal brittleness.

## Method Summary
The study evaluates causal reasoning under quantization by testing Llama-3-8B across Pearl's three causal levels using a 3,000-sample stratified benchmark. NF4 quantization is applied to assess precision loss effects, while GraphRAG augmentation uses ground-truth causal facts to measure retrieval impact. Interventional accuracy serves as the primary sensitivity metric, with counterfactual reasoning tested using CRASS benchmarks. The experimental design compares full-precision and quantized models across association, intervention, and counterfactual tasks to isolate quantization artifacts from architectural limitations.

## Key Results
- NF4 quantization maintains causal reasoning accuracy within 1% degradation across association and counterfactual levels
- GraphRAG using ground-truth causal facts improves NF4 interventional accuracy by 1.7%
- Counterfactual benchmarks like CRASS show no sensitivity to quantization, suggesting limited diagnostic power

## Why This Works (Mechanism)
The stability of causal reasoning under quantization stems from the models' ability to preserve essential numerical relationships despite precision reduction. GraphRAG provides targeted stabilization by supplying precise causal facts that compensate for quantization-induced noise in interventional reasoning. The differential sensitivity across causal levels reflects the varying computational demands: association relies on pattern matching less affected by precision loss, while intervention requires more precise numerical reasoning that benefits from graph-augmented context.

## Foundational Learning
- **Causal reasoning levels (Pearl's hierarchy)**: Association, intervention, and counterfactual inference represent increasing complexity in causal inference; needed to structure benchmark design and isolate quantization effects per causal level
- **NF4 quantization**: 4-bit precision compression technique that reduces model size while attempting to preserve numerical fidelity; critical for understanding precision-sensitivity trade-offs
- **GraphRAG**: Retrieval-augmented generation using structured knowledge graphs; essential for evaluating whether external causal knowledge can stabilize compressed models

## Architecture Onboarding
- **Component map**: Llama-3-8B -> Quantization (NF4) -> GraphRAG augmentation -> Causal benchmark evaluation
- **Critical path**: Model inference → Precision reduction → Causal fact retrieval → Accuracy measurement
- **Design tradeoffs**: Precision reduction for efficiency vs. accuracy preservation; automated vs. ground-truth knowledge graphs
- **Failure signatures**: Interventional accuracy degradation under quantization; counterfactual benchmark insensitivity
- **First experiments**: 1) Cross-architecture quantization testing, 2) Noisy knowledge graph evaluation, 3) Multi-step counterfactual reasoning tasks

## Open Questions the Paper Calls Out
None identified in source material.

## Limitations
- Evaluation limited to Llama-3-8B architecture, restricting generalizability
- 3,000-sample benchmark may not capture edge cases or distributional shifts
- CRASS counterfactual benchmark's insensitivity raises questions about causal reasoning measurement validity

## Confidence
- **High confidence**: NF4 quantization maintains causal reasoning accuracy within 1% degradation
- **Medium confidence**: 1.7% GraphRAG improvement in interventional accuracy is significant but may not generalize
- **Low confidence**: CRASS benchmark insensitivity to quantization requires further validation

## Next Checks
1. Test quantization effects on multiple LLM families (Mistral, Qwen) to determine generalizability
2. Evaluate GraphRAG performance using automatically extracted or noisy causal graphs
3. Develop or adapt counterfactual reasoning tasks that stress-test causal inference under precision constraints