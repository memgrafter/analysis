---
ver: rpa2
title: 'Causal SHAP: Feature Attribution with Dependency Awareness through Causal
  Discovery'
arxiv_id: '2509.00846'
source_url: https://arxiv.org/abs/2509.00846
tags:
- causal
- shap
- feature
- shapley
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the limitation of SHAP in differentiating between
  causality and correlation in feature attribution. While SHAP is widely used for
  model interpretability, it fails to account for causal relationships between features,
  often misattributing importance in high-stakes domains like healthcare.
---

# Causal SHAP: Feature Attribution with Dependency Awareness through Causal Discovery

## Quick Facts
- **arXiv ID:** 2509.00846
- **Source URL:** https://arxiv.org/abs/2509.00846
- **Reference count:** 32
- **One-line primary result:** Causal SHAP integrates causal discovery with Shapley values to improve feature attribution by distinguishing causation from correlation, achieving RMSE of 0.0167 vs 1.6357 for Independent SHAP on synthetic data.

## Executive Summary
This paper addresses a critical limitation in SHAP-based feature attribution methods: their inability to distinguish between causal relationships and mere correlations between features. Standard SHAP can misattribute importance to features that are merely correlated with the target rather than causally related, which is problematic in high-stakes domains like healthcare. The authors propose Causal SHAP, a framework that incorporates causal relationships into feature attribution while preserving SHAP's theoretical properties. The method uses the Peter-Clark algorithm for causal discovery and Intervention Calculus when the DAG is Absent (IDA) for causal strength quantification, demonstrating superior performance on both synthetic and real-world biomedical datasets.

## Method Summary
The method integrates causal discovery into the Shapley value framework through three key modifications: causal-aware sampling in the value function that respects conditional distributions based on a discovered causal graph, weighting of feature contributions by their total causal effects estimated via IDA, and normalization to maintain local accuracy. The process involves running the PC algorithm to discover the causal structure, using IDA to estimate causal strengths, implementing a custom value function with Monte Carlo sampling that respects the causal graph topology, and finally computing weighted Shapley values with a normalization step. The framework is evaluated on synthetic datasets with known ground truth and real-world biomedical datasets using RMSE and insertion test metrics.

## Key Results
- On synthetic data, Causal SHAP achieved RMSE of 0.0167 compared to 1.6357 for Independent SHAP
- On IBS biomedical data, Causal SHAP achieved AUROC of 0.8594
- On colorectal cancer data, Causal SHAP achieved AUROC of 0.6271

## Why This Works (Mechanism)

### Mechanism 1: Causal-Aware Value Function (Sampling)
Standard SHAP samples out-of-coalition features from marginal distributions, potentially generating "impossible" data instances that violate known dependencies. Causal SHAP modifies the value function to sample out-of-coalition features based on their conditional distribution given in-coalition features, respecting the discovered causal graph. If an out-of-coalition feature has parents within the coalition, it is sampled using regression based on those parent values.

### Mechanism 2: Causal Strength Weighting
The method weights feature contributions by their Total Causal Effect (TCE) estimated via IDA. This ensures features with stronger causal links to the target receive higher attribution, distinguishing causation from correlation. The causal effect is converted into a weight factor that scales the Shapley kernel weight.

### Mechanism 3: Normalization for Local Accuracy
Because the weighting and sampling modifications break the standard efficiency property of Shapley values, the method applies a post-hoc normalization step that forces the sum of attributions to equal the difference between the prediction and the expected value, preserving the local accuracy axiom.

## Foundational Learning

- **Concept: Shapley Values (Game Theory)**
  - Why needed here: This is the mathematical foundation of SHAP. Understanding "marginal contribution" and the "value function" is essential to grasp what Causal SHAP modifies.
  - Quick check question: If a feature contributes 0 to every possible subset of features, what is its Shapley value?

- **Concept: Causal Discovery (PC Algorithm)**
  - Why needed here: The mechanism relies on PC algorithm to generate the DAG. Understanding that it uses conditional independence tests to remove edges is vital for debugging the "Structure" component.
  - Quick check question: Does the PC algorithm start with a fully connected graph or an empty graph, and how does it decide to remove an edge?

- **Concept: Interventional vs. Observational (do-calculus)**
  - Why needed here: The paper distinguishes between standard SHAP (often interventional/independent sampling) and its method (causal/conditional sampling). Understanding P(Y|X) vs P(Y|do(X)) clarifies why "impossible points" occur in standard SHAP.
  - Quick check question: In a causal graph where X → Y, how does P(Y|do(X)) differ from P(Y|X) if there are no other variables?

## Architecture Onboarding

- **Component map:** Data → PC Algorithm (Structure Learning) → IDA (Parameter Estimation) → Causal Value Function (Sampling) → Weighted Aggregation → Normalization
- **Critical path:** Data → PC Algorithm (Structure Learning) → IDA (Parameter Estimation) → Causal Value Function (Sampling) → Weighted Aggregation → Normalization
- **Design tradeoffs:**
  - Runtime vs. Accuracy: PC algorithm is computationally intensive on high-dimensional data (exponential complexity in node degree), whereas standard SHAP approximations are often faster
  - Linearity Assumption: Uses linear regression for effect estimation and sampling, trading ability to model complex non-linear causal mechanisms for computational tractability
- **Failure signatures:**
  - Spurious Edges: If PC alpha parameter is too low, graph becomes dense, leading to computationally expensive sampling and potential noise
  - Zero Attribution: If IDA estimates zero causal effect, valid features might be zeroed out by the weighting factor
- **First 3 experiments:**
  1. Graph Validation: Run PC on synthetic dataset with known ground truth graph to tune independence test threshold
  2. Sanity Check for "Impossible Points": Visualize synthetic data samples generated by Causal Value Function vs. Standard SHAP to verify correlations are preserved
  3. Insertion Test Benchmark: Implement Insertion Test on real-world dataset to compare how quickly Causal SHAP restores model confidence vs. Kernel SHAP

## Open Questions the Paper Calls Out
- Can the framework be extended to handle hidden confounders using the FCI algorithm?
- How can computational efficiency be optimized for high-dimensional datasets?
- Does aggregating multiple possible causal graphs improve attribution robustness?
- To what extent does the linearity assumption affect performance on non-linear data?

## Limitations
- Assumes linear relationships between variables for causal strength estimation and conditional sampling
- PC algorithm performance is sensitive to significance level threshold which is not specified
- Computationally expensive as feature dimensionality increases due to causal discovery and Monte Carlo sampling requirements

## Confidence
- **High confidence:** Theoretical framework integrating causal discovery with Shapley values is sound and mathematically rigorous
- **Medium confidence:** Empirical results on synthetic datasets are convincing, but real-world experiments lack full disclosure of preprocessing steps
- **Low confidence:** Robustness to incorrect causal graph discovery and sensitivity to hidden confounders is not thoroughly explored

## Next Checks
1. **Linearity Stress Test:** Apply Causal SHAP to synthetic dataset with known non-linear causal relationships and compare attribution accuracy against non-linear causal effect estimation method
2. **Graph Sensitivity Analysis:** Systematically vary PC algorithm's significance threshold on benchmark dataset and measure how attribution quality changes
3. **Hidden Confounder Robustness:** Construct synthetic dataset with unobserved confounder and evaluate whether Causal SHAP incorrectly attributes importance to correlated observed features versus true direct causes