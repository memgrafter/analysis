---
ver: rpa2
title: Feature Attribution from First Principles
arxiv_id: '2505.24729'
source_url: https://arxiv.org/abs/2505.24729
tags:
- attribution
- feature
- where
- given
- apnq
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of evaluating and comparing feature\
  \ attribution methods in machine learning, where the lack of reliable evaluation\
  \ metrics and overly restrictive axioms hinder progress. The authors argue that\
  \ common axioms like Completeness, Sensitivity, and Linearity, while intuitive,\
  \ are too restrictive and produce attributions similar to Gradient\xD7Input, limiting\
  \ the diversity of explanations."
---

# Feature Attribution from First Principles

## Quick Facts
- arXiv ID: 2505.24729
- Source URL: https://arxiv.org/abs/2505.24729
- Reference count: 40
- One-line primary result: Constructivist framework building feature attributions from indicator functions via measure theory, deriving closed-form solutions for ReLU networks and recovering existing methods as special cases.

## Executive Summary
This paper addresses fundamental limitations in evaluating and comparing feature attribution methods for machine learning. The authors argue that common axioms like Completeness, Sensitivity, and Linearity are too restrictive, collapsing all methods to Gradient×Input approximations. They propose a constructivist framework that builds attributions from the ground up using measure theory, starting with simple indicator functions and extending to complex models. This approach naturally integrates with existing XAI techniques and enables efficient computation for deep ReLU networks through closed-form solutions.

## Method Summary
The framework defines feature attributions through a constructivist approach: (1) define atomic attributions for indicator functions ϕ(x, 1_R)_j := μ_{j,x}(R), (2) extend to general models via Lebesgue-Stieltjes integral representation ϕ(x,f)_j = ∫ f(y) dμ_{j,x,j}(y) for Linear and FSC methods, and (3) for ReLU networks, compute closed-form attributions using partition into linear regions ϕ(x,f)_j = Σ_P μ_{j,x}(P)(a_P^T m_{P,j,x} + b_P). The choice of measures μ_{j,x} determines the specific attribution method, recovering PDP, Shapley values, and other techniques as special cases.

## Key Results
- Common axioms (Completeness, Sensitivity, Linearity) force attributions to approximate Gradient×Input for smooth models
- Any Linear and FSC attribution method has unique representation as Lebesgue-Stieltjes integral with respect to signed Borel measures
- Closed-form feature attributions for deep ReLU networks enable efficient computation without numerical integration
- Framework recovers Partial Dependence, Shapley values, and other methods as special cases through measure selection
- Theoretical framework for optimizing evaluation metrics with respect to feature attributions

## Why This Works (Mechanism)

### Mechanism 1: Axiom Constraint Collapse to Gradient×Input
- Claim: Any feature attribution method satisfying Completeness, Sensitivity, and Linearity necessarily produces attributions approximately equal to Gradient×Input for smooth models.
- Mechanism: Completeness and Sensitivity uniquely determine attributions for projection functions. Combined with Linearity, this forces the attribution to follow first-order Taylor expansion terms, which correspond to Gradient×Input, plus a remainder bounded by model curvature.
- Core assumption: The model is twice continuously differentiable, or can be approximated via mollifier convolution.
- Evidence anchors: Abstract mentions common axioms produce attributions similar to Gradient×Input; Theorem 2.1 provides explicit bound on deviation.

### Mechanism 2: Constructivist Extension via Measure-Theoretic Integration
- Claim: Any Linear and Functionally Supremum Continuous attribution method admits unique representation as Lebesgue-Stieltjes integral with respect to signed Borel measures.
- Mechanism: Riesz-Markov representation theorem guarantees that for Linear and FSC attribution φ, there exist unique measures μ_j,x such that φ(x, f)_j = ∫ f(y) dμ_j,x(y).
- Core assumption: Models are continuous on [0,1]^d and attribution method satisfies FSC.
- Evidence anchors: Abstract mentions building from indicator functions and extending using measure theory; Theorem 3.2 provides measure-based representation.

### Mechanism 3: Closed-Form Computation via Linear Region Decomposition
- Claim: For piecewise affine continuous functions (deep ReLU networks), feature attribution reduces to finite weighted sum over polytope regions.
- Mechanism: Deep ReLU networks partition [0,1]^d into polytopes {P} where network is locally linear. Closed-form avoids numerical integration entirely.
- Core assumption: Polytope partition is computable with explicit formulas for linear coefficients.
- Evidence anchors: Abstract mentions derivation of closed-form feature attributions for deep ReLU networks; Corollary 4.1 provides explicit formula.

## Foundational Learning

- Concept: **Riesz-Markov Representation Theorem**
  - Why needed here: The entire framework relies on representing Linear and FSC functionals as integrals against measures.
  - Quick check question: Given a linear functional L on C([0,1]) with L(1) = 1 and L(f) ≥ 0 for f ≥ 0, what measure μ satisfies L(f) = ∫f dμ?

- Concept: **Riemann-Stieltjes and Lebesgue-Stieltjes Integration**
  - Why needed here: The paper uses both formulations to construct attributions via limits of sums over partitions and provide measure-based representation.
  - Quick check question: If g(y) = 1_{y ≥ x} and f is continuous on [0,1], what is ∫_0^1 f(y) dg(y)?

- Concept: **Linear Regions of ReLU Networks**
  - Why needed here: Closed-form solution depends on identifying polytope partition R([0,1]^d) where network is locally linear.
  - Quick check question: A single ReLU neuron with weights w and bias b divides input space into how many linear regions? What is equation of boundary?

## Architecture Onboarding

- Component map: Atomic attribution module -> Measure family specification -> Approximation engine -> Optimization layer

- Critical path:
  1. Implement atomic attribution for indicator functions (defines measure family)
  2. For ReLU networks: compute linear regions via pre-activation patterns, apply Corollary 4.1
  3. For general models: approximate integral ∫f(y) dμ_j,x(y) via sampling or discretization
  4. Validate against known special cases (PDP, coefficient recovery for linear models)

- Design tradeoffs:
  - Product measures vs. joint measures: Product measures assume feature independence but are computationally simpler
  - Monte Carlo vs. grid integration: Monte Carlo scales better to high dimensions but introduces variance
  - FSC vs. FPC continuity: FSC is stronger and required for Riesz-Markov; FPC is weaker but may not guarantee measure representations

- Failure signatures:
  - Attributions do not match Gradient×Input for linear models: Check measure recovers coefficients
  - Numerical instability in ReLU region enumeration: Monitor memory overflow; consider sampling regions
  - FSC violation: Small model perturbations cause large attribution changes

- First 3 experiments:
  1. Sanity check on linear models: Verify φ(x, f)_j = w_j (global) or w_j · x_j (local) for random linear models
  2. Comparison with Gradient×Input on smoothed networks: Verify attributions approach Gradient×Input as smoothing parameter → 0
  3. Measure optimization for Recall: Implement optimization in Problem (6) and verify solution centers-of-mass lie in sets S_j

## Open Questions the Paper Calls Out
None

## Limitations
- Framework's reliance on FSC may be overly restrictive for certain attribution methods
- Closed-form computation for ReLU networks faces exponential complexity in number of linear regions
- Paper does not address computational complexity bounds or approximation strategies for high-dimensional inputs

## Confidence

- **High Confidence**: Axiomatic collapse to Gradient×Input is mathematically rigorous with explicit bounds
- **Medium Confidence**: Measure-theoretic construction is sound but practical measure choices require empirical validation
- **Medium Confidence**: Closed-form solution for ReLU networks is theoretically correct but scalability to deep networks is unproven

## Next Checks

1. Implement atomic attribution for indicator functions and verify recovery of PDP and linear model coefficients
2. For small ReLU network, compute linear regions explicitly and validate attributions match Corollary 4.1
3. Implement measure optimization for Recall on linear model with known ground-truth features and compare against SHAP