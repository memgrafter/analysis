---
ver: rpa2
title: Efficient Deployment of Large Language Models on Resource-constrained Devices
arxiv_id: '2501.02438'
source_url: https://arxiv.org/abs/2501.02438
tags:
- pruning
- lora
- devices
- fine-tuning
- fedspine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently deploying large
  language models (LLMs) on resource-constrained devices in federated learning settings,
  where device heterogeneity and privacy concerns are significant barriers. The proposed
  solution, FedSpine, integrates parameter-efficient fine-tuning (PEFT) with structured
  pruning through an iterative process that adaptively determines pruning ratios and
  LoRA ranks for heterogeneous devices.
---

# Efficient Deployment of Large Language Models on Resource-constrained Devices

## Quick Facts
- **arXiv ID**: 2501.02438
- **Source URL**: https://arxiv.org/abs/2501.02438
- **Reference count**: 40
- **Primary result**: FedSpine speeds up fine-tuning by 1.4×-6.9× and improves final accuracy by 0.4%-4.5% compared to baselines in federated learning on resource-constrained devices.

## Executive Summary
This paper addresses the challenge of efficiently deploying large language models (LLMs) on resource-constrained devices in federated learning settings, where device heterogeneity and privacy concerns are significant barriers. The proposed solution, FedSpine, integrates parameter-efficient fine-tuning (PEFT) with structured pruning through an iterative process that adaptively determines pruning ratios and LoRA ranks for heterogeneous devices. An online Multi-Armed Bandit (MAB) algorithm is employed to optimize these configurations without prior knowledge of device capabilities. Experiments on a physical platform with 80 NVIDIA Jetson devices demonstrate substantial improvements in both speed and accuracy compared to existing approaches.

## Method Summary
FedSpine combines structured pruning with LoRA fine-tuning in a federated learning framework to deploy LLMs on resource-constrained devices. The method employs an iterative joint optimization process where pruning and LoRA fine-tuning alternate within each round, allowing incremental recovery from pruning-induced damage. A Smooth Upper Confidence Bound (S-UCB) algorithm dynamically assigns heterogeneous pruning ratios and LoRA ranks to different devices without requiring prior knowledge of their capabilities. The system uses importance-weighted LoRA aggregation that reconstructs full-rank updates before averaging, preventing bias toward higher-rank devices. The approach was evaluated on SST-2 and MNLI text classification tasks using RoBERTa-110M and LLaMA-7B models across 100 federated learning rounds.

## Key Results
- FedSpine achieves 1.4×-6.9× speedup over baselines in federated learning scenarios
- Final model accuracy improves by 0.4%-4.5% compared to existing approaches
- Maintains 18.4% less inference memory compared to HETLoRA while achieving comparable accuracy
- Successfully handles device heterogeneity without prior knowledge of device capabilities

## Why This Works (Mechanism)

### Mechanism 1
Iterative joint optimization of pruning and fine-tuning produces higher accuracy than sequential approaches under the same sparsity constraints. Alternating between pruning and LoRA fine-tuning within each round allows the model to recover from pruning-induced damage incrementally, rather than attempting recovery after aggressive one-shot pruning. The gradient-guided importance estimation uses LoRA gradients to identify unimportant weights without computing frozen-weight gradients directly. Core assumption: The loss landscape permits incremental recovery; pruning damage is locally recoverable through low-rank updates.

### Mechanism 2
A Smooth Upper Confidence Bound (S-UCB) algorithm can dynamically assign heterogeneous pruning ratios and LoRA ranks without prior knowledge of device capabilities. S-UCB treats (pruning_ratio, LoRA_rank) as a continuous arm space, partitioning it via a decision tree. The reward function balances loss reduction, time alignment with average completion time, pruning progress, and LoRA module importance. Discounted exploration enables real-time adaptation as device conditions change. Core assumption: Device heterogeneity is relatively stable within a round; reward signal correlates with long-term convergence quality.

### Mechanism 3
Importance-weighted LoRA aggregation reconstructs full-rank updates before averaging, preventing bias toward higher-rank devices. Instead of zero-padding heterogeneous LoRA modules, FedSpine reconstructs ΔW = B·A, then aggregates with weights proportional to LoRA module importance. Importance combines gradient-based scores and singular values, capturing both training dynamics and information capacity. Core assumption: Reconstructed ΔW from low-rank factors preserves semantically meaningful information for aggregation; singular values indicate learned feature importance.

## Foundational Learning

- **LoRA (Low-Rank Adaptation)**: Core fine-tuning method; understanding rank selection and BA decomposition is essential for interpreting aggregation and rank adaptation. Quick check: Given a frozen weight matrix W ∈ R^(d×k), what is the parameter count difference between full fine-tuning and LoRA with rank r?
- **Structured Pruning (Attention Heads, FFN Channels)**: FedSpine prunes groups of weights, not individual parameters; dependency rules require understanding which weights must be removed together. Quick check: Why does unstructured pruning not yield inference speedup on standard hardware without sparse kernels?
- **Multi-Armed Bandit / UCB**: Configuration assignment relies on S-UCB; understanding exploration-exploitation tradeoff is critical for debugging slow convergence. Quick check: In UCB, what happens to exploration if the confidence term's denominator (pull count) grows faster than the numerator (log of total rounds)?
- **Federated Averaging (FedAvg) Basics**: Aggregation strategy builds on FedAvg but modifies it for heterogeneous LoRA ranks. Quick check: Why does FedAvg weight client updates by dataset size, and how does FedSpine's importance weighting differ?

## Architecture Onboarding

- **Component map**: Server (S-UCB agent → configuration dispatch → LoRA weight storage → reconstruction + weighted aggregation) → Devices (frozen LLM + LoRA modules → gradient-guided importance estimation → structured pruning → local fine-tuning → state logging) → Communication (MPI-based LoRA weight upload/download)
- **Critical path**: 1. Server runs S-UCB to assign (p_i^t, r_i^t) for each device based on prior-round state. 2. Devices download LoRA weights, shrink/expand to assigned rank. 3. Devices estimate weight importance using cached LoRA gradients, apply pruning masks. 4. Devices fine-tune for τ iterations, log loss change and completion time. 5. Server reconstructs ΔW_i, computes importance weights, aggregates. 6. Repeat until target pruning ratio reached.
- **Design tradeoffs**: τ (local iterations per round): Higher τ improves importance estimation but risks local drift; Table 8 shows τ=20 optimal, τ=40 degrades accuracy. Pruning granularity δ: Smaller δ increases configuration precision but raises MAB search cost. LoRA rank range [r_min, r_max]: Wider range accommodates heterogeneity but increases aggregation complexity.
- **Failure signatures**: Accuracy collapses mid-training → pruning ratio per round too aggressive; reduce ∆p or increase τ. Straggler effect persists despite S-UCB → verify reward computation reflects time gaps correctly; check that exploration term is not dominating early rounds. Aggregation produces unstable weights → importance scores may be near-zero; inspect singular value normalization.
- **First 3 experiments**: 1. Heterogeneity stress test: Deploy on 3 device tiers, measure completion time spread with uniform vs. adaptive configuration. Target: FedSpine reduces time spread by ≥50% vs. FedAPT. 2. Pruning-recovery curve: Fix LoRA rank, vary pruning ratio from 0.1 to 0.5, plot accuracy after 100 rounds. Target: Confirm iterative approach maintains ≥95% of baseline accuracy at 0.3 sparsity. 3. Ablation on τ: Run with τ ∈ {10, 20, 30, 40}, track final accuracy and total rounds to target sparsity. Target: Reproduce Table 8 finding that τ=20 is optimal.

## Open Questions the Paper Calls Out

### Open Question 1
Can FedSpine's Multi-Armed Bandit algorithm maintain its efficiency and accuracy benefits when scaled to LLMs with 30B+ parameters or models with fundamentally different architectures (e.g., Mixture-of-Experts)? Basis: The paper notes "the industry has focused on deploying models with approximately 8 billion parameters on terminal devices" but only evaluates on RoBERTa (110M) and LLaMA-7B. Why unresolved: The computational and memory dynamics of MAB-based configuration assignment may change fundamentally with larger models where pruning decisions have more complex ripple effects across layers. What evidence would resolve it: Experimental results on larger models (e.g., LLaMA-30B, LLaMA-70B) or MoE architectures showing convergence speed, accuracy recovery, and inference efficiency compared to baselines.

### Open Question 2
How sensitive is FedSpine's performance to the MAB hyperparameters (discount factor λ, partition threshold δ) across diverse deployment scenarios? Basis: Section 4.1.2 introduces S-UCB with hyperparameters λ and δ, but only τ (iteration frequency) is ablated in Table 8; other MAB hyperparameters remain fixed without analysis. Why unresolved: The discount factor λ controls exploration-exploitation balance, and δ determines pruning granularity—both could significantly impact regret minimization and final model quality under different heterogeneity and data distribution regimes. What evidence would resolve it: Systematic ablation studies varying λ and δ across different heterogeneity levels and non-IID settings, measuring cumulative regret, convergence speed, and final accuracy.

### Open Question 3
Does the transmission of local loss changes and completion times in FedSpine's reward function introduce privacy leakage vulnerabilities, and can differential privacy mechanisms be integrated without degrading the adaptive configuration benefits? Basis: FedSpine claims privacy preservation via FL, but the MAB reward uses ∆Fᵢᵗ (local loss changes) and Tᵢᵗ (completion times) which could indirectly reveal properties of local data distributions or device capabilities. Why unresolved: The paper does not analyze the privacy implications of the state information collected for MAB decisions, nor does it explore privacy-preserving alternatives for the reward signal. What evidence would resolve it: Formal privacy analysis (e.g., membership inference attacks) on the transmitted metadata, and experiments with differential privacy noise injection on reward signals measuring the accuracy-efficiency tradeoff.

## Limitations
- Empirical validation limited to specific hardware platform (NVIDIA Jetson devices) and task distributions
- Key S-UCB hyperparameters not fully specified, potentially affecting reproducibility
- Importance estimation mechanism assumes stable gradient patterns across rounds
- Focus on structured pruning of specific architectural components, leaving questions about alternative pruning strategies

## Confidence

- **High confidence**: FedSpine's iterative pruning-fine-tuning mechanism improves accuracy over sequential approaches under sparsity constraints
- **Medium confidence**: S-UCB effectively handles device heterogeneity without prior knowledge
- **Medium confidence**: Importance-weighted aggregation prevents bias toward high-rank devices

## Next Checks
1. **Generalization test**: Evaluate FedSpine on cloud-based heterogeneous GPU clusters with varying memory capacities to assess performance outside the Jetson ecosystem
2. **Robustness analysis**: Systematically vary S-UCB hyperparameters (λ, s, δ) across multiple random seeds to quantify sensitivity to configuration choices
3. **Cross-task transfer**: Apply FedSpine to vision transformer models in federated learning settings to verify architecture-agnostic effectiveness of the pruning-guided importance estimation approach