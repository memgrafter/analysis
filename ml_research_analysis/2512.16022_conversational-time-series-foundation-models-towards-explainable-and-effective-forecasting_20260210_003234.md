---
ver: rpa2
title: 'Conversational Time Series Foundation Models: Towards Explainable and Effective
  Forecasting'
arxiv_id: '2512.16022'
source_url: https://arxiv.org/abs/2512.16022
tags:
- uni00000013
- uni00000011
- optimization
- ensemble
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TSOrchestr addresses the challenge of selecting optimal ensemble
  weights for time series foundation models by positioning a large language model
  as an intelligent judge that reasons about weight quality rather than directly predicting
  values. The system uses R1-style fine-tuning guided by SHAP-based faithfulness scores
  to teach the LLM to interpret ensemble weights as meaningful causal statements about
  temporal dynamics, enabling it to evaluate and refine weight configurations through
  iterative multi-turn conversations.
---

# Conversational Time Series Foundation Models: Towards Explainable and Effective Forecasting

## Quick Facts
- **arXiv ID**: 2512.16022
- **Source URL**: https://arxiv.org/abs/2512.16022
- **Reference count**: 40
- **Primary result**: LLM-orchestrated ensemble weights achieve 25.5% improvement over best individual model through causally-grounded weight selection and explainability

## Executive Summary
This paper introduces TSOrchestr, a system that uses a large language model as an intelligent judge to select optimal ensemble weights for time series foundation models. Rather than predicting values directly, the LLM reasons about weight quality through multi-turn conversations guided by SHAP-based faithfulness scores. The approach achieves new state-of-the-art performance on the GIFT-Eval benchmark while providing interpretable explanations for why certain weights were selected, addressing both effectiveness and explainability challenges in time series forecasting.

## Method Summary
TSOrchestr positions an LLM (Qwen-2.5-3B) as an intelligent judge that iteratively evaluates and refines ensemble weights through multi-turn conversations. Foundation models (Moirai-2, Sundial, Toto, TabPFN-TS) generate predictions, then SLSQP optimization produces initial weights under sum-to-one and non-negativity constraints. The LLM agent receives these weights along with cross-validation metrics, dataset features, and model capabilities, then reasons across three dimensions: Align (performance-weight coherence), Match (dataset-model compatibility), and Future (generalization risks). The agent can accept weights, continue optimization with different metrics, or reject weights based on faithfulness scores that measure alignment between LLM explanations and SHAP-derived causal attributions. The system is trained through SFT on optimization trajectories followed by GRPO refinement using faithfulness rewards.

## Key Results
- Achieves rank 7.3 on MASE and 8.2 on CRPS on GIFT-Eval benchmark
- Represents 25.5% improvement over best individual model (Moirai-2)
- Demonstrates 50-100% weight selection accuracy across domains versus 0-45% for non-agentic selectors
- Establishes new state-of-the-art performance while providing interpretable explanations

## Why This Works (Mechanism)

### Mechanism 1: Ensemble Superiority Under Temporal Incompatibility
When time series exhibit regime heterogeneity (high temporal incompatibility), weighted ensembles achieve provably lower loss than any single model. SLSQP optimization discovers weights that exploit model specialization—models excelling in specific regimes receive higher weights when their architectural strengths match dominant temporal patterns. The advantage scales with model diversity and temporal incompatibility index.

### Mechanism 2: SHAP-Grounded Faithfulness Prevents Post-Hoc Rationalization
Aligning LLM explanations with SHAP-derived causal effects produces weight justifications that reflect true temporal dynamics rather than plausible hallucinations. STL decomposition creates counterfactual time series by intervening on Trend/Seasonality/Residual components. The faithfulness score measures correlation between SHAP effects and LLM-claimed effects, directly penalizing explanations that misattribute model contributions.

### Mechanism 3: Metacognitive Control Over Static Optimization
An LLM agent performing forward-looking assessment of cross-validation gaps produces more generalizable weights than pure numerical optimization. The agent evaluates performance-weight coherence, dataset-model compatibility, and generalization risks, and can reject SLSQP weights that overfit limited CV windows. It triggers metric switching to test hypotheses about weight quality.

## Foundational Learning

- **Shapley Values and SHAP**
  - Why needed: Understanding how the paper attributes forecasting performance to temporal components (Trend/Seasonality/Residual) and how this grounds faithfulness scoring
  - Quick check: Given three players {A,B,C} with coalition values f(∅)=0, f({A})=2, f({B})=3, f({C})=1, f({A,B})=5, f({A,C})=3, f({B,C})=4, f({A,B,C})=6, compute the Shapley value for player A.

- **Sequential Least Squares Programming (SLSQP)**
  - Why needed: This is the constrained optimizer that discovers ensemble weights under sum-to-one and non-negativity constraints
  - Quick check: Why must SLSQP (or similar constrained optimizer) be used instead of gradient descent for finding valid ensemble weights?

- **Group Relative Policy Optimization (GRPO)**
  - Why needed: The RL component that refines LLM decision-making using group-comparison advantages rather than a separate value network
  - Quick check: How does GRPO's advantage estimation Ã(y,x) = (r(y,x) - r̄(x)) / (σ_r(x) + ε) differ from PPO's critic-based advantage?

## Architecture Onboarding

Foundation models generate predictions → SLSQP optimizes initial weights → LLM agent reasons across Align/Match/Future dimensions → Agent decides continue/accept/reject → Loop until confidence threshold → Final explanation validated against SHAP decomposition

**Critical path:**
1. Foundation models generate predictions on input series
2. SLSQP optimizes weights for candidate metric
3. LLM agent receives (weights, CV metrics, dataset features, model capabilities)
4. Agent reasons → decides continue/accept → optionally specifies next metric
5. Loop until confidence threshold reached (typically 2-3 iterations)
6. Final explanation validated against SHAP decomposition

**Design tradeoffs:**
- 3-model vs. 4-model ensemble: 3-model (Moirai-Sundial-Toto) selected for efficiency; 4-model adds TabPFN with marginal gains but higher compute
- Agent model size: Qwen-2.5-3B chosen over GPT-4o/Sonnet—comparable accuracy at orders-of-magnitude lower latency
- SFT vs. GRPO ratio: 10:1 training schedule (500 SFT steps, 50 GRPO steps) prevents overfitting to specific weight patterns

**Failure signatures:**
- Premature termination: Agent accepts weights at 60-70% confidence when further optimization would yield >5% MASE improvement—indicates undertrained boundary calibration
- Metric cycling: Agent oscillates between MAE→SMAPE→MSE without convergence—suggests unfaithful explanations causing spurious reasoning
- Weight collapse: Single model receives >95% weight across all datasets—indicates agent not learning complementary model selection

**First 3 experiments:**
1. Baseline sanity check: Run SLSQP-only (no agent) on 5 GIFT-Eval datasets with each metric; verify ensemble beats best single model by ~15-20% on average
2. Faithfulness ablation: Disable r_faith reward component (set β=0 in GRPO); measure explanation-SHAP correlation degradation and weight selection accuracy drop
3. Agent generalization test: Train R1-tuned agent on Healthcare+Sales domains only; evaluate zero-shot on Energy+Finance—expect 10-15% accuracy drop if domain knowledge not transferring

## Open Questions the Paper Calls Out

The paper identifies three future directions: enhancing optimization with multi-objective criteria, scaling to larger foundation model pools, and incorporating more granular temporal decompositions beyond Trend/Seasonality/Residual.

## Limitations

- SHAP-based faithfulness relies on STL decomposition stability, but no validation is provided for cases where temporal components are highly correlated
- The 25.5% improvement comparison uses SLSQP-optimized ensembles without LLM reasoning as baseline, not pure numerical optimization
- Agent reasoning quality depends heavily on underspecified R1 fine-tuning dataset construction details

## Confidence

- **High**: Ensemble optimization superiority when temporal incompatibility is high - supported by clear mathematical formulation and optimization results
- **Medium**: SHAP-grounded faithfulness preventing post-hoc rationalization - theoretical framework is sound but empirical validation of counterfactual decomposition quality is limited
- **Low**: Metacognitive control advantage over static optimization - agent performance improvements demonstrated but attribution to forward-looking reasoning vs. better metric selection is unclear

## Next Checks

1. Conduct ablation study comparing TSOrchestr against SLSQP-only baseline on GIFT-Eval to isolate LLM reasoning contribution from ensemble benefits
2. Test SHAP faithfulness correlation under varying temporal component correlation levels to identify failure thresholds
3. Evaluate zero-shot generalization on unseen dataset types to quantify domain knowledge transfer limitations