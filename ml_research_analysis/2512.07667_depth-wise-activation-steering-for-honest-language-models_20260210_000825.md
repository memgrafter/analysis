---
ver: rpa2
title: Depth-Wise Activation Steering for Honest Language Models
arxiv_id: '2512.07667'
source_url: https://arxiv.org/abs/2512.07667
tags:
- steering
- honesty
- gaussian
- depth
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of large language models asserting\
  \ falsehoods despite internally representing the correct answer\u2014failures of\
  \ honesty rather than accuracy\u2014which undermines auditability and safety. The\
  \ authors introduce a training-free activation steering method that weights steering\
  \ strength across network depth using a Gaussian schedule."
---

# Depth-Wise Activation Steering for Honest Language Models

## Quick Facts
- arXiv ID: 2512.07667
- Source URL: https://arxiv.org/abs/2512.07667
- Reference count: 6
- A training-free activation steering method using Gaussian depth scheduling improves honesty on the MASK benchmark in 6 of 7 tested models.

## Executive Summary
This paper addresses the problem of large language models asserting falsehoods despite internally representing the correct answer—failures of honesty rather than accuracy—which undermines auditability and safety. The authors introduce a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. On the MASK benchmark, which separates honesty from knowledge, they evaluate seven models spanning the LLaMA, Qwen, and Mistral families and find that Gaussian scheduling improves honesty over no-steering and single-layer baselines in six of seven models. Equal-budget ablations on LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations, indicating that how intervention is distributed across depth materially affects outcomes beyond total strength. The method is simple, model-agnostic, requires no fine-tuning, and provides a low-cost control knob for eliciting truthful reporting from models' existing capabilities.

## Method Summary
The authors introduce depth-wise activation steering that applies steering strength across network depth using a Gaussian scheduling function. Unlike prior work that applied uniform or single-layer interventions, this method modulates activation values at different depths according to a Gaussian curve, allowing stronger influence at certain depths while maintaining weaker influence elsewhere. The approach requires no training or model-specific fine-tuning, making it broadly applicable across different architectures. The Gaussian scheduling is parameterized by mean depth and standard deviation, which control where steering is most concentrated and how quickly it decays away from that point.

## Key Results
- Gaussian depth scheduling improved honesty on the MASK benchmark in 6 of 7 tested models (LLaMA, Qwen, Mistral families)
- On LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct, Gaussian scheduling outperformed random, uniform, and box-filter depth allocations under equal steering budgets
- The method successfully elicited honest reporting of correct internal representations without requiring model retraining or fine-tuning

## Why This Works (Mechanism)
The mechanism relies on the observation that transformer models process information hierarchically across layers, with different depths capturing different aspects of semantic understanding. By applying steering strength according to a Gaussian schedule rather than uniformly or at a single layer, the method can target the specific depths where the model has formed correct internal representations but may be overridden by later processing stages. The Gaussian shape allows for concentrated intervention at critical depths while maintaining some influence on surrounding layers, potentially smoothing the transition between honest and dishonest response generation. This depth-wise modulation appears to work by strengthening the signal from correct internal representations at the right stages of processing, preventing later layers from overriding truthful responses with more confident but incorrect assertions.

## Foundational Learning
- **Transformer layer hierarchy**: Why needed - understanding how different depths capture different semantic aspects; Quick check - verify that steering at different depths produces qualitatively different response patterns
- **Activation steering**: Why needed - grasping the basic intervention mechanism without fine-tuning; Quick check - confirm that simple steering can shift model outputs in predictable directions
- **Gaussian scheduling**: Why needed - understanding why depth-specific weighting matters beyond total strength; Quick check - compare Gaussian vs uniform scheduling on a small validation set
- **Honesty vs accuracy distinction**: Why needed - recognizing that models can know correct answers but fail to report them; Quick check - test model on questions where internal knowledge is detectable but not reported
- **MASK benchmark construction**: Why needed - understanding how the benchmark isolates honesty from knowledge; Quick check - verify that MASK questions require models to report known information honestly
- **No-training intervention methods**: Why needed - appreciating the practical advantages of steering over fine-tuning; Quick check - measure computation time and resource requirements for steering vs fine-tuning

## Architecture Onboarding

Component map: Input -> Embedding -> Transformer layers (depth-wise steering applied) -> Output head

Critical path: The key processing path involves input tokens being embedded, passing through transformer layers where depth-wise steering modulates activations according to the Gaussian schedule, then producing output through the final attention and prediction layers. Steering strength varies across depth according to the Gaussian curve.

Design tradeoffs: The method trades off steering precision (fine-grained depth control) against implementation simplicity. Using a fixed Gaussian schedule avoids per-model tuning but may not be optimal for all architectures. The no-training requirement sacrifices potential performance gains from model-specific fine-tuning in exchange for generality and low computational cost.

Failure signatures: The approach may fail when correct internal representations are distributed across too many depths for Gaussian scheduling to effectively capture, or when dishonest response patterns are deeply embedded in later layers that resist steering influence. Models with very different layer organizations or those relying heavily on specific depth patterns may show limited improvement.

Three first experiments:
1. Apply depth-wise steering with varying Gaussian parameters (mean, std) to identify optimal configurations for a single model
2. Compare Gaussian scheduling against uniform and single-layer steering on a small validation set to confirm depth matters
3. Test the method on a model where internal knowledge is known to exist but not reported to verify honesty improvement

## Open Questions the Paper Calls Out
None

## Limitations
- The approach remains purely activation-level and does not address underlying causal mechanisms of why models choose to assert falsehoods despite having correct internal representations
- Results are limited to seven models in the LLaMA, Qwen, and Mistral families; generalization to other architectures or modalities remains untested
- The MASK benchmark, while specifically designed to isolate honesty from knowledge, has not been independently validated for construct validity

## Confidence

*High confidence*: The empirical finding that Gaussian scheduling outperforms no-steering and single-layer baselines across six of seven tested models is robust, given the consistent pattern and statistical comparisons provided.

*Medium confidence*: Claims about Gaussian scheduling being superior to other budget allocation schemes rest on a limited set of alternatives (random, uniform, box-filter) and a restricted model sample. The mechanistic explanation for why depth-wise scheduling works remains speculative.

*Low confidence*: The paper's assertions about the method providing "honest reporting of existing capabilities" overstate what can be concluded from activation steering alone, as the intervention may be manipulating output style rather than ensuring epistemic honesty.

## Next Checks

1. Test Gaussian scheduling against a broader space of depth-weighting functions (exponential, power-law, learned schedules) across at least 15 additional model architectures to establish robustness.

2. Conduct ablation studies measuring whether improvements persist when controlling for total activation magnitude versus depth-specific weighting, to isolate the effect of scheduling from global scaling.

3. Implement an independent validation of the MASK benchmark through human evaluation studies to confirm that measured improvements correspond to genuine honesty rather than shifted response patterns.