---
ver: rpa2
title: Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?
arxiv_id: '2510.06594'
source_url: https://arxiv.org/abs/2510.06594
tags:
- jailbreak
- prompts
- layer
- representations
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores whether internal layers of LLMs reveal patterns
  useful for jailbreak detection. The authors propose a tensor-based approach to analyze
  hidden representations of LLMs when processing jailbreak versus benign prompts.
---

# Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?

## Quick Facts
- **arXiv ID**: 2510.06594
- **Source URL**: https://arxiv.org/abs/2510.06594
- **Reference count**: 6
- **Primary result**: Tensor decomposition of internal LLM representations achieves 67-95% F1 scores for jailbreak detection

## Executive Summary
This paper investigates whether internal layers of large language models contain discernible patterns that can be leveraged for jailbreak detection. The authors propose a tensor-based approach that extracts hidden representations from LLM layers, constructs 3D tensors from these representations, and applies CP tensor decomposition to obtain latent embeddings. These embeddings are then classified to distinguish between jailbreak and benign prompts. The approach demonstrates clear separation between jailbreak and benign prompts in the latent space, achieving F1 scores ranging from approximately 67% to 95% across different layers and model architectures. The findings suggest that analyzing internal LLM representations through tensor decomposition is a promising direction for detecting adversarial prompts.

## Method Summary
The authors employ a tensor-based methodology to analyze hidden representations of LLMs when processing jailbreak versus benign prompts. They extract layer outputs from GPT-J and Mamba2 models, stacking them into 3D tensors where dimensions represent layers, sequence length, and hidden dimension size. CP (CANDECOMP/PARAFAC) tensor decomposition is then applied to obtain latent embeddings that capture the essential patterns in the hidden representations. These embeddings serve as features for classification using standard machine learning models. The approach focuses on multi-head attention (MHA) and mixer outputs from each layer, comparing their effectiveness in capturing discriminatory information for jailbreak detection.

## Key Results
- Clear separation between jailbreak and benign prompts in latent space embeddings
- F1 scores ranging from ~67% to 95% across different layers and models
- MHA/mixer outputs perform best for jailbreak detection compared to other layer components
- Tensor decomposition approach successfully captures discriminatory patterns in hidden representations

## Why This Works (Mechanism)
The approach works because jailbreak prompts induce distinct activation patterns in LLM hidden representations compared to benign prompts. These patterns are preserved and made more discernible through tensor decomposition, which captures multi-linear relationships across layers, sequence positions, and hidden dimensions. The CP decomposition reduces dimensionality while maintaining the essential structure that distinguishes adversarial from normal inputs.

## Foundational Learning
- **CP Tensor Decomposition**: Decomposes multi-dimensional arrays into rank-one components; needed to extract latent patterns from high-dimensional hidden representations; quick check: verify decomposition reconstructs original tensor within acceptable error margin
- **Multi-head Attention (MHA)**: Mechanism allowing models to focus on different input positions; needed as key source of discriminatory patterns; quick check: compare MHA vs feed-forward layer outputs for detection performance
- **Layer-wise Analysis**: Examining internal representations at each transformer layer; needed to identify where jailbreak patterns emerge; quick check: plot detection accuracy across layers to find optimal detection depth
- **3D Tensor Construction**: Organizing layer outputs into tensors with dimensions (layers × sequence × hidden); needed to preserve spatial relationships in activations; quick check: validate tensor dimensions match model architecture specifications
- **Latent Embedding Classification**: Using decomposed tensors as features for downstream classification; needed to translate pattern discovery into practical detection; quick check: test multiple classifier types (SVM, logistic regression, neural nets) for robustness

## Architecture Onboarding

**Component Map**: Prompt → LLM Layer Extraction → 3D Tensor Construction → CP Decomposition → Latent Embeddings → Classification

**Critical Path**: The most time-consuming step is CP tensor decomposition, which scales with tensor size and decomposition rank. Efficient implementation is crucial for practical deployment.

**Design Tradeoffs**: Higher decomposition ranks capture more information but increase computational cost and risk overfitting. The choice of tensor dimensions affects information preservation versus computational efficiency.

**Failure Signatures**: Poor separation in latent space indicates either insufficient discriminatory information in hidden representations or inappropriate tensor construction parameters. Performance degradation on out-of-distribution jailbreaks suggests the approach may not generalize beyond training prompt types.

**First Experiments**:
1. Compare detection performance using different layer components (MHA vs mixer vs feed-forward)
2. Test various tensor dimensions and decomposition ranks to optimize the tradeoff between accuracy and efficiency
3. Evaluate robustness by testing on jailbreak prompts not present in the original dataset

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several emerge from the methodology and results. The generalizability across different model architectures remains uncertain, particularly for larger models with different attention mechanisms. The approach's effectiveness against evolving jailbreak techniques that may not resemble the 10 types studied is also unclear. Additionally, the static nature of the analysis may miss temporal dynamics crucial for detecting sophisticated multi-turn jailbreaks.

## Limitations
- Results may not generalize to larger models like GPT-4 or Claude with different architectures
- Only 10 jailbreak types from AdvJamBench were tested, potentially missing novel attack patterns
- Static layer output analysis may miss temporal or conversational jailbreak patterns
- Fixed tensor dimensions may introduce information loss and aren't optimized across architectures

## Confidence

**High confidence**: The technical implementation of CP tensor decomposition and its application to layer-wise analysis is sound and reproducible.

**Medium confidence**: The observed separation between jailbreak and benign prompts in latent space is compelling but requires validation on more diverse datasets and model architectures.

**Low confidence**: The claim that tensor decomposition provides a scalable defense mechanism against evolving jailbreak techniques, given the rapidly changing landscape of adversarial prompt engineering.

## Next Checks

1. Evaluate the approach on out-of-distribution jailbreak prompts not present in the training data, including multi-turn jailbreaks and those with novel linguistic patterns.

2. Test scalability by applying the method to larger models (GPT-3.5, GPT-4) and measuring performance degradation across different parameter scales.

3. Conduct ablation studies to determine the optimal tensor dimensions and decomposition rank for maximizing detection accuracy while minimizing computational overhead.