---
ver: rpa2
title: 'Large Language Models for Planning: A Comprehensive and Systematic Survey'
arxiv_id: '2505.19683'
source_url: https://arxiv.org/abs/2505.19683
tags:
- arxiv
- planning
- preprint
- language
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a comprehensive and systematic survey of Large
  Language Model (LLM) planning, covering planning definitions, methodologies, evaluation
  frameworks, and underlying mechanisms. It categorizes existing approaches into three
  main types: External Module Augmented Methods (combining LLMs with planners or memory),
  Finetuning-based Methods (using trajectory data or feedback signals), and Searching-based
  Methods (decomposition, exploration, and decoding strategies).'
---

# Large Language Models for Planning: A Comprehensive and Systematic Survey

## Quick Facts
- **arXiv ID**: 2505.19683
- **Source URL**: https://arxiv.org/abs/2505.19683
- **Reference count**: 40
- **Primary result**: Comprehensive survey of LLM planning methodologies, evaluation frameworks, and future directions

## Executive Summary
This paper presents a systematic survey of Large Language Model planning approaches, organizing the rapidly evolving field into three main categories: External Module Augmented Methods, Finetuning-based Methods, and Searching-based Methods. The survey covers planning definitions, methodologies, evaluation frameworks, and underlying mechanisms, providing a comprehensive overview of the current state of LLM planning research. It examines datasets across digital, embodied, everyday, and vertical scenarios, along with corresponding metrics and analysis techniques. The paper identifies key trends including the dominance of fine-tuning methods and the growing popularity of multimodal agents, while highlighting critical challenges in generalization and efficiency that need to be addressed for future development.

## Method Summary
The survey systematically categorizes LLM planning approaches into three main types: External Module Augmented Methods (combining LLMs with planners or memory), Finetuning-based Methods (using trajectory data or feedback signals), and Searching-based Methods (decomposition, exploration, and decoding strategies). The authors collected and analyzed 40+ references to create a comprehensive framework that examines planning definitions, methodologies, evaluation frameworks, and underlying mechanisms. The survey also summarizes evaluation datasets across different scenarios and provides analysis from both external (factors affecting planning) and internal (circuit/neuron-level) perspectives, offering a structured approach to understanding the complex landscape of LLM planning research.

## Key Results
- LLMs have achieved significant performance improvements in planning tasks through fine-tuning methods, which dominate current approaches
- The survey identifies three main methodological categories for LLM planning, with searching-based methods gaining popularity through decomposition and exploration strategies
- Key challenges remain in generalization across diverse scenarios and efficiency of planning systems, with future directions pointing toward RL integration and edge deployment

## Why This Works (Mechanism)
The effectiveness of LLM planning stems from the models' ability to leverage learned world knowledge and reasoning capabilities through structured approaches. External module augmentation enhances LLMs with specialized planners and memory systems, while fine-tuning methods adapt pre-trained models to specific planning tasks using trajectory data. Searching-based approaches decompose complex planning problems into manageable sub-tasks and explore solution spaces systematically. The combination of these methods with multimodal capabilities enables LLMs to handle diverse planning scenarios effectively, though challenges remain in achieving robust generalization and computational efficiency.

## Foundational Learning
- **Planning Task Decomposition**: Breaking complex planning problems into manageable sub-tasks - needed to handle multi-step reasoning and improve computational efficiency - quick check: measure success rate of decomposed vs. monolithic planning approaches
- **Trajectory-based Fine-tuning**: Using task-specific data to adapt pre-trained LLMs - essential for improving planning performance on specialized domains - quick check: compare performance before and after fine-tuning on planning benchmarks
- **Memory Integration**: Incorporating external memory systems with LLMs - critical for maintaining long-term planning context and information retrieval - quick check: evaluate memory-assisted vs. standalone planning performance
- **Multimodal Planning**: Extending planning capabilities to multiple input modalities - necessary for real-world embodied and visual planning tasks - quick check: assess performance on multimodal vs. text-only planning datasets
- **Circuit-level Interpretability**: Analyzing internal LLM mechanisms for planning decisions - important for understanding and improving planning reliability - quick check: correlate neuron activation patterns with planning success rates

## Architecture Onboarding

**Component Map**: LLM Core -> Planning Module -> Memory System -> Output Generator
External Planner/Tool -> LLM Core -> Planning Module -> Evaluation Module -> LLM Core
Fine-tuning Dataset -> LLM Core -> Planning Module -> Performance Metrics -> LLM Core

**Critical Path**: LLM Core -> Planning Module -> Output Generation
The core LLM processes input, passes through planning module for task decomposition and strategy selection, then generates output plans. This path is critical as it determines the quality and coherence of final planning outputs.

**Design Tradeoffs**: Fine-tuning vs. prompting efficiency, memory vs. computational cost, generalization vs. specialization, multimodal capability vs. model complexity
Key tradeoffs include balancing the performance gains from fine-tuning against computational costs, deciding between external memory systems (higher accuracy, higher cost) versus in-context learning (lower cost, potential context limitations), and choosing between general-purpose planning capabilities versus specialized domain performance.

**Failure Signatures**: Over-reliance on learned patterns, inability to generalize to novel scenarios, computational inefficiency in complex planning tasks, hallucination of unrealistic plans
Common failures include producing plans that work in training scenarios but fail in novel situations, generating overly complex or computationally expensive plans, and creating plans that violate real-world constraints or physical laws.

**First Experiments**:
1. Implement a baseline planning system using zero-shot prompting on a simple planning benchmark to establish performance reference
2. Apply fine-tuning on a small planning dataset and compare performance against the baseline to measure improvement potential
3. Integrate a basic external memory system and evaluate its impact on long-term planning task performance

## Open Questions the Paper Calls Out
The paper identifies several open questions in LLM planning research, including how to improve generalization across diverse planning scenarios, the development of more efficient planning mechanisms that can operate on edge devices, and the integration of reinforcement learning techniques to enhance planning capabilities. Additionally, the survey highlights the need for better evaluation metrics that can capture the nuances of different planning tasks and the development of universal planning systems that can handle multiple domains effectively. The interpretability of internal planning mechanisms at both circuit and neuron levels remains an open challenge for improving reliability and trustworthiness.

## Limitations
- The survey may not capture the most recent developments given the rapidly evolving nature of LLM planning research
- The categorization framework might oversimplify certain hybrid methods that combine multiple approaches
- The evaluation metrics summary may not fully capture task-specific nuances or practical deployment considerations
- Internal mechanism analysis (circuit/neuron-level interpretability) remains largely theoretical with limited empirical validation

## Confidence

| Claim | Confidence |
|-------|------------|
| Survey comprehensiveness | Medium |
| Methodology categorization | High |
| Performance trends | Medium |
| Future directions | High |

## Next Checks
1. Cross-validate the survey's categorization framework by applying it to 10-15 recent (2024-2025) LLM planning papers not included in the original survey to test its comprehensiveness and adaptability
2. Conduct a systematic comparison of evaluation metrics across different planning scenarios (digital, embodied, everyday, vertical) to identify potential metric biases or gaps
3. Implement and test the proposed interpretability analysis (circuit/neuron-level) on at least two representative planning tasks to verify practical feasibility and insights gained