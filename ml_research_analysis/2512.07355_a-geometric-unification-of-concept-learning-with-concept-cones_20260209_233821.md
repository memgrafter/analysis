---
ver: rpa2
title: A Geometric Unification of Concept Learning with Concept Cones
arxiv_id: '2512.07355'
source_url: https://arxiv.org/abs/2512.07355
tags:
- concept
- concepts
- learning
- cone
- dictionary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes a geometric unification between Concept
  Bottleneck Models (CBMs) and Sparse Autoencoders (SAEs) by showing they both learn
  concept cones - sets of linear directions in activation space whose nonnegative
  combinations form convex cones. CBMs provide human-annotated concept directions
  through supervised learning, while SAEs discover emergent concept directions through
  sparse coding.
---

# A Geometric Unification of Concept Learning with Concept Cones
## Quick Facts
- arXiv ID: 2512.07355
- Source URL: https://arxiv.org/abs/2512.07355
- Authors: Alexandre Rocchi--Henry; Thomas Fel; Gianni Franchi
- Reference count: 40
- Geometric unification between Concept Bottleneck Models (CBMs) and Sparse Autoencoders (SAEs) through concept cones

## Executive Summary
This paper presents a geometric unification between Concept Bottleneck Models and Sparse Autoencoders by showing both learn concept cones - convex cones formed by nonnegative combinations of linear directions in activation space. CBMs use human-annotated concept directions through supervised learning, while SAEs discover emergent concept directions through sparse coding. The authors propose metrics to measure the geometric and semantic alignment between these approaches, finding that intermediate sparsity levels (0.01-0.05%) and expansion factors (3×) maximize alignment.

The containment hypothesis asserts that CBM concepts should lie within or be well-approximated by SAE concept cones. Through extensive experiments across multiple backbones and datasets, the authors demonstrate that deeper layers of ResNet-50 show stronger semantic alignment with CBM concepts, and that BatchTopK and Archetypal SAE variants provide superior coverage and alignment compared to other SAE variants.

## Method Summary
The paper establishes a geometric framework where both CBMs and SAEs learn concept cones - sets of linear directions whose nonnegative combinations form convex cones in activation space. CBMs provide human-annotated concept directions through supervised learning, while SAEs discover emergent concept directions through sparse coding with learnable basis vectors. The authors propose metrics to measure geometric alignment (using angle-based measures between cone directions) and semantic alignment (using trained classifiers to measure concept presence). Experiments span multiple architectures including ResNet-50, ConvNeXt, and various SAE variants, testing different sparsity levels and expansion factors to identify optimal configurations.

## Key Results
- Intermediate sparsity levels (0.01-0.05%) and expansion factors (3×) maximize geometric and semantic alignment between CBMs and SAEs
- Deeper layers of ResNet-50 show stronger semantic alignment with CBM concepts
- BatchTopK and Archetypal SAE variants demonstrate superior coverage and alignment compared to other SAE variants
- Proposed metrics successfully distinguish trained from untrained SAEs, validating their ability to measure meaningful semantic alignment

## Why This Works (Mechanism)
The geometric unification works because both CBMs and SAEs learn to represent concepts as linear directions in high-dimensional activation space. CBMs do this through supervised learning with human-annotated concepts, while SAEs discover these directions through sparse coding optimization. The concept cone framework captures how these directions combine to form convex regions representing concept presence. The alignment between CBM and SAE concept cones emerges because both approaches are solving related representation problems - identifying meaningful directions in the same activation space that correspond to interpretable concepts.

## Foundational Learning
- Concept Bottleneck Models: Models that explicitly use human-annotated concepts as intermediate representations. Needed to provide ground-truth concept directions for comparison with SAEs. Quick check: Verify that CBM concepts are linearly separable in activation space.
- Sparse Autoencoders: Neural networks trained to reconstruct inputs with sparse activations, discovering emergent features. Needed to identify natural concept directions without supervision. Quick check: Confirm sparsity constraints effectively reduce reconstruction error.
- Concept Cones: Convex cones formed by nonnegative combinations of linear directions representing concepts. Needed to unify the geometric interpretation of both approaches. Quick check: Verify cone membership through non-negative combination tests.
- Geometric Alignment Metrics: Angle-based measures comparing cone directions between CBMs and SAEs. Needed to quantify alignment between supervised and emergent concepts. Quick check: Ensure metrics are sensitive to both direction and coverage differences.

## Architecture Onboarding
Component Map: Input Features -> Concept Bottleneck Model -> CBM Concepts -> Geometric Alignment Metrics -> SAE -> SAE Concepts -> Semantic Alignment Metrics
Critical Path: The critical path involves learning CBM concepts through supervised training, learning SAE concepts through sparse reconstruction, and measuring alignment between both sets of concepts using geometric and semantic metrics.
Design Tradeoffs: Supervised CBM learning provides interpretable concepts but requires human annotation, while unsupervised SAE learning discovers emergent concepts but may lack semantic meaning. The tradeoff is between annotation cost and concept interpretability.
Failure Signatures: Poor alignment indicates either ineffective SAE learning (too sparse/too dense) or concept misalignment between human-annotated and emergent concepts. Untrained SAEs show random alignment patterns distinguishable from trained models.
First Experiments:
1. Train CBM and SAE on a simple dataset and visualize cone directions to verify geometric alignment patterns
2. Vary sparsity levels systematically to identify the optimal "sweet spot" for alignment
3. Compare semantic alignment scores across different SAE variants (BatchTopK, Archetypal, etc.)

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the generalizability of the "sweet spot" hyperparameters across different datasets and model architectures, the stability of these parameters in diverse settings, and whether the pattern of stronger semantic alignment in deeper layers extends beyond ResNet-50 to other architectures like ViT and ConvNeXt.

## Limitations
- The identified "sweet spot" for sparsity (0.01-0.05%) and expansion factors (3×) may not generalize across all datasets and architectures
- The containment hypothesis assumes semantic alignment correlates with geometric containment, which may not always hold
- The finding that deeper ResNet-50 layers show stronger semantic alignment may be architecture-specific and not universal

## Confidence
- **High confidence**: The geometric framework unifying CBMs and SAEs through concept cones is mathematically sound and well-supported by experimental evidence
- **Medium confidence**: The empirical "sweet spot" for SAE hyperparameters is robust within tested configurations but may not generalize universally
- **Medium confidence**: The claim that deeper layers show stronger semantic alignment is supported by experiments but may be architecture-dependent

## Next Checks
1. Test the identified "sweet spot" hyperparameters (0.01-0.05% sparsity, 3× expansion) across multiple architectures (ViT, ConvNeXt) and diverse datasets to verify generalizability
2. Conduct ablation studies on different layer depths across multiple architectures to determine if the pattern of stronger semantic alignment in deeper layers holds beyond ResNet-50
3. Evaluate the proposed metrics' ability to distinguish semantically meaningful concept directions from random directions in zero-shot transfer scenarios where no labeled concepts are available