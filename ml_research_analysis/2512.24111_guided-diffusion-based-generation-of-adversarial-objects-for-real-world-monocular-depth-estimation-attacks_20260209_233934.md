---
ver: rpa2
title: Guided Diffusion-based Generation of Adversarial Objects for Real-World Monocular
  Depth Estimation Attacks
arxiv_id: '2512.24111'
source_url: https://arxiv.org/abs/2512.24111
tags:
- adversarial
- depth
- diffusion
- objects
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the vulnerability of monocular depth estimation
  (MDE) models in autonomous driving systems to adversarial attacks. Existing physical
  attacks rely on unnatural texture patches with limited placement flexibility, reducing
  their stealthiness and practical applicability in complex driving environments.
---

# Guided Diffusion-based Generation of Adversarial Objects for Real-World Monocular Depth Estimation Attacks

## Quick Facts
- arXiv ID: 2512.24111
- Source URL: https://arxiv.org/abs/2512.24111
- Reference count: 40
- Key outcome: Training-free diffusion-based framework generates naturalistic adversarial objects that cause depth misestimation in autonomous driving systems, achieving superior effectiveness and stealthiness compared to patch-based attacks

## Executive Summary
This work addresses the vulnerability of monocular depth estimation (MDE) models in autonomous driving systems to adversarial attacks. Existing physical attacks rely on unnatural texture patches with limited placement flexibility, reducing their stealthiness and practical applicability in complex driving environments. To overcome these limitations, the authors propose a training-free generative adversarial attack framework that produces naturalistic, scene-consistent adversarial objects via a diffusion-based conditional generation process. The method introduces a Salient Region Selection module to identify the most influential regions for depth estimation and a Jacobian Vector Product Guidance mechanism to steer adversarial gradients while preserving the visual plausibility of generated objects.

## Method Summary
The framework consists of two stages: (1) Salient Region Selection identifies top-k vulnerable regions through gradient-based sensitivity analysis, and (2) Adversarial Object Generation uses PowerPaint-v2 diffusion model with Jacobian Vector Product Guidance to create realistic objects conditioned on text descriptions from Qwen3-VL. The approach is training-free, leveraging pre-trained models for both diffusion generation and depth estimation. Physical experiments validate the method by printing generated objects and measuring depth shift under real-world camera capture conditions.

## Key Results
- Achieves higher Mean Relative Shift Ratio (MRSR) than baseline patch-based attacks while maintaining superior CLIP-Score for visual realism
- Successfully deploys adversarial objects in physical environments, demonstrating real-world attack feasibility
- Outperforms existing physical attack methods across effectiveness, stealthiness, and deployability metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Perturbation-based saliency ranking identifies image regions that exert disproportionate influence on target depth predictions
- Mechanism: First-order gradient ascent is applied within localized patch masks to maximize depth shift in the target region; patches are ranked by induced perturbation magnitude
- Core assumption: MDE models exhibit non-uniform spatial sensitivity, and regions with higher gradient-based saliency generalize to stronger adversarial manipulation
- Evidence anchors:
  - [abstract] "incorporates a Salient Region Selection module that identifies regions most influential to MDE"
  - [Section IV-B, Algorithm 1] Describes partitioning into candidate patches, gradient ascent updates, and scoring by depth difference ϕ(i)
  - [corpus] Projection-based adversarial attacks (arXiv:2512.24792) similarly use gradient-based optimization for MDE attacks, supporting the gradient-sensitivity premise
- Break condition: If saliency scores plateau or show negligible variance across patches, the MDE model may have uniform spatial sensitivity, invalidating selective targeting

### Mechanism 2
- Claim: Jacobian Vector Product Guidance (JVPG) aligns adversarial gradients with semantic directions in the diffusion model's learned manifold
- Mechanism: The Jacobian of the score network captures local curvature; projecting adversarial perturbations onto dominant singular directions preserves semantic coherence while suppressing artifact-producing directions
- Core assumption: The pre-trained diffusion model encodes meaningful geometric priors, and Jacobian singular vectors correspond to semantically valid vs. invalid perturbation directions
- Evidence anchors:
  - [abstract] "steers adversarial gradients toward update directions supported by the pre-trained diffusion model"
  - [Section IV-C, Fig. 4] Visualizes that perturbations along largest singular direction preserve structure while smallest singular direction produces artifacts
  - [corpus] Corpus lacks direct validation of Jacobian-based guidance in adversarial diffusion; mechanism remains specific to this paper
- Break condition: If generated objects show persistent artifacts or low CLIP-Scores despite JVPG, the Jacobian may not reliably encode semantic directions, or the linearization assumption fails

### Mechanism 3
- Claim: Energy-based adversarial conditioning enables training-free integration of task-specific gradients into diffusion sampling
- Mechanism: The adversarial loss is treated as an energy function; its gradient with respect to the noisy latent is approximated via posterior mean estimation and injected into the reverse diffusion update
- Core assumption: The posterior mean approximation z₀|t provides a sufficiently accurate clean-latent proxy for evaluating the energy function at each timestep
- Evidence anchors:
  - [Section III-C, Eq. 5-6] Derives energy-based guidance using ∇zt log p(c|zt) ∝ −∇zt hθ(c, z₀|t)
  - [Section IV-C, Eq. 13] Combines text-conditional score with Jacobian-modulated adversarial gradient in the reverse step
  - [corpus] MonoDiff9D (arXiv:2504.10433) applies diffusion for monocular pose estimation, showing diffusion can incorporate task constraints, though not adversarial
- Break condition: If guidance strength γ must be tuned per-scene or causes sampling divergence, the energy approximation or gradient scale may be unstable across diverse inputs

## Foundational Learning

- **Score-based diffusion models and DDIM reverse sampling**: Why needed here: The entire framework builds on modifying the reverse diffusion trajectory; understanding score networks and noise schedules is prerequisite. Quick check question: Can you derive how adding a guidance term to the score affects the denoising trajectory?
- **Adversarial robustness and perturbation-based sensitivity analysis**: Why needed here: Salient Region Selection relies on gradient-ascent perturbation to rank vulnerable regions. Quick check question: Why might patch-constrained perturbations yield different sensitivity rankings than unconstrained perturbations?
- **Energy-based models and conditional inference via gradient guidance**: Why needed here: JVPG frames the adversarial objective as an energy function; understanding how energy gradients steer sampling is essential. Quick check question: What happens to sampling stability if the energy gradient magnitude varies dramatically across timesteps?

## Architecture Onboarding

- **Component map**: Input image → Salient Region Selection → VLM text conditioning → Jacobian Vector Product Guidance → diffusion reverse sampling → adversarial object extraction
- **Critical path**: 1) Obtain target mask M_T and candidate patch masks from scene, 2) Run Salient Region Selection to get M_A (top-k regions), 3) Initialize noisy latent, apply JVPG-guided reverse diffusion with text + adversarial conditioning, 4) Extract adversarial object from final sample and composite into scene
- **Design tradeoffs**: More insertion regions (higher k) → higher MRSR but increased computational cost and potential detection risk; stronger guidance strength γ → deeper depth shift but risk of visual artifacts if misaligned with diffusion geometry; coarse vs. fine text conditioning → coarse preserves flexibility for adversarial appearance; fine constrains realism but may limit attack potency
- **Failure signatures**: Low MRSR with high CLIP-Score: adversarial gradient too weak or misaligned with effective depth-perturbation directions; High MRSR with low CLIP-Score: guidance pushes into out-of-distribution regions; check Jacobian projection or reduce γ; Physical-domain effectiveness drops significantly from digital: printing artifacts, lighting mismatch, or camera ISP differences degrade the adversarial pattern
- **First 3 experiments**: 1) Validate Salient Region Selection by comparing MRSR on SRS-selected vs. randomly sampled regions on MonoDepth2, 2) Ablate JVPG against DPS, MPGD, and ADMM-Diff guidance, measuring both MRSR and CLIP-Score to confirm realism-effectiveness tradeoff, 3) Test physical deployability by printing generated adversarial objects and measuring depth shift under real-world camera capture on at least two target categories

## Open Questions the Paper Calls Out
None

## Limitations
- Physical attack experiments use limited sample size (5 out of 22 attempts successfully deployed) that may not capture environmental variability across different lighting conditions, camera sensors, or object materials
- The JVPG mechanism lacks direct empirical validation against alternative gradient steering approaches in adversarial diffusion contexts
- The energy-based guidance formulation assumes stable Jacobian directions across timesteps, which may not hold for complex scene geometries

## Confidence

- **High confidence**: Salient Region Selection mechanism and its gradient-based sensitivity analysis (supported by established adversarial attack literature)
- **Medium confidence**: Physical attack effectiveness claims (limited sample size, potential environmental confounders)
- **Medium confidence**: JVPG mechanism (novel application without direct empirical validation in corpus)
- **Medium confidence**: Energy-based guidance formulation (theoretical soundness but potential stability issues across timesteps)

## Next Checks

1. **Jacobian Stability Analysis**: Quantify how JVPG singular vector directions vary across timesteps for diverse scene types. Measure cosine similarity between consecutive timestep Jacobians and correlate with artifact occurrence rates.

2. **Physical Robustness Stress Test**: Systematically vary printing materials, lighting conditions, and camera sensors across 50+ physical attack attempts. Measure degradation in MRSR relative to digital performance and identify failure patterns.

3. **Guidance Ablation Study**: Replace JVPG with alternative gradient steering methods (gradient sign projection, gradient normalization, random subspace projection). Compare MRSR-CLIP Score tradeoffs to validate JVPG's specific contribution to artifact suppression.