---
ver: rpa2
title: Position-aware Automatic Circuit Discovery
arxiv_id: '2502.04577'
source_url: https://arxiv.org/abs/2502.04577
tags:
- schema
- circuit
- edges
- faithfulness
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses a key limitation in automatic circuit discovery
  methods: their assumption that circuits are position-invariant, treating model components
  as equally relevant across all input positions. This limits their ability to capture
  cross-positional interactions or mechanisms that vary across positions.'
---

# Position-aware Automatic Circuit Discovery
## Quick Facts
- arXiv ID: 2502.04577
- Source URL: https://arxiv.org/abs/2502.04577
- Reference count: 40
- Primary result: Position-aware circuits achieve better faithfulness-size tradeoffs than position-agnostic circuits

## Executive Summary
This paper addresses a key limitation in automatic circuit discovery methods: their assumption that circuits are position-invariant, treating model components as equally relevant across all input positions. This limits their ability to capture cross-positional interactions or mechanisms that vary across positions. The authors propose two improvements to incorporate positionality into circuits, even on tasks containing variable-length examples. First, they extend edge attribution patching to differentiate between token positions, allowing computation of the importance of cross-positional edges and separate evaluation of edge importance at each position. Second, they introduce dataset schemas - which define token spans with similar semantics across examples - enabling position-aware circuit discovery in datasets with variable length examples.

## Method Summary
The authors develop a position-aware circuit discovery pipeline that extends edge attribution patching to differentiate between token positions, enabling computation of cross-positional edge importance and separate evaluation at each position. They introduce dataset schemas to handle variable-length examples by defining token spans with similar semantics across examples. An automated pipeline for schema generation and application using large language models enables fully automated discovery of position-sensitive circuits. The approach is evaluated on GPT2-small and Llama-3-8B across IOI, Greater-Than, and Winobias tasks, showing better tradeoffs between circuit size and faithfulness compared to position-agnostic circuits.

## Key Results
- Position-aware circuits discovered using the method achieved better tradeoffs between circuit size and faithfulness to the model's behavior than position-agnostic circuits
- Circuits derived using automatically generated and applied schemas achieved comparable faithfulness scores to circuits discovered with human-designed and manually applied schemas
- The automated schema generation pipeline successfully identified meaningful positional dependencies across the tested tasks

## Why This Works (Mechanism)
The paper introduces position-aware circuit discovery by addressing the fundamental limitation that traditional methods treat model components as position-invariant. By extending edge attribution patching to differentiate between token positions, the method can capture cross-positional interactions that are crucial for understanding how models process variable-length inputs. The schema-based approach provides a semantic framework that allows the algorithm to identify equivalent positions across different examples, making the discovery process robust to input length variations. The automated schema generation using LLMs enables scalability to new tasks without requiring manual schema design.

## Foundational Learning
- **Edge attribution patching**: A technique for measuring the importance of individual model components to specific behaviors. Needed to quantify how changes in model components affect output, serving as the foundation for circuit discovery. Quick check: Verify that edge attribution values correlate with component removal effects on model performance.

- **Dataset schemas**: Definitions of token spans with similar semantics across examples. Needed to handle variable-length inputs by providing a consistent semantic framework for position-aware analysis. Quick check: Confirm that schema-defined spans capture equivalent semantic roles across different examples.

- **Position-aware analysis**: Differentiating between token positions rather than treating all positions equivalently. Needed to capture position-dependent mechanisms and cross-positional interactions. Quick check: Verify that position-specific circuits capture different mechanisms than position-agnostic ones.

## Architecture Onboarding
**Component Map**: Schema Generator -> Position-aware Edge Attribution Patching -> Circuit Extraction -> Faithfulness Evaluation

**Critical Path**: The core pipeline flows from schema generation through position-aware patching to circuit extraction, with faithfulness evaluation providing feedback for circuit optimization.

**Design Tradeoffs**: The method trades computational complexity for position sensitivity, requiring more sophisticated analysis but capturing richer mechanisms. The schema-based approach adds flexibility for variable-length inputs but introduces dependency on schema quality.

**Failure Signatures**: Poor schema generation leads to meaningless positional groupings; position-agnostic circuits fail to capture cross-positional dependencies; overly large circuits indicate insufficient pruning or poor faithfulness metrics.

**First Experiments**: 1) Apply the pipeline to a simple position-dependent task to verify basic functionality. 2) Compare position-aware vs position-agnostic circuits on a controlled dataset with known positional dependencies. 3) Test schema generation quality by manually verifying schema-defined spans on a subset of examples.

## Open Questions the Paper Calls Out
None

## Limitations
- The approach assumes LLMs can reliably generate accurate schemas for arbitrary datasets, which may not generalize to complex or nuanced tasks
- The evaluation focuses on faithfulness to model behavior without addressing whether circuits correspond to human-understandable mechanisms
- The comparison assumes human-designed schemas are "correct," potentially overlooking biases or missed dependencies

## Confidence
- **High confidence**: Technical validity of extending edge attribution patching to incorporate position information; observation that position-aware circuits achieve better faithfulness-size tradeoffs
- **Medium confidence**: Generalizability of the schema generation approach to arbitrary tasks beyond the three tested examples
- **Low confidence**: Claims about the interpretability or mechanistic insight provided by the discovered circuits

## Next Checks
1. Test schema generation and circuit discovery on a diverse set of tasks including more complex reasoning tasks, multi-step inference problems, and tasks with subtle positional dependencies to evaluate robustness.

2. Conduct ablation studies removing the LLM-generated schemas and comparing performance against random or heuristic-based schema generation to quantify the value added by the LLM component.

3. Perform cross-validation where schemas generated for one dataset or model are applied to different datasets or models to test the portability and generalizability of the approach.