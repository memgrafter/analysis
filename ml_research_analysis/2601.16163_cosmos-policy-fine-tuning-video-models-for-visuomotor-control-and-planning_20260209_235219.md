---
ver: rpa2
title: 'Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning'
arxiv_id: '2601.16163'
source_url: https://arxiv.org/abs/2601.16163
tags:
- policy
- cosmos
- training
- value
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Cosmos Policy fine-tunes a pretrained video model (Cosmos-Predict2)
  into a robot policy through a single stage of post-training, with no architectural
  changes. The method injects robot actions, future states, and values as latent frames
  within the model's latent diffusion sequence, enabling direct policy learning and
  future state/value prediction.
---

# Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning

## Quick Facts
- arXiv ID: 2601.16163
- Source URL: https://arxiv.org/abs/2601.16163
- Reference count: 21
- Primary result: Cosmos Policy fine-tunes video models for robot control, achieving 98.5% success rate on LIBERO and 67.1% on RoboCasa benchmarks

## Executive Summary
Cosmos Policy introduces a novel approach to robot policy learning by fine-tuning pretrained video generation models for visuomotor control and planning. The method injects robot actions, future states, and values as latent frames within the model's latent diffusion sequence, enabling direct policy learning and future state/value prediction. This allows test-time planning via best-of-N sampling to select higher-likelihood successful actions. The approach achieves state-of-the-art performance on simulation benchmarks (LIBERO, RoboCasa) and real-world bimanual manipulation tasks, outperforming diffusion policies trained from scratch, video model-based policies, and fine-tuned vision-language-action models.

## Method Summary
Cosmos Policy fine-tunes a pretrained video model (Cosmos-Predict2) into a robot policy through a single stage of post-training, with no architectural changes. The method injects robot actions, future states, and values as latent frames within the model's latent diffusion sequence, enabling direct policy learning and future state/value prediction. This allows test-time planning via best-of-N sampling to select higher-likelihood successful actions. The approach achieves state-of-the-art performance on LIBERO (98.5% average success rate) and RoboCasa (67.1% average success rate) simulation benchmarks, and highest average score on challenging real-world bimanual manipulation tasks.

## Key Results
- Achieves 98.5% average success rate on LIBERO simulation benchmark
- Achieves 67.1% average success rate on RoboCasa simulation benchmark
- Highest average score on real-world bimanual manipulation tasks

## Why This Works (Mechanism)
The method works by leveraging the rich spatiotemporal representations learned by pretrained video models and adapting them for robot control. By injecting robot actions, future states, and values as latent frames, the model learns to predict successful action sequences. The best-of-N sampling during test-time planning allows the selection of high-likelihood successful actions, improving overall performance.

## Foundational Learning
1. **Video generation models**: Pretrained models that learn rich spatiotemporal representations from video data. Why needed: To leverage existing knowledge about video dynamics for robot control. Quick check: Verify the model's ability to generate realistic video sequences.

2. **Latent diffusion**: A technique for generating data by iteratively denoising latent representations. Why needed: To enable efficient sampling and planning in the latent space. Quick check: Ensure the model can generate diverse and realistic latent sequences.

3. **Robot action prediction**: The task of predicting robot actions given visual observations. Why needed: To enable the model to control robots based on visual input. Quick check: Evaluate the model's ability to predict accurate robot actions in simulation.

4. **Planning via sampling**: A method for selecting the best action by sampling multiple candidates and evaluating their likelihood of success. Why needed: To improve the model's decision-making by considering multiple possible futures. Quick check: Compare the performance of planning via sampling against greedy action selection.

## Architecture Onboarding

Component map: Video model -> Latent injection -> Policy head -> Action sampler

Critical path: Input video frames -> Video model encoder -> Latent space manipulation -> Policy head -> Action sampler -> Robot control

Design tradeoffs: The method trades off the flexibility of training from scratch with the efficiency of fine-tuning a pretrained model. The use of latent injection allows for efficient adaptation but may limit the model's ability to learn complex action-state relationships.

Failure signatures: The model may struggle with tasks that require long-term planning or involve complex action-state relationships not captured by the pretrained video model. It may also be sensitive to the choice of hyperparameters and design decisions.

First experiments:
1. Evaluate the model's ability to predict robot actions in a simple simulation environment.
2. Compare the performance of the fine-tuned model against a model trained from scratch on a standard robotics benchmark.
3. Assess the impact of different latent injection strategies on the model's performance.

## Open Questions the Paper Calls Out
None

## Limitations
- The method relies on a specific pretrained video model (Cosmos-Predict2) and its success may not generalize to other video models or architectures.
- The evaluation is primarily conducted in simulation environments (LIBERO and RoboCasa), with limited real-world testing on bimanual manipulation tasks.
- The paper does not provide a detailed ablation study on the impact of different hyperparameters and design choices.

## Confidence
- High confidence in the proposed method's ability to fine-tune video models for robot control and planning.
- Medium confidence in the method's generalization to different video models and real-world scenarios.
- Low confidence in the robustness of the method to hyperparameter choices and design variations.

## Next Checks
1. Evaluate the method on a broader range of real-world robot manipulation tasks, including tasks with varying complexities and environments.
2. Conduct an extensive ablation study to assess the impact of different hyperparameters, architectural choices, and design decisions on the method's performance.
3. Investigate the transferability of the method to other pretrained video models and compare its performance with alternative approaches in the literature.