---
ver: rpa2
title: 'LLMCode: Evaluating and Enhancing Researcher-AI Alignment in Qualitative Analysis'
arxiv_id: '2504.16671'
source_url: https://arxiv.org/abs/2504.16671
tags:
- coding
- qualitative
- examples
- research
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "LLMCode introduces a systematic approach to evaluate and align\
  \ LLM-driven qualitative coding within research for design (RfD). The tool integrates\
  \ two metrics\u2014Intersection over Union (IoU) and Modified Hausdorff Distance\
  \ (MHD)\u2014to measure alignment between human and LLM-generated insights."
---

# LLMCode: Evaluating and Enhancing Researcher-AI Alignment in Qualitative Analysis

## Quick Facts
- arXiv ID: 2504.16671
- Source URL: https://arxiv.org/abs/2504.16671
- Authors: Joel Oksanen; Andrés Lucero; Perttu Hämäläinen
- Reference count: 40
- Primary result: Introduces IoU and MHD metrics for LLM-human alignment in qualitative coding; shows strong deductive performance but limited deep interpretation

## Executive Summary
LLMCode is a tool designed to evaluate and enhance alignment between researchers and LLMs in qualitative analysis. It uses two complementary metrics—Intersection over Union (IoU) for segment overlap and Modified Hausdorff Distance (MHD) for semantic code similarity—to quantify alignment quality. Tested with 26 designers, the system demonstrated effective deductive coding but revealed limitations in capturing deeper interpretive reasoning. The iterative refinement process showed bidirectional influence, where researchers both shaped and adapted to AI suggestions. The findings emphasize the need for tools that balance interpretive depth with scalable collaboration.

## Method Summary
LLMCode uses gpt-4o with in-context learning (few-shot prompting) to perform qualitative coding. Researchers manually code a subset of texts with highlights and codes, then select representative examples for the prompt. The LLM processes remaining texts, and IoU (character-level overlap) and MHD (embedding-based semantic distance) are computed to measure alignment. Users iteratively refine examples based on metric-sorted divergence cases. String matching reconstructs annotations if