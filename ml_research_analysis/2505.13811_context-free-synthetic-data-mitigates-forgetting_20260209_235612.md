---
ver: rpa2
title: Context-Free Synthetic Data Mitigates Forgetting
arxiv_id: '2505.13811'
source_url: https://arxiv.org/abs/2505.13811
tags:
- data
- forgetting
- synthetic
- table
- context-free
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in language models,
  where fine-tuning degrades performance on previously learned tasks. The authors
  propose a data-oblivious method called context-free synthetic data (CFS) that mitigates
  forgetting by estimating and penalizing KL divergence between the original and fine-tuned
  models.
---

# Context-Free Synthetic Data Mitigates Forgetting
## Quick Facts
- arXiv ID: 2505.13811
- Source URL: https://arxiv.org/abs/2505.13811
- Reference count: 18
- Key outcome: CFS outperforms standard fine-tuning in preserving pre-existing task performance while maintaining new task learning

## Executive Summary
This paper addresses catastrophic forgetting in language models by proposing a data-oblivious method called context-free synthetic data (CFS). The method generates unconditional samples from the base model using only the beginning-of-sentence token, then fine-tunes using a weighted combination of standard loss and pretraining-style loss on the synthetic data. Experiments demonstrate that CFS effectively mitigates forgetting compared to several baselines, particularly when synthetic data generation is limited to 10% of the fine-tuning dataset size.

## Method Summary
The CFS approach works by first generating context-free synthetic data from the original model using only the beginning-of-sentence token. This synthetic data approximates the original model's distribution. During fine-tuning on the downstream task, the method combines the standard fine-tuning loss with a pretraining-style loss computed on the synthetic data, weighted to balance learning the new task while preserving knowledge of pre-existing tasks. The method requires no access to the original training data and can be implemented with minimal modifications to standard fine-tuning pipelines.

## Key Results
- CFS achieved 29.34% accuracy on GSM8K while maintaining 28.24% average performance on pre-existing tasks
- Standard fine-tuning achieved 29.49% on GSM8K but only 23.55% on pre-existing tasks
- CFS effectiveness maintained even with synthetic data generation limited to 10% of fine-tuning data size
- Outperformed baselines including LoRA, ℓ2 regularization, and model averaging

## Why This Works (Mechanism)
The mechanism relies on KL divergence estimation between the original and fine-tuned models. By generating unconditional samples from the base model using only the BOS token, CFS captures the original distribution without requiring the full training data. The weighted loss function during fine-tuning penalizes deviations from this original distribution while still allowing learning of the new task. This creates a regularization effect that preserves knowledge of pre-existing tasks.

## Foundational Learning
- **KL Divergence**: Measures difference between probability distributions - needed to quantify forgetting
- **Context-Free Generation**: Unconditional sampling without task-specific prompts - needed for distribution approximation
- **Weighted Loss Functions**: Combining multiple objectives during training - needed to balance new learning with retention
- **Synthetic Data Generation**: Creating artificial training examples - needed to avoid accessing original data
- **Catastrophic Forgetting**: Degradation of previous knowledge during sequential learning - the problem being solved

## Architecture Onboarding
**Component Map**: BOS token generation -> Synthetic data creation -> Weighted loss computation -> Fine-tuning
**Critical Path**: Generate synthetic data from BOS token → Compute weighted loss (downstream + synthetic) → Update model parameters
**Design Tradeoffs**: Computation overhead of synthetic generation vs. performance retention; synthetic data quality vs. quantity; weighting hyperparameters
**Failure Signatures**: Over-regularization (poor new task performance); under-regularization (catastrophic forgetting); synthetic data mismatch with original distribution
**First Experiments**: 1) Generate BOS-only samples from base model 2) Test weighted loss combinations 3) Compare retention vs. baselines on simple sequential tasks

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- Assumption that BOS token generation adequately approximates base model distribution not rigorously validated across domains
- Evaluation limited to mathematical reasoning tasks, unclear if method generalizes to other domains
- Computational overhead of synthetic data generation may become prohibitive at larger scales
- Ablation studies don't fully explore sensitivity to generation temperature and synthetic data weighting

## Confidence
- **High confidence**: CFS improves retention of pre-existing task performance compared to standard fine-tuning
- **Medium confidence**: Context-free generation from BOS token is sufficient for distribution approximation
- **Low confidence**: CFS is broadly applicable across diverse task domains

## Next Checks
1. Test CFS on non-mathematical domains (code completion, summarization, dialogue) to verify cross-domain effectiveness
2. Conduct ablation studies varying generation temperature, synthetic data ratio, and sequence length to identify optimal configurations
3. Measure wall-clock time and memory overhead of CFS generation compared to fine-tuning to assess practical scalability