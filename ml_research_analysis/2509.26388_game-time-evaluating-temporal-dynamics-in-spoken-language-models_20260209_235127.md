---
ver: rpa2
title: 'Game-Time: Evaluating Temporal Dynamics in Spoken Language Models'
arxiv_id: '2509.26388'
source_url: https://arxiv.org/abs/2509.26388
tags:
- arxiv
- tasks
- language
- speech
- temporal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Game-Time Benchmark to evaluate the temporal
  dynamics of Spoken Language Models (SLMs) in real-time conversational settings.
  The benchmark is inspired by how humans learn languages through activities that
  involve timing, tempo, and synchronization.
---

# Game-Time: Evaluating Temporal Dynamics in Spoken Language Models

## Quick Facts
- **arXiv ID**: 2509.26388
- **Source URL**: https://arxiv.org/abs/2509.26388
- **Reference count**: 0
- **Primary result**: SOTA SLMs degrade significantly under temporal constraints, revealing lack of time-awareness and full-duplex capability.

## Executive Summary
This paper introduces the Game-Time Benchmark to evaluate how well Spoken Language Models handle temporal dynamics in real-time conversational settings. The benchmark tests models on basic instruction-following tasks and more complex temporal constraints like speed, silence, tempo adherence, and simultaneous speaking. Using a dual-channel LLM-as-a-judge evaluation method validated against human judgments, the study finds that while current SOTA models handle basic tasks reasonably well, all models show substantial degradation when temporal constraints are introduced, exposing persistent weaknesses in time-awareness and full-duplex interaction capabilities.

## Method Summary
The Game-Time Benchmark evaluates temporal dynamics in SLMs through a hierarchical task structure. Basic Tasks test fundamental instruction-following (Sequence, Repeat, Compose, Recall, Open-Ended, Role-Play), while Advanced Tasks add temporal constraints (Time-Fast/Slow/Silence, Tempo-Interval/Adhere, SimulSpeak-Shadow/Cue). The evaluation uses a dual-channel approach: user and model audio are transcribed separately with Whisper-medium to obtain word-level timestamps, then fed to an LLM judge (Gemini 2.5 Pro) for temporal constraint assessment. An SSML-LLM oracle provides an upper bound using non-causal processing. The method is validated against human judgments with reasonable correlation (Spearman's ρ=0.677).

## Key Results
- All tested models (Freeze-Omni, Unmute, Moshi, GPT-realtime, Gemini-Live) show significant performance degradation when temporal constraints are introduced.
- Time-multiplexing models outperform dual-channel models on basic instruction-following, suggesting fine-tuning text LLMs on speech remains challenging.
- Models can adjust speaking rate (Time-Fast/Slow) but fail at precise temporal targets like silence duration and tempo adherence.
- No current model demonstrates reliable full-duplex capability for simultaneous speaking tasks.

## Why This Works (Mechanism)

### Mechanism 1: Dual-Channel LLM-as-Judge Evaluation
The evaluation pipeline transcribes both user and model audio channels separately using Whisper-medium to obtain word-level alignments. A capable LLM (Gemini 2.5 Pro) then receives these time-aligned transcripts and evaluates whether temporal constraints were satisfied, using its reasoning capacity to interpret natural conversational behaviors rather than rigid rule-based metrics. This approach is validated against human judgments with reasonable correlation.

### Mechanism 2: Hierarchical Task Augmentation for Temporal Constraint Testing
Basic Tasks (Sequence, Repeat, Compose, Recall, Open-Ended, Role-Play) test fundamental speech capabilities. Advanced Tasks pair these with temporal constraints (Time-Fast/Slow/Silence, Tempo-Interval/Adhere, SimulSpeak-Shadow/Cue). By sharing the same underlying base task between basic and advanced variants, performance differences can be attributed specifically to temporal constraint handling rather than general capability limitations.

### Mechanism 3: Architecture-Specific Temporal Capability Limits
Time-multiplexing models use state prediction to alternate between listening and speaking; dual-channel models process both streams simultaneously. Despite architectural differences, both paradigms lack explicit mechanisms for fine-grained temporal planning—coordinating speaking rate, content length, and synchronization targets requires temporal reasoning not built into current training objectives.

## Foundational Learning

- **Concept: Full-Duplex Speech Interaction**
  - **Why needed here**: The benchmark specifically tests models that must listen and speak simultaneously, which fundamentally differs from turn-based dialogue. Understanding this distinction is prerequisite to interpreting why temporal synchronization tasks are challenging.
  - **Quick check question**: Can you explain why "listening while speaking" requires different architectural commitments than alternating turn-taking?

- **Concept: Temporal Constraint Formalization**
  - **Why needed here**: The paper formalizes temporal tasks as instruction-following with constraint predicates (duration τ, tempo δ, silence s). Grasping this abstraction helps understand how the benchmark systematically varies difficulty.
  - **Quick check question**: Given the instruction "count from 1 to 5 with 2-second intervals," what are the base task and constraint variables?

- **Concept: SSML-as-Oracle Baseline**
  - **Why needed here**: The SSML-LLM oracle operates non-causally with future knowledge of user speech to achieve precise temporal synchronization. This establishes a performance ceiling and reveals what's theoretically achievable versus what streaming models can accomplish.
  - **Quick check question**: Why can't the SSML-LLM approach be used in real-time deployment, and what does this imply about the gap between oracle and streaming model performance?

## Architecture Onboarding

- **Component map**: [User Audio Input] → [Streaming Encoder] → [LLM Core (frozen or fine-tuned)] → [Streaming Decoder] → [Model Audio Output] ↓ [State Predictor] (time-multiplexing only)

- **Critical path**: The benchmark execution flows through: (1) audio instruction synthesis via TTS with controlled temporal properties, (2) SLM inference in real-time, (3) dual-channel audio capture, (4) time-stamped transcription, (5) LLM-based evaluation. Breakdowns most commonly occur at step 2 (model fails temporal constraint) or step 5 (evaluation ambiguity).

- **Design tradeoffs**:
  - **Time-multiplexing vs. Dual-channel**: Time-multiplexing models (Freeze-Omni, Unmute) use frozen text LLMs with speech encoders/decoders, preserving reasoning capability but adding latency from state prediction. Dual-channel models (Moshi) fine-tune LLMs directly on speech, enabling tighter integration but showing weaker instruction-following in this benchmark.
  - **Rule-based vs. LLM evaluation**: Rule-based metrics are rigid but reproducible; LLM judges handle natural variation but require validation against human judgments.
  - **Assumption**: The paper assumes the LLM judge's reasoning about temporal constraints generalizes across task types; this is validated for the tested scope but may not hold for novel temporal patterns.

- **Failure signatures**:
  - **Time-Silence failure**: Models generate filler speech instead of maintaining specified silence, indicating inability to withhold output.
  - **Tempo-Adhere failure**: Models cannot match user-provided tempo examples, suggesting no internal beat-tracking or rhythmic adaptation.
  - **SimulSpeak failure**: Models wait for turn completion rather than overlapping speech, indicating lack of full-duplex synchronization capability.
  - **Common pattern**: Models can adjust speaking rate (Time-Fast/Slow) but fail at precise temporal targets requiring planning and prediction.

- **First 3 experiments**:
  1. **Reproduce Basic Task baseline**: Run a time-multiplexing model (e.g., Freeze-Omni if available, or substitute) on Basic Tasks only to establish content-generation competency before introducing temporal complexity.
  2. **Ablate constraint types systematically**: Test a single model across all Advanced Task categories to identify which temporal dimension (duration, tempo, synchronization) causes the steepest performance drop.
  3. **Validate LLM judge on held-out samples**: Manually evaluate 20-30 Advanced Task responses and compare with LLM judge scores to confirm correlation holds for your specific model/system before relying on automated evaluation at scale.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What specific architectural components or training paradigms are required to endow Spoken Language Models (SLMs) with "time-awareness" capable of handling precise temporal constraints?
- **Basis in paper**: The authors conclude that the "widespread inability to manage precise timing... reveals a persistent lack of time-awareness in current SLMs," explicitly stating this "highlights the need to focus on this capability in future research."
- **Why unresolved**: The paper successfully identifies the failure mode (performance degradation in Advanced Tasks) but does not propose or test architectural solutions to bridge the gap between current causal models and the non-causal oracle.
- **What evidence would resolve it**: A study demonstrating that a modified SLM architecture (e.g., one with explicit timing embeddings or a distinct temporal control mechanism) can maintain performance parity between Basic and Advanced Tasks.

### Open Question 2
- **Question**: Why do SLMs successfully modulate speaking rate (Time-Fast/Slow) yet fail to grasp absolute timing requirements (Time-Silence)?
- **Basis in paper**: The results section notes that models perform "comparatively better on Time-Fast and Time-Slow, but fail on Time-Silence," leading the authors to infer that models can adjust rate but "still fail to grasp precise temporal requirements."
- **Why unresolved**: The paper highlights this disparity but leaves the underlying mechanism unexplored; it is unclear if the failure is due to the absence of an internal "clock," inability to process empty audio intervals, or lack of training data with precise silence labels.
- **What evidence would resolve it**: An ablation study showing whether models trained with explicit duration tokens or auxiliary time-prediction losses can specifically improve performance on the Time-Silence and Tempo-Interval tasks.

### Open Question 3
- **Question**: Does the text-based LLM-as-a-judge methodology fully capture prosodic and temporal nuances, or does its reliance on transcription (ASR) obscure critical evaluation signals?
- **Basis in paper**: The authors rely on a text-based LLM judge (Gemini 2.5 Pro) over an audio-LLM due to cost and alignment, but they report a correlation of only 0.677 with human judges, suggesting the automated metric does not fully explain human perception of temporal fluency.
- **Why unresolved**: While validated as reliable, the method discards the raw audio stream in favor of timestamps, potentially missing subtle but important prosodic errors or unnatural rhythmic artifacts that a human would catch.
- **What evidence would resolve it**: A comparative analysis showing that an audio-based judge (or a multimodal judge) correlates significantly more strongly with human evaluation than the proposed text-based method on temporal synchronization tasks.

## Limitations
- The dual-channel LLM judge methodology, while validated against human judgments, may not generalize to all temporal patterns or more nuanced conversational dynamics.
- The benchmark covers a limited slice of real-world temporal dynamics with synthesized TTS audio rather than natural speech.
- The evaluation doesn't fully account for how latency affects performance in real-time temporal tasks.

## Confidence

- **High Confidence**: The finding that current SLM architectures degrade significantly under temporal constraints is well-supported by systematic evaluation across multiple model types and constraint categories.
- **Medium Confidence**: The attribution of temporal failures to specific architectural limitations (time-multiplexing vs. dual-channel) is supported but not definitively proven.
- **Low Confidence**: The claim that the LLM judge methodology will reliably scale to novel temporal patterns or more complex conversational dynamics requires further validation.

## Next Checks
1. **Cross-validation with diverse models**: Test the dual-channel LLM judge evaluation methodology on a broader range of SLM architectures to assess generalizability.
2. **Human evaluation scaling study**: Conduct systematic human evaluation on a stratified sample of tasks to better understand the variance and reliability of the LLM judge approach.
3. **Temporal pattern generalization test**: Create and evaluate novel temporal patterns not present in the original benchmark to test whether the evaluation methodology and architectural insights generalize beyond tested scenarios.