---
ver: rpa2
title: 'When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning'
arxiv_id: '2511.02794'
source_url: https://arxiv.org/abs/2511.02794
tags:
- modality
- multimodal
- fusion
- emotion
- diagnostic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces "modality sabotage" as a diagnostic lens
  for analyzing multimodal reasoning failures, where a high-confidence unimodal error
  overrides other evidence and misleads the final prediction. The authors propose
  a lightweight, model-agnostic evaluation framework that treats each modality (text,
  audio, vision) as an agent, producing candidate labels with confidence scores and
  self-assessments.
---

# When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning

## Quick Facts
- arXiv ID: 2511.02794
- Source URL: https://arxiv.org/abs/2511.02794
- Reference count: 35
- One-line primary result: Introduces "modality sabotage" as a diagnostic lens for analyzing multimodal reasoning failures where high-confidence unimodal errors override other evidence

## Executive Summary
This paper introduces "modality sabotage" as a diagnostic framework for analyzing multimodal reasoning failures, where a high-confidence unimodal error overrides other evidence and misleads final predictions. The authors propose treating each modality (text, audio, vision) as an autonomous agent that produces candidate labels with confidence scores and self-assessments. A lightweight fusion mechanism aggregates these outputs to identify "contributors" (modalities supporting correct outcomes) and "saboteurs" (modalities causing errors). Applied to multimodal emotion recognition benchmarks, the approach reveals systematic reliability profiles and shows that while fusion maintains baseline top-1 accuracy, it substantially improves top-k coverage, preserving correct hypotheses even when top-1 predictions are affected.

## Method Summary
The framework treats each modality as an autonomous agent producing candidate labels with confidence scores and self-assessments. These unimodal outputs are then fused using a simple aggregation mechanism that identifies which modalities contribute to correct outcomes versus which cause errors through high-confidence mistakes. The approach is model-agnostic and lightweight, requiring only access to unimodal predictions and their associated confidence measures. The diagnostic lens can distinguish between dataset artifacts and model limitations by analyzing which modalities consistently act as saboteurs across different examples and datasets.

## Key Results
- Introduces "modality sabotage" phenomenon where high-confidence unimodal errors override other evidence
- Fusion maintains baseline top-1 accuracy while substantially improving top-k coverage
- Provides actionable insights into whether failures stem from dataset artifacts or model limitations
- Reveals systematic reliability profiles of different modalities across emotion recognition benchmarks

## Why This Works (Mechanism)
The mechanism works by treating each modality as an autonomous reasoning agent with its own confidence assessment. When a modality produces a high-confidence prediction that is incorrect, this "sabotage" effect can override the combined evidence from other modalities, even when they are collectively more reliable. The framework captures this dynamic by allowing each modality to self-assess its reliability and then aggregating these assessments in a way that can identify when one modality's overconfidence is drowning out more nuanced, but collectively stronger, evidence from other sources.

## Foundational Learning

**Modality Sabotage** - When a single high-confidence unimodal error overrides correct predictions from other modalities
*Why needed:* Understanding how individual modalities can dominate collective reasoning
*Quick check:* Identify cases where confident wrong predictions from one modality override correct but less confident predictions from others

**Agent-based Multimodal Fusion** - Treating each modality as an autonomous reasoning agent with confidence scores
*Why needed:* Enables granular analysis of how individual modalities contribute to or detract from final predictions
*Quick check:* Verify each modality can produce both predictions and self-assessed confidence measures

**Contributor vs Saboteur Classification** - Categorizing modalities based on whether they support correct or incorrect outcomes
*Why needed:* Provides diagnostic clarity about which modalities are reliable versus problematic
*Quick check:* Label each modality as contributor or saboteur for each prediction instance

## Architecture Onboarding

Component map: Text Modality -> Confidence Score -> Fusion Layer -> Final Prediction; Audio Modality -> Confidence Score -> Fusion Layer -> Final Prediction; Vision Modality -> Confidence Score -> Fusion Layer -> Final Prediction

Critical path: Each unimodal model generates prediction + confidence → Self-assessment aggregation → Contributor/saboteur classification → Final prediction via fusion mechanism

Design tradeoffs: Simple fusion maintains interpretability and diagnostic capability vs. complex attention-based methods that might capture richer interactions but obscure failure modes

Failure signatures: High-confidence unimodal errors overriding collective evidence, systematic patterns of certain modalities acting as consistent saboteurs, cases where confidence scores misalign with actual prediction quality

First experiments: 1) Run unimodal models on test set to establish baseline predictions and confidences; 2) Apply fusion mechanism to identify contributor/saboteur patterns; 3) Compare top-1 vs top-k accuracy to measure coverage improvements

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Generalizability beyond emotion recognition tasks remains unexplored
- Assumes confidence scores reliably indicate true predictive quality, which may not hold with miscalibrated models
- Simple fusion mechanism may not capture complex interactions that more sophisticated approaches could reveal

## Confidence
High confidence in core finding that high-confidence unimodal errors can override other evidence (demonstrated on established benchmarks)
Medium confidence in framework's ability to diagnose model versus dataset limitations (relies on assumptions about "correct" modality contributions)
Medium confidence that approach provides actionable insights for improving multimodal systems (demonstrates diagnostic capability but not direct performance improvements)

## Next Checks
1. Apply the modality sabotage framework to multimodal reasoning tasks outside emotion recognition, such as visual question answering or multimodal entailment, to test generalizability
2. Conduct controlled experiments where modality confidence scores are systematically manipulated to verify whether the sabotage phenomenon persists under different calibration conditions
3. Compare the simple fusion mechanism against more sophisticated multimodal fusion approaches to determine whether observed sabotage effects are amplified, reduced, or fundamentally altered by more complex integration strategies