---
ver: rpa2
title: Continually Evolving Skill Knowledge in Vision Language Action Model
arxiv_id: '2511.18085'
source_url: https://arxiv.org/abs/2511.18085
tags:
- knowledge
- task
- learning
- arxiv
- skill
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of continual skill learning in
  vision-language-action (VLA) models, which struggle to retain and adapt knowledge
  across diverse manipulation tasks. To overcome this, the authors propose Stellar
  VLA, a knowledge-driven continual learning framework with two variants: T-Stellar,
  which models task-centric knowledge spaces, and TS-Stellar, which additionally captures
  hierarchical task-skill structures.'
---

# Continually Evolving Skill Knowledge in Vision Language Action Model

## Quick Facts
- arXiv ID: 2511.18085
- Source URL: https://arxiv.org/abs/2511.18085
- Reference count: 40
- Primary result: Stellar VLA achieves over 50% average improvement in final success rates compared to baselines

## Executive Summary
This paper addresses the critical challenge of continual skill learning in vision-language-action (VLA) models, which typically struggle to retain and adapt knowledge across diverse manipulation tasks. The authors propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, which models task-centric knowledge spaces, and TS-Stellar, which additionally captures hierarchical task-skill structures. The framework uses a Dirichlet Process-based knowledge space that evolves self-supervised through joint learning of task representations and the knowledge space. This enables the model to dynamically discover and preserve task knowledge while reducing annotation needs. Knowledge-guided expert routing allows task specialization without extra network parameters, balancing parameter sharing and isolation. Experiments on the LIBERO benchmark and real-world tasks demonstrate significant performance improvements, with TS-Stellar excelling in complex action inference.

## Method Summary
The Stellar VLA framework addresses continual skill learning through a knowledge-driven approach that combines task-centric knowledge spaces with hierarchical task-skill structures. The method employs a Dirichlet Process-based knowledge space that evolves self-supervised through joint learning of task representations and the knowledge space itself. This allows the model to dynamically discover and preserve task knowledge while minimizing annotation requirements. Knowledge-guided expert routing enables task specialization without additional network parameters, achieving a balance between parameter sharing and isolation. The framework includes two variants: T-Stellar, which focuses on task-centric knowledge modeling, and TS-Stellar, which additionally captures hierarchical task-skill relationships. The approach is evaluated on the LIBERO benchmark and real-world robotic manipulation tasks, demonstrating significant improvements in success rates compared to baseline methods.

## Key Results
- Stellar VLA achieves over 50% average improvement in final success rates compared to baselines
- TS-Stellar variant excels in complex action inference tasks
- The framework demonstrates effective knowledge retention and discovery capabilities
- Real-world task evaluations validate the practical applicability of the approach

## Why This Works (Mechanism)
The Stellar VLA framework works by creating a dynamic knowledge space that evolves alongside task learning, rather than relying on static knowledge representations. The Dirichlet Process-based knowledge space allows for flexible adaptation to new tasks while preserving existing knowledge through a probabilistic framework that can accommodate uncertainty. The self-supervised evolution of the knowledge space through joint learning reduces dependency on extensive annotations, making the system more scalable. Knowledge-guided expert routing enables specialized processing for different task types while maintaining parameter efficiency through selective sharing. The hierarchical structure in TS-Stellar captures relationships between tasks and skills, allowing for more effective knowledge transfer and inference in complex scenarios.

## Foundational Learning

**Dirichlet Process-based Knowledge Space**: A probabilistic framework for modeling knowledge distributions that can grow and adapt dynamically as new tasks are encountered. Why needed: Traditional static knowledge representations cannot effectively handle the evolving nature of continual learning. Quick check: Verify the DP can correctly model multimodal task distributions and adapt to new modes.

**Self-supervised Knowledge Evolution**: The process of jointly learning task representations and knowledge space without requiring extensive external annotations. Why needed: Annotation requirements become prohibitive in continual learning scenarios with many tasks. Quick check: Confirm that knowledge space quality improves over time without additional supervision.

**Knowledge-guided Expert Routing**: A mechanism for directing inputs to specialized processing paths based on learned knowledge representations. Why needed: Different tasks may require different processing strategies, but maintaining separate networks is inefficient. Quick check: Validate that routing decisions align with task characteristics and improve performance.

**Hierarchical Task-Skill Structures**: A representation framework that captures relationships between tasks and the skills they require. Why needed: Many manipulation tasks share underlying skills, and leveraging these relationships improves learning efficiency. Quick check: Ensure the hierarchy correctly reflects task similarities and enables effective knowledge transfer.

**Joint Representation Learning**: The simultaneous learning of task representations and knowledge space structure. Why needed: Isolated learning of representations and knowledge space leads to suboptimal performance. Quick check: Verify that joint optimization improves both representation quality and knowledge space coherence.

## Architecture Onboarding

Component map: Input Vision/Language/Action -> Task Representation Encoder -> Knowledge Space Module -> Expert Routing -> Task-specific Experts -> Output Action Prediction

Critical path: The primary inference flow involves encoding multimodal inputs into task representations, querying the knowledge space to determine appropriate routing, and then processing through specialized experts for final action prediction. The knowledge space serves as the central hub that enables continual adaptation and knowledge preservation.

Design tradeoffs: The framework balances parameter sharing (through the shared knowledge space and routing mechanism) against isolation (through task-specific experts). This tradeoff enables efficient use of parameters while maintaining task specialization. The choice of Dirichlet Process allows for flexible knowledge space growth but may introduce computational overhead.

Failure signatures: Potential failures include knowledge space collapse (where the DP becomes too concentrated), routing errors (where inputs are directed to inappropriate experts), and catastrophic forgetting (where new tasks overwrite knowledge of previous tasks). Performance degradation on previously learned tasks is a key indicator of these issues.

Three first experiments: 1) Evaluate knowledge space evolution over time to verify adaptive capabilities. 2) Test routing accuracy across diverse task types to ensure proper expert selection. 3) Measure performance retention on earlier tasks after learning new tasks to validate knowledge preservation.

## Open Questions the Paper Calls Out
None

## Limitations

The paper lacks statistical significance testing and confidence intervals for the claimed 50% improvement, making it difficult to assess the robustness of performance gains. The evaluation scope is limited to the LIBERO benchmark and a small set of real-world tasks, raising questions about generalizability to more diverse robotic manipulation scenarios. The scalability of the Dirichlet Process-based knowledge space to extremely large numbers of tasks or skills is not demonstrated, and the computational overhead of the knowledge-guided expert routing mechanism during inference is not discussed.

## Confidence

High confidence in the novel architecture design combining task-centric knowledge spaces with hierarchical task-skill structures
Medium confidence in the claimed performance improvements, pending statistical validation
Low confidence in the scalability claims due to limited evaluation scope and lack of stress testing with large-scale task sets

## Next Checks

1. Conduct statistical significance testing with confidence intervals for the claimed 50% improvement across all benchmark tasks to validate the robustness of performance gains

2. Perform stress testing with an expanded set of 100+ diverse manipulation tasks to evaluate the scalability and performance degradation patterns of the Dirichlet Process-based knowledge space

3. Implement ablation studies comparing annotation requirements and computational overhead between Stellar VLA and baseline methods to quantify the claimed reduction in annotation needs and inference efficiency