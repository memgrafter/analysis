---
ver: rpa2
title: How to inject knowledge efficiently? Knowledge Infusion Scaling Law for Pre-training
  Large Language Models
arxiv_id: '2509.19371'
source_url: https://arxiv.org/abs/2509.19371
tags:
- knowledge
- subject
- object
- infusion
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of optimizing domain knowledge
  infusion during large language model pretraining. The authors systematically vary
  knowledge injection frequency, model scale (137M-3B parameters), and training tokens
  (up to 100B) to investigate memorization dynamics.
---

# How to inject knowledge efficiently? Knowledge Infusion Scaling Law for Pre-training Large Language Models

## Quick Facts
- arXiv ID: 2509.19371
- Source URL: https://arxiv.org/abs/2509.19371
- Reference count: 25
- Key outcome: Identifies a "Memory Collapse Phenomenon" where excessive knowledge injection degrades retention, and proposes a scaling law predicting optimal infusion frequency based on model size and training tokens.

## Executive Summary
This paper addresses the challenge of optimizing domain knowledge infusion during large language model pretraining. The authors systematically vary knowledge injection frequency, model scale (137M-3B parameters), and training tokens (up to 100B) to investigate memorization dynamics. They identify a "Memory Collapse Phenomenon" where excessive knowledge injection beyond a model-specific threshold degrades retention performance. Building on this insight, they propose a Knowledge Infusion Scaling Law that predicts optimal infusion frequency based on model size and training token budget. The law is validated through extensive experiments showing that larger models reach collapse points earlier and require proportionally less infusion. The work provides actionable guidelines for efficient domain-specialized LLM development while avoiding overfitting and catastrophic forgetting.

## Method Summary
The authors inject 28,108 Wikidata triples into FineWeb-Edu corpus using templated natural language sentences at controlled frequencies. They train Llama2-style models (137M-3B params) from scratch on 58B-100B tokens while varying injection frequencies. Performance is measured via Perplexity-based multiple-choice evaluation to calculate Memorization Rate. The data is filtered to remove any paragraphs containing evaluation triples, and knowledge is inserted randomly into the corpus. The method fits two key functions: P(F) = a·F^b · exp(-c·F) to model knowledge retention dynamics, and F(C) = A/C^α + E to predict optimal frequency based on compute budget.

## Key Results
- Knowledge retention follows a non-monotonic curve with a predictable collapse point, not linear improvement
- Larger models achieve knowledge saturation at lower infusion frequencies, requiring proportionally less repetition
- The Knowledge Infusion Scaling Law accurately predicts optimal infusion frequency across different model scales and training token budgets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge retention follows a non-monotonic curve with a predictable collapse point, not linear improvement.
- Mechanism: The proposed function P(F) = a·F^b · exp(-c·F) captures two competing dynamics: the F^b term models knowledge accumulation through repeated exposure (power-law improvement), while exp(-c·F) models performance degradation from over-saturation. The derivative peaks at F' = b/c, which analytically identifies the optimal infusion frequency.
- Core assumption: Knowledge acquisition and "collapse" dynamics transfer predictably across model scales, allowing small-model experiments to predict large-model optima.
- Evidence anchors:
  - [abstract] "each model exhibits a threshold beyond which its knowledge retention capabilities sharply degrade"
  - [Section 3.2] "This adverse effect is modeled by the exponential decay term exp(-c·F), which captures the decline in performance once a critical threshold is exceeded"
  - [corpus] Limited direct validation; related work on data scaling laws (e.g., "Perplexity-Aware Data Scaling Law") addresses data quantity but not the specific collapse phenomenon
- Break condition: If the knowledge being infused has significant overlap with general pretraining corpus (leakage), or if evaluation uses out-of-distribution query formats, the predicted collapse point may not hold.

### Mechanism 2
- Claim: Larger models achieve knowledge saturation at lower infusion frequencies, requiring proportionally less repetition.
- Mechanism: Model parameter count N scales with memorization capacity. Larger models encode knowledge more efficiently per exposure, reaching optimal retention with fewer repetitions. The scaling law F(C) = A/C^α + E (where C = 6ND compute) predicts this inverse relationship.
- Core assumption: The relationship between compute budget and optimal infusion frequency follows a power law similar to Chinchilla scaling, which may not hold for architectures beyond standard Transformers.
- Evidence anchors:
  - [abstract] "larger models reach collapse points earlier and require proportionally less infusion"
  - [Section 3.1] "Larger models reach their collapse point earlier (i.e., at lower injection frequencies)"
  - [corpus] Not directly validated in neighbor literature; concurrent work on scaling behaviors focuses on loss/perplexity rather than knowledge memorization dynamics
- Break condition: Architectures with different parameter efficiency (e.g., Mixture-of-Experts, sparse models) may exhibit different saturation dynamics since effective capacity differs from nominal parameter count.

### Mechanism 3
- Claim: Optimal infusion frequency scales predictably with both model size and training token budget.
- Mechanism: Larger training corpora dilute infused knowledge across more tokens, requiring higher infusion frequencies to maintain equivalent exposure. The collapse point shifts right as token budget increases, following a predictable pattern.
- Core assumption: Knowledge retention depends on relative frequency within the corpus, not absolute repetition count alone.
- Evidence anchors:
  - [Section 3.3] "Larger corpora exhibit collapse points shift to higher injection frequencies compared to smaller counterparts"
  - [Section 4.4] "increasing the infusion frequency becomes necessary to counteract knowledge dilution as training tokens scale"
  - [corpus] Weak external validation; continual pre-training literature discusses data scaling but focuses on perplexity/loss rather than memorization-specific thresholds
- Break condition: If the base corpus has highly non-uniform token distributions (some domains vastly overrepresented), the effective dilution may differ from predictions.

## Foundational Learning

- Concept: **Catastrophic Forgetting**
  - Why needed here: The memory collapse phenomenon is framed as a form of forgetting—over-infusion degrades retention of the very knowledge being injected. Understanding that neural networks can unlearn or overwrite knowledge with excessive exposure is essential.
  - Quick check question: When a model trained on task A is then trained on task B, why might performance on A degrade?

- Concept: **Power-Law Scaling**
  - Why needed here: The paper's scaling law builds directly on Kaplan/Chinchilla traditions. The proposed F(C) = A/C^α + E mirrors the power-law form used for predicting optimal compute allocation.
  - Quick check question: In Chinchilla scaling, what two variables determine optimal loss, and what is their relationship?

- Concept: **Perplexity-Based Evaluation**
  - Why needed here: The evaluation pipeline converts knowledge triples to multiple-choice questions and uses perplexity to rank options. Lower perplexity indicates higher model confidence in an answer.
  - Quick check question: If a model assigns perplexities [45.2, 52.1, 48.3, 51.0] to four answer options, which does it prefer?

## Architecture Onboarding

- Component map:
Raw Corpus (FineWeb-Edu)
    ↓ [Entity filtering - remove paragraphs containing evaluation triples]
Filtered Corpus (58B/75B/100B tokens)
    ↓ [Knowledge injection - insert templated triples at controlled frequency F]
Infused Corpus
    ↓ [Standard Llama2-style Transformer pretraining]
Pretrained Model
    ↓ [PPL-based multiple-choice evaluation]
Memorization Rate (MR)

- Critical path: The filtering step is crucial—if evaluation knowledge leaks into the base corpus, frequency effects are confounded. The paper uses lexical matching to remove any paragraph containing (subject, relation, object) words concurrently.

- Design tradeoffs:
  - Single template vs. diverse templates: Experiments show minimal difference for models ≥377M parameters; single template suffices for efficiency
  - Coarse vs. fine frequency sweep: The paper uses {10, 100, 200, 500, 1000, 10000} initially, then finer resolution near collapse points to fit curves accurately
  - Compute budget: Even 137M models require substantial GPU hours; the approach trades small-model experiments to avoid large-model trial-and-error

- Failure signatures:
  - Retention performance declining with increased infusion frequency (indicates past collapse point)
  - High variance in retention across different relation types (suggests template or knowledge format issues)
  - Evaluation accuracy near random baseline (25% for 4-choice) suggests knowledge not encoded or query format mismatch

- First 3 experiments:
  1. **Pilot sweep on smallest model (137M)**: Train with frequencies {10, 100, 500, 1000, 5000} on filtered 58B corpus; plot retention curve to verify collapse phenomenon appears
  2. **Fit P(F) and locate optimum**: Using pilot data, fit P(F) = a·F^b · exp(-c·F) via L-BFGS-B; verify R² > 0.9 and identify F' = b/c
  3. **Cross-scale validation**: Repeat experiment at 300M and 562M with only {F'/2, F', 2F'} to confirm predicted optimal frequency shifts inversely with model size (requires fewer training runs than full sweep)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Knowledge Infusion Scaling Law maintain predictive accuracy for models significantly larger than 3B parameters?
- Basis in paper: [explicit] The authors state in the Limitations section that computational constraints restricted experiments to models up to 3B parameters and regard the exploration of larger scales as future work.
- Why unresolved: It is uncertain if the observed inverse correlation between model size and optimal infusion frequency follows a consistent power law at massive scales (e.g., 70B+ parameters) or if emergent capabilities alter the collapse dynamics.
- What evidence would resolve it: Validation experiments conducted on larger model architectures (e.g., 7B to 70B parameters) comparing the collapse points predicted by the law against actual pre-training outcomes.

### Open Question 2
- Question: Can the proposed scaling framework be generalized to multi-modal knowledge infusion scenarios?
- Basis in paper: [explicit] The Conclusion explicitly outlines plans to "extend our framework to larger-scale modal knowledge infusion scenarios" in future research.
- Why unresolved: The current law is derived strictly from text-based factual triples; visual or auditory knowledge may exhibit different saturation points or retention dynamics compared to textual data.
- What evidence would resolve it: Experiments applying the infusion scaling law to image-text or video-text pre-training tasks to verify if a "Memory Collapse" occurs and if the current parametric form (P(F) = a·F^b · exp(-c·F)) fits multi-modal data.

### Open Question 3
- Question: How do semantically equivalent paraphrases, which survive lexical filtering, influence the precise onset of memory collapse?
- Basis in paper: [inferred] The Limitations section notes that the filtering method fails to address "semantically equivalent paraphrases" that implicitly reinforce knowledge, potentially altering the effective injection frequency.
- Why unresolved: The current model assumes injection frequency is defined by explicit template repetitions, but implicit reinforcement from paraphrases in the base corpus might cause the model to reach the collapse threshold earlier than predicted.
- What evidence would resolve it: A comparative study using semantic deduplication tools to remove paraphrastic interference from the pre-training corpus, followed by an analysis of any shifts in the collapse point compared to the lexically filtered baseline.

## Limitations

- The filtering strategy for preventing data leakage relies on strict lexical matching, which may not generalize to noisy or multi-lingual corpora where entity mentions vary significantly in surface form.
- The knowledge triples used (Wikidata facts) represent structured factual knowledge but may not capture the complexity of domain-specific concepts in specialized fields like medicine or law.
- The single-template approach for knowledge injection may not capture the full diversity of natural language expressions needed for robust generalization.

## Confidence

**High confidence** in the empirical observation of the collapse phenomenon and the validity of the proposed P(F) = a·F^b · exp(-c·F) functional form for modeling knowledge retention. The experimental design is rigorous, with systematic variation across model scales and training budgets, and the predicted optimal frequencies are validated through targeted experiments.

**Medium confidence** in the scaling law's predictive power across diverse model architectures and knowledge domains. While the law is validated within the Llama2-style Transformer framework, its applicability to sparse architectures, Mixture-of-Experts models, or knowledge requiring deeper reasoning remains uncertain.

**Low confidence** in real-world applicability without further validation. The paper demonstrates the phenomenon in controlled settings but doesn't address challenges like noisy corpora, partial knowledge overlap with pretraining data, or evaluation metrics beyond factual memorization.

## Next Checks

1. **Architecture Transfer Test**: Validate the scaling law on a different architecture family (e.g., sparse MoE models or convolutional architectures) to test whether the inverse relationship between model size and optimal infusion frequency holds across architectural paradigms.

2. **Domain Generalization Test**: Apply the methodology to a specialized domain corpus (e.g., biomedical literature or legal documents) with domain-specific knowledge triples to verify whether the collapse phenomenon and optimal frequency predictions transfer beyond general knowledge.

3. **Template Diversity Test**: Systematically vary the number and diversity of templates used for knowledge injection while keeping model size and training budget constant to quantify the trade-off between template diversity and knowledge retention, particularly for larger models where the paper claims minimal impact.