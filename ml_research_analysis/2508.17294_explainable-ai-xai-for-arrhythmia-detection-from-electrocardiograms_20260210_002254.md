---
ver: rpa2
title: Explainable AI (XAI) for Arrhythmia detection from electrocardiograms
arxiv_id: '2508.17294'
source_url: https://arxiv.org/abs/2508.17294
tags:
- arrhythmia
- dataset
- figure
- detection
- beat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates explainable AI (XAI) methods for arrhythmia
  detection from electrocardiogram (ECG) signals using deep learning. A convolutional
  neural network was developed for arrhythmia classification using R-peak-based segmentation
  via the Pan-Tompkins algorithm on the MIT-BIH dataset.
---

# Explainable AI (XAI) for Arrhythmia detection from electrocardiograms

## Quick Facts
- arXiv ID: 2508.17294
- Source URL: https://arxiv.org/abs/2508.17294
- Authors: Joschka Beck; Arlene John
- Reference count: 29
- Primary result: CNN achieved 98.3% validation accuracy on MIT-BIH dataset for arrhythmia detection, with saliency maps preferred by clinicians over counterfactual explanations

## Executive Summary
This study develops and evaluates explainable AI methods for arrhythmia detection using deep learning on electrocardiogram signals. A convolutional neural network was trained on R-peak-based segmentation of ECG data from the MIT-BIH dataset, achieving 98.3% validation accuracy. The research compares four SHAP-based XAI approaches and finds that gradient-based methods and DeepLIFT produce more clinically interpretable saliency maps than permutation importance or KernelSHAP. Medical professionals showed a clear preference for saliency map-based explanations over counterfactual visualizations, highlighting the importance of domain-specific XAI adaptations.

## Method Summary
The researchers developed a CNN architecture for arrhythmia classification using R-peak-based segmentation via the Pan-Tompkins algorithm on the MIT-BIH dataset. To address class imbalance, an additional 12-lead ECG dataset was incorporated. Four SHAP-based XAI methods were implemented and compared: permutation importance, KernelSHAP, gradient-based methods, and DeepLIFT. The model was evaluated on both the original MIT-BIH dataset and a combined dataset with the additional 12-lead ECG data. Medical professionals were consulted to assess the interpretability and clinical utility of different XAI visualizations.

## Key Results
- CNN achieved 98.3% validation accuracy on MIT-BIH dataset
- Model performance degraded significantly when applied to combined dataset
- Medical professionals preferred saliency map-based explanations over counterfactual visualizations
- Gradient-based SHAP methods and DeepLIFT highlighted waveform regions consistent with clinical reasoning
- Permutation importance and KernelSHAP produced cluttered, less interpretable outputs

## Why This Works (Mechanism)
The CNN architecture effectively captures temporal patterns in ECG signals through convolutional layers that identify characteristic waveform features. R-peak-based segmentation ensures consistent temporal alignment of cardiac cycles, allowing the model to learn arrhythmia-specific patterns. The SHAP-based XAI methods provide attribution scores that highlight which regions of the ECG waveform contribute most to classification decisions, with gradient-based approaches and DeepLIFT being particularly effective at identifying clinically relevant features.

## Foundational Learning
- R-peak detection (Pan-Tompkins algorithm): Essential for accurate segmentation of ECG signals into individual cardiac cycles
- CNN architecture for time-series data: Convolutional layers can learn hierarchical features from sequential ECG waveforms
- SHAP (SHapley Additive exPlanations): Provides theoretically grounded feature attribution by considering all possible feature combinations
- Gradient-based attribution methods: Efficiently compute feature importance by backpropagating gradients through the network
- DeepLIFT (Deep Learning Important FeaTures): Compares activation of each neuron to a reference activation to compute contribution scores
- Counterfactual explanations: Generate alternative scenarios to understand what changes would alter model predictions

## Architecture Onboarding

Component Map:
ECG signal -> R-peak detection -> Segmentation -> CNN feature extraction -> Classification -> SHAP attribution -> Saliency visualization

Critical Path:
R-peak detection → Segmentation → CNN feature extraction → Classification → SHAP attribution → Clinical validation

Design Tradeoffs:
- Model complexity vs. interpretability: Complex CNN provides high accuracy but requires XAI methods for clinical adoption
- Dataset size vs. generalization: MIT-BIH provides good performance but limited generalizability to combined datasets
- Explanation type vs. clinical utility: Saliency maps preferred over counterfactuals despite potentially providing less detailed reasoning

Failure Signatures:
- Performance degradation on combined datasets suggests overfitting to MIT-BIH characteristics
- Cluttered SHAP outputs indicate model may be relying on spurious correlations rather than clinically meaningful features
- Preference for saliency maps suggests counterfactual explanations may not align with clinical reasoning patterns

First Experiments:
1. Compare model performance across different arrhythmia types to identify specific failure modes
2. Evaluate SHAP-based explanations on synthetic ECG data with known features to validate attribution accuracy
3. Test model robustness to noise and signal quality variations common in clinical settings

## Open Questions the Paper Calls Out
The paper does not explicitly call out additional open questions beyond those already addressed in the main findings.

## Limitations
- Significant performance degradation when applied to combined datasets raises concerns about generalizability
- Preference for saliency maps based on qualitative feedback without detailed methodology for professional selection or sample size
- Lack of detailed implementation specifications for SHAP methods limits reproducibility
- No assessment of model performance across different ECG recording qualities or patient populations

## Confidence
- High confidence in model performance on MIT-BIH dataset (98.3% accuracy)
- Medium confidence in generalizability to combined datasets due to observed performance degradation
- Low confidence in generalizability of preference for saliency maps without broader validation

## Next Checks
1. Conduct larger-scale study with diverse medical professionals to validate saliency map preference
2. Fine-tune model on combined dataset and assess robustness across ECG signal variations
3. Provide detailed documentation of SHAP method implementations and parameter settings for reproducibility