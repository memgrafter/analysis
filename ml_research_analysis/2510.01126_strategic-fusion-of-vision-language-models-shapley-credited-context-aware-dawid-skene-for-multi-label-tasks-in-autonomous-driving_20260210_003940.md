---
ver: rpa2
title: 'Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware
  Dawid-Skene for Multi-Label Tasks in Autonomous Driving'
arxiv_id: '2510.01126'
source_url: https://arxiv.org/abs/2510.01126
tags:
- driving
- language
- arxiv
- large
- vlms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a game-theoretic fusion method for multi-label
  understanding of ego-view dashcam video in autonomous driving. The method, Shapley-credited
  Context-Aware Dawid-Skene with Agreement, learns per-model, per-label, context-conditioned
  reliabilities from historical data and aggregates model reports using agreement-weighted
  log-likelihood ratios, contextual priors, and a public reputation state updated
  via Shapley-based team credit.
---

# Strategic Fusion of Vision Language Models: Shapley-Credited Context-Aware Dawid-Skene for Multi-Label Tasks in Autonomous Driving

## Quick Facts
- **arXiv ID**: 2510.01126
- **Source URL**: https://arxiv.org/abs/2510.01126
- **Reference count**: 40
- **Primary result**: 47% Micro-F1 on HDD multi-label manoeuvre classification using Shapley-credited ensemble of three VLMs

## Executive Summary
This paper presents a game-theoretic fusion framework for multi-label video understanding in autonomous driving, specifically designed to aggregate outputs from heterogeneous vision-language models (VLMs). The method, Shapley-credited Context-Aware Dawid-Skene with Agreement, dynamically estimates per-model, per-label reliabilities conditioned on visual context and updates reputations using Shapley values derived from historical marginal contributions. Empirically, this approach achieves a 47% Micro-F1 on the Honda HRI Driving Dataset, significantly outperforming static weighting baselines.

## Method Summary
The framework fuses three fine-tuned VLMs (VLAAD, VideoLLaMA2, VideoLLaVA) on ego-view dashcam video for multi-label classification of driving manoeuvres. Each VLM is fine-tuned using LoRA on 1,000 real-world clips with structured annotations (scene description, manoeuvre recommendation, rationale) generated via a three-step LLaMA-3.2 Chain-of-Thought pipeline. At runtime, the system estimates context-aware reliabilities using kernel-weighted Beta-Bernoulli pooling over CLIP embeddings of labeled neighbors, applies correlation guardrails to mitigate double-counting of shared errors, and updates model reputations via Shapley-based credit attribution. The final prediction is an agreement-weighted log-likelihood ratio aggregation.

## Key Results
- 47% Micro-F1 on HDD test split, outperforming static weighting baselines
- Ablation shows correlation guardrails are critical (Micro-F1 drops to 0.16 when disabled)
- Context-aware reliability estimation improves rare label performance
- Shapley-based reputation updates necessary (performance collapses to 0.05 Micro-F1 with naive scoring)

## Why This Works (Mechanism)

### Mechanism 1: Shapley-based team credit
Weighted voting based on marginal contributions prevents a single hallucinating model from dominating. The system calculates Shapley values per round based on each model's marginal contribution to the team's log-score, dynamically filtering out low-utility signals.

### Mechanism 2: Correlation guardrails
Prevents "double-counting" errors where multiple models share the same bias. When models agree on a label, their log-likelihood ratios are downscaled by a factor dependent on pairwise error correlations, forcing the aggregation to value independent confirmation.

### Mechanism 3: Context-aware reliability estimation
Allows the system to switch authority between models based on specific driving scenarios. The system computes kernel-weighted similarity to find nearest labeled contexts and estimates per-model, per-label reliability specifically for that context, allowing specialized performance to be leveraged.

## Foundational Learning

- **Concept: Dawid-Skene Aggregation**
  - **Why needed here:** Extends the classic algorithm for crowd-sourcing to estimate a "true label" from noisy, dependent VLM annotators
  - **Quick check question:** How does the system estimate the probability of a label being true if VLMs have varying, unknown error rates and dependencies?

- **Concept: Shapley Values (Game Theory)**
  - **Why needed here:** Fairly distributes "credit" for correct predictions among ensemble members by measuring marginal utility
  - **Quick check question:** In a coalition of 3 models where A and B always agree and are correct, while C only corrects them when they fail, which model has the higher Shapley value?

- **Concept: LoRA (Low-Rank Adaptation)**
  - **Why needed here:** Adapts general VLMs to driving domain while preserving pretrained knowledge
  - **Quick check question:** Why does updating low-rank matrices $A$ and $B$ (where $\Delta W = AB$) preserve the general knowledge of the pretrained VLM while fitting the driving domain?

## Architecture Onboarding

- **Component map:**
  1. **Annotation Pipeline (Offline):** YOLOv11/BoT-SORT (tracking) + HDD Ground Truth + LLaMA-3.2 CoT (label synthesis)
  2. **Specialist Training (Offline):** Three VLMs fine-tuned via LoRA using generated labels
  3. **Runtime Fusion Service (Flask):**
     - *Context Encoder:* CLIP embeddings to find nearest labeled neighbors
     - *Reliability Engine:* Computes Beta-Bernoulli parameters ($\theta$) and correlation guardrails ($\rho$)
     - *Game Engine:* Updates Shapley credits and reputation weights ($w_{i,t}$) per batch
     - *Aggregator:* Outputs final calibrated probabilities $q_t(k)$

- **Critical path:** The Shapley-credited reputation update loop, which requires ground-truth data to compute marginal contributions and update model weights.

- **Design tradeoffs:** Trades inference latency for robustness by running three large VLMs in parallel, and relies on a labeled history window for correlation and reliability estimation, creating a tradeoff between adaptability and stability.

- **Failure signatures:**
  1. **Reputation Collapse:** One model achieves $w_{i,t} \approx 1.0$ early, turning the system into a single-model predictor
  2. **Hallucination Resonance:** All three models hallucinate the same object, and the correlation guardrail underestimates correlation

- **First 3 experiments:**
  1. **Static vs. Dynamic Weighting:** Compare Shapley-credited reputation against static "best single model" baseline and simple majority vote
  2. **Correlation Ablation:** Run inference with $\rho_{i,j,k} = 0$ forced to confirm degradation on confusing classes
  3. **Context Window Sensitivity:** Vary the $K$ (nearest neighbors) used in Beta-Bernoulli pooling to determine sensitivity to labeled history bank size

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the framework perform under distribution shift conditions such as nighttime, rain, snow, or unfamiliar road geometries?
- **Basis:** Authors explicitly state plans to "stress-test the method on more challenging and diverse video segments" to probe robustness
- **Why unresolved:** HDD dataset contains San Francisco Bay Area driving which may not capture severe weather or geographically diverse road infrastructure
- **What evidence would resolve it:** Experiments on datasets with adverse weather, nighttime driving, and diverse geographic locations reporting performance degradation rates

### Open Question 2
- **Question:** Can the credit-and-reputation mechanism scale computationally to ensembles of 5, 10, or more VLMs while maintaining real-time inference latency?
- **Basis:** Authors note the design "is tailored to three models" and plan to "scale the credit-and-reputation mechanism to larger ensembles"
- **Why unresolved:** Shapley value computation has exponential complexity O(2^n); kernel-weighted retrieval scales with labeled bank size
- **What evidence would resolve it:** Empirical latency measurements and accuracy metrics for ensembles of 5, 7, 10, and 15 VLMs

### Open Question 3
- **Question:** How does the framework perform when label density drops below the 1,000-clip threshold or when ground-truth labels become unavailable for extended sequences?
- **Basis:** Authors acknowledge reliance on "regular ground-truth for updating reputations and correlations" and plan to "reduce reliance on labels via active and semi-supervised updates"
- **Why unresolved:** Context-aware reliability requires sufficient labeled neighbors; reputation updates require ground-truth revelation
- **What evidence would resolve it:** Ablation experiments varying labeled data from 1,000 down to 100 clips; simulations of consecutive unlabelled inference rounds tracking reputation drift

## Limitations
- The framework depends on a labeled history window for context-aware reliability and reputation updates, creating a dependency on ground-truth availability
- Computational overhead increases with ensemble size due to Shapley value calculations and pairwise correlation estimation
- Performance under distribution shift (nighttime, adverse weather, unfamiliar roads) remains untested and may degrade

## Confidence

- **High confidence:** The necessity of the correlation guardrail (proven by ablation showing performance collapse when removed)
- **Medium confidence:** The Shapley-based reputation system's superiority (proven against naive baselines but not more advanced ensembles)
- **Medium confidence:** The context-aware reliability framework (demonstrated to help but untested for out-of-distribution contexts)

## Next Checks

1. **Distribution shift test:** Run the system on a held-out HDD subset with significantly different weather/lighting conditions to measure performance decay and validate whether Shapley credits adapt quickly enough

2. **Guardrail sensitivity analysis:** Systematically vary the correlation threshold parameter to find the optimal balance between penalizing correlated errors and not over-penalizing genuine consensus

3. **Memory bank density mapping:** Analyze the coverage of the CLIP embedding space for the 1,000-clip training set, identifying regions with sparse neighbors and measuring the resulting reliability variance