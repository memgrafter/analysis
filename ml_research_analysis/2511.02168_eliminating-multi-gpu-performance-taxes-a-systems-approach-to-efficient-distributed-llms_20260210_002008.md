---
ver: rpa2
title: 'Eliminating Multi-GPU Performance Taxes: A Systems Approach to Efficient Distributed
  LLMs'
arxiv_id: '2511.02168'
source_url: https://arxiv.org/abs/2511.02168
tags:
- kernel
- data
- distributed
- communication
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the inefficiencies of the bulk synchronous\
  \ parallel (BSP) model in distributed large language model (LLM) workloads. The\
  \ authors introduce the \"Three Taxes\" framework\u2014Kernel Launch Overhead, Bulk\
  \ Synchronous, and Inter-Kernel Data Locality\u2014to characterize performance bottlenecks\
  \ in conventional distributed GPU execution."
---

# Eliminating Multi-GPU Performance Taxes: A Systems Approach to Efficient Distributed LLMs

## Quick Facts
- **arXiv ID:** 2511.02168
- **Source URL:** https://arxiv.org/abs/2511.02168
- **Reference count:** 6
- **One-line result:** Fusing communication and computation into fine-grained GPU kernels eliminates BSP inefficiencies, achieving 10-20% latency improvements in distributed LLM workloads.

## Executive Summary
This paper addresses fundamental inefficiencies in distributed large language model (LLM) execution by identifying three performance bottlenecks in the Bulk Synchronous Parallel (BSP) model: kernel launch overhead, global barrier synchronization, and inter-kernel data locality losses. The authors propose fusing computation and communication into single fine-grained GPU kernels using the Iris library for Triton, enabling direct tile-level producer-consumer pipelines and fine-grained dataflow synchronization. Experimental results on All-Gather + GEMM and Flash Decode kernels demonstrate 10-20% end-to-end latency improvements over BSP-based RCCL baselines, with strong scaling from 1 to 8 GPUs.

## Method Summary
The authors implement fine-grained fusion of communication and computation using the Iris library, which extends Triton with cross-GPU addressing primitives. They develop two execution patterns: "Pull" (consumer-initiated remote loads) and "Push" (producer-initiated remote stores with fine-grained synchronization flags). The approach is evaluated on All-Gather + GEMM benchmarks with varying matrix dimensions and Flash Decode kernels for inference workloads. The implementation targets AMD MI300X/MI325X hardware with ROCm 6.4.3 and RCCL 2.22.3, comparing fused kernels against standard BSP-based implementations using `torch.matmul` and RCCL collectives.

## Key Results
- **10-20% latency improvement** over BSP-based RCCL baselines for All-Gather + GEMM and Flash Decode kernels
- **Strong scaling** demonstrated from 1 to 8 GPUs with consistent performance gains
- **Fine-grained synchronization** enables immediate processing of arriving data tiles, reducing idle time at global barriers
- **Pull model** optimal for small matrices (M<128), **Push model** superior for larger workloads (M>128)

## Why This Works (Mechanism)

### Mechanism 1: Kernel Launch Overhead Elimination
Fusing communication into compute kernels eliminates multiple host-side dispatches. Standard BSP issues separate launches for compute and collectives, each incurring fixed driver latency. By embedding communication primitives directly in the compute kernel via Iris, dispatch cost is paid once per iteration rather than multiple times.

### Mechanism 2: Fine-Grained Dataflow Synchronization
Global barriers force all GPUs to wait for the slowest GPU before proceeding. Fine-grained waits allow consumer kernels to begin processing tiles immediately upon arrival, overlapping computation with ongoing communication. This converts serial wait time into productive work.

### Mechanism 3: Tile-Level Data Locality Preservation
Separate kernels force intermediate results from fast on-chip SRAM/cache to be spilled to slow HBM, then reloaded by the next kernel. Fused kernels pass tiles directly through shared memory or register files, avoiding the round-trip bandwidth and latency penalty.

## Foundational Learning

- **Concept:** Bulk Synchronous Parallel (BSP) Model
  - Why needed here: The paper's entire contribution characterizes BSP's inefficiencies and proposes alternatives. Understanding BSP is prerequisite to understanding what's being eliminated.
  - Quick check question: In the BSP "Compute-Wait-Collective-Wait-Compute" pattern, when can GPU 2 begin its collective operation if GPU 1 hasn't finished computing?

- **Concept:** GPU Memory Hierarchy (SRAM/Cache vs HBM)
  - Why needed here: The Inter-Kernel Tax is fundamentally about data movement between fast on-chip and slow off-chip memory. Without this mental model, the locality optimization is opaque.
  - Quick check question: Why does separating a producer kernel from a consumer kernel force an HBM round-trip even if both kernels run on the same GPU?

- **Concept:** Collective Communication Operations (All-Gather, All-Reduce)
  - Why needed here: The paper's case studies rely on collectives as the synchronization points being fused. You need to know what these operations do to understand the fusion opportunity.
  - Quick check question: In a 4-GPU All-Gather where each GPU holds a different shard, what does each GPU possess after the operation completes?

## Architecture Onboarding

- **Component map:** Iris library -> Triton kernels -> Fine-grained sync flags -> Direct tile-level pipelines
- **Critical path:** For Flash Decode: (1) Local attention compute → (2) Fused push of partial results to remote inboxes → (3) Fine-grained wait + global reduction
- **Design tradeoffs:**
  - Pull vs Push: Pull is simpler but doesn't scale as well; Push requires explicit flag management but achieves higher throughput for M≥128
  - Tile size: Smaller tiles enable finer-grained overlap but increase synchronization overhead
  - Baseline comparison: For M=8-64, `torch.matmul` is highly optimized and outperforms fused kernels; fusion wins at extremes
- **Failure signatures:**
  - Deadlock: If sync flags are not properly initialized in Push model
  - Performance regression: Fused kernels slower than baseline for M=8-64 due to highly optimized vendor GEMM
  - Scaling plateau: For small KV lengths, adding GPUs yields minimal improvement as communication dominates
- **First 3 experiments:**
  1. Reproduce All-Gather + GEMM baseline on 2 GPUs with RCCL + `torch.matmul`, measure latency for M=32, 128, 512
  2. Implement Pull Model using `iris.load()` within Triton GEMM kernel; verify correctness against baseline
  3. Profile with and without fusion to isolate each tax: measure kernel launch overhead, barrier wait time, and HBM traffic

## Open Questions the Paper Calls Out

### Open Question 1
Can the fused GEMM approach be optimized to outperform vendor libraries (`torch.matmul`) for small matrix dimensions (M < 128) where it currently lags?
- Basis: Authors note fused kernels are slower than baseline for M=8-64 and state "we leave further optimization to the GEMM kernel to future work."
- Why unresolved: Baseline's underlying GEMM implementation appears highly optimized for these specific small dimensions
- What evidence would resolve it: Fused kernel benchmarks demonstrating lower latency than `torch.matmul` specifically in the M=8 to M=64 range

### Open Question 2
How does the fine-grained fusion methodology apply to training workloads requiring Reduce-Scatter or All-Reduce collectives?
- Basis: Authors suggest "Training workloads could benefit from fusing Reduce-Scatter or All-Reduce operations directly," but only evaluate inference workloads
- Why unresolved: Efficacy for reduction operations (common in training) versus gathering operations (common in inference) remains uncharacterized
- What evidence would resolve it: Evaluation of fused Reduce-Scatter implementations showing similar latency reductions over standard BSP-based training collectives

### Open Question 3
Does fine-grained dataflow synchronization remain efficient across slower network interconnects (Ethernet/InfiniBand) in multi-node setups?
- Basis: Evaluation restricted to single-node servers using high-bandwidth Infinity Fabric; paper notes distributed execution relies on clusters but doesn't test network-bound scenarios
- Why unresolved: Fine-grained synchronization relies on low-latency communication; higher network latencies could negate gains from eliminating the Bulk Synchronous Tax
- What evidence would resolve it: Benchmarks on multi-node clusters demonstrating 10-20% speedup persists despite network latency

## Limitations

- **Hardware scope:** Results demonstrated only on AMD MI300X/MI325X with ROCm/RCCL, limiting generalizability to NVIDIA or other platforms
- **Training workloads:** Methodology validated only for inference workloads; effectiveness for training with Reduce-Scatter/All-Reduce collectives remains unexplored
- **Small matrix performance:** Fused kernels underperform highly optimized vendor GEMM libraries for M=8-64, requiring further optimization

## Confidence

- **High Confidence:** Identification of "Three Taxes" framework and their characterization as fundamental BSP limitations for LLM workloads
- **Medium Confidence:** Experimental results demonstrating 10-20% latency improvements, though limited hardware scope reduces universal applicability
- **Low Confidence:** Claim of providing a "more programmable" paradigm given complexity of managing fine-grained sync flags and specialized knowledge requirements

## Next Checks

1. **Hardware Portability Test:** Implement and benchmark fused kernels on NVIDIA A100/H100 GPUs using NCCL collectives to verify if "Three Taxes" elimination translates to similar performance gains across different hardware platforms

2. **Scalability Boundary Analysis:** Scale experiments to 32-64 GPUs to identify at what point fine-grained synchronization overhead dominates or network topology becomes limiting factor

3. **Workloads Beyond LLM:** Apply fusion approach to other distributed workloads (scientific computing kernels, recommendation system embeddings) to test whether "Three Taxes" framework and solutions generalize beyond LLM domain