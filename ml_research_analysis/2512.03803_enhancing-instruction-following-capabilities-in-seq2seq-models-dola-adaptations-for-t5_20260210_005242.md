---
ver: rpa2
title: 'Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations
  for T5'
arxiv_id: '2512.03803'
source_url: https://arxiv.org/abs/2512.03803
tags:
- dola
- layers
- steering
- decoder
- instruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work investigates why encoder-decoder models such as FLAN-T5\
  \ often fail to follow instructions when they conflict with memorized training continuations.\
  \ The authors adapt DoLa to FLAN-T5 to study how decoder representations evolve\
  \ with depth and develop a gradient-based activation steering method that injects\
  \ an \u201Cinstruction-compliance\u201D direction into mid-decoder layers."
---

# Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5

## Quick Facts
- arXiv ID: 2512.03803
- Source URL: https://arxiv.org/abs/2512.03803
- Reference count: 40
- Primary result: Activation steering dramatically improves MemoTrap performance (52% to 99.7%) by steering in mid-depth layers where representations are informative but not yet committed

## Executive Summary
This work investigates why encoder-decoder models like FLAN-T5 often fail to follow instructions when they conflict with memorized training continuations. The authors adapt DoLa to FLAN-T5 to study how decoder representations evolve with depth and develop a gradient-based activation steering method that injects an "instruction-compliance" direction into mid-decoder layers. DoLa performs inconsistently across tasks, improving on some instruction types but failing on others due to volatile intermediate token preferences. In contrast, targeted activation steering dramatically improves MemoTrap performance (52% to 99.7%) by steering in mid-depth layers where representations are informative but not yet committed. The findings demonstrate that mechanistic steering succeeds where contrastive decoding fails in Seq2Seq architectures.

## Method Summary
The authors adapt DoLa (contrastive decoding by layers) to FLAN-T5 encoder-decoder models and develop a gradient-based activation steering method. For DoLa, they select a premature decoder layer using Jensen-Shannon divergence between final-layer and intermediate distributions, then adjust logits to promote earlier layer preferences. For activation steering, they compute contrastive loss between instruction-compliant and trap tokens, backpropagate to obtain steering vectors, and inject these into mid-depth decoder layers during inference. The approach targets the specific challenge where instructions conflict with memorized continuations, particularly in proverb completion tasks where models must generate endings that follow instructions rather than default memorized patterns.

## Key Results
- DoLa shows inconsistent performance across IFEval categories: improves Keyword Existence but fails on Start-End tasks due to volatile intermediate token preferences
- Activation steering dramatically improves MemoTrap performance from 52% to 99.7% by steering in mid-depth layers (Small=2, Base=5, Large=10)
- Mid-depth layers represent the "Goldilocks zone" where representations are informative but not yet committed to memorized continuations
- Contrastive decoding fails in Seq2Seq architectures due to non-monotonic probability trajectories across cross-attention layers

## Why This Works (Mechanism)
The paper demonstrates that encoder-decoder models like FLAN-T5 have volatile intermediate token preferences due to cross-attention integration, making contrastive decoding unreliable. Activation steering succeeds by directly modifying hidden states in mid-depth layers where representations capture task-relevant information without being locked into memorized patterns. The steering vector encodes the difference between instruction-compliant and trap tokens, allowing precise control over generation without disrupting fluency.

## Foundational Learning
- **Jensen-Shannon divergence for layer selection**: Measures distributional similarity between layers to identify when decoder transitions from memorization to instruction-following. Quick check: Compute JSD across decoder layers and verify peak indicates premature commitment.
- **Contrastive loss for steering vector mining**: Maximizes probability of instruction-compliant tokens while minimizing trap tokens. Quick check: Verify loss gradient points from trap toward compliant direction.
- **Layer-wise activation injection**: Modifies hidden states at specific decoder depths rather than final logits. Quick check: Plot token probabilities across layers to confirm mid-depth intervention point.
- **Cross-attention layer volatility**: Intermediate layers in T5 show non-monotonic token preferences unlike decoder-only models. Quick check: Visualize token probability trajectories to identify volatile regions.
- **Steering vector normalization**: Scales steering direction by vector norm to maintain consistent magnitude. Quick check: Verify steering vector norms are non-trivial and α scaling appropriate.

## Architecture Onboarding

**Component Map**
FLAN-T5 encoder -> Cross-attention layers -> Decoder stack (even-indexed layers for DoLa) -> LM head -> Output logits

**Critical Path**
Input prompt → Encoder embedding → Cross-attention integration → Mid-decoder layer injection → Steering vector modification → Generation

**Design Tradeoffs**
DoLa trades computational overhead (layer-wise distributions) for potentially unreliable contrastive gains vs. activation steering's direct state modification that requires precise layer identification but provides more reliable control.

**Failure Signatures**
DoLa harms Start-End tasks when premature layer matches final layer preferences; activation steering fails when α too small (no effect) or too large (degraded fluency); both approaches struggle when x⁺/x⁻ identification is ambiguous.

**Three First Experiments**
1. Plot token probability trajectories across decoder layers for MemoTrap examples to identify volatile regions and validate mid-depth "Goldilocks zone"
2. Sweep λ values in DoLa decoding to characterize sensitivity and identify conditions where contrastive decoding helps vs. harms
3. Test steering vector injection at multiple layers to verify performance peaks at specified positions (2, 5, 10) and degrades when applied too early or late

## Open Questions the Paper Calls Out
None

## Limitations
- DoLa adaptation shows highly variable performance across instruction types due to volatile intermediate token preferences in T5's cross-attention layers
- Steering vector methodology depends critically on correct identification of x⁺/x⁻ token pairs, but identification method is not specified
- Gradient computation details for activation steering lack clarity on model mode, gradient requirements, and autoregressive persistence

## Confidence

**High Confidence**
- DoLa's inconsistent performance across IFEval categories is well-supported by reported heterogeneous gains/losses
- Mid-depth layer identification for optimal steering is strongly supported by MemoTrap performance improvement

**Medium Confidence**
- Activation steering's superiority over contrastive decoding in Seq2Seq architectures is reasonable but depends on correct steering vector mining
- Specific layer positions (2, 5, 10) are well-supported but may be model-specific

**Low Confidence**
- Repetition penalty effectiveness (1.2) in DoLa is mentioned but not extensively validated
- Exact mechanism for identifying instruction-compliant vs. trap tokens remains unclear

## Next Checks
1. Validate steering vector mining process by implementing full pipeline to programmatically identify x⁺/x⁻ tokens and verify contrastive effect
2. Test DoLa sensitivity to λ by sweeping 0.1-2.0 and documenting performance variation across IFEval categories
3. Characterize layer-wise token probability trajectories by plotting evolution across all decoder layers for MemoTrap examples to confirm non-monotonic behavior and validate mid-depth intervention point