---
ver: rpa2
title: 'Adversarial-Ensemble Kolmogorov Arnold Networks for Enhancing Indoor Wi-Fi
  Positioning: A Defensive Approach Against Spoofing and Signal Manipulation Attacks'
arxiv_id: '2501.09609'
source_url: https://arxiv.org/abs/2501.09609
tags:
- indoor
- adversarial
- positioning
- ensemble
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the enhancement of Wi-Fi-based indoor positioning
  systems' robustness against adversarial attacks, specifically Wi-Fi spoofing and
  signal strength manipulation. The research introduces a novel approach combining
  adversarial training and ensemble modeling, utilizing Kolmogorov-Arnold Networks
  (KAN) as the underlying architecture.
---

# Adversarial-Ensemble Kolmogorov Arnold Networks for Enhancing Indoor Wi-Fi Positioning: A Defensive Approach Against Spoofing and Signal Manipulation Attacks

## Quick Facts
- arXiv ID: 2501.09609
- Source URL: https://arxiv.org/abs/2501.09609
- Reference count: 40
- Primary result: Ensemble model achieves 2.01m and 1.975m RMSE under adversarial spoofing and signal manipulation attacks

## Executive Summary
This study introduces a novel defense framework for Wi-Fi-based indoor positioning systems using Kolmogorov-Arnold Networks (KAN) with adversarial training and ensemble modeling. The approach addresses two attack types—Wi-Fi spoofing and signal strength manipulation—by training models on adversarially perturbed data and combining predictions from both clean and robust models. The robust model achieves a 10% error reduction compared to baseline under adversarial conditions, while the ensemble model shows the lowest error rates overall. Results demonstrate the effectiveness of integrating adversarial training with ensemble techniques for developing secure and reliable indoor positioning systems.

## Method Summary
The methodology combines three KAN models: a baseline trained on clean data, a robust model trained on clean plus adversarially perturbed data, and an ensemble that weights predictions from both base and robust models. KAN implements the Kolmogorov-Arnold representation theorem with 15 inner MLP functions and tanh-activated outer aggregation. Training uses Huber loss, RMSprop optimizer, and early stopping. Adversarial augmentation employs Gaussian noise injection (ε ~ N(0,σ²I)) for spoofing attacks and element-wise scaling (U(-α,α)) for signal strength manipulation. The ensemble combines models via weighted averaging with λ optimized through grid search on validation data.

## Key Results
- Robust model achieves 10% error reduction (2.07m → 2.03m) under spoofing attacks at ε=0.1
- Ensemble model shows lowest error rates: 2.01m and 1.975m for spoofing and signal manipulation attacks
- KAN architecture outperforms MLP-LSTM (2.5-3.69m) and KNN (3.1-4.64m) baselines
- Marginal ensemble improvement (0.02-0.06m) over robust model alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial training improves model resilience to RSSI perturbations by exposing the model to attack-pattern distributions during training.
- Mechanism: The robust model (M_Rob) trains on an augmented dataset combining clean samples with adversarially perturbed samples. Gaussian noise injection simulates Wi-Fi spoofing (ε ~ N(0, σ²Iₙ)), while element-wise scaling simulates signal strength manipulation (U(-α, α)). This conditions the model to map perturbed inputs to correct coordinates.
- Core assumption: The synthetic perturbation distributions approximate real-world attack patterns and environmental noise.
- Evidence anchors:
  - [abstract] "The robust model is trained with adversarially perturbed data to improve resilience"
  - [section III.A, Algorithm 1] "Generate adversarial samples A = {x'_i} using: Wi-Fi Spoofing: x'_i = x_i + ε, Signal Strength Manipulation: x'_i = x_i ⊙ (1_n + U(-α, α))"
  - [corpus] Weak direct evidence; related work on GAN-augmented fingerprinting (LiGen) suggests data augmentation benefits localization but does not specifically validate KAN-based adversarial training.

### Mechanism 2
- Claim: Ensemble combination of base and robust predictions balances clean-data accuracy with adversarial resilience.
- Mechanism: The ensemble model computes weighted predictions: ŷ_ens = (1-λ)·M_Base(x) + λ·M_Rob(x). M_Base optimizes for clean conditions; M_Rob optimizes for perturbed conditions. The λ parameter (optimized via grid search on validation data) dynamically weights their contributions.
- Core assumption: The error distributions of M_Base and M_Rob are at least partially uncorrelated, enabling complementary error cancellation.
- Evidence anchors:
  - [abstract] "The ensemble model further outperforms with errors of 2.01 meters and 1.975 meters for the respective attack types"
  - [section III.B, Equation 8] "ŷ_ens = (1 - λ) · M_Base(x) + λ · M_Rob(x)"
  - [corpus] Ensemble approaches for Wi-Fi positioning are supported by Taniuchi & Maekawa (2014) showing ensemble learning improves robustness, but KAN-specific ensemble evidence is absent.

### Mechanism 3
- Claim: KAN architecture enables flexible function approximation through learnable inner-outer function decomposition.
- Mechanism: KAN implements the Kolmogorov-Arnold representation theorem with m=15 inner functions (each an MLP with Dense, ReLU, BatchNorm, Dropout layers) and outer aggregation functions. This decomposes the RSSI-to-coordinate mapping into learnable univariate functions rather than fixed activation patterns.
- Core assumption: The indoor positioning function can be approximated more efficiently via sum-of-univariate decompositions than conventional MLP architectures.
- Evidence anchors:
  - [section III.B, Equation 3-4] "f₁ⱼ(x) = Dropout(BatchNorm(ReLU(Wⱼx + bⱼ)))" and "ŷ = F₂(F₁(x))"
  - [Table II] Ensemble KAN achieves 2.03m/1.975m RMSE vs. MLP-LSTM (2.5-3.69m) and KNN (3.1-4.64m)
  - [corpus] "Enhancing Physics-Informed Neural Networks with a Hybrid Parallel Kolmogorov-Arnold and MLP Architecture" confirms KAN applicability to complex function approximation but does not validate positioning-specific benefits.

## Foundational Learning

- Concept: **Received Signal Strength Indicator (RSSI) Fingerprinting**
  - Why needed here: The entire system maps RSSI vectors from multiple access points to 2D coordinates. Without understanding that RSSI values are location-dependent but noise-sensitive, the adversarial attack rationale is unclear.
  - Quick check question: Given RSSI readings from 8 APs at two locations 2 meters apart, would you expect distinguishable fingerprints? What factors could collapse their separability?

- Concept: **Adversarial Training Paradigm**
  - Why needed here: M_Rob's effectiveness depends on training with perturbed data. Understanding why this improves robustness (distributional coverage vs. memorization) is essential for interpreting results.
  - Quick check question: If you train a model only on Gaussian-noise-augmented data, will it generalize to uniform-scaling attacks? Why or why not?

- Concept: **RobustScaler vs. Standard Normalization**
  - Why needed here: The paper explicitly uses RobustScaler (median/IQR-based) to handle outliers in RSSI data. Understanding this choice clarifies preprocessing rationale.
  - Quick check question: If your RSSI dataset contains 5% corrupted readings from hardware failures, would StandardScaler (mean/variance) or RobustScaler produce more stable normalization?

## Architecture Onboarding

- Component map:
```
Input (RSSI from n APs)
    ↓
RobustScaler Normalization (median-centering, IQR-scaling)
    ↓
Kolmogorov Layer (2n+1 nodes, weighted transformations)
    ↓
Inner Functions (m=15 MLPs: Dense→ReLU→BatchNorm→Dropout)
    ↓
Outer Functions (aggregation + tanh activation)
    ↓
Output (2D coordinates: x, y)
```

Training variants:
- M_Base: Clean data only, Huber loss
- M_Rob: Clean + adversarial data, weighted Huber loss
- M_Ens: λ-weighted combination of M_Base and M_Rob predictions

- Critical path:
  1. Data preprocessing (RobustScaler fit on training set)
  2. Adversarial sample generation (Equations 6-7)
  3. Parallel model training (M_Base, M_Rob with early stopping at 100 epochs max)
  4. λ optimization via grid search on validation set
  5. Ensemble inference

- Design tradeoffs:
  - **M_Base vs. M_Rob**: M_Base excels on clean data (~1.9m at low attack strength); M_Rob sacrifices ~1% clean performance for 10% adversarial improvement
  - **Ensemble complexity**: M_Ens adds inference overhead (two forward passes + weighted combination) for marginal gains (~0.02-0.06m over M_Rob)
  - **Attack strength parameterization**: Paper tests 0.05-0.30 dBm; real-world attack calibration required

- Failure signatures:
  - RMSE exceeding 2.3m at high attack strength (0.25-0.30 dBm) indicates model degradation to baseline vulnerability
  - Large prediction variance across attack types suggests overfitting to specific perturbation patterns
  - Validation loss diverging from training loss indicates insufficient adversarial sample diversity

- First 3 experiments:
  1. **Reproduce baseline comparison**: Train M_Base and M_Rob on the UVictoria dataset, verify 10% error reduction (2.07m → 2.03m) under spoofing attacks at ε=0.1
  2. **Attack strength sensitivity analysis**: Sweep attack strength from 0.01-0.50 dBm to identify the breaking point where M_Ens exceeds 2.5m RMSE
  3. **Lambda ablation**: Test fixed λ values (0.3, 0.5, 0.7) vs. grid-search-optimized λ to quantify ensemble optimization impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can more sophisticated ensemble techniques further improve resilience compared to the current linear combination of models?
- Basis in paper: [explicit] The conclusion suggests, "Future research could explore more sophisticated ensemble techniques or hybrid approaches to further improve system resilience."
- Why unresolved: The current ensemble uses a simple weighted sum, providing only marginal gains over the robust model alone.
- What evidence would resolve it: Demonstration of non-linear or stacking ensembles showing statistically significant error reduction over the robust baseline.

### Open Question 2
- Question: How does the model perform against physical hardware-based attacks compared to the mathematically simulated perturbations used in training?
- Basis in paper: [inferred] Attacks are simulated via Gaussian noise and uniform scaling, which may not fully capture the temporal and multipath complexity of real-world signal spoofing.
- Why unresolved: Validation relies on synthetic perturbations rather than data from active, physical layer attacks.
- What evidence would resolve it: Evaluation on a dataset collected during actual rogue access point transmission or hardware-based signal interference.

### Open Question 3
- Question: Is the KAN architecture specifically responsible for the adversarial robustness, or is the performance driven primarily by the adversarial training regimen?
- Basis in paper: [inferred] The paper compares the full pipeline to other methodologies but lacks an ablation study isolating the KAN architecture from the WREP training protocol.
- Why unresolved: It is unclear if a standard MLP would achieve similar robustness results under the same adversarial training conditions.
- What evidence would resolve it: An ablation study comparing KAN against standard architectures (e.g., MLP, CNN) using identical training data and loss functions.

## Limitations
- Attack simulation methodology uses synthetic perturbations that may not capture real-world attack complexity
- Dataset collected from single building using custom ESP32C3 hardware limits external validity
- Ensemble model provides only marginal improvement (0.02-0.06m) over robust model alone
- KAN architecture details for inner functions are underspecified, creating implementation ambiguity

## Confidence
- **High confidence**: The fundamental mechanism of adversarial training improving robustness is well-established in the literature. The observed 10% error reduction for the robust model under attack conditions is consistent with expected transfer learning benefits from augmented data.
- **Medium confidence**: The KAN architecture's superiority over MLP-LSTM and KNN baselines is supported by experimental results, but the specific contribution of KAN versus other architectural choices cannot be isolated without ablation studies.
- **Low confidence**: The ensemble model's marginal gains and the optimal λ selection process lack sufficient empirical justification. The assumption that M_Base and M_Rob errors are uncorrelated enough for effective ensemble learning is stated but not empirically validated through error correlation analysis.

## Next Checks
1. **Attack realism validation**: Generate adversarial samples using real-world attack signatures (e.g., collected from compromised APs) rather than synthetic Gaussian/uniform perturbations, and measure performance degradation compared to the current methodology.

2. **Cross-dataset generalization**: Train the KAN models on the UVictoria dataset, then evaluate on publicly available Wi-Fi positioning datasets (UJIIndoorLoc, Tampere) to assess whether the 2m accuracy advantage transfers across different environments and hardware.

3. **Error correlation analysis**: Compute Pearson correlation coefficients between M_Base and M_Rob prediction errors across the validation set, and measure ensemble performance with fixed λ values (0.3, 0.5, 0.7) to quantify whether the grid-search-optimized λ provides meaningful improvement over simple averaging.