---
ver: rpa2
title: 'SafePred: A Predictive Guardrail for Computer-Using Agents via World Models'
arxiv_id: '2602.01725'
source_url: https://arxiv.org/abs/2602.01725
tags:
- risk
- task
- action
- agent
- long-term
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of long-term risks in computer-using
  agents (CUAs) that arise from actions appearing safe in the short term but causing
  harmful delayed consequences. The core method idea is a predictive guardrail framework
  called SafePred that leverages a world model to predict both short- and long-term
  risks, then translates these predictions into actionable decision guidance through
  a risk-to-decision loop.
---

# SafePred: A Predictive Guardrail for Computer-Using Agents via World Models

## Quick Facts
- arXiv ID: 2602.01725
- Source URL: https://arxiv.org/abs/2602.01725
- Reference count: 36
- Primary result: SafePred achieves over 97.6% safety performance across benchmarks while improving task utility by up to 21.4% compared to reactive baselines.

## Executive Summary
SafePred introduces a predictive guardrail framework designed to address the challenge of long-term risks in computer-using agents (CUAs). These risks arise when actions that appear safe in the short term lead to harmful delayed consequences. The framework leverages a world model to predict both short- and long-term risks, translating these predictions into actionable decision guidance through a risk-to-decision loop. SafePred demonstrates strong safety performance and improved task utility on controlled benchmarks, with a lightweight 8B model achieving comparable results to larger models.

## Method Summary
SafePred operates by integrating a predictive world model into the decision-making process of computer-using agents. This world model forecasts potential risks over both short and long time horizons, allowing the agent to anticipate and avoid actions that may cause delayed harm. The framework employs a risk-to-decision loop that converts these predictions into concrete guidance, enabling the agent to make safer choices without sacrificing task performance. SafePred was evaluated on synthetic benchmarks, where it achieved over 97.6% safety performance and improved utility by up to 21.4% compared to reactive baselines. A lightweight SafePred-8B model, trained on just 1.5K samples, demonstrated safety performance comparable to much larger models like Deepseek-V3.2.

## Key Results
- SafePred achieves over 97.6% safety performance across benchmarks.
- Task utility improved by up to 21.4% compared to reactive baselines.
- SafePred-8B model trained on 1.5K samples achieves safety performance comparable to Deepseek-V3.2.

## Why This Works (Mechanism)
SafePred addresses a fundamental limitation in current computer-using agents: the inability to foresee and mitigate long-term risks arising from seemingly safe short-term actions. By leveraging a world model, SafePred predicts both immediate and delayed consequences of agent actions, enabling proactive risk mitigation. The risk-to-decision loop translates these predictions into actionable guidance, ensuring that safety considerations are integrated into the agent's decision-making process without compromising task utility. This predictive approach is particularly effective in environments where delayed consequences can be severe, such as system configuration changes or file operations.

## Foundational Learning
- **World Models**: Simulate future states based on current actions to predict potential risks. *Why needed*: To anticipate both short- and long-term consequences of agent actions. *Quick check*: Verify that the world model can accurately simulate realistic system states and transitions.
- **Risk-to-Decision Loop**: Converts predicted risks into actionable guidance for the agent. *Why needed*: To ensure that safety predictions are effectively integrated into the agent's decision-making process. *Quick check*: Confirm that the loop produces guidance that meaningfully reduces risk without degrading task performance.
- **Predictive Guardrails**: Proactive safety mechanisms that prevent harmful actions before they occur. *Why needed*: To address risks that may not be immediately apparent but could cause significant harm over time. *Quick check*: Test the guardrail's ability to block high-risk actions while allowing low-risk, high-utility actions.

## Architecture Onboarding

**Component Map**
World Model -> Risk Predictor -> Risk-to-Decision Loop -> Agent Action Selector

**Critical Path**
1. Agent performs an action.
2. World model predicts short- and long-term consequences.
3. Risk predictor evaluates the safety of predicted outcomes.
4. Risk-to-decision loop translates risks into actionable guidance.
5. Agent adjusts its action selection based on the guidance.

**Design Tradeoffs**
- **Model Size vs. Performance**: A lightweight SafePred-8B model achieves comparable safety performance to larger models, but may have reduced generalization in highly complex scenarios.
- **Prediction Horizon vs. Accuracy**: Longer prediction horizons improve risk detection but may introduce compounding errors.
- **Computational Overhead vs. Real-Time Usability**: Predictive guardrails add latency, which could impact the agent's responsiveness in time-sensitive tasks.

**Failure Signatures**
- **False Positives**: Overly conservative risk predictions that block safe actions, reducing task utility.
- **False Negatives**: Missed risks that allow harmful actions to proceed, compromising safety.
- **Prediction Drift**: Degradation in world model accuracy over time, leading to unreliable risk forecasts.

**3 First Experiments**
1. **Baseline Safety Comparison**: Compare SafePred's safety performance against reactive baselines on a controlled benchmark.
2. **Utility Impact Test**: Measure the impact of SafePred on task utility to ensure safety improvements do not come at the cost of performance.
3. **Model Scalability Evaluation**: Assess the performance of SafePred-8B versus larger models to determine the optimal balance between size and effectiveness.

## Open Questions the Paper Calls Out
None

## Limitations
- Potential gap between synthetic benchmarks and real-world deployment scenarios.
- Risk of compounding errors in world model predictions over extended time horizons.
- Lack of discussion on computational overhead and its impact on real-time usability.

## Confidence
- **Safety performance (97.6% across benchmarks)**: High - supported by reported results on established benchmarks.
- **Utility improvement (up to 21.4% vs. reactive baselines)**: Medium - results are promising, but benchmarks may not fully reflect real-world utility gains.
- **SafePred-8B model performance**: Medium - claims are based on limited training samples (1.5K), and the comparison to Deepseek-V3.2 may not be fully representative of all deployment contexts.

## Next Checks
1. Evaluate SafePred in diverse, real-world computer-using agent scenarios to assess robustness and generalization beyond synthetic benchmarks.
2. Conduct long-term deployment studies to measure the impact of prediction errors and model drift on safety performance over extended periods.
3. Benchmark the computational overhead and latency introduced by SafePred to ensure it does not impede real-time agent responsiveness.