---
ver: rpa2
title: 'KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing
  Automated Fact-checking'
arxiv_id: '2601.19447'
source_url: https://arxiv.org/abs/2601.19447
tags:
- contrastive
- claim
- questions
- knowledge
- kg-craft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KG-CRAFT introduces a knowledge graph-based contrastive reasoning
  framework for automated fact-checking, addressing the challenge of verifying claims
  by constructing structured evidence from claims and reports. The method first builds
  a knowledge graph from textual input, then formulates contrastive questions grounded
  in this structure, generates evidence-based answers, and synthesizes a concise summary
  for veracity assessment by LLMs.
---

# KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking

## Quick Facts
- **arXiv ID:** 2601.19447
- **Source URL:** https://arxiv.org/abs/2601.19447
- **Reference count:** 34
- **Primary result:** Achieves up to 73.87% F1-score on LIAR-RAW, outperforming baselines

## Executive Summary
KG-CRAFT introduces a knowledge graph-based contrastive reasoning framework for automated fact-checking, addressing the challenge of verifying claims by constructing structured evidence from claims and reports. The method first builds a knowledge graph from textual input, then formulates contrastive questions grounded in this structure, generates evidence-based answers, and synthesizes a concise summary for veracity assessment by LLMs. Evaluations on LIAR-RAW and RAWFC datasets show KG-CRAFT achieves state-of-the-art performance, with up to 73.87% F1-score on LIAR-RAW, significantly outperforming traditional and LLM-based baselines. Ablation studies confirm the superiority of KG-based contrastive questions over LLM-only generation and demonstrate robust performance across varying numbers of questions. Even smaller language models benefit from KG-CRAFT, narrowing performance gaps with larger models.

## Method Summary
KG-CRAFT leverages a knowledge graph (KG) constructed from claim and report texts to generate structured, contrastive questions for fact-checking. The pipeline involves: (1) KG construction using entity and relation extraction, (2) contrastive question formulation grounded in the KG, (3) evidence generation by querying LLMs with these questions, and (4) summarization of generated answers to assess claim veracity. The framework uses both open-source and proprietary LLMs, and ablation studies show that KG-based contrastive reasoning significantly improves accuracy over LLM-only baselines.

## Key Results
- Achieves up to 73.87% F1-score on LIAR-RAW, significantly outperforming traditional and LLM-based baselines
- KG-based contrastive questions outperform LLM-only generation in all ablation studies
- Even smaller language models benefit from KG-CRAFT, narrowing performance gaps with larger models
- Performance remains robust across varying numbers of contrastive questions

## Why This Works (Mechanism)
KG-CRAFT improves fact-checking by structuring the reasoning process: instead of relying on free-form LLM responses, it first builds a knowledge graph to capture explicit relationships in the claim and report, then generates targeted contrastive questions that probe for missing or conflicting evidence. This structured approach reduces hallucination, ensures coverage of relevant facts, and enables more consistent, interpretable reasoning by LLMs. The contrastive nature of the questions forces the model to consider alternative scenarios, increasing robustness.

## Foundational Learning
- **Knowledge Graph Construction:** Extracting entities and relations from text to form a structured representation of facts; needed to provide explicit evidence for reasoning, quickly checked by verifying entity and relation extraction accuracy on sample texts.
- **Contrastive Question Formulation:** Generating targeted questions that probe for missing or conflicting evidence; needed to systematically explore claim validity, quickly checked by ensuring questions are answerable from the KG and diverse in perspective.
- **LLM-based Evidence Synthesis:** Using LLMs to answer contrastive questions and summarize findings; needed to automate reasoning over structured evidence, quickly checked by verifying answer relevance and consistency with KG facts.
- **Ablation Testing:** Systematically removing or modifying components to assess their contribution; needed to isolate the impact of KG and contrastive reasoning, quickly checked by comparing performance drops when components are removed.
- **Dataset Evaluation:** Measuring performance on established fact-checking datasets; needed to benchmark against baselines and demonstrate generalization, quickly checked by confirming correct handling of dataset formats and labels.

## Architecture Onboarding

**Component Map:** KG Construction -> Contrastive Question Formulation -> Evidence Generation -> Summary Synthesis -> Veracity Prediction

**Critical Path:** The core pipeline is KG Construction → Contrastive Question Formulation → Evidence Generation → Summary Synthesis. Each step must succeed for accurate veracity prediction.

**Design Tradeoffs:** The use of KG-based questions increases robustness and interpretability but adds complexity and computational cost compared to direct LLM prompting. KG quality directly impacts downstream performance.

**Failure Signatures:** If KG construction fails or is incomplete, contrastive questions will be less effective and answers may be unreliable. Low-quality or biased LLM answers will propagate errors into the final veracity assessment.

**First Experiments:**
1. Validate KG construction by manually inspecting extracted entities and relations for a sample of claims.
2. Test contrastive question generation by ensuring questions are answerable and probe for missing evidence.
3. Verify evidence generation by checking LLM answers for consistency with KG facts and relevance to the claim.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains depend heavily on the quality of automatically generated knowledge graphs, which are not thoroughly evaluated for completeness or accuracy.
- No analysis of potential biases introduced during question generation or answer synthesis.
- Dataset-specific artifacts may inflate generalization claims; method's scalability to real-time applications remains unclear due to computational costs.

## Confidence
- KG-CRAFT architecture and methodology: **High**
- Reported performance on benchmark datasets: **Medium** (pending independent replication)
- Generalization across diverse fact-checking domains: **Low** (limited domain testing)
- Computational efficiency for real-world deployment: **Low** (no runtime or cost analysis)

## Next Checks
1. Replicate the KG-CRAFT pipeline on an unseen fact-checking dataset (e.g., FEVER or Climate-FEVER) to assess cross-domain robustness.
2. Perform an ablation study isolating the effect of knowledge graph quality (using oracle vs. automatically constructed KGs) on downstream veracity prediction.
3. Benchmark the end-to-end runtime and API costs of KG-CRAFT against real-time fact-checking requirements.