---
ver: rpa2
title: Exploring Robustness of Multilingual LLMs on Real-World Noisy Data
arxiv_id: '2501.08322'
source_url: https://arxiv.org/abs/2501.08322
tags:
- noisy
- language
- clean
- performance
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores how real-world spelling mistakes affect the
  performance of multilingual large language models (LLMs) across different tasks
  and languages. The authors construct a dataset of real-world typos from Wikipedia
  edit history and use it to create noisy test sets for three NLP tasks: natural language
  inference, named entity recognition, and intent classification in six languages.'
---

# Exploring Robustness of Multilingual LLMs on Real-World Noisy Data

## Quick Facts
- arXiv ID: 2501.08322
- Source URL: https://arxiv.org/abs/2501.08322
- Reference count: 39
- Key outcome: mT5 models, especially the 13B version, are most robust to real-world spelling noise with an average performance gap of 2.3 percentage points between clean and noisy data across three NLP tasks and six languages

## Executive Summary
This paper investigates how real-world spelling mistakes affect the performance of multilingual large language models across different tasks and languages. The authors construct a dataset of real-world typos from Wikipedia edit history and use it to create noisy test sets for natural language inference, named entity recognition, and intent classification tasks. They evaluate nine models ranging from 0.2B to 13B parameters, including mT5, BLOOM, Falcon, and BERT-like models. Results show that mT5 models, especially the largest 13B version, are most robust to noise, with an average performance gap of 2.3 percentage points between clean and noisy data. English shows higher vulnerability than other languages due to higher concentration of content-word typos.

## Method Summary
The authors construct a WikiTypo dictionary from Wikipedia edit history containing 6 languages and 3,300-15,000 typo-correction pairs per language. They apply noise injection to held-out test sets using WikiTypo for XNLI/SNIPS tasks and NLPAug keyboard augmentation for WikiANN proper nouns. Models are fine-tuned on combined multilingual clean training data (2-6 epochs depending on convergence) and evaluated on matched clean and noisy test sets. The performance gap (C-N) between clean and noisy accuracy is computed per model, language, and task. Nine models are evaluated including mT5 variants (300M-13B), BLOOM-7B, Falcon-7B, mBERT-179M, and XLM-R-279M.

## Key Results
- mT5 models, especially the 13B version, show superior robustness to spelling noise compared to BLOOM, Falcon, and BERT-like models
- NLI tasks are most sensitive to noise, while intent classification is least affected
- English shows higher vulnerability than other languages due to higher concentration of content-word typos
- Noise-augmented training can reduce the performance gap but may lower clean performance

## Why This Works (Mechanism)

### Mechanism 1: Training data scale drives cross-lingual noise robustness
- Claim: Models exposed to larger multilingual token volumes during pre-training develop greater robustness to spelling variations
- Mechanism: Massive pre-training corpora create broader lexical coverage, enabling the model to map noisy variants to canonical representations through distributed pattern recognition
- Core assumption: Larger pre-training corpora contain proportionally more examples of naturally-occurring spelling variations
- Evidence anchors: mT5 shows more robustness compared to BLOOM and Falcon; mT5 has seen the largest number of tokens across all languages

### Mechanism 2: Encoder-decoder with MLM outperforms decoder-only for token-level tasks under noise
- Claim: Masked Language Modeling pre-training creates representations more robust to input noise for token-level tasks compared to causal next-token prediction
- Mechanism: MLM explicitly trains models to reconstruct corrupted inputs by predicting masked spans, directly teaching noise invariance at the token level
- Core assumption: The pre-training objective's alignment with downstream task requirements determines robustness transfer efficiency
- Evidence anchors: BLOOM-7B shows 8.32 average F1 gap vs mT5-13B's 1.94 gap on WikiANN NER task; decoder-only models struggle with NER

### Mechanism 3: Semantic word category amplifies noise impact across languages
- Claim: Noise affecting content words (verbs, nouns, proper nouns) causes larger performance degradation than noise in function words
- Mechanism: Content words carry primary semantic load in sentence understanding; misspelled verbs and nouns disrupt meaning representation more severely
- Core assumption: The part-of-speech distribution of naturally-occurring typos varies systematically by language
- Evidence anchors: English has almost twice as many noisy verb instances compared to other languages; English shows highest average performance gap across models

## Foundational Learning

- Concept: Levenshtein edit distance
  - Why needed here: WikiTypo construction filters for single-character edit distance pairs; understanding string similarity metrics is essential for reproducing the noise injection methodology
  - Quick check question: Why might filtering for exactly 1-character edits miss common real-world errors like transpositions ("teh" for "the")?

- Concept: Encoder-decoder vs decoder-only attention mechanisms
  - Why needed here: The study differentiates mT5 (encoder-decoder with bidirectional attention) from BLOOM/Falcon (decoder-only with causal masking)
  - Quick check question: How does bidirectional self-attention in the encoder enable different noise handling characteristics compared to causal attention?

- Concept: Noise-augmented training for robustness
  - Why needed here: Section 5.4 demonstrates that fine-tuning on noisy data reduces the C-N gap
  - Quick check question: Table 8 shows noisy training reduces the gap partly by lowering clean performance—what does this tradeoff imply about deployment decisions?

## Architecture Onboarding

- Component map: WikiTypo noise dictionary (6 languages, 3,300-15,000 pairs) -> NLPAug keyboard augmenter -> Noise injection parameters (r=0.2, m=4) -> Model families (mT5 5 sizes, BLOOM-7B, Falcon-7B, mBERT-179M, XLM-R-279M) -> Evaluation metric (C-N gap)

- Critical path:
  1. Extract typo pairs from Wikipedia edit history with Levenshtein distance = 1
  2. Apply noise injection to held-out test sets (WikiTypo for XNLI/SNIPS, NLPAug for WikiANN)
  3. Fine-tune each model on combined multilingual clean training data
  4. Evaluate on matched clean and noisy test sets; compute C-N gap
  5. Analyze degradation patterns by architecture, scale, task type, and language

- Design tradeoffs:
  - WikiTypo vs NLPAug: Real Wikipedia typos are authentic but sparse for proper nouns
  - Noise ratio (r=0.2): Higher ratios stress-test robustness more severely but may exceed typical user error rates
  - Combined multilingual training: Enables cross-lingual transfer but may dilute language-specific robustness patterns

- Failure signatures:
  - Decoder-only models showing 2-4× larger C-N gaps on NER vs IC tasks
  - English showing consistently higher degradation across all architectures
  - Small models (<1B parameters) requiring 6 epochs vs 2 for convergence

- First 3 experiments:
  1. Reproduce mT5-300M vs mT5-13B comparison on XNLI for English only to validate scaling effect
  2. Implement noise-augmented training on a decoder-only model for WikiANN to measure robustness improvement
  3. Analyze the PoS distribution of typos in your target deployment language to predict vulnerability

## Open Questions the Paper Calls Out

- **Does the robustness of multilingual LLMs to real-world noise continue to improve with model scale beyond 13 billion parameters?**
  - The authors note they evaluated models up to 13B parameters but current capabilities extend beyond this
  - Evaluating larger open-source models (e.g., Llama-3, Command R) on the WikiTypo benchmark would resolve this

- **How does robustness differ when models are evaluated on non-Wikipedia noise sources, such as social media slang or OCR errors?**
  - The authors suggest exploring other noise sources could strengthen the research
  - A comparative study using the same model suite on OCR scans or social media data would provide evidence

- **Are decoder-only models specifically vulnerable to noise in proper nouns during Named Entity Recognition (NER) tasks?**
  - The authors note decoder-only models struggled most with NER using synthetic proper noun noise
  - Creating a natural noisy NER dataset with real-world misspellings of proper nouns would resolve this

## Limitations

- The WikiTypo dictionary filters for exactly one Levenshtein edit distance and excludes numbers/special characters, potentially missing common error patterns
- The NLPAug keyboard augmentation introduces synthetic noise that may not match actual typing error distributions
- The noise ratio (r=0.2) represents severe perturbation exceeding typical user error rates in production systems
- Combined multilingual training may dilute language-specific robustness patterns and obscure fine-grained variations

## Confidence

- **High confidence**: mT5 models show superior robustness to spelling noise compared to BLOOM, Falcon, and BERT-like models
- **Medium confidence**: Encoder-decoder MLM architecture provides inherent advantages for token-level tasks under noise
- **Medium confidence**: English shows systematically higher vulnerability to spelling noise due to greater concentration of content-word typos
- **Low confidence**: The semantic word category hypothesis fully explains cross-linguistic robustness differences

## Next Checks

1. Validate noise injection realism by comparing WikiTypo and NLPAug distributions against actual user-generated text errors from social media or chat logs
2. Test robustness mitigation strategies by implementing noise-augmented fine-tuning on a decoder-only model for the NER task and measuring the C-N gap reduction
3. Analyze the part-of-speech distribution of naturally-occurring typos in your specific target language and domain to predict vulnerability using the semantic-load mechanism before model selection