---
ver: rpa2
title: Debiasing Reward Models by Representation Learning with Guarantees
arxiv_id: '2510.23751'
source_url: https://arxiv.org/abs/2510.23751
tags:
- latent
- reward
- learning
- variables
- spurious
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses reward model biases in reinforcement learning
  from human feedback (RLHF), such as length bias, sycophancy, and concept bias. These
  biases occur when models learn spurious correlations rather than true human preferences.
---

# Debiasing Reward Models by Representation Learning with Guarantees

## Quick Facts
- **arXiv ID**: 2510.23751
- **Source URL**: https://arxiv.org/abs/2510.23751
- **Reference count**: 30
- **Primary result**: Proposed method CARD achieves worst-case accuracy of 0.63 on sycophancy bias compared to 0.47 for vanilla reward models, and lower average bias@C (0.15 vs 0.42) on concept bias tasks.

## Executive Summary
This paper addresses reward model biases in reinforcement learning from human feedback (RLHF), such as length bias, sycophancy, and concept bias. These biases occur when models learn spurious correlations rather than true human preferences. The proposed method, CARD, identifies and leverages bias-free latent variables to train reward models, making them more robust to these biases. The approach is grounded in theoretical identifiability results, showing that bias-free latent variables can be recovered under mild assumptions. Experiments on synthetic and real-world datasets demonstrate CARD's effectiveness in mitigating various forms of reward model bias.

## Method Summary
The method employs a two-stage approach to debias reward models. Stage 1 trains a customized VAE (based on LangVAE) that encodes text into bias-free (Ẑc) and spurious (Ẑs) latent variables, with an explicit independence constraint between Ẑc and a known surrogate S using HSIC regularization. The prior p(Ẑ|S) is modeled using normalizing flows. Stage 2 freezes the encoder and trains a reward model exclusively on the bias-free representation Ẑc using Bradley-Terry likelihood. The framework theoretically guarantees identifiability of the bias-free subspace under sufficient variability assumptions about the surrogate variable.

## Key Results
- CARD achieves worst-case accuracy of 0.63 on sycophancy bias compared to 0.47 for vanilla reward models
- CARD has lower average bias@C (0.15) than vanilla model (0.42) on concept bias tasks
- Synthetic experiments show mean R² of 0.83 ± 0.03 between ground-truth and recovered latent variables
- The method demonstrates robustness to distribution shifts where spurious correlations change between training and testing

## Why This Works (Mechanism)

### Mechanism 1
The bias-free latent subspace (Ẑc) can be recovered up to an invertible transformation, provided there is sufficient variability in the spurious features relative to the surrogate. The framework models observed text as a mixture of spurious (Zs) and bias-free (Zc) latent variables. By enforcing independence between the learned Ẑc and a known surrogate S, the VAE is forced to separate the underlying "true preference" factors from the spurious ones. This relies on Assumption A1 (sufficient variability w.r.t. surrogate): the probability of events depending on spurious latents must change as the surrogate S changes.

### Mechanism 2
Training the reward model exclusively on the disentangled bias-free representation (Ẑc) prevents the model from accessing spurious information, thereby mitigating reward hacking. This operates as an information bottleneck - standard RMs learn directly from text embeddings containing both causal and spurious signals. By training the RM solely on Ẑc (which contains no information about S), the RM physically cannot develop a dependence on the spurious feature, making it counterfactually invariant to the bias.

### Mechanism 3
Explicit independence regularization (HSIC) is necessary in practice to enforce the theoretical independence constraint between Ẑc and S. While the ELBO is theoretically sufficient for identification in the infinite sample limit, the authors add an HSIC penalty to the VAE loss. This forces the distribution of Ẑc to be statistically independent of the surrogate S, aiding disentanglement with finite data. The regularization weight λ must be carefully tuned to balance independence enforcement with reconstruction quality.

## Foundational Learning

**Concept: Causal Representation Learning / Nonlinear ICA**
- Why needed here: The core theoretical contribution relies on the "identifiability" of latent variables. Without understanding that deep generative models usually have infinite equivalent solutions (unidentifiable), the guarantees in Theorem 1 seem like magic.
- Quick check question: Why can't we just use a standard VAE to cluster "good" vs "bad" text without the surrogate constraint? (Answer: Without the constraint/assumption, a standard VAE cannot distinguish between a "good" sentence and a "long" sentence if they always co-occur).

**Concept: Surrogate Variables**
- Why needed here: The paper distinguishes between the true spurious variable (unobserved) and a surrogate (observed proxy, like text length).
- Quick check question: If we use "text length" as a surrogate S, does the model assume length is the only bias, or just a bias connected to the unobserved spurious factors? (Answer: It models S as a variable that Zs depends on, allowing S to act as a hook to isolate Zs).

**Concept: Variational Autoencoders (VAEs) with Normalizing Flows**
- Why needed here: The implementation uses a specific VAE architecture where the prior p(Ẑ|S) is modeled using normalizing flows rather than a fixed Gaussian.
- Quick check question: How does the conditioning on S in the prior p(Ẑ|S) help the VAE? (Answer: It allows the model to learn how the distribution of latent variables shifts as the bias changes, providing the "variability" needed for identification).

## Architecture Onboarding

**Component map**: Input (Prompt-Response pairs T + Surrogate label S) -> Encoder (BERT + MLPs) -> Latents (Ẑc, Ẑs) -> Prior (Normalizing Flows conditioned on S) -> Decoder (MLP + GPT-2) -> Output (Reconstructed text) -> Reward Head (2-layer MLP on Ẑc)

**Critical path**:
1. Stage 1 (Representation): Train VAE. Loss = Reconstruction + β-KL + λ-HSIC
2. Freeze Encoder
3. Stage 2 (Rewarding): Pass text through frozen Encoder → extract Ẑc
4. Train Reward MLP on Ẑc using Bradley-Terry likelihood

**Design tradeoffs**:
- Pre-trained vs. Scratch: Uses pre-trained BERT/GPT-2 to reduce training parameters. Tradeoff: Faster convergence, but the latent space geometry is constrained by the pre-training.
- Surrogate Availability: Offers two theories (with/without surrogate). Tradeoff: Experiments focus on "Surrogate Known" case as it is more practical for targeted debiasing.

**Failure signatures**:
- Semantic Drift: If λ (HSIC weight) is too high, the model might enforce independence by stripping valid semantic content from Ẑc, resulting in high reconstruction loss.
- Unbroken Correlation: If Synthetic R² is low (<0.5), check Assumption A1 (variability of S). If S is constant or binary with extreme imbalance, identification fails.

**First 3 experiments**:
1. Synthetic Sanity Check: Generate data with known Zc and Zs. Train the VAE. Verify that R²(Ẑc, Zc) > 0.8 to confirm the implementation of Theorem 1.
2. Ablation on Latents: Train three RMs (on Ẑc, Ẑs, and Ẑ). Verify that the Ẑc model has the lowest Bias@C score (replicating Table 2).
3. Sycophancy Robustness: Replicate the "distribution shift" experiment (Fig 4). Plot "Deviation from Oracle" vs. p_test. Verify the curve is flat for CARD but rises for Vanilla RM.

## Open Questions the Paper Calls Out

**Open Question 1**: Can the theoretical identifiability guarantees for the no-surrogate case (Theorem 2) be extended to nonlinear reward functions, rather than only linear ones? The paper explicitly assumes "r^k is assumed to be linear, i.e., r^k(Z_{A^k}) = W^{(k)}Z_{A^k}" as a requirement for subspace identifiability without surrogate access.

**Open Question 2**: How does the method perform when multiple spurious correlations (e.g., length bias, sycophancy, concept bias) co-occur in the same dataset? The introduction lists multiple bias types but experiments only evaluate single-bias scenarios in controlled settings.

**Open Question 3**: What is the minimum number and diversity of human labelers required for reliable bias-free latent identification in the no-surrogate setting? Corollary 1 states identifiability requires "sufficient diversity among the human labelers" but provides no quantitative guidance.

**Open Question 4**: How sensitive is the method to violations of the "sufficient variability" assumptions (A1, A3-A5) in realistic, finite-sample settings? The identifiability theorems rely on variability assumptions described as "common in causal representation learning," but these may not hold when spurious features have limited variation in real preference data.

## Limitations

- Theoretical Scope: Identifiability guarantees depend critically on Assumption A1 (sufficient variability of surrogate), which is not empirically validated beyond synthetic settings.
- Architecture Opacity: Key design choices like latent dimensions for Ẑc and Ẑs are underspecified, making it difficult to assess VAE capacity for disentanglement.
- Generalization Gaps: Method's effectiveness on other bias types (e.g., recency bias, position bias) is not demonstrated; relies on known surrogate S.

## Confidence

- **High**: The mechanism of using bias-free latent subspace (Ẑc) to train reward models is sound and well-supported by sycophancy and concept bias experiments.
- **Medium**: Theoretical identifiability results are valid under stated assumptions, but practical impact is uncertain due to sensitivity of Assumption A1.
- **Low**: Long-term generalization to unseen distributions and robustness to unknown or evolving biases are not established.

## Next Checks

1. **Assumption A1 Validation**: Design a controlled experiment where variability of surrogate S is systematically reduced. Measure degradation in R² between ground-truth and recovered latent variables to empirically validate necessity and sufficiency of Assumption A1.

2. **Architecture Sensitivity Analysis**: Conduct ablation study systematically varying dimensions of Ẑc and Ẑs. Identify minimum latent capacity required for effective disentanglement and report sensitivity of Bias@C score to these architectural choices.

3. **Out-of-Distribution Generalization Test**: Train CARD on sycophancy dataset where "Yes, you are right" phrase is prepended with p_train=0.8. Evaluate on test set where phrase is replaced with semantically similar but structurally different phrase (e.g., "You make a good point") with p_test=0.8. Measure worst-case accuracy to assess robustness to semantic shifts in surrogate.