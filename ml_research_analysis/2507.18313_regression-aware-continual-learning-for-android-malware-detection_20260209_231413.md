---
ver: rpa2
title: Regression-aware Continual Learning for Android Malware Detection
arxiv_id: '2507.18313'
source_url: https://arxiv.org/abs/2507.18313
tags:
- malware
- regression
- learning
- forgetting
- security
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of security regression in continual
  learning (CL) for Android malware detection. While CL helps mitigate catastrophic
  forgetting, it can still introduce security regression - where previously correctly
  detected malware samples are misclassified after model updates.
---

# Regression-aware Continual Learning for Android Malware Detection

## Quick Facts
- arXiv ID: 2507.18313
- Source URL: https://arxiv.org/abs/2507.18313
- Reference count: 31
- Key outcome: CL strategies without regression mitigation exhibit significant security regression, with negative flip rates (NFR) for malware reaching 3.40% on ELSA and 2.92% on Tesseract. By integrating PCT, these rates are reduced by approximately 50%, achieving NFR values as low as 1.19% and 1.75% respectively, while maintaining strong detection performance (F1 scores around 85-87%).

## Executive Summary
This paper addresses the problem of security regression in continual learning (CL) for Android malware detection. While CL helps mitigate catastrophic forgetting, it can still introduce security regression - where previously correctly detected malware samples are misclassified after model updates. This is particularly problematic in security-critical applications as it can undermine user trust.

The authors propose adapting Positive Congruent Training (PCT) to the CL setting. PCT is a regression-aware penalty that preserves prior predictive behavior by jointly minimizing the classification loss and a regularization term designed to penalize harmful prediction changes at the sample level. This approach is model-agnostic and can be integrated with various CL strategies.

## Method Summary
The paper introduces a regression-aware penalty called Positive Congruent Training (PCT) adapted for continual learning scenarios. PCT works by jointly minimizing classification loss and a regularization term that penalizes harmful prediction changes at the sample level. The method is model-agnostic and can be integrated with various CL strategies including regularization-based approaches and replay-based methods. The evaluation is conducted across three Android malware datasets (ELSA, Tesseract, and AZ-Class) using different CL scenarios to assess both detection performance and security regression.

## Key Results
- CL strategies without regression mitigation exhibit significant security regression, with negative flip rates (NFR) for malware reaching 3.40% on ELSA and 2.92% on Tesseract
- By integrating PCT, these rates are reduced by approximately 50%, achieving NFR values as low as 1.19% and 1.75% respectively
- Detection performance remains strong with F1 scores around 85-87%, and combination with replay-based methods shows even better results in reducing malware NFR

## Why This Works (Mechanism)
PCT preserves prior predictive behavior by introducing a regression-aware penalty that minimizes harmful prediction changes at the sample level. By jointly optimizing classification loss and this regularization term, the model maintains security-relevant predictions while adapting to new threats. The sample-level penalty ensures that individual malware detections are protected from being incorrectly flipped to benign during model updates, directly addressing the security regression problem that standard CL methods cannot resolve.

## Foundational Learning

**Continual Learning (CL)**: A learning paradigm where models are trained sequentially on different tasks without forgetting previously learned knowledge. Why needed: Traditional batch learning assumes all data is available simultaneously, which is unrealistic for evolving security threats. Quick check: Can the model maintain performance on Task A after being trained on Task B?

**Catastrophic Forgetting**: The phenomenon where neural networks rapidly lose previously acquired knowledge when trained on new tasks. Why needed: Android malware detection must handle evolving threat landscapes while maintaining detection of known malware families. Quick check: Does model performance degrade significantly on older malware samples after training on new samples?

**Security Regression**: The mislabeling of previously correctly classified malware samples as benign after model updates. Why needed: In security applications, incorrectly classifying known malware as benign undermines trust and system integrity. Quick check: What percentage of previously detected malware samples are now classified as benign after model updates?

## Architecture Onboarding

**Component Map**: Input Features -> Feature Extractor -> Classifier -> PCT Penalty -> Loss Function -> Model Parameters

**Critical Path**: The critical path flows from input features through the classifier to the final predictions, where PCT applies its sample-level regularization to prevent harmful prediction changes before the loss function updates model parameters.

**Design Tradeoffs**: The main tradeoff involves balancing adaptation to new threats against preserving detection of known malware. PCT adds computational overhead through its regularization term but provides crucial security guarantees. The model-agnostic nature allows integration with various architectures but may not be optimally tuned for specific architectures.

**Failure Signatures**: Security regression manifests as increased negative flip rates where malware samples shift from positive to negative predictions. Performance degradation on older malware families while maintaining or improving detection on newer samples indicates problematic forgetting that PCT aims to prevent.

**First Experiments**:
1. Baseline CL performance comparison on ELSA dataset to establish security regression baseline
2. PCT integration with regularization-based CL method to measure NFR reduction
3. PCT combination with replay-based method to evaluate synergistic effects on security regression

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not address computational overhead introduced by the regression-aware penalty during online learning scenarios
- Datasets may not capture the full diversity of Android malware encountered in production environments
- Long-term stability under continuous model updates over extended periods is not evaluated

## Confidence

**High confidence**: The core observation that CL methods can cause security regression in malware detection is well-supported by empirical results showing significant NFR reductions.

**Medium confidence**: Results show promising performance on tested datasets, but generalizability to completely different malware detection architectures remains uncertain.

**Low confidence**: Long-term stability of the regression-aware approach under continuous model updates over extended periods is not evaluated.

## Next Checks
1. Real-time performance evaluation under streaming data conditions with strict latency requirements to assess practical deployment feasibility
2. Cross-architecture validation with fundamentally different malware detection architectures to verify model-agnostic claims
3. Extended experiments with continuous model updates over 6+ months of synthetic threat evolution to evaluate long-term security regression behavior