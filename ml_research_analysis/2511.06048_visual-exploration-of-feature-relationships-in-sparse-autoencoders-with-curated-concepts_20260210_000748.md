---
ver: rpa2
title: Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated
  Concepts
arxiv_id: '2511.06048'
source_url: https://arxiv.org/abs/2511.06048
tags:
- features
- arxiv
- mapper
- sparse
- concepts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of visualizing relationships
  among the vast number of features extracted by sparse autoencoders (SAEs) from large
  language models, which becomes intractable due to sheer scale and the presence of
  polysemantic or low-quality features. To overcome limitations of conventional dimensionality
  reduction methods like UMAP, which introduce distortions and overplotting, the authors
  propose a focused exploration framework that prioritizes curated concept sets and
  their corresponding SAE features.
---

# Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated Concepts

## Quick Facts
- arXiv ID: 2511.06048
- Source URL: https://arxiv.org/abs/2511.06048
- Reference count: 40
- One-line primary result: A visual exploration framework combining ball mapper topology graphs with UMAP projections enables targeted analysis of SAE feature relationships across model layers.

## Executive Summary
This paper introduces a visual exploration framework for understanding relationships among the vast number of features extracted by sparse autoencoders (SAEs) from large language models. The authors address the intractability of conventional dimensionality reduction methods like UMAP when dealing with hundreds of thousands of features, many of which are polysemantic or low-quality. Their approach prioritizes curated concept sets and their corresponding SAE features, using ball mapper to construct a network representation that preserves both local and global structural properties. The resulting SAE Semantic Explorer system enables interpretable analysis of how models encode semantic relationships across layers, revealing progressive abstraction patterns and persistent local semantic proximity.

## Method Summary
The framework retrieves SAE features per concept via Neuronpedia API using cosine similarity between concept and feature explanations in sentence embedding space (default threshold 0.5). It constructs ball mapper graphs where nodes represent ε-neighborhoods of points and edges connect overlapping balls, preserving discrete cluster membership and explicit interconnections. The system combines this topology-based encoding with UMAP projections in a coordinated visualization interface, enabling cross-layer comparison of how curated concept sets map to SAE features. The approach uses adaptive ball mapper with max node size 5 and radius reduction factor η=0.9, with epsilon estimated from the elbow point of pairwise cosine distance distributions.

## Key Results
- Ball mapper preserves local semantic relationships better than UMAP, which introduces distortions in nearest neighbor proximities
- Layer-wise analysis reveals progressive abstraction patterns, with early layers showing dense clustering that gradually separates and recombines
- The framework enables interpretable exploration of concept representation evolution across 26 residual-stream layers of gemma-2-2b
- Coordinated views allow tracing persistent local semantic proximity across layers while maintaining global context

## Why This Works (Mechanism)

### Mechanism 1: Curated Concept Filtering Reduces Cognitive and Computational Load
The system retrieves only features with cosine similarity >0.5 between concept embeddings and SAE feature explanations, filtering the feature space from hundreds of thousands to a semantically relevant subset before visualization.

### Mechanism 2: Ball Mapper Preserves Local Topology Better Than Pure Dimensionality Reduction
Ball mapper constructs a graph where each node represents a ball (ε-neighborhood) of points, and edges connect overlapping balls, preserving discrete cluster membership rather than forcing continuous 2D projections that distort distances.

### Mechanism 3: Cross-Layer Analysis Reveals Progressive Abstraction Patterns
The system loads SAE features per layer, enabling comparison of UMAP clustering patterns and ball mapper topology across depths to show how category separation and local semantic proximity evolve.

## Foundational Learning

- **Sparse Autoencoders (SAEs) for interpretability**: SAEs decompose activations into sparse, interpretable directions; understanding this decomposition is essential since the entire framework operates on SAE-extracted features. Quick check: Can you explain why sparsity helps disentangle superposed neural representations?

- **Topological Data Analysis (Mapper Graphs)**: Ball mapper is the core novelty; understanding how mapper graphs encode point cloud topology as overlapping neighborhoods is necessary to interpret the visualizations. Quick check: What does an edge between two ball mapper nodes signify about the underlying data?

- **UMAP limitations (distance distortion, overplotting)**: The paper motivates ball mapper specifically by addressing UMAP failures; understanding these failure modes clarifies when each view is trustworthy. Quick check: Why might two points appear close in a UMAP projection despite being far apart in the original high-dimensional space?

## Architecture Onboarding

- **Component map**: Data layer (SAE features per layer + LLM-generated feature explanations + curated concept sets) -> Retrieval layer (Neuronpedia API for cosine similarity matching) -> Visualization layer (coordinated views—UMAP, Ball Mapper, Category/Feature details) -> Interaction layer (threshold adjustment, category pinning, lasso selection, cross-view highlighting)

- **Critical path**: Concept selection → Feature retrieval (cosine >0.5) → Layer selection → Dual visualization (UMAP + Ball Mapper) → Feature inspection → Cross-layer comparison

- **Design tradeoffs**: Curated concepts vs. exhaustive (precision/interpretability gained, comprehensive coverage lost); Ball mapper vs. pure UMAP (topology preserved, intuitive spatial interpretation reduced); Auto-interpretability explanations (scalability gained, reliability uncertain)

- **Failure signatures**: Empty or sparse retrieval (concept similarity threshold too high or concept not represented); Ball mapper graph too dense/fragmented (ε parameter inappropriate); UMAP and ball mapper show contradictory structures (trust ball mapper for local neighborhoods); Cross-layer patterns inconsistent (may indicate SAE instability)

- **First 3 experiments**: 
  1. Validate retrieval quality: Select a well-understood concept (e.g., "dog"), inspect top-retrieved features via Neuronpedia links, verify explanations semantically match.
  2. Calibrate ball mapper ε: Visualize the same layer with varying ε values; identify the range where clusters are neither over-merged nor over-fragmented.
  3. Cross-layer concept tracking: Pin a category (e.g., "food"), trace its UMAP clustering and ball mapper topology from layer 0 to 25; document when separation/integration occurs.

## Open Questions the Paper Calls Out

### Open Question 1
How can the reliability of SAE feature exploration be improved when identified features depend heavily on the quality of automatically generated explanations? The framework relies on LLM-generated feature explanations whose semantic accuracy is unverified, creating uncertainty in feature-concept alignment.

### Open Question 2
How does ball mapper quantitatively compare to UMAP and other dimensionality reduction methods in preserving local and global SAE feature relationships? The paper lacks quantitative benchmarking to substantiate claims of superior structure preservation.

### Open Question 3
Does this focused exploration framework yield measurable improvements in downstream tasks such as model editing, feature-level intervention, or unlearning? The paper demonstrates visualization capabilities but does not evaluate whether insights translate to practical improvements in intervention tasks.

## Limitations
- The framework depends on LLM-generated feature explanations whose semantic accuracy is unverified, potentially undermining interpretability claims
- Using curated concept sets intentionally excludes the majority of SAE features, creating blind spots where important but uncategorized features remain unexplored
- The superiority of ball mapper for preserving local topology lacks direct experimental validation on this specific dataset

## Confidence

**High confidence**: The architectural framework (SAE features → cosine similarity retrieval → ball mapper + UMAP visualization) is clearly specified and reproducible given access to underlying data.

**Medium confidence**: The claim that ball mapper better preserves local topology than UMAP is plausible given topological data analysis literature, but lacks direct experimental validation on this dataset.

**Low confidence**: The reliability of auto-interpretability explanations as semantic anchors for feature retrieval has not been independently verified.

## Next Checks

1. **Explanation quality audit**: Manually verify 20-30 top-retrieved features for several concepts (e.g., "dog", "justice", "algorithm") to assess whether auto-interpretability explanations accurately capture semantic content.

2. **Ball mapper parameter sensitivity**: Systematically vary ε and max node size across multiple layers; document how cluster structure and node connectivity change to establish parameter guidelines.

3. **Cross-run stability test**: Train SAEs from scratch twice on the same model; compare ball mapper graphs for identical concept sets across layers to assess whether observed topological patterns are stable or training artifacts.