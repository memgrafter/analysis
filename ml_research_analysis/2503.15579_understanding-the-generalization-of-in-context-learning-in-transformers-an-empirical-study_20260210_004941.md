---
ver: rpa2
title: 'Understanding the Generalization of In-Context Learning in Transformers: An
  Empirical Study'
arxiv_id: '2503.15579'
source_url: https://arxiv.org/abs/2503.15579
tags:
- generalization
- functions
- function
- combinations
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper systematically investigates the generalization capabilities
  of transformers in in-context learning (ICL) along three dimensions: inter-problem,
  intra-problem, and intra-task generalization. The authors define a task-centric
  framework and conduct extensive experiments using function-fitting tasks, API calling,
  and translation to evaluate these capabilities.'
---

# Understanding the Generalization of In-Context Learning in Transformers: An Empirical Study

## Quick Facts
- arXiv ID: 2503.15579
- Source URL: https://arxiv.org/abs/2503.15579
- Reference count: 40
- Primary result: Transformers excel at intra-task and intra-problem generalization but fail at inter-problem generalization, with training data diversity being key for improving ICL generalization

## Executive Summary
This paper presents a systematic empirical investigation of transformers' generalization capabilities in in-context learning across three dimensions: inter-problem, intra-problem, and intra-task generalization. The authors develop a task-centric framework and conduct extensive experiments using function-fitting tasks, API calling, and translation. Their findings reveal that while transformers demonstrate strong performance in intra-task and intra-problem generalization, they fundamentally fail to generalize across different problem types (inter-problem generalization). The study identifies training data diversity as a critical factor for improving ICL generalization on unseen tasks and enhancing performance on known simple tasks.

## Method Summary
The authors establish a comprehensive experimental framework to evaluate transformer generalization in in-context learning. They define three types of generalization: inter-problem (across different task types), intra-problem (within the same task type but different instances), and intra-task (within the same specific task). Experiments are conducted across three domains: function-fitting tasks (to systematically control problem diversity), API calling tasks (to test practical reasoning capabilities), and translation tasks (to evaluate cross-domain generalization). The study systematically varies training data diversity and examines its impact on each type of generalization, using both standard transformers and controlled pretraining conditions.

## Key Results
- Transformers show strong intra-task and intra-problem generalization capabilities across all tested domains
- Transformers completely fail at inter-problem generalization, unable to transfer ICL capabilities across fundamentally different task types
- Training data diversity significantly improves ICL generalization on unseen tasks and enhances performance on known simple tasks
- The results suggest that maximizing task diversity and combination in training data is more effective than focusing solely on target tasks

## Why This Works (Mechanism)
The paper's findings suggest that transformers learn to perform in-context learning through pattern recognition within specific problem distributions rather than developing generalizable reasoning capabilities. The failure at inter-problem generalization indicates that transformers memorize task-specific patterns rather than learning underlying principles that transfer across domains. The success of training data diversity implies that exposing models to varied task combinations helps them develop more flexible pattern-matching capabilities within their training distribution, but not truly general reasoning abilities.

## Foundational Learning
- In-context learning (ICL): The ability to perform tasks based on examples provided in the prompt without parameter updates
  - Why needed: Forms the basis for understanding how transformers can adapt to new tasks without fine-tuning
  - Quick check: Verify that the model can perform tasks correctly when provided with in-context examples

- Task diversity: The variety and combination of different tasks in training data
  - Why needed: Central to understanding what improves ICL generalization capabilities
  - Quick check: Compare model performance on diverse vs. homogeneous training sets

- Generalization types: The three dimensions (inter-problem, intra-problem, intra-task) used to evaluate ICL capabilities
  - Why needed: Provides a structured framework for understanding different aspects of ICL generalization
  - Quick check: Ensure experiments systematically test each type of generalization

## Architecture Onboarding
Component map: Pretraining data -> Transformer architecture -> In-context learning capabilities -> Generalization evaluation

Critical path: Diverse training data exposure → Pattern recognition development → ICL capability formation → Generalization performance

Design tradeoffs: The paper implicitly trades off between task-specific performance and generalizable capabilities, showing that transformers prioritize the former.

Failure signatures: Complete inability to perform ICL on out-of-distribution task types, despite extensive pretraining on similar but different tasks.

First experiments:
1. Test function-fitting tasks with varying degrees of problem similarity to assess intra-problem generalization
2. Evaluate API calling performance on unseen API structures to test inter-problem generalization limits
3. Measure translation quality on low-resource language pairs to assess intra-task generalization

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses on function-fitting, API calling, and translation tasks, which may not represent the full spectrum of real-world ICL applications
- The generalization definitions, while systematic, may not align with all practical use cases of in-context learning
- The failure at inter-problem generalization is based on constrained task distributions and may not hold for more diverse or complex problem spaces
- The emphasis on training data diversity may oversimplify the complex interplay between architecture, objectives, and generalization

## Confidence
- High: Claims about transformers' strong performance on intra-task and intra-problem generalization
- Medium: Claims about transformers' fundamental failure at inter-problem generalization across all tested domains
- Medium: Claims about training data diversity being the key factor for improving ICL generalization

## Next Checks
1. Test inter-problem generalization claims on more diverse and complex task distributions, including real-world datasets beyond function-fitting, API calling, and translation
2. Investigate how model size and architecture variations affect ICL generalization capabilities across all three generalization dimensions
3. Evaluate the impact of different pretraining objectives and optimization strategies on achieving inter-problem generalization, beyond just training data diversity