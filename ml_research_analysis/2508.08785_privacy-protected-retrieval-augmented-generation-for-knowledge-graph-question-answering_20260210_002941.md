---
ver: rpa2
title: Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question
  Answering
arxiv_id: '2508.08785'
source_url: https://arxiv.org/abs/2508.08785
tags:
- entities
- abstraction
- arog
- llms
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses privacy concerns in RAG systems using KGs
  by proposing ARoG, a framework that anonymizes entities while preserving semantic
  meaning. It introduces relation-centric and structure-oriented abstraction strategies
  to convert anonymous entities into retrievable concepts and guide retrieval without
  exposing sensitive data.
---

# Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering

## Quick Facts
- arXiv ID: 2508.08785
- Source URL: https://arxiv.org/abs/2508.08785
- Reference count: 11
- Primary result: ARoG achieves strong privacy protection while maintaining high accuracy in KGQA through semantic-preserving anonymization

## Executive Summary
This paper introduces ARoG, a privacy-protected framework for Retrieval-Augmented Generation (RAG) systems using Knowledge Graphs (KGs). The framework addresses privacy concerns by anonymizing entities while preserving semantic meaning, enabling accurate question answering without exposing sensitive data. Through relation-centric and structure-oriented abstraction strategies, ARoG converts anonymous entities into retrievable concepts that guide the retrieval process. The approach demonstrates strong performance across three benchmark datasets while providing robust privacy protection against various attacks.

## Method Summary
ARoG employs a two-stage abstraction process that transforms sensitive entity information into anonymized representations. The framework first applies relation-centric abstraction to identify and encode semantic relationships between entities, then uses structure-oriented abstraction to capture the topological patterns within the KG. These abstractions preserve the essential information needed for accurate retrieval while removing identifiable entity details. The system integrates these anonymized representations into the RAG pipeline, allowing models to retrieve relevant information and generate answers without direct access to sensitive data.

## Key Results
- Achieves strong performance on three benchmark KGQA datasets while protecting entity privacy
- Outperforms existing methods in privacy-protected scenarios through semantic-preserving anonymization
- Demonstrates robustness against various privacy attacks through perturbation-based testing

## Why This Works (Mechanism)
ARoG works by creating semantic-preserving abstractions that maintain the relational and structural information necessary for accurate retrieval while removing identifiable entity details. The relation-centric approach captures the semantic meaning of relationships between entities, while the structure-oriented method preserves the topological patterns that guide effective information retrieval. By converting sensitive entities into anonymized concepts that retain their semantic essence, the framework enables accurate KGQA without exposing private information.

## Foundational Learning

- **Knowledge Graph Embeddings**: Vector representations of KG entities and relations that capture semantic meaning. Why needed: Enables semantic search and similarity comparison. Quick check: Can embeddings capture both local and global graph structure effectively.

- **Privacy-Preserving Data Mining**: Techniques for analyzing sensitive data while protecting individual privacy. Why needed: Ensures compliance with data protection regulations. Quick check: Does the method provide provable privacy guarantees under formal definitions.

- **Semantic Similarity Measures**: Methods to quantify similarity between anonymized and original concepts. Why needed: Ensures abstractions preserve meaning for accurate retrieval. Quick check: Are similarity scores correlated with retrieval accuracy.

- **Adversarial Robustness**: System's ability to resist attacks aimed at recovering private information. Why needed: Validates the effectiveness of privacy protection. Quick check: Can the system withstand targeted re-identification attempts.

## Architecture Onboarding

Component map: Question -> Entity Recognition -> ARoG Abstraction -> Retriever -> Generator -> Answer
Critical path: Question processing flows through ARoG's abstraction layer before reaching the retriever, with the abstracted representations guiding the entire retrieval process.
Design tradeoffs: Balances privacy protection (through aggressive anonymization) against retrieval accuracy (requiring sufficient semantic preservation).
Failure signatures: Poor anonymization may lead to either loss of retrieval accuracy or insufficient privacy protection.
First experiments: 1) Test abstraction quality on entity recognition tasks, 2) Evaluate retrieval performance with different anonymization levels, 3) Measure privacy protection against synthetic attacks.

## Open Questions the Paper Calls Out
None

## Limitations
- Privacy claims rely primarily on synthetic anonymization experiments rather than real-world privacy risk assessment
- Effectiveness across diverse knowledge domains and entity types remains uncertain
- Computational overhead of two-stage abstraction process not fully characterized for real-time deployment

## Confidence
- Privacy protection claims: Medium
- Performance improvements: High
- Generalizability across domains: Low

## Next Checks
1. Conduct user studies to assess whether the anonymized entities are truly indistinguishable from real data to human observers
2. Test ARoG's performance and privacy protection on knowledge graphs containing sensitive information from different domains (healthcare, finance, etc.)
3. Evaluate the framework's robustness against adversarial attacks designed to recover original entity information from anonymized representations