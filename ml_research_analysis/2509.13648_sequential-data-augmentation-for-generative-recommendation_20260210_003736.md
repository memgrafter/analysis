---
ver: rpa2
title: Sequential Data Augmentation for Generative Recommendation
arxiv_id: '2509.13648'
source_url: https://arxiv.org/abs/2509.13648
tags:
- training
- target
- data
- augmentation
- strategies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of data augmentation in generative
  recommendation systems, which is critical for improving model generalization and
  performance but often overlooked or inconsistently applied. The authors conduct
  a thorough analysis of how different data augmentation strategies reshape training
  distributions and influence model alignment with future targets and generalization
  to unseen inputs.
---

# Sequential Data Augmentation for Generative Recommendation

## Quick Facts
- arXiv ID: 2509.13648
- Source URL: https://arxiv.org/abs/2509.13648
- Reference count: 40
- Primary result: GenPAS improves NDCG@10 by up to 783.7% on ML1M dataset compared to Last-Target strategy

## Executive Summary
This paper addresses the critical but often overlooked role of data augmentation in generative recommendation systems. The authors propose GenPAS, a principled three-step sampling framework that models augmentation as a stochastic process over input-target pairs with controllable bias parameters. Through extensive experiments on benchmark and industrial datasets, GenPAS demonstrates superior accuracy, data efficiency, and parameter efficiency compared to existing strategies. The framework unifies existing augmentation approaches as special cases and enables flexible control of the training distribution, addressing the challenge of optimizing augmentation for better model generalization.

## Method Summary
GenPAS (Generative Pre-training with Augmented Sequences) is a three-step sampling framework that models data augmentation as a stochastic process over input-target pairs. The method samples a subsequence length from a length distribution, then samples the subsequence position using two bias parameters that control how close the subsequence is to the sequence start and target position, respectively. This approach unifies existing augmentation strategies as special cases and enables controllable bias in the training distribution. The framework is evaluated on SASRec and TIGER architectures across multiple datasets, demonstrating significant improvements in recommendation accuracy and efficiency compared to traditional augmentation methods.

## Key Results
- GenPAS improves NDCG@10 by up to 783.7% on ML1M dataset compared to Last-Target strategy
- Achieves 6.6x better data efficiency than baseline methods
- Outperforms existing strategies on industrial-scale datasets with 96.5% improvement in HR@10

## Why This Works (Mechanism)
GenPAS works by explicitly modeling the augmentation process as a stochastic sampling procedure that captures the distribution of training data. By introducing bias parameters that control the proximity of sampled subsequences to both the sequence start and target position, the method can optimize the training distribution to better align with the test distribution. This principled approach addresses the fundamental problem that traditional augmentation strategies either overfit to specific sequence positions or fail to capture the diversity needed for robust generalization. The framework's ability to unify existing methods as special cases provides theoretical justification for why certain strategies work better than others in specific contexts.

## Foundational Learning

**Stochastic Process Modeling**: Understanding how data augmentation can be formalized as a random process over input-target pairs is essential for principled method design. Quick check: Can you derive the probability distribution used in GenPAS from first principles?

**Total Variation Distance**: This metric quantifies the difference between training and test distributions, providing theoretical guidance for augmentation strategy selection. Quick check: Calculate the TV distance between two simple categorical distributions to verify understanding.

**Contiguous vs Non-contiguous Sampling**: The paper's finding that contiguous subsequences outperform non-contiguous ones challenges common assumptions about data augmentation flexibility. Quick check: Explain why contiguous sampling might preserve temporal dependencies better than random deletion or reordering.

## Architecture Onboarding

**Component Map**: Data Generator -> GenPAS Sampler -> Sequence Encoder -> Prediction Head -> Loss Function

**Critical Path**: The augmentation process occurs at the data generator level, where sequences are transformed into training examples before being fed to the encoder. This preprocessing step is critical because it directly determines the quality and diversity of training data.

**Design Tradeoffs**: GenPAS trades computational complexity for better generalization. The three-step sampling process adds overhead compared to simple strategies, but this cost is justified by the significant performance gains and improved data efficiency.

**Failure Signatures**: Poor performance may indicate: 1) inappropriate bias parameter settings for the specific dataset, 2) violation of the i.i.d. user assumption, or 3) model architecture mismatch with the augmentation strategy.

**First Experiments**:
1. Compare GenPAS with different (α, β, γ) parameter settings on a small validation set to identify optimal configurations
2. Run ablation studies removing each bias parameter to understand their individual contributions
3. Test the framework on a simple sequential model before applying to complex architectures like SASRec

## Open Questions the Paper Calls Out

**Open Question 1**: How do specific generative model architectures and training objectives (e.g., contrastive vs. generative losses) modulate the optimal configuration of sequence augmentation parameters? While GenPAS is shown to work on SASRec and TIGER, the study does not isolate the causal impact of architectural inductive biases on the optimal settings.

**Open Question 2**: What are the formal lower bounds for the distance between training and test target distributions under different augmentation strategies? The paper provides upper bounds on Total Variation distance but lacks theoretical lower bounds to certify when an augmentation strategy is provably insufficient.

**Open Question 3**: Is the exclusion of non-contiguous sampling methods (e.g., item deletion, reordering) universally justified, or does their utility depend on specific model-data interactions? The paper empirically dismisses non-contiguous inputs for tested models but does not verify if this holds for all generative recommendation settings.

## Limitations
- Limited scalability analysis across diverse recommendation scenarios beyond proprietary industrial datasets
- Absence of computational overhead comparison with simpler augmentation strategies
- Lack of ablation studies to isolate contributions of individual GenPAS components

## Confidence
- **High**: The theoretical framework of GenPAS and its ability to unify existing augmentation strategies as special cases
- **Medium**: The experimental results demonstrating performance improvements on benchmark and industrial datasets
- **Low**: The generalizability of GenPAS to diverse recommendation scenarios and the absence of computational overhead analysis

## Next Checks
1. Conduct ablation studies to isolate the contributions of individual components within the GenPAS framework
2. Evaluate GenPAS on a broader range of recommendation tasks, including those with sparse interactions and highly dynamic user behavior
3. Analyze the computational overhead of GenPAS compared to simpler augmentation strategies in large-scale settings