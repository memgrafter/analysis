---
ver: rpa2
title: Composable Building Blocks for Controllable and Transparent Interactive AI
  Systems
arxiv_id: '2506.02262'
source_url: https://arxiv.org/abs/2506.02262
tags:
- building
- blocks
- systems
- interactive
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach to enhance the transparency
  and controllability of interactive AI systems by representing them as sequences
  of structural building blocks (e.g., AI models, control mechanisms) and explaining
  them through visual building blocks (e.g., XAI techniques). The method extends beyond
  individual model explanations to address system-level workflows, enabling both humans
  and automated agents like LLMs to understand and audit complex architectures.
---

# Composable Building Blocks for Controllable and Transparent Interactive AI Systems

## Quick Facts
- arXiv ID: 2506.02262
- Source URL: https://arxiv.org/abs/2506.02262
- Reference count: 33
- This paper proposes a novel approach to enhance the transparency and controllability of interactive AI systems by representing them as sequences of structural building blocks and explaining them through visual building blocks

## Executive Summary
This paper introduces a compositional framework for creating transparent and controllable interactive AI systems by representing them as sequences of structural building blocks (AI models, control mechanisms) explained through visual building blocks (XAI techniques). The approach extends beyond individual model explanations to address system-level workflows, enabling both humans and automated agents like LLMs to understand and audit complex architectures. A 5-layer architecture is proposed with structural building blocks defining the system pipeline, an API exposing functionality, and visual building blocks providing explanations and control interfaces.

## Method Summary
The proposed method extends XAI beyond individual model explanations to system-level workflows by introducing structural building blocks (AI models, control mechanisms) and visual building blocks (explanatory techniques). A 5-layer architecture is presented: structural building blocks define the system pipeline, control mechanisms enable system behavior modification, an API exposes functionality, visual building blocks provide explanations, and an interaction layer enables human-machine collaboration. The approach uses Explainable AI techniques like LIME and SHAP to explain both individual models and the overall system behavior, with What-If tools for interactive exploration.

## Key Results
- Prototype heart disease prediction ensemble demonstrates the approach with model ensembles and control mechanisms explained via LIME, SHAP, and What-If tools
- System serves as a shared knowledge base aligning human and machine interpretability of AI models within interactive systems
- Structural blocks like model ensembles and control mechanisms (filters, guards) can be explained at the system level

## Why This Works (Mechanism)
The compositional approach works by breaking down complex AI systems into interpretable building blocks that can be individually explained and then composed into a coherent whole. By representing both the structural components (models, control mechanisms) and their explanations (visual blocks) as standardized elements, the system creates a common language for human and machine understanding. The 5-layer architecture provides a systematic framework where each layer serves a specific purpose in enabling transparency and control, from defining the pipeline to exposing functionality and providing explanations.

## Foundational Learning
- **5-layer architecture**: Required to systematically organize system components from pipeline definition to interaction; quick check: can you map each layer to its specific function in the prototype?
- **Structural building blocks**: AI models and control mechanisms that form the system pipeline; quick check: identify which blocks in the heart disease prototype serve as structural components
- **Visual building blocks**: XAI techniques used to explain structural components; quick check: what techniques are used to explain the ensemble model?
- **Control mechanisms**: Filters, guards, and policies that modify system behavior; quick check: how do control mechanisms differ from AI models in the architecture?
- **API layer**: Interface exposing system functionality to users and automated agents; quick check: what capabilities does the API need to support the building block approach?

## Architecture Onboarding

Component Map: Structural Blocks -> Control Mechanisms -> API -> Visual Blocks -> Interaction Layer

Critical Path: User/LLM requests explanation/control -> API processes request -> Control mechanisms adjust behavior -> Visual blocks generate explanation -> Interaction layer delivers to user

Design Tradeoffs: Granular building blocks vs. system complexity; standardization vs. flexibility; human interpretability vs. computational efficiency

Failure Signatures: Incomplete explanations (missing visual blocks), uncontrolled behavior (broken control mechanisms), API failures (unresponsive interface)

First Experiments:
1. Deploy the heart disease ensemble prototype and verify all 5 layers function correctly
2. Test explanation generation for individual structural blocks using LIME/SHAP
3. Validate control mechanism effectiveness through system behavior modification

## Open Questions the Paper Calls Out
None

## Limitations
- Prototype limited to single heart disease ensemble without multi-domain validation
- No empirical validation with end-users or automated agents to measure comprehension
- 5-layer architecture lacks quantitative benchmarks or comparative studies against existing approaches

## Confidence
- Medium for system transparency benefits (conceptual framework demonstrated but no measurable impact)
- Low for human-machine interpretability alignment (no user studies or agent-based validation)
- Medium for compositional approach validity (well-grounded in XAI literature but not empirically validated)

## Next Checks
1. Implement a multi-domain prototype (beyond healthcare) to test architectural scalability and generalizability
2. Conduct controlled experiments measuring human comprehension and decision-making with/without the building block explanations
3. Develop and test LLM agent integration to verify automated understanding and control capabilities claimed in the paper