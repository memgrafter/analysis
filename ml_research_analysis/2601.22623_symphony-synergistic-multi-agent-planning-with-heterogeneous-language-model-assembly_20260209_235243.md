---
ver: rpa2
title: 'SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model
  Assembly'
arxiv_id: '2601.22623'
source_url: https://arxiv.org/abs/2601.22623
tags:
- agent
- symphony
- search
- reasoning
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SYMPHONY addresses the limited diversity in LLM-based planning
  by introducing a multi-agent framework that integrates heterogeneous language models
  for Monte Carlo Tree Search. The method combines UCB-based agent scheduling, entropy-modulated
  confidence scoring, and pool-wise memory sharing to enhance exploration and robustness.
---

# SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly

## Quick Facts
- arXiv ID: 2601.22623
- Source URL: https://arxiv.org/abs/2601.22623
- Reference count: 40
- Key outcome: SYMPHONY achieves state-of-the-art performance in LLM-based planning using heterogeneous models, outperforming baselines in accuracy and efficiency on complex reasoning tasks.

## Executive Summary
SYMPHONY introduces a novel multi-agent framework for planning that leverages heterogeneous language models within a Monte Carlo Tree Search (MCTS) structure. By integrating UCB-based agent scheduling, entropy-modulated confidence scoring, and pool-wise memory sharing, SYMPHONY enhances exploration, robustness, and decision-making in complex reasoning and planning tasks. The approach demonstrates superior performance across diverse datasets (HotpotQA, WebShop, MBPP), even with open-source models on consumer hardware, while maintaining efficiency in node expansions and token usage.

## Method Summary
SYMPHONY enhances LLM-based planning by integrating heterogeneous language models into a Monte Carlo Tree Search framework. It employs a UCB-based agent scheduling mechanism to dynamically select the most suitable model for each decision point, entropy-modulated confidence scoring to assess and prioritize promising actions, and pool-wise memory sharing to enable collaborative learning among agents. This synergistic assembly of models improves exploration, reduces redundancy, and achieves state-of-the-art performance in tasks requiring complex reasoning and planning, such as HotpotQA, WebShop, and MBPP, while maintaining efficiency in terms of node expansions and token costs.

## Key Results
- SYMPHONY achieves state-of-the-art performance on HotpotQA, WebShop, and MBPP benchmarks.
- Demonstrates strong efficiency with fewer node expansions and lower token costs compared to prior methods.
- Shows robustness and adaptability, performing well even with open-source models on consumer hardware.

## Why This Works (Mechanism)
SYMPHONY's success stems from its synergistic integration of heterogeneous language models within an MCTS framework. By dynamically scheduling agents using UCB-based policies, the system selects the most appropriate model for each decision point, optimizing exploration and exploitation. Entropy-modulated confidence scoring ensures that high-uncertainty actions are prioritized, enhancing robustness in complex scenarios. Pool-wise memory sharing allows agents to collaboratively learn and refine their strategies, reducing redundancy and improving overall planning efficiency. This multi-agent assembly leverages the strengths of diverse models, enabling superior performance in tasks requiring intricate reasoning and decision-making.

## Foundational Learning
- **Monte Carlo Tree Search (MCTS)**: A decision-making algorithm that balances exploration and exploitation by iteratively building a search tree; needed to systematically explore action spaces in planning tasks.
- **Upper Confidence Bound (UCB)**: A strategy for selecting actions in MCTS that balances exploration of less-visited nodes with exploitation of known high-reward paths; needed to dynamically schedule heterogeneous agents.
- **Entropy Modulation**: A technique to measure uncertainty in model predictions and adjust confidence scores; needed to prioritize uncertain or ambiguous actions for robust planning.
- **Pool-wise Memory Sharing**: A collaborative mechanism where agents share and update memory to avoid redundant computations and accelerate learning; needed to enhance efficiency and scalability in multi-agent systems.
- **Heterogeneous Model Integration**: Combining diverse language models with varying strengths to leverage complementary capabilities; needed to improve adaptability and performance across complex reasoning tasks.

## Architecture Onboarding

**Component Map**
UCB Scheduler -> Heterogeneous LLMs Pool -> Entropy-Modulated Confidence Scorer -> MCTS Tree -> Pool-wise Memory Store -> UCB Scheduler (feedback loop)

**Critical Path**
1. UCB scheduler selects the most suitable LLM for the current decision point.
2. Selected LLM generates action proposals.
3. Entropy-modulated confidence scorer evaluates and ranks proposals.
4. MCTS tree updates based on selected action and observed reward.
5. Pool-wise memory store updates shared knowledge across agents.
6. UCB scheduler adjusts future agent selections based on updated MCTS statistics.

**Design Tradeoffs**
- **Exploration vs. Exploitation**: UCB scheduling balances trying new models (exploration) with relying on proven ones (exploitation), optimizing long-term planning accuracy.
- **Model Diversity vs. Coordination Overhead**: Heterogeneous models bring varied strengths but require careful synchronization via memory sharing to avoid conflicts.
- **Confidence Scoring Granularity vs. Computational Cost**: Finer entropy modulation improves decision quality but increases scoring overhead.

**Failure Signatures**
- **Over-reliance on single model**: UCB scheduler fails to diversify agent selection, leading to brittle planning.
- **Memory staleness**: Pool-wise memory updates lag behind, causing agents to repeat outdated strategies.
- **Confidence miscalibration**: Entropy scoring underestimates uncertainty, pushing the system into risky decisions.

**First 3 Experiments to Run**
1. Validate UCB scheduling by comparing single-agent vs. multi-agent performance on a simple grid-world planning task.
2. Test entropy-modulated confidence scoring by measuring robustness to noisy or ambiguous action proposals in a controlled environment.
3. Assess pool-wise memory sharing by measuring convergence speed and redundancy reduction in a multi-agent cooperative task.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance robustness is uncertain when scaling to domains with significantly larger action spaces or longer planning horizons than those tested.
- Ablation studies focus on internal components rather than comparing against a broader range of alternative multi-agent or planning frameworks.
- Detailed wall-clock time and computational overhead measurements across different hardware setups are not provided, limiting reproducibility of efficiency claims.

## Confidence
- **High**: SYMPHONY's ability to improve planning performance through heterogeneous model integration and memory sharing is directly validated in experiments.
- **Medium**: Efficiency and scalability claims are supported by results on specific benchmarks and hardware, but broader generalization remains untested.
- **Medium**: Novelty of multi-agent scheduling and confidence scoring mechanisms is partially established, as these build on existing approaches with limited discussion of practical differences from prior work.

## Next Checks
1. Evaluate SYMPHONY's performance and efficiency on domains with significantly larger action spaces and longer planning horizons than those in the current benchmarks.
2. Conduct a comprehensive ablation study comparing SYMPHONY's components against a wider range of alternative multi-agent and planning frameworks, not just its internal ablations.
3. Provide detailed wall-clock time and computational overhead measurements across multiple hardware setups to substantiate efficiency claims and enable reproducibility.