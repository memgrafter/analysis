---
ver: rpa2
title: Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning
arxiv_id: '2505.15467'
source_url: https://arxiv.org/abs/2505.15467
tags:
- tasks
- learning
- task
- arxiv
- joint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses catastrophic forgetting in large language models
  during incremental learning of new tasks. Joint Flashback Adaptation introduces
  a limited number of prompts from old tasks (flashbacks) during new task adaptation
  and constrains output deviations using divergence loss.
---

# Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning

## Quick Facts
- **arXiv ID:** 2505.15467
- **Source URL:** https://arxiv.org/abs/2505.15467
- **Reference count:** 15
- **Primary result:** Achieves best or second-best performance on most evaluated tasks while reducing catastrophic forgetting using minimal replay data

## Executive Summary
Joint Flashback Adaptation addresses catastrophic forgetting in large language models during incremental learning of new tasks. The method introduces a limited number of prompts from old tasks (flashbacks) during new task adaptation and constrains output deviations using divergence loss. It further interpolates latent tasks between flashbacks and new tasks to enable joint learning, alleviating data sparsity and facilitating knowledge sharing. Experiments on Vicuna-13B and Llama3.1-8B across 1000+ instruction-following, arithmetic reasoning, and general reasoning tasks show that the method improves generalization on new tasks while reducing forgetting in old tasks, achieving the best or second-best performance on most evaluated tasks compared to six state-of-the-art baselines, while requiring only a few flashback prompts without access to replay data.

## Method Summary
Joint Flashback Adaptation introduces a limited number of prompts from old tasks (flashbacks) during new task adaptation and constrains output deviations using divergence loss. It further interpolates latent tasks between flashbacks and new tasks to enable joint learning, alleviating data sparsity and facilitating knowledge sharing. The method addresses catastrophic forgetting by maintaining knowledge of old tasks while learning new ones, using a combination of selective replay and output regularization.

## Key Results
- Achieved best or second-best performance on most evaluated tasks compared to six state-of-the-art baselines
- Improved generalization on new tasks while reducing forgetting in old tasks
- Required only a few flashback prompts without access to replay data

## Why This Works (Mechanism)
The mechanism works by combining selective replay of old task prompts with regularization of output distributions. By introducing flashbacks from previous tasks during new task training, the model maintains exposure to previously learned patterns. The divergence loss ensures that outputs for old tasks remain consistent with their original distributions, preventing catastrophic forgetting. The latent task interpolation creates intermediate training examples that bridge the gap between old and new tasks, enabling smoother knowledge transfer and reducing the abrupt shift that typically causes forgetting.

## Foundational Learning

**Catastrophic forgetting:** The tendency of neural networks to rapidly lose previously acquired knowledge when trained on new tasks. Needed to understand the problem being solved; quick check: verify models show performance degradation on old tasks after new task training.

**Incremental learning:** The process of learning new tasks sequentially without retraining on previous tasks. Needed to contextualize the adaptation scenario; quick check: confirm the method operates without full retraining.

**Divergence loss:** A regularization technique that constrains the difference between model outputs before and after adaptation. Needed to understand how the method prevents forgetting; quick check: verify divergence loss maintains output consistency for old tasks.

**Latent space interpolation:** The technique of creating intermediate representations between different task distributions. Needed to understand how knowledge sharing is facilitated; quick check: confirm interpolation improves performance on both old and new tasks.

## Architecture Onboarding

**Component map:** Flashback prompts -> Divergence loss -> Latent task interpolation -> Joint adaptation

**Critical path:** The core adaptation process flows from flashback selection through divergence loss computation to latent task interpolation, with joint optimization occurring across all components simultaneously.

**Design tradeoffs:** The method trades increased training complexity for reduced memory requirements compared to full replay approaches. The interpolation mechanism adds computational overhead but enables better knowledge sharing than simple selective replay.

**Failure signatures:** Poor performance on old tasks indicates insufficient divergence loss weighting; degraded new task performance suggests excessive regularization or inadequate interpolation.

**First experiments:** 1) Verify divergence loss prevents forgetting without blocking new learning, 2) Test interpolation effectiveness on a simple two-task scenario, 3) Compare flashback selection strategies for optimal performance.

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability to much larger models beyond the tested 8B-13B parameter range remains unverified
- Performance when adapting to more than two sequential tasks has not been thoroughly evaluated
- Computational overhead of the latent task interpolation mechanism could impact practical deployment

## Confidence

**Performance claims:** High - Comprehensive experiments on two different model architectures across diverse task categories provide strong evidence

**Scalability claims:** Medium - Limited testing on larger models raises questions about broader applicability

**Efficiency claims:** Medium - While minimal replay data is required, computational overhead is not extensively analyzed

## Next Checks

1. Evaluate the method's performance when adapting to three or more sequential tasks to assess long-term effectiveness
2. Conduct ablation studies to quantify the contribution of each component (divergence loss, latent task interpolation, and flashback prompts) to overall performance
3. Test the approach on models with 30B+ parameters to verify scalability and assess any changes in the trade-off between forgetting reduction and new task learning efficiency