---
ver: rpa2
title: 'Debiasing CLIP: Interpreting and Correcting Bias in Attention Heads'
arxiv_id: '2505.17425'
source_url: https://arxiv.org/abs/2505.17425
tags:
- states
- spurious
- image
- dataset
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Locate-Then-Correct (LTC), a method to identify
  and correct bias in CLIP's vision transformer attention heads. LTC uses linear decomposition
  to locate attention states encoding spurious attributes and class features, then
  applies mean-ablation to remove spurious associations and knowledge injection to
  enhance discriminative features.
---

# Debiasing CLIP: Interpreting and Correcting Bias in Attention Heads

## Quick Facts
- arXiv ID: 2505.17425
- Source URL: https://arxiv.org/abs/2505.17425
- Authors: Wei Jie Yeo; Rui Mao; Moloud Abdar; Erik Cambria; Ranjan Satapathy
- Reference count: 40
- Primary result: Introduces Locate-Then-Correct (LTC) method that improves worst-group accuracy by over 50% on Waterbirds, CounterAnimal, and GenderBias-VL datasets without fine-tuning

## Executive Summary
This paper introduces Locate-Then-Correct (LTC), a novel method to identify and correct bias in CLIP's vision transformer attention heads. LTC uses linear decomposition to locate attention states encoding spurious attributes and class features, then applies mean-ablation to remove spurious associations and knowledge injection to enhance discriminative features. The method achieves over 50% improvement in worst-group accuracy compared to non-training baselines while being interpretable and lightweight. When combined with fine-tuning, LTC further improves debiasing performance.

## Method Summary
Locate-Then-Correct (LTC) identifies bias in CLIP's vision transformer attention heads through a two-stage process. First, it uses linear decomposition to locate attention states that encode both spurious attributes (like background) and class features. Then it applies two correction mechanisms: mean-ablation removes spurious associations by averaging out biased representations, while knowledge injection enhances discriminative features by incorporating targeted information. The method focuses on specific attention heads rather than the entire representation, making it computationally efficient. LTC is evaluated on three benchmark datasets with different bias types (background, animal species, gender) and demonstrates superior performance compared to orthogonal projection methods applied to full representations.

## Key Results
- Achieves over 50% improvement in worst-group accuracy compared to non-training baselines on Waterbirds, CounterAnimal, and GenderBias-VL datasets
- Outperforms orthogonal projection methods applied to full representations
- Improves debiasing when used in conjunction with fine-tuning
- Provides interpretable insights into which attention heads encode specific biases

## Why This Works (Mechanism)
LTC works by targeting the specific attention heads that encode both spurious correlations and class-relevant features. The linear decomposition precisely locates these dual-encoding heads, while mean-ablation effectively removes the spurious associations without destroying all information. Knowledge injection then compensates by strengthening the discriminative features that were previously overshadowed by bias. This selective approach preserves model performance while correcting bias, unlike methods that modify entire representations which can degrade overall accuracy.

## Foundational Learning

- **Vision Transformer attention heads**: Required to understand how CLIP processes visual information through self-attention mechanisms. Quick check: Review ViT architecture and attention head operations.
- **Linear decomposition for feature analysis**: Needed to separate spurious from genuine class features in attention states. Quick check: Understand singular value decomposition and its application to representation analysis.
- **Bias in multimodal models**: Essential context for why CLIP exhibits background and demographic biases. Quick check: Review literature on spurious correlations in vision-language models.
- **Mean-ablation technique**: Core mechanism for removing bias without retraining. Quick check: Examine how averaging operations affect representation distributions.
- **Knowledge injection methods**: Used to enhance discriminative features post-ablation. Quick check: Understand techniques for targeted feature enhancement in neural representations.
- **Worst-group accuracy**: Primary evaluation metric for debiasing methods. Quick check: Learn how worst-group accuracy differs from overall accuracy and why it matters for fairness.

## Architecture Onboarding

**Component Map**: Input Images -> CLIP Vision Transformer -> Attention Heads -> LTC Locator (Linear Decomposition) -> Biased Heads Identified -> Mean-Ablation & Knowledge Injection -> Debiased Representations -> Downstream Task Evaluation

**Critical Path**: The critical path flows from input through CLIP's attention mechanism, where LTC intervenes at the head level. The linear decomposition step is crucial as it determines which heads will be corrected, making the accuracy of this identification directly impacts overall debiasing effectiveness.

**Design Tradeoffs**: LTC trades comprehensive representation modification for targeted head-level intervention. This makes it lightweight and interpretable but potentially less effective for biases encoded across multiple heads or at deeper representation levels. The method prioritizes interpretability and computational efficiency over potentially higher but less explainable gains from full-representation approaches.

**Failure Signatures**: If linear decomposition incorrectly identifies heads, bias may persist or legitimate features may be corrupted. Over-aggressive mean-ablation can degrade overall model performance, while insufficient ablation leaves bias intact. Knowledge injection that's too strong can introduce new spurious correlations or distort genuine features.

**First 3 Experiments**:
1. Verify linear decomposition correctly identifies known biased attention heads on a simple synthetic dataset with clear spurious correlations
2. Test mean-ablation alone on Waterbirds dataset to measure baseline effectiveness of spurious feature removal
3. Evaluate knowledge injection on CounterAnimal dataset to confirm it enhances discriminative features without introducing new biases

## Open Questions the Paper Calls Out

The paper identifies several key uncertainties: generalizability of LTC beyond the three evaluated bias types (background, animal species, gender), potential sensitivity to hyperparameters like the threshold τ, and whether performance gains translate to real-world deployments where bias sources are more complex. The method's reliance on fixed CLIP weights and lack of fine-tuning may limit its ability to correct biases requiring representation-level changes. Additionally, the ablation of only top-k heads (k=1) may miss multi-head interactions that encode bias, and the approach's effectiveness for underrepresented domains beyond the studied datasets remains unclear.

## Limitations

- Limited generalizability to bias types beyond background, animal species, and gender
- Potential sensitivity to hyperparameters like the threshold τ
- Reliance on fixed CLIP weights may limit effectiveness for representation-level biases
- Ablation of only top-k heads may miss multi-head interactions encoding bias
- Unclear effectiveness for underrepresented domains beyond studied datasets

## Confidence

- High confidence in the interpretability and lightweight nature of LTC, supported by clear empirical demonstrations and ablation studies
- Medium confidence in the relative effectiveness compared to full-representation debiasing methods, given the controlled experimental settings
- Low confidence in scalability and robustness to unseen bias types, due to limited domain coverage and lack of cross-dataset validation

## Next Checks

1. Test LTC's effectiveness on a broader range of bias types and real-world datasets with more diverse spurious correlations
2. Investigate multi-head debiasing strategies and their impact on both bias mitigation and overall model performance
3. Evaluate the method's robustness when applied to CLIP variants trained on different datasets or with different architectures