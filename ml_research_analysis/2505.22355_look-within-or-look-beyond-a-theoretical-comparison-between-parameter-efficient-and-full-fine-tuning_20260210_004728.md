---
ver: rpa2
title: Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient
  and Full Fine-Tuning
arxiv_id: '2505.22355'
source_url: https://arxiv.org/abs/2505.22355
tags:
- peft
- fine-tuning
- performance
- language
- lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper compares Parameter-Efficient Fine-Tuning (PEFT) methods
  with Full Fine-Tuning (FFT) in terms of representational capacity and robustness,
  grounded in optimization theory. It proves that PEFT is a strict subset of FFT,
  meaning its limited parameter space inherently constrains its representational ability
  and makes it more susceptible to perturbations.
---

# Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning

## Quick Facts
- arXiv ID: 2505.22355
- Source URL: https://arxiv.org/abs/2505.22355
- Reference count: 40
- Primary result: Proves PEFT is mathematically a strict subset of FFT, constraining representational capacity and robustness

## Executive Summary
This paper establishes a theoretical framework comparing Parameter-Efficient Fine-Tuning (PEFT) with Full Fine-Tuning (FFT) through optimization theory. It proves that PEFT operates within a constrained parameter subspace that is a strict mathematical subset of FFT's full optimization space, inherently limiting its representational ability and making it more susceptible to perturbations. The authors introduce provable upper bounds for PEFT's representational capacity and demonstrate that FFT's marginal benefit from additional data and parameters significantly exceeds PEFT's. Experiments across 15 diverse datasets and 11 adversarial test sets validate these theoretical findings, showing FFT consistently outperforms PEFT on complex tasks and adversarial scenarios.

## Method Summary
The study compares PEFT methods (LoRA, AdaLoRA, Prefix-Tuning, IA³, BitFit) against FFT across multiple dimensions using both theoretical proofs and empirical validation. Theoretical analysis establishes PEFT as a strict subset of FFT through measure-zero arguments and proves bounds on representational capacity and perturbation sensitivity. Empirically, the authors fine-tune models (RoBERTa-base/large, LLaMA2-7B/13B/70B, Mistral-7B, OPT-13B, TinyLLaMA) on 15 datasets spanning classification, generation, reasoning, and instruction tasks. They evaluate performance on both original and adversarial test sets (AdvGLUE with 6 subtasks, Adversarial SQuAD with 5 subtasks) using AdamW optimization with extensive hyperparameter tuning across 5 random seeds.

## Key Results
- PEFT is mathematically proven to be a strict subset of FFT, creating inherent representational limitations
- FFT's marginal benefit from additional data and parameters is significantly greater than PEFT's (Theorem 5)
- PEFT shows systematically greater sensitivity to input perturbations than FFT (Theorem 4)
- On adversarial datasets, FFT outperforms PEFT by 5-10% average accuracy (Table 3)
- Performance crossover occurs at approximately 20 samples per class in few-shot settings (Figure 2)

## Why This Works (Mechanism)

### Mechanism 1: PEFT as Strict Subset of FFT
- Claim: PEFT operates within a constrained parameter subspace that is mathematically a strict subset of FFT's full optimization space.
- Mechanism: PEFT updates parameters Φ in a k-dimensional space (k ≪ d) via a non-surjective mapping g: R^k → R^d. This creates a low-dimensional embedded submanifold with Lebesgue measure zero in the full d-dimensional parameter space, meaning PEFT cannot reach most parameter configurations accessible to FFT.
- Core assumption: The mapping g (e.g., low-rank decomposition, sparse updates) cannot cover all directions in the full parameter space R^d.
- Evidence anchors:
  - [abstract]: "We theoretically demonstrate that PEFT is a strict subset of FFT"
  - [section]: Theorem 1 and Appendix F.1 prove that Im(g) has measure zero in R^d when k ≪ d
  - [corpus]: PrunePEFT confirms PEFT achieves "comparable task performance with substantial reduction of trainable parameters"
- Break condition: When PEFT methods approach full-rank updates or use d trainable parameters, the subset relationship weakens toward equivalence.

### Mechanism 2: Bounded Representational Capacity
- Claim: PEFT's parameter count directly constrains the maximum extent of model adaptation through a provable upper bound.
- Mechanism: The output deviation ∥f(x) - f₀(x)∥ is bounded by Σ M^(N-k) L^(N-k) α_k ∥x∥ where α_k ∝ ∥Φ_k∥. Since ∥Φ∥ is limited by PEFT's small parameter count, the representational change is capped. Parameters closer to output layers have greater impact due to smaller exponents N-k.
- Core assumption: Weight norms ∥W₀,k∥ ≤ M and activation Lipschitz constants L_k ≤ L have finite upper bounds.
- Evidence anchors:
  - [abstract]: "limited parameter space constrains the model's representational ability"
  - [section]: Theorem 2 (Equation 6) and Figure 1 show PEFT incremental parameters cluster sharply near zero (steeper distributions)
  - [corpus]: GraLoRA notes LoRA "suffers from overfitting when the bottleneck is widened" and performs best only at ranks 32-64
- Break condition: For simple tasks with straightforward label characteristics (e.g., basic classification), constrained capacity is sufficient and PEFT can match or exceed FFT.

### Mechanism 3: Heightened Perturbation Sensitivity
- Claim: PEFT exhibits systematically greater sensitivity to input perturbations than FFT due to its inability to counteract orthogonal disturbance components.
- Mechanism: Perturbations ε decompose into subspace-aligned (ε∥) and orthogonal (ε⊥) components. PEFT can only address ε∥ within its k-dimensional subspace, leaving ε⊥ unmitigated. This yields ∆L_peft > ∆L_full, meaning greater loss fluctuation under the same perturbation.
- Core assumption: Hessian matrix is positive definite or semi-definite; perturbations have components both within and orthogonal to PEFT's subspace.
- Evidence anchors:
  - [abstract]: PEFT is "more susceptible to perturbations"
  - [section]: Theorem 4 (Equation 8) and Tables 3-5 show FFT consistently outperforms PEFT on AdvGLUE and Adversarial SQuAD (e.g., RoBERTa-base FFT: 36.58 avg vs LoRA: 30.89 avg on AdvGLUE)
  - [corpus]: Weak corpus evidence—neighbors focus on efficiency rather than robustness
- Break condition: When perturbations align purely with PEFT's subspace (ε⊥ = 0), the robustness gap narrows significantly.

## Foundational Learning

- **Optimization on Manifolds**
  - Why needed here: Understanding Theorem 1 requires grasping why a k-dimensional embedded submanifold cannot cover R^d.
  - Quick check question: Given g: R^8 → R^4096 (LoRA adapting a 4096-dim weight matrix), can g be surjective? Why does Sard's theorem matter?

- **Rademacher Complexity and Generalization Bounds**
  - Why needed here: Theorem 5's marginal benefit analysis relies on generalization error scaling as O(√(d/N)) for FFT vs O(√(k/N)) for PEFT.
  - Quick check question: If FFT has d=7B parameters and PEFT has k=8M, what is the theoretical ratio of marginal data benefits ∆R_full/∆R_peft?

- **Hessian-Based Loss Landscape Analysis**
  - Why needed here: Theorem 4's perturbation sensitivity proof uses Hessian eigenstructure and pseudo-inverse properties.
  - Quick check question: Why does H_Φ^+ (pseudo-inverse of P^T H P) yield larger loss perturbations than H^(-1) when ε has orthogonal components?

## Architecture Onboarding

- **Component map:**
  - Base model: Frozen pretrained weights θ₀ ∈ R^d
  - PEFT parameters: Trainable subset Φ ∈ R^k (k ≪ d)
  - Mapping function g: Projects Φ to full space (e.g., LoRA's BA decomposition, Prefix-Tuning's soft prompts)
  - Merge operation: θ_final = θ₀ + g(Φ) for inference

- **Critical path:**
  1. Select PEFT method and identify trainable parameter locations (attention layers, biases, prefixes)
  2. Initialize Φ (typically near-zero for LoRA, random for prefixes)
  3. Forward: Compute g(Φ) and apply to frozen θ₀ during each pass
  4. Backward: Compute gradients only for Φ, accumulate updates
  5. Merge: After training, fold g(Φ) into θ₀ for deployment efficiency

- **Design tradeoffs:**
  - **Rank r (LoRA):** Higher r increases capacity (Theorem 2) but yields diminishing returns past critical rank r_c (Theorem 3, empirically r=8-16 often sufficient)
  - **Training data size N:** FFT requires N > ~20 samples per class to surpass PEFT (Figure 2); below this, PEFT's regularization advantage dominates
  - **Task complexity:** Simple classification may favor PEFT; reasoning/math/SQL generation favor FFT (Table 1: FFT +7.31% on GSM8k vs LoRA)

- **Failure signatures:**
  - PEFT matches/exceeds FFT on clean data but degrades severely on adversarial test sets (Table 3: LoRA beats FFT by 1.3% on GLUE but loses by 5.69% on AdvGLUE)
  - Performance plateaus despite increasing PEFT rank r from 8→16→32 (Table 4: minimal improvement)
  - Incremental parameter distribution is sharply peaked near zero with low variance (Figure 1: LoRA std=0.0117 vs FFT std=0.0268), indicating limited knowledge acquisition

- **First 3 experiments:**
  1. **Robustness baseline:** Train RoBERTa-base with LoRA (r=8), AdaLoRA, BitFit, Prefix-Tuning, and FFT on GLUE. Evaluate on AdvGLUE to quantify robustness gap. Expected: FFT outperforms all PEFT on adversarial subset by 5-10%.
  2. **Data scaling inflection point:** Fine-tune LLaMA2-7B with LoRA vs FFT using k ∈ {5, 10, 20, 50, 100, 200} samples per class on SST-2, EmoC, TREC, Amazon, AGNews. Identify crossover point where FFT begins outperforming PEFT (expected: k ≈ 20).
  3. **Rank saturation test:** Train LoRA with r ∈ {8, 16, 32, 64} on Adversarial SQuAD. Measure if adversarial EM/F1 improves beyond r=16 to validate Theorem 3's diminishing marginal benefit prediction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can "task complexity" be formally defined to accurately predict the performance gap between PEFT and FFT?
- Basis in paper: [explicit] The authors state in the limitations: "We do not provide a strict definition of task complexity, we empirically observe that tasks such as reasoning are generally more complex."
- Why unresolved: The paper relies on empirical observation to categorize tasks (e.g., reasoning vs. classification) rather than providing a quantitative metric that determines when PEFT's capacity will be insufficient.
- What evidence would resolve it: A quantitative metric (e.g., based on intrinsic dimensionality or feature variance) that correlates strongly with the performance delta between PEFT and FFT across diverse tasks.

### Open Question 2
- Question: Can hybrid fine-tuning strategies (combining partial FFT with PEFT) bridge the gap in robustness and representational capacity?
- Basis in paper: [explicit] The authors explicitly list as a limitation: "We focus solely on a single PEFT method and do not extend our investigation to hybrid PEFT approaches."
- Why unresolved: The study establishes a strict theoretical subset relationship for pure PEFT vs. FFT, but it remains unexplored if partially unfreezing critical layers (a hybrid approach) can mitigate the identified robustness issues while maintaining efficiency.
- What evidence would resolve it: Empirical results showing that hybrid methods sustain performance on adversarial datasets comparable to full FFT, while utilizing significantly fewer trainable parameters than full FFT.

### Open Question 3
- Question: How can the critical parameter count ($r_c$) be estimated prior to training to avoid the "Rule of Diminishing Marginal Benefit"?
- Basis in paper: [inferred] Theorem 3 proves the existence of a critical parameter threshold $r_c$ beyond which PEFT yields negligible returns, but the paper does not provide a method for calculating this value for a specific downstream task.
- Why unresolved: While the theoretical bound exists, practitioners currently lack a mechanism to determine the optimal rank or parameter count without extensive trial and error.
- What evidence would resolve it: A predictive framework or heuristic that estimates the optimal number of trainable parameters based on dataset size and model architecture.

### Open Question 4
- Question: How can PEFT methods be modified to defend against perturbations orthogonal to the tuning subspace?
- Basis in paper: [inferred] Theorem 4 proves PEFT is susceptible to orthogonal perturbations ($\epsilon_\perp$) because the model "loses the ability to extract effective features" in those directions, but no mitigation strategy is proposed.
- Why unresolved: The theoretical analysis suggests a fundamental geometric vulnerability in PEFT, but it is unclear if the subspace can be rotated or regularized to improve robustness without increasing dimensionality to that of FFT.
- What evidence would resolve it: A modified PEFT algorithm that demonstrably reduces the loss sensitivity to orthogonal perturbations ($\Delta L_{peft}$) on adversarial test sets like AdvGLUE.

## Limitations

- The theoretical proofs rely on simplifying assumptions about weight norms and activation Lipschitz constants that may not hold uniformly across all network architectures
- The perturbation sensitivity analysis assumes Hessian positiveness, which may not hold near saddle points
- The empirical validation focuses primarily on transformer-based architectures, potentially limiting generalizability to other model families
- The measure-zero argument for PEFT's subspace assumes k ≪ d remains strictly true, but some modern PEFT variants approach full-rank updates

## Confidence

- **High confidence**: PEFT as strict subset of FFT (Theorem 1), marginal benefit scaling differences (Theorem 5)
- **Medium confidence**: Perturbation sensitivity bounds (Theorem 4) due to Hessian assumptions, few-shot crossover point predictions
- **Low confidence**: Exact rank saturation thresholds across all task types, universal applicability to non-transformer architectures

## Next Checks

1. **Architectural generalization test**: Apply the theoretical framework to CNN and MLP architectures to verify if PEFT vs FFT robustness gaps persist outside the transformer domain
2. **Non-convexity stress test**: Generate synthetic loss landscapes with known negative Hessian eigenvalues to validate Theorem 4's perturbation bounds under realistic conditions
3. **Extreme parameter ratio experiment**: Test PEFT methods where k/d approaches 0.1-0.5 (rather than typical 0.001) to examine when the strict subset relationship breaks down