---
ver: rpa2
title: Information-Theoretic Complementary Prompts for Improved Continual Text Classification
arxiv_id: '2505.20933'
source_url: https://arxiv.org/abs/2505.20933
tags:
- learning
- tasks
- knowledge
- prompt
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces InfoComp, an information-theoretic approach
  to continual text classification (CTC) that addresses catastrophic forgetting by
  learning two complementary prompt spaces: P-Prompt (task-specific) and S-Prompt
  (task-invariant). Drawing inspiration from complementary learning systems theory,
  InfoComp leverages mutual information maximization between prompts and other parameters,
  and between different encoded representations, to generate more informative prompts.'
---

# Information-Theoretic Complementary Prompts for Improved Continual Text Classification

## Quick Facts
- arXiv ID: 2505.20933
- Source URL: https://arxiv.org/abs/2505.20933
- Reference count: 40
- Primary result: InfoComp achieves 80.0% average accuracy on standard CTC benchmarks, improving over ProgPrompt by 0.9-1.3%

## Executive Summary
This paper introduces InfoComp, an information-theoretic approach to continual text classification that addresses catastrophic forgetting through complementary prompt learning. The method leverages mutual information maximization to learn two distinct prompt spaces: P-Prompt for task-specific knowledge and S-Prompt for task-invariant knowledge. By drawing inspiration from complementary learning systems theory, InfoComp generates more informative prompts while maintaining constant prompt length regardless of task sequence length, and operates without requiring data replay.

## Method Summary
InfoComp introduces a novel approach to continual text classification by learning two complementary prompt spaces through mutual information maximization. The method learns P-Prompt to capture task-specific knowledge for mitigating forgetting, and S-Prompt to preserve task-invariant knowledge for improving forward knowledge transfer. Two novel loss functions are introduced: one enhances task-specific knowledge accumulation in P-Prompt, while the other preserves task-invariant knowledge in S-Prompt. The approach is theoretically grounded in complementary learning systems theory and demonstrates significant performance improvements over previous state-of-the-art methods on both standard and long-sequence CTC benchmarks.

## Key Results
- Achieves 80.0% average accuracy on standard CTC benchmarks
- Improves over ProgPrompt by 0.9-1.3% on standard benchmarks
- Improves over ProgPrompt by 2.7% on long-sequence benchmarks (69.6% accuracy)

## Why This Works (Mechanism)
The approach works by learning complementary prompt spaces that capture different aspects of task knowledge. P-Prompt focuses on task-specific information, helping to mitigate catastrophic forgetting by maintaining knowledge about previous tasks. S-Prompt captures task-invariant information, enabling forward knowledge transfer to new tasks. The mutual information maximization between prompts and parameters, as well as between different encoded representations, ensures that the learned prompts are informative and complementary, allowing the model to effectively balance between preserving old knowledge and acquiring new knowledge.

## Foundational Learning
- Mutual Information Maximization: Why needed - to ensure learned prompts capture meaningful relationships between parameters and representations; Quick check - verify that MI estimates are stable during training
- Complementary Learning Systems Theory: Why needed - provides theoretical foundation for separating task-specific and task-invariant knowledge; Quick check - validate that learned prompts indeed capture complementary information
- Prompt-based Learning: Why needed - enables efficient parameter-efficient adaptation without modifying model weights; Quick check - confirm that prompt length remains constant across task sequences
- Catastrophic Forgetting: Why needed - core challenge in continual learning that the method specifically addresses; Quick check - measure forgetting rates across tasks

## Architecture Onboarding
Component map: Input Text -> Encoder -> P-Prompt & S-Prompt -> Classification Head -> Output

Critical path: The mutual information maximization between prompts and parameters forms the core optimization mechanism, with the balance between P-Prompt and S-Prompt determining overall performance.

Design tradeoffs: The method trades computational complexity for improved performance and reduced forgetting, requiring careful tuning of the mutual information loss weights.

Failure signatures: Poor performance may indicate issues with mutual information estimation, improper balance between P-Prompt and S-Prompt, or inadequate representation capacity.

First experiments: 1) Validate mutual information estimation on synthetic data, 2) Test P-Prompt and S-Prompt separation on a simple two-task scenario, 3) Evaluate performance on a single CTC task to establish baseline prompt effectiveness.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance metrics primarily focus on average accuracy without detailed per-task analysis or forgetting rates
- Experimental evaluation gaps in scalability to very long task sequences and behavior under task distribution shifts
- Potential optimization challenges with mutual information maximization in high-dimensional prompt spaces

## Confidence
High confidence in: Theoretical foundation of complementary prompt spaces and basic effectiveness on tested benchmarks
Medium confidence in: Robustness across different task types and optimization stability in practice
Low confidence in: Performance under significant domain shifts, computational efficiency in resource-constrained settings, and handling extreme task sequence lengths

## Next Checks
1. Evaluate InfoComp on cross-domain CTC scenarios with significantly different data distributions
2. Conduct ablation studies targeting mutual information loss components to quantify individual contributions
3. Test approach with varying prompt lengths and architectures to assess hyperparameter impact on performance and efficiency