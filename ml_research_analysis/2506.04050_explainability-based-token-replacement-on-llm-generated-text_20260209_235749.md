---
ver: rpa2
title: Explainability-Based Token Replacement on LLM-Generated Text
arxiv_id: '2506.04050'
source_url: https://arxiv.org/abs/2506.04050
tags:
- text
- detection
- ensemble
- token
- rewriting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how XAI methods can reduce AI-generated
  text (AIGT) detectability through token replacement. The authors develop an ensemble
  classifier and use SHAP/LIME to identify influential tokens for modification via
  four strategies: synonym replacement, POS-constrained substitution, GPT-based replacement,
  and GPT-based replacement with genre context.'
---

# Explainability-Based Token Replacement on LLM-Generated Text

## Quick Facts
- arXiv ID: 2506.04050
- Source URL: https://arxiv.org/abs/2506.04050
- Reference count: 40
- Primary result: XAI-guided token replacement reduces AIGT detectability while maintaining text fidelity

## Executive Summary
This paper investigates how explainable AI (XAI) methods can reduce AI-generated text (AIGT) detectability through targeted token replacement. The authors develop an ensemble classifier combining frozen pre-trained and fresh fine-tuned transformers, then apply SHAP and LIME to identify influential tokens for modification. Results show that XAI-guided token replacement can significantly reduce single-model detection accuracy (e.g., F1 dropping from 0.81 to 0.25), while the ensemble maintains robust performance across languages and domains. Human evaluators achieved only 47% detection accuracy on rewritten texts, demonstrating the practical effectiveness of this approach.

## Method Summary
The method uses an ensemble of six transformers—three frozen (pre-trained on AuTextTification) and three fresh (fine-tuned on augmented CLIN33)—to detect AIGT. SHAP and LIME are applied to identify influential tokens in AI-generated texts, which are then replaced using four strategies: synonym replacement (HSR), POS-constrained substitution (PSR), GPT-based replacement, and GPT-based replacement with genre context. The approach is evaluated on English and Dutch texts across news, reviews, and Twitter domains, measuring both detection performance (F1, accuracy) and text fidelity (BLEU, ROUGE).

## Key Results
- Ensemble achieves F1 scores of 0.85 (English) and 0.82 (Dutch), outperforming single models
- XAI-guided token replacement reduces XGBoost F1 from 0.81 to 0.25 (LIME+HSR), while ensemble drops only to 0.64
- Human evaluators correctly identified AIGT in rewritten texts only 47% of the time
- GPT-based rewriting strategies show higher text modification (BLEU 0.76-0.86) but don't guarantee better evasion

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble architectures with both frozen (pre-trained) and fresh (fine-tuned) transformer branches exhibit greater robustness against token-level adversarial modifications than single-model detectors.
- Mechanism: The ensemble combines six transformer outputs through concatenation and a dense classifier. When token replacements fool one detection pathway, other pathways often retain correct classifications. The frozen branch captures general AI-detection patterns; the fresh branch adapts to domain-specific characteristics.
- Core assumption: The failure modes of constituent models are sufficiently uncorrelated that attacks successful against one model remain detectable by others.
- Evidence anchors: [abstract] "our ensemble classifier maintains strong performance across multiple languages and domains, showing that a multi-model approach can mitigate the impact of token-level manipulations"; [section 5, Table 5] Ensemble shows maximum 19pp F1 drop under LIME+HSR (0.83→0.64), while XGBoost drops 56pp (0.81→0.25)

### Mechanism 2
- Claim: XAI methods (SHAP, LIME) identify tokens whose replacement more efficiently evades detection than random token selection.
- Mechanism: SHAP computes Shapley values measuring each token's marginal contribution to the detection decision across all token subsets. LIME perturbs tokens locally to fit an interpretable model. Both assign importance scores; tokens with highest absolute scores contribute most to the "AI-generated" prediction.
- Core assumption: The importance scores from SHAP/LIME accurately reflect genuine detector dependencies rather than artifacts of the explanation method.
- Evidence anchors: [abstract] "apply SHAP and LIME to identify tokens that most strongly influence its predictions"; [section 5, Table 5] LIME+HSR causes XGBoost F1 to drop from 0.81 to 0.25 (-56pp), while Random+HSR drops only to 0.73 (-8pp) with similar BLEU scores

### Mechanism 3
- Claim: The effectiveness of token replacement strategies exhibits a fidelity-evasion trade-off: aggressive rewrites (GPT-based) change more text but don't necessarily achieve higher evasion against robust detectors.
- Mechanism: HSR/PSR replace tokens with Word2Vec synonyms, preserving structure (BLEU 0.90–0.97) but potentially leaving AI patterns intact. GPT-based methods paraphrase more extensively (BLEU 0.76–0.86), removing local AI indicators but potentially introducing new detectable patterns from the rewriting model.
- Core assumption: The ensemble captures patterns that persist across rewriting methods, including patterns introduced by the rewriting model itself.
- Evidence anchors: [section 5, Table 6] GPT-based rewrites show BLEU 0.76–0.86 vs HSR/PSR at 0.84–0.97; [section 5] "LIME+GPT, the Ensemble still attains an F1 of 0.83, substantially above XGBoost's 0.57"

## Foundational Learning

- Concept: SHAP (SHapley Additive exPlanations)
  - Why needed here: Core mechanism for identifying which tokens drive detector predictions; enables targeted adversarial attacks and reveals detector vulnerabilities
  - Quick check question: Given a text classified as "AI-generated" with 85% confidence, how would you use SHAP to identify the top 5 tokens contributing to this classification?

- Concept: Ensemble learning with heterogeneous architectures
  - Why needed here: The paper's main defense mechanism; understanding why different model types provide complementary detection signals is essential for reproducing robustness
  - Quick check question: Why might XGBoost on TF-IDF features and BERT on contextualized embeddings fail on different types of adversarial modifications?

- Concept: BLEU/ROUGE metrics for text similarity
  - Why needed here: Quantifies the fidelity-evasion trade-off; essential for evaluating whether evasion success comes from clever token targeting or simply destroying the original text
  - Quick check question: If a rewriting strategy achieves 90% flip rate but BLEU of 0.45, what does this suggest about the practical utility of this evasion method?

## Architecture Onboarding

- Component map: AuTextTification data -> Frozen BERT/DistilBERT/XLM-RoBERTa (weights locked) -> CLIN33 data -> Fresh BERT/DistilBERT/XLM-RoBERTa (weights trainable) -> Concatenation -> Dense classifier with L2 regularization -> Sigmoid output

- Critical path:
  1. Pre-train frozen branch models on AuTextTification, save and lock weights
  2. Initialize fresh branch models, augment CLIN33 training data (synonym substitution, swaps, deletions, back-translation)
  3. Train combined ensemble end-to-end on augmented data with frozen branch weights fixed
  4. Apply SHAP/LIME to trained ensemble on held-out AI-generated samples to extract token importance
  5. Replace top-K influential tokens using each strategy
  6. Evaluate detection metrics (F1, accuracy) and text fidelity (BLEU, ROUGE) on modified texts

- Design tradeoffs:
  - Frozen vs. fresh branch ratio: More frozen → better generalization, more fresh → better domain adaptation. Paper uses 50/50 split.
  - Ensemble size vs. inference cost: 908M parameters, ~200ms inference per sample vs. ~50ms for single BERT. Production may require distillation.
  - Augmentation intensity: 3.5× expansion improves robustness but may introduce distribution shift. Paper applies only to training split.
  - Token replacement depth: Higher K increases evasion but degrades text quality. Paper uses importance threshold rather than fixed count.

- Failure signatures:
  - XGBoost shows 65% flip rate under LIME+HSR but ensemble only 27.5%: If single models flip much higher than ensemble, ensemble is working correctly
  - XLM-Roberta recall stuck at ~1.0 with precision ~0.53: Indicates overprediction of "AI" class—useful for robustness but problematic for precision-sensitive applications
  - BLEU < 0.80 with flip rate < 20%: Aggressive rewriting without evasion success suggests detector captures patterns beyond surface tokens

- First 3 experiments:
  1. Replicate single-model baselines on CLIN33 test set (Table 4) to validate data processing pipeline—target F1 within ±0.03 of reported values
  2. Train frozen branch on AuTextTification, verify transfer by testing on CLIN33 before fresh branch fine-tuning—expect moderate performance drop vs. final ensemble
  3. Implement SHAP-based token extraction on 20 correctly-classified AI samples, manually verify top-5 tokens per sample align with intuitive "AI-like" phrasing (e.g., formal transitions, hedging patterns)

## Open Questions the Paper Calls Out

- Question: Do explanation-based evasion strategies generalize to text generated by the latest generation of LLMs (e.g., Llama 3, Claude)?
  - Basis in paper: [explicit] The authors state in the Limitations section that they used GPT-4 and Vicuña, and that newer models may exhibit different patterns affecting vulnerability.
  - Why unresolved: LLM architectures and token distributions evolve rapidly; detection and evasion signals likely shift with new model generations.
  - Evidence to resolve: Replicating the token replacement experiments on a dataset generated exclusively by Claude 3 or Llama 3.

- Question: What is the optimal number of tokens ($K$) to replace that maximizes evasion success while minimizing semantic degradation?
  - Basis in paper: [explicit] The Sensitivity Analysis section notes that a systematic parameter sweep for $K$ was not conducted, leaving the trade-off curve undefined.
  - Why unresolved: It is currently unknown if a specific "sweet spot" exists where evasion success saturates before textual fidelity drops significantly.
  - Evidence to resolve: An ablation study varying the top-$K$ tokens replaced and plotting the resulting F1 drop against BLEU/ROUGE scores.

- Question: Can combined adversarial attacks (e.g., XAI-guided rewriting plus style transfer) successfully bypass robust ensemble detectors?
  - Basis in paper: [explicit] The Future Directions section explicitly proposes "investigating combinations of XAI-guided rewriting with other adversarial techniques."
  - Why unresolved: The study tested strategies in isolation; ensemble models showed robustness against single-vector attacks but might fail against compound methods.
  - Evidence to resolve: Experiments applying sequential transformations (e.g., SHAP replacement followed by syntax alterations) against the ensemble model.

## Limitations

- The specific hyperparameter configurations remain underspecified—particularly the number of tokens replaced per text, the exact Word2Vec model parameters, and the SHAP/LIME configuration details
- The corpus evidence is limited to related work on paraphrase attacks (PADBen) and detection benchmarks, with minimal direct validation of the XAI mechanisms themselves
- The human evaluation showing 47% detection accuracy provides important ecological validity but lacks detailed methodology description (number of evaluators, inter-rater reliability, or specific instructions)

## Confidence

**High Confidence:** The ensemble architecture provides greater robustness against token-level adversarial modifications than single-model detectors. This is well-supported by direct experimental comparisons showing ensemble F1 drops of 19pp versus single model drops of 56pp under identical attacks.

**Medium Confidence:** XAI methods (SHAP/LIME) identify tokens whose replacement more efficiently evades detection than random token selection. While the quantitative differences are clear (56pp vs 8pp F1 drop), the explanation quality and whether these reflect true detector dependencies versus explanation artifacts remains uncertain without deeper ablation studies.

**Low Confidence:** The effectiveness of token replacement strategies exhibits a fidelity-evasion trade-off where more aggressive rewrites don't necessarily achieve higher evasion. The observation that LIME+GPT shows 0% F1 change while LIME+HSR shows 19pp drop is intriguing but may reflect random variation or unmeasured factors like genre differences in the test set.

## Next Checks

1. **Ablation study on token importance scoring**: Compare SHAP/LIME token selection against alternative importance measures (gradient-based, attention weights) to verify that the reported 56pp F1 drop advantage over random replacement is not method-specific artifact.

2. **Ensemble component vulnerability analysis**: Systematically remove individual ensemble components (e.g., test XGBoost alone, each transformer alone) under identical token replacement attacks to quantify exactly how much robustness comes from ensemble averaging versus complementary detection capabilities.

3. **Human evaluation replication with controls**: Replicate the 47% human detection accuracy finding with documented methodology including inter-rater reliability, clear evaluation instructions, and comparison to human detection on unmodified AIGT to establish whether rewriting actually helps humans or simply increases uncertainty.