---
ver: rpa2
title: 'The Zero Body Problem: Probing LLM Use of Sensory Language'
arxiv_id: '2504.06393'
source_url: https://arxiv.org/abs/2504.06393
tags:
- language
- sensory
- human
- each
- gemini
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines whether language models use sensory language
  similarly to humans by comparing 18 models against human-written stories. The research
  extends an existing dataset with 18,000 stories from six model families (Gemini,
  GPT, Llama, OLMo, Phi, Qwen) and measures sensory language use across twelve axes
  using cognitive science lexicons.
---

# The Zero Body Problem: Probing LLM Use of Sensory Language

## Quick Facts
- arXiv ID: 2504.06393
- Source URL: https://arxiv.org/abs/2504.06393
- Reference count: 16
- Primary result: All 18 tested models differ significantly from human sensory language use, with Gemini models using more sensory language and most others using less

## Executive Summary
This study investigates whether large language models use sensory language similarly to humans by comparing 18 models against human-written stories across twelve sensory dimensions. The research extends an existing dataset with 18,000 stories from six major model families and measures sensory language use using cognitive science lexicons. Results reveal systematic differences between model and human usage patterns, with all models showing statistically significant deviations from human norms. The findings suggest that post-training fine-tuning, particularly RLHF, may discourage certain forms of sensory language use that are natural to humans.

## Method Summary
The researchers extended an existing dataset with 18,000 stories generated by six model families (Gemini, GPT, Llama, OLMo, Phi, Qwen), creating the largest comparative study of its kind. They measured sensory language use across twelve axes using established cognitive science lexicons and conducted linear probe analyses to assess whether models could identify sensory content in text. The study also analyzed RLHF data to investigate potential causes of observed differences. Statistical comparisons were performed between model-generated and human-written stories to identify significant deviations in sensory language patterns.

## Key Results
- All 18 tested models showed statistically significant differences from human sensory language use patterns
- Gemini models used significantly more sensory language than humans, while most other families used less
- Linear probe analyses revealed models can identify sensory content, suggesting differences stem from instruction tuning rather than inability to recognize sensory language
- Analysis of RLHF data indicates post-training fine-tuning may discourage certain forms of sensory language use

## Why This Works (Mechanism)
The observed differences in sensory language use likely stem from how language models are trained and fine-tuned. Models appear capable of recognizing and potentially generating sensory language (as shown by linear probe success), but post-training processes like RLHF and instruction tuning systematically discourage certain sensory expressions. This suggests a mismatch between human natural language patterns and the preferences encoded during fine-tuning, where models are optimized for task completion and coherence rather than mimicking human sensory-rich communication.

## Foundational Learning
- **Sensory lexicons**: Standardized vocabularies mapping words to sensory categories (vision, touch, taste, etc.) - needed to quantify sensory language use across models; quick check: validate lexicon coverage across domains
- **Statistical significance testing**: Methods to determine whether observed differences are meaningful rather than random variation - needed to establish reliable comparisons between models and humans; quick check: confirm p-values and effect sizes
- **Linear probe analysis**: A technique to test whether models encode specific information without fine-tuning - needed to distinguish between inability and choice in sensory language use; quick check: verify probe accuracy on held-out data

## Architecture Onboarding
Component map: Data Collection -> Lexicon Analysis -> Statistical Comparison -> RLHF Analysis -> Interpretation
Critical path: The analysis pipeline processes 18,000 stories through standardized lexicons, performs statistical comparisons, and examines fine-tuning data to identify causal factors
Design tradeoffs: The study prioritizes breadth (18 models across 6 families) over depth (individual model architecture analysis), enabling generalizable findings but limiting architectural insights
Failure signatures: If models cannot perform linear probe tasks, it would indicate fundamental inability to encode sensory information rather than fine-tuning preferences
First experiments: 1) Replicate analysis with different sensory lexicons to test robustness, 2) Compare pre- and post-fine-tuning model versions, 3) Test model outputs with modified prompts emphasizing sensory description

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on existing cognitive science lexicons may not capture all ways models express sensory concepts
- Token-level frequency analysis doesn't account for context-dependent usage or semantic equivalence
- RLHF analysis shows correlation but cannot definitively establish causation between fine-tuning and sensory language reduction

## Confidence
- High Confidence: All models differ significantly from human sensory language use patterns
- Medium Confidence: Instruction tuning and RLHF specifically cause observed differences
- Medium Confidence: Gemini uses more sensory language while other families use less

## Next Checks
1. Conduct qualitative analysis of model outputs to identify alternative linguistic patterns for sensory concepts
2. Implement ablation studies on model variants with different fine-tuning approaches
3. Expand analysis to include non-English languages and cross-linguistic comparisons