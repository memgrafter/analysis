---
ver: rpa2
title: 'Linear Personality Probing and Steering in LLMs: A Big Five Study'
arxiv_id: '2512.17639'
source_url: https://arxiv.org/abs/2512.17639
tags:
- have
- personality
- disagree
- always
- steering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether linear directions in neural activation
  space can detect and control personality traits in large language models, using
  the Big Five framework as a validated psychometric foundation. The authors generate
  406 character profiles with trait scores, collect hidden activations in response
  to personality-relevant prompts, and learn per-trait linear directions via regression.
---

# Linear Personality Probing and Steering in LLMs: A Big Five Study

## Quick Facts
- **arXiv ID:** 2512.17639
- **Source URL:** https://arxiv.org/abs/2512.17639
- **Reference count:** 40
- **Primary result:** Linear directions in neural activation space can detect personality traits and partially control responses in structured tasks, but show limited effect in open-ended generation when context is present.

## Executive Summary
This study investigates whether personality traits from the Big Five framework can be detected and controlled through linear directions in LLM activation spaces. Using 406 fictional character profiles with quantified trait scores, the authors learn per-trait linear directions via regression on hidden activations and demonstrate their ability to separate trait-related adjectives. The directions show reliable steering effects in forced-choice tasks but fail when competing personality context is present. The findings suggest personality is linearly separable but highly context-dependent in LLMs, with important implications for psychometric assessment and personality modeling in artificial systems.

## Method Summary
The authors generate 406 fictional characters with Big Five trait scores using the 50-item IPIP questionnaire, then collect hidden activations from Llama 3.3 70B when responding in character to personality-relevant prompts. They learn per-layer, per-trait linear directions through regression on mean input prompt activations, then validate these directions by testing their ability to separate trait-relevant adjectives and steer responses in structured tasks. Steering is implemented by adding scaled trait vectors to hidden states at inference, with effects evaluated across different contexts and task types.

## Key Results
- Linear directions learned from trait-scored activations generalize to separate trait-relevant adjectives with ROC-AUC > 0.7 for most traits in middle layers
- Steering via activation addition produces reliable effects in forced-choice tasks but fails when explicit personality descriptions are present in prompts
- Mean input prompt activations yield most reliable steering, while last token and mean output positions show weaker or unreliable effects
- Open-ended generation shows minimal steering influence even without competing context

## Why This Works (Mechanism)

### Mechanism 1: Supervised Linear Direction Extraction from Trait-Annotated Activations
The authors learn per-trait linear directions by fitting regression models to activations averaged by trait score across 406 characters. This supervised approach captures the relationship between personality variation and activation patterns, assuming traits are linearly represented in the residual stream.

### Mechanism 2: Trait Detection via Activation Projection
Learned directions generalize beyond training items by projecting activations from trait-relevant adjectives onto the trait subspace. The separation between positively and negatively loading adjectives (measured via ROC curves) validates that directions capture genuine semantic structure rather than training artifacts.

### Mechanism 3: Context-Conditional Activation Steering
Adding scaled trait vectors to hidden activations shifts response distributions, but only when no stronger contextual signals override the intervention. The steering hierarchy reveals that explicit personality descriptions dominate learned directions, suggesting prompt-based signals control trait expression.

## Foundational Learning

- **Concept: Big Five Personality Framework (OCEAN)**
  - Why needed here: The entire methodology depends on validated trait scores derived from psychometric instruments
  - Quick check question: If an item like "I don't talk a lot" loads negatively on extraversion, how would you expect its activation projection to compare to "I am the life of the party"?

- **Concept: Hidden State Activations in Transformer Residual Stream**
  - Why needed here: Different extraction positions (last token, mean input, mean output) contain different trait information that determines which strategy generalizes
  - Quick check question: Why might the last token of the input contain different trait information than the mean of generated output tokens?

- **Concept: Linear Probes vs. Control Vectors**
  - Why needed here: Probes detect trait presence while control vectors modify trait expression; the paper shows these are not equivalent
  - Quick check question: If a direction perfectly classifies traits but fails to steer, what does that imply about the causal role of that subspace?

## Architecture Onboarding

- **Component map:** Data Generation Layer → Activation Collection Layer → Direction Extraction Layer → Probing Evaluation Layer → Steering Intervention Layer
- **Critical path:** Regression on mean input prompt activations (not last token, not SVD) → middle/late layers (peaks around layer 18-32) → forced-choice evaluation without competing context
- **Design tradeoffs:**
  - Regression vs. SVD: SVD captures maximum variance directions that are nearly orthogonal to regression directions and fail for steering
  - Extraction position: Mean input prompt yields most reliable steering; last token and mean output show weaker or unreliable effects
  - Steering coefficient (α): |α| > 0.4 causes incoherent outputs; smaller values produce graded but noisy effects
- **Failure signatures:**
  - Context override: Any explicit personality description in prompt nullifies steering
  - Task prior interference: Customer service or factual recall tasks resist steering due to strong role priors
  - Over-steering: Large |α| produces gibberish, not exaggerated traits
  - No effect in open-ended generation: Even without explicit override, personality signal in open-ended text is too weak to detect reliably
- **First 3 experiments:**
  1. Replicate adjective probing at layer 18: Extract activations for 20 adjectives (10 positive, 10 negative) per trait → project onto regression directions → compute ROC-AUC
  2. Steering ablation by extraction position: Compare steering efficacy for directions extracted from mean input vs. last token vs. mean output
  3. Context hierarchy test: Systematically vary prompt context strength → measure at what point steering effect drops to zero

## Open Questions the Paper Calls Out

- **Open Question 1:** Is personality encoded as multiple independent factors or as a lower-dimensional shared structure with small deviations? The authors note that SVD-derived directions for different traits tend to align, raising this fundamental question about the dimensionality of trait representations.

- **Open Question 2:** Can different control mechanisms (prompt-based, vector-based, fine-tuning) cooperate rather than compete? The authors state that understanding how these mechanisms interact remains an open question requiring systematic investigation.

- **Open Question 3:** Are personality traits encoded along single one-dimensional directions or in small low-rank subspaces? The authors speculate that traits might require multiple dimensions rather than single linear directions.

- **Open Question 4:** Does LLM personality mirror human personality concepts, or do models lack consistent personality structure derived from lived experience? The authors acknowledge the possibility that LLM personality may not mirror human concepts.

## Limitations

- Context dependency severely limits steering effectiveness, with explicit personality descriptions completely overriding learned directions
- Limited steering effects in open-ended generation raise questions about whether detected directions capture genuine personality traits
- Use of fictional character data rather than real personality assessments limits generalizability to authentic personality expression
- Substantial data collection requirements (406 characters × 50 items × 10 prompts) make scaling challenging

## Confidence

- **High Confidence:** The existence of linear directions that separate trait-related adjectives (ROC-AUC > 0.7) and their effectiveness in forced-choice tasks without competing context
- **Medium Confidence:** The claim that personality traits are represented as linear directions in activation space, given context-dependent failure modes
- **Low Confidence:** The practical utility of these methods for real-world personality control, given strong context override effects

## Next Checks

1. **Context Hierarchy Validation:** Systematically test steering effectiveness across varying context strengths to quantify the exact point where steering fails and whether this threshold varies by trait or layer

2. **Real-Personality Transfer Test:** Apply learned directions to LLMs responding to real personality assessments rather than fictional characters to verify whether linear representations generalize beyond synthetic data

3. **Open-Ended Steering Analysis:** Conduct rigorous evaluation of steering in open-ended generation using structured rubrics or human evaluation to determine whether effects exist but are masked by measurement noise