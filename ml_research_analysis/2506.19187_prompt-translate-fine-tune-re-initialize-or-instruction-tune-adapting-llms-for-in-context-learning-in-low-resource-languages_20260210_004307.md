---
ver: rpa2
title: Prompt, Translate, Fine-Tune, Re-Initialize, or Instruction-Tune? Adapting
  LLMs for In-Context Learning in Low-Resource Languages
arxiv_id: '2506.19187'
source_url: https://arxiv.org/abs/2506.19187
tags:
- language
- outputs
- languages
- adaptation
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluates five adaptation methods for cross-lingual
  transfer to low-resource languages in in-context learning: few-shot prompting, translate-test,
  language-adaptive fine-tuning (LAFT), FOCUS (embedding re-initialization + LAFT),
  and language-adaptive instruction tuning (LAIT). Across three base models, five
  languages, and seven tasks, prompting-based methods consistently outperformed gradient-based
  methods.'
---

# Prompt, Translate, Fine-Tune, Re-Initialize, or Instruction-Tune? Adapting LLMs for In-Context Learning in Low-Resource Languages

## Quick Facts
- arXiv ID: 2506.19187
- Source URL: https://arxiv.org/abs/2506.19187
- Authors: Christopher Toukmaji; Jeffrey Flanigan
- Reference count: 33
- Key outcome: Few-shot prompting and translate-test methods consistently outperformed gradient-based methods across models, languages, and tasks in cross-lingual in-context learning

## Executive Summary
This study systematically compares five adaptation strategies for enabling large language models to perform in-context learning in low-resource languages: few-shot prompting, translate-test, language-adaptive fine-tuning (LAFT), FOCUS (embedding re-initialization + LAFT), and language-adaptive instruction tuning (LAIT). Across three base models, five languages, and seven tasks, prompting-based methods consistently outperformed gradient-based methods. The analysis revealed that gradient-based adaptation methods caused catastrophic forgetting, degrading both linguistic ability and task alignment in trained models. This suggests that gradient-based adaptation is harmful for cross-lingual in-context learning in low-resource settings.

## Method Summary
The paper evaluates five adaptation methods: few-shot prompting (prompting the base model in target language with English exemplars), translate-test (translating target language input to English), language-adaptive fine-tuning (LAFT, continued pre-training on target language data), FOCUS (re-initializing certain embedding layers then LAFT), and language-adaptive instruction tuning (LAIT, fine-tuning on instruction-following datasets in target language). The study tests these across three base models, five low-resource languages, and seven task types. Performance is measured using a novel Valid Output Recall (VOR) metric designed to detect catastrophic forgetting by comparing model outputs against both target language data and English exemplars.

## Key Results
- Few-shot prompting and translate-test methods consistently outperformed gradient-based adaptation methods across all tested configurations
- Gradient-based methods (LAFT, FOCUS, LAIT) showed significant performance degradation, losing both linguistic ability and task alignment
- The VOR metric revealed that trained models suffered from catastrophic forgetting, with performance worse than baseline prompting methods
- These results were consistent across three base models, five languages, and seven task types

## Why This Works (Mechanism)
The paper identifies catastrophic forgetting as the primary mechanism explaining why gradient-based adaptation methods fail. When models are fine-tuned or instruction-tuned on target language data, they lose the ability to both understand the target language and follow the original task instructions. This suggests that gradient-based methods fundamentally alter the model's representations in ways that degrade cross-lingual transfer capabilities. The consistent superiority of prompting-based methods indicates that leveraging the model's existing multilingual capabilities through few-shot examples or translation is more effective than attempting to retrain those capabilities.

## Foundational Learning
- **In-context learning**: The ability of LLMs to perform tasks given prompts with examples, without parameter updates during inference. Needed to understand the evaluation framework; quick check: can the model complete tasks given 2-3 exemplars in the prompt.
- **Cross-lingual transfer**: Applying knowledge from high-resource languages (typically English) to low-resource languages. Critical for understanding the adaptation challenge; quick check: model performance on translated vs. native language inputs.
- **Catastrophic forgetting**: The phenomenon where training on new tasks causes dramatic loss of previously learned capabilities. Central to the paper's findings; quick check: VOR metric showing degradation in both language understanding and task following.
- **Few-shot prompting**: Providing 2-3 exemplars in the prompt to guide model behavior. The baseline method tested; quick check: model performance with 2-3 examples versus zero-shot.
- **Translate-test**: Translating input from target language to English before prompting. A simple adaptation method tested; quick check: performance comparison between translated and native language inputs.
- **Instruction tuning**: Fine-tuning models on instruction-following datasets to improve task generalization. One of the gradient-based methods tested; quick check: whether fine-tuning improves or degrades cross-lingual task performance.

## Architecture Onboarding

**Component Map:**
Base Model -> Adaptation Method -> Evaluation Tasks -> VOR Metric

**Critical Path:**
Base model selection → Adaptation method application → Task performance evaluation → VOR analysis for catastrophic forgetting detection

**Design Tradeoffs:**
- Prompting methods preserve original capabilities but require more input tokens
- Gradient-based methods attempt parameter efficiency but risk catastrophic forgetting
- Translation adds preprocessing overhead but leverages strong English capabilities
- Re-initialization strategies (FOCUS) try to balance adaptation and preservation

**Failure Signatures:**
- Performance degradation below baseline prompting levels
- VOR scores indicating loss of both linguistic ability and task alignment
- Inconsistent performance across different task types

**First Experiments:**
1. Compare few-shot prompting versus translate-test on a simple classification task
2. Measure VOR metric on a gradient-based adaptation method to detect catastrophic forgetting
3. Test baseline prompting performance across multiple low-resource languages

## Open Questions the Paper Calls Out
None

## Limitations
- The study does not systematically disentangle whether performance degradation stems from catastrophic forgetting versus optimization instabilities or suboptimal hyperparameters
- Results may not generalize to other low-resource language families or different task categories beyond those tested
- The paper does not explore whether regularization techniques or gradual unfreezing could mitigate catastrophic forgetting in gradient-based methods

## Confidence

**High confidence:**
- Few-shot prompting and translate-test consistently outperforming gradient-based methods across tested configurations

**Medium confidence:**
- Catastrophic forgetting explanation for degraded performance, given lack of systematic control for alternative causes
- VOR metric's validity as diagnostic tool, though not validated against human judgments

## Next Checks
1. Conduct ablation studies to isolate whether performance degradation stems from catastrophic forgetting versus optimization instabilities or suboptimal hyperparameters
2. Test adaptation methods on additional low-resource languages from different families and diverse task types to assess generalizability
3. Investigate whether regularization techniques (elastic weight consolidation, learning rate scheduling) or gradual unfreezing can mitigate catastrophic forgetting in gradient-based adaptation methods