---
ver: rpa2
title: 'Documenting SME Processes with Conversational AI: From Tacit Knowledge to
  BPMN'
arxiv_id: '2512.05122'
source_url: https://arxiv.org/abs/2512.05122
tags:
- process
- bpmn
- business
- knowledge
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: A large-language-model-driven chatbot was developed to capture
  tacit, experience-based know-how from shop-floor staff and convert it into formal
  BPMN 2.0 process models through conversational dialogue. Using Gemini 2.5 Pro, the
  system generates and refines diagrams in real time, with client-side bpmn-js visualisation
  and prompt engineering ensuring XML compliance.
---

# Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN

## Quick Facts
- arXiv ID: 2512.05122
- Source URL: https://arxiv.org/abs/2512.05122
- Reference count: 10
- Prototype LLM chatbot converts SME tacit knowledge into formal BPMN 2.0 process models through conversational dialogue

## Executive Summary
This paper introduces a large-language-model-driven chatbot that captures tacit, experience-based know-how from shop-floor staff and converts it into formal BPMN 2.0 process models through conversational dialogue. Using Gemini 2.5 Pro, the system generates and refines diagrams in real time, with client-side bpmn-js visualization and prompt engineering ensuring XML compliance. In an equipment-maintenance scenario, the prototype produced an accurate "AS-IS" model, annotated it with bottleneck analysis, and created an improved "TO-BE" variant, all within 12 minutes while keeping API costs within SME budgets. Latency stemmed from verbose BPMN XML generation; future work includes agentic dialogue, multimodal inputs, and on-premise deployment.

## Method Summary
The approach uses a Gemini 2.5 Pro-driven chatbot to engage shop-floor SMEs in natural conversation, extracting process knowledge through structured prompts and iterative refinement. Client-side bpmn-js renders the generated BPMN 2.0 diagrams, while prompt engineering ensures XML compliance. The system supports real-time model generation and annotation, enabling identification of bottlenecks and creation of improved "TO-BE" process variants. Costs are kept within SME budgets by limiting API calls and optimizing prompt design.

## Key Results
- Prototype produced accurate "AS-IS" BPMN model from SME conversation in 12 minutes
- Annotated model identified bottlenecks and enabled creation of improved "TO-BE" variant
- Client-side bpmn-js visualization and prompt engineering ensured XML compliance and cost efficiency

## Why This Works (Mechanism)
The system leverages LLM conversational capabilities to bridge the gap between tacit, experience-based knowledge and formal process modeling. By engaging SMEs in dialogue, it captures nuanced, undocumented know-how that traditional documentation methods miss. Real-time BPMN generation and visualization make the process accessible and actionable for non-technical users, while prompt engineering ensures the output is both compliant and useful.

## Foundational Learning
- **BPMN 2.0**: Standard for business process modeling; needed for interoperability and clarity in process documentation
- **LLM Prompt Engineering**: Crafting prompts to elicit structured, compliant output; quick check: test prompt variations for XML accuracy
- **bpmn-js**: JavaScript library for BPMN diagram rendering; needed for client-side visualization; quick check: verify diagram fidelity across browsers
- **Conversational AI**: Natural language interface for knowledge extraction; needed to engage SMEs without technical barriers; quick check: measure user satisfaction and knowledge capture completeness

## Architecture Onboarding

**Component Map:**
Chatbot (Gemini 2.5 Pro) -> bpmn-js Renderer -> Client Interface -> SME User

**Critical Path:**
SME input → LLM processing → BPMN XML generation → Client-side rendering → Visual feedback loop

**Design Tradeoffs:**
- API cost vs. model accuracy: Gemini 2.5 Pro chosen for quality, but increases token costs
- Latency vs. completeness: Verbose XML ensures detail but slows rendering
- Client-side vs. server-side rendering: Client-side reduces server load but requires robust client resources

**Failure Signatures:**
- Incomplete or inaccurate BPMN models from vague SME input
- High latency due to large XML payloads
- Rendering errors in bpmn-js due to malformed XML

**3 First Experiments:**
1. Test the system with a different SME domain (e.g., logistics) to assess generalizability
2. Compare latency and token costs with on-premise open-source LLM alternatives
3. Conduct a longitudinal study with actual SMEs to measure adoption barriers and process improvement outcomes

## Open Questions the Paper Calls Out
None

## Limitations
- Verbose BPMN XML generation introduces latency and increases token consumption
- Evaluation limited to single equipment-maintenance scenario; generalizability unverified
- Reliance on external LLM API raises cost and availability concerns; on-premise deployment proposed but untested

## Confidence
- **High Confidence**: Feasibility of converting conversational input into BPMN 2.0 models; proof-of-concept success in SME maintenance scenario
- **Medium Confidence**: Scalability to complex processes; robustness across diverse SME domains
- **Low Confidence**: Long-term cost-effectiveness for SMEs; effectiveness of proposed on-premise deployment

## Next Checks
1. Test the system across multiple SME sectors (e.g., logistics, healthcare, retail) to assess domain transferability
2. Benchmark latency and token costs against on-premise open-source LLM alternatives
3. Conduct a longitudinal study with actual SMEs to measure adoption barriers and process improvement outcomes