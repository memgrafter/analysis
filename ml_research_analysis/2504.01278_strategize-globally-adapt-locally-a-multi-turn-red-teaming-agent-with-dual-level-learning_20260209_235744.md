---
ver: rpa2
title: 'Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level
  Learning'
arxiv_id: '2504.01278'
source_url: https://arxiv.org/abs/2504.01278
tags:
- learning
- goal
- malware
- attack
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GALA, a novel multi-turn red-teaming agent
  that employs dual-level learning to enhance both attack success rate and diversity.
  GALA combines global tactic-wise learning to accumulate knowledge and develop a
  goal-based tactic selection framework, with local prompt-wise learning to refine
  prompt implementations for specific goals.
---

# Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level Learning

## Quick Facts
- arXiv ID: 2504.01278
- Source URL: https://arxiv.org/abs/2504.01268
- Reference count: 40
- Key result: GALA achieves >90% attack success rate against GPT-3.5-Turbo and Llama-3.1-70B within 5 turns

## Executive Summary
This paper introduces GALA, a novel multi-turn red-teaming agent that employs dual-level learning to enhance both attack success rate and diversity. GALA combines global tactic-wise learning to accumulate knowledge and develop a goal-based tactic selection framework, with local prompt-wise learning to refine prompt implementations for specific goals. Evaluations on JailbreakBench show GALA achieves over 90% attack success rates against GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns, outperforming state-of-the-art baselines. The framework also demonstrates higher attack diversity, effectively identifying a broader range of vulnerabilities compared to existing approaches.

## Method Summary
GALA implements a dual-level learning approach that separates strategic knowledge accumulation from tactical prompt refinement. The global level employs tactic-wise learning to build a repository of successful attack patterns and develop a goal-based selection framework for choosing appropriate tactics based on the current conversation state. The local level performs prompt-wise learning to fine-tune specific prompt implementations for each goal, adapting the general tactics to particular conversational contexts. This hierarchical structure allows GALA to maintain strategic consistency while dynamically adjusting its approach based on real-time feedback from the target model.

## Key Results
- Achieves >90% attack success rates against GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns
- Outperforms state-of-the-art baselines on JailbreakBench evaluation
- Demonstrates higher attack diversity, identifying broader vulnerability ranges

## Why This Works (Mechanism)
The dual-level learning architecture enables GALA to balance strategic planning with tactical flexibility. The global tactic-wise learning component builds a comprehensive understanding of effective attack patterns across different scenarios, creating a knowledge base that can be systematically applied. Meanwhile, the local prompt-wise learning allows for fine-grained adaptation to specific conversational contexts, ensuring that broad tactics are implemented in ways that resonate with the target model's current state. This separation of concerns prevents the system from becoming either too rigid in its approach or too scattered in its tactical choices.

## Foundational Learning
- **Tactic-wise learning**: Understanding broad attack patterns and their effectiveness across scenarios - needed to build generalizable attack strategies, quick check: success rate consistency across different model types
- **Prompt-wise learning**: Fine-tuning specific prompt implementations for contextual effectiveness - needed to adapt general tactics to specific conversation states, quick check: variance in success rates for identical tactics across different contexts
- **Goal-based selection framework**: Systematically choosing appropriate tactics based on conversation state - needed to maintain strategic coherence, quick check: correlation between selected tactics and conversation progression

## Architecture Onboarding

**Component Map**: Global Strategy Module -> Tactic Selection Engine -> Local Prompt Adapter -> Conversation Interface

**Critical Path**: The system flows from global strategy formulation through tactic selection to local prompt adaptation, with the conversation interface providing feedback loops to both levels of learning.

**Design Tradeoffs**: The architecture trades computational complexity for adaptability - maintaining both global and local learning systems requires more resources but enables more effective attacks. The separation of strategy and implementation allows for cleaner knowledge accumulation but introduces potential synchronization challenges.

**Failure Signatures**: Failure typically manifests as either strategic misalignment (global tactics poorly matched to conversation state) or tactical ineffectiveness (local prompts failing to implement selected tactics). Monitoring success rates at both levels can help diagnose which component needs adjustment.

**First Experiments**:
1. Test basic tactic selection without local adaptation to establish baseline effectiveness
2. Evaluate local prompt adaptation on pre-selected tactics to measure tactical refinement capability
3. Measure knowledge transfer between different attack goals to assess global learning effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to GPT-3.5-Turbo and Llama-3.1-70B, with no testing against other frontier models like GPT-4 or Claude
- Potential overfitting to JailbreakBench patterns, with unclear transfer to novel scenarios
- Diversity metrics remain underspecified, making it difficult to assess the novelty of identified attack vectors

## Confidence
- **High**: Core methodology of combining global tactic-wise learning with local prompt-wise learning is technically sound
- **Medium**: Claims about superior attack diversity require more rigorous validation due to underspecified metrics
- **Low**: Generalizability claims to "any frontier LLM" are not substantiated by testing across diverse model families

## Next Checks
1. Test GALA against additional frontier models including GPT-4, Claude-3, and specialized safety-focused models to verify cross-model effectiveness
2. Conduct ablation studies removing either global tactic-wise or local prompt-wise components to quantify individual contributions
3. Perform out-of-distribution testing using jailbreak scenarios not present in JailbreakBench to assess adaptation to novel contexts