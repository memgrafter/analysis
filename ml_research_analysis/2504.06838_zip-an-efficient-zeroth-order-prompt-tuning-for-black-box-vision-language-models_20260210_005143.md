---
ver: rpa2
title: 'ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language
  Models'
arxiv_id: '2504.06838'
source_url: https://arxiv.org/abs/2504.06838
tags:
- accuracy
- number
- queries
- train
- validation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ZIP, a zeroth-order optimization-based prompt
  tuning method for black-box vision-language models. The key idea is to reduce the
  dimensionality of prompts and the variance of gradient estimates by reparameterizing
  prompts in low-rank representations and clipping gradients based on problem dimensionality.
---

# ZIP: An Efficient Zeroth-order Prompt Tuning for Black-Box Vision-Language Models

## Quick Facts
- **arXiv ID**: 2504.06838
- **Source URL**: https://arxiv.org/abs/2504.06838
- **Reference count**: 40
- **Primary result**: ZIP achieves 6% improvement in few-shot accuracy and 48% improvement in query efficiency compared to best alternative black-box prompt tuning methods across 13+ vision-language tasks

## Executive Summary
This paper introduces ZIP (Zeroth-order prompt tuning), a novel approach for optimizing prompts in black-box vision-language models using zeroth-order optimization. The key innovation lies in addressing the curse of dimensionality through low-rank reparameterization of prompts and gradient clipping based on problem dimensionality. ZIP demonstrates significant performance gains over existing black-box prompt tuning methods while maintaining computational efficiency, establishing a new state-of-the-art in this challenging setting.

## Method Summary
ZIP tackles the challenge of prompt tuning in black-box vision-language models by combining two key techniques: low-rank reparameterization and gradient clipping. The low-rank representation reduces the effective dimensionality of prompts, making optimization more tractable in high-dimensional spaces. The gradient clipping mechanism further improves optimization stability by accounting for the problem's dimensionality. Together, these approaches enable more efficient and effective prompt optimization without requiring access to model internals, making ZIP particularly suitable for black-box scenarios where only input-output pairs are available.

## Key Results
- Achieves approximately 6% improvement in few-shot accuracy over best alternative black-box prompt tuning methods
- Demonstrates 48% improvement in query efficiency across 13+ vision-language tasks
- Establishes new state-of-the-art performance for black-box prompt tuning in vision-language models

## Why This Works (Mechanism)
ZIP works by addressing the fundamental challenges of zeroth-order optimization in high-dimensional spaces. The low-rank reparameterization reduces the effective search space for prompts, making gradient estimation more reliable and efficient. By constraining prompts to lower-dimensional manifolds, ZIP mitigates the curse of dimensionality that typically plagues zeroth-order methods. The gradient clipping based on problem dimensionality further stabilizes the optimization process, preventing large gradient estimates that could lead to poor convergence. This combination enables more efficient exploration of the prompt space while maintaining the ability to discover effective prompts for downstream tasks.

## Foundational Learning

**Zeroth-order optimization**: Optimization methods that only require function evaluations, not gradients. Needed because black-box models don't expose gradients. Quick check: Can estimate gradients using finite differences or random perturbations.

**Prompt engineering for VLMs**: Crafting text inputs to guide vision-language models' behavior. Needed to adapt pre-trained models to specific tasks without fine-tuning. Quick check: Should improve task performance without modifying model weights.

**Low-rank matrix factorization**: Representing matrices as products of smaller matrices. Needed to reduce dimensionality while preserving important information. Quick check: Rank should be much smaller than original dimensions.

**Curse of dimensionality**: Problems become exponentially harder as dimensionality increases. Needed to understand why standard zeroth-order methods fail in high dimensions. Quick check: Performance degrades rapidly with increasing dimensions.

## Architecture Onboarding

**Component map**: Input images → Vision encoder → CLIP/LLaVA backbone → Prompt optimization (ZIP) → Task-specific output

**Critical path**: Image input → Visual feature extraction → Prompt optimization loop (forward pass, gradient estimation, update) → Final prediction

**Design tradeoffs**: Low-rank vs. full-rank prompts (efficiency vs. expressiveness), clipping threshold (stability vs. exploration), number of queries (accuracy vs. cost)

**Failure signatures**: Poor performance on tasks requiring complex prompts, sensitivity to initial prompt values, failure to converge on high-dimensional tasks

**First experiments**:
1. Verify low-rank reparameterization reduces effective dimensionality on synthetic prompt spaces
2. Test gradient clipping sensitivity by varying problem dimensionality
3. Compare query efficiency against baseline zeroth-order methods on a simple vision-language task

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses exclusively on black-box settings, limiting understanding of performance in gray-box or white-box scenarios
- Low-rank reparameterization and gradient clipping mechanisms may not scale effectively to very large vision-language models
- Claims of "new state-of-the-art" are based on comparisons within black-box prompt tuning literature, potentially missing broader approaches

## Confidence
- **High confidence**: The 6% accuracy improvement and 48% query efficiency gains are well-supported by extensive experiments across multiple tasks
- **Medium confidence**: Theoretical motivation for low-rank reparameterization and gradient clipping is sound, but practical limitations at scale are not fully explored
- **Medium confidence**: Comprehensive comparison within black-box prompt tuning scope, though limited generalizability due to exclusive focus on black-box settings

## Next Checks
1. Evaluate ZIP performance in gray-box and white-box settings to assess whether advantages persist with partial model information
2. Test scalability by applying ZIP to larger VLMs (e.g., LLaVA-1.6, 34B parameters) and complex multimodal tasks
3. Conduct ablation studies isolating gradient clipping versus low-rank reparameterization contributions to performance gains