---
ver: rpa2
title: Native-Resolution Image Synthesis
arxiv_id: '2506.03131'
source_url: https://arxiv.org/abs/2506.03131
tags:
- width
- height
- arxiv
- generalization
- resolution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Native-resolution image synthesis introduces a generative modeling
  paradigm that enables the synthesis of images at arbitrary resolutions and aspect
  ratios. The key innovation is the Native-resolution diffusion Transformer (NiT),
  which directly models variable-length visual tokens without resolution-modifying
  augmentations.
---

# Native-Resolution Image Synthesis

## Quick Facts
- arXiv ID: 2506.03131
- Source URL: https://arxiv.org/abs/2506.03131
- Reference count: 40
- Primary result: State-of-the-art native-resolution image synthesis with zero-shot generalization to unseen resolutions

## Executive Summary
Native-resolution image synthesis introduces a generative modeling paradigm that enables the synthesis of images at arbitrary resolutions and aspect ratios. The key innovation is the Native-resolution diffusion Transformer (NiT), which directly models variable-length visual tokens without resolution-modifying augmentations. By incorporating dynamic tokenization, variable-length sequence processing, and 2D structural prior injection via axial 2D Rotary Positional Embedding, NiT learns intrinsic visual distributions from images spanning diverse resolutions and aspect ratios.

## Method Summary
NiT processes images at their native resolutions without resizing or cropping, creating variable-length token sequences that maintain exact spatial relationships. The architecture builds on DiT with patch size=1, using DC-AE encoding to produce variable-length latents. Multiple images are packed into fixed-size batches using longest-pack-first histogram packing, processed with Flash Attention-2 and axial 2D RoPE for positional encoding. The model is trained using flow matching (velocity prediction) and achieves state-of-the-art performance on both standard and high-resolution benchmarks while demonstrating excellent zero-shot generalization to unseen aspect ratios and resolutions.

## Key Results
- Achieves SOTA FID of 2.03 on ImageNet-256x256 and 1.45 on 512x512
- Zero-shot generation at 1536x1536 resolution with FID 4.52
- Successful generation at diverse aspect ratios (16:9, 3:1, 4:3) with FID 4.11 on 9:16
- Superior performance compared to fixed-resolution baselines across all resolution and aspect ratio combinations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Processing images at native resolution preserves spatial fidelity that enables zero-shot generalization to unseen resolutions.
- **Mechanism:** Images are