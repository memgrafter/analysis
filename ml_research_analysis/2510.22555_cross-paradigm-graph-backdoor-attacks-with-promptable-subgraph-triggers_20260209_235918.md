---
ver: rpa2
title: Cross-Paradigm Graph Backdoor Attacks with Promptable Subgraph Triggers
arxiv_id: '2510.22555'
source_url: https://arxiv.org/abs/2510.22555
tags:
- graph
- trigger
- learning
- backdoor
- triggers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of backdoor attacks on graph neural
  networks (GNNs) that can transfer across different learning paradigms (graph supervised
  learning, contrastive learning, and prompt learning). The key idea is to use graph
  prompt learning (GPL) to optimize a set of condensed subgraph triggers, making them
  generalizable across diverse paradigms.
---

# Cross-Paradigm Graph Backdoor Attacks with Promptable Subgraph Triggers

## Quick Facts
- arXiv ID: 2510.22555
- Source URL: https://arxiv.org/abs/2510.22555
- Authors: Dongyi Liu; Jiangtong Li; Dawei Cheng; Changjun Jiang
- Reference count: 40
- Key outcome: CP-GBA achieves state-of-the-art attack success rates with 40.4% average speedup using condensed subgraph triggers optimized via graph prompt learning across multiple GNN paradigms

## Executive Summary
This paper addresses the challenge of backdoor attacks on graph neural networks (GNNs) that can transfer across different learning paradigms. Current graph backdoor attacks are typically tailored to specific paradigms and fail to generalize across supervised learning, contrastive learning, and prompt learning approaches. The proposed CP-GBA framework introduces a novel approach using graph prompt learning to optimize a set of condensed subgraph triggers that maintain effectiveness across diverse learning paradigms while improving efficiency.

The method constructs a structured trigger repository with class-aware, feature-rich, and structurally consistent subgraphs, then optimizes them via GPL using a bi-level optimization framework. Experiments on four real-world datasets (Cora, Pubmed, Facebook, OGB-arxiv) and four defense strategies demonstrate that CP-GBA achieves state-of-the-art attack success rates with an average 40.4% speedup compared to existing methods, showcasing strong transferability and stealthiness across different GNN architectures and learning paradigms.

## Method Summary
The CP-GBA framework introduces a novel approach to graph backdoor attacks by leveraging graph prompt learning (GPL) to optimize condensed subgraph triggers. The method constructs a trigger repository containing class-aware, feature-rich, and structurally consistent subgraphs, then uses a bi-level optimization framework to fine-tune these triggers across multiple GNN paradigms simultaneously. The key innovation is the use of condensed triggers - compact subgraphs that can be efficiently optimized and maintain transferability. The GPL framework optimizes trigger features to ensure effectiveness across supervised learning, contrastive learning, and prompt learning paradigms. The approach also includes an adaptive poisoning strategy that dynamically adjusts trigger injection based on the target paradigm's characteristics, ensuring robust attack performance even when GNN architectures change.

## Key Results
- CP-GBA achieves state-of-the-art attack success rates across graph supervised learning, contrastive learning, and prompt learning paradigms
- The method demonstrates 40.4% average speedup compared to existing backdoor attack methods through condensed trigger optimization
- Strong transferability and stealthiness are maintained across different GNN architectures and learning paradigms on four real-world datasets

## Why This Works (Mechanism)
The mechanism exploits the shared vulnerability across different GNN paradigms by optimizing triggers that exploit common structural and feature patterns learned by GNNs. By using graph prompt learning, the method can adapt triggers to be effective across multiple learning objectives simultaneously. The condensed trigger design reduces computational overhead while maintaining attack effectiveness. The bi-level optimization framework ensures that triggers are optimized not just for one specific task but for cross-paradigm generalization, making the attacks more robust to paradigm shifts.

## Foundational Learning
- Graph Neural Networks (GNNs): Why needed - Core target of the attack; quick check - Understanding how GNNs aggregate and propagate information across graph structures
- Backdoor Attacks: Why needed - Attack methodology being extended; quick check - Familiarity with trigger injection and model poisoning concepts
- Graph Prompt Learning: Why needed - Novel optimization technique used; quick check - Understanding how prompts can guide model behavior in graph settings
- Bi-level Optimization: Why needed - Framework for cross-paradigm optimization; quick check - Grasping how upper and lower-level objectives interact
- Contrastive Learning: Why needed - One of the target paradigms; quick check - Understanding how contrastive objectives differ from supervised learning

## Architecture Onboarding

**Component Map:**
Trigger Repository -> GPL Optimizer -> Condensed Trigger Generator -> Attack Injection -> Target Model

**Critical Path:**
1. Construct initial trigger repository with class-aware, feature-rich subgraphs
2. Apply GPL optimization to fine-tune triggers for cross-paradigm effectiveness
3. Generate condensed triggers from optimized repository
4. Inject triggers into training data and evaluate attack success
5. Iterate optimization based on attack performance feedback

**Design Tradeoffs:**
The paper balances trigger size (stealthiness) against attack effectiveness, using condensed triggers to reduce computational overhead while maintaining cross-paradigm transferability. The GPL approach trades off paradigm-specific optimization for broader generalization, accepting potentially lower peak performance on any single paradigm in exchange for consistent effectiveness across all paradigms.

**Failure Signatures:**
- Poor attack success rates indicate insufficient trigger optimization or inappropriate repository construction
- Limited transferability suggests triggers are too paradigm-specific or the GPL optimization failed to capture cross-paradigm patterns
- High computational overhead may indicate inefficient condensed trigger generation or suboptimal GPL parameters

**First Experiments to Run:**
1. Test CP-GBA on a single dataset with one GNN architecture to verify basic functionality
2. Evaluate attack success rates across different paradigms on the same dataset to measure transferability
3. Compare condensed trigger performance against full subgraph triggers to quantify efficiency gains

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can cross-paradigm backdoor attacks be generalized to multi-task settings where a single trigger simultaneously manipulates distinct graph learning tasks (e.g., node classification and link prediction)?
- Basis in paper: Section VI-B states, "Existing graph backdoor attacks are task-specific... Generalizing them to multi-task settings offers a promising path toward a more universal attack."
- Why unresolved: The current CP-GBA framework is optimized solely for node classification; extending to multi-task learning requires balancing potentially conflicting trigger optimization objectives.
- What evidence would resolve it: High Attack Success Rates (ASR) maintained simultaneously across multiple downstream tasks using a single, universal trigger set.

### Open Question 2
- Question: How can transferable graph backdoor attacks be designed to function effectively when the attacker has extremely limited or zero access to training data and labels?
- Basis in paper: Section VI-B identifies "Designing data-efficient attacks that operate with extremely limited or zero data access" as a critical future direction.
- Why unresolved: The current method assumes a "gray-box" scenario where the attacker can access and poison the training graph to optimize the condensed triggers via bi-level optimization.
- What evidence would resolve it: Successful attack performance in few-shot or zero-shot data poisoning scenarios where the attacker lacks access to the full training graph.

### Open Question 3
- Question: Does the CP-GBA framework maintain its theoretical transferability and attack success when applied to heterogeneous graphs with diverse node and edge types?
- Basis in paper: The experiments are restricted to homogeneous citation and social networks (Cora, Pubmed, etc.) and standard GNNs. Theoretical proofs assume generic surjective mappings but do not explicitly model the semantic constraints of heterogeneous structures.
- Why unresolved: The condensed trigger construction uses K-means clustering on node embeddings which may fail to capture the complex semantic relationships required for heterogeneous graph neural networks (e.g., RGCN, HAN).
- What evidence would resolve it: High ASR on standard heterogeneous graph benchmarks without structural modifications to the trigger repository construction.

## Limitations
- Assumes shared vulnerabilities across different GNN paradigms may not hold for all possible architecture combinations
- Limited evaluation of detection by sophisticated defense mechanisms beyond the four tested strategies
- Restricted to homogeneous graph datasets, leaving heterogeneous graph applicability unverified

## Confidence
- **High confidence**: The core methodology of using graph prompt learning for trigger optimization is technically sound and the reported speedup (40.4% average) is likely reproducible given the algorithmic improvements
- **Medium confidence**: The cross-paradigm transferability claims are supported by experimental results but may not generalize to all possible GNN architectures or more diverse graph types beyond the tested datasets
- **Medium confidence**: The effectiveness against the four defense strategies tested suggests robustness, but the defense landscape is rapidly evolving and more sophisticated techniques may reduce effectiveness

## Next Checks
1. Test CP-GBA's transferability on additional graph datasets with different characteristics (e.g., larger graphs, different edge distributions, temporal graphs) to verify robustness across graph types
2. Evaluate the method's effectiveness against emerging defense strategies such as adaptive certification methods or dynamic graph sanitization techniques not included in the current evaluation
3. Conduct ablation studies on the trigger repository construction parameters (class-aware ratios, feature richness thresholds, structural consistency metrics) to quantify their individual contributions to attack success and transferability