---
ver: rpa2
title: Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance
arxiv_id: '2508.15650'
source_url: https://arxiv.org/abs/2508.15650
tags:
- point
- attack
- adversarial
- clouds
- pointnet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of black-box attacks on 3D point
  cloud classifiers, where the attacker lacks access to model parameters or gradients.
  Most existing 3D adversarial attack methods require knowledge of the target model,
  limiting their practical applicability.
---

# Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance

## Quick Facts
- arXiv ID: 2508.15650
- Source URL: https://arxiv.org/abs/2508.15650
- Authors: Shuchao Pang; Zhenghan Chen; Shen Zhang; Liming Lu; Siyuan Liang; Anan Du; Yongbin Zhou
- Reference count: 40
- Primary result: Proposes CFG, a transfer-based black-box attack method achieving up to 88% success rate on 3D point cloud classifiers while maintaining imperceptibility

## Executive Summary
This paper addresses the challenge of black-box attacks on 3D point cloud classifiers, where attackers lack access to model parameters or gradients. Most existing 3D adversarial attack methods require knowledge of the target model, limiting their practical applicability. The authors propose CFG, a novel transfer-based black-box attack method that leverages Critical Feature Guidance to improve attack transferability. The key insight is that critical features used for point cloud classification are consistent across different DNN architectures.

The method identifies and prioritizes the corruption of these critical features while constraining the maximum deviation of generated adversarial point clouds to ensure imperceptibility. Extensive experiments on ModelNet40 and ScanObjectNN datasets demonstrate that CFG significantly outperforms state-of-the-art attack methods, achieving up to 88% attack success rate on advanced models while maintaining high imperceptibility. The proposed method shows strong resistance to potential defenses and maintains efficiency with a running time of 0.07 minutes per adversarial point cloud.

## Method Summary
CFG operates by first identifying critical features that are consistently important across different 3D point cloud classifiers. These features are determined through an analysis of feature importance scores from multiple pre-trained models. The attack then prioritizes the perturbation of points associated with these critical features while maintaining a constraint on the maximum deviation to ensure the adversarial examples remain imperceptible. This approach leverages the transferability of critical features across architectures to enable effective black-box attacks without requiring access to the target model's parameters or gradients.

## Key Results
- Achieves up to 88% attack success rate on advanced 3D point cloud classifiers
- Outperforms state-of-the-art transfer-based attack methods on ModelNet40 and ScanObjectNN datasets
- Maintains high imperceptibility through maximum deviation constraints
- Demonstrates strong resistance to potential defenses
- Efficient runtime of 0.07 minutes per adversarial point cloud

## Why This Works (Mechanism)
The effectiveness of CFG stems from the observation that critical features for 3D point cloud classification are architecture-agnostic. By identifying and prioritizing the corruption of these universally important features, the attack can effectively transfer across different models without requiring gradient information from the target model. The method exploits the consistency in how different architectures extract and utilize critical geometric and semantic features from point clouds.

## Foundational Learning
- **Critical Feature Identification**: Understanding which features are consistently important across different architectures is essential for transferability. Quick check: Verify feature importance consistency across at least 5 different 3D classifier architectures.
- **Transfer-based Attack Principles**: The attack must work without target model access, relying on transferability from surrogate models. Quick check: Test attack success rate when transferring from models with different architectures.
- **Imperceptibility Constraints**: Maintaining visual/physical plausibility requires constraining perturbation magnitude. Quick check: Measure perceptual difference between original and adversarial samples using human evaluation.
- **Black-box Attack Limitations**: Without gradient access, attacks must rely on transferability or optimization heuristics. Quick check: Compare performance against white-box attacks on the same task.
- **3D Point Cloud Representation**: Understanding how point clouds encode geometric and semantic information is crucial for feature identification. Quick check: Analyze feature importance across different point cloud resolutions.

## Architecture Onboarding

**Component Map**: Critical Feature Analyzer -> Feature Prioritization Module -> Adversarial Point Cloud Generator -> Imperceptibility Constraint Enforcer

**Critical Path**: The Critical Feature Analyzer identifies important features across multiple models, which are then prioritized by the Feature Prioritization Module. The Adversarial Point Cloud Generator creates perturbations targeting these features, while the Imperceptibility Constraint Enforcer ensures the perturbations remain within acceptable bounds.

**Design Tradeoffs**: The method balances attack effectiveness against imperceptibility, requiring careful tuning of the deviation constraint. Prioritizing critical features may miss subtle vulnerabilities in less important regions. The assumption of architecture-agnostic critical features may not hold for all model types.

**Failure Signatures**: Attacks may fail when critical features differ significantly across architectures, when the imperceptibility constraint is too restrictive, or when the target model uses fundamentally different feature extraction methods. Performance degradation is expected on datasets with domain shift from training data.

**3 First Experiments**:
1. Compare feature importance consistency across 3 different 3D classifier architectures on ModelNet40
2. Evaluate attack success rate when transferring from PointNet to DGCNN vs. PointNet to PointNet++
3. Test imperceptibility by measuring maximum deviation and conducting human perceptual studies

## Open Questions the Paper Calls Out
None

## Limitations
- The assumption that critical features are architecture-agnostic may not hold for all model types, particularly transformer-based architectures
- Empirical validation is limited to specific datasets (ModelNet40 and ScanObjectNN) and may not generalize to real-world scenarios with noise and occlusions
- Imperceptibility is defined by maximum deviation limits rather than comprehensive perceptual metrics
- Resistance to defenses is claimed but not rigorously tested against specific state-of-the-art defense mechanisms

## Confidence

**High Confidence**: The methodology for identifying and prioritizing critical features shows technical soundness and the experimental results demonstrate clear performance improvements over baseline transfer-based attacks on the tested datasets and architectures.

**Medium Confidence**: The claim of significantly outperforming state-of-the-art attack methods (88% success rate) is supported by the presented experiments, though the evaluation scope is limited to specific model architectures and datasets. The efficiency claim (0.07 minutes per sample) appears reasonable given the algorithmic complexity described.

**Low Confidence**: The claim about strong resistance to potential defenses is weakly supported, as no specific defense mechanisms are tested. The assertion that critical features are universally consistent across different architectures lacks rigorous theoretical justification and requires broader empirical validation.

## Next Checks

1. **Cross-architecture Generalization Test**: Evaluate CFG's effectiveness against a more diverse set of 3D point cloud architectures, including transformer-based models and architectures with fundamentally different design principles (e.g., point-voxel hybrid models).

2. **Defense Robustness Validation**: Test the attack against state-of-the-art 3D point cloud defense mechanisms, including adversarial training, input transformation defenses, and certified robustness approaches to substantiate the claimed resistance to defenses.

3. **Physical-world Feasibility Assessment**: Conduct a small-scale 3D printing experiment to assess whether the generated adversarial point clouds maintain their adversarial properties when physically realized, accounting for manufacturing tolerances and material properties.