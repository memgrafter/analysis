---
ver: rpa2
title: 'lm-Meter: Unveiling Runtime Inference Latency for On-Device Language Models'
arxiv_id: '2510.06126'
source_url: https://arxiv.org/abs/2510.06126
tags:
- latency
- on-device
- inference
- runtime
- profiling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: lm-Meter is a lightweight online profiler for on-device LLM inference
  that provides accurate phase- and kernel-level latency measurements with minimal
  system overhead. It addresses the challenge of profiling LLMs on resource-constrained
  mobile and edge devices where existing profilers are either too heavy or lack fine-grained
  visibility.
---

# lm-Meter: Unveiling Runtime Inference Latency for On-Device Language Models

## Quick Facts
- **arXiv ID**: 2510.06126
- **Source URL**: https://arxiv.org/abs/2510.06126
- **Reference count**: 40
- **Primary result**: Lightweight profiler achieving 99.99% phase accuracy and 96.82% kernel accuracy with <3% throughput overhead on mobile devices

## Executive Summary
lm-Meter is a lightweight online profiler for on-device LLM inference that provides accurate phase- and kernel-level latency measurements with minimal system overhead. It addresses the challenge of profiling LLMs on resource-constrained mobile and edge devices where existing profilers are either too heavy or lack fine-grained visibility. lm-Meter achieves 99.99% accuracy for phase-level profiling and 96.82% accuracy for kernel-level profiling on commercial mobile devices, with only 2.58% throughput reduction during prefill and 0.99% during decode under the most constrained power settings. Using lm-Meter, the study reveals that prefill, not decode, is the dominant bottleneck on mobile devices, identifies architecture- and task-specific trade-offs, and demonstrates the value of the proposed Harmonic Quantization score for evaluating quantization techniques in on-device settings.

## Method Summary
lm-Meter is built on MLC and TVM (approximately 3,500 lines across C++, Python, and Java/Kotlin) and provides both phase-level and kernel-level profiling for on-device LLM inference. For phase-level profiling, the tool instruments the native C++ runtime with `std::chrono::steady_clock` timestamps at semantic phase boundaries (embedding, prefill, decode, softmax, sampling). For kernel-level profiling, it attaches OpenCL/Vulkan/Metal event callbacks to capture four timestamps per kernel (QUEUED, SUBMIT, START, END) via native GPU profiling APIs. The profiler integrates with the Android runtime and can be deployed as an APK. Accuracy is validated against AGI ground truth using kernel duplication, while throughput overhead is measured across different CPU governors (Performance, Conservative, Powersave).

## Key Results
- Achieves 99.99% accuracy for phase-level profiling (embedding, prefill, decode, softmax) and 96.82% accuracy for kernel-level profiling on commercial mobile devices
- Maintains minimal overhead with only 2.58% throughput reduction during prefill and 0.99% during decode under constrained power settings
- Reveals that prefill, not decode, is the dominant bottleneck on mobile devices (158× slowdown vs 10× for decode when scaling from 70M to 1.4B parameters)
- Introduces Harmonic Quantization score (H_Q) to quantify architecture- and task-specific trade-offs in quantization techniques

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Native runtime instrumentation using monotonic clocks yields phase-level latency measurements with >99.9% accuracy for latency-dominant phases.
- Mechanism: The profiler inserts `std::chrono::steady_clock` timestamps immediately before and after each semantic phase (embedding, prefill, decode, softmax, sampling) in the C++ backend. Monotonicity ensures wall-clock adjustments don't corrupt measurements; hardware-backed sub-microsecond precision captures phases from microseconds to hundreds of milliseconds.
- Core assumption: Phase boundaries are well-defined within the native runtime and instrumentation overhead remains negligible relative to phase duration.
- Evidence anchors:
  - [section 3.1]: "steady_clock strikes an effective balance between portability, accuracy, and low instrumentation overhead"
  - [section 4.2, Table 4]: Prefill, decode, softmax phases achieve α ≥ 99.91% accuracy across five LLMs
  - [corpus]: Weak direct validation; related work focuses on end-to-end benchmarking rather than phase decomposition
- Break condition: Short phases (<100μs, e.g., sampling at 50–80μs) show degraded accuracy (α = 75–92%) due to measurement noise dominating signal.

### Mechanism 2
- Claim: GPU event callback mechanisms expose kernel lifecycle timestamps without requiring source code access.
- Mechanism: The profiler attaches callbacks to OpenCL/Vulkan/Metal command queues via native event interfaces (e.g., `clGetEventProfilingInfo`). Four timestamps are captured per kernel: QUEUED (enqueue time), SUBMIT (dispatch time), START (execution begin), END (execution complete). This reconstructs timelines and attributes latency to host-device queuing, scheduling delays, and execution.
- Core assumption: GPU drivers correctly report profiling timestamps and event overhead is acceptably low.
- Evidence anchors:
  - [section 3.2, Fig. 1]: Code snippet querying four CL_PROFILING timestamps
  - [section 4.3, Table 5]: Mean kernel-level accuracy 96.82% (Pixel 8 Pro), 96.61% (Pixel 7); GEMM kernels in prefill achieve 95.18–99.86%
  - [corpus]: nnPerf [36] demonstrated similar event-based profiling for CNNs but lacks LLM-specific phase awareness
- Break condition: Proprietary GPU drivers may limit access or introduce variable latency; micro-kernels (<1ms) show higher relative error (ε★ up to 84.9 μs/ms).

### Mechanism 3
- Claim: Lightweight online profiling induces <3% throughput degradation even under constrained CPU governors.
- Mechanism: By avoiding heavyweight tracing (e.g., AGI's full system traces) and using minimal in-path instrumentation, the profiler avoids introducing observable scheduling contention or memory pressure. Event callbacks fire asynchronously, decoupling measurement from execution path.
- Core assumption: Overhead remains bounded under DVFS and thermal throttling conditions typical of mobile workloads.
- Evidence anchors:
  - [abstract]: "only 2.58% throughput reduction in prefill and 0.99% in decode under the most constrained Powersave governor"
  - [section 4.4, Fig. 4]: MELTing Point shows 22% prefill and 93% decode degradation under Powersave; lm-Meter matches no-profiling baseline under Performance and Conservative governors
  - [corpus]: MELTing Point [35] reported as state-of-the-art but with substantial kernel-tracing overhead; no other corpus papers address profiler overhead quantification
- Break condition: Assumption—overhead may scale differently with non-GPU accelerators (NPU, DSP) not tested in this work.

## Foundational Learning

- Concept: **LLM Inference Phase Decomposition (Prefill vs. Decode)**
  - Why needed here: Understanding that prefill processes the entire input context in one parallelized pass, while decode generates tokens autoregressively with growing KV cache, is essential to interpret why on-device prefill becomes the bottleneck (158× slowdown vs. 10× for decode when scaling from 70M to 1.4B parameters).
  - Quick check question: Why does the paper observe prefill as the dominant bottleneck on mobile but decode as the bottleneck on server-scale GPUs?

- Concept: **GPU Kernel Scheduling and Idle Periods**
  - Why needed here: The profiler reveals >21% GPU idle time during decode steps due to host-side data preparation and kernel launch delays. Recognizing kernel-launch overhead and memory-bound vs. compute-bound kernels helps interpret optimization opportunities.
  - Quick check question: What causes the gray "GPU idle" regions in Figure 10a, and what system-level intervention could reduce them?

- Concept: **Quantization-Accuracy-Latency Trade-offs**
  - Why needed here: The Harmonic Quantization score (H_Q) formalizes that quantization benefits are architecture- and task-dependent. Understanding how 4-bit quantization improves latency but may harm accuracy on numerically sensitive tasks (e.g., SmolLM2-1.7B on GSM8K) informs deployment decisions.
  - Quick check question: Why might aggressive 4-bit quantization collapse H_Q for certain model-task combinations despite reducing latency?

## Architecture Onboarding

- Component map: Native Instrumentation Layer (C++) -> GPU Event Profiler -> Data Post-Processing (Python) -> Android App (Java/Kotlin) -> Integration Layer
- Critical path: User initiates inference → Native runtime triggers phase timers → GPU kernels execute with event callbacks → Timestamps logged to per-kernel structures → Data exported for analysis → Accuracy/overhead metrics computed against ground truth (AGI with kernel duplication)
- Design tradeoffs:
  - `steady_clock` vs. `system_clock`: Chose monotonic `steady_clock` for reliability over wall-clock alignment
  - Kernel duplication for ground truth: Provides reliable baseline but requires model recompilation and controlled conditions (fixed CPU/GPU frequencies, disabled optimizations)
  - Sampling-based benchmarking: KL-divergence subset selection (10% for most tasks, 1% for HellaSwag) balances evaluation cost against representativeness (KL < 0.0433)
- Failure signatures:
  - Sampling phase accuracy drops to 75–85% due to sub-100μs duration being noise-dominated
  - Kernel profiling on proprietary GPU drivers may yield incomplete timestamps or elevated error for micro-kernels
  - Aggressive quantization can cause near-zero accuracy on numerically sensitive tasks (e.g., SmolLM2-1.7B on GSM8K), collapsing H_Q
- First 3 experiments:
  1. Validate phase-level accuracy on a new device (e.g., Pixel 6) by comparing lm-Meter measurements against AGI ground truth across all phases; confirm α ≥ 99% for prefill/decode/softmax
  2. Quantify kernel-level profiling overhead on Powersave governor by measuring throughput with and without event callbacks enabled; expect <1–3% degradation consistent with paper
  3. Replicate the H_Q analysis for a new quantization scheme (e.g., 8-bit) on SmolLM2 and Pythia suites across the four benchmark tasks to validate architecture- and task-dependent sweet spots

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the observed phase- and kernel-level bottlenecks (e.g., prefill dominance, GPU idle periods) persist across diverse edge hardware architectures such as Intel NPUs or Nvidia Jetson devices?
- Basis in paper: [explicit] Section 5.3 states the work is limited to mobile SoCs and that "Other edge platforms (Jetsons and Intel NPUs) may exhibit different bottlenecks."
- Why unresolved: The evaluation was restricted to commercial mobile platforms (Google Pixel 6, 7, and 8 Pro), leaving the behavior on other edge accelerators unknown.
- Evidence to resolve it: Porting lm-Meter to alternative edge platforms and comparing the resulting kernel timelines and phase latency distributions against the mobile SoC baseline.

### Open Question 2
- Question: How does the Harmonic Quantization score ($H_Q$) characterize the trade-offs of diverse compression techniques, such as structured pruning, activation sparsity, and hybrid-precision quantization?
- Basis in paper: [explicit] Section 5.3 notes the analysis focuses on "a narrow slice of the broader compression landscape," and Section 5.1 states, "We consider evaluating diverse quantization techniques using $H_Q$ as our future work."
- Why unresolved: The empirical study using $H_Q$ was limited to post-training 4-bit weight quantization.
- Evidence to resolve it: A comprehensive benchmark of various compression algorithms using the $H_Q$ metric to correlate accuracy degradation with latency improvements on-device.

### Open Question 3
- Question: Can lm-Meter be extended to provide accurate energy profiling by integrating with on-device current sensors or external power monitors?
- Basis in paper: [explicit] Section 3.3 states that while lm-Meter targets latency, "its modular architecture readily supports integration with energy and power measurement tools," identifying this as a foundation for future work.
- Why unresolved: The current implementation focuses on latency and does not output energy consumption data.
- Evidence to resolve it: An extension of the tool that time-aligns phase/kernel traces with power measurements to validate energy profiling accuracy with minimal overhead.

## Limitations
- Validation limited to Google Pixel 6, 7, and 8 Pro devices, potentially limiting generalizability to other mobile platforms
- Kernel-level profiling accuracy depends on GPU driver behavior, which may vary across different SoC generations
- Short sampling phases (<100μs) show degraded accuracy (75-92%) due to measurement noise dominating signal

## Confidence
- **High Confidence (α ≥ 99%)**: Phase-level latency measurements for prefill, decode, and softmax phases on mobile devices
- **Medium Confidence (96.82% kernel accuracy)**: Kernel-level profiling accuracy, acknowledging dependency on GPU driver behavior
- **Medium Confidence (≤3% overhead)**: Throughput degradation claims, based on controlled experiments under different CPU governors
- **Medium Confidence (Prefill bottleneck finding)**: The conclusion that prefill dominates mobile inference latency
- **Low Confidence (H_Q generalizability)**: The Harmonic Quantization score's applicability beyond tested quantization scheme and task set

## Next Checks
1. **Ground-truth validation on new device**: Validate lm-Meter's phase-level accuracy on a Samsung Galaxy S24 (Snapdragon 8 Gen 3) by comparing measurements against AGI ground truth across all phases. Confirm α ≥ 99% for prefill/decode/softmax while measuring thermal and DVFS effects.

2. **Quantify GPU driver variability**: Test kernel-level profiling accuracy on the same S24 device but with GPU performance mode toggled between default and high-performance settings. Measure changes in ε★ for GEMM kernels and assess driver-dependent timestamp reliability.

3. **Expand H_Q analysis to 8-bit quantization**: Replicate the Harmonic Quantization score analysis using 8-bit symmetric quantization (instead of 4-bit group-wise) on the SmolLM2 and Pythia suites across all four benchmark tasks. Compare H_Q distributions to identify whether higher-bit quantization provides more stable task-agnostic performance.