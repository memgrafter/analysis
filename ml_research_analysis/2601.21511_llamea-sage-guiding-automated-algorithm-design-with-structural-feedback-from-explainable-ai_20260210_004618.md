---
ver: rpa2
title: 'LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from
  Explainable AI'
arxiv_id: '2601.21511'
source_url: https://arxiv.org/abs/2601.21511
tags:
- code
- algorithm
- llamea
- llamea-sage
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LLaMEA-SAGE, a method that augments LLM-driven
  automated algorithm design with structural feedback derived from code analysis.
  By extracting graph-theoretic and complexity features from Abstract Syntax Trees
  (ASTs) of generated algorithms, learning a surrogate model, and using SHAP to identify
  influential code properties, the approach translates structural insights into natural-language
  mutation prompts that guide subsequent LLM-based modifications.
---

# LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI

## Quick Facts
- arXiv ID: 2601.21511
- Source URL: https://arxiv.org/abs/2601.21511
- Reference count: 24
- Authors: Niki van Stein; Anna V. Kononova; Lars Kotthoff; Thomas Bäck
- Primary result: Achieves better or equal performance than vanilla LLaMEA faster with reduced variance across runs

## Executive Summary
This paper introduces LLaMEA-SAGE, a method that augments LLM-driven automated algorithm design with structural feedback derived from code analysis. By extracting graph-theoretic and complexity features from Abstract Syntax Trees (ASTs) of generated algorithms, learning a surrogate model, and using SHAP to identify influential code properties, the approach translates structural insights into natural-language mutation prompts that guide subsequent LLM-based modifications. Evaluated on black-box optimization benchmarks, LLaMEA-SAGE achieves the same or better performance than vanilla LLaMEA faster, with reduced variance across runs. In a large-scale comparison on the MA-BBOB suite, it outperforms state-of-the-art baselines including MCTS-AHD and LHNS, while maintaining low token costs. Validation on unseen instances confirms strong generalization, with the best discovered algorithms outperforming competition winners in higher dimensions.

## Method Summary
LLaMEA-SAGE operates through an iterative evolutionary loop where generated algorithms are parsed into ASTs, from which graph-theoretic and complexity features are extracted. These features are used to train an XGBoost surrogate model that predicts algorithm performance, with SHAP values identifying the most influential structural properties. The top feature's attribution determines whether the LLM should increase or decrease that property in the next generation, with guidance injected as natural-language mutation prompts. The archive of evaluated solutions grows over time, improving surrogate accuracy and guidance quality. The method is evaluated on continuous black-box optimization benchmarks using IOH-BLADE, comparing against vanilla LLaMEA and state-of-the-art baselines.

## Key Results
- LLaMEA-SAGE achieves the same or better performance than vanilla LLaMEA faster, with reduced variance across runs
- In large-scale MA-BBOB comparison, LLaMEA-SAGE outperforms MCTS-AHD and LHNS baselines while maintaining low token costs
- Best discovered algorithms generalize to higher dimensions and outperform competition winners

## Why This Works (Mechanism)

### Mechanism 1
Static code structure features extracted from abstract syntax trees correlate with algorithm performance and can guide search. Parse generated Python code into AST → construct directed graph G_c = (V, E) → compute graph-theoretic statistics (node/edge counts, degree entropy, tree depth, clustering coefficients, diameter) and code complexity indicators (cyclomatic complexity, token counts, parameter counts) → train XGBoost surrogate model to approximate f(cf) ≈ fitness → use SHAP to identify highest-impact feature. Core assumption: Structural properties of code causally or correlatively influence optimization performance; the surrogate can capture this mapping with sufficient archive data. Break condition: If AST features are uninformative, surrogate predictions degrade and guidance becomes noise.

### Mechanism 2
SHAP-based feature attribution translates learned correlations into actionable natural-language mutation guidance. For each feature j, SHAP computes attribution φ_j → select feature k with largest |φ_k| → sign determines "increase" or "decrease" → inject template: "Based on archive analysis, try to <a> the <k> of the solution." → LLM generates code biased toward that structural direction. Core assumption: LLMs can interpret and act on abstract structural guidance; single-feature guidance provides useful bias without over-constraining. Break condition: If LLM ignores guidance or if selected feature is irrelevant to actual performance drivers, guidance adds noise without benefit.

### Mechanism 3
Archive-based iterative learning accumulates signal-to-noise in feature-performance mapping, improving guidance over time. Archive A = {(s_i, f_i, cf_i)} accumulates all evaluated solutions → surrogate retrained as archive grows → early noisy guidance stabilizes as more data informs feature importance → LLM mutations receive increasingly grounded prompts. Core assumption: Feature-performance relationships are sufficiently stable across the search process; early random exploration populates archive before meaningful guidance kicks in. Break condition: If feature-performance mapping shifts dramatically during search, fixed surrogate provides misleading guidance.

## Foundational Learning

- Concept: Abstract Syntax Trees (AST) and static code analysis
  - Why needed here: Core to extracting structural features from generated code; must understand how Python parses into nodes/edges
  - Quick check question: Given a simple Python function, can you sketch its AST node types (FunctionDef, arguments, Assign, BinOp, etc.)?

- Concept: Surrogate modeling with gradient-boosted trees (XGBoost)
  - Why needed here: Maps high-dimensional code features to scalar fitness; must understand regression, overfitting risks with small archives, and feature importance extraction
  - Quick check question: Why might a surrogate trained on 8 samples (initial population) provide unreliable guidance?

- Concept: SHAP (SHapley Additive exPlanations) for tree models
  - Why needed here: Identifies which structural features drive predictions; requires understanding of local vs global explanations and sign interpretation
  - Quick check question: If SHAP value for "cyclomatic complexity" is +0.15 for a candidate, what does that mean for predicted fitness?

## Architecture Onboarding

- Component map: LLM Code Generator -> AST Parser & Feature Extractor -> Archive Store -> Surrogate Trainer -> SHAP Analyzer -> Prompt Augmenter -> Evaluator -> Archive Store

- Critical path: Archive populated → surrogate trained → SHAP computes attributions → guidance injected → LLM generates → evaluate → update archive. If archive < threshold, fall back to vanilla mutation.

- Design tradeoffs:
  - Single-feature vs multi-feature guidance: Paper uses single top feature; multi-feature could capture interactions but increases prompt complexity and LLM confusion risk
  - Minimum archive size: Too small → noisy surrogate; too large → delayed guidance. Paper uses initial pop size (8 in Exp1, 4 in Exp2)
  - Feature set scope: Generic AST features vs domain-specific features. Generic enables transfer but may miss task-critical signals

- Failure signatures:
  - LLM ignores guidance: Observed for "random new" prompt vs "refine" (~70% match)
  - Surrogate overfits small archive: Early guidance may chase noise
  - Stagnation on wrong feature: If top SHAP feature is correlational not causal, search may exploit spurious patterns
  - Token explosion: Guidance slightly increases prompt length; monitor if guidance chains grow unbounded

- First 3 experiments:
  1. Baseline isolation test: Run vanilla LLaMEA vs LLaMEA-SAGE on small benchmark (SBOX-COST, 5 functions) with 200 evaluations, 5 seeds. Confirm faster convergence in first 50-100 evaluations
  2. Guidance adherence analysis: Log parent-child feature deltas vs guidance direction. Replicate Figure 5 analysis—expect high adherence for "refine" prompt, near-zero for "random new"
  3. Feature importance audit: Track which features SHAP selects over time. Check if certain features dominate vs diverse usage. If single feature dominates >80% of guidance, consider multi-feature or feature rotation strategies

## Open Questions the Paper Calls Out

- Does LLaMEA-SAGE generalize effectively to high-dimensional, noisy, or non-continuous optimization problems? Experiments were limited to noiseless continuous benchmarks at moderate dimensionalities (d=5,10,20).
- Can integrating dynamic execution features with static AST features improve performance correlation? Current set captures only static structural properties and does not account for dynamic execution behavior.
- Do adaptive or multi-feature guidance strategies outperform the current single-feature attribution approach? Current method relies on single feature with largest absolute SHAP value, potentially missing complex structural interactions.

## Limitations
- Relies on GPT-5-mini (future model) for reproducibility, creating immediate barrier
- Single-feature guidance may miss important feature interactions that multi-feature guidance could capture
- Primary uncertainty whether observed gains are genuinely driven by structural guidance or artifacts of surrogate learning capacity

## Confidence

**High confidence**: The framework's general architecture is sound and well-motivated by related work in program analysis and explainable AI. The benchmark results showing LLaMEA-SAGE outperforming baselines on MA-BBOB are robust and statistically validated.

**Medium confidence**: The specific claim that structural feedback from AST features is the primary driver of performance improvement. While results support this, the mechanism could also be partially explained by surrogate model's ability to memorize successful patterns.

**Low confidence**: The generalizability of results to other algorithm domains beyond continuous black-box optimization, and the scalability of the approach to higher-dimensional problems where AST feature relevance may shift dramatically.

## Next Checks

1. **Causal Ablation Test**: Run controlled experiments where guidance is systematically degraded (random feature selection, inverted guidance directions) while keeping all other components constant. Compare performance degradation against full LLaMEA-SAGE to quantify specific contribution of correct structural feedback.

2. **Multi-Feature Guidance Experiment**: Modify guidance system to incorporate top-3 SHAP features with combined instructions, then evaluate whether this improves performance over single-feature guidance on a subset of the benchmark suite.

3. **Cross-Domain Transfer Validation**: Apply complete LLaMEA-SAGE pipeline to a different algorithm design domain (e.g., scheduling heuristics or graph algorithms) with known structural performance patterns. Success in this transfer would validate general applicability of structural feedback beyond original continuous optimization context.