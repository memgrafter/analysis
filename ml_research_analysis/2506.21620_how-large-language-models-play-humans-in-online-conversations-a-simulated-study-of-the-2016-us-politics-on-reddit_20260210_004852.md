---
ver: rpa2
title: 'How Large Language Models play humans in online conversations: a simulated
  study of the 2016 US politics on Reddit'
arxiv_id: '2506.21620'
source_url: https://arxiv.org/abs/2506.21620
tags:
- user
- comments
- history
- real
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the ability of GPT-4 to simulate user-generated
  content in politically charged Reddit discussions during the 2016 US presidential
  election. Three experimental scenarios tested GPT-4's performance in impersonating
  real users, generating supportive content, and producing dissenting content, using
  real conversation threads from r/TheDonald and r/HillaryClinton.
---

# How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit

## Quick Facts
- arXiv ID: 2506.21620
- Source URL: https://arxiv.org/abs/2506.21620
- Authors: Daniele Cirulli; Giulio Cimini; Giovanni Palermo
- Reference count: 40
- Key outcome: GPT-4 generates realistic Reddit comments but consistently favors consensus over dissent, even when prompted with opposing views.

## Executive Summary
This study evaluates GPT-4's ability to simulate user-generated content in politically charged Reddit discussions during the 2016 US presidential election. The researchers tested GPT-4 across three scenarios: impersonating real users, generating supportive content, and producing dissenting content. Using real conversation threads from r/The_Donald and r/HillaryClinton, they found GPT-4 could produce realistic comments but consistently favored consensus over dissent, even when explicitly prompted to generate opposing views. The analysis revealed that while generated comments were manually indistinguishable from real ones, they occupied distinct regions in semantic embedding space.

## Method Summary
The researchers used Reddit data from r/The_Donald (387 users, 5,488 comments) and r/HillaryClinton (100 users, 5,220 comments) from 2015-2016. They constructed four prompt conditions: real user history, no history (null model), pro-candidate history, and anti-candidate history. GPT-4-turbo was used with temperature=0.0 and top-p=1.0 to generate comments. Generated and real comments were classified on party alignment, sentiment, and violence using GPT-4 with in-context learning. Semantic embeddings were computed using text-embedding-3-small (1536 dimensions) and visualized with t-SNE to compare real and synthetic content.

## Key Results
- GPT-4 generated anti-candidate comments in only 22-32% of cases when prompted with anti-candidate histories, compared to 55% pro-candidate when using pro-candidate histories
- Generated comments were manually indistinguishable from real comments but showed clear separation in semantic embedding space
- The model's consensus bias persisted even when provided with real user histories showing anti-candidate sentiment

## Why This Works (Mechanism)

### Mechanism 1: Consensus Generation Bias
GPT-4 generates consensus-aligned content more readily than dissent, even when explicitly prompted with opposing views. This behavior stems from the model's training objective as a "helpful assistant" that prioritizes agreement and compliance over adversarial stance-taking. The causal mechanism is inferred from observed behavior rather than proven through controlled experiments.

### Mechanism 2: Semantic Embedding Separability
Real and LLM-generated comments occupy distinct regions in embedding space despite being manually indistinguishable. This occurs because LLMs produce text with consistent statistical signatures that differ from human text, manifesting as separable clusters when projected via text-embedding-3-small and visualized with t-SNE.

### Mechanism 3: User History Conditioning with Incomplete Control
Providing user history constrains generated content but does not fully determine political alignment. GPT-4 conditions on provided context but weights multiple factors, with thread context potentially overriding user history conditioning. The model's context integration is additive rather than hierarchical.

## Foundational Learning

- **Semantic embeddings (text-embedding-3-small, t-SNE)**: Why needed: The paper's core detection claim relies on embedding-space separation; understanding how embeddings capture semantic and stylistic features is prerequisite to reproducing or extending the analysis. Quick check: Can you explain why t-SNE preserves local structure while potentially distorting global distances?

- **LLM temperature and top-p sampling**: Why needed: The paper uses temperature=0.0, top-p=1.0 (deterministic, greedy). Understanding these parameters is essential for interpreting why results are reproducible and what changes with higher temperatures. Quick check: What output behavior would you expect if temperature were raised to 0.7 in Scenario 1?

- **In-context learning for classification**: Why needed: The paper uses GPT-4 to classify its own outputs (party alignment, sentiment, violence) via in-context learning. Understanding this technique is necessary to evaluate potential classification biases. Quick check: Why might providing a violent example in the in-context prompt affect classification of borderline content?

## Architecture Onboarding

- Component map: Reddit data (Pushshift/Politosphere) → Preprocessing (2015 history, 2016 targets) → Prompt construction (thread context + user history variant) → GPT-4 generation (temperature=0.0, top-p=1.0) → GPT-4 classification (party alignment, sentiment, violence) → text-embedding-3-small → t-SNE visualization → SVC classifier

- Critical path: Prompt design is the highest-leverage component; small changes in user history framing produce measurable but incomplete alignment shifts. Classification pipeline must use consistent in-context examples. Embedding analysis requires averaging multiple runs to control for randomness.

- Design tradeoffs: Temperature=0.0 ensures reproducibility but may underrepresent human variability. Using GPT-4 for both generation and classification introduces correlated biases. Fictitious user histories are manually crafted rather than procedurally generated, limiting scalability.

- Failure signatures: If generated comments cluster with real comments in t-SNE, check embedding model compatibility. If classification fails to match human judgment, verify in-context examples are representative. If anti-candidate prompts produce pro-candidate output at high rates, inspect whether safety filters are overriding user history conditioning.

- First 3 experiments:
  1. Reproduce t-SNE separation with a different embedding model (e.g., Sentence-BERT) to test robustness of the separability claim.
  2. Test hierarchical prompting for dissent generation: explicitly instruct the model to argue against its provided user history and measure dissent rates.
  3. Train classifier on embedding space using cross-validation: extend the SVC experiment with stratified k-fold and report confidence intervals on real vs. synthetic discrimination.

## Open Questions the Paper Calls Out

### Open Question 1
How does LLM performance and consensus bias evolve when generating sustained, multi-turn conversations? The authors state the study is limited to "generating a synthetic text for only the last comment in a post branch." It is unknown if single-turn success translates to maintaining a persona over time or if the model drifts toward consensus in longer threads. Experiments where the model generates sequential replies within a single conversation tree would resolve this.

### Open Question 2
Is the semantic separation between real and artificial text robust enough to serve as a general bot detection tool? The authors note "additional studies in different context would be needed to confirm that real users and bots can be distinguished" via embeddings. The distinct clustering was only observed in the specific context of the 2016 US election on Reddit. Successful classification using embedding distances on datasets from diverse social platforms and non-political topics would resolve this.

### Open Question 3
Does the observed reluctance to generate dissent stem from model architecture or safety alignment? The authors "speculate that generating dissent might be a more costly task" or result from its "designing purpose of creating a helpful assistant." The paper identifies the consensus bias but does not isolate the specific training component responsible for the behavior. Comparing the dissent rates of base models against their instruction-tuned counterparts using the same adversarial prompts would resolve this.

## Limitations

- The study's findings are based on GPT-4 specifically and may not generalize to other LLMs or future model versions
- The deterministic generation setting (temperature=0.0) may underrepresent human variability in online discourse
- The use of GPT-4 for both generation and classification introduces potential circular biases

## Confidence

- **High Confidence**: The consensus generation bias finding is well-supported by multiple scenario comparisons and aligns with RLHF literature on alignment effects
- **Medium Confidence**: The semantic embedding separability claim is demonstrated but may be dependent on the specific embedding model used
- **Low Confidence**: The interpretation of why GPT-4 struggles with dissent generation remains theoretical without direct testing of alternative prompting strategies

## Next Checks

1. Replicate the t-SNE embedding analysis using a different semantic embedding model (e.g., Sentence-BERT or another non-OpenAI embedding) to test whether separability is model-specific or a robust finding

2. Systematically test hierarchical prompting strategies that explicitly instruct the model to argue against its provided user history, measuring whether this overcomes the dissent generation limitation

3. Conduct cross-validation with an external classifier (not GPT-4) trained on the embedding space to provide independent validation of real vs. synthetic discrimination performance