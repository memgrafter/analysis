---
ver: rpa2
title: 'FrameShield: Adversarially Robust Video Anomaly Detection'
arxiv_id: '2510.21532'
source_url: https://arxiv.org/abs/2510.21532
tags:
- adversarial
- training
- anomaly
- clean
- video
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FrameShield addresses the vulnerability of weakly supervised video
  anomaly detection (WSVAD) models to adversarial attacks. The core issue is that
  existing methods rely on video-level labels and MIL-based losses, which result in
  weak adversarial perturbations during training, leaving the models susceptible to
  attacks during inference.
---

# FrameShield: Adversarially Robust Video Anomaly Detection

## Quick Facts
- arXiv ID: 2510.21532
- Source URL: https://arxiv.org/abs/2510.21532
- Authors: Mojtaba Nafez; Mobina Poulaei; Nikan Vasei; Bardia Soltani Moakhar; Mohammad Sabokrou; MohammadHossein Rohban
- Reference count: 40
- Primary result: Outperforms state-of-the-art WSVAD methods by 71.0% average AUROC against adversarial attacks

## Executive Summary
FrameShield addresses the vulnerability of weakly supervised video anomaly detection (WSVAD) models to adversarial attacks by introducing a two-phase training approach. The framework first generates pseudo-labels for anomaly videos using PromptMIL, then employs adversarial training with synthetically generated anomalies created through Spatiotemporal Region Distortion (SRD). This approach provides precise frame-level annotations while preserving temporal consistency, significantly improving model robustness against adversarial attacks while maintaining competitive performance on standard benchmarks.

## Method Summary
FrameShield tackles the weakness of existing WSVAD models that rely on video-level labels and MIL-based losses, which produce weak adversarial perturbations during training. The framework implements a two-phase approach: first training a standard PromptMIL model to generate pseudo-labels for anomaly videos, then employing an adversarial training pipeline using these pseudo-labels and SRD-generated anomalies. SRD applies severe augmentations to localized regions in normal videos while preserving temporal consistency, providing precise frame-level annotations. The method significantly improves robustness against adversarial attacks while maintaining competitive performance on standard setups.

## Key Results
- Achieves 71.0% average improvement in overall AUROC performance across five benchmarks compared to state-of-the-art methods
- Demonstrates significant robustness improvements on UCSD Ped2, ShanghaiTech, TAD, UCF Crime, and MSAD datasets
- Maintains competitive performance on standard (non-adversarial) setups while providing enhanced adversarial defense

## Why This Works (Mechanism)
FrameShield addresses the fundamental weakness in WSVAD models where MIL-based losses result in weak adversarial perturbations during training. By generating precise pseudo-labels through PromptMIL and using SRD to create realistic synthetic anomalies with localized, temporally consistent distortions, the framework provides stronger supervisory signals during adversarial training. This enables the model to learn more robust feature representations that are less susceptible to adversarial manipulation while maintaining the weakly supervised learning paradigm.

## Foundational Learning
- **PromptMIL for pseudo-label generation**: Converts video-level labels into frame-level pseudo-labels, enabling supervised training signals. Needed to provide precise annotations for the adversarial training phase. Quick check: Verify pseudo-label quality by comparing against ground truth on labeled frames.
- **Spatiotemporal Region Distortion (SRD)**: Applies localized augmentations while preserving temporal consistency in normal videos. Needed to create realistic synthetic anomalies that serve as training data for adversarial robustness. Quick check: Validate that SRD maintains temporal coherence by analyzing frame sequences.
- **Adversarial training pipeline**: Uses generated pseudo-labels and SRD anomalies to train robust models. Needed to expose the model to strong perturbations during training, preventing overfitting to weak adversarial patterns. Quick check: Measure model performance degradation under various attack strengths.

## Architecture Onboarding

Component Map: Normal Video Input -> SRD Augmentation -> Frame-Level Annotations -> Adversarial Training -> Robust WSVAD Model

Critical Path: The most critical sequence is Normal Video -> SRD Augmentation -> Frame-Level Annotations -> Adversarial Training. This path determines the quality of synthetic anomalies used for training robust models. Any weakness in SRD's ability to generate realistic anomalies or preserve temporal consistency directly impacts the final model's robustness.

Design Tradeoffs: The framework trades increased computational complexity for enhanced robustness. The two-phase training approach requires generating pseudo-labels and synthetic anomalies, adding overhead compared to standard WSVAD methods. However, this tradeoff is justified by the significant improvements in adversarial defense. The reliance on synthetic anomalies may limit real-world generalization compared to using actual anomaly data.

Failure Signatures: Model performance degradation would likely manifest as reduced AUROC scores on adversarial test sets while maintaining reasonable performance on clean data. Failure in SRD could result in temporally inconsistent anomalies that confuse the model during training. Poor quality pseudo-labels from the initial PromptMIL training would propagate errors throughout the adversarial training phase.

First Experiments:
1. Baseline evaluation: Test PromptMIL performance on standard benchmarks to establish pseudo-label quality.
2. SRD validation: Verify that SRD-generated anomalies maintain temporal consistency and realistic appearance.
3. Ablation study: Compare adversarial training with and without pseudo-labels to quantify their contribution to robustness.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance generalization against novel attack strategies beyond tested methods remains unverified
- Computational overhead from two-phase training may impact scalability for large-scale deployment
- Dependence on synthetic anomaly generation through SRD may not fully capture real-world anomaly diversity

## Confidence

**High confidence** in effectiveness against specific tested adversarial attacks, based on significant AUROC improvements reported.

**Medium confidence** in generalization to real-world scenarios due to controlled experimental conditions and synthetic anomaly generation.

**Medium confidence** in scalability and practical deployment due to lack of real-world performance data and computational complexity analysis.

## Next Checks

1. Evaluate robustness against broader range of attack methods, including adaptive attacks designed to circumvent SRD-based defense.
2. Conduct real-world deployment tests in operational video surveillance systems to assess practical performance under diverse conditions.
3. Perform ablation studies to quantify impact of each component (PromptMIL pseudo-labels, SRD augmentation) on overall adversarial robustness.