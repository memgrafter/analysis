---
ver: rpa2
title: Identifying environmental factors associated with tetrodotoxin contamination
  in bivalve mollusks using eXplainable AI
arxiv_id: '2511.20395'
source_url: https://arxiv.org/abs/2511.20395
tags:
- contamination
- bivalve
- features
- mollusks
- water
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed an explainable deep learning model to predict
  tetrodotoxin (TTX) contamination in bivalve mollusks using environmental data from
  the Dutch Zeeland estuary. The model used 35 days of meteorological and hydrological
  features as inputs to predict the presence of TTX above regulatory limits.
---

# Identifying environmental factors associated with tetrodotoxin contamination in bivalve mollusks using eXplainable AI

## Quick Facts
- arXiv ID: 2511.20395
- Source URL: https://arxiv.org/abs/2511.20395
- Reference count: 11
- Primary result: LSTM model achieves AUC 0.93 for TTX contamination prediction in bivalves using 35-day environmental data

## Executive Summary
This study develops an explainable deep learning model to predict tetrodotoxin (TTX) contamination in bivalve mollusks using environmental data from the Dutch Zeeland estuary. The researchers employed a long short-term memory (LSTM) network that uses 35 days of meteorological and hydrological features to predict TTX presence above regulatory limits. The model demonstrates strong predictive performance with an AUC of 0.93 on a held-out test set, achieving 83% specificity at 90% sensitivity for predicting contamination above the Action Limit. Using explainable AI techniques, the study identifies key environmental drivers including time of sunrise and sunset, global radiation, water temperature, and chloride concentration.

## Method Summary
The researchers developed an LSTM-based deep learning model that predicts TTX contamination in bivalve mollusks using environmental data. The model takes 35 days of meteorological and hydrological features as input to predict the presence of TTX above regulatory limits. The environmental data includes solar radiation metrics, water temperature, and chloride concentration measurements. The LSTM architecture was chosen to capture temporal patterns in the environmental data that may correlate with TTX contamination events. The model was trained and validated using data from the Dutch Zeeland estuary, with performance evaluated using standard metrics including area under the curve (AUC), specificity, and sensitivity.

## Key Results
- LSTM model achieved AUC of 0.93 on held-out test set for predicting TTX contamination
- Model achieved 83% specificity at 90% sensitivity for predicting contamination above Action Limit
- Explainable AI identified sunrise/sunset times, global radiation, water temperature, and chloride concentration as key environmental drivers

## Why This Works (Mechanism)
The model's success stems from its ability to capture complex temporal relationships between environmental factors and TTX production. The 35-day input window allows the LSTM to learn patterns in solar radiation, temperature fluctuations, and water chemistry changes that may trigger bacterial or algal TTX production. The explainable AI component reveals that solar radiation metrics (sunrise/sunset times and global radiation) are particularly important, suggesting that effective sun hours and solar intensity play crucial roles in TTX contamination through their influence on bacterial or algal activity in the estuary ecosystem.

## Foundational Learning
- LSTM networks for time series prediction: Essential for capturing temporal dependencies in environmental data; check by verifying gradient flow through time steps
- Explainable AI techniques for model interpretation: Critical for identifying environmental drivers; validate by comparing SHAP values with permutation importance
- Binary classification metrics (AUC, sensitivity, specificity): Necessary for evaluating contamination prediction performance; confirm by checking confusion matrix and ROC curve
- Environmental toxicology data preprocessing: Important for handling missing values and temporal alignment; validate by examining feature distributions and temporal consistency
- Regulatory threshold classification: Required for converting continuous predictions to actionable alerts; verify by testing different threshold values

## Architecture Onboarding

Component map: Environmental data (35-day window) -> LSTM network -> Binary classification output -> SHAP values for interpretation

Critical path: Input feature processing -> LSTM temporal modeling -> Dense layer classification -> Threshold application -> SHAP explanation generation

Design tradeoffs: The 35-day window balances model complexity with practical monitoring needs; binary classification simplifies decision-making but loses concentration information; LSTM chosen over simpler models for capturing temporal patterns despite higher computational cost

Failure signatures: Model degradation during unusual weather patterns, false positives during extreme solar events, temporal drift as climate patterns change

First experiments: 1) Test model sensitivity to input window length (20 vs 35 vs 50 days), 2) Compare LSTM performance against simpler temporal models (ARIMA, random forest), 3) Validate SHAP explanations with feature ablation studies

## Open Questions the Paper Calls Out
None

## Limitations
- Single-site study limits generalizability to other geographic regions
- Environmental factors identified are correlative rather than causative
- Binary classification approach doesn't predict actual TTX concentrations
- 35-day input window may miss longer-term environmental patterns

## Confidence

**Major claim confidence:**
- Model predictive performance: **High** - well-documented with cross-validation
- Environmental factor identification: **Medium** - statistically derived but mechanistically unclear
- Generalizability to other regions: **Low** - single-site study with limited validation

## Next Checks
1. Test the model on independent datasets from different geographic locations with varying environmental conditions
2. Conduct laboratory experiments to validate the mechanistic links between identified environmental factors and TTX production in bacteria/algae
3. Extend the model to predict TTX concentrations rather than binary classification to improve risk quantification