---
ver: rpa2
title: Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using
  Knowledge Graphs
arxiv_id: '2508.17340'
source_url: https://arxiv.org/abs/2508.17340
tags:
- legal
- reasoning
- facts
- norm
- court
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper constructs a legal knowledge graph (LKG) from Japanese
  administrative court decisions to explicitly model the multi-step reasoning paths
  connecting facts, legal norms, and statutory provisions. By extracting and linking
  these elements using structured prompts and an ontology, the approach captures the
  inferential structure of judicial decisions.
---

# Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using Knowledge Graphs

## Quick Facts
- arXiv ID: 2508.17340
- Source URL: https://arxiv.org/abs/2508.17340
- Reference count: 17
- Primary result: LKG-based retrieval achieves significantly higher recall (0.667 micro at k=3) than LLM and RAG baselines

## Executive Summary
This paper constructs a legal knowledge graph (LKG) from Japanese administrative court decisions to model the multi-step reasoning paths connecting facts, legal norms, and statutory provisions. By extracting and linking these elements using structured prompts and an ontology, the approach captures the inferential structure of judicial decisions. Evaluation shows the LKG-based retrieval method achieves significantly higher recall than large language model baselines and retrieval-augmented methods, demonstrating that structured legal knowledge graphs enable more accurate and interpretable legal search than general-purpose language models alone.

## Method Summary
The approach extracts structured elements (Facts, Legal Norms, Legal Applications, Provisions) from court judgments using GPT-4o with specific prompts including a "Martian Law" one-shot example. These elements are linked through an ontology to create a directed graph representing legal reasoning paths. The retrieval system embeds Fact nodes, finds similar facts using approximate nearest neighbor search, and traverses the graph to collect relevant provisions. The method includes a "Fact-Masked" setting that masks the query fact's own edges to ensure retrieval relies on analogous reasoning paths rather than exact matches.

## Key Results
- LKG-based retrieval achieves 0.667 micro recall and 0.311 macro recall at k=3
- Outperforms GPT-4o RAG (0.118 micro recall) and LLM baselines significantly
- High precision for Provision extraction (1.0) but lower for Legal Application (0.87)
- Graph structure enables more accurate legal provision retrieval than unstructured semantic search

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Structured legal ontologies constrain LLM outputs, reducing "hallucination" of legal logic by forcing text into explicit reasoning steps
- **Mechanism:** The system defines a rigid schema (RDF/JSON-LD) with distinct classes—Fact, LegalNorm, LegalApplication, and Provision—and requires the LLM to classify text into these buckets. This transforms unstructured judicial text into a directed graph where edges represent specific inferential relations
- **Core assumption:** Legal reasoning can be decomposed into discrete, sequential nodes (Fact → Application → Norm) without significant loss of nuance
- **Evidence anchors:** [abstract] "link facts, norms, and legal applications through an ontology of legal inference"; [Section 2.1] "Our schema introduces a minimal, but highly expressive, set of classes"

### Mechanism 2
- **Claim:** Accumulating context via "scoped-history prompting" allows the model to link legally dependent concepts that appear far apart in the document text
- **Mechanism:** Instead of relying on local context windows, the prompt for edge construction injects a list of all previously extracted candidate nodes from the judgment. This emulates the non-linear flow of judicial opinions where conclusions often rely on facts stated pages earlier
- **Core assumption:** The LLM can effectively attend to a large list of candidate nodes without getting distracted or losing coherence
- **Evidence anchors:** [Section 2.2 (iii)] "We adopted a scoped-history prompting strategy: each Legal Application node was paired with all preceding Legal Norm or Fact nodes"

### Mechanism 3
- **Claim:** Graph traversal from fact-anchored embeddings retrieves relevant provisions with higher recall than unstructured semantic search because it follows explicit logical paths rather than text similarity
- **Mechanism:** The system embeds a query fact, finds the top-k most similar facts in the graph (using Annoy), and then traverses the explicit edges (Fact → Legal Application → Provision) to retrieve the law. It masks the query fact's own edges to ensure retrieval relies on analogous reasoning paths
- **Core assumption:** Semantically similar facts generally invoke the same legal norms and provisions within the graph structure
- **Evidence anchors:** [abstract] "achieves significantly higher recall (0.667 micro... at k=3) in retrieving relevant legal provisions from facts"

## Foundational Learning

- **Concept: Legal Ontology (RDF/JSON-LD)**
  - **Why needed here:** The paper relies on defining semantic classes (Fact, Norm) to structure data. Without understanding schemas, you cannot interpret the graph structure
  - **Quick check question:** Can you distinguish between a "Legal Norm" (the rule) and a "Legal Application" (applying the rule to a fact) in a short text?

- **Concept: Approximate Nearest Neighbor (ANN) Search**
  - **Why needed here:** The retrieval mechanism uses Annoy to find similar facts efficiently. Understanding vector space search is critical for the "Fact-Masked" retrieval component
  - **Quick check question:** Why would you use an approximate search algorithm like Annoy instead of exact search for a graph with 11,199 Fact nodes?

- **Concept: Prompt Engineering (Context Injection)**
  - **Why needed here:** The extraction quality depends on "scoped-history" prompting
  - **Quick check question:** How does providing a "case overview" and a fictional "Martian Law" example in the prompt improve node extraction accuracy?

## Architecture Onboarding

- **Component map:** HTML Court Judgments → Preprocessor (Regex/HTML parser) → Node Extractor (GPT-4o + "Martian Law" prompt → JSON nodes) → Normalizer (GPT-4o → Standardizes statutory references) → Edge Constructor (GPT-4o + Scoped History → Links Provision → Norm → Application → Fact) → Retrieval (Embedding + Annoy Index + Graph Traversal)

- **Critical path:** The Node Extractor is the bottleneck. The evaluation shows that while Provision extraction is perfect (1.0), Application extraction has lower recall (0.87). Errors here cascade to Edge Construction, resulting in broken reasoning paths

- **Design tradeoffs:**
  - Recall vs. Precision: The LKG retrieval achieves high recall (0.667) but lower precision (0.239) at k=3. The system is optimized for finding relevant laws (recall) rather than filtering out irrelevant ones (precision)
  - Fictional vs. Real Examples: The authors use a fictional "Martian Law" for few-shot prompting to avoid overfitting to specific legal artifacts, trading realism for generalization

- **Failure signatures:**
  - Norm/Application Confusion: The model frequently mislabels "Legal Application" sentences as "Legal Norms" (Section 3.1). This happens when the text blends the rule statement with its application
  - Dangling Nodes: If the Edge Constructor fails to find a link (returns [] due to context distance), nodes become isolated, reducing graph connectivity

- **First 3 experiments:**
  1. Node Validation: Run the extraction prompt on 5 randomly selected judgment sections. Manually verify if "Legal Norm" and "Legal Application" labels are assigned correctly according to the definitions
  2. Context Window Stress Test: Test the "scoped-history" prompt by progressively increasing the number of candidate nodes provided. Measure if accuracy drops as the context length approaches the token limit
  3. Retrieval Ablation: Run the retrieval task with and without the "Fact-Masked" setting to confirm that the system is retrieving via analogy rather than matching the query case itself

## Open Questions the Paper Calls Out

- **Open Question 1:** Can expanding the schema to support direct edges between legal norms (e.g., Legal Norm → Legal Norm) improve the capture of hierarchical reasoning structures?
  - **Basis in paper:** [explicit] The authors note the current schema does not support edges between norms, which caused the model to miss links to secondary norms that support or constrain primary ones (Page 10)
  - **Why unresolved:** The current structure forces a flat representation of norms, failing to encode the layered logic where one norm derives from or modifies another
  - **What evidence would resolve it:** A modified schema allowing inter-norm edges that results in higher recall for complex multi-layered reasoning during expert evaluation

- **Open Question 2:** How can the graph construction be adapted to bridge the disconnected components (individual judgments) to enable cross-precedent legal reasoning?
  - **Basis in paper:** [inferred] The structural analysis reveals the graph is fragmented into isolated subgraphs based on specific judgments, lacking "strong connectivity" (Page 11)
  - **Why unresolved:** The current pipeline treats each judgment in isolation, preventing the system from modeling relationships between similar facts or norms across different cases
  - **What evidence would resolve it:** The development of an entity alignment or linking method that connects semantically similar Fact or Norm nodes across different weakly connected components

- **Open Question 3:** Is the proposed ontology and LLM-based extraction pipeline effective for legal domains with different reasoning structures, such as Common Law or criminal litigation?
  - **Basis in paper:** [inferred] The authors limit their scope to Japanese administrative litigation (Civil Law) due to practical considerations and computational costs, leaving other domains unexplored (Page 9)
  - **Why unresolved:** Administrative law relies heavily on specific statutory interpretation; the prompts and schema may not generalize to systems relying on binding case precedents or criminal intent
  - **What evidence would resolve it:** Successful application of the same extraction prompts and schema to a dataset of Common Law (e.g., US/UK) or criminal judgments without significant loss in precision or recall

## Limitations
- Norm vs. Application Classification Ambiguity: The ontology may not cleanly map to Japanese administrative court language patterns, with GPT-4o frequently misclassifying Applications as Norms
- Context Window Constraints: The exact token limits and context selection algorithms are not specified, making performance degradation thresholds unknown
- Single Jurisdiction Focus: All experiments use Japanese administrative court decisions; effectiveness for other legal systems remains untested

## Confidence
- **High Confidence:** The LKG retrieval system achieves higher recall than baseline RAG and LLM methods (0.667 vs 0.118 micro recall). The graph traversal mechanism is clearly specified and reproducible
- **Medium Confidence:** The edge construction quality depends heavily on GPT-4o's ability to maintain coherence with large context windows. While the "scoped-history" design is validated, exact implementation details are sparse
- **Low Confidence:** The system's performance on novel legal scenarios with no similar neighbors in the graph is untested. The paper doesn't address what happens when a query fact has zero semantically similar matches

## Next Checks
1. **Ontology Boundary Testing:** Manually annotate 20 randomly selected sentences from the corpus to verify if the distinction between "Legal Norm" and "Legal Application" is consistently meaningful in Japanese administrative court language
2. **Context Length Stress Test:** Systematically vary the number of preceding nodes provided in the scoped-history prompt (e.g., 5, 10, 20, 30 nodes) and measure the degradation in edge construction accuracy to identify the practical context window limit
3. **Novel Scenario Evaluation:** Create synthetic query facts that represent legal scenarios absent from the 648-judge corpus. Test whether the Fact-Masked retrieval setting can still retrieve relevant provisions by analogy, or if it fails entirely when no similar neighbors exist