---
ver: rpa2
title: Multi-Task Semantic Communications via Large Models
arxiv_id: '2503.22064'
source_url: https://arxiv.org/abs/2503.22064
tags:
- semantic
- data
- encoder
- decoder
- lam-based
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of deploying large AI models
  (LAMs) for multi-task semantic communications (MTSC) in resource-constrained wireless
  networks. The authors propose a LAM-based MTSC architecture that includes adaptive
  model compression, federated split fine-tuning, and retrieval-augmented generation
  (RAG) to enable efficient multi-modal semantic extraction and content generation.
---

# Multi-Task Semantic Communications via Large Models

## Quick Facts
- arXiv ID: 2503.22064
- Source URL: https://arxiv.org/abs/2503.22064
- Reference count: 15
- Primary result: LAM-based MTSC with adaptive compression and federated split fine-tuning achieves BLEU scores up to 70% for VQA and CIDEr scores up to 90% for captioning tasks across varying SNR conditions.

## Executive Summary
This work proposes a LAM-based multi-task semantic communication architecture for resource-constrained wireless networks handling multi-modal data (image, text, audio, video) across VQA, captioning, and image reconstruction tasks. The approach combines modality-specific encoders with pre-trained LAM encoder for semantic fusion, joint source-channel coding with importance-aware variable-rate encoding, and federated split fine-tuning with retrieval-augmented generation. The architecture demonstrates robust performance across varying signal-to-noise ratios while preserving privacy through split architecture design and reducing bandwidth requirements through adaptive compression.

## Method Summary
The proposed LAM-based MTSC architecture employs modality-specific encoders (CNNs for images, Transformers for text/audio) that feed into a pre-trained LAM encoder for unified semantic fusion. A joint source-channel coding (JSC) encoder with importance-aware variable-rate encoding transmits compressed semantics over AWGN channels with Rician fading. At the receiver, JSC decoding and LAM decoding feed into task-specific decoders for multi-task execution. The system uses federated split fine-tuning with LoRA parameters to enable collaborative model refinement while preserving privacy, and RAG for knowledge base updates. Training uses LoRA on BART-base backbone across VQAv2, COCO, Audiocaps, MSRVTT, and CIFAR-10 datasets with BLEU, CIDEr, and PSNR metrics.

## Key Results
- BLEU scores reach up to 70% for VQA tasks across varying SNR conditions
- CIDEr scores reach up to 90% for captioning tasks under channel impairments
- PSNR values of 28-30 dB for image reconstruction tasks demonstrate robust performance
- Outperforms traditional coding + UnIVAL and U-DeepSC baselines especially at low SNR
- Maintains task accuracy while reducing bandwidth requirements through adaptive compression

## Why This Works (Mechanism)

### Mechanism 1: Unified Multi-Modal Semantic Fusion via Pre-Trained LAM Encoder
- Combining modality-specific encoders with pre-trained LAM encoder enables cross-modal semantic alignment that outperforms separate uni-modal processing. Modality encoders extract features → input projections map to common dimension → pre-trained LAM encoder fuses into unified semantic space → JSC coding transmits compressed semantics. The pre-trained representations provide semantic grounding across modalities.
- Core assumption: Pre-trained LAM representations transfer effectively to wireless channel-impacted semantic features without catastrophic degradation.
- Evidence anchors: Architecture employs modality-specific encoders combined with pre-trained LAM encoder for semantic fusion; LaMoSC validates LAM-driven semantic communication but lacks direct multi-modal fusion results.

### Mechanism 2: Importance-Aware Variable-Rate JSC Coding
- Dynamically adjusting encoding rates based on semantic importance and real-time CSI improves robustness under low SNR conditions. Semantic importance matrix computed → binary mask applied to semantic symbols → variable-rate encoding allocates more bits to high-importance semantics → JSC decoder reconstructs with channel-adaptive algorithms. This prioritizes task-critical information over redundant detail.
- Core assumption: Semantic importance can be reliably estimated and remains stable across channel conditions.
- Evidence anchors: Variable-rate JSC encoding method integrates semantic importance and channel conditions; proposed scheme outperforms baselines especially when SNR is low with BLEU scores reaching 70% at low SNR; Visual Fidelity Index paper supports importance-weighted transmission plausibility.

### Mechanism 3: Federated Split Fine-Tuning with Privacy-Preserving Task Decoder Placement
- Splitting the task decoder to client side eliminates transmission of ground-truth labels while enabling collaborative model refinement. Client holds LAM encoder + JSC encoder + task decoder → server holds JSC decoder + LAM decoder → forward pass transmits encoded semantics → server returns intermediate outputs → client computes loss locally → gradients flow back via split architecture → LoRA matrices updated on client, server aggregates only non-private parameters.
- Core assumption: Split point does not create unacceptable communication latency for interactive applications.
- Evidence anchors: Task decoder is split and deployed on client, which eliminates necessity of transmitting ground-truth data labels; federated split fine-tuning approach facilitates efficient deployment while preserving privacy; Semantic-Aware Task Clustering addresses cooperative multi-task SemCom but does not validate split architecture privacy claims directly.

## Foundational Learning

- **Joint Source-Channel Coding (JSCC)**: Why needed here: Architecture replaces separate source/channel coding with learned JSC encoder/decoder pairs that must be understood as end-to-end trainable blocks, not modular components. Quick check question: Can you explain why JSCC outperforms separate coding at low SNR but may underperform at high SNR with abundant bandwidth?

- **Low-Rank Adaptation (LoRA)**: Why needed here: Fine-tuning large models in federated settings requires parameter-efficient methods; LoRA freezes pre-trained weights and trains only low-rank decomposition matrices. Quick check question: If a LoRA module has rank-8 decomposition on a 1024-dimension layer, how many trainable parameters does it add versus full fine-tuning?

- **Retrieval-Augmented Generation (RAG)**: Why needed here: Architecture uses RAG to update knowledge without model retraining; understanding vector database indexing and retrieval relevance scoring is essential for implementation. Quick check question: Why does RAG provide faster knowledge updates than federated fine-tuning, and what is the latency-relevance tradeoff?

## Architecture Onboarding

- **Component map**: Modality encoders → Input projections → Pre-trained LAM encoder → JSC encoder → Wireless channel → JSC decoder → Pre-trained LAM decoder → Task-specific heads (VQA, captioning, reconstruction)
- **Critical path**: Identify target tasks → select/modify task decoder heads → assess client resources → determine compression strategy → initialize from BART-base → deploy split architecture → configure RAG → train via federated split fine-tuning with LoRA on client encoder modules
- **Design tradeoffs**: Compression level vs. semantic fidelity (aggressive pruning reduces bandwidth but may lose fine-grained semantics needed for VQA); Split point depth vs. latency (earlier split reduces client compute but increases uplink semantic payload); RAG retrieval depth vs. inference time (more retrieved context improves accuracy but adds latency)
- **Failure signatures**: Task performance collapses at specific SNR thresholds → check importance-aware encoding configuration; VQA answers become generic/irrelevant → RAG retrieval may be returning stale or irrelevant knowledge chunks; Federated rounds show no improvement → verify LoRA gradients are flowing correctly through split point; High-performing clients degrade after aggregation → check for heterogeneous compression scheme conflicts
- **First 3 experiments**: Single-task baseline validation with VQA only and fixed compression on AWGN channel at SNR = 0, 6, 10 dB; Ablation of semantic importance weighting by disabling importance-aware rate adaptation and measuring performance gap at low SNR (-2 to 2 dB); Split point sensitivity analysis by moving task decoder from client to server and measuring latency vs. accuracy tradeoff on captioning task

## Open Questions the Paper Calls Out

- **Unified Mathematical Theory for Semantic Information**: There is still a lack of semantic information theory, especially in mathematical expression of semantics and limit bounds of semantic compression. The authors call for unified mathematical form to achieve accurate representation and quantitative evaluation of semantics for multi-modal data. Why unresolved: Current semantic communications rely on empirical deep learning approaches without theoretical foundations comparable to Shannon's information theory for bit-oriented communications.

- **Metrics for Balancing Creativity with Semantic Accuracy**: Although large models can output high-quality contents, existing models may generate creative yet semantically incorrect or misleading content. The authors call for new metrics or methods that can guide these large models to create highly relevant and semantically accurate contents. Why unresolved: Current evaluation metrics (BLEU, CIDEr, PSNR) capture surface-level similarity but cannot reliably detect semantic errors or factual inconsistencies in generated content.

## Limitations

- Semantic importance estimation lacks validation across diverse task distributions, creating risk of systematic under-encoding for novel or rare semantic concepts
- Channel-induced semantic degradation may exceed robustness bounds observed in controlled training environments
- Split fine-tuning privacy claims assume server-side aggregation cannot reconstruct private data, but no formal differential privacy analysis is provided

## Confidence

- **High Confidence**: BLEU/CIDEr/PSNR improvement over traditional coding baselines (mechanistically straightforward, well-established metrics)
- **Medium Confidence**: Multi-modal semantic fusion benefits (requires empirical validation of cross-modal alignment quality)
- **Medium Confidence**: Federated split fine-tuning privacy preservation (depends on implementation details not fully specified)
- **Low Confidence**: Variable-rate JSC coding robustness under extreme channel conditions (limited SNR range validation)

## Next Checks

1. **Channel Robustness Boundary**: Test semantic fusion performance under SNR < -6 dB and Rician K-factor < 1 to identify breaking points where proposed scheme degrades faster than baselines
2. **Cross-Domain Generalization**: Evaluate multi-task performance on out-of-distribution data (medical images for VQA, non-COCO captioning datasets) to verify semantic importance estimation generalizes beyond training distribution
3. **Privacy Threat Modeling**: Implement membership inference attacks on server-aggregated parameters to quantify actual privacy leakage versus theoretical claims of label-free fine-tuning