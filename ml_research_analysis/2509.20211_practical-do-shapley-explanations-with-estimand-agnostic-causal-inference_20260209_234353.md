---
ver: rpa2
title: Practical do-Shapley Explanations with Estimand-Agnostic Causal Inference
arxiv_id: '2509.20211'
source_url: https://arxiv.org/abs/2509.20211
tags:
- causal
- which
- do-shap
- graph
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes practical estimation of do-Shapley values (do-SVs)
  for interpretable feature attributions in causal models. The key contribution is
  using estimand-agnostic causal inference, allowing a single trained SCM to estimate
  any identifiable causal query without deriving query-specific formulas.
---

# Practical do-Shapley Explanations with Estimand-Agnostic Causal Inference

## Quick Facts
- **arXiv ID:** 2509.20211
- **Source URL:** https://arxiv.org/abs/2509.20211
- **Authors:** Ãlvaro Parafita; Tomas Garriga; Axel Brando; Francisco J. Cazorla
- **Reference count:** 40
- **Primary result:** Proposes practical estimation of do-Shapley values using estimand-agnostic causal inference with significant computation acceleration via the Frontier-Reducibility Algorithm.

## Executive Summary
This work introduces a practical method for computing do-Shapley values (do-SVs) for interpretable feature attributions in causal models. The key innovation is leveraging estimand-agnostic causal inference, which allows a single trained Structural Causal Model (SCM) to estimate any identifiable causal query without deriving query-specific formulas. This approach makes do-SHAP feasible for complex graphs. A novel Frontier-Reducibility Algorithm (FRA) significantly accelerates computation by identifying and skipping reducible coalitions. Experiments demonstrate accurate do-SV estimation across multiple SCM architectures and substantial speedups with FRA, validated on real-world datasets.

## Method Summary
The method trains a proxy SCM (Deep Causal Graphs or Normalizing Flows) to approximate the observational distribution $P(V)$. For any coalition $S$, the do-interventional query $E[Y|do(S=s)]$ is estimated by mutilating the graph (removing incoming edges to intervened nodes) and sampling from the SCM. Shapley values are computed by averaging marginal contributions over random permutations of features. The FRA identifies "frontier" subsets that block all paths from a feature to the target, allowing the system to skip redundant coalition evaluations by caching and reusing results for irreducible subsets.

## Key Results
- Estimand-agnostic approaches enable a single SCM to estimate any identifiable causal query without deriving specific formulas for each query.
- The Frontier-Reducibility Algorithm (FRA) significantly accelerates Shapley value computation by skipping reducible coalitions with negligible cost.
- Experiments demonstrate accurate do-SV estimation across multiple SCM architectures (Linear, DCG, CNF) and substantial speedups with FRA.
- Real-world validation on Diabetes and Bike Rental datasets highlights do-SHAP's explanatory power over non-causal alternatives like marginal and conditional SHAP.

## Why This Works (Mechanism)

### Mechanism 1: Single-Model Interventional Query Estimation
Traditional estimand-based methods require deriving unique mathematical formulas for every coalition $S$ to estimate $\nu(S) = E[Y|do(S=s)]$. The EA approach circumvents this by training a proxy SCM to approximate the observational distribution $P(V)$. Because the query is identifiable in graph $G$, intervening on this proxy model and sampling yields the correct causal effect. This works if the proxy SCM has sufficient capacity to model $P(V)$ accurately and the causal queries are identifiable in $G$.

### Mechanism 2: Topological Frontiers for Coalition Reduction
FRA identifies "frontier" subsets that block all directed paths from a node $X$ to the target $Y$. If $S$ is a frontier, then $\nu(S \cup \{X\}) = \nu(S)$. By mapping any coalition to its irreducible subset and caching the result, the system avoids redundant Monte Carlo simulations for coalitions that are causally equivalent. This is effective when the graph is a DAG with a topological order and the target $Y$ has ancestors that are not direct parents.

### Mechanism 3: Attribution of Exogenous Noise
To explain a specific realization $y$ (not just population $E[Y|do(X=x)]$), the paper treats the exogenous noise $E_Y$ as a player. If $Y$ follows an additive noise model, the noise contribution $\phi_{E_Y}$ is simply $y - E[Y|pa_Y]$. This allows attribution to the noise variable under the assumptions that $Y$ has no latent confounders and follows an additive noise model.

## Foundational Learning

**Concept: Structural Causal Models (SCMs) & Interventions**
*Why needed:* The core shift is from training ML models on correlations to training SCMs that support *do*-interventions ($do(X=x)$). Without understanding how an intervention "mutilates" the graph (removes incoming edges), the EA approach cannot be implemented.
*Quick check:* In the Salary example ($A \to E \to S \to Y$), if we intervene on Education ($do(E=e)$), do we sever the edge from Age to Education?

**Concept: Shapley Value Efficiency**
*Why needed:* The method relies on the property that Shapley values sum to the total contribution (Efficiency). Understanding that we are averaging marginal contributions over all permutations is necessary to see why caching specific coalition values works.
*Quick check:* If Player A contributes 0 to every coalition, what is their Shapley value?

**Concept: Identifiability**
*Why needed:* The entire EA framework collapses if the causal query cannot be answered from observational data alone (non-identifiability). Users must grasp that identifiability depends on the graph structure, not just the data volume.
*Quick check:* Does the presence of a latent confounder between Treatment and Outcome always render the causal effect non-identifiable?

## Architecture Onboarding

**Component map:**
SCM (DCG/CNF) -> FRA Cache -> $\nu$ Cache -> Shapley Values

**Critical path:**
1. Define causal graph $G$ and topological order
2. Train proxy SCM (DCG/CNF) to maximize likelihood of $P(V)$
3. Sample random ordering of features
4. Use FRA to find irreducible subset for coalition
5. If uncached, perform $do$-intervention on SCM and sample to estimate $\nu(S)$
6. Aggregate into Shapley values based on differential $\nu(S \cup X) - \nu(S)$

**Design tradeoffs:**
- **Architecture Choice:** DCG admits latent confounders but CNF may have better variance stability. Choose DCG if latent variables are assumed; CNF for Markovian cases.
- **Approximation:** Exact Shapley is $O(K!)$. The system uses Monte Carlo approximation; the tradeoff is between number of permutations and estimation variance.

**Failure signatures:**
- **Stagnant FRA:** If speedup is negligible, check if $P a_Y \approx X$ (all ancestors are parents), which renders FRA useless.
- **High Estimation Loss:** If SHAP estimation loss is high despite high test log-likelihood, the SCM architecture likely lacks capacity to model specific structural equations.

**First 3 experiments:**
1. **Synthetic Validation:** Train Linear/DGC/CNF models on a synthetic DGP to compare estimated do-SVs against ground truth do-SVs.
2. **FRA Ablation:** Run do-SHAP on random graphs $G_{K,p}$ with and without FRA cache to measure skipped coalitions and wall-clock time reduction.
3. **Real-world Explainability:** Train DCG on Diabetes dataset. Compare "do-Shapley" explanation against "Marginal SHAP" to highlight difference between causal and associational attributions.

## Open Questions the Paper Calls Out

**Open Question 1:** Is there a general graphical criterion to determine the non-parametric identifiability of do-Shapley values without checking every coalition?
*Status:* Left for future work. Currently, identifiability must be verified for each of the $2^{|X|}$ possible coalitions individually.

**Open Question 2:** Can a counterfactual value function be developed to close the explanation gap inherent in interventional do-Shapley values?
*Status:* Identified as promising avenue of research. Current do-SVs aggregate to $E[Y|do(X)]$, creating a gap between sum of attributions and specific observed outcome $y$.

**Open Question 3:** Can estimand-agnostic causal inference methods be equipped with doubly-robust guarantees against model misspecification?
*Status:* Stated as disadvantage compared to some estimand-based alternatives. Current proxy SCM approach relies on single model fitting distribution perfectly.

## Limitations
- FRA effectiveness is highly dependent on graph structure; provides no speedup when all ancestors are direct parents of target
- The framework assumes causal queries are identifiable, but does not provide methods to verify identifiability in practice
- Noise attribution method relies on strong assumptions (additive noise model, no latent confounders) that may not hold in real-world scenarios

## Confidence

**High Confidence:** Core mechanism of using estimand-agnostic causal inference to train single SCM for any identifiable query is well-supported by literature on meta-prediction and Black Box Causal Inference.

**Medium Confidence:** FRA algorithm is theoretically sound but practical speedup is heavily dependent on graph structure, which is not always predictable.

**Medium Confidence:** DCG/CNF architectures' ability to model complex DGPs is supported by related work, but specific configurations are not fully explored or justified for all data types.

## Next Checks
1. **Graph Structure Sensitivity:** Conduct systematic study on FRA's effectiveness across range of synthetic graphs (varying densities and depths) to quantify expected speedup for different topologies.

2. **Non-linear DGP Robustness:** Replace linear Gaussian DGP in synthetic experiments with non-linear DGP (sigmoid or polynomial structural equations) to test SCM's ability to model complex relationships and impact on do-SHAP estimation accuracy.

3. **Identifiability Verification:** Develop method or set of tests to verify identifiability of causal query in given graph G. Apply to real-world datasets to ensure used queries are truly identifiable, and document any cases where they are not.