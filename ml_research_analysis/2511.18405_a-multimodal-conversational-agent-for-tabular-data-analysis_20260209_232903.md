---
ver: rpa2
title: A Multimodal Conversational Agent for Tabular Data Analysis
arxiv_id: '2511.18405'
source_url: https://arxiv.org/abs/2511.18405
tags:
- code
- data
- execution
- design
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Talk2Data is a multimodal conversational agent for tabular data
  analysis that enables users to query datasets via voice or text and receive multimodal
  responses (plots, tables, statistics, or spoken explanations). Built on an LLM orchestration
  loop with OpenAI Whisper (ASR), Qwen-coder (code generation), a sandboxed execution
  environment, and Coqui TTS, the system supports multi-turn dialogues grounded in
  dataset context.
---

# A Multimodal Conversational Agent for Tabular Data Analysis

## Quick Facts
- arXiv ID: 2511.18405
- Source URL: https://arxiv.org/abs/2511.18405
- Reference count: 34
- Primary result: Achieved 95.8% accuracy on 48 multimodal data analysis tasks with sub-1.7s latency using a 7B LLM

## Executive Summary
Talk2Data is a multimodal conversational agent that enables users to interact with tabular datasets through voice or text, receiving responses in the form of plots, tables, statistics, or spoken explanations. The system employs an LLM orchestration loop that processes user queries, generates and executes Python code in a sandboxed environment, and produces multimodal outputs. Evaluated across three public datasets, Talk2Data demonstrated high accuracy while maintaining interactive latency, with a 7B model providing the optimal balance of performance and cost.

## Method Summary
The system integrates speech recognition via OpenAI Whisper, LLM-based query understanding and code generation using Qwen-coder, and a sandboxed execution environment for safe code evaluation. User queries are processed through a conversation loop that maintains context from prior interactions, generates appropriate Python code for data analysis, executes this code securely, and produces multimodal responses through plotting libraries and text-to-speech synthesis using Coqui TTS. The architecture supports both voice and text input modalities while maintaining a consistent analytical workflow.

## Key Results
- Achieved 95.8% accuracy across 48 evaluation tasks on three public datasets
- Model-only latency remained under 1.7 seconds for the 7B configuration
- 7B model provided optimal accuracy-latency-cost trade-off for interactive use
- Voice-based task completion averaged 1.77 seconds including ASR time

## Why This Works (Mechanism)
The system's effectiveness stems from its multimodal orchestration approach that combines natural language understanding with executable code generation. By maintaining conversation context and grounding responses in actual dataset content, the agent can handle complex analytical queries while providing transparent, verifiable results through visible code execution. The sandboxed environment ensures safety while enabling sophisticated data analysis operations.

## Foundational Learning
- LLM Orchestration Loop: Why needed - Coordinates multiple AI components for coherent task completion; Quick check - Verify consistent context tracking across multi-turn conversations
- Sandboxed Code Execution: Why needed - Enables safe evaluation of user-generated code; Quick check - Confirm no system access or malicious operations succeed
- Multimodal Response Generation: Why needed - Provides accessible results through multiple formats; Quick check - Test all output modes (plots, tables, speech) function correctly
- Context Management: Why needed - Maintains conversation state for coherent interactions; Quick check - Ensure relevant history is preserved across queries
- ASR/TTS Integration: Why needed - Enables natural voice-based interaction; Quick check - Verify speech input/output quality and accuracy

## Architecture Onboarding
Component Map: Whisper (ASR) -> LLM Orchestrator -> Qwen-coder (Code Gen) -> Sandboxed Executor -> Response Generator -> Coqui TTS (TTS)

Critical Path: User input → ASR (voice only) → Context augmentation → Code generation → Sandboxed execution → Result processing → Multimodal output

Design Tradeoffs: Balanced LLM size (7B) for optimal accuracy-latency-cost; Simplified history management (last-N) for performance; Transparent code generation for user trust

Failure Signatures: ASR errors cause query misinterpretation; Code generation failures from ambiguous queries; Execution errors from malformed or invalid code; Context loss in long conversations

First Experiments:
1. Test basic data query accuracy with simple table operations
2. Validate voice input recognition and response generation
3. Measure end-to-end latency for multimodal responses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the agent maintain high accuracy on noisy, hierarchical, or time-series data without extensive prompt engineering?
- Basis in paper: [explicit] Section VIII.A calls for extending capability "beyond clean tabular data to time series, relational joins, and schema mismatch."
- Why unresolved: The current evaluation relied on three clean, structured datasets, leaving performance on complex data structures unknown.
- What evidence would resolve it: Benchmark results on noisy or hierarchical datasets showing comparable accuracy to the current 95.8% baseline.

### Open Question 2
- Question: Does semantic compression or retrieval-augmented memory outperform simple last-N history in long analytical sessions?
- Basis in paper: [explicit] Section VIII.A proposes to "Replace last-N history with episodic summaries and retrieval-augmented prompting."
- Why unresolved: The current prototype uses a lightweight memory buffer which may induce hallucinations or lose context over long interactions.
- What evidence would resolve it: Comparative studies measuring context retention and accuracy in dialogues exceeding the current token limit.

### Open Question 3
- Question: To what extent does code transparency influence trust and cognitive load for non-technical users compared to results-only interfaces?
- Basis in paper: [explicit] Section VIII.A lists "Run controlled studies with non-technical users to measure task time, trust, and cognitive load."
- Why unresolved: The current study evaluated task correctness manually but did not assess the human user's psychological response to the system.
- What evidence would resolve it: Data from controlled user studies quantifying trust levels and cognitive effort when code is visible versus hidden.

## Limitations
- Evaluation based on 48 synthetic tasks across three public datasets may not reflect real-world complexity
- Latency measurements exclude ASR and code execution time, creating optimistic interactivity estimates
- System performance on ambiguous, incomplete, or context-dependent user requests remains untested

## Confidence
High confidence in system architecture and technical implementation details
Medium confidence in performance claims due to controlled evaluation setting
Low confidence in accessibility and usability benefits without user studies

## Next Checks
1. Conduct user studies with diverse participants performing real-world data analysis tasks to validate usability and accessibility
2. Test system on broader range of datasets including those with missing values and mixed data types
3. Measure complete end-to-end latency including ASR processing and code execution on representative queries