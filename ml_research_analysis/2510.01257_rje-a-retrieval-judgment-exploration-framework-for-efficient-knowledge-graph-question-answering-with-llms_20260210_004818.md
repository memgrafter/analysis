---
ver: rpa2
title: 'RJE: A Retrieval-Judgment-Exploration Framework for Efficient Knowledge Graph
  Question Answering with LLMs'
arxiv_id: '2510.01257'
source_url: https://arxiv.org/abs/2510.01257
tags:
- reasoning
- question
- paths
- exploration
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RJE, a Retrieval-Judgment-Exploration framework
  for knowledge graph question answering (KGQA) using large language models (LLMs).
  RJE addresses the limitations of retrieval-based and agent-based methods by first
  retrieving relevant reasoning paths from a knowledge graph, then using an LLM to
  judge if the evidence is sufficient to answer the question, and finally exploring
  additional evidence only when needed.
---

# RJE: A Retrieval-Judgment-Exploration Framework for Efficient Knowledge Graph Question Answering with LLMs

## Quick Facts
- arXiv ID: 2510.01257
- Source URL: https://arxiv.org/abs/2510.01257
- Authors: Can Lin; Zhengwang Jiang; Ling Zheng; Qi Zhao; Yuhang Zhang; Qi Song; Wangqiu Zhou
- Reference count: 40
- Primary result: Small open-source LLMs (3B, 8B) achieve competitive KGQA results without fine-tuning using RJE

## Executive Summary
This paper introduces RJE, a Retrieval-Judgment-Exploration framework that addresses the computational inefficiency of agent-based KGQA methods while maintaining accuracy. The framework first retrieves relevant reasoning paths from a knowledge graph, uses an LLM to judge if the evidence is sufficient to answer the question, and conditionally explores additional evidence only when needed. RJE includes three auxiliary modules: Reasoning Path Ranking to prioritize relevant paths, Question Decomposition to break down complex questions, and Retriever-assisted Exploration to focus the search. Experiments demonstrate that RJE outperforms existing baselines on standard KGQA benchmarks while significantly reducing LLM calls and token usage.

## Method Summary
RJE is a three-stage framework for knowledge graph question answering that operates on Freebase. The retrieval stage uses a fine-tuned PLM to retrieve relation paths, which are then ranked by a RoBERTa-based model to select top-K reasoning paths. The judgment stage employs an LLM to evaluate whether these paths contain sufficient evidence to answer the question. If insufficient, the exploration stage is conditionally executed, involving question decomposition to generate sub-questions for each topic entity, followed by retriever-assisted relation exploration (where the retriever pre-filters top-N relevant relations) and entity exploration. The framework is trained with weak supervision using answer labels and inference hyperparameters include K=10 paths, N=30 relations, and temperature=0.3.

## Key Results
- RJE outperforms existing baselines on WebQuestionsSP and Complex WebQuestions benchmarks
- Small-sized open-source LLMs (3B and 8B parameters) achieve competitive results without fine-tuning
- RJE reduces LLM calls and token usage compared to agent-based methods, yielding significant efficiency improvements
- For WebQSP, 77.7% of questions are correctly answered during the judgment stage with a single LLM call

## Why This Works (Mechanism)

### Mechanism 1: Conditional Bypass via Sufficiency Judgment
The LLM evaluates whether retrieved reasoning paths contain sufficient evidence before committing to exploration. If sufficient, the system generates an answer immediately, avoiding iterative KG traversal. This creates a two-path execution: fast-path for answerable questions and full-path for complex multi-hop questions. Core assumption: LLMs can reliably distinguish sufficient from insufficient evidence when presented with structured reasoning paths.

### Mechanism 2: Noise Reduction via Reasoning Path Ranking
A PLM-based ranker scores paths using question-path relevance, retaining only top-K paths. This prevents LLMs from processing noisy or irrelevant paths that could cause hallucinations or misdirected reasoning. The ranker is trained with weak supervision using answer coverage as positive signals. Core assumption: Answer-containing paths are identifiable via semantic similarity between question and path structure.

### Mechanism 3: Search Space Contraction via Retriever-Assisted Exploration
During exploration, instead of presenting all KG relations to the LLM, the retriever pre-filters top-N relevant relations. The LLM then selects from this reduced set. This two-stage filtering (retriever → LLM) prevents small LLMs from being overwhelmed by large relation vocabularies typical in KGs. Core assumption: Relevant relations are recoverable via semantic similarity between sub-questions and relation names.

## Foundational Learning

- Concept: **Knowledge Graph Structure (Entities, Relations, Triples)**
  - Why needed here: RJE operates on KG paths defined as alternating entity-relation sequences; understanding triple structure (subject, predicate, object) is prerequisite for interpreting reasoning paths.
  - Quick check question: Given a triple `(Peyton Manning, parents, Archie Manning)`, which entity is the subject and what relation connects them?

- Concept: **Beam Search for Path Retrieval**
  - Why needed here: The relation path retriever uses beam search to iteratively expand candidate paths based on semantic similarity; understanding search space exploration is essential for tuning retrieval breadth.
  - Quick check question: How does beam search differ from greedy search when expanding relation paths from a topic entity?

- Concept: **Weak Supervision with Answer Labels**
  - Why needed here: The reasoning path ranker is trained without explicit path annotations, using only question-answer pairs; understanding how positive/negative samples are constructed from answer presence is critical for reproducing training.
  - Quick check question: If a reasoning path ends at an answer entity, how is it labeled during ranker training?

## Architecture Onboarding

- Component map: Retrieval Stage (PLM fine-tuned on question-relation pairs → Reasoning Path Ranker (RoBERTa-based, margin ranking loss)) → Judgment Stage (LLM prompted with top-K paths → sufficiency decision) → Exploration Stage (Question Decomposition → Retriever-assisted Relation Exploration → Entity Exploration)
- Critical path: Retrieval → Judgment → (if insufficient) Exploration Loop → Answer Generation. The judgment stage is the branch point controlling whether exploration executes.
- Design tradeoffs:
  - `K` (number of reasoning paths): Too few → insufficient evidence; too many → noise degrades LLM reasoning. Paper suggests K=10 as optimal.
  - `N` (number of filtered relations): Too few → exclude relevant relations; too many → overwhelm small LLMs. Paper suggests N=30.
  - `D_max` (max exploration rounds): Higher values improve complex question accuracy but increase latency. Paper uses 2 for WebQSP, 4 for CWQ.
- Failure signatures:
  - High judgment-stage errors with low exploration correction → sufficiency judgment prompt needs refinement or LLM upgrade
  - Good retrieval coverage but poor ranker performance → ranker training data quality issue (check positive/negative sample balance)
  - Exploration loops hitting `D_max` without answer → retriever filtering too aggressive or exploration entity selection misaligned with question decomposition
- First 3 experiments:
  1. Baseline retrieval test: Run only Retrieval + Judgment stages (skip exploration) on WebQSP; measure accuracy to quantify how many questions are answerable without exploration.
  2. Ranker ablation: Disable the Reasoning Path Ranker, pass all retrieved paths to judgment; compare answer coverage at K=5, 10, 20 to validate noise reduction claims.
  3. Small model scaling test: Deploy RJE with Llama3.2-3B on a held-out subset; compare LLM call counts and token usage against ToG/PoG baselines to verify efficiency gains scale to smaller models.

## Open Questions the Paper Calls Out

### Open Question 1
How can RJE's robustness be improved when the relation path retriever initially returns low-quality or irrelevant reasoning paths? The authors explicitly state in the Limitations section that "noisy triples and outdated information" in KGs can mislead LLMs, even within their framework. This remains unresolved as the paper does not address failure modes where initial retrieval is compromised by noisy data.

### Open Question 2
What is the error propagation and recovery capability of RJE when the Judgment LLM makes an incorrect sufficiency assessment? The framework's conditional exploration is triggered solely by the LLM's judgment. An incorrect judgment (e.g., deeming evidence sufficient when it is not) would prematurely halt exploration, or vice versa, leading to inefficiency or errors. The paper presents ablation studies on removing modules but does not analyze the sensitivity of the final answer to errors specifically from the judgment stage.

### Open Question 3
Can the principles and auxiliary modules of RJE be effectively generalized to cross-lingual KGQA tasks? The authors note in the Limitations section that their experimental evaluation is limited to English datasets and plan to "extend our evaluation to multiple languages." The auxiliary modules are trained or prompted on English data, and their effectiveness on other languages, along with the framework's overall cross-lingual transferability, is unknown.

## Limitations
- RJE's performance heavily depends on the quality of initial retrieval and sufficiency judgment accuracy, which are not directly measured
- The framework's effectiveness on languages other than English remains untested
- Error propagation from the judgment stage is not analyzed, leaving uncertainty about how incorrect sufficiency assessments affect final accuracy

## Confidence

**High Confidence**: RJE reduces computational overhead compared to agent-based methods (supported by concrete LLM call and token usage reductions)

**Medium Confidence**: Small LLMs achieve competitive results with RJE (performance gains are substantial but rely on retriever quality)

**Low Confidence**: Sufficiency judgment reliably distinguishes answerable questions (accuracy not directly measured, only end-to-end performance reported)

## Next Checks

1. Measure sufficiency judgment accuracy on a validation set by comparing LLM sufficiency decisions against human annotations
2. Conduct ranker ablation with varying K values (5, 10, 20) to quantify noise reduction impact on answer coverage
3. Test RJE with retrievers of different quality levels to establish the framework's robustness to retrieval errors