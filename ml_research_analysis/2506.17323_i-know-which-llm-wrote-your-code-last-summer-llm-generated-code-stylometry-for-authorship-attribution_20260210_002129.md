---
ver: rpa2
title: 'I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry
  for Authorship Attribution'
arxiv_id: '2506.17323'
source_url: https://arxiv.org/abs/2506.17323
tags:
- code
- attribution
- authorship
- token
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first systematic study of LLM authorship
  attribution for C code, addressing the challenge of identifying which model generated
  a given program. The authors propose CodeT5-Authorship, a custom encoder-only model
  derived from CodeT5, optimized for authorship classification using a two-layer classification
  head.
---

# I Know Which LLM Wrote Your Code Last Summer: LLM generated Code Stylometry for Authorship Attribution

## Quick Facts
- arXiv ID: 2506.17323
- Source URL: https://arxiv.org/abs/2506.17323
- Reference count: 40
- Introduces first systematic study of LLM authorship attribution for C code

## Executive Summary
This paper presents the first systematic study of LLM authorship attribution for C code, introducing CodeT5-Authorship, a custom encoder-only model derived from CodeT5, and LLM-AuthorBench, a dataset of 32,000 compilable C programs from eight state-of-the-art LLMs. Evaluations demonstrate high accuracy in both binary and multi-class classification, with CodeT5-Authorship achieving 97.56% accuracy in distinguishing closely related models like GPT-4.1 vs. GPT-4o, and 95.40% accuracy in multi-class attribution across five leading models. The approach outperforms traditional ML methods and off-the-shelf transformer models, showing that stylistic fingerprints persist across LLM families and can be reliably detected.

## Method Summary
The authors propose CodeT5-Authorship, a custom encoder-only model optimized for authorship classification using a two-layer classification head. They also introduce LLM-AuthorBench, a dataset of 32,000 compilable C programs generated from eight state-of-the-art LLMs. The model is trained and evaluated on this dataset, demonstrating superior performance in both binary and multi-class classification tasks, with ablation studies and error analysis confirming the robustness of the approach.

## Key Results
- CodeT5-Authorship achieves 97.56% accuracy in binary classification (distinguishing closely related models like GPT-4.1 vs. GPT-4o)
- Multi-class attribution accuracy reaches 95.40% across five leading models
- Outperforms traditional ML methods and off-the-shelf transformer models

## Why This Works (Mechanism)
The approach works by leveraging the unique stylistic fingerprints present in code generated by different LLMs, which persist even across model families. The CodeT5-Authorship model, derived from CodeT5, is specifically optimized for authorship classification using a two-layer classification head, enabling it to capture these subtle stylistic differences. The LLM-AuthorBench dataset provides a large, diverse, and compilable set of C programs generated from multiple state-of-the-art LLMs, ensuring robust training and evaluation.

## Foundational Learning
- **CodeT5**: A transformer-based encoder-decoder model for code understanding and generation. Why needed: Provides a strong base architecture for code-related tasks. Quick check: Can the model handle variable-length code inputs?
- **Encoder-only architecture**: A transformer variant that only encodes input, without decoding. Why needed: Efficient for classification tasks where only input representation is required. Quick check: Does the model maintain context across the entire code input?
- **Two-layer classification head**: A custom classification layer added to the encoder output. Why needed: Enables fine-tuning for specific authorship attribution tasks. Quick check: Does the classification head improve accuracy over the base model?

## Architecture Onboarding
**Component Map**: CodeT5 (encoder) -> Two-layer classification head -> Authorship attribution
**Critical Path**: Input C code -> CodeT5 encoder -> Classification head -> Model prediction
**Design Tradeoffs**: Uses an encoder-only model for efficiency, but this may limit some expressive power compared to encoder-decoder models. The two-layer classification head adds specificity but may overfit to the training dataset.
**Failure Signatures**: Low accuracy in binary classification could indicate insufficient stylistic differentiation between models or overfitting to the training data. High variance in multi-class attribution might suggest ambiguity in model fingerprints.
**First Experiments**:
1. Evaluate binary classification accuracy between closely related models (e.g., GPT-4.1 vs. GPT-4o).
2. Test multi-class attribution across five leading models.
3. Compare performance against traditional ML baselines and off-the-shelf transformer models.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to C code, raising questions about generalizability to other languages or domains
- Dataset generated under controlled conditions, so real-world contamination scenarios are untested
- Does not address potential confounds from code length, syntactic complexity, or prompt engineering effects
- Precision in distinguishing fine-grained model versions or variants remains underexplored

## Confidence
- **High confidence**: Binary classification accuracy (97.56%) between closely related models; superiority over traditional ML and generic transformer baselines; stability across syntactic variations
- **Medium confidence**: Multi-class attribution performance (95.40%) and cross-model generalization; robustness to minor code edits
- **Low confidence**: Generalization to other languages, real-world contamination scenarios, adversarial robustness, and sensitivity to prompt or length variations

## Next Checks
1. Test cross-language transferability by retraining and evaluating on code in Python, Java, and JavaScript using the same model architecture.
2. Introduce adversarial attacks or style obfuscation techniques (e.g., paraphrasing, variable renaming, structural shuffling) to assess model robustness.
3. Conduct ablation studies on code length, syntactic complexity, and prompt phrasing to quantify their impact on attribution accuracy.