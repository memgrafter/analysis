---
ver: rpa2
title: Evaluating Retrieval-Augmented Generation Strategies for Large Language Models
  in Travel Mode Choice Prediction
arxiv_id: '2508.17527'
source_url: https://arxiv.org/abs/2508.17527
tags:
- travel
- retrieval
- mode
- choice
- trip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates the application of large language models\
  \ (LLMs) with retrieval-augmented generation (RAG) for travel mode choice prediction.\
  \ It compares four RAG strategies\u2014basic RAG, balanced retrieval, cross-encoder\
  \ re-ranking, and their combination\u2014across three LLM architectures (GPT-4o,\
  \ o4-mini, o3) using 2023 Puget Sound travel survey data."
---

# Evaluating Retrieval-Augmented Generation Strategies for Large Language Models in Travel Mode Choice Prediction

## Quick Facts
- arXiv ID: 2508.17527
- Source URL: https://arxiv.org/abs/2508.17527
- Authors: Yiming Xu; Junfeng Jiao
- Reference count: 9
- Primary result: GPT-4o with combined balanced retrieval and cross-encoder re-ranking achieved 80.8% accuracy, outperforming traditional statistical and ML baselines for travel mode choice prediction

## Executive Summary
This study evaluates retrieval-augmented generation (RAG) strategies for improving large language model (LLM) performance in travel mode choice prediction. Four RAG strategies—basic RAG, balanced retrieval, cross-encoder re-ranking, and their combination—were tested across three LLM architectures (GPT-4o, o4-mini, o3) using 2023 Puget Sound travel survey data. The research demonstrates that RAG significantly enhances LLM predictive accuracy, with the most advanced combination strategy achieving 80.8% accuracy, surpassing traditional baseline methods.

The findings reveal that RAG effectiveness varies substantially by model capability, with advanced models like o3 showing strong zero-shot performance but experiencing slight accuracy reductions with basic RAG strategies. This suggests that sophisticated LLM architectures require highly optimized retrieval approaches and that alignment between retrieval strategy and model capability is crucial for optimal performance in travel mode prediction tasks.

## Method Summary
The study evaluated four RAG strategies—basic RAG, balanced retrieval, cross-encoder re-ranking, and their combination—across three LLM architectures (GPT-4o, o4-mini, o3) using 2023 Puget Sound travel survey data. The researchers compared these approaches against traditional statistical and machine learning baselines, measuring predictive accuracy for travel mode choice prediction. The cross-encoder re-ranking component was used to refine retrieval results, while balanced retrieval aimed to optimize the trade-off between precision and recall in the retrieved information.

## Key Results
- GPT-4o with combined balanced retrieval and cross-encoder re-ranking achieved the highest accuracy of 80.8%
- RAG strategies significantly improved LLM predictive accuracy across all model architectures
- o3 demonstrated strong zero-shot performance at 78.3% accuracy, though basic and balanced RAG slightly reduced its accuracy
- Retrieval strategy effectiveness varied substantially depending on the underlying LLM's capability

## Why This Works (Mechanism)
The effectiveness of RAG strategies in travel mode choice prediction stems from their ability to provide LLMs with contextually relevant historical data during inference. By retrieving past travel patterns and contextual information, RAG reduces the model's reliance on parametric knowledge and enhances its ability to make accurate predictions based on current travel conditions and individual characteristics. The cross-encoder re-ranking component specifically improves precision by learning to distinguish between highly relevant and less relevant retrieved documents, while balanced retrieval optimizes the trade-off between retrieving comprehensive information and maintaining high precision.

## Foundational Learning
**Travel Mode Choice Prediction**: Understanding how individuals select transportation modes (car, transit, walking, cycling) based on various factors including trip purpose, demographics, and infrastructure availability. Why needed: This is the core prediction task that the RAG-enhanced LLMs are solving. Quick check: Can identify the key factors influencing travel mode selection in the Puget Sound dataset.

**Retrieval-Augmented Generation (RAG)**: A framework that combines information retrieval with text generation to enhance model performance on knowledge-intensive tasks. Why needed: Forms the fundamental approach being evaluated for improving LLM predictions. Quick check: Can explain how retrieved documents augment the generation process in the context of travel prediction.

**Cross-Encoder Re-ranking**: A model architecture that jointly processes query and document pairs to score relevance, typically using transformer-based architectures. Why needed: Critical component for improving retrieval precision in the most successful RAG strategy. Quick check: Can describe how cross-encoders differ from bi-encoder architectures in information retrieval.

**Zero-shot Learning**: The ability of models to perform tasks without specific training on that task, relying solely on pre-existing knowledge. Why needed: Important benchmark for evaluating o3's baseline performance before RAG enhancement. Quick check: Can compare zero-shot accuracy (78.3%) with RAG-enhanced performance.

**Balanced Retrieval**: A strategy that optimizes the trade-off between precision and recall in information retrieval systems. Why needed: One of the key RAG strategies evaluated, particularly important for avoiding information overload. Quick check: Can explain how balanced retrieval differs from basic RAG in terms of precision-recall trade-off.

## Architecture Onboarding

**Component Map**: Survey Data -> Feature Extraction -> Retrieval Module -> LLM (GPT-4o/o4-mini/o3) -> Cross-Encoder Re-ranking -> Mode Choice Prediction

**Critical Path**: Travel survey features → Retrieval system → LLM input → Generation → Mode prediction. The retrieval system and cross-encoder re-ranking are the most critical components for accuracy improvement.

**Design Tradeoffs**: The study balances retrieval comprehensiveness against computational efficiency, with more sophisticated strategies (cross-encoder re-ranking) providing accuracy gains but potentially increasing latency and computational costs. Basic RAG offers simplicity but may underutilize advanced model capabilities.

**Failure Signatures**: When retrieval quality is poor, LLMs revert to less accurate parametric knowledge. For advanced models like o3, overly aggressive retrieval strategies may introduce noise that reduces accuracy below zero-shot performance levels.

**3 First Experiments**:
1. Test basic RAG on a held-out validation set to establish baseline performance before adding retrieval enhancements
2. Evaluate cross-encoder re-ranking independently by comparing its output against original retrieval results
3. Conduct ablation study removing the balanced retrieval component to measure its specific contribution to accuracy gains

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Analysis based on single 2023 Puget Sound travel survey dataset, limiting generalizability to other regions
- Traditional baseline methods lack detailed specification, making comprehensive performance comparison difficult
- Computational costs and latency implications of different RAG strategies were not evaluated
- Potential biases in travel survey data and fairness implications across demographic groups were not addressed

## Confidence

High confidence:
- GPT-4o with combined balanced retrieval and cross-encoder re-ranking achieving 80.8% accuracy

Medium confidence:
- RAG significantly improving LLM predictive accuracy across all tested architectures

Low confidence:
- Generalizability of findings about which RAG strategies work best for different LLM architectures

## Next Checks

1. Test the RAG strategies across multiple diverse travel datasets from different geographic regions and travel contexts to assess generalizability of the findings.

2. Conduct ablation studies on the cross-encoder re-ranking component to determine its specific contribution to accuracy improvements and whether simpler alternatives could achieve similar results.

3. Perform a comprehensive cost-benefit analysis comparing computational resources, latency, and accuracy across all RAG strategies and baseline methods to evaluate real-world deployment feasibility.