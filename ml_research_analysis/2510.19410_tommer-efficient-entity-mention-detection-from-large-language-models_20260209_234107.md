---
ver: rpa2
title: ToMMeR -- Efficient Entity Mention Detection from Large Language Models
arxiv_id: '2510.19410'
source_url: https://arxiv.org/abs/2510.19410
tags:
- entity
- tommer
- mention
- detection
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ToMMeR is a lightweight probing architecture that efficiently extracts
  mention detection capabilities from early layers of large language models, requiring
  fewer than 300K parameters and no schema input, prompting, or text generation. Trained
  solely on span boundaries from LLM-labeled data, ToMMeR achieves 93% recall and
  92% precision across 13 diverse NER benchmarks, validated by an LLM-as-judge approach.
---

# ToMMeR -- Efficient Entity Mention Detection from Large Language Models
## Quick Facts
- **arXiv ID**: 2510.19410
- **Source URL**: https://arxiv.org/abs/2510.19410
- **Reference count**: 39
- **Primary result**: 93% recall and 92% precision across 13 NER benchmarks with sub-300K parameters

## Executive Summary
ToMMeR introduces a lightweight probing architecture that extracts mention detection capabilities from early layers of large language models without requiring schema input, prompting, or text generation. The system achieves state-of-the-art efficiency with fewer than 300K parameters while maintaining high performance across diverse NER benchmarks. By leveraging LLM-labeled training data focused solely on span boundaries, ToMMeR demonstrates that mention detection emerges naturally from language modeling rather than being dataset-specific.

## Method Summary
ToMMeR operates by probing early layers of frozen LLMs to detect entity mentions through a lightweight architecture that requires no schema input, prompting, or text generation. The system is trained exclusively on span boundary annotations derived from LLM-labeled data, eliminating the need for expensive human annotation. A critical innovation is the use of LLM-as-judge validation, which provides a consistent evaluation framework across diverse benchmarks. The architecture achieves remarkable efficiency by maintaining sub-300K parameters while extracting meaningful mention detection capabilities from the underlying LLM representations.

## Key Results
- Achieves 93% recall and 92% precision across 13 diverse NER benchmarks
- Demonstrates strong cross-model agreement (DICE >75%) across LLM architectures ranging from 14M to 15B parameters
- Extends to full NER with competitive performance (80-87% F1) when combined with span classification heads
- Requires only 0.05% of LLaMA's parameters while maintaining high accuracy

## Why This Works (Mechanism)
ToMMeR leverages the inherent mention detection capabilities that emerge from the self-supervised training of large language models. The architecture exploits the fact that early transformer layers naturally encode syntactic and semantic boundaries that align with entity mentions. By probing these layers with a lightweight classifier trained on LLM-labeled span boundaries, ToMMeR extracts this emergent capability without requiring task-specific fine-tuning or complex prompting strategies. The efficiency stems from focusing only on boundary detection rather than full sequence labeling, reducing the learning task to a simpler binary classification problem.

## Foundational Learning
- **Language Model Pre-training**: Understanding how LLMs learn hierarchical representations of language; needed to explain why early layers contain mention boundary information; quick check: examine attention patterns in early layers for boundary detection
- **Probe Architecture Design**: Knowledge of linear classifiers and lightweight neural architectures; needed to understand efficiency gains; quick check: compare parameter counts between probe and base LLM
- **Evaluation Methodology**: Familiarity with LLM-as-judge approaches; needed to assess validation reliability; quick check: compare judge consistency across different evaluation samples
- **Cross-Model Agreement Metrics**: Understanding DICE coefficient and agreement measures; needed to interpret cross-architecture consistency; quick check: calculate agreement scores between different LLM pairs

## Architecture Onboarding
**Component Map**: Input Text -> Early LLM Layers -> Linear Probe -> Span Boundaries
**Critical Path**: Text input flows through frozen early LLM layers, whose representations feed into a linear probe that outputs mention boundary predictions
**Design Tradeoffs**: Sacrifices full NER capability for efficiency by focusing only on mention boundaries rather than complete entity classification; gains massive parameter efficiency but requires additional components for complete NER tasks
**Failure Signatures**: Poor performance on nested entities, potential bias propagation from LLM-labeled training data, reduced effectiveness on languages beyond English
**First 3 Experiments**:
1. Evaluate cross-model agreement by running ToMMeR across different LLM architectures on the same benchmark
2. Test mention detection performance on nested entity scenarios to identify architectural limitations
3. Compare efficiency metrics (parameters, inference time) against traditional NER models on identical hardware

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Narrow focus on mention boundary detection without addressing nested entities limits real-world applicability
- Reliance on LLM-labeled training data raises concerns about bias propagation into the probe's predictions
- Evaluation primarily focuses on English-language benchmarks with limited cross-lingual performance exploration

## Confidence
- **Cross-model agreement claim**: High confidence due to strong DICE >75% results across diverse architectures
- **Efficiency claims**: High confidence supported by clear parameter count comparisons (0.05% of LLaMA)
- **Generalizability beyond tested architectures**: Medium confidence due to limited architectural diversity in evaluation
- **LLM-as-judge validation reliability**: Medium confidence, though potential judge bias wasn't fully explored
- **Full NER extension performance**: Medium confidence with 80-87% F1 scores requiring additional components

## Next Checks
1. Evaluate ToMMeR's performance on nested entity recognition tasks and complex NER scenarios involving discontinuous spans to assess real-world applicability limits.
2. Conduct cross-lingual benchmarking across diverse language families to validate the claim that mention detection capabilities emerge universally from language modeling.
3. Perform ablation studies comparing ToMMeR's performance when trained on human-annotated versus LLM-labeled data to quantify potential bias propagation from the training methodology.