---
ver: rpa2
title: Towards Atoms of Large Language Models
arxiv_id: '2509.20784'
source_url: https://arxiv.org/abs/2509.20784
tags:
- layer
- atoms
- language
- representation
- large
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Atom Theory to formally define, evaluate,
  and identify fundamental representational units (FRUs) of large language models
  (LLMs), termed atoms. The theory is built on the atomic inner product (AIP), a non-Euclidean
  metric that captures the underlying geometry of LLM representations.
---

# Towards Atoms of Large Language Models

## Quick Facts
- arXiv ID: 2509.20784
- Source URL: https://arxiv.org/abs/2509.20784
- Reference count: 40
- Primary result: Introduces Atom Theory to formally define, evaluate, and identify fundamental representational units (atoms) in large language models using atomic inner product metric

## Executive Summary
This paper introduces Atom Theory as a principled framework for understanding fundamental representational units (FRUs) in large language models. The theory is built on atomic inner product (AIP), a non-Euclidean metric that captures the underlying geometry of LLM representations. Atoms are characterized by three properties: representability (measured by faithfulness R²), sparsity, and separability (measured by stability q*). The authors prove that atoms are identifiable under threshold-activated sparse autoencoders (TSAEs) and demonstrate empirically that atoms exhibit substantially higher monosemanticity than neurons or features.

The work addresses a critical gap in interpretability research by providing formal definitions and evaluation metrics for FRUs, rather than relying on ad-hoc methods. Through extensive experiments across multiple models, the authors show that TSAEs can reliably identify atoms with near-perfect faithfulness (R²=99.9%) and stability (q*=99.8%). The paper also uncovers a pervasive representation shift in LLMs and demonstrates that AIP corrects this shift, validating the theoretical framework.

## Method Summary
The authors propose a three-step approach to identify atoms: first, they compute the atomic inner product (AIP) matrix from activation vectors to capture the underlying geometry of LLM representations; second, they apply threshold-activated sparse autoencoders (TSAEs) to the AIP matrix to decompose it into sparse, interpretable components; third, they evaluate the identified components against three criteria - representability (R²), sparsity, and separability (q*) - to determine if they qualify as atoms. The TSAE architecture uses a threshold activation function to enforce sparsity and employs a reconstruction loss based on the AIP metric. The theoretical framework proves that atoms are identifiable under TSAEs when certain conditions are met, providing a foundation for the empirical validation.

## Key Results
- TSAEs achieve near-perfect faithfulness (R²=99.9%) and stability (q*=99.8%) in identifying atoms across multiple models
- Atoms exhibit substantially higher monosemanticity compared to neurons and features
- AIP successfully corrects a pervasive representation shift observed in LLM activations
- Neurons and traditional features fail to meet ideal atom criteria, while TSAE-identified atoms satisfy all three properties

## Why This Works (Mechanism)
The atomic inner product metric captures non-Euclidean relationships in high-dimensional activation spaces that Euclidean metrics miss. This allows TSAEs to decompose the representation into truly fundamental units rather than artifacts of the Euclidean geometry. The threshold activation in TSAEs enforces sparsity while maintaining reconstruction accuracy, enabling the identification of distinct, interpretable components that satisfy all three atom criteria simultaneously.

## Foundational Learning

**Atomic Inner Product (AIP)**: A non-Euclidean metric that measures similarity between activation vectors in a way that captures the true underlying geometry of LLM representations. Why needed: Euclidean metrics fail to account for the complex, non-linear relationships in high-dimensional activation spaces. Quick check: Compute AIP between random activation vectors and compare to cosine similarity.

**Threshold-Activated Sparse Autoencoders (TSAEs)**: Autoencoders with threshold activation functions that enforce sparsity while maintaining reconstruction fidelity. Why needed: Traditional autoencoders produce dense representations that don't align with the sparse, modular nature of neural representations. Quick check: Verify that activation patterns are sparse (e.g., <5% active units) while maintaining low reconstruction error.

**Representability (R²)**: The coefficient of determination measuring how well identified atoms can reconstruct the original representations. Why needed: Without high representability, identified units cannot faithfully capture the information in the original activations. Quick check: Compute R² between original activations and reconstructions from identified atoms.

**Separability (q*)**: A stability metric measuring how consistently atoms can be identified across different samples or random seeds. Why needed: Units that aren't stable across contexts aren't truly fundamental representational elements. Quick check: Compute q* by measuring atom consistency across multiple runs with different random seeds.

## Architecture Onboarding

**Component Map**: Input Activations -> AIP Matrix Computation -> TSAE Encoder -> Sparse Features -> TSAE Decoder -> Reconstruction -> R²/q* Evaluation

**Critical Path**: The pipeline from computing AIP matrix to TSAE decomposition to atom evaluation represents the core workflow for identifying and validating atoms. Each component must function correctly for the final atom identification to be meaningful.

**Design Tradeoffs**: The threshold activation in TSAEs balances sparsity against reconstruction accuracy - higher thresholds produce sparser but less accurate representations. The AIP metric trades computational complexity for geometric fidelity. The evaluation criteria (R², sparsity, q*) must be balanced to identify truly fundamental units rather than artifacts.

**Failure Signatures**: Low R² indicates poor representability; high density in TSAE activations suggests threshold issues; low q* values indicate instability across runs. The representation shift phenomenon manifests as systematic deviations in activation patterns that AIP corrects.

**First Experiments**:
1. Compute AIP matrix for a small transformer layer and visualize its structure compared to cosine similarity
2. Run TSAE with different threshold values on toy data to observe the sparsity-reconstruction tradeoff
3. Measure R² and q* for atoms identified from a single attention head to verify the evaluation pipeline

## Open Questions the Paper Calls Out
None

## Limitations

- AIP metric validation is empirical rather than theoretical, with effectiveness unproven across different architectures or modalities
- Atom identification depends on TSAE-specific hyperparameters and may not generalize to other sparse autoencoder variants
- Monosemanticity claims lack absolute interpretability benchmarks, making practical significance uncertain

## Confidence

- **High Confidence**: TSAEs achieve high faithfulness (R²=99.9%) and stability (q*=99.8%) in identifying atoms across multiple models
- **Medium Confidence**: AIP captures "underlying geometry" of LLM representations, though theoretical guarantees are limited
- **Medium Confidence**: Atoms exhibit substantially higher monosemanticity compared to neurons and features, but absolute standards are lacking

## Next Checks

1. Test AIP and atom identification across different model architectures (transformers, RNNs, CNNs) and modalities (vision, speech) to verify generalizability beyond LLMs.

2. Evaluate the robustness of atom identification to TSAE hyperparameter choices, including different activation thresholds, regularization strengths, and sparse autoencoder architectures.

3. Conduct controlled interpretability studies with human annotators to establish whether identified atoms correspond to coherent semantic concepts and whether their "monosemanticity" translates to practical interpretability gains.