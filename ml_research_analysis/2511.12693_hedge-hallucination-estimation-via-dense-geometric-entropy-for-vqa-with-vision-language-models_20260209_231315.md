---
ver: rpa2
title: 'HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language
  Models'
arxiv_id: '2511.12693'
source_url: https://arxiv.org/abs/2511.12693
tags:
- arxiv
- hallucination
- clustering
- semantic
- radflag
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HEDGE, a hallucination detection framework
  for vision-language models that reframes the problem as one of geometric stability
  under controlled visual perturbations. It combines answer sampling, semantic clustering
  (via entailment-based and embedding-based methods), and uncertainty metrics (SE,
  RadFlag, VASE) to estimate hallucination likelihood without requiring task-specific
  labels.
---

# HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models

## Quick Facts
- arXiv ID: 2511.12693
- Source URL: https://arxiv.org/abs/2511.12693
- Reference count: 40
- Introduces HEDGE: a hallucination detection framework for vision-language models based on geometric stability under controlled visual perturbations

## Executive Summary
This paper reframes hallucination detection in vision-language models as a geometric stability problem, measuring answer consistency under controlled visual perturbations. The HEDGE framework samples perturbed versions of input images, clusters the resulting answers semantically, and computes uncertainty metrics to estimate hallucination likelihood. Unlike prior approaches requiring task-specific labels, HEDGE is domain-agnostic and leverages dense geometric entropy as a universal signal for unreliable outputs.

## Method Summary
HEDGE operates by systematically perturbing input images and observing how VLMs' answers change. The framework samples multiple perturbed versions, clusters answers using either entailment-based or embedding-based semantic clustering, and calculates uncertainty metrics (SE, RadFlag, VASE) to quantify answer stability. Geometric entropy captures the "density" of answer distributions across perturbations, with lower entropy indicating higher hallucination likelihood. The method is designed to work without ground truth labels, making it applicable across domains and VLM architectures.

## Key Results
- VASE uncertainty metric consistently outperforms SE and RadFlag across three VLMs and multiple medical VQA datasets
- Embedding-based semantic clustering outperforms entailment-based clustering for detecting hallucinations
- Moderate sampling scales (~10-15 perturbed images) yield optimal detection performance
- Denser fusion architectures and concise answers produce clearer hallucination signals

## Why This Works (Mechanism)
HEDGE exploits the geometric principle that hallucinated answers exhibit low density in the semantic space of perturbed inputs. When a VLM hallucinates, small visual perturbations cause erratic answer changes that fail to form coherent semantic clusters. The geometric entropy metric quantifies this instability by measuring the spread of answers across perturbations. VASE captures this effect more effectively than alternative metrics by incorporating both answer variation and semantic consistency. The method works because real answers tend to be geometrically stable under reasonable perturbations, while hallucinations lack this stability.

## Foundational Learning
- **Geometric entropy**: Measures semantic spread of answers across perturbed inputs; needed to quantify answer stability; quick check: compare entropy values for consistent vs inconsistent answer sets
- **Semantic clustering**: Groups similar answers to identify coherent response patterns; needed to handle answer variation; quick check: verify clustering captures semantic similarity rather than surface form
- **Uncertainty metrics**: Quantify answer consistency and confidence; needed to translate geometric patterns into hallucination scores; quick check: test metric sensitivity to controlled perturbations
- **Visual perturbation design**: Controlled modifications to input images; needed to create test conditions; quick check: ensure perturbations preserve task-relevant information
- **Entailment vs embedding clustering**: Different approaches to semantic similarity; needed to compare clustering effectiveness; quick check: evaluate clustering quality on known similar/dissimilar pairs
- **VASE metric**: Variance-aware semantic entropy; needed for improved hallucination detection; quick check: compare VASE scores against ground truth hallucination labels

## Architecture Onboarding

**Component map**: Input Image -> Perturbation Generator -> VLM Sampling -> Answer Clustering -> Uncertainty Metrics -> Hallucination Score

**Critical path**: Perturbation generation and sampling → semantic clustering → uncertainty metric computation

**Design tradeoffs**: 
- Sampling scale vs computational cost
- Perturbation intensity vs task relevance preservation
- Clustering granularity vs false positive rate
- Metric sensitivity vs robustness to benign variation

**Failure signatures**:
- High false positives when answers naturally vary under perturbations
- Missed hallucinations when geometric patterns remain stable
- Sensitivity to clustering threshold choices
- Performance degradation with extreme perturbation regimes

**First experiments**:
1. Baseline comparison: Run HEDGE with SE, RadFlag, and VASE metrics on a held-out test set
2. Clustering comparison: Evaluate entailment-based vs embedding-based clustering performance
3. Sampling scale sweep: Test detection accuracy across 5, 10, 15, and 20 perturbation samples

## Open Questions the Paper Calls Out
The paper identifies several limitations including the need for broader domain validation beyond medical imaging, systematic ablation studies of clustering methods in isolation, and calibration of perturbation budgets for different task types.

## Limitations
- Limited evaluation to medical VQA datasets raises questions about domain transferability
- Critical clustering method choice lacks systematic ablation studies in isolation
- Perturbation budget calibration remains unclear for varied regimes
- Performance under severe or diverse perturbation types untested

## Confidence

| Claim | Confidence |
|-------|------------|
| VASE outperforms SE and RadFlag | High |
| Embedding clustering outperforms entailment clustering | Medium |
| Architectural and prompt design findings | Low to Medium |

## Next Checks
1. Test HEDGE on non-medical VQA datasets (VQA v2, GQA) to assess domain transferability
2. Conduct controlled ablation studies isolating clustering method, sampling scale, and perturbation type effects
3. Evaluate HEDGE's sensitivity to different perturbation budgets and types beyond moderate perturbations used here