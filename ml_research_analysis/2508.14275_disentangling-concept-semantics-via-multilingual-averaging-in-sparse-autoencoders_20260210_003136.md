---
ver: rpa2
title: Disentangling concept semantics via multilingual averaging in Sparse Autoencoders
arxiv_id: '2508.14275'
source_url: https://arxiv.org/abs/2508.14275
tags:
- concept
- ontology
- class
- average
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether multilingual averaging can isolate
  semantic information in sparse autoencoder representations of ontology classes.
  The authors parse OWL ontology classes into text, translate English versions into
  French and Chinese, and use these as prompts for a Gemma 2B LLM with Sparse Autoencoders
  to obtain concept activations.
---

# Disentangling concept semantics via multilingual averaging in Sparse Autoencoders

## Quick Facts
- arXiv ID: 2508.14275
- Source URL: https://arxiv.org/abs/2508.14275
- Reference count: 19
- Primary result: Multilingual averaging of sparse autoencoder activations significantly improves correlation with ground truth ontology alignments compared to single-language representations

## Executive Summary
This paper explores whether averaging concept representations across multiple languages can isolate pure semantic information in sparse autoencoder models. The authors parse ontology classes into text, translate English versions into French and Chinese, and use these as prompts for a Gemma 2B LLM with Sparse Autoencoders to obtain concept activations. They find that averaging activations across language versions yields significantly stronger correlations with ground truth ontology alignments compared to single-language representations, suggesting that multilingual averaging suppresses syntactic and language-specific information while preserving semantic content.

## Method Summary
The authors parse OWL ontology classes into text descriptions, then translate English versions into French and Chinese to create multilingual concept prompts. These prompts are fed into a Gemma 2B LLM with Sparse Autoencoders to obtain concept activations. The key innovation is creating "conceptual averages" by averaging these multilingual activations, which are then compared against ground truth ontology alignments. The approach tests whether multilingual averaging can disentangle semantic information from language-specific and syntactic noise in the internal representations.

## Key Results
- English-only correlations with ground truth ontology alignments: 0.09
- English-French average correlations: 0.39
- English-Chinese average correlations: 0.33
- Multilingual averaging yields significantly stronger correlations than single-language representations
- Method appears to suppress syntactic and language-specific information, leaving purer semantic representations

## Why This Works (Mechanism)
The multilingual averaging technique works by leveraging the fact that semantic content should remain consistent across translations while syntactic and language-specific features vary. When activations from different language versions are averaged, the semantic signal reinforces while language-specific noise cancels out. This creates cleaner representations that better capture the underlying conceptual meaning rather than surface-level linguistic patterns.

## Foundational Learning
- **Sparse Autoencoders**: Neural network components that learn compressed representations by enforcing sparsity constraints, useful for identifying interpretable features in LLM activations
  - *Why needed*: Enable extraction of meaningful, interpretable features from LLM internal states
  - *Quick check*: Verify that SAE activations show sparse, interpretable patterns for known concepts

- **Ontology Alignment**: The task of determining semantic equivalence between concepts from different knowledge bases or ontologies
  - *Why needed*: Provides ground truth for evaluating whether representations capture true semantic meaning
  - *Quick check*: Ensure alignment scores correlate with human judgments of concept similarity

- **Multilingual Representation Learning**: Techniques for leveraging multiple languages to improve semantic understanding
  - *Why needed*: Different languages provide diverse perspectives on the same concepts, helping isolate semantic from linguistic features
  - *Quick check*: Confirm that translations preserve core semantic content while varying syntactic structure

## Architecture Onboarding

**Component Map:**
Gemma 2B LLM -> Sparse Autoencoder -> Multilingual Prompts (EN/FR/ZH) -> Conceptual Averaging -> Correlation with Ground Truth

**Critical Path:**
The critical path flows from multilingual prompt generation through the LLM and SAE to produce activations, which are then averaged across languages and evaluated against ground truth alignments. The quality of translations and the effectiveness of the SAE in extracting meaningful features are key bottlenecks.

**Design Tradeoffs:**
The method trades computational overhead (processing multiple languages) for improved semantic representation quality. Using only three languages limits generalizability, while relying on a single 2B parameter model restricts conclusions about scalability. The approach assumes semantic consistency across translations, which may not hold for culturally-specific concepts.

**Failure Signatures:**
Poor alignment scores would indicate that either the SAE fails to extract meaningful features, the translations don't preserve semantic content, or the averaging process doesn't effectively suppress language-specific information. Low correlations across all language combinations would suggest fundamental issues with the representation extraction.

**First Experiments:**
1. Test the averaging approach on unstructured natural language concepts and ambiguous terms to assess robustness beyond ontology-derived classes
2. Expand evaluation to include more diverse language pairs (e.g., non-European languages, language families with different syntactic structures)
3. Conduct ablation studies comparing multilingual averaging against alternative techniques like prompt ensembling or embedding regularization

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to ontology-derived concepts and three languages (English, French, Chinese)
- Single 2B parameter Gemma model restricts conclusions about scalability to larger architectures
- Averaging method's effectiveness for complex or ambiguous concepts remains unverified
- Does not address performance with non-English-centric language combinations

## Confidence
- **High Confidence**: Multilingual averaging produces stronger correlations with ground truth ontology alignments compared to single-language representations
- **Medium Confidence**: Averaging suppresses syntactic and language-specific information to yield purer semantic representations
- **Low Confidence**: This represents a "new technique for improving mechanistic interpretability" beyond the ontology domain

## Next Checks
1. Test multilingual averaging on unstructured natural language concepts and ambiguous terms to assess robustness beyond ontology-derived classes
2. Expand evaluation to include more diverse language pairs (e.g., non-European languages, language families with different syntactic structures) and larger LLM architectures
3. Conduct ablation studies comparing multilingual averaging against alternative techniques like prompt ensembling or embedding regularization