---
ver: rpa2
title: 'QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models'
arxiv_id: '2507.09514'
source_url: https://arxiv.org/abs/2507.09514
tags:
- quartermap
- pruning
- vmamba
- accuracy
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: QuarterMap is a post-training activation pruning method designed
  to improve the runtime efficiency of visual State Space Models (SSMs) like VMamba.
  It reduces spatial redundancy in activation maps by pruning spatial dimensions before
  the scanning operation and restoring them via nearest-neighbor upsampling.
---

# QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models

## Quick Facts
- **arXiv ID:** 2507.09514
- **Source URL:** https://arxiv.org/abs/2507.09514
- **Reference count:** 34
- **Primary result:** Achieves up to 11% inference speedup on VMamba with less than 0.9% accuracy drop

## Executive Summary
QuarterMap is a post-training activation pruning method designed to improve the runtime efficiency of visual State Space Models (SSMs) like VMamba. It reduces spatial redundancy in activation maps by pruning spatial dimensions before the scanning operation and restoring them via nearest-neighbor upsampling. On ImageNet-1K, QuarterMap achieves up to 11% speedup with less than 0.9% accuracy drop on VMamba. It also improves throughput by 1.21× on MedMamba for medical imaging tasks without accuracy loss. The method is specifically effective for SSMs due to their four-directional scanning structure and is not applicable to CNNs or 1D-scanning SSMs. QuarterMap avoids costly merge-unmerge operations compared to token merging methods and is designed for deployment-time efficiency without retraining.

## Method Summary
QuarterMap applies spatial pruning to VMamba's activation maps before the SS2D cross-scan operation, reducing spatial dimensions by half (m=2, n=1) and restoring them after cross-merge using nearest-neighbor upsampling. The pruning is applied to every 3rd block (k=3) starting from layer 2, excluding the first layer. This reduces the sequence length for the SSM recurrence, directly lowering computational cost at its source. The method leverages the four-directional scanning structure of VMamba, which creates recoverable spatial redundancy, allowing for aggressive pruning without substantial information loss. QuarterMap is explicitly designed as a deployment-time optimization that requires no retraining.

## Key Results
- Achieves 11% inference speedup on VMamba-B with less than 0.9% accuracy drop on ImageNet-1K
- Improves MedMamba throughput by 1.21× on medical imaging tasks without accuracy loss
- Reduces scan kernel execution time from 1.4ms to 0.6ms while adding only 0.2ms overhead
- Not applicable to CNNs or 1D-scanning SSMs (ViM) due to architectural incompatibility

## Why This Works (Mechanism)

### Mechanism 1: Four-Directional Scanning Creates Recoverable Spatial Redundancy
VMamba's cross-scan mechanism produces redundant activations that can be pruned without substantial information loss because each spatial position receives contributions from four traversal directions. The SS2D module unfolds 2D feature maps into four 1D sequences (top-left→bottom-right, bottom-right→top-left, top-right→bottom-left, bottom-left→top-right). This multi-directional traversal means each output position aggregates information from multiple neighboring paths, creating spatial overlap. The core assumption is that adjacent spatial positions in feature maps encode similar semantic information, making selective retention sufficient for reconstruction. Models lacking multi-directional scanning (CNNs, 1D SSMs like ViM) do not exhibit recoverable redundancy.

### Mechanism 2: Pre-Scan Pruning Reduces SSM Sequence Length Directly
Pruning before the selective scan operation reduces the computational cost at its source—the SSM recurrence—rather than adding post-hoc compression overhead. QuarterMap downsamples the activation map from H×W to ⌈H/2⌉×⌈W/2⌉ before cross-scan, directly shortening the sequence length L in the discrete SSM equations (ht = Āht-1 + B̄ut), reducing both the recurrence computation and the selective mechanism's linear projections. The core assumption is that the selective scan kernel dominates runtime, so reducing its input length yields net speedup even with pruning/upsampling overhead.

### Mechanism 3: Nearest-Neighbor Upsampling Minimizes Restoration Overhead
Nearest-neighbor interpolation provides sufficient reconstruction quality at minimal computational cost compared to learned or higher-order interpolation. After cross-merge, QuarterMap applies U(y) using nearest-neighbor interpolation to restore H×W dimensions. This simply replicates values without arithmetic operations across multiple positions. The core assumption is that the pruned activations lost truly redundant information, so simple replication recovers adequate spatial detail for downstream layers. Nearest-neighbor is ~3× faster than bilinear and ~5× faster than bicubic, making it the only viable option for maintaining speedup.

## Foundational Learning

- **Concept: State Space Models (SSMs) and Discretization**
  - Why needed: QuarterMap operates on the SSM recurrence (ht = Āht-1 + B̄ut). Understanding how continuous dynamics become discrete sequences explains why reducing sequence length L directly lowers compute.
  - Quick check: Can you explain why the SSM recurrence has O(L) complexity per layer, and how this differs from transformer attention's O(L²)?

- **Concept: VMamba's SS2D Module (Cross-Scan, Selective Scan, Cross-Merge)**
  - Why needed: QuarterMap inserts between cross-scan and cross-merge. You must understand what each stage does to see why pruning before scan saves compute across all three stages.
  - Quick check: Draw the four scanning directions and explain why cross-merge requires all four processed sequences to reconstruct a 2D output.

- **Concept: Post-Training vs. Training-Aware Compression**
  - Why needed: QuarterMap is explicitly deployment-focused—no retraining, no weight modification. This constrains what operations are viable (e.g., no learned upsampling, no fine-tuning to recover accuracy).
  - Quick check: Why can't QuarterMap use a learned deconvolution layer for upsampling? What deployment scenario would this violate?

## Architecture Onboarding

- **Component map:** Input Feature Map (H×W×D) → [QuarterMap Prune] → Pruned Map (⌈H/2⌉×⌈W/2⌉×D) → [Cross-Scan] → [Selective Scan (Mamba)] → [Cross-Merge] → [QuarterMap Upsample] → Output Feature Map (H×W×D)

- **Critical path:** The pruning interval (m, n) and block selection (k) directly control the accuracy-throughput tradeoff. The scan kernel reduction is the primary speedup source; upsampling overhead must stay minimal.

- **Design tradeoffs:**
  - **Block selection (k):** k=3 applies QuarterMap every 3rd block (excluding first layer). Lower k = more speedup, more accuracy loss. k=2 yields 1.16× speedup but 1.30% accuracy drop vs. 0.86% for k=3.
  - **Pruning granularity (m, n):** m=2, n=1 (keep 1 of every 2 pixels) is optimal. Higher m increases speedup but accuracy degrades nonlinearly.
  - **Layer selection:** First layer is most sensitive (applying to layer 1 drops accuracy to 78.75%). Deeper layers are more resilient.
  - **Upsampling method:** Only nearest-neighbor is viable; bilinear/bicubic overhead negates speedup.

- **Failure signatures:**
  - Applying to CNNs: Spatial continuity breaks, accuracy collapses (ConvNeXt-B: 84.89% → 45.71%)
  - Applying to 1D-scanning SSMs (ViM): No multi-direction redundancy to exploit (ViM-B: 80.40% → 71.00%)
  - Applying to early layers: Low-level feature encoding disrupted
  - Using bilinear/bicubic upsampling: Throughput drops below baseline

- **First 3 experiments:**
  1. **Validate baseline overhead:** Apply QuarterMap (k=3, m=2, n=1) to VMamba-B on ImageNet-1K validation. Measure: (a) throughput in img/s, (b) top-1 accuracy, (c) scan kernel time vs. pruning+upsampling overhead. Confirm speedup comes from kernel reduction, not other sources.
  2. **Block selection ablation:** Test k∈{2,3,4,5} on VMamba-B. Plot accuracy vs. throughput Pareto curve (Figure 5 style). Identify the k value where accuracy drop exceeds 1%—this is your practical deployment boundary.
  3. **Architecture compatibility test:** Apply QuarterMap (same hyperparameters) to one CNN (ConvNeXt), one ViT (DeiT), and one 1D-SSM (ViM). Confirm failure modes match Table 3 before attempting to extend to new architectures.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does QuarterMap interact with quantization techniques to achieve compound efficiency gains?
- **Basis:** The conclusion states QuarterMap is "orthogonal to techniques such as quantization, enabling further efficiency gains."
- **Why unresolved:** The paper proposes this combination but provides no experimental validation of joint optimization.
- **Evidence to resolve it:** Experiments applying post-training quantization (e.g., INT8/INT4) to QuarterMap-pruned VMamba models to measure compound latency reductions and accuracy trade-offs.

### Open Question 2
- **Question:** Can activation pruning strategies be adapted for 1D-scanning SSMs (e.g., ViM) where the current method yields significant accuracy drops?
- **Basis:** The authors explicitly note that QuarterMap is "less compatible with... 1D-scanning SSMs like ViM," causing accuracy to drop from 80.4% to 71.0%.
- **Why unresolved:** The paper identifies the failure mode—lack of four-directional redundancy—but does not offer a solution for unidirectional scanning architectures.
- **Evidence to resolve it:** A modified pruning heuristic designed for 1D scans that maintains accuracy within 1% of the baseline while improving throughput.

### Open Question 3
- **Question:** Does a dynamic, content-aware block selection strategy outperform the fixed interval (k=3) used in the study?
- **Basis:** The paper relies on static block selection interval (k) and fixed pruning dimensions (m=2, n=1) determined by grid search.
- **Why unresolved:** Static hyperparameters may be suboptimal; early layers or simple images might tolerate more pruning than complex ones, suggesting an adaptive approach could improve the trade-off frontier.
- **Evidence to resolve it:** A mechanism that adjusts the pruning interval k or ratio m/n based on input complexity (e.g., activation variance) and compares the Pareto curve against the static baseline.

### Open Question 4
- **Question:** Can the spatial pruning logic be effectively extended to the temporal dimension for video-based State Space Models?
- **Basis:** The paper validates image tasks and cites VideoMamba in the references, but excludes video experiments despite the high temporal redundancy in video data.
- **Why unresolved:** It is unclear if the hypothesis "adjacent spatial positions convey similar information" transfers effectively to temporal frames without disrupting the SSM's state dynamics over time.
- **Evidence to resolve it:** Application of QuarterMap to VideoMamba to measure throughput speedup and mAP degradation on standard video action recognition benchmarks.

## Limitations

- The method's effectiveness is tightly coupled to VMamba's four-directional scanning architecture; it cannot be directly applied to CNNs or 1D SSMs without significant degradation.
- The claim that adjacent spatial elements contain "similar information" sufficient for nearest-neighbor recovery is an assumption that may not hold for all visual tasks, particularly those requiring fine spatial precision.
- The evaluation focuses primarily on VMamba-B and VMamba-S; performance on larger models or different SSM variants (like U-Net SSM backbones) remains untested.

## Confidence

- **High confidence:** Throughput improvements on VMamba architectures (11% speedup with <0.9% accuracy drop), the architectural incompatibility with CNNs and 1D SSMs, and the computational dominance of the scan kernel (18.3% of execution time).
- **Medium confidence:** The claim that spatial redundancy is recoverable specifically due to four-directional scanning, and that nearest-neighbor upsampling is optimal.
- **Low confidence:** The generalization of these findings to medical imaging tasks beyond MedMNIST, and the assumption that spatial redundancy is a universal property of visual SSMs rather than VMamba-specific.

## Next Checks

1. **Architectural transfer validation:** Apply QuarterMap to a U-Net backbone using VMamba blocks for medical image segmentation. Measure whether the accuracy-throughput tradeoff observed on MedMNIST (1.21× speedup, no accuracy loss) extends to more complex, high-resolution medical imaging tasks with boundary-sensitive outputs.

2. **Learned upsampling ablation:** Implement a lightweight learned upsampling module (e.g., a small convolutional layer) as an alternative to nearest-neighbor. Compare accuracy-throughput tradeoffs to determine if the strict deployment constraint (no retraining) is truly necessary for practical efficiency gains.

3. **Early-layer sensitivity analysis:** Systematically apply QuarterMap to individual blocks starting from the first layer, measuring accuracy degradation per layer. This would quantify the exact sensitivity threshold and potentially identify opportunities for earlier application with minimal impact.