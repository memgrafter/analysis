---
ver: rpa2
title: 'Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review'
arxiv_id: '2502.11518'
source_url: https://arxiv.org/abs/2502.11518
tags:
- multi-agent
- agents
- collaboration
- embodied
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey systematically examines the integration of generative
  foundation models into embodied multi-agent systems (EMAS), addressing the challenge
  of creating more adaptive and robust multi-agent collaboration in complex real-world
  environments. The paper proposes a taxonomy categorizing EMAS architectures by system
  control (centralized vs.
---

# Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review

## Quick Facts
- arXiv ID: 2502.11518
- Source URL: https://arxiv.org/abs/2502.11518
- Reference count: 6
- This survey examines how generative foundation models enhance embodied multi-agent systems through improved perception, planning, communication, and feedback mechanisms.

## Executive Summary
This survey systematically examines the integration of generative foundation models into embodied multi-agent systems (EMAS), addressing the challenge of creating more adaptive and robust multi-agent collaboration in complex real-world environments. The paper proposes a taxonomy categorizing EMAS architectures by system control (centralized vs. decentralized) and embodiment modalities (physical vs. virtual), then analyzes four key functional building blocks: perception, planning, communication, and feedback. Through concrete examples across applications from intelligent transportation to household robotics, the authors demonstrate how generative techniques can enhance system robustness and flexibility.

The survey identifies critical open challenges including benchmarking and evaluation standards, data collection and heterogeneity, scalability of agents, human-centric collaboration, and theoretical foundations. While providing a comprehensive framework for understanding generative foundation models in EMAS, the authors acknowledge limitations in current evaluation metrics and the need for standardized protocols to guide future research.

## Method Summary
The survey employs systematic literature review methodology, analyzing research from 2020 to 2024 across multiple databases including arXiv, Google Scholar, and IEEE Xplore. The authors categorize papers based on system architecture (centralized vs. decentralized control) and embodiment modality (physical vs. virtual environments). They extract and analyze functional components across perception, planning, communication, and feedback mechanisms, organizing findings into a taxonomy with 16 distinct categories. The review focuses on applications in transportation, robotics, and embodied question answering while identifying common challenges and future research directions.

## Key Results
- Taxonomy framework categorizes EMAS architectures by control structure (centralized vs. decentralized) and embodiment (physical vs. virtual)
- Generative techniques improve system robustness across four key functional blocks: perception, planning, communication, and feedback
- Applications span intelligent transportation, household robotics, and embodied question answering scenarios
- Identified open challenges include benchmarking standards, data heterogeneity, agent scalability, and human-centric collaboration requirements

## Why This Works (Mechanism)
Generative foundation models enhance embodied multi-agent collaboration by providing adaptive reasoning capabilities that can handle environmental uncertainty and complex interactions. The mechanism works through multi-modal learning that integrates perception data with contextual understanding, enabling agents to generate appropriate responses in dynamic scenarios. Central to this approach is the ability of generative models to synthesize information from multiple sources and generate novel solutions for coordination challenges. The integration of generative models with traditional control architectures creates hybrid systems that combine the flexibility of learned behaviors with the reliability of engineered control systems.

## Foundational Learning
**Embodied AI** - AI systems that interact with physical or virtual environments through sensors and actuators; needed for grounding abstract reasoning in concrete environmental interactions; quick check: can the system manipulate objects or navigate spaces?

**Multi-Agent Systems** - Networks of autonomous agents that can cooperate, compete, or coordinate to achieve goals; needed to model complex scenarios requiring distributed decision-making; quick check: do agents have independent goals and communication capabilities?

**Generative Foundation Models** - Large-scale pre-trained models capable of generating novel outputs across multiple modalities; needed to provide flexible reasoning and adaptation capabilities; quick check: can the model generate contextually appropriate responses for novel situations?

**Centralized vs. Decentralized Control** - Architectural paradigms determining whether a single controller manages all agents or agents make independent decisions; needed to balance coordination efficiency with system resilience; quick check: what happens when the central controller fails?

**Embodiment Modalities** - Physical (robots, drones) vs. virtual (simulated agents) embodiments; needed to understand deployment constraints and interaction capabilities; quick check: what are the sensory and actuation limitations of each modality?

## Architecture Onboarding

**Component Map:** Perception -> Planning -> Communication -> Feedback -> Action

**Critical Path:** The most critical path flows through perception (gathering environmental data) → planning (determining agent actions) → communication (coordinating with other agents) → feedback (learning from outcomes) → action (executing decisions). Disruptions at any stage can cascade through the system.

**Design Tradeoffs:** Centralized systems offer better coordination but create single points of failure and scalability bottlenecks. Decentralized systems provide resilience and scalability but may suffer from inconsistent decision-making. Physical embodiments require robust hardware and safety considerations while virtual embodiments allow faster iteration but may not capture real-world complexities.

**Failure Signatures:** Communication breakdowns lead to agent collisions or conflicting actions. Perception failures cause navigation errors or object misidentification. Planning failures result in inefficient task allocation or suboptimal path planning. Feedback loop failures prevent learning from experience and adaptation to environmental changes.

**3 First Experiments:**
1. Compare centralized vs. decentralized generative EMAS architectures on standardized navigation tasks to quantify coordination efficiency and failure resilience.
2. Test multi-modal perception integration by having agents navigate environments with varying sensory inputs (visual, auditory, tactile).
3. Evaluate communication protocols by measuring task completion rates when agents have different levels of shared information and varying communication bandwidths.

## Open Questions the Paper Calls Out
The survey identifies several critical open questions: How can we develop standardized benchmarking and evaluation metrics for multi-agent collaboration quality? What are the best practices for collecting and managing heterogeneous data across different embodiment modalities? How can we ensure scalability when increasing the number of agents in complex environments? What frameworks enable effective human-agent collaboration in shared spaces? How do we establish theoretical foundations that can guide the design of robust generative EMAS architectures?

## Limitations
- The taxonomy proposed may not capture emerging hybrid or partially distributed architectures that combine centralized and decentralized elements
- Many cited examples represent ongoing research rather than fully validated deployments, suggesting practical robustness remains unproven at scale
- The survey's treatment of evaluation metrics is limited, reflecting a broader field-wide gap rather than a specific survey limitation

## Confidence
**High**: The fundamental taxonomy structure and identification of key functional building blocks (perception, planning, communication, feedback)
**Medium**: The practical applicability of generative techniques across different EMAS architectures
**Medium**: The comprehensiveness of identified challenges and future research directions

## Next Checks
1. Conduct empirical validation comparing centralized vs. decentralized generative EMAS architectures on standardized benchmarks to quantify performance trade-offs
2. Develop and test specific evaluation metrics for multi-agent collaboration quality that can distinguish between different generative approaches
3. Create a systematic mapping study tracking the evolution of EMAS publications from 2020-2024 to identify emerging patterns and validate the survey's identified trends