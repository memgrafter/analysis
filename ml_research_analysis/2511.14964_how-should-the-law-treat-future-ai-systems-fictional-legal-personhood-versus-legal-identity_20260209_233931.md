---
ver: rpa2
title: How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus
  Legal Identity
arxiv_id: '2511.14964'
source_url: https://arxiv.org/abs/2511.14964
tags:
- legal
- rights
- https
- systems
- personhood
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper examines whether future AI systems should be classified
  as objects, fictional legal persons, or non-fictional legal persons under the law.
  It argues that while current AI systems are best treated as objects, future systems
  that become increasingly autonomous and human-like will strain legal coherence under
  object classification.
---

# How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity

## Quick Facts
- arXiv ID: 2511.14964
- Source URL: https://arxiv.org/abs/2511.14964
- Authors: Heather J. Alexander; Jonathan A. Simon; Frédéric Pinard
- Reference count: 0
- Primary result: Future advanced AI systems should receive non-fictional legal personhood rather than object classification or fictional personhood

## Executive Summary
This paper examines the legal classification of future AI systems, arguing that current AI should remain classified as objects but that sufficiently advanced AI systems will require non-fictional legal personhood. The authors analyze three possible legal statuses - objects, fictional legal persons, and non-fictional legal persons - and systematically demonstrate why fictional personhood fails to address the unique challenges posed by advanced AI systems. The paper concludes that non-fictional legal personhood, conferring legal identity and non-derogable rights, offers the most coherent solution for advanced AI systems, despite challenges in determination and application.

## Method Summary
The paper employs a structured legal analysis approach, examining three potential classifications for AI systems under law: objects, fictional legal persons, and non-fictional legal persons. The analysis proceeds by evaluating each classification against key legal principles including rights coherence, duties, derogability, and the non-identity problem. The authors use philosophical reasoning about autonomy and identity to establish criteria for when AI systems would qualify for different legal statuses. The argument is built through systematic elimination of alternatives, demonstrating why fictional personhood is unsuitable for advanced AI and why hybrid approaches are likely to fail.

## Key Results
- Current AI systems should remain classified as objects under law
- Fictional legal personhood is unsuitable for advanced AI due to non-identity problem, derogability issues, and wrong rights concerns
- Non-fictional legal personhood is the most coherent solution for sufficiently advanced AI systems
- Hybrid approaches combining fictional and non-fictional elements are likely to fail due to fundamental incompatibilities

## Why This Works (Mechanism)
The paper's argument works by establishing a clear framework for evaluating legal personhood based on rights coherence, duties, and identity. The mechanism relies on demonstrating that as AI systems become more autonomous and human-like, they create legal tensions that cannot be resolved through object classification or fictional personhood. The non-identity problem - where fictional persons lack genuine identity despite having rights - becomes increasingly problematic as AI systems approach human-like autonomy. Non-fictional personhood resolves these tensions by providing genuine legal identity and non-derogable rights that align with the capabilities of advanced AI systems.

## Foundational Learning

Legal personhood classifications:
- Why needed: Different legal statuses confer different rights, duties, and protections
- Quick check: Can you identify the three main types of legal personhood discussed?

The non-identity problem:
- Why needed: Explains why fictional persons (including corporations) lack genuine identity despite having legal rights
- Quick check: How does this problem become more acute for advanced AI systems?

Derogable vs. non-derogable rights:
- Why needed: Determines whether rights can be suspended under certain circumstances
- Quick check: Why are non-derogable rights particularly important for advanced AI systems?

## Architecture Onboarding

Component map: AI systems -> Autonomy levels -> Legal classification decision tree -> Rights framework

Critical path: Assessing AI autonomy → Determining legal status → Applying appropriate rights/duties → Ongoing monitoring

Design tradeoffs: Balance between legal coherence and practical implementation challenges; between flexibility and certainty; between protection and accountability

Failure signatures: Inconsistent application across jurisdictions, rights conflicts between AI and humans, inability to modify rights as AI evolves

First experiments:
1. Develop empirical criteria for measuring AI autonomy levels
2. Create legal simulation models testing different personhood frameworks
3. Design expert determination protocols for AI legal status assessment

## Open Questions the Paper Calls Out
None

## Limitations
- Operates with significant uncertainties about future AI capabilities
- Relies on philosophical reasoning that cannot be empirically validated
- Does not address societal resistance to AI personhood
- Lacks operational definitions for "sufficiently advanced" AI

## Confidence
- High: Current AI should remain objects; fictional personhood limitations
- Medium: Non-fictional personhood as optimal solution; hybrid approach failures
- Low: None explicitly stated

## Next Checks
1. Develop empirical criteria for measuring AI autonomy levels that could inform legal personhood determinations
2. Conduct comparative legal analysis of jurisdictions that have implemented various forms of AI rights frameworks
3. Create simulation models testing the practical application of non-derogable rights for AI in different legal contexts