---
ver: rpa2
title: 'Prime Convolutional Model: Breaking the Ground for Theoretical Explainability'
arxiv_id: '2503.02773'
source_url: https://arxiv.org/abs/2503.02773
tags:
- neural
- classes
- modulo
- prime
- congruence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new theoretical approach to Explainable AI
  based on the Scientific Method, formulating mathematical models to explain and predict
  neural network behaviors from empirical evidence. The authors develop a case study
  called the Prime Convolutional Model (p-Conv), which identifies congruence classes
  modulo an integer m in a dataset of the first one million natural numbers.
---

# Prime Convolutional Model: Breaking the Ground for Theoretical Explainability

## Quick Facts
- arXiv ID: 2503.02773
- Source URL: https://arxiv.org/abs/2503.02773
- Authors: Francesco Panelli; Doaa Almhaithawi; Tania Cerquitelli; Alessandro Bellini
- Reference count: 40
- This paper proposes a new theoretical approach to Explainable AI based on the Scientific Method, formulating mathematical models to explain and predict neural network behaviors from empirical evidence.

## Executive Summary
This paper introduces a novel theoretical framework for Explainable AI (XAI) based on the Scientific Method, using mathematical modeling to explain neural network behaviors. The authors develop the Prime Convolutional Model (p-Conv), a convolutional neural network designed to identify congruence classes modulo an integer m in the first one million natural numbers. Through extensive experiments with different parameter settings, they derive precise mathematical relationships that predict when and how the model succeeds or fails, providing a rigorous approach to understanding neural network behavior.

## Method Summary
The Prime Convolutional Model (p-Conv) uses a convolutional-type neural network that processes sequences of B consecutive numbers as input, representing them through prime grid vector representation to leverage the multiplicative structure of natural numbers. The model is trained on the first one million natural numbers to identify congruence classes modulo m. The authors conduct systematic experiments across various values of m (2-30) and sequence lengths B (8, 16, 24), analyzing the relationship between these parameters and network performance. This empirical approach is combined with theoretical modeling to establish mathematical relationships that explain the observed behaviors.

## Key Results
- p-Conv can identify all congruence classes when m ≤ B + 2
- When m > B + 2, the model correctly identifies class [0]m and the last B classes while randomly mixing the remaining classes
- The mathematical model explains both successful performance conditions and error patterns, providing theoretical predictability for neural network behavior

## Why This Works (Mechanism)
The mechanism works because the convolutional architecture processes sequential patterns in natural numbers, while the prime grid vector representation captures the multiplicative structure inherent in number theory. The model's success depends on the relationship between the number of classes m and the sequence length B, where sufficient context (B ≥ m - 2) allows the network to distinguish all congruence classes. The mathematical framework translates empirical observations into predictive relationships, enabling theoretical explanation of why the network behaves as it does under different parameter configurations.

## Foundational Learning
- **Congruence Classes**: Groups of integers that have the same remainder when divided by m. Needed to understand the classification task. Quick check: Verify that integers 5, 11, and 17 all belong to the same congruence class modulo 6.
- **Prime Grid Vector Representation**: A method to encode natural numbers using their prime factorization properties. Needed to capture multiplicative structure. Quick check: Confirm that the prime grid representation preserves unique factorization for numbers 1-100.
- **Convolutional Neural Networks**: Neural networks that use convolution operations to process sequential or spatial data. Needed to process sequences of consecutive numbers. Quick check: Validate that the network correctly processes sliding windows of size B.
- **Scientific Method for XAI**: An approach that formulates hypotheses, conducts experiments, and derives mathematical models to explain AI behavior. Needed to create rigorous theoretical explanations. Quick check: Ensure the mathematical model accurately predicts experimental outcomes across parameter ranges.

## Architecture Onboarding

**Component Map**: Input Sequence -> Prime Grid Vectorization -> Convolutional Layers -> Dense Layers -> Output Classes

**Critical Path**: The sequence processing through convolutional layers is critical, as it captures the sequential patterns necessary for congruence class identification. The prime grid representation must preserve number-theoretic properties for the model to succeed.

**Design Tradeoffs**: 
- Shorter sequence lengths (B) reduce computational cost but limit the model's ability to distinguish many congruence classes
- Longer sequences improve performance but increase computational requirements and may introduce redundancy
- The prime grid representation adds preprocessing complexity but provides theoretical advantages in capturing multiplicative structure

**Failure Signatures**: When m > B + 2, the model exhibits a specific failure pattern: correct identification of class [0]m and the last B classes, with remaining classes randomly mixed. This predictable failure mode enables theoretical explanation rather than black-box uncertainty.

**First 3 Experiments**:
1. Test p-Conv with m = 5 and B = 8 to verify the condition m ≤ B + 2 holds and all classes are correctly identified
2. Evaluate the model with m = 15 and B = 8 to observe the error pattern when m > B + 2
3. Experiment with varying B values (8, 16, 24) for fixed m = 10 to analyze how sequence length affects performance

## Open Questions the Paper Calls Out
None

## Limitations
- The mathematical models may not generalize beyond congruence class identification to other domains or complex neural network architectures
- Experimental validation is limited to natural numbers and convolutional networks, raising questions about applicability to other data types
- Extensive computational resources are required, potentially limiting reproducibility in resource-constrained environments

## Confidence

**High Confidence**: The mathematical relationships between model parameters (m and B) and performance outcomes are well-established through empirical testing and theoretical derivation. The observation that p-Conv identifies all congruence classes when m ≤ B + 2 is supported by consistent experimental results across multiple trials.

**Medium Confidence**: The error pattern description when m > B + 2 shows consistency in identifying class [0]m and the last B classes, but the "random mixing" of remaining classes requires further statistical validation to confirm it follows a truly random distribution rather than exhibiting hidden patterns.

**Low Confidence**: The generalizability of this theoretical approach to Explainable AI beyond the specific case study remains unproven. The claim that this framework suggests "new directions for AI explainability research" is speculative without validation on diverse datasets and architectures.

## Next Checks

1. Conduct experiments with non-linear and non-sequential data structures to test the framework's applicability beyond natural numbers and convolutional networks.

2. Perform statistical analysis on the "random mixing" error pattern to quantify the distribution and verify it follows expected random behavior rather than systematic biases.

3. Apply the theoretical framework to a real-world dataset (e.g., medical imaging or financial time series) to evaluate its practical utility for explaining complex neural network behaviors in applied settings.