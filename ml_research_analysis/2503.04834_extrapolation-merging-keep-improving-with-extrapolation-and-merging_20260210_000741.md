---
ver: rpa2
title: 'Extrapolation Merging: Keep Improving With Extrapolation and Merging'
arxiv_id: '2503.04834'
source_url: https://arxiv.org/abs/2503.04834
tags:
- merging
- performance
- extrapolation
- exme
- points
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving large language
  model (LLM) performance without requiring additional computational resources or
  labeled data. The authors propose Extrapolation Merging (ExMe), a method that combines
  model extrapolation and merging techniques.
---

# Extrapolation Merging: Keep Improving With Extrapolation and Merging

## Quick Facts
- arXiv ID: 2503.04834
- Source URL: https://arxiv.org/abs/2503.04834
- Authors: Yiguan Lin; Bin Xu; Yinghao Li; Yang Gao
- Reference count: 9
- Key outcome: ExMe improves Qwen2-7B by 3.23 points and Qwen1.5-14B by 2.87 points in average score across seven tasks without additional compute or data

## Executive Summary
This paper addresses the challenge of improving large language model (LLM) performance after instruction fine-tuning without requiring additional computational resources or labeled data. The authors propose Extrapolation Merging (ExMe), a method that combines model extrapolation and merging techniques to achieve performance gains. ExMe first fine-tunes a base model to obtain multiple checkpoints, then applies model extrapolation to generate models optimized in different directions, and finally merges the two best-performing extrapolated models using weighted averaging. Experiments on seven tasks show that ExMe consistently improves model performance compared to other merging methods, with gains of 3.23 points for Qwen2-7B and 2.87 points for Qwen1.5-14B in average score.

## Method Summary
ExMe is a three-stage pipeline that leverages SFT checkpoints to create improved models without additional training. First, a base model undergoes instruction fine-tuning with multiple checkpoints saved during training. The top-2 checkpoints are selected based on their overall performance across benchmark tasks. Second, model extrapolation is applied to each selected checkpoint using the formula Θ_EXPO = Θ_SFT + α(Θ_SFT - Θ_base) with α values from 0.1 to 0.5, creating models optimized in amplified directions. The best extrapolation for each checkpoint is selected. Third, the two best-performing extrapolated models are merged using weighted averaging with β values from 0.1 to 0.9, and the optimal β is selected. This approach amplifies the optimization direction captured in SFT checkpoints while balancing their complementary strengths through merging.

## Key Results
- ExMe improves Qwen2-7B by 3.23 points and Qwen1.5-14B by 2.87 points in average score across seven tasks
- The method demonstrates greater robustness, balancing performance improvement and stability compared to other merging techniques
- ExMe consistently outperforms baseline merging methods across all tested model scales (7B and 14B parameters)

## Why This Works (Mechanism)

### Mechanism 1: Extrapolation Amplifies SFT Optimization Direction
The SFT model is treated as an interpolation between a base model and an unknown stronger model, enabling inference of a further-optimized model through parameter arithmetic. The SFT model (Θ_SFT) is viewed as a weighted combination: Θ_SFT = λΘ_EXPO + (1-λ)Θ_base. Solving for Θ_EXPO yields Θ_EXPO = Θ_SFT + α(Θ_SFT - Θ_base), where α = 1/λ - 1. This amplifies the delta vector (Θ_SFT - Θ_base) that represents the SFT optimization direction. The core assumption is that the parameter trajectory from base to SFT model lies on a meaningful optimization manifold that can be linearly extended. This mechanism breaks when SFT model performance is weaker than base model, causing extrapolation to monotonically degrade performance.

### Mechanism 2: Multi-Checkpoint Extrapolation Escapes Single-Path Local Optima
Different SFT checkpoints capture distinct capability emphases (e.g., one stronger on math, another on code). Extrapolating both creates models optimized along different trajectories; merging balances their strengths. The core assumption is that multiple SFT checkpoints from the same training run traverse meaningfully different regions of parameter space. This approach is supported by prior work on multi-checkpoint merging strategies. The mechanism breaks when the two extrapolated models have large performance gaps (>1.5 points average), causing merging to show monotonic degradation with increasing β.

### Mechanism 3: Weighted Merging Recovers Robustness Lost in Extrapolation
Weighted averaging of extrapolated models mitigates capability regressions that individual extrapolation can introduce. Extrapolation amplifies optimization in specific directions but can cause regressions (e.g., Qwen1.5-14B EXPO-1 drops 3.66 points on HumanEval). Merging with β weighting allows the stronger model to dominate while the weaker model provides corrective signals. The core assumption is that extrapolation-induced regressions are not perfectly correlated across checkpoints; merging can average them out. This mechanism breaks when both extrapolated models regress on the same benchmark, preventing merging from recovering performance.

## Foundational Learning

- **Concept: Linear interpolation/extrapolation in parameter space**
  - Why needed here: ExMe's core operation assumes parameters lie in a vector space where linear combinations produce meaningful models
  - Quick check question: Can you explain why Θ_merged = λΘ_1 + (1-λ)Θ_2 might produce a model with capabilities neither original model possessed?

- **Concept: SFT training dynamics and checkpoint selection**
  - Why needed here: The method depends on selecting SFT checkpoints with different optimization directions; understanding when/why checkpoints diverge is critical
  - Quick check question: During SFT, why might different checkpoints emphasize different capabilities even when trained on the same data?

- **Concept: Alpha (α) extrapolation parameter semantics**
  - Why needed here: α controls how far beyond the SFT model to extrapolate; too small = minimal gain, too large = instability
  - Quick check question: If α = 0.5 produces best results, what does this suggest about how far the SFT model is from the "optimal" point along its trajectory?

## Architecture Onboarding

- **Component map**: SFT Stage -> Extrapolation Stage -> Merging Stage
- **Critical path**: Checkpoint selection is the highest-leverage decision; poor checkpoints cannot be rescued by extrapolation/merging. Evaluate all SFT checkpoints on the FULL benchmark suite before selection, not just validation loss.
- **Design tradeoffs**:
  - **α range**: Paper uses {0.1-0.5}; larger α risks instability, smaller α yields minimal gains. Optimal α varies by model (0.5 for Qwen2-7B, 0.1 for Mistral).
  - **β selection**: Smaller β (favoring the stronger extrapolated model) works best in 3/4 models. Assumption: weaker model provides subtle corrections rather than complementary capabilities.
  - **Number of models merged**: Paper merges exactly 2, citing prior work that merging >2 models typically degrades performance.
- **Failure signatures**:
  1. **Extrapolation degradation**: If SFT model is weaker than base on a benchmark, extrapolation worsens it further
  2. **Monotonic merge degradation**: Large performance gap between extrapolated models causes performance to decrease as β increases
  3. **Persistent capability regression**: SFT data mismatch with benchmark format causes regressions that ExMe cannot fix
- **First 3 experiments**:
  1. **Baseline SFT checkpoint sweep**: Train base model with SFT, save 10+ checkpoints, evaluate ALL on your target benchmark suite. Identify which checkpoints excel at which tasks before any extrapolation.
  2. **Single-checkpoint extrapolation grid**: Pick your best SFT checkpoint, run extrapolation with α ∈ {0.1, 0.2, ..., 1.0}, plot performance vs. α to find the stability cliff for your model scale.
  3. **Ablation: merge without extrapolation**: Merge the two best SFT checkpoints directly (β sweep) vs. merge extrapolated versions. Quantify how much gain comes from extrapolation vs. merging alone.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can rigorous mathematical proofs be established to explain why model extrapolation and merging effectively optimize the parameter space? The authors explicitly state in the Limitations section that their work relies on methods that "lack rigorous mathematical proofs" and that such proofs have not been provided. This remains unresolved as the current study relies solely on empirical validation across specific models and tasks rather than theoretical derivation.

- **Open Question 2**: Does identifying and removing redundant parameters during the extrapolation or merging phases improve the efficiency or performance of ExMe? The paper notes that the current method involves all parameters "without identifying or addressing the impact of redundant parameters," identifying this as a "potential direction for future optimization." This remains unresolved as the proposed ExMe method applies operations to the full parameter matrix without distinguishing between essential and non-essential weights.

- **Open Question 3**: Does increasing the diversity of the SFT training data prevent the degradation of specific capabilities (e.g., multiple-choice questions) observed after merging? The authors observe that ExMe does not improve performance on tasks like CMMLU and MMLU, attributing this to the "lack of diversity in SFT data" and the dialogue-style format of the Alpaca dataset. This remains unresolved as the experiments were limited to specific instruction-tuning datasets which may have induced a trade-off between generative capabilities and discriminative multi-choice performance.

## Limitations

- The method's effectiveness is highly sensitive to the quality of SFT checkpoints - if checkpoints do not capture meaningfully different optimization directions, the extrapolation stage provides minimal benefit.
- The paper demonstrates strong results but only on a limited set of model scales (7B and 14B parameters) and specific instruction datasets, leaving uncertainty about generalization to other model families or training regimes.
- The linear extrapolation assumption may break down for models with complex optimization trajectories, particularly when SFT and base models differ substantially in architecture or training objectives.

## Confidence

- **High confidence**: The weighted merging mechanism for combining extrapolated models (β optimization) is well-established and the empirical results are consistent across multiple model families and benchmarks.
- **Medium confidence**: The extrapolation amplification principle works as described, but the optimal α parameter varies significantly between models (0.5 for Qwen2-7B vs 0.1 for Mistral), suggesting the method may require careful tuning for different architectures.
- **Low confidence**: The claim that extrapolation consistently improves performance across all benchmarks is questionable - the paper shows clear degradation on certain tasks (e.g., CMMLU declines persist even after merging), and the method fails when SFT checkpoints are weaker than base models.

## Next Checks

1. **Cross-dataset validation**: Apply ExMe to SFT checkpoints trained on different instruction datasets (e.g., OpenAssistant, Dolly) to test whether the method generalizes beyond the specific alpaca-gpt4-data used in the paper.
2. **Architectural generalization test**: Validate ExMe on decoder-only models (GPT-style) versus encoder-decoder models (BART-style) to determine if the linear extrapolation assumption holds across different model architectures.
3. **Ablation on checkpoint quality**: Systematically test ExMe with checkpoints selected purely by validation loss versus checkpoints selected by downstream task performance to quantify how sensitive the method is to checkpoint selection criteria.