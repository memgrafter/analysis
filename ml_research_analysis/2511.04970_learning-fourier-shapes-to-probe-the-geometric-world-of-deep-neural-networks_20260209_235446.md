---
ver: rpa2
title: Learning Fourier shapes to probe the geometric world of deep neural networks
arxiv_id: '2511.04970'
source_url: https://arxiv.org/abs/2511.04970
tags:
- shape
- adversarial
- image
- shapes
- fourier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel method for probing deep neural networks'
  geometric understanding by learning adversarial shapes using Fourier series parameterization.
  The approach addresses the challenge of directly optimizing object shapes, which
  requires bridging the gap between abstract geometric parameters and the pixel grid
  used by DNNs.
---

# Learning Fourier shapes to probe the geometric world of deep neural networks

## Quick Facts
- arXiv ID: 2511.04970
- Source URL: https://arxiv.org/abs/2511.04970
- Reference count: 40
- Introduces a novel method for probing deep neural networks' geometric understanding by learning adversarial shapes using Fourier series parameterization

## Executive Summary
This paper introduces a novel method for probing deep neural networks' geometric understanding by learning adversarial shapes using Fourier series parameterization. The approach addresses the challenge of directly optimizing object shapes, which requires bridging the gap between abstract geometric parameters and the pixel grid used by DNNs. The method employs a differentiable framework that parameterizes arbitrary closed contours using Fourier series coefficients, maps these coefficients to pixel images using the winding number theorem, and introduces signal energy constraints for effective optimization.

## Method Summary
The method introduces a differentiable framework for learning adversarial shapes that probe deep neural networks' geometric understanding. It parameterizes arbitrary closed contours using Fourier series coefficients, maps these coefficients to pixel images via the winding number theorem, and introduces signal energy constraints for effective optimization. This approach bridges the gap between abstract geometric parameters and the pixel grid used by DNNs, enabling the generation of shapes that can act as powerful semantic carriers for classification tasks.

## Key Results
- Shapes alone can achieve high-confidence classifications (over 90% success rate for most architectures) without any texture information
- The method serves as a high-fidelity interpretability tool, isolating model salient regions with sharp boundaries more precise than Grad-CAM
- Adversarial shapes constitute a generalizable attack paradigm that can evade object detectors with success rates increasing with shape complexity (K)

## Why This Works (Mechanism)
The method works by parameterizing shapes using Fourier series coefficients, which allows for efficient representation of arbitrary closed contours. By mapping these coefficients to pixel images using the winding number theorem, the approach creates a differentiable pipeline that can optimize shapes directly with respect to network outputs. The introduction of signal energy constraints ensures effective optimization by preventing degenerate solutions and maintaining meaningful shape representations throughout the learning process.

## Foundational Learning
- **Fourier series parameterization**: Needed to represent arbitrary closed contours mathematically; Quick check: Verify that the chosen number of Fourier coefficients (K) captures the essential shape features
- **Winding number theorem**: Required to convert Fourier coefficients to pixel images while maintaining closed contours; Quick check: Confirm that all generated shapes are indeed closed and differentiable
- **Differentiable optimization**: Essential for backpropagating gradients from network outputs to shape parameters; Quick check: Ensure gradient flow is maintained throughout the optimization process
- **Signal energy constraints**: Needed to prevent degenerate solutions and maintain meaningful shape representations; Quick check: Verify that energy constraints do not overly constrain the optimization

## Architecture Onboarding

**Component map**: Fourier coefficients -> Winding number mapping -> Pixel image generation -> DNN input -> Network output

**Critical path**: The critical path involves computing Fourier coefficients, mapping them to pixel images via the winding number theorem, and feeding these images through the target DNN for classification or detection tasks.

**Design tradeoffs**: The method trades computational complexity (approximately 2000 iterations for convergence) for the ability to generate high-fidelity adversarial shapes. The choice of Fourier series parameterization balances expressiveness with computational tractability.

**Failure signatures**: Poor convergence, degenerate shapes, or failure to generate closed contours indicate issues with the optimization process or parameterization scheme.

**3 first experiments**:
1. Verify shape generation by testing the method on simple geometric shapes (circle, square)
2. Test classification performance using shapes as inputs to various DNN architectures
3. Evaluate the precision of salient region isolation compared to Grad-CAM on benchmark datasets

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity requiring approximately 2000 iterations for convergence
- Limited generalizability testing across diverse vision model architectures
- Uncertainty about performance when scaling to more complex datasets or real-world scenarios

## Confidence
- **High**: Geometric fidelity of learned shapes with sharp boundaries
- **Medium**: Generalizability of adversarial attack results across three detector architectures
- **Low**: Performance on real-world applications and scalability to larger, more diverse datasets

## Next Checks
1. Conduct extensive cross-architecture testing with additional vision models beyond the three currently evaluated
2. Perform ablation studies to determine the relative importance of Fourier series parameterization versus alternative contour representations
3. Evaluate computational efficiency improvements achievable through second-order optimization or other acceleration techniques while maintaining shape quality