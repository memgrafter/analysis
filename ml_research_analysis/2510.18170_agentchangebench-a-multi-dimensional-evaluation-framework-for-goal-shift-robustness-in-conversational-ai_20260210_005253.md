---
ver: rpa2
title: 'AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift
  Robustness in Conversational AI'
arxiv_id: '2510.18170'
source_url: https://arxiv.org/abs/2510.18170
tags:
- tool
- user
- goal
- evaluation
- airline
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'AgentChangeBench introduces the first multi-dimensional evaluation
  framework for measuring how conversational AI agents adapt to mid-dialogue goal
  shifts. The benchmark spans 315 tasks across banking, retail, and airline domains
  with five distinct user personas, evaluating agents through four complementary metrics:
  Task Success Rate (TSR), Tool Use Efficiency (TUE), Tool Call Redundancy Rate (TCRR),
  and Goal-Shift Recovery Time (GSRT).'
---

# AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI

## Quick Facts
- arXiv ID: 2510.18170
- Source URL: https://arxiv.org/abs/2510.18170
- Reference count: 40
- Agents achieve 92.2% recovery on airline shifts but only 48.6% with Gemini; retail tasks show near-perfect parameter validity yet redundancy rates exceeding 80%.

## Executive Summary
AgentChangeBench introduces the first multi-dimensional evaluation framework for measuring how conversational AI agents adapt to mid-dialogue goal shifts. The benchmark spans 315 tasks across banking, retail, and airline domains with five distinct user personas, evaluating agents through four complementary metrics: Task Success Rate (TSR), Tool Use Efficiency (TUE), Tool Call Redundancy Rate (TCRR), and Goal-Shift Recovery Time (GSRT). Experiments with frontier models reveal significant performance variations obscured by traditional pass@k scores, demonstrating that high raw accuracy does not guarantee robustness under dynamic goals.

## Method Summary
The framework uses τ²-bench evaluation harness with a user simulator that enacts persona-driven responses and goal transitions. Agents make tool calls for each domain (banking: 5 tools, retail: 5 tools, airline: 7 tools) and an evaluator computes four metrics. The Task Success Rate combines communication quality (using gpt-4o-mini as judge) with action accuracy and natural language assertion. Tool Use Efficiency measures correctness and parameter accuracy of tool calls. TCRR tracks duplicate calls within 3-turn windows. GSRT measures turns from shift to acknowledgment. Three independent runs per task ensure statistical validity.

## Key Results
- GPT-4o achieves 92.2% recovery on airline booking shifts while Gemini drops to 48.6%
- Retail tasks show near-perfect parameter validity yet redundancy rates exceeding 80%
- High raw accuracy does not guarantee robustness under dynamic goals
- Performance variations across models are significant and masked by traditional pass@k scores

## Why This Works (Mechanism)
The framework captures goal-shift robustness by combining multiple evaluation dimensions that expose different failure modes. TSR measures whether agents complete the full task sequence including communication quality, while TUE evaluates technical correctness of tool usage. TCRR identifies inefficiency in repeated tool calls, and GSRT quantifies responsiveness to change. This multi-dimensional approach reveals that models excelling at static tasks often struggle with dynamic goal adaptation.

## Foundational Learning
- **Multi-dimensional evaluation**: Why needed - single metrics like pass@k miss robustness aspects. Quick check - compare TSR vs raw accuracy across models.
- **Tool call redundancy tracking**: Why needed - identifies inefficient agent behavior. Quick check - verify TCRR calculation on sample duplicate calls.
- **Goal-shift recovery time measurement**: Why needed - quantifies responsiveness to change. Quick check - confirm GSRT counts turns from shift to acknowledgment.
- **LLM-as-judge communication scoring**: Why needed - objective assessment of information quality. Quick check - test judge consistency on sample tool outputs.
- **Persona-driven user simulation**: Why needed - creates realistic interaction patterns. Quick check - verify persona responses trigger expected goal sequences.
- **Three-run replication**: Why needed - ensures statistical reliability. Quick check - compute standard deviation across runs for key metrics.

## Architecture Onboarding
- **Component map**: User Simulator -> Agent -> Tool API -> Evaluator -> LLM Judge -> Metrics
- **Critical path**: User simulator sends goal sequence -> agent makes tool calls -> evaluator computes TSR/TUE/TCRR/GSRT -> LLM judge scores communication
- **Design tradeoffs**: Explicit goal sequences vs implicit detection (current: explicit for control), 3-turn window for TCRR (vs longer windows), gpt-4o-mini for judge (vs more expensive models)
- **Failure signatures**: High TCRR (>80%) indicates repeated tool calls; Low GSRT recovery (<50%) suggests failure to acknowledge shifts; Communication subscore collapse with high action accuracy indicates over-confirmation
- **First experiments**: 1) Run baseline evaluation on GPT-4o to verify metric ranges, 2) Test TCRR threshold with known duplicate scenarios, 3) Validate GSRT measurement on explicit goal shift tasks

## Open Questions the Paper Calls Out
- **Implicit goal drift detection**: The authors state they "do not yet evaluate detection of implicit goal drift" and that shifts are "often explicitly signaled." A comparative study measuring GSRT on a modified dataset featuring latent shifts versus the current explicit baseline would resolve this.
- **Adversarial user personas**: Current personas are "relatively benign" and do not "stress adversarial, deceptive, [or] hostile... behaviors." Evaluation of models on a new task set including adversarial personas to observe changes in transfer rates would address this gap.
- **State-tracking architecture improvements**: Retail tasks achieve near-perfect parameter validity but redundancy rates exceeding 80%, indicating a specific failure in efficiency. Ablation studies on agents equipped with explicit state management or caching layers running on the retail subset to measure TCRR reduction would test this.

## Limitations
- Missing exact user simulator prompts for five personas limits reproducibility
- Tool API implementations and parameter schemas not fully detailed
- No evaluation of implicit goal drift detection
- Current personas focus on cooperation rather than adversarial behavior

## Confidence
- **Multi-dimensional robustness findings**: High - consistent performance variations across metrics and domains clearly demonstrated
- **Absolute metric values**: Medium - depend on exact implementation details of missing components
- **Conclusion about pass@k inadequacy**: High - well-supported by presented evidence

## Next Checks
1. Request or reconstruct the exact user simulator prompts for all five personas from the authors to ensure persona consistency
2. Validate TCRR metric implementation by testing known duplicate tool call scenarios and verifying the 3-turn window threshold behavior
3. Cross-validate GSRT measurements by manually reviewing a sample of goal shift acknowledgments to confirm they occur before subsequent tool calls