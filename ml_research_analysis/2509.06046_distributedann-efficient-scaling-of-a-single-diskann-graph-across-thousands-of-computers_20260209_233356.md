---
ver: rpa2
title: 'DISTRIBUTEDANN: Efficient Scaling of a Single DISKANN Graph Across Thousands
  of Computers'
arxiv_id: '2509.06046'
source_url: https://arxiv.org/abs/2509.06046
tags:
- search
- index
- distributedann
- graph
- vectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DISTRIBUTEDANN addresses the challenge of serving large-scale vector
  search on datasets that cannot fit in a single machine's memory by distributing
  a single logical graph index across thousands of machines using a distributed key-value
  store. The approach modifies DISKANN's graph index layout to enable efficient distributed
  serving, including duplicating compressed vectors into graph nodes, introducing
  an in-memory head index for fast traversal initiation, and implementing near-data
  computation for scoring candidates.
---

# DISTRIBUTEDANN: Efficient Scaling of a Single DISKANN Graph Across Thousands of Computers

## Quick Facts
- **arXiv ID:** 2509.06046
- **Source URL:** https://arxiv.org/abs/2509.06046
- **Reference count:** 9
- **Primary result:** Achieved 26ms median query latency and processed over 100,000 queries per second on a 50-billion vector dataset, representing 6x more efficiency than conventional partitioning approaches.

## Executive Summary
DISTRIBUTEDANN addresses the challenge of serving large-scale vector search on datasets that cannot fit in a single machine's memory by distributing a single logical graph index across thousands of machines using a distributed key-value store. The approach modifies DISKANN's graph index layout to enable efficient distributed serving, including duplicating compressed vectors into graph nodes, introducing an in-memory head index for fast traversal initiation, and implementing near-data computation for scoring candidates. The system uses an orchestration service to manage multi-hop searches across distributed nodes. Evaluated on a 50-billion vector web search dataset, DISTRIBUTEDANN achieved 26ms median query latency and processed over 100,000 queries per second, representing 6x more efficiency than conventional partitioning approaches. The system delivered 7.8 and 4.5 percentage point improvements in recall@5 and recall@200 respectively compared to previous production systems, while maintaining graceful degradation under partial failures.

## Method Summary
DISTRIBUTEDANN scales DISKANN to massive datasets by storing a unified graph index across thousands of machines in a distributed key-value store. The approach involves building clustered partitions independently, then stitching them together by merging neighbor lists for overlapping vectors. The system duplicates compressed OPQ vectors (64 bytes) into graph nodes to reduce network round-trips, implements a sharded in-memory head index over the top graph layers for fast entry points, and performs near-data computation where scoring happens on storage nodes. An orchestration service manages the multi-hop beam search traversal, with the system supporting graceful degradation under partial failures.

## Key Results
- Achieved 26ms median query latency and processed over 100,000 queries per second on a 50-billion vector dataset
- Delivered 7.8 and 4.5 percentage point improvements in recall@5 and recall@200 respectively compared to previous production systems
- Demonstrated 6x efficiency improvement over conventional partitioning approaches with graceful degradation under partial failures

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Duplicating compressed vector representations (OPQ codes) directly into graph nodes reduces query latency by minimizing network round-trips required for scoring.
- **Mechanism**: By embedding compressed vectors inside graph nodes, the system performs scoring immediately upon retrieving a node, reducing read operations per search to the IO limit I.
- **Core assumption**: Storage amplification is an acceptable trade-off for lower latency, with the paper noting a ~10x space amplification for specific parameters.
- **Evidence anchors**: The abstract states this duplication "reduces network round-trips," and Section 2.2 confirms it "reduces the number of read operations per search to I."

### Mechanism 2
- **Claim**: An in-memory "Head Index" decouples initial graph traversal from the higher latency of the distributed key-value store.
- **Mechanism**: The top layers of the graph are cached in a dense, in-memory index on the orchestrator, allowing queries to find optimal entry points before touching the slower distributed store.
- **Core assumption**: The "head" of the graph fits in memory and provides good entry points for the full graph.
- **Evidence anchors**: The abstract mentions "creating a small in-memory 'head index' for fast initial traversal," and Section 2.2 describes building "a conventional sharded in-memory ANN index over these" top layers.

### Mechanism 3
- **Claim**: Near-data computation reduces network bandwidth consumption and serial compute latency.
- **Mechanism**: Instead of pulling full graph nodes across the network to the orchestrator for scoring, the orchestrator sends the query to storage nodes which score locally and return only results.
- **Core assumption**: Storage nodes have spare CPU cycles to handle scoring logic while the network is the bottleneck.
- **Evidence anchors**: The abstract states "implementing near-data computation where scoring happens on the same machines storing the data," and Section 2.3 explains this approach "only transmit[s] scores over the network instead of full nodes."

## Foundational Learning

- **Concept**: **Product Quantization (PQ/OPQ)**
  - **Why needed here**: Understanding OPQ is required to grasp why "duplicating compressed vectors" is cheaper than duplicating raw vectors and how distance tables work.
  - **Quick check question**: How does storing an OPQ code inside a graph node allow the system to calculate a distance without fetching the full precision vector?

- **Concept**: **Graph-based ANN (Beam Search/Vamana)**
  - **Why needed here**: The system is essentially a distributed Vamana/DISKANN graph, requiring understanding of greedy beam search to see why "hops" and "entry points" matter for latency.
  - **Quick check question**: Why does reducing the number of "hops" (iterations) directly lower the number of network round-trips in a distributed graph?

- **Concept**: **Distributed Key-Value (KV) Stores & Sharding**
  - **Why needed here**: DISTRIBUTEDANN treats the KV store as a "virtual disk," requiring understanding of consistent hashing or sharding to see how the system locates graph nodes across thousands of machines.
  - **Quick check question**: If a graph node points to a neighbor on a different machine, how does the KV store abstraction retrieve it transparently?

## Architecture Onboarding

- **Component map**: Orchestration Service -> Head Index -> Distributed KV Store (Node Storage) -> Node Scoring Service
- **Critical path**:
  1. Query Ingestion: Orchestrator receives query
  2. Head Search: Orchestrator queries Head Index → gets entry point IDs
  3. Distributed Traversal (Loop):
     - Orchestrator sends batch of candidate IDs to KV Store
     - Node Scoring Service on KV hosts retrieves nodes, computes distances locally
     - Hosts return sorted IDs/distances
     - Orchestrator merges results, updates heaps, determines next hop batch
  4. Result: Return top k results after H iterations

- **Design tradeoffs**:
  - Space vs. Latency: The ~10x storage amplification (duplicating PQ codes) buys lower latency (fewer lookups)
  - Recall vs. Reliability: The system allows partial failures (timing out node scoring requests), ensuring low tail latency but gracefully lowering recall

- **Failure signatures**:
  - Head Index CPU Saturation: If the Head Index hits CPU limits, query throughput stalls regardless of KV store capacity
  - Graceful Recall Degradation: If network issues cause packet loss/timeouts, queries succeed but recall drops proportionally to failure rate
  - Stitching Artifacts: During index building, if graph stitching fails to merge partitions correctly, the unified graph may have disconnected components

- **First 3 experiments**:
  1. IO Distribution Analysis: Profile a single query to verify that DISTRIBUTEDANN touches a more flexible set of clusters compared to the rigid "fixed IO per partition" of the legacy system
  2. Failure Injection: Intentionally drop Node Scoring requests (simulate 1-4% failure rate) to validate the linear "graceful degradation" curve of recall
  3. Scaling Head Index: Run a load test where the Head Index is under-provisioned to observe if it becomes the bottleneck before the Node Scoring Service

## Open Questions the Paper Calls Out

- **Question**: How does DISTRIBUTEDANN compare empirically to advanced graph partitioning schemes regarding latency and operational load balancing?
  - **Basis in paper**: [explicit] The authors state in Section 4.4 that "Further work is needed to compare the empirical performance of these approaches and DISTRIBUTEDANN," specifically referencing recent work on reducing cross-partition edges.
  - **Why unresolved**: The paper only benchmarks DISTRIBUTEDANN against a conventional "Clustered Partitioning" approach, omitting comparisons to more sophisticated partitioning methods.
  - **What evidence would resolve it**: A comparative benchmark analyzing recall/latency tradeoffs and load distribution between DISTRIBUTEDANN and schemes like those proposed by Dong et al. (2019) or Gottesbüren et al. (2024).

- **Question**: Can co-locating multiple full-dimension vectors within a single graph node effectively reduce the 10x storage amplification overhead?
  - **Basis in paper**: [explicit] Section 5.1 notes that "A significant reduction in space overhead is likely possible by placing multiple nearby full-dimension vectors into a single graph node, but further experimentation is needed to understand the tradeoffs."
  - **Why unresolved**: The current design duplicates compressed vectors into every graph node to save network round-trips, creating high space amplification; grouping vectors alters the fundamental graph structure and traversal logic.
  - **What evidence would resolve it**: Experimental results showing the index size reduction and corresponding impact on query latency and recall when implementing vector grouping.

- **Question**: Is serving the in-memory "head index" on GPUs cost-effective compared to simply increasing the number of CPU-based replicas?
  - **Basis in paper**: [explicit] Section 5.1 suggests, "It may be cost-effective to serve this index from GPU rather than increasing the number of replicas to serve more traffic."
  - **Why unresolved**: The head index becomes CPU-bound at high query throughput (Section 4.1), but the paper does not quantify the economic or performance tradeoffs of offloading this specific component to GPU hardware.
  - **What evidence would resolve it**: A cost-performance analysis comparing the throughput scaling of a GPU-accelerated head index against the current horizontal scaling strategy.

## Limitations

- The 10x storage amplification from compressed vector duplication may become prohibitive for higher-dimensional vectors or larger graph degrees
- The system's graceful degradation under failure assumes uniform query distribution and may not hold for highly skewed workloads
- The reliance on near-data computation assumes storage nodes have sufficient CPU headroom, which may not be true in resource-constrained deployments

## Confidence

- **High confidence**: The core architectural approach (distributed KV store + head index + near-data scoring) is well-grounded in existing distributed systems literature and the paper provides clear implementation details for each component
- **Medium confidence**: Performance metrics (26ms latency, 100k QPS) are impressive but may be environment-specific, depending on the KV store configuration and network topology not fully disclosed in the paper
- **Medium confidence**: The 6x efficiency improvement over conventional partitioning assumes the baseline implementation is equivalent to the authors' production system, which may not be generalizable

## Next Checks

1. **Storage cost validation**: Implement a cost model comparing the 10x storage amplification against the latency gains for different vector dimensions (d=128, d=512, d=1024) and graph degrees (R=64, R=128) to determine the breaking point where space overhead negates latency benefits

2. **Failure mode stress testing**: Create a synthetic workload with realistic query skew (e.g., power-law distribution) and systematically inject network failures at different rates (1%, 5%, 10%) to verify whether the graceful degradation curve holds under non-uniform access patterns

3. **CPU saturation analysis**: Instrument the system to monitor CPU utilization on storage nodes during peak load, then artificially constrain CPU resources to determine the actual throughput ceiling when near-data computation becomes the bottleneck rather than network bandwidth