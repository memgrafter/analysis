---
ver: rpa2
title: 'Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse'
arxiv_id: '2410.22598'
source_url: https://arxiv.org/abs/2410.22598
tags:
- features
- feature
- explanations
- responsive
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce feature responsiveness scores to address
  limitations of standard feature attribution methods like SHAP and LIME, which can
  highlight features that do not provide recourse. Their approach measures the probability
  that a decision subject can attain a target prediction by intervening on a specific
  feature, considering actionability constraints and downstream effects.
---

# Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse

## Quick Facts
- **arXiv ID:** 2410.22598
- **Source URL:** https://arxiv.org/abs/2410.22598
- **Reference count:** 40
- **Primary result:** Feature responsiveness scores identify actionable features for recourse better than standard methods like SHAP

## Executive Summary
Standard feature attribution methods like SHAP and LIME often highlight features that cannot provide recourse for decision subjects, limiting their utility for actionable explanations. The authors introduce feature responsiveness scores, which measure the probability that intervening on a specific feature will achieve a target prediction while respecting actionability constraints and downstream effects. Their approach provides model-agnostic explanations that are both interpretable and actionable, addressing a critical gap in existing explanation methods.

## Method Summary
The authors develop a framework for computing feature responsiveness scores that captures both the probability of achieving recourse through feature intervention and the downstream effects on other features. They introduce efficient sampling and enumeration algorithms to compute these scores for arbitrary models. The method can identify when predictions are fixed (no recourse possible) and provide informative explanations even in these cases. By explicitly modeling actionability constraints and feature interdependencies, their approach ensures that highlighted features are genuinely responsive to interventions.

## Key Results
- On the heloc dataset, achieved 100% responsive features in explanations versus 0.2% for SHAP-AW
- Reduced proportion of cases lacking actionable features from 94% to 8% by including intervention information
- Successfully identified fixed predictions where no recourse was possible

## Why This Works (Mechanism)
Feature responsiveness scores work by directly modeling the probability of achieving recourse through specific feature interventions, rather than simply measuring feature importance for the current prediction. The method accounts for actionability constraints (which features can actually be changed) and downstream effects (how changing one feature affects others). This probabilistic approach ensures that highlighted features are not only important but also genuinely responsive to intervention, providing actionable guidance for decision subjects seeking to change their outcomes.

## Foundational Learning
- **Feature importance vs. recourse**: Standard attribution methods measure importance for current predictions, but recourse requires understanding which features enable prediction changes - needed to bridge gap between explanation and action
- **Actionability constraints**: Not all features can be practically changed; modeling which features are actionable is essential for useful explanations - check by verifying intervention feasibility
- **Downstream effects**: Changing one feature can affect others; modeling these dependencies ensures realistic recourse paths - verify through causal analysis
- **Fixed predictions**: Some predictions have no possible recourse; identifying these cases prevents futile intervention attempts - validate by exhaustive search when feasible

## Architecture Onboarding
**Component map:** Input features -> Actionability constraints -> Model predictions -> Feature responsiveness scores -> Actionable explanations

**Critical path:** The core computation involves sampling possible interventions, evaluating model responses, and aggregating probabilities to compute feature responsiveness scores.

**Design tradeoffs:** The method trades computational complexity for more actionable explanations, using sampling to approximate exact enumeration when feature spaces are large.

**Failure signatures:** If actionability constraints are too restrictive or downstream effects are not properly modeled, the method may miss viable recourse paths or suggest impossible interventions.

**First experiments:** 1) Compare feature responsiveness scores against SHAP on simple linear models, 2) Test identification of fixed predictions on datasets with clear recourse limitations, 3) Evaluate computational efficiency on datasets with varying feature dimensions.

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Experimental validation limited to three lending datasets with binary classification tasks
- Comparison focuses primarily on SHAP-AW, not broader range of counterfactual methods
- Computational costs for high-dimensional feature spaces not thoroughly evaluated

## Confidence
- **High confidence:** Theoretical framework for feature responsiveness scores is sound and well-defined
- **Medium confidence:** Experimental results showing improved feature responsiveness identification
- **Low confidence:** Claims about computational efficiency for arbitrary models without extensive empirical validation

## Next Checks
1. Test the approach on non-lending domains (e.g., healthcare or education) with different prediction tasks
2. Conduct ablation studies comparing against a broader set of counterfactual explanation methods beyond SHAP-AW
3. Evaluate computational scalability on high-dimensional datasets with 50+ features to verify claimed efficiency