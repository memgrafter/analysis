---
ver: rpa2
title: 'Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded
  Devices: A Survey'
arxiv_id: '2510.00078'
source_url: https://arxiv.org/abs/2510.00078
tags:
- arxiv
- dynamic
- memory
- preprint
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides the first systematic characterization of adaptive
  and resource-efficient agentic AI systems for mobile and embedded devices. It addresses
  the fundamental tension between the growing complexity of foundation models and
  the limited resources of deployment environments by proposing a unified taxonomy
  spanning elastic inference, test-time adaptation, dynamic multimodal integration,
  and agentic AI applications.
---

# Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded Devices: A Survey

## Quick Facts
- arXiv ID: 2510.00078
- Source URL: https://arxiv.org/abs/2510.00078
- Authors: Sicong Liu; Weiye Wu; Xiangrui Xu; Teng Li; Bowen Pang; Bin Guo; Zhiwen Yu
- Reference count: 40
- One-line primary result: First systematic characterization of adaptive and resource-efficient agentic AI systems for mobile and embedded devices, proposing a unified taxonomy and identifying key challenges in accuracy-latency-communication trade-offs.

## Executive Summary
This survey addresses the fundamental tension between the growing complexity of foundation models and the limited resources of mobile and embedded deployment environments. It provides a comprehensive framework for scalable, adaptive, and resource-efficient agentic AI systems, balancing user goals with dynamic device constraints through real-time adjustment of model structure, reasoning depth, and resource allocation. The work identifies key challenges in accuracy-latency-communication trade-offs and robustness under distribution shifts while highlighting future opportunities in algorithm-system co-design, cognitive adaptation, and collaborative edge deployment.

## Method Summary
The survey employs a systematic characterization approach, mapping enabling techniques for adaptive and resource-efficient agentic AI systems onto a unified hardware-software spectrum. It organizes the field into four main categories: elastic inference, test-time adaptation, dynamic multimodal integration, and agentic AI applications. The methodology involves analyzing the fundamental tensions between foundation model complexity and deployment environment limitations, identifying key trade-offs, and proposing a comprehensive framework for addressing these challenges through real-time adaptation strategies.

## Key Results
- Proposed unified taxonomy spanning elastic inference, test-time adaptation, dynamic multimodal integration, and agentic AI applications
- Identified key challenges in accuracy-latency-communication trade-offs and robustness under distribution shifts
- Mapped enabling techniques into a hardware-software spectrum with focus on algorithm-system co-design opportunities

## Why This Works (Mechanism)
The survey works by systematically organizing the complex landscape of adaptive and resource-efficient agentic AI systems into a coherent framework that addresses the fundamental resource constraints of mobile and embedded devices. By mapping techniques across a hardware-software spectrum and identifying key trade-offs, it provides a structured approach to understanding how to balance model complexity with deployment limitations through real-time adaptation.

## Foundational Learning

1. **Foundation Model Complexity vs. Edge Resource Constraints**
   - Why needed: Understanding this fundamental tension is crucial for developing practical deployment strategies
   - Quick check: Verify that proposed techniques address specific resource limitations (memory, compute, power) of target edge devices

2. **Hardware-Software Co-Design Principles**
   - Why needed: Effective adaptation requires coordination between algorithm optimizations and hardware capabilities
   - Quick check: Assess whether techniques leverage hardware-specific features (e.g., accelerators, heterogeneous computing)

3. **Real-time Adaptation Mechanisms**
   - Why needed: Dynamic environments require systems that can adjust to changing conditions and constraints
   - Quick check: Evaluate the latency overhead of adaptation mechanisms and their impact on user experience

## Architecture Onboarding

**Component Map:**
Elastic Inference Techniques -> Test-time Adaptation Mechanisms -> Dynamic Multimodal Integration -> Agentic AI Applications -> Resource Management Layer

**Critical Path:**
Model Structure Adjustment → Reasoning Depth Optimization → Resource Allocation → User Goal Alignment

**Design Tradeoffs:**
- Accuracy vs. Latency: Higher accuracy typically requires more computation, increasing latency
- Model Complexity vs. Resource Utilization: Complex models provide better performance but consume more resources
- Static vs. Dynamic Adaptation: Static approaches are simpler but less responsive to changing conditions

**Failure Signatures:**
- Performance degradation under distribution shifts
- Resource exhaustion during peak usage periods
- Communication bottlenecks in collaborative edge scenarios
- Inaccurate user goal alignment due to insufficient context understanding

**First 3 Experiments:**
1. Deploy elastic inference techniques on heterogeneous edge devices with varying workloads to measure accuracy-latency trade-offs
2. Implement test-time adaptation mechanisms under simulated distribution shifts to evaluate robustness
3. Create multi-modal integration scenarios with dynamic resource allocation to assess system responsiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Claim to be "first systematic characterization" may not account for recent developments outside surveyed timeframe
- Proposed taxonomy may not fully capture emerging hybrid approaches that span multiple categories
- Real-world deployment scenarios may involve more complex competing objectives than theoretical framework suggests

## Confidence

- **High Confidence**: Fundamental tensions between foundation model complexity and deployment environment limitations are well-established
- **Medium Confidence**: Unified taxonomy provides useful organizing framework but completeness remains to be validated
- **Low Confidence**: Future opportunities in cognitive adaptation and collaborative edge deployment are speculative without concrete implementation details

## Next Checks
1. Conduct systematic literature review with expanded search parameters to verify first systematic characterization claim
2. Implement subset of taxonomy categories across diverse edge devices to empirically validate hardware-software spectrum mapping
3. Design case study deploying agentic AI systems on heterogeneous edge devices under realistic distribution shifts to assess practical validity