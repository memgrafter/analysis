---
ver: rpa2
title: 'Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications'
arxiv_id: '2511.14769'
source_url: https://arxiv.org/abs/2511.14769
tags:
- retrieval
- documents
- query
- coinbase
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Cluster-based Adaptive Retrieval (CAR) addresses the problem of
  static top-k retrieval in RAG systems, which often fails to adapt to query complexity,
  leading to either insufficient context or redundant information. CAR dynamically
  determines the optimal number of documents by analyzing clustering patterns in ranked
  query-document similarity distances, detecting natural breakpoints where relevance
  shifts.
---

# Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications

## Quick Facts
- **arXiv ID:** 2511.14769
- **Source URL:** https://arxiv.org/abs/2511.14769
- **Reference count:** 34
- **Primary result:** Dynamic retrieval that adapts context size based on query complexity, improving RAG performance and efficiency

## Executive Summary
Cluster-based Adaptive Retrieval (CAR) addresses the fundamental challenge of static top-k retrieval in RAG systems, where fixed document limits often fail to match query complexity. By analyzing clustering patterns in ranked query-document similarity distances, CAR dynamically determines optimal context sizes through natural relevance breakpoints. The system achieves significant improvements in production environments, including reduced token usage, lower latency, and decreased hallucinations while maintaining answer quality.

## Method Summary
CAR introduces a dynamic retrieval approach that moves beyond static top-k selection by analyzing the similarity landscape between queries and retrieved documents. The core innovation lies in detecting natural clustering patterns in ranked similarity distances, where sharp changes indicate transitions between relevant and less relevant documents. This breakpoint detection mechanism allows the system to adapt context size based on query complexity, providing more documents for complex queries while limiting redundancy for simpler ones. The approach is evaluated on both academic benchmarks and production datasets, demonstrating consistent improvements across multiple performance metrics.

## Key Results
- Consistently achieves highest TES scores on MultiHop-RAG benchmark, outperforming fixed top-k baselines
- Reduces LLM token usage by 60% in production RAG evaluations while preserving answer relevance
- Cuts end-to-end latency by 22% and reduces hallucinations by 10% in Coinbase's virtual assistant deployment
- User engagement increases by 200% following CAR deployment in production environment

## Why This Works (Mechanism)
CAR works by recognizing that query complexity varies significantly, making static top-k retrieval inefficient. The mechanism analyzes the distribution of similarity scores between queries and ranked documents, identifying natural clustering patterns where relevance changes. By detecting breakpoints where similarity drops sharply, the system can dynamically determine the optimal number of documents to include, ensuring sufficient context for complex queries while avoiding redundancy in simpler cases.

## Foundational Learning
- **Query-document similarity analysis:** Understanding how queries relate to documents through similarity metrics is essential for determining relevance boundaries
- **Clustering breakpoint detection:** Identifying sharp transitions in similarity distributions allows for dynamic context sizing
- **RAG pipeline optimization:** Adaptive retrieval reduces unnecessary token consumption and improves response efficiency
- **Relevance assessment metrics:** TES (Trust, Efficiency, Satisfaction) scores provide comprehensive evaluation beyond traditional accuracy measures
- **Production performance monitoring:** Real-world metrics like latency, token usage, and hallucination rates are critical for system validation

## Architecture Onboarding
**Component Map:** Query -> Similarity Scoring -> Ranking -> Clustering Analysis -> Breakpoint Detection -> Document Selection -> LLM Processing

**Critical Path:** The most critical components are the similarity scoring and clustering analysis stages, as they directly determine context selection quality and downstream performance impacts.

**Design Tradeoffs:** CAR trades computational overhead for adaptive precision, requiring real-time clustering analysis but avoiding over/under-fetching issues of static approaches.

**Failure Signatures:** Poor breakpoint detection leads to either excessive document retrieval (token waste, latency) or insufficient context (incomplete answers, hallucinations).

**First Experiments:**
1. Test clustering breakpoint detection on benchmark datasets with varying query complexity
2. Compare CAR's adaptive retrieval against fixed top-k baselines on TES score
3. Measure production performance impacts (token usage, latency, hallucination rates)

## Open Questions the Paper Calls Out
None

## Limitations
- Production performance claims rely on proprietary internal evaluations rather than peer-reviewed publication
- User engagement increase correlation with CAR deployment may not establish direct causation
- Implementation details and evaluation methodology are not fully disclosed for independent verification

## Confidence
- **High confidence:** MultiHop-RAG benchmark TES score improvements are reproducible with standard evaluation protocols
- **Medium confidence:** Production token reduction and latency improvement claims based on internal Coinbase evaluations
- **Low confidence:** 200% user engagement increase post-deployment conflates correlation with causation

## Next Checks
1. Independent replication of the clustering breakpoint detection algorithm on open-source retrieval datasets to verify performance improvements
2. A/B testing framework analysis to isolate CAR's specific contribution to user engagement metrics versus other system changes
3. Publication of implementation details and evaluation methodology to enable community verification of production performance claims