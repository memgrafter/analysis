---
ver: rpa2
title: A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path Planning
  in Spatiotemporal Dynamics
arxiv_id: '2510.21695'
source_url: https://arxiv.org/abs/2510.21695
tags:
- mission
- plane
- agent
- data
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of translating high-level mission
  objectives into actionable plans for autonomous agents in dynamic environments.
  The authors propose a Knowledge Graph (KG)-based translation layer that decouples
  mission semantics from a domain-agnostic planner.
---

# A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path Planning in Spatiotemporal Dynamics

## Quick Facts
- arXiv ID: 2510.21695
- Source URL: https://arxiv.org/abs/2510.21695
- Reference count: 32
- Authors: Edward Holmberg; Elias Ioup; Mahdi Abdelguerfi
- One-line primary result: KG-based translation layer enables mission-aware multi-agent path planning with 22.5% reward spread across declarative policies.

## Executive Summary
This paper introduces a Knowledge Graph (KG)-based translation layer that decouples mission semantics from domain-agnostic planners, enabling autonomous agents to execute complex missions in dynamic spatiotemporal environments. The two-plane architecture (Data Plane and Control Plane) compiles declarative facts into per-agent "worldviews" and physics-aware traversal rules, allowing different policies to produce distinct high-performing outcomes. A case study with Autonomous Underwater Vehicles in the Gulf of Mexico demonstrates the framework's effectiveness in generating coordinated paths that adapt to changing mission objectives.

## Method Summary
The method employs a two-plane Knowledge Graph architecture where Φ2 (Data Plane) compiles declarative facts into per-agent mission tensors through layer blending and confidence scaling, while Φ1 (Control Plane) generates seam feasibility rules and navigation graphs. The system uses HYCOM ocean current data, SST-derived frontness layers, and spatial constraints to populate the KG schema, then applies Viterbi-style dynamic programming to stitch per-window micro-paths into long-horizon plans. Agent policies are encoded as weighted combinations of value layers, constraints, and physics-based costs, with greedy coordination resolving conflicts. The KG's provenance tracking enables incremental recompilation of only affected time windows when mission facts change.

## Key Results
- Mission reward spread of 22.5% across five declarative policies (1407.0 to 1725.0)
- KG-based translation successfully decouples mission semantics from domain-agnostic planning
- Different declarative policies produce measurably distinct agent behaviors
- Fast replanning enabled by dirty-window tracking in KG structure

## Why This Works (Mechanism)

### Mechanism 1: Two-Plane Compilation Decouples Semantics from Optimization
Separating mission context (Data Plane) from coordination logic (Control Plane) allows a domain-agnostic planner to serve multiple mission types by compiling declarative facts into numerical artifacts—Φ2 generates per-agent mission tensors while Φ1 generates traversal feasibility rules and seam costs.

### Mechanism 2: Declarative Policies Induce Distinct Agent Behaviors
Changing declarative KG facts (policy weights, constraint definitions) produces measurably different mission outcomes without code changes, as each agent's Policy node stores weights that control layer blending, constraint attenuation, and cost tradeoffs.

### Mechanism 3: Dirty-Window Tracking Enables Fast Replanning
The KG's structured provenance allows incremental recompilation of only affected time windows when facts change, identifying dependent artifacts via prov:wasDerivedFrom links and flagging stale items for selective recompilation.

## Foundational Learning

- **Knowledge Graphs & Ontologies (OWL-Time, GeoSPARQL, PROV-O)**: Why needed here: The system's core innovation is representing mission context as typed, temporal graph entities with standardized spatial/temporal semantics. Quick check question: Can you write a SPARQL query that retrieves all TimeWindows with confidence < 0.5 and their derived TensorArtifacts?

- **Viterbi Algorithm / Dynamic Programming for Path Stitching**: Why needed here: The planner stitches per-window micro-paths into long-horizon plans using Viterbi-style optimization over the NavGraph. Quick check question: Explain why Viterbi is preferred over Dijkstra for the temporal stitching problem in this architecture.

- **Model Predictive Control (MPC) Concepts**: Why needed here: The framework uses receding-horizon replanning where only dirty windows are recomputed. Quick check question: What determines the replanning frequency in an MPC loop, and how does the KG's incrementality affect latency?

## Architecture Onboarding

- **Component map**: Input Layer (HYCOM NetCDF → KG adapters) -> KG Core (schema + compiled artifacts) -> Φ2 Compiler (layer blending → TensorArtifact) -> Φ1 Compiler (waypoint sampling → NavGraph + costs) -> Agnostic Planner (Viterbi stitching) -> Selector/Coordinator (greedy deconfliction → Assignments to KG)

- **Critical path**: Policy definition → KG population → Φ2 compilation (tensor fusion) → Φ1 compilation (NavGraph + costs) → Planner execution → Assignment commit. Latency dominated by Φ2 raster operations and Viterbi search.

- **Design tradeoffs**: Expressiveness vs. tractability (rich ontologies vs. compilation time); Centralized vs. distributed coordination (greedy selector vs. market-based auction); Provenance depth vs. storage (full prov:wasDerivedFrom vs. storage overhead).

- **Failure signatures**: Empty NavGraph (waypoint sampling finds no valid cells); Path reward collapse (agents converge to same waypoints); Replanning stalls (dirty-window tracking misses dependencies).

- **First 3 experiments**: 1) Schema validation: Ingest 7-window HYCOM data, run Φ2 compilation, verify TensorArtifact nodes exist with prov:wasDerivedFrom links. 2) Policy differentiation: Run planner with "naive" vs. "poi focus" policies; confirm NavGraph structures differ visually and rewards differ by >10%. 3) Replanning latency: Mid-mission, inject new hard constraint; measure wall-clock time for dirty-window identification + recompilation vs. full replan.

## Open Questions the Paper Calls Out

- Can market-based auction mechanisms in the Control Plane improve task allocation optimality compared to the current greedy selection method? (Future work: explore more sophisticated coordination strategies for optimal task allocation.)

- Can machine learning techniques effectively learn and optimize declarative policy weights automatically from historical mission outcomes? (Future work: incorporate ML to automatically learn policy weights from mission outcomes, closing the loop from execution back to strategy.)

- How can the ontology be extended to reason about path robustness and risk, rather than solely maximizing mission reward? (Future work: expand ontology to include uncertainty and risk concepts, allowing reasoning about robust paths.)

## Limitations

- No baseline comparisons against non-KG or pure tensor-based planners to validate the necessity of KG-based translation
- Physics-aware seam rules (Φ1) are not fully specified; correctness depends on unstated parameters for waypoint sampling and edge cost computation
- Static declarative policies may be insufficient for complex coordination requiring dynamic weight adjustment during execution

## Confidence

- **High confidence**: The two-plane architecture correctly separates data compilation (Φ2) from coordination logic (Φ1), and the incremental replanning mechanism via KG provenance is technically sound
- **Medium confidence**: The declarative policy framework produces distinct agent behaviors as claimed, but the extent of behavioral diversity relative to learned approaches is unclear
- **Low confidence**: The claim that KG-based translation is essential for mission-aware planning—no ablation against non-KG methods exists

## Next Checks

1. **Schema validation and provenance**: Ingest a minimal HYCOM dataset, populate the KG schema, and verify that TensorArtifacts correctly link to source ValueLayers via prov:wasDerivedFrom

2. **Policy differentiation test**: Run the planner with two contrasting policies (e.g., FAST vs. SAFE) and confirm that their intermediate heatmaps and final mission rewards differ by >10% as reported

3. **Incremental replanning benchmark**: Measure wall-clock time for dirty-window recompilation versus full regeneration when injecting a mid-mission constraint; quantify the speedup factor