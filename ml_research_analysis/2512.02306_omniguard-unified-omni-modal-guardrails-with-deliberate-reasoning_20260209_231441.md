---
ver: rpa2
title: 'OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning'
arxiv_id: '2512.02306'
source_url: https://arxiv.org/abs/2512.02306
tags:
- safety
- https
- omni-modal
- audio
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OmniGuard, the first family of unified omni-modal
  guardrail models designed to perform safety moderation across text, images, videos,
  and audio with deliberate reasoning. To support training, the authors construct
  a large-scale omni-modal safety dataset of over 210K samples, covering unimodal
  and cross-modal inputs, each annotated with safety labels, violation categories,
  and expert-generated reasoning critiques via targeted distillation.
---

# OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning

## Quick Facts
- **arXiv ID:** 2512.02306
- **Source URL:** https://arxiv.org/abs/2512.02306
- **Reference count:** 40
- **Primary result:** OmniGuard-7B outperforms strong baselines on 15 safety benchmarks with deliberate reasoning; OmniGuard-3B matches or exceeds much larger models like GPT-4o and Qwen3-235B.

## Executive Summary
This paper introduces OmniGuard, the first family of unified omni-modal guardrail models designed to perform safety moderation across text, images, videos, and audio with deliberate reasoning. To support training, the authors construct a large-scale omni-modal safety dataset of over 210K samples, covering unimodal and cross-modal inputs, each annotated with safety labels, violation categories, and expert-generated reasoning critiques via targeted distillation. OmniGuard employs mission-focused instruction tuning with a reasoning-augmented framework to enhance cross-modal generalization and explainability. Extensive experiments on 15 benchmarks show that OmniGuard-7B consistently outperforms strong baselines, including large-scale proprietary and open-source models, while OmniGuard-3B achieves competitive or superior performance compared to much larger models such as GPT-4o, Qwen3-235B, and Qwen3-VL-235B. The reasoning-based approach improves both performance and generalization in complex cross-modal safety scenarios.

## Method Summary
OmniGuard is built on Qwen2.5-Omni base models (7B and 3B parameters) and trained using supervised fine-tuning with a reasoning-augmented framework. The training data consists of 210K+ omni-modal safety samples from 17 sources across text, image, video, audio, and cross-modal domains. Each sample includes safety labels, violation categories, and distilled reasoning critiques generated by specialized teacher models. The training objective combines classification loss, category prediction loss, and critique generation loss, optimized via the SWIFT platform on 8×H100 GPUs. The reasoning framework aims to improve cross-modal generalization and explainability compared to label-only approaches.

## Key Results
- OmniGuard-7B achieves 79.6% F1 score, outperforming the Qwen2.5-Omni-7B baseline (73.1%) and strong open-source models on 15 safety benchmarks.
- OmniGuard-3B matches or exceeds much larger models including GPT-4o, Qwen3-235B, and Qwen3-VL-235B while using significantly fewer parameters.
- The reasoning-augmented approach improves cross-modal generalization, with 76.6% accuracy on Video-SafetyBench compared to 65.3% for label-only SFT.
- OmniGuard-7B outperforms LlamaGuard-3V on cross-modal tasks despite LlamaGuard-3V being 7× larger (17B vs 7B parameters).

## Why This Works (Mechanism)
OmniGuard works by integrating deliberate reasoning into the safety moderation process through targeted distillation from specialized teacher models. The reasoning-augmented framework forces the model to generate explicit explanations for safety judgments, which serves dual purposes: improving transparency and forcing deeper understanding of safety concepts across modalities. This approach is particularly effective for cross-modal scenarios where simple pattern matching would fail. The unified training on diverse modalities with explicit reasoning objectives enables the model to develop transferable safety reasoning capabilities rather than modality-specific heuristics.

## Foundational Learning
- **Cross-modal safety reasoning**: Understanding how safety concepts transfer between text, images, videos, and audio. *Why needed:* Safety issues often span multiple modalities (e.g., harmful text overlaid on images). *Quick check:* Test model on cross-modal benchmarks like MM-SafetyBench and Video-SafetyBench.
- **Reasoning distillation**: Using teacher models to generate explicit safety critiques that are then distilled into student models. *Why needed:* Pure classification lacks explainability and may not capture nuanced safety reasoning. *Quick check:* Compare performance of reasoning-augmented vs. label-only variants on cross-modal tasks.
- **Unified multimodal safety taxonomy**: Mapping diverse safety categories from 17 datasets into a coherent framework. *Why needed:* Different datasets use different violation category schemes that must be reconciled. *Quick check:* Verify category mapping consistency across all training samples.
- **Mission-focused instruction tuning**: Adapting general-purpose omni-modal models to safety-specific tasks through targeted fine-tuning. *Why needed:* Base omni-modal models lack specialized safety reasoning capabilities. *Quick check:* Compare against Qwen2.5-Omni baseline on safety benchmarks.

## Architecture Onboarding

**Component Map:** OmniGuard base model (Qwen2.5-Omni) -> SFT fine-tuning with reasoning augmentation -> Safety moderation outputs (label + categories + critique)

**Critical Path:** Input (any modality) → Instruction parsing → Safety assessment → Violation categorization → Reasoning critique generation → Output

**Design Tradeoffs:** The reasoning-augmented approach trades increased inference complexity for improved cross-modal generalization and explainability. The unified framework sacrifices some modality-specific optimization for broader coverage and transferability.

**Failure Signatures:** 
- Poor cross-modal generalization when reasoning components are absent (8-10% accuracy drop on cross-modal benchmarks)
- All-safe outputs on standalone images (LLaMA-Guard-3V exhibits this limitation)
- Degradation when leaving out training data for specific modalities (~2-4% F1 drop on unseen modalities)

**First 3 Experiments to Run:**
1. Train OmniGuard-7B with reasoning augmentation and evaluate on BeaverTails benchmark to verify basic functionality.
2. Implement label-only SFT ablation and compare cross-modal performance on Video-SafetyBench to confirm reasoning benefits.
3. Test cross-modal generalization by training without audio data and measuring performance degradation on WildGuard-TTS.

## Open Questions the Paper Calls Out
None

## Limitations
- Access to specialized teacher models (gpt-oss-120b, Qwen3-VL-235B-A22B-Instruct, Kimi-Audio-7B-Instruct) is required for targeted distillation and may not be publicly available.
- The complete policy guidelines G and violation category taxonomy C are not fully specified, making exact replication challenging.
- The methodology for mapping violation categories across 17 diverse datasets with different taxonomies is not detailed.

## Confidence
- **High confidence**: OmniGuard's architecture using reasoning-augmented instruction tuning for safety moderation, the 210K+ dataset aggregation from 17 sources, and the reported improvement over Qwen2.5-Omni-7B baseline (73.1%→79.6% F1) are well-supported by experimental design and methodology.
- **Medium confidence**: The claim that OmniGuard-3B outperforms much larger models like GPT-4o and Qwen3-235B requires careful scrutiny due to potential differences in teacher model access and implementation details that may not be fully reproducible.
- **Medium confidence**: The cross-modal generalization improvements (73.3%→76.6% accuracy on Video-SafetyBench) depend critically on the reasoning framework's effectiveness, which may vary with alternative teacher models or different policy interpretations.

## Next Checks
1. **Teacher model substitution validation**: Train OmniGuard using Qwen2.5-72B-Instruct (or similar available model) as the critique teacher instead of gpt-oss-120b, then compare critique quality and downstream safety performance on a subset of benchmarks to quantify the impact of teacher model differences.

2. **Policy guideline specification**: Request or reconstruct the complete violation category taxonomy C and policy guidelines G from the authors, then verify that all 17 source datasets have been correctly mapped to this unified category system through manual inspection of 50 randomly sampled training examples.

3. **Ablation on reasoning components**: Implement and train a label-only SFT variant (without reasoning critique generation) using identical hyperparameters, then measure performance degradation specifically on cross-modal benchmarks (Video-SafetyBench, MM-SafetyBench) to confirm the 8-10% accuracy drop reported in Figure 4.