---
ver: rpa2
title: 'OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use'
arxiv_id: '2508.04482'
source_url: https://arxiv.org/abs/2508.04482
tags:
- agents
- arxiv
- zhang
- wang
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive survey of OS Agents, which
  are (M)LLM-based agents that use computing devices (e.g., computers and mobile phones)
  by operating within the environments and interfaces (e.g., Graphical User Interface
  (GUI)) provided by operating systems (OS) to automate tasks. The survey covers the
  fundamentals of OS Agents, including their key components (environment, observation
  space, and action space) and essential capabilities (understanding, planning, and
  grounding).
---

# OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use

## Quick Facts
- arXiv ID: 2508.04482
- Source URL: https://arxiv.org/abs/2508.04482
- Reference count: 40
- Primary result: Comprehensive survey of OS Agents covering fundamentals, methodologies, evaluation protocols, and future research directions

## Executive Summary
This survey provides a comprehensive overview of OS Agents, which are MLLM-based agents that automate tasks by operating within operating system environments and interfaces. The paper systematically examines the key components and capabilities of OS Agents, including environment understanding, observation space, action space, and essential functions like understanding, planning, and grounding. It then reviews methodologies for constructing these agents, focusing on domain-specific foundation models and agent frameworks. The survey also analyzes evaluation protocols and benchmarks used to assess OS Agent performance across diverse tasks.

## Method Summary
The paper employs a systematic literature review approach to survey the field of OS Agents. It categorizes existing research based on agent architecture, methodologies, and evaluation frameworks. The survey methodology involves identifying key publications in the field, analyzing their contributions to OS Agent development, and synthesizing common patterns and approaches. The authors organize their findings around the fundamental components of OS Agents, their construction methodologies, and the protocols used to evaluate their effectiveness.

## Key Results
- Comprehensive coverage of OS Agent fundamentals including environment, observation space, and action space
- Detailed examination of domain-specific foundation models and agent frameworks
- Analysis of current evaluation protocols and benchmarks for OS Agents
- Identification of key challenges including safety, privacy, and personalization
- Discussion of promising future research directions for the field

## Why This Works (Mechanism)
OS Agents work by leveraging MLLM capabilities to interact with operating system environments through graphical user interfaces and other system interfaces. The agents process visual and textual observations of the computing environment, reason about user intent and task requirements, and generate appropriate action sequences to accomplish goals. The integration of multimodal understanding with planning capabilities allows these agents to navigate complex software environments, interpret user instructions, and execute tasks autonomously while adapting to different operating systems and applications.

## Foundational Learning

**Environment Understanding**
- Why needed: OS Agents must comprehend the computing environment they operate in
- Quick check: Can the agent identify active windows, applications, and system states?

**Observation Space**
- Why needed: Agents require mechanisms to perceive and interpret system states
- Quick check: Does the agent effectively process GUI elements, system messages, and user inputs?

**Action Space**
- Why needed: Agents need defined interfaces to interact with the operating system
- Quick check: Can the agent execute mouse movements, keyboard inputs, and system commands reliably?

## Architecture Onboarding

**Component Map**
OS Agent Architecture: Environment Observation -> Understanding Module -> Planning Module -> Grounding Module -> Action Execution -> Feedback Loop

**Critical Path**
The critical execution path flows from environment observation through understanding and planning to action execution, with continuous feedback for adaptation and learning.

**Design Tradeoffs**
Agents must balance between task completion speed and accuracy, between generic capability and specialized performance, and between autonomous operation and user control. The choice of observation methods (GUI vs. API) impacts both capability and security considerations.

**Failure Signatures**
Common failure modes include misinterpretation of GUI elements, incorrect planning sequences, inability to handle edge cases, and failure to adapt to system changes. These often manifest as task abandonment, incorrect actions, or infinite loops in execution.

**3 First Experiments**
1. Task completion on standardized GUI automation benchmarks
2. Cross-platform compatibility testing across different operating systems
3. User intent understanding evaluation with diverse command sets

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Rapidly evolving field may not capture very recent developments
- Classification system may not fully account for hybrid methodological approaches
- Technical focus may underemphasize practical deployment challenges in real-world settings

## Confidence

**High Confidence:**
- Fundamental components and capabilities of OS Agents are well-established and consistently reported

**Medium Confidence:**
- Methodology for constructing OS Agents and evaluation protocols are accurately represented
- Identified challenges and future directions reflect current consensus in the field

## Next Checks
1. Validate the survey's taxonomy against recent conference proceedings (NeurIPS, ICML, ICLR) for emerging approaches
2. Conduct systematic comparison of performance metrics across different OS Agent benchmarks
3. Survey practitioners in industry settings to assess practical relevance of identified challenges