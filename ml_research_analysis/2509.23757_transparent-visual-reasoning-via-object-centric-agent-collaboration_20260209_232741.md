---
ver: rpa2
title: Transparent Visual Reasoning via Object-Centric Agent Collaboration
arxiv_id: '2509.23757'
source_url: https://arxiv.org/abs/2509.23757
tags:
- slot
- game
- learning
- consensus
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OCEAN addresses the challenge of producing human-understandable
  explanations in visual classification by integrating object-centric learning with
  multi-agent collaboration. The framework uses Slot Attention to extract object-centric
  representations, which are then processed by two agents playing a consensus game.
---

# Transparent Visual Reasoning via Object-Centric Agent Collaboration
## Quick Facts
- arXiv ID: 2509.23757
- Source URL: https://arxiv.org/abs/2509.23757
- Reference count: 28
- Key outcome: OCEAN combines object-centric learning with multi-agent consensus to produce interpretable visual reasoning while matching black-box accuracy on synthetic multi-object datasets.

## Executive Summary
OCEAN is a visual classification framework designed to produce human-understandable explanations by integrating object-centric learning with multi-agent collaboration. It uses Slot Attention to extract object-centric representations, which are then processed by two agents playing a consensus game to jointly argue over object slots and reach a shared prediction. This design embeds explainability directly into the model architecture rather than relying on post-hoc methods. Evaluations on CLEVR-Hans and Multi-dSprites show competitive accuracy with state-of-the-art black-box models, and user studies indicate higher perceived intuitiveness and trustworthiness compared to Grad-CAM and LIME.

## Method Summary
OCEAN integrates object-centric learning with multi-agent collaboration for transparent visual reasoning. The framework extracts object-centric representations using Slot Attention, then processes them with two agents that play a consensus game to argue over object slots and arrive at a shared prediction. The model is trained end-to-end, jointly optimizing object extraction and agent-based reasoning. Evaluation on synthetic multi-object datasets shows competitive classification accuracy with black-box models, and a user study indicates OCEAN's explanations are more intuitive and trustworthy than post-hoc methods like Grad-CAM and LIME.

## Key Results
- OCEAN matches state-of-the-art black-box models on CLEVR-Hans and Multi-dSprites synthetic datasets.
- User studies find OCEAN's explanations more intuitive and trustworthy than Grad-CAM and LIME.
- The approach demonstrates that embedding explainability in architecture yields faithful, human-aligned visual reasoning.

## Why This Works (Mechanism)
OCEAN's design leverages object-centric representations to isolate and reason about individual entities in an image. By using Slot Attention, it breaks down complex scenes into manageable, interpretable components. The multi-agent consensus game introduces a deliberative process where agents must justify and negotiate their reasoning, making the decision pathway transparent. Joint training ensures that object extraction and reasoning are optimized together, improving both accuracy and interpretability.

## Foundational Learning
- **Slot Attention**: Needed to decompose images into object-centric slots; quick check: verify slots capture distinct objects without overlap.
- **Multi-agent consensus games**: Needed to simulate deliberative reasoning and expose decision logic; quick check: ensure agents converge on consistent predictions.
- **End-to-end joint optimization**: Needed to align object extraction with reasoning goals; quick check: monitor training stability and co-adaptation of components.

## Architecture Onboarding
**Component map**: Image -> Slot Attention -> Object slots -> Agent 1 & Agent 2 -> Consensus game -> Prediction + Explanation

**Critical path**: Input image → Slot Attention → Two agents debate via consensus game → Final prediction and explanation.

**Design tradeoffs**: Object-centric decomposition improves interpretability but may struggle with occlusion/clutter; multi-agent debate adds transparency but risks mode collapse or degenerate agreement.

**Failure signatures**: Degenerate consensus (agents agree without meaningful debate), Slot Attention failing to isolate objects in cluttered scenes, explanations that do not align with human reasoning.

**First experiments**:
1. Verify Slot Attention correctly isolates objects in simple synthetic scenes.
2. Test consensus game outputs for consistency and meaningful disagreement.
3. Compare classification accuracy with and without the consensus mechanism.

## Open Questions the Paper Calls Out
None.

## Limitations
- Evaluation limited to synthetic, controlled multi-object datasets; real-world generalizability unknown.
- Performance may degrade with occlusion, clutter, or large numbers of objects.
- User study lacks details on participant expertise and statistical power.

## Confidence
- Claims about architectural innovation: High
- Claims about real-world transparency and robustness: Medium
- Claims about superiority over post-hoc methods: Medium

## Next Checks
1. Test OCEAN on natural image datasets (e.g., COCO, VQA) with occluded or cluttered scenes to assess robustness.
2. Perform ablation studies removing the consensus game to quantify its contribution to both accuracy and interpretability.
3. Conduct a controlled, statistically powered user study comparing OCEAN to post-hoc and other interpretable baselines across varied user expertise levels.