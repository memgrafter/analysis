---
ver: rpa2
title: 'Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport
  Phenomena'
arxiv_id: '2505.06123'
source_url: https://arxiv.org/abs/2505.06123
tags:
- wasserstein
- transport
- distance
- data
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work proposes a method to explain Wasserstein distances,\
  \ which are widely used for comparing distributions in fields like physics, medicine,\
  \ and machine learning. The key idea is to treat the Wasserstein distance as a neural\
  \ network and apply Explainable AI techniques\u2014specifically Layer-wise Relevance\
  \ Propagation (LRP)\u2014to attribute the distance to specific data components like\
  \ features or data points."
---

# Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena

## Quick Facts
- **arXiv ID**: 2505.06123
- **Source URL**: https://arxiv.org/abs/2505.06123
- **Reference count**: 40
- **Key outcome**: Proposes a method to explain Wasserstein distances by treating them as neural networks and applying LRP to attribute distances to specific data components

## Executive Summary
This work introduces WaX (Wasserstein distances eXplained), a method to attribute Wasserstein distances between distributions to specific input features or data points. The approach treats the Wasserstein distance computation as a two-layer neural network and applies Layer-wise Relevance Propagation (LRP) to backpropagate relevance scores. The method enables interpretable insights into dataset shifts and transport phenomena, revealing which features or data points contribute most to observed distributional differences. The framework extends to subspace analysis (U-WaX) for identifying interpretable concepts behind transport, and is validated across multiple datasets and configurations with consistently high accuracy.

## Method Summary
WaX decomposes the Wasserstein distance into a two-layer neural network: the first layer computes pairwise Minkowski distances between instances, and the second layer aggregates these using the optimal coupling as weights. LRP rules with specific hyperparameters (α=p, β=min(p+2,q)) are then applied to backpropagate relevance from the final distance score to individual features or data points. The method supports both exact and Sinkhorn-regularized optimal transport couplings. A subspace extension (U-WaX) projects data onto orthogonal subspaces to attribute distances to interpretable concepts. The framework is evaluated using the Symmetric Relevance Gain metric, which measures how much the distance decreases when top-relevant features are removed.

## Key Results
- WaX achieves high accuracy in attributing Wasserstein distances compared to baselines like random feature removal and magnitude-based ranking
- The method successfully disentangles transport phenomena into interpretable concepts (e.g., separating size-related and weight-related aging effects in abalone dataset)
- Real-world applications demonstrate insights into biological aging patterns and differences between large image datasets
- The LRP-based approach with conservation property provides stable attributions even for high-dimensional transport problems

## Why This Works (Mechanism)

### Mechanism 1
Treating the Wasserstein distance computation as a two-layer neural network allows standard explainability techniques (specifically LRP) to attribute the distance to specific data components. The method "neuralizes" the Optimal Transport problem by expressing the primal formulation as a graph where Layer 1 computes pairwise Minkowski distances and Layer 2 aggregates them using the optimal coupling as weights. This structure enables a backward pass to propagate relevance. The approach assumes the optimal coupling is treated as a fixed weight during explanation, decoupling transport optimization from attribution.

### Mechanism 2
Layer-wise Relevance Propagation (LRP) rules with specific hyperparameters (α=p, β=min(p+2,q)) provide stable and conserving attribution for high-dimensional transport problems. The backward pass uses propagation rules that satisfy the conservation property (sum of relevances equals total distance). The heuristic β=min(p+2,q) acts as a smoothing mechanism to prevent gradient explosion for high p or q values. This approach assumes relevance conservation is necessary for faithful explanation and uses a "detach trick" to reconcile LRP rules with gradient-based computations.

### Mechanism 3
Decomposing the input space into orthogonal subspaces allows Wasserstein distance attribution to human-interpretable "concepts" rather than raw features. U-WaX projects transport difference vectors onto an orthogonal matrix U, computes concept-specific scores, and attributes distance to these subspaces. It maximizes a "tailedness" statistic to find subspaces explaining significant transport portions. This assumes distinct sub-shifts in data are geometrically orthogonal or can be approximated as such in latent space.

## Foundational Learning

- **Concept: Optimal Transport (OT) & Wasserstein Distance (Wp)**
  - Why needed: This is the core object being explained - measures "cost" of moving mass between distributions with coupling dictating how mass moves
  - Quick check: If two datasets overlap significantly but have different densities in overlap region, will Wp be zero? (No - Wp measures density differences even in support overlap)

- **Concept: Layer-wise Relevance Propagation (LRP)**
  - Why needed: Method relies on LRP to backpropagate scalar distance score, distinct from standard backpropagation
  - Quick check: In standard backprop, if neuron has zero gradient, does it contribute to output? In LRP, can neuron have zero relevance but non-zero gradient? (Yes to both distinctions)

- **Concept: Minkowski Distance (ℓq norm)**
  - Why needed: Paper varies p (Wasserstein exponent) and q (ground metric exponent) - crucial for neuralization step and β heuristic
  - Quick check: What happens to distance metric as q→∞? (Approaches Chebyshev distance, focusing on maximum dimension-wise difference)

## Architecture Onboarding

- **Component map**: Source/Target datasets → OT Solver (computes γ*) → Neuralizer (constructs computational graph) → WaX Engine (LRP backward pass) → Relevance scores → U-WaX (optional subspace projection)

- **Critical path**: Calculation of Symmetric Relevance Gain (SRG) in Eq. 5 - validation loop that removes highest relevance features, recalculates Wp, and verifies distance drops significantly more than random removal

- **Design tradeoffs**:
  - Exact vs Regularized Coupling: Supports Sinkhorn distances - uniform coupling is faster but less sensitive to specific transport paths
  - Choice of β: Using β=q matches gradient but β=min(p+2,q) handles outliers better, sacrificing gradient equivalence for stability

- **Failure signatures**:
  - Irrelevant Attribution: Low/negative SRG score indicates method identifying anti-relevant features or random noise - check detach implementation
  - Sensitivity to p: Very high p values cause discontinuous gradients - ensure β heuristic caps exponent to prevent overflow

- **First 3 experiments**:
  1. Sanity Check: Compute Wp on synthetic dataset with known shift, run WaX, verify correct features have high relevance, retain top features and check Wp remains high
  2. Ablation on Hyperparameters: Run grid search over α,β on real dataset, plot SRG surface to confirm proposed heuristic falls in optimal region
  3. Subspace Discovery: Run U-WaX on Abalone dataset, visualize clusters in t-SNE, check if subspaces isolate size vs weight features as claimed

## Open Questions the Paper Calls Out

- How can WaX framework extend to Gromov-Wasserstein distances for handling transport between unregistered or heterogeneous data spaces?
- Can WaX attribution method adapt to account for temporal dynamics and causality in time-series distribution shifts?
- Is there theoretical guarantee for optimality of heuristic choice of propagation parameters (α=p, β=min(p+2,q)) used in LRP rules?

## Limitations

- Computational complexity from computing optimal couplings for all pairwise distances, potentially prohibitive for large datasets
- Hyperparameter sensitivity to proposed heuristic β=min(p+2,q) may not generalize across diverse data distributions
- Subspace orthogonality assumption may break down when underlying shifts are correlated or non-linear

## Confidence

- **High Confidence**: Core neuralization framework and conservation property of LRP rules are mathematically rigorous with strong empirical backing
- **Medium Confidence**: Attribution accuracy comparisons show high performance but baselines are relatively simple; more sophisticated comparisons would strengthen claims
- **Medium Confidence**: Subspace analysis produces interpretable results on abalone dataset but generalization to other domains remains untested

## Next Checks

1. Implement method on datasets with 10K+ samples and measure both accuracy (SRG) and runtime, comparing exact vs Sinkhorn couplings to quantify tradeoff

2. Systematically vary α and β across wider range than tested, measuring how SRG scores degrade as hyperparameters deviate from proposed heuristic

3. Apply SHAP or integrated gradients to neuralized Wasserstein formulation and compare attribution rankings against WaX to test if specific LRP formulation provides advantages