---
ver: rpa2
title: 'TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories
  for Server-Side Adversarial Training'
arxiv_id: '2512.15123'
source_url: https://arxiv.org/abs/2512.15123
tags:
- adversarial
- training
- client
- data
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of applying adversarial training
  in federated learning (FL) settings, where client data privacy constraints and limited
  computational resources on edge devices prevent both server-side and client-side
  adversarial training. The authors propose TrajSyn, a novel framework that synthesizes
  a proxy dataset from client model trajectories (sequences of model updates) without
  accessing raw client data.
---

# TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training

## Quick Facts
- **arXiv ID**: 2512.15123
- **Source URL**: https://arxiv.org/abs/2512.15123
- **Reference count**: 36
- **Primary result**: Achieves 51.75% adversarial accuracy on ConvNet and 53.09% on AlexNet in FL settings

## Executive Summary
This paper introduces TrajSyn, a novel framework that addresses the challenge of implementing adversarial training in federated learning (FL) environments. By synthesizing a proxy dataset from client model trajectories, TrajSyn enables server-side adversarial training without accessing raw client data or imposing computational burdens on resource-constrained client devices. The framework demonstrates significant improvements in adversarial robustness while maintaining clean accuracy, making it a practical solution for enhancing security in FL deployments.

## Method Summary
TrajSyn operates by leveraging the sequential model updates (trajectories) from FL clients to synthesize a representative dataset on the server side. This synthetic dataset captures the underlying data distribution without exposing raw client information. The server then uses this dataset to perform adversarial training, effectively transferring the computational load from clients to the server. The framework maintains privacy constraints while enabling stronger model robustness against adversarial attacks.

## Key Results
- Increases adversarial accuracy from 41.73% to 51.75% on ConvNet architecture
- Improves adversarial accuracy from 35.31% to 53.09% on AlexNet architecture
- Achieves better balance between clean and adversarial performance compared to standard FL training
- Imposes no additional computational load on client devices

## Why This Works (Mechanism)
TrajSyn exploits the information embedded in model trajectories during FL training. As clients update their models based on local data, these updates encode patterns about the underlying data distribution. By analyzing these trajectories, the server can reconstruct a synthetic dataset that approximates the original client data without violating privacy constraints. This synthetic dataset then enables effective adversarial training on the server side, leveraging the server's superior computational resources to enhance model robustness.

## Foundational Learning

**Federated Learning (FL)**: Decentralized training where clients collaboratively train a model without sharing raw data. Why needed: Establishes the context of privacy constraints that prevent standard adversarial training approaches. Quick check: Verify understanding of client-server architecture and data locality principles.

**Adversarial Training**: Training process that improves model robustness against adversarial examples by incorporating adversarial examples during training. Why needed: Explains the security challenge TrajSyn addresses in FL settings. Quick check: Confirm knowledge of adversarial examples and their generation methods (e.g., FGSM, PGD).

**Model Trajectories**: Sequences of model parameters updated during training, representing the learning path of the model. Why needed: Core concept enabling dataset synthesis without raw data access. Quick check: Understand how parameter updates encode information about training data distribution.

## Architecture Onboarding

**Component Map**: Clients -> Model Updates -> Server -> Trajectory Analysis -> Synthetic Dataset -> Adversarial Training -> Robust Model

**Critical Path**: The trajectory synthesis and adversarial training pipeline forms the critical path, where any failure in generating representative synthetic data directly impacts the effectiveness of adversarial training.

**Design Tradeoffs**: Privacy preservation vs. dataset quality - more aggressive privacy measures may reduce synthetic dataset fidelity, while less restrictive approaches risk privacy leakage.

**Failure Signatures**: Poor adversarial accuracy improvement indicates either inadequate trajectory analysis or synthetic dataset that fails to capture the true data distribution.

**First Experiments**:
1. Validate synthetic dataset generation by comparing statistical properties with original data distributions
2. Test adversarial training effectiveness using the synthetic dataset on a centralized benchmark
3. Measure privacy leakage through membership inference attacks on the synthetic dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to CIFAR-10 with only ConvNet and AlexNet architectures
- No assessment of privacy leakage through the synthesized dataset itself
- Server-side computational overhead not quantified
- Convergence behavior and training stability not thoroughly investigated

## Confidence

**High confidence**: TrajSyn successfully synthesizes a dataset from model trajectories enabling server-side adversarial training in FL settings.

**Medium confidence**: The specific accuracy improvements reported (41.73% to 51.75% for ConvNet, 35.31% to 53.09% for AlexNet) are reliable within the experimental setup but may not generalize.

**Low confidence**: Claims about practical deployment feasibility without detailed server-side computational overhead analysis and privacy risk assessment of the synthetic dataset.

## Next Checks

1. Evaluate TrajSyn on diverse datasets (e.g., CIFAR-100, TinyImageNet) and modern architectures (e.g., ResNet, Vision Transformers) to assess scalability.

2. Conduct a formal privacy analysis to quantify potential information leakage from the synthesized dataset.

3. Measure and report server-side computational overhead and compare it with alternative approaches to contextualize resource requirements.