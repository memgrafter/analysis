---
ver: rpa2
title: 'Highlight & Summarize: RAG without the jailbreaks'
arxiv_id: '2508.02872'
source_url: https://arxiv.org/abs/2508.02872
tags:
- question
- highlighter
- answer
- pipeline
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of preventing jailbreaking and
  model hijacking attacks in retrieval-augmented generation (RAG) systems, where malicious
  users can input specially crafted prompts to cause the LLM to generate undesirable
  content or perform unintended tasks. The core method, called Highlight & Summarize
  (H&S), prevents these attacks by design by splitting the pipeline into two components:
  a highlighter that extracts relevant passages from retrieved documents based on
  the user''s question, and a summarizer that generates an answer by summarizing the
  highlighted passages without ever seeing the user''s question.'
---

# Highlight & Summarize: RAG without the jailbreaks
## Quick Facts
- arXiv ID: 2508.02872
- Source URL: https://arxiv.org/abs/2508.02872
- Authors: Giovanni Cherubin; Andrew Paverd
- Reference count: 38
- One-line primary result: Novel H&S method prevents jailbreaks in RAG systems while improving accuracy

## Executive Summary
This paper addresses critical security vulnerabilities in retrieval-augmented generation (RAG) systems by introducing the Highlight & Summarize (H&S) method. Traditional RAG pipelines are susceptible to jailbreak attacks where malicious users can manipulate the system through specially crafted prompts. The H&S approach fundamentally restructures the RAG pipeline by separating the question context from the answer generation process, thereby preventing direct injection of malicious prompts into the language model.

The method achieves this by splitting the pipeline into two distinct components: a highlighter that extracts relevant passages from retrieved documents based solely on the document content, and a summarizer that generates answers by synthesizing the highlighted content without ever receiving the user's question. This architectural separation effectively isolates the system from potentially harmful prompt injections while maintaining or improving response quality.

## Method Summary
The Highlight & Summarize method restructures the traditional RAG pipeline by dividing it into two specialized components that operate sequentially. First, the highlighter component processes retrieved documents and identifies relevant passages based on their content alone, without access to the user's question. This isolation ensures that no malicious prompt information can directly influence the LLM. Second, the summarizer component takes the highlighted passages and generates a final answer by synthesizing the information contained within them, again without seeing the original question.

This architectural separation creates a security boundary where potentially harmful prompt injections cannot reach the LLM's decision-making process. The highlighter uses semantic analysis and keyword matching to identify relevant content, while the summarizer employs standard text generation techniques to produce coherent answers from the highlighted material. The system maintains accuracy by ensuring the highlighter captures all relevant information, while the summarizer can piece together the final answer without being influenced by potentially malicious question framing.

## Key Results
- H&S implementations achieved 59% and 54% win rates against standard RAG in LLM-as-Judge comparisons
- Completely prevented jailbreak attacks in tool-calling scenarios during controlled experiments
- Received 13,698 wins out of 17,955 examples on RepliQA dataset using H&S Structured pipeline
- Preferred over highlighting-only approaches in 58% of cases on BioASQ dataset

## Why This Works (Mechanism)
The H&S method works by breaking the direct line of attack that jailbreakers exploit in traditional RAG systems. In standard RAG, malicious prompts can flow directly from the user through the retrieval step into the LLM's context window, where they can manipulate the model's behavior. By isolating the question context from the answer generation process, H&S eliminates this attack vector at its source.

The highlighter component acts as a filter that only sees document content, not user prompts, preventing any prompt injection from reaching the LLM. The summarizer then operates on the sanitized, highlighted content to generate responses. This separation means that even if a user attempts to inject malicious instructions through their question, those instructions never reach the LLM responsible for generating the final answer. The system essentially treats all questions as requests for information extraction rather than as instructions to be followed.

## Foundational Learning
- **Retrieval-augmented generation security**: Understanding how RAG systems can be compromised through prompt injection is essential for recognizing the vulnerability landscape that H&S addresses. Quick check: Can you identify the attack vector in a standard RAG pipeline?
- **Component isolation principles**: The security-through-separation approach used in H&S draws from broader cybersecurity principles where isolating components limits attack surfaces. Quick check: What other systems use component isolation for security?
- **Semantic highlighting techniques**: The highlighter must accurately identify relevant content without question context, requiring robust semantic understanding algorithms. Quick check: How does keyword-based highlighting differ from semantic highlighting?
- **LLM-as-a-Judge methodology**: Understanding how automated evaluation using LLMs works and its potential biases is crucial for interpreting the experimental results. Quick check: What are the limitations of using LLMs to evaluate other LLMs?
- **Text summarization fundamentals**: The summarizer component relies on established text summarization techniques to synthesize coherent answers from highlighted passages. Quick check: What's the difference between extractive and abstractive summarization?
- **Prompt engineering security**: Recognizing how prompt injection attacks work helps understand why H&S's architectural separation is effective. Quick check: Can you construct a simple jailbreak prompt for a standard RAG system?

## Architecture Onboarding
- **Component map**: Documents -> Highlighter -> Highlighted Passages -> Summarizer -> Final Answer
- **Critical path**: The highlighter must accurately extract all relevant information, as the summarizer has no access to the original question for context. Any failure in highlighting directly impacts answer quality.
- **Design tradeoffs**: The system trades some potential precision (not having question context during highlighting) for security and robustness against attacks. The highlighter must be more comprehensive to compensate for the lack of question guidance.
- **Failure signatures**: Poor highlighting leads to incomplete or irrelevant answers, while overly aggressive highlighting can introduce noise. The summarizer may produce generic answers if highlighting is too sparse.
- **First experiment 1**: Test the highlighter in isolation with various document types to ensure it captures relevant content without question context
- **First experiment 2**: Validate that the summarizer can generate coherent answers from highlighted passages alone
- **First experiment 3**: Conduct controlled prompt injection attempts to verify the security boundary between components

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation relies heavily on LLM-as-a-Judge comparisons, which may introduce subjectivity and bias
- Claims of complete prevention of jailbreak attacks are based on controlled experimental conditions that may not capture all real-world attack vectors
- The paper does not extensively address computational overhead or latency implications compared to standard RAG systems

## Confidence
- **High**: The core methodology of separating question context from answer generation is technically sound and addresses a real security concern
- **Medium**: The experimental results showing improved performance over standard RAG are supported but could benefit from broader validation
- **Low**: Claims of complete prevention of jailbreak attacks require additional independent verification

## Next Checks
1. Conduct adversarial testing with diverse jailbreak prompt categories not included in the original evaluation to verify robustness claims
2. Perform end-to-end latency and computational cost analysis comparing H&S with standard RAG across different document corpus sizes
3. Validate results using human evaluation panels to complement LLM-as-a-Judge assessments and identify potential systematic biases in automated evaluation