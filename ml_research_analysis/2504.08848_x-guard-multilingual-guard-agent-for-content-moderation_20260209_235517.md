---
ver: rpa2
title: 'X-Guard: Multilingual Guard Agent for Content Moderation'
arxiv_id: '2504.08848'
source_url: https://arxiv.org/abs/2504.08848
tags:
- safety
- text
- label
- language
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The X-Guard agent was developed to address multilingual safety
  evaluation challenges for LLMs, focusing on low-resource languages and code-switching
  attacks. The method employs a two-stage architecture combining a custom-finetuned
  mBART-50 translation module with an X-Guard 3B evaluation model, trained using supervised
  fine-tuning and GRPO.
---

# X-Guard: Multilingual Guard Agent for Content Moderation

## Quick Facts
- arXiv ID: 2504.08848
- Source URL: https://arxiv.org/abs/2504.08848
- Reference count: 40
- Primary result: 70.38% accuracy and 70.44% F1-score across 132 languages on 65K samples

## Executive Summary
X-Guard addresses the critical challenge of multilingual safety evaluation for Large Language Models (LLMs), particularly focusing on low-resource languages and code-switching attacks. The system employs a two-stage architecture that combines a custom-finetuned mBART-50 translation module with an X-Guard 3B evaluation model, trained using supervised fine-tuning and GRPO (Group Relative Policy Optimization). A jury of judges approach is implemented to mitigate individual LLM biases, providing transparent reasoning in safety decisions.

The agent demonstrates robust performance across diverse linguistic contexts, achieving 70.38% accuracy and 70.44% F1-score across 132 languages on 65K samples, while maintaining strong performance on English-only data at 97.20% accuracy. Category classification yields a weighted F1-score of 52.37% across all languages. The system successfully defends against Sandwich Attacks with 83% accuracy versus 62% for Llama-Guard-8B, showcasing its effectiveness in multilingual safety evaluation scenarios.

## Method Summary
X-Guard employs a two-stage architecture combining translation and evaluation components to address multilingual safety assessment challenges. The system uses a custom-finetuned mBART-50 translation module to handle low-resource languages and code-switching, followed by an X-Guard 3B evaluation model trained through supervised fine-tuning and GRPO. A jury of judges approach is implemented to mitigate individual LLM biases and provide transparent reasoning for safety decisions. The architecture is designed to maintain performance across 132 languages while defending against sophisticated attacks like Sandwich Attacks, where benign content is strategically embedded within harmful material.

## Key Results
- 70.38% accuracy and 70.44% F1-score across 132 languages on 65K samples
- 97.20% accuracy on English-only data, demonstrating strong performance in high-resource languages
- 83% accuracy in defending against Sandwich Attacks versus 62% for Llama-Guard-8B

## Why This Works (Mechanism)
X-Guard's effectiveness stems from its two-stage architecture that addresses the fundamental challenge of multilingual safety evaluation: the combination of translation accuracy, bias mitigation through jury deliberation, and robust reward modeling via GRPO. The system leverages mBART-50's multilingual capabilities to handle low-resource languages and code-switching scenarios, while the jury of judges approach ensures diverse perspectives in safety assessment. The GRPO training methodology enables the model to optimize for nuanced safety concerns across different cultural contexts, making it particularly effective against sophisticated attacks like Sandwich Attacks where content masking techniques are employed.

## Foundational Learning
- **mBART-50 Fine-tuning**: Required to adapt the translation model for low-resource languages and code-switching patterns; quick check: validate translation accuracy across target language pairs
- **GRPO (Group Relative Policy Optimization)**: Needed to optimize reward modeling for nuanced safety concerns; quick check: compare performance against standard PPO implementations
- **Jury of Judges Approach**: Essential for bias mitigation across diverse cultural contexts; quick check: measure inter-judge agreement rates and identify systematic disagreements
- **Sandwich Attack Detection**: Critical for defending against sophisticated content masking techniques; quick check: test against known adversarial attack patterns beyond Sandwich Attacks

## Architecture Onboarding

**Component Map**: Input Text -> mBART-50 Translation Module -> X-Guard 3B Evaluation Model -> Jury of Judges -> Safety Decision with Reasoning

**Critical Path**: Translation -> Evaluation -> Jury Deliberation -> Decision Output

**Design Tradeoffs**: The system balances translation accuracy with evaluation precision, choosing a 3B parameter model for efficiency while maintaining multilingual coverage. The jury approach adds computational overhead but provides bias mitigation and transparency benefits.

**Failure Signatures**: 
- Translation errors propagating through to evaluation stage
- Judge consensus failures indicating systematic biases
- False negatives in detecting Sandwich Attacks
- Performance degradation in truly low-resource languages

**First 3 Experiments**:
1. Validate translation accuracy across representative low-resource language pairs
2. Test jury consensus rates across different content categories and cultural contexts
3. Benchmark against baseline models on known adversarial attack patterns

## Open Questions the Paper Calls Out
None

## Limitations
- 70.38% overall accuracy still indicates substantial error rates for safety-critical applications
- Weighted F1-score of 52.37% for category classification suggests challenges in fine-grained threat detection
- Significant performance differential between English-only (97.20%) and multilingual scenarios (70.44% F1)

## Confidence
High confidence in English-only performance metrics and basic two-stage architecture effectiveness.
Medium confidence in multilingual results due to potential data distribution artifacts and limited transparency in judge selection and training.
Low confidence in robustness against novel adversarial attacks beyond tested Sandwich Attacks.

## Next Checks
1. Conduct adversarial testing across diverse cultural contexts and emerging threat patterns beyond current attack types.
2. Perform ablation studies to quantify individual contributions of translation accuracy, judge diversity, and reward modeling to overall performance.
3. Evaluate real-world deployment scenarios with continuous monitoring of false negative rates across different demographic groups and content types.