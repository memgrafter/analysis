---
ver: rpa2
title: 'CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese'
arxiv_id: '2511.04139'
source_url: https://arxiv.org/abs/2511.04139
tags:
- correction
- cantonese
- tonal
- speech
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of automatic speech recognition
  (ASR) for low-resource Cantonese, which is hindered by limited data, six lexical
  tones, tone sandhi, and accent variation. Existing models like Whisper suffer from
  high word error rates, especially for tonal distinctions.
---

# CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese

## Quick Facts
- arXiv ID: 2511.04139
- Source URL: https://arxiv.org/abs/2511.04139
- Reference count: 0
- Primary result: Substantial CER reduction for low-resource Cantonese ASR using forced alignment, LoRA-finetuned Whisper, and prosody-aware correction

## Executive Summary
CantoASR addresses the challenge of automatic speech recognition for low-resource Cantonese by integrating forced alignment, LoRA-finetuned Whisper, and an instruction-tuned Qwen-Audio for prosody-aware correction. The framework targets Cantonese's six lexical tones, tone sandhi, and accent variation, which are difficult for standard ASR models. Evaluations on spontaneous Cantonese data show significant character error rate (CER) gains over Whisper-Large-V3, demonstrating the value of combining acoustic cues with large audio-language model (LALM) reasoning for low-resource tonal ASR.

## Method Summary
The CantoASR framework combines forced alignment for acoustic feature extraction, LoRA-finetuned Whisper for improved tone discrimination, and an instruction-tuned Qwen-Audio for prosody-aware correction. Forced alignment extracts precise acoustic features to better capture Cantonese tonal distinctions. LoRA adaptation of Whisper fine-tunes the model on Cantonese data to improve its tone handling. The Qwen-Audio model provides prosody-aware correction by leveraging large audio-language model reasoning to refine transcriptions. The collaborative pipeline is designed to address the specific challenges of low-resource tonal languages, especially Cantonese.

## Key Results
- Significant CER reduction compared to Whisper-Large-V3 on spontaneous Cantonese data
- Improved tone discrimination and prosody handling in low-resource settings
- Demonstrated feasibility of ASR-LALM collaboration for tonal and dialectal languages

## Why This Works (Mechanism)
CantoASR improves ASR accuracy by leveraging acoustic feature extraction, model adaptation, and language model reasoning. Forced alignment provides precise acoustic cues for Cantonese tones, which are critical for distinguishing words. LoRA fine-tuning adapts Whisper to better handle tonal distinctions in low-resource Cantonese data. The Qwen-Audio model applies prosody-aware correction, using its instruction-tuned reasoning to refine transcriptions based on context and tonal patterns. This multi-stage approach addresses both acoustic and linguistic challenges in Cantonese ASR.

## Foundational Learning
- **Forced alignment**: Aligns speech segments with text to extract accurate acoustic features; needed to capture Cantonese tonal nuances; quick check: verify alignment accuracy on test set
- **LoRA fine-tuning**: Low-rank adaptation of large models for efficient domain adaptation; needed to adapt Whisper to Cantonese without full retraining; quick check: compare CER before/after LoRA
- **Qwen-Audio instruction tuning**: Fine-tunes audio-language models for specific tasks; needed for prosody-aware correction in Cantonese; quick check: assess correction quality on tonal errors
- **Tonal languages**: Languages where pitch changes word meaning; needed context for Cantonese ASR challenges; quick check: review Cantonese tone inventory
- **Word error rate (WER) and character error rate (CER)**: Standard ASR evaluation metrics; needed to quantify model performance; quick check: compare CantoASR CER to baseline

## Architecture Onboarding
- **Component map**: Forced alignment -> LoRA-finetuned Whisper -> Qwen-Audio prosody correction
- **Critical path**: Acoustic feature extraction (forced alignment) -> ASR transcription (LoRA-Whisper) -> Post-correction (Qwen-Audio)
- **Design tradeoffs**: Uses modular pipeline for flexibility and targeted improvements; may introduce latency and complexity
- **Failure signatures**: Errors in forced alignment propagate to later stages; LoRA may overfit to training tones; Qwen-Audio may overcorrect or introduce errors
- **First experiments**:
  1. Validate forced alignment accuracy on Cantonese test set
  2. Measure CER improvement from LoRA fine-tuning alone
  3. Evaluate impact of Qwen-Audio correction on tone errors

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to one spontaneous Cantonese test set, raising questions about robustness to different speaking styles and accents
- Acoustic feature extraction and LoRA fine-tuning details are not provided, hindering reproducibility
- The impact and consistency of prosody-aware correction are not fully explored
- Claims about generalizability to other tonal languages are not empirically supported

## Confidence
- CER improvements: Medium (limited and narrowly focused evaluation)
- LALM collaboration claims: Low (unclear practical impact, no user studies)
- Cross-linguistic applicability: Low (unsupported beyond theoretical reasoning)

## Next Checks
1. Replicate the full pipeline on an additional Cantonese test set with varied speaker demographics
2. Conduct A/B testing with native Cantonese speakers to assess the perceptual quality and utility of prosody-aware corrections
3. Perform ablation studies to quantify the marginal benefit of each pipeline component (forced alignment, LoRA adaptation, prosody correction)