---
ver: rpa2
title: Collaborative Learning with Multiple Foundation Models for Source-Free Domain
  Adaptation
arxiv_id: '2511.19147'
source_url: https://arxiv.org/abs/2511.19147
tags:
- coma
- adaptation
- domain
- target
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces CoMA, a source-free domain adaptation framework
  that jointly leverages two complementary foundation models (CLIP and BLIP) to address
  the limited semantic diversity of single-foundation-model approaches. The method
  employs a bidirectional adaptation mechanism: Target-Guided Consistency Adjustment
  aligns the MFMs with task-relevant semantics while'
---

# Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation

## Quick Facts
- arXiv ID: 2511.19147
- Source URL: https://arxiv.org/abs/2511.19147
- Authors: Huisoo Lee; Jisu Han; Hyunsouk Cho; Wonjun Hwang
- Reference count: 40
- Key outcome: Introduces CoMA, a source-free domain adaptation framework that jointly leverages two complementary foundation models (CLIP and BLIP) to address the limited semantic diversity of single-foundation-model approaches, employing a bidirectional adaptation mechanism with target-guided consistency adjustment and mutual knowledge transfer.

## Executive Summary
This paper presents CoMA, a source-free domain adaptation (SFDA) framework that overcomes the semantic limitations of single-foundation-model approaches by leveraging two complementary vision-language models (CLIP and BLIP) through bidirectional adaptation. The method employs a novel Decomposed Mutual Information (DMI) formulation to stabilize batch training and prevent false dependencies arising from incomplete class coverage in mini-batches. Through extensive experiments across four benchmarks (Office-31, Office-Home, DomainNet-126, VisDA), CoMA demonstrates significant performance improvements over state-of-the-art SFDA methods while maintaining inference efficiency.

## Method Summary
CoMA operates in two stages: first, a burn-in phase trains a BLIP-proxy model using pseudo-labels generated by InstBLIP-XL. Then, the bidirectional adaptation mechanism begins with Target-Guided Consistency Adjustment (TCA) that aligns both foundation models (CLIP and BLIP) with the target model through mutual consistency and conditional decorrelation, followed by Mutual Distillation Adaptation (MDA) that transfers complementary knowledge via agreement-guided supervision and selective information maximization. The framework uses Decomposed Mutual Information (DMI) to selectively enhance true dependencies while suppressing false ones from incomplete class coverage in mini-batches, enabling stable optimization without source data access.

## Key Results
- Achieves state-of-the-art performance across four SFDA benchmarks, with up to 6.2% accuracy improvement on challenging domain shifts
- Demonstrates robust performance across closed-set, partial-set, and open-set adaptation scenarios
- Maintains inference efficiency with no foundation model overhead despite 66% increased training time and 50% higher GPU memory usage during training

## Why This Works (Mechanism)

### Mechanism 1: Complementary Foundation Model Semantic Coverage
- Claim: Joint use of CLIP and BLIP provides broader semantic coverage than either model alone.
- Mechanism: CLIP captures global, category-level semantics through image-text contrastive learning, while BLIP employs cross-attention to establish region-text correspondences, emphasizing local contextual cues. The bidirectional adaptation aligns both with the target model while preserving their distinctiveness.
- Core assumption: The two foundation models encode complementary rather than redundant semantic information.
- Evidence anchors:
  - [abstract] "jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues"
  - [section 1, page 1] "FM I (e.g., CLIP) captures global, category-level semantics (e.g., 'tram'), whereas FM II (e.g., BLIP) captures local contextual semantics with fine-grained details (e.g., 'wheels')"
  - [corpus] Weak direct evidence for CLIP+BLIP pairing specifically; related SFDA papers focus on single foundation models.
- Break condition: If CLIP and BLIP predictions highly correlate on a target domain, their complementarity assumption fails, collapsing to single-FM behavior.

### Mechanism 2: Decomposed Mutual Information (DMI) for Stable Batch Training
- Claim: DMI stabilizes mutual information optimization by selectively enhancing true dependencies while suppressing false ones from incomplete class coverage in mini-batches.
- Mechanism: Decomposes the joint distribution into confident joint subset (CJS)—classes present with confident predictions—and uncertain regions (complement). Maximizes MI in CJS, minimizes MI in uncertain region. The formulation: I_D(X;Y) = I(X_S;Y_S) - (log|S|/log|S^c|)·I(X_S^c;Y_S^c).
- Core assumption: Confident predictions within a batch indicate true dependencies; absent/unconfident classes represent spurious correlations.
- Evidence anchors:
  - [abstract] "Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage"
  - [section 3.1, page 4] "conventional MI maximization can inadvertently reinforce false dependencies for classes that are unobserved in the current batch"
  - [corpus] No direct corroboration; this is a novel contribution of the paper.
- Break condition: If batch size is too small relative to class count (e.g., |S| ≤ 1 frequently), DMI skips batches and learning stalls.

### Mechanism 3: Two-Stage Bidirectional Knowledge Transfer
- Claim: Separating FM alignment from target adaptation prevents semantic collapse and improves knowledge distillation quality.
- Mechanism: Stage 1 (TCA): Target model guides both FMs toward task-relevant semantics via mutual consistency (maximize DMI) while enforcing conditional decorrelation (minimize conditional DMI) to preserve distinctiveness. Stage 2 (MDA): Agreement-guided supervision uses consensus pseudo-labels; selective information maximization reinforces target model predictions within FM-defined semantic scope.
- Core assumption: Task-agnostic FMs can be jointly aligned without collapsing their semantic diversity, and their agreement signals reliable supervision.
- Evidence anchors:
  - [abstract] "bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge"
  - [section 3.2-3.3, pages 4-5] TCA uses L_MC for mutual consistency and L_CD for conditional decorrelation; MDA uses L_AGS for agreement-guided supervision and L_SIM for selective information maximization
  - [corpus] Related SFDA methods (DIFO, ProDe) use single-FM guidance without bidirectional stages.
- Break condition: If α (decorrelation weight) is too low, FMs converge to similar predictions; if too high, they remain misaligned with the target task.

## Foundational Learning

- Concept: **Mutual Information in Unsupervised Learning**
  - Why needed here: DMI extends standard MI; understanding I(X;Y) = H(Y) - H(Y|X) is essential for interpreting enhancement/suppression tradeoffs.
  - Quick check question: Can you explain why maximizing MI promotes diagonal concentration in a joint distribution matrix?

- Concept: **Vision-Language Foundation Models (CLIP, BLIP)**
  - Why needed here: CLIP uses contrastive image-text alignment (global semantics); BLIP uses cross-attention (local grounding). Their architectural differences explain complementarity.
  - Quick check question: Which model would better capture "the texture of a bicycle tire" versus "the concept of a bicycle"?

- Concept: **Source-Free Domain Adaptation Constraints**
  - Why needed here: No source data access; only unlabeled target data and a pre-trained source model are available. This motivates external FM guidance.
  - Quick check question: Why can't standard domain adaptation methods (e.g., domain adversarial training) be applied directly in SFDA?

## Architecture Onboarding

- Component map:
  - Target model (θ_t) -> ResNet-50/101 + classifier; initialized from source model
  - CLIP (Θ_c) -> ViT-B/32 encoder + text encoder; frozen with learnable prompt context v
  - BLIP-proxy (θ_b) -> Same architecture as target model; trained on BLIP-generated pseudo-labels during burn-in
  - Loss modules: L_MC (mutual consistency), L_CD (conditional decorrelation), L_AGS (agreement-guided supervision), L_SIM (selective information maximization)

- Critical path:
  1. Burn-in phase: Train BLIP-proxy on BLIP-generated pseudo-labels (offline, once per dataset)
  2. Initialize θ_t from source model θ_s
  3. For each batch: (a) TCA stage—update prompt v and θ_b via L_TCA; (b) MDA stage—update θ_t via L_MDA
  4. Deploy only θ_t at inference (no FM overhead)

- Design tradeoffs:
  - Accuracy vs. training cost: CoMA requires +66% training time and +50% GPU memory vs. single-FM methods (Table 10, supplementary), but inference is unchanged.
  - Batch size vs. DMI stability: Smaller batches increase spurious dependencies; DMI mitigates but doesn't eliminate (Fig. 5 shows degradation at batch size 8 even with DMI).
  - λ (DMI scale): Paper uses λ=0.5; lower values emphasize enhancement, higher values risk over-suppression (Fig. 6).

- Failure signatures:
  - Performance collapses when batch size is too small and λ is too high (over-suppression of uncertain region).
  - If CLIP and BLIP predictions align too closely, L_CD cannot preserve distinctiveness; check correlation of FM outputs.
  - If L_AGS has few agreement samples, pseudo-label supervision degrades; monitor agreement rate.

- First 3 experiments:
  1. **Ablation on Office-Home**: Replicate Table 5 to verify each loss component's contribution; expect ~30% gain from baseline to full model.
  2. **DMI vs. MI vs. KL comparison**: On Office-Home (65 classes) and VisDA (12 classes), compare Table 6 configurations to validate DMI's stability benefit.
  3. **Batch size sensitivity**: Sweep batch sizes {8, 16, 32, 64} with and without DMI (Fig. 5) to confirm robustness claims; expect larger degradation gap without DMI at small batches.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the bidirectional adaptation mechanism be scaled to integrate three or more foundation models without causing semantic collapse or prohibitive computational overhead?
- **Basis in paper:** [inferred] The paper explicitly frames the contribution around "jointly leveraging **two** different FMs" and validates the method using a pair (CLIP and BLIP), leaving the scalability of the collaborative learning framework to $N > 2$ models unexplored.
- **Why unresolved:** The Conditional Decorrelation loss ($L_{CD}$) is designed to preserve distinctiveness between two models; it is unclear if this mechanism is sufficient to prevent homogenization or optimization conflicts in a higher-dimensional model space.
- **What evidence would resolve it:** Experimental results on Office-Home or DomainNet applying CoMA with a set of 3+ diverse MFMs (e.g., CLIP, BLIP, LLaVA), analyzing the divergence of their representations and the resulting accuracy.

### Open Question 2
- **Question:** Is there a theoretical or quantitative metric for selecting the optimal combination of foundation models for a given target domain, rather than relying on the manual selection of "global" vs. "local" properties?
- **Basis in paper:** [inferred] The authors rely on the qualitative assumption that CLIP captures global semantics and BLIP captures local cues. While Table 7 shows ablations on different pairs, it does not propose a general principle for predicting which model pairs yield "complementary" properties.
- **Why unresolved:** "Complementarity" is demonstrated empirically but not formally defined or measured a priori, making it difficult to apply the framework to new, unstudied foundation models without trial and error.
- **What evidence would resolve it:** A correlation analysis showing that a specific metric (e.g., representational similarity or gradient conflict) between two candidate MFMs predicts the performance gain of the CoMA framework.

### Open Question 3
- **Question:** Can the Decomposed Mutual Information (DMI) formulation be adapted for dense prediction tasks (e.g., semantic segmentation) where the output space is continuous or high-dimensional?
- **Basis in paper:** [inferred] The DMI formulation relies on constructing a "Confident Joint Subset" based on discrete class indices ($S \subseteq C$) within a mini-batch.
- **Why unresolved:** The current mathematical formulation (Eq. 3) depends on the cardinality of the candidate class subset ($|S|$), which assumes a discrete label space. It is unclear how the "confident region" would be defined or suppressed for pixel-level predictions.
- **What evidence would resolve it:** A modified theoretical formulation of DMI applicable to continuous variables and experimental validation on a segmentation benchmark (e.g., GTAV $\to$ Cityscapes).

## Limitations

- The bidirectional adaptation framework requires substantial computational resources during the burn-in phase to generate pseudo-labels for the BLIP-proxy model
- The DMI formulation depends heavily on batch size and may not generalize well to extremely imbalanced datasets with many classes
- The assumption of complementary semantic coverage between CLIP and BLIP may not hold across all domain pairs, particularly in specialized domains where both models exhibit similar biases

## Confidence

- **High confidence**: Claims about computational overhead increase (+66% training time, +50% GPU memory) and inference efficiency (no FM overhead) are supported by Table 10
- **Medium confidence**: Performance improvements over baseline methods are well-documented but may be sensitive to hyperparameter choices (α, β, λ) not fully explored in the paper
- **Low confidence**: The generalizability of the CLIP+BLIP complementarity assumption across diverse domains beyond the tested benchmarks remains unproven

## Next Checks

1. **Cross-domain generalization test**: Apply CoMA to specialized domains (medical imaging, satellite imagery) where CLIP and BLIP may have limited pre-training coverage to verify the complementarity assumption holds
2. **Resource-constrained evaluation**: Implement CoMA on a single GPU with batch size 8 to measure the practical impact of the training time overhead and identify the minimum viable configuration
3. **Alternative MFM pairing analysis**: Replace CLIP+BLIP with other vision-language foundation model pairs (e.g., CLIP+OWL-ViT, BLIP+ALIGN) to determine if the bidirectional framework generalizes beyond the specific models used