---
ver: rpa2
title: Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial
  learning
arxiv_id: '2503.18569'
source_url: https://arxiv.org/abs/2503.18569
tags:
- samples
- class
- minority
- data
- majority
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Anch-SCGAN, a novel oversampling framework
  for imbalanced tabular data using contrastive and adversarial learning. The method
  first selects anchor samples near the decision boundary and trains an MLP classifier
  to provide class representations.
---

# Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial learning

## Quick Facts
- arXiv ID: 2503.18569
- Source URL: https://arxiv.org/abs/2503.18569
- Reference count: 40
- Introduces Anch-SCGAN, a novel oversampling framework achieving 16.96% AUC improvement over original data

## Executive Summary
This paper introduces Anch-SCGAN, a novel oversampling framework for imbalanced tabular data that combines contrastive and adversarial learning. The method first identifies anchor samples near the decision boundary, trains an MLP classifier to provide class representations, and then employs a customized Conditional GAN with two specialized generators (minority and majority) and a discriminator enhanced with class-specific features. A novel anchor loss based on contrastive learning and a stabilizing scoring strategy are incorporated to improve sample quality and training stability. Experimental results on 16 imbalanced datasets demonstrate that Anch-SCGAN outperforms existing methods, achieving significant improvements in both AUC and F1-scores for minority class classification.

## Method Summary
Anch-SCGAN is a two-stage oversampling framework that addresses class imbalance in tabular data. First, it identifies anchor samples near the decision boundary and trains an MLP classifier to obtain class representations. Second, it employs a customized Conditional GAN with two specialized generators (one for minority and one for majority classes) and a discriminator enhanced with class-specific features from the pre-trained MLP. The framework incorporates a novel anchor loss based on contrastive learning and a stabilizing scoring strategy to improve sample quality and training stability. The method generates synthetic samples that better represent the minority class while maintaining realistic data distributions, leading to improved classification performance on imbalanced datasets.

## Key Results
- Achieves 16.96% average AUC improvement over original imbalanced data
- Outperforms baseline GAN-based techniques by 2.6-3.3% on average
- Achieves highest F1-scores on 14 out of 16 tested datasets
- Demonstrates superior performance in minority class classification across diverse datasets

## Why This Works (Mechanism)
The method leverages anchor-based sample selection to identify critical decision boundary regions where synthetic samples can have the most impact. The contrastive learning component ensures that generated samples maintain appropriate semantic relationships with their class representations. The two-generator architecture allows specialized handling of minority and majority class characteristics, while the enhanced discriminator with class-specific features improves sample quality assessment. The anchor loss and scoring strategy work together to stabilize training and ensure that generated samples are both diverse and representative of their respective classes.

## Foundational Learning
- **Contrastive learning**: Why needed - to maintain semantic relationships between samples and class representations; Quick check - verify that anchor samples are properly clustered in the learned representation space
- **Conditional GAN architecture**: Why needed - to generate class-specific samples while maintaining data distribution characteristics; Quick check - ensure that generator outputs match target class distributions
- **Anchor-based sample selection**: Why needed - to identify critical decision boundary regions for effective oversampling; Quick check - validate that selected anchors are near actual decision boundaries
- **Class representation learning**: Why needed - to provide meaningful features for the discriminator and guide sample generation; Quick check - confirm that MLP classifier achieves reasonable baseline performance
- **Two-generator architecture**: Why needed - to allow specialized handling of minority and majority class characteristics; Quick check - verify that each generator produces samples with appropriate class characteristics
- **Discriminator enhancement**: Why needed - to improve sample quality assessment using class-specific features; Quick check - ensure discriminator can distinguish real from generated samples

## Architecture Onboarding
**Component map**: Data -> Anchor Selection -> MLP Classifier -> GAN (Generator1 + Generator2) -> Discriminator -> Output Samples

**Critical path**: Anchor selection and MLP training provide class representations that guide the GAN's two generators. The discriminator, enhanced with class-specific features, evaluates sample quality. The anchor loss and scoring strategy stabilize training and ensure sample diversity.

**Design tradeoffs**: The two-generator architecture increases model complexity but allows specialized handling of class characteristics. Contrastive learning adds computational overhead but improves sample quality. Anchor-based selection focuses on decision boundary regions but may miss other important areas.

**Failure signatures**: Poor anchor selection leading to ineffective oversampling, unstable GAN training resulting in mode collapse, inadequate class representation causing poor sample quality, or imbalanced generator performance favoring one class over another.

**First experiments**: 1) Validate anchor selection effectiveness on a simple binary classification dataset, 2) Test single-generator vs two-generator performance to isolate architecture benefits, 3) Compare contrastive loss vs standard GAN loss to measure contribution of this component

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but the limited scope of evaluation on 16 datasets and lack of statistical significance testing represent implicit areas for further investigation.

## Limitations
- Experimental evaluation limited to 16 datasets, potentially restricting generalizability
- No statistical significance testing provided for performance claims
- Focus on tabular data excludes applicability to other data types
- Two-generator architecture may pose scalability challenges for larger datasets
- Limited analysis of failure cases or scenarios where anchor selection might be problematic

## Confidence
- Performance improvement claims: High - based on systematic comparison across multiple datasets
- Anchor-based approach effectiveness: Medium - novel but limited ablation studies
- Contrastive learning contribution: Medium - effectiveness demonstrated but not extensively isolated

## Next Checks
1. Conduct statistical significance testing (e.g., paired t-tests or Wilcoxon signed-rank tests) across datasets to validate performance claims
2. Perform ablation studies to isolate the contribution of individual components (anchor selection, contrastive loss, two-generator architecture)
3. Test the method on additional datasets with different characteristics (dimensionality, imbalance ratios, domain types) to assess generalizability