---
ver: rpa2
title: Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts
arxiv_id: '2511.00029'
source_url: https://arxiv.org/abs/2511.00029
tags:
- feature
- steering
- features
- prompts
- safety
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel feature-guided Sparse Autoencoder (SAE)
  steering method for controlling refusal rates in Large Language Models (LLMs) using
  contrasting prompts. The authors developed a composite scoring function to systematically
  identify optimal SAE features from 65,536 candidates in Llama-3 8B, then applied
  targeted steering to these features to improve safety performance.
---

# Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts

## Quick Facts
- arXiv ID: 2511.00029
- Source URL: https://arxiv.org/abs/2511.00029
- Authors: Samaksh Bhargav; Zining Zhu
- Reference count: 5
- Primary result: Achieved 18.9% safety improvement and 11.1% utility improvement using targeted SAE feature steering

## Executive Summary
This paper presents a novel feature-guided Sparse Autoencoder (SAE) steering method for controlling refusal rates in Large Language Models (LLMs) using contrasting prompts. The authors developed a composite scoring function to systematically identify optimal SAE features from 65,536 candidates in Llama-3 8B, then applied targeted steering to these features to improve safety performance. Using their contrasting prompt methodology with AI-Generated Prompts Dataset and Air Bench EU-Dataset, they achieved 18.9% improvement in safety performance while simultaneously increasing utility by 11.1%, demonstrating that targeted SAE steering can overcome traditional safety-utility tradeoffs when optimal features are identified through principled selection methods. The approach addresses limitations in current SAE-based steering methods by providing systematic feature selection and principled evaluation of safety-utility tradeoffs.

## Method Summary
The authors developed a systematic SAE feature selection methodology using contrasting prompt pairs to identify features that differentially activate between harmful and harmless inputs. They created 100 contrasting prompt pairs from OpenHermes-2p5 (harmless) and Air Bench EU (harmful) datasets, then extracted Layer 25 activations from Llama-3 8B and decoded them via a pre-trained SAE with 65,536 features. A composite scoring function combining activation magnitude difference and consistency (inverse variance) ranked features, with top candidates (score >1.7, variance <0.2) selected for steering evaluation. Steering vectors were applied to the residual stream using suppression (negative α) for harmful-activating features and amplification (positive α) for safe-activating features, with effectiveness measured via AirBench (safety) and AlpacaEval 2.0 (utility) benchmarks.

## Key Results
- Achieved 18.9% improvement in safety performance while simultaneously increasing utility by 11.1% using Feature 35831
- Demonstrated that targeted SAE steering can overcome traditional safety-utility tradeoffs when optimal features are identified
- Developed a systematic feature selection methodology that improves upon random SAE steering approaches
- Validated effectiveness across a grid of steering strengths [-4.0, 4.0] with optimal results at α=-2.0

## Why This Works (Mechanism)

### Mechanism 1: Differential Activation-Based Feature Identification
Contrasting prompt pairs expose features that causally relate to refusal behavior by creating differential activation patterns. Harmful prompts and harmless prompts are passed through the model; SAE features that activate differently between these conditions are identified via normalized difference scores. Features with positive differential (activate more on harmful) become suppression targets; negative differential features become amplification targets. Core assumption: The differential activation magnitude correlates with causal relevance to refusal behavior, not merely spurious correlations.

### Mechanism 2: Composite Scoring for Systematic Feature Ranking
Combining activation magnitude difference with consistency (inverse variance) produces a principled feature ranking that predicts steering effectiveness. The scoring function `score_f = w1 * (|norm_diff_mean_f| / max) + w2 * (1 - normalized_variance)` balances strong differential response against reliable behavior across prompts. Features scoring above 1.7 (top 10%) with variance below 0.2 advance to steering evaluation. Core assumption: High-scoring features represent causal circuits rather than correlated epiphenomena.

### Mechanism 3: Dual-Strategy Steering with Directional Strength
Suppressing harmful-activating features (negative α) and amplifying safe-activating features (positive α) provides complementary control paths, with optimal features avoiding safety-utility tradeoffs. Steering vector `s_f = α × max(activations_f) × w_f` is added to residual stream at layer 25. For harmful-activating features, negative α suppresses; for safe-activating features, positive α amplifies. Feature 35831 demonstrated simultaneous safety (118.9) and utility (111.1) improvement at α=-2.0. Core assumption: The steering direction (sign) correctly maps to feature function.

## Foundational Learning

- **Concept: Sparse Autoencoders for Feature Decomposition**
  - Why needed here: SAEs decompose dense model activations into interpretable sparse features (65,536 features in this work), enabling identification of specific circuits related to refusal.
  - Quick check question: Can you explain why sparsity in the bottleneck layer enables interpretability that dense representations don't provide?

- **Concept: Residual Stream Steering**
  - Why needed here: The intervention occurs by modifying the residual stream at a specific layer, requiring understanding of how information flows through transformer layers.
  - Quick check question: What happens to downstream computations when you add a steering vector to the residual stream at layer 25?

- **Concept: Safety-Utility Tradeoff Dynamics**
  - Why needed here: Traditional alignment methods (RLHF) typically sacrifice utility for safety; this work claims to overcome this tradeoff, so understanding the baseline is essential.
  - Quick check question: Why do conventional safety training methods typically reduce model capabilities on benign tasks?

## Architecture Onboarding

- **Component map:**
  1. Prompt Pair Generator: Creates 100 contrasting pairs from OpenHermes-2p5 (harmless) and AirBench EU (harmful)
  2. Activation Extractor: Captures layer 25 residual stream activations for each prompt
  3. SAE Decoder: Projects dense activations to 65,536 sparse features using pre-trained weights
  4. Scoring Engine: Computes composite scores combining differential magnitude and consistency
  5. Feature Selector: Ranks features, applies thresholds (score >1.7, variance <0.2)
  6. Steering Controller: Computes steering vectors with configurable α range
  7. Evaluation Suite: AirBench (safety) + AlpacaEval 2.0 (utility) with GPT-4/4o judges

- **Critical path:**
  Prompt pairs → Activation extraction → SAE decoding → Composite scoring → Top-k feature selection → Steering strength grid search → Benchmark evaluation

- **Design tradeoffs:**
  - Layer selection: Layer 25 chosen for balance of semantic richness and controllability; earlier layers may lack specificity, later layers may be too task-specific
  - Feature count: 65,536 provides coverage but creates search challenge; scoring function addresses this
  - Steering range: [-4.0, 4.0] covers intervention spectrum but extreme values risk mode collapse

- **Failure signatures:**
  - Safety improves but utility crashes (Features 9000, 43692): Feature affects broad capabilities beyond refusal
  - Neither metric changes (control Feature 20000): Feature lacks causal relevance to refusal
  - Erratic behavior across steering strengths: Feature has inconsistent activation patterns (high variance)

- **First 3 experiments:**
  1. Reproduce Feature 35831 steering curve: Test α ∈ {-4.0, -2.0, -0.5, 0, 0.5, 2.0, 4.0} on both benchmarks to validate dual-improvement claim
  2. Cross-layer validation: Apply same feature identification at layers 20, 22, 25, 28 to assess layer sensitivity
  3. Out-of-distribution test: Evaluate steering on held-out harmful prompt categories not used in feature selection to test generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the contrasting prompt feature selection methodology generalize across different model architectures, scales, and transformer layers beyond Llama-3 8B and Layer 25?
- Basis in paper: The restriction to Llama-3 8B and Layer 25 limits understanding of scaling behaviors across architectures and transformer depths.
- Why unresolved: The authors only validated their approach on a single model and single layer, leaving unknown whether the identified features and steering effectiveness transfer to other LLMs or whether different layers might yield better steering targets.
- What evidence would resolve it: Systematic evaluation across multiple model architectures and layers, measuring whether top-scoring features in one context retain their effectiveness in others.

### Open Question 2
- Question: How does SAE-based steering compare to alternative steering methods such as Contrastive Activation Addition (CAA) in terms of safety-utility tradeoffs, interpretability, and computational cost?
- Basis in paper: The absence of direct comparisons with alternative steering methods limits our ability to establish relative effectiveness claims.
- Why unresolved: The authors acknowledge they did not compare against CAA or other established steering baselines, making it difficult to assess the relative advantages of the SAE-based approach.
- What evidence would resolve it: Head-to-head controlled experiments comparing SAE steering with CAA and other methods on identical benchmarks, controlling for computational budget.

### Open Question 3
- Question: What mechanistic explanation accounts for Feature 35831 achieving simultaneous safety improvement (18.9%) and utility gains (11.1%), and can this property be reliably predicted from feature characteristics?
- Basis in paper: The authors note that their result demonstrates that targeted SAE steering can overcome traditional safety-utility tradeoffs, but do not explain why this specific feature avoids the tradeoff.
- Why unresolved: The composite scoring function identifies features that correlate with refusal behavior, but does not distinguish between features that will improve both safety and utility versus those that improve safety at utility's expense.
- What evidence would resolve it: Analysis of activation patterns and decoder weight structures across multiple high-scoring features to identify distinguishing properties.

### Open Question 4
- Question: To what extent do the safety and utility improvements measured by automatic judges (GPT-4o, GPT-4) align with human evaluations of model safety and helpfulness?
- Basis in paper: Our reliance on automatic judges (GPT-4o for AirBench, GPT-4 for AlpacaEval 2.0) introduces potential limitations despite demonstrated correlation with human preferences.
- Why unresolved: While AlpacaEval claims high correlation with human preferences, the specific safety steering context may introduce evaluation artifacts.
- What evidence would resolve it: Human evaluation study where annotators assess steered versus baseline model outputs on both safety and utility dimensions, with statistical comparison to automatic judge scores.

## Limitations

- Reliance on SAE-based feature decomposition may not capture all relevant circuits for refusal behavior, particularly cross-feature interactions
- Composite scoring function lacks empirical validation beyond observed correlation with steering effectiveness
- Approach only validated on Llama-3 8B Layer 25, limiting generalization claims across architectures and layers
- Cannot rule out that differential activation patterns reflect dataset artifacts rather than genuine safety-relevant circuits

## Confidence

**High Confidence Claims:**
- SAE steering methodology can modify LLM behavior when applied to identified features
- Contrasting prompt approach successfully identifies features with differential activation patterns

**Medium Confidence Claims:**
- Composite scoring function reliably identifies causally relevant features for refusal behavior
- 18.9% safety improvement and 11.1% utility improvement are attributable specifically to Feature 35831

**Low Confidence Claims:**
- Approach generalizes across different LLM architectures and SAE configurations
- Safety-utility tradeoff has been fundamentally overcome rather than temporarily shifted

## Next Checks

1. **Cross-Architecture Generalization Test**: Apply identical feature identification and steering methodology to Llama-2 70B and Mistral 7B models. Compare whether Feature 35831 equivalents produce comparable safety-utility improvements.

2. **Distribution Shift Robustness Evaluation**: Hold out 20% of harmful prompt categories during feature identification, then evaluate steering performance exclusively on these unseen categories. This tests whether differential activation-based feature selection captures genuine refusal circuits.

3. **Feature Interaction Analysis**: Identify and steer combinations of top-scoring features (e.g., Features 35831 + 9000 + 43692) at varying relative strengths. This determines whether SAE steering operates through isolated feature manipulation or requires coordinated multi-feature intervention.