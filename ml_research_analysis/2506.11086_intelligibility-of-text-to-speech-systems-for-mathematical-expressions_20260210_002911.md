---
ver: rpa2
title: Intelligibility of Text-to-Speech Systems for Mathematical Expressions
arxiv_id: '2506.11086'
source_url: https://arxiv.org/abs/2506.11086
tags:
- audio
- categories
- audiomx
- latex
- intelligibility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the intelligibility of five state-of-the-art
  TTS models when converting mathematical expressions into speech. Since TTS models
  cannot directly process LaTeX, two LLMs (QWEN and GPT4) are used to generate English
  pronunciations, which are then input to the TTS models.
---

# Intelligibility of Text-to-Speech Systems for Mathematical Expressions

## Quick Facts
- **arXiv ID**: 2506.11086
- **Source URL**: https://arxiv.org/abs/2506.11086
- **Reference count**: 0
- **Primary result**: TTS outputs for mathematical expressions are not always intelligible, with performance varying across expression categories and TTS models

## Executive Summary
This study evaluates the intelligibility of five state-of-the-art TTS models when converting mathematical expressions into speech. Since TTS models cannot directly process LaTeX, two LLMs (QWEN and GPT4) are used to generate English pronunciations, which are then input to the TTS models. Listening tests with 49 participants assess user perception through Mean Opinion Scores and transcription accuracy using three metrics: Count of Correct, LCER, and TeXBLEU. Results show that TTS outputs for mathematical expressions are not always intelligible, with performance varying across expression categories and TTS models. For most categories, TTS models perform significantly worse than expert-rendered audio. The choice of LLM has limited impact when pronunciations are correct. These findings highlight the need for improved TTS models tailored to mathematical expressions.

## Method Summary
The study uses five TTS models to convert mathematical expressions to speech through a two-step process: first, LLMs (QWEN and GPT4) convert LaTeX expressions to English pronunciations, then TTS models generate the final audio output. The evaluation framework employs listening tests with 49 participants who assess intelligibility using Mean Opinion Scores and transcription accuracy. Three metrics are used for quantitative assessment: Count of Correct (percentage of correct words), LCER (Levenshtein Character Error Rate), and TeXBLEU (modified BLEU score for LaTeX structure). The study compares TTS model performance against expert-rendered audio as ground truth across different mathematical expression categories including fractions, exponents, integrals, and complex equations.

## Key Results
- TTS outputs for mathematical expressions show significant intelligibility issues across all tested models
- Performance varies substantially across different categories of mathematical expressions
- TTS models perform significantly worse than expert-rendered audio for most expression categories
- Choice of LLM has limited impact when generated pronunciations are correct

## Why This Works (Mechanism)
The study demonstrates that mathematical expressions require specialized handling in TTS systems due to their complex hierarchical structure and precise semantic requirements. The mechanism involves converting symbolic mathematical notation (LaTeX) to spoken language through intermediate LLM processing, then synthesizing speech. The failure modes identified include incorrect pronunciation generation by LLMs, inadequate prosodic features in TTS synthesis for mathematical structure, and listener difficulty in parsing complex mathematical relationships from audio alone. The study's quantitative metrics (Count of Correct, LCER, TeXBLEU) effectively capture different aspects of intelligibility failures, from word-level accuracy to structural preservation.

## Foundational Learning

**Mathematical Expression Structure**: Understanding hierarchical and nested relationships in mathematical notation is crucial for accurate speech synthesis. Quick check: Verify understanding by converting complex nested expressions to speech.

**LaTeX to Natural Language Conversion**: Converting symbolic notation to spoken language requires preserving semantic meaning while maintaining grammatical correctness. Quick check: Compare LLM-generated pronunciations against expert human conversions.

**Speech Synthesis for Technical Content**: Technical mathematical content requires specific prosodic features to convey structural relationships. Quick check: Analyze intonation patterns in expert-rendered mathematical speech.

## Architecture Onboarding

**Component Map**: LaTeX -> LLM (QWEN/GPT4) -> English Pronunciations -> TTS Models -> Audio Output -> Listener Evaluation

**Critical Path**: The core workflow involves LaTeX expression input, LLM pronunciation generation, TTS synthesis, and listener comprehension assessment. The critical path determines overall intelligibility and requires all components to function correctly.

**Design Tradeoffs**: The study uses intermediate LLM conversion rather than direct LaTeX processing, trading computational complexity for leveraging existing TTS infrastructure. This approach limits handling of complex mathematical structures but enables practical evaluation.

**Failure Signatures**: Common failure modes include incorrect LLM pronunciation generation, loss of mathematical hierarchy in speech synthesis, and listener confusion with complex nested expressions. These manifest as low Count of Correct scores, high LCER values, and poor TeXBLEU performance.

**First Experiments**:
1. Test individual TTS models with simple fractions to establish baseline performance
2. Evaluate LLM pronunciation accuracy with basic arithmetic expressions
3. Compare expert human narration against TTS output for complex integrals

## Open Questions the Paper Calls Out
None

## Limitations
- Small participant pool of 49 participants may not represent diverse user populations
- Evaluation limited to English language only, restricting applicability to other languages and notation systems
- Study assumes LLM-generated pronunciations are accurate without systematic validation

## Confidence

**Core Finding Confidence**: High
- Consistent performance degradation across multiple metrics (Count of Correct, LCER, TeXBLEU)
- Statistical significance tests support the conclusion of TTS limitations

**Comparative Model Confidence**: Medium
- Limited number of TTS models tested
- Potential for performance variations across untested mathematical expression types

## Next Checks

1. Conduct listening tests with larger, more diverse participant pool including non-native English speakers and visually impaired users
2. Implement systematic validation of LLM pronunciation accuracy against expert-curated reference pronunciations
3. Test additional TTS models and include more complex mathematical expressions with multi-line equations and advanced structures