---
ver: rpa2
title: Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in
  UGC Platforms
arxiv_id: '2508.02506'
source_url: https://arxiv.org/abs/2508.02506
tags:
- relevance
- document
- query
- reasoning
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces R\xB3A, a novel decomposed reasoning framework\
  \ for relevance assessment in UGC platforms. The method addresses challenges of\
  \ ambiguous user intent and noisy content by leveraging auxiliary in-platform documents\
  \ to infer query intent and requiring verbatim fragment extraction from candidate\
  \ documents."
---

# Decomposed Reasoning with Reinforcement Learning for Relevance Assessment in UGC Platforms

## Quick Facts
- arXiv ID: 2508.02506
- Source URL: https://arxiv.org/abs/2508.02506
- Reference count: 20
- R³A achieves 83.1% AUC and 65.2% accuracy on NoteRel dataset

## Executive Summary
This paper introduces R³A, a decomposed reasoning framework for relevance assessment in user-generated content platforms. The method addresses challenges of ambiguous user intent and noisy content by leveraging auxiliary in-platform documents to infer query intent and requiring verbatim fragment extraction from candidate documents. Based on reinforcement learning with Group Relative Policy Optimization, R³A performs a two-round interaction: first inferring intent from auxiliary documents, then extracting relevant fragments to ground its assessment.

Experiments on the NoteRel dataset demonstrate R³A significantly outperforms baseline methods, achieving 83.1% AUC on the 0/12 metric and 65.2% accuracy. Notably, the distilled R³A-1.5B model surpasses the larger 7B SFT model by 1.7% in accuracy and shows practical effectiveness with a 1.03% reduction in re-query rate in online A/B testing.

## Method Summary
R³A employs a two-round interaction framework using reinforcement learning with Group Relative Policy Optimization. The method first infers user intent by analyzing auxiliary in-platform documents, then extracts verbatim fragments from candidate documents to ground its relevance assessment. The RL objective rewards accurate intent inference and precise fragment extraction, with the policy trained to maximize the final relevance assessment accuracy. The framework addresses UGC-specific challenges including ambiguous queries, noisy content, and diverse user intents by decomposing the relevance assessment task into interpretable sub-tasks.

## Key Results
- R³A achieves 83.1% AUC on the 0/12 metric and 65.2% accuracy on NoteRel dataset
- Distilled R³A-1.5B model outperforms 7B SFT model by 1.7% in accuracy
- Online A/B testing shows 1.03% reduction in re-query rate, demonstrating practical effectiveness

## Why This Works (Mechanism)
R³A's effectiveness stems from its decomposed reasoning approach that explicitly addresses UGC-specific challenges. By requiring verbatim fragment extraction, the method ensures concrete grounding of relevance assessments rather than relying on abstract reasoning. The two-round interaction allows the model to first establish a clear understanding of user intent through auxiliary documents before evaluating candidate content, creating a more focused and accurate assessment process.

## Foundational Learning

**Reinforcement Learning with Group Relative Policy Optimization** - This optimization technique enables stable policy learning by comparing performance within groups rather than absolute rewards, crucial for handling the sparse reward signals in relevance assessment tasks.

**Why needed**: Standard RL approaches struggle with the delayed and sparse rewards in multi-step reasoning tasks like relevance assessment.

**Quick check**: Verify that GRPO gradients are computed using relative performance within batches rather than absolute reward values.

**Verbatim Fragment Extraction** - The requirement to extract exact text passages from candidate documents provides concrete evidence for relevance judgments.

**Why needed**: Prevents vague or hallucinated reasoning by anchoring assessments to specific document content.

**Quick check**: Confirm that extracted fragments are exact substrings of the candidate documents without paraphrasing.

**Auxiliary Document Utilization** - Leveraging in-platform documents to infer user intent creates a richer context for relevance assessment.

**Why needed**: UGC queries are often ambiguous and benefit from additional context beyond the query text itself.

**Quick check**: Validate that auxiliary documents are actually relevant to the query intent and not just randomly selected.

## Architecture Onboarding

**Component map**: Query -> Auxiliary Document Analysis -> Intent Inference -> Candidate Document Analysis -> Fragment Extraction -> Relevance Assessment -> Final Score

**Critical path**: The two-round interaction sequence is critical - first intent inference from auxiliary documents, then fragment extraction and relevance assessment. Each round depends on successful completion of the previous step.

**Design tradeoffs**: 
- Verbosity vs. conciseness: Requires explicit fragment extraction which adds complexity but improves grounding
- Computational cost vs. accuracy: Two-round interaction increases inference time but significantly improves performance
- Model size vs. effectiveness: Distilled 1.5B model outperforms larger models, suggesting architectural efficiency

**Failure signatures**: 
- Poor intent inference leads to irrelevant fragment extraction and incorrect relevance scores
- Over-reliance on auxiliary documents when they're not representative of query intent
- Fragment extraction that's too narrow or too broad, missing key relevance signals

**First experiments**:
1. Run ablation tests removing auxiliary document analysis to measure its contribution to accuracy
2. Test with paraphrased fragment extraction instead of verbatim to evaluate grounding importance
3. Compare single-round vs. two-round interaction to quantify the benefit of decomposed reasoning

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Results rely heavily on a single NoteRel dataset, limiting generalizability to other UGC platforms
- Limited transparency in online A/B testing methodology and statistical validation
- Comparison between 1.5B and 7B models within same dataset context may not reflect real-world deployment scenarios

## Confidence

High: Decomposed reasoning approach with auxiliary document utilization appears technically sound and well-executed

Medium: Experimental results on NoteRel dataset, as dataset may be specialized and not fully representative of real-world UGC diversity

Medium: Online A/B testing results due to limited transparency in methodology and statistical validation

## Next Checks

1. Conduct cross-dataset validation by testing R³A on multiple UGC relevance datasets to assess generalization beyond NoteRel

2. Perform ablation studies removing the auxiliary document component to quantify its specific contribution to performance gains

3. Implement rigorous statistical analysis of online A/B testing results, including confidence intervals and effect size measurements to verify practical significance of the 1.03% re-query rate reduction