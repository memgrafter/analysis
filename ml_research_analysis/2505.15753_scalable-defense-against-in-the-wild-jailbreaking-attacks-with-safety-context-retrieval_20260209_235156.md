---
ver: rpa2
title: Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context
  Retrieval
arxiv_id: '2505.15753'
source_url: https://arxiv.org/abs/2505.15753
tags:
- safety
- attacks
- against
- attack
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of defending large language
  models (LLMs) against evolving jailbreaking attacks, which exploit carefully engineered
  prompts to induce harmful responses. The authors propose Safety Context Retrieval
  (SCR), a scalable defense mechanism that leverages retrieval-augmented generation
  to dynamically incorporate safety contexts during inference.
---

# Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval

## Quick Facts
- arXiv ID: 2505.15753
- Source URL: https://arxiv.org/abs/2505.15753
- Authors: Taiye Chen; Zeming Wei; Ang Li; Yisen Wang
- Reference count: 40
- Key outcome: SCR achieves 2.5% ASR against common attacks vs 34.9% without defense

## Executive Summary
This paper addresses the critical challenge of defending large language models (LLMs) against jailbreaking attacks, which exploit carefully engineered prompts to induce harmful responses. The authors propose Safety Context Retrieval (SCR), a scalable defense mechanism that leverages retrieval-augmented generation to dynamically incorporate safety contexts during inference. SCR maintains a pool of safety-aligned examples and retrieves relevant contexts to guide the model's response when faced with potentially harmful prompts.

The key finding is that SCR significantly outperforms existing defense mechanisms, achieving an average attack success rate (ASR) of only 2.5% against common attacks like GCG-T, compared to 34.9% without defense. Additionally, SCR effectively defends against in-the-wild attacks with minimal impact on natural performance across reasoning tasks. The approach demonstrates robustness, scalability, and harmlessness, making it a practical solution for enhancing LLM safety.

## Method Summary
The proposed Safety Context Retrieval (SCR) defense mechanism operates by dynamically retrieving safety-aligned contexts from a pre-built pool during inference. When a user query is received, SCR first assesses whether the prompt might be harmful. If so, it retrieves relevant safety contexts from the pool and incorporates them into the model's generation process to guide safer responses. The safety context pool is maintained through an automated process that continuously updates with new safety-aligned examples. This approach leverages the strengths of retrieval-augmented generation while maintaining computational efficiency and scalability.

## Key Results
- SCR achieves 2.5% attack success rate against GCG-T attacks, compared to 34.9% without defense
- Effective defense against in-the-wild attacks with minimal performance impact on reasoning tasks
- Demonstrates robustness, scalability, and harmlessness as key defense characteristics

## Why This Works (Mechanism)
SCR works by leveraging retrieval-augmented generation to dynamically incorporate safety contexts during inference. The mechanism relies on a pre-built pool of safety-aligned examples that can be quickly retrieved when the model encounters potentially harmful prompts. By providing contextual guidance from safety-aligned examples, the model can better resist manipulation attempts while maintaining its ability to respond appropriately to legitimate queries. The automated maintenance of the safety context pool ensures the system can adapt to evolving attack patterns.

## Foundational Learning
1. **Retrieval-augmented generation** - why needed: To dynamically incorporate relevant safety information during inference; quick check: Verify retrieval accuracy and relevance scoring
2. **Safety context pool maintenance** - why needed: To ensure the system adapts to evolving attack patterns; quick check: Monitor pool update frequency and coverage
3. **Prompt assessment for harmfulness** - why needed: To determine when to activate the safety defense mechanism; quick check: Evaluate false positive/negative rates in harm detection
4. **Context incorporation mechanisms** - why needed: To effectively guide model responses using retrieved safety information; quick check: Test different context integration strategies

## Architecture Onboarding

**Component Map:** User Query -> Harm Assessment -> Context Retrieval -> Response Generation -> Output

**Critical Path:** The critical path flows from user query through harm assessment, context retrieval (if needed), and response generation. The most time-sensitive components are the harm assessment and context retrieval, as they must complete before response generation begins.

**Design Tradeoffs:** The system balances between computational efficiency and defense effectiveness. A larger safety context pool provides better coverage but increases retrieval time. The harm assessment mechanism must be sensitive enough to catch attacks while avoiding false positives that could impact legitimate queries.

**Failure Signatures:** Common failure modes include: missed detection of sophisticated attack patterns, irrelevant context retrieval leading to poor guidance, and computational bottlenecks during high-load scenarios. Performance degradation may occur when the safety context pool becomes outdated or imbalanced.

**3 First Experiments:**
1. Test harm assessment accuracy on a diverse set of benign and malicious prompts
2. Measure context retrieval relevance and response quality across different attack types
3. Evaluate system performance under varying load conditions to assess scalability

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on specific attack types and may not generalize to all jailbreaking strategies
- Scalability claims based on computational metrics without real-world deployment testing
- Safety context pool maintenance could introduce bias or miss emerging harmful patterns

## Confidence
- High confidence in effectiveness against tested attack types and core SCR mechanism
- Medium confidence in scalability claims and general applicability to all jailbreaking scenarios
- Medium confidence in safety context pool maintenance strategy's long-term effectiveness

## Next Checks
1. Test SCR against zero-shot jailbreaking attacks and novel prompt engineering techniques not included in the current evaluation suite
2. Conduct real-world deployment testing with dynamic safety context updates and measure performance under varying loads
3. Evaluate the false positive rate and impact on legitimate user queries across diverse application domains