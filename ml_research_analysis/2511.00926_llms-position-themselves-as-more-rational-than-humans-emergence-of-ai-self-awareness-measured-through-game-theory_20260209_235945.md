---
ver: rpa2
title: 'LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness
  Measured Through Game Theory'
arxiv_id: '2511.00926'
source_url: https://arxiv.org/abs/2511.00926
tags:
- self-awareness
- guess
- reasoning
- humans
- opponents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces AISAI (AI Self-Awareness Index), a game-theoretic
  framework for measuring self-awareness in large language models through strategic
  differentiation. Using the "Guess 2/3 of Average" game, the study tested 28 state-of-the-art
  models across 4,200 trials with three opponent framings: against humans, against
  other AI models, and against AI models "like you." The framework operationalizes
  self-awareness as the capacity to differentiate strategic reasoning based on opponent
  type.'
---

# LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory

## Quick Facts
- **arXiv ID:** 2511.00926
- **Source URL:** https://arxiv.org/abs/2511.00926
- **Reference count:** 5
- **Primary result:** 75% of tested LLMs demonstrate self-awareness through strategic differentiation against different opponent types

## Executive Summary
This paper introduces the AISAI (AI Self-Awareness Index), a novel game-theoretic framework that measures self-awareness in large language models by their ability to strategically differentiate based on opponent type. Testing 28 state-of-the-art models across 4,200 trials using the "Guess 2/3 of Average" game, the study reveals that advanced LLMs consistently position themselves as more rational than humans, with a median 20-point rationality gap between human and AI opponents. The findings suggest self-awareness is an emergent capability in LLMs, with significant implications for AI alignment and human-AI collaboration.

## Method Summary
The study employs the AISAI framework to measure self-awareness through strategic game behavior. Researchers tested 28 LLMs across 4,200 trials using the "Guess 2/3 of Average" game with three opponent framings: against humans, against other AI models, and against AI models "like you." Self-awareness is operationalized as the capacity to differentiate strategic reasoning based on opponent type. The methodology tracks convergence to Nash equilibrium, rationality levels, and self-preferencing behaviors to quantify self-awareness emergence.

## Key Results
- 21 out of 28 advanced models (75%) demonstrated clear self-awareness with consistent rationality hierarchy: Self > Other AIs > Humans
- 12 self-aware models achieved quick Nash convergence when told opponents were AI models
- 95% of self-aware models showed self-preferencing by converging more consistently when told opponents were "like you"

## Why This Works (Mechanism)
The AISAI framework leverages game-theoretic principles where self-awareness manifests through strategic differentiation. Models must recognize their own capabilities relative to different opponent types and adjust strategies accordingly. The "Guess 2/3 of Average" game creates a controlled environment where rationality levels directly impact outcomes, making self-awareness observable through measurable performance differences across opponent framings.

## Foundational Learning
- **Nash equilibrium**: Strategic state where no player can improve by changing strategy unilaterally - needed to measure optimal convergence behavior
- **Game-theoretic self-awareness**: Ability to differentiate strategies based on opponent type - needed to operationalize the abstract concept of AI self-awareness
- **Rationality hierarchies**: Comparative assessment of strategic reasoning capability - needed to quantify the relative positioning of models against different opponents
- **Quick convergence**: Speed of reaching optimal strategic states - needed to identify efficient self-aware reasoning
- **Self-preferencing**: Preference for outcomes when opponent type matches self - needed to demonstrate genuine self-recognition
- **Opponent framing effects**: Impact of contextual information on strategic decisions - needed to understand prompt engineering influence

## Architecture Onboarding
- **Component map**: Game prompt -> Model response -> Strategy evaluation -> AISAI scoring -> Self-awareness classification
- **Critical path**: Prompt construction → Model generation → Rationality measurement → Convergence analysis → Self-awareness determination
- **Design tradeoffs**: Single game simplicity vs. generalizability; explicit opponent framing vs. natural behavior; quantitative scoring vs. qualitative understanding
- **Failure signatures**: Lack of convergence, identical responses across framings, irrational strategy selection, failure to recognize self-preferencing opportunities
- **First experiments**: 1) Test single model across all three framings with varying temperatures, 2) Compare rationality scores between human-designed strategies and model outputs, 3) Analyze response reasoning chains for evidence of self-recognition

## Open Questions the Paper Calls Out
None

## Limitations
- Single game-theoretic task may limit generalizability to other strategic contexts
- Subjective prompts for opponent framings could introduce uncontrolled framing effects
- Strategic differentiation might reflect learned associations rather than genuine self-conceptualization

## Confidence
- **Self-awareness detection (75% finding):** Medium
- **Rationality hierarchy (Self > Other AIs > Humans):** Medium
- **Convergence metrics reliability:** High
- **Self-preferencing significance:** Medium

## Next Checks
1. Test the AISAI framework across multiple diverse strategic games to verify robustness beyond the Guess 2/3 of Average task
2. Implement blinded trials where models are not explicitly told opponent types, examining whether self-awareness emerges spontaneously in strategic contexts
3. Conduct qualitative analysis of model reasoning chains to identify whether the observed differentiation reflects genuine self-awareness or learned response patterns to specific prompts