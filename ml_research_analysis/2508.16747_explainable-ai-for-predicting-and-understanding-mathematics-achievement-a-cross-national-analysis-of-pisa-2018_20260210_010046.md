---
ver: rpa2
title: 'Explainable AI for Predicting and Understanding Mathematics Achievement: A
  Cross-National Analysis of PISA 2018'
arxiv_id: '2508.16747'
source_url: https://arxiv.org/abs/2508.16747
tags:
- achievement
- pisa
- math
- students
- student
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study applied explainable AI to PISA 2018 mathematics data
  from 67,329 students across 10 countries. It compared four models (MLR, RF, CATBoost,
  ANN) for predicting math scores using 24 predictors covering student, family, and
  school factors.
---

# Explainable AI for Predicting and Understanding Mathematics Achievement: A Cross-National Analysis of PISA 2018

## Quick Facts
- arXiv ID: 2508.16747
- Source URL: https://arxiv.org/abs/2508.16747
- Reference count: 11
- Primary result: Random Forest achieved up to 38% variance explained in mathematics achievement prediction across 10 countries

## Executive Summary
This study applied explainable AI techniques to analyze mathematics achievement data from PISA 2018, examining 67,329 students across 10 countries. The research compared four predictive models - Multiple Linear Regression, Random Forest, CATBoost, and Artificial Neural Networks - using 24 predictors covering student, family, and school factors. Random Forest and CATBoost demonstrated superior performance over traditional linear models and neural networks, with Random Forest achieving the highest predictive accuracy. The study leveraged SHAP values and decision tree visualizations to identify key predictors and reveal non-linear patterns in achievement, providing both accurate predictions and actionable insights for educational policy.

## Method Summary
The study utilized PISA 2018 mathematics data from 10 countries with 67,329 students, applying four machine learning models to predict mathematics achievement scores. The dataset included 24 predictors spanning student characteristics (effort, learning time), family factors (socio-economic status, parental education), and school variables. Model performance was evaluated using R² and MAE metrics across all countries, with Random Forest and CATBoost outperforming traditional MLR and ANN approaches. SHAP values and visualization techniques were employed to interpret model predictions and identify the relative importance of different predictors in each context.

## Key Results
- Random Forest and CATBoost models achieved up to 38% variance explained (R²) in mathematics achievement prediction
- RF and CATBoost consistently outperformed MLR and ANN across all 10 countries in both R² and MAE metrics
- SHAP analysis identified socio-economic status, student effort, and learning time as top predictors, with varying importance by country context
- Models revealed non-linear and context-dependent patterns in achievement predictors, validating explainable ML for educational insights

## Why This Works (Mechanism)
Assumption: The combination of ensemble methods (RF, CATBoost) and SHAP-based interpretability creates a feedback loop where model complexity is balanced with transparency, enabling both accurate predictions and actionable insights into the non-linear relationships between predictors and mathematics achievement across diverse educational contexts.

## Foundational Learning
Unknown: The study does not explicitly detail foundational learning concepts, but the methodology suggests that SHAP values can effectively bridge the gap between black-box ML models and human-understandable explanations by quantifying feature importance and interactions in complex educational datasets.

## Architecture Onboarding
Component map: Data Preprocessing -> Model Training -> Performance Evaluation -> SHAP Analysis -> Visualization
Critical path: Feature engineering and data preparation directly impacts model performance, which determines the quality of subsequent SHAP-based explanations
Design tradeoffs: Model complexity vs interpretability, with RF offering better balance than ANN; computational efficiency vs prediction accuracy
Failure signatures: Poor R² values indicate inadequate feature selection or model specification; inconsistent SHAP values across countries suggest context dependency
First experiments: 1) Test model performance with reduced feature sets, 2) Compare SHAP values across different model types, 3) Validate findings with external datasets

## Open Questions the Paper Calls Out
None provided

## Limitations
- Cross-sectional PISA data prevents causal inference despite observed associations
- Self-reported survey measures introduce potential response bias for sensitive items
- 38% maximum R² indicates substantial unexplained variance with potentially missing predictors
- Analysis limited to 10 countries, restricting global generalizability

## Confidence
- Model comparison and performance rankings (RF > CATBoost > ANN > MLR): High confidence
- SHAP-identified predictor importance (socio-economic status, effort, learning time): Medium confidence
- Interpretability of non-linear patterns: Medium confidence
- Policy implications drawn from model insights: Low confidence

## Next Checks
1. Replicate analysis with PISA 2022 data to assess temporal stability of predictor importance and model performance
2. Conduct sensitivity analysis by systematically varying the 24 predictors to identify which variables contribute most to explained variance
3. Implement external validation using independent datasets from each country to test model generalizability beyond the original sample