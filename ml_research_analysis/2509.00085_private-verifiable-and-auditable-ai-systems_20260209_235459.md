---
ver: rpa2
title: Private, Verifiable, and Auditable AI Systems
arxiv_id: '2509.00085'
source_url: https://arxiv.org/abs/2509.00085
tags:
- data
- privacy
- these
- systems
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis addresses the critical challenge of building trustworthy
  AI systems by examining how to balance AI's utility with the needs for privacy,
  verifiability, and auditability. The research introduces technical solutions to
  enable verifiable and auditable claims about AI systems using zero-knowledge cryptography
  (zkSNARKs), allowing third parties to confirm model performance or fairness metrics
  without direct model access.
---

# Private, Verifiable, and Auditable AI Systems

## Quick Facts
- arXiv ID: 2509.00085
- Source URL: https://arxiv.org/abs/2509.00085
- Authors: Tobin South
- Reference count: 40
- This thesis addresses the critical challenge of building trustworthy AI systems by examining how to balance AI's utility with the needs for privacy, verifiability, and auditability.

## Executive Summary
This thesis tackles the fundamental challenge of creating trustworthy AI systems that can simultaneously deliver utility while ensuring privacy, verifiability, and auditability. The research presents a comprehensive framework for addressing these competing requirements through technical solutions grounded in cryptography and security principles. The work introduces novel approaches for verifiable AI system claims using zero-knowledge cryptography, secure retrieval-augmented generation systems, and authenticated delegation frameworks for autonomous agents.

The thesis argues that by applying rigorous cryptographic methods, particularly zero-knowledge proofs and secure multi-party computation, we can construct foundation model-based AI systems that reconcile the often-competing demands of privacy, verifiability, and auditability. These technical solutions enable third parties to confirm model performance or fairness metrics without direct model access, while ensuring private data remains protected and accountability is maintained in multi-agent AI systems.

## Method Summary
The research employs a combination of zero-knowledge cryptography (zkSNARKs), secure multi-party computation (MPC), and trusted execution environments (TEEs) to develop technical solutions for verifiable and auditable AI systems. The methodology involves designing cryptographic protocols that enable verification of AI system claims without revealing underlying model parameters or sensitive data. The approach includes creating frameworks for authenticated delegation and credentialing systems to secure interactions with autonomous and multi-agent AI systems, establishing clear chains of accountability.

## Key Results
- Introduces technical solutions using zero-knowledge cryptography to enable third parties to verify AI system performance and fairness metrics without direct model access
- Develops private retrieval augmented generation (PRAG) systems using MPC and TEEs to protect private data while enabling secure and auditable RAG operations
- Presents frameworks for authenticated delegation and credentialing systems that secure interactions with autonomous and multi-agent AI systems

## Why This Works (Mechanism)
The technical solutions work by leveraging cryptographic primitives to create verifiable proofs of system properties without revealing sensitive information. Zero-knowledge proofs allow for the verification of AI system claims (such as performance metrics or fairness criteria) without exposing the underlying model parameters or training data. Secure multi-party computation enables collaborative computation on private data without revealing individual inputs, while trusted execution environments provide hardware-level isolation for sensitive operations. These mechanisms create a foundation for building AI systems that can be both useful and trustworthy.

## Foundational Learning
- Zero-knowledge proofs (zkSNARKs): Why needed - to verify system claims without revealing sensitive information; Quick check - can confirm model performance without accessing the model
- Secure multi-party computation (MPC): Why needed - to enable collaborative computation on private data; Quick check - can compute RAG results without revealing individual data elements
- Trusted execution environments (TEEs): Why needed - to provide hardware-level isolation for sensitive operations; Quick check - can execute private computations in secure hardware enclaves
- Cryptographic credentialing systems: Why needed - to establish trust and accountability in multi-agent systems; Quick check - can trace actions back to authenticated entities
- Verifiable computation: Why needed - to ensure computational integrity without re-execution; Quick check - can confirm correct model execution without seeing model weights

## Architecture Onboarding

**Component Map:**
Data Sources -> Secure Multi-party Computation -> Trusted Execution Environment -> Zero-knowledge Proof Generator -> Verification Layer -> External Auditors

**Critical Path:**
1. Data ingestion and preprocessing in secure environment
2. Computation of model outputs or metrics
3. Generation of zero-knowledge proofs for verification
4. External verification of proofs without accessing sensitive data
5. Auditable logging of all system interactions and verifications

**Design Tradeoffs:**
- Privacy vs. Verifiability: Higher privacy guarantees may require more complex proofs and computational overhead
- Performance vs. Security: Stronger security measures (like MPC) can significantly impact system performance
- Auditability vs. Efficiency: Comprehensive audit trails improve accountability but increase storage and processing requirements

**Failure Signatures:**
- Verification failures indicating potential model performance discrepancies
- Cryptographic proof generation failures suggesting implementation issues
- Performance degradation when security measures are enabled
- Increased latency in multi-party computations

**First Experiments:**
1. Implement a basic zkSNARK proof for a simple model performance claim
2. Benchmark MPC-based computation overhead for RAG systems
3. Test TEE isolation by attempting unauthorized access to protected computations

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability challenges with cryptographic techniques when applied to large-scale AI models
- Security guarantees depend on the continued security of underlying cryptographic primitives
- Lack of extensive real-world validation in production environments with real user loads

## Confidence
- Major claims about technical solutions for verifiable and auditable AI systems: Medium
- Assertions about balancing privacy, verifiability, and auditability: Medium
- Claims about effectiveness of authenticated delegation frameworks: Low to Medium

## Next Checks
1. Implement and benchmark the proposed PRAG system with large-scale real-world datasets to evaluate performance, security, and privacy guarantees under practical conditions
2. Conduct a formal security analysis of the zero-knowledge proof implementations to identify potential vulnerabilities and assess their resilience against emerging quantum computing threats
3. Develop and deploy a pilot program of the authenticated delegation and credentialing system in a multi-agent AI environment to evaluate its effectiveness in maintaining accountability and traceability in complex AI interactions