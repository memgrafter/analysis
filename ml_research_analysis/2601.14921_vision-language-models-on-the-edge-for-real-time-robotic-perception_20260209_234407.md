---
ver: rpa2
title: Vision-Language Models on the Edge for Real-Time Robotic Perception
arxiv_id: '2601.14921'
source_url: https://arxiv.org/abs/2601.14921
tags:
- edge
- uni00000013
- latency
- robot
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a real-time robotic perception system deploying
  vision-language models (VLMs) on ORAN/MEC edge infrastructure. Using the Unitree
  G1 humanoid robot, the authors implement a WebRTC-based pipeline streaming multimodal
  data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct against cloud deployment.
---

# Vision-Language Models on the Edge for Real-Time Robotic Perception

## Quick Facts
- arXiv ID: 2601.14921
- Source URL: https://arxiv.org/abs/2601.14921
- Reference count: 28
- Primary result: Edge deployment achieves 5% latency reduction with near-cloud accuracy for real-time robotic perception

## Executive Summary
This paper presents a real-time robotic perception system deploying vision-language models (VLMs) on ORAN/MEC edge infrastructure using the Unitree G1 humanoid robot. The authors implement a WebRTC-based pipeline streaming multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct against cloud deployment. Results show edge deployment achieves 5% latency reduction (1600.03 ms vs. 1685.20 ms) while maintaining near-cloud accuracy. They also evaluate Qwen2-VL-2B-Instruct, achieving sub-second responsiveness but with 13% lower accuracy. The study demonstrates edge VLMs are viable for real-time robotics, offering latency and privacy benefits over cloud alternatives.

## Method Summary
The authors implement a WebRTC-based pipeline streaming multimodal data from the Unitree G1 humanoid robot to an edge node for VLM processing. They compare edge deployment of LLaMA-3.2-11B-Vision-Instruct against cloud deployment, measuring latency and accuracy. The system also evaluates Qwen2-VL-2B-Instruct for sub-second responsiveness. Edge infrastructure leverages ORAN/MEC architecture to minimize latency while maintaining privacy benefits compared to cloud alternatives.

## Key Results
- Edge deployment achieves 5% latency reduction (1600.03 ms vs. 1685.20 ms) compared to cloud
- LLaMA-3.2-11B-Vision-Instruct maintains near-cloud accuracy at edge
- Qwen2-VL-2B-Instruct achieves sub-second responsiveness with 13% lower accuracy

## Why This Works (Mechanism)
The edge deployment reduces latency by processing data closer to the source robot, eliminating round-trip communication to distant cloud servers. WebRTC streaming enables real-time bidirectional communication between the robot and edge node, supporting the low-latency requirements for robotic perception. The ORAN/MEC infrastructure provides the computational resources needed for running large VLMs (11B parameters) while maintaining proximity to the robot. This architectural approach balances computational demands with network latency, making real-time inference feasible for complex vision-language tasks in robotics.

## Foundational Learning

### WebRTC Streaming
- Why needed: Enables real-time bidirectional communication between robot and edge node
- Quick check: Verify bidirectional data flow and sub-100ms connection establishment

### VLM Inference Optimization
- Why needed: Large models (11B parameters) require efficient inference for real-time response
- Quick check: Measure inference time per frame and verify GPU utilization

### ORAN/MEC Architecture
- Why needed: Provides edge computing resources with minimal latency to connected devices
- Quick check: Confirm network slicing and edge node proximity to robot deployment

## Architecture Onboarding

### Component Map
Robot sensors -> WebRTC stream -> Edge node -> VLM inference -> Action commands

### Critical Path
Sensor capture → WebRTC encoding → Network transmission → Edge processing → Response generation → Command transmission

### Design Tradeoffs
Latency vs. accuracy: Larger models provide better accuracy but increase inference time; edge deployment trades some computational power for reduced network latency.

### Failure Signatures
Network congestion: Increased WebRTC latency and dropped frames
Edge resource contention: Longer inference times and potential timeout failures
Model incompatibility: Incorrect input/output handling causing pipeline stalls

### First Experiments
1. Measure WebRTC round-trip latency with varying packet sizes
2. Benchmark VLM inference time with different batch sizes
3. Test edge deployment with synthetic sensor data before robot integration

## Open Questions the Paper Calls Out
None

## Limitations
- Restricted hardware comparison (only Unitree G1 tested against cloud)
- Limited evaluation scope (only two VLM models assessed)
- WebRTC streaming network variability not thoroughly characterized

## Confidence
- High confidence in latency measurements and WebRTC implementation
- Medium confidence in accuracy claims
- Medium confidence in privacy benefits
- Low confidence in scalability claims

## Next Checks
1. Test across multiple robot platforms with varying computational capabilities
2. Expand VLM model evaluation to include larger models and different architectures
3. Conduct long-term deployment trials in real-world conditions with variable network conditions