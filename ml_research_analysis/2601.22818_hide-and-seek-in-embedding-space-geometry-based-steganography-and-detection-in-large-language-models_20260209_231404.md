---
ver: rpa2
title: 'Hide and Seek in Embedding Space: Geometry-based Steganography and Detection
  in Large Language Models'
arxiv_id: '2601.22818'
source_url: https://arxiv.org/abs/2601.22818
tags:
- embedding
- secret
- detection
- token
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "We introduce low-recoverability steganography for LLMs, which\
  \ embeds secrets in model outputs while making them harder to reverse-engineer.\
  \ Prior steganographic schemes like TrojanStego achieve 100% recoverability\u2014\
  both the encoded bits and original secrets can be perfectly extracted without the\
  \ key."
---

# Hide and Seek in Embedding Space: Geometry-based Steganography and Detection in Large Language Models

## Quick Facts
- arXiv ID: 2601.22818
- Source URL: https://arxiv.org/abs/2601.22818
- Reference count: 37
- We introduce low-recoverability steganography for LLMs that embeds secrets in model outputs while making them harder to reverse-engineer

## Executive Summary
This paper addresses the challenge of embedding secrets in LLM outputs while making them difficult to detect and recover without the key. Prior steganographic schemes achieve perfect recoverability, allowing adversaries to extract both encoded bits and original secrets from outputs alone. The authors introduce two metrics, Rbucket (probability of inferring encoded bits from outputs) and Rsecret (probability of recovering the secret from those bits), to quantify recoverability. They propose using random hyperplane projections in embedding space to create collision-free secret encodings and balanced bucket partitions that leverage the model's learned semantic structure. This approach improves exact secret recovery while reducing payload recoverability compared to traditional encoding schemes.

## Method Summary
The authors formalize steganography using two metrics: Rbucket (chance of inferring encoded bits from outputs) and Rsecret (chance of recovering the secret from those bits). They propose replacing arbitrary encoding schemes with methods derived from the model's embedding geometry. Specifically, they use random hyperplane projections in embedding space to define collision-free secret encodings and balanced bucket partitions. This approach leverages the model's learned semantic structure, making it easier to learn during fine-tuning while requiring the secret key for recovery. The method is evaluated across multiple models (Llama-8B, Ministral-8B, Llama-70B) using LoRA fine-tuning, showing substantial improvements in exact secret recovery while reducing output-side recoverability.

## Key Results
- Exact secret recovery improves from 17%→30% (+78%) on Llama-8B, 24%→43% (+80%) on Ministral-8B, and 9%→19% (+123%) on Llama-70B
- Steganographic fine-tuning maintains text quality within normal ranges, with perplexity and KL divergence increases remaining within typical fine-tuning bounds
- Linear probes trained on later-layer activations detect secrets with up to 33% higher accuracy in fine-tuned models compared to base models

## Why This Works (Mechanism)
The method works by leveraging the geometry of the embedding space through random hyperplane projections. These projections create partitions that are both balanced (ensuring payload capacity) and collision-resistant (ensuring security). By aligning the encoding scheme with the model's learned semantic structure, the steganographic signal becomes easier to learn during fine-tuning while remaining difficult to reverse-engineer from outputs alone. The approach reduces Rbucket and Rsecret by making the relationship between outputs and secrets non-invertible without knowledge of the hyperplane configuration.

## Foundational Learning
**Random Hyperplane Projections**: Used to partition embedding space into balanced buckets. Why needed: Provides collision-resistant partitioning while maintaining payload capacity. Quick check: Verify partition balance and collision rate empirically.

**Rbucket and Rsecret Metrics**: Formal measures of steganalysis difficulty. Why needed: Quantifies the trade-off between recoverability and payload capacity. Quick check: Compute metrics on synthetic and real data to validate sensitivity.

**Linear Probe Detection**: Mechanistic interpretability approach using later-layer activations. Why needed: Detects steganographic signals that distributional methods miss. Quick check: Compare detection accuracy between base and fine-tuned models.

## Architecture Onboarding
**Component Map**: Token Embeddings -> Hyperplane Projections -> Bucket Encoding -> Fine-tuning -> Output Generation

**Critical Path**: The steganographic signal flows from token embeddings through hyperplane partitions to bucket assignments, which are then learned during fine-tuning. The critical path is: Embedding Space → Projection → Bucket Assignment → Fine-tuning → Output Token Selection.

**Design Tradeoffs**: Higher payload capacity requires more buckets, which increases collision probability and reduces security. The authors balance this by using random hyperplanes that maximize partition balance while minimizing collisions.

**Failure Signatures**: High Rbucket indicates poor collision resistance; low exact recovery suggests inadequate fine-tuning capacity; high perplexity indicates text quality degradation.

**3 First Experiments**:
1. Compute Rbucket and Rsecret for baseline vs. hyperplane-projection encoding on a small vocabulary
2. Measure partition balance and collision rate for different numbers of hyperplanes
3. Evaluate text quality (perplexity, KL divergence) for different payload capacities

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on synthetic secret distributions rather than real-world steganographic use cases
- Detection mechanism assumes adversaries cannot learn to mask internal signatures during fine-tuning
- Payload capacity measurements limited by small vocabulary size and single-token replacement strategy

## Confidence
- Exact secret recovery improvements: Medium confidence (synthetic evaluation)
- Text quality preservation: Medium confidence (perplexity/KL metrics only)
- Detection mechanism effectiveness: Low confidence (controlled conditions only)

## Next Checks
1. Test recoverability metrics against adaptive adversaries who attempt to reverse-engineer the embedding space geometry from output samples, measuring how quickly secrets can be extracted without the key.

2. Evaluate detection mechanisms against models fine-tuned with steganographic objectives that explicitly try to minimize detectable internal signatures, using interpretability methods beyond linear probes.

3. Assess real-world steganographic utility by testing secret embedding and recovery with larger vocabularies, multi-token payloads, and secrets that follow natural language distributions rather than synthetic patterns.