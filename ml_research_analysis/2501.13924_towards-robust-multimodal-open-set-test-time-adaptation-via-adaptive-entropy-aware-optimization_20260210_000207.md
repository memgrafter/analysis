---
ver: rpa2
title: Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware
  Optimization
arxiv_id: '2501.13924'
source_url: https://arxiv.org/abs/2501.13924
tags:
- unknown
- samples
- h-score
- fpr95
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Adaptive Entropy-aware Optimization (AEO),
  the first framework designed for Multimodal Open-set Test-time Adaptation (MM-OSTTA).
  The method addresses the challenge of adapting pre-trained multimodal models to
  target domains containing unknown classes by amplifying the entropy difference between
  known and unknown samples during online adaptation.
---

# Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization

## Quick Facts
- **arXiv ID:** 2501.13924
- **Source URL:** https://arxiv.org/abs/2501.13924
- **Reference count:** 28
- **Primary result:** Introduces AEO, the first framework for Multimodal Open-set Test-time Adaptation, improving H-score by 22.07% on EPIC-Kitchens.

## Executive Summary
This paper introduces Adaptive Entropy-aware Optimization (AEO), the first framework designed for Multimodal Open-set Test-time Adaptation (MM-OSTTA). The method addresses the challenge of adapting pre-trained multimodal models to target domains containing unknown classes by amplifying the entropy difference between known and unknown samples during online adaptation. AEO introduces two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). UAE dynamically adjusts entropy optimization based on sample uncertainty, while AMP exploits cross-modal interactions to enhance separation between known and unknown classes. The authors establish a new benchmark using existing datasets across action recognition and 3D semantic segmentation tasks with five modalities. Extensive experiments show AEO significantly improves performance, increasing the H-score by 22.07% on EPIC-Kitchens and achieving strong results in long-term and continual adaptation scenarios.

## Method Summary
AEO implements a test-time adaptation framework that leverages entropy differences to distinguish known from unknown classes in multimodal settings. The method uses UAE to adaptively minimize or maximize entropy based on prediction confidence, and AMP to create modality discrepancies for uncertain samples. The framework is trained online using mini-batches from the target domain without access to source data. The approach employs a joint classifier with modality-specific encoders, using adaptive weights derived from prediction entropy to guide the optimization process. The method is evaluated across three datasets with five different modalities, establishing a new benchmark for multimodal open-set TTA.

## Key Results
- Achieves 22.07% improvement in H-score on EPIC-Kitchens dataset
- Outperforms existing open-set TTA methods including Tent and Max-Entropy
- Demonstrates effectiveness across multiple modalities: video, audio, optical flow, LiDAR, and camera
- Shows strong performance in long-term and continual adaptation scenarios

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Entropy Polarity Switching (UAE)
The Unknown-aware Adaptive Entropy Optimization (UAE) module separates known and unknown samples by reversing the direction of entropy optimization based on prediction confidence. UAE utilizes a hyperbolic tangent function ($W_{ada} = \text{Tanh}(\beta \cdot (H(\hat{p}) - \alpha))$) to assign weights. If entropy $H(\hat{p})$ is below threshold $\alpha$ (high confidence/likely known), weight is negative, minimizing entropy. If $H(\hat{p}) > \alpha$ (low confidence/likely unknown), weight is positive, maximizing entropy. The core assumption is that prediction entropy acts as a reliable proxy for distinguishing known versus unknown class samples in the target domain.

### Mechanism 2: Uncertainty-Aware Modality Discrepancy (AMP)
The Adaptive Modality Prediction Discrepancy Optimization (AMP) encourages disagreement between modalities for uncertain samples while enforcing agreement for certain samples. For unknowns ($W_{ada} > 0$), it maximizes the L1 distance between modality predictions; for knowns, it minimizes it. The core assumption is that for unknown classes, modalities cannot form a coherent consensus and forcing them to disagree increases the final fused entropy, making unknowns easier to detect.

### Mechanism 3: Gradient Suppression for Ambiguous Samples
The Tanh-based weighting mechanism suppresses gradients for samples near the decision boundary ($H(\hat{p}) \approx \alpha$), preventing noisy updates from corrupting the model. Samples with intermediate confidence are assumed to be the most dangerous to adapt to, as they are likely misclassified or ambiguous. The function $\text{Tanh}(x)$ approaches 0 as $x$ approaches 0, effectively neutralizing their contribution to the loss.

## Foundational Learning

- **Concept: Test-Time Adaptation (TTA)**
  - **Why needed here:** AEO modifies the standard TTA paradigm (usually entropy minimization) to handle open-set scenarios. Understanding the baseline "Tent" method is required to see why standard entropy minimization collapses in the presence of unknowns.
  - **Quick check question:** How does minimizing entropy on *all* samples harm performance when unknown classes are present?

- **Concept: Entropy as an Out-of-Distribution (OOD) Score**
  - **Why needed here:** The paper relies on the correlation between high prediction entropy and unknown class status. You must understand that entropy is not just a loss function but here serves as a detection metric.
  - **Quick check question:** Why does the paper argue that maximizing entropy for unknown samples improves detection rates (AUROC)?

- **Concept: Multimodal Fusion (Late vs. Early)**
  - **Why needed here:** The AMP module manipulates the discrepancy between modality-specific predictions before the final fusion.
  - **Quick check question:** How does the architecture maintain separate classifiers $h_k(\cdot)$ for each modality alongside the joint classifier $h(\cdot)$?

## Architecture Onboarding

- **Component map:** Pre-trained encoders (SlowFast, ResNet) -> Modality-specific classifiers ($h_k$) -> Joint Classifier ($h$) -> Entropy calculator -> Weight Generator ($W_{ada}$) -> Loss Composer
- **Critical path:** Forward pass input batch $X_b$ through all modalities to get $\hat{p}$ (joint) and $\hat{p}_k$ (unimodal) -> Calculate entropy $H(\hat{p})$ for every sample -> Compute adaptive weights $W_{ada}$ using Eq. (3) -> Apply weights to entropy loss and discrepancy loss -> Backpropagate $L_{AEO}$
- **Design tradeoffs:** Threshold Sensitivity ($\alpha$) dictates the known/unknown boundary; Discrepancy vs. Consistency - increasing discrepancy helps unknown detection but risks reducing known-class accuracy if the adaptive weight misclassifies a known sample as unknown.
- **Failure signatures:** Model Collapse (Accuracy on known classes drops rapidly due to $W_{ada}$ sign flipped for knowns), Stagnation (Loss does not decrease due to all samples in "neutral zone"), High FPR95 (Model fails to reject unknowns due to unknowns having low entropy).
- **First 3 experiments:** 1) Sanity Check: Run Source model, Tent, and AEO on HAC $\to$ HAC-corrupted to verify entropy separation; 2) Ablation on $\alpha$: Sweep threshold to find optimal H-score; 3) Module Ablation: Compare UAE only, AMP only, and UAE+AMP configurations.

## Open Questions the Paper Calls Out

- **Question 1:** How does AEO perform when applied to transformer-based multimodal architectures or large foundation models?
- **Question 2:** What is the computational overhead and latency introduced by AEO during online inference for real-time applications?
- **Question 3:** Can the entropy threshold ($\alpha$) and scaling factor ($\beta$) be adapted dynamically rather than set as fixed hyperparameters?

## Limitations
- Fixed hyperparameters ($\alpha$, $\beta$) may not generalize across all dataset distributions and require manual tuning
- Assumes sufficient inter-modality variance exists for unknown samples, which may not hold for highly correlated modalities
- Does not evaluate against recent vision-language approaches that could potentially handle open-set adaptation more effectively

## Confidence
- UAE mechanism effectiveness: **Medium** (strong ablation in Table 1 but limited threshold analysis)
- AMP contribution: **Low-Medium** (Table 2 shows benefit but lacks modality correlation analysis)
- Benchmark significance: **Medium** (first in multimodal open-set TTA but limited competitor diversity)

## Next Checks
1. **Threshold sensitivity analysis**: Sweep α across its full range for each dataset to verify the claimed robustness and identify failure points where known samples are incorrectly treated as unknown.
2. **Modality correlation study**: Calculate the correlation coefficient between modality predictions for known versus unknown samples to quantify the effectiveness of AMP's discrepancy maximization.
3. **Cross-dataset generalization**: Apply the same α and β values from EPIC-Kitchens to nuScenes to test whether the hyperparameters generalize or require dataset-specific tuning.