---
ver: rpa2
title: 'CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning'
arxiv_id: '2601.15141'
source_url: https://arxiv.org/abs/2601.15141
tags:
- uni00000013
- arxiv
- uni00000018
- reasoning
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of execution failures in agentic
  reinforcement learning with parameter-constrained models. It proposes CLEANER, a
  framework that uses the model's intrinsic self-correction capabilities to eliminate
  error-contaminated context directly during data collection.
---

# CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning

## Quick Facts
- arXiv ID: 2601.15141
- Source URL: https://arxiv.org/abs/2601.15141
- Reference count: 9
- Key outcome: Achieves 6% average accuracy gains on AIME, 3% on GPQA, and 5% on LiveCodeBench while matching state-of-the-art performance using one-third of training steps

## Executive Summary
CLEANER addresses execution failures in agentic reinforcement learning with parameter-constrained models by leveraging the model's intrinsic self-correction capabilities. The framework eliminates error-contaminated context during data collection through a method called Similarity-Aware Adaptive Rollback (SAAR), which constructs clean trajectories by replacing failures with successful self-corrections. This approach adaptively regulates replacement granularity based on semantic similarity between failed and corrected actions. Empirical results demonstrate significant accuracy improvements across multiple benchmarks while maintaining training efficiency.

## Method Summary
CLEANER introduces a self-purification framework that operates during the data collection phase of reinforcement learning. The core innovation is the Similarity-Aware Adaptive Rollback (SAAR) mechanism, which identifies failed trajectories and retrospectively replaces them with successful self-correction paths. The system analyzes semantic similarity between consecutive actions to determine optimal replacement granularity, ensuring that context remains clean and informative for subsequent learning steps. By filtering out error-contaminated trajectories early in the training pipeline, CLEANER reduces the noise that typically hinders learning in parameter-constrained models, allowing the agent to focus on successful patterns and corrections rather than propagating execution errors.

## Key Results
- 6% average accuracy gains on AIME benchmark compared to baseline methods
- 3% improvement on GPQA benchmark demonstrating cross-domain effectiveness
- 5% accuracy increase on LiveCodeBench while using only one-third of training steps required by state-of-the-art approaches

## Why This Works (Mechanism)
The effectiveness of CLEANER stems from its proactive approach to error management during data collection. Rather than allowing failed trajectories to contaminate the learning process, SAAR identifies semantic failures and replaces them with successful self-correction paths before they can negatively influence model updates. This mechanism exploits the model's existing self-correction capabilities to create cleaner training data, reducing the signal-to-noise ratio in the reinforcement learning pipeline. The adaptive granularity regulation ensures that replacements are neither too coarse (losing valuable context) nor too fine (insufficient error elimination), maintaining the semantic coherence necessary for effective learning while removing execution failures that would otherwise propagate through training iterations.

## Foundational Learning

**Semantic Similarity Analysis**
*Why needed:* To determine optimal granularity for trajectory replacement and identify when self-corrections are semantically related to failures
*Quick check:* Verify that cosine similarity between failed and corrected actions falls within expected ranges (typically 0.7-0.9) for meaningful replacements

**Reinforcement Learning with Parameter Constraints**
*Why needed:* Understanding how limited model capacity affects learning efficiency and error propagation in agentic systems
*Quick check:* Monitor gradient norms and learning rates to ensure stable updates despite reduced parameter count

**Self-Correction Mechanisms in LLMs**
*Why needed:* Leveraging the model's existing ability to recognize and correct its own mistakes during inference
*Quick check:* Validate that self-corrected outputs maintain task-relevant information while eliminating execution errors

**Trajectory-Based Learning**
*Why needed:* Recognizing that sequential decision-making requires clean, coherent paths rather than isolated state-action pairs
*Quick check:* Ensure trajectory continuity scores remain above threshold (typically >0.8) after SAAR processing

## Architecture Onboarding

**Component Map:**
CLEANER -> SAAR Module -> Similarity Analyzer -> Trajectory Reconstructor -> Filtered Dataset

**Critical Path:**
Data Collection → Failure Detection → Semantic Analysis → Adaptive Rollback → Clean Trajectory Generation → Model Training

**Design Tradeoffs:**
The system balances between aggressive error removal (which might eliminate useful learning signals) and conservative filtering (which allows noise to persist). The semantic similarity threshold represents a key tradeoff point where higher values preserve more context but risk retaining errors, while lower values ensure cleaner data but may over-filter useful information.

**Failure Signatures:**
- Excessive rollback frequency indicating overly aggressive similarity thresholds
- Persistent error patterns suggesting insufficient similarity sensitivity
- Trajectory fragmentation showing inappropriate granularity selection
- Training instability resulting from over-filtered context

**First Experiments:**
1. Baseline comparison: Run CLEANER vs standard RL without context cleaning on AIME benchmark to verify 6% accuracy improvement claim
2. Efficiency validation: Measure training steps required to reach 95% of maximum performance with CLEANER versus baselines to confirm 1/3 training step reduction
3. Granularity sensitivity: Test CLEANER with varying semantic similarity thresholds (0.6, 0.7, 0.8, 0.9) to identify optimal replacement granularity across different task domains

## Open Questions the Paper Calls Out

The paper identifies several open questions regarding the generalizability of CLEANER to broader agentic applications beyond the tested narrow task domains. Specifically, it questions how the framework would perform on open-ended, multi-step reasoning tasks such as tool-use agents and planning tasks. Additionally, the authors acknowledge the need for more extensive hyperparameter sensitivity analysis across diverse task types and similarity thresholds to fully understand the robustness of the SAAR mechanism.

## Limitations

- Evaluation focuses on narrow task domains (mathematics, coding, science questions), limiting generalizability to broader agentic applications
- SAAR mechanism's reliance on semantic similarity thresholds introduces hyperparameter sensitivity without thorough exploration across diverse task types
- Lack of ablation studies examining individual contributions of context cleaning versus self-correction mechanisms

## Confidence

- **High confidence**: The core methodology (SAAR algorithm, context cleaning approach) is clearly described and reproducible
- **Medium confidence**: Benchmark results showing accuracy improvements, though limited to specific datasets and task types
- **Low confidence**: Claims about efficiency (1/3 training steps) due to lack of detailed training cost analysis and comparison methodology

## Next Checks

1. Test CLEANER's effectiveness on open-ended, multi-step reasoning tasks beyond the current narrow benchmarks (e.g., tool-use agents, planning tasks)
2. Conduct ablation studies to quantify the individual contributions of context cleaning, self-correction, and adaptive rollback mechanisms
3. Perform extensive hyperparameter sensitivity analysis across different similarity thresholds and task domains to assess robustness