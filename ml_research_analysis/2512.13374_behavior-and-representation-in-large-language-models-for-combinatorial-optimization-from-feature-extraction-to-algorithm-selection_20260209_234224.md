---
ver: rpa2
title: 'Behavior and Representation in Large Language Models for Combinatorial Optimization:
  From Feature Extraction to Algorithm Selection'
arxiv_id: '2512.13374'
source_url: https://arxiv.org/abs/2512.13374
tags:
- representation
- mean
- instance
- features
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how Large Language Models (LLMs) represent
  combinatorial optimization problems and whether their internal representations can
  support algorithm selection. Using direct querying and probing analyses across four
  benchmark problems, we assess whether LLMs can extract instance features and whether
  their hidden-layer activations encode meaningful structural information.
---

# Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection

## Quick Facts
- arXiv ID: 2512.13374
- Source URL: https://arxiv.org/abs/2512.13374
- Reference count: 40
- Primary result: LLM-derived representations achieve comparable predictive power to traditional ISA-based features for per-instance algorithm selection.

## Executive Summary
This study investigates whether Large Language Models can effectively represent and extract features from combinatorial optimization problems, and whether these representations can support algorithm selection. Through direct querying and probing analyses across four benchmark problems (bin packing, graph coloring, job shop scheduling, and knapsack), the authors demonstrate that while LLMs can reliably infer simple features, they struggle with complex computations. More importantly, the hidden-layer activations of LLMs capture structural information that enables accurate algorithm selection, performing comparably to traditional Instance Space Analysis features despite the high computational cost of LLM inference.

## Method Summary
The authors evaluate LLM representations through three complementary approaches: direct querying for feature extraction using structured prompts with constrained JSON decoding, probing hidden layers to decode features using various pooling strategies and regression models, and algorithm selection classification comparing LLM-derived representations against traditional ISA-based features. Using Llama-3.2-3B-Instruct with VLLM, they analyze 26,860 instances across four combinatorial problems represented in natural language, code-like (MiniZinc), and standard formats. Performance is measured through feature extraction accuracy (MAE, exact match, tolerance-based metrics) and set-aware accuracy for algorithm selection, with 5-fold stratified cross-validation.

## Key Results
- LLMs can reliably extract simple features (e.g., vertex/edge counts) but struggle with complex computations (e.g., gap percentage)
- Probing hidden layers reveals that complex features are more accurately decoded from internal representations than through direct querying
- LLM-derived representations achieve comparable predictive power to ISA-based features for per-instance algorithm selection
- Max pooling of hidden states performs best for algorithm selection tasks
- Despite higher computational costs, LLMs capture relevant structural information sufficient for algorithm selection

## Why This Works (Mechanism)
The effectiveness stems from LLMs' ability to process structured representations of combinatorial problems and encode their inherent properties in hidden states, even when direct reasoning fails. The probing approach bypasses the LLM's limited explicit reasoning capability by treating internal representations as feature-rich embeddings that can be decoded through supervised learning. This suggests that LLMs implicitly capture problem structure through pretraining on diverse text corpora, including mathematical and computational content, which manifests in representations useful for downstream optimization tasks.

## Foundational Learning
- **Combinatorial Optimization Problems**: Why needed - Core domain being studied; Quick check - Can identify four benchmark problems (BP, GCP, JSP, KP) and their characteristics
- **Instance Space Analysis (ISA)**: Why needed - Provides traditional feature extraction and algorithm selection framework; Quick check - Understands ISA uses handcrafted features to characterize instance landscapes
- **LLM Hidden Representations**: Why needed - The study's core innovation is probing these for optimization features; Quick check - Can explain what hidden states are and why they might encode problem structure
- **Algorithm Selection**: Why needed - The ultimate downstream task being evaluated; Quick check - Understands it's choosing the best solver for a given instance
- **Structured Prompting with JSON Decoding**: Why needed - Method for extracting features from LLMs reliably; Quick check - Can describe how constrained decoding ensures consistent output format
- **Probing (Representation Learning)**: Why needed - Technique for extracting features from model activations; Quick check - Understands it involves training a separate model on LLM hidden states

## Architecture Onboarding

### Component Map
Llama-3.2-3B-Instruct (LLM) -> Hidden State Extractor -> Pooling Layer -> Probing Model (Linear/MLP/LightGBM) -> Feature Vector

### Critical Path
Problem instance -> Representation converter -> LLM inference -> Hidden state extraction -> Pooling -> Probing model training -> Algorithm selection classifier

### Design Tradeoffs
- Direct querying vs probing: Simpler but less accurate vs more complex but captures richer features
- Different pooling strategies: Mean (smooth), max (peak features), last (sequence end) with max performing best
- Representation formats: Natural language (human-readable) vs code-like (structured) vs standard (compact) with varying token efficiency

### Failure Signatures
- Null or malformed JSON responses indicate structured decoding failures
- Poor probing accuracy suggests inadequate representation or probe model mismatch
- Algorithm selection performance similar to random indicates representations lack discriminative power

### First Experiments
1. Test direct querying on simple features (vertex count) across all four problems to establish baseline capability
2. Compare pooling strategies (mean, max, last) on probing accuracy for a single complex feature
3. Run algorithm selection with LLM-derived features vs ISA baseline on one problem to measure relative performance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the predictive power of LLM-derived representations generalize to other model architectures and real-world optimization settings?
- **Basis in paper:** [explicit] The authors state the analysis is restricted to a single LLM family and benchmark problems, noting that extending to other architectures and real-world problems represents an important direction for future research.
- **Why unresolved:** The study is limited to the Llama-3.2-3B-Instruct model and four benchmark COPs (BPP, GCP, JSP, KP).
- **What evidence would resolve it:** Replicating the probing experiments across different model families (e.g., commercial LLMs) and industrial optimization datasets.

### Open Question 2
- **Question:** How should practitioners balance the trade-off between the high computational cost of LLMs and the reduced need for manual feature engineering?
- **Basis in paper:** [explicit] The conclusion highlights a broader question regarding "how to balance interpretability, reproducibility, human effort, and energy efficiency."
- **Why unresolved:** The paper establishes that LLMs match traditional features in predictive power but notes they do so at a "significantly higher computational cost."
- **What evidence would resolve it:** A quantitative cost-benefit analysis comparing the energy consumption of inference against the person-hours required for handcrafted feature design.

### Open Question 3
- **Question:** Can LLM-derived representations effectively support broader Instance Space Analysis (ISA) tasks beyond algorithm selection, such as instance clustering and performance landscape modeling?
- **Basis in paper:** [explicit] The authors identify "integrating LLM-derived activations into broader ISA pipelines" for tasks like clustering and landscape modeling as a promising avenue.
- **Why unresolved:** The current study focuses solely on the downstream task of per-instance algorithm selection, leaving other ISA applications unexplored.
- **What evidence would resolve it:** Experiments evaluating LLM embeddings for clustering validity indices and visualization in low-dimensional instance spaces.

## Limitations
- Limited to a single LLM architecture (Llama-3.2-3B-Instruct), restricting generalizability claims
- Experiments confined to four benchmark combinatorial problems, not testing real-world optimization scenarios
- High computational cost of LLM inference compared to traditional feature extraction methods
- Black-box nature of probing approach provides limited interpretability of extracted features

## Confidence

| Claim | Confidence |
|-------|------------|
| LLM hidden states capture more complex features than direct querying can extract | High |
| LLM-derived representations are comparable to ISA features for algorithm selection | Medium |
| Findings generalize to larger or more diverse combinatorial problem classes | Low |

## Next Checks
1. Replicate the probing pipeline on an unseen combinatorial problem (e.g., Graph Coloring) to test transferability of the feature extraction capability
2. Perform ablation studies on pooling strategies and probe model complexity to isolate the minimal representation needed for algorithm selection
3. Conduct controlled experiments comparing LLM-derived features to ground-truth instance features (when available) to quantify approximation error in feature space