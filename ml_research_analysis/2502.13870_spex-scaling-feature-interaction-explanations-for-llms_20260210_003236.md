---
ver: rpa2
title: 'SPEX: Scaling Feature Interaction Explanations for LLMs'
arxiv_id: '2502.13870'
source_url: https://arxiv.org/abs/2502.13870
tags:
- spex
- interaction
- interactions
- fourier
- order
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "SPEX is a model-agnostic interaction attribution method that scales\
  \ to large input lengths (n\u22481000) by leveraging sparse Fourier transforms and\
  \ channel decoding algorithms. It exploits the natural sparsity of interactions\
  \ in real-world data to efficiently identify important feature interactions without\
  \ exhaustive enumeration."
---

# SPEX: Scaling Feature Interaction Explanations for LLMs

## Quick Facts
- **arXiv ID:** 2502.13870
- **Source URL:** https://arxiv.org/abs/2502.13870
- **Reference count:** 40
- **Key outcome:** SPEX scales interaction attribution to nâ‰ˆ1000 features using sparse Fourier transforms, achieving 20% better faithfulness than marginal methods and identifying model reasoning patterns

## Executive Summary
SPEX introduces a model-agnostic method for explaining feature interactions in large language models by leveraging the natural sparsity of interactions in real-world data. The approach uses sparse Fourier transforms and channel decoding algorithms to efficiently identify important feature interactions without exhaustive enumeration, enabling scalability to inputs with thousands of features. The method demonstrates significant improvements in faithfulness metrics over traditional marginal attribution methods while successfully identifying key features and interactions that influence model outputs.

## Method Summary
SPEX operates by first generating perturbed input samples with random binary masks, then computing the model's log probability ratios for masked versus unmasked tokens. These log probability differences are aggregated and transformed using sparse Fourier techniques to identify which feature interactions most influence the model's output. The method exploits the observation that real-world interactions are typically sparse - only a small subset of possible feature pairs significantly impact model predictions. By using compressed sensing techniques adapted from signal processing, SPEX can efficiently recover these sparse interaction patterns without the exponential computational cost of traditional exhaustive methods.

## Key Results
- Outperforms marginal attribution methods by up to 20% in faithfulness metrics
- Successfully identifies key features and interactions influencing model outputs
- Aligns with human annotations on HotpotQA and detects reasoning errors in GPT-4o mini

## Why This Works (Mechanism)
SPEX leverages the mathematical property that real-world feature interactions are sparse - only a small fraction of possible feature pairs have meaningful effects on model outputs. This sparsity allows the use of compressed sensing techniques, specifically sparse Fourier transforms, to efficiently recover the important interactions from a relatively small number of perturbed samples. The method treats interaction detection as a signal recovery problem, where the "signal" (important interactions) is sparse in a high-dimensional space, enabling efficient identification without exhaustive enumeration.

## Foundational Learning

**Sparse Fourier Transforms:** Mathematical technique for recovering sparse signals from frequency domain measurements
*Why needed:* Enables efficient identification of sparse feature interactions without computing all possible pairs
*Quick check:* Verify that interaction matrices from real datasets are indeed sparse (few non-zero entries)

**Compressed Sensing Theory:** Framework for recovering sparse signals from underdetermined linear systems
*Why needed:* Provides theoretical guarantees for accurate interaction recovery with limited samples
*Quick check:* Confirm recovery guarantees hold for the specific sparsity levels observed in model outputs

**Channel Decoding Algorithms:** Error-correcting methods for recovering transmitted information from noisy channels
*Why needed:* Used to solve the inverse problem of identifying interactions from observed log probability differences
*Quick check:* Validate that decoding algorithms converge reliably for the noise levels present in log probability estimates

## Architecture Onboarding

**Component Map:** Input perturbations -> Log probability computation -> Sparse Fourier transform -> Channel decoding -> Interaction attribution

**Critical Path:** The bottleneck is the generation and processing of perturbed samples (O(sdn) complexity), where s is sparsity, d is sample count, and n is input length

**Design Tradeoffs:** 
- Higher sparsity assumptions enable faster computation but may miss complex interactions
- More samples improve accuracy but increase computational cost
- Random binary masks balance exploration of interaction space with computational efficiency

**Failure Signatures:**
- Dense interaction patterns lead to poor recovery and high computational cost
- Insufficient samples result in noisy interaction attributions
- Model architectures with inherently dense interactions violate sparsity assumptions

**First Experiments:**
1. Validate sparsity assumption on benchmark datasets by computing interaction density
2. Test recovery accuracy with varying sample counts and sparsity levels
3. Compare faithfulness metrics against marginal attribution baselines on simple tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on sparsity assumptions that may not hold for all model architectures or datasets
- O(sdn) complexity improvement depends critically on sparsity parameter s remaining small
- Evaluation focuses primarily on specific datasets with limited exploration of broader generalization

## Confidence
- **Computational efficiency claims:** High confidence - clear algorithmic presentation with established theoretical foundations
- **Faithfulness improvements:** Medium confidence - evaluation relies on proxy metrics that may not capture real-world utility
- **Reasoning error identification:** Low confidence - limited sample size and lack of systematic error analysis

## Next Checks
1. Systematically stress-test SPEX on datasets known to have dense interaction patterns to quantify robustness when sparsity assumptions fail
2. Conduct ablation studies comparing SPEX against baseline interaction detection methods across diverse model architectures
3. Perform user studies evaluating whether SPEX-identified interactions improve human understanding of model behavior for debugging scenarios