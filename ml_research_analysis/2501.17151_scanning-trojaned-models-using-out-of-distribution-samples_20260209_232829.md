---
ver: rpa2
title: Scanning Trojaned Models Using Out-of-Distribution Samples
arxiv_id: '2501.17151'
source_url: https://arxiv.org/abs/2501.17151
tags:
- samples
- adversarial
- training
- attacks
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TRODO, a novel method for scanning trojaned
  (backdoored) deep neural network models by leveraging out-of-distribution (OOD)
  samples. The key insight is that trojaned classifiers contain "blind spots" in their
  decision boundaries where OOD samples are misclassified as in-distribution.
---

# Scanning Trojaned Models Using Out-of-Distribution Samples
## Quick Facts
- arXiv ID: 2501.17151
- Source URL: https://arxiv.org/abs/2501.17151
- Reference count: 40
- Primary result: TRODO achieves 79.4% zero-data accuracy in detecting trojaned models using OOD samples

## Executive Summary
This paper introduces TRODO, a novel method for detecting trojaned (backdoored) deep neural network models using out-of-distribution (OOD) samples. The key insight is that trojaned classifiers contain "blind spots" in their decision boundaries where OOD samples are misclassified as in-distribution. TRODO detects these blind spots by adversarially shifting OOD samples toward the in-distribution region and measuring increases in their ID-Scores (maximum softmax probability). The method works without access to clean training data (TRODO-Zero) and remains effective against adversarially trained trojaned models.

## Method Summary
TRODO leverages the observation that trojaned classifiers exhibit decision boundary inconsistencies that can be exploited using OOD samples. The method involves shifting OOD samples toward the in-distribution region using an adversarial perturbation-based optimization process. The core metric is the ID-Score, which represents the maximum softmax probability of a sample being classified as in-distribution. By measuring how much this score increases when OOD samples are adversarially shifted toward the ID region, TRODO identifies trojaned models. The approach works even in zero-data scenarios where no clean training data is available, making it particularly practical for real-world deployment.

## Key Results
- TRODO achieves 79.4% accuracy in zero-data scenarios for detecting trojaned models
- With minimal clean data, accuracy improves to 90.7% on standard and adversarially trained trojaned models
- Outperforms existing methods by 11.4% and 24.8% on standard and adversarially trained trojaned models respectively
- Demonstrates label-mapping agnostic capability across various trojan scenarios and datasets

## Why This Works (Mechanism)
TRODO exploits the fundamental property that trojaned models have corrupted decision boundaries with "blind spots" where they misclassify OOD samples as in-distribution. These blind spots arise because the trojaning process creates shortcuts in the decision boundary that allow backdoor triggers to work. When OOD samples are adversarially shifted toward the in-distribution region, trojaned models show disproportionately large increases in ID-Scores compared to clean models, revealing their compromised nature.

## Foundational Learning
1. **ID-Score concept**: Measures maximum softmax probability for in-distribution classification. Needed to quantify how confidently a model classifies samples as belonging to the training distribution.
   - Quick check: Compare ID-Scores between clean and trojaned models on the same OOD samples

2. **Adversarial perturbation optimization**: Technique for finding small input modifications that cause large output changes. Essential for shifting OOD samples toward decision boundaries.
   - Quick check: Verify perturbations remain imperceptible while effectively shifting samples

3. **Decision boundary analysis**: Understanding how trojaned models create inconsistent regions in their classification boundaries. Critical for identifying the blind spots TRODO exploits.
   - Quick check: Visualize decision boundaries to confirm trojan-induced inconsistencies

## Architecture Onboarding
**Component map**: OOD samples -> Adversarial perturbation optimization -> ID-Score calculation -> Comparison with threshold -> Trojan detection

**Critical path**: The adversarial shifting of OOD samples toward the in-distribution region, followed by ID-Score measurement, represents the core detection mechanism. The quality and diversity of OOD samples directly impacts detection performance.

**Design tradeoffs**: 
- Using OOD samples provides a data-efficient detection approach but depends on having meaningful OOD distributions
- Adversarial shifting balances perturbation magnitude with effectiveness
- Zero-data mode sacrifices some accuracy for practical deployability

**Failure signatures**: 
- Low detection accuracy when OOD samples are too similar to in-distribution data
- False negatives when trojan triggers create very subtle decision boundary changes
- Performance degradation on highly complex model architectures

**First experiments**:
1. Test ID-Score shifts on clean vs. trojaned models using CIFAR-10 OOD samples
2. Evaluate zero-data mode performance across different trojaning techniques
3. Measure adversarial training robustness by comparing detection accuracy before and after adversarial training

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Detection effectiveness depends on availability of meaningful OOD samples that can be effectively shifted
- 79.4% zero-data accuracy, while impressive, still leaves room for improvement in practical scenarios
- Performance against sophisticated adaptive attacks beyond adversarial training remains unclear
- Scalability to larger, more complex model architectures beyond tested configurations is uncertain

## Confidence
**Major claim confidence:**
- TRODO's core detection mechanism using ID-Score shifts: High
- Zero-data effectiveness without clean training samples: Medium
- Adversarial training robustness claims: Medium
- Label-mapping agnostic capability: High

## Next Checks
1. Test TRODO against advanced adaptive trojaning strategies that specifically avoid creating detectable blind spots in OOD regions
2. Evaluate performance on larger-scale models (e.g., Vision Transformers, language models) and diverse datasets beyond the current selection
3. Investigate the impact of OOD sample quality and diversity on detection accuracy through controlled ablation studies