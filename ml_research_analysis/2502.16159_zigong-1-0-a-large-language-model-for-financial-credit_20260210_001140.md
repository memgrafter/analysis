---
ver: rpa2
title: 'ZiGong 1.0: A Large Language Model for Financial Credit'
arxiv_id: '2502.16159'
source_url: https://arxiv.org/abs/2502.16159
tags:
- data
- financial
- credit
- training
- large
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving large language
  models for financial credit assessment tasks, which require specialized expertise
  and suffer from issues like hallucination and knowledge forgetting. The authors
  propose ZiGong, a Mistral-based model enhanced through multi-task supervised fine-tuning
  and a novel data pruning methodology.
---

# ZiGong 1.0: A Large Language Model for Financial Credit

## Quick Facts
- **arXiv ID**: 2502.16159
- **Source URL**: https://arxiv.org/abs/2502.16159
- **Reference count**: 2
- **Primary result**: Novel ZiGong model achieves superior performance on financial credit assessment tasks through data pruning and hybrid training.

## Executive Summary
ZiGong 1.0 addresses the challenge of applying large language models to financial credit assessment tasks, which require specialized expertise and suffer from issues like hallucination and knowledge forgetting. The authors propose a Mistral-based model enhanced through multi-task supervised fine-tuning and a novel data pruning methodology called TracSeq. This approach effectively mitigates hallucinations while maintaining reliability in downstream applications, achieving superior performance across multiple financial credit tasks compared to other models. The method has been successfully deployed in their Behavior Card service, demonstrating practical efficacy in real-world loan process applications.

## Method Summary
ZiGong is a Mistral 7B model fine-tuned with LoRA using a hybrid training dataset. The approach employs TracSeq, an improved data distillation method that incorporates temporal dependencies in financial data. A proxy model scores training samples to select top-k influential data points, which are then combined with random samples (70/30 split) for training. This data refinement strategy effectively reduces hallucinations in LLMs while maintaining reliability. The model is evaluated on CALM benchmark datasets covering credit scoring, fraud detection, financial distress identification, and claim analysis tasks.

## Key Results
- ZiGong achieves superior performance across multiple financial credit tasks compared to other models
- Notable improvements on datasets like Australia and Credit Card Fraud
- Successfully deployed in real-world Behavior Card service for loan process applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Selecting high-influence training samples via TracSeq improves training efficiency and model generalization for financial tasks.
- Mechanism: TracSeq builds upon TracInCP by calculating an influence score for each training sample using gradient similarity between training and test samples at various checkpoints, with time decay weighting recent behaviors.
- Core assumption: Influence scores calculated by a lightweight proxy model accurately reflect training sample value for the final LLM, and recent financial behaviors are more predictive of future outcomes.
- Evidence anchors:
  - [abstract] "Our approach utilizes a proxy model to score training samples... This data refinement strategy effectively reduces hallucinations in LLMs..."
  - [section 3.1] "...we propose an improved version of TracInCP, denoted as TracSeq... The time decay factor ensures that more recent samples receive higher weights..."
- Break condition: Proxy model is too dissimilar from target LLM, or time-decay assumption fails for financial tasks where long-term history is critical.

### Mechanism 2
- Claim: A hybrid training dataset combining high-influence samples with random samples improves model robustness and mitigates hallucinations.
- Mechanism: Constructs training set by mixing 30% high-influence samples with 70% randomly selected samples to leverage focused signal from pruned data while maintaining broad coverage.
- Core assumption: Pruned samples contain specialized knowledge that corrects specific model failures, while random samples provide sufficient diversity for general competence.
- Evidence anchors:
  - [abstract] "...subsequently combining filtered data with original datasets for model training. This... effectively reduces hallucinations in LLMs while maintaining reliability..."
  - [section 5] "...utilizing only half of the high-influence samples can achieve superior performance compared to using the entire original dataset."
- Break condition: Pruned samples introduce or amplify biases, or random sample proportion is too low to ensure generalization.

### Mechanism 3
- Claim: Incorporating temporal dependencies into data selection better aligns model training with sequential nature of financial behavior.
- Mechanism: TracSeq introduces multiplicative decay term γ^(T-t_i) to influence score calculation, exponentially reducing weight of training sample's influence based on its age.
- Core assumption: Financial behavior is non-stationary, and data distribution shifts over time, making older data points proportionally less relevant to current predictions.
- Evidence anchors:
  - [section 3.1] "The time decay factor γ^(T-t_i) ensures that more recent samples receive higher weights, accounting for potential data distribution shifts over time."
  - [section 3.1] "Simply treating different time periods as separate, independent samples leads to information loss, as it ignores the inherent time dependencies..."
- Break condition: Decay rate γ is suboptimal, causing model to either overfit to recent noise or fail to adapt to new trends.

## Foundational Learning

- Concept: **Influence Functions**
  - Why needed here: Core of TracSeq is an influence function (TracInCP) that estimates impact of single training point on model's loss at test point by tracing gradients.
  - Quick check question: If a training sample has a large, positive influence score on a given test sample, what does that imply about its role in training?

- Concept: **Instruction Tuning / Supervised Fine-Tuning (SFT)**
  - Why needed here: ZiGong is not used zero-shot but is a Mistral model enhanced via multi-task SFT on structured "instruct data."
  - Quick check question: What is the primary difference between pre-training and the supervised fine-tuning stage used to create ZiGong?

- Concept: **LoRA (Low-Rank Adaptation)**
  - Why needed here: Authors specify they "use the LORA... to reduce the computation cost," making fine-tuning a 7B parameter model feasible.
  - Quick check question: How does LoRA minimize the number of trainable parameters during the fine-tuning process?

## Architecture Onboarding

- Component map: Base Model (Mistral 7B) -> Proxy Model (Agent) -> Data Pruning Pipeline -> Instruction Data Constructor -> Fine-Tuning Engine
- Critical path:
  1. Train or select suitable proxy model on financial data
  2. Run TracSeq algorithm to score and rank all training samples
  3. Select Top-K samples and combine with random subset to form final dataset
  4. Format data using templates in Table 1
  5. Fine-tune Mistral 7B with LoRA
- Design tradeoffs:
  - Proxy Model Fidelity: More complex proxy model gives better scores but increases pre-processing time
  - Pruning Ratio: 70/30 random/pruned split is a hyperparameter; higher prune ratio increases focus but risks losing data diversity
  - Time Decay Factor (γ): Critical and likely task-dependent parameter requiring tuning to balance value of recent vs. historical data
- Failure signatures:
  - No Performance Gain: Proxy model's gradients not representative of LLM's learning process
  - Model Forgetting: Pruned dataset too small or biased, causing loss of general capabilities
  - Temporal Misalignment: Incorrect γ causes overfitting to recent noise or failure to adapt to new trends
- First 3 experiments:
  1. Baseline Comparison: Fine-tune Mistral 7B with LoRA on full dataset without pruning
  2. Pruning Ablation: Implement TracSeq scoring pipeline; compare runs with (a) Full dataset, (b) Pruned-only dataset, and (c) Hybrid dataset (70% random, 30% pruned)
  3. Hyperparameter Sensitivity: Test different values for time decay factor γ (e.g., 0.9, 0.95, 0.99) and Top-K selection threshold

## Open Questions the Paper Calls Out
None

## Limitations
- Critical hyperparameters like time decay factor γ, training steps, and proxy model architecture are not fully specified
- Paper does not address potential biases introduced by the proxy model or 70/30 random/pruned split
- Experiments limited to specific CALM benchmark datasets without broader generalization testing
- Real-world deployment claims lack quantitative evaluation or user studies within the paper

## Confidence
- **High Confidence**: Core mechanism of TracSeq (influence functions with temporal decay) is well-established, and hybrid data training approach to reduce hallucinations is sound
- **Medium Confidence**: Specific implementation details of TracSeq are described but not fully specified, making exact replication challenging
- **Low Confidence**: Claim of successful deployment in Behavior Card service is anecdotal without quantitative backing

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary time decay factor γ (e.g., 0.9, 0.95, 0.99) and Top-K pruning ratio (e.g., 10%, 30%, 50%) to determine impact on model performance and robustness
2. **Proxy Model Ablation**: Compare ZiGong performance using different proxy model architectures (e.g., logistic regression, random forest, small transformer) for TracSeq scoring step
3. **Fairness and Bias Audit**: Evaluate ZiGong on fairness metrics using known sensitive attributes in CALM datasets to quantify biases introduced by hybrid training approach