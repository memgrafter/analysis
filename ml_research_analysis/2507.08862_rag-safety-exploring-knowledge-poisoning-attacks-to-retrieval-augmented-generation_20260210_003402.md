---
ver: rpa2
title: 'RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation'
arxiv_id: '2507.08862'
source_url: https://arxiv.org/abs/2507.08862
tags:
- attack
- kg-rag
- adversarial
- knowledge
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first systematic study of data poisoning
  attacks on knowledge graph-based retrieval-augmented generation (KG-RAG) systems.
  The authors propose an attack strategy that inserts perturbation triples into the
  knowledge graph to construct misleading inference chains, thereby degrading KG-RAG
  performance.
---

# RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2507.08862
- Source URL: https://arxiv.org/abs/2507.08862
- Reference count: 40
- Primary result: First systematic study of knowledge graph poisoning attacks on KG-RAG systems, showing up to 46% F1 score degradation

## Executive Summary
This paper presents the first systematic study of data poisoning attacks on knowledge graph-based retrieval-augmented generation (KG-RAG) systems. The authors propose an attack strategy that inserts perturbation triples into the knowledge graph to construct misleading inference chains, thereby degrading KG-RAG performance. Experiments on two benchmarks and four representative KG-RAG methods show significant performance degradation, with the attack being particularly effective in the retrieval stage. The work identifies retrieval as the critical vulnerability point in KG-RAG systems and demonstrates the effectiveness of knowledge poisoning under realistic black-box conditions.

## Method Summary
The authors propose a knowledge poisoning attack that operates by inserting adversarial triples into the knowledge graph. Under a black-box setting where attackers can only insert a small number of triples using existing entities and relations, the attack constructs misleading inference chains. The attack strategy involves creating triples that appear semantically plausible but lead to incorrect inferences when retrieved. The evaluation is conducted on two benchmarks using four representative KG-RAG methods, measuring the impact on QA performance through standard metrics like F1 score.

## Key Results
- Knowledge poisoning attacks can reduce KG-RAG QA performance by up to 46% F1 score on WebQSP
- Over 90% of questions retrieved at least one adversarial triple, demonstrating attack effectiveness in the retrieval stage
- KG-RAG methods are highly vulnerable to knowledge poisoning, with retrieval being the critical weak point
- The attack operates successfully under realistic black-box conditions with limited insertion capabilities

## Why This Works (Mechanism)
The attack exploits the fundamental reliance of KG-RAG systems on knowledge graph retrieval. By inserting adversarial triples that create misleading inference paths, the attack corrupts the information retrieved during the knowledge retrieval phase. Since KG-RAG systems treat retrieved knowledge as trusted input for generation, poisoned triples lead to incorrect answers. The effectiveness stems from the fact that retrieval occurs before any verification, making it difficult for downstream generation components to detect or correct poisoned information. The attack leverages the semantic similarity between adversarial and legitimate triples to evade detection while still leading to incorrect inferences.

## Foundational Learning
- **Knowledge Graph Poisoning**: Tampering with KG data to mislead downstream reasoning - needed to understand attack vector; quick check: Can identify how triple insertion affects query results
- **Retrieval-Augmented Generation (RAG)**: Combining retrieval systems with language models for enhanced generation - needed to understand system architecture; quick check: Can explain how retrieved knowledge informs generation
- **Black-box Attack Setting**: Attacker has limited knowledge of target system - needed to assess attack realism; quick check: Can describe constraints on triple insertion
- **Inference Chains**: Paths through knowledge graphs that connect entities via relations - needed to understand how poisoning creates misleading paths; quick check: Can trace how inserted triples affect reasoning paths
- **QA Performance Metrics**: F1 score and related measures for evaluating answer quality - needed to quantify attack impact; quick check: Can calculate F1 score from precision and recall

## Architecture Onboarding

Component Map: Knowledge Graph -> Retrieval Engine -> Generator -> Answer Output

Critical Path: Question -> Knowledge Graph Query -> Triple Retrieval -> Context Formation -> Answer Generation

Design Tradeoffs:
- Attack effectiveness vs. stealth (plausible triples vs. obvious poisoning)
- Number of triples inserted vs. performance degradation
- Black-box constraints vs. attack sophistication
- Retrieval stage vulnerability vs. generation stage defenses

Failure Signatures:
- Retrieval of semantically plausible but factually incorrect triples
- Answer generation based on corrupted knowledge paths
- High retrieval rates of adversarial triples (over 90%)
- Significant F1 score drops (up to 46%) on benchmark datasets

3 First Experiments:
1. Insert single adversarial triple and measure retrieval rate and impact on specific questions
2. Vary number of inserted triples (1, 5, 10) to assess scalability of attack effectiveness
3. Test attack across different KG-RAG methods to identify method-specific vulnerabilities

## Open Questions the Paper Calls Out
None

## Limitations
- Real-world applicability may be constrained by practical limitations on triple insertion
- Attack effectiveness assumes sophisticated triple crafting that may not be feasible in all scenarios
- Findings focus on knowledge graph-based RAG systems, leaving text-based RAG approaches unexplored
- Study does not explore defensive mechanisms at the generation stage
- Generalizability to larger, more complex knowledge graphs remains unclear

## Confidence
- High: Experimental methodology and results demonstrating significant performance degradation (up to 46% F1 score drop) are well-documented and reproducible
- Medium: Claim that retrieval is the critical vulnerability is supported by data but lacks exploration of alternative scenarios or defensive strategies
- Medium: Effectiveness of attack in controlled settings is clear, but real-world feasibility and generalizability require further validation

## Next Checks
1. Test the attack's effectiveness on larger, more complex knowledge graphs with varying densities and structures to assess scalability and generalizability
2. Evaluate the attack under stricter constraints, such as limiting the number of triples an attacker can insert or requiring the use of entirely new entities
3. Investigate whether defensive mechanisms at the generation stage, such as fact-checking or consistency verification, can mitigate the impact of retrieved adversarial triples