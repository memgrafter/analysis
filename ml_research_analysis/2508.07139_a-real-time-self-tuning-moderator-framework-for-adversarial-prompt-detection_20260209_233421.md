---
ver: rpa2
title: A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection
arxiv_id: '2508.07139'
source_url: https://arxiv.org/abs/2508.07139
tags:
- arxiv
- prompt
- prompts
- adversarial
- rtst
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "RTST is a real-time, self-tuning moderator framework that defends\
  \ against adversarial prompts without degrading responses to benign prompts. It\
  \ uses two LLM agents\u2014an Evaluator and a Reviewer\u2014to score prompts against\
  \ a set of Behaviors and adapt weights in real time."
---

# A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection

## Quick Facts
- **arXiv ID**: 2508.07139
- **Source URL**: https://arxiv.org/abs/2508.07139
- **Reference count**: 40
- **Key outcome**: RTST reduced attack success rates from 12–63% to 0–17% across multiple jailbreak datasets on Gemini 2.5 Flash.

## Executive Summary
RTST introduces a real-time, self-tuning moderator framework designed to defend against adversarial prompts without compromising responses to benign prompts. The framework employs two LLM agents—an Evaluator and a Reviewer—that collaboratively score prompts against predefined Behaviors and dynamically adapt their weights. Experiments demonstrate substantial reductions in attack success rates while maintaining acceptable false refusal rates, highlighting RTST's potential as a lightweight, adaptive defense mechanism against evolving adversarial threats.

## Method Summary
RTST operates by deploying two specialized LLM agents: an Evaluator that assesses prompts for malicious intent and a Reviewer that refines these assessments in real time. The framework dynamically tunes the weights assigned to different Behaviors, enabling it to adapt to evolving attack patterns without manual intervention. This self-tuning capability is central to RTST's effectiveness, allowing it to maintain high detection accuracy while minimizing disruption to legitimate user interactions.

## Key Results
- Attack success rates dropped from 12–63% to 0–17% across multiple jailbreak datasets on Gemini 2.5 Flash.
- False refusal rates increased modestly from 12% to 18%, indicating maintained benign prompt response quality.
- Real-time weight tuning improved detection accuracy and F1 scores compared to static baselines.

## Why This Works (Mechanism)
RTST's effectiveness stems from its dual-agent architecture and adaptive weighting system. The Evaluator agent continuously scores prompts against a set of Behaviors, while the Reviewer agent refines these scores and adjusts the importance of each Behavior in real time. This dynamic adjustment allows the system to respond to novel attack patterns without requiring manual retraining, effectively balancing security and usability.

## Foundational Learning
- **LLM agent collaboration**: Why needed: Enables distributed reasoning for complex threat detection. Quick check: Verify agents can communicate and update weights without conflicts.
- **Real-time weight adaptation**: Why needed: Allows the system to evolve defenses as attack strategies change. Quick check: Confirm weight updates occur within acceptable latency bounds.
- **Behavior-based scoring**: Why needed: Provides granular, interpretable threat assessment. Quick check: Ensure Behavior definitions cover known attack vectors.
- **Dual-agent redundancy**: Why needed: Reduces single points of failure in threat detection. Quick check: Test system robustness when one agent is degraded.

## Architecture Onboarding
**Component map**: User Prompt -> Evaluator Agent -> Behavior Scoring -> Reviewer Agent -> Weight Adjustment -> Final Decision
**Critical path**: Prompt ingestion → Evaluator scoring → Reviewer refinement → Adaptive weight update → Output decision
**Design tradeoffs**: Lightweight real-time tuning vs. computational overhead; interpretability vs. detection accuracy; false positives vs. false negatives
**Failure signatures**: Consistent false refusals indicate overly aggressive Behavior weights; missed attacks suggest insufficient weight tuning or Behavior coverage gaps
**First experiments**: (1) Benchmark RTST against static baselines on standard jailbreak datasets; (2) Measure latency impact of real-time weight tuning under load; (3) Test cross-model robustness by deploying RTST on non-Gemini LLMs

## Open Questions the Paper Calls Out
None

## Limitations
- Performance generalizability across diverse LLM architectures beyond Gemini 2.5 Flash remains uncertain.
- Real-time weight tuning's computational overhead and scalability under sustained attack loads were not fully characterized.
- Limited temporal testing raises questions about long-term stability of the adaptive mechanism.

## Confidence
- Confidence in maintaining benign prompt response quality: High (modest increase in false refusal rates: 12% to 18%)
- Confidence in detection accuracy improvements: Medium (ablation tests support real-time tuning but lack exploration of alternatives)
- Confidence in adaptability to evolving attacks: Low (limited temporal testing and no evaluation against adaptive attackers)

## Next Checks
1. Test RTST across multiple LLM architectures and model families to assess cross-model robustness.
2. Evaluate performance under sustained, evolving attack scenarios over extended time periods to measure adaptation stability.
3. Quantify computational overhead and latency impacts under realistic, high-volume operational conditions.