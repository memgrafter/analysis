---
ver: rpa2
title: 'Autoregressive Language Models for Knowledge Base Population: A case study
  in the space mission domain'
arxiv_id: '2503.18502'
source_url: https://arxiv.org/abs/2503.18502
tags:
- ontology
- mission
- language
- knowledge
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The authors investigate fine-tuning autoregressive language models\
  \ for end-to-end knowledge base population (KBP) in the space mission domain. Instead\
  \ of large general-purpose models, they fine-tune smaller Pythia models on a synthetic\
  \ dataset generated via instruction-tuning, using mission descriptions from the\
  \ ESA\u2019s EOPortal and structured CEOS database as reference."
---

# Autoregressive Language Models for Knowledge Base Population: A case study in the space mission domain

## Quick Facts
- arXiv ID: 2503.18502
- Source URL: https://arxiv.org/abs/2503.18502
- Authors: Andrés García-Silva; José Manuel Gómez-Pérez
- Reference count: 9
- Primary result: Fine-tuned smaller Pythia models (1B-2.8B parameters) achieve >90% syntactic correctness and strong semantic accuracy for space mission KBP without requiring ontology in prompts

## Executive Summary
This paper investigates fine-tuning autoregressive language models for end-to-end knowledge base population (KBP) in the space mission domain. The authors fine-tune smaller Pythia models (160M to 12B parameters) on synthetic data generated via instruction-tuning, using ESA's EOPortal and CEOS database as reference. The models extract instances from a predefined ontology and serialize them in Turtle format. The key finding is that models 1B+ parameters show high syntactic correctness (>90%) and strong semantic accuracy, with the 2.8B model performing best without including the ontology in prompts, leaving more context space for input text.

## Method Summary
The authors fine-tuned Pythia autoregressive language models on a synthetic dataset generated from space mission descriptions. The training data was created through instruction-tuning using mission descriptions from ESA's EOPortal and structured data from the CEOS database as reference. The task involved extracting instances from a predefined ontology and serializing them in Turtle format. Multiple model sizes (160M to 12B parameters) were evaluated, with the 1B+ models showing the best balance of performance and efficiency.

## Key Results
- Pythia models 1B+ parameters achieved >90% syntactic correctness for Turtle serialization
- Semantic accuracy measured by ROUGE-L and LLM-based similarity was strong for 1B+ models
- The 2.8B model performed best without including the ontology in prompts, while the 1B model remained competitive
- Smaller models (1B-2.8B) performed comparably to larger ones, indicating that large models are not necessary for this task

## Why This Works (Mechanism)
The approach works by leveraging fine-tuning on domain-specific synthetic data to adapt general-purpose language models to the KBP task. By generating synthetic examples through instruction-tuning from structured references (CEOS database) and natural language descriptions (EOPortal), the models learn to map mission descriptions to ontology instances. The removal of the ontology from prompts creates more context space for the input text, allowing the model to focus on the mission description itself rather than referring to external ontology definitions.

## Foundational Learning
- **Autoregressive language models**: Generate text sequentially, predicting the next token based on previous context. Needed for end-to-end text generation tasks like Turtle serialization.
- **Knowledge base population (KBP)**: The task of automatically extracting information and populating knowledge bases. Quick check: Verify the model can extract structured triples from unstructured text.
- **Instruction-tuning**: A fine-tuning approach where models are trained on instruction-response pairs. Quick check: Ensure synthetic dataset quality through manual inspection.
- **ROUGE-L metric**: Measures n-gram overlap between generated and reference text, useful for evaluating semantic similarity in structured output tasks.
- **Turtle serialization**: A standard syntax for expressing RDF data, used here to represent ontology instances in a machine-readable format.

## Architecture Onboarding

Component Map:
ESA EOPortal/ CEOS Database -> Synthetic Dataset Generator -> Fine-tuning Pipeline -> Pythia Models (160M-12B) -> KBP Output (Turtle)

Critical Path:
Mission description input → Context processing → Ontology instance extraction → Turtle serialization → Output validation

Design Tradeoffs:
- Model size vs. performance: Larger models show marginal improvements but increase computational cost
- Prompt design: Including vs. excluding ontology affects context space allocation
- Synthetic vs. real data: Synthetic data enables controlled training but may miss edge cases

Failure Signatures:
- Low syntactic correctness indicates issues with Turtle format generation
- Poor semantic accuracy suggests misalignment between mission descriptions and ontology mapping
- Hallucinations may occur when processing descriptions outside training distribution

First Experiments:
1. Test syntactic correctness on held-out space mission descriptions
2. Evaluate semantic accuracy using ROUGE-L and LLM-based similarity
3. Compare performance with and without ontology in prompts

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Narrow domain focus on space missions limits generalizability to other KBP tasks
- Synthetic dataset generation may introduce biases from instruction-tuning methodology
- Evaluation relies heavily on automated metrics that may not capture all aspects of semantic accuracy
- Does not address potential model hallucinations or factual inconsistencies with out-of-distribution inputs

## Confidence

High confidence:
- Syntactic correctness metrics (>90% for 1B+ models)
- Core finding that smaller models (1B-2.8B) perform competitively with larger ones

Medium confidence:
- Semantic accuracy measurements via ROUGE-L and LLM-based similarity
- Claim that omitting ontology from prompts improves performance

## Next Checks

1. Test fine-tuned models on space mission descriptions from sources not used in training to assess robustness and generalization
2. Conduct human evaluation of extracted triples to validate semantic accuracy beyond automated metrics
3. Evaluate model performance on KBP tasks in other domains (e.g., biomedical, legal) to determine approach transferability