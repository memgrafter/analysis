---
ver: rpa2
title: Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented
  Generation
arxiv_id: '2505.11995'
source_url: https://arxiv.org/abs/2505.11995
tags:
- knowledge
- external
- internal
- information
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a systematic investigation into how large language
  models (LLMs) utilize internal and external knowledge in retrieval-augmented generation
  (RAG) systems. The authors propose a novel framework that analyzes knowledge utilization
  from both macroscopic knowledge streaming perspectives and microscopic module-level
  functions.
---

# Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2505.11995
- Source URL: https://arxiv.org/abs/2505.11995
- Reference count: 40
- This paper presents a systematic investigation into how large language models (LLMs) utilize internal and external knowledge in retrieval-augmented generation (RAG) systems.

## Executive Summary
This paper systematically investigates knowledge utilization mechanisms in LLM-based RAG systems through both macroscopic knowledge streaming analysis and microscopic module-level function examination. The authors propose a novel framework that identifies four distinct stages of knowledge streaming in RAG: refinement, elicitation, expression, and contestation. They introduce a new metric called Knowledge Activation Probability Entropy (KAPE) to identify neurons associated with internal and external knowledge, demonstrating that selective deactivation of these neurons can effectively shift the model's reliance between knowledge sources. The study reveals complementary roles between multi-head attention and multi-layer perceptron modules, with MLP layers showing particular sensitivity to the factual accuracy of external knowledge.

## Method Summary
The authors developed a comprehensive framework analyzing knowledge utilization in RAG systems from two perspectives: macroscopic knowledge streaming and microscopic module functions. They introduced four stages of knowledge streaming (refinement, elicitation, expression, and contestation) and a new metric called Knowledge Activation Probability Entropy (KAPE) to identify knowledge-specific neurons. The experimental setup involved creating "gold" and "fake" passages to test knowledge source reliance, along with systematically deactivating identified neurons to observe changes in model behavior. The study used LLaMA and Qwen models across various scales, validating their framework on open-domain QA datasets including NQ, TriviaQA, and HotpotQA.

## Key Results
- Four distinct stages of knowledge streaming were identified: knowledge refinement, elicitation, expression, and contestation
- KAPE metric successfully identified neurons associated with internal and external knowledge utilization
- Selective deactivation of identified neurons can effectively shift model reliance between knowledge sources
- MLP layers showed particular sensitivity to the factual accuracy of external knowledge, while MHA modules demonstrated complementary roles

## Why This Works (Mechanism)
The framework works by analyzing information flow through attention weights and saliency scores across different layers of the LLM, revealing distinct patterns in how models process and integrate internal versus external knowledge. The KAPE metric quantifies neuron activation patterns to identify which neurons are most associated with knowledge from different sources, enabling targeted interventions. The complementary relationship between MHA and MLP modules allows for both content-based similarity matching and factual accuracy assessment, creating a robust knowledge integration mechanism.

## Foundational Learning
- **Knowledge Activation Probability Entropy (KAPE)**: A metric quantifying neuron activation patterns to identify knowledge-specific neurons; needed to distinguish between internal and external knowledge utilization patterns; quick check: verify KAPE scores correlate with known knowledge source indicators
- **Multi-head Attention (MHA) modules**: Process context through content-based similarity matching; needed for initial knowledge refinement and expression stages; quick check: examine attention weight distributions across heads
- **Multi-layer Perceptron (MLP) modules**: Transform embeddings while maintaining dimensional consistency; needed for factual accuracy assessment and contestation resolution; quick check: measure unembedding logit changes when MLP neurons are deactivated
- **Knowledge streaming stages**: Four-stage process (refinement → elicitation → expression → contestation); needed to understand temporal progression of knowledge integration; quick check: verify stage transitions using layer-wise attention and saliency metrics
- **Neuron deactivation technique**: Method for selectively disabling specific neurons to test their functional contribution; needed to validate KAPE-identified knowledge-specific neurons; quick check: measure knowledge source preference shifts after targeted deactivation

## Architecture Onboarding

**Component Map**: Input Query → RAG System (Knowledge Refinement Stage → Knowledge Elicitation Stage → Knowledge Expression Stage → Knowledge Contestation Stage) → Output Generation

**Critical Path**: The critical path follows the four-stage knowledge streaming process, where each stage progressively transforms and integrates knowledge from internal and external sources before final generation.

**Design Tradeoffs**: The framework balances between comprehensive knowledge integration (using both internal and external sources) and computational efficiency (selectively activating knowledge-specific neurons). The use of KAPE enables targeted interventions but requires additional computation for neuron identification.

**Failure Signatures**: Models may fail when external knowledge is factually incorrect but highly relevant, leading to contestation stage conflicts. Performance degradation occurs when neuron deactivation disrupts critical knowledge integration pathways, particularly in the elicitation and contestation stages.

**First 3 Experiments**:
1. Apply the framework to non-QA tasks (e.g., summarization) to test generalizability of the four-stage model
2. Test KAPE metric effectiveness across different LLM architectures (GPT, Claude) beyond LLaMA and Qwen
3. Evaluate knowledge streaming patterns with varying passage qualities and retrieval strategies

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do the four identified knowledge streaming stages (refinement, elicitation, expression, contestation) persist structurally in generative tasks beyond open-domain QA, such as summarization or complex reasoning?
- **Basis in paper:** [explicit] The authors explicitly limit the investigation to "typical application scenarios: open-domain question answering (ODQA)" in Section 2.1.
- **Why unresolved:** The paper validates the four-stage hypothesis exclusively on single-hop and multi-hop QA datasets (NQ, TriviaQA, HotpotQA), leaving the generalizability of this mechanism to other RAG-integrated tasks unproven.
- **What evidence would resolve it:** Applying the attention and saliency-based information flow metrics to non-QA tasks (e.g., long-form generation) to verify if the distinct layer-wise stage transitions remain statistically significant.

### Open Question 2
- **Question:** Can the KAPE metric be utilized for permanent training-time interventions (e.g., regularization) rather than temporary inference-time deactivation?
- **Basis in paper:** [inferred] The paper demonstrates controlling knowledge reliance by "selectively deactivating these neurons" during inference in Section 4.1.2, but does not explore if this mechanism can persist through weight updates.
- **Why unresolved:** It is unclear if the "knowledge-specific neurons" identified by KAPE are stable enough to be targeted by loss functions during fine-tuning to permanently bias a model without ongoing manual intervention.
- **What evidence would resolve it:** Experiments fine-tuning models with a penalty on the activation of specific KAPE-identified neurons to see if the model permanently shifts its knowledge source preference.

### Open Question 3
- **Question:** How does the knowledge contestation stage resolve inputs where external evidence is partially relevant or subtly conflicting, rather than strictly "gold" or "fake"?
- **Basis in paper:** [inferred] The experimental setup in Section 2.2 constructs "fake passages" by replacing correct answers with incorrect ones (binary), while the conclusion in Section 5 calls for "more nuanced models" to handle "complexities of knowledge integration."
- **Why unresolved:** The binary nature of the experimental validation (correct vs. incorrect passage) may not capture the "contestation" dynamics in real-world scenarios where retrieved text is relevant but factually outdated or contradictory in nuance.
- **What evidence would resolve it:** Testing the unembedding logits of MLP and MHA modules using "gray-area" passages to observe if the contestation mechanism functions linearly or exhibits threshold behavior when facing partial contradictions.

## Limitations
- Study focuses exclusively on LLaMA and Qwen model families, limiting generalizability to other LLM architectures
- Experimental scope limited to relatively short text generation tasks (4-6 tokens per output), raising questions about scalability to longer generation scenarios
- KAPE metric may not capture all aspects of knowledge utilization, particularly for distributed representations across multiple neurons

## Confidence
- **High**: The identification of four distinct knowledge streaming stages and the complementary roles of MHA and MLP modules
- **Medium**: The effectiveness of neuron deactivation in shifting knowledge source preference, as this is demonstrated within the specific experimental setup
- **Medium**: The claim that relevance guides knowledge streaming, particularly given the limited scope of passage types and tasks

## Next Checks
1. Test the framework and KAPE metric across diverse LLM architectures (GPT, Claude, domain-specific models) to assess generalizability
2. Conduct experiments with longer generation tasks (multiple sentences or paragraphs) to evaluate scalability of the identified mechanisms
3. Perform ablation studies varying retrieval quality and passage relevance to quantify their impact on knowledge streaming patterns and the effectiveness of neuron deactivation interventions