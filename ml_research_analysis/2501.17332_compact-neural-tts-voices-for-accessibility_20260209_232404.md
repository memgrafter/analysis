---
ver: rpa2
title: Compact Neural TTS Voices for Accessibility
arxiv_id: '2501.17332'
source_url: https://arxiv.org/abs/2501.17332
tags:
- neural
- speech
- system
- latency
- acoustic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a compact neural TTS system optimized for
  accessibility applications on low-power devices. The approach applies aggressive
  compression techniques to each component of a cascaded TTS pipeline: a Transformer-based
  frontend, FastSpeech2 acoustic model, and WaveRNN vocoder.'
---

# Compact Neural TTS Voices for Accessibility

## Quick Facts
- arXiv ID: 2501.17332
- Source URL: https://arxiv.org/abs/2501.17332
- Reference count: 24
- Key outcome: 15ms latency, 18MB disk footprint, 4.09 MOS score achieved through aggressive compression of TTS pipeline components

## Executive Summary
This paper presents a compact neural text-to-speech system optimized for accessibility applications on low-power devices. The approach applies aggressive compression techniques to each component of a cascaded TTS pipeline including a Transformer-based frontend, FastSpeech2 acoustic model, and WaveRNN vocoder. Through parameter sharing, quantization, sparsity, and other optimization techniques, the system achieves real-time performance with minimal resource requirements while maintaining high perceptual quality. The resulting architecture enables deployment of multiple high-quality TTS voices in accessibility tools with strict memory and latency constraints.

## Method Summary
The authors developed a compact TTS system by applying aggressive compression to each component of a cascaded pipeline. The frontend uses Transformer layers with parameter sharing and KV-caching for efficient text processing. The acoustic model employs INT8 quantization and filter reduction in FastSpeech2 to reduce memory footprint. The WaveRNN vocoder implements sparsity and subscale generation to minimize computational requirements. These optimizations collectively achieve 15ms latency and 18MB disk footprint while maintaining 4.09 MOS score quality.

## Key Results
- Achieves 15ms latency suitable for real-time accessibility applications
- Reduces disk footprint to 18MB enabling multiple voice deployments
- Maintains high perceptual quality with 4.09 MOS score
- Enables pre-installation across multiple voices on resource-constrained devices

## Why This Works (Mechanism)
The system achieves its compact footprint through component-wise optimization targeting different aspects of the TTS pipeline. The frontend compression reduces text processing overhead while maintaining linguistic accuracy. Acoustic model quantization and filter reduction significantly decrease memory requirements without substantial quality loss. Vocoder sparsity and subscale generation minimize the computational cost of waveform generation. The cascaded architecture allows each component to be independently optimized while maintaining end-to-end quality through careful calibration.

## Foundational Learning
- Transformer attention mechanisms: Used in frontend for text processing, requires understanding of self-attention and cross-attention patterns (Quick check: Verify attention patterns capture linguistic dependencies)
- INT8 quantization: Applied to acoustic model weights, involves understanding quantization noise and calibration (Quick check: Measure quality