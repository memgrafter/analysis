---
ver: rpa2
title: Improving End-to-End Training of Retrieval-Augmented Generation Models via
  Joint Stochastic Approximation
arxiv_id: '2508.18168'
source_url: https://arxiv.org/abs/2508.18168
tags:
- training
- retriever
- jsa-rag
- passage
- vrag
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of end-to-end training for retrieval-augmented
  generation (RAG) models, where marginalization over discrete latent variables (relevant
  passages) is required. Traditional approaches like top-K marginalization and variational
  RAG (VRAG) suffer from biased or high-variance gradient estimates.
---

# Improving End-to-End Training of Retrieval-Augmented Generation Models via Joint Stochastic Approximation

## Quick Facts
- arXiv ID: 2508.18168
- Source URL: https://arxiv.org/abs/2508.18168
- Reference count: 11
- Primary result: JSA-RAG achieves +4.1% EM on TQA and +8.5% R@1 on NQ compared to VRAG

## Executive Summary
This paper addresses the fundamental challenge of end-to-end training for retrieval-augmented generation (RAG) models, where marginalization over discrete latent variables (relevant passages) creates optimization difficulties. Traditional approaches like top-K marginalization and variational RAG suffer from biased or high-variance gradient estimates. The authors propose Joint Stochastic Approximation (JSA) based training for RAG, called JSA-RAG, which introduces an auxiliary posterior retriever and employs Metropolis independence sampling to approximate the E-step. The method is evaluated on five datasets across two tasks: open-domain question answering and knowledge-grounded dialogs, demonstrating significant improvements over baseline methods.

## Method Summary
JSA-RAG introduces a novel training framework that tackles the discrete latent variable problem in RAG models through joint stochastic approximation. The key innovation is the introduction of an auxiliary posterior retriever that approximates the true posterior distribution over relevant passages. During training, Metropolis independence sampling is used to approximate the E-step, generating samples from the proposal distribution that approximates the true posterior. The parameter updates follow a supervised training-like procedure, alternating between E-step (posterior approximation) and M-step (parameter updates). This approach effectively reduces the high variance associated with traditional REINFORCE-based methods while avoiding the bias introduced by top-K marginalization, enabling more stable and effective end-to-end training of RAG models.

## Key Results
- JSA-RAG achieves +4.1% Exact Match improvement on TQA dataset compared to VRAG
- Shows +8.5% R@1 retrieval accuracy improvement on NQ dataset over baseline methods
- Demonstrates +10.3% BLEU-4 improvement on DoQA dataset, validating effectiveness across multiple knowledge-intensive tasks

## Why This Works (Mechanism)
The mechanism works by addressing the core challenge of marginalization over discrete latent variables in RAG models. Traditional approaches either introduce bias (top-K) or suffer from high variance (REINFORCE). JSA-RAG circumvents this by introducing an auxiliary posterior retriever that approximates the true posterior distribution, then using Metropolis independence sampling to generate samples from this approximation. This creates a controlled approximation that balances bias and variance, enabling more stable gradient estimates. The joint stochastic approximation framework allows for alternating optimization between the posterior approximation and model parameters, similar to expectation-maximization but with stochastic updates that scale better to large datasets.

## Foundational Learning
- Variational Inference: Needed to understand how VRAG approximates posterior distributions using KL divergence minimization; quick check: verify understanding of ELBO derivation
- REINFORCE Algorithm: Essential for grasping why high-variance gradient estimates occur in discrete latent variable models; quick check: derive the gradient estimator for discrete variables
- Metropolis-Hastings Sampling: Critical for understanding the independence sampling approach used to approximate posteriors; quick check: verify acceptance probability calculation
- EM Algorithm: Provides context for the alternating optimization framework; quick check: compare standard EM with JSA's stochastic updates
- Latent Variable Models: Fundamental for understanding the marginalization challenge in RAG; quick check: identify how discrete variables affect gradient computation
- Stochastic Optimization: Important for understanding the scalability advantages of JSA over batch EM; quick check: contrast convergence properties of stochastic vs batch updates

## Architecture Onboarding

Component Map:
Input Text -> Retriever Module -> Passage Selection -> Generator Module -> Output Text
                          ↓
                  Auxiliary Posterior Retriever
                          ↓
                  Metropolis Independence Sampler

Critical Path:
The critical path follows: Input Text → Retriever → Passage Selection → Generator → Output. The auxiliary posterior retriever and sampler work in parallel during training to provide better gradient estimates, but during inference only the main retriever and generator are used.

Design Tradeoffs:
The primary tradeoff is between approximation quality and computational overhead. The auxiliary posterior retriever adds parameters and computation during training but enables better gradient estimates. The Metropolis independence sampling provides better approximation than top-K selection but requires multiple sampling steps per update. This design sacrifices some training efficiency for improved optimization stability and final model quality.

Failure Signatures:
Training instability or divergence would manifest as increasing loss despite continued training, particularly in the generator's ability to condition on retrieved passages. Poor retrieval performance despite good generation might indicate the auxiliary retriever isn't properly approximating the true posterior. If generation quality doesn't improve with better retrieval, it suggests the model isn't effectively utilizing the improved passage selection.

First Experiments:
1. Verify the auxiliary retriever learns to approximate the true posterior by comparing its output distribution to ground truth relevant passages
2. Test the variance reduction of gradient estimates by comparing to REINFORCE-based training on a simplified task
3. Evaluate the impact of different proposal distributions in Metropolis independence sampling on final performance

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses primarily on retrieval-based tasks, leaving unclear how JSA-RAG performs in broader text generation scenarios
- Computational overhead compared to standard RAG approaches is not thoroughly discussed, which is crucial for practical deployment
- Does not compare against more recent RAG variants or explore scaling behavior with larger models

## Confidence
- Mathematical formulation and algorithmic improvements: High
- Practical significance of improvements: Medium
- Claims about low-variance gradient estimates: High
- Impact of improvements on real-world applications: Medium

## Next Checks
1. Evaluate JSA-RAG on additional tasks beyond question answering and dialog systems, such as long-form document generation or summarization, to assess broader applicability
2. Conduct ablation studies isolating the contributions of Metropolis independence sampling versus the auxiliary posterior retriever to better understand which components drive performance gains
3. Measure and report the computational overhead of JSA-RAG during both training and inference phases, comparing it directly against competing methods to assess practical deployment viability