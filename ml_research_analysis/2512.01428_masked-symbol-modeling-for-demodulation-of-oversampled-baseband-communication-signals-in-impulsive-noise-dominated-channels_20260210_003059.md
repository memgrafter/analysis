---
ver: rpa2
title: Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication
  Signals in Impulsive Noise-Dominated Channels
arxiv_id: '2512.01428'
source_url: https://arxiv.org/abs/2512.01428
tags:
- symbol
- noise
- symbols
- impulsive
- masked
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Masked Symbol Modeling (MSM), a self-supervised
  framework that applies BERT-style training to oversampled complex baseband signals.
  MSM treats inter-symbol contribution from pulse shaping as contextual information:
  it masks a random subset of symbols and trains a Transformer to predict their identifiers
  from surrounding samples.'
---

# Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels

## Quick Facts
- arXiv ID: 2512.01428
- Source URL: https://arxiv.org/abs/2512.01428
- Reference count: 26
- Primary result: BERT-style masked symbol prediction framework for robust demodulation under impulsive noise using waveform context

## Executive Summary
This paper introduces Masked Symbol Modeling (MSM), a self-supervised framework that applies BERT-style training to oversampled complex baseband signals. MSM treats inter-symbol contribution from pulse shaping as contextual information: it masks a random subset of symbols and trains a Transformer to predict their identifiers from surrounding samples. The method is demonstrated on symbol recovery under Middleton Class-A impulsive noise, where the model infers corrupted symbols using learned waveform context. For non-impaired signals, the model achieves high symbol error rates across diverse modulations (BPSK, QPSK, PSK8/16, QAM4/16/64/256). Under impulsive noise, it successfully recovers masked symbols with performance remaining stable across SNR ranges, as the masking isolates impulsive interference.

## Method Summary
MSM adapts BERT-style self-supervised learning to communication signals by masking random symbols in oversampled baseband waveforms and training a Transformer to predict the masked symbols from their temporal context. The framework leverages pulse shaping-induced inter-symbol structure as contextual features, allowing the model to infer masked symbol identities from surrounding samples. Training uses synthetic Middleton Class-A impulsive noise models, with evaluation across multiple modulation schemes and SNR conditions. The approach positions the Transformer as a context-aware demodulator that can recover symbols corrupted by impulsive interference.

## Key Results
- Transformer successfully predicts masked symbols across BPSK, QPSK, PSK8/16, QAM4/16/64/256 modulations with high accuracy
- Performance remains stable across SNR ranges under Middleton Class-A impulsive noise when symbols are masked
- Model leverages inter-symbol pulse shaping structure as contextual information for symbol identification

## Why This Works (Mechanism)
MSM works by treating the inter-symbol contributions from pulse shaping as contextual features that carry information about symbol identity. When symbols are masked, the surrounding waveform structure provides sufficient information for the Transformer to infer the missing symbols. Under impulsive noise, masking the corrupted symbols effectively isolates the interference, allowing the model to recover the clean symbols using the learned waveform context. This approach transforms demodulation from a simple detection problem into a context-aware inference task.

## Foundational Learning
- Oversampling: Why needed - provides multiple samples per symbol for temporal context; Quick check - verify sampling rate is sufficient for pulse shaping capture
- Pulse shaping: Why needed - creates inter-symbol structure that serves as contextual features; Quick check - confirm pulse shape length relative to symbol duration
- Middleton Class-A noise: Why needed - models real-world impulsive interference; Quick check - validate noise parameters match target environment
- BERT-style masking: Why needed - creates self-supervised learning signal from unlabeled data; Quick check - ensure masking rate preserves enough context for recovery
- Transformer architecture: Why needed - captures long-range temporal dependencies in waveform context; Quick check - verify attention mechanism effectively uses context

## Architecture Onboarding
Component map: Baseband signal -> Oversampler -> Symbol Masking -> Transformer Encoder -> Masked Symbol Prediction
Critical path: Signal preprocessing → Masking → Context encoding → Symbol recovery
Design tradeoffs: Masking rate vs. context sufficiency, Transformer depth vs. computational complexity
Failure signatures: High error rates when masking removes too much context, degraded performance with inadequate oversampling
First experiments:
1. Test symbol recovery with no masking on clean signals
2. Evaluate performance with varying masking rates (10%, 25%, 50%)
3. Compare against classical sequence detector on impulsive noise channels

## Open Questions the Paper Calls Out
None

## Limitations
- Performance evaluation limited to synthetic simulations without real-world hardware validation
- Computational overhead and latency trade-offs relative to classical receivers not characterized
- Assumes prior synchronization and timing recovery which may not hold in practical deployment

## Confidence
- Context-aware symbol recovery in controlled synthetic conditions: High
- Robustness to real impulsive noise environments: Medium
- Generalization to unseen modulation schemes: Medium

## Next Checks
1. Test MSM on recorded over-the-air signals from impulsive noise environments (e.g., automotive ignition systems, industrial switching) to assess real-world robustness.
2. Benchmark end-to-end latency and computational complexity against classical sequence detectors under equivalent conditions.
3. Evaluate cross-modulation generalization by training on one modulation family and testing on unseen schemes with different pulse shaping filters.