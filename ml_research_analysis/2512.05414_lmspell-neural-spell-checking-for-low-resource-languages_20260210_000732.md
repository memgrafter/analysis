---
ver: rpa2
title: 'LMSpell: Neural Spell Checking for Low-Resource Languages'
arxiv_id: '2512.05414'
source_url: https://arxiv.org/abs/2512.05414
tags:
- correction
- spell
- language
- pages
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "LMSpell presents the first comprehensive empirical study on PLMs\
  \ for spell correction across multiple languages, including low-resource languages.\
  \ The toolkit supports all three PLM architectures\u2014encoder-only, decoder-only,\
  \ and encoder-decoder\u2014abstracting model-specific implementation details."
---

# LMSpell: Neural Spell Checking for Low-Resource Languages

## Quick Facts
- arXiv ID: 2512.05414
- Source URL: https://arxiv.org/abs/2512.05414
- Reference count: 40
- First comprehensive empirical study on PLMs for spell correction across multiple languages, including low-resource languages

## Executive Summary
LMSpell introduces a comprehensive toolkit for neural spell checking across multiple languages, including low-resource languages. The toolkit supports all three PLM architectures - encoder-only, decoder-only, and encoder-decoder - while abstracting model-specific implementation details. A key innovation is the evaluation function that compensates for LLM hallucination through proper sentence alignment. The study reveals that encoder models underperform despite multilingual pretraining, while LLMs excel for Latin script languages with large fine-tuning datasets, and mixed-language training significantly improves LLM performance for non-Latin scripts.

## Method Summary
The toolkit implements spell correction using three PLM architectures: encoder-only (XLM-R, mT5), decoder-only (Llama 3.1, Gemma 2), and encoder-decoder models. The evaluation function addresses LLM hallucination by performing proper sentence alignment between predicted and reference corrections. The study conducts experiments across seven languages with varying script types and resource levels, employing both monolingual and mixed-language training approaches. Fine-tuning is performed with varying dataset sizes to assess model performance across different resource scenarios.

## Key Results
- Encoder models (XLM-R, mT5) consistently underperform despite multilingual pretraining across all tested languages
- LLMs (Llama 3.1, Gemma 2) demonstrate superior performance, particularly for Latin script languages with large fine-tuning datasets
- Mixed-language training significantly improves LLM performance for non-Latin script languages
- Sinhala case study shows LLM robustness across domains and improved downstream task performance with spell correction

## Why This Works (Mechanism)
The success of LLMs stems from their generative capabilities and contextual understanding, which enable better handling of spelling variations and error patterns. The evaluation function's sentence alignment mechanism effectively addresses the hallucination problem inherent in LLMs by ensuring proper comparison between predicted and reference corrections. Mixed-language training appears to enhance LLMs' ability to generalize across script types by exposing them to diverse linguistic patterns during fine-tuning.

## Foundational Learning

**Pretrained Language Models (PLMs)**
- Why needed: Form the foundation for spell correction through learned linguistic patterns
- Quick check: Verify model architecture matches intended task requirements

**Sentence Alignment for Evaluation**
- Why needed: Enables accurate comparison when LLM outputs don't perfectly match references
- Quick check: Test alignment function with various error patterns and corrections

**Mixed-language Training**
- Why needed: Improves performance on non-Latin scripts by exposing models to diverse patterns
- Quick check: Compare performance with monolingual vs mixed-language training on target scripts

## Architecture Onboarding

**Component Map**
Data Preprocessing -> Model Training (Encoder/Decoder/Encoder-Decoder) -> Spell Correction Prediction -> Sentence Alignment Evaluation -> Performance Metrics

**Critical Path**
Input text -> Error detection -> Candidate generation -> Contextual correction -> Sentence alignment -> Evaluation

**Design Tradeoffs**
- Encoder models: Faster inference but limited generation capabilities
- Decoder models: Better generation but higher computational cost
- Mixed-language training: Improved script generalization but potential cross-lingual interference

**Failure Signatures**
- Encoder models: Inability to generate corrections, relying only on masked token prediction
- LLMs: Hallucination of non-existent words or excessive corrections
- Mixed-language training: Loss of language-specific nuances

**3 First Experiments**
1. Compare encoder vs decoder performance on a small validation set
2. Test sentence alignment function with artificially corrupted text
3. Evaluate mixed-language training impact on non-Latin script performance

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness of hallucination compensation mechanism across diverse linguistic structures remains untested
- Generalizability to other low-resource languages with different typological features is uncertain
- Documentation and reproducibility across different hardware configurations are not discussed

## Confidence

**Encoder models underperform despite multilingual pretraining** (Medium): Consistent pattern across seven languages, but fine-tuning strategies not fully explored

**LLMs excel for Latin script languages with large fine-tuning datasets** (High): Robust experimental results with multiple evaluation metrics

**Mixed-language training significantly improves LLM performance for non-Latin scripts** (Medium): Positive results but limited sample size of non-Latin languages tested

## Next Checks

1. Reproduce encoder model results with alternative fine-tuning strategies to determine if underperformance is architecture-specific

2. Test mixed-language training approach on additional non-Latin script families (Arabic, Hebrew, Thai) to assess generalizability

3. Evaluate hallucination compensation mechanism on broader range of linguistic structures and error types