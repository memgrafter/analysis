---
ver: rpa2
title: Adversarially Probing Cross-Family Sound Symbolism in 27 Languages
arxiv_id: '2512.12245'
source_url: https://arxiv.org/abs/2512.12245
tags:
- accuracy
- language
- size
- languages
- epoch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates cross-linguistic sound symbolism for size
  using 810 adjectives from 27 typologically diverse languages. A novel adversarial
  scrubber suppresses language-family signals while preserving size-related phonetic
  patterns, achieving 54.4% size classification accuracy while reducing language prediction
  to chance (34%).
---

# Adversarially Probing Cross-Family Sound Symbolism in 27 Languages

## Quick Facts
- arXiv ID: 2512.12245
- Source URL: https://arxiv.org/abs/2512.12245
- Reference count: 40
- Primary result: Adversarial scrubbing isolates cross-family size sound symbolism, achieving 54.4% size classification while suppressing language identity to chance (34%)

## Executive Summary
This study investigates whether size sound symbolism patterns generalize across language families by training an adversarial neural network that suppresses genealogical signals while preserving size-related phonetic patterns. Using 810 size adjectives from 27 typologically diverse languages, the model identifies vowels (/a/, /i/, /o/) and consonants (/Q/, /H/) as key predictors of size across families. The adversarial approach successfully isolates universal patterns from genealogical relatedness, suggesting acoustic properties beyond vowel height underlie cross-linguistic size symbolism.

## Method Summary
The research employs a leave-one-language-out framework with 27 typologically diverse languages, each contributing 30 size adjectives (15 small, 15 large). Languages are grouped into similarity bins using normalized Levenshtein distances from genealogical data. The adversarial model combines a frozen BERT encoder pretrained on WikiPron IPA sequences with a linear projection layer, size classifier, and bin adversary connected via gradient reversal. The model is trained to maximize size classification while minimizing language-bin prediction, with epoch selection based on maximizing the size-bin accuracy difference while keeping bin accuracy at chance.

## Key Results
- Adversarial model achieves 54.4% size classification accuracy while suppressing language prediction to chance (34%)
- Vowels /a/ and /o/ show strongest association with largeness; /i/ with smallness across all similarity bins
- Decision trees maintain significant above-chance performance (Cohen's d = 1.23, 0.78, 0.65) even in the least-similar language bin
- Voiced fricatives like /Q/ and /H/ contribute to size prediction across language families

## Why This Works (Mechanism)

### Mechanism 1: Phoneme-Level Acoustic Size Mapping
- Claim: Specific phonological segments carry systematic size associations that generalize across language families.
- Mechanism: Back/low vowels (e.g., /a/, /o/) correlate with "largeness" through lower formant frequencies and larger sub-oral cavities, while front vowels (e.g., /i/) correlate with "smallness" via higher formants. Voiced fricatives contribute low-frequency energy associated with largeness.
- Core assumption: Assumption: Perceptual grounding in acoustic properties explains cross-linguistic patterns rather than shared ancestry alone.
- Evidence anchors:
  - [abstract] "vowels like /a/ and /i/ and consonants such as /Q/ and /H/ as key predictors"
  - [Section 4.2] "/o/ showed the strongest association with largeness (100% positive, mean = +0.67), while /i/ showed the strongest association with smallness (99% negative, mean = -0.44)"
  - [corpus] Related work (Loakman et al., 2024) confirms MLLMs can recover sound symbolism patterns, suggesting acoustic grounding is detectable computationally.
- Break condition: If phoneme-to-size mappings reverse direction across unrelated languages, or if performance drops to chance when training only on typologically distant languages, the mechanism may be genealogy-driven rather than perceptually grounded.

### Mechanism 2: Adversarial Gradient Reversal for Language-Agnostic Representations
- Claim: A gradient reversal layer (GRL) can suppress genealogical identity while preserving size-predictive structure.
- Mechanism: The encoder receives reversed gradients from the language-bin adversary (multiplied by −λ), learning representations that minimize bin predictability while maximizing size classification. During forward pass, both heads receive identical representations; during backprop, the encoder moves away from language-discriminative features.
- Core assumption: Assumption: Size-relevant phonetic features are at least partially orthogonal to language-identity features in the learned representation space.
- Evidence anchors:
  - [abstract] "adversarial scrubber that suppresses language identity while preserving size signal"
  - [Section 4.3] "The adversarial model achieved test size accuracy of 54.4% and train bin accuracy of 34.0% (at chance)"
  - [corpus] No direct corpus evidence for adversarial scrubbing in sound symbolism; this appears novel.
- Break condition: If size accuracy degrades significantly (approaching 50%) when bin accuracy is suppressed, the size signal may be inseparable from language identity, indicating genealogical confounding.

### Mechanism 3: Similarity-Binned Cross-Family Generalization
- Claim: Phoneme-level size classifiers trained on genealogically distant languages can predict size in held-out languages above chance.
- Mechanism: Languages are partitioned into similarity tertiles (most/somewhat/least similar) using normalized Levenshtein distances (LDN/LDND). Classifiers trained within each bin are evaluated on held-out targets, with above-chance performance in the least-similar bin indicating cross-family signal.
- Core assumption: Assumption: LDN/LDND distances adequately capture genealogical relatedness for partitioning purposes.
- Evidence anchors:
  - [Section 4.1] "Decision Trees performed significantly above chance across all three similarity bins (p < 0.01)... Cohen's d = 1.23, 0.78, 0.65"
  - [Table 1] Logistic regression: 59.2%, 57.0%, 52.2% (Most → Least similar); Decision tree: 60.2%, 56.4%, 55.8%
  - [corpus] Related work (Blasi et al., 2016) found small but consistent form-meaning biases across families using stratification, supporting cross-family signal existence.
- Break condition: If performance in the "least similar" bin drops to chance or below, genealogical confounding dominates; cross-family sound symbolism would not be supported.

## Foundational Learning

- Concept: **Gradient Reversal Layer (GRL)**
  - Why needed here: Central to the adversarial scrubbing mechanism that isolates size signal from language identity.
  - Quick check question: During backpropagation, does a GRL (a) zero out gradients, (b) reverse gradient sign, or (c) amplify gradients? (Answer: b)

- Concept: **Phonemic vs. Phonetic Transcription**
  - Why needed here: The paper uses phonemic (contrastive) rather than phonetic (surface) representations to capture language-universal patterns while reducing dialectal noise.
  - Quick check question: Would /p/ and /pʰ/ (aspirated) be distinct in a phonemic transcription of English? (Answer: No—they're allophones of the same phoneme)

- Concept: **Leave-One-Language-Out (LOLO) Evaluation**
  - Why needed here: Ensures the model generalizes to unseen languages rather than memorizing training language patterns.
  - Quick check question: In LOLO with 27 languages, how many training runs are required? (Answer: 27—one per held-out target)

## Architecture Onboarding

- Component map:
  - WikiPron IPA sequences -> BERT encoder (2 layers, 128 hidden) -> Projection layer (128→64, dropout=0.1) -> Size classifier (2-layer FFN) and Bin adversary (2-layer FFN via GRL)

- Critical path:
  1. Pretrain BERT on WikiPron IPA (freeze before adversarial training).
  2. For each target language, assign training languages to similarity bins via LDN/LDND.
  3. Train projection + both heads with λ ramped 0→1 over 20 epochs.
  4. Select epoch where (train_size_acc − train_bin_acc) is maximized with bin_acc ≤ chance.
  5. Evaluate test_size_acc on held-out language.

- Design tradeoffs:
  - **Phonemic over phonetic**: Reduces dialectal noise but may miss acoustic symbolism cues.
  - **Suprasegmentals excluded**: Avoids language-specific encoding issues but discards potential prosodic symbolism.
  - **Bag-of-segments representation**: Ignores phonotactics/sequence order but simplifies cross-linguistic comparison.
  - **Small dataset (810 words)**: Enables audio validation but limits statistical power for fine-grained analyses.

- Failure signatures:
  - Bin accuracy stays high (>50%) during adversarial training → GRL not suppressing language identity.
  - Size accuracy drops to chance (<52%) → size signal inseparable from genealogy.
  - High variance across LOLO runs → model overfitting to specific language subsets.
  - Per-language results unstable across 5 runs → insufficient signal or hyperparameter sensitivity.

- First 3 experiments:
  1. **Reproduce baseline LOLO results**: Train logistic regression and decision tree on the 810-word dataset with 27-fold LOLO; verify mean accuracies match reported values (~59% most similar, ~52% least similar).
  2. **Ablate vowel features**: Remove all vowel phonemes from input; confirm consonants alone maintain above-chance performance only in most-similar bin (reported: 58.6% LR, 55.8% DT).
  3. **Adversarial sweep on λ_max**: Vary λ_max ∈ {0.5, 1.0, 2.0} and plot test_size_acc vs. train_bin_acc; verify tradeoff curve shows size accuracy stable while bin accuracy decreases to chance near λ_max = 1.0.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do sound-symbolic patterns for size generalize beyond adjectives to other lexical categories (nouns, verbs)?
- Basis in paper: [explicit] "Future work can expand... lexical categories"
- Why unresolved: The study controlled lexical scope by using only size adjectives (30 per language), following prior work showing English size effects may not transfer across parts of speech.
- What evidence would resolve it: Replicating the adversarial framework on matched noun/verb datasets; finding consistent above-chance prediction when language identity is suppressed.

### Open Question 2
- Question: Would continuous size scales reveal stronger or different sound-symbolic patterns than binary small/large labels?
- Basis in paper: [explicit] "Future work can...move from binary labels to continuous size scales"
- Why unresolved: The study used binary classification (small vs. large), but size semantics may be gradient; binary labels may obscure finer-grained phonetic correlations.
- What evidence would resolve it: Collecting human ratings on continuous size scales for the same adjectives; testing regression models with adversarial language suppression.

### Open Question 3
- Question: Do suprasegmental features (tone, stress, intonation) carry size-symbolic information, particularly in tone languages?
- Basis in paper: [explicit] "In our analysis, suprasegmentals are only partially incorporated; some languages (e.g., tone systems) might merit full prosodic modeling"
- Why unresolved: The authors excluded suprasegmentals due to inconsistent encoding across languages and lack of expert annotators for all 27 languages.
- What evidence would resolve it: Annotating suprasegmentals for tone languages (e.g., Mandarin, Twi); including prosodic features in the adversarial model; assessing whether suppression of language identity still preserves size signal.

### Open Question 4
- Question: Does phonetic (allophonic) transcription reveal sound-symbolic patterns that phonemic transcription misses?
- Basis in paper: [explicit] "We relied on phonemic rather than phonetic transcriptions; although phonemic representations offer greater cross-speaker consistency, they may miss subtle sound-symbolic cues present in actual pronunciation"
- Why unresolved: Phonetic variation within phoneme categories (e.g., precise formant values) may encode additional symbolic information that abstracted phonemes obscure.
- What evidence would resolve it: Collecting narrow phonetic transcriptions from native speakers; comparing model performance on phonetic vs. phonemic representations.

## Limitations

- Genealogical distance calibration relies on Levenshtein-based metrics that may not accurately represent linguistic ancestry, particularly given limited vocabulary overlap (30 adjectives per language)
- Phonemic representation may discard crucial acoustic information for size symbolism that would be captured in phonetic transcriptions
- Small sample size (810 words total) limits statistical power for fine-grained phonological analyses and may produce unstable per-language results

## Confidence

- **High Confidence**: The adversarial framework successfully suppresses language-family signals while preserving size-related phonetic patterns (verified through above-chance size accuracy with chance-level bin accuracy)
- **Medium Confidence**: The identification of specific phonemes (/a/, /i/, /o/, /Q/, /H/) as size predictors across families is statistically significant but requires further validation through acoustic analysis
- **Low Confidence**: The claim that cross-family sound symbolism extends beyond vowel height to include consonants is suggestive but underdetermined given the small sample size

## Next Checks

1. **Acoustic Validation**: Analyze the actual acoustic properties (formant frequencies, voice onset time, spectral characteristics) of the identified key phonemes across languages to verify whether their physical properties align with proposed size associations, rather than relying solely on phonemic transcriptions.

2. **Cross-Linguistic Replication**: Test the adversarial model on a held-out set of languages from different families not represented in the original 27-language sample to assess generalizability of the cross-family patterns beyond the studied genealogical sample.

3. **Genealogical Distance Sensitivity**: Vary the threshold parameters for binning languages by similarity (beyond the three-tertile approach) and assess how sensitive the size prediction results are to different calibrations of genealogical distance, testing the robustness of the adversarial scrubbing mechanism across different relatedness partitions.