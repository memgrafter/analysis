---
ver: rpa2
title: Human vs. AI Safety Perception? Decoding Human Safety Perception with Eye-Tracking
  Systems, Street View Images, and Explainable AI
arxiv_id: '2509.25457'
source_url: https://arxiv.org/abs/2509.25457
tags:
- human
- safety
- images
- perceptions
- urban
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the limitations of prior safety perception
  research that relied solely on street view images and computer vision techniques,
  which often overlooked the specific visual environmental factors that draw human
  attention. To bridge this gap, the authors propose a computational framework integrating
  eye-tracking systems, street view images, and eXplainable AI (XAI).
---

# Human vs. AI Safety Perception? Decoding Human Safety Perception with Eye-Tracking Systems, Street View Images, and Explainable AI

## Quick Facts
- arXiv ID: 2509.25457
- Source URL: https://arxiv.org/abs/2509.25457
- Authors: Yuhao Kang; Junda Chen; Liu Liu; Kshitij Sharmad; Martina Mazzarello; Simone Mora; Fabio Duarte; Carlo Ratti
- Reference count: 22
- Primary result: Eye-tracking systems reveal that human safety perception focuses on urban infrastructure and public space features, while open elements like sky are less relevant; XGradCAM and EigenCAM XAI models best align with human attention patterns

## Executive Summary
This study addresses the gap in safety perception research by integrating eye-tracking systems with street view images and eXplainable AI (XAI) to understand how humans visually process urban environments for safety assessment. The researchers collected eye-tracking data from participants viewing street scenes of Helsingborg, Sweden, and compared human attention patterns with those generated by XAI models. The framework identifies specific urban features that attract human attention when perceiving safe environments and validates which XAI explanation methods most closely align with human perceptual patterns, offering a new tool for urban planning and design.

## Method Summary
The study employed a mixed-method approach combining eye-tracking technology with street view imagery and XAI analysis. Participants' gaze patterns were recorded while viewing street view images of Helsingborg, Sweden, using eye-tracking systems to capture visual attention. The collected eye-tracking data was then compared with attention heatmaps generated by various XAI models, including XGradCAM and EigenCAM. The researchers identified urban infrastructure and public space features that consistently attracted human attention during safety perception tasks, while also evaluating which XAI methods best replicated human attention patterns for potential use in urban planning applications.

## Key Results
- Urban infrastructure and public space features are the primary visual elements that attract human attention for safety perception
- Open elements like sky and open spaces are less relevant to human safety perception compared to built environment features
- XGradCAM and EigenCAM XAI models most closely align with human safety perceptual patterns, validating their reliability for urban planning applications

## Why This Works (Mechanism)
The framework works by capturing real-time human visual attention through eye-tracking while viewing urban scenes, providing direct insight into what features people focus on when assessing safety. By comparing these human attention patterns with XAI-generated heatmaps, the study identifies which explanation methods best replicate human perception. This approach bridges the gap between subjective human experience and objective computational analysis, allowing for validation of AI models against actual human behavior rather than just performance metrics.

## Foundational Learning
- **Eye-tracking technology**: Captures precise gaze patterns and fixations, needed to understand where humans direct attention when assessing safety; quick check: calibration accuracy and participant comfort
- **Street view imagery**: Provides standardized urban scene representations, needed for consistent comparison across participants and with XAI models; quick check: image quality and representativeness of urban contexts
- **eXplainable AI (XAI)**: Generates interpretable attention heatmaps from AI models, needed to compare with human attention patterns; quick check: explanation method reliability across different model architectures
- **Attention heatmaps**: Visual representations of feature importance, needed to identify which urban elements attract human and AI attention; quick check: heatmap resolution and alignment with actual visual features
- **Urban infrastructure analysis**: Categorization of built environment features, needed to identify specific elements that influence safety perception; quick check: comprehensive feature taxonomy
- **Cross-validation between human and AI attention**: Comparison methodology, needed to validate which XAI methods best replicate human perception; quick check: statistical significance of alignment between human and AI attention patterns

## Architecture Onboarding
- **Component map**: Eye-tracking system -> Street view image presentation -> Gaze data collection -> XAI model application -> Attention heatmap generation -> Human-AI attention comparison
- **Critical path**: Participant eye-tracking data collection is the critical path, as it provides the ground truth for comparing with AI-generated attention patterns
- **Design tradeoffs**: The study prioritizes ecological validity (using real street view images) over controlled laboratory conditions, trading experimental control for more realistic safety perception scenarios
- **Failure signatures**: Poor eye-tracking calibration would result in noisy gaze data; insufficient image diversity would limit generalizability; XAI model misalignment would indicate limitations in the explanation methods rather than the framework itself
- **First experiments**:
  1. Validate eye-tracking calibration by comparing gaze patterns across multiple trials with the same images
  2. Test XAI model alignment by comparing attention heatmaps on known reference images with established feature importance
  3. Conduct pilot studies with a small participant group to refine image selection and experimental protocol

## Open Questions the Paper Calls Out
None

## Limitations
- Geographic and demographic scope limited to Helsingborg, Sweden with 72 participants, raising questions about generalizability to other urban contexts and cultural settings
- Eye-tracking methodology captures only visual attention patterns without accounting for other sensory inputs or contextual factors that may influence safety perceptions
- Comparison between human attention and XAI-generated heatmaps does not establish causal relationships between specific visual features and actual safety outcomes

## Confidence
- **High confidence** in the technical implementation of the eye-tracking and XAI integration methodology
- **Medium confidence** in the identification of urban features that attract human attention for safety perception
- **Medium confidence** in the comparison between human attention patterns and XAI model outputs
- **Low confidence** in the generalizability of findings across different urban contexts and populations

## Next Checks
1. Replicate the study in multiple cities across different countries and cultural contexts to test the robustness of identified safety perception patterns
2. Conduct longitudinal studies to examine how safety perception patterns change over time and with familiarity
3. Integrate additional data sources (e.g., crime statistics, pedestrian counts) to validate the relationship between attention patterns and actual safety outcomes