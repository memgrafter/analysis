---
ver: rpa2
title: Probing a Vision-Language-Action Model for Symbolic States and Integration
  into a Cognitive Architecture
arxiv_id: '2502.04558'
source_url: https://arxiv.org/abs/2502.04558
tags:
- object
- states
- action
- bowl
- openvla
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of integrating vision-language-action
  (VLA) models with cognitive architectures (CA) to combine the generalist capabilities
  of VLAs with the interpretability and symbolic reasoning of CAs. The authors propose
  probing OpenVLA's hidden layers to extract symbolic representations of object properties,
  relations, and action states.
---

# Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture

## Quick Facts
- arXiv ID: 2502.04558
- Source URL: https://arxiv.org/abs/2502.04558
- Authors: Hong Lu; Hengxu Li; Prithviraj Singh Shahani; Stephanie Herbers; Matthias Scheutz
- Reference count: 20
- One-line primary result: Linear probes achieve >0.90 accuracy for object and action state prediction across most OpenVLA layers

## Executive Summary
This paper addresses the challenge of integrating vision-language-action (VLA) models with cognitive architectures (CA) to combine the generalist capabilities of VLAs with the interpretability and symbolic reasoning of CAs. The authors propose probing OpenVLA's hidden layers to extract symbolic representations of object properties, relations, and action states. They train linear probes on different layers of OpenVLA to predict symbolic states during manipulation tasks, specifically using the LIBERO-spatial pick-and-place benchmark. The primary result shows consistently high accuracies (> 0.90) for both object and action state predictions across most layers of OpenVLA, though contrary to hypotheses, object states were not encoded earlier than action states. The authors successfully demonstrate an integrated DIARC-OpenVLA system that leverages these symbolic representations for real-time state monitoring, laying the foundation for more interpretable and reliable robotic manipulation.

## Method Summary
The authors train linear probes on different layers of OpenVLA to predict symbolic states during manipulation tasks using the LIBERO-spatial pick-and-place benchmark. The probes are trained to extract symbolic representations of object properties, relations, and action states from OpenVLA's hidden layers. They then integrate these symbolic representations into the DIARC cognitive architecture for real-time state monitoring during robotic manipulation tasks.

## Key Results
- Linear probes achieve consistently high accuracies (> 0.90) for both object and action state predictions across most layers of OpenVLA
- Contrary to hypotheses, object states were not encoded earlier than action states in OpenVLA's layers
- Successful demonstration of integrated DIARC-OpenVLA system using symbolic representations for real-time state monitoring

## Why This Works (Mechanism)
The probing approach leverages the rich representations learned by VLA models during training on large-scale multimodal data. By applying linear classifiers to different layers of OpenVLA, the authors can extract task-relevant symbolic information without modifying the underlying model. This allows VLA models to provide the perception and action capabilities needed for robotic manipulation while maintaining compatibility with cognitive architectures that rely on symbolic representations for reasoning and planning.

## Foundational Learning
- **VLA models** (why needed: provide generalist capabilities for perception and action; quick check: understand transformer architecture and multimodal pretraining)
- **Cognitive architectures** (why needed: enable symbolic reasoning and interpretability; quick check: understand how CAs represent and reason about states)
- **Linear probing** (why needed: extract symbolic representations from neural representations; quick check: understand how linear classifiers can reveal information content)
- **Symbolic state representations** (why needed: enable reasoning and planning in cognitive architectures; quick check: understand object properties, relations, and action states)
- **DIARC architecture** (why needed: provides framework for integrating symbolic and subsymbolic components; quick check: understand DIARC's modules and integration mechanisms)

## Architecture Onboarding

**Component Map:**
OpenVLA (perception/action) -> Linear probes (symbolic extraction) -> DIARC modules (reasoning/planning) -> Robot control

**Critical Path:**
Perception input -> OpenVLA processing -> Probe extraction -> Symbolic state update -> DIARC reasoning -> Action output

**Design Tradeoffs:**
- Linear vs. non-linear probes (simplicity vs. expressiveness)
- Layer selection for probing (early vs. late representations)
- Real-time performance vs. accuracy of symbolic extraction

**Failure Signatures:**
- Low probe accuracy indicates insufficient information in layer representations
- DIARC reasoning failures suggest mismatch between extracted symbols and expected format
- Integration bottlenecks may occur at the symbolic-subsymbolic interface

**First Experiments:**
1. Verify probe accuracy on held-out test data from LIBERO-spatial benchmark
2. Test real-time performance of symbolic state extraction during task execution
3. Validate DIARC's ability to reason with extracted symbolic states in simple scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Probing methodology relies on linear models which may underestimate VLA capabilities
- LIBERO-spatial benchmark has limited object diversity and manipulation scenarios
- DIARC integration remains at proof-of-concept level without extensive validation
- Unexpected finding that object states were not encoded earlier than action states

## Confidence
- High confidence: Technical implementation of linear probes on OpenVLA layers is sound
- Medium confidence: DIARC integration represents valid proof-of-concept but scalability unproven
- Medium confidence: Characterization of information encoding may be limited by probing approach

## Next Checks
1. Test probing approach on additional benchmarks with greater object diversity and manipulation complexity
2. Implement non-linear probing methods to determine if linear separability represents lower bound on information
3. Conduct extensive end-to-end testing of DIARC-OpenVLA integrated system across multiple manipulation tasks