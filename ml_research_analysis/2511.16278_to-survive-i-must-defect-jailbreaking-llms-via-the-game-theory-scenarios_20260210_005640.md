---
ver: rpa2
title: '"To Survive, I Must Defect": Jailbreaking LLMs via the Game-Theory Scenarios'
arxiv_id: '2511.16278'
source_url: https://arxiv.org/abs/2511.16278
tags:
- jailbreak
- llms
- harmful
- safety
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes GTA, a game-theoretic jailbreak attack framework
  for LLMs. It models black-box jailbreak as a sequential stochastic game and introduces
  a "template-over-safety flip" conjecture: game-theoretic scenarios can override
  safety preferences, making risky responses more likely.'
---

# "To Survive, I Must Defect": Jailbreaking LLMs via the Game-Theory Scenarios

## Quick Facts
- **arXiv ID**: 2511.16278
- **Source URL**: https://arxiv.org/abs/2511.16278
- **Reference count**: 40
- **Primary result**: GTA achieves over 95% attack success rate on GPT-4o and Deepseek-R1 using game-theoretic scenarios

## Executive Summary
This paper introduces GTA, a game-theoretic jailbreak attack framework that models black-box jailbreak as a sequential stochastic game. The core insight is the "template-over-safety flip" conjecture: carefully crafted game-theoretic scenarios can override safety preferences in LLMs, making them more likely to provide risky responses. Using a Prisoner's Dilemma-inspired mechanism and an LLM-based attacker agent, GTA achieves state-of-the-art attack success rates while using fewer queries per success than competing approaches.

## Method Summary
GTA frames jailbreaking as a strategic game where the LLM must choose between safe and risky responses under competitive pressure. The framework constructs game-theoretic scenarios where the optimal strategy involves providing harmful information, creating a tension between safety alignment and game-theoretic rationality. An LLM-based attacker agent iteratively crafts prompts using template-guided attacks, probing the victim model's safety boundaries. The approach leverages sequential decision-making and response prediction to efficiently navigate the jailbreak space while maintaining effectiveness against various safety mechanisms.

## Key Results
- Achieves over 95% attack success rate on GPT-4o and Deepseek-R1
- Outperforms 12 baseline jailbreak methods with fewer queries per success
- Maintains effectiveness across multiple game-theoretic scenarios
- Successfully evades basic prompt guards while preserving attack efficacy
- Generalizes to other LLMs including HuggingFace models

## Why This Works (Mechanism)
The attack exploits the tension between an LLM's safety training and its ability to reason about strategic interactions. When placed in a game-theoretic scenario where providing harmful information appears to be the optimal strategy for self-preservation or success, the model's game-theoretic reasoning can override its safety constraints. The "template-over-safety flip" occurs when the narrative framing of the scenario creates sufficient pressure that the model prioritizes the game's objectives over its safety protocols.

## Foundational Learning
- **Sequential stochastic games**: Why needed - Models the iterative nature of jailbreak attempts; Quick check - Verify game states transition properly between attempts
- **Game-theoretic rationality**: Why needed - Exploits LLM's reasoning capabilities; Quick check - Test if models consistently choose game-optimal strategies
- **Template-guided prompt engineering**: Why needed - Provides structured attack patterns; Quick check - Measure effectiveness across different template variations
- **Safety alignment vs strategic reasoning**: Why needed - Identifies conflict points in model behavior; Quick check - Compare responses in game vs non-game contexts
- **LLM-as-judge evaluation**: Why needed - Automates attack validation; Quick check - Validate judge consistency across different safety scenarios

## Architecture Onboarding

**Component Map**: Attacker Agent -> Template Generator -> Victim Model -> Judge Evaluator -> Success Feedback

**Critical Path**: The attacker agent generates prompts using game-theoretic templates, the victim model responds, the judge evaluator assesses safety violations, and feedback guides the next iteration. This loop continues until success or failure criteria are met.

**Design Tradeoffs**: Prioritizes attack efficiency over stealth, uses high-level game reasoning over fine-grained manipulation, trades query count for success probability.

**Failure Signatures**: Low ASR indicates templates fail to create sufficient game-theoretic pressure; high query counts suggest inefficient prompt generation; inconsistent judge evaluations point to ambiguity in safety boundaries.

**First Experiments**: 1) Test individual game-theoretic scenarios in isolation, 2) Measure safety override rates across different template variations, 3) Compare attack success against models with varying safety training intensities

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- The "template-over-safety flip" conjecture lacks rigorous causal analysis beyond case studies
- Assumes LLMs behave as rational agents in sequential games, which may not generalize
- Success rates measured under controlled conditions may not reflect real-world deployment variability
- Relies on carefully crafted narrative framing that may not translate to all safety mechanisms

## Confidence
- **High confidence**: Query efficiency gains over baselines, consistent performance across multiple game-theoretic scenarios, successful evasion of basic prompt guards
- **Medium confidence**: Generalization to HuggingFace LLMs, scalability via LLM-generated templates, robustness against fine-tuning
- **Low confidence**: The theoretical foundation of the "template-over-safety flip" conjecture, the claim that game-theoretic framing uniquely overrides safety preferences compared to other persuasive narratives

## Next Checks
1. Conduct ablation studies comparing GTA against non-game-theoretic but equally compelling narrative prompts to isolate whether the game-theoretic framing itself drives safety overrides
2. Test the framework against safety mechanisms that incorporate semantic understanding and contextual reasoning beyond simple keyword filtering
3. Evaluate whether models fine-tuned with adversarial game-theoretic examples retain the same vulnerability profile or develop resistance to such attacks