---
ver: rpa2
title: Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace
arxiv_id: '2508.05661'
source_url: https://arxiv.org/abs/2508.05661
tags:
- search
- image
- visual
- retrieval
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a scalable visual search system for Mercari\u2019\
  s consumer-to-consumer marketplace using zero-shot vision-language models. The system\
  \ employs multilingual SigLIP embeddings and dimensionality reduction (768D \u2192\
  \ 128D) to balance retrieval effectiveness and efficiency."
---

# Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace

## Quick Facts
- arXiv ID: 2508.05661
- Source URL: https://arxiv.org/abs/2508.05661
- Authors: Andre Rusli, Shoma Ishimoto, Sho Akiyama, Aman Kumar Singh
- Reference count: 10
- Key result: 13.3% nDCG@5 improvement over fine-tuned baseline; 40.9% transaction/user increase in A/B test

## Executive Summary
This paper presents a scalable visual search system for Mercari's consumer-to-consumer marketplace using zero-shot vision-language models. The system employs multilingual SigLIP embeddings with dimensionality reduction (768D → 128D) to balance retrieval effectiveness and efficiency. Offline evaluation on 10,000 search sessions showed a 13.3% improvement in nDCG@5 over a fine-tuned baseline. A one-week A/B test demonstrated significant gains: 40.9% increase in transactions per user, 34.1% higher conversion rate, and 46.6% more item views via image search.

## Method Summary
The system uses multilingual SigLIP embeddings as a zero-shot approach for visual search, eliminating the need for expensive fine-tuning on Mercari's product catalog. To improve computational efficiency, embeddings are reduced from 768 dimensions to 128 dimensions using dimensionality reduction techniques. This enables faster similarity calculations while maintaining retrieval quality. The zero-shot approach allows the system to handle Mercari's diverse, multilingual product inventory without requiring extensive retraining when catalog characteristics change.

## Key Results
- 13.3% improvement in nDCG@5 over fine-tuned baseline in offline evaluation
- 40.9% increase in transactions per user in one-week A/B test
- 34.1% higher conversion rate and 46.6% more item views via image search

## Why This Works (Mechanism)
The system leverages zero-shot vision-language models (SigLIP) that can generalize across diverse product categories without task-specific training. By using multilingual embeddings, it handles Mercari's international marketplace naturally. The dimensionality reduction from 768D to 128D maintains sufficient semantic information for effective retrieval while dramatically improving computational efficiency, enabling real-time search at scale.

## Foundational Learning
- **Zero-shot learning**: Why needed - eliminates costly fine-tuning for each new product category or language; Quick check - model performs well on unseen categories without additional training
- **Vision-language embeddings**: Why needed - captures semantic relationships between visual appearance and product descriptions; Quick check - similar items cluster together in embedding space
- **Dimensionality reduction**: Why needed - reduces computational cost while preserving retrieval quality; Quick check - maintains nDCG metrics after reduction
- **nDCG@5 metric**: Why needed - measures ranking quality for top-5 results, critical for user experience; Quick check - higher scores indicate better top results
- **A/B testing**: Why needed - validates real-world impact on business metrics; Quick check - statistically significant improvements in transactions and conversion

## Architecture Onboarding

Component map: User Query -> Image Embedding (SigLIP) -> Dimensionality Reduction (768D→128D) -> Vector Index -> Ranked Results

Critical path: Image upload → embedding generation → dimensionality reduction → vector similarity search → result ranking → display

Design tradeoffs: Zero-shot vs. fine-tuned models (generalization vs. domain specificity); 768D vs. 128D embeddings (accuracy vs. efficiency); multilingual support vs. potential dilution of language-specific nuances

Failure signatures: Poor retrieval quality for entertainment/character goods; longer response times with full 768D embeddings; reduced effectiveness for exact identity matching requirements

First experiments:
1. Validate nDCG@5 metrics across different product categories to identify performance gaps
2. Test response latency with 768D vs. 128D embeddings under production load
3. Measure embedding quality preservation after dimensionality reduction using nearest neighbor accuracy

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Reduced effectiveness for entertainment and character goods categories requiring exact identity matching
- Dimensionality reduction (768D → 128D) may introduce approximation errors affecting retrieval quality
- Lack of category-level performance breakdown and detailed infrastructure cost analysis

## Confidence

**High confidence**: A/B test results showing transaction per user (40.9% lift), conversion rate (34.1% lift), and item views (46.6% lift) through image search are well-documented and directly measured.

**Medium confidence**: Offline nDCG@5 improvement of 13.3% over fine-tuned baseline is credible but evaluated on only 10,000 sessions. SigLIP embeddings' effectiveness for Mercari's domain-specific needs is demonstrated but could benefit from broader testing.

**Medium confidence**: The claim that the system is "low-overhead" is supported by zero-shot models but lacks detailed infrastructure cost analysis or comparison to alternative approaches.

## Next Checks

1. Conduct category-level A/B testing to quantify performance differences between general merchandise and entertainment/character goods, particularly for exact identity matching requirements.

2. Perform ablation studies on the dimensionality reduction step (768D → 128D) to identify whether specific product attributes or item types experience disproportionate quality degradation.

3. Measure and compare computational overhead, serving latency, and infrastructure costs against both the previous fine-tuned system and alternative embedding approaches to validate the "low-overhead" characterization.