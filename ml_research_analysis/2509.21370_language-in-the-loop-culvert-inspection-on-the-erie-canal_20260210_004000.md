---
ver: rpa2
title: Language-in-the-Loop Culvert Inspection on the Erie Canal
arxiv_id: '2509.21370'
source_url: https://arxiv.org/abs/2509.21370
tags:
- inspection
- culvert
- vision
- canal
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents VISION, an autonomous culvert inspection system
  that uses a vision-language model (VLM) for defect detection without requiring domain-specific
  fine-tuning. VISION captures a query image, prompts the VLM to propose regions of
  interest (ROIs), fuses stereo depth to estimate scale, and plans constrained viewpoints
  for targeted close-ups.
---

# Language-in-the-Loop Culvert Inspection on the Erie Canal

## Quick Facts
- arXiv ID: 2509.21370
- Source URL: https://arxiv.org/abs/2509.21370
- Reference count: 33
- System uses GPT-5 to detect defects in culverts without fine-tuning, achieving 61.4% SME agreement on initial proposals and 80% after re-imaging.

## Executive Summary
This work presents VISION, an autonomous culvert inspection system that leverages a vision-language model (VLM) for zero-shot defect detection without domain-specific training data. VISION captures query images, uses GPT-5 to propose regions of interest (ROIs), fuses stereo depth for 3D localization, and plans constrained viewpoints for targeted close-ups. Deployed on a legged robot in a 66 m Erie Canal culvert, VISION runs end-to-end on-board and produces high-resolution imagery for reporting. In evaluations by NYCC personnel, initial ROI proposals achieved 61.4% agreement with experts, and post-re-imaging assessments reached 80%, demonstrating that VISION converts tentative hypotheses into expert-aligned findings.

## Method Summary
VISION is an autonomous culvert inspection system deployed on a Boston Dynamics Spot robot. It uses GPT-5 via OpenAI API to perform zero-shot defect detection without fine-tuning. The pipeline captures query images from a forward-facing stereo camera, obtains ROI proposals with rationales and confidences from the VLM, fuses stereo depth to lift ROIs to 3D, and plans constrained viewpoints using a two-stage optimization (coarse grid search + L-BFGS-B refinement). A gimbal-mounted camera captures high-resolution close-ups, which are re-submitted to the VLM for assessment. The system uses ROS 2 on an NVIDIA Jetson, with waypoints spaced every 5m along the culvert. Cost terms encode coverage, centering, scale, obliquity, and range constraints. The inspection targets a 66m, 1.2m diameter culvert.

## Key Results
- Initial ROI proposals achieved 61.4% agreement with NYCC subject-matter experts
- Post-re-imaging assessments reached 80% agreement with experts
- Defect description score averaged 2.48/3
- Viewpoint planning optimized in 5-8 seconds for seed, 15-20ms for refinement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Open-vocabulary VLM prompting enables zero-shot defect detection without domain-specific training data.
- Mechanism: Sparse, general prompts (avoiding fixed defect taxonomies) solicit ROI proposals with bounding boxes, rationales, and confidence scores from GPT-5. The VLM's web-scale pretraining provides sufficient visual-semantic priors to hypothesize anomalies in unfamiliar culvert environments.
- Core assumption: VLMs trained on diverse internet imagery can generalize to highly specific, degraded infrastructure scenes despite domain shift and poor illumination.
- Evidence anchors:
  - [abstract] "Brief prompts to the VLM solicit open-vocabulary ROI proposals with rationales and confidences... without domain-specific fine-tuning."
  - [Section III-A] "the prompts are intentionally general... this bare-bones prompting encouraged broader hypothesis generation and produced proposals that aligned more closely with expert assessments."
  - [corpus] Limited direct corpus validation for this specific zero-shot infrastructure inspection mechanism; related work [ID 81292] shows LLM-VLM fusion for maritime inspection but in different domain.
- Break condition: If culvert defects fall entirely outside VLM pretraining distribution (e.g., novel degradation types with no web analogues), rationale quality and ROI localization will degrade substantially.

### Mechanism 2
- Claim: Two-stage viewpoint optimization (grid search + gradient refinement) efficiently finds feasible camera poses under severe kinematic constraints.
- Mechanism: Stage 1 conducts coarse brute-force search over bounded yaw/pitch/translation to escape local minima. Stage 2 refines via L-BFGS-B with motion/translation regularization. The composite cost (coverage, centering, size, obliquity, range) encodes inspection-specific requirements.
- Core assumption: The non-convex objective landscape has reachable global minima within gimbal limits and culvert geometry.
- Evidence anchors:
  - [Section III-C] "Instage one, a coarse brute-force grid searchover the bounded yaw, pitch, and translation is used to obtain a feasible seed configuration... The discretization for this is empirically selected to ensure tractability... solving for a single viewpoint takes on the order of 5 to 8 seconds."
  - [Section III-C] "This seed is thenrefined using a gradient-based optimization in stage two, which converges rapidly to a optimal solution in 15-20ms."
  - [corpus] Weak corpus coverage for this specific constrained view-planning mechanism; [ID 35927] addresses text-guided inspection trajectories but without kinematic constraints.
- Break condition: If culvert diameter narrows below robot+gimbal clearance, or if ROI lies in mechanically unreachable zone (e.g., directly behind robot), optimization returns infeasible solutions.

### Mechanism 3
- Claim: Re-imaging with VLM assessment closes the hypothesis-verification loop, converting tentative detections into expert-aligned findings.
- Mechanism: Initial ROI proposals trigger targeted close-up capture. Close-ups are re-submitted to VLM with assessment prompts, yielding {Confirmed, Partially Confirmed, Not Confirmed} labels plus defect descriptions. This iterative refinement filters false positives.
- Core assumption: Higher-resolution, near-frontal imagery provides sufficient signal for VLM to discriminate real defects from spurious proposals.
- Evidence anchors:
  - [abstract] "initial ROI proposals achieved 61.4% agreement with subject-matter experts, and final post-re-imaging assessments reached 80%"
  - [Section IV-B] "the ROIs whose hypotheses were not confirmed during the assessment step were precisely those lacking SME agreement"
  - [corpus] [ID 4730] shows multilayer VLM-LLM pipeline for construction inspection with similar verification stages, providing modest mechanistic support.
- Break condition: If close-up imagery still lacks discriminative features (e.g., sub-pixel cracks, lighting artifacts masquerading as defects), VLM assessment will produce inconsistent or uncalibrated judgments.

## Foundational Learning

- Concept: **Zero-shot VLM prompting for visual grounding**
  - Why needed here: The system depends on crafting prompts that elicit accurate bounding boxes and rationales from GPT-5 without any fine-tuning on culvert imagery.
  - Quick check question: Given an image of a degraded concrete surface, can you write a prompt that asks a VLM to identify anomalies without prescribing specific defect types?

- Concept: **Constrained optimization with non-convex costs**
  - Why needed here: Viewpoint planning must jointly satisfy visibility, centering, scale, obliquity, and range constraints while respecting gimbal limits and robot mobility.
  - Quick check question: Given