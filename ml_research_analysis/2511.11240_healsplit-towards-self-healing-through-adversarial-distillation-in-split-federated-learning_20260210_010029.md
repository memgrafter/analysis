---
ver: rpa2
title: 'HealSplit: Towards Self-Healing through Adversarial Distillation in Split
  Federated Learning'
arxiv_id: '2511.11240'
source_url: https://arxiv.org/abs/2511.11240
tags:
- data
- learning
- healsplit
- poisoning
- smashed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HealSplit introduces the first unified defense framework for Split
  Federated Learning (SFL), protecting against five types of poisoning attacks (label,
  data, smashed data, weight, and multi-vector poisoning). The method employs topology-aware
  detection using Personalized PageRank on k-nearest neighbor graphs to identify poisoned
  samples via topological anomaly scoring, followed by GAN-based generation of semantically
  consistent substitutes validated by a consistency student.
---

# HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning

## Quick Facts
- arXiv ID: 2511.11240
- Source URL: https://arxiv.org/abs/2511.11240
- Reference count: 17
- Primary result: First unified defense framework for Split Federated Learning protecting against 5 poisoning attacks, achieving >92% accuracy across all attack scenarios

## Executive Summary
HealSplit introduces a comprehensive defense framework for Split Federated Learning (SFL) that addresses five types of poisoning attacks through a three-stage pipeline: topology-aware detection, GAN-based recovery, and adversarial multi-teacher distillation. The method constructs k-nearest neighbor graphs over smashed data representations and uses Personalized PageRank to compute Topological Anomaly Scores (TAS) for identifying poisoned samples. These are then replaced with GAN-generated substitutes validated for semantic consistency, with the final model trained via dual-teacher distillation that balances clean semantic knowledge against anomaly pattern recognition.

## Method Summary
HealSplit operates through a three-stage pipeline: (1) detection using k-nearest neighbor graphs and Personalized PageRank to compute TAS scores that identify poisoned samples; (2) GAN-based generation of semantically consistent substitutes validated by a consistency student; (3) adversarial multi-teacher distillation combining a Vanilla Teacher for clean semantics and an Anomaly-Influence Debiasing Teacher that weights labels based on gradient interaction scores. The framework synchronizes with SFL at appropriate intervals, using only smashed data from the current update round for GAN training and maintaining stable performance even under adaptive attacks.

## Key Results
- Consistently achieves over 92% accuracy across all attack scenarios on four benchmark datasets
- Outperforms ten state-of-the-art defenses in both clean and poisoned data conditions
- Maintains stable performance under adaptive attacks with only 3-5% accuracy degradation
- Effective against label, data, smashed data, weight, and multi-vector poisoning attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Poisoned smashed data exhibits topological anomalies—locally dense clusters with weak global connectivity—that can be detected via graph propagation.
- Mechanism: Constructs a k-nearest neighbors graph over smashed data representations and computes a Topological Anomaly Score (TAS) using Personalized PageRank. Samples with TAS below an adaptive threshold (computed via kernel density estimation) are flagged as poisoned.
- Core assumption: Poisoned samples cluster together due to similar attack patterns while being structurally isolated from benign data distributions.
- Evidence anchors:
  - [Abstract]: "topology-aware detection module that constructs graphs over smashed data to identify poisoned samples via topological anomaly scoring (TAS)"
  - [Page 3, Methodology]: "poisoned samples tend to form locally dense, yet globally isolated clusters in the feature space"
  - [corpus]: Weak direct support; neighboring papers focus on SFL efficiency/privacy, not detection mechanisms.
- Break condition: Attackers who can craft poisoned samples that match the global topological distribution (adaptive attacks) reduce detection efficacy by ~3-5% accuracy (see Fig. 8).

### Mechanism 2
- Claim: Replacing poisoned smashed data with GAN-generated substitutes validated for semantic consistency restores training integrity.
- Mechanism: Train a vanilla GAN on identified clean smashed data to learn the feature distribution. Generated replacements are filtered through a consistency validation student—only high-confidence, label-consistent outputs are retained.
- Core assumption: Clean smashed data from a single round is sufficient to approximate the global feature distribution; the student can reliably detect semantic inconsistencies.
- Evidence anchors:
  - [Page 4]: "HealSplit synchronizes with SFL at appropriate intervals, using only the smashed data from the current update round to train the GAN"
  - [Abstract]: "GAN-based generation of semantically consistent substitutes validated by a consistency student"
  - [corpus]: No direct corpus support for GAN-based recovery in SFL defense.
- Break condition: Severe data heterogeneity (high non-IID) may limit GAN's ability to generalize across client distributions.

### Mechanism 3
- Claim: Dual-teacher adversarial distillation with anomaly-aware debiasing improves student robustness by balancing clean semantic knowledge against anomaly pattern recognition.
- Mechanism: The Anomaly-Influence Debiasing (AD) Teacher uses Gradient Interaction Scores (GIS) combined with TAS to weight label influences—amplifying labels that aid detection, suppressing those that introduce bias. The Vanilla Teacher provides clean semantic supervision. Momentum-adaptive optimization dynamically balances contributions (µ and η weights updated per iteration).
- Core assumption: Gradient alignment between tasks (poisoning detection, client ID, classification) correlates with information reliability for debiasing.
- Evidence anchors:
  - [Page 4-5]: "The term [Mp] quantifies the influence between the label sets of tasks a and b for sample k"
  - [Page 5, Eq. 14-15]: Momentum-based weight updates for µ and η
  - [corpus]: Neighboring papers mention distillation but not dual-teacher adversarial frameworks for SFL defense.
- Break condition: Removal of AD Teacher drops accuracy 6-10 points (Table 3), indicating heavy reliance on anomaly-aware supervision.

## Foundational Learning

- Concept: **Split Federated Learning (SFL) Architecture**
  - Why needed here: Defense operates on smashed data (intermediate representations transmitted from client to server), not raw gradients. Understanding where the split occurs is essential for threat modeling.
  - Quick check question: Can you trace where smashed data is generated and which party controls the server-side model?

- Concept: **Personalized PageRank for Graph Anomaly Detection**
  - Why needed here: TAS computation relies on PPR's ability to capture both local neighborhood density and global propagation patterns—standard for node importance scoring.
  - Quick check question: How does the restart probability (α in Eq. 3) control the local-vs-global trade-off?

- Concept: **Knowledge Distillation with Temperature Scaling**
  - Why needed here: The adversarial multi-teacher framework uses KL divergence with temperature τ (Eq. 11-12) to soften logits and transfer dark knowledge.
  - Quick check question: Why use LogSoftmax for the teacher output but Softmax for the student in Eq. 11-12?

## Architecture Onboarding

- Component map: Detection Module (KNN graph → PPR-based TAS → Adaptive threshold) → Recovery Pipeline (Clean smashed data → GAN generator → Substitute candidates) → Validation Module (Consistency student → Accept/reject substitutes) → Teachers (AD Teacher + Vanilla Teacher → Distillation losses)

- Critical path: Detection triggers → GAN generates replacements → Student validates → Substitutes replace poisoned data before aggregation. Failure at any stage propagates corruption downstream.

- Design tradeoffs:
  - Detection sensitivity vs. false positives: Lower threshold catches more attacks but risks discarding benign data.
  - GAN training frequency: More frequent updates improve distribution tracking but increase compute overhead.
  - Teacher balance (µ/η): Over-weighting AD Teacher may cause overfitting to attack patterns; over-weighting Vanilla Teacher reduces anomaly awareness.

- Failure signatures:
  - Detection misses: TAS distributions of poisoned and clean samples overlap significantly (check Fig. 2c).
  - GAN mode collapse: Generated substitutes lack diversity; validation student rejects most outputs.
  - Distillation imbalance: Rapid oscillation in µ/η weights (monitor Eq. 14-15 updates) indicates unstable training.

- First 3 experiments:
  1. **Detection-only ablation**: Run TAS detection without GAN replacement to isolate detection precision/recall across attack types (DP, SP, LP, WP).
  2. **Non-IID stress test**: Evaluate on M-q datasets with increasing q (0.1 → 0.5) to find heterogeneity breaking point; compare against DnC baseline.
  3. **Adaptive attack robustness**: Implement the divergence-minimizing adaptive attack (Page 7) and measure accuracy drop vs. vanilla attack; quantify detection rate degradation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can HealSplit maintain robustness if adaptive attacks specifically target the GAN-based recovery or distillation components rather than just the detection module?
- Basis in paper: [inferred] The "Adaptive Attack" experiment (Fig. 8) only evaluates an attacker minimizing divergence in Topological Anomaly Scoring (TAS) to evade detection. It does not explore attacks designed to poison the generative pipeline or manipulate the gradient interaction scores used by the teachers.
- Why unresolved: The current evaluation assumes the adaptive attacker focuses solely on bypassing the graph-based detection; the vulnerability of the subsequent generative and distillation stages to targeted manipulation remains untested.
- What evidence would resolve it: Results from experiments where adversaries craft perturbations specifically designed to disrupt the consistency validation student or the Anomaly-Influence Debiasing Teacher's gradients.

### Open Question 2
- Question: What is the computational and communication overhead of HealSplit relative to standard SFL and other defense baselines?
- Basis in paper: [inferred] The "Experimental Setup" and results focus exclusively on accuracy metrics. The framework introduces complex operations—KNN graph construction, GAN training, and multi-teacher distillation—which are computationally intensive compared to statistical aggregation methods like Krum or Trim-Mean.
- Why unresolved: While the paper claims SFL offers "reduced computational overhead," it does not quantify the added latency, training time, or resource consumption introduced by HealSplit's three-component pipeline.
- What evidence would resolve it: A comparative analysis of training time per round and communication costs for HealSplit versus FedAvg, DnC, and ShieldFL under identical hardware constraints.

### Open Question 3
- Question: Does the topology-aware detection mechanism generalize to non-image data modalities where feature spaces are less structured?
- Basis in paper: [inferred] The evaluation is restricted to image datasets (MNIST, CIFAR-10, HAM10000). The detection module relies on KNN graphs and the assumption that poisoned samples form "locally dense" clusters in visual feature space.
- Why unresolved: It is unclear if the Topological Anomaly Score (TAS) effectively distinguishes poisoned from clean samples in high-dimensional, sparse, or sequential data (e.g., text or time-series) where "local density" may not behave similarly.
- What evidence would resolve it: Experimental results applying HealSplit to text classification (e.g., sentiment analysis) or tabular data benchmarks using appropriate split learning architectures.

## Limitations
- Detection mechanism's effectiveness may degrade when adaptive attacks craft poisoned samples matching global topological distributions
- GAN-based recovery assumes clean smashed data from a single round sufficiently represents global feature distribution, which may fail under severe data heterogeneity
- Several critical hyperparameters are not fully specified, including KNN graph parameters and various scaling parameters that significantly impact performance

## Confidence

- **High Confidence**: The detection mechanism using Personalized PageRank on KNN graphs for identifying poisoned samples is well-established in anomaly detection literature and the paper provides clear algorithmic details.
- **Medium Confidence**: The GAN-based recovery and validation pipeline is technically sound, but lacks empirical validation of its effectiveness under extreme data heterogeneity conditions.
- **Medium Confidence**: The dual-teacher adversarial distillation framework is innovative but the theoretical justification for anomaly-aware debiasing through gradient alignment could be strengthened with additional experiments.

## Next Checks

1. **Detection Precision-Recall Analysis**: Conduct a comprehensive ablation study of the TAS detection module alone, measuring precision and recall across all five attack types (DP, SP, LP, WP, multi-vector) to identify detection weaknesses and false positive rates.

2. **Non-IID Robustness Testing**: Systematically evaluate HealSplit on M-q datasets with increasing heterogeneity levels (q from 0.1 to 0.5) to determine the breaking point where detection and recovery mechanisms fail, and compare performance against baseline defenses like DnC.

3. **Adaptive Attack Vulnerability Assessment**: Implement and test the divergence-minimizing adaptive attack described in the paper to measure actual accuracy degradation versus the claimed 3-5% drop, and evaluate whether detection rates significantly decrease under such sophisticated attacks.