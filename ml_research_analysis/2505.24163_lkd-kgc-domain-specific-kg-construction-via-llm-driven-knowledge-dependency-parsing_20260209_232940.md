---
ver: rpa2
title: 'LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency
  Parsing'
arxiv_id: '2505.24163'
source_url: https://arxiv.org/abs/2505.24163
tags:
- knowledge
- https
- entity
- schema
- types
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LKD-KGC is a framework for unsupervised domain-specific knowledge
  graph construction that addresses limitations in existing LLM-based methods. It
  autonomously analyzes document repositories to infer knowledge dependencies, determines
  optimal processing sequences via LLM-driven prioritization, and autoregressively
  generates entity schemas by integrating hierarchical inter-document contexts.
---

# LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing

## Quick Facts
- arXiv ID: 2505.24163
- Source URL: https://arxiv.org/abs/2505.24163
- Authors: Jiaqi Sun; Shiyou Qian; Zhangchi Han; Wei Li; Zelin Qian; Dingyu Yang; Jian Cao; Guangtao Xue
- Reference count: 40
- Primary result: 10%-20% improvements in precision and recall compared to state-of-the-art baselines across three domain-specific datasets

## Executive Summary
LKD-KGC presents a framework for unsupervised domain-specific knowledge graph construction that addresses limitations in existing LLM-based methods. The framework autonomously analyzes document repositories to infer knowledge dependencies, determines optimal processing sequences via LLM-driven prioritization, and autoregressively generates entity schemas by integrating hierarchical inter-document contexts. This schema guides unsupervised extraction of entities and relationships without relying on predefined structures or external knowledge. The approach demonstrates significant improvements in both precision and recall compared to baseline methods.

## Method Summary
LKD-KGC operates through a three-stage autonomous process for domain-specific knowledge graph construction. First, it analyzes document repositories to infer knowledge dependencies using LLM-driven parsing. Second, it determines optimal processing sequences through LLM-based prioritization of knowledge dependencies. Finally, it generates entity schemas autoregressively by integrating hierarchical inter-document contexts, which then guide the unsupervised extraction of entities and relationships. The framework is designed to operate without predefined structures or external knowledge bases, making it suitable for truly unsupervised domain-specific KG construction.

## Key Results
- Achieves 10%-20% improvements in both precision and recall compared to state-of-the-art baselines
- Demonstrates effectiveness across three different domain-specific datasets
- Shows consistent performance across two different base LLMs
- Operates without predefined structures or external knowledge bases

## Why This Works (Mechanism)
The framework's effectiveness stems from its autonomous approach to knowledge dependency parsing and schema generation. By using LLMs to analyze document repositories and infer knowledge dependencies, LKD-KGC can identify the optimal sequence for processing information. The autoregressive schema generation, which integrates hierarchical inter-document contexts, creates a robust foundation for unsupervised entity and relationship extraction. This approach addresses key limitations in existing LLM-based methods by eliminating the need for predefined structures while maintaining high precision and recall through intelligent dependency analysis and context integration.

## Foundational Learning

**Knowledge Dependency Parsing**: The ability to automatically identify relationships between different pieces of knowledge within documents. Needed to determine processing order and extract meaningful connections. Quick check: Verify that the framework correctly identifies hierarchical and sequential relationships in sample documents.

**Hierarchical Context Integration**: The technique of combining information from multiple document levels to create comprehensive schemas. Needed to ensure that extracted knowledge captures the full complexity of domain-specific relationships. Quick check: Test that schemas generated from multi-document contexts are more complete than those from single documents.

**Unsupervised Entity Extraction**: Methods for identifying and extracting entities without predefined schemas or training data. Needed to enable truly autonomous KG construction. Quick check: Validate that extracted entities align with domain-specific terminology and concepts.

## Architecture Onboarding

**Component Map**: Document Repository -> Knowledge Dependency Parser -> Processing Sequence Generator -> Schema Generator -> Entity/Relationship Extractor -> Knowledge Graph

**Critical Path**: The most time-critical path is Document Repository -> Knowledge Dependency Parser -> Schema Generator, as accurate dependency parsing directly impacts schema quality, which in turn determines extraction accuracy.

**Design Tradeoffs**: The framework trades computational complexity (multiple LLM calls for dependency parsing and prioritization) for higher accuracy and autonomy. This approach eliminates the need for manual schema definition but increases processing time and computational resource requirements.

**Failure Signatures**: 
- Poor schema quality indicates inadequate knowledge dependency parsing
- Low recall suggests insufficient context integration during schema generation
- Incorrect entity extraction points to errors in the dependency analysis stage

**First Experiments**:
1. Test knowledge dependency parsing accuracy on a small, controlled document set with known relationships
2. Validate schema generation quality by comparing automatically generated schemas against expert-defined schemas for the same domain
3. Measure entity extraction precision and recall on documents with annotated entities to establish baseline performance

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided content.

## Limitations

- Limited statistical significance testing of the reported 10%-20% improvements, making it difficult to assess whether gains are robust or domain-dependent
- Potential brittleness in LLM-driven knowledge dependency parsing when applied to more complex or heterogeneous domains
- Narrow experimental scope covering only three domain-specific datasets and two base LLMs, limiting generalizability claims

## Confidence

**High confidence**: The framework's core methodology (LLM-driven knowledge dependency parsing, hierarchical context integration) is clearly described and internally consistent.

**Medium confidence**: The reported performance improvements are plausible but require additional validation due to limited statistical analysis and narrow experimental scope.

**Low confidence**: Generalizability claims across diverse domains and the framework's robustness to complex knowledge structures are not sufficiently supported by the presented evidence.

## Next Checks

1. Conduct statistical significance testing (e.g., paired t-tests) across multiple runs to verify the 10%-20% improvement claims are not due to random variation.

2. Test the framework on at least 3-5 additional diverse domain-specific datasets (e.g., medical, legal, technical) to evaluate robustness and generalizability beyond the current narrow scope.

3. Perform ablation studies to isolate the contribution of key components (knowledge dependency parsing vs. schema generation vs. unsupervised extraction) and identify potential failure modes.