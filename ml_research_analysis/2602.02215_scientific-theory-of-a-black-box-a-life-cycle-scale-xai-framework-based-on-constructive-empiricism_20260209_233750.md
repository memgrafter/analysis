---
ver: rpa2
title: 'Scientific Theory of a Black-Box: A Life Cycle-Scale XAI Framework Based on
  Constructive Empiricism'
arxiv_id: '2602.02215'
source_url: https://arxiv.org/abs/2602.02215
tags:
- stobb
- surrogate
- black-box
- observations
- adequacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a framework for consolidating explanatory
  information about a fixed black-box model into a persistent, auditable artifact
  throughout its lifecycle. Grounded in Constructive Empiricism, the framework defines
  a Scientific Theory of a Black-Box (SToBB) that must be empirically adequate, adaptable,
  and auditable.
---

# Scientific Theory of a Black-Box: A Life Cycle-Scale XAI Framework Based on Constructive Empiricism

## Quick Facts
- arXiv ID: 2602.02215
- Source URL: https://arxiv.org/abs/2602.02215
- Reference count: 40
- Introduces a lifecycle-scale XAI framework grounded in Constructive Empiricism for consolidating explanations of a fixed black-box model into a persistent, auditable artifact.

## Executive Summary
This paper presents a framework for consolidating explanatory information about a fixed black-box model into a persistent, auditable artifact throughout its lifecycle. Grounded in Constructive Empiricism, the framework defines a Scientific Theory of a Black-Box (SToBB) that must be empirically adequate, adaptable, and auditable. The authors operationalize this by introducing the Constructive Box Theoriser (CoBoT) algorithm, which constructs and maintains an interpretable rule-based surrogate as observations accumulate. As a proof of concept, they instantiate a complete SToBB for a neural-network classifier on the Abalone dataset, achieving 0.64 validation accuracy. The surrogate comprises 20 boxes over 16 feature sets, compressing 4,177 observations with a gain of ~0.995. CoBoT performs 187 updates (4.5%) and provides interfaces for local, contrastive, and global explanations, enabling reuse and consistent analysis across stakeholder needs.

## Method Summary
The framework is grounded in Constructive Empiricism, requiring a Scientific Theory of a Black-Box (SToBB) to be empirically adequate, adaptable, and auditable. The Constructive Box Theoriser (CoBoT) algorithm constructs and maintains an interpretable rule-based surrogate as new observations accumulate. The surrogate is a collection of "boxes" (rules) over feature sets, updated incrementally as new data arrives. The proof of concept applies this to a neural-network classifier on the Abalone dataset, building a surrogate with 20 boxes over 16 feature sets from 4,177 observations, achieving 0.64 validation accuracy and a compression gain of ~0.995. The framework supports local, contrastive, and global explanations through defined interfaces.

## Key Results
- Surrogate model achieves 0.64 validation accuracy for neural-network classifier on Abalone dataset.
- CoBoT performs 187 updates (4.5%) and compresses 4,177 observations with a gain of ~0.995.
- Surrogate comprises 20 boxes over 16 feature sets, enabling reuse and consistent analysis across stakeholder needs.

## Why This Works (Mechanism)
The framework works by treating XAI explanations as a scientific theory that must be empirically adequate, adaptable, and auditable throughout the model's lifecycle. CoBoT incrementally builds and updates a rule-based surrogate as new observations arrive, ensuring the surrogate remains faithful to the black-box behavior. The use of boxes (rules) over feature sets allows for interpretable and reusable explanations, supporting local, contrastive, and global analysis. The persistence and versioning of the SToBB artifact enable auditability and traceability across the model's lifecycle.

## Foundational Learning
- Constructive Empiricism: An epistemological stance asserting that scientific theories should be judged by empirical adequacy rather than truth; needed to ground the framework in a defensible philosophy of explanation.
  - Quick check: Compare empirical adequacy of SToBB against black-box model predictions.
- Rule-based surrogates: Interpretable models composed of logical rules; needed to provide human-understandable explanations.
  - Quick check: Validate surrogate accuracy and interpretability via user studies.
- Incremental update mechanism: CoBoT updates the surrogate as new data arrives; needed to maintain empirical adequacy over the model's lifecycle.
  - Quick check: Monitor update frequency and surrogate performance over time.
- Box representation: Each box is a rule over a feature set; needed to compress and organize explanatory information.
  - Quick check: Measure compression gain and surrogate complexity.
- Auditability and adaptability: The SToBB artifact must be persistent and versioned; needed for regulatory compliance and lifecycle management.
  - Quick check: Test version control and governance integration.

## Architecture Onboarding
- Component map: Data/Observations -> CoBoT -> SToBB (surrogate) -> Explanation Interfaces (local, contrastive, global)
- Critical path: Observation ingestion → CoBoT update → SToBB maintenance → Explanation generation
- Design tradeoffs: Rule-based surrogates favor interpretability over raw accuracy; incremental updates balance recency and stability.
- Failure signatures: High update frequency may indicate poor surrogate stability; low accuracy suggests insufficient empirical adequacy.
- First experiments: (1) Evaluate surrogate accuracy vs. black-box on multiple datasets; (2) Measure update frequency and compression gain over time; (3) Test explanation interfaces with end-users for interpretability and trust.

## Open Questions the Paper Calls Out
None.

## Limitations
- Empirical validation limited to a single proof-of-concept case with the Abalone dataset and a neural-network classifier, which may not generalize.
- Surrogate accuracy (0.64 validation accuracy) and compression gain (~0.995) lack comparative benchmarks or statistical significance tests.
- Framework's reliance on rule-based surrogates may struggle with high-dimensional or continuous data without substantial preprocessing.
- Auditability and adaptability claims are design-time assertions, not yet tested in real-world deployments.
- Theoretical grounding in Constructive Empiricism is compelling but not empirically validated against alternative epistemological foundations.

## Confidence
- Core framework design (SToBB and CoBoT): Medium
- Empirical results: Low
- Auditability and adaptability claims: Medium

## Next Checks
1. Evaluate CoBoT on multiple datasets and model types, comparing surrogate accuracy, update frequency, and compression gain against established XAI methods.
2. Conduct a user study with diverse stakeholders to assess the usability, interpretability, and trust in the SToBB artifact for local, contrastive, and global explanations.
3. Implement the SToBB artifact within an MLops pipeline to test version control, governance, and integration for auditability across model lifecycle stages.