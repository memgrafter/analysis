---
ver: rpa2
title: 'Identifying Fine-grained Forms of Populism in Political Discourse: A Case
  Study on Donald Trump''s Presidential Campaigns'
arxiv_id: '2507.19303'
source_url: https://arxiv.org/abs/2507.19303
tags:
- populist
- trump
- discourse
- speeches
- populism
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores whether large language models can identify
  and classify fine-grained forms of populism in political discourse. The authors
  curate and release novel datasets to train and benchmark a range of pre-trained
  language models, both open-weight and proprietary, across multiple prompting paradigms.
---

# Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns

## Quick Facts
- arXiv ID: 2507.19303
- Source URL: https://arxiv.org/abs/2507.19303
- Reference count: 32
- Primary result: Fine-tuned RoBERTa classifier outperforms instruction-tuned LLMs on identifying fine-grained populism in political discourse

## Executive Summary
This study investigates whether large language models can identify and classify fine-grained forms of populism in political discourse. The authors curate and release novel datasets to train and benchmark various pre-trained language models, including both open-weight and proprietary options across multiple prompting paradigms. The research focuses on Donald Trump's presidential campaign speeches as a case study, applying the best-performing model to extract insights into his strategic use of populist rhetoric. The study also assesses the generalizability of these models by benchmarking them on campaign speeches by European politicians, examining cross-context transferability in political discourse analysis.

## Method Summary
The authors curated novel datasets for training and benchmarking pre-trained language models on populism classification tasks. They evaluated multiple approaches including fine-tuned RoBERTa classifiers and instruction-tuned large language models across various prompting paradigms. The study employed a comparative methodology, testing models on both in-domain data (Trump's speeches) and out-of-domain data (European politicians' speeches) to assess generalizability. The best-performing model was then applied to analyze Trump's campaign speeches for insights into his populist rhetoric patterns.

## Key Results
- Fine-tuned RoBERTa classifier vastly outperforms all new-era instruction-tuned LLMs on in-domain populism classification tasks
- Instruction-tuned LLMs exhibit greater robustness on out-of-domain data when tested on European politicians' speeches
- The analysis of Trump's campaign speeches reveals valuable insights into his strategic use of populist rhetoric across different contexts

## Why This Works (Mechanism)
The superior performance of fine-tuned RoBERTa on in-domain data stems from its ability to learn task-specific patterns through supervised training on curated datasets. Fine-tuning allows the model to adapt its representations to the specific linguistic patterns and nuances of populist discourse. In contrast, instruction-tuned LLMs rely on zero-shot or few-shot learning capabilities, which may not capture the subtle distinctions between different forms of populism without explicit training examples. The improved performance of LLMs on out-of-domain data suggests their generalization capabilities may be more robust across different political contexts, though this requires further validation.

## Foundational Learning

1. **Populism classification in political discourse**
   - Why needed: Understanding how to identify and categorize different forms of populist rhetoric is essential for political analysis and democratic monitoring
   - Quick check: Can the model distinguish between different subtypes of populism (left-wing, right-wing, anti-elite, etc.)?

2. **Fine-tuning vs. instruction-tuning paradigms**
   - Why needed: Different training approaches have distinct advantages for specialized NLP tasks
   - Quick check: Does supervised fine-tuning consistently outperform zero-shot learning for domain-specific classification?

3. **Cross-context transferability in political NLP**
   - Why needed: Political discourse varies significantly across regions and cultures, requiring models that can generalize
   - Quick check: How well do models trained on one political context perform on speeches from different countries or political systems?

## Architecture Onboarding

**Component Map:** Data Curation -> Model Training -> Benchmarking -> Cross-context Validation -> Application to Trump Speeches

**Critical Path:** The critical path involves creating high-quality labeled datasets, training fine-tuned models (particularly RoBERTa), benchmarking against instruction-tuned LLMs, and validating generalizability on out-of-domain European data.

**Design Tradeoffs:** The study balances between model performance (favoring fine-tuned RoBERTa for in-domain tasks) and generalization capability (where instruction-tuned LLMs show promise). The tradeoff between task-specific accuracy and cross-context robustness is central to the design choices.

**Failure Signatures:** Poor performance on out-of-domain data, inability to distinguish fine-grained forms of populism, overfitting to specific rhetorical patterns, and prompt engineering limitations for LLMs.

**First Experiments:**
1. Fine-tune RoBERTa on the curated populism dataset and evaluate on Trump's speeches
2. Test instruction-tuned LLMs with various prompting strategies on the same dataset
3. Benchmark both approaches on European politicians' speeches to assess cross-context performance

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Narrow focus on Donald Trump's campaign speeches limits generalizability to other political contexts
- Small sample size when validating on European politicians' speeches
- Potential for improved LLM performance through better prompt engineering that was not explored
- The performance gap raises questions about whether prompting strategies for LLMs were fully optimized

## Confidence
- **Medium** for the core finding that fine-tuned RoBERTa outperforms instruction-tuned LLMs on in-domain data
- **Medium** for the cross-context transferability insights, limited by small validation sample

## Next Checks
1. Test the models on a larger corpus of political speeches from multiple countries and political parties to better assess cross-context transferability
2. Systematically explore prompt engineering techniques for instruction-tuned LLMs to determine if their performance can match or exceed fine-tuned RoBERTa
3. Conduct human validation studies to verify the accuracy of model classifications against expert political discourse analysis