---
ver: rpa2
title: 'Discursive Circuits: How Do Language Models Understand Discourse Relations?'
arxiv_id: '2510.11210'
source_url: https://arxiv.org/abs/2510.11210
tags:
- discourse
- circuits
- relation
- cudr
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces discursive circuits, the first mechanistic
  analysis of how language models process discourse relations. The authors develop
  a novel Completion under Discourse Relation (CuDR) task to enable circuit discovery
  in this complex domain, constructing a dataset of minimal contrastive pairs across
  three discourse frameworks (PDTB, RST, SDRT).
---

# Discursive Circuits: How Do Language Models Understand Discourse Relations?

## Quick Facts
- arXiv ID: 2510.11210
- Source URL: https://arxiv.org/abs/2510.11210
- Authors: Yisong Miao; Min-Yen Kan
- Reference count: 40
- Key outcome: Discursive circuits (≈0.2% of model size) recover discourse understanding with ~90% faithfulness and generalize across frameworks

## Executive Summary
This paper introduces discursive circuits, the first mechanistic analysis of how language models process discourse relations. The authors develop a novel Completion under Discourse Relation (CuDR) task to enable circuit discovery in this complex domain, constructing a dataset of minimal contrastive pairs across three discourse frameworks (PDTB, RST, SDRT). Discursive circuits successfully recover discourse understanding with ~90% faithfulness and generalize across frameworks. Analysis reveals lower layers capture linguistic features while upper layers encode discourse-level abstractions, with consistent feature utility across frameworks. This work provides the first neural-based discourse hierarchy and offers new insights into the mechanistic basis of discourse comprehension.

## Method Summary
The paper introduces the CUDR task to create minimal contrastive pairs for circuit discovery in discourse processing. The method involves: (1) generating CUDR pairs from discourse corpora by fixing Arg1 and swapping connectives to create counterfactual conditions, (2) fine-tuning GPT-2 Medium on this task to ensure proper instruction following, and (3) applying Edge Attribution Patching (EAP) to identify sparse computational subgraphs (circuits) that causally control discourse predictions. The EAP method scores edges based on their contribution to logit differences when patching activations from clean to corrupted runs. The top ~200 edges form a discursive circuit, achieving ~90% faithfulness compared to the full model. The approach is validated across multiple discourse frameworks and includes analysis of layer-wise contributions and cross-framework generalization.

## Key Results
- Sparse discursive circuits (≈0.2% of model size) achieve ~90% faithfulness in recovering discourse understanding
- Lower layers (8-16) capture linguistic features while upper layers encode discourse-level abstractions
- Circuits generalize well across frameworks, with positive correlation between overlap and performance in cross-framework transfer
- Circuit hierarchy can be constructed from fine-grained (L3) to coarse-grained (L0) relations

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Minimal Pair Steering
The CUDR task creates minimal contrastive pairs by holding Arg1 fixed and swapping the discourse connective, forcing the model to shift predictions. Activation patching identifies edges whose restoration from the original run to the counterfactual run recovers the original output, pinpointing components causally responsible for discourse understanding. The method uses EAP approximation g(e) ≈ (z_ori_u − z_cf_u)^T ∇_v L(x_cf) to score edges efficiently.

### Mechanism 2: Hierarchical Circuit Composition
Discourse understanding is realized by a hierarchy of circuits where higher-level abstractions build upon lower-level linguistic features. The paper constructs a circuit hierarchy (L3 → L2 → L1 → L0), with lower layers capturing linguistic features (antonymy, coreference) and upper layers encoding discourse-level abstractions. Analysis shows minimal overlap between linguistic feature circuits and discourse abstraction circuits in high layers.

### Mechanism 3: Cross-Framework Generalization via Shared Representations
Language models encode shared representations of discourse relations, enabling circuits learned on one framework (PDTB) to generalize to others (RST, SDRT). Using framework mappings, circuits learned on PDTB data achieve substantial faithfulness on RST and SDRT tasks. Cross-framework results reveal positive correlation between circuit overlap and performance, suggesting shared circuitry handles core discourse concepts.

## Foundational Learning

- **Concept: Mechanistic Interpretability & Activation Patching**
  - Why needed: This is the core methodology for identifying causally responsible model components
  - Quick check: If patching an activation from a "clean" run where a model predicts "he" to a "corrupted" run where it predicts "the" shifts output back toward "he", what does that tell you about the patched component? (It's causally responsible for the prediction)

- **Concept: Discourse Relations & Frameworks (PDTB, RST, SDRT)**
  - Why needed: This is the domain of study - understanding how models connect text spans semantically
  - Quick check: In the CUDR task, what two components are swapped to create the counterfactual condition? (Arg2 and Arg'2, while keeping Arg1 fixed)

- **Concept: Circuit Faithfulness & Hierarchy**
  - Why needed: These are the evaluation metric and structural finding of the paper
  - Quick check: A circuit achieves 90% faithfulness. Does this mean it *is* the full mechanism, or that it is a *sufficient* subset? (It's a sufficient subset that recovers most performance)

## Architecture Onboarding

- **Component map**: GPT-2 Medium (Transformer) -> Edges (MLP layers to Attention Heads) -> Discursive Circuits -> Logit difference between Arg2 and Arg'2

- **Critical path**:
  1. Generate CUDR pairs using LLM with provided prompt
  2. Fine-tune GPT-2 Medium on held-out PDTB data via NSP-style task
  3. Run EAP: forward pass with counterfactual, forward/backward with original to compute gradients
  4. Score all edges using g(e) ≈ (z_u^ori - z_u^cf)^T ∇_v L(x^cf)
  5. Select top 200-1000 edges, average across 5 runs
  6. Patch top edges from original to counterfactual run, measure faithfulness

- **Design tradeoffs**:
  - EAP vs. Exhaustive Patching: ~1000x faster but relies on linear approximation
  - GPT-2 Medium vs. Larger Models: Chosen for tractability; results may not scale linearly
  - LLM-Generated vs. Human Data: Efficient but potentially more "straightforward" counterfactuals

- **Failure signatures**:
  - Low Faithfulness (<50%): Insufficient circuit or incorrect edge identification
  - Random Baseline Outperforms Learned Circuit: EAP implementation bug or metric error
  - Poor Generalization: Frameworks not well-aligned or model lacks unified discourse representation

- **First 3 experiments**:
  1. Reproduce L3 Circuit for single PDTB relation: Use 32 samples, implement EAP, select top 200 edges, evaluate faithfulness (~90% target)
  2. Analyze layer-wise contribution: Plot edges per layer, patch low layers (0-10) and high layers (10-20) separately
  3. Test cross-framework transfer: Apply PDTB circuit for Contingency.Cause.Reason to SDRT 'Explanation' data, observe performance gap closure

## Open Questions the Paper Calls Out

- **Cross-lingual circuit space**: The paper notes it would be promising to extend circuit discovery to multiple languages and explore whether a unified circuit space exists across different languages, as current work is restricted to English corpora.

- **Behavioral steering applications**: Future work plans to adapt the methodology to broader tasks such as steering models in biased contexts and guiding future discourse taxonomy development, though current work focuses only on identifying circuits.

- **Intra-framework generalization paradox**: The paper observes no correlation between circuit overlap and faithfulness within PDTB (r=-0.007) despite positive correlation in cross-framework transfer (r=0.44), without explaining this counterintuitive finding.

## Limitations

- Task specificity may not capture full complexity of natural discourse comprehension
- EAP method relies on linear approximation that may break down for certain relations
- LLM-generated counterfactuals may introduce subtle biases affecting mechanistic interpretation
- Results may not scale proportionally to larger models (GPT-2 Large showed different patterns)

## Confidence

**High Confidence** (supported by direct experimental evidence):
- Sparse discursive circuits achieve ~90% faithfulness on PDTB tasks
- Lower layers capture linguistic features while upper layers encode discourse abstractions
- Circuit hierarchy can be constructed from fine-grained to coarse-grained relations

**Medium Confidence** (supported by indirect evidence or reasonable inference):
- Cross-framework generalization via shared representations exists
- Circuit composition follows hierarchical structure from linguistic to discourse features
- Mechanistic explanation through sparse computational subgraphs is valid

**Low Confidence** (based on limited evidence or significant assumptions):
- Discovered circuits represent complete mechanism for discourse understanding
- Results will scale proportionally to larger models
- CUDR task fully captures complexity of discourse comprehension

## Next Checks

1. **Ablation Study on Circuit Components**: Systematically remove subsets of identified edges from full circuit and measure faithfulness degradation to test sufficiency of sparse circuit

2. **Human Evaluation of Counterfactual Quality**: Conduct blind human evaluation comparing LLM-generated counterfactuals to human-written ones to quantify potential biases affecting circuit behavior

3. **Cross-Architecture Transfer**: Test whether discursive circuits discovered in GPT-2 Medium transfer to other architectures (BERT, RoBERTa) on same discourse tasks to validate architecture-agnostic properties