---
ver: rpa2
title: Extracting Conceptual Spaces from LLMs Using Prototype Embeddings
arxiv_id: '2509.19269'
source_url: https://arxiv.org/abs/2509.19269
tags:
- dataset
- embeddings
- protosim
- predicted
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to extract conceptual spaces from
  large language models (LLMs) by using prototype embeddings. The key idea is to model
  perceptual features using embeddings of prototype descriptions (e.g., "a very sweet
  food") and fine-tune the LLM to align these prototype embeddings with entity embeddings.
---

# Extracting Conceptual Spaces from LLMs Using Prototype Embeddings

## Quick Facts
- arXiv ID: 2509.19269
- Source URL: https://arxiv.org/abs/2509.19269
- Authors: Nitesh Kumar; Usashi Chatterjee; Steven Schockaert
- Reference count: 40
- Key outcome: Method extracts conceptual spaces from LLMs by embedding prototype descriptions (e.g., "a very sweet food") and computing similarity with entity embeddings; outperforms existing LLM-based embedding models on perceptual feature ranking tasks.

## Executive Summary
This paper introduces ProtoSim, a method to extract conceptual spaces from large language models by using prototype embeddings. The approach models perceptual features as directions in embedding space through descriptions of prototypical entities (e.g., "a very sweet food" for sweetness), then fine-tunes the LLM to align these prototype embeddings with entity embeddings. Experiments demonstrate that ProtoSim outperforms both pre-trained and fine-tuned LLM-based embedding models on multiple perceptual datasets, achieving state-of-the-art results in ranking entities along conceptual space dimensions. The method also enables predicting degrees of features with strong correlation to human ratings.

## Method Summary
ProtoSim extracts conceptual spaces by verbalizing perceptual features as prototype descriptions, then embedding these descriptions to serve as basis vectors in LLM embedding space. The method fine-tunes the LLM using a combined classification and ranking loss to align prototype embeddings with entity embeddings. Classification loss uses centroid-based softmax over positive prototype vs. negative properties, while ranking loss explicitly orders entity pairs along feature dimensions. The approach handles ambiguity by prepending category names to entities and uses EOL-style prompts for decoder-only LLMs. Fine-tuning employs QLoRa optimization and shows that smaller models (Llama3-8B) often outperform larger ones after fine-tuning.

## Key Results
- ProtoSim achieves state-of-the-art performance on perceptual feature ranking, outperforming pre-trained LLM2Vec models by 2.8% to 11.6% on various datasets
- The method successfully predicts degrees of perceptual features, showing strong Pearson correlation with human ratings on sweetness and other dimensions
- Classification-only fine-tuning performs comparably to classification+ranking, with ranking loss providing inconsistent benefits across domains

## Why This Works (Mechanism)

### Mechanism 1: Prototype-as-Feature-Direction Encoding
Perceptual features are represented as directions in LLM embedding space by embedding descriptions of prototypical entities rather than learning from labeled examples. This treats prototype embeddings as basis vectors in a conceptual space, assuming LLMs already encode perceptual knowledge in a structured way accessible through natural language descriptions. Break condition: fails when prototype descriptions activate spurious associations.

### Mechanism 2: Cross-Subspace Alignment via Classification Fine-Tuning
Pre-trained LLM embeddings place prototype descriptions and entities in different subspaces; fine-tuning with classification objective aligns them sufficiently for similarity-based feature extraction. The method uses a small synthetic dataset pairing properties with positive entities and negative properties. Break condition: fails if fine-tuning causes catastrophic forgetting or overfits to synthetic categories.

### Mechanism 3: Ranking Loss as Perceptual Regularization
Adding ranking loss on perceptual datasets improves generalization to held-out perceptual features by explicitly training the model to order entities along feature dimensions. This supplements classification loss with pairwise ordering objectives. Break condition: limited or inconsistent benefit across datasets, with ranking sometimes underperforming classification alone.

## Foundational Learning

- **Conceptual Spaces (Gärdenfors, 2000)**
  - Why needed here: The entire method targets extraction of these geometric meaning representations where dimensions correspond to perceptual features (not distributional semantics)
  - Quick check question: Can you explain why a conceptual space differs from standard word embeddings?

- **Contrastive Fine-Tuning for Embeddings**
  - Why needed here: The classification loss is essentially contrastive—pulling prototype embeddings toward positive centroids while pushing away from negatives
  - Quick check question: How does the centroid-based classification differ from pairwise contrastive losses like SimCSE?

- **Cross-Domain Transfer in LLMs**
  - Why needed here: The method relies on generalization from 123 synthetic categories + perceptual ranking data to held-out perceptual domains
  - Quick check question: What evidence exists that fine-tuning on one perceptual modality transfers to another?

## Architecture Onboarding

- **Component map:** Entity verbalizer -> Prototype verbalizer -> EOL prompt encoder -> Classification fine-tuning head -> Ranking fine-tuning head
- **Critical path:** Start with base LLM (Llama3-8B recommended) -> Generate/obtain classification dataset (123 categories from GPT-4o) -> Fine-tune with L1 + 0.25×L2 loss, T=0.25, α=10 -> Evaluate on held-out perceptual domain using pairwise accuracy
- **Design tradeoffs:** Llama3-8B vs. larger models (smaller often outperforms larger after fine-tuning); Pre-trained embedding models vs. base LLMs (LLM2Vec underperforms Llama3-8B post-fine-tuning); Classification-only vs. classification+ranking (ranking adds complexity without consistent gains)
- **Failure signatures:** Negative preferences (fails on "without cranberry sauce" queries); Lexical distraction (overweights word overlap); Single-feature focus (attends to one salient word); Intermediate values (poor calibration for mid-range sweetness)
- **First 3 experiments:** 1) Reproduce classification-only baseline with Llama3-8B on 123-category dataset; 2) Test linear mapping alternative using Procrustes-based orthogonal mapping; 3) Probe failure mode on negation with diagnostic dataset of negative preference queries

## Open Questions the Paper Calls Out

### Open Question 1
Can linear transformations effectively align prototype and entity embedding spaces without the need for fine-tuning the underlying LLM? The authors note that preliminary experiments with linear mappings failed to yield competitive results, but a further investigation is left for future work.

### Open Question 2
Can the ProtoSim approach be extended to accurately predict the absolute degree to which a perceptual feature is satisfied, rather than just ranking entities? The paper focused on ranking and leaves formal evaluation of measuring degrees for future work.

### Open Question 3
How can the model be improved to handle natural language queries containing negative constraints (e.g., "lactose-free")? The qualitative analysis identifies difficulties with negative preferences as a key limitation where the model selects options based on lexical overlap with the negated term.

## Limitations
- The method relies on the assumption that LLMs already encode perceptual knowledge in a structured way, which is not extensively validated
- Fine-tuning shows limited data efficiency, requiring careful dataset size selection to avoid overfitting
- The method struggles with negative preferences and lexical distraction, suggesting fundamental limitations in handling negation and compositional queries

## Confidence
- **High confidence**: Core methodology of using prototype descriptions as basis vectors is technically sound and implementation details are well-specified
- **Medium confidence**: Claim that ProtoSim outperforms existing methods is supported by results, but improvement margins vary significantly across datasets
- **Low confidence**: Generalization claim that fine-tuning on one perceptual modality transfers to others is weakly supported

## Next Checks
1. **Cross-modal transfer validation**: Test whether fine-tuning on taste + rocks + odour actually improves performance on a held-out perceptual domain compared to training only on that domain
2. **Ablation on dataset size**: Systematically vary the number of synthetic categories from 10 to 200+ and measure pairwise accuracy degradation/gains
3. **Negation and compositionality stress test**: Construct controlled dataset of queries with varying levels of negation complexity and measure performance drop from simple positive queries