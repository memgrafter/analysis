---
ver: rpa2
title: Agentic generative AI for media content discovery at the national football
  league
arxiv_id: '2510.07297'
source_url: https://arxiv.org/abs/2510.07297
tags:
- media
- content
- language
- agentic
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper describes an agentic generative AI system developed for
  the NFL to enable natural language search of historical game footage. The system
  translates user queries into structured database API calls using LLM-based entity
  extraction, schema selection, and API formulation, with semantic caching to improve
  accuracy and latency.
---

# Agentic generative AI for media content discovery at the national football league

## Quick Facts
- arXiv ID: 2510.07297
- Source URL: https://arxiv.org/abs/2510.07297
- Reference count: 28
- Primary result: Agentic generative AI system achieves >95% accuracy for natural language video search, reducing NFL media search time from 10 minutes to 30 seconds

## Executive Summary
This paper presents an agentic generative AI system developed for the NFL to enable natural language search of historical game footage. The system translates user queries into structured database API calls using LLM-based entity extraction, schema selection, and API formulation, with semantic caching to improve accuracy and latency. The solution has been deployed across NFL media teams, enabling faster retrieval of relevant video content and allowing users to focus more on creative production. The system represents a significant advancement in media content discovery for sports organizations with large video archives.

## Method Summary
The agentic generative AI system employs a multi-stage approach to convert natural language queries into executable database API calls. The system uses large language models to extract entities from user queries, select appropriate database schemas, and formulate API calls. Semantic caching is implemented to store and reuse results from similar queries, improving both accuracy and latency. The system processes queries through a pipeline that includes natural language understanding, entity recognition, schema mapping, API generation, and result retrieval. The architecture is designed to handle the specific domain of NFL game footage, with custom training on football-related terminology and metadata structures.

## Key Results
- Achieved over 95% accuracy on a test set of 100 queries
- Reduced average search time from 10 minutes to 30 seconds
- Successfully deployed across NFL media teams for content discovery

## Why This Works (Mechanism)
The system works by leveraging the strengths of large language models in understanding natural language while maintaining the precision of structured database queries. The agentic approach allows the system to break down complex queries into actionable components, extract relevant entities, and map them to the appropriate database schema. Semantic caching provides significant performance improvements by storing results of similar queries, reducing redundant processing and database calls. The system's accuracy comes from the combination of LLM-based entity extraction with domain-specific training on NFL terminology and metadata structures, ensuring that the generated API calls accurately reflect user intent.

## Foundational Learning
- Entity extraction from natural language - why needed: To identify specific people, teams, events, and timeframes in user queries; quick check: Verify system correctly identifies entities like player names, team names, and game events
- Schema selection and mapping - why needed: To match extracted entities to appropriate database structures for accurate query formulation; quick check: Validate correct schema selection for various query types
- API call formulation - why needed: To convert natural language intent into executable database queries; quick check: Test generated API calls against sample database to ensure they return expected results
- Semantic caching mechanisms - why needed: To improve performance by reusing results from similar queries; quick check: Measure cache hit rates and performance improvements
- Domain-specific LLM training - why needed: To ensure system understands NFL-specific terminology and query patterns; quick check: Test system accuracy on queries with football-specific terminology

## Architecture Onboarding

Component map: User Query -> LLM Entity Extractor -> Schema Selector -> API Formulator -> Semantic Cache -> Database API -> Results

Critical path: User query processing through LLM components to database API call and result retrieval, with semantic caching providing potential shortcut for repeated queries.

Design tradeoffs: The system trades computational resources for improved accuracy and user experience, with semantic caching reducing latency at the cost of storage requirements. Domain-specific training improves accuracy but limits generalizability to other sports or content types.

Failure signatures: Common failures include incorrect entity extraction (especially with ambiguous player/team names), wrong schema selection for complex queries, API formulation errors when handling nested or conditional queries, and cache misses leading to slower response times.

First experiments to run:
1. Test entity extraction accuracy on a diverse set of 100 NFL-related queries with varying complexity
2. Measure cache hit rate and performance improvement by running repeated queries with slight variations
3. Evaluate system accuracy on edge cases including queries with ambiguous entities, incomplete information, or complex temporal relationships

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Limited generalizability beyond NFL's specific media archive and query patterns
- Lack of information about query complexity distribution and failure modes
- No quantification of semantic caching effectiveness (cache hit rates)
- No addressing of potential biases in historical footage database or handling of incomplete metadata

## Confidence
- High confidence in reported accuracy (95% on 100 test queries) and latency improvements (10 minutes to 30 seconds)
- Medium confidence in generalizability claims due to limited detail about query diversity
- Low confidence in behavioral claims about user productivity without supporting user studies

## Next Checks
1. Conduct an independent accuracy evaluation using a diverse set of 500+ queries spanning different game types, seasons, and query complexities
2. Perform A/B testing comparing user productivity (time spent on content discovery vs. creative tasks) before and after system deployment
3. Test the system's performance and accuracy when applied to a different sports organization's media archive with different schema and query patterns