---
ver: rpa2
title: 'CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer'
arxiv_id: '2512.02711'
source_url: https://arxiv.org/abs/2512.02711
tags:
- languages
- safety
- language
- multilingual
- low-resource
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CREST introduces a multilingual safety guardrail that supports
  100 languages using only 0.13% of the training data by clustering languages based
  on representational similarity in XLM-R embeddings and training on just 13 high-resource
  languages. It outperforms small-scale baselines and matches large-scale models on
  six safety benchmarks, achieving strong zero-shot transfer to low-resource languages.
---

# CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer

## Quick Facts
- arXiv ID: 2512.02711
- Source URL: https://arxiv.org/abs/2512.02711
- Authors: Lavish Bansal; Naman Mishra
- Reference count: 17
- Supports 100 languages with only 0.5B parameters by training on 13 high-resource languages

## Executive Summary
CREST introduces a multilingual safety guardrail that supports 100 languages using only 0.13% of the training data by clustering languages based on representational similarity in XLM-R embeddings and training on just 13 high-resource languages. It outperforms small-scale baselines and matches large-scale models on six safety benchmarks, achieving strong zero-shot transfer to low-resource languages. With 0.5B parameters, it runs 10x faster than models with ≥2.5B parameters, enabling real-time, on-device deployment. Evaluations on cultural safety datasets confirm robustness across linguistic and regional contexts, highlighting the effectiveness of cluster-guided cross-lingual transfer for scalable, inclusive safety alignment.

## Method Summary
CREST uses cluster-guided cross-lingual transfer via XLM-R embeddings to enable safety classification across 100 languages. Languages are clustered using K-Means on averaged sentence embeddings, and 13 high-resource languages (1-2 per cluster) are selected for fine-tuning. The model architecture is a standard XLM-RoBERTa encoder with a simple classification head. Training uses translated versions of the Aegis-AI dataset across the 13 languages. The approach achieves strong zero-shot performance on low-resource languages while maintaining parameter efficiency (0.5B parameters) and 10x faster inference than larger models.

## Key Results
- Achieves strong zero-shot transfer from 13 high-resource to 100 languages
- Matches or exceeds performance of models with ≥2.5B parameters while using only 0.5B parameters
- Runs 10x faster than larger models, enabling on-device deployment
- Demonstrates robust performance across cultural safety benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Cluster-Guided Cross-Lingual Transfer via Shared Representational Space
CREST generalizes safety classification from high-resource languages to low-resource languages by leveraging the shared representational space of XLM-R, where structurally or linguistically similar languages cluster together. The system computes sentence embeddings for a benchmark dataset translated into 100 languages using a pre-trained XLM-R model. It averages these embeddings to create a centroid per language. K-Means clustering (k=8) groups these centroids. A few high-resource languages (1-2) are selected from each cluster for fine-tuning. The hypothesis is that safety knowledge learned on a high-resource language will transfer effectively to other languages within the same cluster due to their representational proximity.

### Mechanism 2: Efficient Scaling via Strategic High-Resource Language Selection
By selecting a minimal but representative set of high-resource languages for training, the model avoids the "curse of multilinguality" and achieves high performance with a small parameter count (0.5B). CREST uses clusters derived from Mechanism 1 to select 13 representative high-resource languages (e.g., English, German from the Germanic cluster; Hindi, Tamil from the Indic cluster). This ensures broad coverage of the linguistic landscape represented by the 100 languages. The model is a standard XLM-RoBERTa (Base or Large) with a simple classification head, keeping the parameter count low.

### Mechanism 3: Generalization from Synthetic Translations
The model learns to generalize to low-resource languages despite being trained on a dataset created by translating a single high-resource dataset (Aegis-AI) into the 13 target high-resource languages. The Aegis-AI-Content-Safety-Dataset-2.0 is translated into the 13 selected high-resource languages using a combination of SOTA translation models. The model is fine-tuned on this aggregated, translated dataset. The assumption is that safety concepts are preserved across translation and that the XLM-R backbone, being pre-trained multilingual, can align these translated concepts with its internal representations of the target low-resource languages.

## Foundational Learning

**Cross-Lingual Transfer**
- Why needed here: The entire premise of CREST is that knowledge acquired from high-resource languages can be applied to low-resource languages without direct training on the latter.
- Quick check question: If a model is trained only on English data to detect insults, why might it also be able to detect insults in French with reasonable accuracy?

**Multilingual Encoders (specifically XLM-RoBERTa)**
- Why needed here: CREST is built on XLM-R. Its ability to map over 100 languages into a shared embedding space is the foundational capability enabling the cluster-based transfer mechanism.
- Quick check question: What property of a multilingual encoder's output allows us to compute a single distance metric (like cosine similarity) between sentences in different languages, such as English and Swahili?

**Clustering (K-Means)**
- Why needed here: The paper uses K-Means clustering to objectively group the 100 languages based on embedding similarity. Understanding this clarifies how the "strategic subset" of 13 training languages is chosen.
- Quick check question: In this paper, what is the data point that the K-Means algorithm clusters? Is it a single sentence, a whole language, or the entire training dataset?

## Architecture Onboarding

**Component map**: Input text -> Tokenizer (XLM-R tokenizer) -> XLM-RoBERTa Encoder -> `[CLS]` token hidden state -> Classification Head -> Softmax -> Binary Label (Safe/Unsafe)

**Critical path**: The critical design decisions are not in the architecture itself, but in the data pipeline: which languages are used for fine-tuning and how that training data is created.

**Design tradeoffs**:
- **Performance vs. Scale**: CREST uses a small model (0.5B params) vs. LLM-based guardrails (e.g., LlamaGuard3, 8B params). The tradeoff is potentially lower performance on complex inputs, but massive gains in inference speed and deployability on edge devices.
- **Native vs. Translated Data**: The authors chose machine-translated data over collecting native, human-annotated data for 13 languages. The tradeoff is scalability and speed vs. potential loss of cultural nuance and translation artifacts.
- **In-Domain vs. Out-of-Domain**: The model is explicitly trained on a specific subset of languages. The paper demonstrates transfer to Out-of-Domain languages, but performance may vary based on their cluster and the quality of the cluster's representative.

**Failure signatures**:
- **Poor performance on a specific low-resource language**: Diagnostic: Check its cluster assignment. Is the high-resource proxy language in that cluster performing well? If the proxy's performance is weak, transfer will likely be weak.
- **Over-refusal (flagging safe content as unsafe)**: Diagnostic: The training data (Aegis-AI) may have ambiguous labels, or translation may have altered tone. Results on XSTest indicate this is a known challenge.
- **Under-refusal on code-switched inputs**: Diagnostic: While CREST outperforms baselines on the CSRT benchmark, code-switching remains a difficult area. Failure here indicates a limitation in handling mixed-language contexts.

**First 3 experiments**:
1. **Baseline Validation**: Load the `repelloai/CREST-Base` model from HuggingFace. Evaluate it on the provided benchmarks (e.g., Aegis-CS2 test set, HarmBench) for the 13 training languages to confirm F1 scores reported in Table 2.
2. **Intra-Cluster Transfer Ablation**: Following section 6, fine-tune an XLM-R model on just one language from a cluster (e.g., Hindi) and evaluate its zero-shot performance on other languages within the same cluster (e.g., Tamil, Bengali) versus a language from a different cluster (e.g., French). This validates the core transfer assumption.
3. **Low-Resource Language Generalization Check**: Evaluate the pre-trained CREST model on the 11 Out-of-Domain low-resource languages listed in section 4. Compare its performance to a baseline multilingual model like DuoGuard-0.5B to quantify the advantage of the cluster-guided approach.

## Open Questions the Paper Calls Out

**Question 1**: Can lightweight generative LLMs provide superior contextualized safety modeling compared to the encoder-based architecture used in CREST?
- Basis in paper: The limitations section states the method "does not explicitly account for reasoning or contextual comprehension" and suggests future work explore "contextualized multilingual safety modeling using lightweight multilingual LLMs."
- Why unresolved: CREST relies on XLM-RoBERTa, an encoder-only model, which may lack the deep semantic reasoning required for complex safety judgments compared to generative models.

**Question 2**: To what extent does machine-translated training data degrade the detection of culturally specific or nuanced harm in low-resource languages?
- Basis in paper: The authors acknowledge in Section 9 that "machine-translated data can alter the original intent/tone of harmful content, potentially misrepresenting linguistic or cultural nuances critical for safety tasks."
- Why unresolved: While CREST performs well on translated benchmarks, it may fail to capture native idioms or context-specific threats that do not translate literally from English.

**Question 3**: Do clustering methods based on linguistic typology outperform the current embedding-based clustering for cross-lingual safety transfer?
- Basis in paper: The paper relies entirely on XLM-R embedding similarity for clustering, yet the analysis notes performance variances based on script and morphological complexity.
- Why unresolved: It is unclear if the "semantic similarity" captured by XLM-R is the optimal metric for grouping languages for safety transfer, versus structural typological features.

## Limitations

- Reliance on machine-translated training data may not capture cultural nuances and linguistic subtleties critical for safety detection
- Asymmetric transfer performance within clusters suggests not all high-resource proxy languages are equally effective representatives
- Under-refusal of harmful content on code-switched and culturally diverse inputs remains a challenge despite benchmark success

## Confidence

**High Confidence Claims**:
- CREST achieves strong zero-shot transfer from 13 to 100 languages (validated by Table 2 F1 scores)
- The model is parameter-efficient (0.5B vs 2.5B+ baselines) and inference speeds are ~10x faster (supported by experimental comparisons)
- Cluster-guided selection improves transfer efficiency compared to random language selection (shown in Table 6 ablation)

**Medium Confidence Claims**:
- Cluster-based transfer works "effectively" for both high-resource and low-resource languages (supported by results but limited by potential translation artifacts)
- The model is "culturally safe" (evaluated on UbuntuGuard but acknowledges ongoing challenges with under-refusal)

**Low Confidence Claims**:
- Claims about on-device deployment readiness are theoretical given the 0.5B parameter count, though no empirical edge device testing is reported

## Next Checks

1. **Translation Quality Audit**: Manually evaluate a sample of translated training data across 3 languages to assess whether safety labels are preserved during translation. Compare model performance when trained on original vs translated content for the same language.

2. **Cluster Transfer Asymmetry Investigation**: Systematically test transfer performance from each high-resource proxy to all other languages in its cluster. Measure whether certain language pairs show consistently poor transfer and analyze linguistic features (morphological complexity, script type) that might explain asymmetries.

3. **Real-World Robustness Test**: Deploy CREST on a live moderation platform with actual user-generated content in target low-resource languages. Measure precision/recall on true positives vs benchmark performance to quantify real-world degradation.