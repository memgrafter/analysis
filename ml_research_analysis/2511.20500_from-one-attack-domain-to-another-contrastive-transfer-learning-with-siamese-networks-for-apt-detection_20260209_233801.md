---
ver: rpa2
title: 'From One Attack Domain to Another: Contrastive Transfer Learning with Siamese
  Networks for APT Detection'
arxiv_id: '2511.20500'
source_url: https://arxiv.org/abs/2511.20500
tags:
- learning
- transfer
- feature
- detection
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a hybrid transfer learning framework for detecting
  Advanced Persistent Threats (APTs) across different attack domains. The method integrates
  explainable AI-guided feature selection using SHAP and entropy, an attention-based
  autoencoder for knowledge transfer, contrastive learning for feature space refinement,
  and a Siamese network for cross-domain feature alignment.
---

# From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection

## Quick Facts
- **arXiv ID:** 2511.20500
- **Source URL:** https://arxiv.org/abs/2511.20500
- **Reference count:** 40
- **Primary result:** Proposed hybrid transfer learning framework outperforms classical and deep learning baselines in cross-domain APT detection (nDCG, AUC metrics).

## Executive Summary
This paper introduces a hybrid transfer learning framework for detecting Advanced Persistent Threats (APTs) across different attack domains. The method integrates explainable AI-guided feature selection, an attention-based autoencoder for knowledge transfer, contrastive learning for feature space refinement, and a Siamese network for cross-domain feature alignment. Evaluated on real-world APT traces from the DARPA Transparent Computing program, augmented with synthetic attack scenarios, the approach consistently outperforms classical and deep learning baselines in both anomaly ranking and classification metrics across multiple operating systems and attack scenarios.

## Method Summary
The framework combines XAI-guided feature selection using SHAP and entropy, an attention-based autoencoder for knowledge transfer, contrastive learning for feature space refinement, and a Siamese network for cross-domain feature alignment. It is evaluated on real-world APT traces from the DARPA Transparent Computing program, augmented with synthetic attack scenarios generated via cGANs and VAEs. The approach demonstrates consistent outperformance against classical and deep learning baselines in anomaly ranking (nDCG) and classification (AUC) metrics across multiple operating systems and attack scenarios.

## Key Results
- The proposed method consistently outperforms classical and deep learning baselines in both anomaly ranking (nDCG) and classification (AUC) metrics.
- Statistical tests confirm the significance of the improvements across multiple operating systems (BSD, Windows, Linux, Android) and attack scenarios.
- The framework incorporates LLM-based explanations to provide interpretable insights into detected threats.

## Why This Works (Mechanism)

### Mechanism 1
XAI-guided feature selection improves transfer efficiency by retaining only stable, informative features across domains. A composite score S_j = α·RE_j + β·Ent_j + γ·SHAP_j ranks features by reconstruction error, entropy, and SHAP importance, with top-K features retained via cumulative contribution threshold. Core assumption: Features with high SHAP importance and reconstruction difficulty in source domain remain discriminative in target domain. Evidence: [abstract] states SHAP selects stable, informative features; ablation (P2 vs. P3) shows performance drops without XAI selection.

### Mechanism 2
Contrastive learning refines embeddings to improve anomaly separability across domains. InfoNCE loss pulls anchor-positive pairs closer and pushes anchor-negative pairs apart in latent space, with hard negative mining focusing on confusing pairs. Core assumption: Pseudo-labels from K-means clustering in source domain generalize to define "similar" behaviors in target. Evidence: [abstract] states Siamese encoder increases anomaly separability; Figure 2 visualizes before/after separation.

### Mechanism 3
Siamese network alignment mitigates feature drift by explicitly minimizing cross-domain embedding distances. Two identical subnetworks process source/target embeddings; Euclidean distance D is minimized for similar pairs and maximized for dissimilar pairs via contrastive loss with margin m=1.0. Core assumption: Domain-invariant similarity can be learned without target labels using cluster-based pseudo-labels. Evidence: [abstract] states Siamese network mitigates feature drift; Figure 10 shows improved cosine similarity separation post-alignment.

## Foundational Learning

- **Concept: Transfer Learning (Domain Adaptation)**
  - Why needed here: APT traces are scarce; models trained on one OS/attack scenario must generalize to others with different feature distributions.
  - Quick check question: Can you explain why minimizing P(X_s) ≠ P(X_t) degrades a model trained only on source data?

- **Concept: Contrastive Learning (Self-Supervised)**
  - Why needed here: Without abundant labels, the model must learn to separate anomalies from normals by relative similarity rather than absolute class boundaries.
  - Quick check question: How does InfoNCE loss differ from triplet loss in handling multiple negatives simultaneously?

- **Concept: Siamese Networks**
  - Why needed here: Provides an explicit distance metric between source and target embeddings, enabling cross-domain comparability without shared feature spaces.
  - Quick check question: Why must the two subnetworks share weights in a Siamese architecture?

## Architecture Onboarding

- **Component map:** Raw provenance logs → cGAN/VAE augmentation → Binary feature matrices → XAI feature selection (SHAP+Entropy+RE) → Top-K features → Attention-based Autoencoder → Latent embeddings Z_s, Z_t → Contrastive refinement → Refined embeddings → Siamese alignment → Aligned embeddings → Anomaly scorers (IF, OC-SVM, LOF, KNN, DBSCAN, AAE) → Scores

- **Critical path:** XAI selection → AAE pretraining on source → Fine-tune on target → Siamese alignment → Anomaly scoring. Breaks in feature selection or alignment cascade to downstream detectors.

- **Design tradeoffs:**
  - Higher ξ (e.g., 95%) retains more features but increases compute and may include noisy dimensions; lower ξ risks dropping discriminative features.
  - Larger margin m in Siamese loss enforces stricter separation but may reject valid cross-domain similarities.
  - Hard negative mining improves discrimination but adds O(M) pair sampling cost per epoch.

- **Failure signatures:**
  - P1 (no transfer) ≈ P3 (full transfer): Feature spaces already aligned; transfer unnecessary.
  - P3 nDCG/AUC lower than P0 (in-domain): Alignment overcorrects, erasing domain-specific signals.
  - Siamese distance D → 0 for all pairs: Margin m too small or pseudo-labels degenerate.

- **First 3 experiments:**
  1. Ablation by protocol: Run P0→P3 on a single OS (e.g., BSD PE) to isolate gains from XAI, contrastive, and Siamese components individually.
  2. Feature selection sensitivity: Vary ξ (60%, 80%, 95%) and measure nDCG/AUC vs. compute time on Windows PA.
  3. Cross-OS transfer stress test: Train on Linux (Scenario 1), test on Android (Scenario 2) with and without Siamese alignment to quantify drift mitigation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the integration of temporal sequence models (e.g., Transformers or RNNs) affect the framework's sensitivity to evolving APT stages compared to the current static feature approach?
- Basis in paper: [explicit] The Conclusion explicitly lists integrating temporal dynamics via sequence models as a necessary step to "enhance sensitivity to evolving APT stages."
- Why unresolved: The current architecture vectorizes process data into binary matrices, losing the sequential ordering and temporal dependencies of events.
- What evidence would resolve it: A comparative performance analysis (AUC/nDCG) on the DARPA TC datasets between the current AAE model and a time-aware variant (e.g., LSTM-AAE).

### Open Question 2
- Question: Can the proposed transfer learning framework be effectively adapted for decentralized environments where privacy constraints prohibit centralized training?
- Basis in paper: [explicit] The authors state they aim to "explore federated transfer learning for decentralized environments where privacy constraints prohibit centralized training."
- Why unresolved: The current framework assumes centralized access to source and target datasets to train the attention-based autoencoder and align Siamese networks.
- What evidence would resolve it: Implementation of a federated learning variant (e.g., FedAvg) showing comparable cross-domain generalization (transfer loss) without sharing raw data.

### Open Question 3
- Question: To what extent does the framework generalize when applied to non-binary feature representations and highly heterogeneous cross-OS datasets?
- Basis in paper: [explicit] The Conclusion identifies a need to "investigate cross-OS transfer learning using more heterogeneous datasets and non-binary feature representations."
- Why unresolved: The experimental evaluation relies strictly on binary-valued datasets derived from provenance graphs, potentially limiting applicability to continuous or unstructured telemetry data.
- What evidence would resolve it: Evaluation results on datasets containing continuous or categorical features, demonstrating that the XAI-guided selection and Siamese alignment still function effectively.

### Open Question 4
- Question: How sensitive is the model's performance to the specific weights (α, β, γ) assigned to SHAP, entropy, and reconstruction error during feature selection?
- Basis in paper: [inferred] The paper sets these weights to 0.5 by default and notes they are tunable, but provides no sensitivity analysis to determine if this equal weighting is optimal across different attack scenarios.
- Why unresolved: Without ablation studies on the feature selection weights, it remains unclear if prioritizing reconstruction error over SHAP (or vice versa) significantly alters the quality of the latent embeddings.
- What evidence would resolve it: A parameter sweep of the weight combinations showing the variance in nDCG and AUC scores.

## Limitations

- Synthetic data generation (cGAN/VAE) quality and realism for APT scenarios remain unverified against ground truth.
- The composite feature selection score weights (α, β, γ) are assumed equal without justification for optimal domain-specific tuning.
- Hard negative mining threshold and Siamese margin are empirically set without sensitivity analysis.

## Confidence

- **High confidence:** Transfer learning framework architecture, XAI feature selection methodology, and statistical significance of nDCG/AUC improvements.
- **Medium confidence:** Contrastive learning refinement benefits and Siamese alignment effectiveness across OS families.
- **Low confidence:** Synthetic APT scenario generation fidelity and LLM-based explanation accuracy.

## Next Checks

1. Conduct ablation studies varying ξ (60%, 80%, 95%) to quantify feature selection tradeoff between performance and computational cost.
2. Perform cross-OS transfer stress test (Linux→Android) with and without Siamese alignment to measure drift mitigation effectiveness.
3. Validate synthetic cGAN/VAE-generated APT traces against real attack patterns through expert review or detection consistency checks.