---
ver: rpa2
title: Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence
  and the Surprising Efficiency Paradox
arxiv_id: '2512.14717'
source_url: https://arxiv.org/abs/2512.14717
tags:
- financial
- performance
- accuracy
- across
- sentiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper benchmarks five large language models on ten financial
  NLP tasks, evaluating both accuracy and computational efficiency. The study reveals
  that GPT-OSS-20B achieves 97.9% of the accuracy of its 120B parameter counterpart
  while being 2.3x faster and using 83% less memory.
---

# Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox

## Quick Facts
- arXiv ID: 2512.14717
- Source URL: https://arxiv.org/abs/2512.14717
- Authors: Ziqian Bi; Danyang Zhang; Junhao Song; Chiung-Yi Tseng
- Reference count: 40
- Primary result: GPT-OSS-20B achieves 97.9% of 120B model accuracy while using 83% less memory and running 2.3x faster

## Executive Summary
This paper benchmarks five large language models across ten financial NLP tasks, revealing that smaller models can achieve near-parity with larger counterparts when optimized for domain-specific applications. The study introduces a Token Efficiency Score that captures the trade-off between model performance and resource utilization, challenging the conventional wisdom that model scale directly correlates with task performance. GPT-OSS models demonstrate superior efficiency compared to larger competitors like Qwen3-235B, suggesting that architectural innovations and domain-appropriate training can compensate for reduced parameter counts in financial applications.

## Method Summary
The study evaluates five large language models on ten standardized financial NLP tasks, measuring both accuracy and computational efficiency metrics including inference time and memory consumption. A novel Token Efficiency Score is introduced to quantify the trade-off between performance and resource utilization. The benchmarking framework tests models across various financial intelligence tasks including named entity recognition, sentiment analysis, and document classification. Comparative analysis examines the relationship between parameter count and task performance