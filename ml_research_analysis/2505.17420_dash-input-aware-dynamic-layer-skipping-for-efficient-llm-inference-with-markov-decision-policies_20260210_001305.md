---
ver: rpa2
title: 'DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with
  Markov Decision Policies'
arxiv_id: '2505.17420'
source_url: https://arxiv.org/abs/2505.17420
tags:
- layer
- skipping
- layers
- accuracy
- dash
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DASH addresses the high computational cost of large language model
  inference by introducing an adaptive layer-skipping framework that dynamically selects
  computation paths based on input characteristics. The core method models layer skipping
  as a Markov Decision Process, enabling token-level decisions using intermediate
  representations.
---

# DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies

## Quick Facts
- arXiv ID: 2505.17420
- Source URL: https://arxiv.org/abs/2505.17420
- Authors: Ning Yang; Fangxin Liu; Junjie Wang; Tao Yang; Kan Liu; Haibing Guan; Li Jiang
- Reference count: 6
- One-line primary result: Dynamic layer skipping via MDP policies achieves 1.33× speedup on LLaMA-2-7B while maintaining 69.7% MMLU accuracy

## Executive Summary
DASH addresses the high computational cost of large language model inference by introducing an adaptive layer-skipping framework that dynamically selects computation paths based on input characteristics. The core method models layer skipping as a Markov Decision Process, enabling token-level decisions using intermediate representations. To preserve accuracy, DASH incorporates a lightweight compensation mechanism that injects differential rewards into the decision process and uses asynchronous execution to overlap layer computation with policy evaluation. Experiments on multiple LLM architectures show DASH achieves significant inference acceleration while maintaining competitive task performance, outperforming existing methods across benchmarks like MMLU and CNN/DM.

## Method Summary
DASH formulates dynamic layer skipping as a Markov Decision Process with token-level decisions. The method uses a scoring MLP that takes as input the current hidden state, layer embeddings for current and next layers, and outputs a state-action value. Three execution modes are available: skip with input scaling, INT4/INT8 quantization, or full FP16 computation. First and last layers are always executed in FP16. The system trains using a combined cross-entropy and policy-gradient loss with differential rewards that account for accuracy and efficiency trade-offs. During inference, asynchronous execution overlaps computation of layer i with decision-making for layer i+1 using scaled approximations.

## Key Results
- DASH maintains 69.7% accuracy on MMLU at 1.33× speedup compared to 56.4% for early-exit methods
- Achieves 1.67× and 2.0× speedups on CNN/DM summarization while preserving Rouge-L scores
- Outperforms existing layer-skipping approaches across multiple benchmarks and speed targets

## Why This Works (Mechanism)
The method works by learning input-aware policies that dynamically select between skipping, quantization, or full computation based on token characteristics. The MDP formulation with differential rewards allows the system to optimize the trade-off between computational efficiency and accuracy preservation. Asynchronous execution hides decision latency, making the approach practical for real-time inference.

## Foundational Learning
- **Markov Decision Process formulation**: Needed to model sequential layer-skipping decisions with state transitions. Quick check: Verify state transitions follow the defined policy and produce valid sequences of execution modes.
- **Differential reward mechanism**: Needed to balance accuracy preservation against computational efficiency during training. Quick check: Confirm reward calculation incorporates both ω_i scaling and efficiency terms correctly.
- **Asynchronous execution**: Needed to overlap policy evaluation with layer computation to avoid latency overhead. Quick check: Measure actual inference time and verify async execution provides expected speedup gains.

## Architecture Onboarding
- **Component map**: Input tokens -> Hidden states -> Scoring MLP (with layer embeddings) -> State selection (skip/quantize/full) -> Execution mode -> Output
- **Critical path**: Token generation requires sequential execution of layers with embedded decision points; first and last layers always use FP16
- **Design tradeoffs**: Skip+scale mode trades accuracy for speed via input scaling compensation; INT4/INT8 modes provide middle ground; FP16 ensures accuracy-critical layers are preserved
- **Failure signatures**: Accuracy collapse at high speedup targets indicates insufficient compensation; conservative skipping in early layers suggests low I/O similarity detection; unstable decisions indicate temperature or reward weight issues
- **3 first experiments**: 1) Verify layer-wise scale factors computed correctly on calibration data, 2) Test single-layer skip decision accuracy, 3) Validate asynchronous execution timing with synthetic workloads

## Open Questions the Paper Calls Out
None

## Limitations
- Missing critical hyperparameters (α, τ₀, λ, β, ε, MLP dimensions) prevent exact replication
- Unclear training specifics including learning rate, batch size, and whether base LLM is frozen
- Quantization implementation details for INT4/INT8 layers not specified, potentially affecting consistency

## Confidence
- **High Confidence**: MDP formulation for token-level decisions, asynchronous execution mechanism
- **Medium Confidence**: Overall experimental results and reported speedups (1.33×, 1.67×, 2.0×)
- **Low Confidence**: Precise accuracy metrics (e.g., 69.7% MMLU at 1.33× speedup)

## Next Checks
1. Perform grid search over α, τ₀, and λ to find hyperparameter settings achieving target speedups while maintaining accuracy within 5% of baseline
2. Validate INT4/INT8 quantization consistency across different libraries and confirm per-layer scale factors are correctly applied
3. Log skip rates per layer during inference to verify asynchronous execution doesn't cause over-conservative skipping in early layers due to low I/O similarity