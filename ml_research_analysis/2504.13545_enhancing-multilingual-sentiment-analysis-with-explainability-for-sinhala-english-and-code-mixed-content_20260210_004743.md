---
ver: rpa2
title: Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala,
  English, and Code-Mixed Content
arxiv_id: '2504.13545'
source_url: https://arxiv.org/abs/2504.13545
tags:
- sentiment
- sinhala
- english
- banking
- mixed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research addresses the challenge of multilingual sentiment
  analysis for Sinhala, English, and code-mixed content in banking, particularly for
  low-resource languages. The authors developed a hybrid aspect-based sentiment analysis
  framework combining BERT-base-uncased for English, XLM-RoBERTa with domain-specific
  lexicon correction for Sinhala and code-mixed text, and integrated SHAP and LIME
  for explainability.
---

# Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content

## Quick Facts
- **arXiv ID:** 2504.13545
- **Source URL:** https://arxiv.org/abs/2504.13545
- **Reference count:** 0
- **Primary result:** 92.3% accuracy and F1-score of 0.89 for English, 88.4% accuracy and 0.84 F1-score for Sinhala and code-mixed banking sentiment analysis with SHAP/LIME explainability

## Executive Summary
This research addresses multilingual sentiment analysis for low-resource languages (Sinhala, English, and code-mixed) in banking contexts. The authors developed a hybrid aspect-based sentiment analysis framework combining BERT-base-uncased for English, XLM-RoBERTa with domain-specific lexicon correction for Sinhala and code-mixed text, and integrated SHAP and LIME for explainability. The system achieved strong performance metrics while providing interpretable sentiment insights for real-world financial applications.

## Method Summary
The authors developed a hybrid aspect-based sentiment analysis framework using BERT-base-uncased for English content and XLM-RoBERTa with domain-specific lexicon correction for Sinhala and code-mixed text. They integrated SHAP and LIME for model explainability, evaluating the system on 15,000 banking customer reviews. The approach addresses the challenge of low-resource languages by combining transformer models with specialized lexicon correction techniques.

## Key Results
- Achieved 92.3% accuracy and F1-score of 0.89 for English sentiment analysis
- Achieved 88.4% accuracy and F1-score of 0.84 for Sinhala and code-mixed content
- Integrated SHAP and LIME explainability tools providing interpretable sentiment insights

## Why This Works (Mechanism)
The hybrid approach combines the strengths of language-specific transformer models (BERT for English, XLM-RoBERTa for Sinhala/code-mixed) with domain-specific lexicon correction to address the unique challenges of low-resource languages. The explainability tools (SHAP and LIME) provide interpretable insights into sentiment predictions, improving transparency and trust for financial applications where understanding decision rationale is critical.

## Foundational Learning
- **Multilingual transformer models (BERT, XLM-RoBERTa)**: Why needed - to capture language-specific linguistic patterns and semantic relationships; Quick check - validate model performance on monolingual test sets before multilingual evaluation
- **Domain-specific lexicon correction**: Why needed - to address vocabulary and context specific to banking domain; Quick check - verify lexicon coverage across different banking subdomains (loans, accounts, services)
- **Aspect-based sentiment analysis**: Why needed - to identify specific features or aspects being reviewed rather than just overall sentiment; Quick check - ensure aspect extraction aligns with domain-relevant features
- **SHAP and LIME explainability**: Why needed - to provide interpretable insights into model predictions for stakeholder trust; Quick check - validate that explanations are meaningful to domain experts in banking context
- **Code-mixed language handling**: Why needed - to process content where Sinhala and English are mixed within single reviews; Quick check - test on pure Sinhala, pure English, and varying degrees of code-mixing
- **Low-resource language adaptation**: Why needed - to build effective models despite limited training data for Sinhala; Quick check - compare performance with and without lexicon correction

## Architecture Onboarding

**Component Map:**
Data Preprocessing -> Language Detection -> Model Selection (BERT/XLM-RoBERTa) -> Lexicon Correction -> Sentiment Classification -> Explainability (SHAP/LIME)

**Critical Path:**
Raw review text → Language detection → Appropriate transformer model → Domain lexicon correction → Sentiment prediction → SHAP/LIME explanation generation

**Design Tradeoffs:**
- Specialized models per language vs. unified multilingual model
- Domain-specific lexicon vs. general vocabulary
- Black-box models with post-hoc explainability vs. inherently interpretable models
- Aspect-level vs. document-level sentiment analysis

**Failure Signatures:**
- Poor performance on code-mixed content indicating lexicon correction gaps
- Uninterpretable SHAP/LIME outputs suggesting feature importance issues
- Domain vocabulary misclassification indicating lexicon coverage limitations
- Language detection errors causing wrong model selection

**First Experiments:**
1. Test language detection accuracy on mixed-language reviews
2. Validate lexicon correction effectiveness on domain-specific terms
3. Compare explainability outputs between SHAP and LIME for consistency

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size of 15,000 reviews may not adequately represent all language variants and sentiment distributions
- Domain-specific lexicon correction approach may not generalize beyond banking contexts
- Explainability outputs (SHAP/LIME) were not validated for interpretability by domain experts or end users

## Confidence
- **High Confidence**: General methodology combining multilingual transformers with explainability tools is well-established and accuracy ranges are plausible
- **Medium Confidence**: Specific performance numbers are internally consistent but would benefit from additional validation on independent datasets
- **Medium Confidence**: Explainability implementation using SHAP and LIME is technically sound, but actual utility for Sinhala language content requires further validation

## Next Checks
1. Conduct cross-domain validation by testing the model on non-banking Sinhala, English, and code-mixed content to assess generalizability
2. Perform ablation studies comparing the hybrid approach against a unified multilingual model (mBERT or XLM-RoBERTa fine-tuned on all three language variants)
3. Implement a user study with banking domain experts to validate that SHAP and LIME explanations are interpretable and useful for decision-making in the Sinhala language context