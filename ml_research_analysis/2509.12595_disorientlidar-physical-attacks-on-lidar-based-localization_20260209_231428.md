---
ver: rpa2
title: 'DisorientLiDAR: Physical Attacks on LiDAR-based Localization'
arxiv_id: '2509.12595'
source_url: https://arxiv.org/abs/2509.12595
tags:
- attack
- registration
- point
- attacks
- lidar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DisorientLiDAR, a novel adversarial attack
  framework targeting LiDAR-based localization in autonomous vehicles. The core method
  identifies critical keypoints in point cloud registration models and physically
  removes them using near-infrared absorbing materials to degrade localization accuracy.
---

# DisorientLiDAR: Physical Attacks on LiDAR-based Localization

## Quick Facts
- arXiv ID: 2509.12595
- Source URL: https://arxiv.org/abs/2509.12595
- Reference count: 40
- Authors successfully demonstrate physical attack degrading LiDAR localization accuracy by >50% in registration recall across multiple models

## Executive Summary
This paper introduces DisorientLiDAR, a novel adversarial attack framework targeting LiDAR-based localization in autonomous vehicles. The core method identifies critical keypoints in point cloud registration models and physically removes them using near-infrared absorbing materials to degrade localization accuracy. The attack is evaluated on three state-of-the-art registration models (HRegNet, D3Feat, GeoTransformer) using the KITTI dataset, showing significant degradation in registration accuracy when removing top-K keypoints. In real-world scenarios, the attack induces noticeable localization drift in the Autoware autonomous driving platform. Physical attacks using near-infrared absorptive materials successfully replicated the observed effects in KITTI data, demonstrating the attack's practicality and effectiveness across different LiDAR configurations (64-line, 128-line, and 16-line).

## Method Summary
The attack methodology consists of four stages: First, extract keypoints and confidence scores from pre-trained registration models (HRegNet, D3Feat, GeoTransformer) using input point clouds. Second, select Top-K keypoints with highest contribution scores using min-max normalization. Third, simulate region removal by filtering points within radius L of selected keypoints. Fourth, implement physical occlusion using VL Flock Sheet (>95% NIR absorption at Î»<2200nm) to block LiDAR returns. The attack targets critical geometric features by covering them with NIR-absorbing material, creating voids in the point cloud that disrupt registration accuracy. Four-stage filtering ensures only relevant high-altitude features are targeted, with ambush placement 1m ahead of target locations.

## Key Results
- Registration Recall (RR) degrades by >50% when removing Top-1% keypoints from HRegNet and D3Feat models
- Physical deployment using VL Flock Sheet successfully occludes objects in real-world scenarios, reducing point counts to zero in covered regions
- Localization drift observed in Autoware platform: noticeable trajectory deviation before GPS correction when critical regions are hidden
- Attack remains effective across different LiDAR configurations (VLP-16, VLS-128) with consistent performance degradation

## Why This Works (Mechanism)

### Mechanism 1: Saliency-Based Key Region Collapse
The attack reverse-engineers target models to generate registration saliency maps, identifying and physically occluding Top-K keypoints with highest confidence scores. This forces registration solvers to rely on sub-optimal correspondences, maximizing transformation error. Core assumption: target localization depends heavily on sparse high-confidence geometric correspondences. Break condition: dense keypoint-free approaches or aggressive outlier rejection diminish effectiveness.

### Mechanism 2: Spectral Occlusion via NIR Absorption
VL Flock Sheet material absorbs >95% of 905nm LiDAR light, creating "voids" in point cloud data by preventing returns. Core assumption: LiDAR relies solely on reflected light intensity at 905nm without supplemental sensing. Break condition: multi-sensor fusion (camera-LiDAR) or thermal/mmWave radar detects the occlusion.

### Mechanism 3: Trajectory Drift via Registration Error Propagation
Inducing significant relative pose error in single frames leads to persistent trajectory drift through sequential registration. Core assumption: system lacks immediate high-confidence fallback that overrides LiDAR-based registration errors instantly. Break condition: perfect RTK-GPS coverage where LiDAR is negligible in sensor fusion Kalman filter.

## Foundational Learning

- **Point Cloud Registration (Scan Matching):** Core target process where algorithms align two point clouds by minimizing distance error. Understanding ICP vs feature-based methods reveals why removing keypoints breaks alignment.
  - Quick check: How does ICP differ from feature-based methods like HRegNet in terms of robustness to outliers?

- **Adversarial Saliency Maps:** Method to identify which points matter by calculating gradient or confidence score relative to model's loss function. Understanding this reveals attack's targeting mechanism.
  - Quick check: In classification, does high saliency mean feature is necessary for correct classification or merely correlated?

- **LiDAR Return Intensity and Materials:** Explains why certain materials fail to return LiDAR pulses. Understanding this reveals why NIR-absorbing sheets work as physical occluders.
  - Quick check: Why does LiDAR wavelength (905nm vs 1550nm) matter when selecting occluding material?

## Architecture Onboarding

- **Component map:** LiDAR Simulator -> Top-K Selector -> Physical Occluder (NIR Sheet) -> Victim Stack: LiDAR Sensor -> Pre-processor -> Feature Extractor (DNN) -> Matcher (RANSAC/SVD) -> Pose Estimator

- **Critical path:** Physical occluder placement must align with LiDAR's Field of View and specific frame's Saliency Map

- **Design tradeoffs:**
  - Targeting: Top-K (max damage but requires model knowledge) vs. Rand-K (model-agnostic but lower success rate)
  - Stealth: Large sheets (more effective) vs. small patches (harder to detect)

- **Failure signatures:**
  - Defender View: Sudden geometric "voids" or point density drops in structurally significant areas
  - Model View: Spikes in Relative Translation Error (RTE) or Relative Rotation Error (RRE) exceeding RTE > 0.3m thresholds

- **First 3 experiments:**
  1. Digital Ablation Study: Run KITTI through HRegNet/D3Feat, compare registration recall when removing Top-1% vs 1% random points
  2. Material Absorption Test: Place VLP-16 LiDAR in front of traffic pole, cover with VL Flock Sheet, verify point count drops to zero in RViz
  3. Closed-Loop Simulation: In Autoware, simulate vehicle driving past hidden region, monitor ndt_pose vs gnss_pose drift delta

## Open Questions the Paper Calls Out

### Open Question 1
Can a unified saliency model be developed to identify universally high-contribution keypoints across heterogeneous registration architectures to enable transferable physical attacks? The paper states future work to "propose a model that can select universally high-contribution keypoints among different registration models" to reduce field deployment labor. This remains unresolved as current attacks require model-specific keypoint extraction.

### Open Question 2
How effective are multi-sensor fusion defenses at detecting NIR-absorbing occlusions in real-world scenarios? The paper proposes sensor-level defenses like Vision-LiDAR consistency checks but provides no quantitative evaluation against DisorientLiDAR. This theoretical concept requires empirical testing of detection rates and false positives.

### Open Question 3
To what extent does the attack remain effective in black-box settings where adversary doesn't know target model? The paper assumes model knowledge and identifies dependency on model-specific keypoints as practical constraint. Black-box transferability of saliency maps to unknown architectures remains unverified.

## Limitations
- Attack effectiveness depends on knowing target model architecture to generate saliency maps
- Physical deployment stealth not extensively evaluated against human operators or camera-based monitoring
- Environmental robustness (rain, fog, snow) that degrade LiDAR performance not evaluated

## Confidence
- **High Confidence:** NIR absorption disrupting LiDAR point clouds and basic registration error propagation
- **Medium Confidence:** Saliency-based keypoint selection works for tested models but generalizability needs validation
- **Medium Confidence:** Physical implementation achieves claimed occlusion effects, but long-term durability requires verification

## Next Checks
1. Cross-model transferability test: Evaluate attack success when saliency map from Model A is applied to attack Model B (HRegNet saliency targeting D3Feat)
2. Multi-sensor fusion resilience test: Implement camera-based detection system for NIR occlusions, measure localization recovery when attack is detected
3. Environmental degradation analysis: Test attack effectiveness across varying weather conditions (rain, fog, snow) at different intensities, measuring registration accuracy degradation vs baseline conditions