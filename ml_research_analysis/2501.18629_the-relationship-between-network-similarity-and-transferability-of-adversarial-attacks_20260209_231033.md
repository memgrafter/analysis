---
ver: rpa2
title: The Relationship Between Network Similarity and Transferability of Adversarial
  Attacks
arxiv_id: '2501.18629'
source_url: https://arxiv.org/abs/2501.18629
tags:
- similarity
- attacks
- network
- networks
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between network similarity
  and the transferability of adversarial attacks. Using Centered Kernel Alignment
  (CKA) to measure similarity across torchvision models, the authors find that networks
  exhibit moderate overall similarity, with more complex architectures like DenseNet
  showing lower similarity scores.
---

# The Relationship Between Network Similarity and Transferability of Adversarial Attacks

## Quick Facts
- **arXiv ID:** 2501.18629
- **Source URL:** https://arxiv.org/abs/2501.18629
- **Reference count:** 40
- **Primary result:** Network similarity measured via CKA can predict adversarial transferability with >90% accuracy for specific attack types using DecisionTreeRegressor

## Executive Summary
This paper investigates the relationship between neural network similarity and adversarial attack transferability using Centered Kernel Alignment (CKA) and a novel Diagonal Box Similarity (DBS) metric. The authors find that networks with more complex architectures like DenseNet exhibit lower similarity scores compared to simpler networks like VGG. Their key finding is that a DecisionTreeRegressor can predict the success rate of transferred adversarial attacks with over 90% accuracy for black-box and Carlini & Wagner attacks, suggesting that network similarity metrics can be useful predictors under specific conditions.

## Method Summary
The study uses 20 pre-trained torchvision CNN models and computes CKA similarity and DBS scores between all model pairs using activations from identical input batches. Adversarial attacks from ART are generated on source models and evaluated for success on target models to measure transferability. A DecisionTreeRegressor is trained on features including similarity scores and layer counts to predict transferred attack success rates, with results showing high accuracy for certain attack types but poor performance for others.

## Key Results
- Networks with complex architectures (DenseNet) show lower similarity scores compared to simpler architectures (VGG)
- DecisionTreeRegressor achieves >90% accuracy in predicting transferred attack success for black-box and C&W attacks
- Transfer success rates vary significantly across attack types, with complex networks showing higher vulnerability
- Layer similarity is highest for basic layers (DataParallel, Dropout, Conv2d) and decreases with architectural complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representational similarity measured via CKA correlates with adversarial transferability under specific attack conditions
- Mechanism: CKA compares activation-pattern similarity matrices across networks processing identical inputs. Higher similarity implies shared decision boundaries, which may cause perturbations effective on one model to generalize to another
- Core assumption: Similar internal representations imply similar gradient directions or decision boundaries exploitable by transferred attacks
- Evidence anchors: [abstract] mentions correlation between CNNs and adversarial attacks; [section 4.5.2] shows DecisionTreeRegressor achieves MSE close to zero for black-box and C&W attacks
- Break condition: If target network uses significantly different training data, normalization, or task objective, CKA similarity may not predict transferability

### Mechanism 2
- Claim: Architectural complexity reduces network similarity but increases vulnerability to transferred attacks
- Mechanism: Complex architectures (e.g., DenseNet with DenseBlocks) create distinctive internal representations that lower CKA scores against simpler models. However, their larger parameter space and more numerous decision boundaries provide more "attack surfaces" where transferred perturbations can succeed
- Core assumption: Transferability depends on both representational overlap and architectural susceptibility; these factors can operate in opposing directions
- Evidence anchors: [section 4.1] shows DenseNet models consistently have lower similarity scores; [section 4.4] shows RegNet_X_32GF has highest mean success rate
- Break condition: If complexity is achieved via regularization techniques that smooth decision boundaries, vulnerability may not increase

### Mechanism 3
- Claim: Layer-position alignment matters more than overall network similarity for transfer prediction
- Mechanism: Early layers extract common low-level features (edges, textures); final layers converge to similar classification structures. The Diagonal Box Similarity (DBS) metric focuses on positionally-aligned layers, yielding better differentiation than whole-network CKA
- Core assumption: Layers at similar depths perform functionally analogous operations across architectures, making their similarity more predictive of attack transfer
- Evidence anchors: [section 4.2] shows first layers consistently have highest similarity scores; [section 4.3] shows DBS scores range from 0.40 to 0.75 while CKA scores range from 0.32 to 0.57
- Break condition: If networks have fundamentally different depth-to-function mappings, positional alignment becomes misleading

## Foundational Learning

- **Concept: Centered Kernel Alignment (CKA)**
  - Why needed here: Core metric for measuring representational similarity between networks; understanding how it captures nonlinear relationships is essential for interpreting results
  - Quick check question: Given two networks with CKA=0.45, can you explain what this means about their activation patterns?

- **Concept: Adversarial Transferability**
  - Why needed here: The central phenomenon being studied; distinguishes white-box (gradient-access) from black-box (query-only) scenarios and targeted vs. non-targeted attacks
  - Quick check question: Why might an attack crafted on AlexNet transfer better to other networks than one crafted on RegNet_X_32GF?

- **Concept: Decision Tree Regression for Prediction**
  - Why needed here: The practical tool demonstrating predictability; understanding feature-importance and overfitting risks is crucial for deployment
  - Quick check question: The decision tree achieves >90% accuracy on black-box attacks but ~3% on white-box attacks—what does this suggest about the underlying relationship?

## Architecture Onboarding

- **Component map:** CKA computation module -> DBS extraction module -> Attack generation pipeline -> Transfer evaluation framework -> Prediction model
- **Critical path:** Select torchvision model pairs -> Extract activations for identical input batch -> Compute CKA/DBS scores -> Generate adversarial examples on source model -> Evaluate attack success on target model -> Fit DecisionTreeRegressor on similarity features
- **Design tradeoffs:** Box size in DBS (size 5 balances range vs. specificity); Attack subset selection (black-box and C&W attacks are predictable, FGSM/PGD show high variance); Layer count threshold (architectural family matters more than size)
- **Failure signatures:** Predictions fail on white-box attacks (accuracy ~3%)—these exploit gradient access; High standard deviation in transfer success (>15%) indicates unreliable prediction; DenseNet consistently shows low similarity regardless of pairing
- **First 3 experiments:** 1) Reproduce CKA heatmap for 5 torchvision models and verify similarity range matches paper (0.32–0.57); 2) Train DecisionTreeRegressor on black-box attacks only with 80/20 split and confirm accuracy threshold (73% non-targeted, 96% targeted); 3) Ablate DBS box sizes (1, 5, 15, 50) on same attack subset and compare prediction accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- High variance in prediction accuracy across different data subsets (>15% standard deviation) suggests reliability is context-sensitive
- Performance drops dramatically for white-box attacks (~3% accuracy) versus black-box attacks (>90% accuracy)
- Unspecified dataset details and attack hyperparameters could significantly impact reproducibility

## Confidence
- **Claim:** CKA similarity can predict adversarial transferability → **Medium confidence** (high accuracy for specific attack types but not universal)
- **Claim:** Complex architectures are more vulnerable to transferred attacks → **Medium confidence** (supported by results but mechanism unclear)
- **Claim:** DecisionTreeRegressor can reliably predict transfer success → **Low confidence** (high variance across subsets and attack types)

## Next Checks
1. Reproduce CKA similarity matrix for 5 torchvision models and verify the 0.32-0.57 range matches paper results
2. Train DecisionTreeRegressor on black-box attacks only with 80/20 split to confirm accuracy thresholds (73% non-targeted, 96% targeted)
3. Ablate DBS box sizes (1, 5, 15, 50) on the same attack subset to identify optimal configuration for prediction accuracy