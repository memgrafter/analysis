---
ver: rpa2
title: Optimal Interactive Learning on the Job via Facility Location Planning
arxiv_id: '2505.00490'
source_url: https://arxiv.org/abs/2505.00490
tags:
- human
- coil
- cost
- robot
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: COIL addresses the problem of minimizing human effort during multi-task
  human-robot collaboration by strategically planning when to learn new skills, request
  preferences, or ask for human assistance. The core method formulates interactive
  learning as an uncapacitated facility location problem, enabling bounded-suboptimal
  planning in polynomial time.
---

# Optimal Interactive Learning on the Job via Facility Location Planning

## Quick Facts
- arXiv ID: 2505.00490
- Source URL: https://arxiv.org/abs/2505.00490
- Authors: Shivam Vats; Michelle Zhao; Patrick Callaghan; Mingxi Jia; Maxim Likhachev; Oliver Kroemer; George Konidaris
- Reference count: 40
- Optimal Interactive Learning on the Job via Facility Location Planning

## Executive Summary
This paper addresses the problem of minimizing human effort during multi-task human-robot collaboration by strategically planning when to learn new skills, request preferences, or ask for human assistance. The authors propose COIL (Conditional Interactive Learning), which formulates interactive learning as an uncapacitated facility location problem, enabling bounded-suboptimal planning in polynomial time. The method extends this formulation to handle preference uncertainty through one-step belief space planning, allowing the robot to adapt its learning strategy based on estimated skill learnability and teacher availability.

The core contribution is demonstrating that interactive learning can be cast as a facility location problem where skills are facilities and human teaching actions are clients. This formulation provides theoretical guarantees on planning efficiency while maintaining practical effectiveness. COIL's ability to dynamically decide between learning new skills, using learned skills with requested preferences, or seeking human assistance enables significant reductions in human effort while ensuring task completion. Experiments across gridworld, simulated manipulation, and real-world conveyor domains validate the approach, showing 12-23% reduction in human effort compared to baselines while maintaining task completion rates.

## Method Summary
COIL addresses the problem of minimizing human effort during multi-task human-robot collaboration by strategically planning when to learn new skills, request preferences, or ask for human assistance. The core method formulates interactive learning as an uncapacitated facility location problem, enabling bounded-suboptimal planning in polynomial time. COIL extends this formulation to handle preference uncertainty through one-step belief space planning. Experiments across gridworld, simulated manipulation, and real-world conveyor domains show COIL reduces human effort by 12%-23% compared to baselines while maintaining task completion, and adapts online to teaching failures by updating plans based on observed skill learnability.

## Key Results
- COIL reduces human effort by 12%-23% compared to baselines while maintaining task completion
- The facility location formulation enables bounded-suboptimal planning in polynomial time
- COIL successfully adapts online to teaching failures by updating plans based on observed skill learnability

## Why This Works (Mechanism)
The facility location formulation works because it captures the fundamental trade-off in interactive learning: investing human effort upfront to learn skills versus paying the cost of human assistance later. By treating skills as facilities and human teaching actions as clients, COIL can optimally balance these competing demands while respecting the temporal dependencies of task execution. The belief space extension handles uncertainty in skill learnability and teacher availability, allowing the system to plan robust strategies that hedge against teaching failures.

## Foundational Learning
- **Facility Location Problem**: A combinatorial optimization problem where facilities must be opened to serve clients at minimum cost, essential for modeling the trade-off between learning costs and assistance costs
- **Belief Space Planning**: Planning under uncertainty by maintaining probability distributions over states, necessary for handling uncertain skill learnability and teacher availability
- **Bounded-Suboptimal Planning**: Planning algorithms that guarantee solutions within a factor of optimal, crucial for ensuring computational tractability while maintaining solution quality
- **Multi-task Planning**: Coordinating multiple interdependent tasks, fundamental for realistic human-robot collaboration scenarios
- **Skill Learnability Estimation**: Predicting the probability of successful skill acquisition from human teaching, critical for adaptive planning

## Architecture Onboarding

Component Map:
Planner -> Skill Selector -> Preference Requester -> Human Assistant
         \       |           /               /
          \      |          /               /
           \     |         /               /
            \    |        /               /
             \   |       /               /
              \  |      /               /
               \ |     /               /
                \|    /               /
                 Skill Learner -> Human Teacher

Critical Path:
Task arrival -> Planner evaluates options -> Skill selection/creation -> Preference acquisition (if needed) -> Task execution -> Human assistance (if needed)

Design Tradeoffs:
- Learning new skills vs. using human assistance: upfront cost vs. ongoing cost
- Preference precision vs. learning time: high precision requires more teacher effort
- Planning horizon length vs. computational complexity: longer horizons enable better planning but increase computation

Failure Signatures:
- Consistently requesting human assistance indicates poor skill learnability estimates
- Frequent preference requests suggest insufficient skill learning
- Planning failures may indicate overly optimistic learnability assumptions

First Experiments:
1. Gridworld navigation with varying skill complexities to test basic formulation
2. Simulated pick-and-place with changing object configurations to evaluate preference handling
3. Real-world conveyor belt sorting with human teachers to validate in practical settings

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes known skill learnability probabilities that may not hold in real-world scenarios with varying teacher expertise
- Experiments focus on structured environments (gridworld, conveyor belt) that may not capture full complexity of real-world human-robot collaboration
- Bounded-suboptimal planning assumes perfect information about facility location problem formulation, but interactive settings require online learning of these parameters

## Confidence

High confidence: The theoretical formulation connecting facility location planning to interactive learning is sound and the polynomial-time complexity claims are well-established. The experiments demonstrating reduced human effort compared to baselines are methodologically sound.

Medium confidence: The online adaptation mechanism for handling teaching failures is presented, but the experimental validation is limited to specific scenarios. The performance improvements (12-23%) are reported, but the statistical significance and variance across different conditions are not fully characterized.

Low confidence: The generalization of results to diverse real-world applications is uncertain given the controlled experimental conditions. The impact of partial observability and noisy human feedback on the learning system is not thoroughly evaluated.

## Next Checks

1. Conduct ablation studies to isolate the contribution of the facility location formulation from other components (preference modeling, online adaptation) to the observed performance improvements.

2. Test the system in more complex, unstructured environments with varying task types and durations to evaluate robustness and generalization beyond the current experimental domains.

3. Implement a real-world user study with diverse human teachers to validate the assumption of known skill learnability probabilities and assess the system's performance when these probabilities are uncertain or time-varying.