---
ver: rpa2
title: Attribution-guided Pruning for Compression, Circuit Discovery, and Targeted
  Correction in LLMs
arxiv_id: '2506.13727'
source_url: https://arxiv.org/abs/2506.13727
tags:
- pruning
- attribution
- wanda
- performance
- unstructured
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces a unified attribution-guided pruning framework
  for Large Language Models (LLMs) with three core applications: model compression,
  circuit discovery, and targeted model correction. The framework leverages Layer-wise
  Relevance Propagation (LRP) to identify and remove parameters based on their attributed
  importance, enabling fine-grained interventions without fine-tuning.'
---

# Attribution-guided Pruning for Compression, Circuit Discovery, and Targeted Correction in LLMs

## Quick Facts
- **arXiv ID:** 2506.13727
- **Source URL:** https://arxiv.org/abs/2506.13727
- **Reference count:** 40
- **Primary result:** Unified LRP-guided pruning framework for LLM compression, circuit discovery, and targeted correction without fine-tuning

## Executive Summary
This work introduces a unified attribution-guided pruning framework for Large Language Models (LLMs) with three core applications: model compression, circuit discovery, and targeted model correction. The framework leverages Layer-wise Relevance Propagation (LRP) to identify and remove parameters based on their attributed importance, enabling fine-grained interventions without fine-tuning. For compression, row-wise unstructured pruning achieves significant model size reduction with minimal performance loss. For circuit discovery, LRP effectively extracts sparse, task-relevant subgraphs—circuits—that explain specific model behaviors, such as indirect object identification. For model correction, the method suppresses undesired behaviors (e.g., toxic outputs or repetitive text generation) by pruning harmful components while preserving general capabilities.

## Method Summary
The framework uses Layer-wise Relevance Propagation (LRP) to compute attribution scores for each parameter in LLMs, identifying their contribution to specific outputs. These scores guide pruning decisions: parameters with low relevance are removed for compression, high-relevance parameters are retained for circuit discovery, and harmful parameters are pruned for targeted correction. The approach applies row-wise unstructured pruning, allowing removal of individual weights rather than entire neurons. Experiments span Llama and OPT models across various tasks, comparing LRP-based pruning against gradient-based and random baselines. The method demonstrates superior sparsity in circuit extraction and more effective behavioral suppression while maintaining general model capabilities.

## Key Results
- LRP-guided row-wise unstructured pruning achieves significant model size reduction with minimal performance degradation
- Circuit discovery yields sparser, more interpretable task-specific subgraphs compared to baseline methods
- Targeted correction effectively suppresses toxic outputs and repetitive text generation without requiring fine-tuning

## Why This Works (Mechanism)
The approach works by leveraging LRP's ability to backpropagate relevance scores from output to input, quantifying each parameter's contribution to specific behaviors. This attribution-guided pruning enables precise interventions: compressing by removing low-importance weights, discovering circuits by isolating high-importance task-specific parameters, and correcting by removing harmful components. The row-wise unstructured approach allows fine-grained pruning at the weight level rather than coarser neuron-level removal, preserving more model capacity while achieving desired modifications.

## Foundational Learning
- **Layer-wise Relevance Propagation (LRP):** Backpropagation technique that assigns relevance scores to input features or parameters based on their contribution to output predictions. Needed to identify which parameters matter most for specific behaviors. Quick check: Verify relevance scores sum to output value across all input features.
- **Unstructured pruning:** Weight-level removal rather than neuron/channel removal. Needed for fine-grained compression without losing entire functional units. Quick check: Confirm pruning ratio matches target sparsity while maintaining computational efficiency.
- **Circuit discovery in neural networks:** Identifying sparse subgraphs that explain specific model behaviors. Needed to understand how models implement particular tasks. Quick check: Verify extracted circuits are both sparse and functionally sufficient for target task.
- **Targeted behavioral correction:** Modifying specific model behaviors without affecting general capabilities. Needed for safety and alignment applications. Quick check: Measure both targeted behavior reduction and general capability preservation on held-out tasks.

## Architecture Onboarding

**Component map:** Input -> Embedding Layer -> Attention Blocks -> Feed-Forward Layers -> Output Layer -> LRP Attribution -> Pruning Mask

**Critical path:** The attribution computation through LRP followed by pruning mask application is critical, as errors here directly impact which parameters are removed and thus model behavior.

**Design tradeoffs:** Row-wise unstructured pruning offers fine-grained control but requires careful consideration of which weight statistics to use for attribution. The framework trades computational overhead of LRP attribution for more precise interventions compared to gradient-based methods.

**Failure signatures:** Over-aggressive pruning may cause catastrophic forgetting of general capabilities. Under-pruning fails to achieve desired compression or behavioral correction. Poor attribution quality leads to removing important parameters or keeping harmful ones.

**3 first experiments to run:**
1. Verify LRP attribution scores correctly identify known important parameters in a small toy model
2. Test row-wise pruning at various ratios (10%, 25%, 50%) on a held-out task to establish baseline behavior
3. Compare circuit sparsity and functionality between LRP-based and random pruning approaches

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- General applicability beyond tested Llama and OPT models remains uncertain
- Behavioral preservation claims need stronger validation across diverse failure modes
- Potential distributional shift effects from pruning are not addressed
- Long-form generation impacts of behavioral correction require further investigation

## Confidence

**Compression results:** High confidence - follows established unstructured pruning practices with clear performance retention
**Circuit discovery:** Medium confidence - compelling visualizations but limited to few investigated circuits
**Targeted correction:** Low-Medium confidence - promising results but not thoroughly validated across varied failure modes

## Next Checks
1. Test attribution-guided pruning on multilingual and multimodal LLMs to assess cross-domain robustness
2. Evaluate pruned models on out-of-distribution prompts to measure robustness to distributional shift
3. Perform ablation studies comparing LRP-based pruning to gradient-based and random baselines on tasks beyond those presented