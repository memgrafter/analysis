---
ver: rpa2
title: 'Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis
  of Methodologies'
arxiv_id: '2507.13875'
source_url: https://arxiv.org/abs/2507.13875
tags:
- language
- catalan
- speech
- data
- spanish
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work improves automatic speech recognition (ASR) for Catalan-Spanish
  code-switching, a task challenged by limited training data and linguistic similarities.
  We explore three strategies: generating synthetic CS data, concatenating monolingual
  audio, and leveraging real CS data with language tokens.'
---

# Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies

## Quick Facts
- arXiv ID: 2507.13875
- Source URL: https://arxiv.org/abs/2507.13875
- Reference count: 0
- We improve ASR for Catalan-Spanish code-switching using synthetic data generation and language token strategies, achieving WER as low as 14.48% on ParlamentParla.

## Executive Summary
This work addresses automatic speech recognition for Catalan-Spanish code-switching, a challenging task due to limited training data and linguistic similarities between the languages. The researchers explore three main strategies: generating synthetic code-switched data, concatenating monolingual audio, and using real code-switched data with language tokens. They extract code-switched data from Catalan speech corpora and fine-tune OpenAI's Whisper models, making their models available on Hugging Face. The study demonstrates that combining a modest amount of synthetic code-switched data with the dominant language token (<ca>) yields the best transcription performance.

## Method Summary
The researchers fine-tuned OpenAI's Whisper models on three different training approaches: synthetic code-switched data generation, concatenated monolingual audio, and real code-switched data with language tokens. They extracted code-switched data from Catalan speech corpora and created a pipeline to generate synthetic code-switched utterances. The models were evaluated on two parliamentary datasets - ParlamentParla and Corts Valencianes - using Word Error Rate (WER) as the primary metric. The study focused on determining the optimal combination of training data and language token strategies for code-switched ASR.

## Key Results
- Best performance achieved with 17 hours of synthetic CS data plus dominant language token (<ca>)
- WER of 14.48% on ParlamentParla and 16.38% on Corts Valencianes
- Outperforms models trained on 100 hours of concatenated speech or 4 hours of real CS data
- Synthetic approach proves especially effective with limited data

## Why This Works (Mechanism)
The success of the synthetic data approach stems from its ability to create controlled code-switching patterns that expose the model to realistic bilingual transitions while maintaining linguistic coherence. By using the dominant language token strategy, the model can better handle the asymmetrical distribution of language switches typical in code-switching speech. The synthetic generation process allows for systematic exploration of different code-switching densities and patterns that may be underrepresented in real data.

## Foundational Learning
**Code-switching patterns** - Understanding how languages alternate in bilingual speech is crucial for generating realistic synthetic data and designing appropriate language token strategies. Quick check: Analyze switch point distribution in target corpus.
**Language modeling for bilingual contexts** - Models must maintain separate language representations while handling transitions. Quick check: Test monolingual baseline performance on code-switched input.
**Data augmentation techniques** - Synthetic data generation requires understanding of both languages' phonetic and syntactic characteristics. Quick check: Compare synthetic vs real data feature distributions.

## Architecture Onboarding

Component map: Whisper encoder -> Transformer blocks -> Decoder with language token conditioning -> Output layer

Critical path: Audio input → Feature extraction → Cross-attention with language tokens → Language-specific decoding → Transcription output

Design tradeoffs: The study balances between model complexity (Whisper base vs large) and data efficiency, choosing synthetic data generation over collecting more real code-switched data due to scarcity.

Failure signatures: Poor handling of rapid language switches, confusion between similar-sounding words across languages, and degradation when encountering code-switching patterns not represented in training data.

First experiments:
1. Test monolingual Whisper performance on code-switched test sets
2. Evaluate impact of different language token combinations
3. Compare synthetic data generation with different switch densities

## Open Questions the Paper Calls Out
The paper identifies several areas requiring further investigation, particularly regarding the generalizability of the synthetic data generation approach across different language pairs and code-switching patterns. The effectiveness of synthetic data generation may depend heavily on the specific linguistic characteristics of the language pair and the quality of the synthetic generation pipeline. The study's exclusive focus on Catalan-Spanish limits broader applicability claims.

## Limitations
- Results may not generalize to other language pairs beyond Catalan-Spanish
- Focus on parliamentary speech limits applicability to conversational contexts
- Only tested with 17 hours of data, limiting scalability conclusions
- Synthetic data quality depends on generation pipeline robustness

## Confidence

High confidence:
- Synthetic data with dominant language token provides optimal performance for Catalan-Spanish parliamentary corpus
- Approach outperforms 100 hours of concatenated monolingual speech on tested datasets

Medium confidence:
- Scalability to larger datasets or different domains
- Cross-linguistic applicability of synthetic generation approach

## Next Checks
1. Test the synthetic data generation approach on additional language pairs (e.g., Hindi-English, Mandarin-English) to validate cross-linguistic applicability
2. Evaluate model performance on spontaneous conversational code-switching data outside the parliamentary domain
3. Conduct ablation studies varying the amount of synthetic data to determine optimal ratios for different training regimes