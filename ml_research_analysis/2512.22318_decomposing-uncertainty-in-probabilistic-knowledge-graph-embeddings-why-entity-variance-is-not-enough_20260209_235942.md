---
ver: rpa2
title: 'Decomposing Uncertainty in Probabilistic Knowledge Graph Embeddings: Why Entity
  Variance Is Not Enough'
arxiv_id: '2512.22318'
source_url: https://arxiv.org/abs/2512.22318
tags:
- entities
- uncertainty
- novel
- auroc
- contexts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a fundamental limitation in probabilistic
  knowledge graph embeddings: learned entity variances are relation-agnostic, meaning
  they cannot distinguish between emerging entities (rare, poorly-learned) and novel
  relational contexts (familiar entities in unobserved relationships). The authors
  prove that any uncertainty estimator using only entity-level statistics independent
  of relation context achieves near-random out-of-distribution (OOD) detection on
  novel contexts.'
---

# Decomposing Uncertainty in Probabilistic Knowledge Graph Embeddings: Why Entity Variance Is Not Enough

## Quick Facts
- arXiv ID: 2512.22318
- Source URL: https://arxiv.org/abs/2512.22318
- Authors: Chorok Lee
- Reference count: 16
- Primary result: Entity-level uncertainty is relation-agnostic and insufficient for OOD detection; structural uncertainty is required.

## Executive Summary
This paper reveals a fundamental limitation in probabilistic knowledge graph embeddings: learned entity variances cannot distinguish between emerging entities and novel relational contexts. The authors prove that uncertainty estimators using only entity-level statistics independent of relation context achieve near-random OOD detection on novel contexts. They propose CAGP (Co-occurrence Augmented Gaussian Processes), which decomposes uncertainty into semantic uncertainty (from entity embedding variance) and structural uncertainty (from entity-relation co-occurrence). CAGP achieves 0.94–0.99 AUROC on temporal OOD detection across multiple benchmarks, representing a 60–80% relative improvement over relation-agnostic baselines.

## Method Summary
The paper introduces CAGP (Co-occurrence Augmented Gaussian Processes), which combines semantic uncertainty from entity embedding variance with structural uncertainty from entity-relation co-occurrence. The method learns complementary uncertainty signals via weighted combination, where semantic uncertainty captures entity-specific uncertainty and structural uncertainty captures the novelty of entity-relation pairs. The framework addresses the fundamental limitation that entity variances are relation-agnostic, making them unable to distinguish between emerging entities and novel relational contexts. CAGP is validated across three datasets (FB15k-237, WN18RR, YAGO3-10) with empirical results showing substantial improvements in out-of-distribution detection.

## Key Results
- CAGP achieves 0.94–0.99 AUROC on temporal OOD detection across multiple benchmarks
- Represents 60–80% relative improvement over relation-agnostic baselines
- 100% of novel-context triples have frequency-matched in-distribution counterparts across datasets, confirming theoretical impossibility assumptions

## Why This Works (Mechanism)
The paper demonstrates that probabilistic knowledge graph embeddings suffer from relation-agnostic entity variances, which cannot distinguish between emerging entities (rare, poorly-learned) and novel relational contexts (familiar entities in unobserved relationships). The key insight is that uncertainty must be decomposed into semantic uncertainty (entity-specific) and structural uncertainty (entity-relation co-occurrence). By combining these complementary signals through learned weights, CAGP captures both the uncertainty inherent in entity embeddings and the novelty of specific entity-relation pairs, enabling effective OOD detection.

## Foundational Learning

**Probabilistic Knowledge Graph Embeddings** - Why needed: Foundation for understanding uncertainty in KG representations; Quick check: Can represent entities and relations as probability distributions.

**Out-of-Distribution Detection** - Why needed: Core task being evaluated; Quick check: Ability to distinguish test data from training distribution.

**Uncertainty Decomposition** - Why needed: Central theoretical contribution; Quick check: Understanding semantic vs structural uncertainty sources.

**Temporal Knowledge Graphs** - Why needed: Benchmark setting; Quick check: Time-evolving entity and relation dynamics.

## Architecture Onboarding

Component map: Entity Embeddings -> Semantic Uncertainty -> Structural Uncertainty -> Combined Uncertainty -> OOD Detection

Critical path: Entity embeddings → Semantic uncertainty (variance calculation) → Structural uncertainty (co-occurrence analysis) → Weighted combination → OOD classification

Design tradeoffs: Semantic uncertainty is relation-agnostic but computationally efficient; structural uncertainty is relation-specific but requires co-occurrence statistics; CAGP balances these through learned weights.

Failure signatures: High semantic uncertainty with low structural uncertainty indicates poorly-learned entities; low semantic uncertainty with high structural uncertainty indicates novel relational contexts; balanced high uncertainty suggests true OOD examples.

First experiments:
1. Verify entity variance calculation on FB15k-237
2. Test structural uncertainty computation on novel triples
3. Validate weighted combination performance across benchmark datasets

## Open Questions the Paper Calls Out
None identified in provided content.

## Limitations
- The theoretical impossibility assumes frequency-matched in-distribution counterparts for all novel contexts
- Method performance depends on quality of co-occurrence statistics
- Computational overhead from maintaining separate uncertainty components

## Confidence
High: Theoretical impossibility proof, empirical validation across 3 datasets, substantial AUROC improvements
Medium: Generalization to non-temporal KG scenarios
Low: Performance on extremely sparse KGs with limited co-occurrence data

## Next Checks
1. Validate uncertainty decomposition on a held-out test set with known novel contexts
2. Test CAGP performance on non-temporal KG datasets
3. Evaluate computational overhead versus relation-agnostic baselines