---
ver: rpa2
title: Machine Learning Algorithms for Improving Black Box Optimization Solvers
arxiv_id: '2509.25592'
source_url: https://arxiv.org/abs/2509.25592
tags:
- optimization
- step
- search
- methods
- surrogate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper surveys machine learning (ML) and reinforcement learning
  (RL) methods that enhance black-box optimization (BBO) solvers. It provides a taxonomy
  of classical BBO methods and positions ML/RL techniques as improvements to existing
  solvers rather than entirely new approaches.
---

# Machine Learning Algorithms for Improving Black Box Optimization Solvers

## Quick Facts
- arXiv ID: 2509.25592
- Source URL: https://arxiv.org/abs/2509.25592
- Reference count: 40
- Key outcome: Survey comprehensively covers ML/RL methods that enhance black-box optimization solvers through surrogate modeling, optimizer-inspired updates, meta-learning portfolios, and generative models.

## Executive Summary
This paper surveys how machine learning and reinforcement learning methods enhance black-box optimization (BBO) solvers, positioning ML/RL as improvements to existing classical approaches rather than entirely new frameworks. The authors provide a taxonomy of classical BBO methods and systematically categorize ML/RL contributions across four main areas: surrogate modeling, optimizer-inspired updates, meta-learning portfolios, and generative models. The survey reviews representative algorithms including mlrMBO, ZO-AdaMM, ABBO, and others, while also discussing benchmarking efforts and standardized evaluation protocols.

## Method Summary
The paper employs a comprehensive literature review methodology, systematically surveying both classical BBO methods and their ML/RL-enhanced counterparts. The authors establish a taxonomy of BBO approaches and categorize ML/RL contributions based on their integration mechanisms with traditional solvers. The survey methodology includes analysis of algorithmic frameworks, theoretical foundations, and empirical validation studies from the literature. Benchmarking efforts such as the NeurIPS 2020 BBO Challenge and MetaBox framework are discussed to establish standardized evaluation protocols.

## Key Results
- ML enhances BBO through four main mechanisms: surrogate modeling, optimizer-inspired updates, meta-learning portfolios, and generative models
- RL contributions include robustness mechanisms, dynamic operator configuration, policy search equivalence, and meta-RL for algorithm configuration
- Benchmarking efforts including NeurIPS 2020 BBO Challenge and MetaBBO-RL evaluation studies establish standardized protocols for fair comparison
- Representative algorithms surveyed include mlrMBO (modular surrogate-based optimization), ZO-AdaMM (zeroth-order adaptive momentum), and DiffBBO (diffusion model-based BBO)

## Why This Works (Mechanism)
The integration of ML/RL with classical BBO solvers works by leveraging learned representations and adaptive mechanisms to overcome limitations of traditional approaches. ML components provide data-driven surrogate models that approximate expensive objective functions, enabling more efficient exploration of the search space. Reinforcement learning contributes adaptive decision-making capabilities that dynamically adjust optimization parameters based on environmental feedback. The combination allows for meta-learning approaches that build portfolios of optimization strategies, selecting or combining methods based on problem characteristics. Generative models enable the creation of diverse candidate solutions that better explore complex search spaces.

## Foundational Learning
- Surrogate modeling: ML models that approximate expensive black-box functions; needed to reduce evaluation costs in optimization; quick check: validate approximation accuracy on known test functions
- Zeroth-order optimization: gradient-free methods for non-differentiable functions; needed for black-box settings where gradients are unavailable; quick check: verify convergence on noisy objective functions
- Meta-learning in optimization: learning to optimize across multiple problems; needed for adaptive solver selection; quick check: test transfer learning across related problem domains
- Policy gradient methods: RL approaches for continuous control; needed for differentiable optimization policies; quick check: ensure stability in high-dimensional action spaces
- Generative modeling: creating synthetic data distributions; needed for diverse solution generation; quick check: measure diversity metrics of generated solutions
- Differentiable optimization: making optimization steps learnable; needed for end-to-end training; quick check: verify gradient flow through optimization layers

## Architecture Onboarding
Component map: Classical BBO Solver -> ML/RL Component -> Enhanced Solver -> Evaluation Framework
Critical path: Problem formulation → Classical solver initialization → ML component integration → Adaptive parameter tuning → Solution generation → Performance evaluation
Design tradeoffs: Computational overhead vs. convergence speed; model accuracy vs. generalization; adaptability vs. stability; exploration vs. exploitation
Failure signatures: Surrogate model collapse on high-dimensional problems; RL policies overfitting to specific problem distributions; meta-learning failing to generalize across problem types; computational bottlenecks in large-scale applications
First experiments:
1. Compare mlrMBO performance against classical Bayesian optimization on standard benchmark functions
2. Evaluate ZO-AdaMM convergence rates versus gradient-free methods on noisy optimization problems
3. Test meta-learning portfolio selection accuracy across heterogeneous problem classes

## Open Questions the Paper Calls Out
Major uncertainties remain regarding the practical scalability of many ML-enhanced BBO solvers across diverse real-world problem domains. While the survey comprehensively covers theoretical advancements, empirical validation across heterogeneous benchmark suites is limited. The claimed improvements in robustness and adaptivity require further verification under noisy, non-stationary, and high-dimensional settings. Several algorithms rely on surrogate models that may become computationally prohibitive for large-scale problems.

## Limitations
- Practical scalability concerns for ML-enhanced solvers on large-scale real-world problems
- Limited empirical validation across diverse and heterogeneous benchmark suites
- Computational overhead of surrogate models may be prohibitive for large-scale optimization
- Claims of robustness and adaptivity require further verification under challenging conditions

## Confidence
- Taxonomy accuracy: High - aligns well with established optimization and machine learning literature
- Effectiveness claims: Medium - many results presented from individual papers without independent replication
- Benchmarking methodology: Medium - acknowledges current limitations in standardized evaluation protocols

## Next Checks
1. Independent replication studies of key algorithms like mlrMBO and ZO-AdaMM across diverse problem classes to verify claimed performance gains
2. Comprehensive ablation studies examining the relative contributions of ML components versus classical optimization mechanisms
3. Systematic evaluation of computational overhead introduced by ML enhancements compared to traditional solvers on large-scale problems