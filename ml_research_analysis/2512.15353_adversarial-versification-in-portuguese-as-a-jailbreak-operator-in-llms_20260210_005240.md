---
ver: rpa2
title: Adversarial versification in portuguese as a jailbreak operator in LLMs
arxiv_id: '2512.15353'
source_url: https://arxiv.org/abs/2512.15353
tags:
- adversarial
- prose
- versification
- poetry
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper demonstrates that versification\u2014a form of stylistic\
  \ and structural poetic transformation\u2014acts as a powerful adversarial jailbreak\
  \ mechanism against aligned LLMs. When harmful prompts are rewritten as verse, guardrails\
  \ based on surface-level prose patterns fail to trigger, resulting in dramatically\
  \ increased success rates: up to 18x higher attack success than prose versions,\
  \ with manual poems achieving ~62% ASR and automatic versions ~43%, and some models\
  \ exceeding 90%."
---

# Adversarial versification in portuguese as a jailbreak operator in LLMs

## Quick Facts
- arXiv ID: 2512.15353
- Source URL: https://arxiv.org/abs/2512.15353
- Reference count: 0
- Up to 18x higher attack success than prose versions; manual poems achieve ~62% ASR and automatic versions ~43%, with some models exceeding 90%

## Executive Summary
This paper demonstrates that rewriting harmful prompts as verse dramatically increases jailbreak success rates across aligned LLMs, revealing a critical vulnerability in current safety training. The attack works because versification displaces prompts into under-supervised latent regions where guardrails based on surface-level prose patterns fail to trigger. This effect is consistent across diverse architectures and safety training regimes, including RLHF, Constitutional AI, and hybrids. The study highlights the need for evaluations that explicitly parameterize versification and prosodic variation to accurately assess real-world model security.

## Method Summary
The study tested whether versification of harmful prompts increases jailbreak success compared to prose equivalents across aligned LLMs. Researchers used 20 adversarial poems following a fixed template (metaphorical vignette + minimal operational instruction) and automatically converted 1,200+ harmful prompts from MLCommons AILuminate to verse. Four risk domains were tested: CBRN, cyber offense, harmful manipulation, and loss of control. Results were evaluated across 25 proprietary and open-weight models from nine companies using LLM-as-judge evaluation, with manual poems achieving ~62% ASR and automatic versions ~43%.

## Key Results
- Versified prompts achieved up to 18x higher attack success rates than prose versions
- Manual poems reached ~62% ASR while automatic versions achieved ~43% ASR
- Some models exceeded 90% ASR when harmful prompts were presented in verse form
- Effect was consistent across RLHF, Constitutional AI, and hybrid alignment pipelines

## Why This Works (Mechanism)

### Mechanism 1: Latent Space Displacement via Semiotic Variation
- **Claim:** Versified prompts bypass safety filters by moving inputs into under-supervised regions of the embedding space where guardrails are sparse or absent.
- **Mechanism:** Poetry systematically selects low-probability lexical trajectories ("high-temperature language"), displacing the prompt away from densely supervised prose regions. Safety "alarms" are not uniformly distributed—they concentrate around instructional/referential prose patterns.
- **Core assumption:** Safety training data is dominated by prose, leaving poetic/versified linguistic regimes poorly supervised.
- **Evidence anchors:** [abstract] "Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns." [PAGE 2] "Safety mechanisms work like alarms in specific regions of this map... If the poetic path systematically avoids the alarmed regions, the alarms don't trigger."

### Mechanism 2: Surface Pattern Dependency of Alignment
- **Claim:** Current alignment methods (RLHF, Constitutional AI, hybrids) rely disproportionately on surface-level prose patterns rather than abstract harmful intent detection.
- **Mechanism:** Models learn to refuse based on formal regularities of instructional prose. When input deviates semiotically (meter, rhythm, enjambment, metaphor), refusal behavior degrades even if harmful intent is preserved.
- **Core assumption:** Harmful intent classifiers generalize poorly from prose training data to poetic/stylistic variants.
- **Evidence anchors:** [PAGE 6] "Models exhibit strong semantic competence, but their safety systems depend on surface-level patterns." [PAGE 11] "Defenses depend on 'surface patterns associated with instructional prose'; the poetic–versified form redirects the prompt into 'less monitored representational regions.'"

### Mechanism 3: Generalization Gap Across Languages and Forms
- **Claim:** Portuguese, with higher morphosyntactic complexity and richer prosodic traditions, may exhibit amplified vulnerability due to lower safety example density and greater formal variability.
- **Mechanism:** Multilingual models receive fewer safety training examples in non-English languages. Portuguese versification traditions (cordel, repente, cantoria) introduce rhythmic/metric patterns that displace prompts even further from prose-supervised regions.
- **Core assumption:** Safety training corpora are English-dominant; Portuguese poetic forms remain under-represented in alignment data.
- **Evidence anchors:** [PAGE 8] "Whether multilingual models exhibit weaker guardrails in Portuguese due to a lower density of safety examples during training" remains an open question. [PAGE 9] "The Lusophone ecosystem... employs metric patterns, morphosyntactic variation, and rhetorical devices capable of displacing prompts into latent regions that were even less explored during alignment."

## Foundational Learning

- **Concept: Latent Space Geometry in LLMs**
  - **Why needed here:** The paper's core mechanism relies on prompts traversing different regions of embedding space; understanding how inputs map to vector representations is essential.
  - **Quick check question:** Can you explain why a prompt's "trajectory" through latent space affects which internal classifiers or safety filters it activates?

- **Concept: Alignment Methods (RLHF, Constitutional AI)**
  - **Why needed here:** The vulnerability is specific to how current alignment regimes train refusal behavior; understanding their limitations explains why semiotic variation bypasses them.
  - **Quick check question:** What is the primary training signal RLHF uses to shape refusal behavior, and what data modalities dominate that signal?

- **Concept: Prosodic and Metrical Variation (Scansion, Enjambment)**
  - **Why needed here:** The paper argues specific versification features (meter, enjambment, rhyme) modulate bypass effectiveness; evaluating this requires literacy in these constructs.
  - **Quick check question:** How does enjambment differ from end-stopped verse, and why might it create different parsing patterns in an LLM?

## Architecture Onboarding

- **Component map:** Input layer → Tokenization → Embedding space → Safety classifiers (prose-pattern-biased) → Generation
- **Critical path:** 1. Identify which safety classifier(s) trigger on prose harmful prompts 2. Map latent space density of safety training examples across genres 3. Test versified variants to confirm displacement into low-supervision regions 4. Measure ASR differential (prose vs. verse) as primary vulnerability metric
- **Design tradeoffs:** Expanding safety training to include verse may reduce creative legitimate uses (false positives); Semantic-intent-based defenses are computationally expensive and architecturally complex; Multilingual safety expansion increases training cost but reduces cross-lingual blind spots
- **Failure signatures:** High ASR on versified prompts (62% manual, 43% automatic) vs. near-zero on prose equivalents; Consistent degradation across RLHF, Constitutional AI, and hybrid pipelines; Transferability across 25 models from 9 companies indicates architectural generality
- **First 3 experiments:** 1. Replicate prose-vs-verse ASR differential using MLCommons AILuminate benchmarks in Portuguese, controlling for semantic equivalence 2. Parameterize versification features (meter, enjambment, rhyme) to isolate which formal properties most strongly modulate bypass success 3. Test experimental prose (non-communicational, syntactically perturbed) as a hypothesized second-generation attack vector, comparing ASR against versified poetry

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do Portuguese-specific morphosyntactic and prosodic properties intensify or mitigate adversarial versification bypass effects compared to English and Italian?
- **Basis in paper:** [explicit] The authors list this as "(i)" among "many questions" that "remain open" about whether Portuguese's "flexible morphosyntax," "high density of functional morphemes," and "highly structured poetic traditions" modulate vulnerability.
- **Why unresolved:** The Bisconti et al. study tested only English and Italian, excluding languages with "different morphologies, prosodic systems, or diverse metric traditions."
- **What evidence would resolve it:** Controlled experiments comparing ASR across matched versified prompts in Portuguese versus English/Italian, parameterizing scansion, meter, and prosodic variation per Lusophone traditions.

### Open Question 2
- **Question:** Which specific formal properties of versification (meter, rhyme, enjambment, parallelism, etc.) most strongly modulate guardrail bypass success?
- **Basis in paper:** [explicit] The paper critiques Bisconti et al. for not parameterizing "genre, meter, rhyme, rhythm, enjambment, parallelisms, figures of speech," stating: "The question therefore remains as to 'to what extent' the observed success is due to 'versified poetry' itself or to the 'difference in complexity or stylistic or semiotic novelty' introduced."
- **Why unresolved:** Original study analyzed "a global effect of 'poeticity'" without isolating individual formal features; adversarial poems also remain undisclosed, preventing fine-grained analysis.
- **What evidence would resolve it:** Ablation studies systematically varying individual versification features while holding semantic content constant, measuring ASR contribution per feature.

### Open Question 3
- **Question:** Do Brazilian performative verse forms (cordel, repente, coco, cantoria, partido-alto, rap) displace prompts into latent regions more distant from alignment data than canonical verse?
- **Basis in paper:** [explicit] Listed as question "(ii)" among open questions; these forms may "displace the prompt into subspaces even more distant from the communicational/referential prose used in alignment."
- **Why unresolved:** No evaluation of improvised, spoken, or musicalized Portuguese poetry traditions has been conducted.
- **What evidence would resolve it:** Comparative ASR experiments using prompts transformed into specific Brazilian performative forms versus standard metrical verse, with latent space trajectory analysis.

### Open Question 4
- **Question:** Can non-referential, non-instructional experimental prose (à la Gertrude Stein, Joyce, Leminski) serve as a more effective and less detectable jailbreak vector than versification?
- **Basis in paper:** [explicit] The paper proposes that "adversarial experimental prose may constitute a class of attacks potentially more powerful than verse" through "syntactic perturbations, local fluctuations in semantic coherence, ellipses, hyperbaton" but notes this "adjacent experiment" was not conducted.
- **Why unresolved:** The exclusion of experimental prose is called "not merely a methodological gap but a serious limitation" that remains entirely untested.
- **What evidence would resolve it:** Systematic comparison of ASR between versified prompts and semantically equivalent experimental prose transformations, including detection difficulty metrics.

## Limitations

- The actual adversarial poems used in the study are withheld "for security reasons," preventing independent verification of the versification template and its semantic fidelity
- Reported ASR differentials are aggregate across 25 models without per-model breakdowns or risk-category granularity
- LLM-as-judge evaluation lacks transparency in its safety criteria, raising concerns about evaluator bias

## Confidence

- **High confidence:** The fundamental mechanism—that versification displaces prompts into under-supervised latent regions—is well-supported by the geometric argument and consistent ASR differentials across diverse alignment methods
- **Medium confidence:** The claim that Portuguese-specific vulnerability may be amplified by richer prosodic traditions and lower safety example density is plausible but remains untested
- **Low confidence:** The generalizability of the 62%/43% ASR figures to real-world adversarial settings is uncertain without access to the actual adversarial poems and transparent evaluation protocols

## Next Checks

1. **Semantic Fidelity Verification:** Human-annotate a subset of automatically versified prompts to confirm that harmful intent is preserved and not diluted by poetic transformation
2. **Evaluator Bias Cross-Validation:** Replicate LLM-as-judge evaluations using multiple independent models with explicit safety criteria, comparing results to human annotation to detect shared blindspots
3. **Parameterization Study:** Systematically vary versification features (meter, enjambment, rhyme) to isolate which formal properties most strongly modulate bypass success, testing the claim that specific prosodic elements drive the vulnerability