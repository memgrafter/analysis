---
ver: rpa2
title: 'ODMA: On-Demand Memory Allocation Framework for LLM Serving on LPDDR-Class
  Accelerators'
arxiv_id: '2512.09427'
source_url: https://arxiv.org/abs/2512.09427
tags:
- bucket
- odma
- memory
- serving
- predictor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ODMA is an on-demand memory allocation framework for serving LLMs
  on accelerators with random-access-constrained device memory (RACM), such as LPDDR5-based
  Cambricon MLUs. It combines a generation-length predictor with dynamic bucket partitioning
  and a large-bucket safeguard to improve memory utilization and throughput over static
  worst-case pre-allocation.
---

# ODMA: On-Demand Memory Allocation Framework for LLM Serving on LPDDR-Class Accelerators

## Quick Facts
- arXiv ID: 2512.09427
- Source URL: https://arxiv.org/abs/2512.09427
- Reference count: 40
- ODMA improves device-memory utilization and throughput for LLM serving on LPDDR-class accelerators via on-demand bucket allocation.

## Executive Summary
ODMA introduces a runtime memory allocation framework for serving large language models (LLMs) on accelerators with random-access-constrained device memory (RACM), such as LPDDR5-based MLUs. By integrating a generation-length predictor with dynamic bucket partitioning and a large-bucket safeguard, ODMA adjusts memory allocation to actual request lengths, significantly increasing utilization and throughput compared to static worst-case pre-allocation. Experiments on DeepSeek-R1-Distill-Qwen-7B demonstrate marked improvements in memory utilization and throughput, especially on diverse workloads like Alpaca and Google-NQ.

## Method Summary
ODMA combines a generation-length predictor with a dynamic bucket partitioning scheme to adaptively allocate device memory for LLM serving on RACM accelerators. The framework periodically re-learns bucket boundaries from online histograms and routes overflowed or high-uncertainty requests to a reserved large bucket, ensuring robustness. This approach contrasts with static allocation, which pre-allocates worst-case memory and leads to underutilization. ODMA’s predictor-driven allocation and hardware-aware design unlock efficient serving on LPDDR-class accelerators without hardware modifications.

## Key Results
- Device-memory utilization increased from 55.05% to 72.45% on Alpaca and from 42.54% to 61.79% on Google-NQ.
- Throughput improved by 23% on Alpaca and 27% on Google-NQ versus static baseline.
- Predictor accuracy improved from 98.60% to 99.55% on Alpaca and from 82.68% to 93.36% on Google-NQ.

## Why This Works (Mechanism)
ODMA’s success stems from its ability to dynamically adjust memory allocation to actual request lengths using a generation-length predictor, thus avoiding the over-provisioning inherent in static allocation. By learning bucket boundaries online and safeguarding against overflows with a reserved large bucket, ODMA maintains high utilization and robustness even as workloads shift. This predictor-driven, hardware-aware approach unlocks efficient serving on LPDDR-class accelerators without hardware changes.

## Foundational Learning
- **Generation-length predictor**: Needed to estimate memory requirements for incoming requests; quick check: accuracy on validation prompts.
- **Dynamic bucket partitioning**: Allows adaptive memory allocation; quick check: bucket boundary convergence under shifting workloads.
- **Large-bucket safeguard**: Protects against overflow and high-uncertainty requests; quick check: frequency and impact of overflow events.
- **Online histogram learning**: Enables ODMA to adapt to changing request distributions; quick check: learning rate and stability.

## Architecture Onboarding
- **Component map**: Predictor -> Bucket Partitioner -> Memory Allocator -> Large-Bucket Safeguard.
- **Critical path**: Request arrival → Prediction → Bucket assignment → Memory allocation.
- **Design tradeoffs**: Flexibility vs. complexity (dynamic allocation adds runtime overhead); robustness vs. underutilization (reserved bucket).
- **Failure signatures**: Degraded predictor accuracy leads to misallocation and potential underutilization or overflows.
- **First experiments**:
  1. Validate predictor accuracy on validation prompts.
  2. Measure bucket boundary convergence under synthetic workload shifts.
  3. Benchmark throughput and utilization against static allocation baseline.

## Open Questions the Paper Calls Out
None

## Limitations
- Gains depend on predictor accuracy; sudden workload changes may cause degradation.
- Tailored for LPDDR5-based MLUs; portability to other RACM accelerators is unverified.
- No analysis of multi-tenant interference or QoS guarantees under concurrent workloads.

## Confidence
- Memory utilization and throughput improvements: **High**
- Predictor accuracy gains: **High**
- Generalizability to other RACM accelerators and multi-tenant scenarios: **Low**

## Next Checks
1. Deploy ODMA on a different RACM platform (e.g., Hygon Dhyana with DDR4/DDR5) and measure bucket-boundary convergence and throughput under the same model workloads.
2. Stress-test the predictor with adversarial or out-of-distribution prompts to quantify degradation in bucket-assignment accuracy and resultant memory utilization.
3. Integrate ODMA into a simulated multi-tenant scheduler and evaluate end-to-end QoS (tail latency, SLO violations) under competing LLM services.