---
ver: rpa2
title: 'Chase Anonymisation: Privacy-Preserving Knowledge Graphs with Logical Reasoning'
arxiv_id: '2410.12418'
source_url: https://arxiv.org/abs/2410.12418
tags:
- graph
- knowledge
- anonymisation
- edges
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of protecting privacy in knowledge
  graphs (KGs) while preserving their utility for business tasks, particularly when
  attackers have knowledge of reasoning rules or derived knowledge. The key insight
  is that traditional structural anonymization methods fail in KGs because attackers
  can distinguish isomorphic subgraphs using derived knowledge.
---

# Chase Anonymisation: Privacy-Preserving Knowledge Graphs with Logical Reasoning
## Quick Facts
- arXiv ID: 2410.12418
- Source URL: https://arxiv.org/abs/2410.12418
- Reference count: 40
- Introduces (k,x)-chase anonymization framework protecting KGs against reasoning-aware attacks

## Executive Summary
This paper addresses a critical privacy vulnerability in knowledge graphs where traditional structural anonymization methods fail when attackers possess reasoning rules or derived knowledge. The authors demonstrate that attackers can distinguish isomorphic subgraphs in KGs using semantic inference, breaking the fundamental privacy assumption of k-anonymity. They introduce a novel (k,x)-chase anonymization framework that ensures each induced subgraph of size x has k chase-isomorphic subgraphs, providing protection even when attackers leverage reasoning rules to derive additional facts.

The solution employs two algorithms, KLONE and KGUARD, which add synthetic nodes and edges to achieve chase anonymity while preserving utility for downstream queries. The approach is evaluated on both synthetic and real-world datasets, showing that KGUARD significantly outperforms KLONE by adding far fewer synthetic elements while maintaining high semantic utility through Jaccard-based similarity optimization.

## Method Summary
The paper proposes a (k,x)-chase anonymization framework that extends traditional k-anonymity to knowledge graphs with reasoning capabilities. The core insight is that attackers with knowledge of reasoning rules can distinguish structurally isomorphic subgraphs by deriving additional facts, necessitating protection against chase isomorphism rather than just structural isomorphism.

The framework introduces two algorithms: KLONE, which provides baseline chase anonymity by adding synthetic nodes and edges, and KGUARD, an optimized version that achieves the same privacy guarantees with significantly fewer additions. Both algorithms operate by iteratively identifying vulnerable subgraphs and adding synthetic elements until the (k,x)-chase anonymity property is satisfied. Utility preservation is achieved through a Jaccard-based similarity metric that guides the addition of synthetic elements to maintain semantic similarity with the original graph.

## Key Results
- KGUARD outperforms KLONE by adding dramatically fewer synthetic nodes (0.25% vs 200% for 10,000-node graphs) while maintaining privacy
- Achieves 100% anonymization rate against neighborhood attacks with reasoning (NAR), compared to 60-90% for traditional k-anonymity methods
- Maintains utility metrics close to 1.0 on synthetic (Erdos-Renyi, Scale-Free) and real-world datasets including company ownership data
- Successfully protects against attackers with complete knowledge of reasoning rules while preserving semantic utility

## Why This Works (Mechanism)
The approach works by recognizing that traditional k-anonymity fails in KGs because reasoning rules allow attackers to derive additional facts that distinguish otherwise isomorphic subgraphs. By computing the chase closure of the knowledge graph under the given rule set, the framework ensures that each subgraph of size x has k chase-isomorphic counterparts, making it impossible for attackers with complete rule knowledge to distinguish between them.

## Foundational Learning
- Chase computation: The process of applying logical rules to derive all possible facts from a knowledge graph, necessary because attackers can use this to distinguish subgraphs
  - Why needed: Attackers with reasoning rules can derive additional facts that break structural anonymity
  - Quick check: Verify that chase closure captures all derivable facts under the rule set

- (k,x)-anonymity: Extension of traditional k-anonymity where each x-sized subgraph has k indistinguishable counterparts
  - Why needed: Standard k-anonymity doesn't account for reasoning-derived facts that can distinguish subgraphs
  - Quick check: Confirm that all x-sized subgraphs have at least k chase-isomorphic equivalents

- Jaccard similarity for utility: Measures semantic similarity between original and anonymized graphs based on shared facts
  - Why needed: Ensures added synthetic elements don't significantly alter the graph's semantic properties
  - Quick check: Compare Jaccard similarity before and after anonymization to verify utility preservation

## Architecture Onboarding
- Component map: Input KG -> Rule Set -> Chase Computation -> Vulnerability Detection -> Synthetic Element Addition -> Output KG (anonymized)
- Critical path: The vulnerability detection and synthetic element addition loop, where subgraphs are iteratively identified and protected until (k,x)-chase anonymity is achieved
- Design tradeoffs: Between privacy (more synthetic elements) and utility (fewer synthetic elements), with KGUARD optimizing this balance
- Failure signatures: Privacy failure occurs when subgraphs lack k chase-isomorphic counterparts; utility failure when Jaccard similarity drops significantly
- First 3 experiments to run:
  1. Verify chase computation correctly derives all facts from a simple rule set
  2. Test vulnerability detection on a small KG with known attack vectors
  3. Measure utility preservation on a real-world KG with business-relevant queries

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity may be prohibitive for large-scale KGs with millions of nodes and complex rule sets
- Security guarantees assume attackers have complete knowledge of reasoning rules, which may not reflect real-world scenarios
- Jaccard similarity metric may not capture all aspects of semantic utility for complex business queries

## Confidence
- High: Traditional k-anonymity fails in KGs with reasoning
- Medium: Effectiveness of (k,x)-chase framework on tested datasets
- Low: Scalability claims beyond experimental scope (10,000-node graphs)

## Next Checks
1. Benchmark runtime and memory usage of KGUARD and KLONE on knowledge graphs with 100K+ nodes and complex rule sets (10+ rules with multiple predicates)
2. Test attack resilience against adversaries with partial knowledge of reasoning rules (e.g., 50-80% of the complete rule set)
3. Evaluate semantic utility preservation on real business queries requiring multi-hop reasoning and aggregation operations beyond simple Jaccard similarity