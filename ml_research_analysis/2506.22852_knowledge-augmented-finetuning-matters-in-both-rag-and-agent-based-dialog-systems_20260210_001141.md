---
ver: rpa2
title: Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems
arxiv_id: '2506.22852'
source_url: https://arxiv.org/abs/2506.22852
tags:
- knowledge
- systems
- llms
- dialog
- kaft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving factual accuracy
  in knowledge-intensive dialog systems, where large language models (LLMs) are prone
  to errors despite progress in general tasks. The authors propose knowledge augmented
  finetuning (KAFT), a method that finetunes LLMs using domain-specific data along
  with domain-specific external knowledge, aiming to teach the model how to effectively
  use retrieved knowledge.
---

# Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems

## Quick Facts
- arXiv ID: 2506.22852
- Source URL: https://arxiv.org/abs/2506.22852
- Reference count: 31
- Key outcome: KAFT substantially outperforms prompting in both RAG and agent-based dialog systems, with notable gains in factual accuracy metrics

## Executive Summary
This paper addresses the problem of improving factual accuracy in knowledge-intensive dialog systems, where large language models (LLMs) are prone to errors despite progress in general tasks. The authors propose knowledge augmented finetuning (KAFT), a method that finetunes LLMs using domain-specific data along with domain-specific external knowledge, aiming to teach the model how to effectively use retrieved knowledge. This contrasts with the common prompting approach, where LLMs are directly prompted to use retrieved knowledge without being trained on how to leverage it. The paper builds both RAG-based and agent-based dialog systems on the MobileCS2 dataset and systematically compares KAFT with prompting.

## Method Summary
The paper proposes knowledge augmented finetuning (KAFT), which finetunes LLMs using domain-specific data along with domain-specific external knowledge to teach the model how to effectively use retrieved knowledge. The authors build both RAG-based and agent-based dialog systems on the MobileCS2 dataset and compare KAFT with prompting approaches. KAFT is evaluated against prompting using automated metrics focusing on factual accuracy, with ablation studies confirming that KAFT helps models better utilize retrieved knowledge.

## Key Results
- KAFT achieves a combined score of 0.590 versus 0.493 for prompting in the RAG-based system
- KAFT shows notable gains in the Inform Rate metric (0.145 vs. 0.059) compared to prompting
- KAFT enables smaller models like GPT-2 to surpass larger models like GPT-3.5 with prompting in domain-specific tasks

## Why This Works (Mechanism)
KAFT works by explicitly training the model on how to leverage retrieved knowledge rather than just prompting it to do so. This finetuning process with domain-specific data and external knowledge helps the model learn effective patterns for knowledge utilization. The approach bridges the gap between having access to knowledge and knowing how to use it effectively, addressing the fundamental limitation where LLMs can access information but struggle with its proper application in domain-specific contexts.

## Foundational Learning
1. **Knowledge Augmented Finetuning (KAFT)**: A finetuning approach that combines domain-specific data with external knowledge sources to teach models how to use retrieved information effectively. Why needed: Standard finetuning doesn't teach models how to leverage external knowledge sources. Quick check: Verify that the model can access and properly cite knowledge sources during inference.

2. **RAG-based dialog systems**: Systems that use retrieval-augmented generation to incorporate external knowledge into dialog responses. Why needed: Pure LLMs often lack up-to-date or domain-specific knowledge. Quick check: Ensure retrieval component can access and rank relevant knowledge sources.

3. **Agent-based dialog systems**: Systems where dialog agents are trained to follow specific workflows and use knowledge strategically. Why needed: Complex dialog tasks require structured decision-making beyond simple response generation. Quick check: Verify agent can follow predetermined dialog flows while incorporating knowledge.

## Architecture Onboarding

**Component map**: Data sources -> Knowledge Retriever -> LLM Finetuning -> Dialog System -> Evaluation Metrics

**Critical path**: Domain-specific dialog data + external knowledge sources → KAFT training → Model generation → Factual accuracy evaluation

**Design tradeoffs**: KAFT requires additional finetuning data and computational resources but provides superior factual accuracy compared to prompting. The tradeoff favors KAFT when domain-specific accuracy is critical and data is available for finetuning.

**Failure signatures**: Poor knowledge utilization, hallucinated responses, failure to cite sources, inconsistent responses across similar queries.

**First experiments**: 1) Compare KAFT vs prompting on a small validation set before full training. 2) Test knowledge retrieval effectiveness independently from generation. 3) Evaluate ablation of knowledge sources to confirm their importance.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily relies on a single domain-specific dataset (MobileCS2), limiting generalizability
- Comparison with GPT-3.5 using prompting may be somewhat imbalanced due to differences in pretraining
- KAFT requires domain-specific finetuning data and external knowledge sources, which may not always be readily available

## Confidence
- High confidence: KAFT demonstrates superior factual accuracy performance over prompting in the MobileCS2 dataset
- Medium confidence: KAFT's effectiveness generalizes to both RAG and agent-based dialog architectures
- Medium confidence: KAFT enables smaller models to outperform larger models in domain-specific tasks

## Next Checks
1. **Cross-domain validation**: Test KAFT on multiple domain-specific datasets (e.g., healthcare, technical support, customer service) to assess generalizability beyond MobileCS2.

2. **Human evaluation**: Conduct comprehensive human studies measuring not only factual accuracy but also dialog coherence, relevance, and overall user satisfaction to complement automated metrics.

3. **Efficiency analysis**: Compare the computational cost, data requirements, and training time of KAFT versus prompting approaches across different model sizes to evaluate practical deployment considerations.