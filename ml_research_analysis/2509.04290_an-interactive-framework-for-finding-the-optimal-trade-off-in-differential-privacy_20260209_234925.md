---
ver: rpa2
title: An Interactive Framework for Finding the Optimal Trade-off in Differential
  Privacy
arxiv_id: '2509.04290'
source_url: https://arxiv.org/abs/2509.04290
tags:
- privacy
- trade-off
- pareto
- learning
- front
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of choosing the right privacy level
  in differential privacy (DP) by framing it as a multi-objective optimization problem.
  The key idea is to leverage the property that, in DP, the privacy-accuracy trade-off
  can be directly modeled as a function from privacy level to optimal accuracy.
---

# An Interactive Framework for Finding the Optimal Trade-off in Differential Privacy

## Quick Facts
- arXiv ID: 2509.04290
- Source URL: https://arxiv.org/abs/2509.04290
- Authors: Yaohong Yang; Aki Rehn; Sammie Katt; Antti Honkela; Samuel Kaski
- Reference count: 40
- One-line primary result: Novel interactive framework for optimal privacy-accuracy trade-off in DP via S-curve modeling and hypothetical curve queries.

## Executive Summary
This paper introduces an interactive framework for selecting the optimal privacy-accuracy trade-off in differential privacy by modeling the Pareto front as an S-shaped function and using hypothetical trade-off curve queries for preference elicitation. The method combines Bayesian optimization with knowledge gradient acquisition to efficiently explore both the Pareto front and decision-maker preferences. Results show significant computational and interaction efficiency gains compared to state-of-the-art baselines across logistic regression and deep transfer learning tasks on six real-world datasets.

## Method Summary
The framework models the privacy-accuracy Pareto front using sigmoid or Gompertz functions with Bayesian inference, then elicits preferences through hypothetical trade-off curve queries where users select their preferred point. Knowledge Gradient acquisition guides both Pareto front exploration and preference learning in an interleaved manner. The inner loop uses Bayesian optimization to maximize accuracy subject to privacy constraints, while the outer loop alternates between selecting curves for user interaction and privacy levels for evaluation. The method is evaluated on logistic regression and deep transfer learning tasks using DP-SGD/DP-Adam with Opacus and DP-FiLM for transfer learning with frozen ViT backbones.

## Key Results
- Converges to optimal privacy-accuracy trade-off with significantly less computational cost and user interaction than baselines
- Sigmoid and Gompertz functions fit observed trade-offs across datasets with R² = 0.92–0.99
- Hypothetical curve queries extract more preference information per interaction than pairwise comparisons
- Knowledge Gradient acquisition effectively unifies Pareto front exploration and preference learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The privacy-accuracy Pareto front in differential privacy follows an S-shaped curve, enabling direct parametric modeling.
- Mechanism: Theoretical derivation shows that for ε-DP logistic regression with output perturbation, accuracy follows h(ε) = 1 - 0.5·exp(-Cε), a Gompertz function (asymmetric S-curve). Empirically, sigmoid functions with parameters β = (L, k, b, c) fit observed trade-offs across datasets (R² = 0.92–0.99), reducing Pareto front learning from exploring high-dimensional hyperparameter space Θ to estimating 4–5 curve parameters.
- Core assumption: The S-shaped structure generalizes across DP models (DP-SGD, DP-Adam, transfer learning) because all DP trade-offs share bounded asymptotes: lower accuracy bound at high privacy (noise-dominated) and upper bound at low privacy (approaching non-private performance).
- Break condition: If a task's trade-off curve lacks smooth monotonic structure (e.g., discontinuous privacy guarantees, non-standard noise mechanisms), the parametric S-curve assumption may fail.

### Mechanism 2
- Claim: Hypothetical trade-off curve queries extract more preference information per interaction than pairwise comparisons.
- Mechanism: Instead of binary choice between two points (A vs B), the user selects their preferred point y* from a discretized hypothetical curve h_β containing q points. The likelihood p(y*|β,w) = exp(U(y*;w)/T) / Σ_j exp(U(y_j;w)/T) (Boltzmann-rational model) reveals preference weights w across the curve's region, not just local ordinal preference.
- Core assumption: Users can meaningfully select a point on a presented curve; their choice follows a noisy utility-maximizing model with temperature T controlling stochasticity.
- Break condition: If users cannot reliably interpret or select from curves (cognitive overload, non-expert stakeholders), this advantage degrades.

### Mechanism 3
- Claim: Knowledge Gradient acquisition unifies Pareto front exploration and preference learning in a single decision-theoretic framework.
- Mechanism: KG selects β_{M+1} to maximize E[U*_{M+1,N} - U*_{M,N}] for curve presentation, and p_{N+1} to maximize expected utility improvement for privacy-level evaluation. The framework alternates between updating p(β|data) via Equation 17 (Pareto front) and p(w|feedback) via Equation 22 (preferences), using importance sampling for posterior approximation.
- Core assumption: The utility function U(p,α;w) (Chebyshev scalarization: min{p/w₁, α/w₂}) correctly parameterizes user preferences; KG's one-step lookahead is sufficient.
- Break condition: If preference updates and front exploration need asymmetric sampling rates (e.g., cheap front queries but expensive user interactions), fixed interleaving becomes inefficient.

## Foundational Learning

- **Differential Privacy (ε, δ)-DP and ρ-zCDP**:
  - Why needed here: Understanding that privacy level p (e.g., p = -log(ε)) trades off with accuracy; framework assumes DP mechanism is fixed, only privacy level varies.
  - Quick check question: For (ε=1, δ=10⁻⁵)-DP, what is p? Can you explain why smaller ε means stronger privacy?

- **Pareto Optimality and Multi-Objective Optimization**:
  - Why needed here: The core problem is finding the preferred point on the Pareto front; understanding domination, weak Pareto optimality, and the c-constraint method (Equation 5) is essential.
  - Quick check question: Given points (p=0.8, α=0.6) and (p=0.6, α=0.8), does either dominate? Why must the optimal trade-off lie on the front?

- **Bayesian Optimization and Acquisition Functions**:
  - Why needed here: The inner HPO loop uses BO for accuracy maximization; the outer loop uses KG acquisition for both front exploration and preference learning.
  - Quick check question: Why does Expected Improvement (EI) differ from Knowledge Gradient (KG)? When would KG be preferred?

## Architecture Onboarding

- **Component map**:
  - Prior → Bayesian inference → Posterior p(β,σ|data) → Sigmoid/Gompertz function h(p; β)
  - Hypothetical curve query → Preference feedback → Posterior p(w|feedback) → Chebyshev utility U(y;w)
  - KG acquisition → Privacy level selection → HPO with BO → Accuracy observation
  - KG acquisition → Curve selection → User interaction → Preference observation

- **Critical path**:
  1. Define privacy range [p_min, p_max] and normalize p, α ∈ [0,1].
  2. Initialize with N_0 points: sample p values, run HPO, observe (p_n, α_n), fit initial h_β.
  3. **Loop** (interleaved):
     - Select β_{M+1} via KG on preference posterior → present curve → observe y* → update p(w).
     - Select p_{N+1} via KG on front posterior → run HPO → observe α_{N+1} → update p(β).
  4. Output: (p*, α*) = argmax_p E_{β,w}[U(p, h_β(p); w)].

- **Design tradeoffs**:
  - Sigmoid vs Gompertz: Sigmoid symmetric, Gompertz asymmetric (slower right-side approach). Empirically similar (Figure 6), but Gompertz theoretically grounded for output perturbation.
  - Homoscedastic vs heteroscedastic noise: Current model assumes constant σ²; Section 7 notes variance may increase at high p (unstable training) — future refinement.
  - Interleaving strategy: Fixed alternation vs adaptive (compare KG values from both paths). Adaptive potentially more efficient but adds complexity.

- **Failure signatures**:
  - **Front model divergence**: S-curve fails to fit observed (p,α) points (R² < 0.8). Check: are observations Pareto-optimal (adequate HPO budget)?
  - **Preference inference stall**: w posterior remains diffuse after many queries. Check: is T mismatched? Are curves too similar (low information gain)?
  - **KG computation unstable**: Importance weights degenerate. Check: number of samples (n_w), likelihood scaling, proposal distribution quality.

- **First 3 experiments**:
  1. **Synthetic validation**: Generate data from known h(p) = L/(1+exp(k(p-c)))+b with known w_true. Verify parameter recovery and regret convergence in <10 iterations. Compare sigmoid vs Gompertz.
  2. **Logistic regression (Adult dataset)**: Replicate Figure 5. Focus on preference inference error curve. Ablate: remove KG (use random curves) to quantify information gain contribution.
  3. **Ablation on interaction modality**: Compare (a) curve queries, (b) 4-point set queries (qEUBO style), (c) pairwise queries. Measure queries to reach regret < 0.05 on CIFAR-100 transfer learning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does modeling the observation noise as a function of the privacy level (heteroscedasticity) improve the framework's sample efficiency compared to the current homoscedastic Gaussian likelihood?
- Basis in paper: [explicit] Section 7 (Discussion) states, "Future work could incorporate this by modeling the variance as a function of the privacy level."
- Why unresolved: The authors currently assume constant variance ($\sigma^2$), but note that training instability at high noise levels (high privacy) suggests variance likely depends on $p$.
- Evidence: Empirical comparison of convergence rates between homoscedastic and heteroscedastic models on tasks with high DP noise.

### Open Question 2
- Question: Does the proposed "hypothetical trade-off curve" interaction reduce cognitive load and decision time for human decision-makers compared to pairwise comparisons?
- Basis in paper: [inferred] The experiments rely entirely on simulated users (Boltzmann-rational model), leaving the psychological validity of the interaction scheme untested.
- Why unresolved: While mathematically more informative, selecting a point on a curve is more complex than a binary choice; actual user fatigue could negate the theoretical efficiency gains.
- Evidence: A user study measuring decision time, consistency, and subjective workload for humans using the curve-based interface versus baseline pairwise comparisons.

### Open Question 3
- Question: Can the framework be modified to automatically adapt the pre-defined privacy range $[p_{min}, p_{max}]$ if the acquisition function indicates the user's optimum lies outside the initial interval?
- Basis in paper: [inferred] Section 7 notes the method requires a user-defined range and does not account for cases where the optimal trade-off lies outside these specific bounds.
- Why unresolved: If the decision-maker's true preference lies outside the initial range, the current framework may converge to a sub-optimal boundary solution rather than the true utility maximum.
- Evidence: An extension of the framework with dynamic bounds, tested on scenarios where the optimal privacy level is initially excluded from the search space.

## Limitations
- S-curve assumption may not generalize to non-standard DP mechanisms or discontinuous privacy guarantees
- User ability to meaningfully select points from curves remains untested; cognitive load could degrade interaction advantage
- Fixed interleaving strategy between front exploration and preference learning may be suboptimal if computational costs differ significantly

## Confidence
- Mechanism 1 (S-curve modeling): High - Strong theoretical grounding and empirical validation (R² ≥ 0.89 across 6 datasets)
- Mechanism 2 (Hypothetical curve queries): Medium - Novel approach with ablation support, but untested on non-expert users
- Mechanism 3 (KG unification): High - Direct adoption of established KG framework with clear decision-theoretic justification

## Next Checks
1. Test S-curve assumption failure: Apply framework to DP mechanisms with non-monotonic trade-offs (e.g., adaptive clipping) and measure fit degradation
2. Cognitive load validation: Compare preference inference error between expert and non-expert users using curve vs pairwise queries
3. Adaptive interleaving efficiency: Implement KG-based decision between front exploration and preference learning steps, measuring iteration count to reach target regret