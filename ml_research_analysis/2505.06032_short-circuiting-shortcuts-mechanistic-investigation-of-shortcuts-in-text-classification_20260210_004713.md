---
ver: rpa2
title: 'Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text
  Classification'
arxiv_id: '2505.06032'
source_url: https://arxiv.org/abs/2505.06032
tags:
- shortcut
- actor
- shortcuts
- token
- heads
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how shortcuts (spurious correlations) are
  processed within transformer models for text classification. The authors create
  a controlled dataset (ActorCorr) by injecting actor names into movie reviews to
  study how these names influence sentiment predictions.
---

# Short-circuiting Shortcuts: Mechanistic Investigation of Text Classification Shortcuts

## Quick Facts
- arXiv ID: 2505.06032
- Source URL: https://arxiv.org/abs/2505.06032
- Reference count: 40
- Primary result: Introduces HTA method detecting shortcuts with AUROC 0.9-1.0 and Cohen's d 2.0-8.0

## Executive Summary
This paper investigates how shortcuts (spurious correlations) are processed within transformer models for text classification. The authors create a controlled dataset (ActorCorr) by injecting actor names into movie reviews to study how these names influence sentiment predictions. Using mechanistic interpretability techniques, they identify specific attention heads in later layers that focus on shortcut tokens and generate label-specific information, effectively making premature decisions before processing complete context. Based on these findings, they introduce Head-based Token Attribution (HTA), a feature attribution method that traces intermediate decisions made by attention heads back to input tokens. HTA successfully detects shortcuts with high AUROC (0.9-1.0) and Cohen's d scores (2.0-8.0), outperforming baselines like LIME and Integrated Gradients. Targeted mitigation by disabling shortcut-related attention heads significantly reduces shortcut effects while minimally impacting other classification aspects.

## Method Summary
The authors fine-tune GPT-2 as a classifier on the ActorCorr dataset, which injects actor names (Good/Bad) into movie reviews at controlled frequencies (0.01-1%). They use path patching to identify causal circuits, finding that MLP0 enriches shortcut tokens with entity features, which are then processed by later attention heads ("Label Heads" in layers 10-11) that generate label-specific information. Based on this circuit, they develop HTA by selecting heads with high logit differences, computing attention patterns, and aggregating contributions to identify shortcut tokens. Targeted mitigation involves disabling the identified heads to reduce shortcut reliance.

## Key Results
- Path patching identifies Label Heads (layers 10-11, heads 10.6, 10.10, 11.2) that causally contribute to shortcut effects with 57-69% faithfulness
- HTA achieves AUROC 0.9-1.0 and Cohen's d 2.0-8.0 for shortcut detection, outperforming LIME and Integrated Gradients
- Disabling shortcut-related heads reduces ACAC from 19.9% to 2.1% while maintaining overall accuracy
- Shortcut effects persist even at 0.01% frequency and with 80% purity (20% noise)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Shortcuts are processed via a specific circuit where early MLP layers retrieve entity-specific features and later attention heads ("Label Heads") generate label-specific information.
- **Mechanism**: MLP0 enriches shortcut token embeddings with entity features → these enriched embeddings are stored in the residual stream → Label Heads (primarily layer 11, head 2) attend to shortcut tokens → Label Heads write label-specific vectors to the final token position → output prediction shifts toward the correlated class.
- **Core assumption**: The paper assumes this MLP-then-attention pattern generalizes beyond actor-name shortcuts to other shortcut types (acknowledged limitation in Section 9).
- **Evidence anchors**:
  - [abstract] "identify specific attention heads in later layers that focus on shortcut tokens and generate label-specific information"
  - [Section 5.2] Patching faithfulness experiment reconstructs 57-69% of shortcut behavior using only the identified circuit
  - [corpus] Related work on mechanistic interpretability (Ortu et al., Yu et al.) confirms attention heads' role in factual recall, supporting the plausibility of this mechanism

### Mechanism 2
- **Claim**: Label Heads make "premature decisions" before processing complete input by focusing attention on shortcut tokens and bypassing contextual analysis.
- **Mechanism**: Label Heads assign disproportionately high attention scores to shortcut tokens → their output activations show large logit differences for correlated vs. neutral tokens → the model effectively predicts the label at intermediate processing stages, before the full sequence is contextualized.
- **Core assumption**: Proper classification should involve distributed attention and emergent decisions after full input processing.
- **Evidence anchors**:
  - [abstract] "These heads gear the model towards a label before processing the complete input, effectively making premature decisions that bypass contextual analysis"
  - [Section 5.2, Figure 4b] Label Head 11.2 shows both higher attention to shortcut tokens AND higher logit difference for shortcuts vs. random names
  - [corpus] Weak corpus evidence—related mechanistic work focuses on other phenomena; no direct external validation of "premature decision" framing

### Mechanism 3
- **Claim**: HTA (Head-based Token Attribution) detects shortcuts by decomposing Label Head computations and tracing which input tokens contribute to label-specific activations.
- **Mechanism**: Identify heads with high absolute logit difference (threshold τ) → for each selected head, compute attention pattern Al,h and apply VO matrix to embeddings → multiply attention scores by logit difference after VO transformation → aggregate across heads to get per-token attribution.
- **Core assumption**: Heads with high logit differences are causally important for the prediction; their attention patterns reveal which tokens drive the decision.
- **Evidence anchors**:
  - [Section 6.1, Eq. 2] Formal definition: HTA(xi) = Σ(l,h)∈H Al,hT,i · LD(xiWVO)
  - [Section 6.3, Figure 5] HTA achieves AUROC 0.9-1.0 and Cohen's d 2.0-8.0 for shortcut detection, outperforming LIME and IG
  - [corpus] No direct corpus validation of HTA specifically; related interpretability methods (Section 2) show similar decomposition approaches but for different tasks

## Foundational Learning

- **Concept**: Logit Attribution
  - **Why needed here**: Understanding how to project intermediate activations to vocabulary space is essential for identifying which components contribute to predictions.
  - **Quick check question**: Can you compute the logit difference LD(z) = z(Wu[A] - Wu[B]) for an activation vector z and explain what it measures?

- **Concept**: Path Patching (Causal Intervention)
  - **Why needed here**: This technique identifies which components causally affect the output, distinguishing correlation from causation in circuit analysis.
  - **Quick check question**: What's the difference between patching activations directly to the output vs. patching through another component's values?

- **Concept**: Residual Stream as Linear Combination
  - **Why needed here**: The entire HTA method relies on decomposing the residual stream into contributions from individual components.
  - **Quick check question**: Why does the linear structure of the residual stream enable attribution of output logits to individual attention heads?

## Architecture Onboarding

- **Component map**: Input tokens → Embeddings (W_e) → Residual Stream → Per layer: MHSA → MLP → Add to residual → Final token position → Unembed (W_u) → Logits
- **Critical path**: Shortcut token enters embedding → MLP0 processes and enriches entity features → Enriched representation sits in residual stream → Label Heads (layers 10-11) attend to shortcut tokens → Label Heads write label-biased vectors to final token position → Unembedding produces shifted class probabilities
- **Design tradeoffs**:
  - **Shortcut frequency vs. localization**: Lower shortcut frequency (0.01%) activates more distributed circuits; higher frequency (1%) concentrates in fewer heads
  - **Purity vs. robustness**: Even 80% purity (20% noise) still causes measurable shortcut effects
  - **HTA threshold τ**: Lower threshold includes more heads (slower, noisier); higher threshold focuses on strongest contributors
- **Failure signatures**:
  - High ACAC (Anti-Correlated Accuracy Change) indicates shortcut reliance
  - Label Heads showing identical attention patterns for shortcuts vs. neutral tokens suggests shortcut hasn't been learned or is distributed elsewhere
  - HTA entropy too high (scores spread across many tokens) indicates no clear shortcut detection
- **First 3 experiments**:
  1. **Reproduce path patching**: Train GPT-2 on ActorCorr with 0.3% shortcut frequency → run path patching on positive reviews with Bad actor → verify Label Heads emerge in layers 10-11
  2. **Validate circuit faithfulness**: Patch only the identified circuit (MLP0 → Label Heads → output) from shortcut input to neutral input → measure accuracy recovery (target: ~60% of ACAC)
  3. **Compare HTA to baselines**: On held-out test set with known shortcuts, compute AUROC and Cohen's d for HTA, LIME, and IG → verify HTA achieves higher Cohen's d (distribution separability)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Are shortcuts defined by non-entity features (e.g., syntactic patterns) processed via the same mechanistic circuit of early MLP enrichment and late-layer Label Heads as actor-name shortcuts?
- **Basis in paper**: [explicit] The authors state, "further research is needed to understand if other types of shortcuts are processed similarly and if token attribution via HTA would work in those cases."
- **Why unresolved**: The study isolates a specific type of shortcut (actor names in reviews), leaving the universality of the identified mechanism unverified for other spurious correlations.
- **What evidence would resolve it**: Applying the path patching methodology to datasets containing syntactic or semantic shortcuts (e.g., lexical overlap in NLI) to see if the same layers and heads are implicated.

### Open Question 2
- **Question**: Do later transformer layers contain circuits that actively negate or remove label information when a shortcut is deemed irrelevant to the current context?
- **Basis in paper**: [explicit] The authors propose that "future work might investigate if later layers or token streams do not remove or negate label information when a shortcut is deemed irrelevant in the current context."
- **Why unresolved**: The current analysis focuses on how shortcuts positively influence predictions, not how models might successfully suppress them in out-of-distribution or over-ruled contexts.
- **What evidence would resolve it**: Analyzing residual stream updates in later layers to detect anti-correlated signals that counteract the initial Label Head outputs.

### Open Question 3
- **Question**: How can Head-based Token Attribution be refined to distinguish between a token acting as a shortcut versus a token that is simply accumulating necessary contextual information?
- **Basis in paper**: [explicit] The authors note a limitation: "HTA only identifies which token stream contains the class information... [which] could misleadingly suggest that the final token itself is most relevant, when it may simply be accumulating contextual information."
- **Why unresolved**: HTA currently flags the location of class information but lacks the granularity to determine if that location represents a premature decision (shortcut) or a final aggregation (proper reasoning).
- **What evidence would resolve it**: Developing methods to trace the flow of information into the flagged token to verify if it originates from a narrow subset of tokens (shortcut) or the full input.

## Limitations
- The identified shortcut processing circuit may not generalize to other shortcut types beyond actor names in movie reviews
- The ActorCorr dataset represents a controlled synthetic environment that may not capture the complexity of real-world shortcuts
- The approach focuses on token-level shortcuts and may not address higher-level shortcuts operating at phrase or semantic levels

## Confidence
- **High confidence**: The existence of Label Heads and their role in shortcut processing (verified through path patching with 57-69% faithfulness)
- **Medium confidence**: The MLP0 enrichment hypothesis (based on component-level analysis but requires further validation)
- **Medium confidence**: HTA's effectiveness as a shortcut detection tool (strong empirical results but limited to this specific domain)

## Next Checks
1. **Circuit generalization test**: Apply the path patching methodology to a different shortcut type (e.g., location names correlated with sentiment) and verify whether the same MLP0 → Label Heads pattern emerges, or whether a different circuit structure is required.

2. **HTA robustness evaluation**: Test HTA on real-world datasets with naturally occurring shortcuts (not synthetically injected) to assess whether it maintains high AUROC and Cohen's d scores when shortcuts are less clean and more distributed across the input.

3. **Ablation completeness verification**: Beyond disabling shortcut-related heads, systematically ablate other components (different MLP layers, earlier attention heads) to determine whether the proposed circuit captures the complete shortcut processing pathway or if additional components contribute significantly.