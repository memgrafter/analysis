---
ver: rpa2
title: Explainable Earth Surface Forecasting under Extreme Events
arxiv_id: '2410.01770'
source_url: https://arxiv.org/abs/2410.01770
tags:
- next
- data
- event
- available
- kndvi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study introduces DeepExtremeCubes, a dataset comprising 40,000\
  \ Sentinel-2 minicubes and labeled extreme events, to train a convolutional long\
  \ short-term memory (convLSTM) model for forecasting vegetation impacts under extreme\
  \ climate conditions. The model predicts future reflectances and kernel NDVI (kNDVI),\
  \ achieving an R\xB2 score of 0.9055 on the test set."
---

# Explainable Earth Surface Forecasting under Extreme Events

## Quick Facts
- arXiv ID: 2410.01770
- Source URL: https://arxiv.org/abs/2410.01770
- Reference count: 40
- Primary result: ConvLSTM model achieves R² score of 0.9055 for forecasting vegetation impacts under extreme events

## Executive Summary
This study introduces DeepExtremeCubes, a dataset of 40,000 Sentinel-2 minicubes with labeled extreme events, to train a convolutional long short-term memory (convLSTM) model for forecasting vegetation impacts under extreme climate conditions. The model predicts future reflectances and kernel NDVI (kNDVI) with strong performance (R² = 0.9055) on the test set. Explainable AI techniques, specifically Integrated Gradients, are applied to analyze feature importance during the October 2020 Central South America heatwave, revealing regime shifts in predictor importance before the event that suggest potential for early warning.

## Method Summary
The study employs a 3-layer convLSTM architecture with 768k parameters trained on the DeepExtremeCubes dataset, which contains ~40,000 Sentinel-2 minicubes (128×128 pixels, 2.5×2.5 km) with 495 timesteps from January 2016 to October 2022. The model predicts future Sentinel-2 reflectances and kNDVI one timestep (5 days) ahead using a weighted L1 loss function with weights of 0.125 for raw reflectances and 0.5 for kNDVI. Training uses 4 epochs with batch size 1 and AdamW optimizer (lr=0.001), with data split based on geographic distance (>50km) and temporal separation to prevent leakage.

## Key Results
- ConvLSTM model achieves R² score of 0.9055 on test set for forecasting vegetation impacts
- Integrated Gradients analysis reveals regime shift in feature importance before the October 2020 Central South America heatwave
- Temperature and surface pressure are key predictors under normal conditions, while evaporation and surface latent heat flux anomalies dominate during extreme events

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The convLSTM architecture captures both spatial and temporal dependencies in Sentinel-2 imagery for vegetation impact forecasting.
- Mechanism: Convolutional LSTM layers apply spatial convolutions to input features and then process them through LSTM memory cells, allowing the model to learn both spatial patterns (via convolution) and temporal evolution (via LSTM gates).
- Core assumption: The vegetation impacts and extreme event signals can be effectively represented as spatial-temporal patterns that can be learned by convolutional and recurrent operations.
- Evidence anchors:
  - [abstract]: "convolutional long short-term memory-based architecture on the novel DeepExtremeCubes dataset"
  - [section]: "The employed architecture is a standard 3-layer convLSTM with a total of 768k parameters"
  - [corpus]: Weak correlation found (0.297), suggesting limited prior work on convLSTM for extreme events specifically

### Mechanism 2
- Claim: Explainable AI via Integrated Gradients reveals regime shifts in predictor importance before extreme events.
- Mechanism: Integrated Gradients computes attributions by integrating gradients along the path from a baseline to the input, attributing changes in model output to input features. By comparing attributions during normal vs. extreme conditions, regime shifts in feature importance become visible.
- Core assumption: The model's decision-making process changes meaningfully between normal and extreme conditions, and these changes are captured in feature attributions.
- Evidence anchors:
  - [abstract]: "Explainable artificial intelligence was used to analyze the model's predictions during the October 2020 Central South America compound heatwave and drought event"
  - [section]: "Integrated Gradients (IG) [51] (computed over nine integration steps) was used for the experiments"
  - [section]: "A change of regime is also observed in the attributions before the event, which might help assess how long the event was brewing before happening"

### Mechanism 3
- Claim: Self-supervised training on reflectance anomalies improves model generalization to extreme events.
- Mechanism: By training to predict future reflectances (anomalies relative to climatology), the model learns a representation space where normal variability is compressed and extreme deviations stand out, making extreme event detection more effective.
- Core assumption: Vegetation response to extreme events creates anomalous reflectance patterns that deviate significantly from climatological norms.
- Evidence anchors:
  - [abstract]: "The model achieved an R$^2$ score of 0.9055 in the test set"
  - [section]: "the model was trained to predict the same Sentinel-2 input bands, but one timestep (five days) into the future"
  - [section]: "By weighted sum) with weights 0.125, 0.125, 0.125, 0.125, and 0.5 respectively"

## Foundational Learning

- Concept: Spatio-temporal data representation and tensor operations
  - Why needed here: The DeepExtremeCubes dataset is structured as multi-dimensional tensors (xst, xs, xt) requiring understanding of how to manipulate and combine spatial, temporal, and channel dimensions
  - Quick check question: Can you explain how the input tensors xst, xs, and xt are combined before being fed to the convLSTM?

- Concept: Convolutional LSTM architecture and its variants
  - Why needed here: The model uses convLSTM layers, which combine convolutional operations with LSTM memory cells - understanding the architecture is essential for implementation and debugging
  - Quick check question: What is the key difference between standard LSTM and convLSTM in terms of input processing?

- Concept: Explainable AI methods and feature attribution
  - Why needed here: The study applies Integrated Gradients to understand model predictions during extreme events, requiring knowledge of attribution methods and their interpretation
  - Quick check question: How does Integrated Gradients differ from simpler attribution methods like input×gradient?

## Architecture Onboarding

- Component map: Input pipeline → Tensor preprocessing (xst, xs, xt) → convLSTM layers (3×) → 2D convolutions → Perceptron → Output layers (B02, B03, B04, B8A, kNDVI)
- Critical path: Data loading → Preprocessing → Model forward pass → Loss computation (kNDVI + reflectances) → Backpropagation → Optimization
- Design tradeoffs: convLSTM vs. standard LSTM (spatial context vs. parameter efficiency), L1 vs. L2 loss (detail preservation vs. noise robustness), direct kNDVI prediction vs. indirect (computational stability vs. direct optimization)
- Failure signatures: Training instability (loss explosion), poor generalization (high validation/test error), attribution artifacts (uniform or nonsensical feature importance), cloud handling failures (predictions where clouds are present)
- First 3 experiments:
  1. Verify data preprocessing pipeline produces correct tensor shapes and values by running on a small subset
  2. Train a minimal model (single convLSTM layer) on a small subset to verify basic functionality
  3. Apply Integrated Gradients to a simple trained model on a single sample to verify attribution computation works

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model's performance change when using other vegetation indices like NDVI or NIRv instead of kNDVI?
- Basis in paper: [explicit] The paper compares kNDVI with NDVI and NIRv in terms of their correlation with Gross Primary Production and Solar-Induced Chlorophyll Fluorescence, but does not explore their impact on model performance.
- Why unresolved: The paper only evaluates the model's performance using kNDVI, leaving the impact of other vegetation indices unexplored.
- What evidence would resolve it: Conducting experiments using NDVI and NIRv as the target vegetation indices and comparing their performance metrics with those of kNDVI.

### Open Question 2
- Question: How does the model's performance vary when trained on different geographical regions or climate zones?
- Basis in paper: [inferred] The paper mentions that the dataset includes minicubes sampled from locations affected by extreme climate events worldwide, but does not analyze the model's performance across different regions or climate zones.
- Why unresolved: The paper does not provide a detailed analysis of the model's performance in different geographical regions or climate zones.
- What evidence would resolve it: Training and evaluating the model separately on minicubes from different geographical regions or climate zones and comparing their performance metrics.

### Open Question 3
- Question: How does the model's performance change when using different aggregation strategies for the ERA5-Land variables?
- Basis in paper: [explicit] The paper mentions that the ERA5-Land variables are aggregated to match the five-day spatio-temporal data, but does not explore the impact of different aggregation strategies on model performance.
- Why unresolved: The paper does not provide a detailed analysis of the impact of different aggregation strategies on the model's performance.
- What evidence would resolve it: Conducting experiments using different aggregation strategies for the ERA5-Land variables and comparing their performance metrics with the current approach.

## Limitations

- Model performance metrics based on relatively short training period (4 epochs) with small batch size (1)
- Geographic and temporal split methodology could introduce bias if extreme events have non-random spatial distribution
- Integrated Gradients implementation uses only 9 integration steps, potentially missing critical attribution patterns

## Confidence

**High Confidence:** The core methodology of using convLSTM for spatio-temporal forecasting is well-established in the literature. The dataset creation methodology and model architecture are clearly specified with sufficient detail for reproduction.

**Medium Confidence:** The model's R² score of 0.9055 on the test set is impressive, but without comparison to baseline methods or ablation studies, it's unclear whether this represents state-of-the-art performance or expected accuracy for this type of forecasting task.

**Low Confidence:** The regime shift detection through explainable AI is promising but requires further validation. The study shows attribution changes before the October 2020 event, but without testing on multiple extreme events or establishing what constitutes a statistically significant attribution shift, these findings remain preliminary.

## Next Checks

1. **Attribution Robustness Test:** Repeat the Integrated Gradients analysis with 50+ integration steps and compare results to verify that the 9-step implementation doesn't miss critical attribution patterns.

2. **Multiple Event Validation:** Apply the attribution analysis to at least 5-10 additional extreme events across different regions and seasons to establish whether regime shifts are consistently detectable before extreme events.

3. **Baseline Comparison:** Implement and evaluate at least two baseline forecasting methods (e.g., standard LSTM without convolutions, persistence model) on the same dataset to contextualize the convLSTM performance metrics.