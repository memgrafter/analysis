---
ver: rpa2
title: 'Masked Multi-Domain Network: Multi-Type and Multi-Scenario Conversion Rate
  Prediction with a Single Model'
arxiv_id: '2403.17425'
source_url: https://arxiv.org/abs/2403.17425
tags:
- conversion
- prediction
- display
- learning
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the multi-type and multi-scenario conversion
  rate prediction problem in online advertising systems, where conversions have different
  types (e.g., purchase vs. sign up) and ads are shown in different display scenarios
  (e.g., banner vs.
---

# Masked Multi-Domain Network: Multi-Type and Multi-Scenario Conversion Rate Prediction with a Single Model

## Quick Facts
- arXiv ID: 2403.17425
- Source URL: https://arxiv.org/abs/2403.17425
- Authors: Wentao Ouyang; Xiuwu Zhang; Chaofeng Guo; Shukui Ren; Yupei Sui; Kun Zhang; Jinmei Luo; Yunfeng Chen; Dongbo Xu; Xiangzheng Liu; Yanlong Du
- Reference count: 36
- Key outcome: Proposed MMN achieves highest AUC in most cases, with online CVR improvements of 3.2% to 12.6% and CPM improvement of 5.1% in industrial deployment

## Executive Summary
This paper addresses the challenge of conversion rate prediction in online advertising systems where conversions have different types (e.g., purchase vs. sign up) and ads are shown in different display scenarios (e.g., banner vs. news feed). The authors propose the Masked Multi-Domain Network (MMN) to simultaneously satisfy accuracy, scalability, and convenience requirements. MMN uses a parameter sharing and composition strategy that reduces model parameters from a product space to a sum space, enabling a single model to handle all conversion type and display scenario combinations efficiently.

## Method Summary
The MMN architecture consists of a shared embedding lookup table and CTR tower, followed by multiple CVR towers (one per conversion type-display scenario combination). The key innovations include: (1) parameter sharing and composition that creates ð‘ð‘¡ + ð‘ð‘  + 1 sets of parameters to generate ð‘ð‘¡ Ã— ð‘ð‘  combinations, (2) an auto-masking strategy that allows mixed data from all domains to be processed in a single mini-batch, and (3) a dynamically weighted loss function that addresses loss scale imbalance across domains. The model is trained end-to-end with backpropagation through all components.

## Key Results
- MMN achieves the highest AUC compared to state-of-the-art methods in most cases
- Online deployment shows CVR improvements of 3.2% to 12.6% and CPM improvement of 5.1%
- Parameter reduction from 357 to 39 sets (89.1% reduction) in the Criteo dataset while maintaining performance
- Auto-masking strategy enables single-dataset training without data partitioning overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The parameter sharing and composition strategy reduces model parameters from a product space to a sum space, making the model scalable.
- Mechanism: Instead of creating separate parameter sets for each (conversion type, display scenario) pair, MMN uses one shared parameter set plus type-specific and scenario-specific parameter sets. This allows generation of all combinations while drastically reducing total parameters.
- Core assumption: Different conversion types and display scenarios share some underlying patterns that can be captured by common parameters.
- Evidence anchors:
  - [section] "we design a parameter sharing and composition strategy as follows... reduce model parameters from a product space to a sum space"
  - [section] "we only create ð‘ð‘¡ + ð‘ð‘  + 1 sets of domain-specific parameters, but can generate ð‘ð‘¡ Ã— ð‘ð‘  combinations"
  - [section] "Compared with these methods, MMN reduces the number of sets of domain-specific parameters from 357 to 39 (i.e., 89.1% reduction) in the Criteo dataset"

### Mechanism 2
- Claim: The auto-masking strategy enables processing mixed data from all domains in a single mini-batch without requiring separate datasets.
- Mechanism: For each instance in a mini-batch, MMN creates a mask vector that identifies which CVR tower should process it. The model processes all instances through all towers but only the masked outputs contribute to the final prediction.
- Core assumption: Modern deep learning frameworks can efficiently handle element-wise operations and masking without significant overhead.
- Evidence anchors:
  - [section] "We propose the following auto-masking strategy... can take mixed data from all the domains as input"
  - [section] "By using the auto-masking strategy, we allow a mini-batch of instances from different (conversion type, display scenario) domains to be computed simultaneously"
  - [section] "It avoids the overhead caused by data partitioning, individual processing and separate storage"

### Mechanism 3
- Claim: The dynamically weighted loss addresses loss scale imbalance across different domains within each mini-batch.
- Mechanism: Instead of using a fixed normalization factor for all domains, MMN weights each instance's loss by the ratio of total batch size to the number of instances in that domain, ensuring each domain contributes equally to the overall loss.
- Core assumption: Different domains have different sample frequencies in each mini-batch, and without weighting, domains with fewer samples would be underweighted in the loss calculation.
- Evidence anchors:
  - [section] "we propose the dynamically weighted loss as... dynamically computed within each mini-batch"
  - [section] "the average loss applied on each domain is actually ð‘ð‘/ð‘ð‘Ž â‰¤ ð‘Ž and varies from one domain to another"
  - [section] "Figure 6 plots the AUC difference between MMN and MMN (no dynamic weight)... AUCs of MMN improve a lot compared with MMN (no dynamic weight)"

## Foundational Learning

- Concept: Multi-task vs Multi-domain learning
  - Why needed here: Understanding the distinction is crucial because MMN is a multi-domain model (same task, different domains) while many related works are multi-task models (same domain, different tasks)
  - Quick check question: In multi-task learning, do different tasks share the same input domain? (Answer: Yes)

- Concept: Parameter sharing and composition
  - Why needed here: The core innovation of MMN relies on understanding how to share parameters across domains while maintaining domain-specific capabilities
  - Quick check question: How many parameter sets does MMN create for ð‘ð‘¡ conversion types and ð‘ð‘  display scenarios? (Answer: ð‘ð‘¡ + ð‘ð‘  + 1)

- Concept: Dynamic weighting in loss functions
  - Why needed here: The dynamically weighted loss is essential for addressing the imbalance issue when different domains have different sample frequencies in mini-batches
  - Quick check question: What is the weight applied to an instance in domain ð‘? (Answer: ð‘/ð‘ð‘)

## Architecture Onboarding

- Component map:
  Shared embedding lookup -> CTR tower -> CVR towers (all process all instances) -> Auto-masking layer -> Final prediction

- Critical path:
  1. Input features â†’ Shared embedding lookup
  2. Shared embedding â†’ CTR tower (for all instances)
  3. Shared embedding + type/scenario â†’ CVR towers (all towers process all instances)
  4. Auto-masking â†’ Select correct CVR predictions
  5. Combine masked predictions â†’ Final CVR output
  6. Compute dynamically weighted loss â†’ Backpropagation

- Design tradeoffs:
  - Memory vs. Accuracy: Using more type-specific and scenario-specific parameters increases model size but improves accuracy
  - Speed vs. Convenience: Auto-masking allows single-dataset training but requires processing through all CVR towers
  - Complexity vs. Scalability: Parameter sharing reduces model size but requires careful design of the composition strategy

- Failure signatures:
  - Out-of-memory errors: Indicates too many CVR towers or insufficient parameter sharing
  - Poor convergence: May indicate incorrect dynamic weighting or insufficient training data per domain
  - Inaccurate predictions for rare combinations: Suggests insufficient data or inadequate parameter sharing for that domain

- First 3 experiments:
  1. Compare MMN with and without type-specific parameters on a dataset with known type differences
  2. Test the dynamic weighting by training with and without it on a highly imbalanced dataset
  3. Measure the computational overhead of auto-masking by comparing single-dataset vs. multi-dataset training approaches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the MMN model handle extreme class imbalance in conversion types with very low conversion rates (e.g., 0.05%) versus high conversion rates (e.g., 27.6%)?
- Basis in paper: [explicit] The paper mentions that different conversion types have vastly different CVRs (e.g., from 0.05% to 27.6%) and proposes dynamically weighted loss to address loss scale imbalance within each mini-batch
- Why unresolved: The paper only mentions that the dynamically weighted loss accounts for loss scale imbalance, but doesn't provide detailed analysis of how well this works for extreme CVR ranges or whether additional techniques might be needed
- What evidence would resolve it: Detailed ablation studies showing MMN performance with and without dynamic weighting across different CVR ranges, or comparison with specialized techniques for extreme class imbalance

### Open Question 2
- Question: What is the computational overhead of the auto-masking strategy during training compared to traditional data partitioning approaches?
- Basis in paper: [inferred] The paper claims auto-masking avoids overhead from data partitioning and separate storage, but doesn't provide quantitative comparison of computational costs
- Why unresolved: While the paper mentions that auto-masking reduces data processing overhead, it doesn't provide concrete measurements of training time or memory usage compared to partitioned approaches
- What evidence would resolve it: Detailed runtime and memory consumption analysis comparing MMN with auto-masking versus traditional multi-domain approaches with data partitioning

### Open Question 3
- Question: How does the parameter sharing strategy in MMN affect model performance when conversion types have very different feature importance patterns?
- Basis in paper: [explicit] The paper mentions that type-specific and scenario-specific parameters capture different natures of conversion types and display scenarios, and shows MMN outperforms a version with only common parameters
- Why unresolved: The paper shows that type-specific parameters help, but doesn't analyze how well the parameter sharing strategy handles cases where different conversion types rely on completely different features
- What evidence would resolve it: Analysis of feature importance patterns across different conversion types and how the shared versus specific parameters adapt to these differences, possibly through visualization or ablation studies

## Limitations
- Evaluation relies heavily on a single industrial dataset with limited details about data preprocessing
- Computational overhead of auto-masking strategy is not thoroughly quantified
- Dynamically weighted loss may not generalize well to scenarios with highly skewed domain distributions
- Cold-start problems for new conversion types or display scenarios are not addressed

## Confidence
- High confidence: The parameter sharing and composition strategy effectively reduces model parameters while maintaining performance
- Medium confidence: The auto-masking strategy provides significant convenience benefits without substantial computational overhead
- Medium confidence: The dynamically weighted loss appropriately addresses domain imbalance within mini-batches

## Next Checks
1. Evaluate MMN on multiple public datasets with different domain distributions to test generalization of the dynamically weighted loss approach
2. Measure and compare the computational overhead of auto-masking versus traditional data partitioning approaches across different batch sizes
3. Test the model's performance on scenarios with new (unseen) conversion type and display scenario combinations to assess cold-start capabilities