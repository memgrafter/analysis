---
ver: rpa2
title: Diverse capability and scaling of diffusion and auto-regressive models when
  learning abstract rules
arxiv_id: '2411.07873'
source_url: https://arxiv.org/abs/2411.07873
tags:
- diffusion
- samples
- panel
- rule
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares diffusion and autoregressive models on a rule
  learning task using a synthetic dataset of Raven's Progressive Matrices encoded
  as integer arrays. The authors trained both model families on 40 relational rules
  governing object position, number, or attributes, and evaluated their ability to
  generate consistent samples and complete missing panels.
---

# Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules

## Quick Facts
- arXiv ID: 2411.07873
- Source URL: https://arxiv.org/abs/2411.07873
- Authors: Binxu Wang; Jiaqi Shang; Haim Sompolinsky
- Reference count: 40
- Primary result: Diffusion models (particularly SiT) excel at unconditional generation while autoregressive models (particularly GPT2) perform better at panel completion tasks

## Executive Summary
This paper compares diffusion and autoregressive models on a rule learning task using synthetic Raven's Progressive Matrices encoded as integer arrays. The authors trained both model families on 40 relational rules governing object position, number, or attributes, and evaluated their ability to generate consistent samples and complete missing panels. The study reveals fundamental architectural differences: diffusion models excel at unconditional generation through holistic denoising, while autoregressive models show better conditional generation but struggle with sample consistency due to error compounding.

## Method Summary
The study used the GenRAVEN dataset with 40 relational rules applied to synthetic RPM-like structures encoded as 3×9×9 integer arrays. Both diffusion models (EDM, DiT, SiT) and autoregressive models (GPT2, Mamba) were trained on 4000 random samples per rule. Evaluation included unconditional generation consistency (valid row fraction, C3 sample fraction), panel completion accuracy using Twisted Diffusion Sampler for diffusion models and greedy sampling for autoregressive models, and memorization analysis across different dataset scales (400 vs 4000 samples per rule).

## Key Results
- Diffusion models (SiT) produce more structurally consistent samples from scratch and show minimal memorization of training data
- Autoregressive models (GPT2) perform better at panel completion tasks but generate less consistent samples unconditionally and show more memorization
- Diffusion models improve both generation and completion with more data, while autoregressive models improve only at completion as dataset size increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion models excel at unconditional generation because they maintain a holistic view of the sample throughout the denoising process, allowing corrections at any stage
- Mechanism: During sampling, diffusion models start from Gaussian noise and progressively denoise all tokens/pixels simultaneously through learned vector fields. This allows them to revise any part of the generation at any timestep, preventing error accumulation
- Core assumption: The diffusion process can effectively capture the joint distribution without compounding errors
- Evidence anchors:
  - [abstract] "diffusion models excel at unconditional generation, producing novel and more consistent samples from scratch and memorize less"
  - [section] "diffusion models have a holistic view of the sample from the start and can always change any token on the RPM, which may lead to higher structural consistency of the samples"
  - [corpus] Weak evidence - no direct comparison of diffusion vs autoregressive error compounding in the corpus

### Mechanism 2
- Claim: Autoregressive models show higher memorization because they generate sequences token-by-token without ability to revise earlier decisions
- Mechanism: Each generated token conditions only on previous tokens, so errors compound exponentially. When the model encounters similar contexts during generation, it defaults to regurgitating training sequences
- Core assumption: The conditional independence assumption of autoregressive models leads to error propagation
- Evidence anchors:
  - [section] "autoregressive models default to memorize more global rows and samples" and "many valid generated rows from GPT2 models are simply regurgitating their training sequences"
  - [section] "even if the conditional probability of sampling each token is slightly off, autoregressive sampling will lead to exponentially compounding errors"
  - [corpus] No direct corpus evidence on autoregressive memorization patterns

### Mechanism 3
- Claim: Twisted Diffusion Sampler improves conditional generation by maintaining a population of particles and re-weighting them during sampling
- Mechanism: TDS uses Sequential Monte Carlo techniques to maintain multiple candidate samples and re-weight them based on how well they match the conditioning information, providing asymptotically exact conditional sampling
- Core assumption: Maintaining multiple particles and re-weighting them can better capture the conditional distribution than heuristic methods
- Evidence anchors:
  - [section] "TDS maintains a population of particles and re-weights them during sampling, leveraging the twisting technique from Sequential Monte Carlo (SMC) literature"
  - [section] "we tested both methods on our task and found TDS performed much better than the Repaint method: on DiT-S/1 model, TDS yielded an overall C3 completion accuracy (across all 40 rules) of 45.2% while Repaint yielded accuracy 26.1%"
  - [corpus] Weak evidence - no corpus papers directly comparing TDS to other conditional sampling methods

## Foundational Learning

- Concept: Discrete vs continuous data representation
  - Why needed here: The paper converts RPM data to integer arrays (discrete) but diffusion models traditionally work with continuous data, requiring normalization and rounding strategies
  - Quick check question: How would you handle the conversion between discrete RPM attributes and continuous diffusion model outputs?

- Concept: Joint vs conditional probability distributions
  - Why needed here: Unconditional generation requires modeling the full joint distribution p(X), while panel completion requires conditional sampling p(missing|observed)
  - Quick check question: What's the mathematical relationship between unconditional generation capability and conditional generation performance?

- Concept: Data scaling and model capacity tradeoffs
  - Why needed here: The paper shows divergent scaling behaviors - diffusion models improve with more data while autoregressive models show declining unconditional consistency
  - Quick check question: How would you design an experiment to determine the optimal data-to-model-size ratio for each architecture?

## Architecture Onboarding

- Component map: Input pipeline (3×9×9 integer arrays) → Model backbone (UNet/DiT/SiT or GPT2/Mamba) → Sampling method (Heun/DDIM/Runge-Kutta for diffusion, temperature sampling for autoregressive) → Evaluation (C3 consistency, memorization analysis)
- Critical path: Data preprocessing → Model training → Conditional sampling (for completion tasks) → Evaluation metrics computation
- Design tradeoffs: Diffusion models offer holistic correction but require complex sampling; autoregressive models are simpler to train but suffer from error compounding
- Failure signatures: Low C3 consistency indicates poor rule learning; high memorization rates suggest overfitting to training samples; divergent scaling behavior may indicate architecture mismatch with task requirements
- First 3 experiments:
  1. Replicate unconditional generation consistency comparison between SiT and GPT2 models
  2. Test TDS vs Repaint sampling methods on panel completion for a diffusion model
  3. Vary dataset size (400, 4000, 40000 samples per rule) to observe scaling behavior differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific inductive biases or architectural modifications could help autoregressive models generate more structurally consistent samples from scratch?
- Basis in paper: [explicit] The paper discusses that autoregressive models struggle with unconditional generation consistency and proposes potential solutions like beam search and improved positional encoding.
- Why unresolved: The paper identifies the problem but doesn't test specific architectural modifications or sampling techniques beyond basic temperature sampling.
- What evidence would resolve it: Comparative experiments testing autoregressive models with various architectural modifications (e.g., different positional encodings, cross-scale attention, beam search) against baseline models on the same rule learning task.

### Open Question 2
- Question: How does the sample complexity of rule learning differ between humans and AI models across different rule types?
- Basis in paper: [explicit] The paper notes that current models require thousands of examples per rule while humans can learn with fewer samples, and suggests comparative studies with human subjects.
- Why unresolved: The paper doesn't include human behavioral experiments and only speculates about the sample complexity gap.
- What evidence would resolve it: Direct behavioral experiments comparing human subjects and AI models on the same rule learning tasks with systematically varied sample sizes and rule types.

### Open Question 3
- Question: What are the fundamental computational differences between diffusion and autoregressive models that lead to their divergent scaling behaviors in conditional versus unconditional generation?
- Basis in paper: [explicit] The paper observes that diffusion models improve both tasks with more data while autoregressive models show diverging scaling properties, and discusses potential reasons related to compounding errors.
- Why unresolved: The paper provides theoretical speculation but doesn't conduct detailed computational analysis or ablation studies to isolate the mechanisms.
- What evidence would resolve it: Detailed computational analysis comparing information flow, error propagation, and representation dynamics in both model families during training and sampling, potentially through activation analysis or information-theoretic measures.

## Limitations
- The GenRAVEN dataset uses synthetic RPM-like structures that may not generalize to natural language or image data
- Performance differences heavily depend on sampling strategies, creating an apples-to-oranges comparison
- The study focuses on specific dataset scales without exploring the full spectrum of data efficiency or saturation points

## Confidence
- High Confidence: The fundamental architectural observation that diffusion models maintain holistic views while autoregressive models generate sequentially
- Medium Confidence: The specific performance metrics and their interpretation for the GenRAVEN dataset
- Low Confidence: The claimed superiority of Twisted Diffusion Sampler over alternative methods across different conditional generation scenarios

## Next Checks
1. Replicate the unconditional generation and panel completion experiments on natural image datasets (e.g., CIFAR-10 with synthetic rules) to verify whether diffusion models maintain their holistic advantage when pixel-level semantics replace abstract integer encodings
2. Implement and compare equivalent advanced sampling methods for both model families - apply beam search or chain-of-thought prompting to autoregressive models and test heuristic sampling for diffusion models - to isolate architectural differences from sampling strategy effects
3. Conduct experiments across 10× to 1000× more data and parameters to identify the true scaling breakpoints where diffusion and autoregressive models diverge in their learning curves, particularly focusing on the dataset size where unconditional consistency begins declining for autoregressive models