---
ver: rpa2
title: 'Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic
  Review of Recent Developments and Challenges'
arxiv_id: '2407.00116'
source_url: https://arxiv.org/abs/2407.00116
tags:
- data
- synthetic
- medical
- images
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review surveys recent advances in generative AI
  for synthetic medical data across multiple modalities (imaging, EHR, signals, text).
  It identifies a shift beyond GANs to diffusion models, transformers, and large language
  models, highlighting applications in data augmentation, privacy preservation, and
  personalized synthesis.
---

# Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges

## Quick Facts
- arXiv ID: 2407.00116
- Source URL: https://arxiv.org/abs/2407.00116
- Reference count: 40
- Primary result: Survey identifies shift from GANs to diffusion models and LLMs for medical synthetic data, highlighting gaps in clinical knowledge integration and evaluation standardization

## Executive Summary
This systematic review examines recent advances in generative AI for synthetic medical data across imaging, EHR, signals, and text modalities. The review identifies a significant shift from traditional GANs toward diffusion models, transformers, and large language models, with applications spanning data augmentation, privacy preservation, and personalized synthesis. However, substantial gaps remain in leveraging clinical knowledge, patient-specific context, and comprehensive evaluation frameworks beyond augmentation. The review emphasizes the need for tailored generative approaches that consider medical domain specifics, diverse clinical validation, and standardized benchmarking to ensure synthetic data's utility and trustworthiness in healthcare AI.

## Method Summary
The survey employed a systematic review methodology querying Scopus, PubMed, and ArXiv databases for original research papers published between January 2021 and November 2023. The search focused on papers covering four data modalities (EHR, physiological signals, clinical text, and medical images) and four generative model types (GANs, VAEs, DMs, and LLMs). Papers were screened according to PRISMA guidelines, excluding reviews and perspectives to capture recent advancements. Findings were categorized by modality and synthesis applications, with tables summarizing generation techniques, evaluation methods, and code availability across different medical domains.

## Key Results
- Diffusion models are emerging as stable alternatives to GANs for medical image synthesis, avoiding mode collapse and vanishing gradients
- Cross-modal synthesis without fine-tuning is possible through shared latent space representations across different medical imaging modalities
- Significant gaps exist in standardized evaluation frameworks and comparative studies, hindering clinical adoption of synthetic data

## Why This Works (Mechanism)

### Mechanism 1
Latent diffusion models trained on heterogeneous medical datasets can generate high-fidelity synthetic images across multiple modalities without fine-tuning. The shared latent space compresses diverse imaging data into a common representation where denoising diffusion operates, enabling modality-agnostic synthesis. This works because medical image characteristics across modalities are sufficiently similar in latent space for shared training to be effective.

### Mechanism 2
Textual conditioning through CLIP embeddings enables precise control over synthetic medical image generation. Text prompts are encoded into CLIP embeddings that guide the diffusion process, aligning generated images with clinical descriptions. This mechanism relies on CLIP's vision-language alignment generalizing effectively to medical domain concepts and terminology.

### Mechanism 3
Diffusion models are more stable than GANs for medical image synthesis, avoiding mode collapse and vanishing gradients. The iterative denoising process in diffusion models provides more stable training dynamics compared to adversarial training. This stability translates to better synthetic medical image quality in practice.

## Foundational Learning

- **Medical image acquisition physics and noise characteristics**: Understanding real imaging artifacts is crucial for evaluating synthetic data fidelity. Quick check: What are the primary sources of noise in CT vs MRI images?
- **Latent space representation and compression**: The effectiveness of cross-modal synthesis depends on how well different modalities map to shared latent space. Quick check: How does VQ-VAE quantization affect the preservation of fine medical details?
- **CLIP text-image alignment**: Text conditioning requires understanding how language models map to visual concepts in medical domain. Quick check: What limitations does CLIP have when representing specialized medical terminology?

## Architecture Onboarding

- **Component map**: Medical image → VQ-VAE → Latent → Diffusion → CLIP-guided denoising → Output
- **Critical path**: Image → VQ-VAE → Latent → Diffusion → CLIP-guided denoising → Output
- **Design tradeoffs**: Computational cost vs. synthesis quality, model capacity vs. overfitting on limited medical datasets, text conditioning granularity vs. generation control
- **Failure signatures**: Poor latent space alignment across modalities, text conditioning not reflecting in generated images, mode collapse in diffusion process
- **First 3 experiments**:
  1. Test cross-modal synthesis on paired CT-MRI dataset with/without fine-tuning
  2. Evaluate CLIP-guided generation using radiology report prompts
  3. Compare diffusion vs. GAN stability on small medical datasets

## Open Questions the Paper Calls Out

### Open Question 1
How can synthetic data be effectively used beyond augmentation for model validation and testing in medical AI? Despite its potential, synthetic data is underutilized beyond augmentation and could serve as a comprehensive validation and testing set during model development. This remains unresolved due to lack of concrete methodologies or case studies for implementation.

### Open Question 2
What are the optimal strategies for tailoring generative approaches to the unique characteristics of medical data and specific downstream tasks? Most synthetic methods still largely rely on loss functions and architectures initially designed for natural images, without considering the intricate aspects of medical image acquisition, physics and well-defined statistics that can guide the generative process. The paper highlights the need for tailoring but does not provide specific recommendations.

### Open Question 3
How can generative models be enhanced to leverage clinical knowledge, patient context, and text for more realistic and personalized medical data synthesis? A significant gap exists in the utilization of prior clinical knowledge, leading to potentially sub-optimal results. The paper identifies this gap but does not propose concrete methods for incorporating these elements into generative models.

## Limitations

- Evaluation framework standardization is lacking across modalities, with inconsistent metrics and validation approaches
- Cross-modal generalization claims are based on limited evidence and may not hold across diverse medical imaging scenarios
- Clinical knowledge integration into generative models remains largely theoretical with limited practical implementations

## Confidence

- **High Confidence**: Identification of shift from GANs to diffusion models and LLMs is well-supported by systematic review methodology
- **Medium Confidence**: Claims about diffusion model stability advantages over GANs are supported but lack comprehensive comparative studies
- **Low Confidence**: Specific claims about cross-modal synthesis without fine-tuning and CLIP's effectiveness in medical domains are based on limited evidence

## Next Checks

1. Conduct controlled experiments comparing cross-modal synthesis performance with and without modality-specific fine-tuning across at least three different medical imaging pairs (CT-MRI, X-ray-MRI, Ultrasound-MRI)
2. Develop and test a standardized evaluation framework that includes both quantitative metrics (FID, IS) and qualitative clinical validation across at least two medical imaging modalities
3. Design and implement a study comparing synthetic data quality with and without clinical knowledge integration, using domain experts to evaluate both technical and clinical validity