---
ver: rpa2
title: Test-time Assessment of a Model's Performance on Unseen Domains via Optimal
  Transport
arxiv_id: '2405.01451'
source_url: https://arxiv.org/abs/2405.01451
tags:
- domain
- tetot
- target
- domains
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of assessing ML model performance
  on unseen domains at test time without requiring labeled data from those domains.
  The authors propose TETOT, a metric based on Optimal Transport that computes the
  distributional divergence between source and target domains using unlabeled target
  data and source domain information.
---

# Test-time Assessment of a Model's Performance on Unseen Domains via Optimal Transport

## Quick Facts
- arXiv ID: 2405.01451
- Source URL: https://arxiv.org/abs/2405.01451
- Reference count: 40
- This work addresses the problem of assessing ML model performance on unseen domains at test time without requiring labeled data from those domains.

## Executive Summary
This paper proposes TETOT, a test-time metric for estimating how well a pre-trained model will perform on unseen target domains. The method uses Optimal Transport (OT) to compute distributional divergence between source and target domains, combining feature distances from a pre-trained encoder with label consistency scores using pseudo-labels from the source classifier. TETOT achieves significantly higher correlation with true transferability compared to prediction entropy, particularly for architecture selection tasks, and can be computed using only source domain statistics when raw source data is unavailable.

## Method Summary
TETOT computes a distributional divergence metric between source and target domains using Optimal Transport. The method combines feature-level OT distance (using encoder outputs) with label-level OT distance (using pseudo-labels from the source classifier). The metric can be computed with unlabeled target data and either raw source data or source domain statistics (mean and covariance). For the statistics-only variant, TETOT uses a closed-form Wasserstein distance under Gaussian distribution assumptions. The method achieves high correlation with true transferability through a dual-view approach that captures both representation shift and semantic shift between domains.

## Key Results
- TETOT achieves significantly higher correlation with true transferability compared to prediction entropy, with Pearson correlation coefficients improving from -0.40 to -0.62 on PACS and from -0.29 to -0.40 on VLCS for architecture selection tasks.
- TETOT maintains high correlation even with limited samples (100-500) and can be computed using only source domain statistics when raw source data is unavailable.
- The method demonstrates strong performance across multiple practical applications including architecture selection, source domain selection, and performance estimation on unseen domains.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The combination of feature distances from a pre-trained encoder and label consistency scores via pseudo-labels creates a more informative distributional divergence metric than feature distance alone.
- Mechanism: TETOT constructs a base distance by summing feature-level OT distance (encoder outputs) and label-level OT distance (pseudo-labels from source classifier). This dual-view captures both representation shift and semantic shift between domains.
- Core assumption: Pseudo-labels from the source classifier provide meaningful label alignment even when incorrect, and the optimal transport coupling can still extract useful signal from noisy label alignments.
- Break Condition: If pseudo-labels are systematically incorrect across the entire target domain, or if the encoder's features are too degraded to form meaningful OT couplings, the metric will lose correlation.

### Mechanism 2
- Claim: Optimal Transport provides a geometry-aware divergence that is more sensitive to domain shift than marginal distribution distances like entropy.
- Mechanism: OT computes a coupling between source and target samples that respects the geometry of the feature/label space, yielding a transport cost that directly reflects how much "work" is needed to transform one domain into the other.
- Core assumption: The ground metric (feature + label cost) meaningfully captures the notion of "work" needed to adapt the model, and the OT coupling preserves this signal.
- Break Condition: If the feature/label space geometry is not aligned with transferability (e.g., noisy features or irrelevant label differences), the OT cost will not correlate well.

### Mechanism 3
- Claim: Access to source domain statistics (mean, covariance) enables transferability estimation even without raw source data, via closed-form Wasserstein distance under normality assumptions.
- Mechanism: By modeling source and target distributions as Gaussians, the 2-Wasserstein distance can be computed from statistics alone, avoiding the need for raw source samples.
- Core assumption: Both source and target distributions are approximately Gaussian in the feature space, so the closed-form Wasserstein distance is a valid approximation of the true OT distance.
- Break Condition: If feature distributions are highly non-Gaussian or multimodal, the closed-form approximation will break down and correlation will drop.

## Foundational Learning

- Concept: Optimal Transport (OT) basics
  - Why needed here: TETOT's core divergence measure is based on OT; understanding how OT computes couplings and transport costs is essential to grasp why it works better than simpler metrics.
  - Quick check question: What is the difference between computing OT distance with a cost matrix versus a ground metric, and why does the choice of cost matter for domain shift detection?

- Concept: Pseudo-label generation and its reliability
  - Why needed here: TETOT uses source classifier outputs as pseudo-labels for target data; knowing when and how these labels are trustworthy (or not) is key to understanding the metric's robustness.
  - Quick check question: Under what conditions would pseudo-labels from a source classifier be systematically wrong, and how would that affect TETOT's correlation?

- Concept: Wasserstein distance for Gaussian distributions
  - Why needed here: The approximate TETOT variant relies on the closed-form 2-Wasserstein distance for Gaussians; understanding this formula and its assumptions is required to implement or extend the method.
  - Quick check question: Write the formula for the 2-Wasserstein distance between two Gaussians in terms of their means and covariances.

## Architecture Onboarding

- Component map: Pre-trained encoder (g) and classifier (h) from source domain -> Feature extraction and normalization module -> Pairwise cost matrix construction (feature + label costs) -> OT solver (network simplex or Sinkhorn) -> Correlation computation and comparison module
- Critical path: 1. Sample source and target data 2. Compute encoder features 3. Build cost matrix (feature + label) 4. Solve OT to get coupling and cost 5. Use cost as transferability proxy
- Design tradeoffs:
  - Feature-only vs. feature+label cost: Adding labels improves correlation but requires pseudo-labels; dropping them saves computation but loses signal.
  - OT solver choice: Network simplex is exact but cubic; Sinkhorn is faster but approximate.
  - Sample size: More samples improve OT accuracy but increase cost; TETOT works well even with small samples.
- Failure signatures:
  - Very high OT cost but high accuracy: likely label noise or misaligned feature space.
  - Very low OT cost but low accuracy: possible feature collapse or source classifier not capturing target semantics.
  - Correlation drops when Î» is too high: label noise dominates feature signal.
- First 3 experiments:
  1. Verify OT cost correlates with accuracy drop on corrupted target domains (use PACS with synthetic corruptions).
  2. Compare feature-only vs. feature+label TETOT correlation on VLCS.
  3. Test TETOT-approx (Wasserstein from statistics) against full TETOT on a privacy-constrained dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TETOT compare to other distributional divergence metrics (e.g., KL divergence, total variation) in practical applications?
- Basis in paper: [inferred] The paper mentions that TETOT uses OT to estimate distributional divergence and highlights its effectiveness, but does not compare it to other divergence metrics.
- Why unresolved: The paper focuses on comparing TETOT with prediction entropy but does not explore other distributional divergence metrics.
- What evidence would resolve it: Conducting experiments comparing TETOT with other divergence metrics on the same benchmark datasets and applications would provide insights into its relative performance.

### Open Question 2
- Question: Can TETOT be extended to handle scenarios where the label sets of the source and target domains are different?
- Basis in paper: [explicit] The paper states that it works in the domain generalization setting where the label sets of the source and target domains are the same, unlike in transfer learning where they could be different.
- Why unresolved: The paper does not explore the applicability of TETOT to scenarios with different label sets.
- What evidence would resolve it: Developing and testing an extension of TETOT for different label sets on relevant datasets would demonstrate its broader applicability.

### Open Question 3
- Question: What is the impact of the choice of the encoder architecture on the performance of TETOT?
- Basis in paper: [inferred] The paper uses various pre-trained encoder architectures for evaluation but does not analyze how the choice of encoder affects TETOT's performance.
- Why unresolved: The paper does not provide a detailed analysis of the encoder's impact on TETOT's effectiveness.
- What evidence would resolve it: Conducting experiments with different encoder architectures and analyzing the correlation between TETOT and transferability for each would clarify the impact of the encoder choice.

## Limitations
- The method relies on pseudo-labels from the source classifier, whose accuracy on unseen domains is unknown at test time, introducing uncertainty.
- The closed-form Wasserstein approximation assumes Gaussian distributions, which may not hold for complex, multimodal feature distributions.
- The experimental scope is limited to standard domain generalization benchmarks (PACS, VLCS), leaving uncertainty about performance on real-world, high-dimensional data or non-image domains.

## Confidence

- **High Confidence**: The core claim that OT-based metrics outperform entropy-based ones in architecture selection tasks is well-supported by the experimental results, with clear numerical improvements in correlation coefficients across multiple datasets and scenarios.
- **Medium Confidence**: The assumption that pseudo-labels from a source classifier provide meaningful signal for label-level OT distance is plausible given the results, but the method's robustness to varying levels of pseudo-label accuracy is not thoroughly explored.
- **Medium Confidence**: The closed-form Wasserstein approximation for Gaussian distributions is mathematically sound, but its empirical validity depends on the actual feature distribution shape, which is not rigorously validated beyond standard benchmarks.

## Next Checks

1. **Pseudo-label robustness**: Systematically vary the source classifier's accuracy on target domains (e.g., by fine-tuning on fewer source classes or with more regularization) and measure how TETOT correlation degrades. This would quantify the method's sensitivity to pseudo-label noise.

2. **Distribution assumption validation**: Test the closed-form Wasserstein approximation on datasets with known non-Gaussian feature distributions (e.g., mixture models or real-world data with clear multimodality). Compare the correlation of the exact OT vs. the approximate version to identify when the Gaussian assumption breaks down.

3. **Real-world deployment test**: Apply TETOT to a real-world dataset with domain shift not controlled by standard splits (e.g., medical imaging across hospitals, satellite imagery with varying conditions). Evaluate whether the method maintains high correlation in a less curated setting, and whether the closed-form approximation remains viable when only statistics are available.