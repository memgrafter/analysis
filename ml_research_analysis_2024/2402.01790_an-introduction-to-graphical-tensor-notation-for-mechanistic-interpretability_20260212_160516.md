---
ver: rpa2
title: An introduction to graphical tensor notation for mechanistic interpretability
arxiv_id: '2402.01790'
source_url: https://arxiv.org/abs/2402.01790
tags:
- tensor
- attention
- tensors
- notation
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Graphical tensor notation provides a visual framework for representing
  tensor operations, which are fundamental to modern deep learning and mechanistic
  interpretability. The paper introduces this notation and applies it to linear algebra
  concepts (SVD, CP, Tucker decompositions) and neural network architectures (dense
  networks, transformers).
---

# An introduction to graphical tensor notation for mechanistic interpretability

## Quick Facts
- arXiv ID: 2402.01790
- Source URL: https://arxiv.org/abs/2402.01790
- Authors: Jordan K. Taylor
- Reference count: 0
- Primary result: Graphical tensor notation provides a visual framework for representing tensor operations, clarifying transformer architecture structure and attention head composition

## Executive Summary
This paper introduces graphical tensor notation as a visual framework for representing tensor operations fundamental to deep learning and mechanistic interpretability. The notation uses shapes with legs to represent tensors and connected legs to indicate contractions, making complex operations more intuitive to parse. The framework is applied to linear algebra concepts (SVD, CP, Tucker decompositions) and neural network architectures (dense networks, transformers), demonstrating how visual representation clarifies structural relationships and composition patterns in transformer models.

## Method Summary
The paper presents graphical tensor notation as a theoretical framework for representing tensor operations visually. It builds from basic tensor operations using einsum notation to more complex applications in neural networks, particularly transformers. The method involves representing tensors as shapes with legs corresponding to indices, using connected legs to indicate contractions, and applying special symbols for common operations like identity matrices and delta tensors. The framework is demonstrated through examples including SVD decomposition, linear regression, and transformer architecture analysis, with particular focus on path expansion for understanding information flow through attention mechanisms.

## Key Results
- Graphical tensor notation reduces cognitive load when parsing complex tensor operations in deep learning architectures
- The notation makes structural properties of transformer architectures more apparent, particularly the residual stream backbone and attention head composition
- Path expansion analysis facilitated by the notation helps identify dominant attention head compositions and potentially interpretable pathways through transformer layers
- The framework successfully represents a handcrafted toy induction head circuit, demonstrating its utility for mechanistic interpretability research

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graphical tensor notation reduces cognitive load when parsing complex tensor operations in deep learning architectures.
- Mechanism: The visual representation of tensor contractions and operations as shapes with legs and connected lines allows readers to quickly identify which tensors are being contracted, what the resulting tensor type will be, and see structural relationships that would be difficult to parse from einsum code alone.
- Core assumption: Visual parsing is faster and more intuitive than parsing linear code representations for complex tensor operations.
- Evidence anchors:
  - [abstract] "Graphical tensor notation makes it easier to parse things at a glance and see interesting equivalences"
  - [section] "But in graphical notation this is [diagram], and we can immediately see which tensors are to be contracted, and that the result will be a single number"
  - [corpus] Found 25 related papers with average neighbor FMR=0.48, suggesting moderate relevance in the broader field
- Break condition: If the reader has poor spatial reasoning skills or the operations are simple enough that visual notation provides no additional clarity over code.

### Mechanism 2
- Claim: Graphical tensor notation makes structural properties of transformer architectures more apparent.
- Mechanism: By representing the transformer as a tensor network diagram, the residual stream backbone, the independent nature of attention heads, and the composition patterns between layers become visually obvious. The notation reveals that attention is the only operation that moves information between token positions.
- Evidence anchors:
  - [section] "Here we've also changed how we denote the elementwise addition of tensors (in blue), to emphasize the most dominant part of a transformer: the vertical 'backbone' on the left known as the residual stream"
  - [section] "Attention patterns determine how information is moved between tokens... With attention frozen, the attention block simplifies to [diagram]"
  - [section] "There are three simplest kinds of nontrivial attention composition: Q-composition, K-composition, and V-composition"
- Break condition: If the notation becomes too cluttered for very large models, or if the reader is already familiar enough with the architecture that visual representation provides no new insights.

### Mechanism 3
- Claim: Graphical tensor notation facilitates path expansion analysis for understanding how information flows through transformer layers.
- Mechanism: The visual representation makes it easier to expand the output as a sum of terms from different composition paths, revealing how different attention head combinations contribute to the final output. This helps identify which terms are dominant and potentially interpretable.
- Evidence anchors:
  - [section] "Rather than treating the result of this sum as a single complicated object, we can keep the sum expanded as two separate terms"
  - [section] "There are ten terms which contribute to the final answer for two layers: three non-compositions (shown), three single compositions (shown), and four higher-order compositions (not shown)"
  - [section] "Some intuition for thinking that relatively few terms are important comes from noticing that each head can only write to a relatively small subspace of the residual stream"
- Break condition: If the number of terms grows too large for the expansion to remain tractable, or if the dominant terms are not actually the most interpretable ones.

## Foundational Learning

- Concept: Tensor operations and einsum notation
  - Why needed here: The paper builds graphical notation on top of standard tensor operations, so understanding einsum and basic tensor contractions is prerequisite to understanding the visual representation.
  - Quick check question: Given einsum(A, B, 'i j, j k -> i k'), what type of tensor operation is this and what are the dimensions of the result if A is (5,3) and B is (3,4)?

- Concept: Transformer architecture basics
  - Why needed here: The second half of the paper applies graphical notation to transformer components, so familiarity with attention mechanisms, residual connections, and MLP layers is essential.
  - Quick check question: In a transformer, which component is responsible for moving information between different token positions in the sequence?

- Concept: Singular value decomposition and low-rank approximations
  - Why needed here: The paper uses SVD as a foundational example of how tensor operations can be decomposed and represented graphically, which is relevant for understanding tensor network decompositions.
  - Quick check question: What is the relationship between the singular values in an SVD and the importance of the corresponding outer product terms in the reconstruction?

## Architecture Onboarding

- Component map:
  - Tensors: Represented as shapes with legs corresponding to indices
  - Operations: Connected legs indicate tensor contraction/summation
  - Special tensors: Identity matrices (single lines), isometries (triangles), delta tensors
  - Nonlinearities: Represented as bubbles around contracted tensors
  - Transformer components: Residual stream (vertical backbone), attention heads (independent terms), MLP layers (acting on hidden dimension only)

- Critical path: Understanding tensor operations → Learning graphical representation rules → Applying notation to simple examples (SVD) → Applying notation to complex architectures (transformers) → Using notation for analysis (path expansion)

- Design tradeoffs: The notation trades off some mathematical rigor for visual intuition, and may become cluttered for very large models with many components. It's most effective for understanding structure rather than for actual computation.

- Failure signatures: If a reader cannot parse the diagrams, they likely lack prerequisite knowledge of tensor operations or transformer architecture. If the diagrams seem overly complex, the model being represented may be too large for effective visual representation.

- First 3 experiments:
  1. Take a simple einsum operation like einsum(A, B, 'i j, j k -> i k') and represent it graphically, then verify the result by computing it in code
  2. Draw the graphical representation of a 2-layer transformer with frozen attention, labeling all key components and showing how information flows
  3. Perform a path expansion on the 2-layer transformer, drawing out the different composition terms and identifying which might be dominant based on the architecture

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can graphical tensor notation be extended to better handle nonlinearities in neural networks beyond the simple "bubble" representation?
- Basis in paper: [explicit] The paper notes that tensor network notation was developed for quantum physics where "einsum is all you need - no nonlinearities are allowed" and neural networks require "going slightly beyond the standard graphical tensor notation" to represent nonlinearities
- Why unresolved: The paper only provides a basic bubble notation for nonlinearities but acknowledges this is a limitation of the current notation framework. More sophisticated representations might be needed for complex activation functions or attention mechanisms.
- What evidence would resolve it: Development of extended graphical notation conventions that can cleanly represent various nonlinearities while maintaining the clarity benefits of the current notation. Examples would include representations for GELU, SwiGLU, or attention softmax operations.

### Open Question 2
- Question: What is the optimal strategy for contracting tensor networks in transformer models to balance computational efficiency with interpretability?
- Basis in paper: [inferred] The paper discusses that "finding the optimal order in which to contract a tensor network is an NP-hard problem" and that different contraction orders have vastly different computational costs, but doesn't provide guidance on how to choose contraction strategies specifically for interpretability purposes
- Why unresolved: The paper acknowledges computational complexity issues but doesn't address how to make trade-offs between efficient computation and maintaining interpretability when contracting transformer tensor networks
- What evidence would resolve it: Comparative studies showing how different contraction strategies affect both computational performance and the clarity of interpretability insights extracted from the resulting contracted tensors.

### Open Question 3
- Question: How can graphical tensor notation be automated or integrated into interpretability tools to assist researchers in discovering circuits and mechanisms in neural networks?
- Basis in paper: [explicit] The paper mentions the ACDC (Automated Circuit DisCovery) algorithm and notes that "There may also be much more effective ways of decomposing the computations of a transformer into a series of terms or circuits like this" but doesn't propose specific integration methods
- Why unresolved: While the paper demonstrates the utility of graphical notation for manual analysis, it doesn't explore how these visualizations could be generated automatically or integrated into interpretability workflows
- What evidence would resolve it: Development of software tools that can automatically generate graphical tensor notation from neural network architectures and provide interactive exploration capabilities for mechanistic interpretability research.

## Limitations
- Scalability concerns for large transformer models with hundreds of attention heads
- Lack of quantitative validation of cognitive benefits compared to traditional einsum notation
- Limited demonstration of utility beyond handcrafted circuits to real trained models

## Confidence
- **Medium** - While the graphical notation is visually intuitive for small models, its scalability to large transformer architectures with hundreds of attention heads remains untested. The claim that this notation "makes it easier to parse things at a glance" is supported by anecdotal evidence from the paper but lacks quantitative validation through user studies comparing comprehension speed with traditional einsum notation.
- **Medium** - The path expansion analysis shows promise for identifying dominant composition terms, but the paper does not provide empirical validation that these identified terms correspond to the most mechanistically important pathways in actual transformer models. The assertion that "relatively few terms are important" is based on architectural intuition rather than experimental verification.
- **Low** - The toy induction head example demonstrates the notation's utility, but this is a handcrafted circuit rather than an emergent phenomenon found in trained models. The paper does not demonstrate how graphical tensor notation would help discover such circuits in real models or validate that discovered circuits match known behaviors.

## Next Checks
1. **Scalability test**: Apply graphical tensor notation to a medium-sized transformer (8-12 layers) and document where the notation becomes too cluttered or loses its intuitive advantages compared to code representations.

2. **Comprehension study**: Design a controlled experiment where participants solve tensor manipulation problems using both graphical notation and traditional einsum code, measuring accuracy and time to solution to quantify the claimed cognitive benefits.

3. **Circuit discovery validation**: Use the graphical notation to analyze a trained transformer model, identify attention head compositions that match known induction head circuits, and verify that the path expansion analysis correctly identifies these compositions as dominant terms.