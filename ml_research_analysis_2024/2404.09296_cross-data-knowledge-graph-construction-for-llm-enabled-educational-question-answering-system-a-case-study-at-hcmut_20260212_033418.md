---
ver: rpa2
title: 'Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering
  System: A Case Study at HCMUT'
arxiv_id: '2404.09296'
source_url: https://arxiv.org/abs/2404.09296
tags:
- knowledge
- hcmut
- language
- data
- intents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method for automatically constructing a knowledge
  graph from multiple data sources in the educational domain, specifically applied
  at Ho Chi Minh City University of Technology (HCMUT). The approach involves discovering
  open intents from unstructured FAQ data using an unsupervised learning framework
  (E-OED) and leveraging embedding-based techniques to identify relationships between
  intents and policies.
---

# Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT

## Quick Facts
- arXiv ID: 2404.09296
- Source URL: https://arxiv.org/abs/2404.09296
- Authors: Tuan Bui; Oanh Tran; Phuong Nguyen; Bao Ho; Long Nguyen; Thang Bui; Tho Quan
- Reference count: 40
- Key outcome: 372 intents discovered from over 200,000 FAQ entries with 613 relationships identified

## Executive Summary
This paper presents a method for automatically constructing a knowledge graph from multiple educational data sources, specifically applied at Ho Chi Minh City University of Technology (HCMUT). The approach uses unsupervised learning to discover open intents from unstructured FAQ data and employs embedding-based techniques to identify relationships between intents and policies. The constructed knowledge graph is then integrated with large language models (LLMs) to enable question-answering capabilities for domain-specific educational queries.

## Method Summary
The methodology involves a multi-stage process starting with intent discovery from unstructured FAQ data using an unsupervised learning framework (E-OED). The system then identifies relationships between discovered intents and existing policy documents through embedding-based similarity techniques. These relationships form the edges of the knowledge graph, with intents and policies as nodes. Finally, the knowledge graph is integrated with LLMs to enhance question-answering capabilities, allowing the system to provide more accurate and contextually relevant responses to educational queries by leveraging the structured knowledge representation.

## Key Results
- 372 unique intents successfully discovered from over 200,000 FAQ entries
- 613 relationships identified between intent and policy entities in the knowledge graph
- Effective integration demonstrated between the constructed knowledge graph and LLMs for educational question-answering

## Why This Works (Mechanism)
The approach works by leveraging unsupervised learning to automatically discover latent semantic structures in unstructured FAQ data, eliminating the need for manual labeling. The embedding-based relationship discovery captures semantic similarities between intents and policies, enabling the construction of meaningful connections in the knowledge graph. By integrating this structured knowledge with LLMs, the system can ground responses in verified educational policies while maintaining the language understanding capabilities of LLMs, resulting in more accurate and trustworthy answers to educational queries.

## Foundational Learning
- **Unsupervised Intent Discovery (E-OED)**: Why needed - to extract meaningful categories from unstructured FAQ data without manual labeling; Quick check - verify that discovered intents cover the majority of FAQ topics and show semantic coherence
- **Embedding-based Relationship Identification**: Why needed - to automatically find semantic connections between intents and policies; Quick check - ensure high-similarity pairs correspond to actual related concepts
- **Knowledge Graph Integration with LLMs**: Why needed - to combine structured knowledge with language understanding for improved accuracy; Quick check - validate that KG-augmented responses are more accurate than LLM-only responses
- **Multi-source Data Integration**: Why needed - to create comprehensive knowledge representation from diverse educational sources; Quick check - confirm coverage of all relevant educational domains
- **Vietnamese Language Processing**: Why needed - to handle language-specific nuances in the educational context; Quick check - verify that language-specific models perform better than generic models

## Architecture Onboarding

**Component Map**
FAQ Data -> E-OED Intent Discovery -> Intent Embeddings -> Policy Embeddings -> Relationship Identification -> Knowledge Graph -> LLM Integration -> Question Answering System

**Critical Path**
The critical path flows from FAQ data through intent discovery to knowledge graph construction, then to LLM integration for question answering. The most computationally intensive step is typically the embedding generation and similarity calculation for relationship identification.

**Design Tradeoffs**
- Unsupervised vs supervised intent discovery: Unsupervised eliminates labeling costs but may produce less precise intents
- Embedding similarity threshold: Higher thresholds yield fewer but more confident relationships; lower thresholds increase coverage but risk noise
- Graph density: More relationships provide richer context but increase computational complexity and potential for noise
- LLM integration approach: Direct KG querying vs soft prompting with KG information; trade-off between accuracy and flexibility

**Failure Signatures**
- Intent discovery produces incoherent or overlapping categories
- Relationship identification yields too few connections (threshold too high) or too many spurious connections (threshold too low)
- LLM integration results in factual inconsistencies or hallucinations
- System performance degrades with queries outside the discovered intent space

**First Experiments**
1. Test intent discovery on a small, manually-labeled subset of FAQ data to evaluate precision and coverage
2. Validate relationship identification by manually checking sample intent-policy pairs against gold standard mappings
3. Compare KG-augmented LLM responses against baseline LLM responses on a test set of educational queries

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation methodology lacks comparison to external benchmarks and established knowledge graph evaluation frameworks
- No statistical validation or confidence intervals for reported performance metrics
- Vietnamese language focus limits generalizability to other educational contexts

## Confidence
- **High confidence**: Basic methodology of extracting intents from FAQ data using unsupervised learning is technically sound and well-established
- **Medium confidence**: Reported numbers (372 intents, 613 relationships) appear plausible given the dataset size
- **Low confidence**: Claims about system effectiveness and potential benefits for domain-specific educational queries lack empirical validation

## Next Checks
1. Conduct ablation studies comparing the proposed unsupervised intent discovery method against established clustering algorithms (e.g., K-means, DBSCAN) on the same FAQ corpus, with manual evaluation of intent quality and coverage.

2. Implement a comprehensive evaluation framework testing the KG-augmented LLM system on diverse query types, including edge cases, ambiguous questions, and queries requiring multi-hop reasoning across the knowledge graph.

3. Perform cross-domain validation by applying the methodology to educational FAQ datasets from other institutions or domains (e.g., different universities, MOOCs platforms) to assess generalizability and robustness of the intent discovery approach.