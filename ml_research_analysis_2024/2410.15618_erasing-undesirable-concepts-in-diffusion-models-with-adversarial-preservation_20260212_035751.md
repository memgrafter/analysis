---
ver: rpa2
title: Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation
arxiv_id: '2410.15618'
source_url: https://arxiv.org/abs/2410.15618
tags:
- concepts
- concept
- erasing
- images
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of selectively removing undesirable
  concepts from text-to-image diffusion models while preserving the integrity of other
  unrelated concepts. The proposed method, adversarial concept preservation, identifies
  and preserves the most sensitive concepts affected by the removal of target concepts,
  rather than relying on neutral concepts.
---

# Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation

## Quick Facts
- **arXiv ID**: 2410.15618
- **Source URL**: https://arxiv.org/abs/2410.15618
- **Reference count**: 33
- **Primary result**: Proposed adversarial concept preservation method achieves 98.6% ESR-1 for object-related concepts while maintaining 55.2% PSR-1, outperforming state-of-the-art erasure techniques.

## Executive Summary
This paper addresses the challenge of selectively removing undesirable concepts from text-to-image diffusion models while preserving the integrity of unrelated concepts. The proposed method, adversarial concept preservation, identifies and preserves the most sensitive concepts affected by the removal of target concepts, rather than relying on neutral concepts. The approach uses a bilevel min-max optimization framework with Gumbel-Softmax sampling to adaptively search for adversarial concepts in the discrete concept space. Experiments on Stable Diffusion demonstrate that the method significantly outperforms existing erasure techniques, achieving high erasing success rates while maintaining strong preservation performance.

## Method Summary
The method employs a bilevel optimization framework where the inner level finds the most sensitive concept to preserve during erasure, and the outer level performs the actual concept removal. It uses Gumbel-Softmax sampling to handle the discrete nature of concept embeddings, allowing gradient-based optimization. The approach optimizes for both erasure loss (L1) and preservation loss (L2) simultaneously, with the preservation term focusing on the concept most affected by the target concept's removal. The method fine-tunes the diffusion model using this adversarial preservation mechanism, which adaptively identifies and protects concepts that would otherwise be degraded during the erasure process.

## Key Results
- Achieves 98.6% ESR-1 (erasing success rate) for object-related concepts
- Maintains 55.2% PSR-1 (preserving success rate) for unrelated concepts
- Outperforms baseline methods (LoRA, OpenErase) on both erasure and preservation metrics
- Demonstrates effectiveness across multiple concept types including NSFW content, object categories, and artistic styles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Erasing a target concept changes the model's ability to generate other related concepts.
- Mechanism: When a target concept is removed, the model's parameters are updated to suppress that concept, but this also affects other concepts that are semantically or visually related due to entanglement in the learned representation space.
- Core assumption: Concepts are not isolated in the model; removing one impacts related concepts because they share latent representations.
- Evidence anchors:
  - [abstract]: "removing even one concept can significantly reduce the model's ability to generate other concepts"
  - [section 3.2]: "removing the 'nudity' concept significantly affects highly related concepts such as 'naked', 'men', 'women', and 'person'"
  - [corpus]: "Diffusion models... can inadvertently produce undesirable or harmful content when trained on unfiltered internet data"

### Mechanism 2
- Claim: Preserving the most sensitive concepts during erasure maintains the model's overall generation quality.
- Mechanism: By identifying and preserving concepts most affected by parameter changes during erasure, the model retains its ability to generate these concepts well, which in turn helps preserve related concepts that depend on them.
- Core assumption: The most sensitive concepts act as anchors that stabilize the model's representation space during erasure.
- Evidence anchors:
  - [abstract]: "This approach ensures stable erasure with minimal impact on the other concepts"
  - [section 3.2]: "neutral concepts like 'a photo' or the null concept show resilience and independence from changes in the model's parameters, suggesting that they do not adequately represent the model's capability to be preserved"
  - [section 4]: "We here approach the problem more carefully via a study on the impact of erasing a specific concept on model performance on the remaining ones"

### Mechanism 3
- Claim: Gumbel-Softmax sampling enables efficient search for adversarial concepts in discrete concept space.
- Mechanism: By treating concept embeddings as a continuous distribution and using Gumbel-Softmax, the method can perform gradient-based optimization to find which concept, when preserved, most stabilizes the model during erasure.
- Core assumption: The discrete concept space can be approximated as continuous for optimization purposes without losing meaningful structure.
- Evidence anchors:
  - [section 4]: "Since the concepts exist in a discrete space... we switch to searching for the embedding distribution π on the simplex ∆R and subsequently transform it back into a discrete space using the temperature-dependent GumbelSoftmax trick"
  - [section B.4]: "To further understand how our method searches for adversarial concepts... we show the images generated from the most sensitive concepts ca found by our method"
  - [corpus]: "adversarial learning mechanism. This mechanism identifies the most sensitive concepts affected by the removal of the target concept"

## Foundational Learning

- Concept: Discrete vs continuous optimization spaces
  - Why needed here: The method must search through a discrete set of concepts (words/tokens) but needs continuous optimization for efficiency
  - Quick check question: Why can't we just test every concept in the vocabulary one by one?

- Concept: Bilevel optimization
  - Why needed here: The method needs to simultaneously optimize for erasing the target concept and preserving the most sensitive concepts
  - Quick check question: What is the difference between single-level and bilevel optimization?

- Concept: CLIP score as a proxy for generation quality
  - Why needed here: The paper uses CLIP alignment scores to measure how well the model generates specific concepts
  - Quick check question: How does CLIP score relate to human perception of image quality?

## Architecture Onboarding

- Component map: Text encoder -> CLIP embeddings -> concept space -> Gumbel-Softmax sampler -> concept selection; Diffusion model U-Net -> noise prediction -> latent space -> image generation; Loss functions -> L1 (erasure) + L2 (preservation)
- Critical path: Fine-tuning loop: Sample target concept → Find adversarial concept via Gumbel-Softmax → Compute L1 and L2 losses → Update model parameters
- Design tradeoffs: Continuous approximation (Gumbel-Softmax) vs exact discrete search; Preservation of sensitive concepts vs computational cost; Erasure effectiveness vs preservation quality
- Failure signatures: High ESR but low PSR indicates effective erasure but poor preservation; Low ESR indicates failure to erase; Model collapse to background if adversarial concept search fails
- First 3 experiments:
  1. Erase "nudity" concept and measure impact on related concepts like "woman", "person" using CLIP score differences
  2. Compare preservation performance when using neutral concept vs most sensitive concept as anchor
  3. Test Gumbel-Softmax vs exhaustive search on small concept vocabulary to validate approximation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of search space for adversarial concepts (e.g., CLIP token vocabulary vs. Oxford 3000) impact the trade-off between erasing performance and preservation of unrelated concepts?
- Basis in paper: [explicit] The paper discusses using the Oxford 3000 word list and the CLIP token vocabulary as search spaces, noting that the CLIP vocabulary includes nonsensical tokens and that different tasks might require customized search spaces for optimal performance.
- Why unresolved: The paper provides some comparative results but does not conduct a comprehensive study on how different search spaces affect the balance between erasing and preserving concepts.
- What evidence would resolve it: A systematic evaluation comparing various search spaces (e.g., CLIP tokens, Oxford 3000, domain-specific vocabularies) on multiple erasure tasks, measuring both ESR and PSR metrics, would clarify the impact of search space choice.

### Open Question 2
- Question: What is the relationship between the similarity of concepts in the textual embedding space and their sensitivity to erasure of a target concept?
- Basis in paper: [inferred] The paper empirically demonstrates that concepts close in the textual embedding space (e.g., "nudity" and "a photo") are not necessarily the most sensitive to erasure, suggesting that textual similarity is not a reliable indicator of sensitivity.
- Why unresolved: The paper shows that textual similarity does not correlate with sensitivity but does not explore alternative metrics or methods to predict sensitivity.
- What evidence would resolve it: Research into alternative similarity metrics or predictive models that better capture the relationship between concepts in the model's latent space, validated against erasure experiments, would address this question.

### Open Question 3
- Question: How does the proposed method perform on erasing abstract or less visually concrete concepts (e.g., emotions, cultural symbols) compared to object-related or NSFW concepts?
- Basis in paper: [inferred] The paper focuses on object-related concepts, NSFW content, and artistic styles, but does not explore abstract or culturally nuanced concepts, leaving a gap in understanding the method's generalizability.
- Why unresolved: The experiments are limited to specific types of concepts, and the paper does not discuss the challenges or performance of erasing abstract concepts.
- What evidence would resolve it: Testing the method on a diverse set of abstract concepts (e.g., "joy," "patriotism," "melancholy") and evaluating both ESR and PSR metrics would demonstrate its effectiveness across different concept types.

## Limitations

- Discrete concept space approximation using Gumbel-Softmax may not capture all relevant structure in the concept space
- Method assumes preserving the most sensitive concepts will effectively preserve overall generation quality, which may not always hold
- Evaluation datasets (Imagenette, COCO prompts, NSFW images) may not represent the full diversity of real-world use cases

## Confidence

- **High Confidence**: Experimental results showing superior ESR and PSR performance compared to baselines (LoRA, OpenErase) on tested datasets
- **Medium Confidence**: Theoretical justification for why preserving the most sensitive concepts maintains overall generation quality
- **Low Confidence**: Generalizability to concepts not present in training data or concepts with very different semantic properties than those tested

## Next Checks

1. **Concept Space Coverage Analysis**: Systematically vary the concept search space size K from 10 to 1000 concepts and measure how ESR and PSR scores change to identify the minimum effective search space.

2. **Cross-Dataset Generalization Test**: Apply the method to erase concepts from a different dataset (e.g., LAION-400M subset) and measure whether the same level of performance is maintained.

3. **Concept Sensitivity Ranking Validation**: For a small set of concepts, manually verify the ranking of concept sensitivity by systematically erasing concepts in different orders and measuring the impact on preservation quality.