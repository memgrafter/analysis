---
ver: rpa2
title: 'Constructing Adversarial Examples for Vertical Federated Learning: Optimal
  Client Corruption through Multi-Armed Bandit'
arxiv_id: '2408.04310'
source_url: https://arxiv.org/abs/2408.04310
tags:
- client
- e-ts
- attack
- clients
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of constructing adversarial examples
  in vertical federated learning (VFL) under a threat model where an adversary can
  adaptively corrupt a subset of communication channels between clients and a server.
  The authors formulate this as an online optimization problem and decompose it into
  an inner adversarial example generation (AEG) problem and an outer corruption pattern
  selection (CPS) problem.
---

# Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit

## Quick Facts
- **arXiv ID**: 2408.04310
- **Source URL**: https://arxiv.org/abs/2408.04310
- **Authors**: Duanyi Yao; Songze Li; Ye Xue; Jin Liu
- **Reference count**: 40
- **Key outcome**: The paper proposes E-TS algorithm that outperforms baseline methods in finding optimal corruption patterns for VFL adversarial attacks

## Executive Summary
This paper addresses the challenge of constructing adversarial examples in vertical federated learning (VFL) under a threat model where an adversary can adaptively corrupt communication channels between clients and a server. The authors formulate this as an online optimization problem decomposed into inner adversarial example generation and outer corruption pattern selection. They establish an equivalence between the corruption pattern selection problem and multi-armed bandit problems, then propose a novel Thompson Sampling with Empirical maximum reward (E-TS) algorithm. The algorithm uses empirical maximum rewards to identify competitive arms and restrict exploration space, theoretically characterized through regret bounds and empirically demonstrated across multiple VFL tasks.

## Method Summary
The method combines Natural Evolution Strategy (NES) for adversarial example generation with Thompson Sampling with Empirical maximum reward (E-TS) for corruption pattern selection. NES estimates gradients through sampling to generate effective adversarial perturbations in the black-box VFL setting. E-TS maintains empirical mean and maximum rewards for each corruption pattern (arm), constructs a competitive set of arms based on these estimates, and performs Thompson sampling within this restricted set to efficiently identify the optimal corruption pattern while minimizing regret.

## Key Results
- E-TS consistently outperforms baseline methods in attack success rate across all tested VFL tasks
- The algorithm achieves faster convergence to optimal corruption patterns compared to plain Thompson sampling
- Theoretical regret bounds demonstrate E-TS's effectiveness in large exploration spaces

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: E-TS reduces exploration space by identifying competitive arms using empirical maximum rewards, accelerating convergence
- **Mechanism**: E-TS maintains empirical mean and maximum rewards for each arm, constructs a competitive set containing arms whose empirical maximum reward is at least as high as the empirical mean reward of the best explored arm, then performs Thompson sampling only within this restricted set
- **Core assumption**: Empirical maximum reward reliably proxies expected maximum reward and competitive arm set remains small
- **Evidence anchors**: [abstract] introduces competitive arms concept; [section 5.2] describes restricting exploration to competitive arms

### Mechanism 2
- **Claim**: NES enables effective black-box adversarial example generation by efficiently estimating gradients through sampling
- **Mechanism**: NES samples Gaussian noises, adds them to current perturbation, estimates gradient by averaging product of noise vectors and loss evaluated at perturbed embeddings, then updates perturbation using projected gradient descent
- **Core assumption**: Loss function smoothness allows gradient approximation through finite differences with sufficient queries
- **Evidence anchors**: [section 5.1] explains NES gradient estimation and query efficiency; demonstrates suitability for VFL's limited query setting

### Mechanism 3
- **Claim**: Equivalence between CPS and MAB problems enables application of bandit algorithms for efficient corruption pattern selection
- **Mechanism**: Each corruption pattern treated as MAB arm with reward as attack success rate; CPS transformed to minimizing cumulative regret between optimal arm and selected arm rewards over time
- **Core assumption**: Reward distribution for each arm is stationary and optimal pattern remains consistent
- **Evidence anchors**: [section 5.2] establishes MAB equivalence by defining N arms for N corruption patterns and mapping ASR to rewards

## Foundational Learning

- **Concept: Multi-armed Bandit Problem**
  - Why needed here: Reformulates CPS problem to leverage bandit algorithms for efficient corruption pattern exploration
  - Quick check question: What is the objective of a multi-armed bandit problem, and how does it relate to the CPS problem in this paper?

- **Concept: Thompson Sampling**
  - Why needed here: Balances exploration and exploitation when selecting corruption patterns within competitive set
  - Quick check question: How does Thompson sampling differ from other bandit algorithms like UCB in terms of exploration-exploitation trade-off?

- **Concept: Natural Evolution Strategy**
  - Why needed here: Generates adversarial examples in black-box setting where gradients are not directly accessible
  - Quick check question: How does NES estimate gradients in black-box optimization, and why is it preferred over finite-difference methods here?

## Architecture Onboarding

- **Component map**: Adversary intercepts embeddings → NES generates perturbations → Perturbed embeddings sent to server → Server computes predictions → Adversary observes ASR and updates E-TS corruption selection
- **Critical path**: 1) Adversary intercepts embeddings from corrupted clients, 2) NES generates adversarial perturbations, 3) Perturbed embeddings sent to server, 4) Server computes predictions and sends back, 5) Adversary observes ASR and updates corruption pattern selection using E-TS
- **Design tradeoffs**: Exploration vs exploitation balance in E-TS; query efficiency favoring NES over finite-difference methods; computational overhead of maintaining empirical maximum rewards vs reduced exploration space
- **Failure signatures**: High regret indicates ineffective optimal pattern identification; low attack success rate suggests poor adversarial perturbation generation; slow convergence implies improper warm-up rounds or perturbation budget
- **First 3 experiments**: 1) Verify NES gradient estimation on simple function with known gradients, 2) Test E-TS on small synthetic MAB problem to verify faster optimal arm identification than plain TS, 3) Evaluate attack success rate on simple VFL task with few clients and features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of warm-up rounds (t0) for E-TS in practical scenarios, and how does it scale with the number of arms?
- Basis in paper: [explicit] Suggests t0 at least N, optimal range [2N, 5N] based on numerical experiments, may vary in practice
- Why unresolved: Optimal t0 depends on reward distribution, arm count, and specific task; requires extensive empirical studies across diverse datasets and tasks
- What evidence would resolve it: Experiments varying t0 across wide range of tasks, datasets, and arm numbers comparing regret and convergence speed to identify optimal ranges

### Open Question 2
- Question: How does E-TS perform in even larger exploration spaces beyond tested configurations?
- Basis in paper: [explicit] Discusses regret bounds for large spaces but tests only up to 12,870 arms due to computational constraints
- Why unresolved: Regret bound analysis suggests E-TS should outperform TS in large spaces, but empirical validation is limited; true performance gain and scalability unclear
- What evidence would resolve it: Experiments in exploration spaces with millions of arms comparing E-TS to TS in regret, convergence speed, and computational efficiency

### Open Question 3
- Question: How does E-TS handle non-stationary reward distributions where best arm changes over time?
- Basis in paper: [inferred] Assumes stationary rewards but real-world scenarios may involve concept drift or adversarial adaptation
- Why unresolved: Current regret bounds and results don't account for changing reward distributions; adapting E-TS to handle non-stationarity is open challenge
- What evidence would resolve it: Experiments simulating non-stationary rewards (abrupt or gradual changes), evaluating E-TS's adaptation and regret maintenance; developing algorithms for detecting and responding to non-stationarity

## Limitations

- Computational overhead of maintaining empirical maximum rewards across all arms
- Sensitivity to warm-up period length and exploration-exploitation balance
- Dependence on accurate gradient estimation in black-box setting
- Assumptions about stationary reward distributions may not hold in dynamic environments

## Confidence

- **High confidence**: Theoretical foundation of MAB equivalence and E-TS regret bounds
- **Medium confidence**: Empirical performance across datasets, though limited to specific VFL architectures
- **Medium confidence**: Effectiveness of NES in gradient estimation, dependent on function smoothness

## Next Checks

1. Test E-TS on non-stationary reward distributions to evaluate robustness when optimal corruption patterns change over time
2. Benchmark NES against other black-box optimization methods under varying query budgets and function smoothness conditions
3. Scale experiments to larger VFL systems with more clients (>10) and higher-dimensional feature spaces to assess computational feasibility