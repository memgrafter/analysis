---
ver: rpa2
title: Bayesian WeakS-to-Strong from Text Classification to Generation
arxiv_id: '2406.03199'
source_url: https://arxiv.org/abs/2406.03199
tags:
- weak
- strong
- performance
- classification
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of aligning large language models
  (LLMs) with human preferences when models may surpass human capabilities, specifically
  extending the Weak-to-Strong framework to leverage multiple weak models for better
  supervision. The core method, Bayesian WeakS-to-Strong, uses an ensemble of weak
  models with a Bayesian approach (evidential deep learning) to estimate broader human
  preferences by learning a prior distribution over weak labels, improving robustness
  against individual model errors.
---

# Bayesian WeakS-to-Strong from Text Classification to Generation

## Quick Facts
- arXiv ID: 2406.03199
- Source URL: https://arxiv.org/abs/2406.03199
- Authors: Ziyun Cui; Ziyang Zhang; Guangzhi Sun; Wen Wu; Chao Zhang
- Reference count: 16
- Primary result: Bayesian WeakS-to-Strong achieves 0.828 PGR on classification with 5 weak models versus 0.643 for best single model

## Executive Summary
This paper extends the Weak-to-Strong framework to leverage multiple weak models for better supervision, addressing the challenge of aligning large language models with human preferences when models may surpass human capabilities. The core method uses an ensemble of weak models with a Bayesian approach (evidential deep learning) to estimate broader human preferences by learning a prior distribution over weak labels, improving robustness against individual model errors. The framework is extended from text classification to generation tasks by proposing a token-level probability estimation technique to create soft labels, and by incorporating conservative direct preference optimization (cDPO) to enhance preference learning.

## Method Summary
The method extends weak-to-strong generalization by using an ensemble of multiple weak models with a Bayesian evidential deep learning framework to capture human preference distributions. For classification, weak models provide labels that are aggregated using Dirichlet priors to estimate confidence. For generation, token-level probability estimation bridges tokenizer differences between weak and strong models by decomposing word-level probabilities using strong model confidence scores. The approach incorporates conservative DPO to further improve preference learning, with an auxiliary confidence loss to prevent overconfidence in weak model predictions.

## Key Results
- Bayesian WeakS-to-Strong achieves 0.828 PGR on classification with 5 weak models versus 0.643 for the best single model
- On slot filling generation, achieves 0.668 PGR versus 0.399 for the best single model
- cDPO training further improved generation PGR to 0.705
- Method demonstrates robustness even when weak models vary in quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using an ensemble of weak models provides more robust supervision than a single weak model
- Mechanism: Multiple weak models have complementary error patterns, so their ensemble average reduces overall error rate in supervision
- Core assumption: Different weak models make uncorrelated errors when classifying or generating content
- Evidence anchors: [abstract] "we propose using an ensemble of multiple weak models to improve the quality of weak supervision", [section] "leverage the complementarity of the error patterns of multiple weak models using an ensemble strategy"
- Break condition: If weak models make highly correlated errors, ensemble provides minimal benefit

### Mechanism 2
- Claim: Bayesian EDL framework estimates broader human preferences by learning prior distribution over weak labels
- Mechanism: Dirichlet prior over categorical distribution of weak labels captures uncertainty and diversity in human opinions
- Core assumption: Multiple weak labels can be modeled as samples from an underlying human preference distribution
- Evidence anchors: [abstract] "Confidence scores are estimated using a Bayesian approach to guide the WeakS-to-Strong generalization", [section] "propose a Bayesian WeakS-to-Strong approach based on EDL to estimate the human opinion distribution based on the weak labels"
- Break condition: If weak labels are highly inconsistent or contradictory, prior distribution becomes uninformative

### Mechanism 3
- Claim: Token-level probability estimation bridges tokenizer differences between weak and strong models for generation tasks
- Mechanism: Using word-level probabilities as intermediary, then decomposing into token-level probabilities using strong model confidence scores
- Core assumption: Strong and weak models have similar confidence patterns for corresponding tokens
- Evidence anchors: [section] "we use words as an intermediary, following the equation P(W) = P(w2|w1)P(w1) = P(s2|s1)P(s1)", [section] "This strong model confidence is then used to split word scores into target wordpiece probabilities P(si) while keeping the probability of the word unchanged"
- Break condition: If confidence patterns differ significantly between weak and strong models, probability decomposition becomes inaccurate

## Foundational Learning

- Concept: Bayesian inference with Dirichlet priors
  - Why needed here: To model uncertainty in weak labels and estimate broader human preference distribution
  - Quick check question: What distribution family is conjugate to the categorical distribution for modeling label probabilities?

- Concept: Evidence deep learning (EDL)
  - Why needed here: To implement Bayesian approach for learning Dirichlet priors over weak label distributions
  - Quick check question: How does EDL differ from standard cross-entropy loss in handling label uncertainty?

- Concept: Teacher-forcing in sequence generation
  - Why needed here: To train strong model using weak model outputs as target sequences during training
  - Quick check question: In teacher-forcing, what is fed as input at each decoding step during training versus inference?

## Architecture Onboarding

- Component map:
  Weak model ensemble -> Bayesian EDL layer -> Token probability estimator -> DPO trainer -> Strong model

- Critical path:
  1. Weak models generate labels/sequences for training data
  2. Bayesian EDL estimates prior distributions over weak labels
  3. Strong model trained using EDL loss with auxiliary confidence loss
  4. Optional DPO fine-tuning using weak model preferences
  5. Evaluation of strong model performance against ground truth

- Design tradeoffs:
  - More weak models → better error coverage but higher computational cost
  - Stronger regularization in EDL → better uncertainty estimation but potential underfitting
  - Complex probability estimation → better bridging of tokenizers but increased implementation complexity

- Failure signatures:
  - Weak models make highly correlated errors → ensemble provides minimal benefit
  - Inconsistent weak labels → Bayesian prior becomes uninformative
  - Tokenizer differences too large → probability estimation fails to bridge gap

- First 3 experiments:
  1. Train strong model using single weak model with standard cross-entropy (baseline)
  2. Train strong model using ensemble of weak models with simple averaging (Naive Multi-Weak)
  3. Train strong model using Bayesian EDL with token-level probability estimation for generation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Bayesian WeakS-to-Strong scale with the number of weak models beyond 5, and what is the theoretical limit of performance improvement?
- Basis in paper: [inferred] The paper tested performance with 3 and 5 weak models, showing improvement with more models, but did not explore beyond 5 models
- Why unresolved: The paper's experiments were limited to 3 and 5 weak models due to computational constraints
- What evidence would resolve it: Experiments testing the performance with increasing numbers of weak models (e.g., 10, 20, 50) to determine if there is a plateau in performance improvement

### Open Question 2
- Question: How does the choice of weak model ensemble strategy affect the final strong model performance in different task domains?
- Basis in paper: [explicit] The paper compares Naive Multi-Weak, FlyingSquid, and Bayesian Multi-Weak strategies for weak model ensemble
- Why unresolved: While the paper shows Bayesian Multi-Weak outperforms others in tested tasks, it doesn't provide a comprehensive analysis across various task domains
- What evidence would resolve it: Comparative experiments applying different ensemble strategies to a diverse set of tasks to identify optimal strategies for each domain

### Open Question 3
- Question: What is the impact of weak model quality variation on the performance of Bayesian WeakS-to-Strong, and how can the method be further robustified against low-quality weak models?
- Basis in paper: [explicit] The paper mentions that Bayesian WeakS-to-Strong is more robust against individual weak model quality compared to Joint Decoding
- Why unresolved: The paper doesn't provide a systematic study on how different levels of weak model quality affect the final strong model performance
- What evidence would resolve it: Experiments varying the quality of weak models and measuring the impact on Bayesian WeakS-to-Strong performance, along with proposed methods to improve robustness

## Limitations

- Evaluation limited to two datasets (SciQ and SLURP) with specific 7B parameter model architectures, which may not represent broader LLM alignment tasks
- Bayesian EDL framework assumes weak labels can be modeled as Dirichlet-distributed samples, but limited analysis of when this assumption breaks down
- Token-level probability estimation mechanism lacks empirical validation of the confidence pattern similarity assumption between weak and strong models

## Confidence

**High Confidence**: The core claim that ensemble methods improve weak-to-strong generalization by leveraging complementary error patterns is well-supported by empirical results across multiple datasets.

**Medium Confidence**: The Bayesian EDL approach for estimating human preference distributions shows promise but has limited ablation studies and may not outperform simpler ensemble methods beyond the additional complexity it introduces.

**Low Confidence**: The token-level probability estimation mechanism for bridging tokenizer differences is the least validated component, with minimal empirical evidence that the confidence-based decomposition accurately captures true token-level probabilities.

## Next Checks

1. **Cross-model tokenization consistency test**: Conduct experiments measuring the correlation between weak and strong model confidence scores at the token level across multiple tokenizer pairs to validate the core assumption that confidence patterns are similar enough for meaningful decomposition.

2. **Weak label quality sensitivity analysis**: Systematically vary the quality of weak models (using models of different sizes or fine-tuning levels) and measure how PGR degrades as weak model performance approaches random chance to establish the minimum quality threshold required.

3. **Scaling behavior investigation**: Evaluate the framework with larger model sizes (13B, 33B parameters) and more diverse weak model architectures to test whether the performance gains scale proportionally and generalize beyond the 7B parameter regime.