---
ver: rpa2
title: Effect of Adaptation Rate and Cost Display in a Human-AI Interaction Game
arxiv_id: '2408.14640'
source_url: https://arxiv.org/abs/2408.14640
tags:
- human
- cost
- actions
- action
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a human-AI interaction game where an AI adapts
  using gradient descent with varying adaptation rates, while human participants optimize
  their actions based on cost feedback. Two feedback displays were tested: current
  cost and localized cost landscape.'
---

# Effect of Adaptation Rate and Cost Display in a Human-AI Interaction Game

## Quick Facts
- arXiv ID: 2408.14640
- Source URL: https://arxiv.org/abs/2408.14640
- Reference count: 39
- Key outcome: AI adaptation rate and feedback display type significantly influence whether human-AI interactions converge to Nash or Stackelberg equilibria.

## Executive Summary
This paper presents a human-AI interaction game where an AI adapts using gradient descent with varying adaptation rates, while human participants optimize their actions based on cost feedback. Two feedback displays were tested: current cost and localized cost landscape. The study found that AI adaptation rate significantly affects human behavior, shifting outcomes between Nash and Stackelberg equilibria. Slow adaptation rates led to outcomes closer to Nash equilibrium, while fast rates shifted towards human-led Stackelberg equilibrium. The localized cost information further shifted outcomes towards Nash compared to single-point cost feedback. The results suggest that AI adaptation rate and feedback display type can be used to influence human behavior in human-AI interactions, with potential applications in designing more effective human-AI systems.

## Method Summary
The study implemented a two-player continuous game where humans controlled one player's actions via mouse cursor and an AI controlled the other player's actions using gradient descent updates. Five AI adaptation rates (α ∈ {0, 0.001, 0.01, 0.1, 1}) were tested across two experiments: one with current cost feedback (circle size) and another with localized cost landscape feedback (7x7 heat map). Human actions were recorded over 25-second trials at 60 or 24 samples per second depending on display type. The AI's cost function and human's cost function were both quadratic with specific parameter settings. Median actions and costs were compared to analytically computed Nash and Stackelberg equilibria to assess behavioral shifts.

## Key Results
- AI adaptation rate significantly shifts human behavior between Nash equilibrium (slow rates) and Stackelberg equilibrium (fast rates)
- Localized cost landscape feedback nudges human actions toward Nash equilibrium compared to single-point cost feedback
- Human adaptation modeled as two-point zeroth-order gradient approximation successfully reproduces the same equilibrium shifts seen in human experiments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Varying AI adaptation rate in a two-player continuous game shifts human behavior between Nash and Stackelberg equilibria.
- Mechanism: The AI's adaptation rate controls how quickly it responds to human actions. Slow rates mean the AI behaves almost like a constant, letting humans converge toward the Nash equilibrium where both players play best responses to each other. Fast rates let the AI track human actions closely, effectively letting humans act as leaders in a Stackelberg game and push toward the Stackelberg equilibrium.
- Core assumption: Human actions are driven by minimizing their own cost given observed AI behavior, and AI updates are myopic gradient steps.
- Evidence anchors:
  - [abstract] "slow adaptation rates shift the outcome towards the Nash equilibrium, while fast rates shift the outcome towards the human-led Stackelberg equilibrium."
  - [section 4.1] "We found that distributions of median h and m action vectors of the last 5 seconds of each trial shifted from close to the Nash equilibrium (NE) at the slowest adaptation rate to close to the human-led Stackelberg equilibrium (SE) at the fastest adaptation rate."
- Break condition: If the human does not reliably follow myopic cost minimization or the AI's gradient step becomes too noisy/large, the equilibrium shift may not occur.

### Mechanism 2
- Claim: Providing localized cost landscape information nudges human actions toward the Nash equilibrium compared to single-point cost feedback.
- Mechanism: With a heat map of local costs, humans can infer gradient information and better anticipate the cost surface around their current position. This richer information leads to strategies that favor mutual best-response behavior (Nash) rather than exploiting the AI's rapid response (Stackelberg).
- Core assumption: Humans can interpret the localized cost display to estimate gradients and adjust their strategy accordingly.
- Evidence anchors:
  - [abstract] "The addition of localized cost information had the effect of shifting outcomes towards Nash, compared to the outcomes from cost information at only the current joint action vector."
  - [section 4.2] "Experiment 2 showed a general shift of human action outcomes towards the Nash equilibrium in Experiment 2."
- Break condition: If the localized display is too coarse or humans misinterpret it, the advantage disappears.

### Mechanism 3
- Claim: Human adaptation modeled as two-point zeroth-order gradient approximation reproduces the same equilibrium shifts seen in human experiments.
- Mechanism: By sampling costs at nearby points, the simulation approximates the human gradient and updates actions accordingly. This stochastic gradient descent with exploration mimics human trial-and-error behavior and preserves the dependence on AI adaptation rate.
- Core assumption: Human behavior can be approximated by a zeroth-order optimization method with small exploration noise.
- Evidence anchors:
  - [section 5] "simulating the human adaptation as a two-point zeroth-order approximation of the Human agent's gradient provided similar learning dynamics as our human experiments results."
  - [section 5.2] "Without changing the adaptation rules defined in Algorithm 2, both the simulated Human and AI converged to the NE equilibrium at the slowest adaption rate and the SE equilibrium at the fastest adaptation rate."
- Break condition: If exploration noise is too large or the cost function is non-smooth, the approximation breaks down.

## Foundational Learning

- Concept: Game-theoretic equilibria (Nash vs Stackelberg)
  - Why needed here: The study explicitly frames human-AI outcomes in terms of these equilibria and measures how adaptation rate shifts behavior between them.
  - Quick check question: In a Stackelberg game, which player moves first and why does that matter for equilibrium outcomes?

- Concept: Gradient descent dynamics in continuous games
  - Why needed here: Both AI and (in simulation) human agents update actions via gradient steps; understanding stability and convergence is key to interpreting results.
  - Quick check question: What conditions on the cost matrices ensure that gradient descent converges to a Nash equilibrium?

- Concept: Feedback display design and human decision-making
  - Why needed here: The study contrasts single-point vs localized heat map feedback; knowing how humans use visual cost cues is essential for explaining behavioral shifts.
  - Quick check question: How might a heat map of local costs help a human estimate the gradient of their cost function?

## Architecture Onboarding

- Component map:
  Human input module -> Cost evaluation module -> AI update module -> Display module -> Data logger

- Critical path:
  1. Read human input → update h.
  2. Compute AI gradient ∂cM/∂m → update m with rate α.
  3. Evaluate cH(h,m) → render display.
  4. Log all values → store for analysis.

- Design tradeoffs:
  - Fixed display refresh (60Hz vs 24Hz) trades smoothness vs bandwidth; slower rate in Experiment 2 reduces data size but may miss rapid human reactions.
  - Symmetry flipping (s_i ∈ {−1,+1}) increases data diversity but adds complexity to interpretation.
  - Quadratic cost assumption simplifies equilibrium analysis but may not generalize to non-convex costs.

- Failure signatures:
  - Human actions never converge → likely too high α or too noisy display.
  - AI cost spikes → possible numerical instability in gradient step.
  - Median actions cluster away from both equilibria → symmetry flipping or cost parameters mis-specified.

- First 3 experiments:
  1. Run Experiment 1 with α = 0 (constant AI) and verify median h aligns with Nash equilibrium.
  2. Run Experiment 1 with α = 1 (full best response) and verify median h aligns with Stackelberg equilibrium.
  3. Run Experiment 2 with α = 0.01 and compare median h shift toward Nash vs Experiment 1 same α.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific game-theoretic equilibria (Nash or Stackelberg) are achieved at different adaptation rates and how does this vary across the different game dimensions (1x2, 2x1, 2x2)?
- Basis in paper: [explicit] The paper mentions that different adaptation rates shift outcomes between Nash and Stackelberg equilibria, but does not provide specific numerical values for each game dimension.
- Why unresolved: The paper provides some figures showing median actions and costs but does not explicitly state which equilibria are achieved at each adaptation rate for each game dimension.
- What evidence would resolve it: Detailed numerical results showing the exact equilibrium points achieved at each adaptation rate for each game dimension (1x2, 2x1, 2x2).

### Open Question 2
- Question: How does the localized cost landscape feedback affect human adaptation strategies compared to single-point cost feedback, and what are the underlying cognitive mechanisms?
- Basis in paper: [explicit] The paper notes that localized cost landscape feedback shifts outcomes towards Nash equilibrium and suggests humans may prioritize this information when they are less able to anticipate AI actions.
- Why unresolved: The paper does not delve into the cognitive mechanisms or provide empirical evidence (e.g., eye-tracking data) to support the hypothesis about human prioritization of feedback information.
- What evidence would resolve it: Eye-tracking data or other cognitive measures showing how participants process and prioritize different types of feedback information during the experiments.

### Open Question 3
- Question: How do different adaptation rates affect the AI's cost and what is the relationship between AI adaptation rate and the overall efficiency of the human-AI interaction?
- Basis in paper: [explicit] The paper mentions that AI costs display a U-shape trend from slower to faster adaptation rates and that the AI's cost stays relatively constant while human cost decreases with faster rates.
- Why unresolved: The paper does not provide a detailed analysis of how different adaptation rates impact the AI's cost and the overall efficiency of the interaction.
- What evidence would resolve it: A comprehensive analysis of AI costs at different adaptation rates and a measure of overall interaction efficiency (e.g., total cost, convergence speed) for each rate.

## Limitations

- The study relies on quadratic cost assumptions which may not generalize to non-convex or high-dimensional human-AI interaction scenarios.
- The human adaptation model as a zeroth-order gradient approximation, while supported by experimental results, remains a simplification of actual human decision-making processes.
- The localized cost display's effectiveness depends on humans' ability to interpret heat maps, which may vary across individuals and contexts.

## Confidence

- **High Confidence**: The core finding that AI adaptation rate shifts human behavior between Nash and Stackelberg equilibria is well-supported by both experimental and simulation results, with clear quantitative comparisons to theoretical equilibrium points.
- **Medium Confidence**: The claim that localized cost information shifts outcomes toward Nash equilibrium is supported by Experiment 2 results, though the effect size and robustness across different cost landscapes would benefit from additional validation.
- **Medium Confidence**: The zeroth-order gradient approximation model of human behavior successfully reproduces experimental dynamics, but the assumption of consistent exploration behavior across participants needs further validation.

## Next Checks

1. **Cross-validation with non-quadratic costs**: Test the adaptation rate and display effects with non-convex cost functions to verify the robustness of equilibrium shifting behavior beyond the quadratic case.

2. **Individual differences analysis**: Examine whether the zeroth-order gradient approximation accurately models individual human participants or if there are significant variations in adaptation strategies that the current aggregated analysis masks.

3. **Extended time horizon study**: Conduct trials longer than 25 seconds to determine whether the observed equilibria are transient states or stable long-term outcomes, particularly for intermediate adaptation rates where the system may show more complex dynamics.