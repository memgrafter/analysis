---
ver: rpa2
title: A Unified Data Representation Learning for Non-parametric Two-sample Testing
arxiv_id: '2412.00613'
source_url: https://arxiv.org/abs/2412.00613
tags:
- testing
- test
- data
- two-sample
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper revisits the non-parametric two-sample testing problem
  as a semi-supervised learning (SSL) task. The key idea is to use SSL techniques
  to learn better data representations by leveraging both labeled and unlabeled data,
  thereby avoiding the power loss from data splitting in traditional approaches.
---

# A Unified Data Representation Learning for Non-parametric Two-sample Testing

## Quick Facts
- arXiv ID: 2412.00613
- Source URL: https://arxiv.org/abs/2412.00613
- Reference count: 40
- Key outcome: SSL-C2ST framework learns data representations using semi-supervised learning, achieving higher test power than traditional two-sample tests while maintaining type-I error control

## Executive Summary
This paper addresses the non-parametric two-sample testing problem by reframing it as a semi-supervised learning task. Traditional approaches suffer from power loss due to data splitting between representation learning and testing phases. The authors propose SSL-C2ST, which learns inherent representations from the entire unlabeled dataset using an autoencoder, then fine-tunes these with labeled data to create discriminative representations. This two-phase approach leverages both labeled and unlabeled data while maintaining type-I error control. Theoretical analysis shows that increasing unlabeled data size reduces the upper bound of empirical error rate, leading to improved test power. Empirically, SSL-C2ST outperforms traditional C2ST on MNIST, ImageNet, and HDGM datasets.

## Method Summary
The SSL-C2ST framework operates in two phases: first, an autoencoder learns inherent representations (IRs) from the full dataset without using sample indices, capturing underlying data manifold structure. Second, a classifier head is fine-tuned on labeled data using the pre-trained encoder to obtain discriminative representations (DRs). This approach addresses the power loss in traditional supervised methods that split data between representation learning and testing. The method maintains type-I error control through careful handling of sample information during representation learning. An advanced variant, SSL-C2ST-M, combines the learned features with Maximum Mean Discrepancy (MMD) for enhanced performance. Theoretical analysis establishes that larger unlabeled datasets improve test power through tighter error rate bounds.

## Key Results
- SSL-C2ST outperforms traditional C2ST on MNIST, ImageNet, and HDGM datasets
- SSL-C2ST-M achieves state-of-the-art performance in many cases by combining learned features with MMD
- Theoretical analysis proves that increasing unlabeled data size reduces the upper bound of empirical error rate
- Method maintains type-I error control at nominal levels while improving test power
- Advanced SSL-C2ST-M variant shows consistent improvements across different data types and dimensions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using semi-supervised learning (SSL) on the entire dataset without labels preserves type-I error control while improving test power
- Mechanism: The autoencoder learns inherent representations (IRs) from the full dataset, capturing underlying data manifold structure without access to sample indices. This avoids the power loss from data splitting in traditional supervised approaches
- Core assumption: Discarding sample index information during representation learning does not compromise type-I error control for permutation-based testing
- Evidence anchors:
  - [abstract]: "as long as the sample indexes are not used during the learning process, the whole data can be used to learn data representations, meanwhile ensuring control of Type-I errors"
  - [section 2]: "after discarding the sample information (namely, we do not know which sample the data belongs to), learning representations from whole samples will not influence the type I error of permutation-based testing methods"
  - [corpus]: Weak evidence - no direct corpus support found for this specific claim
- Break condition: If sample index information leaks into the representation learning phase, type-I error control may be compromised

### Mechanism 2
- Claim: Fine-tuning pre-trained IRs with labeled data creates discriminative representations (DRs) that outperform randomly initialized classifiers
- Mechanism: The autoencoder-based representation learning first captures general data structure, then supervised fine-tuning adapts these features for sample discrimination, leveraging both unlabeled and labeled data
- Core assumption: Representations learned from the full dataset provide better initialization for the subsequent supervised task than random initialization
- Evidence anchors:
  - [section 4]: "we propose a pipeline that follows the definition of SSL, which utilizes the unlabelled samples and labelled samples in two phases"
  - [section 5.1]: "learn the IRs from whole dataset in an unsupervised autoencoder-based representation learning...then fine-tune the pre-trained encoder"
  - [corpus]: Weak evidence - no direct corpus support for this specific two-phase SSL approach
- Break condition: If the unsupervised pre-training phase fails to capture useful data structure, the subsequent fine-tuning will not outperform random initialization

### Mechanism 3
- Claim: Increasing the size of unlabeled data in SSL-C2ST reduces the upper bound of empirical error rate, leading to higher test power
- Mechanism: Theoretical analysis shows that larger unlabeled datasets provide tighter bounds on the error rate of the classifier, which directly translates to improved test power
- Core assumption: The compatibility measure between the classifier and dataset follows finite VC-dimension properties
- Evidence anchors:
  - [section 5.2]: "Theorem 5.3 indicates that when we are training model f ′, the increment in the size of unlabelled data mu can reduce the upper bound of the empirical error rate of f ′"
  - [section 5.2]: "this theorem ensures the effectiveness of unlabelled data in the improvement of SSL-C2ST test power"
  - [corpus]: Weak evidence - no direct corpus support for this specific theoretical result
- Break condition: If the unlabeled data violates the compatibility assumptions or the VC-dimension bounds are too loose, the theoretical guarantees may not hold

## Foundational Learning

- Concept: Type-I error control in permutation-based hypothesis testing
  - Why needed here: The paper must ensure that the proposed method maintains the nominal significance level while improving power
  - Quick check question: What happens to type-I error control if sample index information is inadvertently used during representation learning?

- Concept: Autoencoder-based representation learning and its relationship to data manifold structure
  - Why needed here: The method relies on autoencoders to learn inherent representations from the full dataset before supervised fine-tuning
  - Quick check question: How does the autoencoder objective (reconstruction error) relate to capturing the underlying data manifold?

- Concept: VC-dimension and its role in generalization bounds for semi-supervised learning
  - Why needed here: The theoretical analysis depends on compatibility measures and VC-dimension to bound the error rates
  - Quick check question: What role does the VC-dimension of the compatibility function class play in the theoretical guarantees?

## Architecture Onboarding

- Component map:
  Autoencoder (Encoder + Decoder) -> Classifier head -> Permutation test module -> (Optional) MMD module

- Critical path:
  1. Autoencoder pre-training on full dataset (Sunl)
  2. Supervised fine-tuning of classifier head on labeled subset (Str)
  3. Permutation testing on test set (Ste)
  4. (Optional) MMD computation on learned features

- Design tradeoffs:
  - Pre-training depth vs. overfitting risk on small datasets
  - Trade-off between reconstruction quality and feature discrimination
  - Choice of latent dimension size affecting both representation quality and computational cost

- Failure signatures:
  - If pre-training reconstruction loss remains high, the autoencoder failed to capture data structure
  - If test power doesn't improve over baseline, the fine-tuning phase may not be leveraging the pre-trained features effectively
  - If type-I error exceeds nominal level, sample index information may have leaked into representation learning

- First 3 experiments:
  1. Run SSL-C2ST vs C2ST on synthetic HDGM data with varying dimensions to verify power improvements
  2. Test type-I error control by running SSL-C2ST on data where H0 is true across different sample sizes
  3. Compare SSL-C2ST-M vs baseline methods (MMD-D, MMD-FUSE) on MNIST and ImageNet to validate empirical performance

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis relies on finite VC-dimension assumptions which may not hold for complex deep learning models used in practice
- Method requires careful handling of sample index information to maintain type-I error control, which may be challenging in implementation
- Performance depends on the quality of the autoencoder's ability to capture meaningful data structure, which can be dataset-dependent

## Confidence
- Mechanism 1 (Type-I error control): Medium - The theoretical justification is provided but relies on specific assumptions about information leakage
- Mechanism 2 (Representation learning improvement): High - The two-phase SSL approach is well-established in the literature and empirically validated
- Mechanism 3 (Theoretical power bounds): Medium - The VC-dimension based analysis provides theoretical grounding but may not fully capture practical behavior

## Next Checks
1. **Type-I error validation**: Run SSL-C2ST on synthetic datasets where H0 is true across multiple random seeds and sample sizes to verify error rates stay at or below the nominal α = 0.05 level
2. **Ablation study**: Compare SSL-C2ST performance against variants that use only labeled data (traditional C2ST) and only unlabeled data (pure autoencoder approach) to isolate the contribution of each phase
3. **Architecture sensitivity**: Test different autoencoder architectures (varying depth, latent dimension sizes) on the same datasets to determine how sensitive the method is to architectural choices