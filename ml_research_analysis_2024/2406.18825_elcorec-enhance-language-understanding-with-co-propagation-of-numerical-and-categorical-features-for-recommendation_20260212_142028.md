---
ver: rpa2
title: 'ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and
  Categorical Features for Recommendation'
arxiv_id: '2406.18825'
source_url: https://arxiv.org/abs/2406.18825
tags:
- user
- item
- language
- network
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ELCoRec addresses numerical insensitivity and encoding overhead
  in large language models (LLMs) for recommendation tasks. The method introduces
  a GAT expert network to encode user preferences by propagating numerical and categorical
  features, injecting this representation into LLMs via soft prompting.
---

# ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation

## Quick Facts
- arXiv ID: 2406.18825
- Source URL: https://arxiv.org/abs/2406.18825
- Authors: Jizheng Chen; Kounianhua Du; Jianghao Lin; Bo Chen; Ruiming Tang; Weinan Zhang
- Reference count: 40
- Primary result: Achieves AUC scores of 0.8129, 0.8468, and 0.7536 on ML-1M, ML-25M, and BookCrossing datasets respectively

## Executive Summary
ELCoRec addresses the challenge of integrating numerical and categorical features into large language models for recommendation tasks. The method introduces a Graph Attention Network (GAT) expert network that co-propagates numerical features (timestamps, ratings) and categorical features through a heterogeneous graph, creating a comprehensive user preference embedding. This embedding is then injected into the LLM via soft prompting at minimal computational cost. The model uses a Recent interaction Augmented Prompt (RAP) template that combines retrieved similar items with recent user interactions to provide both global and short-term preference signals.

## Method Summary
ELCoRec combines a GAT expert network for feature encoding with soft prompting for efficient LLM injection. The approach constructs a heterogeneous graph where numerical features (timestamps, ratings) and categorical features are modeled as nodes with interaction edges. GAT propagates these features in parallel to generate a user preference embedding, which is then linearly projected and inserted as a single token in the LLM prompt. The RAP template enhances the prompt with both retrieved semantically similar items and recent interactions. The model is fine-tuned using LoRA while keeping the GAT network frozen, achieving significant performance improvements with computational efficiency.

## Key Results
- Achieves AUC of 0.8129 on ML-1M dataset, outperforming baseline models
- Achieves AUC of 0.8468 on ML-25M dataset with substantial margin over competitors
- Achieves AUC of 0.7536 on BookCrossing dataset, demonstrating effectiveness across domains
- Outperforms feature interaction models and LLM-based recommendation approaches
- Maintains computational efficiency through parameter-efficient fine-tuning with frozen GAT network

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ELCoRec solves LLM numerical insensitivity by co-propagating numerical and categorical features through a GAT expert network.
- Mechanism: Numerical features (timestamps, ratings) and categorical features are modeled as nodes in a heterogeneous graph, with edges representing interactions. GAT aggregates these features in parallel, stabilizing heterogeneous signal types and generating an informative user preference embedding that the LLM can inject via soft prompting.
- Core assumption: Graph attention can effectively fuse heterogeneous features into a single representation without significant noise amplification.
- Evidence anchors: [abstract] "we propose to inject the preference understanding capability into LLM via a GAT expert network where the user preference is better encoded by parallelly propagating the temporal relations, and rating signals as well as various side information of historical items." [section 4.3] "Compared to general CTR prediction models, our GAT expert network can better utilize heterogeneous nodes to encode features of different kinds."
- Break condition: If the attention coefficients fail to distinguish between informative and noisy neighbors, the fused embedding could mislead the LLM.

### Mechanism 2
- Claim: ELCoRec reduces encoding overhead by injecting the GAT-derived embedding into LLM space via a single soft prompt token.
- Mechanism: The GAT expert network is frozen during LLM fine-tuning. The GAT embedding is linearly projected into LLM hidden dimension and inserted as one token in the prompt sequence, avoiding full re-encoding of all side features for every item.
- Core assumption: A single projected token can sufficiently convey the multi-dimensional GAT embedding to the LLM without significant information loss.
- Evidence anchors: [abstract] "The parallel propagation mechanism could stabilize heterogeneous features and offer an informative user preference encoding, which is then injected into the language models via soft prompting at the cost of a single token embedding." [section 4.4] "User preference representation is injected into the large language model’s semantic space at the cost of one single token after being mapped to the same dimensionality through a linear layer."
- Break condition: If the linear projection compresses critical feature interactions, the LLM's subsequent reasoning could degrade.

### Mechanism 3
- Claim: The RAP template balances global relevance and recent interest by combining retrieved similar items with recent interactions.
- Mechanism: For a target item, semantically similar historical items are retrieved via cosine similarity on encoded item descriptions. Recent items are appended from the tail of the interaction sequence. Both are merged into one prompt, preserving both global and recent preference signals.
- Core assumption: Retrieval-based filtering improves signal-to-noise ratio compared to raw full histories, and recent items preserve short-term trends.
- Evidence anchors: [section 4.2] "RAP template combines the obtained two sequences along with placeholders for subsequent semantic injections." [section 5.3.1] "The RAP prompt template can enhance the model’s understanding of user sequences solely from the data side."
- Break condition: If retrieval similarity is too coarse or recent items are not truly representative, the prompt may misrepresent the user's actual interest.

## Foundational Learning

- Concept: Graph Attention Networks (GAT)
  - Why needed here: GAT allows heterogeneous node types (user, item, feature) to exchange information through learned attention coefficients, crucial for fusing numerical and categorical features.
  - Quick check question: How does GAT's attention mechanism differ from standard self-attention in Transformers?

- Concept: Soft Prompting / Prompt Injection
  - Why needed here: Instead of fine-tuning all LLM parameters, ELCoRec inserts a learned token embedding, keeping the LLM backbone frozen and reducing computational cost.
  - Quick check question: What is the difference between soft prompting and prefix tuning in LLM adaptation?

- Concept: Semantic Retrieval with Vector Similarity
  - Why needed here: RAP requires finding historical items semantically similar to the target; cosine similarity on LLM embeddings is the practical method used here.
  - Quick check question: What is the trade-off between retrieval accuracy and computational cost when indexing item embeddings?

## Architecture Onboarding

- Component map: Data preprocessing → Item description construction → Knowledge base indexing → RAP template builder → User history retrieval + recent sequence extraction → GAT expert network → Heterogeneous graph construction + GAT propagation → Embedding injector → Linear projection + placeholder token insertion → LLM (Vicuna-13B) + LoRA → Instruction tuning with injected embeddings
- Critical path: Data → RAP template → GAT encoding → Embedding injection → LLM fine-tuning → Inference
- Design tradeoffs:
  - Using a single GAT embedding token vs. multiple tokens: lower cost but possible compression loss.
  - GAT layers fixed during LLM training vs. joint fine-tuning: lower cost but less adaptation.
  - Retrieval-based history filtering vs. raw full history: cleaner signal but may drop useful items.
- Failure signatures:
  - Overfitting to training data: check if GAT embedding patterns diverge between train/test splits.
  - Prompt injection ineffective: monitor if LLM outputs do not change when the placeholder token embedding is varied.
  - Retrieval noise: inspect if retrieved items have low semantic similarity to target.
- First 3 experiments:
  1. Freeze GAT and vary only the embedding injection token; check if AUC changes significantly.
  2. Remove the GAT expert network; replace with raw concatenated features; compare performance.
  3. Vary the number of retrieved vs. recent items in RAP; measure impact on AUC and inference speed.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ELCoRec's performance scale with increasingly large and diverse datasets beyond the three tested datasets (ML-1M, ML-25M, BookCrossing)?
- Basis in paper: [inferred] The paper mentions ELCoRec achieves stable performance improvements across three datasets but does not test scalability to larger or more diverse datasets.
- Why unresolved: The experiments only cover three public datasets with relatively limited scale and diversity compared to industrial-scale recommendation systems.
- What evidence would resolve it: Testing ELCoRec on datasets with millions more users and items, different domain types (e.g., music, news), and varying sparsity levels would demonstrate scalability and generalizability.

### Open Question 2
- Question: What is the optimal balance between retrieved items and recent interactions in the RAP template for different recommendation scenarios?
- Basis in paper: [explicit] The paper mentions RAP template combines retrieved items and recent interactions but does not systematically explore the optimal ratio or its variation across different recommendation contexts.
- Why unresolved: The paper sets K=15 for both retrieved and recent items but doesn't investigate how this ratio affects performance in different scenarios (e.g., trending items vs. long-tail recommendations).
- What evidence would resolve it: Conducting ablation studies with varying ratios of retrieved to recent items across different recommendation tasks and measuring performance impact would identify optimal configurations.

### Open Question 3
- Question: How does ELCoRec's performance compare when using different LLM architectures beyond Vicuna-13B?
- Basis in paper: [explicit] The paper uses Vicuna-13B as the backbone LLM but doesn't explore performance variations with different LLM architectures or sizes.
- Why unresolved: The paper only tests one LLM architecture, limiting understanding of how ELCoRec's effectiveness depends on the underlying language model.
- What evidence would resolve it: Testing ELCoRec with various LLM architectures (e.g., Llama, GPT variants, different sizes) while keeping other components constant would reveal architectural dependencies and optimization opportunities.

## Limitations

- The numerical and categorical feature co-propagation through GAT relies on fixed edge definitions and static graph construction, which may not capture dynamic user preferences over time
- The single-token injection mechanism could bottleneck information from the GAT expert, potentially losing critical feature interactions
- RAP template effectiveness depends heavily on retrieval quality and recent item representativeness, which are not fully validated across diverse user behavior patterns
- GAT expert network is frozen during LLM fine-tuning, preventing adaptation to LLM-specific feature importance patterns

## Confidence

- **High Confidence**: AUC improvement over baseline models (8.2%-16.7% gains), computational efficiency claims supported by parameter count comparisons
- **Medium Confidence**: RAP template design principles and dual-sequence approach, single-token injection mechanism
- **Low Confidence**: GAT feature co-propagation effectiveness without dynamic graph updates, information preservation through linear projection

## Next Checks

1. **GAT Information Bottleneck Test**: Replace the single soft token with a sequence of embedding tokens while keeping other parameters fixed; measure performance changes to quantify information loss
2. **Dynamic Graph Adaptation**: Implement a variant where GAT parameters are updated during LLM fine-tuning; compare performance and training efficiency to frozen GAT baseline
3. **Retrieval Quality Analysis**: For a stratified sample of users, manually verify semantic similarity between retrieved items and target items; correlate retrieval quality scores with model performance variations