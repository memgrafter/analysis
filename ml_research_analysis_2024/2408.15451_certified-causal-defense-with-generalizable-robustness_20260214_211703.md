---
ver: rpa2
title: Certified Causal Defense with Generalizable Robustness
arxiv_id: '2408.15451'
source_url: https://arxiv.org/abs/2408.15451
tags:
- certified
- causal
- robustness
- domains
- radius
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generalizing certified robustness
  across different data domains with distribution shifts, which is critical for deploying
  machine learning models in real-world applications. The authors propose a novel
  framework called GLEAN (GeneraLizable cErtified cAusal defeNse) that incorporates
  a causal perspective into certified defense.
---

# Certified Causal Defense with Generalizable Robustness

## Quick Facts
- arXiv ID: 2408.15451
- Source URL: https://arxiv.org/abs/2408.15451
- Authors: Yiran Qiao; Yu Yin; Chen Chen; Jing Ma
- Reference count: 5
- Key outcome: GLEAN achieves superior certified accuracy and average certified radius compared to baseline methods on synthetic and real-world datasets with distribution shifts

## Executive Summary
This paper addresses the challenge of generalizing certified adversarial robustness across different data domains with distribution shifts. The authors propose GLEAN (GeneraLizable cErtified cAusal defeNse), a novel framework that integrates causal factor learning with certified defense mechanisms. By disentangling causal relations from spurious correlations and leveraging Lipschitz-constrained networks with random smoothing, GLEAN provides theoretical guarantees for robustness on unseen domains while maintaining high performance.

## Method Summary
GLEAN is a framework for generalizing certified robustness across data domains with distribution shifts. It consists of a certifiable causal factor learning component that extracts invariant causal factors from input features using Lipschitz-constrained networks and IRM (Invariant Risk Minimization), and a causally certified defense strategy that applies randomized smoothing in the latent causal space. The framework trains on multiple source domains with varying spurious correlations while maintaining causal invariance, then provides certified robustness bounds on unseen target domains through the Lipschitz constraint mapping.

## Key Results
- GLEAN significantly outperforms baseline methods (Gaussian, MACER, SmoothAdv, Consistency) in certified accuracy at radii 0.00-0.45 on CMNIST dataset
- On CelebA and DomainNet datasets, GLEAN achieves higher Average Certified Radius (ACR) compared to all baselines across all target domains
- GLEAN maintains certified robustness when spurious correlations change across domains while preserving causal relationships

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework achieves cross-domain certified robustness by learning causal factors in a latent space using an invariant causal factor learning component.
- Mechanism: By disentangling causal relations from spurious correlations between input and label, the model filters out the negative effect of spurious correlations on defense. The causal encoder learns high-level causal factors from input features, and the classifier makes predictions based on these invariant causal factors.
- Core assumption: The relationship between causal factors C and label Y remains invariant across domains (P(Y|C) is domain-independent), while spurious correlations between non-causal factors S and Y vary across domains.
- Evidence anchors:
  - [abstract] "our framework integrates a certifiable causal factor learning component to disentangle the causal relations and spurious correlations between input and label"
  - [section] "Based on this assumption, a model that can identify causal factors and make predictions based on them can be generalized to unseen domains"
- Break condition: If the causal invariant assumption fails (P(Y|C) varies across domains) or if causal factors cannot be properly identified from input features.

### Mechanism 2
- Claim: The framework provides theoretical guarantees for robustness on different data domains through Lipschitz-constrained networks and random smoothing in the latent causal space.
- Mechanism: The causal encoder is constrained to be L-Lipschitz, which allows certified radius calculations in the latent space to be mapped back to the input space. Random smoothing is applied to the latent causal representations, and the Lipschitz constraint ensures that perturbations in the input space are bounded by the certified radius scaled by 1/L.
- Core assumption: The causal encoder Ψ is L-Lipschitz, and the random smoothing process provides certifiable robustness bounds in the latent space.
- Evidence anchors:
  - [section] "we utilize a certified causal factor learning module with Lipschitz constraint" and "we can simply scale the certified radius in the latent space by the Lipschitz constant L"
  - [abstract] "The framework leverages Lipschitz-constrained networks to provide theoretical guarantees for certified robustness on unseen domains"
- Break condition: If the Lipschitz constraint cannot be maintained during training or if the random smoothing process fails to provide valid bounds in the latent space.

### Mechanism 3
- Claim: The framework achieves better generalization of certified robustness by optimizing for both predictive accuracy and invariance through IRM (Invariant Risk Minimization).
- Mechanism: The IRM loss function combines the standard prediction loss with an invariance penalty that encourages the learned representations to be predictive across all domains. This ensures that the causal encoder learns representations that capture the invariant causal relationships rather than spurious correlations.
- Core assumption: The IRM objective successfully balances predictive ability with invariance across domains.
- Evidence anchors:
  - [section] "we extract the causal factors of input features in the latent space through techniques in invariant learning" and "we leverage one of the most representative methods: invariant risk minimization (IRM)"
  - [abstract] "Our framework integrates a certifiable causal factor learning component to disentangle the causal relations and spurious correlations between input and label"
- Break condition: If the IRM optimization fails to converge or if the balance between predictive ability and invariance is not properly maintained.

## Foundational Learning

- Concept: Causal inference and causal graphs
  - Why needed here: The framework is built on causal assumptions about how data is generated across domains, with causal factors C determining labels Y and non-causal factors S having spurious correlations with Y that vary across domains.
  - Quick check question: What is the difference between a causal factor and a spurious factor in the context of this framework?

- Concept: Lipschitz continuity and its implications for certified robustness
  - Why needed here: The framework uses L-Lipschitz networks to provide theoretical guarantees for robustness, where the Lipschitz constant bounds how much the output can change relative to input perturbations.
  - Quick check question: How does Lipschitz continuity enable the mapping of certified radii from latent space back to input space?

- Concept: Randomized smoothing and its certification process
  - Why needed here: The framework uses random smoothing in the latent causal space to provide certified robustness bounds, where Gaussian noise is added to the latent representations and Monte Carlo sampling is used to estimate the certified radius.
  - Quick check question: What is the relationship between the noise level σ, the probability bounds pA and pB, and the certified radius in randomized smoothing?

## Architecture Onboarding

- Component map: Input -> Causal encoder Ψ (L-Lipschitz) -> Latent causal representations z -> Classifier β -> Predictions, with certification path involving random smoothing on z and mapping back to input space using Lipschitz constant

- Critical path: Input → Causal encoder Ψ → Latent causal representations z → Classifier β → Predictions, with certification path involving random smoothing on z and mapping back to input space using Lipschitz constant

- Design tradeoffs: 
  - IRM hyperparameter λ balances predictive ability vs. invariance - too high causes underfitting, too low fails to capture causal factors
  - Noise level σ in random smoothing affects certified radius size vs. accuracy - higher σ increases radius but reduces accuracy
  - Lipschitz constant L affects the scaling of certified radius from latent to input space - L=1 gives direct mapping but may be harder to achieve

- Failure signatures:
  - Degraded performance on seen domains indicates issues with causal factor learning
  - Inconsistent predictions across domains with same causal factors indicates Lipschitz constraint violations
  - Zero certified radius for many inputs indicates problems with random smoothing bounds

- First 3 experiments:
  1. Verify Lipschitz constraint: Compute Lipschitz constant of trained encoder on validation data and check it matches expected value
  2. Test causal invariance: Train on multiple domains and verify that representations of same causal content are similar across domains
  3. Validate certification mapping: Check that certified radius in input space correctly scales from latent space by the Lipschitz constant

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- The framework's performance depends critically on the validity of the causal invariant assumption (P(Y|C) is domain-independent), which may not hold in all real-world scenarios.
- The Lipschitz constraint implementation requires careful architectural choices (Cayley transform for orthogonality, GroupSort activations) that are not fully detailed in the paper.
- The IRM regularization hyperparameter λ requires extensive tuning, with the paper only exploring a limited range.

## Confidence
- **High confidence**: The theoretical framework combining causal invariance with Lipschitz-constrained networks for certified robustness is sound and well-established in literature.
- **Medium confidence**: The experimental results showing superior performance over baselines are promising but limited to specific datasets with controlled spurious correlations.
- **Low confidence**: The scalability of the approach to complex real-world scenarios with multiple interacting causal factors and high-dimensional inputs.

## Next Checks
1. **Lipschitz constraint verification**: Compute the exact Lipschitz constant of the trained encoder on held-out validation data and verify it matches the expected value of 1.0, checking for constraint violations.

2. **Causal invariance stress test**: Create synthetic domains with varying degrees of causal factor invariance (P(Y|C) varies slightly across domains) and measure performance degradation to establish robustness bounds.

3. **Cross-dataset generalization**: Train GLEAN on one dataset (e.g., CelebA) and evaluate certified robustness on completely different datasets (e.g., DomainNet) to test true cross-domain generalization capabilities.