---
ver: rpa2
title: Optimal Transport for Probabilistic Circuits
arxiv_id: '2410.13061'
source_url: https://arxiv.org/abs/2410.13061
tags:
- circuit
- circuits
- wasserstein
- node
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel optimal transport framework for probabilistic
  circuits (PCs), enabling computation of Wasserstein-type distances between distributions
  represented as PCs. While existing work can compute divergences between certain
  classes of PCs, no prior approach computes Wasserstein distances.
---

# Optimal Transport for Probabilistic Circuits

## Quick Facts
- arXiv ID: 2410.13061
- Source URL: https://arxiv.org/abs/2410.13061
- Reference count: 33
- Primary result: Introduces a tractable Wasserstein-type distance CWp for probabilistic circuits that upper-bounds the true Wasserstein distance

## Executive Summary
This paper introduces a novel framework for computing Wasserstein-type distances between distributions represented as probabilistic circuits (PCs). The key insight is to restrict the coupling measure to PC structures, enabling efficient computation through small linear programs at sum nodes. While exact Wasserstein computation between PCs is computationally hard, the proposed CWp distance can be computed in quadratic time. The paper also introduces an iterative algorithm for learning PC parameters by minimizing the empirical Wasserstein distance to data.

## Method Summary
The method constructs a coupling circuit between two compatible probabilistic circuits by taking the cross-product of sum node children and solving small linear programs at each sum node to find optimal coupling parameters. The Wasserstein-type distance CWp is then computed recursively through the circuit structure. For parameter learning, an iterative algorithm alternates between computing the optimal coupling given current circuit parameters and updating circuit parameters to minimize expected distance to routed data points.

## Key Results
- CWp can be computed exactly in quadratic time while exact Wp computation is computationally hard
- CWp upper-bounds the true Wasserstein distance Wp by restricting couplings to PC structures
- The iterative Wasserstein minimization algorithm achieves competitive performance with EM for small circuits but doesn't fully exploit larger models
- CWp computation is exponentially faster than applying GMM-based algorithms to unrolled PCs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CWp upper-bounds Wp because it restricts couplings to coupling circuits
- Mechanism: By limiting the coupling measure to PC structures with smoothness and decomposability, the feasible coupling set becomes smaller, resulting in a larger (or equal) optimal value
- Core assumption: Coupling circuit structure preserves marginal-matching properties
- Evidence: Abstract states CWp "upper-bounds the true Wasserstein distance" and section explains that constraints on coupling circuits ensure valid couplings

### Mechanism 2
- Claim: CWp computation is tractable through recursive decomposition
- Mechanism: The Wasserstein objective decomposes at sum nodes (weighted sum of child objectives) and product nodes (sum of child objectives), enabling computation to be pushed down to input nodes
- Core assumption: Circuit structure enables recursive decomposition
- Evidence: Section shows recursive computation of CWp-objective function at each node and demonstrates linearity of integrals

### Mechanism 3
- Claim: Parameter learning monotonically decreases empirical Wasserstein distance
- Mechanism: Iterative algorithm optimizes coupling given circuit parameters, then updates circuit parameters to minimize expected distance to routed data
- Core assumption: Linear programs at sum nodes have closed-form solutions ensuring objective decrease
- Evidence: Section states time complexity is linear in circuit and dataset size, and appendix provides convergence theorem

## Foundational Learning

- Concept: Linear programming and optimal transport
  - Why needed here: Algorithm solves small LPs at sum nodes to find optimal coupling parameters
  - Quick check: What LP structure (continuous knapsack problem) enables closed-form parameter updates?

- Concept: Probabilistic circuits and structural properties
  - Why needed here: Tractability of CWp computation relies on smoothness and decomposability properties
  - Quick check: How do smoothness and decomposability enable recursive Wasserstein objective computation?

- Concept: Optimal transport theory and Wasserstein distances
  - Why needed here: Paper introduces Wasserstein-type distance between PCs, requiring understanding of original formulation
  - Quick check: What distinguishes true Wasserstein distance from proposed CWp?

## Architecture Onboarding

- Component map: Input PCs -> Coupling circuit construction -> Linear program solver at sum nodes -> Recursive CWp computation -> Output distance/transport plan
- Critical path: 1) Build coupling circuit by cross-product at sum nodes, 2) Solve LPs at sum nodes, 3) Compute CWp recursively, 4) Extract transport plan if needed
- Design tradeoffs: Restrictive coupling enables tractability but may not capture all possible couplings; exact CWp computation vs. approximation of true Wp
- Failure signatures: Runtime explosion with incompatible circuits, memory issues with large coupling circuits, convergence problems in parameter learning
- First 3 experiments: 1) Compute CWp between two simple compatible PCs and verify against analytical solution, 2) Test runtime scaling with circuit size using random compatible PCs, 3) Implement parameter learning on small synthetic dataset and compare visually to data distribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact computational complexity gap between CWp and Wp for PCs?
- Basis: Paper states exact Wp computation is hard while CWp is quadratic time but doesn't quantify the gap
- Why unresolved: Proves hardness of Wp and provides efficient CWp algorithm but lacks formal complexity analysis of the gap
- Resolution evidence: Formal complexity analysis comparing time/space requirements of both approaches

### Open Question 2
- Question: Can empirical Wasserstein minimization be modified to better exploit larger circuit parameter spaces?
- Basis: Algorithm performs competitively with EM for small circuits but doesn't fully utilize larger models
- Why unresolved: Observes limitation in experiments but doesn't investigate modifications to address it
- Resolution evidence: Experiments testing modified parameter update strategies with regularization or adaptive learning rates

### Open Question 3
- Question: What is the theoretical relationship between CWp and true Wp for PCs?
- Basis: Establishes CWp upper-bounds Wp but doesn't provide tight bounds or characterize the gap
- Why unresolved: Proves upper bound property but doesn't investigate how tight it is or when CWp approaches Wp
- Resolution evidence: Theoretical analysis proving upper/lower bounds on CWp/Wp ratios or empirical gap characterization

## Limitations
- CWp is an upper bound on true Wp, limiting utility for applications requiring exact distances
- Coupling circuit construction restricted to compatible circuits, with incompatibility causing exponential blowup
- Parameter learning algorithm doesn't fully exploit larger parameter spaces and underperforms EM on larger circuits
- Theoretical guarantees rely heavily on circuit properties that may not hold for all PC structures

## Confidence

- **High confidence**: Hardness of exact Wp computation between PCs (Theorem 1) with well-established proof structure; upper-bound property of CWp on Wp with mathematical proof
- **Medium confidence**: Recursive CWp computation algorithm correctness for compatible circuits, dependent on numerical stability; parameter learning convergence guarantees conditional on closed-form LP solutions
- **Low confidence**: Limited empirical evaluation to small circuit sizes (up to 40 parameters) making scalability assessment difficult; comparison only considers unrolled PC representations

## Next Checks
1. Verify CWp upper-bound property by testing on distributions where both distances can be computed analytically (e.g., Gaussians)
2. Implement benchmark comparing CWp computation time against exact Wp computation for small compatible circuits to validate exponential complexity claim
3. Extend parameter learning experiments to larger circuit architectures (beyond 40 parameters) and compare against EM on equivalent model capacity to assess scalability limitations