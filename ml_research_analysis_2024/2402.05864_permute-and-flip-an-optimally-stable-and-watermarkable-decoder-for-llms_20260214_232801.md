---
ver: rpa2
title: 'Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs'
arxiv_id: '2402.05864'
source_url: https://arxiv.org/abs/2402.05864
tags:
- watermark
- text
- sampling
- decoding
- gumbel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Permute-and-Flip (PF) decoding, a new decoding
  method for large language models (LLMs) that offers robustness properties similar
  to softmax sampling but with significantly improved quality-stability tradeoff,
  achieving up to 2x better performance in some cases. The method iteratively generates
  tokens by randomly permuting the vocabulary and flipping biased coins until the
  first "head" is seen.
---

# Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs

## Quick Facts
- arXiv ID: 2402.05864
- Source URL: https://arxiv.org/abs/2402.05864
- Authors: Xuandong Zhao; Lei Li; Yu-Xiang Wang
- Reference count: 40
- Primary result: PF decoding achieves up to 2x better quality-stability tradeoff than softmax sampling while maintaining watermark detectability

## Executive Summary
This paper introduces Permute-and-Flip (PF) decoding, a new decoding method for large language models that offers robustness properties similar to softmax sampling but with significantly improved quality-stability tradeoff. The method iteratively generates tokens by randomly permuting the vocabulary and flipping biased coins until the first "head" is seen. A key contribution is a cryptographic watermarking scheme tailored for PF decoding, analogous to Aaronson's Gumbel watermark, which does not change the sampling distribution while allowing arbitrarily low false positive rates and high recall when generated text has high entropy. Experiments show that PF decoding (and its watermarked version) significantly outperforms naive sampling (and its Gumbel watermarked counterpart) in terms of perplexity while retaining the same stability and detectability, making it a promising new approach for LLM decoding.

## Method Summary
The paper introduces Permute-and-Flip (PF) decoding, which iteratively generates tokens by randomly permuting the vocabulary and flipping biased coins until the first "head" is seen. This process creates a more concentrated distribution than softmax sampling for the same temperature, leading to higher expected utility while maintaining the same robustness parameter. The watermarking scheme replaces the exponential noise in PF sampling with a pseudo-random function based on a secret key and prefix, making the watermarked distribution computationally indistinguishable from the original while allowing detection through the sum of -log(rt(yt)) values. The method is evaluated on Llama-2-7B and Llama-2-13B models using C4 and Alpaca datasets, comparing perplexity, watermark detection accuracy, and robustness to paraphrasing attacks against baselines including greedy, sampling, KGW watermark, and Gumbel watermark.

## Key Results
- PF decoding achieves up to 2x better quality-stability tradeoff than softmax sampling for the same temperature
- The watermarking scheme maintains computational indistinguishability while enabling detection with controlled false positive rates
- PF watermark maintains high robustness against paraphrasing and editing attacks while controlling false positive rates
- Watermarked PF decoding significantly outperforms Gumbel watermarked sampling in both perplexity and detectability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PF sampling is Pareto optimal in the robustness-perplexity tradeoff compared to softmax sampling
- Mechanism: PF sampling uses a permutation-and-flip process that creates a more concentrated distribution than softmax sampling for the same temperature, leading to higher expected utility (lower suboptimality) while maintaining the same robustness parameter L = 2/T
- Core assumption: The logits function u is bounded and the vocabulary size |V| is finite
- Evidence anchors:
  - [section] "PF sampling was initially proposed in McKenna & Sheldon (2020) as a differentially private selection mechanism that has better utility than the more well-known exponential mechanism"
  - [abstract] "It enjoys stability properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-robustness tradeoff than sampling"
  - [corpus] Weak - corpus provides no direct evidence about Pareto optimality, though it shows related work on decoding methods
- Break condition: If the temperature T approaches 0, both methods become greedy and the difference disappears; if T is very large, both methods become uniform and again the difference vanishes

### Mechanism 2
- Claim: PF watermark maintains computational indistinguishability from non-watermarked PF while providing controlled false positive rates
- Mechanism: By replacing the exponential noise in PF sampling with a pseudo-random function based on a secret key and prefix, the watermarked distribution becomes computationally indistinguishable from the original while allowing detection through the sum of -log(rt(yt)) values
- Core assumption: The pseudo-random function F is computationally indistinguishable from truly random uniform distribution
- Evidence anchors:
  - [section] "We show that the watermarked PF decoder samples from a distribution that is computationally indistinguishable from the non-watermarked PF decoder"
  - [abstract] "The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall"
  - [corpus] Weak - corpus mentions watermarking work but doesn't specifically address PF watermark properties
- Break condition: If the pseudo-random function is predictable or the entropy of generated text is too low, the watermark becomes detectable without the key

### Mechanism 3
- Claim: PF watermark achieves similar or better detectability-greediness tradeoff compared to Gumbel watermark when temperature is appropriately tuned
- Mechanism: PF sampling is more greedy than softmax for the same temperature, so to achieve comparable suboptimality, PF can use higher temperature, which increases the entropy of the distribution and thus the detectability of the watermark
- Core assumption: The relationship between temperature and suboptimality is monotonic and predictable for both methods
- Evidence anchors:
  - [section] "the PF watermark does not beat the Gumbel watermark in terms of detectability when T is fixed. This should not be surprising since for the same temperature, PF watermark is better at optimizing"
  - [abstract] "The watermark scheme also maintains high robustness against paraphrasing and editing attacks"
  - [corpus] Weak - corpus mentions various watermarking approaches but doesn't specifically compare PF vs Gumbel detectability
- Break condition: If the temperature tuning is incorrect or the token distribution has very low entropy, the detectability advantage may not materialize

## Foundational Learning

- Concept: Differential Privacy and Robustness
  - Why needed here: The robustness definition (L-robustness) in this paper is directly derived from differential privacy concepts, specifically the exponential mechanism
  - Quick check question: What is the relationship between L-robustness and pure Îµ-differential privacy?

- Concept: Gumbel-Max Trick and Report-Noisy-Max Mechanisms
  - Why needed here: Understanding that both softmax sampling and PF sampling can be viewed as argmax of noisy logits (Gumbel vs Exponential noise) is crucial for understanding the watermarking scheme
  - Quick check question: How does the Report-Noisy-Max interpretation of PF sampling enable the watermarking scheme?

- Concept: Cryptographic Pseudo-Random Functions
  - Why needed here: The watermarking scheme relies on pseudo-random functions that are computationally indistinguishable from random to maintain the distribution while enabling detection
  - Quick check question: What properties must a pseudo-random function have to be suitable for this watermarking scheme?

## Architecture Onboarding

- Component map: Prompt text -> LLama model API (logits) -> PF decoding algorithm (with optional watermark) -> Generated token sequence

- Critical path:
  1. Compute logits for current prefix
  2. Find maximum logit value u*
  3. Permute vocabulary
  4. For each token in permuted order: generate Bernoulli trial with probability exp((u(y)-u*)/T)
  5. Select first token with successful Bernoulli trial
  6. (Optional) Apply watermark by modifying the random number generation

- Design tradeoffs:
  - Temperature vs. suboptimality vs. robustness: Higher temperature increases robustness but may reduce quality
  - Prefix length for watermark: Longer prefixes increase security but reduce the number of watermarked tokens
  - Vocabulary size: Larger vocabularies may require more permutation operations

- Failure signatures:
  - Degenerate output: If temperature is too low, PF becomes effectively greedy
  - Poor watermark detection: If text entropy is too low or pseudo-random function is weak
  - Performance degradation: If permutation operations are not optimized for large vocabularies

- First 3 experiments:
  1. Compare perplexity of PF vs softmax sampling on a standard dataset (C4 or Alpaca) at various temperatures
  2. Test watermark detection accuracy vs false positive rate on generated text
  3. Measure robustness to paraphrasing attacks on watermarked text

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Permute-and-Flip decoding method's performance vary with different vocabulary sizes and language model architectures?
- Basis in paper: [explicit] The paper mentions that the method's properties are valid for any language model architecture, but specific performance variations are not explored.
- Why unresolved: The experiments focus on a specific model (Llama-2) and do not systematically vary the vocabulary size or explore different model architectures.
- What evidence would resolve it: Conducting experiments with different language models (e.g., GPT, BERT) and varying vocabulary sizes to compare the performance of Permute-and-Flip decoding against other methods.

### Open Question 2
- Question: What are the computational costs of implementing Permute-and-Flip decoding in real-time applications compared to other decoding methods?
- Basis in paper: [inferred] The paper discusses computational efficiency as an important factor but does not provide a detailed comparison of the computational costs of Permute-and-Flip decoding.
- Why unresolved: The paper mentions that each API call to the logits function is costly, but it does not quantify the computational overhead of Permute-and-Flip decoding.
- What evidence would resolve it: A detailed analysis of the computational costs, including time complexity and memory usage, of Permute-and-Flip decoding compared to other methods like softmax sampling and beam search.

### Open Question 3
- Question: How robust is the Permute-and-Flip watermarking scheme against sophisticated adversarial attacks that aim to remove or alter the watermark?
- Basis in paper: [explicit] The paper discusses the robustness of the watermarking scheme against paraphrasing and editing attacks but does not explore more sophisticated adversarial techniques.
- Why unresolved: The experiments focus on basic paraphrasing and deletion attacks, leaving the effectiveness against more advanced adversarial methods unexplored.
- What evidence would resolve it: Conducting experiments with advanced adversarial attacks, such as those designed to specifically target and remove watermarks, to evaluate the robustness of the Permute-and-Flip watermarking scheme.

## Limitations

- The computational assumptions underlying the watermarking scheme depend critically on the pseudo-random function being truly cryptographically secure
- The experimental scope is limited to Llama-2 models and two specific datasets, limiting generalizability
- The relationship between temperature tuning and detectability is not fully characterized for practical use cases

## Confidence

### High Confidence
- PF decoding achieves lower perplexity than softmax sampling while maintaining the same robustness parameter L = 2/T
- The watermarking scheme does not change the sampling distribution when the pseudo-random function is secure
- Watermarked text can be detected with high accuracy (true positive rate) at controlled false positive rates

### Medium Confidence
- PF decoding is Pareto optimal in the robustness-perplexity tradeoff compared to softmax sampling
- The watermarking scheme maintains computational indistinguishability from non-watermarked PF
- PF watermark achieves similar or better detectability-greediness tradeoff compared to Gumbel watermark when temperature is appropriately tuned

### Low Confidence
- The improvements in quality-stability tradeoff (up to 2x better) generalize across all temperature ranges and vocabulary sizes
- The watermark robustness against paraphrasing and editing attacks holds for all possible attack strategies
- The computational indistinguishability guarantee holds against all practical adversaries with realistic computational resources

## Next Checks

1. **Implement and test the watermark detection on adversarial examples**: Generate text with various levels of entropy and apply different paraphrasing strategies to evaluate whether the watermark remains detectable only when the pseudo-random function assumptions hold. This would validate the security claim that the watermark is undetectable without the key when text entropy is high.

2. **Benchmark PF decoding across diverse model architectures and datasets**: Implement PF decoding for models beyond Llama-2 (such as GPT-3.5, PaLM, or open-source alternatives) and test on diverse datasets including code generation, translation, and summarization tasks. This would validate whether the quality-stability improvements generalize beyond the specific experimental setup.

3. **Characterize the temperature-detectability relationship empirically**: Systematically vary temperature parameters for both PF and Gumbel watermarking across a wide range of values, measuring the resulting perplexity, detectability, and suboptimality for each method. This would provide practical guidance for temperature tuning and validate the claim about comparable detectability-greediness tradeoffs.