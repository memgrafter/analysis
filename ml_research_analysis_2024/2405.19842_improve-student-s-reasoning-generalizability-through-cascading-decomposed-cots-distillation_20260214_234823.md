---
ver: rpa2
title: Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs
  Distillation
arxiv_id: '2405.19842'
source_url: https://arxiv.org/abs/2405.19842
tags:
- cascod
- learning
- cots
- answer
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of limited out-of-domain (OOD)
  generalization in chain-of-thought (CoT) distillation from large language models
  (LLMs) to smaller models. The authors propose Cascading Decomposed CoTs Distillation
  (CasCoD), which decomposes the traditional single-step CoT learning into two cascaded
  steps: rationale learning (removing the answer) followed by answer learning (using
  question-rationale pair).'
---

# Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation

## Quick Facts
- **arXiv ID**: 2405.19842
- **Source URL**: https://arxiv.org/abs/2405.19842
- **Authors**: Chengwei Dai; Kun Li; Wei Zhou; Songlin Hu
- **Reference count**: 40
- **Primary result**: CasCoD improves OOD reasoning generalization by up to 8.4% over standard CoT distillation

## Executive Summary
This paper addresses the problem of limited out-of-domain (OOD) generalization in chain-of-thought (CoT) distillation from large language models (LLMs) to smaller models. The authors propose Cascading Decomposed CoTs Distillation (CasCoD), which decomposes the traditional single-step CoT learning into two cascaded steps: rationale learning (removing the answer) followed by answer learning (using question-rationale pair). This approach reduces spurious correlations between questions and answers that interfere with rationale generation. Experiments on multiple reasoning benchmarks show CasCoD significantly outperforms standard CoT distillation and other baselines on both in-domain (up to 6.4% improvement) and OOD tasks (up to 8.4% improvement), with better faithfulness and reasoning consistency.

## Method Summary
CasCoD addresses the challenge of OOD generalization in CoT distillation by decomposing the learning process into two cascaded stages. First, the student model learns to generate rationales by observing only the question and rationale pairs from the teacher model, without seeing the answer. This helps the student learn genuine reasoning patterns rather than spurious correlations between questions and answers. In the second stage, the student learns to generate answers using the question-rationale pairs, effectively learning to use the generated rationale to arrive at the correct answer. This decomposition helps the student develop more robust reasoning capabilities that generalize better to unseen domains compared to standard CoT distillation where students learn to generate both rationale and answer simultaneously.

## Key Results
- CasCoD outperforms standard CoT distillation on in-domain tasks by 4.8-6.4% across multiple benchmarks
- OOD generalization improves by up to 8.4% compared to baseline methods
- The approach demonstrates better faithfulness and reasoning consistency in generated rationales
- CasCoD shows robustness across different model sizes and varying amounts of training data

## Why This Works (Mechanism)
CasCoD works by breaking down the spurious correlations that typically develop when students learn to generate both rationales and answers simultaneously. In standard CoT distillation, students may learn to map question-answer pairs directly without truly understanding the reasoning process, especially when certain question-answer patterns co-occur frequently in the training data. By separating rationale generation from answer generation, CasCoD forces the student to first learn the reasoning process independently of the answer. This two-stage approach ensures that the student develops genuine reasoning capabilities that can be applied to novel problems, rather than memorizing surface-level patterns. The cascaded structure allows the student to refine its understanding progressively, leading to better generalization performance.

## Foundational Learning
- **Chain-of-thought prompting**: A technique where models generate intermediate reasoning steps before producing final answers, crucial for complex reasoning tasks
  - *Why needed*: Enables models to break down complex problems into manageable steps, improving reasoning performance
  - *Quick check*: Verify that the model can generate coherent intermediate steps for arithmetic and commonsense reasoning tasks

- **Knowledge distillation**: Process of transferring knowledge from a larger "teacher" model to a smaller "student" model, essential for creating efficient models
  - *Why needed*: Allows deployment of powerful reasoning capabilities in resource-constrained environments
  - *Quick check*: Confirm that the student model's performance improves over training while using fewer parameters than the teacher

- **Spurious correlations**: Incorrect associations learned by models between features that co-occur in training data but don't represent genuine causal relationships
  - *Why needed*: Understanding these helps prevent models from learning shortcuts that fail on OOD data
  - *Quick check*: Test model performance on datasets where training and test distributions differ in feature correlations

- **Out-of-domain generalization**: Model's ability to perform well on data that differs from training distribution, critical for real-world deployment
  - *Why needed*: Real-world applications rarely have perfectly matched training and test distributions
  - *Quick check*: Evaluate model performance on held-out datasets with different characteristics from training data

- **Causal reasoning**: Understanding cause-and-effect relationships rather than surface-level correlations, fundamental for robust reasoning
  - *Why needed*: Enables models to apply learned reasoning patterns to genuinely novel situations
  - *Quick check*: Test whether the model can solve problems requiring inference beyond memorized patterns

## Architecture Onboarding

**Component map**: Question -> Teacher Model -> (Rationale, Answer) -> CasCoD Pipeline -> Student Model -> (Rationale, Answer)

**Critical path**: 
1. Teacher model generates CoT rationales and answers on training data
2. CasCoD separates rationale learning (Q→R) and answer learning (Q,R→A)
3. Student model first learns rationale generation independently
4. Student then learns answer generation using generated rationales
5. Final evaluation on both in-domain and OOD benchmarks

**Design tradeoffs**: 
- Single-step vs. cascaded learning: Cascaded approach increases training complexity but improves OOD generalization
- Rationale-only vs. full CoT learning: Rationale-only stage may miss answer-relevant patterns but reduces spurious correlations
- Teacher model quality: High-quality rationales are essential but may be expensive to obtain

**Failure signatures**:
- Student generates superficial rationales that don't support the answer
- Performance degradation on in-domain tasks due to over-regularization
- Computational overhead from additional training stage
- Sensitivity to noise in teacher-generated rationales

**First experiments to run**:
1. Compare standard CoT distillation vs. CasCoD on a simple arithmetic reasoning benchmark
2. Ablation study: rationale-only learning vs. full cascaded approach
3. Stress test with noisy teacher rationales to assess robustness

## Open Questions the Paper Calls Out
The authors acknowledge several important limitations in their work. The proposed method focuses primarily on reducing spurious correlations in CoT distillation but does not address other factors affecting OOD generalization such as prompt engineering, model architecture differences, or diverse training data quality. The approach assumes the availability of high-quality CoT annotations from teacher models, which may not always be available in practice. Additionally, the cascaded decomposition may increase training complexity and computational overhead compared to single-step distillation approaches.

## Limitations
- Focuses primarily on spurious correlation reduction but doesn't address other OOD generalization factors like prompt engineering or model architecture
- Requires high-quality CoT annotations from teacher models, which may not be available in practice
- Cascaded decomposition increases training complexity and computational overhead compared to single-step approaches
- Limited evaluation of performance across different reasoning types (mathematical vs. commonsense reasoning)

## Confidence

**Claims about CasCoD outperforming standard CoT distillation on in-domain tasks**: **High** confidence based on consistent improvements across multiple benchmarks (4.8-6.4%)

**Claims about OOD generalization improvements (8.4%)**: **Medium** confidence - while improvements are reported, the OOD generalization challenge is complex and may depend on specific task characteristics

**Claims about robustness across model sizes and training data amounts**: **Medium** confidence - the paper provides evidence but could benefit from more systematic ablation studies across different scales

**Claims about improved faithfulness and reasoning consistency**: **Medium** confidence - these qualitative metrics are important but require careful evaluation to avoid confirmation bias

## Next Checks

1. Test CasCoD performance on additional OOD benchmarks beyond those reported, particularly tasks with different reasoning types (e.g., mathematical reasoning vs. commonsense reasoning) to verify generalization claims

2. Conduct ablation studies isolating the effects of each cascaded step to quantify the contribution of rationale learning vs. answer learning components

3. Evaluate computational overhead and training time differences between CasCoD and standard CoT distillation across different model scales to assess practical deployment considerations