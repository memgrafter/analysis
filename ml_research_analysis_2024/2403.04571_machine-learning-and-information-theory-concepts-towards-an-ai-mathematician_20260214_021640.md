---
ver: rpa2
title: Machine learning and information theory concepts towards an AI Mathematician
arxiv_id: '2403.04571'
source_url: https://arxiv.org/abs/2403.04571
tags:
- learning
- theorems
- statements
- which
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a framework for training an AI mathematician
  to discover new and interesting conjectures, rather than just proving given theorems.
  The key idea is to view theorems as compressing the space of all provable statements
  - a useful theorem allows many other provable statements to be derived from it in
  few steps.
---

# Machine learning and information theory concepts towards an AI Mathematician

## Quick Facts
- arXiv ID: 2403.04571
- Source URL: https://arxiv.org/abs/2403.04571
- Reference count: 6
- Key outcome: Proposes framework for AI mathematician to discover interesting conjectures using information-theoretic compression metrics

## Executive Summary
This paper presents a framework for training an AI system to autonomously discover new mathematical conjectures by viewing theorems as compressors of the space of provable statements. The central hypothesis is that interesting theorems efficiently compress mathematical knowledge - enabling many other statements to be derived in few steps while remaining compact themselves. The authors propose using information-theoretic measures to quantify this compression efficiency and guide the exploration of conjectures. The framework combines goal-conditioned reinforcement learning for proof generation with active learning principles to select the most useful theorems to learn from. This represents a shift from traditional theorem-proving systems that prove given theorems to systems that can discover novel, interesting mathematical statements.

## Method Summary
The proposed method treats theorem discovery as an information-theoretic optimization problem where the goal is to find a compact set of theorems that efficiently compresses the space of all provable statements. The system generates candidate conjectures using a structured generative model (like GFlowNet), estimates their compression efficiency and epistemic uncertainty, and prioritizes them for proof attempts. Goal-conditioned reinforcement learning is used to generate proof sequences, with active learning guiding which conjectures to attempt. The compression metric evaluates how many other provable statements a theorem enables deriving in few steps. The framework iteratively builds a theorem body by adding successful proofs, using the updated body to guide future conjecture generation.

## Key Results
- Presents information-theoretic framework for quantifying theorem "interestingness" via compression efficiency
- Proposes using epistemic uncertainty for active learning to select useful conjectures
- Outlines goal-conditioned reinforcement learning approach for automated proof generation
- Frames mathematical discovery as exploration of conjecture space guided by compression metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Theorems are useful when they compress the space of provable statements
- Mechanism: The framework measures a theorem's value by how many other provable statements it enables deriving in few steps, creating a compression metric that guides conjecture generation
- Core assumption: A "good" mathematical theory is one that efficiently compresses the space of all provable statements while remaining compact itself
- Evidence anchors:
  - [abstract] "The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length while at the same time being close (in terms of number of derivation steps) to many provable statements"
  - [section] "A crucial component of the usefulness of a new proven theorem t is how efficiently T(S) ∪ {t} compresses the set of all provable mathematical statements M"
  - [corpus] Weak evidence - no direct citations found for this specific compression hypothesis in related papers
- Break condition: If compression efficiency cannot be estimated without actually proving many theorems, the framework becomes computationally intractable

### Mechanism 2
- Claim: Active learning principles can guide theorem discovery
- Mechanism: The framework uses epistemic uncertainty - selecting conjectures that the current theorem body cannot confidently predict as true or false - to prioritize which theorems to attempt proving
- Core assumption: Theorems that are surprising given current knowledge are more likely to be useful for compression
- Evidence anchors:
  - [section] "The classical application of such active learning is in deciding which unlabeled example images x should be sent to human labelers" - analogized to selecting which conjectures to attempt
  - [section] "Ex-ante, i.e., before we see a proof... we may rely on the estimated entropy EP(t|T(S))[− log P(t | T(S))] of the truth value of the statement t to ascertain the information gain"
  - [corpus] Moderate evidence - active learning is well-established in ML but not specifically for mathematical conjecture generation
- Break condition: If the model cannot accurately estimate uncertainty about conjecture provability, the active learning heuristic fails

### Mechanism 3
- Claim: Goal-conditioned reinforcement learning can generate proof attempts
- Mechanism: The system treats proof generation as a goal-conditioned RL problem where the conjecture is the goal state, and the agent generates sequences of proof tactics to reach it
- Core assumption: Mathematical proofs can be decomposed into sequences of actions (tactic applications) that can be learned through reinforcement learning
- Evidence anchors:
  - [section] "In the reinforcement learning jargon, we use the term goal-conditioned policy to talk about a generator of sequences of actions (here to prove a theorem) that is provided a goal as a target to reach"
  - [section] "Some of the most successful existing theorem-proving algorithms are large language models trained by imitation learning – learning to mimic human-written proofs"
  - [corpus] Moderate evidence - RL approaches exist for theorem proving but not specifically goal-conditioned methods for conjecture generation
- Break condition: If the action space of proof tactics is too large or sparse, RL may fail to find effective proof strategies

## Foundational Learning

- Concept: Information theory and compression
  - Why needed here: The framework fundamentally relies on information-theoretic notions of compression to evaluate theorem usefulness
  - Quick check question: Can you explain why a theorem that enables deriving many other theorems in few steps is considered "compressive"?

- Concept: Active learning and epistemic uncertainty
  - Why needed here: The system uses uncertainty estimates to prioritize which conjectures to attempt proving
  - Quick check question: How does the framework use entropy to measure how "surprising" a conjecture is given current knowledge?

- Concept: Goal-conditioned reinforcement learning
  - Why needed here: The proof generation component treats conjectures as goals and generates sequences of proof tactics to reach them
  - Quick check question: What distinguishes goal-conditioned RL from standard RL in the context of theorem proving?

## Architecture Onboarding

- Component map:
  Conjecture generator -> Compression estimator -> Uncertainty estimator -> Proof generator -> Proof verifier -> Theorem body manager

- Critical path:
  1. Generate candidate conjectures using GFlowNet
  2. Estimate compression efficiency and uncertainty for each
  3. Select most promising conjectures based on these scores
  4. Attempt to prove selected conjectures using goal-conditioned RL
  5. Add successful proofs to theorem body
  6. Repeat

- Design tradeoffs:
  - Compression estimation vs computational cost: Exact computation requires proving many theorems
  - Exploration vs exploitation: Need to balance finding new compression theorems vs proving known ones
  - Proof search depth: Deeper search may find proofs but increases computation time exponentially

- Failure signatures:
  - Conjecture generator produces only trivial statements
  - Compression estimator cannot distinguish useful from useless theorems
  - Proof generator gets stuck in local optima or fails to generalize
  - System cycles through same conjectures without progress

- First 3 experiments:
  1. Implement compression estimator on a small formal system (e.g., propositional logic) and verify it correctly identifies useful theorems
  2. Test active learning heuristic on held-out theorems from existing libraries (mathlib) to see if uncertainty correlates with usefulness
  3. Implement a simple goal-conditioned RL prover on toy conjectures and measure success rate vs baseline methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What objective function should be used to train an AI mathematician to discover interesting conjectures?
- Basis in paper: [explicit] The paper proposes an information-theoretic objective function that favors a small library of theorems that efficiently compress the set of all provable statements.
- Why unresolved: This is the central open question the paper aims to address, and the proposed objective function is only a hypothesis that needs to be further developed and tested.
- What evidence would resolve it: Developing and testing a concrete implementation of the proposed objective function, and evaluating its ability to generate interesting conjectures that compress the space of provable statements.

### Open Question 2
- Question: How can an AI mathematician be trained to generate useful subgoals (lemmas) that aid in proving theorems?
- Basis in paper: [explicit] The paper suggests using goal-conditioned reinforcement learning to generate proof attempts, and discusses the importance of generating useful subgoals in the form of lemmas.
- Why unresolved: While the paper discusses the general idea of using goal-conditioned RL, it does not provide a concrete algorithm or implementation for generating useful subgoals.
- What evidence would resolve it: Developing and testing a concrete implementation of a goal-conditioned RL algorithm that generates useful subgoals, and evaluating its performance on theorem proving tasks.

### Open Question 3
- Question: How can the compression-based objective function be approximated or estimated efficiently in practice?
- Basis in paper: [explicit] The paper acknowledges that the exact compression objective is too expensive to compute directly, and suggests that approximations and heuristics may be needed.
- Why unresolved: The paper does not provide concrete methods for approximating the compression objective, which is a key challenge in implementing the proposed approach.
- What evidence would resolve it: Developing and testing concrete methods for approximating the compression objective, and evaluating their effectiveness in guiding the discovery of interesting conjectures.

## Limitations
- Core compression hypothesis lacks empirical validation on real mathematical domains
- Compression efficiency metric may be computationally intractable for non-trivial formal systems
- Uncertainty estimation for conjecture provability is difficult without extensive training data
- Proof decomposition into sequences of tactics may not capture complex proof strategies

## Confidence
- **High**: The overall conceptual framework of using information theory to measure theorem usefulness is theoretically sound and well-grounded in existing ML literature on active learning and reinforcement learning
- **Medium**: The compression-based objective function and its implementation details have theoretical justification but lack empirical validation on mathematical domains
- **Low**: The specific implementation details for compression estimation, uncertainty quantification, and goal-conditioned proof generation remain largely unspecified and would require significant research to develop

## Next Checks
1. Implement the compression efficiency metric on a small formal system (e.g., propositional logic) and validate that it correctly identifies known useful theorems by comparing against human intuition of theorem importance
2. Test the active learning heuristic by training on a subset of theorems from mathlib and measuring whether uncertainty-based selection improves coverage of held-out theorems compared to random selection
3. Implement a simplified version of the goal-conditioned RL prover on toy conjectures (e.g., from Peano arithmetic) and measure success rate compared to baseline proof search methods like depth-first search with pruning