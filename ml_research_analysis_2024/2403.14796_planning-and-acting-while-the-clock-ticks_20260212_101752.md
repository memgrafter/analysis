---
ver: rpa2
title: Planning and Acting While the Clock Ticks
arxiv_id: '2403.14796'
source_url: https://arxiv.org/abs/2403.14796
tags:
- planning
- time
- action
- temporal
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces concurrent planning and execution, a novel
  problem setting allowing actions to be dispatched before a complete plan is found.
  The key innovation is extending metareasoning from situated temporal planning to
  handle this setting, accounting for the value of information gained during search.
---

# Planning and Acting While the Clock Ticks

## Quick Facts
- arXiv ID: 2403.14796
- Source URL: https://arxiv.org/abs/2403.14796
- Reference count: 20
- Key outcome: This paper introduces concurrent planning and execution, a novel problem setting allowing actions to be dispatched before a complete plan is found, with empirical results showing significant performance improvements over standard situated temporal planning under time pressure.

## Executive Summary
This paper introduces a novel problem setting called concurrent planning and execution, where actions can be dispatched before a complete plan is found. The key innovation is extending metareasoning from situated temporal planning to handle this setting, accounting for the value of information gained during search. The approach builds on the DDA metareasoning scheme, adapting it to estimate the probability of success for both dispatching and continuing search. Empirical evaluation on robotics domains shows that the proposed method significantly outperforms standard situated temporal planning under time pressure, with the performance gap increasing as CPU speed decreases.

## Method Summary
The proposed method extends the DDA metareasoning scheme to estimate the probability of success for both dispatching an action now and continuing search. It compares these probabilities and dispatches the action if the dispatch probability exceeds the search probability by a threshold. The algorithm also calculates the net value of information (VOI) gained during search to decide whether to dispatch an action or continue searching. The state space is modified to support acting while the clock ticks, keeping track of dispatched actions and their dispatch times, and updating the open list and memoized states accordingly. The decision rule is integrated into the situated temporal planner of Shperberg et al. (2021), yielding a dispatching planner for concurrent planning and execution.

## Key Results
- The proposed method significantly outperforms situated temporal planning under strong time pressure
- Performance gap increases as CPU speed decreases, demonstrating the method's effectiveness when computational resources are limited
- The method successfully balances the trade-off between acting quickly and gathering information to make better decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dispatching actions before planning terminates reduces deadline violations under time pressure.
- Mechanism: The algorithm estimates the probability of success for both dispatching an action now and continuing search. It compares these probabilities and dispatches the action if the dispatch probability exceeds the search probability by a threshold. This balances the trade-off between acting quickly and gathering more information.
- Core assumption: The planner can accurately estimate the probability of success for both dispatching and continuing search, even with incomplete information.
- Evidence anchors:
  - [abstract] "Our empirical evaluation shows that when there is strong time pressure, our approach outperforms situated temporal planning."
  - [section 5.2] "We approximate these utilities by simulating for each case what would be the allocations of the computation time to processes in the ensuing search"
  - [corpus] Weak evidence: The corpus contains related papers on planning and execution, but none directly address the specific mechanism of estimating success probabilities for early action dispatch.
- Break condition: If the probability estimates are inaccurate, the algorithm may dispatch actions that are unlikely to succeed, leading to failure.

### Mechanism 2
- Claim: The value of information (VOI) gained during search is used to decide whether to dispatch an action or continue searching.
- Mechanism: The algorithm calculates the net VOI for each computational action by comparing the expected probability of success if the action is dispatched immediately versus if the computational action is performed first. If the net VOI is positive, the action is not dispatched immediately.
- Core assumption: The computational actions provide useful information that can update the probability estimates and improve the decision-making process.
- Evidence anchors:
  - [section 4.4] "The differenceP ′
i−P ′
0 in probability of success is the gain for
dispatchinga. Alternately, one can do a computationci first, and then decide on dispatching. This is worthwhile only if the expected utility (measured in probability of success Pi) is increased on average vs. dispatching an action immediately by doing ci first."
  - [section 5.3] "This embodies common sense, insofar as while we do not want to dispatch an action with nebulous evidence, there is an intuitive value of information argument."
  - [corpus] Weak evidence: The corpus contains papers on planning and execution, but none directly address the specific mechanism of using VOI to decide whether to dispatch actions.
- Break condition: If the computational actions do not provide useful information, the VOI calculations will be inaccurate, and the algorithm may make suboptimal decisions.

### Mechanism 3
- Claim: The algorithm modifies the state space to support acting while the clock ticks.
- Mechanism: The algorithm keeps track of the dispatched actions and their dispatch times. It modifies the Simple Temporal Problem (STP) to include these constraints and to find the earliest feasible dispatch time for the next action. It also updates the open list and memoized states to account for the dispatched actions.
- Core assumption: The state space modifications allow the algorithm to reason about the temporal constraints imposed by the dispatched actions while still searching for a complete plan.
- Evidence anchors:
  - [section 5.1] "We keep the temporal constraints required in OPTIC but instead also require: ∀aj∈Hi t(aj) =dispatch time[j] ifj≤m t(aj)≥tnow otherwise"
  - [section 5.1] "For duplicate detection, we must be more careful: • We identify a set of states to ‘un-memoize’: any memoized state whose plan prefix Hi does not begin with [a1..am+1], and remove them from the memoized states."
  - [corpus] Weak evidence: The corpus contains papers on planning and execution, but none directly address the specific mechanism of modifying the state space to support acting while the clock ticks.
- Break condition: If the state space modifications are incorrect or incomplete, the algorithm may violate temporal constraints or fail to find a valid plan.

## Foundational Learning

- Concept: Temporal planning with Timed Initial Literals (TILs)
  - Why needed here: The problem formulation uses TILs to represent temporal constraints and deadlines. Understanding TILs is crucial for reasoning about the temporal aspects of the problem.
  - Quick check question: What is the difference between a TIL and a regular action in temporal planning?

- Concept: Heuristic forward search in the space of sequences of happenings
- Why needed here: The algorithm uses heuristic forward search to explore the space of possible plans. Understanding this search technique is essential for implementing the algorithm.
  - Quick check question: What is the role of the heuristic function in guiding the search?

- Concept: Metareasoning and the Delay Damage Aware (DDA) scheme
  - Why needed here: The algorithm uses metareasoning to decide whether to dispatch an action or continue searching. Understanding the DDA scheme is crucial for implementing this decision-making process.
  - Quick check question: How does the DDA scheme allocate computation time to different processes based on their log-probability of failure?

## Architecture Onboarding

- Component map:
  - State space -> Open list -> Memoized states -> Heuristic function -> Metareasoning module

- Critical path:
  1. Initialize the state space with the initial state.
  2. While the open list is not empty and the deadline has not expired:
     a. Select a state from the open list based on the metareasoning decision.
     b. If the metareasoning decision is to dispatch an action:
        i. Dispatch the action with the highest probability of success.
        ii. Update the state space and the open list to reflect the dispatched action.
     c. If the metareasoning decision is to continue searching:
        i. Expand the selected state to generate its successor states.
        ii. Add the successor states to the open list.
  3. If a goal state is found, return the plan. Otherwise, return failure.

- Design tradeoffs:
  - Accuracy vs. efficiency: More accurate probability estimates and VOI calculations may improve the quality of decisions but also increase the computational cost.
  - Exploration vs. exploitation: The algorithm needs to balance between exploring new states to gather more information and exploiting the current best-known actions to make progress towards the goal.

- Failure signatures:
  - Deadline violations: If the algorithm fails to dispatch an action before the deadline expires, the plan will fail.
  - Suboptimal actions: If the algorithm dispatches an action that is unlikely to succeed, the plan may fail or result in a suboptimal solution.
  - Incomplete plans: If the algorithm fails to find a complete plan before the deadline expires, the plan will be incomplete.

- First 3 experiments:
  1. Implement the state space modifications to support acting while the clock ticks.
  2. Implement the metareasoning module to decide whether to dispatch an action or continue searching.
  3. Evaluate the algorithm on a simple domain with a tight deadline to verify that it can dispatch actions before planning terminates.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the measurement model in the CoPEM metareasoning framework be improved to better estimate the probability of success for different processes and deadlines?
- Basis in paper: [explicit] The paper discusses the challenges of lacking a good measurement model and relying on imperfect estimates of Mi and Di distributions.
- Why unresolved: Developing a more accurate measurement model requires extensive empirical evaluation and potentially new theoretical insights into how computational actions affect posterior distributions.
- What evidence would resolve it: A comprehensive evaluation of various measurement models on a diverse set of planning problems, demonstrating significant improvements in dispatch decisions and overall planning success rates.

### Open Question 2
- Question: What are the practical challenges and solutions for integrating the concurrent planning and execution algorithm with real robots, considering uncertainties in action durations and potential failures?
- Basis in paper: [explicit] The discussion section mentions technical challenges of dispatching actions on real hardware and handling uncertainties in action durations and failures.
- Why unresolved: Implementing the algorithm on real robots involves addressing various practical issues like communication delays, sensor noise, and unexpected environmental changes that are not fully captured in the theoretical model.
- What evidence would resolve it: Successful deployment of the algorithm on multiple robot platforms in real-world scenarios, demonstrating robustness to uncertainties and achieving performance gains over traditional planning methods.

### Open Question 3
- Question: How can the decision rule for dispatching actions be adapted to automatically identify whether a problem instance has strong time pressure, and switch between concurrent planning and execution, situated planning, and offline planning accordingly?
- Basis in paper: [explicit] The discussion section suggests the need for a method to automatically switch between different planning approaches based on the time pressure of the problem instance.
- Why unresolved: Developing such an adaptive decision rule requires a deeper understanding of the factors influencing time pressure and their relationship to the performance of different planning approaches.
- What evidence would resolve it: A thorough analysis of various problem instances, characterizing their time pressure based on relevant features, and demonstrating that the proposed adaptive decision rule consistently selects the most appropriate planning approach.

## Limitations

- The paper relies heavily on simulation-based approximations for probability estimates, which may not generalize well to real-world scenarios with high uncertainty
- The empirical evaluation focuses primarily on deadline-driven domains, leaving unclear how the approach performs in other temporal planning contexts
- The state space modifications for handling dispatched actions could become computationally expensive in domains with many parallel actions

## Confidence

- **High confidence** in the theoretical framework for concurrent planning and execution, as it builds on well-established metareasoning principles
- **Medium confidence** in the empirical results, given the limited scope of evaluated domains and lack of ablation studies
- **Low confidence** in the scalability claims, as the paper does not provide runtime complexity analysis or stress tests on larger problem instances

## Next Checks

1. **Cross-domain validation**: Test the algorithm on domains outside the RCLL and office delivery tasks, particularly those with different temporal characteristics (e.g., stochastic durations, non-deadline constraints)

2. **Probability estimation validation**: Conduct controlled experiments to measure the accuracy of the simulation-based probability estimates versus ground truth, particularly in domains with high uncertainty

3. **Scalability analysis**: Systematically evaluate the algorithm's performance as problem size increases, measuring both solution quality and computational overhead of the state space modifications