---
ver: rpa2
title: 'BONES: a Benchmark fOr Neural Estimation of Shapley values'
arxiv_id: '2407.16482'
source_url: https://arxiv.org/abs/2407.16482
tags:
- neural
- shapley
- bones
- values
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BONES is a benchmark for neural Shapley Values estimation that
  addresses the lack of standardized, accessible tools for comparing neural and traditional
  Shapley Value estimators. It provides a suite of state-of-the-art neural and traditional
  estimators, benchmark datasets for both tabular and image data, modules for training
  black-box models and generating ground truth SVs, evaluation functions for quantifying
  estimation accuracy and computational efficiency, and visualization tools for exploratory
  analysis.
---

# BONES: a Benchmark fOr Neural Estimation of Shapley values

## Quick Facts
- arXiv ID: 2407.16482
- Source URL: https://arxiv.org/abs/2407.16482
- Reference count: 27
- Key outcome: BONES is a benchmark for neural Shapley Values estimation that addresses the lack of standardized, accessible tools for comparing neural and traditional Shapley Value estimators.

## Executive Summary
BONES is a comprehensive benchmark framework designed to evaluate and compare neural and traditional Shapley Value (SV) estimators across tabular and image data modalities. It provides a unified, modular Python library that integrates state-of-the-art estimators, benchmark datasets, ground truth computation modules, standardized evaluation metrics, and visualization tools. The framework addresses the current challenge of replicating neural SV experiments due to lack of standardized implementations and evaluation procedures, enabling fair, reproducible, and scalable comparisons of attribution methods.

## Method Summary
BONES implements a modular architecture where estimators, datasets, evaluation metrics, and visualization tools are interchangeable components that support both tabular and image data. The framework provides black-box model training modules, exact and regression-based ground truth SV computation, and multiple evaluation metrics (L1, L2, Kendall correlation, AUC). Users can instantiate datasets and explainers, run benchmark evaluations, and generate comparative visualizations including bar plots, image plots, quadrant plots, and efficiency-performance trade-off curves.

## Key Results
- BONES reduces the barrier to neural SV estimation by providing a unified framework with integrated estimators, datasets, and evaluation tools
- The framework enables modality-agnostic explanations by supporting tabular and image data within the same interface
- BONES improves interpretability research through ground truth computation modules and standardized evaluation metrics for reproducible comparisons

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BONES reduces the barrier to neural Shapley value estimation by providing a unified, ready-to-use benchmark framework that integrates both neural and traditional estimators.
- Mechanism: It consolidates disparate tools (estimators, datasets, evaluation metrics, and visualizations) into a single, modular Python library, enabling fair, reproducible, and scalable comparisons without the need to manually implement or configure each component.
- Core assumption: The performance of neural Shapley estimators depends not only on algorithmic quality but also on ease of use, data preparation, and evaluation standardization.
- Evidence anchors:
  - [abstract] "However, experiments with neural estimators are currently hard to replicate as algorithm implementations, explainer evaluators and results visualizations are neither standardized nor promptly usable."
  - [section] "BONES simplifies and expedites the use of state-of-the-art neural approaches and allows end-users to perform accurate model comparisons considering aspects such as computational efficiency, attribution accuracy, model robustness to data cardinality and dimensionality."
  - [corpus] Corpus signals show this is a novel framework; related papers discuss estimators but not a unified benchmarking library.

### Mechanism 2
- Claim: BONES enables modality-agnostic explanations by supporting both tabular and image data within the same interface, making it applicable across diverse AI use cases.
- Mechanism: It uses a design-by-contract approach where estimators, datasets, and evaluators are defined as interchangeable components that work across modalities, reducing code duplication and enabling end-users to experiment across domains with minimal adaptation.
- Core assumption: Shapley values are fundamentally a model-agnostic concept, and a well-designed framework can abstract modality-specific details without compromising accuracy.
- Evidence anchors:
  - [section] "A core strength of our framework is its modality agnosticism by-design...Our framework is designed to support a wide range of approaches and data types, ensuring its applicability in different input types domains."
  - [section] "Currently, BONES supports tabular and image data. The extension to other modalities is already planned as a future work."
  - [corpus] Corpus signals indicate BONES is among the first to provide a unified XAI benchmarking library; no direct modality-agnostic comparisons found.

### Mechanism 3
- Claim: BONES improves interpretability research by providing ground truth computation modules and standardized evaluation metrics, allowing for more rigorous and reproducible comparisons.
- Mechanism: It implements exact and regression-based ground truth Shapley value computation and integrates multiple evaluation metrics (L1, L2, Kendall, AUC), enabling quantitative benchmarking of estimator accuracy and computational efficiency.
- Core assumption: Ground truth computation is essential for validating approximations, and standardized metrics are necessary for fair cross-study comparisons.
- Evidence anchors:
  - [section] "Ad hoc modules to train black-box models and generate reliable ground truth SVs, whenever not already available, either exact or approximated."
  - [section] "It allows to quantify the accuracy of the SVs' estimates against the ground truth and the efficiency of the estimation process, as well as to compare different models with each other."
  - [corpus] Corpus signals show no direct evidence of BONES providing exact ground truth modules; this appears to be a novel contribution.

## Foundational Learning

- Concept: Shapley values and their computational intractability
  - Why needed here: Understanding why exact computation is exponential and why approximation methods are necessary is foundational to appreciating the need for neural estimators and BONES.
  - Quick check question: What is the computational complexity of computing exact Shapley values, and why is this a problem for real-world datasets?

- Concept: Neural Shapley estimators (e.g., FastSHAP, ViT-Shapley)
  - Why needed here: These are the primary focus of BONES; understanding their architecture, training process, and strengths/weaknesses is critical for effective use.
  - Quick check question: How do neural Shapley estimators like FastSHAP differ from traditional sampling-based methods in terms of speed and accuracy?

- Concept: XAI evaluation metrics (e.g., L1/L2 distance, Kendall correlation, AUC)
  - Why needed here: These metrics are used within BONES to compare estimators; understanding their meaning and trade-offs is essential for interpreting results.
  - Quick check question: What is the difference between L1 and L2 distance as evaluation metrics for Shapley value estimation?

## Architecture Onboarding

- Component map: bones.sv.<modality>.explainers -> bones.sv.<modality>.datasets -> bones.sv.<modality>.evaluation -> bones.sv.<modality>.display -> bones.sv.<modality>.metrics
- Critical path: Instantiate dataset → Instantiate black-box model → Instantiate explainers → Run benchmark → Visualize/compare results
- Design tradeoffs:
  - Modularity vs. ease of use: Modular design allows extensibility but may require more setup for new users
  - Modality support vs. depth: Supporting multiple modalities reduces specialization but broadens applicability
  - Exact vs. approximate ground truth: Exact computation is more accurate but slower; approximate methods are faster but less precise
- Failure signatures:
  - Estimator performance degrades sharply with increasing feature cardinality or dimensionality
  - Visualization tools produce misleading or uninformative plots due to data scaling issues
  - Ground truth computation is too slow or memory-intensive for large datasets
- First 3 experiments:
  1. Run BONES on a small tabular dataset (e.g., Monks) with a subset of explainers (FastSHAP, KernelSHAP, Exact) to validate basic functionality and compare results
  2. Visualize Shapley values for a sample image from ImageNette using FastSHAP and ViT-Shapley to understand modality-specific behavior
  3. Benchmark computational time vs. number of samples and features to assess scalability and identify bottlenecks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do neural Shapley Value estimators perform on data modalities beyond tabular and image data (e.g., text, time series, graph data)?
- Basis in paper: [inferred] The paper mentions that BONES is "modality-agnostic" and plans to extend support to other modalities as future work.
- Why unresolved: The current benchmark only supports tabular and image data, and no experimental results or evaluations exist for other modalities.
- What evidence would resolve it: Implementation and benchmarking of neural Shapley Value estimators on text, time series, and graph data within BONES, with comparative performance metrics.

### Open Question 2
- Question: How does the accuracy-efficiency trade-off of neural Shapley Value estimators vary across different dataset characteristics (e.g., feature cardinality, feature dimensionality, sample size, feature density)?
- Basis in paper: [explicit] The paper mentions that BONES allows for "accurate model comparisons considering aspects such as computational efficiency, attribution accuracy, model robustness to data cardinality and dimensionality."
- Why unresolved: While BONES provides tools for evaluation, the paper does not present comprehensive empirical studies on how these