---
ver: rpa2
title: Focus On This, Not That! Steering LLMs with Adaptive Feature Specification
arxiv_id: '2410.22944'
source_url: https://arxiv.org/abs/2410.22944
tags:
- latexit
- focus
- sha1
- base64
- spurious
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Focus Instruction Tuning (FIT), a method to
  dynamically steer large language models by specifying which features to focus on
  or ignore during inference. FIT extends instruction tuning by fine-tuning models
  on focus instructions, enabling them to adapt their behavior based on user-specified
  features through natural language.
---

# Focus On This, Not That! Steering LLMs with Adaptive Feature Specification

## Quick Facts
- arXiv ID: 2410.22944
- Source URL: https://arxiv.org/abs/2410.22944
- Reference count: 40
- Introduces FIT, a method to dynamically steer LLMs by specifying which features to focus on or ignore during inference

## Executive Summary
This paper introduces Focus Instruction Tuning (FIT), a novel approach to dynamically steer large language models by specifying which features to focus on or ignore during inference. FIT extends instruction tuning by fine-tuning models on focus instructions, enabling them to adapt their behavior based on user-specified features through natural language. Across diverse tasks including sentiment analysis, natural language inference, and question-answering, FIT demonstrates strong performance, increasing robustness by emphasizing core task signals and down-weighting spurious or biased cues. It also mitigates social bias and generalizes under distribution shifts and to unseen features.

## Method Summary
FIT fine-tunes LLMs using focus instructions that specify which features to focus on or ignore. The method creates synthetic datasets with controlled spurious features, then trains models to condition their responses based on these focus specifications. During training, focus labels guide the model to produce different outputs for the same input based on the specified features. The approach relies on independence assumptions between spurious features and labels during training to enable effective feature manipulation at inference time.

## Key Results
- FIT achieves strong focus accuracy across multiple datasets and tasks, outperforming baseline methods including zero-shot, few-shot, and standard fine-tuning
- The method successfully mitigates social bias in datasets like BBQ while maintaining steerability and core task performance
- FIT generalizes well to unseen bias features and distribution shifts, demonstrating robust feature-handling capabilities

## Why This Works (Mechanism)

### Mechanism 1
FIT modifies model behavior by fine-tuning on feature-specific focus instructions that explicitly teach the model to condition its responses on specified features. During training, FIT introduces focus labels that map the same input to different output targets depending on the focus instruction. This creates a conditional mapping where the model learns to dynamically switch its reasoning process based on the presence of a focus instruction without losing its core task-solving capability.

### Mechanism 2
FIT increases robustness by amplifying core task signals and down-weighting spurious cues through targeted feature manipulation during training. By training on focus labels that explicitly separate core features from spurious ones, FIT teaches the model to prioritize task-relevant features. When a focus instruction targets the core feature, the model learns to rely on it exclusively. When told to ignore a spurious feature, the model learns to suppress its influence on predictions.

### Mechanism 3
FIT generalizes to unseen features and distribution shifts by learning abstract feature-handling capabilities rather than memorizing specific feature-label associations. FIT trains on multiple focus instruction types (focus on, ignore, both) for known features, teaching the model a general strategy for feature manipulation. When encountering unseen features, the model applies this learned strategy rather than relying on specific feature knowledge.

## Foundational Learning

- **Conditional probability and feature independence**: FIT relies on understanding how features relate to labels and how conditioning on specific features changes prediction probabilities. The independence assumptions (Y ⊥ ⊥S, YS ⊥ ⊥C) are crucial for the method to work correctly.
  - Quick check: If a spurious feature S is correlated with label Y during training, what happens to FIT's ability to ignore S at inference time?

- **Spurious correlation and distribution shift**: FIT specifically targets spurious correlations that cause models to fail under distribution shift. Understanding how features that correlate with labels in training data may not correlate in test data is fundamental to why FIT works.
  - Quick check: Why does FIT perform better than standard fine-tuning when spurious feature correlations change between training and test sets?

- **Feature engineering and label manipulation**: FIT creates "focus labels" that are different from ground truth labels depending on the focus instruction. Understanding how to manipulate labels to teach specific feature handling is key to implementing FIT.
  - Quick check: How does FIT create different training targets for the same input when different focus instructions are provided?

## Architecture Onboarding

- **Component map**: Pre-trained LLM -> Focus instruction processor -> Focus label generator -> Model fine-tuning with conditional loss function -> Evaluation with different focus instructions
- **Critical path**: Training data creation → Focus instruction parsing → Focus label generation → Model fine-tuning with conditional loss function → Evaluation with different focus instructions
- **Design tradeoffs**: FIT trades some model capacity for steerability. The method requires annotated spurious features, which adds data annotation overhead but enables precise control. The focus instruction parser must handle natural language variability.
- **Failure signatures**: Low focus accuracy indicates the model isn't learning to switch behavior based on instructions. Poor generalization to unseen features suggests the model is memorizing specific feature-label pairs rather than learning abstract feature-handling strategies. Degraded performance on core tasks indicates the focus training interferes with basic capabilities.
- **First 3 experiments**:
  1. Train FIT on SMNLI with known genre-spurious correlations and test focus accuracy on core vs spurious features
  2. Test FIT generalization by evaluating on SHANS with unseen sub-sequence heuristic feature
  3. Compare FIT against SFT(yfocus) baseline on BBQ to verify debiasing effectiveness while maintaining steerability

## Open Questions the Paper Calls Out

The authors identify three key open questions: whether FIT can be effectively extended to open-ended generation tasks like summarization or translation while maintaining steerability; how FIT performs when handling instructions involving multiple simultaneous features; and whether FIT can maintain steerability when features overlap or are not sufficiently distinct, as seen in the SHANS dataset where overlapping heuristics confused the model during generalization.

## Limitations

- FIT relies on the assumption that spurious features are independent of labels during training, which may not hold in many real-world scenarios
- The method requires substantial manual effort for feature annotation and synthetic dataset creation, creating practical barriers to implementation
- FIT's scalability to production environments with limited annotation budgets is unclear

## Confidence

- **High confidence** in the core mechanism: The theoretical framework for feature-based steering is sound, and empirical results on controlled synthetic datasets demonstrate effective feature conditioning
- **Medium confidence** in generalization claims: Promising results on unseen features and distribution shifts, but evaluation is limited to synthetic datasets
- **Low confidence** in scalability: The method requires substantial manual effort for feature annotation and synthetic dataset creation

## Next Checks

1. Test FIT on real-world datasets with naturally occurring spurious correlations (e.g., medical diagnosis with demographic variables, hiring decisions with education credentials) to validate the approach beyond synthetic settings.

2. Conduct ablation studies removing the independence assumptions to quantify FIT's performance degradation when spurious features correlate with labels, establishing clear boundaries for the method's applicability.

3. Measure computational overhead and annotation costs for implementing FIT at scale, comparing against alternative bias mitigation approaches to assess practical feasibility for production deployment.