---
ver: rpa2
title: 'Algorithmic Fairness in Performative Policy Learning: Escaping the Impossibility
  of Group Fairness'
arxiv_id: '2405.20447'
source_url: https://arxiv.org/abs/2405.20447
tags:
- fairness
- policy
- equality
- group
- performative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the feasibility of achieving group fairness
  in performative settings where a policy affects the population's distribution. The
  authors formalize long-term group fairness constraints (equality of outcomes) that
  focus on ex-post fairness rather than just ex-ante policy properties.
---

# Algorithmic Fairness in Performative Policy Learning: Escaping the Impossibility of Group Fairness

## Quick Facts
- arXiv ID: 2405.20447
- Source URL: https://arxiv.org/abs/2405.20447
- Reference count: 40
- One-line primary result: Performative policy learning can achieve simultaneously traditionally incompatible fairness constraints by steering populations toward equitable states.

## Executive Summary
This paper demonstrates that group fairness constraints normally considered incompatible can be simultaneously satisfied in performative settings where policies affect population distributions. The authors formalize long-term group fairness constraints focused on ex-post fairness rather than ex-ante policy properties. Through theoretical analysis and computational experiments on labor market models, they show that policymakers with sufficient flexibility can achieve both equal responses across groups and equal treatment, effectively escaping the impossibility results that plague traditional fairness approaches.

## Method Summary
The paper proposes a reduction algorithm that translates long-term fairness constraints into moment inequalities and solves them using mirror ascent on dual variables. The method requires a specified population model describing how individuals respond to policies, a policy class defining possible interventions, and fairness metrics measuring desired long-term outcomes. The algorithm iteratively updates dual variables to find policies minimizing ex-post risk while satisfying moment constraints derived from desired fairness properties.

## Key Results
- In performative settings, a single policy can simultaneously satisfy demographic parity, separation, and sufficiency constraints by steering populations toward equitable states
- When policymakers have sufficient flexibility (e.g., multiple skill investment options), they can achieve both equal responses across groups and equal treatment
- The reduction algorithm successfully enforces long-term fairness constraints in modified labor market models, demonstrating practical feasibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Performative settings enable simultaneous satisfaction of multiple group fairness constraints
- Mechanism: Policymakers steer populations so response distributions become equal across groups ex-post, eliminating conflicts between constraints
- Core assumption: Sufficient policy flexibility exists to adjust parameters without disrupting equalized responses
- Break condition: Insufficient flexibility or non-adjustable feature matrices prevent simultaneous constraint satisfaction

### Mechanism 2
- Claim: Long-term fairness can be enforced computationally through moment inequality constraints
- Mechanism: Iterative dual variable updates via mirror ascent find policies minimizing ex-post risk while satisfying fairness constraints
- Core assumption: Correctly specified response model D(f,g) at sample level
- Break condition: Model misspecification or restrictive policy classes prevent feasible solution discovery

### Mechanism 3
- Claim: Discrimination based on education costs can be remedied without disadvantaging advantaged groups
- Mechanism: Flexible hiring policies with multiple skill investment options incentivize disadvantaged groups to improve skills
- Core assumption: Unbiased skill assessment and rational worker responses to policy changes
- Break condition: Excessive cost disparities or biased skill assessments prevent gap closure

## Foundational Learning

- Concept: Performative prediction
  - Why needed here: Policy affects distribution of prediction target, creating feedback loop between decisions and outcomes
  - Quick check question: If a hiring policy increases average skill of hired workers, what happens to distribution of future applicants' skills?

- Concept: Group fairness constraints
  - Why needed here: Contrast traditional ex-ante constraints with long-term ex-post fairness showing performativity enables simultaneous satisfaction
  - Quick check question: If classifier satisfies separation, does it necessarily satisfy demographic parity?

- Concept: Stochastic dominance
  - Why needed here: Formalizes ex-ante skill disparities between groups that create barriers to equal responses
  - Quick check question: If random variable A stochastically dominates B, what can you say about P(A ≤ x) compared to P(B ≤ x)?

## Architecture Onboarding

- Component map: Population model -> Policy class -> Fairness metrics -> Reduction algorithm
- Critical path: 1) Specify population model and response mechanism 2) Define policy class and ex-post risk 3) Translate fairness to moment inequalities 4) Implement reduction algorithm 5) Validate on held-out data
- Design tradeoffs: Flexibility vs. simplicity, model accuracy vs. computational cost, ex-ante vs. ex-post fairness focus
- Failure signatures: Empty feasible set, high generalization error, moment constraint violations on test data
- First 3 experiments: 1) Verify reduction algorithm on simple synthetic Gaussian data 2) Test on modified labor market model with known feasibility 3) Evaluate under model misspecification

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions does performative power become insufficient to achieve equality of treatment and responses simultaneously?
- Basis in paper: [explicit] Paper provides specific impossibility results but lacks general characterization
- Why unresolved: Focuses on examples rather than general theorem
- What evidence would resolve it: General theorem characterizing sufficient conditions in terms of parameter space dimension or response mechanism structure

### Open Question 2
- Question: How does algorithm performance scale with multiple groups or sensitive attributes?
- Basis in paper: [explicit] Mentions multi-class cases are "relatively similar" but provides no empirical results
- Why unresolved: Only presents binary classification results
- What evidence would resolve it: Empirical results on datasets with multiple groups/attributes showing performance and needed modifications

### Open Question 3
- Question: What is the impact of relaxing perfect knowledge assumption of ex-post distribution map D(f,g)?
- Basis in paper: [explicit] Assumes correct specification but doesn't explore misspecification consequences
- Why unresolved: Focuses on perfect knowledge case only
- What evidence would resolve it: Empirical results showing performance under different misspecification levels and error propagation analysis

## Limitations
- Theoretical results rely heavily on Gaussian assumptions and diagonal effort matrices
- Reduction algorithm requires correctly specified response model with no validation approach provided
- Computational approach scales poorly with feature dimensionality and response function complexity

## Confidence

- **High**: Impossibility results for ex-ante fairness constraints and basic mechanism enabling ex-post fairness
- **Medium**: Theoretical feasibility under Gaussian assumptions and strong duality claim for reduction algorithm
- **Low**: Practical effectiveness on real-world data and robustness to model misspecification

## Next Checks

1. **Empirical robustness test**: Implement reduction algorithm on non-Gaussian data distributions to assess feasibility result degradation when assumptions are violated

2. **Model misspecification analysis**: Compare algorithm performance using incorrect response model versus true data-generating process across multiple simulation runs

3. **Scalability benchmark**: Evaluate computational efficiency and solution quality on datasets with increasing feature dimensionality and sample size to identify practical limits