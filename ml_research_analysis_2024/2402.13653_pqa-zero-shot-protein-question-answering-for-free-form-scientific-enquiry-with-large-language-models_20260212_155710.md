---
ver: rpa2
title: 'PQA: Zero-shot Protein Question Answering for Free-form Scientific Enquiry
  with Large Language Models'
arxiv_id: '2402.13653'
source_url: https://arxiv.org/abs/2402.13653
tags:
- protein
- information
- training
- sequences
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces zero-shot Protein Question Answering (PQA),
  a novel task designed to answer diverse protein-related queries without task-specific
  training. Current computational methods for studying protein structure and function
  are often resource-intensive and limited to specific tasks.
---

# PQA: Zero-shot Protein Question Answering for Free-form Scientific Enquiry with Large Language Models

## Quick Facts
- arXiv ID: 2402.13653
- Source URL: https://arxiv.org/abs/2402.13653
- Authors: Eli M Carrami; Sahand Sharifzadeh
- Reference count: 30
- Key outcome: Introduces Pika framework with debiased dataset and multimodal LLMs for zero-shot protein QA

## Executive Summary
This paper introduces zero-shot Protein Question Answering (PQA), a novel task designed to answer diverse protein-related queries without task-specific training. Current computational methods for studying protein structure and function are often resource-intensive and limited to specific tasks. The authors address this by proposing PQA, leveraging large language models (LLMs) to answer free-form scientific questions about proteins using only their sequences. To overcome limitations in existing datasets and evaluation methods, they introduce the Pika framework, which includes a curated, debiased dataset (Pika-DS) tailored for PQA and biochemically relevant benchmarking strategies.

## Method Summary
The Pika framework combines protein language models (PLMs) like ESM2 with LLMs like Phi-2 through learned adapters to create multimodal models for PQA. The Pika-DS dataset contains over 257,000 protein sequences with expert-curated annotations including summaries, Q&A pairs, and ground-truth metrics. The framework introduces two-tiered benchmarking: Biochem-Lite for lightweight evaluation using keyword comparison and Biochem-ReAct for rigorous scientific accuracy assessment using xLLMs. Models are trained with evolution-aware splits using UniRef50 clustering to ensure generalization to evolutionarily distant proteins.

## Key Results
- Pika models outperform lower-bound baselines and achieve performance close to upper-bound baselines
- Models maintain strong performance even on evolutionarily distant proteins
- Biochem-Lite metrics provide more reliable evaluation than traditional BLEU/ROUGE metrics
- Zero-shot performance demonstrates potential for flexible protein property exploration

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pika models leverage multimodal LLMs to answer free-form protein questions by combining protein sequence embeddings with natural language reasoning.
- Mechanism: The model fuses ESM2-derived protein embeddings with Phi-2 LLM through learned adapters, allowing cross-modal information transfer for zero-shot inference.
- Core assumption: Protein sequences contain sufficient information to predict biochemical properties when contextualized with an LLM's general knowledge.
- Evidence anchors: [abstract] "propose multimodal large language models as a strong baseline for PQA, leveraging their natural language processing and knowledge" [section 3.3.1] "Pika models... combine the ESM2 protein language model (PLM) with the Phi-2 LLM"
- Break condition: If protein embeddings do not encode functional features, or if the LLM lacks relevant biochemical knowledge, cross-modal fusion fails.

### Mechanism 2
- Claim: The Pika-DS dataset is debiased using UniRef50 clustering to avoid overrepresentation of common protein families and ensure generalization.
- Mechanism: Filtering to two sequences per UniRef50 cluster reduces frequency bias, and strict similarity thresholds ensure evolutionary diversity in train/test splits.
- Core assumption: Overrepresented protein families in SwissProt skew model performance toward those families; removing them forces models to learn broader patterns.
- Evidence anchors: [section 3.1.1] "limiting Pika-DS to a maximum of two most informative sequences per UniRef50 cluster" [section 4.2] "zero-shot scenario... proteins similar to those in the training dataset were excluded"
- Break condition: If evolutionary similarity does not correlate with functional similarity, debiasing may remove informative homologs.

### Mechanism 3
- Claim: Biochem-Lite metrics provide more reliable evaluation of scientific accuracy than BLEU/ROUGE in PQA tasks.
- Mechanism: Single-word ground truth labels extracted from protein metadata allow direct keyword matching and F1 scoring, reflecting biochemical correctness rather than linguistic similarity.
- Core assumption: Protein functional attributes (e.g., cofactor, localization) are accurately captured in SwissProt fields and can be distilled into discrete labels.
- Evidence anchors: [section 3.2.1] "go beyond standard linguistic evaluations... biochemically-significant questions... reflect biochemical properties" [section 4.1] "Biochem-Lite metrics are significantly better... while all ROUGE metrics fail to highlight any differences"
- Break condition: If SwissProt metadata are incomplete or noisy, extracted labels misrepresent true protein properties.

## Foundational Learning

- Concept: Protein sequence embedding via PLMs (e.g., ESM2)
  - Why needed here: Encodes structural and functional motifs from raw amino acid strings for model consumption
  - Quick check question: What does an ESM2 embedding vector represent, and how is it derived from a protein sequence?

- Concept: Multimodal fusion architectures (cross-attention vs self-attention adapters)
  - Why needed here: Enables seamless integration of protein embeddings into LLM token space for cross-modal reasoning
  - Quick check question: How do gated cross-attention adapters differ from soft-prompt concatenation in injecting protein context?

- Concept: Evolutionary homology and its impact on zero-shot evaluation
  - Why needed here: Determines whether test sequences are truly unseen or merely homologs of training data
  - Quick check question: Why might a 50% sequence similarity threshold still allow evolutionary leakage in protein datasets?

## Architecture Onboarding

- Component map: PLM (ESM2) -> Perceiver adapter -> Gated cross-attention (Cross-Pika) OR soft-prompt concat (Self-Pika) -> Frozen LLM (Phi-2) -> QA output
- Critical path: Protein sequence -> PLM embedding -> adapter transformation -> LLM input -> predicted answer
- Design tradeoffs:
  - Cross-Pika: Higher expressivity via layer-specific adapters but increased parameters and training complexity
  - Self-Pika: Simpler, fewer parameters, but less granular control over information injection
- Failure signatures:
  - Low exact cofactor recall -> adapters not injecting relevant motifs
  - High perplexity but low F1 -> LLM generating fluent but inaccurate responses
  - Poor performance on EvoGroup splits -> model relying on homology rather than sequence features
- First 3 experiments:
  1. Train Self-Pika on UniRef50 split, evaluate with Biochem-Lite; verify performance gap vs Pika w/o PLM
  2. Replace Phi-2 with GPT-2 medium; measure impact on exact cofactor metric
  3. Evaluate same model on EvoGroup split; compare BLAST baseline to test evolutionary generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of PQA models change when trained on larger, more diverse LLMs?
- Basis in paper: [inferred] The authors note that their current models use a modestly sized Phi-2 LLM and suggest that leveraging larger, more diverse LLMs may offer substantial gains in model generalization.
- Why unresolved: The paper primarily uses the Phi-2 LLM due to its accessibility and manageable size. While the authors demonstrate the potential of this approach, they acknowledge that larger LLMs could further improve performance and generalization capabilities.
- What evidence would resolve it: Training and evaluating PQA models using larger LLMs (e.g., GPT-4, Claude) on the Pika dataset and comparing their performance against the current models would provide concrete evidence of the impact of LLM size on PQA performance.

### Open Question 2
- Question: Can PQA models accurately answer questions about novel protein sequences that have no evolutionary relatives in the training data?
- Basis in paper: [explicit] The authors evaluate the models on EvoGroup splits, which aim to minimize evolutionary connections between training and test data. However, they note that even on these splits, the models perform well, suggesting they can infer functional properties based on sequence information.
- Why unresolved: While the EvoGroup splits reduce evolutionary connections, they do not completely eliminate the possibility of distant evolutionary relationships. It remains unclear whether the models can truly generalize to completely novel protein sequences with no evolutionary relatives.
- What evidence would resolve it: Testing PQA models on a dataset of truly novel protein sequences with no known evolutionary relatives, and comparing their performance to that on the EvoGroup splits, would provide evidence of their ability to generalize to completely unseen protein sequences.

### Open Question 3
- Question: How do the performance and limitations of PQA models compare to those of specialized, task-specific models for individual protein properties?
- Basis in paper: [inferred] The authors propose PQA as a unified approach to protein sequence-related inquiries, but they acknowledge that current task-specific models exist for predicting specific biochemical properties. They suggest that PQA models have the potential to challenge the current state-of-the-art in task-specific models.
- Why unresolved: The paper does not directly compare the performance of PQA models to that of specialized, task-specific models. While they demonstrate the potential of PQA, it remains unclear how it stacks up against existing approaches for individual protein properties.
- What evidence would resolve it: A comprehensive comparison of PQA models and specialized, task-specific models on a set of benchmark tasks for individual protein properties (e.g., ligand binding, thermal stability, subcellular localization) would provide evidence of the relative strengths and limitations of each approach.

## Limitations
- Debiasing effectiveness remains correlative rather than experimentally validated with direct ablation studies
- Ground truth quality depends on automated processing of SwissProt metadata without independent expert validation
- Generalizability to truly novel protein families outside curated databases remains untested

## Confidence
- **High confidence**: The basic premise that multimodal fusion of protein embeddings with LLMs can enable zero-shot protein question answering
- **Medium confidence**: The claim that Pika models outperform baselines, particularly on evolutionarily distant proteins
- **Low confidence**: The assertion that Pika-DS represents a comprehensive solution to the limitations of existing protein QA datasets

## Next Checks
1. **Ground truth validation study**: Have three independent protein biochemistry experts evaluate 100 randomly sampled Pika-DS entries to assess accuracy of the GPT-3.5 processed annotations against original SwissProt entries.

2. **Ablation on debiasing**: Train identical models on the full SwissProt dataset without UniRef50 filtering and compare performance on held-out evolutionary distant proteins to quantify the impact of debiasing.

3. **Novel protein testing**: Evaluate the best Pika model on a set of recently deposited protein sequences (post-2024) from UniProt that were not available during dataset creation to test true zero-shot generalization.