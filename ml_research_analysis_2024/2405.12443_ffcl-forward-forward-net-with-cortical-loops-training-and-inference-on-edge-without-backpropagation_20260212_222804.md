---
ver: rpa2
title: 'FFCL: Forward-Forward Net with Cortical Loops, Training and Inference on Edge
  Without Backpropagation'
arxiv_id: '2405.12443'
source_url: https://arxiv.org/abs/2405.12443
tags:
- layer
- training
- learning
- each
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes enhancements to the Forward-Forward Learning
  (FFL) algorithm, a recently introduced method for training neural networks without
  backpropagation. The authors address two key challenges: computational inefficiency
  during inference and limited accuracy.'
---

# FFCL: Forward-Forward Net with Cortical Loops, Training and Inference on Edge Without Backpropagation

## Quick Facts
- arXiv ID: 2405.12443
- Source URL: https://arxiv.org/abs/2405.12443
- Reference count: 12
- This paper proposes enhancements to the Forward-Forward Learning (FFL) algorithm, improving accuracy and reducing inference complexity for edge devices.

## Executive Summary
This paper introduces FFCL, an enhancement to the Forward-Forward Learning algorithm that addresses computational inefficiency during inference and limited accuracy. The authors propose two key innovations: direct label feeding, which improves learning by providing clear label information to each layer, and cortical loops, which introduce brain-inspired feedback mechanisms. Their approach achieves up to 97.23% accuracy on MNIST while significantly reducing computational load, making it more suitable for resource-constrained edge devices.

## Method Summary
FFCL builds upon Forward-Forward Learning by introducing two main improvements: direct label feeding and cortical loops. Direct label feeding appends label vectors as additional input channels to each layer, enabling neurons to compute goodness based on both label weights and intermediate activation without mixing feature and label data. Cortical loops implement feedback pathways by unrolling the network multiple times with weight sharing, allowing higher-level features to inform earlier layers. The model is trained using the Adam optimizer for 5,000 epochs across 50 runs on 4-layer MLPs with 500-neuron hidden layers.

## Key Results
- FFCL achieves 97.23% accuracy on MNIST, surpassing both FFL and FFDL baselines
- Computational efficiency improves significantly, with FFCL reducing inference complexity compared to FFL
- The combined approach of direct label feeding and cortical loops consistently outperforms individual techniques across MNIST, Fashion-MNIST, and CIFAR-10 datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Direct label feeding improves accuracy and reduces inference complexity by providing clear, layer-specific label information without mixing with features.
- **Mechanism:** Labels are appended as additional input channels to each layer, enabling each neuron to compute goodness based on both label weights and the intermediate activation. This separation avoids dilution of label information across layers and eliminates need to recompute all layers for each class during inference.
- **Core assumption:** Each layer can learn more effectively when it directly receives the label signal rather than inferring it from mixed feature/label data.
- **Evidence anchors:** Abstract states "We optimize label processing by segregating label and feature forwarding between layers, enhancing learning performance"; section 3.1 describes direct label input into each layer.
- **Break condition:** If label information is redundant or noisy, or if layer-wise label processing overwhelms memory constraints, accuracy gains may plateau or degrade.

### Mechanism 2
- **Claim:** Cortical loops introduce feedback pathways that allow higher-level features to inform earlier layers, improving learning efficiency.
- **Mechanism:** The network is unrolled multiple times with weight sharing; each unrolled instance receives the same input, and feedback flows from later layers back to earlier ones within the same unrolled copy. This mimics cortical feedback in the brain, enriching representation before final classification.
- **Core assumption:** Feedback connections can enhance feature extraction without requiring separate backward training phases.
- **Evidence anchors:** Abstract mentions "feedback loops akin to cortical loops in the brain, where information cycles through and returns to earlier neurons"; section 3.2 describes incorporating feedback mechanisms analogous to those found in the brain.
- **Break condition:** If unrolled network becomes too large or if feedback weights are poorly initialized, training may become unstable or computationally prohibitive.

### Mechanism 3
- **Claim:** Combining direct label feeding with cortical loops yields higher accuracy than either technique alone by leveraging both precise label signals and enriched feature representations.
- **Mechanism:** The model first processes input with direct label channels, then allows feedback to propagate enriched features back through unrolled copies, so each layer benefits from both explicit labels and contextual information from higher layers.
- **Core assumption:** The two enhancements are complementary and their combination does not cause interference or overfitting.
- **Evidence anchors:** Section 3 introduces FFCL as building on FFL with improvements through direct labeling and feedback loops; section 4 tables show FFCL consistently outperforming both FFL and FFDL.
- **Break condition:** If combined model overfits to training data or if feedback introduces instability that outweighs accuracy gain, performance may drop on unseen data.

## Foundational Learning

- **Concept:** Forward-Forward Learning (FFL) replaces backpropagation with two forward passes—one with positive data and one with negative data—to train each layer locally.
  - **Why needed here:** FFCL is built on FFL, so understanding local goodness function and layer-wise training without gradient propagation is essential.
  - **Quick check question:** In FFL, how does a layer update its weights without receiving gradients from later layers?

- **Concept:** Label segregation and padding as a data augmentation technique.
  - **Why needed here:** Direct label feeding relies on treating labels as additional input channels; knowing how to append labels without corrupting feature data is critical.
  - **Quick check question:** What shape does the input tensor have after appending N label channels to a 784-pixel image for 10 classes?

- **Concept:** Network unrolling and weight sharing for feedback simulation.
  - **Why needed here:** Cortical loops are implemented by duplicating the network and sharing weights; understanding how to unroll without duplicating parameters is key.
  - **Quick check question:** If a 3-layer network is unrolled twice, how many total layers are there in the unrolled graph?

## Architecture Onboarding

- **Component map:** Input layer (flattened image + N label channels) → feature MAC + ReLU → label MAC + ReLU (goodness) → next layer feature MAC → repeat → aggregate votes from all layers across unrolled instances
- **Critical path:** Input → feature MAC + ReLU → label MAC + ReLU (goodness) → next layer feature MAC → repeat → aggregate votes
- **Design tradeoffs:**
  - Accuracy vs. FLOPs: FFCL increases FLOPs over FFDL but less than FFL; cortical loops boost accuracy at moderate computational cost
  - Model size vs. feedback depth: Deeper feedback requires more unrolled copies, increasing memory but not parameter count (weight sharing)
  - Label channel overhead: Adding N channels increases input size; may hurt efficiency if N is large relative to image size
- **Failure signatures:**
  - Accuracy drops sharply in deeper layers: likely label dilution or feedback not propagating
  - Training instability or divergence: possible feedback weight conflicts or poor initialization
  - Excessive inference time: unrolled network too deep or label channels too large
- **First 3 experiments:**
  1. Train FFDL on MNIST with 4 hidden layers (500 units each), compare accuracy to FFL baseline
  2. Add one unrolled copy to FFDL, measure accuracy and FLOPs vs. FFDL baseline
  3. Vary number of unrolled copies (1, 2, 3) on Fashion-MNIST, plot accuracy vs. FLOPs trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of FFCL compare to traditional backpropagation methods on the same datasets when trained for the same number of epochs?
- Basis in paper: The paper compares FFCL to FFL but does not directly compare it to backpropagation.
- Why unresolved: The paper focuses on comparing different variants of FFL rather than benchmarking against traditional methods.
- What evidence would resolve it: Conducting experiments training FFCL and backpropagation models on the same datasets for the same number of epochs and comparing their accuracy.

### Open Question 2
- Question: What is the impact of different unrolling strategies (e.g., number of unrolled copies) on the accuracy and computational complexity of FFCL?
- Basis in paper: The paper mentions that the extent of unrolling determines how far back information can propagate, but does not explore different unrolling strategies.
- Why unresolved: The paper only presents one unrolling strategy and does not investigate the impact of varying the number of unrolled copies.
- What evidence would resolve it: Conducting experiments with different numbers of unrolled copies and comparing their accuracy and computational complexity.

### Open Question 3
- Question: How does the performance of FFCL change when using different activation functions (e.g., ReLU, sigmoid, tanh) in the network layers?
- Basis in paper: The paper uses ReLU activation function but does not explore the impact of using different activation functions.
- Why unresolved: The choice of activation function can significantly impact the performance of neural networks, and it is unclear how different activation functions would affect FFCL.
- What evidence would resolve it: Conducting experiments using different activation functions in FFCL and comparing their performance.

## Limitations
- Exact implementation details of the one_layer_backpropagate function are not specified, making faithful reproduction challenging
- The paper does not fully clarify how FLOPs are calculated in the unrolled, weight-shared cortical loop setup
- Limited exploration of how different unrolling strategies affect accuracy and computational complexity

## Confidence
- **High:** MNIST and Fashion-MNIST accuracy improvements of FFDL and FFCL over FFL
- **Medium:** Computational efficiency claims for edge deployment
- **Low:** Generalization to deeper networks or alternative architectures

## Next Checks
1. Verify the exact tensor shapes and data flow for label padding in the goodness computation by reproducing the 4-layer FFDL baseline on MNIST
2. Implement and benchmark a single unrolled cortical loop (FFCL-1) to measure accuracy and FLOPs before scaling up
3. Test label channel overhead by varying N (number of classes) on a fixed image size and observing FLOPs and accuracy trade-offs