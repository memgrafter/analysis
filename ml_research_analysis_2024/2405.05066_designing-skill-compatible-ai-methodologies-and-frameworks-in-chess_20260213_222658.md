---
ver: rpa2
title: 'Designing Skill-Compatible AI: Methodologies and Frameworks in Chess'
arxiv_id: '2405.05066'
source_url: https://arxiv.org/abs/2405.05066
tags:
- agents
- leela
- agent
- chess
- focal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a formal framework for evaluating and designing\
  \ skill-compatible AI agents\u2014AI systems that maintain high performance while\
  \ remaining interpretable and cooperative with less-skilled counterparts. The authors\
  \ use collaborative chess variants as testbeds, proposing three methodologies (Tree,\
  \ Expector, and Attuned agents) to create AI seniors that can effectively partner\
  \ with weaker juniors like Maia engines."
---

# Designing Skill-Compatible AI: Methodologies and Frameworks in Chess

## Quick Facts
- arXiv ID: 2405.05066
- Source URL: https://arxiv.org/abs/2405.05066
- Reference count: 40
- Key outcome: Skill-compatible AI agents maintain high performance while remaining interpretable and cooperative with less-skilled counterparts, outperforming strong baseline engines in collaborative chess variants.

## Executive Summary
This paper introduces a formal framework for evaluating and designing skill-compatible AI agents—systems that maintain high performance while remaining interpretable and cooperative with less-skilled counterparts. The authors use collaborative chess variants as testbeds, proposing three methodologies (Tree, Expector, and Attuned agents) to create AI seniors that can effectively partner with weaker juniors like Maia engines. Experiments show that these skill-compatible agents outperform state-of-the-art AlphaZero-based engines in collaborative frameworks despite being weaker in conventional chess, demonstrating that skill-compatibility is a distinct and measurable property separate from raw performance.

## Method Summary
The paper proposes three methodologies for creating skill-compatible AI agents in chess: the Tree agent uses Monte Carlo Tree Search guided by a weaker partner's policy, the Expector agent simulates moves ahead with partner models to optimize team outcomes, and the Attuned agent fine-tunes a strong engine through self-play with weaker partners. These agents are evaluated in two collaborative chess frameworks—Stochastic Tag Team and Hand and Brain—where they partner with Maia engines of varying skill levels. The methodologies focus on training AI to anticipate and adapt to suboptimal moves from partners rather than optimizing purely for individual strength.

## Key Results
- The Expector agent achieved a 66.5% win rate against Leela in Stochastic Tag Team play
- Skill-compatible agents outperform state-of-the-art AlphaZero-based engines in collaborative frameworks despite being weaker in conventional chess
- Different agents employ varying strategies—some focus on helping weaker partners, others on exploiting opponent weaknesses

## Why This Works (Mechanism)

### Mechanism 1
Skill-compatible agents achieve better team performance by optimizing for partner interaction, not just board strength. Agents explicitly model and adapt to the weaker partner's decision-making patterns, sacrificing some individual optimality to enable the partner to contribute effectively. This assumes the weaker partner's moves are predictable and can be modeled to some degree. The mechanism is supported by evidence showing traditional chess engines designed for near-optimal moves fail as partners when paired with weaker engines.

### Mechanism 2
Different skill-compatible agents employ distinct strategies - some help partners, others exploit opponent weaknesses. Agents optimize for different components of the team objective, with some focusing on improving their weaker partner's position when it plays, while others create situations where the opponent's weaker partner will make mistakes. This dual strategy approach is evidenced by different agents displaying varying helping effects, with magnitude differing across agent types.

### Mechanism 3
Training with the weaker partner present creates agents that naturally adapt to suboptimal play. By training in frameworks where the weaker agent intervenes at random points or influences piece selection, the stronger agent learns to anticipate and work around suboptimal moves rather than assuming optimal play. This is supported by the Attuned agent's creation through fine-tuning on games with weaker partners, demonstrating that exposure to suboptimal play during training enables effective adaptation.

## Foundational Learning

- **Game theory and cooperative multi-agent systems**: Understanding how agents with different capabilities can coordinate effectively requires knowledge of cooperative game theory and how to design reward structures that encourage beneficial interaction. Quick check: How would you modify a standard minimax algorithm to account for a partner who makes suboptimal moves?

- **Monte Carlo Tree Search (MCTS) with policy/value networks**: All three methodologies use MCTS or variants - Tree uses maia-guided MCTS, Expector uses MCTS for expectation calculation, and Attuned modifies MCTS through training. Quick check: What changes would you make to MCTS if you knew your opponent would make a suboptimal move 30% of the time?

- **Neural network training and fine-tuning**: The Attuned agent is created by fine-tuning existing Leela weights on games with weaker partners, requiring understanding of transfer learning and catastrophic forgetting. Quick check: How would you structure a training dataset to teach a strong chess engine to work with weaker partners without destroying its ability to play strong chess?

## Architecture Onboarding

- **Component map**: Chess board state, partner identity, framework type (STT/HB) -> MCTS with partner-aware policy/value networks -> Move selection with partner consideration -> Win probability calculation with partner model -> Game generation with partner teams + backpropagation

- **Critical path**: 1) Receive board state and framework context, 2) Query partner model to predict likely moves, 3) Run MCTS incorporating partner predictions, 4) Select move that optimizes team objective, 5) Update partner model based on actual moves

- **Design tradeoffs**: Tree vs Attuned: Tree requires no training but is less flexible; Attuned requires training but can adapt to specific partners. STT vs HB: STT requires handling complete board states; HB requires modeling piece-type preferences. Computational cost vs performance: Expector provides theoretical optimum but is expensive; Tree and Attuned are cheaper but approximate

- **Failure signatures**: If partner model is inaccurate → poor move selection in team context. If MCTS depth is insufficient → failure to anticipate partner's limitations. If training data is unrepresentative → inability to generalize to new partner types

- **First 3 experiments**: 1) Implement basic Tree agent and verify it outperforms vanilla Leela in STT framework, 2) Add partner modeling to MCTS and measure improvement in team performance, 3) Create synthetic partner data with varying skill levels and test cross-compatibility of trained agents

## Open Questions the Paper Calls Out

### Open Question 1
Can the skill-compatibility training methodologies generalize to other domains beyond chess, such as real-time strategy games or autonomous driving scenarios? The paper discusses potential generalization but doesn't test this empirically. This remains unresolved because the paper only validates in chess variants without empirical testing in other domains. Empirical testing in at least one non-chess domain would resolve this question.

### Open Question 2
What is the minimum level of skill compatibility needed for effective human-AI collaboration in real-world applications? The paper notes current chess engines are incompatible with human players but doesn't establish thresholds for effective collaboration. This remains unresolved because the paper establishes skill-compatibility as measurable but doesn't determine sufficiency for practical applications. Controlled experiments measuring task completion rates across varying degrees of compatibility would resolve this.

### Open Question 3
How do different skill-compatibility strategies (helping vs. tricking) affect long-term collaboration dynamics and user trust? The paper identifies helping and tricking mechanisms but only measures immediate performance effects. This remains unresolved because the paper focuses on short-term win rates without examining sustained collaboration or user preferences. Longitudinal studies comparing user retention and trust ratings would resolve this.

## Limitations
- The framework's generalizability beyond chess variants remains untested for domains with less structured partner behavior
- The computational cost of the Expector agent makes it impractical for real-time applications
- The paper focuses on pairwise interactions and doesn't address team compositions with multiple skill levels simultaneously

## Confidence

- **High Confidence**: The core methodology of creating skill-compatible agents through partner modeling and training frameworks is well-supported by experimental results showing measurable improvements in team performance
- **Medium Confidence**: The interpretation of different agent strategies (helping vs. exploiting) is plausible but could benefit from more detailed behavioral analysis
- **Low Confidence**: The claim that skill-compatibility is "distinct and measurable" separate from raw performance needs more rigorous validation across diverse partner types and domains

## Next Checks
1. Test the Expector agent's performance on unseen Maia skill levels to verify the robustness of its partner modeling across different ability ranges
2. Implement ablation studies removing the partner modeling component from each agent to quantify exactly how much skill-compatibility contributes to team performance
3. Evaluate agents in a third chess variant with different interaction patterns to assess the framework's generalizability beyond STT and HB