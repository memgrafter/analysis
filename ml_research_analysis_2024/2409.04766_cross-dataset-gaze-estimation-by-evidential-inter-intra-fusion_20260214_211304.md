---
ver: rpa2
title: Cross-Dataset Gaze Estimation by Evidential Inter-intra Fusion
arxiv_id: '2409.04766'
source_url: https://arxiv.org/abs/2409.04766
tags:
- gaze
- source
- domain
- fusion
- cross-dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces cross-dataset training to gaze estimation,
  demonstrating that training on multiple datasets with distribution variations significantly
  improves generalization to unseen domains. To address performance degradation in
  source domains caused by non-stationary gaze behavior, the authors propose Evidential
  Inter-intra Fusion (EIF), which employs multiple single-dataset branches with local
  regressors for each dataset, and a cross-dataset branch for aggregating generalizable
  features.
---

# Cross-Dataset Gaze Estimation by Evidential Inter-intra Fusion

## Quick Facts
- arXiv ID: 2409.04766
- Source URL: https://arxiv.org/abs/2409.04766
- Authors: Shijing Wang; Yaping Huang; Jun Xie; Yi Tian; Feng Chen; Zhepeng Wang
- Reference count: 40
- Key outcome: Improves cross-dataset gaze estimation performance, achieving 7.26% improvement on EyeDiap compared to state-of-the-art methods

## Executive Summary
This paper addresses the challenge of cross-dataset gaze estimation by proposing a framework that trains on multiple source domains while maintaining performance on both source and unseen domains. The authors identify that joint training of multiple datasets can significantly improve generalization to unseen domains but may degrade performance on source domains due to non-stationary gaze behavior. To address this, they propose Evidential Inter-intra Fusion (EIF), which employs multiple single-dataset branches with local regressors for each dataset, and a cross-dataset branch for aggregating generalizable features. The framework uses evidential regressors based on the Normal and Inverse-Gamma distribution to provide uncertainty estimation, achieving consistent improvements across all evaluated datasets.

## Method Summary
The framework uses a two-stage training strategy with multiple single-dataset branches trained separately for 100k batches each, followed by joint training with a cross-dataset branch for 5k batches. Each branch employs evidential regressors based on the Normal-Inverse Gamma (NIG) distribution, with local regressors partitioned by gaze ranges to handle non-stationary behavior. Intra-evidential fusion combines local regressors within each branch, while inter-evidential fusion aggregates across all branches using the Mixture of NIG (MoNIG) distribution. The model uses ResNet-18 backbone with 224×224 input images and Adam optimizer with learning rate 1e-4 and batch size 128.

## Key Results
- Achieves 7.26% improvement on EyeDiap compared to state-of-the-art methods
- Maintains strong performance on source domains (ETH-XGaze, Gaze360) while improving on unseen domains (MPIIFaceGaze, EyeDiap)
- Demonstrates consistent improvements across all evaluation metrics and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-dataset training improves generalization by exposing the model to diverse data distributions from multiple source domains.
- Mechanism: By merging multiple datasets with different environmental conditions and data distributions, the model learns more robust and generalizable features that perform better on unseen domains.
- Core assumption: Diverse data distributions in source domains provide richer learning signals than homogeneous datasets.
- Evidence anchors:
  - [abstract] "We discover that training these datasets jointly can significantly improve the generalization of gaze estimation"
  - [section] "By merging these datasets, we increase the variety of the training data, which largely enhances the model's generalization ability to unseen domains"
  - [corpus] Weak - no direct corpus evidence supporting this mechanism specifically for gaze estimation
- Break condition: If the distribution shifts between datasets are too extreme, the model may not learn transferable features and performance on both source and unseen domains could degrade.

### Mechanism 2
- Claim: Evidential fusion with Normal-Inverse Gamma (NIG) distribution provides both accurate predictions and uncertainty estimation.
- Mechanism: The NIG distribution models both the mean and variance of gaze predictions as random variables, allowing the framework to capture aleatoric (data) uncertainty and epistemic (model) uncertainty simultaneously.
- Core assumption: Gaze estimation inherently involves uncertainty that can be meaningfully captured through probabilistic modeling.
- Evidence anchors:
  - [abstract] "evidential regressors based on the Normal and Inverse-Gamma (NIG) distribution are designed to additionally provide uncertainty estimation apart from predicting gaze"
  - [section] "Building upon this foundation, our proposed framework achieves both intra-evidential fusion among numerous local regressors within each dataset and inter-evidential fusion across multiple-dataset branches by Mixture of Normal Inverse-Gamma (MoNIG) distribution"
  - [corpus] Weak - no direct corpus evidence supporting NIG distribution specifically for gaze estimation
- Break condition: If the NIG distribution assumptions don't match the true data distribution, the uncertainty estimates may be unreliable or misleading.

### Mechanism 3
- Claim: Partitioning data space into overlapping subspaces with local regressors addresses non-stationary gaze behavior within datasets.
- Mechanism: By dividing each dataset into gaze-specific subspaces and assigning dedicated local regressors to each, the model can handle varying effects of head posture and eye movement across different gaze ranges more effectively.
- Core assumption: Gaze behavior exhibits non-stationary characteristics that vary significantly across different gaze ranges.
- Evidence anchors:
  - [abstract] "we argue that the non-stationary gazing process inherent in each dataset should be carefully considered, where non-stationary refers to our gaze being primarily influenced by head posture and eye movement with their effects varying across different gaze ranges"
  - [section] "we draw inspiration from similar challenges addressed in other tasks such as age estimation [21], action quality assessment [36], equipping each branch with multiple local regressors tailored to specific data subspaces"
  - [corpus] Weak - no direct corpus evidence supporting this partitioning approach specifically for gaze estimation
- Break condition: If the partitioning strategy doesn't align with actual gaze behavior patterns, it may introduce unnecessary complexity without performance gains.

## Foundational Learning

- Concept: Normal-Inverse Gamma (NIG) Distribution
  - Why needed here: Provides a probabilistic framework for both prediction and uncertainty estimation in gaze regression tasks
  - Quick check question: What are the four parameters of the NIG distribution and what do they represent in the context of gaze estimation?

- Concept: Mixture of NIG (MoNIG) Distribution
  - Why needed here: Enables fusion of multiple evidential regressors by combining their NIG distributions into a single coherent distribution
  - Quick check question: How are the parameters of the fused MoNIG distribution computed from the individual NIG distributions?

- Concept: Two-stage training strategy
  - Why needed here: Allows the model to first learn dataset-specific features and then generalize across datasets without catastrophic forgetting
  - Quick check question: What is the purpose of training single-dataset branches separately before joint training?

## Architecture Onboarding

- Component map: Backbone -> Multiple single-dataset branches -> Local regressors -> Intra-evidential fusion -> Cross-dataset branch -> Inter-evidential fusion -> Final prediction
- Critical path: 1) Feature extraction through backbone networks 2) Local regressor selection based on gaze range 3) Intra-evidential fusion within each branch 4) Inter-evidential fusion across all branches 5) Final prediction and uncertainty estimation
- Design tradeoffs:
  - Multiple branches increase model complexity but improve source domain performance
  - Local regressors add computational overhead but handle non-stationary behavior
  - Two-stage training requires more training time but enables better generalization
- Failure signatures:
  - Poor source domain performance: Check if local regressor partitioning is appropriate
  - Unreliable uncertainty estimates: Verify NIG distribution assumptions
  - Slow convergence: Review two-stage training schedule and learning rates
- First 3 experiments:
  1. Train single-dataset branches with evidential regression only (no fusion)
  2. Add intra-evidential fusion to single-dataset branches
  3. Add cross-dataset branch and inter-evidential fusion (complete framework)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EIF scale when applied to more than two source domains with varying degrees of distribution shift?
- Basis in paper: [explicit] The paper mentions using two source domains (ETH-Gaze and Gaze360) but suggests that the model can adapt to new datasets with only a few epochs of training in stage 2.
- Why unresolved: The paper does not provide experimental results for scenarios with more than two source domains or varying degrees of distribution shift.
- What evidence would resolve it: Conducting experiments with multiple source domains (more than two) and varying degrees of distribution shift to evaluate the scalability and robustness of EIF.

### Open Question 2
- Question: What is the impact of the overlap coefficient (α) on the performance of local regressors, and how does it affect the trade-off between model complexity and accuracy?
- Basis in paper: [explicit] The paper mentions using a density overlap strategy with a dense overlap coefficient (α) to ensure data within overlapping regions contribute to training multiple regressors.
- Why unresolved: The paper does not provide a detailed analysis of how varying the overlap coefficient affects model performance or complexity.
- What evidence would resolve it: Performing a sensitivity analysis on the overlap coefficient (α) to determine its impact on model accuracy and complexity, and identifying an optimal range for different scenarios.

### Open Question 3
- Question: How does EIF handle real-time applications where computational efficiency is critical, given its multiple branches and evidential fusion modules?
- Basis in paper: [inferred] The paper discusses the computational cost of training EIF but does not address its efficiency in real-time applications.
- Why unresolved: The paper focuses on training efficiency but does not evaluate the model's performance in real-time scenarios.
- What evidence would resolve it: Benchmarking EIF's inference time and resource usage in real-time applications to assess its suitability for deployment in time-sensitive environments.

### Open Question 4
- Question: Can EIF be extended to handle other tasks beyond gaze estimation, such as facial expression recognition or object detection, where cross-dataset training is also relevant?
- Basis in paper: [explicit] The paper mentions that cross-dataset training has been explored in other tasks like object detection and facial expression recognition but does not discuss extending EIF to these tasks.
- Why unresolved: The paper is specific to gaze estimation and does not explore the applicability of EIF to other computer vision tasks.
- What evidence would resolve it: Adapting EIF to other tasks like facial expression recognition or object detection and evaluating its performance in cross-dataset scenarios for these tasks.

## Limitations
- Performance on source domains degrades when mixing datasets, requiring complex fusion mechanisms
- The preprocessing technique "following [9]" remains unspecified, affecting reproducibility
- The Normal-Inverse Gamma distribution assumptions for gaze uncertainty are not validated against real-world data distributions

## Confidence
- Cross-dataset training benefits: High - Multiple results consistently show performance improvements on unseen domains
- Evidential fusion mechanism: Medium - The theoretical framework is sound but lacks corpus validation for gaze-specific applications
- Partitioning strategy effectiveness: Medium - Performance gains are shown but the optimal partitioning parameters are not explored
- Uncertainty estimation quality: Low - No validation of the quality or calibration of the uncertainty estimates produced

## Next Checks
1. Test the framework on additional gaze datasets beyond the four used in the paper to assess generalizability
2. Perform ablation studies to determine optimal partitioning parameters (number of groups, overlap coefficient)
3. Evaluate the calibration of uncertainty estimates using proper scoring rules on held-out test sets