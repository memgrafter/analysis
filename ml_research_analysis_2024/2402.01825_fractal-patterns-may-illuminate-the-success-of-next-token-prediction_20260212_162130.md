---
ver: rpa2
title: Fractal Patterns May Illuminate the Success of Next-Token Prediction
arxiv_id: '2402.01825'
source_url: https://arxiv.org/abs/2402.01825
tags:
- language
- fractal
- hurst
- self-similarity
- median
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a fractal-based framework for analyzing\
  \ language structure and its connection to LLM performance. It demonstrates that\
  \ language exhibits self-similarity (H\xF6lder exponent S \u2248 0.59 \xB1 0.08)\
  \ and long-range dependence (Hurst parameter H \u2248 0.70 \xB1 0.09), quantified\
  \ through bits-per-byte scores from large language models."
---

# Fractal Patterns May Illuminate the Success of Next-Token Prediction

## Quick Facts
- arXiv ID: 2402.01825
- Source URL: https://arxiv.org/abs/2402.01825
- Reference count: 40
- This paper demonstrates that language exhibits self-similarity and long-range dependence, with fractal parameters improving prediction of downstream LLM performance beyond bits-per-byte alone.

## Executive Summary
This paper introduces a fractal-based framework for analyzing language structure and its connection to LLM performance. It demonstrates that language exhibits self-similarity (Hölder exponent S ≈ 0.59 ± 0.08) and long-range dependence (Hurst parameter H ≈ 0.70 ± 0.09), quantified through bits-per-byte scores from large language models. The study shows these fractal parameters are robust across different model architectures and domains, and that combining the Hurst parameter with bits-per-byte significantly improves prediction of downstream performance (adjusted R² increasing from 0.65 to over 0.86) compared to using bits-per-byte alone.

## Method Summary
The method converts text documents into bit sequences using LLM next-token probability estimates, then normalizes these bits to zero-mean/unit-variance. Fractal parameters are calculated through rescaled-range analysis and probability-mass fitting: the Hölder exponent S measures self-similarity via power-law scaling of probability distributions across time scales, while the Hurst parameter H quantifies long-range dependence through rescaled range analysis. The framework is validated across multiple domains in The Pile dataset and various model architectures including PaLM2, PaLM, and T5.1.1.

## Key Results