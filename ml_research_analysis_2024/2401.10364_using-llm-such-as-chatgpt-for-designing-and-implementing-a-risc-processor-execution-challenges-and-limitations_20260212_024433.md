---
ver: rpa2
title: 'Using LLM such as ChatGPT for Designing and Implementing a RISC Processor:
  Execution,Challenges and Limitations'
arxiv_id: '2401.10364'
source_url: https://arxiv.org/abs/2401.10364
tags:
- code
- instruction
- used
- register
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study evaluated using ChatGPT 3.5 to generate VHDL code for
  a RISC processor. It compared code quality across four components (PC, register
  file, ALU, control unit, instruction and data memory) using metrics: correct first
  iteration, errors embedded, trials to correct, and failure after three iterations.'
---

# Using LLM such as ChatGPT for Designing and Implementing a RISC Processor: Execution,Challenges and Limitations

## Quick Facts
- arXiv ID: 2401.10364
- Source URL: https://arxiv.org/abs/2401.10364
- Authors: Shadeeb Hossain; Aayush Gohil; Yizhou Wang
- Reference count: 23
- Primary result: ChatGPT 3.5 failed to generate correct VHDL code for RISC components in the first iteration, requiring extensive human debugging.

## Executive Summary
This study evaluates the use of ChatGPT 3.5 to generate VHDL code for a simplified RISC processor, focusing on six key components: Program Counter, Register File, ALU, Control Unit, Instruction Memory, and Data Memory. The authors assess code quality using four metrics: correctness on first iteration, errors embedded, trials to correct, and failure after three iterations. Results show that all components failed to produce correct code initially, with significant errors requiring manual debugging. The study concludes that while LLMs can assist in generating preliminary code skeletons, they cannot replace human expertise for complex hardware design tasks.

## Method Summary
The authors used ChatGPT 3.5 to generate VHDL code for a simplified RISC processor based on natural language prompts describing each component. They iteratively refined the generated code, manually debugging errors until the code compiled and passed testbenches. The final designs were implemented on a Basys 3 FPGA board for functional verification. Code quality was evaluated using four metrics: correct on first iteration (binary), number of errors embedded, number of trials to achieve correct code, and failure after three iterations (binary).

## Key Results
- All components failed to produce correct VHDL code in the first iteration.
- Average trials ranged from 3 to over 10 per component, with 100% failure rate for generating error-free code in three attempts.
- Human intervention was required to fix syntax errors, missing control signals, and functional bugs.
- FPGA implementation confirmed functional correctness only after extensive manual correction.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM generates initial VHDL skeleton for RISC components but fails to produce fully correct code in the first iteration.
- Mechanism: The LLM uses tokenization and attention mechanisms to map natural language prompts into token sequences, then applies a transformer-based decoder to produce VHDL code. However, due to the complexity of hardware description and limited context length, the generated code contains syntax errors and missing control signals.
- Core assumption: The model's training data includes general code patterns but lacks sufficient hardware-specific VHDL examples to cover all edge cases in RISC design.
- Evidence anchors:
  - [abstract] "All components failed to produce correct code initially; significant errors required human debugging."
  - [section] "The number of errors and trials required to fix the errors varied and depended mostly on (i) the complexity of the design and (ii) clarity in the prompt."
  - [corpus] Weak: Corpus shows related work on LLM code generation but not hardware-specific, so LLM struggles with domain-specific syntax and semantics.
- Break condition: If prompts are highly detailed and hardware-specific, or if the model is fine-tuned on VHDL datasets, the initial failure rate may decrease.

### Mechanism 2
- Claim: Iterative refinement is necessary because LLM-generated code requires multiple human-led debugging cycles to meet functional correctness.
- Mechanism: Each iteration involves running testbenches, identifying mismatches between expected and actual waveforms, and manually correcting code. The LLM's sampling strategy does not guarantee syntactically or semantically correct VHDL for complex control logic.
- Core assumption: Human expertise is required to interpret simulation results and apply domain knowledge to fix bugs that the LLM cannot self-correct.
- Evidence anchors:
  - [abstract] "Average trials ranged from 3 to over 10 per component, with 100% failure rate for generating error-free code in three attempts."
  - [section] "In all the cases human intervention was eventually required to fix the bugs."
  - [corpus] Weak: General LLM code generation literature shows similar iteration needs but lacks hardware-specific evidence.
- Break condition: If an automated VHDL linter or compiler is integrated to provide immediate feedback, the number of required iterations may reduce.

### Mechanism 3
- Claim: LLM is useful for generating reusable code templates and testbenches but not for final production-ready designs without human oversight.
- Mechanism: The model can produce syntactically plausible VHDL skeletons and basic testbenches based on prompt patterns, but the generated testbenches often miss corner cases or fail to cover all RISC instructions.
- Core assumption: LLM training on general code corpora captures common patterns but lacks exhaustive coverage of all instruction set behaviors and timing constraints.
- Evidence anchors:
  - [abstract] "LLM can therefore be used to complement a programmer's code design."
  - [section] "Though LLM is a great tool for generating a preliminary skeleton for the code, human intervention is eventually required to fix the relevant bugs."
  - [corpus] Weak: No corpus evidence specifically on testbench generation quality, so this is inferred from general code generation trends.
- Break condition: If the model is augmented with a formal verification module, the reliability of generated testbenches may improve significantly.

## Foundational Learning

- Concept: VHDL syntax and hardware description fundamentals
  - Why needed here: Correct VHDL syntax is essential for synthesizable code; LLM often produces syntactically incorrect statements that must be manually fixed.
  - Quick check question: Can you identify the correct VHDL syntax for a 32-bit register with synchronous reset?

- Concept: RISC-V instruction set architecture (ISA) and control unit design
  - Why needed here: Understanding the ISA is crucial to verify that generated control signals and ALU operations match the intended instruction format.
  - Quick check question: What are the OPCODE and funct3 fields for an R-type ADD instruction in RISC-V?

- Concept: FPGA synthesis and timing analysis
  - Why needed here: Ensures that the VHDL code not only simulates correctly but also meets timing and resource constraints on the target FPGA.
  - Quick check question: How do you interpret a timing report that shows setup time violations in the synthesized design?

## Architecture Onboarding

- Component map:
  - Program Counter (PC): 32-bit register with reset and increment logic.
  - Register File: Dual-port memory with write-enable and read-address decoding.
  - ALU: Combinational logic for arithmetic, logic, and shift operations controlled by funct3.
  - Control Unit: Finite state machine decoding OPCODE and funct3 to generate control signals.
  - Instruction Memory: ROM initialized with RISC-V instructions starting at 0x01000000.
  - Data Memory: RAM accessed by LW/SW instructions starting at 0x80000000.

- Critical path:
  - Instruction fetch → Control decode → ALU operation → Register write-back.
  - Longest delay typically in ALU and control unit combinational logic.

- Design tradeoffs:
  - Simplicity vs. completeness: Focus on core 40 RV32I instructions for manageable complexity.
  - Resource usage vs. speed: Optimize for fewer LUTs at the cost of longer critical path.
  - Testbench coverage vs. development time: Prioritize key instruction tests before exhaustive coverage.

- Failure signatures:
  - Simulation mismatches in PC increment or reset behavior.
  - Register file read/write hazards or incorrect data alignment.
  - ALU producing wrong results for specific funct3 combinations.
  - Control unit not asserting correct signals for certain instructions.

- First 3 experiments:
  1. Simulate PC with reset and increment signals; verify waveform matches expected 0x01000000 → 0x01000004.
  2. Test Register File with simultaneous read/write; confirm data integrity after clock edge.
  3. Validate ALU operations (add, sub, and, or) for all funct3 codes; check zero flag behavior.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural or prompt-related modifications to the LLM could reduce the number of human interventions needed for debugging RISC processor VHDL code?
- Basis in paper: [explicit] The paper found that all components required human debugging and identified high error counts and trial numbers.
- Why unresolved: The paper tested only ChatGPT 3.5 without exploring prompt engineering or architectural adjustments.
- What evidence would resolve it: Comparative experiments testing different LLM versions, prompt structures, or fine-tuning approaches on the same RISC components, measuring error reduction and human intervention frequency.

### Open Question 2
- Question: How does the efficiency of LLM-generated VHDL code for RISC processors compare to human-written code in terms of power consumption and timing delays?
- Basis in paper: [inferred] The paper mentions future work on optimizing power consumption and execution time but does not provide comparative data.
- Why unresolved: The study focused on code correctness and debugging, not performance metrics like power or timing.
- What evidence would resolve it: Direct performance benchmarking of LLM-generated versus human-written VHDL implementations, including power usage, clock frequency, and critical path analysis.

### Open Question 3
- Question: What is the minimum level of human expertise required to effectively debug and correct LLM-generated VHDL code for complex hardware designs?
- Basis in paper: [explicit] The paper notes that "senior consultants" were sometimes needed for complex components like the control unit.
- Why unresolved: The study did not systematically assess the skill level or experience required for successful debugging.
- What evidence would resolve it: Controlled studies where participants with varying levels of VHDL expertise attempt to debug the same LLM-generated code, measuring success rates and time to resolution.

## Limitations
- Lack of detailed documentation of the exact natural language prompts used to generate VHDL code for each RISC component.
- Insufficient details on testbench cases and their expected outputs, making it difficult to replicate the verification process exactly.
- Evaluation metrics are somewhat subjective and rely on manual inspection, which may introduce bias.
- Focus on a limited set of RISC components does not explore the full complexity of modern processor designs.

## Confidence
- **High Confidence**: The claim that LLM-generated VHDL code requires iterative refinement and human intervention is supported by the study's results, which show a 100% failure rate in generating error-free code within three attempts.
- **Medium Confidence**: The assertion that LLM can assist in generating code templates and testbenches is plausible but not extensively validated in the study, as it lacks detailed evidence on testbench quality.
- **Low Confidence**: The conclusion that LLM cannot replace programmers for complex hardware design is based on limited experimentation with a simplified RISC processor and may not generalize to more advanced architectures.

## Next Checks
1. **Prompt Optimization**: Conduct experiments with a range of natural language prompts to determine the impact of prompt specificity and detail on the quality of generated VHDL code. This will help identify the optimal prompt structure for hardware design tasks.
2. **Automated Verification Integration**: Integrate automated VHDL linters and formal verification tools into the code generation process to provide immediate feedback and reduce the number of required iterations. Evaluate the effectiveness of this approach in improving code quality.
3. **Scalability Testing**: Extend the study to include more complex RISC-V features, such as pipelining, memory hierarchies, and advanced instructions. Assess whether the observed limitations of LLM in generating hardware code persist or diminish with increased design complexity.