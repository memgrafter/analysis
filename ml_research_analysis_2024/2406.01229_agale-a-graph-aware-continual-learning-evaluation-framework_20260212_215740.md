---
ver: rpa2
title: 'AGALE: A Graph-Aware Continual Learning Evaluation Framework'
arxiv_id: '2406.01229'
source_url: https://arxiv.org/abs/2406.01229
tags:
- learning
- task
- graph
- nodes
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses continual graph learning (CGL) in multi-label
  settings, where nodes in evolving graphs can acquire new labels over time. Existing
  CGL frameworks focus on single-label scenarios and struggle with data leakage, incomplete
  node representations, and changing neighborhood structures in multi-label cases.
---

# AGALE: A Graph-Aware Continual Learning Evaluation Framework

## Quick Facts
- arXiv ID: 2406.01229
- Source URL: https://arxiv.org/abs/2406.01229
- Authors: Tianqi Zhao; Alan Hanjalic; Megha Khosla
- Reference count: 21
- Primary result: AGALE is a novel graph-aware evaluation framework for continual graph learning in multi-label settings that improves label homophily in subgraphs and enables fairer evaluation by preventing data leakage.

## Executive Summary
This paper addresses the challenge of continual graph learning (CGL) in multi-label scenarios where nodes can acquire new labels over time. Existing CGL frameworks focus on single-label scenarios and struggle with data leakage, incomplete node representations, and changing neighborhood structures in multi-label cases. AGALE is a novel graph-aware evaluation framework that handles both single- and multi-label scenarios by defining two incremental settings (Task-IL and Class-IL) and introducing data partitioning algorithms that preserve node labels and structural integrity while preventing data leakage. Theoretical analysis shows that AGALE improves label homophily in subgraphs, which benefits model performance.

## Method Summary
AGALE addresses continual graph learning in multi-label settings by defining two incremental learning paradigms: Task-Incremental Learning (Task-IL) where nodes are assigned non-overlapping label subsets, and Class-Incremental Learning (Class-IL) where nodes' label sets expand over time. The framework includes a task sequence generator that creates multiple random class orders to simulate real-world class emergence, a subgraph generator that extracts relevant portions of the graph for each task, and a data splitter that prevents data leakage by carefully partitioning nodes across train/val/test sets. Theoretical analysis proves that this approach increases label homophily within subgraphs, improving GCN performance. Experiments on real-world datasets (PCG, DBLP, Yelp) demonstrate that methods like LwF and MAS perform well, while SimpleGCN and JointTrainGCN no longer serve as universal lower/upper bounds due to increased subgraph homophily.

## Key Results
- AGALE prevents data leakage in multi-label CGL by partitioning nodes such that each node appears in only one set per task
- Theoretical analysis proves AGALE increases label homophily in subgraphs, benefiting GCN performance
- Experiments show LwF and MAS outperform other methods, with SimpleGCN/JointTrainGCN no longer serving as universal bounds due to subgraph homophily effects
- Random class order generation provides fairer evaluation by simulating realistic class emergence patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AGALE improves label homophily in subgraphs, which enhances GCN performance on multi-label tasks.
- Mechanism: By partitioning the graph into subgraphs where each node appears with non-overlapping subsets of its labels (Task-IL) or expanding label sets (Class-IL), AGALE increases the proportion of edges connecting nodes with shared labels within each subgraph. Higher label homophily reduces neighborhood ambiguity for GCN, leading to better predictions.
- Core assumption: Label homophily is a key factor in GCN effectiveness for node classification tasks.
- Evidence anchors:
  - [abstract]: "Theoretical analysis shows that AGALE improves label homophily in subgraphs, which benefits model performance."
  - [section]: "In Theorem 1 we theoretically analyzed the label homophily of the edges in the subgraphs where we showed that in cases of single-labeled nodes and for higher homophily edges, the homophily in subgraphs typically increases."
- Break condition: If the original graph has very low label homophily and few single-labeled nodes, the improvement in subgraph homophily may be minimal, limiting GCN performance gains.

### Mechanism 2
- Claim: AGALE prevents data leakage in multi-label scenarios by carefully partitioning nodes across train/val/test sets.
- Mechanism: Instead of splitting nodes independently within each class (which can assign the same node to both train and test sets for different labels), AGALE orders classes by size and ensures nodes assigned to one class are excluded from splits in other classes they belong to. This maintains the integrity of the evaluation.
- Core assumption: Data leakage in multi-label settings significantly biases evaluation results and masks true model performance.
- Evidence anchors:
  - [section]: "Previous CGL evaluation frameworks split the nodes into train and evaluation sets within each class, not considering the situation where one node can belong to multiple classes in the task. Such a strategy may lead to data leakage as one node can be assigned to training and testing sets for the same task."
  - [section]: "During task training on a subgraph comprising various classes, our framework ensures no overlap among the training, validation, and test sets."
- Break condition: If class sizes are highly imbalanced and many nodes belong to multiple small classes, the algorithm might struggle to maintain fair splits without excessive node exclusion.

### Mechanism 3
- Claim: AGALE enables fairer evaluation by generating multiple random class orders and task sequences.
- Mechanism: Instead of relying on a single predefined class order, AGALE generates n random orders of classes to simulate the random emergence of new classes in the real world. This exposes models to varied task sequences and prevents overfitting to a specific class emergence pattern.
- Core assumption: A single class order may not reflect the true generation process of the data and can bias evaluation results.
- Evidence anchors:
  - [section]: "We generaten random orders of the remaining classes to simulate the random emergence of new classes in the real world."
  - [section]: "Specifically for multi-label scenarios, the employed class order may not only influence the nodes and their neighborhood structures presented at each time step but also affect the number of labels assigned to a particular node in a given task."
- Break condition: If the number of classes is small relative to n, the random orders may not provide meaningful diversity, reducing the benefit of this mechanism.

## Foundational Learning

- Concept: Label homophily in graphs
  - Why needed here: Understanding label homophily is crucial because AGALE's effectiveness hinges on increasing it within subgraphs to improve GCN performance.
  - Quick check question: What is the difference between edge label homophily and node label homophily, and how does each affect GNN performance?

- Concept: Catastrophic forgetting in continual learning
  - Why needed here: AGALE is designed to evaluate CGL methods, which aim to prevent catastrophic forgetting. Understanding this concept is essential for interpreting experimental results and comparing methods.
  - Quick check question: What are the main strategies used in continual learning to mitigate catastrophic forgetting, and how do they differ?

- Concept: Graph partitioning and subgraph generation
  - Why needed here: AGALE's data partitioning algorithms are central to its design. Understanding how to generate coherent subgraphs while preserving structural integrity is key to grasping its advantages over previous frameworks.
  - Quick check question: What are the key challenges in partitioning a multi-label graph into subgraphs for continual learning, and how does AGALE address them?

## Architecture Onboarding

- Component map: Task Sequence Generator -> Subgraph Generator -> Train/Val/Test Splitter -> Evaluation Engine

- Critical path:
  1. Input: Static multi-label graph dataset.
  2. Task Sequence Generation: Generate n random class orders, group into tasks.
  3. Subgraph Generation: For each task, extract subgraph with relevant nodes and edges.
  4. Data Splitting: Partition nodes into train/val/test sets within each subgraph, preventing leakage.
  5. Model Training/Evaluation: Train models on task sequences, evaluate performance on all tasks seen so far.
  6. Metrics and Visualization: Compute AP, AF, generate heatmaps and learning curves.

- Design tradeoffs:
  - Random class orders vs. predefined order: Random orders better simulate real-world class emergence but may introduce variance in results.
  - Task sequence length vs. task difficulty: Shorter sequences (K=2) allow more tasks but may not capture long-term forgetting; longer sequences increase difficulty but reduce the number of tasks.
  - Single-label vs. multi-label focus: AGALE handles both but may not optimize specifically for either scenario.

- Failure signatures:
  - Low AP and AF: Model fails to learn new tasks and forgets old ones (catastrophic forgetting).
  - High AP but low AF: Model learns new tasks well but fails to retain old knowledge.
  - Low AP but high AF: Tasks are uncorrelated; learning new tasks interferes with old ones.
  - High variance across random splits: Model is sensitive to task sequence order, indicating potential overfitting.

- First 3 experiments:
  1. Run AGALE on a simple multi-label graph (e.g., PCG) with n=1 and K=2, compare SimpleGCN and JointTrainGCN to verify the label homophily mechanism.
  2. Evaluate a basic CL method (e.g., LwF) on the same dataset and setting to observe catastrophic forgetting and the effect of knowledge distillation.
  3. Increase n to 3 and compare the variance in AP and AF across splits to assess the impact of random class orders.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do inter-task edges influence performance in multi-label continual graph learning?
- Basis in paper: [explicit] The authors deliberately exclude inter-task edges from AGALE, noting that "the assumption is that the model loses access to the data from the previous time steps" and that "with the inter-task edges, the node features from the previous time step would also be used as input, which violates this assumption and alleviates the forgetting problem."
- Why unresolved: The paper doesn't empirically test whether including inter-task edges improves or degrades performance, only that they violate the continual learning assumption.
- What evidence would resolve it: Experiments comparing AGALE performance with and without inter-task edges on the same datasets would show if including them improves performance (suggesting they could be useful in relaxed continual learning scenarios) or degrades it (supporting the current design choice).

### Open Question 2
- Question: What is the optimal buffer size for replay-based methods like ERGNN in multi-label continual graph learning?
- Basis in paper: [inferred] ERGNN's poor performance is partly attributed to "disregarding the topological structure surrounding the sampled experience nodes," and the paper notes it samples "isolated nodes in the buffer" rather than maintaining structural relationships.
- Why unresolved: The paper doesn't systematically explore how different buffer sizes or sampling strategies (e.g., sampling subgraphs vs. nodes) affect ERGNN's performance.
- What evidence would resolve it: Experiments varying buffer size and sampling strategies (e.g., sampling edges, subgraphs, or nodes with their neighbors) would reveal the optimal approach for maintaining performance while preventing forgetting.

### Open Question 3
- Question: How does the task sequence length affect the relative performance of knowledge distillation vs. regularization methods?
- Basis in paper: [explicit] The paper notes that "LwF excels on graphs with shorter task sequences (e.g., PCG and DBLP with 7 and 2 tasks, respectively)" while "regularization-based methods like EWC and MAS slightly outperform other approaches" on longer sequences like Yelp with 50 tasks, because "LwF only distills knowledge from the last time step, leading to a performance drop with longer sequences."
- Why unresolved: The paper only tests a few task sequence lengths and doesn't systematically vary the number of tasks to find the breaking point where regularization methods become superior to knowledge distillation.
- What evidence would resolve it: Experiments systematically varying the number of tasks (e.g., 2, 5, 10, 20, 50) on datasets like Yelp would identify the exact task sequence length where regularization methods consistently outperform knowledge distillation.

## Limitations

- AGALE's effectiveness depends on the presence of single-labeled nodes to improve subgraph homophily, which may not hold in datasets where most nodes have many labels
- The theoretical analysis of label homophily improvement assumes specific conditions that may not generalize across all graph topologies
- The computational overhead of generating multiple random class orders and task sequences could be prohibitive for very large graphs or extensive hyperparameter searches

## Confidence

- **High confidence**: AGALE successfully addresses data leakage in multi-label CGL through its partitioning algorithm, as evidenced by the clear problem statement and algorithmic solution
- **Medium confidence**: The theoretical improvement in label homophily and its impact on GCN performance is supported by the analysis, but empirical validation across diverse datasets is needed
- **Medium confidence**: The experimental comparison of CL methods (LwF, MAS performing well vs. SimpleGCN/JointTrainGCN as poor baselines) is based on specific datasets and may not generalize to all graph structures

## Next Checks

1. **Dataset diversity test**: Evaluate AGALE on datasets with varying label distributions (e.g., Cora, Citeseer, PubMed) to assess robustness across different homophily levels and label frequencies
2. **Ablation study**: Remove the random class order generation and compare results to isolate the contribution of this mechanism to overall performance
3. **Computational efficiency analysis**: Measure the time and memory requirements of AGALE's data partitioning algorithms on increasingly large graphs to identify scalability bottlenecks