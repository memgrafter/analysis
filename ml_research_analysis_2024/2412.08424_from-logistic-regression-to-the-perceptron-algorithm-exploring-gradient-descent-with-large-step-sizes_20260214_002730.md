---
ver: rpa2
title: 'From Logistic Regression to the Perceptron Algorithm: Exploring Gradient Descent
  with Large Step Sizes'
arxiv_id: '2412.08424'
source_url: https://arxiv.org/abs/2412.08424
tags:
- step
- perceptron
- batch
- iterations
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates why logistic regression with gradient\
  \ descent (LR+GD) solves separable classification problems with arbitrarily large\
  \ step sizes, defying conventional optimization theory. The key insight is that\
  \ as the step size \u03B3 approaches infinity, LR+GD reduces to a batch version\
  \ of the perceptron algorithm."
---

# From Logistic Regression to the Perceptron Algorithm: Exploring Gradient Descent with Large Step Sizes

## Quick Facts
- arXiv ID: 2412.08424
- Source URL: https://arxiv.org/abs/2412.08424
- Authors: Alexander Tyurin
- Reference count: 40
- Primary result: LR+GD with large step sizes converges to a batch perceptron algorithm, explaining its success despite theoretical limitations

## Executive Summary
This paper investigates the counterintuitive success of logistic regression with gradient descent (LR+GD) when using arbitrarily large step sizes on separable classification problems. The key insight is that as the step size approaches infinity, LR+GD effectively reduces to a batch version of the perceptron algorithm. This reduction provides a simple explanation for LR+GD's ability to solve separable problems even when conventional optimization theory would predict divergence. The paper makes three interconnected observations: LR+GD with large step sizes converges to Batch Perceptron, larger step sizes lead to higher logistic losses but faster convergence to a solution, and LR+GD's iteration complexity is suboptimal. To address these findings, the paper proposes Normalized LR+GD, a new method with improved theoretical guarantees and iteration rates.

## Method Summary
The paper analyzes logistic regression with gradient descent on separable classification problems, exploring how varying step sizes affect convergence. It establishes a theoretical connection between LR+GD with large step sizes and the batch perceptron algorithm, then proposes a normalized variant to improve iteration complexity. The method is tested on standard datasets (CIFAR-10, FashionMNIST, EuroSAT, MNIST) with 5,000 samples per class, comparing accuracy, logistic loss values, and iteration counts against the batch perceptron algorithm.

## Key Results
- LR+GD with large step sizes converges to a batch version of the perceptron algorithm
- Larger step sizes lead to higher logistic losses but faster convergence to a solution
- LR+GD's iteration complexity (nR²/µ²) is suboptimal compared to classical perceptron algorithms (R²/µ²)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LR+GD with large step sizes converges to a batch version of the perceptron algorithm
- Mechanism: As step size γ → ∞, the logistic regression gradient update step θ_{t+1}/γ converges to the batch perceptron update ˆθ_{t+1}, where misclassified samples are identified and used to update the model
- Core assumption: The dataset is separable (Assumption 1.1) and non-degenerate (Assumption 3.1)
- Evidence anchors:
  - [abstract] "LR+GD reduces to a batch version of the celebrated perceptron algorithm when the step size γ → ∞"
  - [section] "θt/γ → ˆθt for all t ≥ 0, with ˆθ0 = 0 if the dataset satisfies Assumption 3.1"
  - [corpus] Weak evidence - no direct citations about LR+GD → Perceptron reduction
- Break condition: If the dataset is not separable or is degenerate (violates Assumption 3.1)

### Mechanism 2
- Claim: Larger step sizes lead to higher logistic losses but faster convergence to a solution
- Mechanism: As γ increases, the logistic loss f(θ_t) becomes a less reliable metric of proximity to a solution. High loss values can actually indicate faster convergence to the classification solution
- Core assumption: The dataset is separable and the goal is to find a solution to the classification problem (1), not minimize the logistic loss (2)
- Evidence anchors:
  - [abstract] "larger step sizes lead LR+GD to higher logistic losses when it tends to the perceptron algorithm, but larger step sizes also lead to faster convergence to a solution"
  - [section] "Theorem 4.1. Assume that θ1 = 0. There exists a separable dataset such that f(θ1) → ∞ and f(θ2) → 0 when γ → ∞"
  - [corpus] Weak evidence - no direct citations about loss being unreliable metric
- Break condition: If evaluating progress based solely on logistic loss values

### Mechanism 3
- Claim: LR+GD with large step sizes has suboptimal iteration complexity compared to classical perceptron algorithms
- Mechanism: The iteration complexity nR²/µ² of LR+GD when γ → ∞ scales linearly with n, while classical perceptron algorithms can achieve R²/µ² complexity. The dependence on n cannot be avoided for batch perceptron but can be improved with proper normalization
- Core assumption: The goal is to minimize iteration complexity to solve the classification problem (1)
- Evidence anchors:
  - [abstract] "LR+GD's iteration complexity is suboptimal" and "we propose a new method, Normalized LR+GD... with much better theoretical guarantees"
  - [section] "The iteration rate nR²/µ² from Theorem 3.3 by LR+GD when γ → ∞ is suboptimal since it linearly depends on n"
  - [corpus] Weak evidence - no direct citations about LR+GD being suboptimal
- Break condition: If comparing methods based solely on function value convergence rather than iteration complexity

## Foundational Learning

- Concept: Gradient Descent optimization
  - Why needed here: Understanding how gradient descent works with logistic regression and how step sizes affect convergence
  - Quick check question: What happens to gradient descent convergence when the step size exceeds 2/L (where L is the smoothness parameter)?

- Concept: Perceptron algorithm
  - Why needed here: Understanding the connection between logistic regression with large step sizes and the perceptron algorithm
  - Quick check question: How does the classical perceptron algorithm update its weights when it encounters misclassified samples?

- Concept: Separable datasets and margin
  - Why needed here: Understanding the problem setup and why certain convergence properties hold for separable data
  - Quick check question: What is the geometric interpretation of the margin µ in a separable classification problem?

## Architecture Onboarding

- Component map: Logistic Regression Model -> Gradient Descent Optimizer -> Separable Dataset -> Convergence Analysis
- Critical path: 1) Initialize model parameters, 2) Compute gradient of logistic loss, 3) Update parameters using gradient descent with varying step sizes, 4) Monitor convergence to solution
- Design tradeoffs: Larger step sizes provide faster convergence but higher logistic loss values; smaller step sizes provide stable convergence but slower progress toward solution
- Failure signatures: If logistic loss continues to increase without bound, it may indicate the algorithm is working correctly for separable data with large step sizes; if accuracy plateaus below 1.0, the data may not be truly separable
- First 3 experiments:
  1. Run LR+GD with step sizes {0.001, 0.01, 0.1, 1.0, 10.0, 100.0} on a small separable dataset and plot both accuracy and loss over iterations
  2. Compare LR+GD with batch perceptron algorithm on the same dataset to verify they converge to similar solutions
  3. Test the normalized LR+GD variant with various step sizes to verify improved iteration complexity claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the reduction of LR+GD to Batch Perceptron hold for all separable datasets, or are there pathological cases where it fails?
- Basis in paper: [explicit] The paper states that LR+GD reduces to Batch Perceptron when γ→∞, but requires Assumption 3.1 for the proof.
- Why unresolved: The paper only proves the reduction under Assumption 3.1, which excludes pathological datasets. It's unclear if this assumption is necessary or if the reduction holds more generally.
- What evidence would resolve it: Numerical experiments on a wide range of datasets, including those that violate Assumption 3.1, to see if LR+GD still aligns with Batch Perceptron behavior. A theoretical proof showing the reduction holds without Assumption 3.1 would be ideal.

### Open Question 2
- Question: Can the Normalized LR+GD method be extended to nonlinear models, such as neural networks, while maintaining its improved iteration rate?
- Basis in paper: [inferred] The paper discusses the potential extension to nonlinear models in the Future Work section but doesn't provide concrete results or guarantees.
- Why unresolved: The paper only analyzes the linear case and suggests a potential connection to a generalized perceptron algorithm for nonlinear models, but doesn't explore this further or provide theoretical guarantees.
- What evidence would resolve it: Developing a theoretical framework for analyzing the behavior of LR+GD with large step sizes on nonlinear models and proving convergence rates similar to those obtained for the linear case. Numerical experiments on nonlinear models, such as neural networks, would provide empirical evidence for the potential benefits of Normalized LR+GD in these settings.

### Open Question 3
- Question: What are the underlying reasons for the improved performance of Normalized Batch Perceptron and Normalized LR+GD on imbalanced datasets?
- Basis in paper: [explicit] The paper observes that Normalized Batch Perceptron and Normalized LR+GD perform better on imbalanced datasets compared to their non-normalized counterparts in numerical experiments.
- Why unresolved: The paper provides a high-level explanation, suggesting that Batch Perceptron performs well "on average" but is not robust to imbalanced data. However, a more detailed analysis of the mechanisms behind this improvement is lacking.
- What evidence would resolve it: A theoretical analysis of how the normalization in these methods affects the update steps and leads to better performance on imbalanced datasets. Numerical experiments comparing the methods on datasets with varying degrees of imbalance and analyzing the convergence behavior in these cases would provide further insights.

## Limitations

- The connection between LR+GD and batch perceptron is established under strong assumptions about dataset separability and non-degeneracy
- The claim about logistic loss being an unreliable progress metric requires empirical validation across diverse datasets
- The practical significance of iteration complexity improvements from the normalized variant may be limited

## Confidence

- High: The theoretical reduction of LR+GD to batch perceptron for separable data with large step sizes
- Medium: The claim about logistic loss being unreliable as a progress metric
- Low: The practical significance of iteration complexity improvements from the normalized variant

## Next Checks

1. **Empirical Validation**: Test LR+GD with varying step sizes on non-separable datasets to verify when the perceptron connection breaks down.
2. **Loss Metric Analysis**: Systematically evaluate how logistic loss values correlate with classification accuracy across different step sizes and dataset properties.
3. **Implementation Verification**: Compare LR+GD and batch perceptron implementations on standardized datasets to confirm they converge to similar solutions with large step sizes.