---
ver: rpa2
title: 'Landscape-Aware Growing: The Power of a Little LAG'
arxiv_id: '2406.02469'
source_url: https://arxiv.org/abs/2406.02469
tags:
- growing
- loss
- step
- layers
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the selection of optimal model growing strategies
  in depth for Transformer-based models. Prior approaches focused on loss/function
  preservation at initialization, but the authors find this does not correlate well
  with final performance (Pearson -0.51, Spearman -0.42).
---

# Landscape-Aware Growing: The Power of a Little LAG

## Quick Facts
- arXiv ID: 2406.02469
- Source URL: https://arxiv.org/abs/2406.02469
- Reference count: 8
- Primary result: Early training loss after ~5,000 steps strongly predicts final performance (Pearson 0.98, Spearman 0.99), enabling better model growing strategy selection

## Executive Summary
This paper challenges the common assumption that loss preservation at initialization is key for model growing. Instead, the authors discover that loss immediately after applying a growth operator poorly predicts final performance (Pearson -0.51, Spearman -0.42), while loss after just 5,000 training steps shows near-perfect correlation with final results. This insight leads to Landscape-Aware Growing (LAG), which selects optimal growth strategies based on early training dynamics rather than initial loss preservation. LAG achieves near-optimal performance in both BERT and UL2 pretraining settings and motivates an adaptive strategy for gradual stacking that outperforms fixed strategies.

## Method Summary
LAG works by applying multiple growth operators in parallel to a pretrained model, training each for a small number of steps (k), and selecting the operator with lowest validation loss at that point. The authors identify a phase transition around step 500,050 where the correlation between early and final performance rapidly increases. For BERT experiments, they use k=200 steps (LAG@200), while for UL2 they use k=2,000 steps (LAG@2000). The method explores a design space of growth operators with varying index, block size, and initialization scheme, finding that early loss prediction consistently outperforms loss-preservation baselines.

## Key Results
- Initial loss after growing shows poor correlation with final performance (Pearson -0.51, Spearman -0.42)
- Loss after ~5,000 steps strongly predicts final performance (Pearson 0.98, Spearman 0.99)
- LAG achieves near-optimal performance in both BERT and UL2 pretraining settings
- An adaptive strategy for gradual stacking outperforms fixed strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Initial loss after growing does not correlate with final performance because the network rapidly adapts to use new layers, creating an unstable initial landscape.
- Mechanism: When a smaller pretrained model is grown by adding layers, the loss at initialization can be misleading because the network quickly adapts to the new architecture in the first few thousand steps. This adaptation phase temporarily disrupts the loss ordering across different growth strategies.
- Core assumption: The pretrained model already has a stable representation that can rapidly integrate new layers, and the initial drop in loss reflects this fast adaptation rather than true long-term performance.
- Evidence anchors:
  - [abstract] "Instead, we identify that behavior at initialization can be misleading as a predictor of final performance"
  - [section 3.1] "the loss immediately after applying the growth operator is not well-correlated with the loss after continued training"
- Break condition: If the pretrained model is not sufficiently stable, or if the new layers are initialized too far from useful representations, the rapid adaptation may not occur, breaking this mechanism.

### Mechanism 2
- Claim: Loss after a small number of training steps (around 5,000) strongly predicts final performance because the network enters a stable training phase where relative performance ordering is preserved.
- Mechanism: After the initial rapid adaptation phase, the network enters a slower, more predictable training phase where the relative ordering of different growth strategies becomes stable. This stable phase allows early loss measurements to predict final performance with high correlation.
- Core assumption: The transition from rapid adaptation to stable training is sharp and measurable, creating a clear phase boundary in the loss landscape.
- Evidence anchors:
  - [abstract] "Instead, we propose an alternative view based on the landscape induced by an initialization through the following key observation: while initial loss can be misleading, the loss after a relatively small number of steps (roughly 5000) correlates very strongly with the final performance"
  - [section 3.2] "we make a surprising discovery that the loss after a few steps of training can be very highly predictive"
- Break condition: If the learning rate schedule or optimization algorithm creates highly variable training dynamics, the stable phase may not emerge clearly, breaking this mechanism.

### Mechanism 3
- Claim: Good predictions for the best strategy can be made even earlier (after a few hundred steps) because a measurable phase transition occurs around step 500,050.
- Mechanism: The loss landscape exhibits a measurable phase transition where the correlation between early and final performance rapidly increases. This transition allows for even earlier identification of optimal strategies than the 5,000-step threshold.
- Core assumption: The phase transition is sharp and consistent across different growth strategies, creating a predictable window for early prediction.
- Evidence anchors:
  - [section 3.3] "we observe several interesting properties" and "a clear phase transition between the earliest few steps of training and the remainder of the first 200 steps"
  - [section 3.3] "The phase transition between the earliest few steps of training and the remainder of the first 200 steps seems to occur roughly around step 500,050"
- Break condition: If the phase transition timing varies significantly across different model architectures or training conditions, the early prediction window may not be reliable.

## Foundational Learning

- Concept: Loss landscape dynamics
  - Why needed here: Understanding how the loss landscape changes after model growing is crucial for interpreting why initial loss is misleading and why early training dynamics predict final performance
  - Quick check question: What is the difference between the initial loss after growing and the loss after a few training steps, and why does this difference matter for model selection?

- Concept: Phase transitions in optimization
  - Why needed here: Recognizing and measuring phase transitions in the training process is essential for implementing the LAG algorithm effectively
  - Quick check question: How can you identify a phase transition in training loss, and what does it indicate about the stability of different growing strategies?

- Concept: Correlation analysis
  - Why needed here: Understanding how to measure and interpret correlations between different performance metrics is crucial for validating the LAG hypothesis
  - Quick check question: What does a high Pearson correlation between early and final loss indicate about the predictive power of early training dynamics?

## Architecture Onboarding

- Component map:
  - Pretrained base model -> Growth operator design space -> Parallel growing strategies -> Early training phase -> Strategy selection -> Continued training

- Critical path:
  1. Pretrain base model (e.g., BERT-BASE)
  2. Apply multiple growing strategies in parallel
  3. Train each grown model for k steps (where k is determined by phase transition analysis)
  4. Select the strategy with lowest validation loss at k steps
  5. Continue training the selected strategy to completion

- Design tradeoffs:
  - k value selection: Larger k provides more stable predictions but increases computational cost
  - Search space size: Larger search spaces provide better coverage but increase parallel training requirements
  - Phase transition detection: More sophisticated detection methods could improve early prediction but add complexity

- Failure signatures:
  - Poor correlation between early and final loss (r < 0.8) indicates unstable training dynamics
  - Phase transition not occurring within expected timeframe suggests model-specific dynamics
  - Best strategy changing significantly after k steps indicates k was chosen too small

- First 3 experiments:
  1. Verify phase transition timing by plotting Spearman correlation heatmap for steps 500,000-500,200
  2. Test different k values (e.g., 100, 200, 500, 1000) to find optimal prediction window
  3. Compare LAG performance against loss-preservation baseline on held-out validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of LAG and landscape-aware growing principles scale to larger models with billions of parameters, and what specific challenges arise in this regime?
- Basis in paper: [inferred] The paper notes limitations including only exploring BERT and UL2 settings with models just over 1B parameters, and acknowledges uncertainty about how results generalize to state-of-the-art model sizes.
- Why unresolved: The authors did not have compute resources to test their approach on the largest modern language models. Larger models may have different loss landscapes and optimization dynamics that could affect the applicability of LAG principles.
- What evidence would resolve it: Empirical testing of LAG on models with 10B+ parameters, comparing performance against traditional loss-preserving growth methods, and analyzing whether the phase transition and correlation patterns observed in smaller models still hold.

### Open Question 2
- Question: What is the theoretical foundation for why loss preservation at initialization does not correlate with final performance, and what mathematical properties of the loss landscape explain this phenomenon?
- Basis in paper: [explicit] The authors observe that loss preservation is not a good heuristic and propose an alternative perspective based on early training dynamics and landscape properties, but do not provide a theoretical explanation for why this occurs.
- Why unresolved: The paper focuses on empirical observations rather than theoretical analysis. The authors identify a phenomenon but do not explain the underlying mathematical reasons why growth operators that disrupt initial loss function can lead to better final performance.
- What evidence would resolve it: Mathematical analysis of how different growth operators affect the curvature, smoothness, or other geometric properties of the loss landscape, and theoretical guarantees or bounds on convergence rates under different initialization schemes.

### Open Question 3
- Question: How sensitive is LAG to the choice of hyperparameters such as the number of training steps k used for evaluation, and what is the optimal strategy for selecting k in different contexts?
- Basis in paper: [explicit] The authors use different values of k for different experiments (LAG@200 for BERT, LAG@2000 for UL2) and mention choosing k to ensure some margin post-phase-transition, but do not provide systematic analysis of this hyperparameter choice.
- Why unresolved: The paper demonstrates LAG works with reasonable choices of k but does not study the sensitivity to this parameter or provide guidance on how to select it optimally for different model sizes, tasks, or growth scenarios.
- What evidence would resolve it: Systematic experiments varying k across multiple orders of magnitude, analysis of how optimal k relates to model size and training dynamics, and development of a principled method for selecting k based on early training behavior or model characteristics.

## Limitations
- Results only verified on BERT and UL2 settings with models just over 1B parameters
- Relies on internal empirical observations rather than external validation of proposed mechanisms
- Does not provide theoretical explanation for why loss preservation fails as a heuristic

## Confidence
**High Confidence**: The empirical correlation results (Pearson 0.98, Spearman 0.99) between early training loss and final performance are robust and well-supported by the data. The LAG algorithm's superior performance in both BERT and UL2 settings is convincingly demonstrated.

**Medium Confidence**: The mechanistic explanations for why the approach works are plausible but not rigorously proven. The phase transition timing and its consistency across different scenarios need further validation.

**Low Confidence**: The generalizability of the findings to other model architectures, tasks, or training regimes remains uncertain without additional experiments.

## Next Checks
1. **Phase Transition Robustness**: Systematically vary learning rates, batch sizes, and model architectures to verify if the 500,050-step phase transition is consistent or architecture-dependent.

2. **Cross-Architecture Validation**: Apply LAG to transformer architectures beyond BERT and UL2 (e.g., GPT, RoBERTa) to test the method's generalizability and identify any architecture-specific adaptations needed.

3. **Early Prediction Window Optimization**: Conduct a systematic study of different early prediction windows (e.g., 100, 500, 1000 steps) across multiple tasks to identify the optimal tradeoff between prediction accuracy and computational efficiency.