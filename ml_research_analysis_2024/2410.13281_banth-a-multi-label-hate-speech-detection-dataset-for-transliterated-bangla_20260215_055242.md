---
ver: rpa2
title: 'BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla'
arxiv_id: '2410.13281'
source_url: https://arxiv.org/abs/2410.13281
tags:
- hate
- speech
- bangla
- text
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We introduce BanTH, the first multi-label transliterated Bangla
  hate speech dataset comprising 37.3k samples. We establish novel transformer encoder-based
  baselines by further pre-training on transliterated Bangla corpus and propose a
  novel translation-based LLM prompting strategy.
---

# BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla

## Quick Facts
- arXiv ID: 2410.13281
- Source URL: https://arxiv.org/abs/2410.13281
- Reference count: 40
- Introduces BanTH, the first multi-label transliterated Bangla hate speech dataset with 37.3k samples

## Executive Summary
This paper introduces BanTH, the first multi-label transliterated Bangla hate speech dataset, addressing the challenge of detecting hate speech in informal, non-standard Bangla text. The dataset comprises 37.3k YouTube comments annotated for binary hate/non-hate classification and multi-label hate categories including political, religious, gender, and personal offense. The authors establish transformer encoder baselines through further pretraining on transliterated Bangla corpus and propose a novel translation-based LLM prompting strategy. Their approach achieves state-of-the-art performance, with translation-based prompting showing particular effectiveness in zero-shot settings.

## Method Summary
The authors collected transliterated Bangla comments from YouTube, filtered for length and language, and manually annotated them for hate speech. They further pretrained transformer encoders using masked language modeling on a transliterated Bangla corpus to adapt them to informal spelling patterns. For baseline models, they fine-tuned various language models on the BanTH dataset. They also developed translation-based prompting strategies for LLMs to handle transliterated text, comparing this approach with zero-shot and few-shot prompting in both English and Bangla.

## Key Results
- BanTH dataset contains 37.3k samples with binary and multi-label hate speech annotations
- Further pretrained transformer encoders achieve state-of-the-art performance on the dataset
- Translation-based LLM prompting outperforms other strategies in zero-shot settings
- Multi-label classification captures nuanced hate speech categories including political, religious, gender, and personal offense

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Further pretraining TB-encoders on transliterated Bangla corpus improves hate speech detection performance.
- Mechanism: MLM objective exposes models to linguistic patterns and informal spelling variations characteristic of transliterated Bangla.
- Core assumption: Pretraining corpus is representative of BanTH dataset text types.
- Evidence anchors: Abstract mentions further pretraining on transliterated corpus; Section 3.1 describes MLM pretraining objective.
- Break condition: If further pretrained TB-encoders don't outperform other language models on BanTH.

### Mechanism 2
- Claim: Translation-based prompting strategy improves LLM performance on transliterated Bangla text.
- Mechanism: Translating transliterated text to standard Bangla or English helps LLMs better understand context for classification.
- Core assumption: LLM translation capabilities are sufficient for accurate conversion.
- Evidence anchors: Abstract mentions novel translation-based LLM prompting; Section 4.2 shows best zero-shot performance.
- Break condition: If translation-based prompting doesn't outperform other strategies in zero-shot setting.

### Mechanism 3
- Claim: Multi-label classification provides more granular understanding of hate motivation.
- Mechanism: Categorizing hate speech into multiple labels captures nuances and overlapping categories.
- Core assumption: BanTH dataset accurately represents different types of hate speech.
- Evidence anchors: Abstract discusses multi-label classification for comprehending hate motivation; Section 2 describes seven hate categories.
- Break condition: If multi-label classification doesn't provide better results than binary classification.

## Foundational Learning

- Concept: Masked Language Modeling (MLM)
  - Why needed here: Used as pretraining objective for further pretraining TB-encoders to learn transliterated Bangla patterns.
  - Quick check question: What is the purpose of masking tokens during the MLM training process?

- Concept: Fine-tuning
  - Why needed here: Adapts pre-trained language models to hate speech detection task on BanTH dataset.
  - Quick check question: What is the difference between pre-training and fine-tuning in the context of language models?

- Concept: Prompting strategies
  - Why needed here: Leverages LLM capabilities for hate speech detection in transliterated Bangla.
  - Quick check question: What are the key differences between zero-shot, few-shot, and translation-based prompting strategies?

## Architecture Onboarding

- Component map: Data collection -> Preprocessing -> Further pretraining -> Fine-tuning -> Evaluation
- Critical path: Collect and annotate BanTH dataset → Further pretrain TB-encoders → Fine-tune language models → Evaluate performance
- Design tradeoffs: Corpus size vs computational resources for pretraining; prompt strategy complexity vs implementation effort
- Failure signatures: Poor minority class performance indicating class imbalance; translation failures suggesting inadequate LLM capabilities
- First 3 experiments:
  1. Fine-tune mBERT on BanTH dataset and evaluate on test set
  2. Further pretrain TB-encoder on transliterated corpus, fine-tune on BanTH, compare with baseline
  3. Implement translation-based prompting for GPT-4o, compare with other strategies on BanTH

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does BanTH model performance generalize to other low-resource languages with similar transliteration patterns?
- Basis in paper: [inferred] Introduces BanTH as benchmark and discusses translation-based prompting generalization potential.
- Why unresolved: Paper focuses solely on transliterated Bangla without cross-linguistic validation.
- What evidence would resolve it: Testing BanTH-trained models and prompting strategies on transliterated texts from other low-resource languages like Hindi or Nepali.

### Open Question 2
- Question: What is the impact of different tokenization strategies on transformer model performance for transliterated Bangla hate speech detection?
- Basis in paper: [explicit] Uses standard transformers without exploring tokenization strategies for transliterated text.
- Why unresolved: Paper doesn't experiment with character-level or subword tokenization that might handle inconsistent spelling better.
- What evidence would resolve it: Comparative experiments using different tokenization strategies and evaluating their impact on model performance.

### Open Question 3
- Question: How does BanTH model performance vary across different demographic groups within the Bangla-speaking population?
- Basis in paper: [explicit] Dataset includes comments from West Bengal and Bangladesh but lacks demographic analysis.
- Why unresolved: No demographic breakdown or analysis of model performance across age groups, genders, or regions.
- What evidence would resolve it: Demographic analysis of dataset and experiments evaluating model performance across different demographic groups.

## Limitations

- Keyword-based YouTube scraping may introduce sampling bias toward specific hate speech types
- Manual annotation process could contain subjective interpretations of hate speech boundaries
- Effectiveness of further pretraining depends on quality and representativeness of pretraining corpus
- Translation-based prompting assumes LLMs can accurately translate transliterated text without losing contextual nuances

## Confidence

- **High Confidence**: Dataset creation methodology and baseline model training procedures are well-documented and follow established NLP practices
- **Medium Confidence**: Superiority of proposed approaches is demonstrated but experimental setup may not account for all confounding factors
- **Low Confidence**: Assumption that multi-label classification provides more meaningful insights lacks external validation beyond dataset creation

## Next Checks

1. **Cross-domain validation**: Evaluate BanTH-trained models on hate speech detection in other South Asian transliterated languages (e.g., Hindi, Nepali) to assess cross-linguistic generalizability.

2. **Adversarial testing**: Design test cases with code-mixed transliterated text containing intentional spelling variations, slang, and context-dependent hate speech to evaluate model robustness.

3. **Human evaluation**: Conduct blind annotation studies comparing model predictions with human judgments on held-out sample to assess practical effectiveness of multi-label classification.