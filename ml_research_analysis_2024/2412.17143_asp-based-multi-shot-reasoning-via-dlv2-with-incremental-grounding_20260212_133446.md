---
ver: rpa2
title: ASP-based Multi-shot Reasoning via DLV2 with Incremental Grounding
arxiv_id: '2412.17143'
source_url: https://arxiv.org/abs/2412.17143
tags:
- program
- shot
- reasoning
- system
- facts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Incremental-DLV2 introduces an efficient multi-shot reasoning system
  for ASP that leverages overgrounding techniques to incrementally handle grounding
  processes across repeated executions. Instead of restarting from scratch, the system
  maintains a growing overgrounded program that is progressively updated with new
  rules based on unseen facts at each shot.
---

# ASP-based Multi-shot Reasoning via DLV2 with Incremental Grounding

## Quick Facts
- arXiv ID: 2412.17143
- Source URL: https://arxiv.org/abs/2412.17143
- Reference count: 11
- Primary result: Incremental-DLV2 achieves 1.6x-4.6x speedup over traditional DLV2 in multi-shot ASP reasoning through incremental overgrounding techniques

## Executive Summary
Incremental-DLV2 introduces an efficient multi-shot reasoning system for Answer Set Programming (ASP) that leverages overgrounding techniques to incrementally handle grounding processes across repeated executions. Instead of restarting from scratch, the system maintains a growing overgrounded program that is progressively updated with new rules based on unseen facts at each shot. This approach significantly reduces grounding efforts, particularly when inputs are largely similar across shots. The system uses tailored overgrounding with simplifications to manage program size and selectively processes smaller equivalent portions for solving, ensuring efficiency. Experiments on real-world benchmarks—Pac-Man, Content Caching, and Photo-voltaic Systems—demonstrate substantial improvements in cumulative execution time, with speedups ranging from 1.6x to 4.6x compared to traditional DLV2, while maintaining manageable memory usage.

## Method Summary
Incremental-DLV2 implements a multi-shot reasoning approach for ASP that maintains a monotonically growing overgrounded program (G) across shots. At each shot, the system identifies unseen facts, generates ground rules only for these new facts, and adds them to G. The solver then processes a simplified, equivalent subset of G rather than the full program to maintain performance. This incremental grounding approach avoids the expensive re-grounding required by traditional DLV2 when handling similar inputs across multiple shots. The system uses meta-data from prior simplifications to identify relevant portions of G that preserve semantic equivalence with the current facts.

## Key Results
- Cumulative execution time improvements of 1.6x to 4.6x compared to traditional DLV2 across three benchmark domains
- Memory usage remains manageable through selective processing of smaller program subsets
- Speedup factors increase with the number of shots as the overgrounding effect compounds
- The system maintains semantic equivalence while significantly reducing grounding overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incremental-DLV2 avoids full re-grounding by maintaining a monotonically growing overgrounded program (G) across shots.
- Mechanism: At each shot, only ground rules corresponding to newly seen facts are generated and added to G; existing rules are reused without re-computation.
- Core assumption: Facts repeat across shots or are subsets of previously seen facts.
- Evidence anchors:
  - [abstract]: "maintains a growing overgrounded program that is progressively updated with new rules based on unseen facts at each shot"
  - [section 2]: "G is monotonically enlarged across shots, in order to be semantics-preserving with respect to new input facts"
- Break condition: If each shot introduces entirely new facts not seen before, grounding effort remains high.

### Mechanism 2
- Claim: The solver processes only a smaller, equivalent subset of the overgrounded program, mitigating performance loss from program growth.
- Mechanism: Meta-data from prior simplifications is used to identify and feed the solver only the relevant portion of G that preserves equivalence with the current facts.
- Core assumption: A subset of G exists that is equivalent to the original program when grounded with current facts.

## Foundational Learning

### Overgrounding
- Why needed: To avoid expensive re-grounding across multiple shots by maintaining a growing program
- Quick check: Verify that G grows monotonically and contains all ground rules from previous shots

### Incremental Grounding
- Why needed: To generate ground rules only for new facts rather than re-grounding entire programs
- Quick check: Confirm that ground rules are only added for previously unseen facts

### Program Simplification
- Why needed: To maintain solver performance as the overgrounded program grows
- Quick check: Ensure simplified subsets preserve semantic equivalence with full programs

### Multi-shot Reasoning
- Why needed: To handle dynamic, reactive reasoning tasks where inputs change incrementally
- Quick check: Validate that the system correctly handles sequences of related fact sets

## Architecture Onboarding

### Component Map
Incremental-DLV2 -> Overgrounding Engine -> Program Simplifier -> ASP Solver

### Critical Path
1. Fact set input detection
2. Incremental grounding of new facts
3. Overgrounded program update
4. Subset selection and simplification
5. Solving with simplified program

### Design Tradeoffs
- Memory vs. Performance: Maintaining overgrounded program increases memory usage but reduces grounding time
- Complexity vs. Efficiency: Simplification metadata adds overhead but enables selective solving
- Generality vs. Optimization: Tailored overgrounding provides better results than generic approaches

### Failure Signatures
- Memory exhaustion from unbounded program growth
- Degraded performance when input similarity is low
- Semantic errors from incorrect subset selection

### First Experiments
1. Single-shot baseline comparison between Incremental-DLV2 and DLV2
2. Two-shot test with overlapping and non-overlapping fact sets
3. Memory profiling during extended shot sequences

## Open Questions the Paper Calls Out
1. How does the performance of Incremental-DLV2 scale with increasing program size and number of facts across multiple shots?
2. How does the effectiveness of overgrounding techniques vary with the similarity of input facts across shots?
3. What are the trade-offs between the memory overhead of maintaining the overgrounded program and the performance gains in terms of execution time?

## Limitations
- Memory growth in long-running systems due to monotonic program enlargement is not fully characterized
- The system's performance depends heavily on fact overlap across shots; no analysis provided for scenarios with low similarity
- Simplified subset selection relies on metadata correctness; potential semantic drift if simplification logic fails

## Confidence
- High confidence in overgrounding mechanism (clear description, well-defined technical process)
- Medium confidence in performance claims (based on specific benchmarks with known characteristics)
- Low confidence in scalability analysis (no stress testing or long-duration evaluation presented)

## Next Checks
1. Stress test with non-overlapping fact sequences to verify grounding overhead remains bounded
2. Implement memory monitoring over extended shot sequences to measure actual growth patterns
3. Verify subset selection correctness by comparing outputs between full overgrounded program and simplified subsets across diverse benchmarks