---
ver: rpa2
title: Transformer based neural networks for emotion recognition in conversations
arxiv_id: '2405.11222'
source_url: https://arxiv.org/abs/2405.11222
tags:
- emotion
- subtask
- task
- language
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents the ISDS-NLP team''s approach to SemEval 2024
  Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). The
  team investigated two approaches for Subtask 1 (emotion classification in dialogues):
  Masked Language Modeling (MLM) using pre-trained BERT-like models, and Causal Language
  Modeling (CLM) using Mistral 7B Instruct V0.2.'
---

# Transformer based neural networks for emotion recognition in conversations

## Quick Facts
- arXiv ID: 2405.11222
- Source URL: https://arxiv.org/abs/2405.11222
- Reference count: 5
- Primary result: Achieved weighted F1 score of 0.43 and 12th place on SemEval 2024 Task 10 (EDiReF) leaderboard for emotion classification in dialogues

## Executive Summary
This paper presents the ISDS-NLP team's approach to SemEval 2024 Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). The team investigated two approaches for Subtask 1 (emotion classification in dialogues): Masked Language Modeling (MLM) using pre-trained BERT-like models, and Causal Language Modeling (CLM) using Mistral 7B Instruct V0.2. For MLM, they fine-tuned multilingual models with varying input lengths, classifier architectures, and fine-tuning strategies, achieving a weighted F1 score of 0.43 and 12th place on the leaderboard. The Causal approach using Mistral showed promise but underperformed compared to MLM for sentence-level emotion classification.

## Method Summary
The paper explores two approaches for emotion classification in conversations: Masked Language Modeling (MLM) and Causal Language Modeling (CLM). For MLM, the team fine-tuned pre-trained BERT-like models (XLM-RoBERTa) with a classifier to predict emotions, experimenting with different input lengths, classifier architectures, and fine-tuning strategies. The CLM approach used Mistral 7B Instruct V0.2 with zero-shot and few-shot prompting. The fine-tuning strategy involved initially training only the classifier with a larger learning rate, followed by fine-tuning both the classifier and the transformer's final layer with a smaller learning rate.

## Key Results
- Achieved weighted F1 score of 0.43 and 12th place on the SemEval 2024 Task 10 leaderboard for Subtask 1
- Fine-tuned Masked Language Models (MLMs) outperformed Causal Language Models (CLMs) for sentence-level emotion classification in conversations
- Best performance achieved with FacebookAI/xlm-roberta-large model, input length of 55 tokens, and classifier architecture with 128 neurons and 0.5 dropout

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning a pre-trained Masked Language Model (MLM) with a classifier layer on task-specific data is effective for emotion classification in conversations.
- Mechanism: The MLM captures rich contextual representations from the pre-training phase, which are then adapted to the emotion classification task through supervised fine-tuning with a classifier.
- Core assumption: The contextual representations learned by the MLM during pre-training are transferable and useful for the downstream emotion classification task.
- Evidence anchors:
  - [abstract] "For MLM, we employ pre-trained BERT-like models in a multilingual setting, fine-tuning them with a classifier to predict emotions. Experiments with varying input lengths, classifier architectures, and fine-tuning strategies demonstrate the effectiveness of this approach."
  - [section] "The large pre-trained language models we employed offer a robust foundation for understanding language in general. Through fine-tuning, we adapt them to the nuances of our emotion recognition task."

### Mechanism 2
- Claim: Using the final hidden state layer of the MLM and the [CLS] token as input to the classifier yields the best performance.
- Mechanism: The final hidden state layer contains the most refined contextual representations after passing through all transformer layers, and the [CLS] token is designed to aggregate information from the entire input sequence.
- Core assumption: Later layers of the transformer capture more abstract and task-relevant features, and the [CLS] token effectively encodes the overall meaning of the input.
- Evidence anchors:
  - [section] "Our experiments demonstrated that using the final layer's output yielded the strongest performance, with accuracy declining in earlier layers. For MLM-type models, the [CLS] token encodes the features, which is what we pass to our classification layer."

### Mechanism 3
- Claim: Fine-tuning the classifier first with a larger learning rate and then the entire model with a smaller learning rate helps prevent overfitting and improves performance.
- Mechanism: Initially training only the classifier allows it to adapt to the task without drastically altering the pre-trained representations. Subsequently fine-tuning the entire model with a smaller learning rate makes more subtle adjustments to better align the representations with the task.
- Core assumption: The pre-trained representations are generally useful but may need some adaptation for the specific task, and gradual fine-tuning helps balance task adaptation and overfitting prevention.
- Evidence anchors:
  - [section] "Inspired by the strategy presented in (Sun et al., 2020), we initially train only the classifier with a larger learning rate (5e-5) and a warm-up period of 10,000 steps over 'k' epochs (we tried a range of 'k' from 1 to 10). Subsequently, we fine-tune both the classifier and the transformer's final layer using a smaller learning rate (2e-5)."

## Foundational Learning

- Concept: Transformer architecture
  - Why needed here: The paper relies heavily on transformer-based models (BERT-like MLMs and Mistral) for emotion recognition in conversations. Understanding the transformer architecture is crucial for comprehending the model choices and their behavior.
  - Quick check question: What are the key components of a transformer, and how do they enable effective context modeling in NLP tasks?

- Concept: Masked Language Modeling (MLM) and Causal Language Modeling (CLM)
  - Why needed here: The paper explores both MLM (used by BERT-like models) and CLM (used by Mistral) approaches. Understanding the differences between these pre-training objectives and their implications for downstream tasks is essential.
  - Quick check question: How do MLM and CLM differ in their pre-training objectives, and what are the potential advantages and disadvantages of each for sentence-level emotion classification?

- Concept: Fine-tuning strategies
  - Why needed here: The paper employs a specific fine-tuning strategy (classifier-first, then full model) to adapt the pre-trained models to the emotion classification task. Understanding fine-tuning techniques and their impact on model performance is crucial.
  - Quick check question: What are the key considerations when fine-tuning a pre-trained model, and how can different fine-tuning strategies affect the model's ability to adapt to a new task?

## Architecture Onboarding

- Component map: Tokenized input -> Pre-trained MLM (e.g., XLM-RoBERTa) -> [CLS] token's output from final hidden state layer -> Classifier (e.g., fully connected layer) -> Emotion classification

- Critical path:
  1. Preprocess the input conversation data.
  2. Tokenize the input using the MLM's tokenizer.
  3. Pass the tokenized input through the MLM to obtain contextual representations.
  4. Extract the [CLS] token's output from the final hidden state layer.
  5. Feed the [CLS] token's output to the classifier.
  6. Compute the loss and update the model parameters using the fine-tuning strategy.

- Design tradeoffs:
  - Input length: Longer inputs may capture more context but increase computational cost and may not improve performance due to the nature of the data.
  - Classifier architecture: More complex classifiers may model non-linear relationships better but are more prone to overfitting.
  - Fine-tuning strategy: More aggressive fine-tuning may lead to better task adaptation but increases the risk of overfitting.

- Failure signatures:
  - Overfitting: High training accuracy but low validation/test accuracy.
  - Underfitting: Low accuracy on both training and validation/test sets.
  - Class imbalance: Poor performance on underrepresented classes.

- First 3 experiments:
  1. Test different input lengths (e.g., 32, 55, 128 tokens) to find the optimal balance between context capture and computational efficiency.
  2. Experiment with different classifier architectures (e.g., fully connected layers with varying sizes, dropout rates, and activation functions) to find the best configuration for the task.
  3. Compare the performance of different fine-tuning strategies (e.g., classifier-first vs. full-model fine-tuning, different learning rates, and warm-up periods) to determine the most effective approach for the given dataset and task.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific techniques or modifications to the model architecture or training process could effectively address the class imbalance issue observed in the emotion recognition task, where the 'neutral' emotion is overrepresented?
- Basis in paper: [explicit] The paper mentions that the model overpredicts the 'neutral' emotion due to its prevalence in the training data and suggests exploring techniques like oversampling or undersampling to address the class imbalance.
- Why unresolved: While the paper acknowledges the class imbalance problem and suggests potential solutions, it does not provide specific evidence or results from implementing these techniques.
- What evidence would resolve it: Implementing and comparing the performance of oversampling, undersampling, and other class imbalance mitigation techniques on the same dataset would provide evidence on the most effective approach.

### Open Question 2
- Question: How do newer causal models like Mixtral and Solar compare to the current state-of-the-art Masked Language Models (MLMs) in terms of performance on sentence-level emotion classification tasks?
- Basis in paper: [explicit] The paper suggests testing newer causal models like Mixtral and Solar, which could potentially perform better at emotion recognition tasks compared to Mistral.
- Why unresolved: The paper does not provide any experimental results or comparisons involving these newer models.
- What evidence would resolve it: Conducting experiments to compare the performance of Mixtral, Solar, and other state-of-the-art causal models against MLMs on the same emotion recognition dataset would provide a clear comparison.

### Open Question 3
- Question: How does incorporating a broader conversational context through multi-turn analysis affect the model's ability to detect emotion flips in dialogues?
- Basis in paper: [explicit] The paper suggests enriching the data by incorporating a broader conversational context through multi-turn analysis to enhance the model's capabilities.
- Why unresolved: The paper does not provide any experimental results or analysis on the impact of multi-turn context on emotion flip detection.
- What evidence would resolve it: Experimenting with models that incorporate multi-turn context and comparing their performance on emotion flip detection tasks against models that do not use this context would provide insights into the effectiveness of this approach.

## Limitations

- The paper lacks detailed hyperparameter specifications, making exact reproduction challenging.
- The evaluation focuses primarily on weighted F1 score without comprehensive analysis of other relevant metrics such as per-class precision and recall.
- The paper does not thoroughly address the impact of class imbalance on the results, which is known to be a significant issue in the dataset.

## Confidence

*High Confidence:* The core finding that fine-tuned Masked Language Models (MLMs) outperform Causal Language Models (CLMs) for sentence-level emotion classification in conversations is well-supported by the experimental results and aligns with established NLP literature on pre-trained transformer models.

*Medium Confidence:* The effectiveness of the specific fine-tuning strategy (classifier-first with larger learning rate, followed by full-model fine-tuning with smaller learning rate) is supported by the results, but could benefit from additional ablation studies to isolate its contribution to the overall performance.

*Low Confidence:* The paper's claims about the superiority of specific hyperparameter choices (e.g., input length of 55 tokens, classifier architecture with 128 neurons) are based on limited experimentation and may not generalize across different datasets or model architectures.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary the input length (e.g., 32, 55, 128 tokens), classifier architecture (e.g., number of neurons, dropout rates), and fine-tuning parameters (learning rates, epochs) to quantify their impact on model performance and identify the most influential factors.

2. **Class Imbalance Mitigation**: Implement and evaluate different techniques to address class imbalance, such as oversampling underrepresented classes, undersampling the majority class, or using class weights in the loss function. Compare the results with the original approach to assess the effectiveness of these methods.

3. **Cross-Dataset Generalization**: Test the fine-tuned models on a separate emotion recognition dataset (e.g., IEMOCAP, MELD) to evaluate their generalization capabilities and robustness to different conversational contexts and emotion distributions.