---
ver: rpa2
title: Optimizing DNN Inference on Multi-Accelerator SoCs at Training-time
arxiv_id: '2409.18566'
source_url: https://arxiv.org/abs/2409.18566
tags:
- odimo
- accuracy
- latency
- layer
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ODiMO is a training-time tool for optimizing DNN mappings onto
  multi-CU heterogeneous SoCs by splitting layers and executing them in parallel on
  different CUs. It uses differentiable optimization to balance accuracy, latency,
  and energy, accounting for hardware-specific constraints like quantization formats
  and layer types.
---

# Optimizing DNN Inference on Multi-Accelerator SoCs at Training-time

## Quick Facts
- arXiv ID: 2409.18566
- Source URL: https://arxiv.org/abs/2409.18566
- Reference count: 40
- Achieved up to 8× latency reduction and 50.8× energy efficiency improvement over manual mappings with minimal accuracy loss (<0.3%)

## Executive Summary
ODiMO introduces a training-time optimization framework for DNN mappings on multi-accelerator heterogeneous SoCs. The approach splits DNN layers and executes them in parallel across different compute units, using differentiable optimization to balance accuracy, latency, and energy while accounting for hardware-specific constraints like quantization formats. Tested on CIFAR-10, CIFAR-100, and ImageNet using DIANA and Darkside SoC architectures, ODiMO achieved significant performance improvements over manual mapping approaches while maintaining minimal accuracy degradation.

## Method Summary
ODiMO employs a differentiable optimization framework that simultaneously learns both DNN weights and optimal mapping decisions during training. The method uses a Monte Carlo approximation of the expected loss over random partitioning schemes, allowing the network to learn how to split and distribute layers across multiple compute units. A key innovation is the use of sigmoid gating functions to handle non-differentiable decisions about which compute unit executes which layer segment, combined with reinforcement learning techniques to handle non-differentiable components like the Hardware Description Language. The framework explicitly models hardware constraints including quantization formats, layer types, and compute unit capabilities to generate valid mappings that respect SoC architecture limitations.

## Key Results
- Achieved up to 8× latency reduction compared to manual mapping approaches
- Demonstrated 50.8× improvement in energy efficiency while maintaining accuracy
- Generated rich Pareto-optimal solution sets showing strong trade-offs between accuracy, latency, and energy consumption
- Maintained minimal accuracy loss (<0.3%) across all tested datasets and architectures

## Why This Works (Mechanism)
ODiMO works by transforming the traditionally separate optimization problems of DNN training and hardware mapping into a unified, end-to-end differentiable process. By incorporating hardware constraints and objectives directly into the training loss function, the framework learns optimal layer partitioning and compute unit assignments that minimize the target objective (latency or energy) while preserving accuracy. The differentiable approximation of discrete mapping decisions through sigmoid gating functions enables gradient-based optimization, while the Monte Carlo sampling approach handles the combinatorial complexity of possible partitioning schemes.

## Foundational Learning

**Differentiable Neural Architecture Search (DNAS)**: Why needed - Enables gradient-based optimization of discrete architecture decisions. Quick check - Verify the framework can handle non-differentiable components through approximation techniques.

**Hardware-aware Neural Architecture Search (HW-NAS)**: Why needed - Ensures learned architectures are compatible with real hardware constraints. Quick check - Confirm the model properly handles quantization formats and compute unit limitations.

**Multi-objective Optimization**: Why needed - Balances competing objectives like accuracy, latency, and energy efficiency. Quick check - Verify Pareto-optimal solutions are properly generated and evaluated.

## Architecture Onboarding

**Component Map**: DNN Layers -> Partitioning Module -> Hardware Mapping Module -> Compute Units (CU0, CU1, etc.) -> Latency/Energy Estimation -> Training Loss

**Critical Path**: The optimization loop involves forward pass through DNN with learned partitioning, hardware constraint checking, latency/energy estimation, and backward pass through differentiable components to update both weights and mapping decisions.

**Design Tradeoffs**: The framework trades computational complexity (handling many partitioning schemes) for flexibility in generating optimal mappings. Using differentiable approximations enables end-to-end optimization but may introduce approximation errors for highly discrete decisions.

**Failure Signatures**: Poor performance may result from: (1) insufficient exploration of partitioning space, (2) inaccurate hardware modeling, (3) optimization getting stuck in local minima, or (4) quantization precision loss being too severe for certain layer partitions.

**First Experiments**: 1) Validate baseline accuracy on CIFAR-10 without optimization, 2) Test single-layer partitioning on simple architectures, 3) Evaluate energy/latency estimation accuracy against hardware simulators.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited validation to specific DIANA and Darkside SoC architectures, not tested on commercial SoCs
- Scalability concerns for very large DNNs with hundreds of layers
- No evaluation of robustness under input distribution shifts or adversarial examples

## Confidence
- Latency and energy improvements: High confidence based on systematic evaluation methodology
- Accuracy preservation (<0.3% loss): Medium confidence, limited to standard vision datasets
- Pareto-optimal solution generation: High confidence due to explicit multi-objective formulation

## Next Checks
1. Test ODiMO's optimization performance on commercially available multi-accelerator SoCs (e.g., NVIDIA Jetson, Google Edge TPUs)
2. Evaluate framework scalability by applying to large-scale models like BERT or ViT with 100+ layers
3. Assess robustness of optimized mappings under input distribution shifts and adversarial conditions beyond standard benchmark datasets