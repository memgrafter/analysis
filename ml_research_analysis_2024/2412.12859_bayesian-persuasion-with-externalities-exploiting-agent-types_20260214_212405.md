---
ver: rpa2
title: 'Bayesian Persuasion with Externalities: Exploiting Agent Types'
arxiv_id: '2412.12859'
source_url: https://arxiv.org/abs/2412.12859
tags:
- agents
- policy
- persuasion
- private
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies Bayesian persuasion with externalities, where
  a principal signals multiple agents about the world state while coordinating their
  actions. The main challenge is that classical revelation principle fails when agents
  can jointly deviate.
---

# Bayesian Persuasion with Externalities: Exploiting Agent Types

## Quick Facts
- arXiv ID: 2412.12859
- Source URL: https://arxiv.org/abs/2412.12859
- Authors: Jonathan Shaki; Jiarui Gan; Sarit Kraus
- Reference count: 22
- Primary result: Polynomial-time algorithms for optimal Bayesian persuasion with externalities when constant number of agents can jointly deviate; NP-hard otherwise

## Executive Summary
This paper studies Bayesian persuasion in settings with externalities where a principal signals multiple agents about the world state while coordinating their actions. The key challenge is that classical revelation principle fails when agents can jointly deviate, requiring a new framework based on blocking profiles. The authors introduce a novel approach where agents are categorized into types sharing identical utility functions, enabling polynomial-time algorithms for computing optimal signaling strategies when the maximum deviation size is constant. The work considers three signaling modes (public, private, semi-private) and introduces lottery policies to exploit symmetry among agents of the same type.

## Method Summary
The paper provides a framework for computing optimal Bayesian persuasion policies in multi-agent games with externalities. The approach involves parsing the problem instance, constructing blocking profile spaces based on the maximum deviation size d, building appropriate linear programming formulations for different signaling modes, solving these LPs, and validating stability using blocking profiles. For private persuasion, they introduce lottery policies that exploit symmetry among agents of the same type. The method achieves polynomial-time computation when d, the number of types, and the number of actions are all constants, but becomes NP-hard when d is part of the input.

## Key Results
- Classical revelation principle fails when agents can jointly deviate (d > 1)
- Polynomial-time algorithms exist for optimal persuasion when d, |T|, and |A| are constants
- NP-hardness result when d is part of the input
- Lottery policies enable tractable private persuasion by exploiting type symmetry
- Semi-private persuasion achieves intermediate expressiveness between public and private modes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The revelation principle fails when agents can jointly deviate because blocking profiles must encode joint deviation costs.
- Mechanism: The principal constructs signals that include both recommended actions and a blocking profile explaining why no profitable joint deviation exists. This replaces the classical IC constraint with a set of inequalities covering all possible deviations.
- Core assumption: Agents cannot communicate after receiving signals, and deviations are bounded by a constant d.
- Evidence anchors:
  - [abstract]: "We show that the classical revelation principle does not hold if agents can deviate jointly."
  - [section]: "The classical revelation principle does not hold any more when there are externalities and multiple agents can deviate together (i.e., d > 1)."
  - [corpus]: Found 25 related papers but none specifically address joint deviation in Bayesian persuasion with externalities. Weak evidence.
- Break condition: If d is part of the input (not constant), the blocking profile space becomes exponential and the problem becomes NP-hard.

### Mechanism 2
- Claim: Lottery policies enable polynomial-time computation of optimal private persuasion by exploiting symmetry among agents of the same type.
- Mechanism: Instead of directly designing private signals for each agent, the principal designs a policy and then applies a uniform random permutation among agents of the same type. This preserves stability while allowing use of representative action vectors.
- Core assumption: Agents of the same type are symmetric in their roles and utility functions.
- Evidence anchors:
  - [abstract]: "They introduce the concept of lottery policy by exploiting a symmetry in the agents' roles."
  - [section]: "Given a private policy σ, a lottery policy λ(σ) 'lotterizes' σ by uniformly randomizing the signals of σ among agents of the same type."
  - [corpus]: No direct corpus evidence found for lottery policies in persuasion. Assumption based on paper content.
- Break condition: If agents within a type have different utilities or the principal values different agents differently, the symmetry breaks and lottery policies no longer apply.

### Mechanism 3
- Claim: Semi-private persuasion achieves intermediate expressiveness between public and private by publicly revealing actions while keeping belief-shaping information private.
- Mechanism: The principal sends the recommended joint action publicly but keeps additional information private. This allows agents to see others' actions while still enabling belief manipulation through private channels.
- Core assumption: Agents can observe each other's actions but not their private information channels.
- Evidence anchors:
  - [abstract]: "Additionally, we also introduce a semi-private interaction framework where, while the principal publicly recommend joint actions for the agents, additional private information is used to further reshape the agents' beliefs."
  - [section]: "In semi-private persuasion, the joint action a in the principal's signal is sent publicly while g remains private."
  - [corpus]: Found 25 related papers but none specifically address semi-private persuasion. Weak evidence.
- Break condition: If agents can communicate about private information after receiving signals, the semi-private assumption fails and the model collapses to either public or private.

## Foundational Learning

- Concept: Action profiles and anonymity
  - Why needed here: The model uses action profiles to represent joint actions without identifying individual agents, which is essential for handling large numbers of agents efficiently.
  - Quick check question: Given a joint action a where agents of type T perform action a, what does ρa(T,a) represent?
- Concept: Blocking profiles
  - Why needed here: Blocking profiles are the key mechanism that replaces the classical IC constraint when agents can jointly deviate, explaining why deviations are not profitable.
  - Quick check question: What information must a blocking profile contain to ensure stability when d > 1?
- Concept: Representative action vectors
  - Why needed here: Representative action vectors reduce the exponentially large space of joint actions to a polynomial space in the public and semi-private cases.
  - Quick check question: Why can't we always restrict private persuasion to representative action vectors?

## Architecture Onboarding

- Component map: Input layer (Ω, µ, N, A, T, d) -> Signal space constructors (φpub, φsem, φprv) -> Optimization engine (LP formulations) -> Lottery policy wrapper (λ(·))
- Critical path:
  1. Parse problem instance and validate type partition
  2. Construct blocking profile space based on d, |T|, |A|
  3. Build appropriate LP (public/semi-private with representative vectors, private with lottery)
  4. Solve LP and extract policy
  5. Validate stability using blocking profiles
- Design tradeoffs:
  - Public vs. private: Public is simpler but less expressive; private can achieve higher utility but requires lottery policy for tractability
  - Constant d assumption: Enables polynomial algorithms but limits applicability to small deviation groups
  - Representative vectors: Work for public/semi-private but not private (counterexample exists)
- Failure signatures:
  - LP solver reports infeasibility: No stable policy exists for given instance
  - Exponential growth in blocking profile space: d is not constant, algorithm becomes intractable
  - Lottery policy produces unstable signals: Agent types are not truly symmetric
- First 3 experiments:
  1. Implement public persuasion LP for a 2-type, 3-action instance with d=1
  2. Verify that private persuasion with representative vectors fails on the provided counterexample
  3. Test lottery policy on a symmetric private instance to confirm it achieves optimal utility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the polynomial-time algorithm for private persuasion extend to cases where the number of agents within each type varies significantly?
- Basis in paper: [explicit] The paper mentions polynomial-time algorithms when d, |T|, and |A| are constants, but doesn't address varying agent numbers within types
- Why unresolved: The lottery policy technique exploits symmetry among agents of the same type, but this symmetry breaks down when agent counts within types differ substantially
- What evidence would resolve it: A computational analysis comparing performance on instances with uniform vs non-uniform type sizes, or a formal proof of computational complexity when type sizes vary

### Open Question 2
- Question: Can the revelation principle variants be extended to settings where agents can communicate with each other before making decisions?
- Basis in paper: [inferred] The paper explicitly states "we do not consider further communication between the agents" as a limitation of the current model
- Why unresolved: The current blocking profiles are designed assuming agents cannot coordinate beliefs or strategies beyond what's revealed in the principal's signals
- What evidence would resolve it: A theoretical framework that characterizes optimal policies when agents can engage in pre-decision communication, or computational experiments showing how communication changes optimal signaling strategies

### Open Question 3
- Question: How do the computational hardness results change when agents have incomplete information about the principal's information structure?
- Basis in paper: [inferred] The current model assumes agents know the prior distribution and signaling policy structure, but real-world agents often have uncertainty about these
- Why unresolved: The current hardness reductions assume complete information about the persuasion problem structure
- What evidence would resolve it: Hardness proofs or polynomial-time algorithms for persuasion problems with uncertain prior distributions or unknown signaling policies

## Limitations
- The constant d assumption is restrictive and limits applicability to scenarios with small deviation groups
- The framework assumes no communication between agents after receiving signals
- Reliance on type anonymity and symmetric utilities within types may not hold in many practical applications

## Confidence
- High Confidence: NP-hardness result for general d, polynomial-time algorithms for constant d cases, structural results about blocking profiles and representative action vectors
- Medium Confidence: Practical applicability given the restrictive constant d assumption and real-world scenarios involving post-signal communication
- Low Confidence: Effectiveness of semi-private persuasion in practice due to lack of empirical validation

## Next Checks
1. **Empirical Scaling Test**: Implement the LP formulations and measure how blocking profile space and solution time scale as d increases from 1 to 5 in small instances (e.g., 3 types, 3 actions). This would validate whether the constant-d assumption is practically restrictive.

2. **Symmetry Breaking Analysis**: Design a private persuasion instance where agents of the same type have slightly different utilities (breaking the lottery policy assumption) and verify that the lottery policy produces unstable results, demonstrating the fragility of the symmetry assumption.

3. **Semi-Private Persuasion Benchmark**: Compare semi-private persuasion performance against pure public and private approaches on a benchmark instance (e.g., coordination game with information externalities) to assess whether the intermediate expressiveness actually provides practical benefits over simpler alternatives.