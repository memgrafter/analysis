---
ver: rpa2
title: 'FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial
  Reasoning Problems?'
arxiv_id: '2402.02611'
source_url: https://arxiv.org/abs/2402.02611
tags:
- input
- board
- assert
- problem
- problems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies whether large language models (LLMs) can solve
  first-order combinatorial reasoning problems such as graph coloring, knapsack, and
  cryptarithmetic. These problems are NP-hard and require multiple reasoning steps,
  but can be instantiated with infinitely many instances of varying sizes.
---

# FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?

## Quick Facts
- arXiv ID: 2402.02611
- Source URL: https://arxiv.org/abs/2402.02611
- Reference count: 40
- Large language models struggle with first-order combinatorial reasoning; SymPro-LM significantly outperforms baselines

## Executive Summary
This paper investigates whether large language models can solve challenging first-order combinatorial reasoning problems, such as graph coloring, knapsack, and cryptarithmetic, which are NP-hard and require multi-step reasoning. The authors introduce FCoReBench, a benchmark of 40 such problems with scripts for generating and verifying instances. Initial experiments show that even state-of-the-art LLMs perform poorly, especially on larger instances. To address this, the authors propose SymPro-LM, a hybrid approach that combines LLMs with symbolic solvers and program interpreters, achieving significant performance improvements.

## Method Summary
The authors present FCoReBench, a dataset of 40 first-order combinatorial reasoning problems that can be instantiated with infinitely many examples of varying sizes. They evaluate standard LLM approaches using few-shot prompting, which perform poorly, particularly as problem size increases. To overcome these limitations, they propose SymPro-LM, which integrates LLMs with symbolic solvers and program interpreters during training. This hybrid model leverages feedback from successfully solved examples to improve reasoning capabilities. The approach does not require LLM calls during inference, relying instead on the trained symbolic components.

## Key Results
- SymPro-LM outperforms few-shot prompting by 21.61 percentage points on FCoReBench.
- SymPro-LM improves over PAL by 3.52 points and Logic-LM by 16.83 points.
- SymPro-LM is robust to changes in problem size and does not require LLM calls during inference.

## Why This Works (Mechanism)
SymPro-LM combines the strengths of LLMs with symbolic solvers and program interpreters. While LLMs provide general reasoning capabilities, symbolic solvers handle exact computation and constraint satisfaction. The integration allows the model to learn from solved examples and apply structured reasoning, avoiding the pitfalls of pure LLM-based approaches on NP-hard problems.

## Foundational Learning
- **First-order combinatorial reasoning**: Reasoning over problems defined by logical rules and constraints (e.g., graph coloring). Needed because NP-hard problems require multi-step, structured reasoning beyond pattern matching.
- **NP-hardness**: Problems for which no known polynomial-time algorithm exists. Important because it explains why pure LLM approaches fail and why hybrid methods are necessary.
- **Symbolic solvers**: Tools that solve logical or mathematical constraints exactly. Required to handle the combinatorial complexity and ensure correctness in reasoning tasks.
- **Program interpreters**: Components that execute or simulate programs to verify or generate solutions. Useful for integrating procedural logic into reasoning pipelines.
- **Few-shot prompting**: A technique where LLMs are given a few examples to learn a task. Insufficient here due to the complexity and variability of first-order combinatorial problems.

## Architecture Onboarding
- **Component map**: LLM -> Symbolic Solver/Program Interpreter -> Feedback Module -> LLM (training only)
- **Critical path**: Input problem → LLM (for initial reasoning) → Symbolic solver (for exact computation) → Feedback (from solved examples) → Updated reasoning (next iteration)
- **Design tradeoffs**: Hybrid approach trades inference-time LLM calls for training-time integration with symbolic components, improving accuracy but increasing training complexity.
- **Failure signatures**: Pure LLM approaches fail on larger instances and complex constraints; SymPro-LM may still struggle with noisy or ambiguous real-world data.
- **First experiments**: 1) Evaluate SymPro-LM on a small subset of FCoReBench problems. 2) Test performance as problem size increases. 3) Compare against pure LLM baselines on logic and reasoning benchmarks.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is limited to synthetically generated instances; real-world applicability is untested.
- Dependence on symbolic solvers and program interpreters during training may limit scalability and increase deployment costs.
- Performance drops for larger instances even with SymPro-LM suggest incomplete generalization.
- The feedback mechanism does not address how the system handles unsolvable or ambiguous instances.

## Confidence
- **High confidence**: The empirical results showing SymPro-LM outperforming baselines (21.61 points over few-shot, 3.52 over PAL, 16.83 over Logic-LM) are well-supported by the data presented.
- **Medium confidence**: The claim that SymPro-LM is "robust to changes in problem size" is supported but requires more extensive testing across diverse problem families and larger instance sizes.
- **Medium confidence**: The assertion that SymPro-LM "does not require LLM calls during inference" is technically accurate but may underestimate the computational overhead of the symbolic components during deployment.

## Next Checks
1. Test SymPro-LM on real-world combinatorial problems with noisy or incomplete constraints to assess practical robustness.
2. Evaluate performance across a broader range of problem sizes, including significantly larger instances than those in the current benchmark.
3. Conduct a cost-benefit analysis comparing inference-time computational requirements of SymPro-LM versus pure LLM approaches to quantify practical deployment implications.