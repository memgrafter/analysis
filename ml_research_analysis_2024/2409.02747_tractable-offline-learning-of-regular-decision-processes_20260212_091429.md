---
ver: rpa2
title: Tractable Offline Learning of Regular Decision Processes
arxiv_id: '2409.02747'
source_url: https://arxiv.org/abs/2409.02747
tags:
- learning
- probability
- state
- reinforcement
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of offline reinforcement learning
  in Regular Decision Processes (RDPs), which are non-Markovian decision processes
  where future observations and rewards depend on past interactions. The authors propose
  two techniques to overcome limitations of previous RDP learning algorithms: a new
  language-based pseudometric for state distinction and the use of Count-Min-Sketch
  for efficient probability distribution representation.'
---

# Tractable Offline Learning of Regular Decision Processes

## Quick Facts
- arXiv ID: 2409.02747
- Source URL: https://arxiv.org/abs/2409.02747
- Reference count: 40
- One-line primary result: Two techniques (language-based pseudometric and Count-Min-Sketch) improve RDP learning sample efficiency and memory usage

## Executive Summary
This paper addresses the problem of offline reinforcement learning in Regular Decision Processes (RDPs), which are non-Markovian decision processes where future observations and rewards depend on past interactions. The authors propose two techniques to overcome limitations of previous RDP learning algorithms: a new language-based pseudometric for state distinction and the use of Count-Min-Sketch for efficient probability distribution representation. The language-based approach removes dependence on problematic Lp∞-distinguishability parameters and is exponentially more sample-efficient in low-complexity domains. Experiments on various domains show that the language-restricted approach learns smaller automata and achieves near-optimal or optimal policies, outperforming both standard methods and FlexFringe in several cases. The CMS approach, while theoretically sound, suffers from high computational costs.

## Method Summary
The paper proposes two main techniques to improve RDP learning: (1) a language-based pseudometric LX that replaces the problematic Lp∞-distinguishability parameters, allowing exponential sample complexity improvements in low-complexity domains by decomposing observations into features and considering distributions over structured strings; and (2) Count-Min-Sketch (CMS) for compact representation of probability distributions over suffixes, reducing memory requirements for long planning horizons from exponential to near-linear. The authors modify the ADACT-H algorithm to incorporate these techniques, with the language-restricted variant focusing on smaller language families for efficiency and the CMS variant maintaining PAC guarantees while using approximate counting.

## Key Results
- Language-restricted approach learns smaller automata than both standard methods and FlexFringe
- Both proposed methods achieve near-optimal or optimal policies in tested domains
- CMS approach suffers from high computational costs despite memory savings
- Language-based metric removes exponential dependencies on horizon length in low-complexity domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language-based pseudometric LX removes dependence on problematic Lp∞-distinguishability parameters and is exponentially more sample-efficient in low-complexity domains.
- Mechanism: Instead of treating each action-observation-reward tuple as atomic, the algorithm decomposes observations into features and considers distributions over structured strings (languages). This allows capturing conditions like "presence of a reward" directly via language patterns, bypassing exponential dependencies on horizon length.
- Core assumption: The underlying RDP has low complexity in language-theoretic terms (i.e., the distinguishing sets X can be expressed with small language families).
- Evidence anchors:
  - [abstract] "development of a new pseudometric based on formal languages, which removes a problematic dependency on Lp∞-distinguishability parameters"
  - [section 4.1] Example 3 explains how in T-maze, LX avoids exponential decay by focusing on observation presence rather than exact path probabilities
  - [corpus] Weak/absent: no direct citations supporting this specific language metric claim
- Break condition: If the RDP complexity is high (large language families needed), the sample complexity gains disappear.

### Mechanism 2
- Claim: Count-Min-Sketch (CMS) reduces memory requirements for long planning horizons by compactly representing large probability distributions.
- Mechanism: CMS stores approximate counts of suffixes in a d×w matrix using hash functions, allowing O(1) updates and queries with bounded error. This replaces explicit storage of all suffix probabilities, which is exponential in horizon.
- Core assumption: The number of distinct suffixes encountered is large, making explicit storage infeasible, but approximate representation suffices for statistical tests.
- Evidence anchors:
  - [abstract] "adoption of Count-Min-Sketch (CMS), instead of naive counting... alleviates the memory requirements for long planning horizons"
  - [section 4.2] Theorem 1 shows CMS can be used while maintaining PAC guarantees
  - [corpus] Weak/absent: no corpus citations directly supporting CMS application in RDP learning
- Break condition: If hash collisions become frequent or the error tolerance is too tight, CMS accuracy degrades.

### Mechanism 3
- Claim: Fine-grained observation decomposition into features simplifies representation of common conditions and reduces state space.
- Mechanism: Observations O = O(1) × ... × O(m) are treated as concatenated feature strings rather than atomic symbols. This allows patterns like matching single features (G1) or combinations (Gm+2) to be tested efficiently.
- Core assumption: The problem structure can be naturally expressed via feature-level conditions rather than full observation sequences.
- Evidence anchors:
  - [section 4.1] "fine-grained representation greatly simplifies the representation of most common conditions, such as the presence of specific rewards or features"
  - [example 3] Shows how feature-level patterns avoid exponential distinguishability issues
  - [corpus] Weak/absent: no direct corpus support for this specific feature decomposition claim
- Break condition: If features are not meaningful or observations are already atomic, decomposition provides no benefit.

## Foundational Learning

- Concept: Formal languages and operators (concatenation, Cℓk, B)
  - Why needed here: The language-based approach relies on constructing sets of languages to define metrics for comparing RDP states. Understanding these operators is essential for grasping how the hierarchy Xi,j,k works.
  - Quick check question: Given G1 = {a/R | a∈A} ∪ {AO/r | r∈R} ∪ {AO(1)...o(i)...O(m)/R | i∈[m]}, what languages are in G2 = G1 ∪ B(G1)?

- Concept: Count-Min-Sketch data structure and error bounds
  - Why needed here: CMS is the core memory-efficient mechanism. Understanding its guarantees (never underestimates, bounded overestimates) is crucial for trusting the statistical tests.
  - Quick check question: If CMS parameters are δc=0.01 and ε=0.1, what is the maximum overestimate factor for any count?

- Concept: Lp norms and prefix distances
  - Why needed here: The paper contrasts Lp∞ with Lp1 and the new language metric LX. Understanding these metrics is essential for grasping the distinguishability problem being solved.
  - Quick check question: For two distributions over strings of length 3, if they differ only on suffixes of length 2, which metric (Lp∞, Lp1, or LX) would detect this difference with the smallest sample complexity?

## Architecture Onboarding

- Component map:
  - Input: Dataset D of episodes, accuracy ε, failure probability δ
  - Core: ADACT-H algorithm with two variants (CMS-based, language-restricted)
  - Output: RDP automaton (Q, τ) and derived policy
  - Supporting: Count-Min-Sketch implementation, language metric computation, statistical tests

- Critical path:
  1. Initialize Q0 with start state and suffixes from all episodes
  2. For each timestep t, generate candidate states Qc,t+1
  3. For each candidate, compute suffixes Z(qao) and perform statistical test
  4. Promote or merge based on test result (using either CMS or LX metric)
  5. Return learned RDP

- Design tradeoffs:
  - CMS vs explicit storage: CMS saves memory but adds approximation error; explicit storage is exact but infeasible for long horizons
  - Language hierarchy levels: Lower levels (G1) are efficient but may miss distinctions; higher levels (Gm+2) are complete but exponential in features
  - Metric choice: Lp∞ is efficient to estimate but can have exponential distinguishability decay; LX trades estimation efficiency for better distinguishability

- Failure signatures:
  - CMS variant: Slow performance despite memory savings (CMS still iterates over all suffixes)
  - Language variant: Larger automata than expected (language family not expressive enough)
  - Both: Suboptimal policies (statistical tests too conservative or not distinguishing enough)

- First 3 experiments:
  1. Implement CMS-based statistical test on toy RDP (e.g., corridor with H=3) and verify memory usage vs explicit storage
  2. Implement language metric LX with X1,1,1 on same toy RDP and compare state counts vs Lp∞
  3. Run both variants on T-maze with restricted actions and verify optimal policy recovery

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the language-based pseudometric (LX) approach scale effectively to larger, more complex RDP domains beyond the tested examples?
- Basis in paper: [explicit] The paper states "This can be accomplished via the introduction of two original techniques: the development of a new pseudometric based on formal languages" and shows experimental results on five domains.
- Why unresolved: The experiments only tested on five relatively small domains (Corridor, T-maze, Cookie, Cheese, Mini-hall). The paper doesn't provide evidence of scalability to larger or more complex RDPs.
- What evidence would resolve it: Experiments on larger RDP domains with more states, observations, and longer horizons would demonstrate scalability. A theoretical analysis of the computational complexity as a function of domain parameters would also help.

### Open Question 2
- Question: How does the Count-Min-Sketch (CMS) approach compare to other space-efficient data structures for probability distribution representation in RDP learning?
- Basis in paper: [explicit] "the adoption of Count-Min-Sketch (CMS), instead of naive counting" and "CMS compactly represents a large non-negative vector v"
- Why unresolved: The paper only compares CMS to naive counting, not to other potential space-efficient alternatives. The experimental results show CMS suffers from high computational costs.
- What evidence would resolve it: A comparison of CMS to other space-efficient data structures (e.g., Bloom filters, HyperLogLog) in terms of memory usage, computational efficiency, and learning performance on RDP domains would provide insight into whether CMS is the optimal choice.

### Open Question 3
- Question: What is the relationship between the choice of language family (Xi,j,k) and the sample complexity and performance of the RDP learning algorithm?
- Basis in paper: [explicit] "we define a hierarchy of sets of languages of increasing complexity" and "The family Xi,j,k induces a family of language metrics LXi,j,k, which are non-decreasing along the dimensions of the hierarchy"
- Why unresolved: The paper only tests the X1,1,1 language family in experiments and mentions the hierarchy theoretically. It doesn't explore how different choices of (i,j,k) affect learning performance or sample complexity.
- What evidence would resolve it: Experiments comparing the performance of the RDP learning algorithm using different language families (Xi,j,k) for various (i,j,k) values would reveal the impact of this choice on sample complexity and learning quality.

## Limitations
- The CMS approach suffers from high computational costs despite memory savings
- Language-restricted approach may not distinguish states effectively if X set is too restrictive
- Theoretical guarantees rely on assumptions about RDP complexity that may not hold in practice

## Confidence

- **High confidence**: The basic framework of RDP learning and the statistical test methodology
- **Medium confidence**: The language metric LX's ability to improve distinguishability in practice
- **Low confidence**: The practical viability of CMS approach given its computational costs

## Next Checks

1. Implement the CMS variant on a toy RDP with H=5 and measure actual memory usage versus theoretical predictions, comparing against explicit storage baseline
2. Create a synthetic RDP where the language metric LX with X1,1,1 clearly fails to distinguish states that Lp∞ would distinguish, demonstrating the tradeoff between metrics
3. Run both approaches (CMS and language-restricted) on the Corridor domain with varying horizon lengths to quantify the computational cost scaling and identify the break-even point where memory savings justify the overhead