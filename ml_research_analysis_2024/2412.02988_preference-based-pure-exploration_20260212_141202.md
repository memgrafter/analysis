---
ver: rpa2
title: Preference-based Pure Exploration
arxiv_id: '2412.02988'
source_url: https://arxiv.org/abs/2412.02988
tags:
- pareto
- bound
- lower
- should
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies preference-based pure exploration in multi-armed
  bandits with vector-valued rewards, where the goal is to identify the set of Pareto
  optimal arms given a preference cone. The authors derive a novel lower bound on
  sample complexity that explicitly captures the impact of the preference cone's geometry
  and extends classical best-arm identification bounds.
---

# Preference-based Pure Exploration

## Quick Facts
- arXiv ID: 2412.02988
- Source URL: https://arxiv.org/abs/2412.02988
- Authors: Apurv Shukla; Debabrota Basu
- Reference count: 40
- Key outcome: Novel lower bound on sample complexity for preference-based pure exploration in multi-armed bandits with vector-valued rewards, and asymptotically optimal PreTS algorithm

## Executive Summary
This paper studies preference-based pure exploration in multi-armed bandits where arms produce vector-valued rewards and the goal is to identify the Pareto optimal set under a given preference cone. The authors derive a novel lower bound on sample complexity that captures the geometry of the preference cone and extends classical best-arm identification bounds. They propose the Preference-based Track-and-Stop (PreTS) algorithm that achieves asymptotically optimal sample complexity by tracking a convexified version of this lower bound. For Gaussian rewards, they characterize how the lower bound depends on a bilinear projection of mean rewards onto the cone and policy gaps.

## Method Summary
The paper addresses preference-based pure exploration in multi-armed bandits with vector-valued rewards by deriving a lower bound on sample complexity and designing the PreTS algorithm. The method involves: (1) deriving a lower bound on sample complexity that explicitly captures the preference cone's geometry, (2) providing a convex relaxation of this non-convex bound using disjunctive programming, and (3) implementing a Track-and-Stop algorithm that tracks this convexified lower bound. The algorithm uses empirical mean estimates, a track-and-stop sampling rule, and a stopping criterion based on KL-divergence confidence bounds. The method is validated through theoretical analysis showing asymptotic optimality and a new concentration inequality for vector-valued rewards.

## Key Results
- Novel lower bound on sample complexity that captures preference cone geometry
- Preference-based Track-and-Stop (PreTS) algorithm achieving asymptotic optimality
- New concentration inequality for vector-valued rewards with preference projections
- Introduction of a distance metric dP between Pareto fronts ensuring reliable identification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PreTS achieves asymptotically optimal sample complexity by tracking a convexified lower bound
- Mechanism: The algorithm repeatedly samples arms according to an allocation policy derived from a convex relaxation of the non-convex alternating set, using empirical estimates of mean rewards. When the stopping condition based on KL-divergence concentration is met, it returns the estimated Pareto front.
- Core assumption: The convexification doesn't significantly increase the characteristic time, and empirical estimates converge to true means
- Evidence: Abstract states "They provide a convex relaxation of this non-convex bound and use it to design the Preference-based Track and Stop (PreTS) algorithm"
- Break condition: If convex relaxation significantly overestimates true characteristic time, sample complexity will be suboptimal

### Mechanism 2
- Claim: Distance metric dP ensures reliable Pareto front identification with high probability
- Mechanism: dP is defined as the maximum distance from each arm in one front to the other, where distance is the minimum epsilon such that an arm's mean plus epsilon times all-ones vector is not weakly dominated by any arm in the front. This metric induces convergence of estimated front to true front.
- Core assumption: dP is a valid metric and the space of Pareto fronts is complete under this metric
- Evidence: Section establishes "d(·, ·) is a valid metric on Z, and Z is compact and complete under d(·, ·)"
- Break condition: If distance metric isn't valid or space isn't complete, convergence argument fails

### Mechanism 3
- Claim: KL-divergence concentration bound with preference projections ensures high-probability stopping
- Mechanism: A new concentration inequality is proved for the sum of KL-divergences between empirical estimates of preference-projected mean rewards and true mean rewards. This ensures the true instance belongs to the confidence ellipsoid with high probability.
- Core assumption: Noise vectors are sub-Gaussian with parameter sigma and adapted to filtration Ft
- Evidence: Theorem 4.3 provides probability bounds for KL divergence exceeding threshold
- Break condition: If noise vectors aren't sub-Gaussian or not adapted to filtration, concentration bound may not hold

## Foundational Learning

- Concept: Multi-armed bandits with vector-valued rewards and preference cones
  - Why needed: Problem setting involves identifying Pareto optimal arms in multi-armed bandit with vector-valued rewards ordered using a preference cone
  - Quick check: What's the difference between scalar-valued and vector-valued rewards in multi-armed bandits?

- Concept: Pure exploration and best arm identification
  - Why needed: Goal is to identify set of Pareto optimal arms with confidence level, which is pure exploration problem building on best arm identification techniques
  - Quick check: What's the difference between pure exploration and regret minimization in multi-armed bandits?

- Concept: Convex relaxation and disjunctive programming
  - Why needed: Alternating set in lower bound is non-convex, requiring convex relaxation for tractable optimization; disjunctive programming formulates the convex relaxation
  - Quick check: What's the difference between convex and non-convex optimization problems, and why is convexity desirable?

## Architecture Onboarding

- Component map: Empirical mean calculation -> Convex relaxation optimization -> Track-and-stop sampling -> KL-divergence stopping check -> Pareto front construction
- Critical path: 1) Initialize empirical estimates of mean rewards, 2) Compute allocation policy from convexified lower bound, 3) Sample arms according to allocation policy and update estimates, 4) Check KL-divergence stopping condition, 5) If met, construct and return estimated Pareto front, 6) If not, return to step 2
- Design tradeoffs: Convexification makes optimization tractable but may overestimate true characteristic time; KL-divergence bound provides high-probability guarantees but may be conservative; preference cone geometry affects problem hardness and sample complexity
- Failure signatures: Algorithm takes too long to converge (loose convexification or conservative concentration bound); algorithm returns incorrect Pareto front (non-converged empirical estimates or weak stopping condition); algorithm is computationally expensive (challenging optimization or large number of arms/objectives)
- First 3 experiments: 1) Verify algorithm returns correct Pareto front on small instance with known means and preferences, 2) Compare sample complexity to theoretical lower bound on larger instance, 3) Test sensitivity to different preference cone geometries and reward distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does sample complexity of PreTS scale with dimensionality L of reward vectors?
- Basis: Paper derives lower bound depending on covariance matrix Σ and discusses how lower bound inflates with covariance matrix for each objective
- Why unresolved: Paper provides insights on covariance matrix impact but doesn't explicitly characterize scaling with L
- Resolution: Formal analysis of sample complexity as function of L, including upper and lower bounds

### Open Question 2
- Question: How does choice of preference cone C impact PreTS performance?
- Basis: Paper discusses geometry of preference cone's role in determining Pareto front and problem hardness
- Why unresolved: Paper provides insights on preference cone impact on hardness but doesn't characterize performance under different C choices
- Resolution: Comprehensive study comparing PreTS performance under different preference cones with theoretical analysis and empirical experiments

### Open Question 3
- Question: How does PreTS compare to other preference-based pure exploration algorithms?
- Basis: Paper focuses on designing PreTS and proving asymptotic optimality without comparing to other algorithms
- Why unresolved: While establishing theoretical properties of PreTS, paper doesn't provide comprehensive comparison to other algorithms
- Resolution: Thorough empirical evaluation comparing PreTS to other algorithms including elimination-based and gap-based approaches

## Limitations

- Convex relaxation of non-convex alternating set may introduce conservatism in sample complexity guarantees
- Concentration inequality assumes sub-Gaussian noise and specific KL-divergence projections, limiting applicability to all noise distributions
- Distance metric dP requires careful implementation for numerical stability in practice
- Known covariance matrices assumption limits real-world applicability where this information must be estimated

## Confidence

- **High confidence**: Tracking convexified lower bound for allocation policy - follows established track-and-stop methodology with well-understood theoretical foundations
- **Medium confidence**: Validity and completeness of Pareto front distance metric dP - theoretical proof provided but requires careful implementation verification
- **Medium confidence**: KL-divergence concentration bound with preference projections - proof is technically involved and assumes specific noise properties that may not hold universally

## Next Checks

1. **Implementation verification**: Implement the convex relaxation optimization problem explicitly and test on small instances to verify numerical solution matches theoretical expectations for allocation policy
2. **Distance metric validation**: Create series of bandit instances with known Pareto fronts and verify dP correctly measures distance between fronts, including edge cases with different cardinalities
3. **Robustness testing**: Evaluate PreTS performance under misspecified covariance matrices and non-sub-Gaussian noise distributions to assess sensitivity to paper's assumptions