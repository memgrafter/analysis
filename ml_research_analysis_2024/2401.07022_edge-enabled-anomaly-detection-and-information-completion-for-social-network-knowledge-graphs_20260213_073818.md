---
ver: rpa2
title: Edge-Enabled Anomaly Detection and Information Completion for Social Network
  Knowledge Graphs
arxiv_id: '2401.07022'
source_url: https://arxiv.org/abs/2401.07022
tags:
- data
- knowledge
- information
- graph
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of real-time anomaly detection
  and information completion in social network knowledge graphs for public safety,
  using edge computing to overcome latency and privacy concerns. It proposes a lightweight
  distributed architecture combining knowledge graph embedding (KGE) with edge deployment.
---

# Edge-Enabled Anomaly Detection and Information Completion for Social Network Knowledge Graphs

## Quick Facts
- arXiv ID: 2401.07022
- Source URL: https://arxiv.org/abs/2401.07022
- Reference count: 40
- This paper proposes a lightweight distributed architecture combining knowledge graph embedding with edge deployment for real-time anomaly detection in social networks

## Executive Summary
This paper addresses the challenge of real-time anomaly detection and information completion in social network knowledge graphs for public safety, using edge computing to overcome latency and privacy concerns. The authors construct a personnel relations knowledge graph from public security data, develop a PDQA method for data quality assessment, and introduce a model pruning algorithm to reduce model size. The RotatE model achieves 86.97% hits@10 performance and can be pruned by 70% while maintaining accuracy, enabling deployment on resource-constrained edge devices like the Jetson Nano.

## Method Summary
The method combines knowledge graph embedding (KGE) with edge deployment to enable real-time anomaly detection while preserving data privacy. A personnel relations knowledge graph is constructed from public security data and cleaned using the PDQA (Personnel Data Quality Assessment) method. The RotatE KGE model is trained centrally, then pruned using a sensitivity-based algorithm to reduce computational requirements. The pruned model is deployed on edge devices for local inference, enabling anomaly detection and information completion without transmitting sensitive data to cloud servers.

## Key Results
- RotatE model achieves 86.97% hits@10 performance, outperforming 11 other KGE models
- Model pruning achieves 70% size reduction while maintaining 86.97% hits@10 performance
- Successfully deployed pruned model on Jetson Nano edge device demonstrating edge feasibility
- PDQA method effectively filters anomalous data, improving downstream KGE performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The combination of knowledge graph embedding (KGE) with edge deployment enables real-time anomaly detection while preserving data privacy.
- Mechanism: KGE models are trained centrally on comprehensive social network data to capture latent relations. Once trained, the pruned model is deployed to edge devices, allowing local inference without transmitting sensitive data to cloud servers. This avoids latency from data transmission and reduces privacy risks.
- Core assumption: The pruned model retains sufficient accuracy for effective anomaly detection after model compression.
- Evidence anchors:
  - [abstract]: "Experimental results show that the RotatE model outperforms 11 other KGE models... and after pruning achieves a 70% size reduction while maintaining 86.97% hits@10 performance. The pruned model is successfully deployed on a Jetson Nano edge device."
  - [section]: "The pruned model is deployed on the edge device Jetson Nano... Processing data at the edge ensures real-time capabilities while, to a certain extent, safeguarding data privacy and security."
- Break condition: If model pruning causes accuracy to drop below a usable threshold, real-time anomaly detection performance would degrade significantly.

### Mechanism 2
- Claim: The PDQA method effectively filters anomalous data before model training, improving downstream KGE performance.
- Mechanism: PDQA uses trained KGE embeddings to compute confidence scores for test data. Data with z-score < -1 are flagged as problematic and removed or corrected manually, ensuring cleaner training data for the KGE model.
- Core assumption: Anomalous data can be identified reliably using confidence scores derived from KGE embeddings.
- Evidence anchors:
  - [section]: "To detect existing anomalous data and reduce the cost of manual screening, this paper introduces a data quality assessment method called PDQA... The algorithm aims to assess the quality of existing data while also verifying the compliance of future input data."
  - [section]: "After standardization, data with z-score values less than -1 are considered problematic and should be reported for further investigation and manual confirmation."
- Break condition: If PDQA incorrectly flags valid data as anomalous or misses actual anomalies, model training could be compromised or false positives could increase.

### Mechanism 3
- Claim: Model pruning based on parameter sensitivity preserves model accuracy while significantly reducing computational requirements for edge deployment.
- Mechanism: The pruning algorithm calculates parameter gradients to determine sensitivity. Parameters with low sensitivity (below threshold) are removed. The pruned model is then fine-tuned to recover lost accuracy. This reduces model size by 70% while maintaining 86.97% hits@10.
- Core assumption: Parameters with low gradients contribute minimally to model performance and can be removed without significant accuracy loss.
- Evidence anchors:
  - [section]: "In the model pruning algorithm proposed in this paper, the process begins by loading the pre-trained model. Subsequently, the sensitivity of each parameter is computed using the validation set, where sensitivity is measured by the gradient of the parameters... A larger absolute gradient indicates a greater impact of the parameter on the model's performance."
  - [section]: "When the pruning ratio reaches 67% and the storage volume decreases by 70%, the accuracy of the pruned model sharply decreases. This drop is much more significant than the previous decrease, indicating that the pruning ratio is approaching its maximum limit."
- Break condition: If the sensitivity threshold is set too aggressively, important parameters may be removed, causing significant accuracy degradation that fine-tuning cannot recover.

## Foundational Learning

- Concept: Knowledge Graph Embeddings (KGE)
  - Why needed here: KGE transforms entities and relations in the social network knowledge graph into vector representations that can be used for inference, anomaly detection, and information completion.
  - Quick check question: What is the primary purpose of using KGE in this social network analysis context?

- Concept: Edge Computing vs Cloud Computing
  - Why needed here: Edge computing processes data near the source, reducing latency and privacy risks compared to cloud computing where data must be transmitted to remote servers.
  - Quick check question: What are the two main advantages of edge deployment for this public safety application?

- Concept: Model Pruning and Sensitivity Analysis
  - Why needed here: Model pruning reduces the computational and storage requirements of the KGE model to make it deployable on resource-constrained edge devices like the Jetson Nano.
  - Quick check question: How does the pruning algorithm determine which parameters to remove from the model?

## Architecture Onboarding

- Component map:
  - Data Layer: Raw personnel data → PDQA cleaning → Knowledge Graph construction (Neo4j)
  - Model Layer: KGE training (DGL-KE, PyTorch) → Model pruning → Fine-tuning
  - Edge Layer: Pruned model deployment on Jetson Nano → Local inference → Anomaly detection and information completion

- Critical path: Data cleaning → Knowledge graph construction → KGE model training → Model pruning → Edge deployment → Real-time inference

- Design tradeoffs:
  - Model accuracy vs. edge deployment feasibility: Aggressive pruning reduces size but may compromise accuracy
  - Data privacy vs. model performance: Edge deployment improves privacy but may limit access to larger training datasets
  - Real-time processing vs. computational resources: Jetson Nano has limited resources requiring careful model optimization

- Failure signatures:
  - High false positive rate in anomaly detection → Check PDQA filtering and KGE model quality
  - Excessive latency in edge inference → Verify model pruning didn't remove critical parameters
  - Memory overflow on Jetson Nano → Model is still too large; need additional pruning or optimization

- First 3 experiments:
  1. Test PDQA filtering on a small dataset with known anomalies to verify it correctly identifies problematic data
  2. Compare KGE model performance (hits@10, AMRI) before and after pruning with different sensitivity thresholds
  3. Deploy the pruned model on Jetson Nano and measure inference latency and memory usage with sample queries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model pruning threshold affect long-term model performance when deployed in dynamic social network environments with evolving relation patterns?
- Basis in paper: [explicit] The paper discusses pruning ratios up to 67% with performance trade-offs, but doesn't examine dynamic data scenarios.
- Why unresolved: The experiments focus on static knowledge graph completion without testing adaptation to changing social network dynamics.
- What evidence would resolve it: Longitudinal studies comparing pruned model performance on datasets with temporal changes in social relations.

### Open Question 2
- Question: What is the optimal balance between edge device computational constraints and knowledge graph embedding accuracy for different deployment scenarios?
- Basis in paper: [explicit] The paper successfully deploys on Jetson Nano but doesn't explore different edge hardware configurations or use cases.
- Why unresolved: Only one edge device configuration is tested, limiting understanding of performance tradeoffs across different hardware capabilities.
- What evidence would resolve it: Comparative experiments across multiple edge devices with varying computational resources and latency requirements.

### Open Question 3
- Question: How does the PDQA method's performance compare to alternative anomaly detection approaches when dealing with adversarial data manipulation?
- Basis in paper: [explicit] The PDQA method is introduced for data quality assessment but not benchmarked against other anomaly detection methods.
- Why unresolved: The paper presents PDQA as novel but doesn't establish its relative effectiveness compared to established anomaly detection techniques.
- What evidence would resolve it: Head-to-head comparison of PDQA with other anomaly detection methods on datasets containing known adversarial patterns.

## Limitations

- Limited validation details on runtime performance metrics on the Jetson Nano device
- PDQA method effectiveness only demonstrated through comparison with TransE model on a single test dataset
- Model pruning relies on a sensitivity threshold that may not generalize to different knowledge graph domains

## Confidence

- High confidence in KGE model selection and comparative performance (HITS@10 reaching 86.97% for RotatE)
- Medium confidence in PDQA filtering effectiveness and edge deployment feasibility
- Low confidence in the generalizability of the pruning threshold and long-term edge inference performance

## Next Checks

1. Deploy the pruned RotatE model on Jetson Nano with actual inference workload measurements including latency, throughput, and memory usage under varying query loads to verify real-time performance claims.

2. Validate PDQA filtering across multiple KGE models (not just TransE) to ensure the filtering method doesn't introduce bias or remove critical data patterns that different models might capture.

3. Test model pruning with different sensitivity thresholds and knowledge graph datasets to establish the robustness and generalizability of the pruning algorithm across domains.