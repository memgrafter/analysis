---
ver: rpa2
title: 'TIGER: Temporally Improved Graph Entity Linker'
arxiv_id: '2410.09128'
source_url: https://arxiv.org/abs/2410.09128
tags:
- entity
- entities
- graph
- dataset
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TIGER addresses temporal degradation in entity linking, where model
  performance decreases as knowledge graphs evolve over time. The approach integrates
  graph-based structural information (entity relationships) with text-based information
  (entity descriptions and mention contexts) using a shared and distinct convolution
  module to learn both common and unique entity features.
---

# TIGER: Temporally Improved Graph Entity Linker

## Quick Facts
- arXiv ID: 2410.09128
- Source URL: https://arxiv.org/abs/2410.09128
- Authors: Pengyu Zhang; Congfeng Cao; Paul Groth
- Reference count: 40
- Primary result: 16-21% improvement over state-of-the-art on temporal entity linking

## Executive Summary
TIGER addresses a critical challenge in entity linking where model performance degrades as knowledge graphs evolve over time. Traditional entity linking systems assume static knowledge graphs, but in reality, these graphs continuously update with new entities and relationships. TIGER introduces a novel approach that combines graph-based structural information with text-based context through shared and distinct convolution modules, enabling the model to learn both common and unique features across different entity representations. The method specifically targets the temporal degradation problem by incorporating time-sensitive information into the linking process.

## Method Summary
TIGER employs a dual-information fusion approach that integrates graph-based structural relationships between entities with text-based descriptions and mention contexts. The model uses a shared and distinct convolution module architecture that allows learning of both common features across entity types and unique characteristics specific to each representation. This hybrid approach enables the system to handle ambiguous entity mentions and adapt to evolving knowledge graphs by capturing temporal dynamics in entity relationships and descriptions. The architecture is designed to be flexible enough to incorporate updates to the knowledge graph while maintaining robust performance across different time periods.

## Key Results
- Achieves 16.24% improvement over state-of-the-art when time gap is one year
- Achieves 20.93% improvement when time gap expands to three years
- Demonstrates particular effectiveness for ambiguous and temporally-sensitive entity linking tasks

## Why This Works (Mechanism)
The mechanism works by addressing the fundamental mismatch between static entity linking models and dynamic knowledge graphs. By combining graph-based structural information (relationships between entities) with text-based information (descriptions and mention contexts), TIGER creates a more robust representation that can adapt to temporal changes. The shared and distinct convolution modules allow the model to learn both universal entity features that apply across time periods and time-specific characteristics that capture evolving relationships and descriptions.

## Foundational Learning
1. **Temporal Entity Linking**: Understanding how entity linking performance degrades over time as knowledge graphs evolve - needed because most models assume static knowledge bases, quick check: knowledge graph update frequency
2. **Graph Neural Networks**: Basic understanding of how structural relationships between entities can be encoded - needed because TIGER uses graph-based information, quick check: adjacency matrix representation
3. **Convolutional Neural Networks**: Understanding how spatial hierarchies in data can be learned - needed for the shared and distinct convolution modules, quick check: filter operations
4. **Knowledge Graph Embeddings**: How entities and relationships can be represented in continuous vector spaces - needed for combining graph and text information, quick check: entity embedding dimensions
5. **Temporal Dynamics in NLP**: How language and entity references change over time - needed for understanding the degradation problem, quick check: temporal drift metrics
6. **Entity Ambiguity Resolution**: How to distinguish between entities with similar names or contexts - needed for handling ambiguous mentions, quick check: disambiguation accuracy metrics

## Architecture Onboarding

**Component Map**: Text Context -> Text Encoder -> Shared Conv -> Distinct Conv -> Graph Structure -> Graph Encoder -> Feature Fusion -> Entity Linking

**Critical Path**: Mention Context -> Text Encoder -> Shared Convolution -> Feature Fusion -> Candidate Selection -> Entity Linking

**Design Tradeoffs**: The model trades computational complexity for improved temporal adaptability. Using both shared and distinct convolution modules increases model capacity but requires more training data and computation. The graph-based approach requires complete relationship information, which may not always be available.

**Failure Signatures**: Performance degradation occurs when knowledge graph updates are too frequent, when entity relationships are incomplete or noisy, or when mention contexts are too short to provide meaningful text features. The model may also struggle with entities that have very few relationships in the graph.

**First 3 Experiments to Run**:
1. Evaluate performance degradation on Graph-TempEL dataset with time gaps of 1, 2, and 3 years to verify the claimed improvements
2. Conduct ablation study removing the graph-based component to measure its contribution to overall performance
3. Test on entities with varying relationship densities to assess robustness to incomplete knowledge graphs

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation based solely on the Graph-TempEL dataset without external validation on other temporal entity linking benchmarks
- Architecture relies on entity relationship information that may not be available or complete in all knowledge graphs
- Computational efficiency and scalability for large-scale knowledge graphs not addressed

## Confidence
- Performance improvement claim (16-21%): Medium confidence - based on single dataset, no ablation studies provided
- Effectiveness for ambiguous entities: High confidence - directly addresses model's design focus
- Shared/distinct convolution mechanism: Medium confidence - architectural details provided but specific contributions not quantified

## Next Checks
1. Evaluate TIGER on additional temporal entity linking benchmarks beyond Graph-TempEL to assess generalizability across different domains and time periods
2. Conduct ablation studies to quantify the contribution of shared vs. distinct convolution modules, and assess performance when entity relationship information is incomplete or unavailable
3. Measure computational efficiency and scalability by testing on progressively larger knowledge graphs and measuring inference time and memory requirements