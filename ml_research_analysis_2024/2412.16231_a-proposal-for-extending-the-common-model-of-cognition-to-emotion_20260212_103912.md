---
ver: rpa2
title: A Proposal for Extending the Common Model of Cognition to Emotion
arxiv_id: '2412.16231'
source_url: https://arxiv.org/abs/2412.16231
tags:
- emotion
- module
- common
- cognitive
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes an extension to the Common Model of Cognition
  to incorporate emotion. The key idea is to add two new modules: one for emotion
  that generates dimensional emotion vectors and filters communications, and one for
  metacognitive assessment that observes the cognitive system to generate low-level
  appraisals.'
---

# A Proposal for Extending the Common Model of Cognition to Emotion

## Quick Facts
- arXiv ID: 2412.16231
- Source URL: https://arxiv.org/abs/2412.16231
- Reference count: 0
- Primary result: Proposes adding emotion and metacognitive assessment modules to the Common Model of Cognition

## Executive Summary
This paper presents a theoretical framework for extending the Common Model of Cognition to incorporate emotion through the addition of two new modules: an emotion module that generates dimensional emotion vectors and filters communications, and a metacognitive assessment module that observes cognitive activity to generate low-level appraisals. The proposal aims to provide a consensus-building starting point for how emotion relates to cognitive architectures aligned with the Common Model, without yet delving into implementation details. The authors argue that emotions can be represented as dimensional vectors that pervasively influence cognitive processing through filtering and modification of communications between modules.

## Method Summary
The paper proposes an architectural extension to the Common Model of Cognition by adding two new modules: an emotion module and a metacognitive assessment module. The emotion module generates dimensional emotion vectors (e.g., valence/arousal) and filters/modifies communications between cognitive modules and working memory. The metacognitive assessment module observes the cognitive system to generate low-level appraisals like surprise and familiarity, which serve as inputs to the emotion module. Both modules are pervasively connected to existing Common Model modules through dedicated buffers and direct communication paths. The paper does not provide implementation details but suggests directions for future work.

## Key Results
- Two new modules proposed: emotion module (generates vectors, filters communications) and metacognitive assessment module (observes system, generates appraisals)
- Emotion vectors provide low-dimensional representation that can filter and modulate all cognitive module communications
- Low-level appraisals computed architecturally by observing cognitive processes serve as inputs to emotion generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Emotion vectors provide a low-dimensional representation that can filter and modulate all cognitive module communications.
- Mechanism: The emotion module generates dimensional vectors (e.g., valence/arousal) that act as a gating/filtering layer on communications between non-WM modules and WM, as well as internally within modules.
- Core assumption: Emotional states can be adequately represented as continuous vectors that modulate cognitive processes without requiring full symbolic representation of emotion.
- Evidence anchors:
  - [abstract] "add two new modules: one for emotion that generates dimensional emotion vectors and filters communications"
  - [section] "This module’s role is to generate emotional vectors, such as <valence, arousal> or more extended vectors, that are central to dimensional models of emotion"
  - [corpus] Weak - corpus papers don't discuss dimensional emotion vectors specifically
- Break condition: If emotional states cannot be adequately captured in dimensional form or if vector-based filtering proves too coarse-grained for specific emotional influences.

### Mechanism 2
- Claim: Metacognitive assessment provides low-level appraisals that feed into emotional state generation.
- Mechanism: A metacognitive assessment module observes cognitive system activity and generates appraisals like surprise and familiarity, which are then used as inputs to the emotion module to generate emotional vectors.
- Core assumption: Low-level appraisals can be computed architecturally by monitoring cognitive processes rather than requiring higher-level cognitive reasoning.
- Evidence anchors:
  - [section] "some forms of low-level appraisals, such as surprise and familiarity, can be thought of as metacognitive assessment that is grounded in fixed, architectural sensors"
  - [section] "The particular point of interest here is that some forms of low-level appraisals...can be thought of as metacognitive assessment"
  - [corpus] Weak - corpus papers don't discuss architectural computation of low-level appraisals
- Break condition: If low-level appraisals cannot be computed through architectural observation alone or if they fail to adequately capture the range of emotional triggers.

### Mechanism 3
- Claim: Emotional states can directly modify how cognitive modules operate, not just filter communications.
- Mechanism: The emotion module's vectors can alter the internal processing of non-WM modules, such as changing how procedural memory selects actions or how declarative memory retrieves information.
- Core assumption: Emotional states have specific, measurable effects on cognitive module operations beyond simple communication filtering.
- Evidence anchors:
  - [section] "emotions may yield rewards for reinforcement learning in procedural long-term memory...or somatic markers in declarative long-term memory"
  - [section] "emotions can exert specific influences on memory storage and retrieval, affecting the processing of learned information"
  - [corpus] Weak - corpus papers don't discuss emotion's direct modification of cognitive module operations
- Break condition: If emotional influences prove too specific or variable to be captured by a general vector-based modification system.

## Foundational Learning

- Concept: Dimensional models of emotion
  - Why needed here: The proposal relies on representing emotions as dimensional vectors (valence/arousal) rather than categorical or symbolic representations
  - Quick check question: Can you explain the difference between dimensional and categorical models of emotion, and why dimensional models might be preferred for architectural integration?

- Concept: Appraisal theories of emotion
  - Why needed here: The proposal connects low-level appraisals to emotional state generation, requiring understanding of how appraisals relate to emotions
  - Quick check question: What is the difference between low-level and high-level appraisals, and how do they differently contribute to emotional experience?

- Concept: Cognitive architecture modules and buffers
  - Why needed here: Understanding how the Common Model's existing modules (WM, procedural/declarative memory, perception/motor) work is essential for implementing the new emotion and metacognitive assessment modules
  - Quick check question: How do buffers function in the Common Model, and why are they important for the proposed emotion module's integration?

## Architecture Onboarding

- Component map: Emotion module → vector generation → communication filtering/modification → impact on cognitive processing. Metacognitive Assessment module → appraisal generation → emotion module input → emotional state update. Both modules pervasively connected to existing Common Model modules through dedicated buffers and direct communication paths.

- Critical path: Emotion module → vector generation → communication filtering/modification → impact on cognitive processing. Metacognitive Assessment module → appraisal generation → emotion module input → emotional state update.

- Design tradeoffs: Vector-based vs. symbolic emotion representation (vectors offer computational efficiency but may lose nuance); architectural vs. cognitive appraisal computation (architectural is faster but may be less flexible); pervasive vs. selective module connections (pervasive ensures coverage but increases complexity).

- Failure signatures: If emotion vectors fail to capture important emotional distinctions, cognitive processes may be incorrectly modulated; if metacognitive assessments are inaccurate, emotional states may not reflect actual system states; if connections are insufficient, emotional influences may not reach all relevant cognitive processes.

- First 3 experiments:
  1. Implement basic emotion vector generation and communication filtering in a simple task (e.g., word recall) to verify basic functionality
  2. Add metacognitive assessment of task performance and verify its impact on emotion vector generation
  3. Test emotion vector effects on procedural memory action selection in a sequential decision task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms should be included in the emotion module to filter and modify communications between other modules and working memory?
- Basis in paper: [explicit] The paper proposes that the emotion module filters communications between other modules and working memory, but does not specify the mechanisms for how this filtering occurs.
- Why unresolved: The paper intentionally leaves this open as part of the proposal, stating that it does not yet delve into implementation details.
- What evidence would resolve it: Empirical studies showing how emotional states affect communication patterns between cognitive modules, or computational models demonstrating effective filtering mechanisms based on emotional vectors.

### Open Question 2
- Question: How should the emotion module generate dimensional emotion vectors from appraisal inputs and physiological signals?
- Basis in paper: [explicit] The paper discusses the generation of dimensional emotion vectors but does not commit to specific mechanisms or the size/contents of such vectors.
- Why unresolved: The proposal acknowledges multiple possible approaches (e.g., one slot per appraisal vs. intensity/valence pairs) but does not choose between them or provide implementation details.
- What evidence would resolve it: Empirical validation of different vector generation methods against human emotional responses, or computational experiments demonstrating the effectiveness of different approaches in producing realistic emotional states.

### Open Question 3
- Question: Should the metacognitive assessment module be implemented as a separate module or distributed across existing modules?
- Basis in paper: [explicit] The paper presents this as an open question, showing the metacognitive assessment as a separate module but noting uncertainty about whether it should be distributed.
- Why unresolved: The paper acknowledges the possibility of both architectural across-module appraisals and module-specific appraisals but does not resolve which approach is preferable.
- What evidence would resolve it: Comparative studies of architectures with centralized vs. distributed metacognitive assessment, or theoretical arguments about the computational advantages of each approach in supporting emotional processing.

## Limitations

- The proposal is theoretical and lacks implementation details, empirical validation, or specific parameter specifications
- Dimensional emotion vectors may oversimplify the nuanced ways emotions influence cognition
- Architectural computation of low-level appraisals may not capture the full range of emotional triggers requiring higher-level cognitive processing

## Confidence

- **High Confidence**: The architectural placement of new modules within the Common Model framework is well-justified and aligns with established cognitive architecture principles
- **Medium Confidence**: The dimensional emotion vector approach is theoretically sound but lacks empirical validation for architectural implementation
- **Low Confidence**: The specific mechanisms for how emotional vectors modify cognitive module operations remain underspecified and require further development

## Next Checks

1. **Vector Representation Validation**: Implement a simple emotion vector generation system and test whether valence/arousal dimensions can capture meaningful distinctions in emotional states that affect cognitive performance across different task domains (memory, decision-making, attention).

2. **Appraisal Architecture Verification**: Build a prototype metacognitive assessment module that computes surprise and familiarity from working memory transitions, then verify whether these architectural appraisals correlate with human-reported emotional responses in controlled tasks.

3. **Communication Filtering Impact Assessment**: Implement the proposed communication filtering mechanism between non-WM modules and working memory, then measure whether emotional state vectors produce predictable and beneficial modifications to cognitive processing patterns in sequential decision tasks.