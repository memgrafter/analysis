---
ver: rpa2
title: Look Into the LITE in Deep Learning for Time Series Classification
arxiv_id: '2409.02869'
source_url: https://arxiv.org/abs/2409.02869
tags:
- time
- lite
- series
- number
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents LITE, a new lightweight deep learning architecture
  for time series classification that uses only 2.34% of the parameters of the state-of-the-art
  InceptionTime model while maintaining competitive performance. The key innovation
  is the use of DepthWise Separable Convolutions combined with three boosting techniques:
  multiplexing, custom filters, and dilated convolution.'
---

# Look Into the LITE in Deep Learning for Time Series Classification

## Quick Facts
- **arXiv ID**: 2409.02869
- **Source URL**: https://arxiv.org/abs/2409.02869
- **Reference count**: 40
- **Primary result**: LITE achieves 97.66% parameter reduction compared to InceptionTime while maintaining competitive accuracy

## Executive Summary
This paper introduces LITE, a lightweight deep learning architecture for time series classification that uses DepthWise Separable Convolutions (DWSC) combined with three boosting techniques: multiplexing, custom filters, and dilated convolution. The resulting model has only 9,814 trainable parameters compared to 420,192 for InceptionTime, making it 2.78 times faster to train while consuming 2.79 times less CO2 and power. The paper also introduces LITEMV for multivariate time series and demonstrates its effectiveness on benchmark datasets and a real-world rehabilitation exercise evaluation task.

## Method Summary
LITE uses DepthWise Separable Convolutions to drastically reduce parameters while maintaining performance. The architecture combines multiplexed standard convolutions in the first layer with custom filters, followed by DWSC layers with increasing dilation rates. LITEMV extends this approach to multivariate time series by replacing the initial standard convolution with a 2D convolution. Both models use ensembles (LITETime and LITETimeMV) to reduce variance, with 5-7 models depending on the variant.

## Key Results
- LITE achieves competitive accuracy with only 9,814 parameters versus 420,192 for InceptionTime
- LITE is 2.78 times faster to train and consumes 2.79 times less CO2 and power
- LITEMV achieves state-of-the-art results on the Kimore dataset for skeleton-based human rehabilitation exercises
- LITE and LITEMV provide interpretability through Class Activation Maps

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: DepthWise Separable Convolutions drastically reduce parameters while maintaining representational power
- **Mechanism**: Separates spatial filtering (depthwise convolution) from channel mixing (pointwise convolution)
- **Core assumption**: Depthwise phase can extract sufficient spatial features without full cross-channel filters initially
- **Evidence anchors**: [abstract] "only 9,814 trainable parameters due to the usage of DepthWise Separable Convolutions"
- **Break condition**: If depthwise phase fails to extract meaningful spatial features, pointwise phase cannot compensate

### Mechanism 2
- **Claim**: Multiplexing convolutions detect multiple temporal patterns of varying lengths simultaneously
- **Mechanism**: Multiple convolution layers with different kernel sizes process input in parallel
- **Core assumption**: Different kernel sizes capture complementary temporal patterns
- **Evidence anchors**: [abstract] "boosted by three techniques: multiplexing, custom filters, and dilated convolution"
- **Break condition**: If dataset contains only patterns of similar length, benefit of multiplexing diminishes

### Mechanism 3
- **Claim**: Custom filters provide strong initialization by encoding domain-agnostic patterns
- **Mechanism**: Hand-crafted filters detect increasing/decreasing intervals and peaks
- **Core assumption**: Certain temporal patterns (trends, peaks) are universally useful across datasets
- **Evidence anchors**: [abstract] "boosted by three techniques: multiplexing, custom filters, and dilated convolution"
- **Break condition**: If dataset's discriminative features are not related to trends or peaks, custom filters add noise

## Foundational Learning

- **Concept**: Convolutional neural networks for time series
  - **Why needed**: LITE is built on convolutional operations
  - **Quick check**: How does a 1D convolution kernel slide over a time series, and what does each output value represent?

- **Concept**: Parameter efficiency in deep learning
  - **Why needed**: Paper's main contribution is reducing parameters by 97.66%
  - **Quick check**: How many parameters does a standard convolution with Cin=3, Cout=64, k=5 have versus a DWSC with the same settings?

- **Concept**: Ensemble methods in deep learning
  - **Why needed**: LITE uses ensembles to reduce variance
  - **Quick check**: Why might an ensemble of five LITE models outperform a single larger model like InceptionTime?

## Architecture Onboarding

- **Component map**: Input → Standard Convolution (multiplexed) → Custom Filters → DWSC Layers (with dilation) → Global Average Pooling → Classification FC Layer
- **Critical path**: First layer extracts diverse features; DWSC layers capture longer-range dependencies; final layer reduces to class scores
- **Design tradeoffs**: Standard conv in first layer needed for univariate data; 3-layer depth balances receptive field and parameter efficiency; 5-model ensemble for fair comparison
- **Failure signatures**: Underfitting (low training accuracy), overfitting (high training but poor test accuracy), poor generalization on long series
- **First 3 experiments**: 1) Train LITE on simple dataset and compare to FCN/ResNet, 2) Remove custom filters and measure performance drop, 3) Replace DWSC with standard convolutions and compare efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does LITE/LITEMV performance scale on datasets with millions of samples or significantly longer series lengths?
- **Basis**: [explicit] Paper explicitly mentions this as a limitation in "Limitations of LITE and LITEMV" section
- **Why unresolved**: Current evaluation only covers UCR/UEA archives with limited samples and series lengths
- **What evidence would resolve it**: Empirical results on datasets with millions of samples and/or very long time series

### Open Question 2
- **Question**: What is the optimal number of LITE models in LITETime ensemble for different dataset characteristics?
- **Basis**: [explicit] Paper shows LITETime-7 performs best on average but optimal number may vary with dataset properties
- **Why unresolved**: Analysis only considers UCR archive as a whole
- **What evidence would resolve it**: Systematic experiments varying ensemble size across datasets with different characteristics

### Open Question 3
- **Question**: How does LITEMV's performance compare to ConvTran on multivariate datasets with >100 dimensions?
- **Basis**: [explicit] Paper notes ConvTran wins when number of dimensions increases but doesn't provide comprehensive high-dimensional results
- **Why unresolved**: Detailed analysis and comparison only covers subset of datasets
- **What evidence would resolve it**: Direct performance comparisons on high-dimensional multivariate datasets

## Limitations
- Evaluation relies heavily on benchmark datasets where architecture shows competitive but not always superior performance
- Real-world application represents single domain-specific use case
- CO2 and power consumption comparisons may not generalize across different hardware configurations

## Confidence
- **Parameter Efficiency Claims**: High confidence - well-quantified with clear comparisons to InceptionTime
- **Accuracy Performance**: Medium confidence - competitive results but with significant variance across datasets
- **Interpretability Claims**: Low confidence - qualitative assessment based on single case study
- **CO2/Energy Claims**: High confidence - based on standardized measurement protocol

## Next Checks
1. Test LITE on additional real-world datasets beyond Kimore to validate domain generalization
2. Conduct comprehensive ablation studies removing each boosting technique individually
3. Validate CO2 and power consumption claims across multiple hardware platforms (GPU, CPU, edge devices)