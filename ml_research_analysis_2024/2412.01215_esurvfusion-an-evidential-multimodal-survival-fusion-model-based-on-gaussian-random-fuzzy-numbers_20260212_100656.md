---
ver: rpa2
title: 'EsurvFusion: An evidential multimodal survival fusion model based on Gaussian
  random fuzzy numbers'
arxiv_id: '2412.01215'
source_url: https://arxiv.org/abs/2412.01215
tags:
- fusion
- survival
- multimodal
- data
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EsurvFusion, a novel evidential multimodal
  survival analysis model that addresses the challenge of combining heterogeneous
  and noisy data sources to improve survival outcome predictions. The model uses Gaussian
  random fuzzy numbers to produce unimodal survival predictions along with aleatoric
  and epistemic uncertainties.
---

# EsurvFusion: An evidential multimodal survival fusion model based on Gaussian random fuzzy numbers

## Quick Facts
- arXiv ID: 2412.01215
- Source URL: https://arxiv.org/abs/2412.01215
- Reference count: 40
- Primary result: New state-of-the-art performance on multimodal survival analysis with calibrated uncertainty quantification

## Executive Summary
This paper introduces EsurvFusion, a novel evidential multimodal survival analysis model that addresses the challenge of combining heterogeneous and noisy data sources to improve survival outcome predictions. The model uses Gaussian random fuzzy numbers to produce unimodal survival predictions along with aleatoric and epistemic uncertainties. It incorporates a reliability discounting layer to correct the impact of noisy data modalities and a multimodal evidence-based fusion layer to combine discounted predictions. Extensive experiments on four multimodal survival datasets demonstrate that EsurvFusion establishes new state-of-the-art performance, particularly in handling high heterogeneity data while providing interpretable predictions and insights into modality contributions through learned reliability coefficients.

## Method Summary
EsurvFusion is an evidential multimodal survival analysis model that processes each data modality independently through an ENNreg module to generate Gaussian random fuzzy number (GRFN) predictions. A reliability discounting layer learns modality-specific reliability parameters that scale the precision of each modality's prediction before fusion. The discounted predictions are then combined using Dempster-Shafer theory's generalized product-intersection rule in a multimodal evidence fusion layer. The model is trained using a hybrid loss function that optimizes both unimodal and multimodal predictions simultaneously, with hyperparameters tuned for each dataset.

## Key Results
- Establishes new state-of-the-art performance on four multimodal cancer survival datasets (HECKTOR2022, BRCA, BLCA, COADREAD)
- Achieves superior C-index, IBS, and IBLL scores compared to existing multimodal fusion methods
- Provides interpretable reliability coefficients that identify noisy or unreliable data modalities
- Successfully handles high heterogeneity data while maintaining calibrated uncertainty quantification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gaussian random fuzzy numbers (GRFNs) enable calibrated aleatoric and epistemic uncertainty quantification in survival prediction.
- Mechanism: GRFNs generalize Gaussian random variables by adding a fuzzy mean, allowing the model to express both randomness in the data (aleatoric) and uncertainty due to limited information (epistemic) through the variance and precision parameters. The contour function from Equation (1) quantifies the plausibility of event times, and Dempster's combination rule preserves this uncertainty during fusion.
- Core assumption: The survival time distribution can be modeled as a continuous random fuzzy set without violating Dempster-Shafer theory constraints.
- Evidence anchors:
  - [abstract] "produces unimodal survival predictions along with corresponding aleatoric and epistemic uncertainties"
  - [section] "GRFNs can be regarded as generalized Gaussian random variables with fuzzy mean"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.515, average citations=0.0. Top related titles: Evidential time-to-event prediction with calibrated uncertainty quantification, An evidential time-to-event prediction model based on Gaussian random fuzzy numbers

### Mechanism 2
- Claim: Reliability discounting corrects for noisy or unreliable modalities before fusion.
- Mechanism: A discounting parameter (0 ≤ r ≤ 1) scales the precision of each modality's GRFN, reducing the influence of unreliable evidence. This is learned during training and applied per modality via Equation (3), ensuring that noisy sources contribute less to the final prediction.
- Core assumption: The reliability of each modality can be accurately estimated from the training data and remains consistent across the dataset.
- Evidence anchors:
  - [abstract] "estimates modality-level reliability through a reliability discounting layer to correct the misleading impact of noisy data modalities"
  - [section] "We correct the reliability of data at the modality level using a possibility discounting approach"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.515, average citations=0.0. Top related titles: Evidential time-to-event prediction with calibrated uncertainty quantification, An evidential time-to-event prediction model based on Gaussian random fuzzy numbers

### Mechanism 3
- Claim: Evidence-based late fusion outperforms early and middle fusion for heterogeneous multimodal survival data.
- Mechanism: Each modality is processed independently into a GRFN, discounted for reliability, and then combined using the generalized product-intersection rule (Equation (4)). This preserves modality-specific uncertainty and reliability signals, avoiding the information loss seen in concatenation-based methods.
- Core assumption: Modalities are conditionally independent given the survival outcome, making Dempster-Shafer combination valid.
- Evidence anchors:
  - [abstract] "designed to combine multimodal data at the decision level through an evidence-based decision fusion layer"
  - [section] "We propose a multimodal evidence fusion layer that combines the discounted prediction to form a unified multimodal survival analysis model"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.515, average citations=0.0. Top related titles: Evidential time-to-event prediction with calibrated uncertainty quantification, An evidential time-to-event prediction model based on Gaussian random fuzzy numbers

## Foundational Learning

- Concept: Dempster-Shafer Theory of Evidence
  - Why needed here: Provides the mathematical framework for combining uncertain evidence from multiple modalities while preserving both aleatoric and epistemic uncertainty.
  - Quick check question: How does Dempster's combination rule handle conflicting evidence from two modalities predicting different survival times?

- Concept: Gaussian Random Fuzzy Numbers (GRFNs)
  - Why needed here: GRFNs allow modeling of survival times as fuzzy intervals with random means, enabling calibrated uncertainty quantification in continuous prediction tasks.
  - Quick check question: What is the difference between the variance (σ²) and precision (h) parameters in a GRFN, and which type of uncertainty does each represent?

- Concept: Possibility Theory and Reliability Discounting
  - Why needed here: Possibility theory extends fuzzy logic to quantify uncertainty, and discounting adjusts the weight of evidence based on reliability, crucial for handling noisy multimodal inputs.
  - Quick check question: In the context of GRFNs, how does the discounting parameter r modify the evidence, and what is its effect on the final prediction?

## Architecture Onboarding

- Component map: Input -> Unimodal ENNreg modules -> Reliability discounting layers -> Multimodal evidence fusion layer -> Final GRFN output
- Critical path: Input → Unimodal prediction → Reliability discounting → Evidence fusion → Final GRFN output
- Design tradeoffs:
  - Early fusion loses modality-specific uncertainty signals; late fusion preserves them but requires reliable discounting.
  - Complex discounting and fusion increase model interpretability but also computational overhead.
  - GRFNs are powerful for uncertainty but may be overkill for datasets with low noise or censoring.
- Failure signatures:
  - Overconfident predictions despite high noise: reliability discounting may be too weak or poorly learned.
  - Poor performance on multimodal inputs: discounting may be over-aggressive, or modalities may be too dependent.
  - Unstable training: hybrid loss may need tuning of λ, η, and φ to balance unimodal vs. multimodal objectives.
- First 3 experiments:
  1. Ablation: Remove reliability discounting and compare C-index and calibration metrics.
  2. Ablation: Replace evidence-based fusion with early or middle fusion and measure performance drop.
  3. Sensitivity: Vary the discounting parameter initialization and observe impact on reliability coefficient convergence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EsurvFusion scale with increasing dataset size and dimensionality of multimodal inputs?
- Basis in paper: [explicit] The paper notes that middle fusion methods require enough training data with effective ground truth, and that multimodal survival databases are usually small scale compared to other tasks, leading to potential overfitting and unsatisfying performance.
- Why unresolved: The experiments were conducted on relatively small datasets (n=383 to 1032), so the model's behavior on larger datasets remains unknown.
- What evidence would resolve it: Experiments on larger multimodal survival datasets or synthetic data with increasing sample sizes and dimensionality would show how performance scales.

### Open Question 2
- Question: What is the impact of different reliability discounting strategies on multimodal fusion performance beyond the simple exponential discounting used in EsurvFusion?
- Basis in paper: [explicit] The paper mentions that Denoeux extended discounting to GRFNs, but only uses a simple exponential discounting approach without exploring alternative strategies.
- Why unresolved: The paper only implements one discounting method without comparing to alternatives like linear, sigmoid, or learned adaptive discounting functions.
- What evidence would resolve it: Comparative experiments testing multiple discounting strategies while keeping other components constant would show the optimal approach.

### Open Question 3
- Question: How does EsurvFusion perform on non-cancer survival tasks with different types of multimodal data distributions and censoring patterns?
- Basis in paper: [explicit] All experiments focus exclusively on cancer survival datasets with clinical, genomic, and imaging modalities, without testing on other domains.
- Why unresolved: The model's generalizability to other survival analysis applications (e.g., cardiovascular disease, organ failure, equipment failure) with different data characteristics is unknown.
- What evidence would resolve it: Experiments on non-cancer survival datasets with different modality combinations and censoring patterns would demonstrate generalizability.

## Limitations
- Performance relies on Dempster-Shafer theory's assumption of modality independence, which may not hold in real-world multimodal datasets.
- Computational complexity increases with the number of modalities, potentially limiting practical deployment in resource-constrained settings.
- The model requires sufficient training data to accurately estimate modality-specific reliability parameters, and poor estimates could lead to over- or under-discounting.

## Confidence
- **High Confidence**: The model's superior performance on C-index, IBS, and IBLL metrics compared to established baselines is well-supported by the reported results across four diverse cancer datasets.
- **Medium Confidence**: The interpretability of learned reliability coefficients and their ability to identify noisy modalities is plausible but requires further validation through controlled experiments with artificially corrupted data.
- **Low Confidence**: The generalizability of EsurvFusion to non-cancer survival tasks and datasets with significantly different characteristics (e.g., shorter follow-up periods, different censoring patterns) remains untested.

## Next Checks
1. Conduct ablation studies systematically removing the reliability discounting layer to quantify its contribution to overall performance gains.
2. Test the model on external validation datasets from different cancer types or non-cancer survival applications to assess generalizability.
3. Perform sensitivity analysis on the discounting parameter initialization and observe its impact on convergence and final reliability coefficient estimates.