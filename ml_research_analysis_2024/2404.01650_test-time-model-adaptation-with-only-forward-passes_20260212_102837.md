---
ver: rpa2
title: Test-Time Model Adaptation with Only Forward Passes
arxiv_id: '2404.01650'
source_url: https://arxiv.org/abs/2404.01650
tags:
- adaptation
- learning
- test-time
- methods
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FOA enables test-time adaptation on resource-limited devices by
  using only forward passes. It optimizes a prompt via derivative-free CMA with a
  novel fitness function combining prediction entropy and feature distribution discrepancy,
  plus a back-to-source activation shifting mechanism.
---

# Test-Time Model Adaptation with Only Forward Passes

## Quick Facts
- arXiv ID: 2404.01650
- Source URL: https://arxiv.org/abs/2404.01650
- Authors: Shuaicheng Niu; Chunyan Miao; Guohao Chen; Pengcheng Wu; Peilin Zhao
- Reference count: 40
- One-line primary result: FOA achieves 66.3% accuracy and 3.2% ECE on full-precision ViT for test-time adaptation, outperforming gradient-based methods while using 24× less memory

## Executive Summary
FOA enables test-time adaptation on resource-limited devices by using only forward passes. It optimizes a prompt via derivative-free CMA with a novel fitness function combining prediction entropy and feature distribution discrepancy, plus a back-to-source activation shifting mechanism. On ImageNet-C, FOA achieves 66.3% accuracy and 3.2% ECE on full-precision ViT, outperforming gradient-based TENT (59.6%, 18.5% ECE), and reaches 63.5% accuracy on 8-bit quantized ViT—exceeding TENT on full-precision. Memory usage drops up to 24×, making it suitable for deployment on FPGAs, smartphones, and other edge devices.

## Method Summary
FOA performs test-time adaptation using only forward passes by optimizing a low-dimensional prompt through CMA-ES. The method adds a 3-embedding prompt to the model input, updates it via evolutionary strategy using a fitness function that measures prediction entropy and feature distribution discrepancy, and applies an activation shifting mechanism to align test activations with source domain statistics. This approach avoids backpropagation entirely, making it suitable for resource-constrained devices while achieving competitive accuracy on out-of-distribution data.

## Key Results
- FOA achieves 66.3% accuracy and 3.2% ECE on full-precision ViT for ImageNet-C Gaussian (level 5), outperforming TENT (59.6%, 18.5% ECE)
- FOA reaches 63.5% accuracy on 8-bit quantized ViT, exceeding TENT's performance on full-precision models
- Memory usage drops up to 24× compared to gradient-based methods, enabling deployment on FPGAs and smartphones

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Forward-only adaptation is possible because the prompt is low-dimensional and can be optimized with a derivative-free evolutionary strategy.
- Mechanism: The method adds a low-dimensional prompt embedding as model input, then updates it via CMA-ES using an unsupervised fitness function that measures entropy and feature distribution discrepancy.
- Core assumption: The added prompt can sufficiently influence the model output without needing to modify internal weights, and the fitness function provides stable gradients for CMA optimization.
- Evidence anchors:
  - [abstract] "FOA enables test-time adaptation on resource-limited devices by using only forward passes. It optimizes a prompt via derivative-free CMA..."
  - [section] "To make CMA work in TTA, we introduce a new prompt as the model’s input (as in Figure 1 (a)) for updating, thereby reducing the dimension of solution space and lowering the complexity for CMA optimization..."
  - [corpus] Weak: No direct neighbor evidence; this is a novel claim.
- Break condition: If the prompt dimension grows large or the fitness function becomes too noisy, CMA-ES will fail to converge in real time.

### Mechanism 2
- Claim: Feature alignment through activation shifting directly corrects out-of-distribution activations without backpropagation.
- Mechanism: During inference, the CLS token of the last layer is shifted toward the source domain's mean activation vector, computed online using exponential moving averages.
- Core assumption: The direction from OOD to ID activation centers is meaningful and stable enough to guide the shift without labels.
- Evidence anchors:
  - [abstract] "...back-to-source activation shifting mechanism... directly tunes the model activations for shifted test samples, making them align with the source training domain..."
  - [section] "Specifically, given a test sample x, we move its corresponding N-th layer’s CLS feature e0 N ... shifting them along the direction from out-of-distribution domain towards in-distribution domain..."
  - [corpus] Weak: No direct neighbor evidence; this is a novel approach.
- Break condition: If the OOD and ID feature distributions overlap heavily or shift unpredictably, the shift direction becomes meaningless.

### Mechanism 3
- Claim: The combined fitness function of prediction entropy and activation distribution discrepancy provides stable learning signals for unsupervised CMA optimization.
- Mechanism: The fitness function penalizes high prediction entropy and large deviations between test and source activation statistics, balancing exploration and distribution alignment.
- Core assumption: Both entropy and distribution discrepancy are reliable proxies for out-of-distribution performance without ground truth labels.
- Evidence anchors:
  - [abstract] "To make this strategy work stably under our online unsupervised setting, we devise a novel fitness function by measuring test-training statistic discrepancy and model prediction entropy."
  - [section] "We devise a new fitness to regularize the activation distribution statistics of OOD testing samples... This fitness functions at the distribution level, circumventing the issues of noise inherent in the uncertain predictions..."
  - [corpus] Weak: No direct neighbor evidence; novel fitness design.
- Break condition: If the test data is extremely noisy or the source statistics are poorly estimated, the fitness function will mislead CMA updates.

## Foundational Learning

- Concept: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
  - Why needed here: Provides a derivative-free optimization method suitable for low-dimensional prompt learning without backpropagation.
  - Quick check question: What is the role of the covariance matrix in CMA-ES, and how does it guide the sampling of new candidate solutions?

- Concept: Entropy minimization in unsupervised learning
  - Why needed here: Used as part of the fitness function to encourage confident predictions on out-of-distribution data.
  - Quick check question: How does entropy minimization help detect or correct distribution shifts during test-time adaptation?

- Concept: Feature distribution alignment via activation statistics
  - Why needed here: Provides an unsupervised signal to align OOD test activations with ID source activations.
  - Quick check question: Why is it useful to compare mean and standard deviation of CLS features between test and source data?

## Architecture Onboarding

- Component map:
  Input image + prompt -> ViT backbone -> CLS activation -> Fitness function (entropy + distribution discrepancy) -> CMA-ES optimizer -> Shifted CLS activation -> Prediction

- Critical path:
  1. Sample prompt candidates with CMA-ES
  2. Forward pass each candidate + test image
  3. Compute fitness (entropy + activation stats)
  4. Update CMA-ES distribution
  5. Select best candidate and shift CLS activation

- Design tradeoffs:
  - Low prompt dim → fast CMA convergence but limited adaptation capacity
  - High population size → better exploration but more forward passes
  - Batch size → affects statistics accuracy but increases latency

- Failure signatures:
  - Fitness plateaus or diverges → CMA-ES not converging
  - Accuracy drops vs. NoAdapt → prompt learning harmful or fitness misaligned
  - High ECE → overconfident wrong predictions

- First 3 experiments:
  1. Compare accuracy/ECE of FOA vs. NoAdapt on ImageNet-C Gaussian (level 5) with batch size 64, K=2.
  2. Sweep population size K in {2, 6, 28} and measure run-time and memory.
  3. Test single-sample adaptation with FOA-I (interval I=4) vs. batch size 64.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FOA's performance scale with larger models (e.g., ViT-Large) and higher-dimensional prompts?
- Basis in paper: [explicit] The paper notes that CMA struggles with ultra-high dimensional optimization and focuses on ViT-Base. It states "For TTA, the model parameters needing update are high-dimensional (even for methods like TENT (Wang et al., 2021) that only updates the affine parameters of normalization layers), since the deep models are often with millions of parameters."
- Why unresolved: The paper only evaluates FOA on ViT-Base, and the authors acknowledge that CMA faces challenges with high-dimensional optimization problems.
- What evidence would resolve it: Experimental results comparing FOA's performance on different model sizes (e.g., ViT-Small, ViT-Large) and prompt dimensions would clarify scalability.

### Open Question 2
- Question: What is the theoretical upper bound on performance improvement achievable through FOA's activation shifting mechanism?
- Basis in paper: [inferred] The paper shows activation shifting improves performance (e.g., 55.5% to 59.1% accuracy) but doesn't establish theoretical limits. It mentions "activation shifting seeks to directly refine the activation features of the final layer, by aligning them from the OOD domain back to the source in-distribution (ID) domain."
- Why unresolved: The paper provides empirical evidence of effectiveness but lacks theoretical analysis of the mechanism's maximum potential impact.
- What evidence would resolve it: Theoretical analysis proving bounds on performance gains from activation shifting, possibly through analyzing the distance between source and target activation distributions.

### Open Question 3
- Question: How does FOA's performance compare to BP-based methods when test data arrives in non-i.i.d. streams with rapidly changing distributions?
- Basis in paper: [explicit] The paper evaluates FOA under non-i.i.d. scenarios (mixed domain shifts, online imbalanced label distribution) but doesn't compare its performance to BP-based methods under rapidly changing distributions. It mentions "FOA performs stably even under non-i.i.d. settings."
- Why unresolved: The paper demonstrates FOA's stability under non-i.i.d. conditions but doesn't benchmark its performance against BP-based methods when distributions shift rapidly within a test stream.
- What evidence would resolve it: Comparative experiments measuring FOA and BP-based methods' accuracy and adaptation speed under test streams with rapidly changing distribution characteristics.

## Limitations

- The fitness function design lacks empirical justification for specific weighting between entropy and distribution discrepancy terms
- Activation shifting mechanism effectiveness depends on the assumption that OOD-to-ID feature shift directions are meaningful and stable
- Memory reduction claims (24×) are implementation-dependent and require careful verification against gradient-based methods

## Confidence

- High: Forward-only adaptation is feasible and achieves accuracy gains over NoAdapt baseline
- Medium: Memory reduction claims (24×) and quantized model performance are valid but implementation-dependent
- Low: Fitness function design choices and activation shifting mechanism effectiveness lack strong empirical justification

## Next Checks

1. Perform ablation studies varying the fitness function weighting between entropy and distribution discrepancy to verify which components drive performance
2. Test activation shifting mechanism on datasets with known severe distribution shifts where OOD-to-ID alignment is questionable
3. Conduct head-to-head memory usage comparison with gradient-based TENT implementation under identical conditions