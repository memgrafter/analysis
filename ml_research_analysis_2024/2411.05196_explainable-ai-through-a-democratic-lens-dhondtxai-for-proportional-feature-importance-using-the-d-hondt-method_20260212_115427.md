---
ver: rpa2
title: 'Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature
  Importance Using the D''Hondt Method'
arxiv_id: '2411.05196'
source_url: https://arxiv.org/abs/2411.05196
tags:
- feature
- features
- importance
- alliance
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces DhondtXAI, a novel method for explainable
  AI that applies proportional representation principles from electoral systems to
  feature importance interpretation. DhondtXAI adapts the D'Hondt method to allocate
  "seats" to features based on their calculated importance, allowing for alliance
  formation and thresholding to enhance interpretability.
---

# Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method

## Quick Facts
- **arXiv ID**: 2411.05196
- **Source URL**: https://arxiv.org/abs/2411.05196
- **Reference count**: 14
- **Primary result**: DhondtXAI achieves 96% accuracy for breast cancer and 98% for diabetes while providing interpretable parliamentary-style feature importance visualization

## Executive Summary
This study introduces DhondtXAI, a novel explainable AI method that applies proportional representation principles from electoral systems to feature importance interpretation. The method adapts the D'Hondt method to allocate "seats" to features based on their calculated importance, allowing for alliance formation and thresholding to enhance interpretability. Evaluated against SHAP using CatBoost and XGBoost models on breast cancer and diabetes datasets, DhondtXAI produced consistent interpretations with Spearman correlation coefficients of 0.83 and 0.40 respectively. The approach achieves high model performance while providing transparent, parliamentary-style visualization of feature importance particularly valuable in healthcare applications.

## Method Summary
DhondtXAI is an explainable AI method that applies the D'Hondt method of proportional representation to feature importance interpretation. The approach treats features as "parties" in an electoral system, converting feature importance scores to votes and allocating seats proportionally. Users can form alliances between related features and apply thresholding to filter out less influential features. The method was evaluated using CatBoost and XGBoost models on breast cancer and diabetes datasets, comparing results with SHAP through Spearman correlation to assess consistency in feature importance interpretation.

## Key Results
- DhondtXAI achieved 96% accuracy on breast cancer dataset and 98% on diabetes dataset
- Spearman correlation coefficients between DhondtXAI and SHAP were 0.83 (breast cancer) and 0.40 (diabetes)
- Parliamentary-style visualization enhanced interpretability while maintaining model performance
- Alliance formation and thresholding mechanisms improved feature representation and filtering

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DhondtXAI provides proportional representation of feature importance through resource allocation.
- Mechanism: Features are treated as "parties" in an electoral system, with importance scores converted to votes using the D'Hondt method. Seats (representation units) are then allocated proportionally based on vote shares.
- Core assumption: Feature importance scores can be meaningfully interpreted as votes in a proportional representation system.
- Evidence anchors:
  - [abstract] "DhondtXAI approach allows for alliance formation and thresholding to enhance interpretability, representing feature importance as seats in a parliamentary view"
  - [section] "DhondtXAI method was utilized to allocate a 600-seat parliamentary representation based on the importance of each feature"
- Break condition: When feature importance scores don't correlate proportionally with actual model behavior, or when the D'Hondt method's slight bias toward larger features becomes problematic.

### Mechanism 2
- Claim: Alliance formation enables collective representation of related features.
- Mechanism: Users can group features into alliances that combine their importance scores and compete as unified entities for seats, allowing smaller but related features to gain representation collectively.
- Core assumption: Related features often work together in models, and their combined importance is more meaningful than individual contributions.
- Evidence anchors:
  - [abstract] "The DhondtXAI approach allows for alliance formation and thresholding to enhance interpretability"
  - [section] "features were organized into alliances, which are groups representing related aspects of diabetes risk factors and symptoms"
- Break condition: When alliances don't reflect actual feature interactions in the model, or when alliance boundaries become arbitrary.

### Mechanism 3
- Claim: Thresholding filters out less influential features to improve interpretability.
- Mechanism: Features below a user-defined vote percentage threshold are excluded from seat allocation, with their votes redistributed to remaining features.
- Core assumption: Some features contribute minimally to model predictions and can be safely filtered without losing critical information.
- Evidence anchors:
  - [section] "The threshold application in DhondtXAI introduces a practical mechanism to filter out variables or alliances that have a minimal impact on the model"
  - [section] "A 10% threshold was applied, meaning only alliances receiving at least 10% of the total votes would be eligible for seat allocation"
- Break condition: When the threshold is set too high, causing important but less dominant features to be excluded, or too low, providing no filtering benefit.

## Foundational Learning

- Concept: Proportional representation electoral systems
  - Why needed here: DhondtXAI directly adapts the D'Hondt method from political science, so understanding how seats are allocated proportionally is essential
  - Quick check question: In the D'Hondt method, how is the number of seats allocated to each party determined from their vote counts?

- Concept: Feature importance calculation in tree-based models
  - Why needed here: DhondtXAI builds on feature importance scores from models like CatBoost and XGBoost, which are calculated from impurity reduction
  - Quick check question: How is feature importance calculated in a decision tree when a feature is used as a split criterion?

- Concept: Spearman correlation for method comparison
  - Why needed here: The paper validates DhondtXAI by comparing it to SHAP using Spearman correlation to assess consistency
  - Quick check question: What does a Spearman correlation coefficient of 0.83 between two feature importance methods indicate about their relationship?

## Architecture Onboarding

- Component map: User parameters → Feature importance calculation → Exclusion and alliance formation → Vote distribution → Threshold application → Seat allocation (D'Hondt) → Visualization
- Critical path: Feature importance calculation → Vote distribution → Seat allocation (these three steps are essential; others are optional user controls)
- Design tradeoffs: Proportional representation provides intuitive visualization but may oversimplify complex feature interactions; alliances improve interpretability but require user expertise to define correctly
- Failure signatures: Low correlation with SHAP indicates inconsistent feature importance interpretation; threshold setting that eliminates too many features suggests poor parameter choice; alliance formation that doesn't improve interpretability indicates incorrect groupings
- First 3 experiments:
  1. Apply DhondtXAI to a simple dataset with known feature importance (like the breast cancer dataset) and verify seat allocation matches expected importance
  2. Test alliance formation by grouping related features and confirming combined importance is correctly calculated
  3. Apply thresholding with different values to observe how feature representation changes and identify optimal threshold levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the DhondtXAI method perform when applied to neural network models compared to tree-based models?
- Basis in paper: [inferred] The paper mentions that DhondtXAI could offer valuable insights for managing feature importance in neural networks and ensemble models where interpreting non-linear relationships is challenging.
- Why unresolved: The study primarily evaluated DhondtXAI on tree-based models (CatBoost and XGBoost), with only theoretical suggestions about its potential application to neural networks.
- What evidence would resolve it: Experimental results comparing DhondtXAI's performance and interpretability when applied to neural network models versus tree-based models on various datasets.

### Open Question 2
- Question: What is the optimal threshold percentage for different types of datasets and model applications?
- Basis in paper: [explicit] The paper discusses the use of threshold values in the DhondtXAI method but doesn't provide guidance on optimal threshold selection for different scenarios.
- Why unresolved: The study applied fixed threshold values (10% in one case) without exploring how different threshold percentages affect interpretability and model performance across various domains.
- What evidence would resolve it: Systematic experiments testing different threshold percentages across multiple datasets and domains to determine optimal threshold values.

### Open Question 3
- Question: How does the DhondtXAI method handle continuous versus categorical features differently in terms of feature importance interpretation?
- Basis in paper: [inferred] The paper mentions applying DhondtXAI to datasets with both continuous and categorical features but doesn't discuss how the method handles these different feature types.
- Why unresolved: The study doesn't explore whether and how the D'Hondt method's proportional allocation might need adjustment for different feature types or if certain feature types are inherently advantaged by the method.
- What evidence would resolve it: Comparative analysis of DhondtXAI's feature importance interpretation for continuous versus categorical features across various model types and datasets.

## Limitations

- The method's generalizability to non-medical domains and complex feature interactions remains untested
- The choice of alliance formation and threshold parameters appears to significantly impact interpretability but lacks systematic optimization guidance
- The correlation between DhondtXAI and SHAP results shows considerable variation (0.83 vs 0.40), suggesting the method may be more reliable for certain data types than others

## Confidence

- **High**: The mathematical foundation of applying D'Hondt method to feature importance allocation is sound and well-documented
- **Medium**: The interpretability benefits of parliamentary-style visualization for healthcare applications are demonstrated but not quantified
- **Medium**: The method's performance correlation with SHAP indicates consistency but doesn't establish superiority or broader applicability

## Next Checks

1. **Cross-domain validation**: Apply DhondtXAI to datasets from different domains (e.g., finance, environmental science) to assess whether the electoral system analogy maintains interpretability benefits across contexts

2. **Parameter sensitivity analysis**: Systematically vary threshold values (5%, 10%, 15%, 20%) and alliance configurations to determine optimal settings for different types of datasets and feature relationships

3. **Comparison with additional XAI methods**: Evaluate DhondtXAI against other feature importance methods like LIME or permutation importance to determine if the electoral system approach provides unique advantages beyond correlation with SHAP