---
ver: rpa2
title: 'StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal'
arxiv_id: '2406.16864'
source_url: https://arxiv.org/abs/2406.16864
tags:
- normal
- diffusion
- estimation
- stablenormal
- vision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'StableNormal addresses the challenge of high-quality surface normal
  estimation from monocular images, a task recently revolutionized by diffusion priors
  but plagued by stochastic inference and slow ensembling. The core method employs
  a coarse-to-fine strategy: first, a one-step estimator (YOSO) generates a reliable
  initial normal guess, then a semantic-guided refinement network (SG-DRN) enhances
  stability and sharpness by integrating DINO semantic priors.'
---

# StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal

## Quick Facts
- arXiv ID: 2406.16864
- Source URL: https://arxiv.org/abs/2406.16864
- Reference count: 24
- One-line primary result: StableNormal achieves state-of-the-art normal estimation accuracy with significantly reduced variance by combining a one-step estimator with semantic-guided refinement.

## Executive Summary
StableNormal addresses the challenge of high-quality surface normal estimation from monocular images, a task recently revolutionized by diffusion priors but plagued by stochastic inference and slow ensembling. The core method employs a coarse-to-fine strategy: first, a one-step estimator (YOSO) generates a reliable initial normal guess, then a semantic-guided refinement network (SG-DRN) enhances stability and sharpness by integrating DINO semantic priors. This approach reduces inference variance and eliminates the need for ensembling, producing stable and sharp normals even under challenging conditions like extreme lighting or cluttered scenes.

## Method Summary
StableNormal uses a two-stage coarse-to-fine approach for surface normal estimation. The first stage, YOSO (one-step estimator), employs a fine-tuned Stable Diffusion V2.1 with a Shrinkage Regularizer to produce a stable coarse normal map in a single inference step. The second stage, SG-DRN (semantic-guided diffusion refinement network), refines this initialization using 10 DDIM steps while incorporating DINO semantic features to enhance local details and reduce sampling variance. The method is trained on over 250,000 synthetic image-normal pairs and evaluated on multiple benchmark datasets including DIODE-indoor, iBims, ScanNetV2, and NYUv2.

## Key Results
- Achieves 13.701° mean angular error on DIODE-indoor benchmark, outperforming DSINE (18.453°) and other state-of-the-art methods
- Reduces output variance to 0.410 compared to 1.370 for DSINE, eliminating need for ensemble strategies
- Improves downstream surface reconstruction performance with lower Chamfer distance metrics
- Maintains performance across challenging conditions including extreme lighting and cluttered scenes

## Why This Works (Mechanism)

### Mechanism 1
The Shrinkage Regularizer reduces variance in YOSO by splitting the diffusion loss into generative and reconstruction terms with probability λ=0.4. When p<λ, the model predicts against zero-noise baseline instead of actual noisy sample, shrinking the distribution toward a Dirac delta function. This creates a sharp, low-variance initialization crucial for stable normal estimation.

### Mechanism 2
SG-DRN leverages DINO features (extracted at lower resolution) aligned to latent feature map via convolution, FeatUp, and bilinear interpolation. These semantic features are added to U-Net encoder layers before denoising steps, biasing the diffusion process toward semantically consistent normals. This injects global scene understanding (e.g., walls vs objects) beyond local pixel information.

### Mechanism 3
The coarse-to-fine strategy decouples stability from sharpness: YOSO provides low-variance, reliable initialization while SG-DRN adds high-frequency details over 10 DDIM steps with semantic conditioning. This two-stage approach ensures stability from the reliable initialization while recovering geometric detail through refinement.

## Foundational Learning

- Concept: Diffusion probabilistic models and their reparameterization (ε vs x0)
  - Why needed here: Understanding how diffusion loss is reformulated for x+t parameterization is critical for implementing YOSO correctly
  - Quick check question: In x+t parameterization, what distribution does x+t follow when t→∞, and why is this choice better than x0 for one-step estimation?

- Concept: Semantic feature extraction and alignment (DINO + FeatUp)
  - Why needed here: SG-DRN relies on upsampled DINO features to inject global context; knowing how to align and fuse them with diffusion latents is essential
  - Quick check question: If DINO features are extracted at 1/16 resolution, what interpolation strategy should you use before adding them to U-Net encoder to preserve semantic integrity?

- Concept: DDIM sampling dynamics and variance control
  - Why needed here: Final refinement step uses DDIM; understanding how noise scale τ and direction term affect variance is key to controlling stability
  - Quick check question: What happens to sampling variance if τ=0 versus τ>0 in DDIM for normal refinement, and why does paper choose τ=0 for inference?

## Architecture Onboarding

- Component map: Input → VAE encoder → YOSO (1 step) → SG-DRN (10 DDIM steps) → final output
- Critical path: RGB image → YOSO stage → SG-DRN stage → final normal map
- Design tradeoffs:
  - One-step vs multi-step YOSO: fewer steps reduce variance but risk smoothing; more steps recover detail but risk variance blow-up
  - Semantic injection resolution: higher resolution DINO features increase detail but also computational cost
  - λ in shrinkage regularizer: controls variance vs fidelity; too high → bias, too low → no benefit
- Failure signatures:
  - YOSO produces overly smooth normals → likely λ too high or t+ too small
  - SG-DRN introduces artifacts → likely DINO features misaligned or semantic injection too strong
  - Overall variance high despite design → likely semantic conditioning weak or DDIM noise scale τ not set to 0
- First 3 experiments:
  1. Ablation: Train YOSO without shrinkage regularizer (λ=1) and measure output variance vs accuracy
  2. Ablation: Remove semantic injection from SG-DRN and compare mean angular error on DIODE-indoor
  3. Ablation: Vary t+ in YOSO (e.g., 201, 401, 601) and evaluate trade-off between sharpness and stability

## Open Questions the Paper Calls Out

- How can diffusion priors be effectively repurposed for deterministic estimation tasks beyond surface normal estimation, such as depth estimation or other perception tasks?
- What is the optimal balance between stability and sharpness in diffusion-based normal estimation, and how does it vary across different datasets and imaging conditions?
- How can the performance of StableNormal be further improved by incorporating additional semantic priors or geometric constraints beyond DINO features?

## Limitations

- The effectiveness depends heavily on the quality of the one-step estimator, but limited ablation studies on parameter sensitivity
- Semantic-guided refinement claims significant improvements, but lacks comparisons to alternative semantic encoders or feature resolutions
- Synthetic training data raises questions about real-world generalization, particularly with novel object types

## Confidence

- High confidence: Experimental results showing StableNormal outperforming state-of-the-art methods on benchmark datasets with lower mean angular errors and reduced variance
- Medium confidence: Effectiveness of Shrinkage Regularizer in reducing variance during YOSO training, as theoretical justification is sound but implementation details are sparse
- Low confidence: Claim that semantic-guided refinement alone provides majority of performance gains, as paper lacks sufficient ablation studies isolating semantic injection contribution

## Next Checks

1. Perform ablation study varying one-step estimator's t+ parameter (e.g., 201, 401, 601) to quantify trade-off between initialization quality and variance control
2. Replace DINO features with alternative semantic encoders (e.g., CLIP, DINOv2) in SG-DRN stage to validate whether performance gains are specific to DINO
3. Conduct real-world generalization test on datasets with significantly different object distributions than training corpus, such as outdoor scenes or industrial environments