---
ver: rpa2
title: Adaptive Two-Phase Finetuning LLMs for Japanese Legal Text Retrieval
arxiv_id: '2412.13205'
source_url: https://arxiv.org/abs/2412.13205
tags:
- retrieval
- documents
- query
- phase
- relevant
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel two-phase fine-tuning approach for
  Japanese legal text retrieval, addressing the challenge of limited Japanese-specific
  datasets and methods. The proposed pipeline first learns global contexts through
  diverse document exposure (positive, negative, and easy documents), then refines
  the model on query-specific hard negatives.
---

# Adaptive Two-Phase Finetuning LLMs for Japanese Legal Text Retrieval

## Quick Facts
- arXiv ID: 2412.13205
- Source URL: https://arxiv.org/abs/2412.13205
- Authors: Quang Hoang Trung; Nguyen Van Hoang Phuc; Le Trung Hoang; Quang Huu Hieu; Vo Nguyen Le Duy
- Reference count: 34
- Primary result: Novel two-phase fine-tuning approach for Japanese legal text retrieval achieving 82.54 MRR@10 on Japanese legal dataset

## Executive Summary
This paper addresses the challenge of Japanese legal text retrieval by introducing a two-phase fine-tuning approach for large language models (LLMs). The method first learns global contextual patterns using diverse document exposure, then refines the model on domain-specific hard negatives. Experiments on a newly created Japanese legal dataset and the MS MARCO benchmark demonstrate superior performance compared to traditional baselines, with the ensemble extension further enhancing retrieval quality.

## Method Summary
The method involves two main phases: Phase 1 learns global contexts using positive, negative, and easy documents through BM25+ retrieval and in-batch negatives; Phase 2 refines the model on hard negatives from the top-50 documents predicted by Phase 1. The approach uses LLaMA-2-7B with LoRA and 16-bit quantization for computational efficiency. An ensemble model combines BM25+ scores with LLM embeddings. The Japanese legal dataset was created by collecting legal articles and employment contracts, chunking documents, and matching chunks to relevant articles using Gemini 1.5 Pro followed by manual verification.

## Key Results
- Achieves 82.54 MRR@10 and 68.86 nDCG@10 on the Japanese legal dataset
- Attains 80.71 Recall@10 on MS MARCO benchmark
- Outperforms traditional baselines by leveraging complementary strengths of fine-tuned LLMs and BM25+ scoring

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-phase fine-tuning improves retrieval by learning global patterns first, then refining on hard negatives
- Mechanism: Phase 1 trains on positive, negative, and easy documents for broad semantic understanding; Phase 2 focuses on hard negatives for difficult cases
- Core assumption: Easy documents in Phase 1 build general patterns while hard negatives in Phase 2 target ambiguous legal cases
- Evidence anchors:
  - [abstract] "In the first phase, the model learns a broad understanding of global contexts, enhancing its generalization and adaptability to diverse queries."
  - [section] "In Phase 1, the model learns a broad understanding of global contexts by leveraging positive, negative, and easy documents... In Phase 2, after mastering the broader global context in Phase 1, the model shifts its focus to fine-tuning on the top-a2 hard documents..."
- Break condition: Overfitting to easy documents in Phase 1 may prevent benefits from Phase 2 hard negatives

### Mechanism 2
- Claim: LoRA and quantization make LLM fine-tuning computationally feasible
- Mechanism: LoRA approximates weight updates with low-rank matrices; quantization reduces model precision
- Core assumption: Low-rank adaptations capture essential retrieval improvements without full fine-tuning
- Evidence anchors:
  - [section] "To mitigate this, we utilized several memory-efficient techniques such as LoRA (Hu et al., 2021), Flash Attention (Dao, 2023), and gradient check-pointing, which significantly reduced memory usage."
  - [section] "Due to resource constraints, unlike the approach in (Ma et al., 2024), we apply quantization techniques to optimize memory usage and reduce storage requirements."
- Break condition: If LoRA rank is too low, fine-tuning may fail to capture domain-specific nuances

### Mechanism 3
- Claim: BM25+ ensemble with LLM embeddings boosts recall and ranking accuracy
- Mechanism: BM25+ provides lexical matching while LLM embeddings capture semantic relevance; weighted sum yields robust retrieval
- Core assumption: Lexical and semantic signals are complementary and jointly cover surface and deep document-query matches
- Evidence anchors:
  - [section] "Our approach outperforms traditional baselines by leveraging the complementary strengths of multiple models, including fine-tuned Large Language Models (LLMs) and the BM25+ scoring method."
  - [section] "In our ensemble framework, we combine BM25+ scores with embeddings produced by fine-tuned LLMs. This allows us to integrate both traditional frequency-based retrieval (BM25+) and the rich semantic embeddings from LLMs..."
- Break condition: Poor ensemble weights may degrade performance below best single model

## Foundational Learning

- Concept: Dense retrieval and contrastive learning
  - Why needed here: Pipeline uses dense embeddings for semantic similarity and contrastive loss for learning from positive/negative pairs
  - Quick check question: What loss function is used to train the dense retriever, and why is it suitable for retrieval?

- Concept: Legal document structure and terminology
  - Why needed here: Dataset built from Japanese legal articles and employment contracts; understanding structure is critical for correct chunking and labeling
  - Quick check question: How are Japanese legal articles and contract clauses mapped to retrieval units in the dataset?

- Concept: Large language model fine-tuning strategies (LoRA, quantization)
  - Why needed here: Efficient adaptation of LLMs requires low-rank updates and precision reduction to fit memory constraints
  - Quick check question: What are the memory and speed benefits of LoRA and 16-bit quantization in the context of this pipeline?

## Architecture Onboarding

- Component map: Query → Tokenizer → LLM Encoder → EOS embedding → Cosine similarity → Ranking
- Critical path: Training → Phase 1 fine-tuning → Phase 2 fine-tuning → Inference (encode query + corpus, rank by similarity). Ensemble adds BM25+ reweighting step.
- Design tradeoffs: LLMs vs. traditional LMs for semantic depth; two-phase vs. single-phase training for balance of generalization and specificity; ensemble vs. single model for performance vs. simplicity
- Failure signatures: Overfitting in Phase 1 (poor generalization), insufficient hard negatives in Phase 2 (missed edge cases), poor ensemble weight tuning (degraded results)
- First 3 experiments:
  1. Train Phase 1 only and evaluate on Japanese legal dataset; compare recall/MRR to baseline dense retrievers
  2. Add Phase 2 hard-negative fine-tuning; measure improvement in precision and ranking metrics
  3. Integrate BM25+ into ensemble; evaluate if combined model outperforms both individual components

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of varying the number of hard negatives (a2) in Phase 2 on retrieval performance across different domains?
- Basis in paper: [explicit] The paper describes Phase 2 as focusing on top-a2 hard documents but does not systematically explore how different values of a2 affect performance
- Why unresolved: Experiments use fixed a2=50, leaving sensitivity to this hyperparameter unexplored
- What evidence would resolve it: Experiments varying a2 values (e.g., 10, 25, 50, 100) across multiple datasets and domains with performance metrics for each setting

### Open Question 2
- Question: How does the proposed two-phase approach compare to other multi-stage fine-tuning strategies for LLMs in text retrieval?
- Basis in paper: [inferred] The paper presents a novel two-phase approach but only compares it to baselines rather than directly comparing it to other multi-stage fine-tuning methods
- Why unresolved: Paper focuses on demonstrating superiority over existing baselines but does not benchmark against alternative multi-stage fine-tuning approaches
- What evidence would resolve it: Direct comparison of two-phase approach with other multi-stage fine-tuning strategies (e.g., CoCondenser, SRM) using same datasets and evaluation metrics

### Open Question 3
- Question: How does the ensemble model perform when incorporating different types of LLMs beyond LLaMA-2 and LLaMA-3?
- Basis in paper: [explicit] The paper mentions that combining LLaMA-2 and LLaMA-3 was not implemented due to resource constraints but represents a promising future direction
- Why unresolved: Paper only experiments with LLaMA-2 and mentions LLaMA-3 as future possibility without actual implementation or results
- What evidence would resolve it: Implementation and evaluation of ensemble models incorporating various LLMs (e.g., GPT, BERT variants) across multiple datasets with performance comparisons

### Open Question 4
- Question: What is the optimal balance between BM25+ scores and LLM embeddings in the ensemble model for different types of queries?
- Basis in paper: [inferred] The ensemble approach combines BM25+ and LLM embeddings but does not explore how weighting should vary based on query characteristics
- Why unresolved: Paper uses fixed weighting scheme (α) for BM25+ in ensemble but does not investigate adaptive weighting strategies
- What evidence would resolve it: Experiments testing different weighting schemes (α values) for BM25+ and LLM embeddings, potentially with adaptive weighting based on query complexity or domain

## Limitations

- Dataset Size and Generalization: Japanese legal dataset contains only 3,259 training examples, relatively small for LLM fine-tuning
- Reproducibility Challenges: Missing critical implementation details like exact LoRA parameters, quantization settings, and ensemble weighting schemes
- Comparative Benchmarking: Limited direct comparisons with other state-of-the-art dense retrievers on Japanese legal text

## Confidence

- **High Confidence**: The general two-phase training methodology (Phase 1 global context learning followed by Phase 2 hard-negative refinement) is well-explained and logically sound
- **Medium Confidence**: The effectiveness of the ensemble approach combining BM25+ with LLM embeddings is supported by results, but optimal weighting scheme sensitivity is not thoroughly explored
- **Low Confidence**: The long-term generalization of the model to other legal domains or languages, and robustness when scaled to larger datasets or different LLM architectures

## Next Checks

1. **Ablation Study on Phase 2 Hard Negatives**: Conduct experiments removing Phase 2 hard-negative fine-tuning to quantify the specific contribution of this component to overall performance. Analyze whether hard negatives selected in Phase 2 are truly challenging and distinct from Phase 1 easy negatives.

2. **Cross-Domain Evaluation**: Test the model's performance on legal documents from different Japanese legal domains (e.g., criminal law, civil law) not represented in the original training data to assess generalization capabilities and identify potential overfitting.

3. **Hyperparameter Sensitivity Analysis**: Systematically vary LoRA rank, quantization settings, and ensemble weights to determine stability of results and identify optimal configurations. This would help establish whether reported performance is robust or sensitive to specific parameter choices.