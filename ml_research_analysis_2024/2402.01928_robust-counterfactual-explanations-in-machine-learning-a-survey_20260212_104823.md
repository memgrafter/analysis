---
ver: rpa2
title: 'Robust Counterfactual Explanations in Machine Learning: A Survey'
arxiv_id: '2402.01928'
source_url: https://arxiv.org/abs/2402.01928
tags:
- robustness
- u1d465
- robust
- counterfactual
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey systematically analyses the rapidly growing field
  of robust counterfactual explanations (CEs) in machine learning. The authors categorize
  robustness into four types: robustness against Model Changes (MC), Model Multiplicity
  (MM), Noisy Execution (NE), and Input Changes (IC).'
---

# Robust Counterfactual Explanations in Machine Learning: A Survey

## Quick Facts
- arXiv ID: 2402.01928
- Source URL: https://arxiv.org/abs/2402.01928
- Authors: Junqi Jiang; Francesco Leofante; Antonio Rago; Francesca Toni
- Reference count: 10
- Primary result: Systematic survey classifying robust counterfactual explanation methods into four categories: Model Changes (MC), Model Multiplicity (MM), Noisy Execution (NE), and Input Changes (IC)

## Executive Summary
This survey systematically analyzes the rapidly growing field of robust counterfactual explanations (CEs) in machine learning. The authors categorize robustness into four distinct types and review existing methods, metrics, and theoretical guarantees for each category. Key findings include the inherent trade-off between CE cost and robustness, the potential connections between robustness and fairness, and the need for standardized benchmarks and user studies. The work provides a comprehensive overview of current state-of-the-art approaches and identifies important directions for future research in robust CE generation.

## Method Summary
The survey employed a keyword-based search methodology on Google Scholar, using patterns like "robust counterfactual explanation" and related terms, filtering for technical papers from 2017 onwards. The authors categorized identified approaches based on the form of robustness they consider (MC, MM, NE, IC) and detailed their suitable models, required model access, computational methods, and theoretical guarantees. The analysis covers evaluation metrics, solution approaches, and theoretical results for each robustness category.

## Key Results
- CE robustness can be categorized into four types: Model Changes, Model Multiplicity, Noisy Execution, and Input Changes
- A fundamental trade-off exists between CE cost and robustness that varies across different robustness categories
- Theoretical guarantees can be provided using different mathematical frameworks (MIP, probabilistic, argumentative ensembling) depending on the robustness category
- Connections between robustness and fairness remain largely unexplored despite recent theoretical indications

## Why This Works (Mechanism)

### Mechanism 1
Different forms of model changes require different mathematical characterizations and solution approaches. Each robustness category targets a specific type of perturbation or variation in the explanation generation process. MC handles parameter changes, MM handles model multiplicity, NE handles noisy execution, and IC handles input changes. This allows tailored solutions.

### Mechanism 2
The cost-robustness tradeoff is a fundamental constraint in counterfactual explanation generation. More robust explanations typically require moving further from decision boundaries, which increases the cost (distance) of the explanation. This tradeoff is inherent because robustness requires the explanation to remain valid under more scenarios.

### Mechanism 3
Theoretical guarantees can be provided for specific robustness categories using different mathematical frameworks. MIP encodings provide deterministic guarantees for MC and NE, while probabilistic approaches handle MC and NE under distributional assumptions. For MM, argumentative ensembling provides formal guarantees. The choice of framework depends on the robustness category and desired guarantee type.

## Foundational Learning

- Concept: Counterfactual explanation generation as optimization problem
  - Why needed here: Understanding the base CE formulation (Eq 1 and 2) is crucial for understanding how robustness modifications work
  - Quick check question: What are the two main formulations for counterfactual explanation generation mentioned in the paper?

- Concept: Model multiplicity and its implications for explanations
  - Why needed here: MM is a distinct robustness category that requires understanding why multiple models with similar accuracy can give different explanations
  - Quick check question: Why might a counterfactual explanation valid for one model in a set of equally performing models not be valid for others?

- Concept: Adversarial robustness concepts and their relation to counterfactual explanations
  - Why needed here: Several robustness approaches borrow techniques from adversarial ML, and understanding these connections is important
  - Quick check question: How do local robustness queries from adversarial ML apply to evaluating counterfactual explanations?

## Architecture Onboarding

- Component map: Input processing → Model access layer → Robustness category selector → Appropriate robustness method → Output CE with robustness guarantees
- Critical path: For a given input and model, select appropriate robustness category → Apply corresponding method → Generate CE → Validate robustness → Output result
- Design tradeoffs: MIP methods offer strong guarantees but are computationally expensive; gradient methods are faster but may only provide weaker guarantees; probabilistic methods balance between these extremes
- Failure signatures: CE invalidation under perturbations, excessive computational cost, inability to find valid CEs, violation of theoretical guarantees
- First 3 experiments:
  1. Implement a simple MC robustness method (e.g., Upadhyay et al. 2021) and test on a linear model with synthetic parameter perturbations
  2. Compare VaR metric calculations for MC robustness across different update strategies (retraining, incremental updates)
  3. Implement a basic IR calculation for NE robustness and test with Gaussian noise on a simple model

## Open Questions the Paper Calls Out

### Open Question 1
What is the exact nature of the trade-off between robustness and cost in counterfactual explanations for non-linear models like neural networks? Most theoretical results on robustness-cost trade-offs focus on linear models. For non-linear models, empirical observations suggest different behaviors that are not yet fully understood.

### Open Question 2
Are the existing notions of robustness (model changes, model multiplicity, noisy execution, input changes) strictly disjoint, or are there fundamental connections between them? While some studies have explored individual robustness notions, there is limited work examining the relationships and potential overlaps between different types of robustness.

### Open Question 3
How do robustness and fairness in counterfactual explanations relate to each other, and under what conditions does robustness imply fairness? While initial results suggest a relationship between robustness and fairness, the precise conditions under which robustness guarantees fairness (or vice versa) are not yet established.

## Limitations

- The keyword-based search methodology may have introduced selection bias, particularly for approaches using different terminology
- The categorization into four robustness types assumes these categories are mutually exclusive and collectively exhaustive
- The survey covers papers from 2017 onwards, potentially missing foundational work from earlier periods

## Confidence

**High confidence**: The classification of robustness approaches into four distinct categories is well-supported by the literature review and shows clear methodological differences between categories.

**Medium confidence**: The identification of trade-offs between cost and robustness is supported by multiple papers, but the universality of this tradeoff across all contexts requires further validation.

**Medium confidence**: The connections drawn between robustness and fairness are based on theoretical reasoning, but empirical validation of these connections is limited in the current literature.

## Next Checks

1. Conduct additional keyword searches using alternative terminology (e.g., "algorithmic recourse", "stable explanations") to verify the completeness of the paper collection and assess whether important approaches were missed.

2. Implement and compare multiple MC robustness methods (MIP-based and probabilistic) on identical benchmark problems to empirically verify the cost-robustness tradeoff across different contexts.

3. Analyze the practical implications of different theoretical guarantee frameworks (MIP vs probabilistic) by testing their performance under realistic perturbation scenarios beyond the assumptions made in theoretical proofs.