---
ver: rpa2
title: Counterfactual Explanations of Black-box Machine Learning Models using Causal
  Discovery with Applications to Credit Rating
arxiv_id: '2402.02678'
source_url: https://arxiv.org/abs/2402.02678
tags:
- causal
- graph
- variable
- variables
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel explainable AI (XAI) framework that
  relaxes the assumption that the causal graph is known. The framework leverages counterfactual
  probabilities and integrates a causal graph estimated through causal discovery methods
  with a black-box classification model.
---

# Counterfactual Explanations of Black-box Machine Learning Models using Causal Discovery with Applications to Credit Rating

## Quick Facts
- arXiv ID: 2402.02678
- Source URL: https://arxiv.org/abs/2402.02678
- Reference count: 28
- Proposes an XAI framework that integrates causal discovery with black-box models for counterfactual explanations when causal graphs are unknown

## Executive Summary
This paper addresses the challenge of generating counterfactual explanations for black-box machine learning models when the underlying causal structure is unknown. The proposed framework integrates causal discovery methods with the LEWIS counterfactual explanation technique, relaxing the common assumption that the causal graph must be known a priori. The method estimates causal relationships from data and uses these to compute counterfactual probabilities that account for the true causal structure. The framework is evaluated on both artificial datasets with known ground truth and real-world credit rating data from Shiga Bank, Japan, demonstrating improved accuracy in explanatory scores compared to methods that ignore causal structure.

## Method Summary
The proposed framework combines causal discovery algorithms with counterfactual explanation generation. First, a causal graph is estimated from observational data using various discovery methods (PC, DirectLiNGAM, RESIT, LiM, NOTEARS, NOTEARS-MLP). The estimated graph is then used with the LEWIS method to compute counterfactual probabilities for explanatory scores (Nesuf, Nec, Suf). The framework generates artificial data from specified causal structures with both linear and nonlinear functions, then performs causal discovery and explanatory score estimation. Performance is evaluated using mean absolute error (MAE) and Spearman's rank correlation coefficient (SPR) by comparing estimated scores against ground truth values. The method is also applied to real-world credit rating data after appropriate preprocessing and discretization.

## Key Results
- Artificial data experiments show the proposed method achieves higher Spearman correlation coefficients (up to 0.934) compared to methods without causal graph information
- The framework demonstrates improved explanatory score estimation accuracy, with MAE values significantly lower when causal structure is incorporated
- Real-world application to Shiga Bank credit rating data successfully demonstrates the method's effectiveness in practical scenarios where causal graphs are unknown

## Why This Works (Mechanism)
The framework works by incorporating causal structure information into counterfactual explanation generation. When explaining black-box model predictions, the causal relationships between variables determine how changes propagate through the system. By first discovering the causal graph and then using it to generate counterfactuals, the method ensures that suggested changes respect the true causal dependencies rather than just statistical correlations. This leads to more realistic and actionable explanations, as the counterfactuals represent interventions that would actually affect the outcome through the correct causal pathways rather than spurious correlations.

## Foundational Learning

**Causal Discovery**: Algorithms that infer causal relationships from observational data without interventions. Needed to estimate the causal graph when it's unknown, enabling causal reasoning in the explanation process. Quick check: Verify the estimated graph matches known structures in synthetic data.

**Counterfactual Probabilities**: Probabilities of observing alternative outcomes under hypothetical interventions. Needed to quantify the likelihood of different counterfactual scenarios consistent with the causal model. Quick check: Ensure probabilities sum to 1 across all counterfactuals.

**Monotonicity Assumption**: The condition that changing an input variable always increases or always decreases the output. Needed for the LEWIS method to guarantee valid counterfactual explanations. Quick check: Test monotonicity on training data before applying LEWIS.

**Causal Sufficiency**: The assumption that all common causes of observed variables are included in the analysis. Needed for accurate causal discovery and valid counterfactual reasoning. Quick check: Assess whether latent variables could plausibly affect multiple observed variables.

## Architecture Onboarding

**Component Map**: Data → Preprocessing → Causal Discovery → Causal Graph → LEWIS Method → Counterfactual Explanations → Evaluation Metrics

**Critical Path**: The causal discovery step is the critical path as it determines the quality of subsequent counterfactual explanations. Errors in graph estimation propagate through to the final explanatory scores.

**Design Tradeoffs**: The framework trades computational complexity (running causal discovery algorithms) for improved explanation accuracy. More sophisticated discovery methods may yield better graphs but require more computational resources and may be less stable with limited data.

**Failure Signatures**: Poor causal graph estimation leads to unreliable counterfactual explanations. This manifests as low correlation between estimated and true explanatory scores, particularly in cases with nonlinear relationships or limited sample sizes.

**First Experiments**:
1. Generate artificial data from a simple causal graph and verify the framework correctly recovers explanatory scores
2. Compare performance of different causal discovery algorithms on the same dataset to identify the most robust method
3. Test the sensitivity of explanatory scores to the choice of discretization method in preprocessing

## Open Questions the Paper Calls Out

**Open Question 1**: Does the proposed XAI framework maintain its effectiveness when applied to multi-class classification problems? The paper mentions LEWIS has been extended to multi-class classification but doesn't evaluate the framework's performance in such scenarios, as experiments only demonstrate binary classification tasks.

**Open Question 2**: How sensitive is the proposed framework to the choice of causal discovery method? While the paper evaluates multiple methods (PC, DirectLiNGAM, RESIT, LiM, NOTEARS, NOTEARS-MLP), it doesn't conduct a systematic comparison or sensitivity analysis to determine the impact of method choice on framework performance.

**Open Question 3**: Can the proposed framework handle non-linear causal relationships effectively? The paper indicates the framework can handle nonlinear structures, but experimental results show lower performance for nonlinear cases compared to linear ones, especially with Gaussian distributions, without detailed analysis of this limitation.

## Limitations

- The proprietary nature of the credit rating dataset prevents independent verification of real-world application results
- Causal discovery methods may struggle with high-dimensional data or strong confounding relationships
- The framework assumes causal sufficiency, which may not hold when latent variables influence multiple observed variables
- The LEWIS method's reliance on monotonicity assumptions could lead to unreliable scores when this assumption is violated

## Confidence

- Effectiveness in artificial data settings: High
- Applicability to real-world credit rating data: Medium
- Robustness across different causal discovery methods: Medium
- Performance on multi-class classification: Low
- Handling of nonlinear causal relationships: Low

## Next Checks

1. **Reproduce artificial data experiments** using the specified causal graph (Figure 4) and verify the improvement in explanatory score estimation when incorporating causal graph information versus using methods without such information.

2. **Implement and compare multiple causal discovery algorithms** (PC, DirectLiNGAM, RESIT, LiM, NOTEARS, NOTEARS-MLP) on the same datasets to assess their relative performance and robustness in estimating the causal graph structure.

3. **Conduct sensitivity analysis** on the real-world credit rating data by systematically varying the causal discovery method and prior information to evaluate the stability and reliability of the explanatory scores across different configurations.