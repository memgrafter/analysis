---
ver: rpa2
title: 'Pfeed: Generating near real-time personalized feeds using precomputed embedding
  similarities'
arxiv_id: '2402.16073'
source_url: https://arxiv.org/abs/2402.16073
tags:
- item
- items
- embeddings
- query
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Pfeed is a near real-time personalized feed system that dynamically
  updates customer profiles every two minutes using precomputed embedding similarities.
  It addresses limitations of traditional user-item embedding approaches by representing
  customers as sets of query embeddings (based on viewed/bought items) rather than
  single vectors, enabling better diversity representation and interpretability.
---

# Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities

## Quick Facts
- arXiv ID: 2402.16073
- Source URL: https://arxiv.org/abs/2402.16073
- Reference count: 38
- Achieved 4.9% conversion uplift in online A/B testing

## Executive Summary
Pfeed introduces a near real-time personalized feed system that addresses limitations of traditional user-item embedding approaches by representing customers as sets of query embeddings rather than single vectors. The system dynamically updates customer profiles every two minutes using precomputed embedding similarities, enabling better diversity representation and interpretability. Deployed at Bol, Pfeed generates personalized feeds like "Top deals for you" and "New for you," demonstrating practical improvements in recommendation conversion rates.

## Method Summary
Pfeed represents customers using sets of query embeddings based on viewed and bought items, overcoming the diversity and interpretability limitations of single-vector representations. The system employs a transformer-based SIMO (Single Input Multi-Output) model that generates three embeddings per item (view query, buy query, target) in a single inference run, achieving 3x efficiency improvements. Customer profiles are dynamically updated every two minutes using precomputed embedding similarities, enabling near real-time personalization while maintaining computational efficiency.

## Key Results
- Achieved 4.9% conversion uplift in online A/B testing compared to non-personalized recommendations
- Generates personalized feeds ("Top deals for you", "New for you", etc.) for customers
- Uses precomputed embedding similarities for 2-minute dynamic customer profile updates

## Why This Works (Mechanism)
Pfeed works by fundamentally changing how customer preferences are represented in recommendation systems. Instead of using a single embedding vector that struggles to capture diverse interests, it represents customers as sets of query embeddings derived from their viewing and purchasing history. This approach allows the system to maintain multiple interest dimensions simultaneously. The transformer-based SIMO model processes items once to generate three different embeddings (view query, buy query, target), making the system computationally efficient while preserving the ability to capture nuanced customer preferences through multiple embedding perspectives.

## Foundational Learning
- **Embedding similarity computation**: Why needed - to measure how closely related items are in vector space for recommendation purposes. Quick check - verify cosine similarity produces meaningful rankings for related products.
- **Transformer-based architectures**: Why needed - to efficiently process sequential data and generate multiple output embeddings from single inputs. Quick check - confirm attention mechanisms properly weight item features during embedding generation.
- **Dynamic profile updating**: Why needed - to ensure recommendations reflect current customer interests rather than stale historical data. Quick check - validate 2-minute update interval provides meaningful freshness improvements.

## Architecture Onboarding
**Component Map**: Customer History -> Query Embedding Generator -> SIMO Model -> Target Embeddings -> Similarity Engine -> Personalized Feed
**Critical Path**: The system processes customer item history through the query embedding generator, which feeds into the SIMO model to produce target embeddings. These are compared against precomputed similarities to generate the final personalized feed within the 2-minute update window.
**Design Tradeoffs**: Uses three embeddings per item for better representation at the cost of increased storage, but compensates through 3x inference efficiency. Updates every 2 minutes balancing freshness against computational overhead.
**Failure Signatures**: Conversion rates dropping when item similarity distributions become too narrow, indicating lack of diversity; increased latency during peak update windows suggesting computational bottlenecks.
**First Experiments**: 1) Test SIMO model output quality by comparing three-embedding representation against single-vector baselines on held-out data. 2) Validate 2-minute update frequency by measuring recommendation relevance decay over time. 3) Benchmark computational costs at scale by simulating increasing customer loads.

## Open Questions the Paper Calls Out
None

## Limitations
- Single A/B test results lack statistical significance details and duration information
- Performance evaluation focuses on conversion metrics without addressing diversity, novelty, or long-term engagement
- No details provided about computational costs, storage requirements, or scalability beyond 2-minute update interval

## Confidence
- Transformer-based SIMO model efficiency claim (3x improvement): Medium - based on reported architecture but lacking comparative benchmarks
- 4.9% conversion uplift: Low - single A/B test without statistical details
- Customer profile representation improvement: High - architectural changes are well-defined and logical

## Next Checks
1. Conduct longer-term A/B testing (minimum 4 weeks) with multiple business metrics including diversity scores, novelty metrics, and long-term engagement to validate the 4.9% conversion claim and assess potential negative effects
2. Benchmark computational costs and storage requirements at scale, testing update intervals below 2 minutes and measuring performance degradation with increasing user base
3. Perform ablation studies comparing the three-embedding representation against traditional single-vector approaches across multiple datasets to quantify improvements in diversity and interpretability claims