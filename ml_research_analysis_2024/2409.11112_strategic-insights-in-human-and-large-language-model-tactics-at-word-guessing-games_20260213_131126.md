---
ver: rpa2
title: Strategic Insights in Human and Large Language Model Tactics at Word Guessing
  Games
arxiv_id: '2409.11112'
source_url: https://arxiv.org/abs/2409.11112
tags:
- guess
- game
- guesses
- word
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how humans and large language models (LLMs)
  approach word-guessing games like Wordle. The authors conducted a survey of Latvian
  Wordle players to understand human strategies and motivations, finding that most
  players use daily as part of their routine, with entertainment and mental exercise
  being key motivators.
---

# Strategic Insights in Human and Large Language Model Tactics at Word Guessing Games

## Quick Facts
- arXiv ID: 2409.11112
- Source URL: https://arxiv.org/abs/2409.11112
- Reference count: 3
- Humans outperform LLMs in Wordle-like games due to better feedback integration and strategic starting word selection

## Executive Summary
This paper investigates how humans and large language models approach word-guessing games like Wordle. The authors conducted a survey of Latvian Wordle players to understand human strategies and motivations, finding that most players use daily as part of their routine, with entertainment and mental exercise being key motivators. They also evaluated several open-access LLMs (ChatGPT, Gemini, Claude, Mistral, and Llama 3) on their ability to guess words in English and Latvian. Results show that while some LLMs perform reasonably well on English words, they struggle significantly with generating correct-length guesses and often produce non-existent words, especially in Latvian. Overall, the study highlights the gap between human and LLM performance in language-based games and suggests room for improvement in LLM capabilities.

## Method Summary
The study employed a mixed-methods approach: a survey of Latvian Wordle players to gather insights on human strategies and motivations, and systematic testing of several open-access LLMs on word-guessing tasks. The LLMs were prompted to play Wordle in both English and Latvian using zero-shot prompting with structured feedback formats. Ten target words (five in each language) were used for evaluation, with responses analyzed for correct guesses, adherence to word length, and generation of valid vs. non-existent words.

## Key Results
- Humans outperform LLMs in Wordle-like games due to better feedback integration and strategic starting word selection
- LLMs struggle significantly with generating correct-length guesses and often produce non-existent words, especially in Latvian
- While some LLMs perform reasonably well on English words, none consistently match human-level performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Humans outperform LLMs in Wordle-like games due to their ability to dynamically incorporate partial feedback into subsequent guesses.
- Mechanism: Humans use a feedback loop where each revealed hint directly shapes the next guess, prioritizing correct-position letters and avoiding previously eliminated options. LLMs often generate guesses without fully integrating all available hints, leading to repeated errors or non-existent words.
- Core assumption: LLMs process hints sequentially but may fail to maintain a complete working memory of all constraints, unlike humans who naturally integrate multiple hints into a coherent strategy.
- Evidence anchors:
  - [abstract] "Results highlight the struggles of certain models to maintain correct guess length and generate repetitions, as well as hallucinations of non-existent words and inflections."
  - [section 4] "Indeed most players, the authors included, more often than not follow the other strategy of forming each subsequent guess with the hints uncovered in previous guesses."
- Break condition: If LLMs are provided with a consolidated list of all hints before making each guess, their performance improves, suggesting the issue is not the feedback itself but the model's ability to retain and process it.

### Mechanism 2
- Claim: Humans select starting words that maximize information gain (e.g., covering high-frequency letters), while LLMs do not consistently use this strategy.
- Mechanism: Humans choose initial guesses based on letter frequency analysis (e.g., "OTHER" and "NAILS" for English), which statistically increases the chance of uncovering correct letters early. LLMs often default to common but less optimal starting words (e.g., "HOUSE" or "TABLE").
- Core assumption: Information-theoretic approaches are more effective for narrowing down possibilities quickly, and humans intuitively apply this principle.
- Evidence anchors:
  - [abstract] "An example of this in English would be guessing 'OTHER' and 'NAILS', which [cover] 10 of the top 12 most frequently used letters in English."
  - [section 4] "Among the 10 game sessions, both Llama 3 models tended to use 'HOUSE' as an opening guess, with 8B using it a total of 4 times and 70B – twice."
- Break condition: If LLMs are explicitly prompted to use high-information starting words, their initial guess accuracy improves, but they still fail to adapt subsequent guesses based on hints.

### Mechanism 3
- Claim: LLMs struggle with non-English languages due to insufficient fine-tuning and lack of exposure to language-specific morphological patterns.
- Mechanism: Human players are familiar with their native language's vocabulary and inflection rules, allowing them to guess valid words even with partial information. LLMs, especially those not fine-tuned for the target language, generate non-existent words or fail to respect word length constraints.
- Core assumption: Language models require task-specific fine-tuning to handle morphology and vocabulary nuances effectively.
- Evidence anchors:
  - [abstract] "Results highlight the struggles of certain models to maintain correct guess length and generate repetitions, as well as hallucinations of non-existent words and inflections."
  - [section 5.3] "Mistral and the Llama 3 models cannot respond in Latvian when prompted to play the game in Latvian... the guesses were almost always non-existent words."
- Break condition: If LLMs are fine-tuned on a comprehensive corpus of the target language's vocabulary and inflections, their ability to generate valid guesses improves significantly.

## Foundational Learning

- Concept: Information Theory in Wordle Strategy
  - Why needed here: Understanding how to maximize information gain with each guess is critical for both human and LLM performance in word-guessing games.
  - Quick check question: If you want to maximize the chance of uncovering new letters in your first guess, should you choose a word with many unique, high-frequency letters or a common word with repeated letters?

- Concept: Feedback Integration and Constraint Satisfaction
  - Why needed here: Effective gameplay requires maintaining and applying all revealed hints to narrow down possible words; LLMs often fail to do this consistently.
  - Quick check question: After guessing "SLATE" and receiving hints that the second letter is correct and the last letter is not in the word, which of the following should you avoid in your next guess: words ending in 'E' or words with 'L' in the second position?

- Concept: Language Morphology and Vocabulary Coverage
  - Why needed here: Handling inflections, diacritics, and rare words is essential for non-English Wordle variants; LLMs often generate non-existent words in these cases.
  - Quick check question: In a language with many inflections (e.g., Latvian), is it more effective to guess common nominative singular forms or to attempt less common inflected forms early in the game?

## Architecture Onboarding

- Component map: Prompt → LM generation → Constraint check → Hint integration → Next guess
- Critical path: Prompt → LM generation → Constraint check → Hint integration → Next guess
- Design tradeoffs:
  - Model size vs. speed: Larger models may generate more valid words but are slower and costlier.
  - Zero-shot vs. fine-tuned: Zero-shot prompting is more flexible but less accurate for non-English languages.
  - Hint integration strategy: Explicit hint concatenation vs. implicit retention in context window.
- Failure signatures:
  - Repeated guesses: Hint integrator not updating constraints correctly.
  - Non-existent words: Language model not properly constrained or fine-tuned.
  - Wrong word length: Constraint checker not enforcing length rules.
- First 3 experiments:
  1. Test zero-shot prompting with explicit hint concatenation for all languages.
  2. Compare performance of base vs. fine-tuned models on non-English Wordle variants.
  3. Evaluate the impact of information-theoretic starting word selection on overall success rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specific prompting strategies affect LLM performance in word-guessing games?
- Basis in paper: [explicit] The paper discusses different prompting formats and mentions that initial experiments with emoji-based feedback were unsuccessful, while structured instructions with hints worked better.
- Why unresolved: The paper only briefly experimented with two prompting formats and didn't systematically explore the full space of possible prompting strategies.
- What evidence would resolve it: A systematic study comparing multiple prompting strategies (e.g., few-shot examples, chain-of-thought prompting, temperature adjustments) across different LLM architectures would clarify optimal prompting approaches.

### Open Question 2
- Question: What are the specific linguistic features that make word-guessing particularly difficult for LLMs in highly inflectional languages?
- Basis in paper: [explicit] The paper notes that LLMs struggle significantly with Latvian, producing non-existent words and inflections, and references prior work showing that uncommon inflections and plural forms make guessing harder for human players.
- Why unresolved: The paper identifies the problem but doesn't analyze which specific linguistic features (e.g., case endings, verb conjugations, accent placement) are most problematic.
- What evidence would resolve it: A detailed linguistic analysis comparing successful vs. unsuccessful guesses, identifying which morphological features correlate with LLM errors, would reveal the underlying challenges.

### Open Question 3
- Question: How does human expertise in word-guessing games develop over time, and what cognitive strategies underlie this improvement?
- Basis in paper: [explicit] The survey found that 50% of players don't find the game easier after playing long-term, and the gameplay analysis reveals different strategic approaches (information theory vs. hint-based guessing).
- Why unresolved: The paper presents initial findings about player strategies but doesn't track individual players over time or investigate the cognitive mechanisms behind strategy development.
- What evidence would resolve it: A longitudinal study following individual players, combined with cognitive analysis of their decision-making processes, would reveal how expertise develops and which strategies are most effective.

## Limitations

- Evaluation based on a small, fixed set of 10 target words (5 English, 5 Latvian), which may not be representative of overall model performance or the full diversity of possible Wordle puzzles
- No direct evidence provided for the core mechanism that humans dynamically integrate all hints into subsequent guesses—this is inferred from survey results and observed model behavior, not directly tested
- Study does not systematically test different prompt formulations or temperature settings, so it's unclear whether model failures are due to architecture limitations or suboptimal prompting

## Confidence

- High Confidence: LLMs struggle with generating correct-length guesses and often produce non-existent words, especially in Latvian
- Medium Confidence: Humans outperform LLMs due to better feedback integration and constraint satisfaction
- Low Confidence: Humans use information-theoretic strategies for starting word selection

## Next Checks

1. Test multiple prompt formulations (with explicit hint concatenation vs. implicit retention) across all models and languages to isolate the effect of prompting on hint integration and word validity
2. Expand the evaluation set to include a broader and more diverse set of target words (e.g., 50+ words per language) to assess whether observed model failures are consistent or sample-specific
3. Conduct a controlled experiment where humans and models are given identical game states and feedback, then compare their guess sequences to directly measure differences in feedback integration strategies