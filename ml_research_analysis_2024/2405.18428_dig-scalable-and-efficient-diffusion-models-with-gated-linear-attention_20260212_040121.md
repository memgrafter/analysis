---
ver: rpa2
title: 'DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention'
arxiv_id: '2405.18428'
source_url: https://arxiv.org/abs/2405.18428
tags:
- diffusion
- arxiv
- attention
- generation
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "DiG improves the efficiency of diffusion models by incorporating\
  \ Gated Linear Attention into the backbone architecture, achieving comparable performance\
  \ to standard transformers while significantly reducing computational cost. Specifically,\
  \ DiG-S/2 is 2.5\xD7 faster and saves 75.7% GPU memory compared to DiT-S/2 at 1792\
  \ resolution, and DiG-XL/2 is 4.2\xD7 faster than the Mamba-based model at 1024\
  \ resolution."
---

# DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention
## Quick Facts
- arXiv ID: 2405.18428
- Source URL: https://arxiv.org/abs/2405.18428
- Reference count: 40
- DiG achieves 2.5× speedup and 75.7% memory savings over DiT-S/2 at 1792 resolution while maintaining competitive FID scores

## Executive Summary
DiG introduces a novel diffusion model architecture that combines gated linear attention with a spatial reorientation module to achieve significant computational efficiency improvements while maintaining competitive image generation quality. The method addresses key limitations in existing linear attention-based models by incorporating local context awareness through block-wise scanning and spatial enhancement mechanisms. Experimental results demonstrate that DiG achieves 2.5× faster inference and 75.7% GPU memory savings compared to standard transformer-based approaches at high resolutions, while maintaining competitive performance on ImageNet generation tasks.

## Method Summary
DiG combines gated linear attention with a spatial reorientation and enhancement module to create an efficient diffusion model architecture. The key innovation is the integration of a lightweight spatial reorientation module that enables block-wise scanning while preserving local context awareness. This addresses the unidirectional modeling limitations of linear attention and maintains local detail sensitivity. The gated linear attention mechanism provides the computational efficiency benefits of sub-quadratic complexity while the spatial module ensures the model retains the spatial understanding necessary for high-quality image generation. The architecture is designed to be scalable across different model sizes while maintaining efficiency gains.

## Key Results
- DiG-S/2 achieves 2.5× speedup and 75.7% memory savings compared to DiT-S/2 at 1792 resolution
- DiG-XL/2 is 4.2× faster than Mamba-based models at 1024 resolution
- On ImageNet 256×256 generation, DiG-XL/2 achieves FID score of 8.60 with only 1.2M training steps
- Competitive performance with DiT and other sub-quadratic-time diffusion models while requiring significantly less computational resources

## Why This Works (Mechanism)
DiG works by combining the computational efficiency of gated linear attention with spatial awareness through a specialized reorientation module. The gated linear attention reduces the quadratic complexity of standard attention to linear time, enabling faster processing of long sequences. However, standard linear attention suffers from unidirectional modeling limitations and lack of local context awareness. The spatial reorientation and enhancement module addresses these limitations by enabling block-wise scanning that maintains local spatial relationships, effectively preserving the detail sensitivity needed for high-quality image generation while retaining the efficiency benefits of linear attention.

## Foundational Learning
**Gated Linear Attention**
- Why needed: Reduces computational complexity from quadratic to linear time in attention mechanisms
- Quick check: Verify that attention weights can be computed efficiently using gating mechanisms without full matrix multiplication

**Spatial Reorientation and Enhancement Module**
- Why needed: Addresses unidirectional modeling and local context awareness limitations in linear attention
- Quick check: Ensure block-wise scanning preserves spatial relationships while maintaining computational efficiency

**Diffusion Model Architecture**
- Why needed: Provides the probabilistic framework for iterative image generation through denoising
- Quick check: Confirm that noise prediction targets are properly formulated for the specific architecture

## Architecture Onboarding
**Component Map**
Gated Linear Attention -> Spatial Reorientation Module -> Denoising Network -> Image Generation Pipeline

**Critical Path**
The critical computational path flows from input tokens through gated linear attention, then through the spatial reorientation module for local context enhancement, before final denoising predictions are made. The gated attention provides the foundation for efficiency, while the reorientation module ensures quality is maintained.

**Design Tradeoffs**
The architecture trades some architectural complexity (additional spatial reorientation module) for significant computational efficiency gains. This adds parameters but enables linear-time processing versus quadratic-time standard attention. The block-wise scanning approach balances local detail preservation against computational overhead.

**Failure Signatures**
Potential failures include loss of long-range dependencies due to unidirectional modeling limitations, insufficient local context preservation leading to detail artifacts, and suboptimal gating mechanisms that don't properly balance efficiency with representational capacity.

**First Experiments**
1. Compare gated linear attention performance versus standard attention on synthetic attention tasks
2. Evaluate spatial reorientation module's ability to preserve local context in controlled spatial reasoning tasks
3. Benchmark computational efficiency (speed/memory) at increasing resolutions to verify linear scaling claims

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Efficiency claims are measured at specific resolutions and may not generalize across all use cases
- Limited qualitative evaluation of generated images, particularly regarding local detail preservation
- Training efficiency improvements demonstrated primarily through step counts rather than wall-clock time
- Unidirectional modeling limitation is addressed but practical impact on generation quality not extensively explored

## Confidence
**High confidence**: Architectural innovations are technically sound and well-described
**Medium confidence**: Efficiency improvements demonstrated but may be context-dependent on specific hardware and resolutions
**Medium confidence**: Competitive image quality claims are supported by FID scores but lack extensive qualitative validation

## Next Checks
1. Conduct comprehensive ablation studies to isolate contributions of spatial reorientation versus gated linear attention components
2. Test model across multiple hardware configurations and batch sizes to verify generalizability of efficiency claims
3. Perform extensive qualitative evaluation of generated images, focusing on local detail preservation and context awareness in complex scenes