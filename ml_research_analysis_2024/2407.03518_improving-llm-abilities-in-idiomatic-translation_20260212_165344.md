---
ver: rpa2
title: Improving LLM Abilities in Idiomatic Translation
arxiv_id: '2407.03518'
source_url: https://arxiv.org/abs/2407.03518
tags:
- idiom
- translation
- idioms
- english
- idiomatic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This research addresses the challenge of translating idiomatic
  expressions in machine translation while preserving both semantic accuracy and cultural
  nuance. The authors propose two complementary methods: Semantic Idiom Alignment
  (SIA), which uses cosine similarity between sentence embeddings to match idioms
  across languages, and LLM-based Idiom Alignment (LIA), which uses LLMs to generate
  corresponding idioms.'
---

# Improving LLM Abilities in Idiomatic Translation

## Quick Facts
- arXiv ID: 2407.03518
- Source URL: https://arxiv.org/abs/2407.03518
- Reference count: 4
- Key outcome: SIA method consistently outperformed others in GPT-4o translations, with average scores of 2.409 (EN→ZH) and 2.761 (ZH→EN), while achieving approximately 50% idiom-to-idiom correspondence rate

## Executive Summary
This research addresses the challenge of translating idiomatic expressions in machine translation while preserving both semantic accuracy and cultural nuance. The authors propose two complementary methods: Semantic Idiom Alignment (SIA), which uses cosine similarity between sentence embeddings to match idioms across languages, and LLM-based Idiom Alignment (LIA), which uses LLMs to generate corresponding idioms. Human evaluations on English-Chinese and Chinese-English translations show the SIA method consistently outperformed others in GPT-4o translations. The study also developed low-resource Urdu and Hindi idiom datasets.

## Method Summary
The study employs two primary methods for idiomatic translation. The Semantic Idiom Alignment (SIA) method uses SentenceTransformers embeddings to convert idiom meanings into vectors, then applies cosine similarity to identify target-language idioms with matching semantic content. The LLM-based Idiom Alignment (LIA) method uses GPT-4o to generate culturally appropriate idiom counterparts through multi-step prompting. Both methods are evaluated against direct translation baselines using human evaluators scoring on a 1-3 scale, as well as LLM-based evaluations. The research tested translations across multiple language pairs including English-Chinese, Chinese-English, Urdu-Hindi, and others.

## Key Results
- SIA method achieved average human evaluation scores of 2.409 (EN→ZH) and 2.761 (ZH→EN)
- Idiom-to-idiom correspondence rate was approximately 50% for SIA method
- Human evaluations showed 65% correlation with GPT-4o assessments versus 53% with GPT-4
- Urdu and Hindi idiom datasets were successfully developed using GPT-4o

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic similarity between idiom meanings across languages enables finding culturally appropriate translations.
- Mechanism: SentenceTransformer embeddings convert idiom meanings into vectors, then cosine similarity identifies target-language idioms with matching semantic content.
- Core assumption: Idiom meanings can be accurately represented as embeddings and cosine similarity will find culturally appropriate matches.
- Evidence anchors:
  - [abstract] "The first method employs the SentenceTransformers model to semantically generate cosine similarity scores between the meanings of the original and target language idioms, selecting the best idiom"
  - [section] "Using SentenceTransformers paraphrase-MiniLM-L6-v2, we generated embeddings for English meanings which are vector representations. These non-zero vectors capture the semantic meaning of the phrases. We then compare them with target language idioms using cosine similarity with a threshold of 0.7"
  - [corpus] Weak - no corpus evidence for this specific semantic similarity mechanism
- Break condition: If cosine similarity threshold is too high (misses matches) or too low (includes poor matches), or if idiom meanings cannot be accurately embedded.

### Mechanism 2
- Claim: LLMs can generate culturally appropriate idiom counterparts when prompted correctly.
- Mechanism: GPT-4o is prompted to find up to 3 target-language idioms matching the source idiom's meaning, then selects the best match.
- Core assumption: LLMs have sufficient cultural knowledge to generate appropriate idioms and can follow multi-step prompts reliably.
- Evidence anchors:
  - [abstract] "The second method uses an LLM to find a corresponding idiom in the target language for use in the translation (LLM-generated idiom method)"
  - [section] "For the LLM-based Idiom Alignment method, we first use GPT 4o to generate corresponding idioms in the target language that have the same meaning as the idiom in the original language"
  - [corpus] Weak - no corpus evidence for LLM-generated idiom accuracy
- Break condition: If LLM hallucinates idioms that don't exist, or if prompt variations lead to inconsistent outputs.

### Mechanism 3
- Claim: Human evaluators provide more reliable assessment of idiom translation quality than LLM evaluators.
- Mechanism: Human evaluators score translations on a 1-3 scale based on whether figurative meaning is preserved, compared to LLM evaluations.
- Core assumption: Human judgment better captures cultural nuance and idiomatic style than automated metrics.
- Evidence anchors:
  - [abstract] "Human evaluations on the English -> Chinese, and Chinese -> English show the Cosine Similarity Lookup method out-performed others in all GPT4o translations"
  - [section] "Evaluators didn't receive compensation. The specific task prompts and evaluation criteria are outlined in the table below"
  - [section] "Using a binary correlation we found that the GPT4o score matched the human evaluation score 65% of the time while the GPT4 score only matched 53% of the time"
- Break condition: If human evaluators lack fluency in target language or if evaluation criteria are ambiguous.

## Foundational Learning

- Concept: Cosine similarity and vector embeddings
  - Why needed here: To measure semantic similarity between idiom meanings across languages
  - Quick check question: If two idiom meanings have cosine similarity of 0.8, are they considered semantically similar enough to match?

- Concept: Idiom classification and cultural context
  - Why needed here: To understand why direct translation fails and why idiom-to-idiom translation preserves cultural nuance
  - Quick check question: Why is "break a leg" difficult to translate directly to Chinese?

- Concept: Prompt engineering for LLMs
  - Why needed here: To reliably generate appropriate idiom counterparts and avoid hallucinations
  - Quick check question: What prompt structure helps GPT-4o find matching idioms rather than generating new ones?

## Architecture Onboarding

- Component map: Data preprocessing -> Embedding generation -> Similarity matching/LLM generation -> Translation -> Evaluation
- Critical path: Semantic Idiom Alignment method: Extract idioms -> Embed meanings -> Cosine similarity search -> GPT confirmation -> Translation
- Design tradeoffs: SIA method trades comprehensiveness (limited idiom matches) for accuracy; LIA method trades control (potential hallucinations) for coverage
- Failure signatures: SIA fails when no idiom matches found; LIA fails when LLM generates inappropriate idioms; both fail when embeddings don't capture cultural nuance
- First 3 experiments:
  1. Test cosine similarity threshold tuning on a small idiom pair dataset
  2. Compare LLM-generated idioms with and without multi-step confirmation prompts
  3. Run human vs LLM evaluation comparison on 50 translations to measure correlation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the SIA method's idiom-to-idiom correspondence rate be improved beyond the current ~50% match rate, and what impact would this have on translation quality?
- Basis in paper: [explicit] The paper states "only about 1/2 of the idioms had a match in the SIA method" and suggests "Had there been a comprehensive dataset that had both the English idiom and its corresponding Chinese idiom, the method would have been much more effective."
- Why unresolved: The current dataset limitations prevent comprehensive idiom coverage, and the paper leaves exploration of more sophisticated semantic similarity measures as future work.
- What evidence would resolve it: Testing SIA with a more comprehensive idiom database showing improved correspondence rates and subsequent evaluation of translation quality improvements would demonstrate the impact.

### Open Question 2
- Question: Why does GPT-4o consistently score translations lower than GPT-4, and what specific aspects of GPT-4o's evaluation criteria make it more aligned with human judgments?
- Basis in paper: [explicit] "the GPT-4o evaluations consistently score the translations lower than the GPT4 evaluations; the evaluation done by GPT-4o matched more closely with the human evaluations" with "Using a binary correlation we found that the GPT4o score matched the human evaluation score 65% of the time while the GPT4 score only matched 53% of the time."
- Why unresolved: The paper notes GPT-4o is "more critical of the idiom translations" but doesn't specify which evaluation criteria or model architecture differences cause this alignment with human judgment.
- What evidence would resolve it: Comparative analysis of GPT-4 and GPT-4o evaluation prompts, assessment of which specific translation aspects each model emphasizes, and identification of model architecture differences that influence evaluation behavior.

### Open Question 3
- Question: How can the SIA method be adapted to better handle idioms with semantically similar but not identical meanings, such as pairing "blind as a bat" with "目光如豆"?
- Basis in paper: [explicit] The paper provides an example where "having extremely poor or no vision" ("blind as a bat") was paired with "having small and narrow vision; lacking in foresight" ("目光如豆"), noting these are "semantically similar but not the same."
- Why unresolved: The current cosine similarity approach with a fixed threshold cannot distinguish between semantically similar but contextually different idioms, and the paper suggests this as a limitation without proposing solutions.
- What evidence would resolve it: Development and testing of hybrid semantic similarity measures that incorporate contextual understanding, evaluation of improved matching accuracy for similar-but-different idioms, and assessment of translation quality improvements.

## Limitations

- Moderate idiom-to-idiom correspondence rate of approximately 50% limits translation coverage
- Reliance on specific LLM models introduces potential variability in performance
- Evaluation methodology may be affected by evaluator bias and fluency inconsistencies

## Confidence

**High Confidence**: The SIA method's effectiveness in improving semantic accuracy and cultural authenticity compared to direct translation baselines, supported by human evaluation scores showing consistent improvement (average 2.409 for EN→ZH and 2.761 for ZH→EN).

**Medium Confidence**: The claim that LLMs can reliably generate culturally appropriate idiom counterparts, as the study demonstrates this capability but acknowledges potential for hallucination and inconsistent outputs.

**Medium Confidence**: The assertion that human evaluations provide more reliable assessments than LLM evaluations, though the study shows correlation differences, it doesn't fully establish superiority in all evaluation contexts.

## Next Checks

1. **Cross-model validation**: Test the SIA and LIA methods across multiple LLM versions (GPT-4, Claude, Gemini) to assess robustness and identify model-specific performance variations in idiomatic translation.

2. **Longitudinal idiom correspondence analysis**: Expand the idiom-to-idiom correspondence study to include additional language pairs (e.g., Spanish-English, Arabic-French) and analyze whether the ~50% match rate holds across different language families and cultural contexts.

3. **Evaluation methodology refinement**: Conduct a controlled study comparing different evaluator pools (native speakers vs. fluent speakers) and different evaluation frameworks (binary vs. multi-point scoring) to determine optimal assessment approaches for idiomatic translation quality.