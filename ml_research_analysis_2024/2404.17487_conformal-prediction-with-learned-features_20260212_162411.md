---
ver: rpa2
title: Conformal Prediction with Learned Features
arxiv_id: '2404.17487'
source_url: https://arxiv.org/abs/2404.17487
tags:
- prediction
- coverage
- conformal
- plcp
- conditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Partition Learning Conformal Prediction (PLCP),
  a method that improves conditional coverage in conformal prediction by learning
  uncertainty-guided features from calibration data. Unlike prior work relying on
  predefined structures, PLCP iteratively learns partitions of the covariate space
  that characterize uncertainty levels in predictions.
---

# Conformal Prediction with Learned Features

## Quick Facts
- arXiv ID: 2404.17487
- Source URL: https://arxiv.org/abs/2404.17487
- Reference count: 40
- Primary result: Introduces Partition Learning Conformal Prediction (PLCP) that learns uncertainty-guided partitions for improved conditional coverage

## Executive Summary
This paper presents Partition Learning Conformal Prediction (PLCP), a method that improves conditional coverage in conformal prediction by learning uncertainty-guided features from calibration data. Unlike prior approaches that rely on predefined covariate partitions, PLCP iteratively learns partitions of the covariate space that characterize uncertainty levels in predictions. The method is implemented using alternating gradient descent with off-the-shelf ML models and provides theoretical guarantees on marginal and conditional coverage.

## Method Summary
PLCP introduces a novel approach to conformal prediction by learning uncertainty-guided features that partition the covariate space based on prediction uncertainty levels. The method uses alternating gradient descent to optimize both the feature learning and conformal prediction components simultaneously. Unlike traditional conformal methods that use predefined structures or simple discretization, PLCP dynamically learns partitions that better capture the relationship between covariates and prediction uncertainty. The approach is compatible with any off-the-shelf ML model and provides both theoretical guarantees and empirical improvements in coverage and prediction set length.

## Key Results
- Provides O(1/√m) convergence rate for MSCE with infinite data and perfect partitioning
- Achieves O(√(m log n + complexity(H))/n + 1/√m) finite-sample MSCE bound with high probability
- Demonstrates superior performance compared to Split Conformal, BatchGCP, and Conditional Calibration methods across four datasets (census, MNIST, synthetic regression, RxRx1)

## Why This Works (Mechanism)
PLCP improves conditional coverage by learning partitions that directly capture uncertainty patterns in the data rather than relying on arbitrary covariate groupings. The method uses an alternating optimization framework where uncertainty-guided features are learned to maximize the informativeness of partitions for prediction uncertainty. This learned partitioning adapts to the specific characteristics of the prediction problem and base model, creating regions where uncertainty levels are more homogeneous. The iterative learning process allows the method to discover complex, non-linear relationships between covariates and prediction uncertainty that would be missed by predefined partitioning schemes.

## Foundational Learning
- **Conformal prediction basics**: Why needed - foundation for understanding coverage guarantees; Quick check - verify understanding of non-conformity scores and quantile-based set construction
- **Conditional coverage**: Why needed - core motivation for learned partitions; Quick check - confirm ability to distinguish between marginal and conditional coverage requirements
- **Alternating optimization**: Why needed - key computational framework for PLCP; Quick check - validate understanding of coordinate descent and convergence properties
- **Hypothesis class complexity**: Why needed - critical for finite-sample theoretical bounds; Quick check - assess familiarity with Rademacher complexity and VC dimension concepts

## Architecture Onboarding

Component map: Data → Feature Learning → Partition Construction → Conformal Prediction → Prediction Sets

Critical path: Feature Learning → Partition Construction → Conformal Prediction

Design tradeoffs:
- Learned vs. predefined partitions: PLCP chooses learned partitions for better conditional coverage but requires more computation
- Alternating optimization: Balances feature learning and partition optimization but may converge to local optima
- Model complexity: More complex base models can improve accuracy but increase hypothesis class complexity

Failure signatures:
- Poor convergence of alternating optimization indicates inappropriate learning rate or initialization
- Overly granular partitions suggest overfitting to calibration data
- Inconsistent coverage across subgroups indicates feature learning isn't capturing uncertainty patterns

First experiments:
1. Compare PLCP coverage vs. baseline methods on simple synthetic dataset with known uncertainty patterns
2. Test convergence behavior of alternating optimization with different learning rates on small dataset
3. Evaluate sensitivity to partition granularity by varying m (number of regions) on census dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees assume infinite data and perfect partitioning, which may not be computationally feasible for high-dimensional spaces
- Performance depends heavily on hyperparameter tuning for the uncertainty-guided feature learning process
- Empirical evaluation focuses on synthetic and controlled distribution shifts rather than complex real-world scenarios

## Confidence
High: The core algorithmic contribution of learning uncertainty-guided partitions is technically sound and builds on established conformal prediction principles.

Medium: The theoretical guarantees are valid under stated assumptions, but their practical relevance depends on how well these assumptions translate to real-world conditions.

Medium: The empirical results demonstrate improvements over baseline methods, but the magnitude of improvement and generalizability require further validation.

## Next Checks
1. **Scalability Assessment**: Evaluate PLCP on high-dimensional datasets (d > 100) with thousands of potential partitions to assess computational feasibility and performance degradation patterns.

2. **Robustness to Hyperparameter Choices**: Conduct systematic ablation studies varying learning rates, partition thresholds, and model architectures to quantify sensitivity and establish robust default configurations.

3. **Real-World Distribution Shift Testing**: Apply PLCP to time-series data with natural temporal drift and multi-source heterogeneous data to evaluate performance under realistic, complex distribution shifts not present in controlled experimental settings.