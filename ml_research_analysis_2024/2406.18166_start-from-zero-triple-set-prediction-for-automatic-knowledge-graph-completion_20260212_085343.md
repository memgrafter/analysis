---
ver: rpa2
title: 'Start from Zero: Triple Set Prediction for Automatic Knowledge Graph Completion'
arxiv_id: '2406.18166'
source_url: https://arxiv.org/abs/2406.18166
tags:
- entity
- triples
- triple
- predict
- gpht
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Triple Set Prediction (TSP), a novel task\
  \ for automatic knowledge graph completion that predicts an entire set of missing\
  \ triples without any prior knowledge of their elements. The authors propose four\
  \ evaluation metrics\u2014three classification metrics (Joint Precision, Squared\
  \ Test Recall, and TSP Score) and one ranking metric (RST Score)\u2014to fairly\
  \ assess TSP results under both partial-open-world and closed-world assumptions."
---

# Start from Zero: Triple Set Prediction for Automatic Knowledge Graph Completion

## Quick Facts
- arXiv ID: 2406.18166
- Source URL: https://arxiv.org/abs/2406.18166
- Authors: Wen Zhang; Yajing Xu; Peng Ye; Zhiwei Huang; Zezhong Xu; Jiaoyan Chen; Jeff Z. Pan; Huajun Chen
- Reference count: 40
- One-line primary result: Proposes TSP task for predicting entire sets of missing triples without prior knowledge, with GPHT method achieving significant space reduction and performance gains over baselines

## Executive Summary
This paper introduces Triple Set Prediction (TSP), a novel task for automatic knowledge graph completion that predicts an entire set of missing triples without any prior knowledge of their elements. The authors propose four evaluation metrics—three classification metrics (Joint Precision, Squared Test Recall, and TSP Score) and one ranking metric (RST Score)—to fairly assess TSP results under both partial-open-world and closed-world assumptions. To tackle the challenge of the large candidate space, they develop GPHT, a subgraph-based method that combines graph partitioning with head-tail entity pair modeling and relationship modeling. Experiments on Wikidata-derived datasets and a complete family dataset show that GPHT outperforms baseline methods in both effectiveness and efficiency, achieving significantly faster prediction times while maintaining strong performance across all evaluation metrics.

## Method Summary
The GPHT method addresses TSP through a three-step approach: (1) Graph partitioning divides the KG into subgraphs to reduce the candidate triple space, (2) Head-tail entity modeling predicts entity pairs likely to have missing relations using relational GNNs and attention mechanisms, and (3) Relationship modeling predicts relations for selected entity pairs using KG embedding methods like HAKE or PairRE. The method also adapts existing rule-based (RuleTensor-TSP) and embedding-based (KGE-TSP) KGC methods as baselines for fair comparison.

## Key Results
- GPHT significantly outperforms baseline methods on Wikidata-derived datasets, achieving 6.9× to 30.4× speedup in prediction time
- The proposed TSP evaluation metrics (Joint Precision, Squared Test Recall, TSP Score, RST Score) provide comprehensive assessment under different open-world assumptions
- GPHT demonstrates strong performance on a complete family dataset, validating its effectiveness on both partial and complete KGs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed method GPHT reduces the candidate triple space through two complementary assumptions: (1) entities with large shortest path distance are unlikely to be related, and (2) even entities with short paths may lack relations due to semantic mismatch.
- Mechanism: GPHT first partitions the graph into subgraphs so that candidate triples are constrained to entities within the same subgraph. Then, it uses head-tail entity modeling to further filter pairs based on semantic likelihood of missing relations.
- Core assumption: Graph structure and semantic mismatch are strong indicators of missing relations in knowledge graphs.
- Evidence anchors:
  - [abstract]: "The first step is to predict a set of head-tail entity pairs with relations missing... reduce the candidate space effectively through the first step with graph partition and head-tail entity pair modeling."
  - [section]: "the number of candidates for a KG G = {E, R, T } is |E| × |R| × |E| − |T |. The number of candidate triples could reach 108 for a KG with thousands of entities."
  - [corpus]: Weak - no direct evidence in neighbors about space reduction via partitioning.

### Mechanism 2
- Claim: The four evaluation metrics (Joint Precision, Squared Test Recall, TSP Score, RST Score) fairly evaluate TSP results under both partial-open-world and closed-world assumptions.
- Mechanism: Joint Precision balances precision and recall in classification terms. Squared Test Recall penalizes small predicted sets to avoid trivial solutions. RST Score incorporates ranking to encourage high scores for true triples.
- Core assumption: Classification metrics alone cannot fully capture the quality of a triple set prediction task; ranking matters.
- Evidence anchors:
  - [abstract]: "To properly and accurately evaluate this new task, we propose 4 evaluation metrics including 3 classification metrics and 1 ranking metric, considering both the partial-open-world and the closed-world assumptions."
  - [section]: "J P recision is the average percentage of unknown-true triples in T W A predict and Tpredict... RST SP ensures that additionally predicting a true triple makes the ranking score higher and additionally predicting a false triple makes the ranking score lower."
  - [corpus]: Weak - neighbors focus on different completion tasks, not on TSP-specific evaluation metrics.

### Mechanism 3
- Claim: Adapting rule-based and embedding-based KGC methods to TSP as baselines enables fair comparison.
- Mechanism: RuleTensor-TSP uses tensor-based rule mining and inference to predict triples iteratively. KGE-TSP trains KG embedding models and uses a softmax over all possible triples to select high-scoring ones.
- Core assumption: Existing KGC methods can be repurposed for TSP by modifying their prediction outputs to return sets rather than single elements.
- Evidence anchors:
  - [abstract]: "To fairly compare the TSP results, we also propose two types of methods RuleTensor-TSP and KGE-TSP applying the existing rule- and embedding-based methods for TSP as baselines."
  - [section]: "RuleTensor-TSP: We use tensor calculation to simulate the rule reasoning... KGE-TSP: Given a KG G, we train the KGE model with triples in G..."
  - [corpus]: Weak - neighbors describe different methods but not adaptations to TSP.

## Foundational Learning

- Concept: Graph partitioning techniques (vertex-cut, edge-cut, hybrid)
  - Why needed here: To reduce the candidate triple space by grouping entities likely to have relations
  - Quick check question: How does the "soft" vertex-cut approach differ from traditional partitioning?

- Concept: Graph neural networks for relational data (RGNN, CompGCN)
  - Why needed here: To encode graph structure and relation-aware representations for head-tail entity modeling
  - Quick check question: What is the role of the inverse and self-loop triples in CompGCN?

- Concept: Knowledge graph embedding models (HAKE, PairRE)
  - Why needed here: To model missing relations between entity pairs predicted by HTEM
  - Quick check question: How do HAKE and PairRE differ in representing relations?

## Architecture Onboarding

- Component map: Graph Partition -> Head-tail Entity Modeling -> Relationship Modeling -> Final prediction
- Critical path: Graph Partition → HTEM → Relationship Modeling → Final prediction
- Design tradeoffs:
  - Larger subgraphs increase recall but also computational cost
  - HTEM threshold (θht) balances precision and recall
  - Relationship modeling method (HAKE vs PairRE) affects performance
- Failure signatures:
  - If predicted triple set is too small: HTEM threshold too high
  - If predicted triple set is too large: Relationship modeling threshold too low
  - If performance fluctuates: Randomness in subgraph selection or HTEM training
- First 3 experiments:
  1. Run GPHT with different subgraph sizes to observe impact on candidate space reduction
  2. Vary HTEM threshold θht to find optimal precision-recall tradeoff
  3. Compare HAKE vs PairRE in relationship modeling for final performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would TSP performance scale on KGs with significantly larger entity and relation sets than those tested in the paper?
- Basis in paper: [inferred] The paper tested TSP on datasets with up to 13,928 entities and 109 relations, but mentions the theoretical candidate space for TSP is |E| × |R| × |E| - |T|, which becomes enormous for larger KGs.
- Why unresolved: The paper only evaluated on relatively small datasets and mentions scalability as a challenge without providing empirical evidence on larger KGs.
- What evidence would resolve it: Experiments on industrial-scale KGs with millions of entities and relations, demonstrating whether GPHT and other TSP methods can maintain performance and efficiency at scale.

### Open Question 2
- Question: How sensitive is TSP performance to the choice of open-world assumption (CW A vs. RS-POW A vs. other variants) in real-world incomplete KGs?
- Basis in paper: [explicit] The paper proposes 4 evaluation metrics considering both partial-open-world (RS-POW A) and closed-world assumptions, but primarily evaluates under RS-POW A.
- Why unresolved: The paper doesn't compare TSP results under different open-world assumptions on the same datasets to quantify the impact on evaluation.
- What evidence would resolve it: Direct comparison of TSP methods' performance metrics under CW A, RS-POW A, and other reasonable open-world assumptions on multiple real-world KGs, showing how sensitive the results are to the assumption choice.

### Open Question 3
- Question: Can the graph partitioning strategy in GPHT be further optimized to achieve better trade-offs between candidate space reduction and information preservation?
- Basis in paper: [inferred] The paper presents a "soft" vertex-cut partition method with primary entity grouping and fine-tuning steps, achieving significant candidate space reduction, but doesn't explore alternative partitioning strategies.
- Why unresolved: The paper only evaluates one partitioning approach without comparing to other graph partitioning methods or optimization techniques.
- What evidence would resolve it: Comparative analysis of GPHT performance using different graph partitioning algorithms (e.g., METIS, Louvain method, spectral partitioning) or optimized versions of the current approach, measuring both space reduction and TSP accuracy.

## Limitations
- The proposed evaluation metrics may struggle to distinguish between high-quality and low-quality predictions when triple sets are of similar size
- TSP performance may be sensitive to the choice of HTEM threshold, potentially leading to unstable results across different runs
- The paper doesn't explore alternative graph partitioning strategies that might achieve better trade-offs between space reduction and information preservation

## Confidence
- High: The effectiveness of graph partitioning in reducing candidate space
- Medium: The proposed evaluation metrics adequately capture TSP quality
- Medium: GPHT's superiority over baseline methods on the tested datasets

## Next Checks
1. Test GPHT's performance on additional knowledge graphs with varying densities and relation types to assess generalizability
2. Conduct ablation studies to quantify the individual contributions of graph partitioning and head-tail entity modeling to overall performance
3. Compare TSP results with alternative methods that use external knowledge or entity descriptions to determine if GPHT's improvements are solely due to the proposed approach