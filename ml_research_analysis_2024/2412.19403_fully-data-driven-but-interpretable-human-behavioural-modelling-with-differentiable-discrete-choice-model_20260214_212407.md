---
ver: rpa2
title: Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable
  Discrete Choice Model
arxiv_id: '2412.19403'
source_url: https://arxiv.org/abs/2412.19403
tags:
- utility
- choice
- functions
- diff-dcm
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the differentiable discrete choice model
  (Diff-DCM), a fully data-driven method for interpretable human behavioral modelling.
  The core idea is to use differentiable programming to automatically estimate interpretable
  closed-form utility functions from input features and choice outcomes, without requiring
  expert knowledge.
---

# Fully Data-driven but Interpretable Human Behavioural Modelling with Differentiable Discrete Choice Model

## Quick Facts
- arXiv ID: 2412.19403
- Source URL: https://arxiv.org/abs/2412.19403
- Authors: Fumiyasu Makinoshima; Tatsuya Mitomi; Fumiya Makihara; Eigo Segawa
- Reference count: 40
- Primary result: Achieves 67.6% accuracy on real-world travel mode choice data, surpassing expert-designed benchmark models

## Executive Summary
This paper introduces Diff-DCM, a fully data-driven method for interpretable human behavioral modelling that automatically estimates closed-form utility functions from input features and choice outcomes. The core innovation uses differentiable programming to create a neural network architecture where weights directly correspond to coefficients and exponents in interpretable utility functions. Experimental results demonstrate high prediction accuracy on both synthetic data (up to 99.7%) and real-world travel mode choice data (67.6%), while maintaining interpretability of the estimated utility functions. The differentiability enables sensitivity analysis and optimal intervention path calculation for behavioral changes.

## Method Summary
Diff-DCM implements a neural network architecture that estimates interpretable utility functions through a log-exponential transformation. The model applies log transformation to input features, processes them through two fully connected layers with exponential activation, and uses softmax to convert utilities to choice probabilities. This design creates a one-to-one mapping between network weights and utility function exponents, enabling gradient-based optimization to automatically discover interpretable closed-form expressions. The model is trained using Adam optimizer with weight decay regularization, and can be fine-tuned to enforce integer exponents for enhanced interpretability.

## Key Results
- Achieves 99.7% prediction accuracy on synthetic linear utility data
- Achieves 67.6% accuracy on real-world Swissmetro travel mode choice data
- Surpasses expert-designed benchmark model with 62.7% accuracy on same dataset
- Demonstrates sensitivity analysis and optimal intervention path calculation capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Differentiable architecture enables gradient-based estimation of interpretable utility functions
- Mechanism: By implementing the utility function estimation as a neural network with log-exponential transformation, the weights directly correspond to exponents in the utility function. This allows gradient-based optimization to automatically discover interpretable closed-form expressions that fit the data.
- Core assumption: The log-exponential transformation creates a one-to-one mapping between network weights and utility function exponents that preserves interpretability
- Evidence anchors:
  - [abstract]: "Diff-DCM can estimate interpretable closed-form utility functions solely from input features and choice outcomes"
  - [section]: "the weights (w(1)ij and w(2)jk) and bias (b(2)k) correspond to the coefficients, exponents, and alternative-specific constants of the utility functions"
  - [corpus]: Weak evidence - no directly comparable differentiable DCM implementations found
- Break condition: If the log-exponential transformation introduces numerical instability or if the mapping between weights and exponents becomes non-unique

### Mechanism 2
- Claim: Softmax on utility functions enables discrete choice modeling while maintaining differentiability
- Mechanism: Applying softmax to the utility functions converts them to choice probabilities, making the loss between predictions and ground truth computable via cross-entropy. This maintains differentiability throughout the model for efficient gradient-based learning.
- Core assumption: The softmax function preserves the differentiability needed for gradient-based optimization while correctly modeling discrete choice behavior
- Evidence anchors:
  - [section]: "By applying the softmax(·) function to the utility functions, we can convert the utilities into choice probabilities pk, enabling the computation of the loss"
  - [section]: "Minimising this loss function is equivalent to maximising the log-likelihood function for parameter estimation in conventional DCM"
  - [corpus]: Weak evidence - no directly comparable softmax-based DCM implementations found
- Break condition: If the softmax function becomes numerically unstable with large utility values or if the model overfits due to the continuous approximation

### Mechanism 3
- Claim: Automatic differentiation enables sensitivity analysis and optimal intervention path calculation
- Mechanism: Since the entire model is differentiable, gradients of utilities with respect to input features can be computed to analyze how changes in features affect choices. This enables both sensitivity analysis (marginal utilities) and intervention planning (gradient-based feature updates).
- Core assumption: The gradients computed via automatic differentiation accurately represent the true sensitivity of choices to feature changes
- Evidence anchors:
  - [section]: "gradients available from automatic differentiation can be utilised for various analysis"
  - [section]: "the sensitivity is given by ∂V/∂x, which is easily obtained via automatic differentiation"
  - [section]: "the optimal direction to making the choice of the individual ϕ(x) close to the desired choice y∗ is given by the gradient of the loss with respect to x"
  - [corpus]: Weak evidence - no directly comparable intervention path calculations found
- Break condition: If the computed gradients become unreliable due to local optima or if the intervention path calculation diverges from the desired outcome

## Foundational Learning

- Concept: Discrete Choice Modeling (DCM)
  - Why needed here: Diff-DCM builds upon conventional DCM principles but automates the utility function specification
  - Quick check question: What is the fundamental difference between logit models and linear regression in terms of choice behavior modeling?

- Concept: Automatic Differentiation
  - Why needed here: Enables efficient gradient-based optimization and sensitivity analysis throughout the differentiable model
  - Quick check question: How does automatic differentiation differ from numerical differentiation in terms of computational efficiency and accuracy?

- Concept: Neural Network Architecture Design
  - Why needed here: The specific log-exponential transformation in Diff-DCM creates the interpretable utility function mapping
  - Quick check question: What architectural choices in neural networks can preserve interpretability while maintaining learning capability?

## Architecture Onboarding

- Component map: Input layer (log-transformed features) → First FC layer (creates polynomial terms via weights as exponents) → Exponential activation → Second FC layer (linear combination of terms) → Softmax (choice probabilities) → Loss computation
- Critical path: Data preprocessing (log transform, normalization) → Forward pass through architecture → Loss computation → Backward pass (automatic differentiation) → Parameter update (Adam optimizer)
- Design tradeoffs: Flexibility vs. interpretability (more complex terms increase expressiveness but reduce interpretability), computational efficiency vs. model complexity (larger networks require more computation but may capture more complex patterns)
- Failure signatures: NaN values from log transform on non-positive inputs, exploding gradients from exponential activation, overfitting from excessive model complexity
- First 3 experiments:
  1. Train on synthetic linear utility data and verify recovered utility functions match ground truth
  2. Test sensitivity analysis on a known nonlinear utility function to verify gradient accuracy
  3. Implement optimal intervention path calculation on a simple synthetic dataset with known intervention targets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Diff-DCM be extended to handle choice problems involving nests or hierarchical structures, similar to nested logit models?
- Basis in paper: [explicit] The paper mentions that an extension would be required for choice involving nests or hierarchical structures, referencing the nested logit model as a conventional DCM approach.
- Why unresolved: The paper does not provide a differentiable implementation for nested logit models or hierarchical structures.
- What evidence would resolve it: A demonstration of Diff-DCM extended to handle nested or hierarchical choice problems with comparable performance to nested logit models.

### Open Question 2
- Question: What are the limits of Diff-DCM's interpretability when utility functions become extremely complex with many interaction terms?
- Basis in paper: [inferred] The paper discusses that complex utility functions with many interaction terms may be difficult to comprehend and suggests using regularization and fine-tuning to simplify them.
- Why unresolved: The paper does not provide a quantitative analysis of when interpretability breaks down or guidelines for managing complexity.
- What evidence would resolve it: Systematic studies showing the trade-off between model complexity and interpretability, with benchmarks for when interpretability becomes impractical.

### Open Question 3
- Question: How can Diff-DCM be integrated into differentiable agent-based simulations to estimate behavioral models from broader types of observations beyond choice outcomes?
- Basis in paper: [explicit] The paper discusses the potential integration of Diff-DCM into differentiable agent-based simulations to enable estimation from various observations via gradient-based optimizations.
- Why unresolved: The paper does not provide a concrete implementation or demonstration of such integration.
- What evidence would resolve it: A working example of Diff-DCM integrated into a differentiable agent-based simulation, showing successful behavioral model estimation from diverse observational data.

## Limitations
- Limited validation on diverse real-world datasets beyond the Swissmetro example
- Unclear robustness of the log-exponential transformation to noise and outliers
- Potential overfitting concerns with the flexible polynomial terms in utility functions
- No comprehensive ablation studies on architectural choices

## Confidence
- High confidence: Prediction accuracy on synthetic data, implementation feasibility of the differentiable architecture
- Medium confidence: Prediction accuracy on real-world data, comparison with benchmark models
- Low confidence: Full interpretability of recovered utility functions, generalizability across diverse behavioral domains

## Next Checks
1. Conduct systematic sensitivity analysis on real-world datasets to verify the stability and reliability of computed gradients for intervention planning
2. Implement cross-validation experiments on multiple behavioral datasets to assess generalizability and potential overfitting
3. Perform detailed ablation studies removing different architectural components (e.g., log transform, polynomial terms) to quantify their contribution to model performance and interpretability