---
ver: rpa2
title: Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation
  (RAG) for Arabic Language
arxiv_id: '2403.18350'
source_url: https://arxiv.org/abs/2403.18350
tags:
- search
- semantic
- arabic
- evaluation
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates semantic search effectiveness in Arabic and
  its impact on Retrieval-Augmented Generation (RAG) systems. A novel dataset of 2,030
  customer support call summaries and 406 queries with relevance scores was created
  using GPT-4.
---

# Evaluation of Semantic Search and its Role in Retrieved-Augmented-Generation (RAG) for Arabic Language

## Quick Facts
- arXiv ID: 2403.18350
- Source URL: https://arxiv.org/abs/2403.18350
- Reference count: 20
- Primary result: Five multilingual encoders tested for Arabic semantic search, with paraphrase-multilingual-mpnet-base-v2 achieving best performance (nDCG@3: 0.879, MRR@3: 0.911, mAP@3: 0.888)

## Executive Summary
This study evaluates semantic search effectiveness for Arabic language in Retrieval-Augmented Generation (RAG) systems. The researchers created a novel dataset of 2,030 customer support call summaries and 406 queries with relevance scores generated using GPT-4. Five multilingual encoders were systematically tested, with paraphrase-multilingual-mpnet-base-v2 emerging as the top performer. The study demonstrates that semantic search is viable for Arabic RAG systems, achieving 63.11% top-3 accuracy and 63.84% top-1 accuracy, though encoder performance varied in the RAG context.

## Method Summary
The study created a novel Arabic dataset using 2,030 customer support call summaries and 406 queries with relevance scores generated by GPT-4. Five multilingual encoders were evaluated for semantic search performance using cosine similarity between embedding vectors, with metrics including nDCG@3, MRR@3, and mAP@3. For RAG evaluation, the best-performing encoder was integrated into a pipeline using GPT-3.5-turbo for response generation and GPT-4-turbo for evaluation. The RAG system retrieved top-3 relevant documents and merged them with the query for generation, with accuracy measured against 816 FAQ questions across four domains.

## Key Results
- paraphrase-multilingual-mpnet-base-v2 achieved the best semantic search performance with nDCG@3: 0.879, MRR@3: 0.911, mAP@3: 0.888
- RAG accuracy varied by encoder, with paraphrase-multilingual-mpnet-base-v2 achieving 63.11% top-3 accuracy and 63.84% top-1 accuracy
- Semantic search shows viability for Arabic RAG systems, though encoder performance differences were observed

## Why This Works (Mechanism)
The study leverages multilingual encoders pre-trained on diverse language data, allowing them to capture semantic relationships in Arabic despite its complex morphology and dialectal variations. By using embedding vectors and cosine similarity, the system can identify relevant documents based on semantic meaning rather than exact keyword matching. The RAG framework combines the strengths of retrieval-based systems (accessing external knowledge) with generation-based systems (producing fluent, contextual responses), addressing the knowledge limitations of standalone language models.

## Foundational Learning
- **Cosine Similarity**: Measures the cosine of the angle between two vectors, used to determine semantic similarity between query and document embeddings; needed for comparing semantic representations, quick check: values range from -1 to 1 with 1 indicating identical direction
- **nDCG@K**: Normalized Discounted Cumulative Gain at position K, measures ranking quality with emphasis on top results; needed to evaluate semantic search effectiveness, quick check: higher values indicate better ranking performance
- **RAG Architecture**: Combines retrieval of relevant documents with generation of responses, addressing knowledge limitations of language models; needed to enable fact-based question answering, quick check: consists of retriever and generator components
- **Multilingual Encoders**: Neural networks trained on multiple languages to generate semantic embeddings; needed to handle Arabic's morphological complexity, quick check: produce fixed-length vector representations of text
- **mAP@K**: Mean Average Precision at position K, averages precision values across queries for ranked results; needed to evaluate overall semantic search quality, quick check: higher values indicate better retrieval accuracy
- **MRR@K**: Mean Reciprocal Rank at position K, averages reciprocal ranks of first relevant documents; needed to assess how quickly relevant results appear, quick check: higher values indicate better early retrieval

## Architecture Onboarding

Component Map: Dataset -> Encoder -> Cosine Similarity -> RAG Pipeline -> GPT-3.5-turbo -> GPT-4-turbo Evaluation

Critical Path: The critical path for semantic search follows: input query -> encoder embedding -> document embeddings -> cosine similarity calculation -> ranking of results. For RAG, it extends to: retrieval results -> context merging -> generation -> evaluation.

Design Tradeoffs: The study chose pre-trained multilingual encoders over Arabic-specific models to leverage existing research and resources, trading potential performance gains for accessibility. The decision to use GPT-4 for both dataset creation and evaluation prioritizes consistency but may introduce bias.

Failure Signatures: Poor semantic search performance manifests as low nDCG/MRR scores and indicates inadequate encoder understanding of Arabic semantics. RAG failures appear as low accuracy scores, suggesting issues with either retrieval relevance or generation quality.

First Experiments:
1. Test each encoder on a small subset of queries to verify basic functionality
2. Compare cosine similarity scores for semantically equivalent but lexically different query pairs
3. Validate GPT-4-generated relevance scores by manually annotating a small sample

## Open Questions the Paper Calls Out

Open Question 1: Which specific aspects of Arabic morphology and dialectal variation most significantly impact semantic search accuracy?
Basis in paper: The paper mentions "complex morphology" and "diversity of dialects" as challenges for Arabic NLP tasks
Why unresolved: The study evaluated encoders but did not analyze which morphological or dialectical features most affect performance
What evidence would resolve it: Detailed error analysis comparing encoder performance across different Arabic morphological forms and dialectal variants

Open Question 2: How does semantic search performance differ between short queries (like the 4-word average in this study) versus longer, more complex queries?
Basis in paper: The paper notes the semantic search evaluation "closely resembles an Asymmetric Semantic Search scenario" with short queries
Why unresolved: The study only tested with relatively short queries and didn't explore performance with longer, more complex queries
What evidence would resolve it: Performance comparison using the same encoders with query length variations from 4 to 20+ words

Open Question 3: What is the relationship between embedding size and RAG accuracy beyond the encoders tested in this study?
Basis in paper: The paper notes Encoder #3 performed best but has the largest embedding size, and states "further investigations are still required to conclude that superior encoders lead to superior RAG results"
Why unresolved: The study only tested five encoders and didn't systematically explore the embedding size-performance relationship
What evidence would resolve it: Systematic testing of encoders with embedding sizes ranging from 128 to 1024 dimensions and their corresponding RAG performance

## Limitations
- The study relies on GPT-4-generated relevance scores, introducing potential bias in the ground truth
- Limited dataset size (2,030 summaries, 406 queries) may not capture full Arabic language complexity
- RAG evaluation limited to 816 FAQ questions across four domains may not reflect broader application contexts

## Confidence
- High Confidence: paraphrase-multilingual-mpnet-base-v2 achieved best semantic search performance (nDCG@3: 0.879, MRR@3: 0.911, mAP@3: 0.888)
- Medium Confidence: RAG accuracy claims (63.11% top-3, 63.84% top-1) supported but may vary with different datasets
- Low Confidence: Assertion that semantic search is viable for Arabic RAG systems requires broader validation

## Next Checks
1. Validate GPT-4-generated relevance scores by manually annotating a subset of the dataset with human evaluators to assess annotation quality and consistency
2. Test the five encoders on additional Arabic datasets from different domains (e.g., medical, legal, social media) to verify generalizability of semantic search performance
3. Conduct ablation studies to evaluate the impact of varying query lengths and document sizes on semantic search and RAG performance, as these factors could significantly affect system effectiveness