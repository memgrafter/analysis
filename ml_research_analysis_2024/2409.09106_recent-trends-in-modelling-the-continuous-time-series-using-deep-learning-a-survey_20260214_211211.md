---
ver: rpa2
title: 'Recent Trends in Modelling the Continuous Time Series using Deep Learning:
  A Survey'
arxiv_id: '2409.09106'
source_url: https://arxiv.org/abs/2409.09106
tags:
- time
- series
- neural
- data
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews recent advancements in deep
  learning for continuous-time series modeling, identifying key challenges such as
  irregular sampling rates, informative missingness, high dimensionality, and pathological
  dependencies. It analyzes various neural network architectures including RNNs, LSTMs,
  CNNs, hybrid models, and differential equation-based approaches, demonstrating their
  strengths and limitations for different time series applications.
---

# Recent Trends in Modelling the Continuous Time Series using Deep Learning: A Survey

## Quick Facts
- arXiv ID: 2409.09106
- Source URL: https://arxiv.org/abs/2409.09106
- Reference count: 40
- Primary result: Comprehensive survey analyzing deep learning architectures for continuous-time series modeling, identifying key challenges and emerging solutions

## Executive Summary
This survey provides a systematic review of recent advancements in deep learning for continuous-time series modeling, addressing critical challenges including irregular sampling rates, informative missingness, high dimensionality, and pathological dependencies. The work examines multiple neural network architectures—RNNs, LSTMs, CNNs, hybrid models, and differential equation-based approaches—analyzing their strengths and limitations across different application domains. Through extensive literature analysis, it identifies current research trends and open problems, offering valuable insights for future research directions in healthcare, IoT, finance, and other domains where temporal data analysis is critical.

## Method Summary
The paper conducts a comprehensive literature review of 40+ research papers covering various neural network architectures for continuous-time series modeling. The methodology involves collecting and categorizing research papers focused on deep learning approaches, analyzing and comparing strengths and limitations of different model types (RNN, LSTM, CNN, hybrid, ODE-based) for various time series characteristics, and synthesizing findings into a taxonomy of problem domains. The survey identifies emerging trends, open problems, and future research directions through comparative analysis of existing deep learning models and their applications across different domains.

## Key Results
- Identifies irregular sampling, informative missingness, high dimensionality, and pathological dependencies as key challenges in continuous-time series modeling
- Demonstrates that differential equation-based approaches like Neural ODEs and Physics-Informed Neural Networks can model continuous-time dynamics without discretization
- Shows that hybrid CNN-RNN models can exploit spatial and temporal features simultaneously for complex time series applications
- Highlights emerging solutions like Phased-LSTM and GRU-D that handle irregular sampling through time-aware gating mechanisms

## Why This Works (Mechanism)

### Mechanism 1
Neural ODEs and Physics-Informed Neural Networks can model continuous-time dynamics without discretizing time by parameterizing the derivative of a hidden state as a neural network. The system learns the continuous evolution directly via differential equations, assuming underlying dynamics are smooth enough to be approximated by differentiable neural networks. This approach is supported by evidence showing ResNet as a special case of Euler method and practical adoption in models like DeNOTS and ContiFormer. The model fails if dynamics are discontinuous or if the ODE solver becomes numerically unstable at high sampling rates.

### Mechanism 2
RNN-based architectures like LSTM and GRU variants handle irregular sampling by gating memory updates conditionally on timestamps. Phased-LSTM and GRU-D introduce time gates and decay rates that control when and how much past information influences the current state, assuming missingness patterns and sampling intervals carry predictive signal beyond raw data. Evidence includes descriptions of GRU-D combining masking and time interval representations and Phased-LSTM adding a new time gate controlled by timestamp inputs. The approach may overfit to noise if temporal patterns are too random.

### Mechanism 3
Hybrid CNN-RNN models exploit spatial and temporal features simultaneously by using CNN layers to extract local patterns while RNN layers model long-term dependencies. Concatenation or attention mechanisms merge these complementary features, assuming local patterns (CNN) and temporal sequences (RNN) are complementary and both improve predictive accuracy. Multiple hybrid examples like FCN-rLSTM and Deep-Sense Model support this approach. The model suffers if one modality dominates, wasting the other's capacity.

## Foundational Learning

- Concept: Differential equations as continuous function approximators
  - Why needed here: They provide mathematical foundation for Neural ODEs and PINNs
  - Quick check question: What is the relationship between Euler integration and residual networks?

- Concept: Gating mechanisms in recurrent architectures
  - Why needed here: They enable selective memory updates crucial for irregular sampling
  - Quick check question: How does a time gate differ from an input gate in LSTM?

- Concept: Convolution for local pattern extraction
  - Why needed here: CNNs capture short-term, spatially local correlations before temporal modeling
  - Quick check question: Why might 1D convolutions be preferred over 2D for univariate time series?

## Architecture Onboarding

- Component map: Input layer → (Optional CNN encoder) → RNN/Neural ODE core → Output head → Time gate/decay module for irregular sampling
- Critical path: Forward pass through dynamics model → Backpropagation via adjoint sensitivity for Neural ODEs → Gradient clipping for exploding gradients
- Design tradeoffs: Neural ODEs offer high accuracy with low memory but slower training; Phased-LSTM provides faster inference and handles irregularity but may lose long-term memory; Hybrid CNN-RNN requires higher compute but delivers better local-temporal synergy
- Failure signatures: Vanishing gradients indicate need for LSTM/GRU or Neural ODE; overfitting to missingness suggests simplifying decay gates; numerical instability requires tightening ODE solver tolerances
- First 3 experiments: 1) Replace vanilla LSTM with Phased-LSTM on benchmark with irregular timestamps; 2) Swap stacked RNN for Neural ODE and compare NFE vs accuracy; 3) Add shallow CNN encoder before RNN and measure improvement on multivariate data

## Open Questions the Paper Calls Out

### Open Question 1
How can neural ODEs be improved to maintain accuracy for long-term prediction in continuous time series? The paper explicitly states Neural ODEs suffer from less accuracy for long-term prediction and discusses how the network learns system states rather than changing rates over training periods. This remains unresolved because the fundamental challenge lies in the architecture's inability to effectively capture long-term dependencies without losing precision. Empirical studies demonstrating Neural ODE architectures that successfully maintain prediction accuracy for sequences longer than current benchmarks would resolve this question.

### Open Question 2
What are the most effective methods for handling informative missingness in multivariate time series without sacrificing model performance? The paper extensively discusses informative missingness as a major challenge, particularly in healthcare applications, and reviews various approaches including GRU-D and neural differential equations. This remains unresolved as there's no clear consensus on which method provides optimal balance between handling missing data and maintaining prediction accuracy across different domains. Comparative studies across multiple domains and datasets showing consistent performance improvements would resolve this question.

### Open Question 3
How can physics-informed neural networks be adapted to handle dynamic model parameters effectively? The paper notes that PINNs support fixed model parameters but struggle with dynamic parameters, limiting their effectiveness in real-world applications. This remains unresolved because current PINN architectures lack flexibility to adapt to changing system dynamics, crucial for many real-world applications where system parameters evolve over time. Development and validation of PINN variants that can successfully incorporate time-varying parameters while maintaining computational efficiency would resolve this question.

## Limitations
- Potential selection bias in the 40+ papers analyzed due to unspecified selection criteria
- Lack of quantitative performance comparisons between different architectures
- Rapidly evolving field may render some findings obsolete quickly
- Does not systematically address computational efficiency trade-offs critical for real-world deployment

## Confidence
- High: Taxonomy of deep learning architectures for continuous-time series modeling
- Medium: Comparative performance claims across architectures
- Medium: Claims about effectiveness of specific mechanisms for irregular sampling

## Next Checks
1. Implement and evaluate Phased-LSTM, GRU-D, and Neural ODE approaches on a standardized continuous-time series benchmark with varying irregularity patterns to empirically validate claimed advantages
2. Conduct controlled experiments removing individual components (time gates, CNN encoders, ODE solvers) from hybrid models to quantify their contribution and identify redundancy
3. Systematically test Neural ODE and PINN implementations across different sampling rates and dynamics complexity to establish failure thresholds and solver configuration guidelines