---
ver: rpa2
title: 'Relevance Score: A Landmark-Like Heuristic for Planning'
arxiv_id: '2403.07510'
source_url: https://arxiv.org/abs/2403.07510
tags:
- planning
- landmarks
- problems
- heuristic
- relevance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel "relevance score" heuristic for classical
  planning, generalizing the landmark-based approach. The relevance score estimates
  the probability that a fact or action appears in plans to achieve a goal, considering
  facts that are relevant in many but not all plans.
---

# Relevance Score: A Landmark-Like Heuristic for Planning

## Quick Facts
- **arXiv ID**: 2403.07510
- **Source URL**: https://arxiv.org/abs/2403.07510
- **Reference count**: 2
- **Key outcome**: Relevance score heuristic improves performance on landmark-free planning problems but performs worse on standard problems due to computational overhead.

## Executive Summary
This paper introduces the "relevance score" heuristic for classical planning, which generalizes the landmark-based approach by estimating the probability that facts or actions appear in plans to achieve a goal. Unlike traditional landmark counting that requires facts to appear in every plan, the relevance score considers facts that are relevant in many but not all plans. The approach uses a non-deterministic agent model to sample a sub-tree of the delete-relaxed planning tree and computes relevance scores from this sample. Experimental evaluation shows that the relevance score heuristic substantially improves performance on problems lacking non-trivial landmarks, but performs worse on standard problems due to additional computation and potential plan interference.

## Method Summary
The relevance score heuristic is implemented by building a delete-relaxed planning tree, sampling a sub-tree using a non-deterministic agent that makes uniform random choices among applicable actions, and computing the frequency with which each fact appears across these samples. This frequency becomes the relevance score for that fact. The heuristic is integrated into the LAMA planner using weighted A* search. For landmark-free problems, the paper generates test cases by merging pairs of standard planning problems, creating instances where no non-trivial landmarks exist between the combined goals.

## Key Results
- Relevance score heuristic substantially improves performance on problems lacking non-trivial landmarks compared to landmark counting
- Performance degrades on standard problems due to additional computation and potential plan interference
- The heuristic provides a viable alternative when landmark counting is ineffective, at the cost of increased computational overhead in other domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The relevance score heuristic generalizes landmarks by considering facts that appear in most but not all plans.
- Mechanism: Instead of requiring a fact to be present in every plan (landmark), the relevance score assigns a probability based on how often the fact appears in sampled delete-relaxed planning trees. This allows the heuristic to guide search in domains where no non-trivial landmarks exist.
- Core assumption: Delete-relaxation preserves enough structure to make sampling a representative sub-tree of the full planning tree feasible and informative.
- Evidence anchors:
  - [abstract]: "relevance score estimates the probability that a fact or action appears in plans to achieve a goal"
  - [section]: "The relevance score that we propose in this paper applicable to both fact-based and action-based landmark-like heuristics."
- Break condition: If delete-relaxation removes critical constraints, the sampling tree will miss essential distinctions, and relevance scores will be misleading.

### Mechanism 2
- Claim: The non-deterministic agent (NDA) sampling procedure creates a probability distribution over partial plans that reflects the relevance of facts.
- Mechanism: The NDA samples a sub-tree of the delete-relaxed planning tree by making uniform random choices among applicable actions. The frequency with which a fact appears across these samples determines its relevance score.
- Core assumption: Uniform random sampling over the delete-relaxed tree is a good proxy for the distribution of facts across all valid plans.
- Evidence anchors:
  - [abstract]: "uses a non-deterministic agent model to sample a sub-tree of the delete-relaxed planning tree and computes the relevance score from this sample"
  - [section]: "We use the behaviour of a hypothetical Non-deterministic agent (NDA) to define this distribution."
- Break condition: If the tree sampling process gets trapped in a small region of the search space, the computed relevance scores will be biased and unrepresentative.

### Mechanism 3
- Claim: Truncating the sampling tree at facts true in the current state allows the relevance score to be state-aware.
- Mechanism: When computing the relevance score for a given state, the algorithm ignores parts of the tree that would achieve facts already true in that state, focusing computational effort on facts that still need to be achieved.
- Core assumption: Facts already achieved in the current state will not need to be re-achieved, so ignoring them simplifies computation without losing information.
- Evidence anchors:
  - [section]: "The relevance score applied to a state Ξσ(l) represents the probability that a node with label l would be sampled by the NDA, if it stops at nodes that are true in state σ"
- Break condition: If the planning problem allows facts to become false again (cyclic dependencies), truncating at true facts could discard relevant information.

## Foundational Learning

- Concept: Delete relaxation in classical planning
  - Why needed here: The relevance score computation relies on delete-relaxation to build the planning tree from which samples are drawn.
  - Quick check question: What does delete relaxation remove from classical planning actions, and why is this done?

- Concept: Landmark counting heuristics
  - Why needed here: The relevance score is presented as a generalization of landmark counting, so understanding the baseline is essential.
  - Quick check question: How does landmark counting estimate distance to goal, and what is its limitation when no non-trivial landmarks exist?

- Concept: Non-deterministic agent models
  - Why needed here: The relevance score is defined through the sampling behavior of a hypothetical non-deterministic agent.
  - Quick check question: How does the NDA choose which action to take at a fact node, and how does this affect the probability distribution over partial plans?

## Architecture Onboarding

- Component map: Delete-relaxed planning tree builder (TΠ) -> Non-deterministic agent sampler (SΠ) -> Relevance score calculator (Ξ(l)) -> LAMA planner integration (weighted A* search with hΞ)

- Critical path:
  1. Build delete-relaxed planning tree TΠ
  2. Sample sub-tree SΠ using NDA procedure
  3. Compute relevance scores Ξ(l) for all facts
  4. Integrate relevance scores into LAMA planner
  5. Run weighted A* search with hΞ heuristic

- Design tradeoffs:
  - Sampling depth vs. computation time: deeper sampling gives more accurate relevance scores but costs more
  - Memory usage for storing TΠ vs. recomputation on demand
  - Rounding hΞ to integer for LAMA compatibility vs. preserving information

- Failure signatures:
  - Poor performance on standard problems with many landmarks (expected)
  - Long computation times on problems with large planning trees
  - Inaccurate relevance scores when sampling doesn't explore enough of the tree

- First 3 experiments:
  1. Compare hΞ vs landmark counting on a domain with no non-trivial landmarks (e.g., merged problems)
  2. Measure convergence of relevance scores as sampling depth increases
  3. Test sensitivity of performance to the exploration threshold ρ

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the relevance score heuristic perform compared to landmark counting on problems with complex logical landmarks versus simple fact landmarks?
- Basis in paper: [explicit] The paper mentions that landmark counting often focuses on fact landmarks due to computational complexity, but the relevance score could generalize to both fact and action-based landmarks
- Why unresolved: The experimental evaluation only compared the relevance score heuristic to landmark counting using fact landmarks
- What evidence would resolve it: Experiments comparing the two heuristics on problems containing complex logical landmarks would show whether the relevance score maintains its advantage in such domains

### Open Question 2
- Question: What is the optimal value of the exploration threshold ρ for the relevance score heuristic, and how sensitive is the heuristic's performance to this parameter?
- Basis in paper: [explicit] The paper mentions using ρ = 0.2 but states that "the performance of hΞ as a heuristic is not sensitive to small changes in the value of ρ"
- Why unresolved: The paper only tested a single value of ρ and did not explore the parameter space
- What evidence would resolve it: Systematic experiments varying ρ across a range of values would determine the optimal setting and sensitivity

### Open Question 3
- Question: Can the relevance score heuristic be combined with landmark counting to leverage the strengths of both approaches?
- Basis in paper: [inferred] The paper discusses how the relevance score provides additional information beyond landmarks, and suggests that "there is an easy and natural way to leverage both heuristics: choose landmark-counting on problems with well-defined landmarks, and use our relevance score heuristic for problems that only have trivial landmarks"
- Why unresolved: The paper only tested the relevance score heuristic in isolation, not in combination with landmark counting
- What evidence would resolve it: Experiments comparing a hybrid approach that uses both heuristics to either heuristic alone would show whether the combination improves performance

## Limitations

- Computational overhead makes the heuristic perform worse than landmark counting on standard problems with many landmarks
- Effectiveness depends on the choice of exploration threshold ρ and sampling depth, which were not fully explored
- The approach may be less effective when delete-relaxation removes critical constraints that distinguish between different plans

## Confidence

- **High Confidence**: The theoretical framework connecting relevance scores to landmark-based heuristics is well-established and mathematically sound.
- **Medium Confidence**: Experimental results showing improved performance on landmark-free problems are compelling but limited in scope.
- **Low Confidence**: Claims about the generality of the approach across different planning domains need more validation.

## Next Checks

1. **Ablation study on sampling parameters**: Systematically vary the exploration threshold ρ and sampling depth to determine their impact on relevance score accuracy and computational efficiency.

2. **Cross-domain evaluation**: Test the relevance score heuristic on a broader range of planning domains, including those with cyclic dependencies and conditional effects, to assess its limitations.

3. **Comparison with learned heuristics**: Evaluate whether the relevance score heuristic can match or exceed the performance of data-driven, learned heuristics on the same benchmark problems.