---
ver: rpa2
title: Explaining Probabilistic Models with Distributional Values
arxiv_id: '2402.09947'
source_url: https://arxiv.org/abs/2402.09947
tags:
- values
- value
- distributional
- games
- shapley
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work generalises the Shapley value and related operators\
  \ for cooperative games to allow for probabilistic outputs. The authors construct\
  \ cooperative games whose payoffs are random variables, then define a class of operators\u2014\
  distributional values\u2014that track changes in the output distribution across\
  \ coalitions."
---

# Explaining Probabilistic Models with Distributional Values

## Quick Facts
- arXiv ID: 2402.09947
- Source URL: https://arxiv.org/abs/2402.09947
- Reference count: 40
- One-line primary result: Generalizes Shapley value framework to probabilistic models by tracking output distribution changes rather than scalar values

## Executive Summary
This paper introduces distributional values, a generalization of the Shapley value framework that enables explanations of probabilistic models by tracking changes in output distributions rather than just expected values. The authors construct cooperative games where payoffs are random variables and define operators that capture full distributional information about marginal contributions. For Bernoulli, Gaussian, and categorical games, they derive analytical expressions that enable contrastive explanations and uncertainty quantification beyond what standard Shapley values can provide.

## Method Summary
The authors construct cooperative games where payoffs are random variables, then define distributional values that track changes in output distributions across coalitions. The key innovation is the "noise sharing" reparameterization technique that allows consistent marginal contribution computation across different coalition structures. For each game type (Bernoulli, Gaussian, categorical), they derive analytical expressions for the marginal contributions and show these distributional values satisfy properties analogous to standard Shapley values. The framework enables contrastive explanations by tracking class transition probabilities and provides uncertainty quantification through variance and entropy measures of the marginal contributions.

## Key Results
- Distributional values for Bernoulli games have non-zero variance even when standard Shapley values are zero, capturing uncertainty that scalar values miss
- Categorical distributional values enable explicit computation of class transition probabilities, providing contrastive explanations like "feature X increases probability of class A over class B by probability p"
- The framework retains the efficiency, symmetry, and dummy properties of standard Shapley values while operating on full output distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distributional values track full probabilistic output structure rather than collapsing to scalar probabilities
- Mechanism: By treating model outputs as random variables and computing marginal contributions as differences between output distributions across coalitions, the method preserves distributional information (e.g., class transition probabilities, variance) that scalar Shapley values lose
- Core assumption: There exists a reparameterization function g(x|S, ε) such that f(x|S) = g(x|S, ε) for ε ~ ρ(ε), allowing exact "noise sharing" across coalitions
- Evidence anchors:
  - [abstract] "random variables that track changes in the model output (e.g. flipping of the predicted class)"
  - [section] "The distributional values of a game (outputs of the operator) are random variables with two mutually independent sources of randomness."
  - [corpus] Weak - corpus neighbors discuss Shapley values but not distributional extensions

### Mechanism 2
- Claim: Distributional values enable contrastive explanations by tracking class transition probabilities
- Mechanism: For categorical games, the difference set T = {er - es} captures all possible class transitions. The probability qi(er - es) represents the likelihood that player i causes a prediction flip from class s to class r, enabling statements like "feature i most increases probability of class c1 over c2"
- Core assumption: The categorical output space is finite and discrete, allowing explicit enumeration of all transition probabilities
- Evidence anchors:
  - [abstract] "the distributional values, random variables that track changes in the model output (e.g. flipping of the predicted class)"
  - [section] "the probability masses at each point z = er − es ∈ T are interpretable as the probability (averaged over coalitions) that player i causes the payoff of v (and hence the prediction of f) to flip from class s to class r."
  - [corpus] Weak - corpus neighbors don't discuss contrastive explanations via distributional tracking

### Mechanism 3
- Claim: Distributional values retain uncertainty quantification that standard Shapley values lose
- Mechanism: By maintaining the full distribution of marginal contributions, the method can compute statistics like variance, entropy, and transition probabilities that capture model behavior uncertainty, rather than only expected contributions
- Core assumption: The output distributions have well-defined statistics (mean, variance, entropy) that meaningfully represent model uncertainty
- Evidence anchors:
  - [abstract] "uncertainty quantification for probabilistic models"
  - [section] "we may determine the largest probability of any change in the output led by player i (i.e. the mode of ξi(v) disregarding 0) as ℓmc"
  - [corpus] Weak - corpus neighbors mention uncertainty but not in distributional Shapley framework

## Foundational Learning

- Concept: Cooperative game theory and Shapley value axioms (efficiency, symmetry, dummy property)
  - Why needed here: The distributional values extend these axioms to stochastic games, so understanding the classical framework is essential for grasping the extensions
  - Quick check question: What does it mean for a value operator to be efficient, and how does this relate to the grand coalition payoff?

- Concept: Reparameterization tricks for sampling from distributions
  - Why needed here: The "noise sharing" construction requires exact reparameterization to ensure consistent marginal contribution computation across coalitions
  - Quick check question: How does the Gumbel-softmax reparameterization work for categorical distributions?

- Concept: Difference sets and random variable algebra
  - Why needed here: The distributional values operate on difference sets T that may not be vector spaces, requiring understanding of random variable differences and their distributions
  - Quick check question: What is the difference set T for Bernoulli games with payoff space {0,1}?

## Architecture Onboarding

- Component map: Input preprocessing -> Model evaluation -> Distributional computation -> Aggregation -> Statistics extraction
- Critical path: Model evaluation → Marginal contribution computation → Distributional aggregation → Statistics extraction
- Design tradeoffs:
  - Exact reparameterization vs. sampling approximation: Exact allows analytic expressions but limits model types
  - Coalition structure choice: Efficient structures give sum-to-grand-payoff property but may not match application needs
  - Transition enumeration vs. sampling: Full enumeration gives complete contrastive info but scales poorly with output dimension
- Failure signatures:
  - Zero variance in distributional values despite model uncertainty: Indicates reparameterization or sampling issues
  - Inconsistent transition probabilities across coalition samples: Suggests noise sharing implementation problems
  - Mean distributional values matching standard Shapley values exactly: May indicate loss of distributional information
- First 3 experiments:
  1. Implement Bernoulli distributional values on XOR game and verify non-zero variance despite zero mean Shapley value
  2. Compute categorical distributional values on simple 3-class classifier and verify transition probabilities sum to 1
  3. Apply distributional values to MNIST classifier and visualize class transition probabilities compared to standard Shapley values

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions beyond the extension to stochastic models like Bayesian networks, which is mentioned as future work.

## Limitations
- Exact reparameterization requirement limits applicability to models that admit such reparameterizations
- Computational complexity of enumerating class transitions scales poorly with output space dimension
- Practical utility for complex real-world models remains unproven beyond synthetic examples and limited case studies

## Confidence
- **High confidence**: The mathematical construction of distributional values and their axiomatic properties (Section 3)
- **Medium confidence**: The analytical derivations for Bernoulli, Gaussian, and categorical games (Section 4)
- **Low confidence**: The practical utility and scalability of the approach for real-world models and high-dimensional output spaces

## Next Checks
1. **Reparameterization robustness test**: Systematically evaluate the framework's performance when the exact reparameterization assumption is violated (e.g., using approximate reparameterizations or sampling-based approaches) and quantify the resulting error in distributional value estimates.

2. **Scalability assessment**: Implement the categorical distributional values on a 10+ class classification problem and measure the computational time for transition probability enumeration, comparing it against the information gain from contrastive explanations.

3. **Comparative validation**: Apply both standard Shapley values and distributional values to a well-studied model (e.g., MNIST CNN) and perform ablation studies to determine which specific insights are uniquely provided by the distributional approach versus what can be inferred from existing methods.