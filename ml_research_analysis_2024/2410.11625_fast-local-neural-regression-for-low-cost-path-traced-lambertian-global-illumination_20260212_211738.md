---
ver: rpa2
title: Fast Local Neural Regression for Low-Cost, Path Traced Lambertian Global Illumination
arxiv_id: '2410.11625'
source_url: https://arxiv.org/abs/2410.11625
tags:
- neural
- quality
- https
- local
- denoising
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of real-time denoising for low-sample
  count path traced global illumination in Lambertian scenes, where neural network-based
  solutions, despite high quality, are computationally expensive for resource-constrained
  systems. The authors propose Fast Local Neural Regression (FLNR), a method that
  integrates a neural network into a computationally efficient local linear model-based
  denoiser.
---

# Fast Local Neural Regression for Low-Cost, Path Traced Lambertian Global Illumination

## Quick Facts
- **arXiv ID**: 2410.11625
- **Source URL**: https://arxiv.org/abs/2410.11625
- **Reference count**: 40
- **Primary result**: Proposes Fast Local Neural Regression (FLNR) achieving state-of-the-art denoising at 1 spp with faster execution than comparable neural network methods

## Executive Summary
This paper addresses the challenge of real-time denoising for low-sample count path traced global illumination in Lambertian scenes. The authors propose Fast Local Neural Regression (FLNR), a method that integrates a neural network into a computationally efficient local linear model-based denoiser. The approach uses a novel windowed linear regression algorithm (Fast Local Regression) that efficiently fits noise-free guide channels to a noisy path-traced input image, with further quality improvements achieved by using a neural network to generate enhanced guide channels. The method achieves state-of-the-art denoising results at very low sample counts (1 spp) with faster execution times than comparable neural network-based methods.

## Method Summary
The method combines Fast Local Regression (FLR) with a neural network to enhance guide channels. FLR uses local linear models to fit noise-free guide channels (normals, depth, ambient occlusion) to noisy path-traced indirect lighting through weighted least squares regression. To improve efficiency, FLR downsamples statistical moment tensors rather than input images, reducing computational cost by a factor of 64. The neural network component uses a U-Net architecture to transform basic guide channels into enhanced guides that capture structural information. The final output is denoised indirect lighting modulated with the albedo. The method is specifically designed for Lambertian scenes and requires precomputed ambient occlusion maps.

## Key Results
- Achieves PSNR of 37.238 and SSIM of 0.904 on 1080p frames at 1 spp
- Runtime of 11.542 ms on Nvidia RTX 2080 Ti, faster than comparable neural network methods
- Outperforms other evaluated methods in both quality and speed at very low sample counts

## Why This Works (Mechanism)

### Mechanism 1
Using neural networks to enhance guide channels enables better denoising of indirect lighting at low sample counts without full denoising. The neural network learns to transform cheap, rasterized guide channels (normals, depth, ambient occlusion) into enhanced guides that contain structural information not directly present in the guides. These enhanced guides are then used in the Fast Local Regression (FLR) step to fit to the noisy path-traced input, preserving structural details like cast shadows while maintaining computational efficiency.

### Mechanism 2
Fast Local Regression achieves computational efficiency by downsampling statistical moment tensors rather than input images. FLR computes outer products (XX^T and XY^T) of the guide and target channels, then downsamples these moment tensors by a factor of 8x before applying separable Gaussian blur. This reduces the computational cost of blurring and matrix inversion by a factor of 64 while preserving quality, as the downsampled moments contain sufficient information to fit the linear model at each 8x8 block.

### Mechanism 3
Ambient occlusion as a guide channel provides information about indirect cast shadows that geometric guides (normals, depth) cannot capture. While surface normals and depth help reconstruct attached shadows and geometry-based features, they don't encode information about where indirect lighting should be occluded by geometry. Ambient occlusion images, precomputed or rasterized, contain this information about likely shadow locations, allowing the denoiser to restore indirect cast shadows that would otherwise be lost.

## Foundational Learning

- **Concept**: Local linear models and least squares regression
  - Why needed here: The FLR algorithm uses local linear models to fit noise-free guide channels to noisy input images. Understanding how least squares regression works and how to compute the closed-form solution (X^T X)^(-1) X^T Y is essential for implementing and debugging the algorithm.
  - Quick check question: Given a local window with guide matrix X and target matrix Y, how do you compute the parameters A that minimize ||XA - Y||^2?

- **Concept**: Convolutional neural networks and U-Net architecture
  - Why needed here: The neural network component uses a U-Net architecture to enhance guide channels. Understanding CNN basics, convolutional layers, skip connections, and how U-Nets are used for image-to-image mapping tasks is necessary for modifying or training the network.
  - Quick check question: What is the purpose of skip connections in a U-Net architecture, and how do they help with detail preservation in the denoised output?

- **Concept**: Path tracing and Monte Carlo integration
  - Why needed here: The input to the denoiser is path-traced images with low sample counts. Understanding how path tracing works, why low sample counts produce noisy results, and how direct and indirect lighting can be separated is important for understanding the denoising problem and evaluating results.
  - Quick check question: Why does path tracing require many samples per pixel to produce low-noise images, and how does the linearity of the rendering equation allow separation of direct and indirect lighting?

## Architecture Onboarding

- **Component map**: Noisy path-traced indirect lighting + noise-free guide channels (normals, depth, AO) + albedo -> U-Net (enhances guides) -> FLR (computes outer products -> downsample moments -> apply Gaussian blur -> solve linear system -> upsample and apply model) -> Denoised indirect lighting modulated with albedo

- **Critical path**: Neural network inference ‚Üí FLR computation (outer products ‚Üí downsample ‚Üí blur ‚Üí solve ‚Üí upsample ‚Üí apply) ‚Üí final output generation

- **Design tradeoffs**:
  - Guide channel selection: More guides provide more information but increase computational cost and neural network complexity
  - Block size (8x8): Larger blocks reduce computation but may lose fine details; smaller blocks increase computation
  - Neural network complexity: Larger networks can learn more complex transformations but increase inference time
  - Blur kernel size and sigma: Larger kernels capture more context but increase computation and may oversmooth

- **Failure signatures**:
  - Bleeding across edges: Indicates insufficient regularization or guide channel issues
  - Missing cast shadows: Indicates missing guide channels (e.g., no AO) or neural network not learning shadow information
  - Chromatic noise: Indicates neural network overfitting or insufficient training
  - Blocky artifacts: Indicates issues with the 8x8 block downsampling/upsampling process

- **First 3 experiments**:
  1. Implement FLR with just surface normals and depth as guides on a simple Lambertian scene, verify it reconstructs geometry but misses cast shadows
  2. Add ambient occlusion as a guide channel, verify cast shadows are restored
  3. Add the neural network to enhance guides, compare quality and runtime against FLR baseline

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the proposed method perform when extended to non-Lambertian surfaces?
  - Basis in paper: [explicit] The authors state "Although many scenes are Lambertian to a first approximation, this restriction of our technique should be relaxed in future work. We anticipate that it can form the core of a more comprehensive denoiser capable of handling more complex surface reflectance behaviour."
  - Why unresolved: The current method is specifically designed for Lambertian scenes and relies on the linearity of the rendering equation for these surfaces. The paper explicitly acknowledges that extending the method to non-Lambertian surfaces is a future research direction.
  - What evidence would resolve it: Experiments demonstrating the method's performance on scenes with non-Lambertian materials (e.g., glossy, specular, or transparent surfaces) and comparison with state-of-the-art methods for such materials would provide evidence of the method's effectiveness in this extended domain.

- **Open Question 2**: How does the inclusion of temporal filtering affect the quality and performance of the proposed method?
  - Basis in paper: [explicit] The authors mention "As a pure spatial denoiser, FLNR is subject to jitter artefacts when applied to temporal sequences. We expect temporal jitter to be addressed effectively by inclusion of temporal filtering, which will also result in a further improvement in result quality."
  - Why unresolved: The paper focuses on spatial denoising and acknowledges the limitations of applying the method to temporal sequences. The authors suggest that temporal filtering could improve results, but this has not been explored in the current work.
  - What evidence would resolve it: Experiments comparing the performance of the proposed method with and without temporal filtering, including metrics for temporal stability (e.g., motion blur, flickering) and overall image quality, would provide evidence of the benefits of temporal filtering.

- **Open Question 3**: What are the optimal values for the regularization parameters (Œµ and ùúñ) used in the matrix inversion process?
  - Basis in paper: [explicit] The authors mention "We learn the regularisation terms with backpropagation, which converge to values in the range [10‚àí5; 10‚àí4]."
  - Why unresolved: While the paper states that the regularization parameters are learned through backpropagation, it does not provide specific values or a detailed analysis of how these parameters affect the denoising quality and stability.
  - What evidence would resolve it: A sensitivity analysis of the regularization parameters, including their impact on denoising quality, numerical stability, and execution time, would provide insights into their optimal values and the trade-offs involved.

## Limitations
- Limited to Lambertian scenes, with explicit acknowledgment that extending to non-Lambertian materials is future work
- Requires precomputed ambient occlusion maps, limiting applicability to static scenes
- 8x8 block downsampling may introduce artifacts in scenes with fine geometric details or sharp transitions

## Confidence
- **Method effectiveness**: High for synthetic Lambertian scenes, Medium for generalization to complex real-world scenes
- **Quantitative results**: High for specific test conditions, Medium for broader generalization across different hardware configurations
- **Runtime claims**: High for RTX 2080 Ti, Medium for other hardware configurations
- **Neural network component**: Medium - effective but introduces additional complexity and training requirements

## Next Checks
1. Test the method on non-Lambertian materials (specular, rough surfaces) to evaluate its generalization beyond the presented synthetic dataset
2. Measure performance degradation when using lower-quality or temporally inconsistent guide channels to assess robustness
3. Compare against recent neural network denoisers with similar computational budgets on identical hardware to establish relative performance more precisely