---
ver: rpa2
title: Preferential Multi-Objective Bayesian Optimization
arxiv_id: '2406.14699'
source_url: https://arxiv.org/abs/2406.14699
tags:
- dsts
- optimization
- objectives
- multi-objective
- objective
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first framework for preferential Bayesian
  optimization (PBO) with multiple objectives, addressing a critical gap in existing
  methods that assume single-objective preferences. The proposed dueling scalarized
  Thompson sampling (DSTS) algorithm combines dueling Thompson sampling with Chebyshev
  scalarizations to efficiently explore Pareto-optimal trade-offs using preference
  feedback.
---

# Preferential Multi-Objective Bayesian Optimization

## Quick Facts
- arXiv ID: 2406.14699
- Source URL: https://arxiv.org/abs/2406.14699
- Reference count: 40
- Introduces first framework for multi-objective Bayesian optimization using preference feedback only

## Executive Summary
This paper addresses a critical gap in Bayesian optimization by developing the first framework for preferential multi-objective optimization. Traditional multi-objective BO requires explicit utility function specifications or direct objective evaluations, but this work enables decision-makers to explore Pareto-optimal trade-offs using only pairwise preference comparisons. The proposed dueling scalarized Thompson sampling (DSTS) algorithm combines dueling Thompson sampling with Chebyshev scalarizations to efficiently navigate the Pareto front through preference feedback. The framework demonstrates superior performance across six test problems, including autonomous driving and exoskeleton gait personalization, while providing the first asymptotic consistency guarantee for dueling Thompson sampling in multi-objective settings.

## Method Summary
The DSTS algorithm combines dueling Thompson sampling with Chebyshev scalarizations to explore Pareto-optimal trade-offs using preference feedback. For each query, the algorithm samples scalarization weights uniformly from the simplex and generates two alternative points by optimizing the corresponding scalarized utility functions. These alternatives are presented to the decision-maker, who provides preference feedback indicating which alternative is better. The preference data is modeled using Gaussian processes with Logistic likelihood and Gumbel noise, enabling Thompson sampling to generate posterior samples for the next query. The method maintains m independent GP models (one per objective) and uses these to construct the scalarized utility functions. The algorithm explores the Pareto front by varying the scalarization weights, allowing the decision-maker to discover optimal trade-offs without requiring pre-specified utility functions.

## Key Results
- DSTS outperforms standard multi-objective BO algorithms (qParEGO, qMES, qEHVI) when adapted to preferential feedback, achieving higher hypervolume values
- The method successfully solves six test problems including DTLZ1, DTLZ2, vehicle safety, car side impact, autonomous driving, and exoskeleton gait personalization
- Theoretical analysis proves DSTS is asymptotically consistent, guaranteeing convergence to the Pareto front under mild assumptions
- Hypervolume improvements range from 5-25% over baseline methods across different problem scales (2-8 dimensions, 2-4 objectives)

## Why This Works (Mechanism)
The DSTS algorithm works by combining Thompson sampling with scalarization techniques to explore the Pareto front through preference feedback. The mechanism relies on sampling scalarization weights from the simplex to generate diverse utility functions, then using dueling Thompson sampling to select alternatives that maximize the probability of improvement under these scalarizations. The Chebyshev scalarization ensures that the selected alternatives are well-distributed across the Pareto front, while the dueling framework allows for efficient exploration without requiring explicit objective evaluations. The preference feedback is modeled using Gumbel noise, which captures the inherent uncertainty in human preferences while maintaining computational tractability.

## Foundational Learning
- Chebyshev scalarization: Combines multiple objectives into a single scalar value using weighted min-max aggregation, needed to enable Thompson sampling to optimize multiple objectives simultaneously; quick check: verify scalarization weights sum to 1 and are sampled uniformly from the simplex
- Dueling Thompson sampling: A Bayesian optimization framework that uses preference feedback instead of direct objective values, needed to handle cases where decision-makers can only compare alternatives; quick check: ensure preference likelihood is properly specified as Logistic with Gumbel noise
- Pareto optimality: The concept that no objective can be improved without worsening another, needed to define the solution space in multi-objective optimization; quick check: verify that generated alternatives are not dominated by existing points
- Hypervolume indicator: A performance metric that measures the volume of objective space dominated by the Pareto front, needed to quantify solution quality; quick check: ensure hypervolume calculations use appropriate reference points
- Gumbel noise model: A statistical model for preference noise that enables tractable Bayesian inference, needed to handle uncertainty in human preferences; quick check: verify noise parameters are properly calibrated for each objective
- Non-myopic acquisition: An approach that considers future information gain beyond immediate utility improvement, needed to balance exploration and exploitation; quick check: confirm that scalarization weights are sampled independently for each query

## Architecture Onboarding

**Component Map:** DM Preferences -> Preference GP Models -> Scalarization Weight Sampling -> Alternative Generation -> Pareto Front Exploration -> Hypervolume Optimization

**Critical Path:** Scalarization weight sampling → Alternative generation → Preference acquisition → GP posterior update → Next query selection

**Design Tradeoffs:** The method trades computational efficiency (maintaining m GP models) for flexibility in handling preference feedback. The use of Chebyshev scalarization enables Thompson sampling but may introduce bias toward extreme trade-offs. The dueling framework reduces query complexity but requires careful noise modeling to ensure accurate preference modeling.

**Failure Signatures:** Poor Pareto front coverage indicates issues with scalarization weight sampling or GP modeling. Inconsistent preference patterns suggest inappropriate noise modeling or insufficient exploration. Computational bottlenecks may arise from maintaining multiple GP models for high-dimensional problems.

**First Experiments:** 1) Validate preference modeling by testing on synthetic preference data with known utilities; 2) Compare hypervolume convergence rates against standard multi-objective BO on simple benchmark problems; 3) Test scalability by evaluating performance on problems with increasing dimensions (2, 4, 8, 16) and objectives (2, 3, 4)

## Open Questions the Paper Calls Out
- What is the convergence rate of DSTS in multi-objective PBO settings?
- How does the performance of DSTS scale with the number of objectives (m) in the problem?
- What alternative sampling policies could improve upon DSTS in multi-objective PBO?

## Limitations
- Theoretical consistency relies on infinite preference feedback and perfect modeling assumptions
- Performance evaluation limited to relatively small-scale problems (≤8 dimensions, ≤4 objectives)
- Implementation details for baseline algorithms in preferential setting not fully specified
- Computational complexity scales linearly with number of objectives due to multiple GP models

## Confidence
- Theoretical consistency proof: Medium-High (assuming stated assumptions hold)
- Empirical performance claims: Medium (limited problem scales and implementations)
- Framework generalizability: Medium (requires further validation on diverse applications)

## Next Checks
1. Validate scalability by testing DSTS on problems with ≥20 dimensions to assess performance degradation
2. Implement and compare against standard multi-objective Bayesian optimization algorithms in their native settings to establish performance baselines
3. Conduct sensitivity analysis on the Gumbel noise parameters (λtrue_j) to determine robustness to different noise levels in preference feedback