---
ver: rpa2
title: 'DELAN: Dual-Level Alignment for Vision-and-Language Navigation by Cross-Modal
  Contrastive Learning'
arxiv_id: '2404.01994'
source_url: https://arxiv.org/abs/2404.01994
tags:
- alignment
- navigation
- instruction
- learning
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DELAN, a Dual-level Alignment framework for
  vision-and-language navigation (VLN) that improves cross-modal fusion through self-supervised
  contrastive learning. The key insight is that aligning instruction, history, and
  observation modalities before fusion enhances the agent's ability to follow natural
  language instructions in unseen environments.
---

# DELAN: Dual-Level Alignment for Vision-and-Language Navigation by Cross-Modal Contrastive Learning

## Quick Facts
- **arXiv ID:** 2404.01994
- **Source URL:** https://arxiv.org/abs/2404.01994
- **Reference count:** 0
- **Primary result:** DELAN achieves state-of-the-art performance across multiple VLN benchmarks including R2R, R4R, RxR, and CVDN with significant improvements in navigation metrics

## Executive Summary
This paper introduces DELAN, a Dual-level Alignment framework for vision-and-language navigation that improves cross-modal fusion through self-supervised contrastive learning. The key insight is that aligning instruction, history, and observation modalities before fusion enhances the agent's ability to follow natural language instructions in unseen environments. DELAN achieves state-of-the-art performance across multiple VLN benchmarks with improvements of 1.7% in SPL on R2R and comparable gains on other datasets.

## Method Summary
DELAN operates within the multi-modal late-fusion paradigm but enhances it with pre-fusion alignment using self-supervised contrastive learning. The framework divides alignment into two levels: instruction-history alignment and landmark-observation alignment. It uses a dual-level instruction format that combines original instructions with extracted landmark words. The approach aligns unimodal representations before fusion, creating shared semantic spaces that make cross-modal fusion more effective without requiring additional supervision.

## Key Results
- Achieves state-of-the-art performance across R2R, R4R, RxR, and CVDN benchmarks
- Improves R2R test SPL by 1.7% over baseline HAMT model, reaching 62.69%
- Demonstrates significant improvements in navigation metrics including SR, SPL, NE, TL, nDTW, SDTW, CLS, and GP

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-fusion alignment reduces modality gaps and improves cross-modal fusion quality
- Mechanism: DELAN aligns unimodal representations before fusion using self-supervised contrastive learning, creating shared semantic spaces that make fusion more effective
- Core assumption: Modality features from disparate uni-encoders reside in different spaces, causing suboptimal fusion; aligning them first creates better representations for fusion
- Evidence anchors: [abstract] "modality features generated by disparate uni-encoders reside in their own spaces, leading to a decline in the quality of cross-modal fusion and decision"

### Mechanism 2
- Claim: Dual-level alignment captures different semantic relationships more effectively
- Mechanism: DELAN partitions alignment into instruction-history (trajectory-level) and landmark-observation (detail-level) components, each using appropriate contrastive strategies
- Core assumption: Navigation history and real-time observations have different semantic relationships with instruction content - history aligns with full instructions while observations align with landmark words
- Evidence anchors: [abstract] "we divide the pre-fusion alignment into dual levels: instruction-history level and landmark-observation level according to their semantic correlations"

### Mechanism 3
- Claim: Self-supervised contrastive learning provides effective training signals despite limited supervision
- Mechanism: DELAN uses contrastive loss across positive/negative pairs within batches to enforce matching between different modalities without requiring additional annotations
- Core assumption: The limited training signals for pre-fusion alignment can be compensated by carefully designed self-supervised contrastive learning strategies
- Evidence anchors: [abstract] "As the training signals for pre-fusion alignment are extremely limited, self-supervised contrastive learning strategies are employed to enforce the matching between different modalities"

## Foundational Learning

- **Concept: Cross-modal contrastive learning**
  - Why needed here: DELAN relies on contrastive learning to align different modalities without additional supervision; understanding how this works is fundamental to grasping the approach
  - Quick check question: How does contrastive learning create alignment between different modalities using only within-batch positive and negative pairs?

- **Concept: Vision-and-Language Navigation (VLN) task structure**
  - Why needed here: DELAN is specifically designed for VLN; understanding the task's requirements (following natural language instructions in unseen environments) is essential for appreciating the design choices
  - Quick check question: What are the key modalities involved in VLN and how do they interact during navigation?

- **Concept: Multi-modal late-fusion paradigm**
  - Why needed here: DELAN operates within this paradigm, enhancing it with pre-fusion alignment; understanding the baseline approach helps contextualize DELAN's contributions
  - Quick check question: How does multi-modal late-fusion differ from early fusion, and what are its typical components in VLN systems?

## Architecture Onboarding

- **Component map:** Dual-level instruction construction → Unimodal encoding → Pre-fusion alignment (contrastive learning) → Cross-modal fusion → Action prediction
- **Critical path:** Instruction parsing → Dual-level instruction construction → Unimodal encoding → Pre-fusion alignment → Cross-modal fusion → Action prediction
- **Design tradeoffs:** Dual-level alignment adds complexity and computational overhead but improves performance; separate encoders vs. shared encoders for instructions and landmarks; global vs. local representation alignment strategies
- **Failure signatures:** Poor alignment quality manifests as degraded navigation performance, especially on landmark recognition and trajectory following; insufficient negative samples in contrastive learning may cause alignment to collapse
- **First 3 experiments:**
  1. Ablation study comparing single-level vs dual-level alignment on R2R dataset
  2. Analysis of landmark-observation alignment effectiveness by removing it and measuring impact on object-seeking ability
  3. Comparison of different separation strategies for instructions and landmarks (shared encoder, separate encoders, independent encoders)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the dual-level alignment framework perform when applied to other vision-language tasks beyond navigation, such as image captioning or visual question answering?
- Basis in paper: [inferred] The paper focuses on vision-and-language navigation (VLN) but mentions that pre-fusion alignment has been validated in traditional vision-language tasks
- Why unresolved: The paper does not explore or provide results for other vision-language tasks
- What evidence would resolve it: Experiments applying the DELAN framework to tasks like image captioning or visual question answering, with performance comparisons to state-of-the-art methods

### Open Question 2
- Question: What is the impact of different landmark extraction methods on the performance of the DELAN framework?
- Basis in paper: [explicit] The paper uses a pre-trained BERT model fine-tuned on part-of-speech task to extract nouns as landmarks
- Why unresolved: The paper only presents results using one specific landmark extraction method
- What evidence would resolve it: Experiments comparing the performance of the DELAN framework using different landmark extraction methods, such as dependency parsing or named entity recognition

### Open Question 3
- Question: How does the DELAN framework handle dynamic environments where landmarks may change or disappear during navigation?
- Basis in paper: [inferred] The paper does not address the scenario of dynamic environments or discuss how the framework adapts to changes in landmarks during navigation
- Why unresolved: The experiments are conducted on static datasets where the environment and landmarks remain constant
- What evidence would resolve it: Experiments testing the DELAN framework in dynamic environments where landmarks may change or disappear

## Limitations
- The empirical necessity of dual-level alignment versus simpler alternatives is not conclusively proven, with only modest performance gains (1.7% SPL improvement) despite added complexity
- Batch size requirements for effective negative sampling in contrastive learning are not thoroughly analyzed, creating uncertainty about scalability
- Exact architectural details of the cross-modal transformer and memory bank implementation are not fully specified, potentially affecting reproducibility

## Confidence

**High Confidence (✦✦✦✧):** The core hypothesis that pre-fusion alignment improves cross-modal fusion quality is well-supported by theoretical reasoning and ablation studies.

**Medium Confidence (✦✦✧✧):** The specific claim that dual-level alignment is superior to single-level approaches is supported by ablation results but lacks comparative analysis against alternative alignment strategies.

**Medium Confidence (✦✦✧✧):** The claim that DELAN achieves state-of-the-art performance is supported by benchmark results, but the improvements are incremental rather than transformative.

## Next Checks
1. **Batch Size Sensitivity Analysis**: Systematically vary batch sizes to determine the minimum effective size for contrastive learning and assess whether the reported improvements depend on specific batch configurations.

2. **Unified vs. Dual Alignment Comparison**: Implement a unified alignment approach that treats all cross-modal pairs identically, then conduct head-to-head comparisons to quantify the actual benefit of separating instruction-history and landmark-observation alignment.

3. **Generalization to New Modalities**: Test DELAN's alignment framework on a modified VLN task that includes additional modalities (e.g., audio or semantic maps) to evaluate whether the dual-level approach generalizes beyond the three core modalities.