---
ver: rpa2
title: Vision-and-Language Navigation via Causal Learning
arxiv_id: '2404.10241'
source_url: https://arxiv.org/abs/2404.10241
tags:
- causal
- learning
- navigation
- vision
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GOAT, a causal learning approach for vision-and-language
  navigation (VLN) that addresses dataset bias by integrating causal inference principles.
  It proposes a unified structural causal model considering both observable (content-related)
  and unobservable (style-related) confounders across vision, language, and history
  modalities.
---

# Vision-and-Language Navigation via Causal Learning

## Quick Facts
- **arXiv ID**: 2404.10241
- **Source URL**: https://arxiv.org/abs/2404.10241
- **Reference count**: 40
- **Primary result**: GOAT achieves state-of-the-art performance on multiple VLN datasets using causal learning to address dataset bias

## Executive Summary
This paper introduces GOAT, a causal learning approach for vision-and-language navigation (VLN) that addresses dataset bias through integration of causal inference principles. The method proposes a unified structural causal model considering both observable and unobservable confounders across vision, language, and history modalities. By employing back-door and front-door adjustment causal learning modules alongside cross-modal feature pooling with contrastive learning, the approach achieves superior performance over state-of-the-art methods on multiple VLN benchmarks.

## Method Summary
GOAT employs a multi-stage causal learning pipeline for VLN. The method uses back-door adjustment (BACL) to break spurious correlations between input features and action predictions by modeling observable confounders through statistic-based or attention-based weighting. Front-door adjustment (FACL) enables debiasing even when unobservable confounders exist by using attentive pooling and K-means clustering to construct global dictionaries, then applying cross-modal attention to approximate expectations over the full feature space. A cross-modal feature pooling (CFP) module with contrastive learning aligns multi-modal features and provides global dictionaries for both adjustment modules. The architecture uses lighter transformer stacks with dual-scale graph transformers for cross-modal fusion and action prediction.

## Key Results
- GOAT achieves state-of-the-art performance on R2R, REVERIE, RxR, and SOON datasets
- Notable improvements in navigation success rates (SR) and success weighted by path length (SPL)
- Demonstrates strong generalization across seen and unseen environments

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Back-door adjustment via do-operator breaks spurious correlations between input features and action predictions by explicitly modeling and neutralizing observable confounders.
- **Mechanism**: The BACL module computes the expected feature representation across confounder categories using either statistic-based or attention-based weighting, effectively replacing the biased P(Y|X) with P(Y|do(X)) = Σ_z P(Y|X,z)P(z).
- **Core assumption**: Observable confounders (e.g., keywords, room references) can be explicitly identified and their distributions modeled from the training data.
- **Evidence anchors**: [abstract] "We propose the back-door and front-door adjustment causal learning (BACL and FACL) modules to promote unbiased learning by comprehensively mitigating potential spurious correlations." [section 4.1] "To obtain Ez[fz(z)], there are two prevalent approaches: statistic-based [42, 66] and attention-based methods [38, 73]."
- **Break condition**: If observable confounders are not reliably extractable (e.g., ambiguous or missing keywords/room labels), the BACL module cannot correctly estimate Ez[fz(z)], leading to residual bias.

### Mechanism 2
- **Claim**: Front-door adjustment enables debiasing even when unobservable confounders exist by inserting a mediator and learning cross-sample feature distributions.
- **Mechanism**: The FACL module uses attentive pooling and K-means clustering to construct global dictionaries and then applies cross-modal attention to approximate the expectation over the full feature space, thereby implementing P(Y|do(X)) = E_x'[x'] + E_m|x[m].
- **Core assumption**: The mediator (e.g., attended features) captures sufficient information to block the back-door path while preserving the causal effect of the input on the outcome.
- **Evidence anchors**: [abstract] "we propose the back-door and front-door adjustment causal learning (BACL and FACL) modules to promote unbiased learning by comprehensively mitigating potential spurious correlations." [section 4.2] "The integration of adjustment formulas, incorporating both the back-door and front-door criteria, encompasses diverse scenarios."
- **Break condition**: If the mediator does not effectively isolate the causal pathway (e.g., poor attention or clustering), the front-door approximation fails and bias remains.

### Mechanism 3
- **Claim**: Cross-modal feature pooling with contrastive learning aligns multi-modal features and provides reliable global dictionaries for both front-door and back-door adjustment.
- **Mechanism**: CFP uses attentive pooling to compress sequences into global features, then applies InfoNCE-style contrastive losses across vision, history, and language modalities to enforce semantic alignment, improving confounder dictionary quality.
- **Core assumption**: Contrastive learning can enforce meaningful cross-modal semantic alignment that generalizes across training and unseen environments.
- **Evidence anchors**: [abstract] "to capture global confounder features, we propose a cross-modal feature pooling (CFP) module supervised by contrastive learning." [section 4.3] "The contrastive loss Lls is constructed as: Lls = - 1/2B Σ_j log exp(⟨ ¯C_lj, ¯C_sj⟩/t) / PB_k exp(⟨ ¯C_lj, ¯C_s_k⟩/t) - 1/2B Σ_k log exp(⟨ ¯C_lk, ¯C_sk⟩/t) / PB_j exp(⟨ ¯C_lj, ¯C_sk⟩/t)"
- **Break condition**: If contrastive alignment is too strict or too loose, the global dictionaries may not capture true confounders, leading to poor adjustment performance.

## Foundational Learning

- **Concept**: Causal inference and do-operator
  - Why needed here: VLN agents suffer from dataset bias due to confounders; causal inference offers a principled way to debias predictions.
  - Quick check question: What is the difference between P(Y|X) and P(Y|do(X)) in the context of confounders?

- **Concept**: Structural causal models (SCM)
  - Why needed here: SCM formally represents the relationships among vision, language, history, and actions, clarifying where confounders exist.
  - Quick check question: In the VLN SCM, what variables are considered confounders, and why?

- **Concept**: Back-door and front-door adjustment criteria
  - Why needed here: These criteria determine when and how causal effects can be identified and estimated from observational data.
  - Quick check question: Under what conditions can back-door adjustment be applied in the VLN setting?

## Architecture Onboarding

- **Component map**: Text encoder (RoBERTa + BACL) → FACL → AGF → cross-modal encoder → Vision encoder (CLIP + BACL) → FACL → AGF → cross-modal encoder → History encoder → FACL → AGF → cross-modal encoder → CFP module → Dual-scale graph transformer for action prediction
- **Critical path**: Input → modality-specific encoders → BACL → FACL (via CFP dictionaries) → AGF fusion → cross-modal encoding → action prediction
- **Design tradeoffs**: Lighter transformer stack (6 text, 2 vision, 3 cross-modal) vs. heavier baselines for efficiency; attention vs. statistic-based BACL: attention for text (contextual), statistic for vision (stable); number of K-means clusters for FACL: 24 chosen for balance between coverage and noise
- **Failure signatures**: Overfitting to seen environments (insufficient confounder dictionary coverage or weak contrastive alignment); degraded performance on instructions with numerical references (insensitivity to numeric cues); high variance in SPL across object types (residual bias in confounder modeling)
- **First 3 experiments**: 1) Ablation: Remove BACL module, measure SR/SPL drop to confirm observable confounder effect; 2) Ablation: Remove FACL module, measure SR/SPL drop to confirm unobservable confounder effect; 3) Ablation: Remove CFP module, measure SR/SPL drop to confirm the benefit of contrastive alignment for confounder dictionaries

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice of cluster number in the K-Means algorithm for the front-door confounder dictionary affect the trade-off between performance and computational overhead?
  - Basis in paper: [explicit] The paper mentions that 24 clusters yield optimal performance in SR and SPL, but also notes that too few categories may overlook distinctions while too many introduce redundant computational overhead.
  - Why unresolved: The paper does not provide a detailed analysis of the computational cost versus performance gains for different cluster numbers.
  - What evidence would resolve it: A detailed study comparing computational time and performance metrics (e.g., SR, SPL) across a range of cluster numbers would provide insights into the optimal balance.

- **Open Question 2**: Can the proposed causal learning pipeline be effectively applied to other vision-and-language tasks beyond navigation, such as visual question answering or image captioning?
  - Basis in paper: [inferred] The paper suggests that the causal learning pipeline could inspire future research in similar learning-based methods, implying potential applicability to other tasks.
  - Why unresolved: The paper does not provide experimental results or theoretical justification for applying the pipeline to tasks other than VLN.
  - What evidence would resolve it: Successful application and performance improvements on other vision-and-language tasks using the proposed pipeline would demonstrate its generalizability.

- **Open Question 3**: How does the performance of the proposed GOAT model compare to models that use more advanced or specialized architectures, such as those incorporating graph neural networks or reinforcement learning?
  - Basis in paper: [inferred] The paper focuses on a transformer-based architecture and does not compare its performance to models using alternative architectures.
  - Why unresolved: The paper does not explore or compare the performance of GOAT with models using different architectural approaches.
  - What evidence would resolve it: Comparative experiments between GOAT and models using graph neural networks or reinforcement learning on the same datasets would provide insights into the relative strengths and weaknesses of different approaches.

## Limitations

- Reliance on explicit identification and modeling of observable confounders assumes clean, unambiguous annotations which may not hold in real-world datasets
- Front-door adjustment effectiveness depends on mediator quality, yet the attention and clustering mechanisms lack sufficient empirical verification
- Contrastive learning may inadvertently introduce bias if semantic alignment is too rigid or influenced by spurious correlations

## Confidence

- **High Confidence**: The overall framework of integrating causal inference (back-door and front-door adjustment) into VLN is well-grounded and aligns with established causal learning principles
- **Medium Confidence**: The proposed modules (BACL, FACL, CFP) and their mechanisms are plausible and supported by indirect evidence from related tasks, but direct validation for VLN is limited
- **Low Confidence**: The specific implementation details of BACL and FACL modules, particularly the calculation of conditional probabilities and the effectiveness of the mediator in front-door adjustment, lack sufficient empirical verification

## Next Checks

1. **Confounder Dictionary Coverage**: Evaluate the coverage and quality of global dictionaries (DU_v, DU_h, DU_s) constructed by CFP across different instruction types and environments. Test whether the dictionaries capture true confounders or are influenced by spurious correlations.

2. **Mediator Effectiveness in Front-Door Adjustment**: Conduct experiments to assess whether the mediator (attended features) effectively isolates the causal pathway. Compare the performance of front-door adjustment with and without the mediator to quantify its contribution.

3. **Ablation of BACL and FACL Modules**: Perform detailed ablation studies to isolate the effects of BACL and FACL modules. Measure the drop in SR and SPL when each module is removed to determine their relative importance and validate their proposed mechanisms.