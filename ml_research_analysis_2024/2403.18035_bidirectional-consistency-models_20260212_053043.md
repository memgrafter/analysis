---
ver: rpa2
title: Bidirectional Consistency Models
arxiv_id: '2403.18035'
source_url: https://arxiv.org/abs/2403.18035
tags:
- noise
- sampling
- song
- inversion
- consistency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Bidirectional Consistency Models (BCMs) unify generation and inversion
  tasks in diffusion models by learning a single neural network that can traverse
  both forward and backward along the probability flow ODE. Unlike prior approaches
  that require separate networks or iterative ODE solvers, BCM establishes bidirectional
  consistency: any two points on the same trajectory can map to each other.'
---

# Bidirectional Consistency Models

## Quick Facts
- arXiv ID: 2403.18035
- Source URL: https://arxiv.org/abs/2403.18035
- Authors: Liangchen Li; Jiajun He
- Reference count: 40
- One-line primary result: BCM unifies generation and inversion in diffusion models with one-step generation capability

## Executive Summary
Bidirectional Consistency Models (BCMs) present a unified framework for both generation and inversion tasks in diffusion models by learning a single neural network that can traverse both forward and backward along the probability flow ODE. Unlike prior approaches requiring separate networks or iterative ODE solvers, BCM establishes bidirectional consistency: any two points on the same trajectory can map to each other. The model can be trained from scratch or fine-tuned from a pretrained consistency model, reducing training cost while achieving comparable or superior performance to diffusion models with at least one order of magnitude fewer function evaluations.

## Method Summary
BCM learns a neural network fθ(xt, t, u) that traverses along the probability flow ODE from time t to time u, enabling both forward (adding noise) and backward (removing noise) traversal along the same trajectory. The training objective combines a consistency training (CT) loss with a soft trajectory constraint, allowing training from scratch or fine-tuning from pretrained consistency models. BCM supports various sampling strategies including one-step generation and inversion, ancestral sampling, zigzag sampling, and their combinations, enabling applications in image interpolation, inpainting, and blind restoration of compressed images.

## Key Results
- Achieves comparable or superior performance to diffusion models with at least one order of magnitude fewer function evaluations
- Enables one-step generation and inversion while supporting multi-step sampling strategies that improve sample quality
- Demonstrates strong performance on CIFAR-10 and ImageNet-64 benchmarks with applications in interpolation, inpainting, and image restoration

## Why This Works (Mechanism)

### Mechanism 1
BCM enables unified generation and inversion by learning bidirectional mappings between any two points on the same probability flow ODE trajectory. The network parameterization uses a skip connection form that explicitly encodes the current time step and target time step, allowing the model to traverse forward or backward along the ODE trajectory and learn the integral between any two points. The core assumption is that the probability flow ODE defines a deterministic trajectory where any two points can be mapped to each other without requiring iterative ODE solving.

### Mechanism 2
The bidirectional consistency objective ensures that points on the same trajectory can map to each other while maintaining generation quality. The training objective combines a consistency training (CT) loss with a "soft" trajectory constraint. The CT loss ensures mapping to the initial point, while the soft constraint enforces consistency between any two points by mapping both forward and backward to time 0 and comparing. The core assumption is that the soft constraint, when combined with CT loss, provides sufficient regularization to learn accurate bidirectional mappings without requiring paired data from a pretrained DM.

### Mechanism 3
BCM's bidirectional consistency enables new sampling strategies that improve sample quality or reduce reconstruction error. The model supports ancestral sampling (sequential denoising), zigzag sampling (iterative denoising with noise amplification), and their combination. The bidirectional capability allows adding small amounts of noise that the network can amplify, maintaining content while improving quality. The core assumption is that the network can accurately amplify small injected noise during zigzag sampling, and the combination of sampling strategies can overcome the limitations of individual approaches.

## Foundational Learning

- **Concept: Probability Flow ODE and its relationship to diffusion models**
  - Why needed here: BCM builds directly on the PF ODE framework, and understanding how diffusion models solve this ODE is crucial for grasping BCM's approach
  - Quick check question: What is the relationship between the stochastic differential equation (SDE) used in diffusion models and the deterministic probability flow ODE?

- **Concept: Consistency models and their training objectives**
  - Why needed here: BCM extends consistency models by adding bidirectional capability, so understanding the original CT training and its limitations is essential
  - Quick check question: How does the consistency training objective ensure that different points on the same trajectory map to the same initial point?

- **Concept: Score matching and denoising score matching**
  - Why needed here: The derivation of BCM's parameterization relies on understanding how score functions relate to the ODE solution and why certain approximations are valid
  - Quick check question: Why can the score function be approximated as (x - xt)/t² in the context of consistency models?

## Architecture Onboarding

- **Component map**: xt (input sample) -> time embeddings for t and u -> residual blocks -> skip connection with coefficients cin, cout, cskip -> xu (output sample)

- **Critical path**: 
  1. Embed time steps t and u using Fourier or positional embeddings
  2. Concatenate embeddings and project to reduce dimensionality
  3. Process input through residual blocks
  4. Apply skip connection with cin, cout, cskip coefficients
  5. Output the transformed sample

- **Design tradeoffs**:
  - Using a single network for both generation and inversion vs. separate networks (simplicity vs. specialization)
  - Fixed parameterization vs. learned parameterization of cskip, cout, cin (theoretical guarantees vs. flexibility)
  - Training from scratch vs. fine-tuning from pretrained CM (scalability vs. initialization quality)

- **Failure signatures**:
  - Poor generation quality: Check if time embeddings are properly initialized and if the CT loss is converging
  - Inaccurate inversion: Verify that the soft constraint loss is working and that initial noise injection is appropriate
  - Unstable training: Monitor if the soft constraint diverges without CT loss, as shown in ablation studies

- **First 3 experiments**:
  1. Train BCM on CIFAR-10 from scratch with the full BCT objective and verify 1-step generation quality
  2. Test inversion capability by inverting real images and checking reconstruction error with different NFEs
  3. Compare ancestral, zigzag, and combined sampling strategies on the same trained model to verify quality improvements

## Open Questions the Paper Calls Out

### Open Question 1
How does the bidirectional consistency model's training objective perform when scaled to higher-resolution images (e.g., 512x512) compared to its performance on 64x64 images? The paper mentions that BCM's bidirectional consistency can enhance or enable more applications, including interpolation and inpainting on higher-resolution images like FFHQ 64x64 and LSUN Bedroom 256x256, but notes that simply following the same algorithm as CIFAR-10 is suboptimal for high-resolution images. The scalability and effectiveness of the training objective for larger images remain unexplored.

### Open Question 2
What are the specific geometric properties of the learned noise space in BCM, and how do they affect the model's performance in tasks like interpolation and inversion? The paper discusses the learned noise space and its relation to initial noise injection during inversion, noting that images inverted with the same initial noise cluster together, suggesting a submanifold structure in the embedding space. While the paper provides some insights into the noise space, it does not fully explore the geometric properties or their implications on performance.

### Open Question 3
How does the combination of ancestral and zigzag sampling in BCM compare to other sampling strategies in terms of sample quality and computational efficiency? The paper introduces a combination of ancestral and zigzag sampling, claiming it yields superior sample quality compared to using either strategy in isolation, and provides experimental results supporting this claim. The paper does not compare this combined approach to other sampling strategies or explore the trade-offs in computational efficiency.

## Limitations

- Generalization to complex data remains untested, particularly for high-resolution or highly diverse datasets
- Computational efficiency claims lack direct wall-clock time comparisons across different hardware configurations
- Numerical stability of bidirectional mappings during zigzag sampling may accumulate errors over multiple iterations

## Confidence

- **Bidirectional consistency mechanism**: High - mathematical formulation and parameterization are clearly specified with strong theoretical support
- **One-step generation capability**: High - training objective and experimental results on standard benchmarks provide strong evidence
- **Multi-step sampling strategy improvements**: Medium - improvements are demonstrated but exact mechanisms could benefit from more rigorous analysis

## Next Checks

1. Implement a systematic evaluation of zigzag sampling on synthetic trajectories with known ground truth to quantify error accumulation over multiple iterations and identify stability thresholds

2. Reproduce the main experiments while measuring actual wall-clock time and memory usage, comparing BCM against both standard diffusion models and consistency models across different hardware configurations

3. Train BCM on a more challenging dataset like LSUN Church-256 or FFHQ-1024 to evaluate whether bidirectional consistency scales effectively to complex, high-resolution image distributions