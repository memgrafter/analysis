---
ver: rpa2
title: Decomposing and Interpreting Image Representations via Text in ViTs Beyond
  CLIP
arxiv_id: '2406.01583'
source_url: https://arxiv.org/abs/2406.01583
tags:
- head
- components
- image
- layer
- clip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a framework to interpret the roles of individual
  components in vision transformers (ViTs) by decomposing their representations into
  component contributions and aligning these to CLIP space for text-based interpretation.
  The approach includes automated decomposition of representations into contributions
  from model components, alignment of these contributions to CLIP space via learned
  linear maps, and a scoring function to rank components by their importance for specific
  image features.
---

# Decomposing and Interpreting Image Representations via Text in ViTs Beyond CLIP

## Quick Facts
- arXiv ID: 2406.01583
- Source URL: https://arxiv.org/abs/2406.01583
- Reference count: 40
- Authors: Sriram Balasubramanian; Samyadeep Basu; Soheil Feizi
- Primary result: Introduces a framework to interpret ViT components by decomposing representations and aligning to CLIP space for text-based interpretation

## Executive Summary
This paper presents a framework for interpreting vision transformer (ViT) components by automatically decomposing their final image representations into contributions from individual model components and aligning these to CLIP space for text-based interpretation. The approach enables ranking components by their importance for specific image features and demonstrates applications including text-based image retrieval, token visualization, and spurious correlation mitigation. The framework reveals that many components in ImageNet-pretrained models encode the same features, suggesting potential redundancy in representation learning.

## Method Summary
The framework introduces REPDECOMPOSE, which recursively traverses the computational graph of a ViT to decompose the final representation into contributions from individual components like attention heads and MLPs. COMPALIGN then trains linear maps with orthogonality constraints to align these component contributions to CLIP space while preserving feature importance rankings. A correlation-based scoring function ranks components by their importance for specific features, enabling applications such as text-based image retrieval, token contribution visualization, and zero-shot spurious correlation mitigation.

## Key Results
- Successfully decomposes ViT representations into individual component contributions for diverse architectures including DeiT, DINO, DINOv2, Swin, and MaxViT
- Reveals that many components in ImageNet-pretrained models encode the same features, indicating potential redundancy
- Demonstrates applications including text-based image retrieval, token visualization heatmaps, and spurious correlation mitigation
- Shows effectiveness through ablation studies, rank correlation analysis, and segmentation experiments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework can decompose a ViT's final representation into contributions from individual components without access to model internals.
- Mechanism: REPDECOMPOSE recursively traverses the computational graph, identifying linear components by following the chain of operations until it reaches a non-linear node. At each linear reduction step, it collects the contributions of each component in the same vector space as the final representation.
- Core assumption: ViT operations are overwhelmingly linear, allowing decomposition via recursive graph traversal.
- Evidence anchors:
  - [abstract]: "automate the decomposition of the final representation into contributions from different model components"
  - [section]: "We thus seek a general algorithm which can automatically decompose the representation for general ViTs. This can be done via a recursive traversal of the computation graph."
  - [corpus]: Weak - no direct mention of computational graph decomposition in neighbors.

### Mechanism 2
- Claim: Component contributions can be mapped to CLIP space for text-based interpretation while preserving the relative importance of features within and across components.
- Mechanism: COMPALIGN trains linear maps for each component that minimize the cosine distance between the sum of mapped contributions and CLIP's final representation, while enforcing orthogonality constraints to preserve feature importance rankings.
- Core assumption: Linear maps can align component representations to CLIP space while maintaining the relative importance of features through orthogonality constraints.
- Evidence anchors:
  - [abstract]: "linearly map these contributions to CLIP space to interpret them via text"
  - [section]: "We train these linear maps with regularizations so that these maps preserve the roles of the individual components while also aligning the model's image representation with CLIP's image representation."
  - [corpus]: Weak - neighbors discuss CLIP alignment but not the specific orthogonality constraints for feature preservation.

### Mechanism 3
- Claim: A continuous scoring function can rank components by their importance for specific image features, revealing that multiple components often encode the same features.
- Mechanism: The scoring function computes the correlation between the projection of each component's CLIP-aligned contribution and the projection of the full representation onto a vector space spanned by CLIP embeddings of feature instantiations.
- Core assumption: The correlation between component projections and full representation projections accurately reflects component importance for specific features.
- Evidence anchors:
  - [abstract]: "introduce a novel scoring function to rank components by their importance with respect to specific features"
  - [section]: "We devise this scoring function... by looking at the projection of each contribution vector ci onto a vector space corresponding to a certain feature."
  - [corpus]: Weak - neighbors discuss feature decomposition but not this specific correlation-based scoring approach.

## Foundational Learning

- Concept: Computational graph traversal
  - Why needed here: REPDECOMPOSE requires understanding how to recursively traverse a computation graph to decompose representations into component contributions
  - Quick check question: How would you modify REPDECOMPOSE to handle higher-order terms (cj,i) that represent indirect contributions through downstream components?

- Concept: Vector space alignment and orthogonal transformations
  - Why needed here: COMPALIGN requires understanding how to align different vector spaces while preserving feature importance rankings through orthogonal transformations
  - Quick check question: What would happen to the component rankings if the orthogonality regularizer in COMPALIGN was removed?

- Concept: Correlation analysis and feature importance
  - Why needed here: The scoring function requires understanding how to measure the importance of components for specific features using correlation analysis
  - Quick check question: How would you modify the scoring function to handle features that require a minimum number of components to be fully encoded?

## Architecture Onboarding

- Component map:
  - REPDECOMPOSE: Recursive computational graph traversal for decomposition
  - COMPALIGN: Linear map training with orthogonality constraints for CLIP alignment
  - Scoring function: Correlation-based component ranking for feature importance
  - Applications: Text-based retrieval, image-based retrieval, token visualization, spurious correlation mitigation

- Critical path:
  1. Compute final representation z from input image
  2. Apply REPDECOMPOSE to decompose z into component contributions {ci}
  3. Apply COMPALIGN to map {ci} to CLIP space as {fi(ci)}
  4. Apply scoring function to rank components for specific features
  5. Use ranked components for desired applications

- Design tradeoffs:
  - Decomposition granularity vs. computational complexity
  - Orthogonality constraint strength vs. alignment quality
  - Feature instantiation quality vs. scoring function accuracy
  - Component selection vs. application performance

- Failure signatures:
  - REPDECOMPOSE fails to decompose if model contains non-linear operations
  - COMPALIGN produces poor alignment if orthogonality constraints are too strong
  - Scoring function produces inaccurate rankings if feature instantiations are poor
  - Applications fail if component selection is incorrect for the task

- First 3 experiments:
  1. Test REPDECOMPOSE on a simple ViT with known linear operations to verify decomposition
  2. Test COMPALIGN on a pre-trained CLIP model to verify alignment quality
  3. Test scoring function on a small dataset with known component-feature relationships to verify ranking accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework be extended to analyze higher-order interactions between model components beyond direct contributions?
- Basis in paper: [explicit] The paper mentions that REPDECOMPOSE could return higher-order terms such as cj,i, which is the contribution of model component i via the downstream component j, but states this is deferred for future work.
- Why unresolved: The current implementation focuses on direct contributions only, leaving the analysis of indirect or higher-order effects unexplored.
- What evidence would resolve it: Empirical results showing improved interpretability or performance when including higher-order terms in the decomposition process.

### Open Question 2
- Question: How does the scoring function perform when applied to tasks beyond the ones tested, such as multi-modal or video-based tasks?
- Basis in paper: [inferred] The scoring function is tested on image-based retrieval, segmentation, and spurious correlation mitigation, but its generalizability to other domains is not explored.
- Why unresolved: The framework's effectiveness in non-image or multi-modal contexts remains untested.
- What evidence would resolve it: Application of the scoring function to tasks like video analysis or text-image alignment with measurable improvements in interpretability or task performance.

### Open Question 3
- Question: What is the impact of using different feature instantiations on the scoring function's accuracy and robustness?
- Basis in paper: [explicit] The paper notes that feature instantiations are chosen arbitrarily and does not explore how different choices affect the scoring results.
- Why unresolved: The sensitivity of the scoring function to the choice of feature instantiations is not quantified or analyzed.
- What evidence would resolve it: Comparative studies showing how varying feature instantiations influence the ranking of components and features, with statistical measures of robustness.

## Limitations
- The framework assumes most ViT operations are linear, which may not hold for all architectures with non-linear components
- Results are constrained by CLIP's capabilities and biases as the interpretation anchor
- Orthogonality constraints in COMPALIGN may not perfectly preserve feature importance rankings across all model variants
- Scoring function accuracy heavily depends on the quality and representativeness of feature instantiations

## Confidence

**High confidence**: The core mechanism of REPDECOMPOSE for decomposing linear operations through computational graph traversal is well-established and theoretically sound. The claim that component contributions can be mapped to CLIP space while preserving relative importance is supported by the orthogonality constraints and alignment objectives.

**Medium confidence**: The effectiveness of the scoring function in accurately ranking components by feature importance depends on the quality of feature instantiations and may vary across different image domains. The generalizability of findings across diverse ViT architectures is supported but requires further validation.

**Low confidence**: The extent to which the orthogonality regularizer perfectly preserves feature importance rankings across all model variants is uncertain. The method's performance in handling highly non-linear or unconventional ViT architectures has not been thoroughly tested.

## Next Checks

1. **Decomposition Completeness Test**: Apply REPDECOMPOSE to a simplified ViT variant where all operations are known to be linear, then verify that the sum of component contributions exactly equals the final representation within numerical precision. This will validate whether the decomposition captures all relevant information.

2. **Orthogonality Constraint Sensitivity**: Systematically vary the orthogonality regularization strength Î» in COMPALIGN and measure its impact on both alignment quality (cosine similarity with CLIP representations) and feature importance preservation (component ranking stability). This will reveal whether the current regularization is optimal or if adjustments are needed.

3. **Feature Instantiation Robustness**: Test the scoring function using multiple sets of feature instantiations for the same semantic features, then measure the consistency of component rankings across different instantiations. This will validate whether the scoring function is robust to variations in how features are defined.