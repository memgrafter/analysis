---
ver: rpa2
title: Variation Due to Regularization Tractably Recovers Bayesian Deep Learning
arxiv_id: '2403.10671'
source_url: https://arxiv.org/abs/2403.10671
tags:
- laplace
- hessian
- network
- picp
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Hessian-free Laplace (HFL), a method for uncertainty
  quantification in deep learning that avoids computing and inverting the Hessian
  matrix required in traditional Laplace approximation. Instead of explicit curvature
  calculation, HFL estimates predictive variance by fine-tuning the model with a small
  regularization term added to the objective function.
---

# Variation Due to Regularization Tractably Recovers Bayesian Deep Learning

## Quick Facts
- arXiv ID: 2403.10671
- Source URL: https://arxiv.org/abs/2403.10671
- Authors: James McInerney; Nathan Kallus
- Reference count: 9
- Key outcome: Introduces Hessian-free Laplace (HFL), a scalable method for uncertainty quantification that avoids computing and inverting Hessian matrices by using prediction-regularized fine-tuning to recover Laplace approximation variance

## Executive Summary
This paper presents Hessian-free Laplace (HFL), a novel approach to uncertainty quantification in deep learning that eliminates the need to compute and invert the Hessian matrix required by traditional Laplace approximation methods. Instead, HFL estimates predictive variance by fine-tuning the model with a small regularization term added to the objective function, requiring only two point estimates: the standard maximum a posteriori (MAP) solution and a prediction-regularized MAP. Under standard assumptions, HFL recovers the same variance as linearized Laplace approximation while being significantly more scalable and efficient.

## Method Summary
HFL estimates predictive variance by fine-tuning the model with a small regularization term proportional to the network prediction added to the objective function. The method requires two point estimates: the standard MAP solution and a prediction-regularized MAP. The predictive variance is computed as the finite difference between these predictions scaled by the regularization parameter λ. The approach can be pre-trained for efficient evaluation across multiple test points by finding an optimal regularization term that minimizes the average squared L2 norm error between f-regularized parameters across evaluation points.

## Key Results
- HFL achieves comparable performance to exact and approximate Hessian methods on synthetic datasets
- The method demonstrates strong coverage for in-between uncertainty in both quadratic and sinusoidal function regression tasks
- Pre-trained HFL variant enables efficient uncertainty estimation across multiple evaluation points without repeated fine-tuning
- HFL enables parameter uncertainty quantification through additional regularization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The finite difference of predictions between MAP and prediction-regularized MAP recovers the Laplace variance.
- Mechanism: By differentiating the prediction-regularized objective with respect to the regularization parameter λ and evaluating at λ=0, the method recovers the posterior covariance term from the Laplace approximation without explicit Hessian computation.
- Core assumption: The prediction-regularized objective is continuously differentiable with respect to network parameters, and the inverse Hessian exists at the optimum.
- Evidence anchors:
  - [abstract] "predictions that are more (less) sensitive to the regularization of network parameters are less (more, respectively) certain"
  - [section] Theorem 3.1 proves that the derivative of the prediction under the prediction-regularized MAP with respect to λ recovers the variance-covariance term in the Laplace approximation
- Break condition: If the prediction-regularized objective is not continuously differentiable or if the inverse Hessian doesn't exist at the optimum.

### Mechanism 2
- Claim: Pre-training with regularization variation amortizes uncertainty computation across multiple evaluation points.
- Mechanism: By finding a regularization term that minimizes the average squared L2 norm error between f-regularized parameters across multiple evaluation points, the method enables efficient uncertainty estimation for arbitrary inputs without repeated fine-tuning.
- Core assumption: The optimal regularization term for a set of evaluation points can be approximated by the average of their predictions.
- Evidence anchors:
  - [abstract] "can be efficiently amortized in a pre-trained network"
  - [section] Theorem 3.2 proves that the optimal regularization term is the average prediction across evaluation points
- Break condition: If the relationship between regularization and parameter changes is highly non-linear or if evaluation points are too diverse.

### Mechanism 3
- Claim: Using absolute value regularization enables both in-distribution and out-of-distribution uncertainty quantification.
- Mechanism: By reformulating the regularization term with absolute values and absorbing sign terms into the regularization parameter, the method can handle both in-sample and out-of-sample uncertainty without changing the underlying approach.
- Core assumption: The sign of the prediction doesn't significantly affect the uncertainty quantification process.
- Evidence anchors:
  - [section] "HFL can be reformulated to absorb a sign term into λ that depends on the sign of the output function"
  - [section] "Using absolute values of both the HFL regularizer and predictive variance"
- Break condition: If the sign of predictions is crucial for uncertainty quantification or if absolute value regularization significantly distorts the optimization landscape.

## Foundational Learning

- Concept: Laplace approximation in Bayesian deep learning
  - Why needed here: Understanding how the Laplace approximation works is essential to grasp why the Hessian-free approach can recover the same variance
  - Quick check question: What is the relationship between the Hessian of the log posterior and the covariance matrix in the Laplace approximation?

- Concept: Implicit function theorem
  - Why needed here: The method relies on differentiating through the optimization process to recover variance information
  - Quick check question: How does the implicit function theorem allow us to differentiate the MAP solution with respect to regularization parameters?

- Concept: Regularization in neural network training
  - Why needed here: The method introduces additional regularization terms to the training objective to enable uncertainty quantification
  - Quick check question: How does adding a regularization term proportional to the network prediction affect the optimization landscape?

## Architecture Onboarding

- Component map: MAP estimator -> Prediction-regularized MAP estimator -> Variance computation (finite differences) -> Pre-training module (optional)

- Critical path:
  1. Train standard MAP model
  2. For each evaluation point, fine-tune with prediction-regularized objective
  3. Compute variance as finite difference of predictions
  4. For multiple evaluation points, pre-train with average regularization term

- Design tradeoffs:
  - Computational efficiency vs. accuracy: Pre-training reduces computation but may introduce approximation error
  - Memory usage: Storing additional model parameters for pre-training
  - Hyperparameter sensitivity: Choice of regularization strength λ affects variance estimates

- Failure signatures:
  - If variance estimates are consistently too low: Check regularization strength λ
  - If uncertainty quantification fails for OOD data: Verify evaluation point selection for pre-training
  - If computational benefits are not realized: Check implementation of pre-training module

- First 3 experiments:
  1. Verify variance recovery on simple synthetic dataset (quadratic function)
  2. Compare uncertainty estimates with exact Laplace approximation on small network
  3. Test scalability by applying to larger network with pre-training module

## Open Questions the Paper Calls Out
None

## Limitations
- The method relies on local approximations around the MAP solution, potentially missing global uncertainty patterns
- Performance depends heavily on appropriate choice of regularization parameter λ, which is not fully characterized
- The pre-training approach assumes evaluation points are representative of test data, which may not hold in practice

## Confidence
- **High confidence**: The theoretical foundation linking HFL to Laplace approximation is well-established through Theorem 3.1
- **Medium confidence**: Experimental results on synthetic datasets demonstrate comparable performance to existing methods
- **Low confidence**: Generalization to real-world datasets and complex architectures beyond the demonstrated feedforward network

## Next Checks
1. Test the method on a real-world regression dataset (e.g., UCI datasets) to verify practical utility beyond synthetic examples
2. Evaluate sensitivity to λ by systematically varying the regularization strength and measuring impact on uncertainty estimates
3. Compare HFL performance with more diverse baselines including deep ensembles and Monte Carlo dropout methods