---
ver: rpa2
title: Discovering Elementary Discourse Units in Textual Data Using Canonical Correlation
  Analysis
arxiv_id: '2406.12997'
source_url: https://arxiv.org/abs/2406.12997
tags:
- latent
- data
- variables
- canonical
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates how Canonical Correlation Analysis (CCA)
  can be used to discover latent states in textual data under a two-view setting.
  By treating consecutive sentences or turns in dialogue as two views, CCA identifies
  a shared latent representation that captures contextual information.
---

# Discovering Elementary Discourse Units in Textual Data Using Canonical Correlation Analysis

## Quick Facts
- arXiv ID: 2406.12997
- Source URL: https://arxiv.org/abs/2406.12997
- Reference count: 40
- Key outcome: CCA-based model achieves Pearson correlation of 0.512 on ASAG task, outperforming BERT, GPT-2, and various deep learning models

## Executive Summary
This paper introduces a novel approach to discovering latent states in textual data using Canonical Correlation Analysis (CCA) under a two-view setting. By treating consecutive sentences or dialogue turns as two views, the method identifies a shared latent representation that captures contextual information. The approach is applied to the Automatic Short Answer Grading (ASAG) task using the Mohler dataset, demonstrating competitive performance without supervision. The model's simplicity, linear nature, and language independence make it particularly effective when labeled data is scarce.

## Method Summary
The method treats consecutive sentences as two views and applies CCA to discover a shared latent representation. For ASAG, reference and student answers are processed through preprocessing (tokenization, stop word removal, GloVe embedding), then CCA projects both into a common space. Cosine similarity between these projections is computed and scaled to a 5-point grading scale. The approach is unsupervised, relying on the conditional independence assumption between views given the latent state.

## Key Results
- Achieves Pearson correlation of 0.512 on Mohler dataset for ASAG task
- Outperforms sophisticated deep learning models including BERT, GPT-2, Bi-LSTM variants, and CNNs
- Demonstrates competitive performance without requiring labeled training data
- Shows effectiveness of simple linear approach for semantic similarity tasks

## Why This Works (Mechanism)

### Mechanism 1
CCA discovers a shared latent representation that captures contextual information between consecutive sentences or dialogue turns by projecting two views onto a maximally correlated subspace. The conditional independence assumption (views are independent given latent state) enables this discovery. Evidence includes theoretical justification from the probabilistic interpretation of CCA, though direct corpus evidence for this specific application is weak.

### Mechanism 2
The latent representation learned by CCA can replace original input views for prediction tasks without loss of predictive power. Lemma 4.2 proves that the best linear predictor using CCA projections is equivalent to the optimal linear predictor using original two views. This requires the conditional independence assumption to hold and latent dimension equal to min(m,n). The lemma provides theoretical support, but corpus evidence directly validating this claim is missing.

### Mechanism 3
CCA-based latent representations enable competitive performance on ASAG tasks even without supervision or large labeled datasets. The model computes similarity scores via cosine distance in CCA-projected space and scales them to a 5-point grading scale. This simple linear approach outperforms complex deep learning models on the Mohler dataset, as evidenced by the empirical Pearson correlation results, though corpus evidence for this specific performance claim is limited.

## Foundational Learning

- Concept: Canonical Correlation Analysis (CCA)
  - Why needed here: Core technique for discovering shared latent representation between two views of textual data
  - Quick check question: What is the primary goal of CCA when applied to two sets of variables?

- Concept: Conditional Independence Assumption
  - Why needed here: Justifies treating consecutive sentences as conditionally independent given the latent state, fundamental to CCA interpretation
  - Quick check question: How does the conditional independence assumption enable CCA to discover latent states?

- Concept: Semantic Textual Similarity (STS)
  - Why needed here: ASAG task is modeled as STS problem where model needs to output similarity score between desired answer and student submission
  - Quick check question: Why is ASAG considered similar to the STS task?

## Architecture Onboarding

- Component map: Preprocessing -> CCA projection -> Cosine similarity -> Scaling -> Output grade
- Critical path: Preprocessing → CCA projection → Cosine similarity → Scaling → Output grade
- Design tradeoffs:
  - Linear vs. deep learning: Simpler, faster, requires less data but may miss complex patterns
  - Unsupervised vs. supervised: No need for labeled training data but relies on assumption validity
  - Fixed vs. adaptive dimensionality: Uses min(m,n) which is data-driven but may be suboptimal for some cases
- Failure signatures:
  - Low Pearson correlation with ground truth grades
  - Unstable or nonsensical similarity scores across different input pairs
  - Performance degradation when tested on datasets significantly different from Mohler
- First 3 experiments:
  1. Verify conditional independence assumption by checking correlation between consecutive sentences given their CCA projection
  2. Test sensitivity to projection dimension by varying min(m,n) and measuring performance impact
  3. Compare against random projection baselines to ensure CCA is capturing meaningful structure

## Open Questions the Paper Calls Out

- How does the performance of the CCA-based model scale with increasing dataset size and vocabulary complexity in the ASAG task? The paper demonstrates competitive performance on the Mohler dataset but does not explore scaling behavior with larger datasets or more complex vocabulary.

- Can the CCA approach be extended to capture syntactic patterns or phrases rather than just unigrams in the latent representation? The conclusion section explicitly mentions exploring variants to discover syntactic patterns or phrases as future work.

- What is the impact of different preprocessing techniques (e.g., stemming, lemmatization) on the performance of the CCA-based model? The paper describes its preprocessing pipeline but does not compare different preprocessing approaches.

- How does the CCA-based model perform on other NLP tasks beyond semantic textual similarity, such as text classification or named entity recognition? The paper focuses on semantic textual similarity and ASAG, leaving open questions about applicability to other tasks.

## Limitations

- The conditional independence assumption underpinning the CCA-EDU approach may not hold for all text types, limiting generalizability
- Performance claim (0.512 Pearson correlation) is based on a single dataset, raising concerns about generalizability
- The simple linear model may miss complex semantic relationships that deep learning models capture

## Confidence

- Mechanism 1 (CCA discovers shared latent representation): Medium - well-grounded theoretically but limited empirical validation
- Mechanism 2 (CCA projections as valid encoding): Medium - supported by lemma but lacks corpus evidence
- Mechanism 3 (Competitive performance without supervision): Medium - based on single dataset, no ablation studies shown

## Next Checks

1. Test the conditional independence assumption by measuring correlations between consecutive sentences given their CCA projections on multiple datasets
2. Conduct ablation studies varying the latent dimension and comparing against random projection baselines
3. Evaluate model performance on additional ASAG datasets with different domains and answer lengths to assess generalizability