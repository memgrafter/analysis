---
ver: rpa2
title: 'CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning'
arxiv_id: '2403.07300'
source_url: https://arxiv.org/abs/2403.07300
tags:
- time
- series
- forecasting
- loss
- temporal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CALF, a cross-modal fine-tuning framework that
  leverages pre-trained large language models (LLMs) for multivariate time series
  forecasting by addressing the distribution discrepancy between textual and temporal
  input tokens. The method employs a dual-branch architecture with temporal and textual
  branches, using a Cross-Modal Match Module, feature regularization loss, and output
  consistency loss to align modalities at multiple levels.
---

# CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning

## Quick Facts
- arXiv ID: 2403.07300
- Source URL: https://arxiv.org/abs/2403.07300
- Reference count: 14
- One-line primary result: State-of-the-art performance in both long-term and short-term forecasting on eight real-world datasets

## Executive Summary
This paper introduces CALF, a cross-modal fine-tuning framework that adapts pre-trained large language models (LLMs) for multivariate time series forecasting by addressing the distribution discrepancy between textual and temporal input tokens. The method employs a dual-branch architecture with temporal and textual branches, using a Cross-Modal Match Module, feature regularization loss, and output consistency loss to align modalities at multiple levels. Experiments on eight real-world datasets demonstrate that CALF achieves state-of-the-art performance in both long-term and short-term forecasting, with favorable few-shot and zero-shot capabilities while maintaining low computational complexity.

## Method Summary
CALF uses a dual-branch architecture where a temporal target branch processes projected time series tokens with LoRA fine-tuning, while a textual source branch processes aligned text tokens through frozen LLM layers. The Cross-Modal Match Module bridges the input distribution gap by projecting time series into high-dimensional tokens and aligning them with reduced-dimension word embeddings via cross-attention. Feature Regularization Loss aligns intermediate features between branches, and Output Consistency Loss ensures coherent final representations. The framework is trained using a total loss combining supervised loss with both regularization terms, optimized with Adam at learning rate 0.0005.

## Key Results
- Achieves state-of-the-art performance across eight real-world datasets including ETT, Weather, ECL, and Traffic
- Demonstrates superior performance in both long-term and short-term forecasting tasks
- Shows favorable few-shot and zero-shot capabilities while maintaining low computational complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-Modal Match Module bridges input distribution gap between time series and language modalities via cross-attention alignment
- Mechanism: Projects time series into high-dimensional tokens, extracts principal word embeddings using PCA, then performs cross-attention to align distributions
- Core assumption: Time series token distribution can be effectively aligned with principal components of LLM word embeddings
- Evidence anchors: Abstract mentions cross-modal match module aligns cross-modal input distributions; section details PCA + cross-attention approach; corpus shows related cross-modal alignment work
- Break condition: If distributions are too dissimilar or PCA removes critical semantic variance

### Mechanism 2
- Claim: Feature Regularization Loss aligns intermediate features between branches for effective gradient guidance
- Mechanism: Matches outputs of each Transformer block between branches using similarity functions, with trainable projection layers transforming features into shared space
- Core assumption: Intermediate feature representations can be meaningfully aligned to guide better weight updates
- Evidence anchors: Abstract mentions feature regularization loss aligns intermediate features; section defines loss with projection layers; corpus shows related cross-modal distillation work
- Break condition: If feature spaces are too different or projection layers fail to learn shared representation

### Mechanism 3
- Claim: Output Consistency Loss ensures final output representations correspond effectively between modalities
- Mechanism: Compares outputs from both branches using similarity function to ensure consistent predictions regardless of input modality
- Core assumption: Outputs of both branches can be meaningfully compared and consistency reflects improved alignment
- Evidence anchors: Abstract mentions output consistency loss allows output representations to correspond; section defines loss as similarity between final outputs; no direct corpus evidence
- Break condition: If branches learn fundamentally different representations, consistency could degrade performance

## Foundational Learning

- Concept: Distribution alignment between modalities
  - Why needed here: Without aligning input and feature distributions, LLM pre-trained weights are not well-suited for time series data
  - Quick check question: What is the core difference between textual and temporal input distributions that must be addressed?

- Concept: Cross-attention for multimodal alignment
  - Why needed here: Cross-attention learns which parts of time series are most relevant to which parts of textual embeddings, enabling effective alignment
  - Quick check question: How does cross-attention help bridge the gap between time series tokens and word embeddings?

- Concept: Parameter-efficient fine-tuning
  - Why needed here: Fine-tuning large LLMs is computationally expensive; LoRA and freezing most weights enable efficient adaptation
  - Quick check question: What is the role of LoRA in the CALF framework?

## Architecture Onboarding

- Component map: Input → Cross-Modal Match Module → Two parallel branches (Textual Source Branch, Temporal Target Branch) → Feature and Output Losses → Final prediction
- Critical path: Cross-Modal Match Module aligns distributions → Dual branches process aligned tokens → Regularization losses align features → Consistency loss ensures coherent outputs → Final prediction
- Design tradeoffs:
  - PCA dimensionality vs. alignment quality
  - Feature regularization vs. overfitting
  - Output consistency vs. modality-specific nuances
- Failure signatures:
  - Misalignment: Poor benchmark performance, large gaps between branches
  - Over-regularization: Loss of modality-specific information, degraded accuracy
  - Computational inefficiency: Excessive training time, memory issues
- First 3 experiments:
  1. Baseline: Compare single-branch LLM adaptation (TimeLLM/GPT4TS) vs. CALF on ETT datasets
  2. Ablation: Remove each loss (feature regularization, output consistency) and measure impact on MSE/MAE
  3. Efficiency: Measure training/inference time and parameter count vs. full fine-tuning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Cross-Modal Match Module perform with different PCA dimensions for word embedding reduction?
- Basis in paper: Explicit statement about choosing d=500 for 88% variance ratio and ablation study on principal components
- Why unresolved: Limited range tested (100-2000 dimensions not explored) and computational cost implications not fully analyzed
- What evidence would resolve it: Comprehensive ablation study testing multiple PCA dimensions with performance metrics across multiple datasets

### Open Question 2
- Question: Impact of Cross-Modal Match Module on datasets with different temporal characteristics
- Basis in paper: Inferred from statement about aligning time series tokens with temporal characteristics in word embeddings
- Why unresolved: No detailed analysis of performance across different time series patterns (periodic vs. irregular)
- What evidence would resolve it: Testing with and without module on datasets with varying temporal patterns and comparing performance metrics

### Open Question 3
- Question: How CALF framework scales with longer time series sequences and computational limitations
- Basis in paper: Inferred from mention of principal word embedding extraction for computational cost reduction
- Why unresolved: No experiments or analysis on very long sequences (thousands of time steps) or computational limitations
- What evidence would resolve it: Benchmarking experiments with increasingly long input sequences measuring accuracy degradation and computational time/memory usage

## Limitations

- Distribution alignment assumption may not hold for all time series data types
- Computational complexity of cross-modal alignment not thoroughly analyzed
- Few-shot and zero-shot capabilities claims not fully supported by experimental results

## Confidence

**High Confidence**: Dual-branch architecture design, LoRA fine-tuning, and supervised loss are well-established and theoretically sound. Experimental results on multiple benchmarks demonstrate clear performance improvements.

**Medium Confidence**: Specific implementation details of Cross-Modal Match Module (PCA dimensionality reduction, cross-attention alignment) are plausible but lack thorough validation. Backbone choice and hyperparameter settings are reasonable but not extensively justified.

**Low Confidence**: Claims about few-shot and zero-shot capabilities are not fully supported by presented experimental results.

## Next Checks

1. **Distribution Alignment Analysis**: Conduct thorough analysis of input distribution alignment between time series tokens and principal word embeddings using KL divergence or Wasserstein distance metrics and visualize cross-attention maps.

2. **Ablation Studies on Loss Components**: Perform comprehensive ablation studies to quantify contribution of each loss component (supervised, feature regularization, output consistency) with different similarity functions and loss weights.

3. **Scalability and Efficiency Evaluation**: Analyze computational complexity of CALF framework, particularly cross-modal alignment module, and evaluate scalability to larger datasets or longer time series compared to state-of-the-art methods.