---
ver: rpa2
title: On the Convergence of Locally Adaptive and Scalable Diffusion-Based Sampling
  Methods for Deep Bayesian Neural Network Posteriors
arxiv_id: '2403.08609'
source_url: https://arxiv.org/abs/2403.08609
tags:
- neural
- step
- distribution
- stationary
- sizes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether scalable, adaptive-step diffusion-based
  MCMC methods for deep Bayesian neural networks converge to the correct posterior
  distribution. While these methods claim to achieve adaptive step sizes similar to
  modern optimizers, the authors show that they can introduce substantial bias into
  the sampled distribution, even in the limit of vanishing step sizes and full batch
  size.
---

# On the Convergence of Locally Adaptive and Scalable Diffusion-Based Sampling Methods for Deep Bayesian Neural Network Posterals

## Quick Facts
- arXiv ID: 2403.08609
- Source URL: https://arxiv.org/abs/2403.08609
- Reference count: 35
- Primary result: Adaptive-step diffusion-based MCMC methods for Bayesian neural networks cannot achieve both scalability and correct convergence without computationally expensive correction terms.

## Executive Summary
This paper investigates whether scalable, adaptive-step diffusion-based MCMC methods can correctly sample from deep Bayesian neural network posteriors. The authors demonstrate that popular methods like PSGLD, SGRLD in Monge and Shampoo metrics, and Adam SGLD introduce substantial bias into the sampled distribution by dropping a corrective term (Γ) required for ergodicity. Through both theoretical analysis and empirical evaluation on a standard normal distribution, they show these algorithms can converge to distributions that deviate significantly from the true posterior, even with vanishing step sizes and full batch sizes. The primary finding is that adaptive step sizes cannot be incorporated without including the computationally intensive correction term, fundamentally challenging the scalability claims of these methods.

## Method Summary
The authors analyze four popular diffusion-based sampling algorithms (PSGLD, SGRLD in Monge and Shampoo metrics, and Adam SGLD) by deriving their stationary distributions when the Γ correction term is dropped. They implement these algorithms to run for 10^7 steps with step size 10^-4 on a standard normal distribution, using the ergodic property to estimate stationary densities with intervals of width 0.1. The theoretical framework shows that dropping the Γ term changes the stationary distribution proportional to the inverse of the metric used, creating systematic bias. The paper provides a detailed mathematical analysis of how exponential moving averages in adaptive metrics remove explicit parameter dependence, causing the Γ term to become negligible while changing the limiting SDE.

## Key Results
- Dropping the Γ term in Riemannian Langevin Dynamics changes the stationary distribution to π(θ) = Zp(θ|D)G(θ)^-α
- Adam SGLD introduces an artificial drift that sharpens posterior density near regions of high gradient magnitude
- Exponential moving averages of gradients remove explicit parameter dependence, making Γ negligible for α close to 1
- The biased algorithms can have deep local minima at the global maximum of the target distribution
- Including the Γ term fixes the biased algorithms but removes computational efficiency benefits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dropping the Γ term in Riemannian Langevin Dynamics changes the stationary distribution proportional to the inverse of the metric used.
- Mechanism: When using an adaptive metric G(θ) that grows large in regions of small gradient, removing the corrective drift term Γ(θ) causes the stationary density to be multiplied by G(θ)^-α where α is determined by the moving average parameter. This distorts the sampling distribution, especially near local maxima where gradients vanish.
- Core assumption: The metric G(θ) is designed to increase step sizes in low-gradient regions, so it becomes very large near local optima.
- Evidence anchors:
  - [section] "π(θ) = Zp(θ|D)G(θ)^-α" - The paper derives this explicit relationship showing how dropping Γ distorts the stationary distribution.
  - [abstract] "the stationary distribution that deviates significantly from the true posterior" - Abstract confirms the distribution deviates from true posterior.
  - [corpus] Weak correlation - The corpus neighbors focus on sampling methods but don't specifically address the Γ term issue in adaptive metrics.

### Mechanism 2
- Claim: Exponential moving averages of gradients in adaptive sampling methods remove explicit parameter dependence, causing the Γ term to become negligible.
- Mechanism: By replacing h(θ_t) with its exponentially moving average V_t in the metric computation, the explicit dependence of G on the current parameters θ_t is lost. This causes Γ_α,t to scale as (1-α)Γ(θ_t), making it negligible for α close to 1, but changing the limiting SDE.
- Core assumption: The exponential moving average introduces a timescale separation between parameter updates and metric updates.
- Evidence anchors:
  - [section] "∂V_t,l/∂θ_t,j = (1-α)∂h_l(θ_t)/∂θ_t,j" - The paper shows explicitly how the derivative structure changes.
  - [abstract] "dropping the corrective Γ term required by the ergodic theory of stochastic differential equations" - Abstract identifies this as the key problem.
  - [corpus] No direct evidence - The corpus doesn't discuss the moving average mechanism in detail.

### Mechanism 3
- Claim: Adam SGLD introduces an artificial drift that sharpens the posterior density near regions of high gradient magnitude.
- Mechanism: The algorithm adds a term aG(θ_t)m_t to the drift, where m_t is the exponential moving average of gradients. This creates an additional force proportional to the metric that enhances sampling in high-gradient regions and suppresses it in low-gradient regions, distorting the stationary distribution.
- Core assumption: The metric G(θ_t) is inversely related to gradient magnitude, so the additional drift term has opposite effects in different regions.
- Evidence anchors:
  - [section] "π(θ) = Zp(θ|D)exp(-a|θ|)(|θ| + 10^-8)^(10^-8)" - The paper derives the explicit form showing the sharpening effect.
  - [abstract] "artificially sharpens the density" - Abstract mentions this specific effect.
  - [corpus] No direct evidence - The corpus neighbors don't discuss Adam SGLD's drift modification.

## Foundational Learning

- Concept: Ergodic theory of stochastic differential equations
  - Why needed here: The paper's entire analysis relies on understanding how SDEs converge to stationary distributions and how time-averages relate to expectations under those distributions.
  - Quick check question: What is the relationship between the Fokker-Planck equation and the stationary distribution of an SDE?

- Concept: Riemannian geometry in parameter space
  - Why needed here: The paper discusses metrics G(θ) that define a Riemannian structure over the parameter space, which is crucial for understanding adaptive step sizes.
  - Quick check question: How does a Riemannian metric G(θ) affect the geometry of the parameter space and consequently the sampling dynamics?

- Concept: Exponential moving averages in optimization
  - Why needed here: The paper analyzes how exponential moving averages of gradients are used in adaptive sampling methods and how they affect the corrective drift term.
  - Quick check question: What is the effect of the smoothing parameter α on the timescale of adaptation in exponential moving averages?

## Architecture Onboarding

- Component map:
  - Target distribution p(θ|D) -> Adaptive metric G(θ) -> Corrective term Γ(θ) -> Sampling algorithm -> Stationary distribution π(θ)

- Critical path:
  1. Define the target posterior distribution
  2. Choose an adaptive metric G(θ)
  3. Compute the metric and its derivatives to get Γ(θ)
  4. Run the sampling algorithm with both the metric term and Γ correction
  5. Verify convergence to the correct stationary distribution

- Design tradeoffs:
  - Computational cost vs. sampling accuracy: Including Γ requires second-order derivatives but ensures correct sampling
  - Adaptation speed vs. stability: Faster adaptation (smaller α) provides better local geometry adaptation but may introduce instability
  - Metric complexity vs. practicality: More sophisticated metrics may capture better geometry but are harder to compute

- Failure signatures:
  - Systematic bias in sampled distributions, especially near local optima
  - Poor uncertainty quantification in regions of low gradient magnitude
  - Failure to explore the full posterior, with samples clustering in specific regions

- First 3 experiments:
  1. Implement PSGLD on a simple 1D distribution (like standard normal) and compare the empirical stationary distribution with the theoretical prediction π(θ) = Zp(θ|D)G(θ)^-α
  2. Add the Γ term back into PSGLD and verify that the stationary distribution matches the target posterior
  3. Test Adam SGLD on a 1D distribution and observe the sharpening effect predicted by the theory

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How much time between updates of adaptive step sizes is needed to maintain convergence to the true posterior distribution?
- Basis in paper: [inferred] The authors discuss Wenzel et al.'s approach of updating adaptive step sizes every few thousand time steps, noting this creates a natural question about the required time interval.
- Why unresolved: The paper doesn't provide specific timing guidelines or experimental results to determine the optimal interval.
- What evidence would resolve it: Experimental results showing convergence quality versus update frequency for various time intervals would establish practical guidelines.

### Open Question 2
- Question: Can the corrective Γ term be computed more efficiently for metrics that depend only on parameters and not their gradients?
- Basis in paper: [explicit] The authors mention Lange et al.'s approach using Riemannian Langevin Dynamics to imitate batch normalization, noting that their metric depends only on current parameters, not gradients.
- Why unresolved: The paper doesn't explore whether this specific property could enable more efficient computation of the Γ term.
- What evidence would resolve it: Implementation and performance comparison of algorithms using such metrics with efficient Γ computation versus standard methods.

### Open Question 3
- Question: What new approaches might enable locally adaptive diffusion-based sampling without computationally intensive correction terms?
- Basis in paper: [explicit] The authors conclude that current approaches don't work and "some new ideas are clearly needed" to incorporate adaptive step sizes.
- Why unresolved: The paper only demonstrates the failure of existing approaches without proposing alternative solutions.
- What evidence would resolve it: Successful implementation and theoretical justification of a new algorithm that achieves local adaptation without requiring expensive corrective terms.

## Limitations
- Theoretical analysis is primarily focused on simple 1D distributions; behavior in high-dimensional spaces with complex posterior geometries remains to be thoroughly validated.
- Limited exploration of the practical impact of identified bias on downstream tasks like uncertainty quantification or prediction in real-world BNN applications.
- Proposed fix (including Γ term) is computationally expensive, but the paper doesn't provide detailed analysis of the trade-off between computational cost and sampling accuracy in practical scenarios.

## Confidence

- High Confidence: The theoretical derivation showing that dropping the Γ term changes the stationary distribution proportional to G(θ)^-α. The mathematical framework is sound and well-explained.
- Medium Confidence: The empirical validation on standard normal distributions. While the results are consistent with theory, the simplicity of the test case limits generalizability.
- Medium Confidence: The claim that adaptive methods can have deep local minima at global maxima. The theoretical analysis supports this, but more extensive empirical validation in complex, high-dimensional settings would strengthen this claim.

## Next Checks

1. **High-Dimensional Validation:** Extend the empirical analysis to higher-dimensional distributions and more complex posterior geometries to assess the generalizability of the theoretical findings.
2. **Downstream Task Impact:** Evaluate the practical impact of the identified bias on uncertainty quantification and prediction tasks in real-world Bayesian neural network applications.
3. **Computational Trade-off Analysis:** Provide a detailed comparison of the computational cost and sampling accuracy of the proposed fix (including Γ) versus the biased adaptive methods in practical scenarios.