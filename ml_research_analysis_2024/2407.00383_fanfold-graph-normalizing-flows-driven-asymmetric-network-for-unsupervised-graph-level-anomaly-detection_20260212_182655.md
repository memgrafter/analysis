---
ver: rpa2
title: 'FANFOLD: Graph Normalizing Flows-driven Asymmetric Network for Unsupervised
  Graph-Level Anomaly Detection'
arxiv_id: '2407.00383'
source_url: https://arxiv.org/abs/2407.00383
tags:
- network
- anomaly
- graph
- detection
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FANFOLD, a novel unsupervised graph-level anomaly
  detection method that uses graph normalizing flows and an asymmetric teacher-student
  network. It addresses the limitations of symmetric distillation-based approaches
  and feature-only methods by modeling the distribution of normal graphs and leveraging
  the density-aware property of normalizing flows.
---

# FANFOLD: Graph Normalizing Flows-driven Asymmetric Network for Unsupervised Graph-Level Anomaly Detection

## Quick Facts
- arXiv ID: 2407.00383
- Source URL: https://arxiv.org/abs/2407.00383
- Reference count: 39
- Key outcome: FANFOLD achieves state-of-the-art performance on 15 benchmark datasets, outperforming existing methods by significant margins in AUC scores

## Executive Summary
This paper proposes FANFOLD, a novel unsupervised graph-level anomaly detection method that uses graph normalizing flows and an asymmetric teacher-student network. It addresses the limitations of symmetric distillation-based approaches and feature-only methods by modeling the distribution of normal graphs and leveraging the density-aware property of normalizing flows. The method first pretrains an encoder with reconstruction loss, then applies normalizing flows to transform normal graph embeddings into a standard Gaussian distribution, and finally uses the asymmetric teacher-student network to compute anomaly scores based on the source-target loss. FANFOLD achieves state-of-the-art performance on 15 benchmark datasets, outperforming existing methods by significant margins in terms of AUC scores.

## Method Summary
FANFOLD uses a teacher-student architecture with normalizing flows on the source network. The training procedure involves four stages: (1) Pre-training the source network encoder with reconstruction loss to capture complex structural and feature characteristics, (2) Training normalizing flows to transform normal graph embeddings to a standard normal distribution, (3) Training the target network with source-target loss while jointly minimizing graph-level and node-level distances, and (4) Computing anomaly scores based on the source-target loss during inference. The asymmetric architecture creates stronger separation between normal and anomalous graph embeddings by introducing density-aware transformation through normalizing flows.

## Key Results
- Achieves state-of-the-art performance on 15 benchmark datasets from TUDataset
- Outperforms existing methods by significant margins in AUC scores
- Ablation studies demonstrate the importance of normalizing flows and asymmetric architecture
- Shows robustness across datasets with varying sensitivity to balance factors α and β

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FANFOLD's asymmetric network architecture creates stronger separation between normal and anomalous graph embeddings by introducing density-aware transformation through normalizing flows.
- Mechanism: The source network applies normalizing flows to transform normal graph embeddings into a standard Gaussian distribution, while the target network (without flows) produces embeddings that only match well for normal graphs. The source-target loss then amplifies the distance for anomalous graphs.
- Core assumption: Normal graphs cluster in high-density regions of the embedding space while anomalies occupy low-density regions, and this density difference is preserved after normalizing flow transformation.
- Evidence anchors:
  - [abstract]: "We introduce normalizing flows to unsupervised graph-level anomaly detection due to their successful application and superior quality in learning the underlying distribution of samples."
  - [section 2.2]: "Normalizing flows are a family of generative models that create tractable distributions, allowing for efficient and exact sampling and density evaluation."
  - [corpus]: Weak evidence - no direct corpus support for this specific density-aware mechanism in graph anomaly detection context.
- Break condition: If anomalous graphs can mimic the density patterns of normal graphs or if the normalizing flows fail to preserve the density distinctions during transformation.

### Mechanism 2
- Claim: The pretraining of the encoder with reconstruction loss ensures the source network captures complex structural and feature characteristics before density transformation.
- Mechanism: The source network first learns to reconstruct both graph structure and node features through binary cross-entropy and Frobenius norm losses, creating rich embeddings that normalizing flows can then transform into a standard distribution.
- Core assumption: Effective reconstruction of both structure and features leads to embeddings that contain the distinguishing characteristics between normal and anomalous graphs.
- Evidence anchors:
  - [section 3.3]: "To preserve the complex structure characteristics, we use the binary cross entropy loss function as Eq. 1 to approximate the adjacent matrix... we employ a decoder to reconstruct the original feature information."
  - [section 3.5]: "The target network is trained by minimizing the distance between its outputs and those of the source..."
  - [corpus]: Weak evidence - no direct corpus support for the specific pretraining-then-normalizing-flows sequence in graph anomaly detection.
- Break condition: If the reconstruction task fails to capture the distinguishing features or if pretraining introduces biases that normalizing flows cannot correct.

### Mechanism 3
- Claim: The joint minimization of graph-level and node-level distances in the target network training ensures comprehensive anomaly detection sensitivity.
- Mechanism: The target network minimizes both ˆLgraph (graph representation distance) and ˆLnode (node embedding distance) to learn normal patterns at multiple granularities, with the balance factor β controlling their relative importance.
- Core assumption: Anomalies manifest differently at graph and node levels, and capturing both perspectives improves detection accuracy.
- Evidence anchors:
  - [section 3.5]: "We jointly minimize the ˆLgraph and ˆLnode to learn normal graph pattern and feature distribution" and "We obtain the graph representation through the READOUT function... we opt for maximum pooling."
  - [section 4.4]: "Different datasets have varying sensitivity to α and β" showing the importance of these balance factors.
  - [corpus]: Weak evidence - no direct corpus support for this specific dual-granularity approach in normalizing flows-driven anomaly detection.
- Break condition: If anomalies don't consistently differ at both graph and node levels, or if the balance between the two distances is poorly tuned for specific datasets.

## Foundational Learning

- Concept: Normalizing Flows
  - Why needed here: They provide the mathematical framework for transforming complex graph embedding distributions into tractable standard distributions while preserving density information crucial for anomaly detection.
  - Quick check question: How do normalizing flows ensure invertibility and what mathematical property allows exact density computation after transformation?

- Concept: Knowledge Distillation in Asymmetric Networks
  - Why needed here: The asymmetric architecture leverages the teacher-student relationship where the source (teacher) with normalizing flows sets the distribution standard that the target (student) tries to match only for normal graphs.
  - Quick check question: What specific architectural difference between source and target networks creates the asymmetry that enables anomaly detection?

- Concept: Graph Neural Network Embeddings
  - Why needed here: The GNN encoder must produce meaningful node and graph embeddings that capture both structural and feature information before normalizing flows transformation.
  - Quick check question: How does the reconstruction loss in the pretraining phase ensure that GNN embeddings contain the distinguishing characteristics between normal and anomalous graphs?

## Architecture Onboarding

- Component map: Encoder → Normalizing Flows → Source Network → Target Network (GIN) → Anomaly Score Computation
- Critical path: Graph input → GNN encoding → reconstruction loss → normalizing flows → source-target loss computation → anomaly scoring
- Design tradeoffs: Symmetric vs asymmetric architecture (FANFOLD chooses asymmetric for better anomaly separation), single vs dual granularity distance minimization (chooses both for comprehensive detection), fixed vs learned balance factors (chooses tunable for dataset adaptation)
- Failure signatures: Poor performance on datasets where anomalies don't exhibit clear density differences, instability when message passing steps are too few or too many, sensitivity to hidden dimension choices showing overfitting or underfitting
- First 3 experiments:
  1. Run with Non-ST variant (only source network, reconstruction loss) to establish baseline performance without asymmetry.
  2. Run with Asy-ST variant (symmetric networks, no normalizing flows) to measure impact of asymmetry alone.
  3. Run with Non-NF variant (asymmetric networks, no normalizing flows) to isolate the contribution of normalizing flows specifically.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the main text, but based on the analysis and limitations discussed, several open questions emerge:

### Open Question 1
- Question: How does FANFOLD's performance change when using different normalizing flow architectures (e.g., RealNVP, Glow, MAF) instead of the current implementation?
- Basis in paper: [inferred] The paper mentions normalizing flows but doesn't explore different architectures or compare their impact on performance.
- Why unresolved: The paper uses a specific normalizing flow implementation but doesn't investigate the sensitivity of the model to different flow architectures or their relative merits.
- What evidence would resolve it: Systematic comparison of FANFOLD's performance using various normalizing flow architectures on the same benchmark datasets.

### Open Question 2
- Question: What is the impact of using different graph augmentation strategies on FANFOLD's performance, and which strategy is most effective for anomaly detection?
- Basis in paper: [explicit] The paper mentions using perturbation-free graph augmentation but doesn't explore alternative strategies or compare their effectiveness.
- Why unresolved: The paper uses a single augmentation strategy without investigating how different augmentation methods might affect the model's ability to detect anomalies.
- What evidence would resolve it: Empirical evaluation of FANFOLD's performance using multiple graph augmentation strategies (e.g., node dropping, edge perturbation, subgraph sampling) across benchmark datasets.

### Open Question 3
- Question: How does FANFOLD's performance scale with graph size and complexity, and what are the computational limitations of the approach?
- Basis in paper: [inferred] While the paper evaluates on various datasets, it doesn't explicitly analyze performance trends with respect to graph size or discuss computational scalability.
- Why unresolved: The paper provides overall performance metrics but lacks detailed analysis of how the model behaves with increasingly large or complex graphs.
- What evidence would resolve it: Comprehensive study of FANFOLD's performance and computational requirements across graphs of varying sizes and complexities, including time and memory complexity analysis.

## Limitations
- The paper lacks direct empirical evidence for the density-aware mechanism central to the approach, with no visualization or quantitative analysis of how normalizing flows transform the embedding space.
- The method's sensitivity to hyperparameter choices (α, β, message passing steps) suggests potential overfitting to the benchmark datasets.
- The computational complexity of training both networks with normalizing flows may limit scalability to larger graphs or datasets.

## Confidence

**Confidence Labels:**
- Mechanism 1 (Density-aware transformation): Medium - The concept is sound but lacks direct empirical validation
- Mechanism 2 (Pretraining effectiveness): Medium - Reconstruction loss is standard but its sufficiency is not thoroughly examined
- Mechanism 3 (Dual-granularity approach): Medium - Ablation shows benefit but the theoretical justification is limited

## Next Checks

1. Conduct visualization experiments showing how normalizing flows transform the embedding space and whether normal/anomalous graphs are indeed separated in the transformed space
2. Test the method's robustness by systematically varying α and β parameters across a wider range to understand the sensitivity and potential overfitting
3. Evaluate scalability by testing on larger graph datasets or graphs with more nodes to assess computational feasibility and performance degradation