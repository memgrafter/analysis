---
ver: rpa2
title: Automated Machine Learning for Positive-Unlabelled Learning
arxiv_id: '2401.06452'
source_url: https://arxiv.org/abs/2401.06452
tags:
- learning
- positive
- systems
- instances
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two new Auto-ML systems for Positive-Unlabeled
  (PU) learning, BO-Auto-PU and EBO-Auto-PU, based on Bayesian Optimisation and a
  hybrid Evolutionary Bayesian Optimisation method, respectively. The systems aim
  to automatically select optimal PU learning methods for a given task, addressing
  the challenge of selecting from numerous PU learning approaches.
---

# Automated Machine Learning for Positive-Unlabelled Learning

## Quick Facts
- arXiv ID: 2401.06452
- Source URL: https://arxiv.org/abs/2401.06452
- Authors: Jack D. Saunders; Alex A. Freitas
- Reference count: 13
- Primary result: Introduces BO-Auto-PU and EBO-Auto-PU, two new Auto-ML systems for PU learning that outperform baselines with statistical significance for F-measure and precision across 60 datasets.

## Executive Summary
This paper addresses the challenge of selecting optimal Positive-Unlabeled (PU) learning methods by introducing two new Auto-ML systems: BO-Auto-PU based on Bayesian Optimisation and EBO-Auto-PU based on a hybrid Evolutionary Bayesian Optimisation approach. The systems automatically search through a space of PU learning configurations to find the best combination for a given dataset. Experiments on 60 datasets (20 real-world datasets, each with 3 versions) demonstrate that EBO-Auto-PU significantly outperforms baseline PU learning methods in terms of F-measure and precision, while BO-Auto-PU achieves substantial computational efficiency gains over the previous GA-Auto-PU system.

## Method Summary
The paper develops two Auto-ML systems for PU learning that search through configurations of two-step PU methods. Each configuration specifies algorithms and hyperparameters for Phase 1A (identifying reliable negatives), Phase 1B (optional refinement), and Phase 2 (final classification). BO-Auto-PU uses Bayesian Optimisation with a random forest surrogate model to predict F-measure and efficiently explore the search space. EBO-Auto-PU combines BO with evolutionary operations (crossover, mutation, tournament selection) to maintain diversity while preserving computational efficiency. Both systems use 5-fold nested cross-validation with F-measure as the objective function. The search space includes base methods (7 hyperparameters) and extended methods (10 hyperparameters including spy-based approaches).

## Key Results
- EBO-Auto-PU significantly outperforms baseline PU learning methods for F-measure and precision across all δ values (20%, 40%, 60%) with statistical significance
- BO-Auto-PU runs approximately 27 times faster than GA-Auto-PU (8.4 vs 226.3 minutes per dataset)
- EBO-Auto-PU achieves better predictive performance than BO-Auto-PU while maintaining computational efficiency
- Both systems demonstrate robust performance across 60 datasets spanning various biomedical domains

## Why This Works (Mechanism)

### Mechanism 1
Bayesian Optimisation and EBO reduce computational cost by evaluating candidate solutions with a surrogate model before the expensive objective function. BO generates candidates, trains a random forest regressor to predict F-measure, and selects only the top-scoring candidate for true evaluation. EBO extends this by evolving a diverse population via crossover/mutation, then selecting the best surrogate-scored candidate plus a tournament-selected subset for objective evaluation. The core assumption is that the surrogate model's predictions correlate strongly with the true objective function, and evaluation with the surrogate is much cheaper than training a PU model.

### Mechanism 2
EBO improves exploration and diversity over BO by evolving a population rather than randomly generating candidates. EBO maintains a population of candidate solutions, applies crossover and mutation to generate offspring, then evaluates the best surrogate-scored candidate plus a tournament-selected subset with the objective function. This preserves diversity and allows better search space coverage. The core assumption is that population diversity improves the chance of finding high-performing configurations, and tournament selection focuses computational budget on promising candidates.

### Mechanism 3
The two-step PU learning framework with Phase 1A, Phase 1B, and Phase 2 allows systematic hyperparameter search across diverse algorithm combinations. Each candidate solution defines a two-step PU method: Phase 1A identifies reliable negative instances, Phase 1B optionally refines them, and Phase 2 trains the final classifier. The Auto-PU system searches over classifiers and thresholds for each phase, optimising predictive performance via F-measure. The core assumption is that the two-step framework is general enough to encompass effective PU learning methods, and the search space covers configurations that can adapt to dataset characteristics.

## Foundational Learning

- Concept: Positive-Unlabelled (PU) Learning
  - Why needed here: PU learning is the core problem being addressed; understanding the two-step framework and its assumptions is essential to grasp the Auto-PU system's purpose.
  - Quick check question: In PU learning, what distinguishes the "reliable negative" set from the general unlabelled set?

- Concept: Bayesian Optimisation
  - Why needed here: BO is one of the optimisation methods used by the Auto-PU systems; knowing how it works (surrogate model + acquisition function) explains the efficiency gains.
  - Quick check question: In BO, what is the role of the acquisition function, and how does it differ from the surrogate model?

- Concept: Genetic Algorithm (GA)
  - Why needed here: GA-Auto-PU is the baseline Auto-ML system; understanding GA's population-based search and operators (crossover, mutation) helps explain the motivation for EBO.
  - Quick check question: In a GA, how does tournament selection contribute to maintaining population diversity?

## Architecture Onboarding

- Component map: Search space definition (base/extended) -> Nested cross-validation -> Objective function (F-measure) -> Surrogate model (for BO/EBO) -> Candidate solution evaluation -> Best configuration output
- Critical path: Search space -> Surrogate model training -> Candidate selection -> Objective evaluation -> F-measure computation -> Best configuration selection
- Design tradeoffs:
  - BO vs. GA: BO is faster but may lack diversity; GA is slower but explores more broadly
  - EBO: Balances BO's efficiency with GA's diversity but adds complexity
  - Base vs. extended search space: Extended includes spy-based methods but increases search space size dramatically
- Failure signatures:
  - Surrogate model poorly predicts true F-measure -> BO/EBO selects bad candidates
  - Search space too small -> Misses optimal configurations
  - Nested cross-validation folds too small -> High variance in F-measure estimates
- First 3 experiments:
  1. Run BO-Auto-PU on a small synthetic PU dataset (e.g., diabetes with δ=20%) and compare runtime to GA-Auto-PU
  2. Compare F-measure distributions of BO-Auto-PU, EBO-Auto-PU, and GA-Auto-PU on the breast-cancer-wisconsin dataset across all δ values
  3. Evaluate the impact of the spy method by running GA-Auto-PU with base vs. extended search space on the parkinsons dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EBO-Auto-PU compare to other Auto-ML methods beyond the scope of this study?
- Basis in paper: [inferred] The paper compares EBO-Auto-PU to GA-Auto-PU and BO-Auto-PU, but does not compare it to other Auto-ML methods.
- Why unresolved: The paper does not provide a comparison with other Auto-ML methods.
- What evidence would resolve it: Conducting experiments comparing EBO-Auto-PU to other Auto-ML methods would provide evidence to answer this question.

### Open Question 2
- Question: How does the performance of Auto-PU systems vary with different types of data beyond biomedical datasets?
- Basis in paper: [inferred] The paper only evaluates Auto-PU systems on biomedical datasets.
- Why unresolved: The paper does not provide a comparison with other types of data.
- What evidence would resolve it: Conducting experiments using Auto-PU systems on different types of data would provide evidence to answer this question.

### Open Question 3
- Question: How does the performance of Auto-PU systems vary with different levels of class imbalance?
- Basis in paper: [explicit] The paper discusses the impact of class imbalance on the performance of Auto-PU systems.
- Why unresolved: The paper does not provide a comprehensive analysis of how class imbalance affects the performance of Auto-PU systems.
- What evidence would resolve it: Conducting experiments with different levels of class imbalance would provide evidence to answer this question.

## Limitations
- The study focuses exclusively on biomedical datasets, which may limit generalizability to other domains
- The surrogate model's predictive power is critical but not thoroughly evaluated or validated
- The search space definition, while detailed, may still miss optimal configurations for some datasets
- Computational efficiency comparisons are based on specific hardware and implementation details

## Confidence
- Claims about BO-Auto-PU and EBO-Auto-PU's superiority: **High confidence** based on statistical significance tests and multiple datasets
- Computational efficiency claims for BO-Auto-PU: **Medium confidence** due to clear runtime comparisons but no independent replication
- Mechanism explanations for BO and EBO: **Low confidence** as they are primarily inferred from paper text rather than supported by direct evidence or citations

## Next Checks
1. Implement and test the surrogate model's predictive accuracy on a held-out validation set to verify its correlation with true F-measure
2. Run the Auto-PU systems on a non-biomedical dataset (e.g., digits from scikit-learn) to assess generalizability
3. Conduct an ablation study removing the surrogate model from BO-Auto-PU to quantify its contribution to efficiency gains