---
ver: rpa2
title: Deep Learning With DAGs
arxiv_id: '2401.06864'
source_url: https://arxiv.org/abs/2401.06864
tags:
- distribution
- these
- causal
- cgnf
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces causal-graphical normalizing flows (cGNFs),
  a deep learning approach for causal inference with directed acyclic graphs (DAGs).
  cGNFs use invertible neural networks to flexibly model the full joint distribution
  of observed data, without assuming parametric functional forms.
---

# Deep Learning With DAGs

## Quick Facts
- arXiv ID: 2401.06864
- Source URL: https://arxiv.org/abs/2401.06864
- Authors: Sourabh Balgi; Adel Daoud; Jose M. Peña; Geoffrey T. Wodtke; Jesse Zhou
- Reference count: 39
- This study introduces causal-graphical normalizing flows (cGNFs), a deep learning approach for causal inference with directed acyclic graphs (DAGs).

## Executive Summary
This paper presents causal-graphical normalizing flows (cGNFs), a novel deep learning method that uses invertible neural networks to model full joint distributions of causal systems represented by DAGs. By recursively transforming samples from the standard normal distribution, cGNFs enable Monte Carlo estimation of any causal effect identified from a given DAG—including total, conditional, direct, indirect, and path-specific effects. The method offers flexibility without parametric assumptions and integrates seamlessly with sensitivity analyses for unobserved confounding.

## Method Summary
cGNFs employ unconstrained monotonic neural networks (UMNNs) to learn transformations that map each variable to a standard normal distribution conditional on its parents in the DAG. The method is trained using SGD to minimize negative log-likelihood of observed data. Once trained, cGNFs generate Monte Carlo samples from interventional distributions by transforming standard normal draws through the inverse flow, enabling estimation of various causal estimands. The approach handles both continuous and discrete variables through dequantization and incorporates sensitivity analysis through correlated normalized disturbances.

## Key Results
- cGNFs capture nonlinear relationships and dynamic selection processes that parametric models miss in reanalyses of Blau and Duncan's (1967) status attainment model
- Monte Carlo experiments show low bias and variance in large samples (16,000+ cases)
- Bootstrap intervals achieve close to nominal coverage for confidence estimation
- The method successfully integrates with sensitivity analyses for unobserved confounding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: cGNFs flexibly approximate the full joint distribution without assuming parametric functional forms
- Mechanism: By mapping each variable to a standard normal distribution conditional on its parents, the method captures complex relationships through deep neural networks
- Core assumption: The DAG structure correctly represents the causal relationships
- Evidence anchors:
  - [abstract] "cGNFs model the full joint distribution of the data according to a DAG supplied by the analyst, without relying on stringent assumptions about functional form"
  - [section] "Unlike conventional approaches, cGNFs model the full joint distribution of the data according to a DAG supplied by the analyst, without relying on stringent assumptions about functional form"
- Break condition: If the assumed DAG is incorrect, estimates will be biased regardless of model flexibility

### Mechanism 2
- Claim: Monte Carlo sampling from interventional distributions enables estimation of any identified causal estimand
- Mechanism: By truncating the flow according to desired interventions and sampling from the modified distribution, the method constructs estimates for total, conditional, direct, indirect, and path-specific effects
- Core assumption: The estimand is non-parametrically identified from the DAG
- Evidence anchors:
  - [abstract] "cGNFs enable Monte Carlo estimation of any causal effect identified from a given DAG—including total, conditional, direct, indirect, and path-specific effects"
  - [section] "With interventional distributions corresponding to different manipulations on the variable V3, we can recover a variety of causal estimands identified from the DAG"
- Break condition: If an estimand is not identified due to unobserved confounding, the method cannot provide accurate estimates

### Mechanism 3
- Claim: Sensitivity analysis through correlated normalized disturbances accounts for unobserved confounding
- Mechanism: By specifying correlations between normalized disturbance terms in the loss function and sampling procedure, the method adjusts estimates for different forms of unobserved confounding
- Core assumption: The correlation structure among normalized disturbances adequately represents the unobserved confounding
- Evidence anchors:
  - [abstract] "cGNFs also integrate seamlessly with sensitivity analyses for unobserved confounding"
  - [section] "cGFs offer a straightforward and intuitive approach for conducting such analyses (Balgi et al., 2022b)"
- Break condition: If the assumed correlation structure does not capture the true confounding pattern, bias-adjusted estimates will still be incorrect

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs) as non-parametric structural equation models
  - Why needed here: The method requires understanding how DAGs represent causal relationships without functional form assumptions
  - Quick check question: Can you explain how a DAG differs from a parametric SEM in terms of assumptions about causal relationships?

- Concept: Normalizing flows and diffeomorphisms
  - Why needed here: The method builds on normalizing flows to transform variables to standard normal distributions
  - Quick check question: What properties must a transformation have to be used in a normalizing flow, and why are these properties important?

- Concept: Monte Carlo estimation and g-computation
  - Why needed here: The method uses Monte Carlo sampling from interventional distributions to estimate causal effects
  - Quick check question: How does Monte Carlo estimation from interventional distributions relate to the g-computation algorithm?

## Architecture Onboarding

- Component map:
  - DAG specification module -> UMNN architecture builder -> Training pipeline with SGD optimization -> Sampling engine for observational and interventional distributions -> Sensitivity analysis framework

- Critical path:
  1. Specify DAG based on theory
  2. Build UMNN architecture with embedding and integrand networks
  3. Train cGNF using SGD on observed data
  4. Sample from relevant interventional distributions
  5. Construct estimates for target estimands
  6. Assess sensitivity to unobserved confounding

- Design tradeoffs:
  - Model complexity vs. overfitting risk
  - Sample size requirements vs. computational cost
  - Architecture expressiveness vs. training stability
  - Bootstrap replication count vs. inference reliability

- Failure signatures:
  - Validation loss plateaus early (underfitting)
  - Training loss diverges (learning rate too high)
  - Confidence intervals too wide (high variance)
  - Estimates inconsistent across replications (instability)

- First 3 experiments:
  1. Linear DAG with known functional forms to verify recovery of true parameters
  2. DAG with discrete variables to test dequantization integration
  3. DAG with unobserved confounding to validate sensitivity analysis framework

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific DAG architectures or model specifications are most effective for cGNFs to reliably estimate causal effects, and how do these vary across different types of causal systems?
- Basis in paper: [explicit] The paper discusses the performance of cGNFs with different DAGs in the empirical illustrations and Monte Carlo experiments, but does not provide a comprehensive framework for selecting optimal DAG architectures.
- Why unresolved: The effectiveness of cGNFs depends on the assumed DAG, and incorrect DAGs can lead to biased estimates. While the paper demonstrates that cGNFs can still provide accurate estimates for certain effects even with incorrectly specified parts of the DAG, a general understanding of which regions of the DAG must be accurately specified for reliable estimation of particular effects is lacking.
- What evidence would resolve it: Systematic studies comparing the performance of cGNFs with various DAG architectures across different causal systems, identifying which parts of the DAG are critical for accurate estimation of specific effects.

### Open Question 2
- Question: What are the precise conditions under which UMNNs can achieve universal density approximation, and how do these conditions relate to the sample size, network architecture, and complexity of the target distribution?
- Basis in paper: [explicit] The paper states that UMNNs are universal density approximators but acknowledges that the precise conditions required for them to reach this level of accuracy are not fully understood.
- Why unresolved: While the paper demonstrates that cGNFs with UMNNs can model complex distributions and yield accurate estimates in large samples, the exact relationship between the network architecture, sample size, and the complexity of the target distribution in achieving universal density approximation is unclear.
- What evidence would resolve it: Theoretical analysis and empirical studies establishing the necessary and sufficient conditions for UMNNs to achieve universal density approximation, including the impact of network architecture, sample size, and target distribution complexity.

### Open Question 3
- Question: How can cGNFs be integrated with measurement error models to improve their performance when input data is subject to inaccuracies?
- Basis in paper: [inferred] The paper discusses the limitations of cGNFs in the presence of measurement error and suggests that future research should explore the possibility of integrating measurement models into the cGNF architecture.
- Why unresolved: Measurement error is pervasive in social science data and can distort the training process of cGNFs, leading to erroneous output. While parametric SEMs have developed techniques for addressing measurement error, analogous methods for deep learning models like cGNFs are still in their infancy.
- What evidence would resolve it: Development and evaluation of measurement error models specifically designed for cGNFs, demonstrating their effectiveness in mitigating the impact of inaccurately measured inputs and improving the network's ability to distinguish signal from noise.

## Limitations

- The method's performance heavily depends on correct DAG specification, yet the paper does not provide guidance on DAG discovery or validation procedures.
- Substantial sample sizes (16,000+ cases) are required for optimal performance, which may not be available in many social science applications.
- Computational demands of training UMNNs and generating bootstrap samples could limit practical adoption.

## Confidence

- **High confidence**: The theoretical framework connecting normalizing flows to causal inference is sound, and the mathematical derivations for the loss function and sampling procedure are correct.
- **Medium confidence**: The empirical demonstrations on real-world datasets show promise, but the sample sizes used may not be representative of typical social science research contexts.
- **Medium confidence**: The sensitivity analysis framework is conceptually valid, but the specific implementation details and effectiveness in realistic confounding scenarios require further validation.

## Next Checks

1. **Small-sample performance evaluation**: Test cGNFs on datasets with sample sizes typical of social science research (n < 1,000) to assess bias and variance under realistic constraints.

2. **DAG misspecification robustness**: Systematically vary DAG structures to evaluate how errors in causal assumptions affect estimation accuracy across different types of estimands.

3. **Computational efficiency benchmarking**: Compare training times and memory requirements against established methods (e.g., parametric SEM, machine learning-based causal inference) across varying network architectures and dataset sizes.