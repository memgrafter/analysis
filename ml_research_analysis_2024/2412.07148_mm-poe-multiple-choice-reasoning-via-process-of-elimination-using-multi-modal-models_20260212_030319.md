---
ver: rpa2
title: 'MM-PoE: Multiple Choice Reasoning via. Process of Elimination using Multi-Modal
  Models'
arxiv_id: '2412.07148'
source_url: https://arxiv.org/abs/2412.07148
tags:
- reasoning
- mm-poe
- elimination
- language
- options
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MM-PoE, a novel approach to enhance the performance
  of Vision-Language Models (VLMs) in multiple-choice visual reasoning tasks. MM-PoE
  employs a two-step scoring method that mimics human test-taking strategies by first
  eliminating implausible options and then selecting the most probable answer from
  the remaining choices.
---

# MM-PoE: Multiple Choice Reasoning via. Process of Elimination using Multi-Modal Models

## Quick Facts
- arXiv ID: 2412.07148
- Source URL: https://arxiv.org/abs/2412.07148
- Authors: Sayak Chakrabarty; Souradip Pal
- Reference count: 40
- Primary result: Improves VLM accuracy on ScienceQA by 2.4% and AI2D by 1.5% using two-step elimination

## Executive Summary
This paper introduces MM-PoE, a novel approach to enhance Vision-Language Models' (VLMs) performance in multiple-choice visual reasoning tasks. The method employs a two-step scoring process that mimics human test-taking strategies by first eliminating implausible options and then selecting from remaining choices. Experimental evaluations demonstrate significant accuracy improvements over baseline methods on ScienceQA and AI2D datasets, with up to 2.4% improvement on ScienceQA and 1.5% on AI2D.

## Method Summary
MM-PoE implements a two-step scoring paradigm where VLMs first score all answer options and eliminate those below average, then re-score the remaining options within a masked context to make the final selection. The method uses a scoring function to evaluate each option's likelihood, masks out low-scoring options in step 1, and constructs a new context containing only plausible options for step 2. This approach is model-agnostic and can be integrated with existing VLMs without retraining.

## Key Results
- ScienceQA: 2.4% accuracy improvement over baseline in zero-shot setting
- AI2D: 1.5% accuracy improvement over baseline in zero-shot setting
- Consistent performance gains across both GIT and BLIP VLMs
- Model-agnostic approach works in both zero-shot and few-shot settings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Two-step scoring improves reasoning by separating elimination and selection into distinct cognitive phases
- **Mechanism**: First scores and masks options below average, then re-scores remaining options in masked context
- **Core assumption**: VLMs benefit from structured reasoning steps rather than evaluating all options simultaneously
- **Evidence anchors**: Abstract states MM-PoE "initially identifies and excludes implausible choices" and "yields more accurate, interpretable results"

### Mechanism 2
- **Claim**: Masking in step 2 forces focus on plausible candidates
- **Mechanism**: Eliminated options are removed from context to prevent "cheating" during final selection
- **Core assumption**: Removing low-scoring options reduces cognitive load and distraction
- **Evidence anchors**: Abstract notes method "emulates human test-taking strategies" by eliminating incorrect answers first

### Mechanism 3
- **Claim**: Method is model-agnostic and generalizes across VLMs
- **Mechanism**: Relies only on scoring function interface, works with any VLM capable of scoring text options
- **Core assumption**: VLMs share enough scoring behavior for common elimination wrapper to work uniformly
- **Evidence anchors**: Abstract states method is "easily integrated with existing VLMs" and designed to be model-agnostic

## Foundational Learning

- **Concept**: Vision-Language Model scoring functions
  - **Why needed here**: MM-PoE relies on scoring each option to rank and eliminate them
  - **Quick check question**: What is the difference between raw likelihood, average log probability, and calibrated log probability in VLM scoring?

- **Concept**: Prompt engineering for few-shot reasoning
  - **Why needed here**: MM-PoE tested in both zero-shot and few-shot settings
  - **Quick check question**: How does few-shot prompting alter the model's internal scoring distribution compared to zero-shot?

- **Concept**: Masking and context manipulation in multimodal inputs
  - **Why needed here**: Elimination step depends on masking options in the prompt
  - **Quick check question**: What happens if a VLM is given a masked option that it has seen in training?

## Architecture Onboarding

- **Component map**: Input -> Scoring Engine -> Step 1 (elimination) -> Step 2 (masked re-scoring) -> Output
- **Critical path**: Scoring → Elimination → Masked re-scoring → Final selection
- **Design tradeoffs**:
  - Mask threshold (average vs. fixed percentile) vs. risk of false positives
  - Number of re-scoring passes vs. latency
  - Model choice (GIT vs. BLIP) vs. computational budget
- **Failure signatures**:
  - Step 1 masks too many options → Step 2 has too few choices
  - Step 1 masks too few options → No benefit over baseline
  - Model ignores mask → Baseline performance
- **First 3 experiments**:
  1. Run MM-PoE with GIT on ScienceQA zero-shot; compare accuracy to baseline LM
  2. Vary mask threshold (mean, 1st quartile, 2nd quartile) and measure impact on final accuracy
  3. Test few-shot (1, 3 shots) with BLIP on AI2D; compare against zero-shot baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MM-PoE's elimination accuracy correlate with its final answer accuracy across different VLM architectures?
- Basis in paper: Explicit - paper mentions higher masking accuracy doesn't necessarily lead to better final scores
- Why unresolved: Paper provides examples but doesn't systematically analyze correlation across models and datasets
- What evidence would resolve it: Comprehensive study showing correlation coefficients between elimination accuracy and final accuracy across multiple VLM architectures and datasets

### Open Question 2
- Question: What are the computational trade-offs between MM-PoE and traditional single-pass scoring methods?
- Basis in paper: Inferred - paper focuses on accuracy but doesn't discuss computational costs
- Why unresolved: Paper doesn't address practical deployment considerations like latency or computational overhead
- What evidence would resolve it: Empirical benchmarks comparing inference time, GPU memory usage, and total computational cost per prediction

### Open Question 3
- Question: How would MM-PoE perform on more complex visual reasoning tasks involving multiple images or sequential visual information?
- Basis in paper: Inferred - current evaluation focuses on single-image questions
- Why unresolved: Current evaluation on relatively simple single-image multiple-choice questions
- What evidence would resolve it: Experiments applying MM-PoE to datasets with multiple images per question or video-based reasoning tasks

### Open Question 4
- Question: What is the optimal number of options to eliminate in Step 1 to maximize final accuracy?
- Basis in paper: Explicit - paper uses average-based threshold without exploring alternatives
- Why unresolved: Current approach uses simple average-based threshold without exploring whether different elimination criteria could improve performance
- What evidence would resolve it: Systematic study testing different elimination thresholds across multiple datasets

## Limitations
- Method's reliance on average-based masking introduces sensitivity to scoring variance across VLMs and datasets
- Scoring function implementation details are underspecified, particularly for multimodal inputs
- Claims about broadening applicability to complex visual reasoning lack demonstration on more challenging benchmarks

## Confidence

- **High confidence**: Two-step elimination framework is novel and logically sound, with clear experimental validation showing consistent accuracy improvements
- **Medium confidence**: Claims about model-agnostic generalization are supported but could be strengthened with more diverse VLM architectures
- **Low confidence**: Assertion that MM-PoE "broadens applicability to complex visual question-answering scenarios" lacks demonstration on more challenging benchmarks

## Next Checks
1. **Ablation on masking thresholds**: Test MM-PoE with multiple masking strategies (mean, median, fixed percentile) to determine sensitivity and optimal configuration
2. **Cross-architecture generalization**: Apply MM-PoE to additional VLMs like Flamingo, CLIP, or PaLI to verify true model-agnostic performance
3. **Failure case analysis**: Systematically identify question types where MM-PoE underperforms baseline methods to understand limitations and failure modes