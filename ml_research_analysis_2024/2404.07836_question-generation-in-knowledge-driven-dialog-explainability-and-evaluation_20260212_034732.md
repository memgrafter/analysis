---
ver: rpa2
title: 'Question Generation in Knowledge-Driven Dialog: Explainability and Evaluation'
arxiv_id: '2404.07836'
source_url: https://arxiv.org/abs/2404.07836
tags:
- triples
- dialog
- question
- context
- triple
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses question generation in knowledge-grounded dialogs
  with a focus on explainability and evaluation. The authors propose a model that
  generates both a knowledge base triple and a question, improving explainability
  by making the grounding of each question explicit.
---

# Question Generation in Knowledge-Driven Dialog: Explainability and Evaluation

## Quick Facts
- arXiv ID: 2404.07836
- Source URL: https://arxiv.org/abs/2404.07836
- Reference count: 9
- One-line primary result: Model generates triples and questions to improve explainability; achieves high G-BLEU scores and on-par human evaluation performance

## Executive Summary
This paper tackles the challenge of generating knowledge-grounded questions in dialog systems with a focus on explainability and fine-grained evaluation. The authors propose a model that first generates a knowledge base triple and then a corresponding question, making the grounding of each question explicit. This approach enables automatic evaluation of factuality, relevance, and pronominalization. Evaluated on the KGConv dataset, the model shows high G-BLEU scores (0.73-0.76) and performs on par with standard question-only models in human evaluations, while offering improved explainability and a richer set of evaluation metrics.

## Method Summary
The method involves fine-tuning a T5-small encoder-decoder to generate both a knowledge base triple and a question, conditioned on dialog context and a knowledge graph. The model is trained on KGConv data with various context types (DQAnl, DQnl, Dkl, DQAnl+kl) and K+ knowledge graphs with distractor triples. Evaluation uses G-BLEU for relevance, pronoun analysis for pronominalization, and human evaluation for fluency, non-repetition, and coherence.

## Key Results
- G-BLEU scores between generated questions and their conditioning triples are high (0.73-0.76), indicating good relevance
- Pronoun analysis reveals high ambiguity (29-36%) and gender errors (3-4%), suggesting room for improvement
- Human evaluation shows the model performs on par with a standard question-only model in fluency, non-repetition, and coherence
- Ablation studies confirm that conditioning on both dialog context and knowledge graph drastically improves coherence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model's dual-step generation (triple first, then question) enables explainability by making the grounding explicit.
- Mechanism: By generating a triple before the question, the model exposes its reasoning chain; the triple acts as an interpretable intermediate representation linking the dialog context to the question.
- Core assumption: The generated triple accurately reflects the intended fact the question is based on.
- Evidence anchors:
  - [abstract] "we present a model which instead of directly generating a question, sequentially predicts first a fact then a question"
  - [section] "In contrast to a standard conversational QG model which generates a question conditioning on some input, we train our question generation model to first generate a KB triple and then continue generating the corresponding question"
  - [corpus] Weak or missing evidence; corpus neighbors do not directly address explainability through intermediate triple generation.
- Break condition: If the generated triple is frequently irrelevant or ill-formed, the explainability benefit collapses.

### Mechanism 2
- Claim: Conditioning on both dialog context and predicted triple improves relevance and factuality.
- Mechanism: The triple acts as a strong inductive bias guiding the question toward a specific fact, reducing off-topic or hallucinated generation.
- Core assumption: The model can reliably select relevant triples from the knowledge graph when conditioned on dialog context.
- Evidence anchors:
  - [section] "we find that the average G-BLEU score is high (from 0.73 to 0.76) across the board. Such high G-BLEU scores indicate a good match between generated triples and questions suggesting that the generated questions are well-formed relevant questions overall"
  - [section] "The motivation for these additional triples is that they act as 'distractors' for content selection"
  - [corpus] Weak or missing evidence; corpus neighbors do not discuss factuality improvements via intermediate triple prediction.
- Break condition: If the model starts generating irrelevant triples or repeats triples already in the dialog, relevance and factuality will degrade.

### Mechanism 3
- Claim: Pronoun evaluation becomes tractable by anchoring pronouns to the subject entity of the generated triple.
- Mechanism: Since the question is conditioned on a specific triple, the gender and referential ambiguity of pronouns can be automatically checked against the triple's subject entity.
- Core assumption: The Wikidata 'sex or gender' property is reliably available and accurate for subject entities.
- Evidence anchors:
  - [section] "For each entity in our dataset, we retrieve its Wikidata 'sex or gender' object if any. We classify the retrieved genders into three main categories"
  - [section] "We approximate the number of ambiguous pronouns using the following two heuristics"
  - [corpus] Weak or missing evidence; corpus neighbors do not address pronoun evaluation in knowledge-grounded dialogs.
- Break condition: If gender metadata is missing or incorrect for many entities, pronoun evaluation accuracy will suffer.

## Foundational Learning

- Concept: Knowledge Graph Content Selection
  - Why needed here: The model must pick a relevant triple from a larger graph without drifting into noise or redundancy.
  - Quick check question: How does the model differentiate between relevant triples and distractor triples (out-of-scope or noise)?
- Concept: Pronoun Coreference Resolution
  - Why needed here: Dialogs contain pronouns that must agree in gender with their referents and be unambiguous.
  - Quick check question: What heuristics are used to detect ambiguous pronouns in generated questions?
- Concept: Automatic Evaluation with Multiple References
  - Why needed here: Standard metrics like BLEU are used to compare generated questions to many possible verbalizations of the same triple.
  - Quick check question: Why is Google BLEU chosen over other metrics for this task?

## Architecture Onboarding

- Component map:
  - Input layer: Root entity, entity type, knowledge graph (KD or KD+distractors), dialog context (DQAnl, DQnl, Dkl, DQAnl+kl)
  - Encoder-decoder: T5-small fine-tuned to generate [TRIPLE] followed by [QUESTION]
  - Output layer: Predicted triple + generated question
- Critical path: Dialog context + knowledge graph → triple prediction → question generation → evaluation
- Design tradeoffs:
  - Longer inference due to dual-step generation
  - More transparent but potentially slightly lower fluency than direct QG
  - Higher explainability at cost of complexity
- Failure signatures:
  - High proportion of ill-formed triples
  - Low G-BLEU between triples and questions
  - Pronoun gender mismatches or high ambiguity rates
  - Repetitive or off-topic questions
- First 3 experiments:
  1. Test triple prediction accuracy on KD only (no distractors)
  2. Compare G-BLEU scores for different context types (DQAnl vs Dkl vs DQAnl+kl)
  3. Evaluate pronoun gender and ambiguity rates on a sample of generated questions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the Extended QG model compare to the Question-Only QG model when evaluated on other knowledge-grounded dialog datasets like CSQA?
- Basis in paper: explicit
- Why unresolved: The paper only evaluates the models on the KGConv dataset, which may not be representative of all knowledge-grounded dialog settings.
- What evidence would resolve it: Conducting experiments on other knowledge-grounded dialog datasets and comparing the performance of both models would provide insights into the generalizability of the Extended QG model.

### Open Question 2
- Question: What are the most effective strategies for mitigating pronoun ambiguity in knowledge-grounded dialogs?
- Basis in paper: explicit
- Why unresolved: The paper identifies pronoun ambiguity as a significant challenge but does not propose specific solutions to address it.
- What evidence would resolve it: Developing and evaluating techniques to improve pronoun resolution in the context of knowledge-grounded dialogs would help mitigate this issue.

### Open Question 3
- Question: How does the Extended QG model perform in terms of explainability when compared to other interpretable dialog models?
- Basis in paper: explicit
- Why unresolved: The paper focuses on the explainability of the Extended QG model but does not compare it to other interpretable dialog models.
- What evidence would resolve it: Conducting a comparative analysis of the explainability of the Extended QG model with other interpretable dialog models would provide insights into its strengths and limitations.

## Limitations

- The reliance on a non-public dataset (KGConv) limits independent verification and broader reproducibility.
- Pronoun gender evaluation depends on external knowledge (Wikidata), which may be incomplete or inaccurate for many entities, introducing potential noise into reported metrics.
- The claim that the model performs "on par" with a standard QG model is based on a relatively small human evaluation sample (300 instances), so the generalizability of these results is uncertain.

## Confidence

- **High**: The sequential generation of triples before questions improves explainability by making grounding explicit; the G-BLEU scores (0.73-0.76) strongly indicate that generated questions are well-formed and relevant to their conditioning triples.
- **Medium**: The model's performance is on par with a standard question-only model in fluency, non-repetition, and coherence; conditioning on both dialog context and knowledge graph drastically improves coherence compared to context-only baselines.
- **Low**: Pronoun gender accuracy and ambiguity rates are reliable indicators of quality; Wikidata 'sex or gender' properties are sufficiently accurate and complete for robust pronoun evaluation.

## Next Checks

1. **Verify triple generation accuracy**: Test the model's ability to generate relevant and factually correct triples from dialog context and knowledge graph, especially when distractor triples are present. This will confirm the mechanism by which the model improves factuality and relevance.

2. **Validate pronoun evaluation pipeline**: Cross-check the Wikidata gender assignments against a random sample of generated questions to assess the reliability of pronoun gender and ambiguity metrics. This will identify whether external knowledge errors are inflating reported pronoun issues.

3. **Replicate human evaluation with expanded sample**: Conduct a larger human evaluation (e.g., 1000 instances) to confirm that the model's fluency, non-repetition, and coherence scores remain on par with standard QG models, ensuring the robustness of these findings.