---
ver: rpa2
title: 'AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties'
arxiv_id: '2410.24178'
source_url: https://arxiv.org/abs/2410.24178
tags:
- anomaly
- detection
- baseline
- xbad
- xfix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces AR-Pro, a framework for generating counterfactual
  explanations for anomaly detection that addresses the interpretability gap in current
  methods. The core idea leverages the observation that many anomaly detectors are
  linearly decomposable, allowing formal properties of counterfactual explanations
  to be defined: overall improvement (reduced anomaly score), similarity (resemblance
  to original), localized improvement (anomalous region repaired), and non-degradation
  (non-anomalous regions preserved).'
---

# AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties

## Quick Facts
- arXiv ID: 2410.24178
- Source URL: https://arxiv.org/abs/2410.24178
- Authors: Xiayan Ji; Anton Xue; Eric Wong; Oleg Sokolsky; Insup Lee
- Reference count: 40
- Primary result: AR-Pro generates counterfactual explanations for anomaly repair with formal properties across vision and time-series domains, achieving 84.27% average improvement on vision data and 60.03% on time-series data

## Executive Summary
AR-Pro introduces a framework for generating counterfactual explanations for anomaly detection by leveraging the observation that many anomaly detectors are linearly decomposable. This enables defining formal properties of counterfactual explanations—overall improvement, similarity, localized improvement, and non-degradation—that guide diffusion-based repair generation. The approach produces semantically meaningful counterfactual explanations showing what non-anomalous versions should look like, with evaluation demonstrating significant improvements over baseline diffusion models across vision and time-series datasets.

## Method Summary
AR-Pro generates counterfactual explanations for anomaly detection by first verifying that anomaly detectors are linearly decomposable (overall score = sum of feature-wise scores + regularizer). It then uses property-guided diffusion models (DDPM for vision, Diffusion-TS for time-series) with guidance terms derived from four property losses: overall improvement (reduced anomaly score), similarity (resemblance to original), localized improvement (anomalous region repaired), and non-degradation (non-anomalous regions preserved). Masked infilling preserves non-anomalous regions while guidance pushes toward lower anomaly scores. The method was evaluated on vision datasets (VisA, MVTec-AD) and time-series datasets (SWaT, WADI, HAI) with pre-trained detectors.

## Key Results
- Achieved 84.27% average improvement across four metrics on vision datasets (VisA, MVTec-AD)
- Achieved 60.03% average improvement on time-series datasets (SWaT, WADI, HAI)
- Reached true negative rates of 99.26% across all evaluated domains
- Outperformed baseline unguided diffusion models in generating semantically meaningful repairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear decomposability of anomaly detectors enables formal property definitions for counterfactual explanations
- Mechanism: Many anomaly detectors compute overall scores by aggregating feature-wise scores plus a regularizer. This structure allows defining four formal properties (overall improvement, similarity, localized improvement, non-degradation) that apply across domains
- Core assumption: Anomaly detectors commonly aggregate feature-wise scores linearly, with a regularizer term
- Evidence anchors:
  - [abstract] "key advantage of this approach is that it enables a domain-independent formal specification of explainability desiderata"
  - [section] "we observe that this aggregation often satisfies the following form: s(x) = α1(x) + · · · + αn(x) + β(x)"
  - [corpus] "Explainable AI in Big Data Fraud Detection" suggests domain-independent explainability is valuable
- Break condition: If anomaly detectors use non-linear aggregations or lack feature-wise decomposition, the formal properties cannot be defined

### Mechanism 2
- Claim: Property-guided diffusion generates semantically meaningful repairs that outperform unguided diffusion
- Mechanism: Diffusion model denoising steps are modified with guidance terms derived from the four property losses. Masked infilling preserves non-anomalous regions while the guidance pushes toward lower anomaly scores and better property satisfaction
- Core assumption: Diffusion models can be effectively guided by property-based loss terms without losing generation quality
- Evidence anchors:
  - [abstract] "AR-Pro, can produce semantically meaningful repairs that outperform off-the-shelf diffusion models"
  - [section] "we use guidance [19] to slightly nudge the iterates xt−1 of (3) at every step using a property-based loss"
  - [corpus] "Counterfactual Explanation for Auto-Encoder Based Time-Series Anomaly Detection" suggests counterfactual approaches work for anomaly detection
- Break condition: If guidance terms destabilize the diffusion process or if the base diffusion model cannot generate quality samples for the domain

### Mechanism 3
- Claim: Domain-independent formal properties provide unified evaluation framework across vision and time-series domains
- Mechanism: The same four properties (overall improvement, similarity, localized improvement, non-degradation) can be computed for any domain where anomaly scores are linearly decomposable, enabling consistent evaluation
- Core assumption: Linear decomposability enables the same formal properties to apply regardless of input modality
- Evidence anchors:
  - [abstract] "key advantage of this approach is that it enables a domain-independent formal specification of explainability desiderata"
  - [section] "Importantly, this is a strong but common condition with which we may formalize the desiderata of counterfactual explanations"
  - [corpus] "Explainable Anomaly Detection: Counterfactual driven What-If Analysis" suggests unified evaluation frameworks are valuable
- Break condition: If domains have fundamentally different requirements for counterfactual explanations that cannot be captured by these four properties

## Foundational Learning

- Concept: Linear decomposition of anomaly scores
  - Why needed here: Forms the mathematical foundation for defining formal properties of counterfactual explanations
  - Quick check question: Can you express an anomaly detector's score as the sum of feature-wise scores plus a regularizer term?

- Concept: Diffusion probabilistic models
  - Why needed here: Provides the generative framework for creating counterfactual repairs
  - Quick check question: How does a diffusion model generate samples from noise through iterative denoising?

- Concept: Counterfactual explanations
  - Why needed here: The goal is to generate what non-anomalous versions should look like
  - Quick check question: What distinguishes a counterfactual explanation from other types of model explanations?

## Architecture Onboarding

- Component map: Anomaly detector → Feature-wise score computation → Linear decomposition check → Property-guided diffusion → Repair generation
- Critical path: Input → Feature-wise anomaly detection → Linear decomposition validation → Diffusion-based repair with property guidance → Evaluation against four formal properties
- Design tradeoffs: Property guidance improves repair quality but increases inference time; linear decomposition assumption enables formal properties but may not hold for all detectors
- Failure signatures: Poor repairs (low similarity, insufficient improvement) suggest guidance weights need tuning; NaN values suggest guidance terms destabilize diffusion
- First 3 experiments:
  1. Verify linear decomposability of your anomaly detector on a small test set
  2. Run baseline diffusion without property guidance on a few anomalous samples
  3. Enable property guidance incrementally (start with overall improvement, then add similarity) to observe quality improvements

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the evaluation and methodology, several implicit questions arise regarding the limitations and future directions of the approach.

## Limitations

- Linear decomposability assumption may not hold for all anomaly detection methods, limiting generalizability
- Computational overhead of property-guided diffusion versus baseline methods is not explicitly quantified
- Evaluation focuses on specific datasets and metrics without exploring broader applicability or robustness to adversarial examples

## Confidence

- Mechanism 1 (Linear decomposability enabling formal properties): Medium - While supported by examples, the assumption may not generalize to all anomaly detectors
- Mechanism 2 (Property-guided diffusion effectiveness): High - Strong empirical results show consistent improvements across domains
- Mechanism 3 (Domain-independent properties): Medium - Demonstrates success on vision and time-series but untested on other modalities

## Next Checks

1. Test AR-Pro on anomaly detectors that do not exhibit clear linear decomposability to assess the framework's limitations
2. Measure and compare inference times between baseline diffusion and property-guided approaches across all evaluated datasets
3. Evaluate robustness of generated counterfactuals against adversarial perturbations to assess practical security implications