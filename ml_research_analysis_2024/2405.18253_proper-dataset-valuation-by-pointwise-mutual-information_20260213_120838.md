---
ver: rpa2
title: Proper Dataset Valuation by Pointwise Mutual Information
arxiv_id: '2405.18253'
source_url: https://arxiv.org/abs/2405.18253
tags:
- data
- dataset
- information
- mutual
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel information-theoretic framework for
  evaluating data curation methods using pointwise mutual information (PMI) between
  curated and test datasets. The key innovation is showing that dataset informativeness
  about true model parameters can be quantified by Shannon mutual information, and
  introducing a practical PMI estimation method based on Bayesian models trained on
  embedded datasets.
---

# Proper Dataset Valuation by Pointwise Mutual Information

## Quick Facts
- arXiv ID: 2405.18253
- Source URL: https://arxiv.org/abs/2405.18253
- Authors: Shuran Zheng; Xuan Qi; Rui Ray Chen; Yongchan Kwon; James Zou
- Reference count: 40
- Key outcome: Novel information-theoretic framework for evaluating data curation methods using pointwise mutual information (PMI) between curated and test datasets

## Executive Summary
This paper introduces a novel information-theoretic framework for evaluating data curation methods using pointwise mutual information (PMI) between curated and test datasets. The key innovation is showing that dataset informativeness about true model parameters can be quantified by Shannon mutual information, and introducing a practical PMI estimation method based on Bayesian models trained on embedded datasets. Experiments on MNIST and CIFAR demonstrate that the proposed PMI-based evaluation correctly identifies strategic curation methods (those that reduce dataset informativeness despite improving test scores), while traditional test score-based evaluation fails to detect such methods. The PMI estimator achieves superior accuracy compared to existing methods, with a convergence rate independent of input dimensionality.

## Method Summary
The method computes dataset informativeness using Shannon mutual information between curated datasets and test datasets. It employs Bayesian models trained on embedded datasets to estimate pointwise mutual information through a closed-form expression involving posterior distributions of model parameters. The approach uses logistic regression with L2 regularization as the Bayesian model, with datasets embedded using pretrained models. This enables strategy-proof evaluation of data curation methods by measuring how much information the curated dataset contains about the true model parameters, rather than just test accuracy.

## Key Results
- PMI-based evaluation correctly identifies strategic curation methods that reduce dataset informativeness despite improving test scores
- The PMI estimator achieves highest Spearman's ρ rank correlation with ground truth MI compared to baseline methods
- Convergence rate of the PMI estimator is independent of input dimensionality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed PMI-based scoring function is strategy-proof because it directly measures the mutual information between curated and test datasets, which is unaffected by manipulations that make datasets more similar to the test set.
- Mechanism: The Shannon mutual information I(bD, T) is a proper scoring rule that incentivizes truthful reporting of data informativeness. Unlike test accuracy, it cannot be gamed by simply making curated data more similar to test data without adding genuine information.
- Core assumption: T → D → f(D) forms a Markov chain, meaning the curated data is conditionally independent of the test data given the original data.
- Evidence anchors:
  - [abstract]: "we propose an information-theoretic framework for evaluating data curation methods... we evaluate the informativeness of a dataset for a given machine learning task."
  - [section 3]: "We therefore define strategic data curation methods as those that reduce the dataset's informativeness about the true underlying model parameters θ, even if they may improve test scores."
- Break condition: If the Markov chain assumption is violated (e.g., test data is somehow used in curating the data), the PMI scoring function may no longer be strategy-proof.

### Mechanism 2
- Claim: The PMI dataset score can be computed as a closed-form expression using Bayesian model posteriors, enabling efficient estimation even for high-dimensional datasets.
- Mechanism: By embedding datasets using pretrained models and training Bayesian models on these embeddings, the pointwise mutual information can be computed using the posterior distributions of model parameters via a novel closed-form formula.
- Core assumption: The posterior distributions of model parameters can be approximated by tractable distributions using established posterior inference techniques.
- Evidence anchors:
  - [section 4.2]: "We exploit a dataset's capacity to train a machine learning model and compute the mutual information using the posterior distributions of model parameters obtained from Bayesian models."
  - [section 4.3]: "To obtain the posterior distributions p(w|·), we train logistic regression models on embedded D and T with L2 regularization parameterized by C."
- Break condition: If the posterior approximation is poor or the embedding model fails to capture relevant information, the PMI estimates will be inaccurate.

### Mechanism 3
- Claim: The PMI estimator achieves superior accuracy compared to existing methods with a convergence rate independent of input dimensionality.
- Mechanism: By leveraging Bayesian models and the closed-form PMI expression, the estimator avoids the high-discrepancy issue that plagues discriminative approaches and the generative modeling challenges of generative approaches.
- Core assumption: The Bayesian model provides accurate posterior probabilities.
- Evidence anchors:
  - [section 4.1]: "Our setting presents a more severe challenge: the aggregate dimensionality of the full datasets becomes prohibitively large due to the number of data points."
  - [section 5.1]: "As shown in Table 1 and Figure 2, our PMI estimator achieves the highest Spearman's ρ rank correlation, producing the most accurate estimates with the smallest variance."
- Break condition: If the dataset is too small to train effective Bayesian models, or if the datasets are too large resulting in significant overlap that violates independence assumptions, the estimator will fail.

## Foundational Learning

- Concept: Blackwell ordering of informativeness
  - Why needed here: It provides the theoretical foundation for distinguishing strategic from non-strategic data curation methods based on their effect on dataset informativeness.
  - Quick check question: What is the key property of a more informative dataset under Blackwell ordering?

- Concept: Shannon mutual information
  - Why needed here: It serves as the metric for quantifying dataset informativeness and forms the basis of the strategy-proof scoring function.
  - Quick check question: How does mutual information capture the relationship between curated and test datasets?

- Concept: Bayesian model posteriors
  - Why needed here: They enable the computation of pointwise mutual information through the closed-form expression, making the estimation tractable for high-dimensional datasets.
  - Quick check question: What role do posterior distributions play in the PMI computation formula?

## Architecture Onboarding

- Component map: Dataset embedding -> Bayesian model training -> Posterior computation -> PMI calculation
- Critical path: Dataset embedding → Bayesian model training → Posterior computation → PMI calculation
- Design tradeoffs: The choice of embedding model affects the quality of PMI estimates; simpler Bayesian models like logistic regression are computationally efficient but may miss complex relationships that more sophisticated Bayesian neural networks could capture.
- Failure signatures: Poor PMI estimates (low rank correlation with ground truth), high variance in estimates across trials, failure to distinguish strategic from non-strategic curation methods in experiments.
- First 3 experiments:
  1. Implement the PMI estimator on Colored MNIST with varying regularization strengths C and compare rank correlation with ground truth MI.
  2. Test the PMI scoring function on data denoising, duplication, and removal scenarios on Colored MNIST.
  3. Evaluate the PMI estimator on Corrupted CIFAR with ResNet18 embeddings and compare with baseline methods.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can one design a principled method for selecting dataset pairs that most effectively estimate mutual information?
- Basis in paper: [inferred] The paper notes that PMI scoring can fail when datasets are too small to train effective models or too large resulting in significant overlap that violates independence assumptions.
- Why unresolved: The paper identifies this as a key challenge but does not provide a systematic solution for optimal dataset pair selection.
- What evidence would resolve it: A framework or algorithm that determines optimal dataset sizes and compositions for reliable PMI estimation, validated through experiments showing consistent performance across different dataset pairs.

### Open Question 2
- Question: What is the impact of prior misspecification on the absolute accuracy of PMI estimates versus their ranking performance?
- Basis in paper: [explicit] The paper states that PMI scoring is robust to prior misspecification in terms of ranking mutual information, but the absolute accuracy of MI estimates is highly sensitive to prior choice.
- Why unresolved: The paper does not explore the trade-off between prior sensitivity and estimation accuracy in depth.
- What evidence would resolve it: Empirical studies comparing PMI estimates under various prior specifications, quantifying the degradation in absolute accuracy while maintaining ranking stability.

### Open Question 3
- Question: Can mutual information estimation be improved by using more advanced Bayesian neural networks beyond simple logistic regression?
- Basis in paper: [explicit] The paper notes that experiments focus on simple logistic regression and asks whether more advanced Bayesian neural networks could improve MI estimation.
- Why unresolved: The paper does not test alternative Bayesian modeling approaches.
- What evidence would resolve it: Comparative experiments using different Bayesian neural network architectures (e.g., Bayesian neural networks with Gaussian mixture approximations or Dirichlet approximations) to measure improvements in MI estimation accuracy and convergence rates.

## Limitations
- The theoretical guarantees rely on the assumption that test data is conditionally independent of curated data given original data, which may not hold in practical scenarios
- The PMI estimation method requires training Bayesian models, making it computationally expensive for very large datasets
- The quality of PMI estimates depends critically on the choice of embedding model and Bayesian architecture, with simple logistic regression potentially missing complex relationships

## Confidence

- **High Confidence**: The theoretical framework connecting Blackwell ordering, mutual information, and strategy-proof evaluation is sound and well-established in information theory.
- **Medium Confidence**: The PMI estimation method and its empirical performance on synthetic datasets, though the generalization to more complex real-world scenarios needs further validation.
- **Medium Confidence**: The claim that PMI scoring is strategy-proof, assuming the Markov chain condition holds and proper Bayesian modeling is used.

## Next Checks

1. Test the PMI scoring function on a real-world dataset curation scenario where curators have partial knowledge of test data to verify the strategy-proof property under Markov chain violations.

2. Compare the PMI estimator's performance against alternative information-theoretic estimators (e.g., variational approaches) on datasets with known ground truth mutual information across varying dimensionalities and sample sizes.

3. Evaluate the computational efficiency and scalability of the PMI estimation method on larger datasets (e.g., ImageNet) with more complex Bayesian architectures (e.g., Bayesian neural networks) to assess practical applicability.