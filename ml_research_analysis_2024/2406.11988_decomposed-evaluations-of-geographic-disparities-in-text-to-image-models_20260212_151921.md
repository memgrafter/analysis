---
ver: rpa2
title: Decomposed evaluations of geographic disparities in text-to-image models
arxiv_id: '2406.11988'
source_url: https://arxiv.org/abs/2406.11988
tags:
- images
- generated
- object
- real
- disparities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Decomposed-DIG, a new set of metrics that
  separately measure geographic disparities in objects and backgrounds in generated
  images. Using Decomposed-DIG, the authors audit a widely used latent diffusion model
  and find that generated images depict objects with better realism than backgrounds
  and that backgrounds in generated images tend to contain larger regional disparities
  than objects.
---

# Decomposed evaluations of geographic disparities in text-to-image models

## Quick Facts
- **arXiv ID:** 2406.11988
- **Source URL:** https://arxiv.org/abs/2406.11988
- **Reference count:** 40
- **Key outcome:** Introduces Decomposed-DIG metrics that separately measure geographic disparities in objects versus backgrounds, finding backgrounds show larger disparities than objects

## Executive Summary
This paper introduces Decomposed-DIG, a new set of metrics that separately measure geographic disparities in objects and backgrounds in generated images. Using Decomposed-DIG, the authors audit a widely used latent diffusion model and find that generated images depict objects with better realism than backgrounds and that backgrounds in generated images tend to contain larger regional disparities than objects. They use Decomposed-DIG to pinpoint specific examples of disparities, such as stereotypical background generation in Africa, struggling to generate modern vehicles in Africa, and unrealistically placing some objects in outdoor settings. Informed by their metric, the authors use a new prompting structure that enables a 52% worst-region improvement and a 20% average improvement in generated background diversity.

## Method Summary
Decomposed-DIG extends the DIG metric by separately measuring precision and coverage for objects versus backgrounds in generated images. The method segments images using LangSAM, extracts ViT features with attention masking to isolate object and background patches, and computes separate precision and coverage metrics for each component. This decomposition reveals that background disparities are typically larger than object disparities, and that prompt structure significantly affects background diversity.

## Key Results
- Generated images depict objects with better realism than backgrounds
- Backgrounds in generated images tend to contain larger regional disparities than objects
- Adjective-based prompting substantially improves background diversity (52% worst-region improvement, 20% average improvement)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decomposed-DIG can separately measure disparities in realism and diversity for objects versus backgrounds in generated images.
- **Mechanism:** The method first segments each image into object and background using LangSAM (object detection + SAM segmentation). It then masks attention in a ViT model so that object features are computed using only object patches and background features using only background patches. Precision and coverage metrics are then calculated separately on these decomposed feature sets.
- **Core assumption:** ViT patch-based architecture allows isolation of features for specific image regions without overlap.
- **Evidence anchors:**
  - [abstract] "Decomposed-DIG that allows us to separately measure geographic disparities in the depiction of objects and backgrounds in generated images."
  - [section] "We consider all the patches that contain at least one pixel of the object as object patches, and the remaining patches (which do not have any object pixels) as background patches (thus, together they make up the full image without overlap)."
  - [corpus] Weak - no direct corpus mention of this specific mechanism.

### Mechanism 2
- **Claim:** Backgrounds in generated images have larger geographic disparities than objects, as measured by Decomposed-DIG.
- **Mechanism:** By computing per-region precision and coverage separately for object-only and background-only feature sets, the method reveals that background coverage varies twice as much between best and worst regions, and background precision spans 1.5x the variance of object precision.
- **Core assumption:** Geographic disparities are not uniform across image components and can be quantified via separate metrics.
- **Evidence anchors:**
  - [abstract] "we find that generated images depict objects with better realism than backgrounds and that backgrounds in generated images tend to contain larger regional disparities than objects."
  - [section] "BG-only measurements reveal that background coverage is twice as large for the best-performing region (Southeast Asia) than the worst performing region (Africa), while only 1.2x larger for object coverage."
  - [corpus] Weak - corpus does not provide direct supporting evidence for this mechanism.

### Mechanism 3
- **Claim:** Prompt structure affects background diversity, with adjective-based prompts reducing geographic disparities.
- **Mechanism:** Using a prompt template "{regional adjective} {object}" instead of "{object} in {region}" shifts emphasis from depicting the object in a region to depicting a region-specific version of the object. This leads to more varied backgrounds (52% improvement in worst-region coverage) with minimal cost to realism.
- **Core assumption:** The model interprets prompts differently based on syntax, affecting background generation.
- **Evidence anchors:**
  - [abstract] "we use a new prompting structure that enables a 52% worst-region improvement and a 20% average improvement in generated background diversity."
  - [section] "We find that adjective-based prompting substantially improves background diversity (coverage), by 52% for the worst region and 20% on average."
  - [corpus] Weak - no direct corpus evidence supporting this specific prompt mechanism.

## Foundational Learning

- **Concept:** Segmentation of images into objects and backgrounds.
  - Why needed here: The core innovation of Decomposed-DIG relies on isolating object and background features to separately measure disparities.
  - Quick check question: How does LangSAM segment an image into object and background components?

- **Concept:** ViT patch-based feature extraction and attention masking.
  - Why needed here: Decomposed-DIG uses ViT patches and masks attention to compute separate features for objects and backgrounds.
  - Quick check question: What does it mean to mask attention in a ViT model, and how does it isolate features for objects versus backgrounds?

- **Concept:** Precision and coverage metrics for generative model evaluation.
  - Why needed here: These metrics quantify realism (precision) and diversity (coverage) in generated images, which are central to Decomposed-DIG's evaluation.
  - Quick check question: How do precision and coverage differ in measuring generative model performance, and why are both needed?

## Architecture Onboarding

- **Component map:** GeoDE dataset -> LangSAM segmentation -> ViT feature extraction -> Decomposed-DIG metrics
- **Critical path:**
  1. Load real and generated images
  2. Segment each image into object and background using LangSAM
  3. Extract ViT features for full-image, object-only, and background-only using attention masking
  4. Compute precision and coverage for each set-up (full, object-only, background-only)
  5. Analyze per-region disparities and identify failure modes
- **Design tradeoffs:**
  - Segmentation accuracy vs. computational cost (LangSAM is fast but may fail on some object classes)
  - ViT vs. CNN for feature extraction (ViT allows patch isolation, CNNs do not)
  - Granularity of segmentation (fine vs. coarse) affects feature quality
- **Failure signatures:**
  - High failure rate in LangSAM segmentation for certain object classes
  - Poor separation of object and background features due to patch overlap or attention leakage
  - Biased metric computation if feature extractor favors objects or backgrounds
- **First 3 experiments:**
  1. Run LangSAM segmentation on a small set of real images and manually verify object/background separation quality
  2. Extract ViT features for full-image, object-only, and background-only sets and compare feature distributions
  3. Compute precision and coverage for a single object-region pair to validate metric calculations

## Open Questions the Paper Calls Out
- The paper does not explicitly call out open questions in the text provided.

## Limitations
- The segmentation pipeline (LangSAM) may have higher failure rates on generated images compared to real images, potentially biasing results
- The paper does not provide empirical comparison between Decomposed-DIG metrics and human evaluations of geographic representation
- The effectiveness of Decomposed-DIG across different text-to-image model architectures remains untested

## Confidence

- **High confidence:** The core mechanism of decomposing DIG metrics into object-only and background-only components is well-supported by the technical description and logical architecture
- **Medium confidence:** The finding that backgrounds show larger geographic disparities than objects is supported by quantitative results, but the mechanism explanation is relatively brief
- **Medium confidence:** The mitigation strategy using adjective-based prompting shows promising quantitative results, but the explanation of why this works is somewhat speculative

## Next Checks

1. **Segmentation robustness test:** Run LangSAM on a small sample of generated images and compare segmentation quality to real images. Document failure rates by region and object class to assess potential bias.
2. **Cross-validation of disparities:** Select 5-10 example images from high-disparity regions and manually verify whether the measured disparities align with visual inspection of object vs. background quality.
3. **Prompt structure ablation:** Test the adjective-based prompt with different adjective choices (e.g., "African", "African-style", "African-inspired") to determine if the improvement is robust to prompt variations or specific to certain descriptors.