---
ver: rpa2
title: Conformal Inductive Graph Neural Networks
arxiv_id: '2407.09173'
source_url: https://arxiv.org/abs/2407.09173
tags:
- coverage
- nodes
- node
- prediction
- calibration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of applying conformal prediction
  (CP) to inductive node classification in graph neural networks (GNNs), where conventional
  CP fails due to distribution shifts caused by message passing with new nodes. The
  authors propose two approaches: NodeEx CP for node-exchangeable graph sequences
  and EdgeEx CP for edge-exchangeable sequences.'
---

# Conformal Inductive Graph Neural Networks

## Quick Facts
- arXiv ID: 2407.09173
- Source URL: https://arxiv.org/abs/2407.09173
- Reference count: 40
- Primary result: NodeEx and EdgeEx CP methods maintain near 1-α coverage while improving prediction set efficiency compared to naive CP

## Executive Summary
This paper addresses the challenge of applying conformal prediction (CP) to inductive node classification in graph neural networks (GNNs), where conventional CP fails due to distribution shifts caused by message passing with new nodes. The authors propose two approaches: NodeEx CP for node-exchangeable graph sequences and EdgeEx CP for edge-exchangeable sequences. Both methods recover the standard 1-α coverage guarantee by recomputing conformity scores conditional to the current subgraph. Experiments across 9 datasets and 4 GNN models demonstrate that the proposed methods maintain near 1-α coverage (target 90%) while improving prediction set efficiency.

## Method Summary
The paper introduces NodeEx CP and EdgeEx CP as solutions for applying conformal prediction to inductive node classification in GNNs. NodeEx CP computes conformity scores conditional to the current subgraph at each timestep, while EdgeEx CP uses weighted CP with weights equal to 1/deg(v). Both methods require retraining or updating the GNN on the current subgraph and recomputing scores for all nodes at each timestep. The key innovation is showing that under node-exchangeability, the effect of new nodes is symmetric to calibration and evaluation sets, allowing valid CP application. Under edge-exchangeability, weighted CP achieves similar guarantees by decomposing edge-exchangeable sequences into weighted node-exchangeable subsequences.

## Key Results
- NodeEx and EdgeEx CP maintain near 1-α coverage (target 90%), while naive CP shows significant deviation (up to 6.86% absolute error)
- Proposed methods improve prediction set efficiency and singleton hit ratio compared to standard CP
- NodeEx CP achieves comparable coverage and efficiency to EdgeEx CP on datasets with sufficient density
- Both methods work across 4 different GNN architectures (GCN, GAT, APPNP, MLP) on 9 datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conformal prediction guarantees 1-α coverage when calibration and test data are exchangeable, even with GNNs.
- Mechanism: Exchangeability allows reordering of calibration and test points without changing joint distribution, enabling quantile calibration to provide valid coverage.
- Core assumption: Node/edge exchangeability of graph sequences, and permutation-equivariant GNN scores.
- Evidence anchors:
  - [abstract]: "CP requires exchangeability, a relaxation of the i.i.d. assumption, to obtain a valid distribution-free coverage guarantee."
  - [section 4.1]: "With node-exchangeability, calibration and evaluation scores computed conditional to a specific subgraph are still exchangeable."
- Break condition: If graph sequence violates exchangeability (e.g., temporal drift), coverage guarantee fails.

### Mechanism 2
- Claim: NodeEx CP recovers coverage guarantee by recomputing conformity scores conditional to current subgraph.
- Mechanism: New nodes shift embeddings symmetrically for calibration and test nodes; conditioning on subgraph preserves exchangeability.
- Core assumption: Message passing with new nodes affects calibration and test nodes symmetrically.
- Evidence anchors:
  - [section 4.1]: "computing the conformity scores conditional to the subgraph at any timestep recovers the guarantee."
  - [section 4.1]: "the effect of new coming nodes is symmetric to the calibration set and the existing nodes."
- Break condition: If symmetry assumption fails (e.g., adversarial node arrivals), coverage breaks.

### Mechanism 3
- Claim: EdgeEx CP achieves valid coverage via weighted conformal prediction with weights 1/deg(v).
- Mechanism: Edge-exchangeable sequences decompose into weighted node-exchangeable subsequences; weighted quantile calibration maintains guarantee.
- Core assumption: Edge-exchangeability implies weighted node-exchangeability with degree-based weights.
- Evidence anchors:
  - [section 4.2]: "w.r.t. scores, any edge-exchangeable sequence is equivalent to a weighted node-exchangeable sequence."
  - [section 4.2]: "weighted CP with weights equal to 1/deg(v) achieves similar guarantees."
- Break condition: If degree distribution changes drastically over time, weighted guarantee may fail.

## Foundational Learning

- Concept: Conformal prediction and exchangeability
  - Why needed here: CP relies on exchangeability to provide coverage guarantees; understanding this is crucial for adapting CP to GNNs.
  - Quick check question: What is the key assumption CP makes about the relationship between calibration and test data?

- Concept: Graph neural networks and message passing
  - Why needed here: GNNs use message passing which causes score shifts with new nodes; understanding this is essential for NodeEx CP mechanism.
  - Quick check question: How does adding new nodes to a graph affect GNN embeddings of existing nodes?

- Concept: Permutation-equivariance in GNNs
  - Why needed here: Ensures GNN scores are invariant to node/edge relabeling, preserving exchangeability under CP.
  - Quick check question: Why is permutation-equivariance important for applying CP to GNNs?

## Architecture Onboarding

- Component map:
  GNN model (any permutation-equivariant architecture) -> Conformance score function (e.g., APS, DAPS, TPS) -> Calibration set (first n nodes/edges in sequence) -> Evaluation set (remaining nodes/edges) -> Subgraph conditioning (for NodeEx CP) -> Weighted quantile computation (for EdgeEx CP)

- Critical path:
  1. Train GNN on initial subgraph G0
  2. For each timestep t:
     - Update graph with new node/edge
     - Recompute GNN scores for all nodes in Gt
     - Compute conditional/weighted quantile threshold
     - Generate prediction sets for evaluation nodes

- Design tradeoffs:
  - NodeEx vs EdgeEx: NodeEx preserves guarantee but produces dense graphs; EdgeEx handles sparsity but requires degree weighting
  - Score function choice: APS provides good efficiency but may sacrifice some coverage; TPS is simpler but less efficient
  - Calibration set size: Larger sets improve concentration but reduce available training data

- Failure signatures:
  - Coverage significantly below 1-α target
  - Empty prediction sets for many nodes (especially with EdgeEx CP on very sparse graphs)
  - Large variance in coverage across different sequences

- First 3 experiments:
  1. Compare NodeEx CP vs naive CP on CoraML with GCN, measuring coverage and set size
  2. Test EdgeEx CP vs NodeEx CP on PubMed with varying graph density
  3. Evaluate different score functions (APS, TPS, DAPS) with NodeEx CP on CiteSeer

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is NodeEx/EdgeEx CP when the node-exchangeable or edge-exchangeable assumptions are violated in real-world graph sequences?
- Basis in paper: [explicit] The authors acknowledge this as a limitation, stating "real-world graphs may not satisfy node- or edge-exchagability" and suggesting that "the beyond exchangeability framework" could partially mitigate this issue.
- Why unresolved: The paper focuses on theoretical guarantees under the exchangeable assumptions and doesn't empirically test the methods on non-exchangeable graphs or explore how far real graphs deviate from exchangeability.
- What evidence would resolve it: Experiments on real-world graphs with known non-exchangeable properties, or quantitative measures of how the coverage guarantee degrades as the degree of exchangeability decreases.

### Open Question 2
- Question: Can NodeEx/EdgeEx CP be extended to handle adversarial evaluation set selection that breaks the coverage guarantee?
- Basis in paper: [explicit] The authors state that "the guarantee does not hold for adversarially chosen evaluation sets" and that "the choice of which nodes is evaluated at which timesteps must be prior to observing the prediction set."
- Why unresolved: The paper only discusses this as a limitation without proposing solutions or exploring the severity of the problem in practice.
- What evidence would resolve it: Analysis of how much an adversary could manipulate the coverage by strategically choosing evaluation sets, and proposed modifications to NodeEx/EdgeEx CP to make it robust to such attacks.

### Open Question 3
- Question: How does the computational overhead of NodeEx/EdgeEx CP compare to naive CP in practice, especially for large graphs and frequent updates?
- Basis in paper: [explicit] The authors discuss the computational complexity in terms of conformal score computation and quantile threshold calculation, noting that "NodeEx CP has an overhead of O(n × ts × t)" for t timesteps and n calibration nodes.
- Why unresolved: The paper mentions that "the total wall-clock overhead is less than a second" but doesn't provide detailed runtime comparisons or scaling analysis with graph size and update frequency.
- What evidence would resolve it: Systematic benchmarking of NodeEx/EdgeEx CP vs naive CP on graphs of varying sizes and update rates, including wall-clock time measurements and memory usage analysis.

## Limitations
- The methods rely on node- or edge-exchangeability assumptions that may not hold in real-world graph sequences
- NodeEx CP requires dense graphs to avoid empty prediction sets, limiting applicability to sparse real-world graphs
- EdgeEx CP requires careful degree-based weighting that may be sensitive to degree distribution changes over time

## Confidence
- **High**: The theoretical guarantees under node- and edge-exchangeability assumptions, as these follow directly from established conformal prediction theory
- **Medium**: The experimental results showing coverage improvement, as these depend on specific dataset characteristics and implementation details
- **Medium**: The efficiency improvements (smaller prediction sets, higher singleton hit ratio), as these trade off against coverage guarantees

## Next Checks
1. **Exchangeability violation test**: Systematically introduce non-exchangeable patterns (e.g., temporal drift, adversarial node arrivals) and measure how quickly coverage guarantees break down for both NodeEx and EdgeEx CP.
2. **Degree distribution sensitivity**: Vary the rate and pattern of edge arrivals to create sequences with rapidly changing degree distributions, then evaluate EdgeEx CP's coverage stability across different weighting schemes.
3. **Score function robustness**: Test the sensitivity of NodeEx CP to different conformity score functions (APS, TPS, DAPS) under varying levels of class imbalance and feature noise in the arriving nodes.