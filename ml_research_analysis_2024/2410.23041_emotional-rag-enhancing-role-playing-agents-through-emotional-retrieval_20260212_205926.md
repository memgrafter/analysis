---
ver: rpa2
title: 'Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval'
arxiv_id: '2410.23041'
source_url: https://arxiv.org/abs/2410.23041
tags:
- memory
- emotional
- role-playing
- agents
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Emotional RAG, a novel framework for enhancing
  role-playing agents by incorporating emotional memory into the retrieval process.
  Inspired by psychological theories of mood-dependent memory, Emotional RAG retrieves
  memory fragments that are both semantically relevant and emotionally consistent
  with the user's current emotional state.
---

# Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval

## Quick Facts
- arXiv ID: 2410.23041
- Source URL: https://arxiv.org/abs/2410.23041
- Authors: Le Huang; Hengzhi Lan; Zijun Sun; Chuan Shi; Ting Bai
- Reference count: 39
- Primary result: Emotional RAG outperforms standard RAG in maintaining personality traits in role-playing agents through emotional retrieval

## Executive Summary
This paper introduces Emotional RAG, a novel framework that enhances role-playing agents by incorporating emotional memory into the retrieval process. Inspired by mood-dependent memory theory, the framework retrieves memory fragments that are both semantically relevant and emotionally consistent with the user's current emotional state. Through extensive experiments on three datasets (InCharacter, CharacterEval, and Character-LLM), Emotional RAG demonstrates superior performance in maintaining personality traits, achieving higher accuracy in both MBTI and BFI personality evaluations compared to standard RAG methods.

## Method Summary
Emotional RAG is a retrieval-augmented generation framework that enhances role-playing agents by incorporating emotional factors into memory retrieval. The framework encodes queries and memory fragments into both semantic (768-dim) and emotional (8-dim) vectors, then retrieves the most relevant memories based on combined semantic and emotional similarity. Two retrieval strategies are employed: combination (add or multiply semantic and emotional scores) and sequential (semantic first then emotional, or vice versa). The retrieved memories are then used to generate responses that maintain personality traits while being emotionally consistent with the conversation context.

## Key Results
- Emotional RAG achieves better personality trait maintenance than standard RAG across all three tested datasets
- Different retrieval strategies show optimal performance for different personality evaluation tasks (S-S for BFI, C-A for MBTI)
- The framework demonstrates improved human-like qualities in role-playing agents through enhanced emotional consistency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Emotional consistency retrieval improves personality trait fidelity in role-playing agents.
- Mechanism: The framework retrieves memory fragments whose emotional state matches the user query's emotion, then combines this with semantic relevance. This dual-matching ensures responses reflect both character personality and emotional context.
- Core assumption: The emotional vector from GPT-3.5 accurately captures the affective state of both queries and memory fragments.
- Evidence anchors:
  - [abstract] "inspired by the Mood-Dependent Memory theory, which indicates that people recall an event better if they somehow reinstate during recall the original emotion they experienced during learning"
  - [section] "scorek emotional = 1 − C(emotionq, emotionk m), where C is a function of the cosine similarity of two vectors. The smaller the distance scorek emotional is, the more similar the emotions contained in the query and the memory fragment."
  - [corpus] Weak. Corpus shows related emotional RAG papers but no direct evaluation of personality trait fidelity.
- Break condition: If the emotion embedding model misclassifies emotions, the retrieval process will be skewed toward emotionally inconsistent memories, degrading personality alignment.

### Mechanism 2
- Claim: Sequential retrieval strategies (semantic first vs emotional first) can be tuned for different personality evaluation metrics.
- Mechanism: Two retrieval orders are defined: retrieve by semantic similarity then rerank by emotional similarity (S-S), or retrieve by emotional similarity then rerank by semantic similarity (S-E). Different personality evaluation tasks benefit from different orderings.
- Core assumption: Reranking by the secondary criterion preserves the top candidates while improving emotional or semantic consistency.
- Evidence anchors:
  - [section] "Sequential strategy: it contains semantic first strategy (S-S) and emotional first strategy (S-E). In the semantic first strategy, the most similar memory fragments are retrieved based on their semantic scores and then re-ranked according to their emotional scores. Different order is conducted in the emotional first strategy."
  - [section] "Different retrieval strategies are applicable to different evaluations. For example, in the BFI personality evaluation, the sequential strategy (S-S) performs the best, while in the MBTI task, the combination strategy (C-A) exhibits the best performance."
  - [corpus] None directly cited. Assumption: reranking preserves top-10 quality.
- Break condition: If the secondary reranking is too aggressive, it may discard semantically relevant memories and harm task performance.

### Mechanism 3
- Claim: Combining semantic and emotional similarity scores (via addition or multiplication) yields better retrieval than either alone.
- Mechanism: The final similarity score is computed as either a weighted sum (C-A) or product (C-M) of semantic and emotional distances, enabling flexible integration of both factors.
- Core assumption: Both semantic and emotional distances are on comparable scales or properly normalized before combination.
- Evidence anchors:
  - [section] "• Combination strategy: this strategy considers the two similarities at the same time. We adopt two functions, i.e., add function (C-A) and multiple function (C-M), to compute the retrieval scores of memory fragments."
  - [section] "Emotional RAG achieves better results than the RAG method without considering the emotion factor."
  - [corpus] Weak. Related work uses combination strategies but no direct comparison with product vs sum for emotional retrieval.
- Break condition: If one factor dominates the other, the combination strategy becomes equivalent to single-criterion retrieval, negating the benefit.

## Foundational Learning

- Concept: Cosine similarity vs Euclidean distance for vector comparison.
  - Why needed here: The framework uses cosine similarity for emotion vectors and Euclidean distance for semantic vectors. Understanding the difference is crucial for tuning similarity metrics.
  - Quick check question: What is the range of cosine similarity between two vectors, and how does it differ from Euclidean distance in interpreting similarity?

- Concept: Retrieval-augmented generation (RAG) architecture.
  - Why needed here: Emotional RAG is a variant of RAG that integrates emotional similarity into the retrieval stage. Knowing standard RAG flow helps understand where and how the emotional factor is added.
  - Quick check question: In a standard RAG pipeline, at what stage are retrieved documents incorporated into the final generation prompt?

- Concept: MBTI and Big Five personality models.
  - Why needed here: The evaluation metrics rely on MBTI (16 types) and BFI (5 dimensions). Understanding these frameworks is necessary to interpret evaluation results and design appropriate prompts.
  - Quick check question: How many dimensions does the Big Five model use, and what are they commonly abbreviated as?

## Architecture Onboarding

- Component map: Query Encoder → Semantic vector (768-dim) + Emotion vector (8-dim) → Memory Encoder → Per fragment: Semantic vector + Emotion vector → Emotional Retrieval → Combine semantic + emotional scores → Top-10 fragments → Response Generator → Prompt template with query, profile, retrieved memories → LLM output
- Critical path: Query encoding → Memory encoding → Emotional retrieval → Response generation. Any bottleneck in retrieval directly impacts generation quality.
- Design tradeoffs:
  - Emotion model choice: GPT-3.5 is accurate but slow and costly; smaller models trade speed for possible accuracy loss.
  - Retrieval strategy: Combination (C-A, C-M) offers simplicity but may blur semantic/affective signals; sequential (S-S, S-E) allows tuning per task but adds reranking overhead.
  - Memory size: Larger memory units improve coverage but increase retrieval latency.
- Failure signatures:
  - Emotionally inconsistent responses → Check emotion embedding quality or similarity scoring.
  - Stale or irrelevant memories in top-10 → Check semantic embedding freshness or similarity threshold.
  - Personality drift across generations → Verify prompt template includes sufficient character profile context.
- First 3 experiments:
  1. Baseline: Run Ordinary RAG (semantic only) on InCharacter, record BFI/MBT I metrics.
  2. Ablation: Run Emotional RAG with only semantic similarity but keep emotion vector extraction to verify retrieval pipeline.
  3. Strategy sweep: Run Emotional RAG with all four retrieval strategies (C-A, C-M, S-S, S-E) and compare performance on both BFI and MBTI tasks.

## Open Questions the Paper Calls Out
None explicitly identified in the paper.

## Limitations
- Evaluation relies primarily on automated personality metrics without extensive human evaluation of emotional consistency or naturalness
- Emotion encoding step using GPT-3.5 introduces potential bias and cost considerations
- Paper doesn't report retrieval latency or memory storage requirements for the emotional vectors

## Confidence
- **High confidence**: The framework's core retrieval mechanism and its comparison with standard RAG on the three datasets are well-documented and reproducible.
- **Medium confidence**: The superiority of emotional retrieval for personality trait fidelity is demonstrated through automated metrics, but lacks human evaluation validation.
- **Medium confidence**: The effectiveness of different retrieval strategies for different personality tasks is shown, though the underlying reasons for strategy-task alignment could benefit from deeper analysis.

## Next Checks
1. Conduct human evaluation studies to assess whether emotionally consistent responses are perceived as more natural and aligned with character personalities compared to standard RAG.
2. Perform ablation studies removing the emotion encoding step entirely to quantify the marginal benefit of emotional retrieval over semantic-only approaches.
3. Test the framework's robustness across different LLM backends (beyond the three models mentioned) to verify consistent performance improvements.