---
ver: rpa2
title: 'Don''t Stop Me Now: Embedding Based Scheduling for LLMs'
arxiv_id: '2410.01035'
source_url: https://arxiv.org/abs/2410.01035
tags:
- time
- predictions
- prediction
- memory
- scheduling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of efficiently scheduling LLM
  inference requests to reduce response times in interactive AI applications. It proposes
  TRAIL, a method that leverages the autoregressive nature of LLM output generation
  to predict request lengths and implement a memory-aware scheduling policy.
---

# Don't Stop Me Now: Embedding Based Scheduling for LLMs

## Quick Facts
- arXiv ID: 2410.01035
- Source URL: https://arxiv.org/abs/2410.01035
- Authors: Rana Shahout; Eran Malach; Chunwei Liu; Weifan Jiang; Minlan Yu; Michael Mitzenmacher
- Reference count: 40
- Primary result: Embedding-based scheduling achieves 1.66x-2.01x lower mean latency and 1.76x-24.07x lower time-to-first-token

## Executive Summary
This paper addresses the challenge of efficiently scheduling LLM inference requests to reduce response times in interactive AI applications. The authors propose TRAIL, a method that leverages the autoregressive nature of LLM output generation to predict request lengths and implement a memory-aware scheduling policy. By using intermediate Transformer layer embeddings to predict output lengths and combining this with a variant of Shortest Remaining Processing Time (SRPT) with limited preemption, the system achieves significant improvements in latency metrics.

The core innovation lies in using the LLM's own intermediate layer embeddings as a lightweight classifier for predicting remaining sequence length, rather than relying on external models like BERT. This approach, combined with a carefully designed preemption policy that balances responsiveness with overhead, enables TRAIL to achieve 2.66x lower mean absolute error in predictions compared to baseline methods while delivering substantial reductions in both mean latency and time-to-first-token.

## Method Summary
TRAIL uses embeddings from intermediate Transformer layers of the LLM to predict output lengths for scheduling decisions. These embeddings are fed into a lightweight linear classifier to estimate the remaining sequence length for each running request. The system then employs a variant of Shortest Remaining Processing Time (SRPT) with limited preemption, allowing preemption early in request execution when memory consumption is low but restricting it as requests approach completion to optimize resource utilization.

## Key Results
- Achieves 1.66x to 2.01x lower mean latency compared to state-of-the-art serving system
- Achieves 1.76x to 24.07x lower mean time to first token
- Prediction accuracy improved by 2.66x lower mean absolute error compared to BERT predictions

## Why This Works (Mechanism)
The method works by exploiting the autoregressive nature of LLM generation, where the model's intermediate layer embeddings contain information about the remaining output length. By using these embeddings as features for a lightweight linear classifier, TRAIL can make real-time predictions about request completion times without the overhead of external prediction models. The limited preemption strategy is critical because it balances the responsiveness benefits of preemption with the overhead costs, particularly as memory consumption increases near request completion.

## Foundational Learning
- **Autoregressive generation**: LLMs generate tokens sequentially, with each output depending on previous tokens. This property enables length prediction based on intermediate states.
  - Why needed: Enables the fundamental assumption that intermediate states contain information about remaining output length
  - Quick check: Verify that output length correlates with intermediate embedding patterns across diverse prompts

- **Transformer layer embeddings**: Intermediate representations in the transformer architecture capture semantic information about the generation process.
  - Why needed: Provides the signal for predicting remaining sequence length without external models
  - Quick check: Compare prediction accuracy using different layer depths

- **Shortest Remaining Processing Time (SRPT)**: A scheduling policy that prioritizes tasks with the shortest remaining processing time.
  - Why needed: Theoretical foundation for achieving optimal mean response time under certain conditions
  - Quick check: Benchmark against FIFO and SJF scheduling policies

- **Limited preemption**: A strategy that allows preemption only during certain execution phases to balance responsiveness and overhead.
  - Why needed: Prevents excessive context-switching overhead while maintaining responsiveness benefits
  - Quick check: Measure preemption overhead at different memory consumption levels

## Architecture Onboarding

**Component Map**: Request Queue -> Embedding Extractor -> Length Predictor -> Scheduler -> LLM Worker

**Critical Path**: Request arrival → Embedding extraction → Length prediction → Scheduling decision → Token generation

**Design Tradeoffs**: The system trades prediction accuracy for inference overhead by using lightweight linear classifiers instead of complex prediction models. The limited preemption strategy balances responsiveness against context-switching overhead. Memory-aware scheduling prioritizes efficient resource utilization over theoretical optimality.

**Failure Signatures**: Prediction errors lead to suboptimal scheduling decisions and increased latency. Excessive preemption causes overhead that negates responsiveness benefits. Memory constraints may prevent optimal scheduling even with accurate predictions.

**First Experiments**:
1. Compare prediction accuracy across different transformer layer depths
2. Measure latency improvements under varying request arrival rates
3. Evaluate the impact of limited preemption thresholds on overall system performance

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Performance improvements based on Alpaca dataset may not generalize to real-world production workloads
- Limited comparison against specific state-of-the-art serving systems makes independent verification difficult
- The memory-aware scheduling strategy may not be optimal for all workload distributions and request patterns

## Confidence

| Claim Cluster | Confidence |
|---|---|
| Embedding-based length prediction accuracy | Medium |
| Overall latency improvements | Medium |
| Memory-aware scheduling benefits | Medium |

## Next Checks

1. Test TRAIL's performance across multiple diverse datasets including code generation, mathematical problems, and specialized domains to assess generalization of prediction accuracy and latency improvements.

2. Compare TRAIL against multiple state-of-the-art serving systems (e.g., vLLM, FasterTransformer) to validate the claimed performance advantages.

3. Evaluate the system under realistic production conditions with varying request arrival patterns, batch sizes, and hardware configurations to assess robustness and identify potential bottlenecks.