---
ver: rpa2
title: Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker
  Embedding
arxiv_id: '2406.08200'
source_url: https://arxiv.org/abs/2406.08200
tags:
- speaker
- speech
- utterances
- were
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses voice privacy protection by proposing asynchronous
  voice anonymization that obscures speaker attributes from machine recognition while
  preserving human perception. The method employs adversarial perturbation on speaker
  embeddings within a speech generation framework, using YourTTS's voice conversion
  function.
---

# Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker Embedding

## Quick Facts
- arXiv ID: 2406.08200
- Source URL: https://arxiv.org/abs/2406.08200
- Authors: Rui Wang; Liping Chen; Kong AiK Lee; Zhen-Hua Ling
- Reference count: 0
- Primary result: 60.71% success rate in obscuring speaker attributes from machines while preserving human perception

## Executive Summary
This paper addresses voice privacy protection by proposing asynchronous voice anonymization that obscures speaker attributes from machine recognition while preserving human perception. The method employs adversarial perturbation on speaker embeddings within a speech generation framework, using YourTTS's voice conversion function. Speaker attributes are altered through FGSM-based adversarial perturbation while maintaining human perception by controlling perturbation intensity. Experiments on the LibriSpeech dataset show that 60.71% of processed utterances successfully obscured machine recognition of speaker attributes while preserving human perception.

## Method Summary
The method uses Fast Gradient Step Method (FGSM) to generate adversarial perturbations on speaker embeddings extracted by a pre-trained speaker encoder. The perturbed embeddings are then used with YourTTS's voice conversion function to generate anonymized speech. The perturbation intensity is controlled by parameter ε to balance between obscuring machine recognition and preserving human perception. The system employs speaker disentanglement to separate speaker identity from content and prosody, allowing independent manipulation of speaker attributes.

## Key Results
- 60.71% of processed utterances successfully obscured machine recognition of speaker attributes while preserving human perception
- Protected utterances achieved higher equal error rates (EERs) in automatic speaker verification compared to regenerated utterances
- Subjective listening tests showed that regenerated utterances had significantly lower speaker similarity compared to protected utterances

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial perturbation on speaker embeddings disrupts machine speaker recognition while preserving human perception.
- Mechanism: FGSM algorithm generates small perturbations that maximize speaker recognition loss while keeping perturbations small enough to be imperceptible to humans.
- Core assumption: Speaker embeddings extracted by neural networks are differentiable and can be manipulated via gradient-based methods without affecting human perception.
- Evidence anchors: [abstract] "The speaker attributes are altered through adversarial perturbation applied on the speaker embedding, while human perception is preserved by controlling the intensity of perturbation."

### Mechanism 2
- Claim: Speaker disentanglement in YourTTS allows independent manipulation of speaker identity while preserving content and prosody.
- Mechanism: YourTTS separates content, speaker, and prosody representations during voice conversion, enabling speaker attribute modification without affecting other speech qualities.
- Core assumption: The disentanglement architecture successfully isolates speaker attributes from other speech components.
- Evidence anchors: [abstract] "a speech generation framework incorporating a speaker disentanglement mechanism is employed to generate the anonymized speech."

### Mechanism 3
- Claim: Asynchronous anonymization achieves different objectives for machine vs human perception through targeted perturbation.
- Mechanism: The system creates a mismatch where machine algorithms detect changed speaker identity while humans still perceive original speaker characteristics.
- Core assumption: Machine recognition systems and human perception rely on different features or representations of speaker identity.
- Evidence anchors: [abstract] "focus on altering the voice attributes against machine recognition while retaining human perception" and "referred to this as the asynchronous voice anonymization."

## Foundational Learning

- Concept: Adversarial machine learning and FGSM algorithm
  - Why needed here: The core technique relies on generating adversarial examples through gradient-based perturbation to fool speaker recognition systems.
  - Quick check question: What is the mathematical formula for FGSM perturbation and how does the ε parameter control perturbation intensity?

- Concept: Speaker embedding extraction and modeling
  - Why needed here: The method manipulates speaker embeddings as the target for adversarial perturbation, requiring understanding of how speaker identity is represented in neural networks.
  - Quick check question: How does the speaker encoder in YourTTS extract and represent speaker attributes as fixed-length vectors from variable-length utterances?

- Concept: Voice conversion and disentanglement architectures
  - Why needed here: YourTTS's ability to separate speaker identity from content and prosody is fundamental to achieving asynchronous anonymization.
  - Quick check question: What are the key components of the disentanglement process in YourTTS and how do they isolate different speech attributes?

## Architecture Onboarding

- Component map:
  Speaker encoder (H/ASP model) -> Content disentanglement module -> FGSM perturbation generator -> YourTTS voice conversion pipeline -> ASR and ASV evaluation modules

- Critical path:
  1. Extract speaker embedding from original speech
  2. Apply FGSM to generate adversarial perturbation
  3. Modify speaker embedding with perturbation
  4. Pass modified embedding through YourTTS VC pipeline
  5. Evaluate against ASV and ASR systems

- Design tradeoffs:
  - Perturbation intensity vs human perception preservation
  - Speaker encoder specificity (white-box vs black-box scenarios)
  - Trade-off between anonymization success rate and speech quality
  - Computational cost of FGSM generation vs real-time requirements

- Failure signatures:
  - High WER in ASR evaluations indicates content corruption
  - Low EER in ASV evaluations indicates insufficient anonymization
  - Human listeners detecting speaker changes indicates perturbation excess
  - Training instability in FGSM suggests learning rate or ε parameter issues

- First 3 experiments:
  1. Baseline evaluation: Run original speech through ASV and ASR systems to establish reference metrics
  2. Perturbation sensitivity: Vary ε parameter systematically and measure impact on EER and WER to find optimal perturbation intensity
  3. Speaker encoder transfer: Test anonymization success when using different speaker encoders than those seen during FGSM training to assess robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical upper limit of speaker identity obfuscation success rate achievable through adversarial perturbation on speaker embeddings while maintaining human perception?
- Basis in paper: [explicit] The paper reports 60.71% success rate in preserving human perception while obscuring machine recognition, but states "our future research will focus on improving the modification of speaker embedding to conduct asynchronous voice anonymization on all utterances"
- Why unresolved: The paper only demonstrates preliminary results and explicitly states this as future work without providing analysis of theoretical limits or technical barriers preventing 100% success

### Open Question 2
- Question: How does the proposed asynchronous voice anonymization method perform when the original speaker is not part of the speaker encoder's training set?
- Basis in paper: [inferred] The paper specifically addresses closed-set speakers and requires the original speaker to be recognizable by the speaker model for the FGSM algorithm to work, indicating potential limitations for open-set scenarios
- Why unresolved: The experiments only evaluate closed-set scenarios, and the paper explicitly mentions this limitation without exploring open-set generalization

### Open Question 3
- Question: What is the impact of asynchronous voice anonymization on downstream speech processing tasks beyond ASR, such as speaker diarization or emotion recognition?
- Basis in paper: [inferred] The paper only evaluates ASV (automatic speaker verification) and ASR (automatic speech recognition) performance, suggesting that other speech processing applications may be affected by the perturbation
- Why unresolved: The authors do not explore the broader ecosystem of speech processing tasks that might be affected by adversarial perturbation of speaker embeddings

## Limitations
- Limited human evaluation with only three listeners, insufficient for robust human perception claims
- White-box assumption for speaker encoder limits real-world applicability where perfect knowledge of target systems is unavailable
- Evaluation focuses primarily on speaker verification without testing against other machine learning models that might use different feature representations

## Confidence
- **High confidence**: The core mechanism of adversarial perturbation on speaker embeddings disrupting machine recognition (Mechanism 1) is well-established in adversarial machine learning literature and the implementation details are clearly specified.
- **Medium confidence**: The speaker disentanglement claims (Mechanism 2) rely on YourTTS's documented capabilities but lack direct empirical validation within this work showing successful isolation of speaker attributes from content and prosody.
- **Medium confidence**: The asynchronous anonymization concept (Mechanism 3) showing differential effects on machine vs human perception is supported by the experimental results, but the small sample size for human evaluation and limited diversity of evaluation metrics reduce confidence.

## Next Checks
1. **Perturbation sensitivity analysis**: Systematically vary the ε parameter from 0.001 to 0.1 in logarithmic steps and measure the relationship between perturbation intensity, EER performance, WER degradation, and human perception scores to establish optimal operating points.

2. **Black-box robustness testing**: Evaluate the anonymization effectiveness against speaker verification systems that use different architectures than the H/ASP encoder used for FGSM generation to assess transferability and real-world applicability.

3. **Extended human evaluation**: Conduct a comprehensive listening test with at least 20 participants rating speaker similarity on a 5-point scale for both protected and regenerated utterances, with proper statistical analysis of inter-rater reliability and significance testing.