---
ver: rpa2
title: 'Fast and Slow Generating: An Empirical Study on Large and Small Language Models
  Collaborative Decoding'
arxiv_id: '2406.12295'
source_url: https://arxiv.org/abs/2406.12295
tags:
- decoding
- large
- language
- collaboration
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates collaborative decoding between large and\
  \ small language models (LLMs and SLMs) through a unified \"Fast and Slow Generating\"\
  \ (FS-GEN) framework inspired by dual-process cognitive theory. The study analyzes\
  \ three collaborative methods\u2014speculative decoding, contrastive decoding, and\
  \ proxy tuning\u2014to understand when and how System 1 (fast SLM) and System 2\
  \ (slow LLM) should collaborate during text generation."
---

# Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding

## Quick Facts
- arXiv ID: 2406.12295
- Source URL: https://arxiv.org/abs/2406.12295
- Reference count: 40
- Only 20% of tokens require LLM-SLM collaboration, following a scaling law based on parameter ratios

## Executive Summary
This paper investigates collaborative decoding between large and small language models (LLMs and SLMs) through a unified "Fast and Slow Generating" (FS-GEN) framework inspired by dual-process cognitive theory. The study analyzes three collaborative methods—speculative decoding, contrastive decoding, and proxy tuning—to understand when and how System 1 (fast SLM) and System 2 (slow LLM) should collaborate during text generation. Empirical results across multiple tasks show that only 20% of tokens require collaboration, following a scaling law related to parameter ratios. Mismatches and interventions occur primarily at the beginning of generation sequences and correlate strongly with token uncertainty in SLMs.

## Method Summary
The study uses Qwen and Pythia model series ranging from 0.5B to 72B parameters across three collaborative decoding methods: speculative decoding, contrastive decoding, and proxy tuning. Experiments employ greedy decoding with few-shot in-context learning (5-shots for MMLU, 10-shots for MBPP, 8-shots for GSM8k) on MMLU-STEM, GSM8k, and MBPP datasets. Collaboration frequency is calculated as the ratio of tokens requiring LLM intervention to total generated tokens, with analysis of scaling laws relating collaboration frequency to parameter ratios through the formula CoF lower = γ · R-α + β.

## Key Results
- Only 20% of generated tokens require collaboration between LLMs and SLMs
- Collaboration frequency follows a scaling law inversely proportional to parameter ratios
- LLM interventions are most critical at the beginning of generation sequences
- Token uncertainty in SLMs is the primary differentiator from LLMs, driving intervention needs

## Why This Works (Mechanism)

### Mechanism 1
Collaborative decoding follows a predictable scaling law based on parameter ratios. The frequency of required interventions is inversely proportional to the parameter ratio raised to a specific power. This assumes token uncertainty distributions scale predictably with model size. Evidence shows collaboration frequency decreases as the parameter ratio increases, but the exact coefficients γ, α, and β remain unspecified.

### Mechanism 2
Token uncertainty in SLMs is the primary differentiator from LLMs. High uncertainty tokens require LLM intervention because SLMs lack confidence in these predictions. This assumes token uncertainty correlates with prediction quality. Analysis shows mismatches correlate strongly with SLM token uncertainty, though causation is not proven.

### Mechanism 3
Collaboration is most critical at the beginning of generation sequences. Initial tokens have higher uncertainty and fewer conditioning tokens, making them more error-prone. This assumes early generation steps have higher stakes due to accumulated errors. Position analysis confirms more collaborations occur early in sequences, but the underlying reason remains unclear.

## Foundational Learning

- **Concept: Dual-process cognitive theory**
  - Why needed here: Provides theoretical framework for categorizing LLMs as System 2 (slow, deliberate) and SLMs as System 1 (fast, intuitive)
  - Quick check question: How does the 95:5 human intuition ratio compare to the observed 80:20 model collaboration ratio?

- **Concept: Token uncertainty quantification**
  - Why needed here: Enables prediction of when LLM intervention is necessary during collaborative decoding
  - Quick check question: What metric would you use to measure token uncertainty in a language model?

- **Concept: Scaling laws in neural networks**
  - Why needed here: Underlies the parameter-ratio-based prediction of collaboration frequency
  - Quick check question: How does the scaling law relationship between model size and performance inform collaborative decoding?

## Architecture Onboarding

- **Component map:** Input → SLM draft → Uncertainty check → LLM intervention (if needed) → Output
- **Critical path:** User input flows through fast SLM generation, with uncertainty-based routing to slow LLM when needed
- **Design tradeoffs:** Collaboration frequency vs. latency (more frequent checks improve quality but increase latency), uncertainty threshold selection (higher thresholds reduce LLM calls but may miss errors), model size ratios (optimal collaboration depends on relative capabilities)
- **Failure signatures:** Too few collaborations (critical errors missed), too many collaborations (defeats purpose of having System 1), position mismatch (interventions too late to be effective)
- **First 3 experiments:**
  1. Test collaboration frequency across different parameter ratios using oracle decoding
  2. Validate uncertainty-based routing by comparing with ground truth intervention points
  3. Measure performance impact of shifting collaboration from early to late sequence positions

## Open Questions the Paper Calls Out

1. What is the precise mathematical relationship between model parameter ratios and the scaling exponent α in the collaboration frequency formula CoF lower = γ · R−α + β?

2. How does collaboration frequency change when using different decoding strategies (e.g., beam search, nucleus sampling) compared to greedy decoding?

3. What is the optimal threshold for token uncertainty that determines when System 2 (LLM) intervention is necessary in speculative decoding?

4. How do different model architectures (e.g., transformer-based, state space models, hybrid architectures) affect collaboration dynamics between System 1 and System 2?

5. What is the trade-off between collaboration frequency and inference cost, and how can we optimize collaboration to balance performance and resource efficiency?

## Limitations

- Scaling law relationship lacks theoretical grounding and is derived from limited model combinations
- Focus on Qwen and Pythia models leaves generalizability to other architectures uncertain
- Token uncertainty as primary differentiator is a hypothesis rather than proven mechanism
- "Beginning of sequence" hypothesis lacks explanation for why this pattern exists

## Confidence

**High Confidence**: The empirical observation that only ~20% of tokens require collaboration across tested model combinations. The experimental setup using Qwen and Pythia models with MMLU-STEM, GSM8k, and MBPP datasets is clearly specified, and the collaboration frequency calculations are reproducible.

**Medium Confidence**: The inverse relationship between parameter ratios and collaboration frequency follows a scaling law. While the empirical relationship is observed, the theoretical foundation and generalizability beyond tested models remain uncertain. The specific form of the power law and its coefficients need further validation.

**Low Confidence**: Token uncertainty is the fundamental differentiator between LLMs and SLMs. The study demonstrates correlation but cannot rule out alternative explanations for when and why LLM intervention is necessary. The assumption that uncertainty directly drives collaboration needs is plausible but unproven.

## Next Checks

1. **Cross-architecture validation**: Test the scaling law relationship with model combinations outside Qwen and Pythia families (e.g., LLaMA, Mistral) to verify whether the parameter-ratio-based collaboration frequency pattern generalizes across different training methodologies and architectures.

2. **Controlled uncertainty experiments**: Create synthetic tokens with varying uncertainty levels in SLMs and measure whether LLM intervention rates match predictions. This would directly test whether uncertainty is the primary driver of collaboration needs rather than confounding factors.

3. **Context sensitivity analysis**: Systematically vary the amount of context provided to SLMs during generation and measure how this affects collaboration frequency across sequence positions. This would clarify whether early-sequence collaborations stem from context poverty or other factors.