---
ver: rpa2
title: 'The ShareLM Collection and Plugin: Contributing Human-Model Chats for the
  Benefit of the Community'
arxiv_id: '2408.08291'
source_url: https://arxiv.org/abs/2408.08291
tags:
- conversations
- plugin
- user
- conversation
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the ShareLM plugin and collection, aiming
  to democratize access to human-model conversations for open-source and research
  communities. While commercial models collect user data through APIs, the open-source
  community lacks similar resources.
---

# The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community

## Quick Facts
- arXiv ID: 2408.08291
- Source URL: https://arxiv.org/abs/2408.08291
- Reference count: 8
- This paper introduces the ShareLM plugin and collection, aiming to democratize access to human-model conversations for open-source and research communities.

## Executive Summary
The ShareLM plugin and collection address a critical gap in the AI community by providing open access to human-model conversations, which are typically collected only by commercial companies through their APIs. The Chrome extension enables users to voluntarily contribute conversations from various platforms, supporting multiple models and interfaces while maintaining user control and privacy. With over 2.3 million conversations from 40+ models already collected, the project demonstrates both technical feasibility and community interest in open, collaborative datasets for AI research and development.

## Method Summary
The ShareLM plugin is a Chrome extension that captures conversations from supported chat interfaces through periodic DOM polling and storage in IndexedDB. After a 24-hour delay allowing users to review and delete conversations locally, the plugin uploads data to a server via REST API, where it undergoes anonymization before being stored in PostgreSQL and released as a HuggingFace dataset. The system supports multiple platforms including Gradio, ChatUI, and ChatGPT, and allows users to rate conversations at both conversation and response levels. The collection currently contains over 2.3 million conversations and continues to grow through community contributions.

## Key Results
- User study with 10 participants showed high satisfaction: 4.8/5 for installation, 4.7/5 for usability, and 4.7/5 for UI design
- Plugin successfully captures conversations from 40+ models across multiple platforms including Gradio, ChatUI, and ChatGPT
- Dataset contains over 2.3 million conversations with metadata including timestamps, model names, and user ratings
- Privacy-preserving design with local storage, 24-hour review window, and server-side anonymization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The ShareLM plugin enables scalable collection of human-model conversations by acting as a transparent mediator between users and multiple chat platforms.
- Mechanism: The plugin automatically detects supported chat interfaces (e.g., Gradio, ChatUI, ChatGPT), captures user and model responses periodically, and stores them locally before delayed upload. This design lowers user friction while maintaining control.
- Core assumption: Users are willing to share conversations when given transparency, delayed upload, and deletion options.
- Evidence anchors:
  - [abstract] states the plugin "allows users to share conversations from most platforms" and provides "delayed upload that allows users to go over their conversations from the last 24 hours and remove those that they prefer to keep private."
  - [section 3.2] describes how "conversations in the local database are posted to the server via a REST API, accompanied by the user ID and user/conversation metadata if available" after a 24-hour delay.
- Break condition: If users perceive the recording banner or delayed upload as intrusive, adoption drops; if anonymization fails, privacy concerns increase.

### Mechanism 2
- Claim: Delayed upload combined with local storage empowers users with ownership and control over their data.
- Mechanism: Conversations are stored locally for 24 hours, during which users can review, rate, or delete them via the plugin popup before any upload occurs. This ensures no conversation leaves the user's device without explicit consent.
- Core assumption: Users trust a system that gives them time and tools to manage their data before it is shared.
- Evidence anchors:
  - [abstract] highlights that "the plugin allows the user to rate their conversations, both at the conversation and the response levels, and delete conversations they prefer to keep private before they ever leave the user's local storage."
  - [section 4.3] explains the "saved conversations table" where users can "click on the red X button will delete the conversation from the local database, without it ever leaving the user storage."
- Break condition: If the 24-hour window is too short for users to review, or if the deletion interface is cumbersome, users may not exercise control, reducing trust.

### Mechanism 3
- Claim: Anonymization at the server level adds a privacy layer without compromising data utility for research.
- Mechanism: After conversations are uploaded, the server runs an anonymization script to remove names, addresses, phone numbers, etc., providing a second line of defense beyond user discretion.
- Core assumption: Automated anonymization can sufficiently protect privacy while retaining enough context for model training and research.
- Evidence anchors:
  - [section 3.2] states "the server runs an anonymization script on the conversation's content, to remove names, addresses, phone numbers, and more."
  - [section 4.2] warns that "as part of the plugin terms of use, we ask users to avoid sharing conversations with such identifying details" and that "no text shared should be assumed fully anonymous."
- Break condition: If anonymization is imperfect or reversible, privacy risks increase; if over-aggressive, data utility for nuanced research decreases.

## Foundational Learning

- Concept: Web extension development and DOM manipulation
  - Why needed here: The plugin must detect chat interfaces and extract conversation elements from web pages dynamically.
  - Quick check question: How would you programmatically identify chat bubbles in a page's DOM structure?

- Concept: Data anonymization techniques
  - Why needed here: Protecting user privacy is critical; anonymization scripts must remove PII without losing conversational context.
  - Quick check question: What are common pitfalls when using regex-based PII removal on natural language text?

- Concept: REST API design and PostgreSQL integration
  - Why needed here: The plugin uploads data to a server; the server must store, anonymize, and manage conversations efficiently.
  - Quick check question: What fields would you include in a PostgreSQL schema to support the ShareLM conversation format?

## Architecture Onboarding

- Component map: Chrome extension (content script + popup script + background script) -> Local IndexedDB -> REST API endpoint -> PostgreSQL database -> Anonymization service -> HuggingFace dataset

- Critical path: 1. User interacts with supported chat interface 2. Content script detects and records conversation turns 3. Background script stores locally and schedules upload 4. After 24h, data is POSTed to server 5. Server anonymizes and inserts into PostgreSQL 6. Periodic dataset release to HuggingFace

- Design tradeoffs:
  - Local vs. immediate upload: Local storage maximizes user control but delays data availability.
  - Broad platform support vs. reliability: Supporting many interfaces increases reach but may introduce detection bugs.
  - Automated anonymization vs. manual review: Automation scales but may miss edge cases; manual review is accurate but slow.

- Failure signatures:
  - Plugin not recording: Check if recording banner is active and if content script matches DOM selectors.
  - Conversations not uploading: Verify 24h delay logic, network connectivity, and server API status.
  - Anonymization errors: Inspect server logs for regex failures or malformed data.

- First 3 experiments:
  1. Install plugin, open a supported demo (e.g., ChatUI), conduct a short conversation, verify it appears in the popup after 24h.
  2. Use the popup to delete a conversation before upload and confirm it does not appear in the dataset.
  3. Check server logs to confirm anonymization script runs and data is inserted into PostgreSQL correctly.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ShareLM plugin be extended to support additional chatbot interfaces beyond the currently supported platforms (Gradio, ChatUI, and ChatGPT)?
- Basis in paper: [explicit] The paper mentions that "adding support to new web platforms is easy" and notes that external contributors are planning to extend support to other interfaces.
- Why unresolved: While the paper indicates ease of extension, it does not provide specific technical details or guidelines on how to implement support for new platforms.
- What evidence would resolve it: A detailed technical documentation or case studies demonstrating the process of integrating new chatbot interfaces with the ShareLM plugin.

### Open Question 2
- Question: What are the long-term effects of delayed data uploads on the quality and relevance of the ShareLM dataset?
- Basis in paper: [explicit] The plugin uses a 24-hour delay for uploading conversations, allowing users to review and delete conversations before they are shared.
- Why unresolved: The paper does not explore how this delay might impact the dataset's comprehensiveness or its ability to capture real-time trends and interactions.
- What evidence would resolve it: Comparative analysis of datasets with and without delayed uploads, focusing on differences in data quality, user engagement, and trend representation.

### Open Question 3
- Question: How can the ShareLM plugin ensure user privacy while maintaining data utility for research purposes?
- Basis in paper: [explicit] The plugin includes anonymization features and terms of use to protect user privacy, but acknowledges that no text shared should be assumed fully anonymous.
- Why unresolved: The paper does not provide a detailed evaluation of the anonymization process's effectiveness or discuss potential trade-offs between privacy and data utility.
- What evidence would resolve it: Empirical studies assessing the anonymization script's performance and user feedback on privacy concerns, alongside analyses of how anonymization affects data utility for research.

## Limitations
- Small user study sample size (n=10) limits generalizability of usability findings
- Privacy claims rely on automated anonymization without empirical validation of effectiveness
- Plugin detection mechanism may break with DOM changes, requiring ongoing maintenance
- Dataset composition and potential biases are not analyzed in depth

## Confidence
**High Confidence**: The core mechanism of the ShareLM plugin - a Chrome extension that captures, stores locally, and uploads human-model conversations with delayed review - is well-specified and technically sound based on the described architecture and user study feedback.

**Medium Confidence**: The claims about user control and privacy protection are plausible given the described features (delayed upload, local storage, anonymization), but lack empirical validation data on actual user behavior and anonymization effectiveness.

**Low Confidence**: The generalizability of the user study findings to broader populations and the long-term sustainability of the platform given potential interface changes and user adoption challenges are uncertain.

## Next Checks
1. **Anonymization Effectiveness Audit**: Conduct a blind test where an independent reviewer attempts to identify PII in a sample of conversations after anonymization, measuring false negatives and false positives to validate the claimed privacy protection.

2. **User Behavior Analysis**: Deploy the plugin to a larger sample (n=100+) for 30 days and analyze actual deletion rates, review patterns, and whether the 24-hour window proves sufficient for meaningful user control.

3. **Platform Compatibility Stress Test**: Test the plugin's conversation detection across 10+ different chat interface versions (including older versions) to measure detection accuracy and identify maintenance requirements for long-term viability.