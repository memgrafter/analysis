---
ver: rpa2
title: Skill Learning Using Process Mining for Large Language Model Plan Generation
arxiv_id: '2410.12870'
source_url: https://arxiv.org/abs/2410.12870
tags:
- process
- skill
- plan
- conformance
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving skill learning
  and retrieval in large language models (LLMs) for plan generation. The proposed
  method integrates process mining techniques to discover structured control flow
  models from flat action sequences, enabling skill storage and retrieval through
  conformance checking.
---

# Skill Learning Using Process Mining for Large Language Model Plan Generation

## Quick Facts
- arXiv ID: 2410.12870
- Source URL: https://arxiv.org/abs/2410.12870
- Reference count: 29
- Key outcome: Integrating process mining into LLM planning enhances skill learning and retrieval through structured control flow models and conformance checking

## Executive Summary
This paper addresses the challenge of improving skill learning and retrieval in large language models (LLMs) for plan generation by integrating process mining techniques. The proposed method discovers structured control flow models from flat action sequences generated by LLMs, enabling skill storage and retrieval through conformance checking. The approach combines text semantic similarity with structural alignment to achieve high retrieval accuracy while maintaining interpretability. Experimental results on synthetic datasets demonstrate the feasibility of the skill learning method and show that the hybrid retrieval approach nearly matches the accuracy of the best embedding models while providing enhanced interpretability.

## Method Summary
The method transforms LLM-generated action sequences into structured process models using the Inductive Miner algorithm for skill acquisition. These process models are stored in a skill library and retrieved through a two-stage approach combining text semantic similarity (using embeddings like ada-002) with conformance checking (measuring alignment fitness). The conformance checking compares the structural control flow of candidate skills against generated plans, providing interpretability beyond text-based similarity. The skill retrieval pipeline first filters candidates using fast text embedding similarity, then re-ranks using computationally expensive conformance checking to balance efficiency with accuracy.

## Key Results
- Skill learning method shows high conformance scores between generated traces and ground-truth process models, demonstrating feasibility
- Two-stage retrieval combining text similarity with conformance checking achieves strong performance, nearly matching best embedding model accuracy
- The approach offers improved interpretability compared to pure text-based retrieval while maintaining competitive retrieval metrics (F1-score, MRR)

## Why This Works (Mechanism)

### Mechanism 1
Process mining enables structured control flow extraction from flat LLM-generated action sequences. The Inductive Miner algorithm discovers process models that capture sequential and parallel relations between actions, transforming unstructured traces into structured skills. Core assumption: LLM-generated traces contain sufficient ordering information to infer meaningful process models. Break condition: If traces are too noisy to reveal consistent patterns, process discovery will fail.

### Mechanism 2
Conformance checking provides interpretable skill retrieval by comparing structural alignment rather than text similarity. Alignment fitness measures how well a candidate skill's process flow matches the structural control flow of a generated plan, enabling retrieval based on logical compatibility. Core assumption: Structural alignment is a better indicator of skill relevance than semantic text similarity alone. Break condition: If process models are too simple, conformance checking won't provide meaningful discrimination.

### Mechanism 3
Two-stage retrieval combining semantic similarity with conformance checking achieves better accuracy and efficiency than either method alone. First stage uses fast text embedding similarity to filter candidates, second stage uses expensive conformance checking to re-rank based on structural alignment. Core assumption: Most irrelevant skills can be filtered by text similarity, leaving a small set for expensive structural checking. Break condition: If text similarity fails to filter effectively, the hybrid approach won't provide efficiency benefits.

## Foundational Learning

- Concept: Process mining and conformance checking
  - Why needed here: The entire approach relies on extracting structured process models from traces and comparing them using conformance checking metrics
  - Quick check question: What's the difference between replay fitness and alignment fitness in conformance checking?

- Concept: Petri nets and process model representations
  - Why needed here: Process models are converted to Petri nets for conformance checking calculations
  - Quick check question: How do you convert a DAG process model to a Petri net representation?

- Concept: Vector embeddings and similarity metrics
  - Why needed here: The two-stage retrieval method uses text embeddings for initial candidate filtering
  - Quick check question: What's the mathematical definition of cosine similarity used for comparing embeddings?

## Architecture Onboarding

- Component map: LLM plan generator → Process discovery (Inductive Miner) → Skill library (process models) → Retrieval pipeline (text embedding + conformance checking) → Final skill selection
- Critical path: Plan generation → Skill learning (discovery) → Skill storage → Retrieval (embedding similarity + conformance) → Skill application
- Design tradeoffs: Conformance checking provides interpretability but is computationally expensive vs text similarity which is fast but less interpretable
- Failure signatures: Low replay/alignment fitness scores indicate poor skill discovery; high text similarity but low conformance indicates text-based retrieval limitations
- First 3 experiments:
  1. Run process discovery on ProcessTBench traces and measure replay/alignment fitness to verify skill learning feasibility
  2. Implement pure conformance checking retrieval and measure accuracy vs text-only baseline
  3. Implement hybrid retrieval and test different k values for candidate filtering to optimize accuracy/efficiency tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of process mining-based skill learning scale with increasing dataset sizes, particularly when moving from synthetic datasets like ProcessTBench to real-world process mining datasets with orders of magnitude more cases? The current experiments are limited to a synthetic dataset with only ~2000 cases total, which is orders of magnitude smaller than real-world process mining datasets containing hundreds of thousands of cases.

### Open Question 2
What is the optimal balance between planner accuracy and conformance checking thresholds that maximizes the combined performance of ada-002 and conformance checking in skill retrieval? The sensitivity analysis shows that with a planner accuracy threshold of 0.7 or higher, the combined model outperforms ada-002 alone, but the optimal threshold is not determined.

### Open Question 3
How would the integration of newer embedding models (25% better than ada-002) and more advanced LLMs affect the relative performance advantage of conformance checking-based skill retrieval? The authors note that both technology domains have advanced substantially since the experiments were conducted, suggesting these advancements could significantly impact results.

## Limitations
- Results are based on synthetic datasets (TaskBench, ProcessTBench) rather than real-world process mining data
- The interpretability claims lack quantitative user studies or systematic comparison with text-based alternatives
- Computational efficiency claims are based on theoretical complexity rather than measured runtime performance

## Confidence

- **High confidence**: The feasibility of skill learning through process discovery (supported by conformance metrics showing good alignment between generated traces and ground-truth models)
- **Medium confidence**: The effectiveness of the two-stage retrieval method (supported by F1-score and MRR results showing competitive performance to best embedding models)
- **Low confidence**: Claims about interpretability improvements from structural alignment (lacking quantitative user studies or systematic comparison)

## Next Checks

1. Measure actual wall-clock time for pure conformance checking vs hybrid retrieval across varying skill library sizes to verify claimed efficiency gains
2. Conduct user experiments comparing how well humans can understand and explain skill retrieval results from conformance-based vs text-similarity approaches
3. Apply the skill learning method to a non-synthetic domain (e.g., API call sequences or business process logs) and evaluate whether process discovery still produces meaningful control flow models