---
ver: rpa2
title: Predicting Lung Cancer Patient Prognosis with Large Language Models
arxiv_id: '2408.07971'
source_url: https://arxiv.org/abs/2408.07971
tags:
- lymph
- prediction
- node
- survival
- cancer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated large language models (LLMs) for predicting
  lung cancer patient prognosis, focusing on survival and post-operative complications.
  GPT-4o mini and GPT-3.5 were tested using zero-shot prompts without patient data,
  and their performance was compared to logistic regression baselines.
---

# Predicting Lung Cancer Patient Prognosis with Large Language Models

## Quick Facts
- arXiv ID: 2408.07971
- Source URL: https://arxiv.org/abs/2408.07971
- Reference count: 40
- Large language models (LLMs) can predict lung cancer patient survival and post-operative complications with competitive accuracy compared to logistic regression baselines, without requiring patient data.

## Executive Summary
This study evaluates the effectiveness of large language models for predicting lung cancer patient prognosis, specifically survival rates and post-operative complications. The research compares GPT-4o mini and GPT-3.5 using zero-shot prompts against logistic regression baselines, demonstrating that LLMs can achieve competitive or superior performance despite not using retrospective patient data. GPT-4o mini showed improvements of 1.4% in AUROC and 2.5% in AUPRC for survival prediction, with even larger gains for complication prediction.

## Method Summary
The study employed zero-shot prompting with GPT-4o mini and GPT-3.5 to predict lung cancer outcomes, using carefully designed prompts with Role, Task, Patient data, and Instruction elements. Chain-of-thought reasoning was incorporated to guide systematic clinical reasoning, and responses were formatted in JSON for structured evaluation. The approach was tested on two datasets: one with 1,277 patients for survival prediction and another with 593 patients for post-operative complication prediction. Logistic regression models served as baselines, and performance was evaluated using AUROC and AUPRC metrics through cross-validation.

## Key Results
- GPT-4o mini achieved 1.4% AUROC improvement and 2.5% AUPRC improvement over logistic regression for survival prediction
- GPT-4o mini showed 3.1% average AUROC improvement for complication prediction tasks
- LLMs successfully predicted outcomes without requiring retrospective patient data, relying instead on pre-trained medical knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs achieve competitive prognosis prediction without requiring retrospective patient data.
- Mechanism: LLMs leverage extensive medical knowledge learned during pre-training to infer outcomes directly from patient clinical data provided in prompts.
- Core assumption: The medical knowledge embedded in LLMs is sufficiently accurate and relevant to lung cancer prognosis tasks.
- Evidence anchors:
  - [abstract] "LLMs can achieve competitive, and in some tasks superior, performance in lung cancer prognosis prediction compared to data-driven logistic regression models despite not using additional patient data."
  - [section] "Instead, they leverage the extensive knowledge acquired from vast corpora to estimate the likelihood of outcomes based solely on the data of the current patient."
- Break Condition: The LLM's pre-trained medical knowledge is outdated, incomplete, or misaligned with current clinical guidelines for lung cancer prognosis.

### Mechanism 2
- Claim: Chain-of-thought prompting improves LLM prediction accuracy for clinical tasks.
- Mechanism: The instruction to "Think step by step" encourages the LLM to reason through clinical factors systematically before generating a prediction.
- Core assumption: LLMs can effectively decompose complex clinical reasoning tasks when guided by explicit reasoning instructions.
- Evidence anchors:
  - [section] "In this element, we instructed the LLMs to use the Chain-of-Thought strategy to reason step by step in estimating likelihoods."
  - [section] "These results indicate that LLMs can effectively predict lung cancer outcomes without relying on extra retrospective patient data."
- Break Condition: The LLM's reasoning process is superficial or biased, leading to incorrect conclusions despite step-by-step prompting.

### Mechanism 3
- Claim: JSON-formatted responses enable structured evaluation and integration of LLM predictions.
- Mechanism: The instruction to provide responses in JSON format with specific key-value pairs standardizes output for consistent comparison with baseline models.
- Core assumption: LLMs can reliably follow formatting instructions when generating predictions.
- Evidence anchors:
  - [section] "the LLMs were directed to provide their responses in JSON format with key-value pairs, such as 'Step by step explanation':'<string>', 'Answer':'<float>'."
  - [section] "For survival prediction, we established 5 prediction tasks, i.e., 1-year, 2-year, 3-year, 4-year, and 5-year survival predictions."
- Break Condition: The LLM fails to adhere to the specified JSON format, causing parsing errors or evaluation inconsistencies.

## Foundational Learning

- Concept: Zero-shot prompting in LLMs
  - Why needed here: The study uses zero-shot prompts without patient data, relying on the LLM's pre-existing knowledge.
  - Quick check question: What distinguishes zero-shot prompting from few-shot prompting in LLM applications?

- Concept: Area Under the ROC Curve (AUROC) and Precision-Recall Curve (AUPRC)
  - Why needed here: These metrics are used to evaluate the predictive performance of both LLM and logistic regression models.
  - Quick check question: How does AUROC differ from AUPRC in evaluating model performance, particularly for imbalanced datasets?

- Concept: Chain-of-thought prompting
  - Why needed here: The study explicitly instructs LLMs to use this reasoning strategy for improved prediction accuracy.
  - Quick check question: What is the primary purpose of chain-of-thought prompting in LLM applications?

## Architecture Onboarding

- Component map: Prompt templates (Role, Task, Patient data, Instruction) -> LLM models (GPT-4o mini, GPT-3.5) -> JSON parsing -> Performance evaluation (AUROC, AUPRC) -> Comparison with logistic regression baselines
- Critical path: Prompt generation → LLM prediction → JSON parsing → Performance evaluation → Comparison with baselines
- Design tradeoffs: Using zero-shot prompting avoids data dependency but relies heavily on the quality of pre-trained knowledge; logistic regression baselines provide interpretable comparisons but may underperform on complex nonlinear relationships
- Failure signatures: Inconsistent JSON formatting, model performance below baseline, inability to handle specific clinical scenarios, or errors in patient data interpretation
- First 3 experiments:
  1. Test LLM response consistency with varied patient data while keeping clinical factors constant.
  2. Compare LLM predictions against logistic regression on a held-out validation set for a single prediction task.
  3. Evaluate the impact of removing chain-of-thought instructions on prediction accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs generalize their prognostic prediction capabilities across different cancer types beyond lung cancer?
- Basis in paper: [inferred] The authors note that "The medical knowledge embedded in LLMs may vary across different diseases and clinical problems, which could affect their predictive performance."
- Why unresolved: The study only tested LLMs on lung cancer prognosis, so their performance on other cancer types remains unknown.
- What evidence would resolve it: Testing the same LLM models on prognostic prediction tasks for multiple other cancer types (breast, prostate, colon, etc.) using similar methodology.

### Open Question 2
- Question: How do LLMs perform when predicting rare complications or outcomes with highly imbalanced datasets?
- Basis in paper: [explicit] "Complications such as asthma attacks, pulmonary embolism, and deep vein thrombosis were observed in only a few patients, resulting in a significant data imbalance."
- Why unresolved: While the paper acknowledges data imbalance issues, it doesn't thoroughly investigate how LLMs handle extremely rare events or outcomes.
- What evidence would resolve it: Evaluating LLMs on datasets with progressively rarer outcomes, comparing performance to traditional models, and testing different prompting strategies for rare event prediction.

### Open Question 3
- Question: What is the optimal way to integrate multimodal data (images, text, structured data) with LLMs for prognosis prediction?
- Basis in paper: [explicit] "we were unable to collect image data, such as pathology images, which are particularly valuable for predicting lung cancer prognosis" and "we plan to collect relevant image data and investigate how to integrate them with clinical data."
- Why unresolved: Current LLMs show limited performance with medical images, and the optimal methodology for combining different data modalities is unknown.
- What evidence would resolve it: Developing and testing various architectures for multimodal LLM integration, comparing their performance to unimodal approaches, and validating on datasets containing multiple data types.

## Limitations

- Small dataset sizes (1,277 for survival, 593 for complications) may limit generalizability
- Zero-shot approach heavily depends on the quality and currency of pre-trained medical knowledge
- Study focuses exclusively on lung cancer, raising questions about applicability to other conditions

## Confidence

- **High Confidence**: The methodology for prompt engineering and evaluation metrics (AUROC, AUPRC) is clearly specified and technically sound.
- **Medium Confidence**: The comparative performance of GPT-4o mini versus logistic regression baselines is supported by results, but the statistical significance and clinical relevance require further validation.
- **Medium Confidence**: The claim that LLMs can effectively predict outcomes without patient data is supported, but the dependency on pre-trained knowledge quality introduces uncertainty.

## Next Checks

1. Test the approach on larger, more diverse lung cancer datasets to assess generalizability and robustness.
2. Conduct head-to-head comparisons with state-of-the-art machine learning models (e.g., random forests, gradient boosting) to benchmark LLM performance.
3. Validate the clinical utility of LLM predictions by involving oncologists in assessing whether the predictions align with their expertise and decision-making processes.