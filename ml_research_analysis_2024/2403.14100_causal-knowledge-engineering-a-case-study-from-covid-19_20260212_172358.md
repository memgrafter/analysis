---
ver: rpa2
title: 'Causal knowledge engineering: A case study from COVID-19'
arxiv_id: '2403.14100'
source_url: https://arxiv.org/abs/2403.14100
tags:
- causal
- knowledge
- experts
- base
- covid-19
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Causal Knowledge Engineering (CKE), a structured
  method for developing causal knowledge bases using Bayesian networks (BNs). CKE
  was developed and tested during the COVID-19 pandemic to capture evolving expert
  knowledge about the disease's pathophysiology and diagnostics.
---

# Causal knowledge engineering: A case study from COVID-19

## Quick Facts
- arXiv ID: 2403.14100
- Source URL: https://arxiv.org/abs/2403.14100
- Reference count: 0
- One-line primary result: Introduces Causal Knowledge Engineering (CKE) methodology for building causal knowledge bases using hierarchical Bayesian networks, validated through a COVID-19 case study

## Executive Summary
This paper introduces Causal Knowledge Engineering (CKE), a structured method for developing causal knowledge bases using Bayesian networks (BNs). Developed and tested during the COVID-19 pandemic, CKE provides a systematic approach to capture evolving expert knowledge about disease pathophysiology and diagnostics. The method involves creating a hierarchical set of causal BNs (CKBNs) that form a knowledge base to support future application-specific models, incorporating systematic expert elicitation, literature review, and qualitative parameterization of causal relationships.

The COVID-19 case study resulted in several validated CKBNs, including models of respiratory pathophysiology and diagnostic testing. The approach successfully addressed the challenges of modeling a highly uncertain problem domain with dynamically evolving knowledge, while also demonstrating the benefits and challenges of remote expert elicitation during pandemic lockdowns. CKE provides a framework for efficiently capturing and organizing causal knowledge, enabling the development of application models while maintaining internal consistency and supporting decision-making.

## Method Summary
The Causal Knowledge Engineering (CKE) process involves defining the purpose and scope of a causal knowledge base, recruiting experts, and developing a hierarchical framework of causal Bayesian networks. The method uses reverse bow-tie approach to create individual CKBNs, conducts group workshops and 1-on-1 expert sessions for knowledge elicitation, and incorporates qualitative parameterization of causal relationships. The process is iterative, with models being revised based on expert feedback and validated through qualitative testing of their logical consistency.

## Key Results
- Successfully developed a hierarchical knowledge base of causal Bayesian networks for COVID-19 pathophysiology and diagnostics
- Demonstrated the effectiveness of remote expert elicitation during pandemic lockdowns, achieving broader geographic coverage and more frequent participation
- Validated the approach of qualitative parameterization for testing model structure without requiring precise quantitative data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The CKE method captures causal knowledge from multiple sources in a structured way that supports future application models.
- Mechanism: The approach uses a hierarchical set of causal BNs (CKBNs) to encode qualitative causal relationships, with each CKBN focusing on a specific aspect of the problem domain. This structure allows for overlapping and competing hypotheses while maintaining internal consistency.
- Core assumption: Experts can accurately convey causal knowledge that can be translated into causal BNs, and these BNs can be meaningfully structured into a knowledge base hierarchy.
- Evidence anchors:
  - [abstract] "CKE provides a structured approach for building a causal knowledge base that can support the development of a variety of application-specific models."
  - [section 2.1] "The structure of the causal knowledge base can in principle take on any form suitable for the problem domain and for supporting the final application. For the CKE process, we recommend that the causal knowledge base be structured as a hierarchical set of models."
  - [corpus] Corpus evidence shows limited direct citations, suggesting this is an emerging methodology rather than a widely adopted practice.
- Break condition: If experts cannot articulate causal relationships clearly, or if the hierarchical structure becomes too complex to maintain coherence.

### Mechanism 2
- Claim: Qualitative parameterisation of causal relationships enables validation of model structure without requiring precise quantitative data.
- Mechanism: By encoding the qualitative nature of causal relationships (e.g., presence of cause increases probability of effect), the models can be tested for logical consistency and used to illustrate intended behavior to experts for validation.
- Core assumption: Experts can validate qualitative relationships even without quantitative estimates, and logical consistency is sufficient for initial validation.
- Evidence anchors:
  - [section 2.3.5] "Qualitative parameterisation is one that captures the qualitative nature of the causal relationships (e.g., when the probability of virus entering NP increases, so too should the risk of upper respiratory infection), without making any claims to quantitative validity or precision."
  - [abstract] "The method includes systematic expert elicitation, literature review, and qualitative parameterization of causal relationships."
  - [corpus] Corpus evidence is weak on this specific mechanism, with no direct supporting citations found.
- Break condition: If qualitative relationships cannot be validated by experts, or if logical inconsistencies emerge during validation.

### Mechanism 3
- Claim: Remote expert elicitation during COVID-19 lockdowns was more effective than anticipated due to increased expert availability and motivation.
- Mechanism: The urgency of the pandemic motivated experts to participate, while remote participation reduced logistical barriers, allowing broader geographic coverage and more frequent, shorter sessions.
- Core assumption: Expert motivation during crisis outweighs typical barriers to participation, and remote tools can effectively facilitate complex causal modeling discussions.
- Evidence anchors:
  - [section 1.1.1] "Government-instituted restrictions on movement during the COVID-19 pandemic meant that a larger pool of experts became available than might have otherwise been the case, and the degree of concern about the pandemic motivated many of these experts to support the project."
  - [section 2.3.3] "The worldwide lockdowns made remote participation mandatory. While this presented new challenges, it also provided many benefits. Experts came from a wide geographic area, and could participate with much greater convenience and lower cost â€” allowing more experts to participate, and on a more regular basis."
  - [corpus] Corpus evidence shows this is a specific case study finding rather than a general principle, with limited broader validation.
- Break condition: If expert motivation wanes as the crisis context changes, or if remote tools prove inadequate for complex causal modeling discussions.

## Foundational Learning

- Concept: Bayesian Networks and causal reasoning
  - Why needed here: The entire methodology is built on representing causal knowledge using Bayesian Networks, so understanding the basics is essential.
  - Quick check question: What distinguishes a causal BN from a standard probabilistic BN?

- Concept: Expert elicitation techniques
  - Why needed here: The methodology relies heavily on extracting causal knowledge from experts, requiring familiarity with various elicitation approaches.
  - Quick check question: What are the key differences between structured and unstructured expert elicitation?

- Concept: Qualitative parameterization
  - Why needed here: This technique allows validation of model structure without requiring precise quantitative estimates, which is crucial given the uncertainty in early COVID-19 knowledge.
  - Quick check question: How does qualitative parameterization differ from quantitative parameterization in terms of validation purposes?

## Architecture Onboarding

- Component map: Expert elicitation sessions -> Individual CKBN development -> Hierarchical knowledge base organization -> Qualitative parameterization -> Validation with experts

- Critical path: 1) Define purpose and scope, 2) Develop top-level framework, 3) Recruit experts, 4) Elicit knowledge for individual CKBNs using group workshops and 1-on-1 sessions, 5) Create variable dictionaries and qualitative parameterizations, 6) Validate models with experts.

- Design tradeoffs: Structured elicitation provides consistency but may limit expert input; qualitative parameterization enables validation without precise data but may miss important quantitative nuances; hierarchical organization supports reuse but adds complexity.

- Failure signatures: Inconsistent expert feedback across sessions, inability to reach consensus on causal relationships, models that cannot be qualitatively parameterized, lack of engagement from recruited experts.

- First 3 experiments:
  1. Conduct a small pilot elicitation session with 2-3 experts to test the workshop format and identify necessary adjustments
  2. Create a single CKBN with a simple causal structure to practice the elicitation and documentation workflow
  3. Perform qualitative parameterization on the pilot CKBN to validate the approach and identify any issues with the qualitative relationships

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can qualitative parameterisation be systematically integrated into the CKE process to improve validation of both CKBNs and future application models?
- Basis in paper: [explicit] The paper discusses qualitative parameterisation as a recommended component of CKBN development, but notes it is optional and provides limited guidance on systematic integration.
- Why unresolved: The paper mentions the benefits of qualitative parameterisation but does not provide a detailed methodology for how to systematically apply it throughout the CKE process.
- What evidence would resolve it: A structured methodology for qualitative parameterisation that can be consistently applied across different CKBNs and validated against expert knowledge and data.

### Open Question 2
- Question: What are the most effective techniques for eliciting causal knowledge from experts in a remote setting, and how do they compare to in-person methods?
- Basis in paper: [explicit] The paper highlights the challenges and benefits of remote expert elicitation during the COVID-19 pandemic, noting that online workshops worked extremely well with many benefits.
- Why unresolved: While the paper discusses the advantages of remote elicitation, it does not provide a comprehensive comparison with in-person methods or identify the most effective techniques for remote settings.
- What evidence would resolve it: Comparative studies or case studies evaluating the effectiveness of different remote elicitation techniques against in-person methods in terms of knowledge capture, expert engagement, and model quality.

### Open Question 3
- Question: How can the CKE process be adapted to handle rapidly evolving knowledge domains where the scope and purpose of the causal knowledge base may need to change frequently?
- Basis in paper: [explicit] The paper discusses the challenges of modeling a highly uncertain problem domain with dynamically evolving knowledge during the COVID-19 pandemic.
- Why unresolved: The paper acknowledges the need for flexibility in the CKE process but does not provide specific strategies for adapting to rapidly changing knowledge domains.
- What evidence would resolve it: A framework or set of guidelines for dynamically updating the CKE process to accommodate changes in scope, purpose, and knowledge as the domain evolves.

## Limitations

- Limited validation across different domains beyond the single COVID-19 case study
- Uncertain generalizability of remote elicitation benefits to non-crisis contexts
- Qualitative parameterization may miss important quantitative nuances needed for some applications

## Confidence

- Core claim about CKE providing structured framework: Medium
- Claim about qualitative parameterization enabling effective validation: Low
- Claim about remote elicitation effectiveness during COVID-19: Medium

## Next Checks

1. Test the CKE methodology on a non-COVID domain with established causal relationships to assess generalizability and identify domain-specific challenges
2. Conduct a controlled comparison of remote versus in-person expert elicitation for complex causal modeling tasks to validate the claimed benefits of remote participation
3. Implement quantitative parameterization for a subset of the COVID-19 CKBNs to determine whether qualitative validation alone is sufficient for practical applications or if quantitative estimates would improve model utility