---
ver: rpa2
title: 'Beyond Text-to-SQL for IoT Defense: A Comprehensive Framework for Querying
  and Classifying IoT Threats'
arxiv_id: '2406.17574'
source_url: https://arxiv.org/abs/2406.17574
tags:
- data
- text-to-sql
- traffic
- network
- malicious
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel IoT text-to-SQL dataset and framework
  for querying and classifying IoT threats. The dataset comprises 10,985 text-SQL
  pairs and 239,398 rows of network traffic data from a smart building's IoT ecosystem,
  including sensor readings and Zeek logs.
---

# Beyond Text-to-SQL for IoT Defense: A Comprehensive Framework for Querying and Classifying IoT Threats

## Quick Facts
- arXiv ID: 2406.17574
- Source URL: https://arxiv.org/abs/2406.17574
- Reference count: 21
- Dataset contains 10,985 text-SQL pairs and 239,398 rows of IoT network traffic data

## Executive Summary
This paper introduces a novel IoT-specific text-to-SQL dataset and framework for querying and classifying IoT threats. The research combines text-to-SQL generation with malicious network traffic detection, training a single model on both tasks. Results demonstrate that joint training improves SQL generation performance by nearly matching larger models, while highlighting current LLMs' limitations in domain-specific reasoning tasks beyond simple query generation.

## Method Summary
The method involves fine-tuning a Flan-T5-base transformer model using Adam optimizer with learning rate 0.0001 for 15 epochs. The model is trained jointly on text-to-SQL generation and malicious traffic detection tasks using a single training loop. Input consists of either (schema + text query) for SQL generation or (instruction + formatted tabular data) for classification. The dataset combines IoT-23 network logs and smart building sensor data, featuring over 1,000 temporal queries and 10,985 text-SQL pairs.

## Key Results
- Joint training on text-to-SQL and malicious traffic detection improves SQL generation performance
- The approach nearly matches performance of substantially larger models
- Current large language models struggle with inferring new information about returned data
- Dataset contains over 1,000 temporal-related queries, significantly expanding beyond prior text-to-SQL datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint training on text-to-SQL and malicious traffic detection improves SQL generation performance through better understanding of table relationships.
- Mechanism: Training on the conn.log table for malicious detection helps the model understand how it relates to other tables via JOIN queries, enhancing overall schema comprehension.
- Core assumption: The conn.log table serves as a central reference point that, when better understood, improves comprehension of the entire database schema.
- Evidence anchors:
  - "Our results show that joint training to query and infer information about the data can improve overall text-to-SQL performance, nearly matching substantially larger models."
  - "Our analysis shows that much of the improvement is on the conn.log-related queries... by better understanding the conn.log table, the model can better understand how it relates more to other tables via JOIN queries."

### Mechanism 2
- Claim: Temporal queries in the dataset improve model performance on time-based reasoning tasks.
- Mechanism: The dataset includes over 1,000 temporally-related queries using MySQL datetime columns, which are missing or limited in prior text-to-SQL datasets. This specialization allows models to learn temporal reasoning patterns specific to IoT environments.
- Core assumption: Temporal reasoning is a distinct skill that requires dedicated training examples and cannot be adequately learned from general text-to-SQL datasets.
- Evidence anchors:
  - "Our dataset contains additional query types limited in prior text-to-SQL datasets, notably temporal-related queries."
  - "There have been limited text-to-dataset resources that contain many temporal-related queries... Our research expands on this work, containing more than 1,000 temporally-related queries using MySQL datetime columns."

### Mechanism 3
- Claim: The dataset provides a unique testbed for evaluating LLMs' ability to perform domain-specific reasoning beyond SQL generation.
- Mechanism: By requiring models to both generate SQL and classify malicious network traffic, the dataset tests whether LLMs can understand and reason about the returned data, not just retrieve it.
- Core assumption: Current LLMs can generate SQL but struggle with domain-specific reasoning tasks that require understanding the semantic meaning of the data.
- Evidence anchors:
  - "We also show that current large language models (e.g., GPT3.5) struggle to infer new information about returned data, thus our dataset provides a novel test bed for integrating complex domain-specific reasoning into LLMs."
  - "Much of this work assumes the table is provided. Hence, we develop a new text-to-SQL dataset to make predictions/inferences about the data and query the data using a single model."

## Foundational Learning

- Concept: Database schema understanding
  - Why needed here: The model must understand the relationships between tables (IoT-23 network logs and smart building sensor data) to generate correct SQL queries involving JOIN operations.
  - Quick check question: Can you explain how the conn.log table relates to the sensor reading tables in this IoT database schema?

- Concept: Temporal data handling
  - Why needed here: The dataset contains numerous temporal queries that require understanding datetime columns and time-based filtering, aggregation, and comparison operations.
  - Quick check question: How would you write a SQL query to find all network connections from the last 24 hours using the ts timestamp column?

- Concept: Malicious activity classification
  - Why needed here: The model must classify network traffic as malicious or benign based on multiple features from the Zeek logs, requiring understanding of network security patterns.
  - Quick check question: What features from the conn.log would be most useful for distinguishing DDoS attacks from normal network traffic?

## Architecture Onboarding

- Component map: Input text → schema preprocessing → model inference → SQL generation or classification output. For evaluation, generated SQL is executed against the database to verify correctness.
- Critical path: Input text → schema preprocessing → model inference → SQL generation or classification output. For evaluation, generated SQL is executed against the database to verify correctness.
- Design tradeoffs: Joint training improves text-to-SQL performance but slightly reduces malicious traffic detection accuracy. Using a smaller base model with joint training achieves comparable results to a larger model trained only on text-to-SQL.
- Failure signatures: Poor performance on conn.log-related queries, inability to generate SQL for complex JOIN operations, misclassifying malicious traffic as benign, or generating syntactically incorrect SQL.
- First 3 experiments:
  1. Evaluate baseline T5-base model on text-to-SQL task only using the provided test set to establish performance metrics.
  2. Train the joint model on both text-to-SQL and malicious traffic detection tasks, then evaluate on both tasks separately to measure the impact of joint training.
  3. Perform ablation study by removing temporal queries from the dataset to measure their impact on overall performance.

## Open Questions the Paper Calls Out

- How does the performance of text-to-SQL models vary when trained on datasets with different levels of temporal query complexity?
- What are the specific limitations of current large language models in inferring new information about returned data, and how can these be addressed?
- How does the joint training of text-to-SQL and malicious network traffic detection tasks affect the performance on each individual task, and what are the underlying mechanisms?

## Limitations
- The dataset is built from a specific smart building environment, which may limit its applicability to other IoT ecosystems.
- The templates used for text-SQL generation and specific preprocessing steps for network traffic data are not fully detailed, potentially affecting reproducibility.
- Evidence for the proposed mechanisms (temporal reasoning benefits, conn.log as central reference point) is speculative and needs more rigorous testing.

## Confidence

- **High Confidence**: The dataset creation process and basic evaluation metrics (Logical Accuracy, Execution Accuracy, macro-F1) are clearly specified and reproducible.
- **Medium Confidence**: The claim that joint training improves text-to-SQL performance is supported by results but requires further validation with different models and datasets.
- **Low Confidence**: The proposed mechanisms (temporal reasoning benefits, conn.log as central reference point) are speculative and need more rigorous testing.

## Next Checks

1. Perform ablation study by removing all temporal-related queries from the dataset and retraining the model to quantify the exact contribution of temporal reasoning to overall performance improvements.

2. Test the trained model on established text-to-SQL benchmarks (e.g., Spider) to assess whether the IoT-specific improvements generalize to broader SQL generation tasks.

3. Evaluate whether other transformer architectures (e.g., CodeT5, PLBART) achieve similar or better performance with joint training, particularly for the malicious traffic detection component.