---
ver: rpa2
title: 'CoNav: A Benchmark for Human-Centered Collaborative Navigation'
arxiv_id: '2406.02425'
source_url: https://arxiv.org/abs/2406.02425
tags:
- human
- agent
- navigation
- person
- motion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoNav, a benchmark for human-centered collaborative
  navigation. The key challenge is enabling an agent to reason about human intentions
  from observed activities and navigate to the intended destination in advance.
---

# CoNav: A Benchmark for Human-Centered Collaborative Navigation

## Quick Facts
- arXiv ID: 2406.02425
- Source URL: https://arxiv.org/abs/2406.02425
- Authors: Changhao Li, Xinyu Sun, Peihao Chen, Jugang Fan, Zixu Wang, Yanxia Liu, Jinhui Zhu, Chuang Gan, Mingkui Tan
- Reference count: 40
- Primary result: CoNav agent achieves 19.8% FASR vs 8.6-61.6% for baselines

## Executive Summary
CoNav introduces a benchmark for human-centered collaborative navigation where an agent must reason about human intentions from observed activities and navigate to the intended destination in advance. The paper presents an LLM-based humanoid animation generation framework to create diverse, realistic human activities conditioned on environmental context, and an intention-aware agent that predicts both long-term and short-term human intentions to guide navigation. Experiments demonstrate the CoNav agent significantly outperforms baseline methods on key metrics like First-to-Arrive Success Rate (19.8% vs 8.6-61.6% for baselines) and Average Steps (354.5 vs 295.5-442.6).

## Method Summary
The CoNav benchmark consists of an LLM-based animation generation framework and an intention-aware navigation agent. The animation framework generates diverse human activities by reasoning environment-aligned activities through LLM prompts, animating these with motion generation models, and incorporating trajectories. The navigation agent predicts long-term intentions (next activity and object) using a Perceiver model and short-term intentions (future trajectory) using a GST model, then uses these predictions in an LSTM policy to determine navigation actions. The system is trained using supervised learning for intention prediction and imitation learning for the navigation policy.

## Key Results
- CoNav agent achieves 19.8% First-to-Arrive Success Rate (FASR), significantly outperforming baselines (8.6-61.6%)
- Average Steps reduced to 354.5, compared to 295.5-442.6 for baselines
- Collision Rate maintained at reasonable levels while improving navigation efficiency
- Demonstrates effectiveness of intention-aware approach for human-robot collaboration

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LLM-based animation generation enables diverse, realistic human activities conditioned on environmental context.
- **Mechanism**: System reasons environment-aligned activities by describing objects to LLM and prompting for two-stage causally related activities, then animates these and fills trajectories between them.
- **Core assumption**: LLM can accurately understand environmental context and generate reasonable, causally related activities executable with given objects.
- **Evidence anchors**:
  - [abstract]: "We design a novel LLM-based humanoid animation generation framework, which is conditioned on both text descriptions and environmental context."
  - [section]: "We first describe all environmental objects to an LLM and prompt it to generate reasonable activities conducted with the given objects."
- **Break condition**: LLM fails to understand environmental context or generate causally related activities, resulting in unrealistic or irrelevant animations.

### Mechanism 2
- **Claim**: Intention-aware agent predicts both long-term and short-term human intentions to guide navigation.
- **Mechanism**: Uses Perceiver model for long-term intentions (next activity/object) from historical movement, GST model for short-term intentions (future trajectory), both used by LSTM policy for navigation.
- **Core assumption**: Historical human movement data contains sufficient information to predict future intentions accurately.
- **Evidence anchors**:
  - [abstract]: "We propose an intention-aware agent for reasoning both long-term and short-term human intention."
  - [section]: "The agent predicts navigation action based on the predicted intention and panoramic observation."
- **Break condition**: Prediction models fail to accurately forecast human intentions, leading to suboptimal navigation decisions.

### Mechanism 3
- **Claim**: Imitation learning effectively trains agent to navigate to human's intended destination.
- **Mechanism**: Trained using supervised learning for intention prediction and imitation learning for navigation policy, mimicking expert trajectories that navigate to goal while avoiding collisions.
- **Core assumption**: Expert trajectories provide good demonstration of desired behavior for agent to imitate.
- **Evidence anchors**:
  - [abstract]: "The agent predicts navigation action based on the predicted intention and panoramic observation."
  - [section]: "We train the intention predictor and policy using supervised learning and imitation learning, respectively."
- **Break condition**: Expert trajectories are suboptimal or imitation learning fails to capture desired behavior, limiting agent performance.

## Foundational Learning

- **Concept**: Understanding of human behavior and intentions
  - **Why needed here**: Core challenge is enabling agent to reason about human intentions from observed activities and navigate accordingly.
  - **Quick check question**: Can you explain how the agent uses historical human movement data to predict future intentions?

- **Concept**: Knowledge of motion generation techniques
  - **Why needed here**: System relies on motion generation models to create realistic human animations for navigation environment.
  - **Quick check question**: How do text-conditioned motion generation models contribute to creating diverse human activities?

- **Concept**: Familiarity with navigation algorithms and techniques
  - **Why needed here**: Agent needs to navigate efficiently to human's intended destination while avoiding collisions.
  - **Quick check question**: What navigation strategies does the agent employ to reach the goal position?

## Architecture Onboarding

- **Component map**: LLM reasoning → Motion generation → Intention prediction → Navigation policy → Action execution

- **Critical path**: LLM reasoning → Motion generation → Intention prediction → Navigation policy → Action execution

- **Design tradeoffs**:
  - Using LLM for activity reasoning vs. manually defining activities
  - Relying on motion generation models vs. pre-recorded animations
  - Predicting intentions vs. reactive navigation

- **Failure signatures**:
  - Unrealistic or irrelevant human animations
  - Inaccurate intention predictions leading to suboptimal navigation
  - High collision rates or inefficient navigation paths

- **First 3 experiments**:
  1. Evaluate quality and diversity of generated human animations in various environments.
  2. Assess accuracy of long-term and short-term intention predictions using different prediction models.
  3. Compare performance of intention-aware agent with baseline navigation methods on CoNav benchmark.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the diversity of human activities in CoNav compare to real-world human behavior, and what is the impact on the generalization of navigation agents?
- Basis in paper: [explicit] Paper mentions generating more than 25k diverse trajectories in 49 environments but doesn't compare to real-world human behavior diversity.
- Why unresolved: Paper lacks quantitative comparison of generated activity diversity to real-world human behavior or discussion of impact on agent generalization.
- What evidence would resolve it: Study comparing CoNav activity diversity to real-world human behavior data and analysis of impact on navigation agent generalization.

### Open Question 2
- Question: How does performance of intention-aware agent change when using different types of human motion generation models?
- Basis in paper: [inferred] Paper uses MotionGPT but doesn't explore impact of different motion generation models on agent performance.
- Why unresolved: Paper lacks comparison of agent performance using different text-to-motion models.
- What evidence would resolve it: Experiment comparing performance when using different text-to-motion models for generating human motions.

### Open Question 3
- Question: How does CoNav agent handle situations where human's intended destination is not directly observable or is occluded?
- Basis in paper: [inferred] Paper mentions agent struggles when human is occluded but doesn't discuss handling non-observable destinations.
- Why unresolved: Paper lacks detailed analysis of agent handling situations where intended destination is not directly observable.
- What evidence would resolve it: Analysis of agent performance in situations where intended destination is not directly observable or occluded, with strategies for improvement.

### Open Question 4
- Question: How does CoNav agent's performance change when human's actions are not causally related?
- Basis in paper: [inferred] Paper assumes human actions are causally related but doesn't explore performance when this assumption is violated.
- Why unresolved: Paper lacks analysis of agent performance when human actions are not causally related.
- What evidence would resolve it: Experiment testing agent performance when human actions are not causally related, with implications for intention-aware navigation design.

## Limitations
- LLM-based animation generation quality depends on prompt quality and may not perfectly align with real-world human behavior
- Imitation learning requires high-quality expert trajectories which may be challenging to obtain in diverse environments
- Generalization to real-world scenarios with more complex human behaviors and dynamic environments is uncertain

## Confidence
- **High Confidence**: Overall methodology and experimental design are sound, results demonstrate significant improvements over baselines
- **Medium Confidence**: Effectiveness of LLM-based animation generation and accuracy of intention prediction may vary with environment complexity
- **Low Confidence**: Generalizability to real-world scenarios with complex human behaviors and dynamic environments is uncertain

## Next Checks
1. Evaluate quality and diversity of generated human animations in wider range of environments with complex object layouts
2. Conduct user studies to assess realism and relevance of generated animations from human perspective
3. Test intention-aware agent's performance in simulated environments with more dynamic human behaviors like sudden activity changes