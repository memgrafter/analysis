---
ver: rpa2
title: 'The Factorization Curse: Which Tokens You Predict Underlie the Reversal Curse
  and More'
arxiv_id: '2406.05183'
source_url: https://arxiv.org/abs/2406.05183
tags:
- training
- language
- backward
- forward
- curse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work identifies the "factorization curse," where large language
  models struggle to retrieve information seen during training when probed in different
  token orders than during training. The authors frame this as a failure to learn
  the same joint distribution under different factorizations of the input into context
  and prediction.
---

# The Factorization Curse: Which Tokens You Predict Underlie the Reversal Curse and More

## Quick Facts
- **arXiv ID**: 2406.05183
- **Source URL**: https://arxiv.org/abs/2406.05183
- **Reference count**: 39
- **One-line primary result**: Factorization-agnostic training objectives that allow predictions using every possible context decomposition significantly mitigate the reversal curse and improve knowledge storage and planning in language models.

## Executive Summary
This work identifies the "factorization curse," where large language models struggle to retrieve information seen during training when probed in different token orders than during training. The authors frame this as a failure to learn the same joint distribution under different factorizations of the input into context and prediction. Through controlled experiments with increasing realism—including a new Wikipedia-based WikiReversal benchmark—they demonstrate that the prevalent next-token prediction objective is inherently susceptible to this issue, which cannot be resolved by scale, reversing tokens, or naive bidirectional attention. Instead, factorization-agnostic objectives that allow predictions using every possible context decomposition significantly mitigate the reversal curse and show promise for knowledge storage and planning. On BioS, MLMs with uniformly sampled masking rates (MLM-U) achieve 68% backward accuracy compared to 0% for autoregressive models. On WikiReversal, MLM-U attains 46% backward accuracy versus 4.3% for autoregressive models.

## Method Summary
The authors investigate the factorization curse through controlled experiments using synthetic tokens and a new Wikipedia-based WikiReversal benchmark. They compare various training paradigms: autoregressive (AR), autoregressive with reverse, masked language modeling (MLM) with fixed and uniformly sampled masking rates (MLM-U), and permutation language modeling (PLM). The core method involves implementing factorization-agnostic objectives that allow predictions using every possible context-prediction decomposition. For MLM-U, they use an encoder-decoder model based on the GPT architecture to support different attention/masking strategies. The experiments evaluate forward and backward retrieval accuracy on synthetic and real-world datasets, measuring how well models can store and retrieve knowledge under different factorizations.

## Key Results
- MLM-U achieves 68% backward accuracy on BioS compared to 0% for autoregressive models
- On WikiReversal, MLM-U attains 46% backward accuracy versus 4.3% for autoregressive models
- The factorization curse is shown to be an inherent limitation of standard next-token prediction objectives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The factorization curse explains why models struggle with reversed queries by failing to learn the same joint distribution under different token orderings.
- Mechanism: Standard autoregressive training factorizes the joint probability as a left-to-right chain, so the model only learns to predict tokens from left context. When asked to predict using right context (e.g., "What is the capital of France?" after seeing "Paris is the capital of..."), the learned factorization doesn't support it.
- Core assumption: Token order during training determines which factorizations are learned; the model does not generalize to unseen factorizations even if the underlying relation is the same.
- Evidence anchors:
  - [abstract] "The reversal curse, where models cannot recall information when probed in a different order than was encountered during training"
  - [section 2] "the factorization curse is an inherent failure of the next-token prediction objective used in popular large language models"
  - [corpus] "Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training" — confirms related work exists
- Break condition: If the model is exposed to multiple factorizations during training, the curse is mitigated.

### Mechanism 2
- Claim: Factorization-agnostic objectives that average predictions over all token orderings allow the model to retrieve information regardless of query order.
- Mechanism: By sampling uniformly over permutations or masking rates, the model sees every possible context-prediction decomposition, so it learns joint distributions invariant to factorization order.
- Core assumption: Uniformly sampling permutations or masking rates during training is sufficient to cover all factorizations the model will encounter at inference.
- Evidence anchors:
  - [section 2.2] "A straightforward way to alleviate the factorization issue, is to write the autoregressive loss in a way that is independent of factorization by averaging over all permutations"
  - [section 3.1] "Introducing a uniformly sampled rate via MLM-U solves the task perfectly"
  - [corpus] "DiffER: Diffusion Entity-Relation Modeling for Reversal Curse" — related work on bidirectional objectives
- Break condition: If the sampling distribution is biased or limited, some factorizations remain under-represented.

### Mechanism 3
- Claim: Fixed masking rates in MLM cause poor generative quality and fail on longer entities because the model never learns to predict tokens given arbitrary right-context.
- Mechanism: With a fixed mask rate (e.g., 15%), the model only ever predicts from a narrow range of context lengths, so it cannot generalize to entities longer than the mask span or to arbitrary-length sequences at inference.
- Core assumption: Training on fixed-length contexts is insufficient for handling variable-length generation at test time.
- Evidence anchors:
  - [section 2.2] "training with a fixed rate does not yield a good generative model"
  - [section 3.1] "MLM exhibits much noisier performance that's consistently lower than MLM-U with uniformly random masking ratio"
  - [corpus] "Bilinear relational structure fixes reversal curse" — suggests structural solutions exist
- Break condition: If the model is fine-tuned with adaptive masking or length-aware objectives.

## Foundational Learning

- Concept: Chain rule of probability for sequence modeling
  - Why needed here: The factorization curse is defined in terms of different decompositions of the joint distribution; understanding the chain rule is essential to see why left-to-right training fails on reversed queries.
  - Quick check question: If p(x) = p(x2|x1)p(x1), is p(x1|x2)p(x2) always equal? Why or why not?

- Concept: Permutations and sampling over orderings
  - Why needed here: Permutation language modeling and MLM-U rely on sampling different token orderings; engineers must grasp how this changes the training objective.
  - Quick check question: What is the effect of averaging the autoregressive loss over all permutations of a sequence?

- Concept: Masking strategies and their impact on bidirectional modeling
  - Why needed here: MLM-U's uniform masking is key to its factorization-agnostic property; fixed-rate MLM is shown to fail.
  - Quick check question: How does a fixed 15% mask rate limit the model's ability to handle longer entities at inference?

## Architecture Onboarding

- Component map: Tokenization -> Masking/Permutation Sampling -> Encoder-Decoder Transformer -> Loss Computation -> Parameter Update
- Critical path: Data → tokenization → masking/permutation sampling → forward pass → loss computation → parameter update. For MLM-U, the encoder-decoder architecture is critical to enable arbitrary context-prediction splits.
- Design tradeoffs: AR is simple and generative but factorization-dependent; MLM is bidirectional but not generative with fixed masks; MLM-U is both but computationally heavier due to sampling over permutations/masks.
- Failure signatures: Zero backward accuracy on reversed queries (AR), poor generative quality or length generalization (fixed MLM), slow convergence or high variance (MLM-U).
- First 3 experiments:
  1. Train AR on synthetic key-value pairs; test forward vs backward retrieval accuracy.
  2. Train MLM with 15% mask; compare to MLM-U on the same task; measure backward accuracy.
  3. Train MLM-U on BioS; plot forward/backward accuracy over training steps to observe delayed generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact mechanism by which factorization-agnostic objectives like MLM-U lead to improved planning capabilities in tasks like the Star Graph Task?
- Basis in paper: [explicit] The paper demonstrates that MLM-U enables the model to reliably solve the path-planning task by better capturing the planning requirements, unlike standard autoregressive training.
- Why unresolved: The paper does not provide a detailed explanation of the underlying mechanism. It only shows that MLM-U outperforms other objectives on this task.
- What evidence would resolve it: Further analysis of the learned representations and attention patterns in MLM-U models compared to autoregressive models during the Star Graph Task would provide insights into the mechanism.

### Open Question 2
- Question: What is the optimal schedule or curriculum for training factorization-agnostic objectives like MLM-U to balance task complexity and learning efficiency?
- Basis in paper: [inferred] The paper mentions that MLM-U has a much more challenging objective and requires better schedules/curricula to smoothly interpolate the difficulty increase from next-token prediction to the highest-complexity factorization the model can handle.
- Why unresolved: The paper does not explore different training schedules or curricula for MLM-U. It only suggests that such approaches could be beneficial.
- What evidence would resolve it: Experiments comparing different training schedules or curricula for MLM-U on various tasks would identify the optimal approach.

### Open Question 3
- Question: How does the performance of factorization-agnostic objectives like MLM-U scale with model size, and what is the impact on the reversal curse?
- Basis in paper: [explicit] The paper shows that MLM-U achieves the highest backward accuracy among the evaluated models on the WikiReversal benchmark, but it still falls short of the AR model's forward performance. It also mentions that significantly better results can be obtained by allowing models to leverage knowledge stored from the QAs themselves.
- Why unresolved: The paper does not investigate the scaling behavior of MLM-U with model size or explore the impact on the reversal curse.
- What evidence would resolve it: Experiments scaling MLM-U models to different sizes and evaluating their performance on the reversal curse tasks would reveal the scaling behavior and impact.

## Limitations

- The computational cost and convergence behavior of MLM-U on large-scale pretraining are not fully characterized
- While MLM-U improves backward accuracy, it still falls short of autoregressive models' forward performance on some benchmarks
- The benefits of factorization-agnostic training may not fully transfer to multi-hop reasoning and open-domain QA without further fine-tuning

## Confidence

- **Problem identification**: High - The reversal curse and factorization curse are convincingly demonstrated through multiple benchmarks
- **Proposed solution effectiveness**: Medium-High - MLM-U shows significant improvements, but results are still below autoregressive forward performance in some cases
- **Scalability claims**: Medium - Results are promising but need validation on larger, more diverse datasets
- **Computational efficiency**: Low - The paper does not fully characterize the training and inference costs of MLM-U

## Next Checks

1. **Scale Up and Generalize**: Evaluate MLM-U and related objectives on diverse, large-scale datasets (e.g., C4, Colossal Cleaned) and test generalization to multi-hop reasoning and open-domain QA
2. **Analyze Computational Efficiency**: Benchmark the training and inference costs of MLM-U versus AR and fixed-rate MLM, and explore optimizations (e.g., curriculum learning, adaptive masking) to reduce overhead
3. **Probe Model Behavior**: Conduct detailed probing studies to understand how factorization-agnostic training changes internal representations and retrieval strategies, and whether the benefits persist after fine-tuning on downstream tasks