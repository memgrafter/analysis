---
ver: rpa2
title: 'Stop Regressing: Training Value Functions via Classification for Scalable
  Deep RL'
arxiv_id: '2403.03950'
source_url: https://arxiv.org/abs/2403.03950
tags:
- hl-gauss
- learning
- classification
- regression
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the performance of classification losses
  (e.g., cross-entropy) as an alternative to regression losses (e.g., MSE) for training
  value functions in deep reinforcement learning (RL). The authors hypothesize that
  the categorical cross-entropy loss can address several challenges inherent to value-based
  RL, such as noisy targets and non-stationarity.
---

# Stop Regressing: Training Value Functions via Classification for Scalable Deep RL

## Quick Facts
- arXiv ID: 2403.03950
- Source URL: https://arxiv.org/abs/2403.03950
- Authors: Jesse Farebrother; Jordi Orbay; Quan Vuong; Adrien Ali Taïga; Yevgen Chebotar; Ted Xiao; Alex Irpan; Sergey Levine; Pablo Samuel Castro; Aleksandra Faust; Aviral Kumar; Rishabh Agarwal
- Reference count: 40
- Key outcome: Training value functions with categorical cross-entropy (particularly HL-Gauss method) significantly outperforms regression losses across diverse domains including Atari, robotic manipulation, chess, and language-agent tasks.

## Executive Summary
This paper investigates using classification losses, specifically categorical cross-entropy, as an alternative to regression losses for training value functions in deep reinforcement learning. The authors propose several methods for deriving classification labels from value targets, with HL-Gauss (Gaussian smoothing) showing consistent improvements across all tested domains. Through extensive experiments and analysis, they demonstrate that cross-entropy training mitigates issues inherent to value-based RL such as noisy targets and non-stationarity, leading to better performance and scalability compared to traditional MSE approaches.

## Method Summary
The paper replaces traditional MSE TD loss with categorical cross-entropy loss for training value functions. Three classification label methods are explored: Two-Hot (binary representation across two bins), C51 (categorical distributional RL), and HL-Gauss (Gaussian smoothing with sigma/width ratio of 0.75). Value estimates are modeled as categorical distributions over a fixed support, with softmax activation producing probabilities. The Bellman operator is adapted to generate target distributions rather than scalar targets. The HL-Gauss method spreads probability mass according to a Gaussian distribution centered on the target value, providing smooth label representations that improve learning stability and performance.

## Key Results
- HL-Gauss consistently outperforms both MSE and other classification methods across all tested domains
- Categorical cross-entropy training shows significant improvements on Atari games, robotic manipulation tasks, chess, and Wordle
- The method demonstrates better robustness to reward noise compared to MSE
- Value networks trained with cross-entropy learn better intermediate representations (verified via linear probing)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-entropy loss mitigates noisy target values in reinforcement learning.
- Mechanism: By modeling value estimates as categorical distributions and minimizing cross-entropy, the method is less sensitive to outliers and stochasticity in rewards and environment dynamics.
- Core assumption: The stochasticity in RL (e.g., sticky actions, reward noise) acts like label noise in supervised learning, which cross-entropy is known to handle better than MSE.
- Evidence anchors:
  - [abstract] "categorical cross-entropy primarily stem from its ability to mitigate issues inherent to value-based RL, such as noisy targets and non-stationarity"
  - [section] "Performance of HL-Gauss degrades more gracefully than MSE as the noise scale increases" (from reward noise experiment)
  - [corpus] Weak; related works on classification vs regression exist but not specifically for RL noise robustness.
- Break condition: If environment dynamics become deterministic and rewards are perfectly predictable, the advantage of cross-entropy over MSE for noise robustness may disappear.

### Mechanism 2
- Claim: Cross-entropy with categorical representations yields better learned representations for value functions.
- Mechanism: The softmax parameterization bounds outputs and gradients, and the cross-entropy loss encourages the network to learn richer features that remain useful across different policies encountered during learning.
- Core assumption: Better intermediate representations translate to improved downstream value estimation and policy learning, especially under non-stationary conditions.
- Evidence anchors:
  - [abstract] "categorical cross-entropy primarily stem from its ability to mitigate issues inherent to value-based RL, such as noisy targets and non-stationarity"
  - [section] "value-networks trained with cross-entropy losses learn better representations than regression" (linear probing results)
  - [corpus] Weak; while supervised learning benefits from cross-entropy are documented, RL-specific representation benefits are less studied.
- Break condition: If the task is fully deterministic and stationary, the representational benefits might be minimal.

### Mechanism 3
- Claim: Cross-entropy handles non-stationary targets better than MSE during value learning.
- Mechanism: As the policy improves, the target values change magnitude; cross-entropy maintains plasticity and does not suffer from capacity loss as severely as MSE under increasing target magnitudes.
- Core assumption: Non-stationarity in RL is analogous to increasing target magnitudes in supervised regression, where cross-entropy has been shown to retain plasticity.
- Evidence anchors:
  - [abstract] "categorical cross-entropy primarily stem from its ability to mitigate issues inherent to value-based RL, such as noisy targets and non-stationarity"
  - [section] "classification losses retain higher plasticity under non-stationary targets compared to regression" (synthetic experiment)
  - [corpus] Weak; the synthetic experiment provides evidence but real-world RL non-stationarity is more complex.
- Break condition: If the learning process is truly offline with a fixed dataset (no policy updates), the non-stationarity advantage may not apply.

## Foundational Learning

- Concept: Categorical distribution parameterization of Q-values.
  - Why needed here: Enables use of cross-entropy loss and provides bounded outputs/gradients.
  - Quick check question: How does the softmax operator convert logits to probabilities in the categorical Q-network?

- Concept: Bellman operator and temporal difference learning.
  - Why needed here: Understanding how scalar targets are generated for both regression and classification approaches.
  - Quick check question: What is the difference between the Bellman operator in MSE and in C51/Categorical RL?

- Concept: Label smoothing and its effect on generalization.
  - Why needed here: HL-Gauss uses Gaussian smoothing; understanding its benefits helps tune hyperparameters.
  - Quick check question: How does spreading probability mass to neighboring bins in HL-Gauss affect overfitting compared to Two-Hot?

## Architecture Onboarding

- Component map: Input → Convolutional/Transformer backbone → Penultimate layer → Softmax → Categorical distribution over value support → Cross-entropy loss with target distribution
- Critical path: Forward pass through network → Compute logits → Apply softmax → Calculate cross-entropy with target categorical distribution → Backpropagate gradients
- Design tradeoffs: More bins increase resolution but also memory/compute; smoothing parameter affects bias-variance tradeoff
- Failure signatures: Poor performance with too few bins; instability with extreme smoothing; divergence if target distribution not properly computed
- First 3 experiments:
  1. Replace MSE loss with HL-Gauss in a simple DQN setup on a subset of Atari games; compare final scores.
  2. Sweep the smoothing ratio σ/Δz in HL-Gauss; observe impact on performance and stability.
  3. Implement and compare Two-Hot vs HL-Gauss on a deterministic environment to isolate noise robustness effects.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the HL-Gauss method outperform MSE when scaling value-based RL methods beyond the Atari domain to more complex environments?
- Basis in paper: [explicit] The paper shows HL-Gauss outperforms MSE on Atari, robotic manipulation, chess, and Wordle, but it is unclear if this trend holds for even more complex environments.
- Why unresolved: The paper does not test the HL-Gauss method on environments more complex than those mentioned.
- What evidence would resolve it: Testing HL-Gauss on environments with higher dimensional state spaces, longer time horizons, or more complex dynamics would provide evidence for or against its scalability.

### Open Question 2
- Question: Can the HL-Gauss method be effectively combined with other techniques for improving value-based RL, such as distributional RL or model-based RL?
- Basis in paper: [explicit] The paper compares HL-Gauss to distributional RL methods (C51) and shows HL-Gauss outperforms C51 in most cases, but it does not investigate combining HL-Gauss with other techniques.
- Why unresolved: The paper does not explore the potential synergies between HL-Gauss and other RL techniques.
- What evidence would resolve it: Combining HL-Gauss with other RL techniques and evaluating the performance on a variety of tasks would provide evidence for or against the effectiveness of such combinations.

### Open Question 3
- Question: What is the theoretical justification for the improved performance of the HL-Gauss method over MSE in value-based RL?
- Basis in paper: [inferred] The paper provides empirical evidence for the improved performance of HL-Gauss, but it does not offer a theoretical explanation for why this is the case.
- Why unresolved: The paper does not provide a theoretical analysis of the HL-Gauss method.
- What evidence would resolve it: A theoretical analysis of the HL-Gauss method, potentially involving concepts from information theory or statistical learning theory, would provide a deeper understanding of its effectiveness.

## Limitations
- Theoretical grounding for cross-entropy's advantages over MSE remains somewhat loose
- The Gaussian smoothing parameter (sigma/width ratio of 0.75) may require task-specific tuning
- Impact of categorical support discretization on value approximation accuracy warrants further investigation

## Confidence
- Mechanism 1 (Noise robustness): High - well-supported by experiments showing graceful degradation under reward noise
- Mechanism 2 (Representation quality): Medium - linear probing provides evidence but direct comparison of feature quality is limited
- Mechanism 3 (Non-stationarity handling): Medium - synthetic experiments support the claim but real RL non-stationarity is more complex

## Next Checks
1. Implement and test the two other classification methods (Two-Hot and C51) alongside HL-Gauss on a small set of Atari games to verify the relative performance ordering
2. Conduct ablation studies systematically varying the sigma/width ratio in HL-Gauss across multiple environments to identify optimal ranges
3. Design experiments comparing value function accuracy (e.g., mean squared Bellman error) between MSE and cross-entropy methods to quantify representational improvements beyond policy performance