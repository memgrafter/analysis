---
ver: rpa2
title: Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data
  Generation
arxiv_id: '2411.05641'
source_url: https://arxiv.org/abs/2411.05641
tags:
- data
- language
- evidence
- llms
- claim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates large language models (LLMs) for Vietnamese
  fact-checking data generation. It constructs datasets by synthesizing claims from
  multiple evidence sentences and uses LLMs with prompt engineering and supervised
  fine-tuning.
---

# Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation

## Quick Facts
- arXiv ID: 2411.05641
- Source URL: https://arxiv.org/abs/2411.05641
- Reference count: 37
- Primary result: LLMs generate Vietnamese fact-checking data but still fall short of human quality, with significant label-specific performance variations

## Executive Summary
This paper evaluates large language models (LLMs) for Vietnamese fact-checking data generation through a systematic approach involving prompt engineering, supervised fine-tuning, and comprehensive evaluation. The study constructs datasets by synthesizing claims from multiple evidence sentences and assesses generation quality using both manual and automatic methods. Results show that while LLMs can produce usable fact-checking data, they exhibit significant limitations in handling complex reasoning tasks, particularly for Refuted and Not_Enough_Information labels. The research highlights the challenges of low-resource language processing and suggests areas for further refinement in LLM-based data generation methods.

## Method Summary
The study constructs Vietnamese fact-checking datasets by extracting evidence sentences from Wikipedia and generating claims using five LLMs (Vistral, Gemini, Qwen, GPT-3.5, Llama2) across three stages: Uncalibrated, Calibration, and Alignment. Prompt engineering with few-shot learning guides initial claim generation, followed by supervised fine-tuning with LoRA adaptation on the ViWikiFC dataset. Evaluation combines automatic language model assessment (XLM-R, mBERT, PhoBERT) with manual quality scoring across fluency, logical consistency, abstractness, and precision metrics. The process generates 7,286 evidence sentences forming 3,643 data lines, with quality analysis focusing on label-specific performance and linguistic features like new word rates and overlap metrics.

## Key Results
- LLMs achieve only 43.99% good data rate for claim generation, with significant performance gaps compared to human-generated data
- Fine-tuning improves results but doesn't fully bridge the quality gap, particularly for Refuted and Not_Enough_Information labels
- Label-specific creativity varies significantly, with highest new word rates in NEI label and lowest in Supported label
- Vietnamese morphological complexity (multi-syllable words) requires specialized processing but impacts LLM performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Prompt engineering with clear role definition and few-shot examples significantly improves LLM-generated data quality for Vietnamese fact-checking.
- **Mechanism:** The standard prompt structure defines the model's role, explains label semantics (Supported, Refuted, NEI), provides explicit instructions on claim generation, and includes multiple examples. This combination reduces ambiguity and guides the LLM toward generating claims that adhere to fact-checking requirements.
- **Core assumption:** LLMs can effectively learn task patterns and constraints from well-structured prompts without requiring extensive fine-tuning.
- **Evidence anchors:**
  - [abstract] "We develop an automatic data construction process using simple prompt techniques on LLMs"
  - [section] "We apply few-shot learning with clear instructions for each label to ensure accurate task comprehension"
  - [corpus] Weak evidence - related papers focus on different aspects of fact-checking evaluation
- **Break condition:** When the prompt structure becomes too complex or examples don't adequately cover edge cases, leading to inconsistent generation quality.

### Mechanism 2
- **Claim:** Fine-tuning LLMs on domain-specific data (ViWikiFC) improves their ability to generate claims with specific labels, particularly the challenging NEI label.
- **Mechanism:** Supervised fine-tuning with LoRA adaptation allows the model to learn domain-specific patterns while preserving general knowledge. This targeted training helps the LLM better understand the nuances of Vietnamese fact-checking labels.
- **Core assumption:** The pre-trained LLM has sufficient capacity to adapt to the fact-checking task without catastrophic forgetting.
- **Evidence anchors:**
  - [section] "In the alignment stage, we employ Vistral and Qwen using the SFT (Supervised Fine-Tuning) and LoRA (Low-Rank Adaptation) techniques"
  - [section] "The results are generally improved compared to the uncalibrated stage and the calibration stage"
  - [corpus] Weak evidence - limited research on Vietnamese LLM fine-tuning for fact-checking
- **Break condition:** When the fine-tuning dataset is too small or unrepresentative, leading to overfitting or poor generalization.

### Mechanism 3
- **Claim:** Automatic evaluation using pre-trained language models (XLM-R, mBERT, PhoBERT) provides scalable assessment of LLM-generated data quality.
- **Mechanism:** Language models evaluate generated claims by measuring their ability to correctly classify labels in a test set. This approach leverages the LMs' cross-lingual understanding and Vietnamese language capabilities to assess generation quality without manual annotation.
- **Core assumption:** Language models trained on multilingual data can effectively evaluate Vietnamese fact-checking tasks.
- **Evidence anchors:**
  - [abstract] "To evaluate the quality of the data generated by LLMs, we conduct both manual quality assessments and performance evaluations using language models"
  - [section] "We select transformer-based language models for their robust performance across various languages and sentence structures"
  - [corpus] Weak evidence - related papers focus on evaluation methods but not specifically for Vietnamese
- **Break condition:** When the evaluation LMs' performance is poor on human-generated data, indicating limited capability to assess complex Vietnamese language patterns.

## Foundational Learning

- **Concept: Prompt engineering principles**
  - Why needed here: Effective prompts guide LLMs toward desired outputs and reduce generation errors in fact-checking tasks.
  - Quick check question: What are the key components of an effective prompt for structured generation tasks?

- **Concept: Few-shot learning techniques**
  - Why needed here: Limited Vietnamese fact-checking data requires LLMs to learn from minimal examples while maintaining quality.
  - Quick check question: How many examples are typically needed for effective few-shot learning in structured text generation?

- **Concept: Fine-tuning methodologies (SFT and LoRA)**
  - Why needed here: Adapting pre-trained models to specific domains improves their performance on specialized tasks like Vietnamese fact-checking.
  - Quick check question: What are the key differences between full fine-tuning and parameter-efficient methods like LoRA?

## Architecture Onboarding

- **Component map:** Wikipedia evidence extraction -> Prompt generation -> LLM claim generation -> Quality filtering -> Evaluation system
- **Critical path:** Evidence sentence selection from Wikipedia → Standard prompt construction with examples → LLM claim generation across multiple models → Quality filtering and dataset creation → Evaluation using both automatic and manual methods
- **Design tradeoffs:** Prompt complexity vs. generation consistency, Fine-tuning data size vs. model performance, Automatic vs. manual evaluation accuracy, Multilingual vs. monolingual model selection
- **Failure signatures:** High proportion of "wrong cases" in generated data (Llama2 at 43.99% good data rate), Significant performance gap between LLM-generated and human-generated test sets, Poor NEI label generation quality across all models
- **First 3 experiments:** Compare claim generation quality across different prompt structures (basic vs. detailed instructions), Evaluate the impact of few-shot examples on label consistency, Test different fine-tuning approaches (full vs. LoRA) on NEI label performance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Why do LLMs show significant variation in performance across different Vietnamese fact-checking labels (Supported, Refuted, NEI)?
- **Basis in paper:** [explicit] The paper reports unbalanced label-specific creativity, with the highest new word rate in the NEI label and lowest in the Supported label. Models also show different error patterns across labels, particularly struggling with NEI generation.
- **Why unresolved:** While the paper identifies this variation, it doesn't fully explain the underlying reasons for why LLMs perform differently across these specific labels. The connection between label complexity and model performance remains unclear.
- **What evidence would resolve it:** Detailed analysis of model internal states and attention patterns when generating each label type, along with comparison to human reasoning processes for the same labels.

### Open Question 2
- **Question:** How does the Vietnamese language's unique morphological structure affect LLM performance in fact-checking tasks compared to other languages?
- **Basis in paper:** [explicit] The paper notes that Vietnamese words are often composed of multiple syllables, requiring specialized word segmentation using VnCoreNLP. This differs from languages where syllables typically correspond to distinct words.
- **Why unresolved:** The paper doesn't investigate how this morphological difference specifically impacts LLM performance or whether models trained on other languages face additional challenges with Vietnamese.
- **What evidence would resolve it:** Comparative experiments with models trained specifically on Vietnamese morphology versus standard multilingual models, measuring performance differences in fact-checking tasks.

### Open Question 3
- **Question:** What are the long-term implications of using synthetic data for training Vietnamese language models, given the observed performance gaps?
- **Basis in paper:** [inferred] The paper shows that while LLMs can generate data at lower cost than human annotation, there remains a significant quality gap. Fine-tuning improves but doesn't fully bridge this gap.
- **Why unresolved:** The paper focuses on immediate evaluation but doesn't address how continued use of synthetic data might affect model development trajectories or whether the quality gap will persist or narrow over time.
- **What evidence would resolve it:** Longitudinal studies tracking model performance over multiple generations of synthetic data training, measuring convergence with human-level performance.

## Limitations
- Significant performance gap between LLM-generated and human-generated data remains unresolved
- Persistent errors in Refuted and Not_Enough_Information label generation across all models
- Limited Vietnamese language resources constrain evaluation scope and model adaptation

## Confidence

**Confidence: Low** - The paper demonstrates significant challenges in LLM-generated fact-checking data, with Llama2 achieving only 43.99% good data rate and substantial performance gaps compared to human-generated data. The study acknowledges that "LLMs still fall short of human-generated data" and face "challenges in synthesizing multi-sentence information." The limited Vietnamese language resources and the complexity of fact-checking tasks create inherent constraints on LLM performance.

**Confidence: Medium** - The effectiveness of prompt engineering and fine-tuning techniques shows mixed results. While the paper reports improvements from uncalibrated to alignment stages, the gains are modest and label-specific. The study notes "unbalanced label-specific creativity" and persistent errors particularly in Refuted and Not_Enough_Information labels, suggesting that current approaches have fundamental limitations in handling complex reasoning tasks.

**Confidence: Medium** - The evaluation methodology combining automatic language model assessment with manual annotation provides reasonable validation, but the study acknowledges limitations in evaluation scope. The automatic evaluation relies on pre-trained models that may not fully capture the nuances of Vietnamese fact-checking, and manual evaluation covers only a subset of generated data.

## Next Checks

1. **Cross-model generalization test:** Evaluate whether improvements from fine-tuning on ViWikiFC generalize to completely unseen Vietnamese fact-checking scenarios, using additional Vietnamese news articles and social media content beyond the Wikipedia-based dataset.

2. **Human-in-the-loop refinement study:** Implement iterative feedback loops where human experts review and correct LLM-generated claims, then measure whether this improves subsequent generations' quality, particularly for the problematic NEI and Refuted labels.

3. **Multilingual transfer validation:** Test whether fine-tuned Vietnamese LLMs can effectively generate fact-checking data for related Southeast Asian languages (Thai, Indonesian) with minimal additional training, assessing the scalability of the approach to low-resource language families.