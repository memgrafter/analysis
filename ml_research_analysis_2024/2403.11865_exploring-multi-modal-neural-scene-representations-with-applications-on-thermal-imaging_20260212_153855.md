---
ver: rpa2
title: Exploring Multi-modal Neural Scene Representations With Applications on Thermal
  Imaging
arxiv_id: '2403.11865'
source_url: https://arxiv.org/abs/2403.11865
tags:
- thermal
- images
- scene
- neural
- multi-modal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper systematically compares four strategies for integrating
  non-RGB modalities into neural scene representations: training from scratch, fine-tuning,
  adding a second branch, and adding a separate component. The authors use thermal
  imaging as a challenging second modality due to its distinct radiosity properties
  compared to RGB.'
---

# Exploring Multi-modal Neural Scene Representations With Applications on Thermal Imaging

## Quick Facts
- arXiv ID: 2403.11865
- Source URL: https://arxiv.org/abs/2403.11865
- Authors: Mert Ã–zer; Maximilian Weiherer; Martin Hundhausen; Bernhard Egger
- Reference count: 40
- Key outcome: Adding a second branch to NeRF (RGB-X) performs best for novel view synthesis on thermal images while maintaining strong RGB reconstruction quality.

## Executive Summary
This paper systematically compares four strategies for integrating non-RGB modalities into neural scene representations, using thermal imaging as a challenging test case. The authors evaluate training from scratch, fine-tuning, adding a second branch, and adding a separate component on a newly captured ThermalMix dataset containing aligned RGB and thermal images. Results show that the RGB-X strategy, which adds a second branch to the NeRF color network, consistently outperforms other approaches for thermal image reconstruction while maintaining competitive RGB quality.

## Method Summary
The study evaluates four strategies for incorporating thermal imaging into neural radiance fields using Instant-NGP as the base architecture. The strategies include: training from scratch separately for each modality, fine-tuning a pre-trained RGB model on thermal data, adding a second branch to the color network for thermal prediction (RGB-X), and adding a separate component for thermal prediction with restricted backpropagation. All methods use cross-modality calibrated data from the ThermalMix dataset, with camera poses derived from RGB images for thermal training.

## Key Results
- RGB-X strategy achieves highest PSNR and SSIM for novel view synthesis on thermal images
- RGB-X maintains competitive RGB reconstruction quality while excelling at thermal reconstruction
- Results generalize to near-infrared and depth modalities, with RGB-X consistently outperforming other strategies

## Why This Works (Mechanism)

### Mechanism 1
Adding a second branch to the NeRF color network (RGB-X) outperforms all other strategies in thermal image reconstruction quality while maintaining competitive RGB quality. By adding a second branch, the density network receives gradients from both RGB and thermal outputs during training. This encourages the density network to implicitly balance information from both modalities, effectively integrating their respective scene geometries. The RGB-derived density serves as a strong prior for the low-texture, ambiguous thermal background, while the thermal branch captures temperature-specific details.

### Mechanism 2
Training from scratch on thermal images using only thermal camera poses (derived from RGB) performs poorly due to unreliable pose estimation and ambiguous background textures. When training from scratch on thermal images, the method relies on camera poses computed from the corresponding RGB images. However, thermal images have extremely low texture and feature-less regions, making pose estimation unreliable. Additionally, the static, uniform background in thermal images creates ambiguities in 360-degree scenes, where the network cannot distinguish between different viewing angles.

### Mechanism 3
Adding a separate component (SC) for thermal prediction maintains strong RGB reconstruction quality because it doesn't interfere with RGB densities, but performs worse on thermal reconstruction than RGB-X because it cannot leverage RGB geometry information. The separate component strategy adds an additional network that only predicts thermal values but restricts backpropagation to the density network during training. This preserves the RGB density network's integrity for RGB reconstruction but prevents the thermal network from benefiting from RGB geometry information.

## Foundational Learning

- Concept: Neural Radiance Fields (NeRF) and volume rendering
  - Why needed here: The entire paper builds on NeRF as the base scene representation. Understanding how NeRF encodes scenes as continuous radiance fields and uses volume rendering to synthesize novel views is fundamental to grasping the proposed multi-modal strategies.
  - Quick check question: What are the two main components that NeRF outputs for each 3D point, and how are they used in volume rendering to compute the final pixel color?

- Concept: Multi-modal learning and cross-modality alignment
  - Why needed here: The paper addresses how to integrate a second modality (thermal imaging) into NeRF. Understanding the challenges of multi-modal learning, including cross-modality calibration and alignment, is essential for appreciating why certain strategies work better than others.
  - Quick check question: Why is cross-modality calibration particularly challenging for RGB and thermal imaging compared to other modality pairs?

- Concept: Loss functions for different modalities
  - Why needed here: Different modalities require different loss functions. The paper uses L2 loss for RGB color reconstruction and a similar loss for thermal temperature values. Understanding how to design appropriate loss functions for different output modalities is crucial for implementing the proposed strategies.
  - Quick check question: How does the loss function for thermal images differ from the standard RGB loss in NeRF, and why is this modification necessary?

## Architecture Onboarding

- Component map:
  - Base model: Instant-NGP with density network (3 FC layers, 64 hidden dims) and color network (3 FC layers, 32 hidden dims)
  - Strategy-specific modifications:
    - TS: Two separate models, one for RGB, one for thermal
    - FT: Pre-train on RGB, fine-tune on thermal with shared weights
    - RGB-X: Add second branch to color network for thermal prediction, shared density network
    - SC: Add separate thermal prediction network, restrict backpropagation to density network
  - Input encoding: Multiresolution hash encoding for coordinates
  - Training components: Adam optimizer, learning rate 0.01, batch size 4096

- Critical path: Training loop for each strategy
  1. Load mini-batch of rays and corresponding RGB/thermal pixel values
  2. Sample points along rays, encode coordinates with hash encoding
  3. Compute densities and colors using appropriate network architecture
  4. Apply volume rendering to compute predicted pixel values
  5. Calculate modality-specific loss (RGB loss, thermal loss, or both)
  6. Backpropagate gradients through appropriate networks
  7. Update network parameters with optimizer

- Design tradeoffs:
  - Shared vs. separate density networks: Shared densities (RGB-X) allow information fusion but risk interference; separate densities (SC) preserve modality independence but lose integration benefits
  - Single vs. dual models: Single models (RGB-X, SC) are more efficient but may compromise quality; dual models (TS, FT) offer flexibility but increase memory/computation
  - Cross-modality calibration: Offline calibration provides perfect alignment but limits application to uncalibrated data; online calibration methods would be more general but add complexity

- Failure signatures:
  - Poor thermal reconstruction: Likely due to inadequate geometry representation in density network or insufficient thermal-specific features
  - Degraded RGB quality: Indicates interference between modalities in shared components or improper loss balancing
  - Training instability: May result from conflicting gradients between RGB and thermal branches or inappropriate learning rates
  - Floaters in 360-degree scenes: Suggests inability to distinguish between similar thermal backgrounds at different viewing angles

- First 3 experiments:
  1. Implement and train the baseline TS strategy on a simple forward-facing scene to verify basic functionality and establish performance baseline
  2. Implement RGB-X strategy and compare thermal reconstruction quality against TS on the same scene to validate the core hypothesis about branch integration
  3. Implement SC strategy and evaluate both thermal and RGB reconstruction quality to understand the tradeoff between modality preservation and integration

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of modality impact the effectiveness of different strategies for incorporating a second modality into NeRFs? The paper systematically compares four strategies for incorporating non-RGB modalities into NeRFs, using thermal imaging as a challenging second modality, but only provides results for thermal imaging, near-infrared images, and depth maps without exploring other potential modalities or providing a comprehensive analysis of how modality choice affects strategy effectiveness.

### Open Question 2
What is the optimal way to balance the influence of RGB and thermal densities in the RGB-X strategy? The paper notes that RGB-X performs best for novel view synthesis on thermal images while maintaining strong RGB reconstruction quality, suggesting a balance between RGB and thermal information, but does not provide specific guidelines or methods for optimizing this balance.

### Open Question 3
How can the proposed strategies be extended to handle uncalibrated, in-the-wild images? The paper mentions that offline cross-modality calibration provides almost perfect alignments between RGB and thermal images, but it prevents building NeRFs of uncalibrated, in-the-wild images, and does not provide solutions or methods for handling uncalibrated images or integrating learning-based calibration methods.

## Limitations
- Requires precise cross-modality calibration between RGB and thermal sensors, limiting applicability to controlled scenarios
- Evaluation focuses on simple forward-facing scenes with single objects, not complex real-world environments
- Relies on RGB-derived camera poses for thermal training without verifying thermal pose accuracy

## Confidence
- High confidence in relative performance ranking of strategies for the ThermalMix dataset
- Medium confidence in generalizability of findings to other multi-modal scenarios
- Low confidence in practical deployment feasibility due to calibration requirements

## Next Checks
1. Implement quantitative evaluation of thermal pose accuracy by comparing reprojection errors of thermal features detected using specialized thermal-specific methods versus RGB-derived poses
2. Evaluate all four strategies on scenes with multiple objects, occlusions, and cluttered backgrounds to assess performance degradation and identify strategy robustness limits
3. Implement an online calibration method or test strategies with synthetic misalignment to quantify performance sensitivity to calibration errors in practical applications