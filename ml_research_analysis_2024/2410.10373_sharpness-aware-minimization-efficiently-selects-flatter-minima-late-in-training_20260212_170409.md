---
ver: rpa2
title: Sharpness-Aware Minimization Efficiently Selects Flatter Minima Late in Training
arxiv_id: '2410.10373'
source_url: https://arxiv.org/abs/2410.10373
tags:
- training
- generalization
- sharpness
- learning
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Sharpness-Aware Minimization (SAM) efficiently selects flatter
  minima over Stochastic Gradient Descent (SGD) when applied late in training, even
  with just a few epochs of SAM after initial SGD training. This late-phase SAM achieves
  comparable generalization and solution sharpness to full SAM training.
---

# Sharpness-Aware Minimization Efficiently Selects Flatter Minima Late in Training

## Quick Facts
- arXiv ID: 2410.10373
- Source URL: https://arxiv.org/abs/2410.10373
- Authors: Zhanpeng Zhou; Mingze Wang; Yuchen Mao; Bingrui Li; Junchi Yan
- Reference count: 40
- Key outcome: SAM efficiently selects flatter minima over SGD when applied late in training, even with just a few epochs of SAM after initial SGD training.

## Executive Summary
This paper demonstrates that Sharpness-Aware Minimization (SAM) can efficiently select flatter minima when applied late in training, achieving comparable generalization and solution sharpness to full SAM training with minimal computational overhead. The authors show that switching from SGD to SAM for just the final few epochs yields results similar to training with SAM from the start. Theoretical analysis reveals a two-phase learning dynamics where SAM first escapes sharp minima found by SGD exponentially fast, then rapidly converges to flatter minima within the same valley. These findings extend beyond SAM to Adversarial Training, suggesting a general principle for efficient selection of flatter/robust minima.

## Method Summary
The method involves switching from SGD to SAM at various epochs during training to assess the impact on late-phase optimization. The switching method applies SGD initially and SAM later, with experiments conducted on CIFAR-10 and CIFAR-100 using standard architectures like WideResNet, ResNet, and VGG. The objective is to measure generalization performance (test error, test loss) and solution sharpness (Hessian spectral norm). The theoretical analysis uses linear stability conditions to explain why SAM can escape sharp minima found by SGD and select flatter minima.

## Key Results
- SAM applied for just a few epochs late in training achieves comparable generalization and sharpness to full SAM training
- Theoretical analysis reveals SAM escapes sharp minima found by SGD exponentially fast, then converges to flatter minima within the same valley
- The findings extend to Adversarial Training, showing it efficiently finds robust minima when applied late in training

## Why This Works (Mechanism)

### Mechanism 1
SAM efficiently escapes sharp minima found by SGD exponentially fast when applied late in training. SAM's inner maximization step moves parameters toward regions of higher loss, allowing escape from sharp minima that SGD cannot leave due to local stability. This relies on the gradient noise structure having an alignment property where the covariance is proportional to the loss times the Fisher matrix. If the gradient noise alignment assumption fails or the learning rate is too small, the escape mechanism may not function efficiently.

### Mechanism 2
SAM selects flatter minima over SGD by imposing stricter sharpness requirements. The stability condition for SAM includes an additional term involving the perturbation radius ρ, making only flatter minima stable compared to SGD's condition. This assumes the linearized model near global minima accurately captures the local dynamics. If the perturbation radius ρ is set too small or the landscape is not sufficiently smooth, the flatter-minima selection may not occur.

### Mechanism 3
SAM remains within the current valley during escape due to sub-quadratic landscape properties. In high-loss regions, the landscape grows slower than quadratic, making these regions flatter and preventing SAM from escaping the valley. This assumes the loss landscape exhibits sub-quadratic growth in high-loss regions. If the landscape is quadratic or super-quadratic in high-loss regions, SAM may escape the valley.

## Foundational Learning

- Concept: Sharpness-aware optimization and loss landscape geometry
  - Why needed here: Understanding how SAM modifies the optimization objective to prefer flatter minima requires knowledge of loss landscape properties and sharpness measures
  - Quick check question: What is the relationship between sharpness (as measured by Hessian eigenvalues) and generalization in neural networks?

- Concept: Linear stability analysis of optimization algorithms
  - Why needed here: The theoretical analysis relies on determining which minima are linearly stable for SAM versus SGD
  - Quick check question: How does the stability condition for an optimization algorithm determine which minima it can converge to?

- Concept: Sub-quadratic landscape properties and Edge of Stability phenomena
  - Why needed here: The analysis of SAM's valley retention behavior requires understanding how loss landscapes behave in high-loss regions
  - Quick check question: What distinguishes a sub-quadratic landscape from a quadratic one, and why does this matter for optimization?

## Architecture Onboarding

- Component map: Model initialization -> SGD training -> SAM switching mechanism -> Sharpness measurement -> Generalization evaluation
- Critical path: 1) Initialize model with SGD, 2) Switch to SAM at specified epoch, 3) Measure generalization and sharpness, 4) Analyze convergence dynamics
- Design tradeoffs: Early-phase SAM vs late-phase SAM effectiveness, perturbation radius selection for SAM, computational cost of SAM's inner loop
- Failure signatures: If SAM doesn't improve generalization, check perturbation radius and learning rate; if SAM escapes valleys, verify sub-quadratic landscape assumption
- First 3 experiments:
  1. Implement the switching method on a simple architecture (VGG-16 on CIFAR-10) to verify late-phase SAM effectiveness
  2. Measure sharpness evolution during training to confirm the two-phase dynamics
  3. Test different perturbation radii to understand their impact on final solution sharpness

## Open Questions the Paper Calls Out

### Open Question 1
Does the late-phase efficiency of SAM generalize to other sharpness-aware optimization algorithms beyond SAM, ASAM, and USAM? The authors extend their findings to Adversarial Training (AT) and suggest generalizing to other optimization algorithms as a future direction. The paper only demonstrates late-phase efficiency for SAM, ASAM, USAM, and AT, leaving open whether this phenomenon applies to other sharpness-aware methods. Experimental validation showing that switching to other sharpness-aware optimizers late in training yields comparable generalization to full training with those methods would resolve this.

### Open Question 2
What is the precise mechanism by which early-phase SAM training influences the optimization trajectory, despite minimal impact on final solution sharpness and generalization? While the paper conjectures that late-phase optimization dominates final solution properties, it does not explain what specific role early-phase SAM plays in the training dynamics. Analysis of how early-phase SAM affects loss landscape topology, optimization path stability, or gradient noise characteristics during subsequent SGD training would resolve this.

### Open Question 3
How do the theoretical assumptions about gradient noise alignment and sub-quadratic landscape structure apply to real neural network training? The theoretical analysis relies on gradient noise alignment (Assumption 4.1) and sub-quadratic landscape (Definition 4.2), which are justified by recent works but may not perfectly capture real neural network behavior. Comprehensive empirical studies measuring gradient noise covariance alignment and loss landscape curvature across diverse neural network settings to verify theoretical assumptions would resolve this.

## Limitations

- The analysis assumes quadratic behavior near minima and sub-quadratic growth in high-loss regions, which may not hold for all architectures
- The perturbation radius ρ is treated as a fixed hyperparameter, but its optimal value likely depends on the specific training dynamics
- The switching method's effectiveness across diverse architectures and tasks requires further validation

## Confidence

- High confidence in the empirical observation that late-phase SAM achieves comparable results to full SAM training
- Medium confidence in the theoretical mechanism explaining exponential escape from sharp minima, due to idealized landscape assumptions
- Medium confidence in the valley retention property, as this depends on specific sub-quadratic landscape conditions that may not hold universally

## Next Checks

1. Test the switching method across different architecture families (Transformers, MLPs) to verify generalizability
2. Conduct ablation studies on perturbation radius ρ to determine its impact on escape dynamics and final solution quality
3. Analyze gradient noise structure empirically to verify the alignment assumption used in theoretical analysis