---
ver: rpa2
title: Dynamic planning in hierarchical active inference
arxiv_id: '2402.11658'
source_url: https://arxiv.org/abs/2402.11658
tags:
- inference
- hidden
- agent
- active
- states
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how to perform dynamic planning in active inference
  by combining discrete decision-making with continuous motor control. The authors
  propose a hybrid approach where discrete hidden causes infer the most likely intentions
  over time, while continuous hidden states generate and track dynamic trajectories.
---

# Dynamic planning in hierarchical active inference

## Quick Facts
- arXiv ID: 2402.11658
- Source URL: https://arxiv.org/abs/2402.11658
- Reference count: 40
- Key outcome: Demonstrates dynamic planning combining discrete decision-making with continuous motor control through hierarchical active inference, enabling flexible tool use and multi-agent interaction.

## Executive Summary
This paper presents a hybrid active inference framework that integrates discrete decision-making with continuous motor control for dynamic planning in complex tasks. The authors propose a hierarchical architecture where discrete hidden causes infer intentions over time while continuous hidden states generate and track dynamic trajectories. Through simulations of reaching, tracking, tool use, and multi-agent interaction tasks, the framework demonstrates how hierarchical representations can flexibly encode object affordances and body schema changes, enabling online replanning in dynamic environments.

## Method Summary
The method combines discrete decision-making with continuous motor control through a hybrid active inference approach. A discrete POMDP model at the top level generates policies via expected free energy minimization, which are then used to generate hidden causes for each hierarchical IE module. These modules contain continuous hidden states representing intrinsic and extrinsic reference frames, connected through forward kinematics. The framework uses Bayesian model reduction to switch between discrete intentions by accumulating continuous prediction errors over time T, allowing the agent to dynamically update its beliefs and generate appropriate motor trajectories.

## Key Results
- Successfully demonstrated reaching, tracking, tool use, and multi-agent interaction tasks using the hybrid active inference framework
- Showed flexible encoding of object affordances and body schema changes through hierarchical representations
- Enabled online replanning in dynamic environments by integrating evidence accumulation over continuous periods with discrete state inference
- Made code and data publicly available for reproduction and extension

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hybrid units can dynamically switch intentions by accumulating evidence over continuous time and then selecting the most likely intention via Bayesian model comparison.
- Mechanism: Hidden causes are modeled as a categorical distribution over discrete intentions. At each time step, continuous hidden states generate prediction errors for each intention. These errors are accumulated over fixed time T to produce log-evidence scores. A softmax over (prior surprise + accumulated evidence) yields a probability distribution over intentions, which is then used to weight trajectory priors for the next period.
- Core assumption: Accumulation of continuous prediction errors over time T is a sufficient statistic for selecting among discrete intentions.
- Evidence anchors:
  - [abstract] "They demonstrate this framework through simulations of increasingly complex tasks—reaching, tracking, tool use, and multi-agent interaction—showing how hierarchical representations can flexibly encode object affordances and body schema changes."
  - [section] "Conversion between discrete hidden causes to continuous hidden states (and vice versa) is done via Bayesian model reduction... we define M reduced prior probability distributions and a full prior model..."
  - [corpus] Weak anchor: The paper does not explicitly compare this evidence accumulation to other switching methods.
- Break condition: If time T is too short, evidence accumulation will be noisy and intention switching unreliable; if too long, the agent will react too slowly to environmental changes.

### Mechanism 2
- Claim: Hierarchical IE modules can represent both self and external entities (objects, other agents) in parallel reference frames, enabling flexible body schema adaptation and affordance-based manipulation.
- Mechanism: Each IE module encodes an extrinsic reference frame via forward kinematics from intrinsic joint angles. Multiple factorizations of hidden states and likelihoods allow parallel representations of self, objects, and others. The extrinsic prediction error flows through the hierarchy, inferring potential body configurations suitable for interaction with each entity.
- Core assumption: Maintaining parallel representations in extrinsic coordinates is sufficient for the agent to infer affordance-based configurations.
- Evidence anchors:
  - [abstract] "They demonstrate this framework through simulations of increasingly complex tasks—reaching, tracking, tool use, and multi-agent interaction—showing how hierarchical representations can flexibly encode object affordances and body schema changes."
  - [section] "For the self, this has a simple explanation, i.e., it just generates, one after the other, the positions of every segment of the kinematic chain depending on its joint angles. Concerning an object, we could encode its Cartesian position by attaching its visual observation to a second factor of the hidden states at a specific level."
  - [corpus] Weak anchor: The paper does not empirically compare parallel vs. serial representation schemes.
- Break condition: If the hierarchy is too deep, inference time and computational cost increase; if too shallow, the agent cannot capture complex causal relationships.

### Mechanism 3
- Claim: Discrete planning at the top level can synchronize and guide continuous motor trajectories across multiple IE modules, enabling complex multi-step behaviors like tool use.
- Mechanism: A discrete POMDP model generates policies (sequences of abstract actions) by minimizing expected free energy. Policies are used to generate hidden causes for each IE module via likelihood matrices. The IE modules then generate continuous trajectories conditioned on these discrete causes. Evidence from continuous trajectories is fed back to update discrete beliefs, allowing online replanning.
- Core assumption: The discrete policies can effectively encode and coordinate the continuous trajectories needed for complex behaviors.
- Evidence anchors:
  - [abstract] "The method enables online replanning in dynamic environments by integrating evidence accumulation over continuous periods with discrete state inference, allowing the agent to switch between subgoals based on sensory input."
  - [section] "Having replaced the continuous hidden causes of Figure 5a with discrete hidden causes in Figure 13c, we can now endow the agent with planning capabilities through a discrete model composed of the following distributions..."
  - [corpus] Weak anchor: The paper does not benchmark this hierarchical planning against purely continuous or purely discrete baselines.
- Break condition: If the discrete state space is too coarse, the agent cannot represent nuanced distinctions; if too fine, policy evaluation becomes intractable.

## Foundational Learning

- Concept: Variational free energy minimization
  - Why needed here: It provides the unifying objective that drives both perception and action in active inference, enabling the agent to balance accuracy and complexity.
  - Quick check question: What two objectives does minimizing variational free energy achieve simultaneously?

- Concept: Bayesian model reduction
  - Why needed here: It allows the agent to switch between discrete intentions by comparing reduced models against the full model's posterior.
  - Quick check question: How does Bayesian model reduction avoid recomputing the full posterior when comparing discrete intentions?

- Concept: Forward-inverse kinematics decomposition
  - Why needed here: It enables the agent to plan in extrinsic space while controlling in intrinsic space, avoiding duplicated computations and allowing constraints in both domains.
  - Quick check question: Why does backpropagating the extrinsic prediction error through the Jacobian yield the correct intrinsic state?

## Architecture Onboarding

- Component map: Discrete POMDP model -> Hybrid units (continuous hidden states + categorical hidden causes) -> IE modules (forward kinematics) -> Likelihood functions (observations) -> Dynamics functions (trajectories)

- Critical path:
  1. Discrete model selects policy → generates hidden causes for each IE module
  2. IE modules generate trajectories via forward kinematics and dynamics
  3. Continuous prediction errors accumulate over time T
  4. Bayesian model comparison selects most likely intention
  5. New hidden causes generated → repeat

- Design tradeoffs:
  - Continuous-only: fast but inflexible, cannot switch intentions dynamically
  - Discrete-only: flexible but slow, cannot generate smooth continuous trajectories
  - Hybrid: balances flexibility and speed but adds complexity of evidence accumulation and model reduction

- Failure signatures:
  - Agent gets stuck in local minima: check dynamics precisions and trajectory priors
  - Intention switching too slow: reduce accumulation time T or increase dynamics precision
  - Kinematic inference fails: check Jacobian computations and extrinsic prediction error propagation

- First 3 experiments:
  1. Single DoF reaching with static target: verify that attractor dynamics generate smooth reaching trajectories
  2. Two-object tracking with intention switching: verify that evidence accumulation correctly selects between object intentions
  3. Simple tool use (stick + ball): verify that parallel body schema representations enable tool manipulation

## Open Questions the Paper Calls Out

- Question: How can deep hierarchical active inference models effectively learn dynamic planning in real-world environments without pre-specified structure?
  - Basis in paper: [explicit] The paper identifies this as a critical open challenge, noting that current implementations rely on pre-defined generative models and hardcoded dynamics functions, which raises concerns about biological plausibility and adaptability.
  - Why unresolved: While the paper demonstrates how discrete and continuous representations can be combined for dynamic planning, it does not address how the hierarchical structure itself could be learned from experience rather than being specified a priori.
  - What evidence would resolve it: Empirical demonstrations of active inference agents that can autonomously discover and adapt their hierarchical representations through interaction with the environment, without explicit programming of the structure.

- Question: What is the optimal balance between discrete and continuous representations in hybrid active inference models for different types of tasks?
  - Basis in paper: [inferred] The paper explores hybrid models combining discrete decision-making with continuous motor control, but acknowledges that the choice between representations depends on model evidence and task characteristics, suggesting this balance needs further investigation.
  - Why unresolved: The paper presents various design choices and demonstrates their utility in different scenarios, but does not provide a systematic framework for determining when to use discrete versus continuous representations or how to optimally combine them.
  - What evidence would resolve it: Comparative studies across diverse task domains showing how different balances between discrete and continuous representations affect performance, learning efficiency, and adaptability.

- Question: How does motor skill learning occur in active inference frameworks, particularly regarding the emergence of flexible intentions from repeated task exposure?
  - Basis in paper: [explicit] The paper discusses how flexible intentions in the continuous framework could be compared to an advanced stage of motor skill learning, but notes that how such intentions emerge during repeated exposure to the same task remains an open question.
  - Why unresolved: While the paper demonstrates how flexible intentions can be encoded in the model, it does not explain the learning mechanisms by which these intentions develop through practice or how the agent learns to score which intentions are appropriate for specific contexts.
  - What evidence would resolve it: Longitudinal studies tracking how active inference agents develop more sophisticated intentions through repeated task performance, showing the emergence of habitual behaviors and the optimization of dynamics precisions.

## Limitations

- The paper does not provide quantitative comparisons with baselines or ablation studies that would validate the necessity of each architectural component
- Simulations demonstrate capability but lack metrics for robustness or generalization across task variations
- The claim of biological plausibility remains largely philosophical without comparative neuroscientific validation

## Confidence

- Hybrid switching mechanism: Medium - well-defined mathematically but not empirically validated against alternatives
- Hierarchical affordance representation: Low - conceptually plausible but lacking direct evidence of superiority over simpler architectures
- Overall framework: Medium - demonstrates capability in specific tasks but scalability and generalizability remain uncertain

## Next Checks

1. Implement an ablation study removing evidence accumulation to test whether intention switching degrades without this mechanism
2. Compare hierarchical IE performance against a flat architecture on the same tool-use task to quantify representational benefits
3. Add noise to sensory inputs and measure robustness of both the reaching and tool-use behaviors across multiple random seeds