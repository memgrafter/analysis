---
ver: rpa2
title: Controllable Image Synthesis of Industrial Data Using Stable Diffusion
arxiv_id: '2401.03152'
source_url: https://arxiv.org/abs/2401.03152
tags:
- data
- image
- images
- diffusion
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of limited annotated industrial
  datasets for training supervised defect detection and segmentation models. The proposed
  method adapts a pre-trained Stable Diffusion model to learn new industrial concepts
  and generate self-annotated synthetic data.
---

# Controllable Image Synthesis of Industrial Data Using Stable Diffusion

## Quick Facts
- arXiv ID: 2401.03152
- Source URL: https://arxiv.org/abs/2401.03152
- Authors: Gabriele Valvano; Antonino Agostino; Giovanni De Magistris; Antonino Graziano; Giacomo Veneri
- Reference count: 40
- Key outcome: Proposed method achieves 79.9% IoU using only 10% of real data, close to 80.9% IoU with full dataset for industrial defect instance segmentation

## Executive Summary
This work addresses the challenge of limited annotated industrial datasets for training defect detection and segmentation models. The authors propose a two-phase approach that adapts a pre-trained Stable Diffusion model to generate self-annotated synthetic industrial defect images. The method involves first learning new industrial concepts using DreamBooth, then conditioning the generation process with HyperNetworks and topological drivers. When evaluated on turbine borescope images, the approach significantly improves instance segmentation performance, especially when real data is scarce, while maintaining high-quality synthetic data as measured by FID scores.

## Method Summary
The proposed method adapts Stable Diffusion to generate synthetic industrial defect images through a two-phase process. Phase 1 uses DreamBooth to fine-tune the pre-trained model on small amounts of annotated industrial data, learning new defect concepts while preserving the general image prior. Phase 2 trains HyperNetworks to condition the generation process based on topological drivers that encode defect geometry and location. The resulting model generates synthetic self-annotated data that can supplement limited real datasets for training downstream instance segmentation models like Mask R-CNN.

## Key Results
- Using only 10% of real data, achieved 79.9% IoU compared to 80.9% IoU with full dataset
- FID scores demonstrate high quality of synthetic data generation
- Ablation study confirms importance of learning concept before conditioning
- Significant performance increases observed when available data is small

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method works because it adapts a pre-trained general-purpose diffusion model to learn new industrial concepts before conditioning the generation process.
- Mechanism: DreamBooth is used to inject knowledge of the new industrial concept into the Stable Diffusion model, preserving the prior knowledge about generic image appearance while adapting to the specific data distribution of industrial images.
- Core assumption: The pre-trained Stable Diffusion model has learned a powerful image prior that can be leveraged for industrial data generation with appropriate fine-tuning.
- Evidence anchors:
  - [abstract]: "we exploit a generic image prior learned by a pre-trained high-capacity model, Stable Diffusion [29]; then, we inject new knowledge about the concept of interest"
  - [section]: "We use DreamBooth to make our model capable of learning new concepts... The model could learn new concepts using LoRA, Textual Inversion, or other approaches"
  - [corpus]: Weak evidence - related papers focus on diffusion models for image generation but don't specifically address industrial data adaptation
- Break condition: If the industrial data distribution is too far from natural images, the learned prior may not transfer effectively, requiring more extensive fine-tuning or a different approach.

### Mechanism 2
- Claim: The method achieves controllable generation by using HyperNetworks to condition the diffusion model on topological drivers that encode defect geometry and location.
- Mechanism: A HyperNetwork is trained to influence the weights of the Stable Diffusion model based on input topological drivers, which contain coarse topological information and defect masks.
- Core assumption: The topological drivers provide sufficient conditioning information to guide the generation process while maintaining flexibility for realistic variations.
- Evidence anchors:
  - [abstract]: "we force it to learn to condition the generative process, producing industrial images that satisfy well-defined topological characteristics and show defects with a given geometry and location"
  - [section]: "We control the synthesis process via HyperNetworks... As conditioning mechanism we use coarse geometrical drivers and a defect mask"
  - [corpus]: Weak evidence - related papers mention HyperNetworks for image generation but don't specifically address industrial defect generation with topological drivers
- Break condition: If the topological drivers are too restrictive or too vague, the generated images may lack diversity or fail to match the desired defect characteristics.

### Mechanism 3
- Claim: The method generates high-quality synthetic data that can improve downstream instance segmentation performance, especially when real data is limited.
- Mechanism: The self-annotated synthetic data generated by the conditioned diffusion model provides additional training examples with known defect locations and geometries, supplementing the limited real data.
- Core assumption: The synthetic data distribution is similar enough to the real data distribution to provide meaningful training signal for the downstream model.
- Evidence anchors:
  - [abstract]: "When the available data is small, we observe considerable performance increase under several metrics, showing the method's potential in production environments"
  - [section]: "When using only 10% of the real data, the method achieves 79.9% IoU, close to using the full dataset (80.9% IoU)"
  - [corpus]: Weak evidence - related papers focus on diffusion-based image generation but don't specifically address the impact on industrial instance segmentation performance
- Break condition: If the synthetic data quality is poor or the distribution mismatch is significant, the downstream model performance may degrade or fail to improve.

## Foundational Learning

- Concept: Diffusion Models
  - Why needed here: The method is built on denoising diffusion probabilistic models (DDPMs) and latent diffusion models (LDMs), which form the basis for the generative approach.
  - Quick check question: What is the main difference between DDPMs and LDMs, and why did the authors choose LDMs for this application?

- Concept: DreamBooth
  - Why needed here: DreamBooth is used to adapt the pre-trained Stable Diffusion model to learn new industrial concepts while preserving the learned image prior.
  - Quick check question: How does DreamBooth prevent catastrophic forgetting when fine-tuning the model on new concepts?

- Concept: HyperNetworks
  - Why needed here: HyperNetworks are used to condition the generation process based on topological drivers, allowing for controllable generation of images with specific defect characteristics.
  - Quick check question: What is the role of the HyperNetwork in this architecture, and how does it differ from simply modifying the input prompt?

## Architecture Onboarding

- Component map: Pre-trained Stable Diffusion model -> DreamBooth fine-tuning -> HyperNetwork training -> Topological driver processing -> Synthetic data generation -> Downstream segmentation model
- Critical path: 1. Fine-tune Stable Diffusion using DreamBooth on industrial concept data; 2. Train HyperNetwork to condition generation on topological drivers; 3. Generate synthetic data using conditioned model; 4. Train downstream instance segmentation model on synthetic + real data
- Design tradeoffs:
  - Using a pre-trained model vs. training from scratch: Faster adaptation but potential distribution mismatch
  - Coarse vs. detailed topological drivers: Flexibility vs. control over generated defects
  - Number of synthetic samples vs. quality: More data vs. potential overfitting to synthetic distribution
- Failure signatures:
  - Poor synthetic data quality: Low FID score, unrealistic defects, or artifacts
  - Downstream model failure: Poor performance on real data despite good synthetic data generation
  - HyperNetwork collapse: Inability to condition generation effectively, leading to random defect placement
- First 3 experiments:
  1. Fine-tune Stable Diffusion on a small subset of industrial data using DreamBooth and evaluate FID score
  2. Train HyperNetwork to condition generation on topological drivers and qualitatively assess defect placement
  3. Generate synthetic data and train a simple instance segmentation model (e.g., U-Net) to evaluate the impact of synthetic data on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of conditioning mechanism (topological drivers) impact the quality and diversity of generated industrial images across different types of defects and industrial domains?
- Basis in paper: [explicit] The paper discusses the use of topological drivers as a conditioning mechanism and mentions that different datasets may require slightly different driver extraction procedures.
- Why unresolved: The paper primarily focuses on a specific industrial dataset (TBI) and a particular type of defect (cracks). It does not explore the effectiveness of the conditioning mechanism across a wide range of industrial defects or domains.
- What evidence would resolve it: Conducting experiments using the proposed method on various industrial datasets with different types of defects and domains would provide insights into the generalizability and effectiveness of the topological driver conditioning mechanism.

### Open Question 2
- Question: How does the proposed approach compare to other methods for generating synthetic industrial data, such as inpainting or other generative models, in terms of data quality, diversity, and downstream task performance?
- Basis in paper: [explicit] The paper mentions that inpainting methods may not fit the use case as well as the proposed approach, but it does not provide a comprehensive comparison with other methods.
- Why unresolved: The paper primarily focuses on demonstrating the advantages of the proposed approach over inpainting, but it does not explore comparisons with other generative models or methods for generating synthetic industrial data.
- What evidence would resolve it: Conducting experiments comparing the proposed approach with other state-of-the-art methods for generating synthetic industrial data, including inpainting and other generative models, would provide a clearer understanding of its relative performance and advantages.

### Open Question 3
- Question: How does the amount of labeled data used for learning the concept and conditioning impact the quality and diversity of generated images, and what is the optimal trade-off between labeled data and generated data for downstream tasks?
- Basis in paper: [explicit] The paper mentions that the method uses a small amount of labeled data for learning the concept and conditioning, and it explores the performance of the approach with different amounts of labeled data.
- Why unresolved: The paper does not provide a detailed analysis of how the amount of labeled data impacts the quality and diversity of generated images, nor does it explore the optimal trade-off between labeled data and generated data for downstream tasks.
- What evidence would resolve it: Conducting experiments varying the amount of labeled data used for learning the concept and conditioning, and analyzing the resulting quality and diversity of generated images, as well as their impact on downstream task performance, would provide insights into the optimal trade-off between labeled data and generated data.

## Limitations
- Evaluation relies on a single industrial dataset (turbine borescope images), limiting generalizability to other defect types or industrial domains
- Claims about effectiveness in "production environments" with minimal real data are speculative without broader empirical validation
- HyperNetwork conditioning mechanism is validated qualitatively but lacks quantitative ablation studies isolating its contribution

## Confidence

- **High confidence**: The core approach of using DreamBooth for concept learning and HyperNetworks for conditioning is technically sound and well-supported by the diffusion model literature
- **Medium confidence**: The performance improvements on the turbine borescope dataset are demonstrated, but may not generalize to other industrial defect types or imaging conditions
- **Low confidence**: Claims about the approach working in "production environments" with minimal real data are speculative without broader empirical validation across multiple datasets and defect types

## Next Checks

1. **Cross-domain validation**: Test the approach on at least two additional industrial defect datasets (e.g., steel surface defects, electronic component defects) to assess generalizability and identify domain-specific limitations
2. **HyperNetwork ablation study**: Systematically vary HyperNetwork capacity and conditioning strength while measuring both synthetic data quality (FID) and downstream segmentation performance to quantify its contribution
3. **Extreme data scarcity test**: Evaluate performance using only 1-5% of real data to determine the practical limits of synthetic data augmentation and identify failure modes in ultra-low data regimes