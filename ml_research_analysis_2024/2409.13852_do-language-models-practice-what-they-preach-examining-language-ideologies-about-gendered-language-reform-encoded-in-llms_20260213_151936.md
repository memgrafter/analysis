---
ver: rpa2
title: Do language models practice what they preach? Examining language ideologies
  about gendered language reform encoded in LLMs
arxiv_id: '2409.13852'
source_url: https://arxiv.org/abs/2409.13852
tags:
- language
- role
- nouns
- llms
- reform
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examined how language ideologies about gendered language
  reform are encoded in large language models (LLMs) through two experiments. The
  first experiment revealed that when prompted to use "correct" or "natural" language,
  LLMs produce language most similar to conservative perspectives, suggesting implicit
  communication of politically biased language ideologies.
---

# Do language models practice what they preach? Examining language ideologies about gendered language reform encoded in LLMs

## Quick Facts
- arXiv ID: 2409.13852
- Source URL: https://arxiv.org/abs/2409.13852
- Authors: Julia Watson; Sophia Lee; Barend Beekhuizen; Suzanne Stevenson
- Reference count: 40
- Primary result: LLMs produce conservative-leaning language when prompted for "correct" language and show inconsistent use of gender-neutral variants across prompt types

## Executive Summary
This study investigates how large language models encode language ideologies about gendered language reform through two controlled experiments. The researchers examined whether LLMs internalize and reproduce societal debates about gendered language reform, specifically testing if models can distinguish between different ideological positions and whether they practice what they preach about gender-neutral language. The findings reveal that LLMs exhibit both explicit bias in their metalinguistic preferences and internal inconsistency in their actual language use, suggesting that these models encode and communicate complex social values through seemingly neutral language choices.

## Method Summary
The researchers conducted two experiments using English and German language models. In Experiment 1, they tested metalinguistic preferences by prompting models with various phrases like "correct," "natural," "inclusive," and "conservative" to generate sentences about a given topic. Experiment 2 examined consistency by prompting models with different types of metalinguistic statements about gendered language reform, ranging from explicit reform endorsements to implicit references. The study used GPT-4 and other models to generate responses, which were then analyzed for the presence and frequency of gender-neutral variants in German and general language patterns in English. Human evaluations supplemented the quantitative analysis to validate the models' preferences and consistency.

## Key Results
- When prompted to use "correct" or "natural" language, LLMs produce output most similar to conservative perspectives on gendered language reform
- LLMs show internal inconsistency in gender-neutral language use, with reform variants appearing more frequently in explicitly metalinguistic contexts
- The study demonstrates that value alignment for LLMs must account for both explicit metalinguistic statements and implicit value judgments embedded in language choices

## Why This Works (Mechanism)
The study works by leveraging the principle that LLMs internalize language ideologies from their training data, which contains encoded social values and linguistic preferences. By systematically varying metalinguistic prompts and analyzing the resulting language output, the researchers can reveal how models internalize and reproduce different ideological positions. The mechanism relies on the fact that language models learn statistical patterns that reflect societal attitudes, allowing researchers to probe these embedded ideologies through carefully constructed prompts that trigger different linguistic responses.

## Foundational Learning

**Language ideologies**: Systems of beliefs about language that associate linguistic forms with social meanings and values. Why needed: Understanding how LLMs encode these ideologies is crucial for assessing their social impact. Quick check: Examine whether models consistently reproduce ideologically marked language patterns across different contexts.

**Gendered language reform**: Movements to modify language to be more inclusive of gender diversity, such as using gender-neutral terms or including both masculine and feminine forms. Why needed: These reforms represent contested social changes that LLMs must navigate. Quick check: Test whether models can appropriately use and discuss reform variants in different contexts.

**Metalinguistic statements**: Explicit comments about language use, such as describing language as "correct" or "inclusive." Why needed: These statements reveal how models position themselves regarding language ideologies. Quick check: Analyze whether models' metalinguistic preferences align with their actual language production.

**Implicit bias in language**: Subtle ways that language choices can encode social values without explicit statement. Why needed: Models may communicate values through word choice rather than explicit statements. Quick check: Compare language output across different prompt framings to identify implicit biases.

## Architecture Onboarding

**Component map**: Input prompt -> Language model (GPT-4/other models) -> Text generation -> Output analysis -> Human evaluation validation

**Critical path**: The study's critical path involves designing prompts that elicit different metalinguistic positions, generating text through the model, and analyzing both the explicit preferences and implicit language choices to reveal encoded ideologies.

**Design tradeoffs**: The study balances between controlled experimental conditions that isolate specific language ideologies and naturalistic prompts that reflect real-world usage patterns. This tradeoff affects how generalizable the findings are to actual LLM applications.

**Failure signatures**: Models may fail to distinguish between different ideological positions, show inconsistent application of stated preferences, or reproduce training data biases without critical evaluation. These failures manifest as unexpected language choices or preference reversals across similar contexts.

**First experiments**:
1. Test model responses to mixed prompts that combine "correct" with reform-oriented language to see if preferences can be overridden
2. Examine whether different model sizes show varying degrees of ideological encoding
3. Test prompts in languages other than English and German to assess cross-linguistic generalizability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs' metalinguistic preferences for gendered language reform vary across different political contexts and languages beyond English?
- Basis in paper: The study focuses on English gendered language reform in the context of US politics, but acknowledges that results might not generalize to other languages or political contexts.
- Why unresolved: The paper's scope is limited to English and US political context, leaving open the question of how these findings would apply in other linguistic and political environments.
- What evidence would resolve it: Comparative studies examining LLM behavior across multiple languages and political systems, testing for similar patterns of metalinguistic bias and inconsistency in various reform contexts.

### Open Question 2
- Question: What are the long-term societal impacts of LLM-generated metalinguistic statements on the adoption and evolution of gender-neutral language reforms?
- Basis in paper: The authors discuss how increased use of LLMs might shape people's attitudes and adoption of reform language in unexpected ways, but do not explore this in depth.
- Why unresolved: While the paper identifies potential for LLMs to influence language reform adoption, it does not examine actual long-term effects on language use and attitudes in real-world scenarios.
- What evidence would resolve it: Longitudinal studies tracking language use and attitudes in populations frequently interacting with LLMs, comparing regions or demographics with varying LLM exposure.

### Open Question 3
- Question: How can value alignment strategies for LLMs be designed to account for both explicit metalinguistic statements and implicit value judgments embedded in language choices?
- Basis in paper: The authors argue that value alignment must consider both explicit metalinguistic statements and implicit value judgments, but do not provide concrete strategies for achieving this.
- Why unresolved: While the paper highlights the importance of considering both aspects of language ideologies, it does not offer specific methods or frameworks for implementing this in LLM training or evaluation.
- What evidence would resolve it: Development and testing of novel value alignment techniques that explicitly address both explicit and implicit aspects of language ideologies, with empirical validation across diverse linguistic and social contexts.

## Limitations
- The study focuses on English language models and German gendered language reform specifically, which may limit generalizability to other languages and cultural contexts
- The observed internal inconsistency in gender-neutral language use may stem from insufficient exposure to reform variants in training data rather than inherent model biases
- The distinction between explicit metalinguistic statements and implicit value judgments embedded in language choices requires further empirical validation across diverse linguistic and cultural contexts

## Confidence

**Major claims**:
- LLMs encode language ideologies about gendered reform: Medium
- Models show internal inconsistency in reform language use: Medium
- Value alignment must account for both explicit and implicit aspects: Medium

## Next Checks

1. Test the same prompts across multiple language models trained on different datasets to isolate whether observed biases stem from training data or model architecture

2. Conduct user studies with native German speakers to verify whether the models' "natural" language output aligns with actual German speakers' intuitions about gendered language reform

3. Expand the analysis to include non-binary and gender-inclusive language reform movements beyond binary gendered language to test the generalizability of findings