---
ver: rpa2
title: Adversarial Testing for Visual Grounding via Image-Aware Property Reduction
arxiv_id: '2403.01118'
source_url: https://arxiv.org/abs/2403.01118
tags:
- peeling
- expression
- adversarial
- image
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PEELING, a text perturbation approach for
  adversarial testing of visual grounding (VG) models. PEELING reduces property-related
  information in expressions while ensuring the target object remains uniquely identifiable
  in the image.
---

# Adversarial Testing for Visual Grounding via Image-Aware Property Reduction

## Quick Facts
- arXiv ID: 2403.01118
- Source URL: https://arxiv.org/abs/2403.01118
- Authors: Zhiyuan Chang; Mingyang Li; Junjie Wang; Cheng Li; Boyu Wu; Fanjiang Xu; Qing Wang
- Reference count: 40
- Primary result: PEELING achieves 21.4% MultiModal Impact score (MMI), outperforming baselines by 8.2%-15.1%

## Executive Summary
This paper introduces PEELING, a text perturbation approach for adversarial testing of visual grounding (VG) models. PEELING reduces property-related information in expressions while ensuring the target object remains uniquely identifiable in the image. The method extracts objects and properties, generates candidate expressions through recombination, and validates them using visual understanding. Experiments on OFA-VG with RefCOCO, RefCOCO+, and RefCOg datasets show PEELING achieves 21.4% MultiModal Impact score (MMI), outperforming baselines by 8.2%-15.1%. The two perturbations in PEELING contribute 11.1% and 14.2% MMI on average. Fine-tuning OFA-VG with adversarial tests improves accuracy by 18.2%-35.8%.

## Method Summary
PEELING operates through a multi-stage process: first extracting objects and properties from expressions using ChatGPT with in-context learning, then generating candidate expressions by recombining objects with subsets of their properties, and finally validating candidates through a three-query VQA system (How Many, Whether, Reflection). The method applies two perturbation types sequentially: property reduction (P1) that removes redundant properties while preserving object identifiability, and semantically-equivalent perturbations (P2) at character, word, and sentence levels using the nlpaug toolkit. The validation system requires all three VQA queries to meet expectations before accepting a candidate, ensuring high-quality adversarial tests that maintain the test oracle while increasing uncertainty for the VG model.

## Key Results
- PEELING achieves 21.4% MultiModal Impact score (MMI), outperforming baselines by 8.2%-15.1%
- The two perturbations in PEELING contribute 11.1% and 14.2% MMI on average
- Fine-tuning OFA-VG with adversarial tests improves accuracy by 18.2%-35.8%
- ATCR (Adversarial Tests Correct Rate) demonstrates high-quality test generation with 84.3% on RefCOCO

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Property reduction expressions preserve test oracle while increasing uncertainty for the VG model.
- Mechanism: By removing redundant property information from expressions while ensuring the target object remains uniquely identifiable via VQA queries, the resulting expressions contain less discriminative information, forcing the VG model to rely more heavily on context and spatial reasoning.
- Core assumption: Redundant properties exist in VG expressions and their removal does not change the target object's identity in the image.
- Evidence anchors:
  - [abstract]: "The core idea is to reduce the property-related information in the original expression meanwhile ensuring the reduced expression can still uniquely describe the original object in the image."
  - [section]: "In the VG task, it is common for expressions to include an abundance of properties when describing an object. In such cases, even if we remove certain redundant properties from the original expressions (i.e., through property reduction), the target object can still be identified within the image."

### Mechanism 2
- Claim: Multi-perspective VQA validation ensures high-quality adversarial tests.
- Mechanism: PEELING uses three different query types ("How Many", "Whether", "Reflection") to validate candidate property reduction expressions, requiring all three to meet expectations before acceptance, which reduces false positives from any single query's errors.
- Core assumption: VQA models can reliably answer yes/no questions about object properties and counts in images.
- Evidence anchors:
  - [section]: "By leveraging Visual Question Answering (VQA) technology, PEELING designs three queries for a VQA model to obtain the model responses. Based on the responses to these queries, PEELING validates whether each candidate is sufficient to locate the original target object in the image."

### Mechanism 3
- Claim: Combined perturbations create more diverse and challenging test cases than single perturbation methods.
- Mechanism: PEELING applies both property reduction (P1) and semantically-equivalent perturbations (P2) sequentially, creating test cases that are both informationally reduced and linguistically varied, which together expose different failure modes in VG models.
- Core assumption: VG models are vulnerable to both information reduction and linguistic variation in input expressions.
- Evidence anchors:
  - [abstract]: "PEELING further conducts semantically-equivalent perturbations at the character/word/sentence level. This can diversify the range of perturbation operations, so as to facilitate uncovering more issues present within the VG model."

## Foundational Learning

- Concept: Visual Grounding fundamentals (matching natural language expressions to image regions)
  - Why needed here: Understanding the core task helps engineers grasp why property reduction is effective - VG models must map linguistic descriptions to spatial regions
  - Quick check question: What is the primary output of a VG model given an image and expression?

- Concept: Multimodal model robustness testing principles
  - Why needed here: PEELING operates on the principle that reducing information in one modality while preserving semantic meaning can expose model weaknesses
  - Quick check question: Why would reducing property information in an expression potentially make a VG model perform worse?

- Concept: Large Language Model (LLM) in-context learning capabilities
  - Why needed here: PEELING uses ChatGPT with in-context learning for object and property extraction, requiring understanding of how few-shot prompting works
  - Quick check question: How does in-context learning differ from fine-tuning for a task like object extraction?

## Architecture Onboarding

- Component map: Image → Object/Property Extraction → Candidate Generation → VQA Validation → Perturbation → Adversarial Test
- Critical path: Image → Object/Property Extraction → Candidate Generation → VQA Validation → Perturbation → Adversarial Test
- Design tradeoffs:
  - Using VQA for validation adds computational overhead but improves test quality
  - Three-query system reduces false positives but increases complexity
  - Sequential perturbations (P1 then P2) create more diverse tests but may reduce interpretability
- Failure signatures:
  - High ATCR but low MMI suggests perturbations are correct but not challenging enough
  - Low ATCR indicates issues with VQA validation or property extraction
  - Poor performance on fine-tuning evaluation suggests generated tests don't capture model weaknesses
- First 3 experiments:
  1. Run PEELING on a small subset of RefCOCO with manual verification of property extraction accuracy
  2. Compare MMI scores with and without the three-query VQA validation system
  3. Evaluate the impact of each perturbation type by running ablation studies on generated test sets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PEELING's performance compare to white-box testing approaches for visual grounding models?
- Basis in paper: [inferred] The paper focuses exclusively on black-box testing, noting that "adopting white-box approaches is much more difficult" in industrial scenarios where internal model parameters are inaccessible. The paper does not compare PEELING to any white-box testing methods.
- Why unresolved: The paper deliberately avoids white-box approaches and does not provide any comparison or analysis of how PEELING would perform relative to white-box testing methods.
- What evidence would resolve it: Comparative experiments between PEELING and white-box testing approaches on the same VG models and datasets, measuring metrics like MMI and accuracy.

### Open Question 2
- Question: How does the effectiveness of PEELING vary across different types of visual grounding models (e.g., two-stage vs. end-to-end architectures)?
- Basis in paper: [inferred] The paper only evaluates PEELING on one state-of-the-art model (OFA-VG), which is a pre-trained transformer-based architecture. The paper does not explore how PEELING performs on different VG model architectures or whether certain types of models are more susceptible to the identified issues.
- Why unresolved: The evaluation is limited to a single model type, and the paper does not discuss whether the identified issues and PEELING's effectiveness would generalize to other VG architectures.
- What evidence would resolve it: Systematic evaluation of PEELING across multiple VG model architectures (two-stage, end-to-end, transformer-based, etc.) with comparison of issue detection rates and model improvement metrics.

### Open Question 3
- Question: What is the relationship between the properties identified by PEELING and the actual features learned by visual grounding models?
- Basis in paper: [explicit] The paper mentions that "through the image understanding, the target object 'bag' distinguishes from the others by either of the two explicit properties" and discusses property reduction, but does not investigate whether the properties PEELING identifies align with the features that VG models actually use for grounding.
- Why unresolved: The paper focuses on human-interpretable properties but does not analyze the model's internal feature representations to determine if PEELING's property identification matches what the model actually learns.
- What evidence would resolve it: Analysis using techniques like feature visualization or saliency maps to compare PEELING-identified properties with the actual features that contribute most to the model's grounding decisions.

## Limitations
- PEELING's effectiveness depends on the reliability of both VQA models and LLMs for property extraction
- The perturbation strategy assumes that property reduction will consistently increase uncertainty for VG models, which may not hold for all VG architectures
- The evaluation focuses primarily on OFA-VG, limiting generalizability to other VG models

## Confidence
- **High Confidence**: The core mechanism of property reduction preserving test oracle while increasing uncertainty (Mechanism 1) is well-supported by the experimental results showing consistent MMI improvements.
- **Medium Confidence**: The effectiveness of the three-query VQA validation system (Mechanism 2) is supported by ATCR metrics, though the robustness across different VQA model qualities remains uncertain.
- **Medium Confidence**: The combined perturbation approach creating more diverse tests (Mechanism 3) shows promise, but the relative contribution of each perturbation type could be more thoroughly analyzed.

## Next Checks
1. Conduct cross-model validation by testing PEELING-generated adversarial examples on multiple VG architectures beyond OFA-VG to assess generalizability.
2. Perform a systematic ablation study isolating the contribution of each VQA query type to identify potential weaknesses in the validation system.
3. Evaluate PEELING's performance on VG datasets with different linguistic characteristics (e.g., non-English expressions) to test robustness across language variations.