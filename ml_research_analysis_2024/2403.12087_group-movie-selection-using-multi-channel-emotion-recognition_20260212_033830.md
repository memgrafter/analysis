---
ver: rpa2
title: Group Movie Selection using Multi-channel Emotion Recognition
arxiv_id: '2403.12087'
source_url: https://arxiv.org/abs/2403.12087
tags:
- movie
- surprise
- happy
- fear
- angry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a multi-channel emotion recognition approach
  for group movie selection by analyzing emotions from movie posters, soundtracks,
  and descriptions. Using Jaccard similarity to match group preferences, the method
  achieved an average similarity coefficient of 0.58 between predicted and real emotion
  distributions.
---

# Group Movie Selection using Multi-channel Emotion Recognition

## Quick Facts
- arXiv ID: 2403.12087
- Source URL: https://arxiv.org/abs/2403.12087
- Reference count: 0
- Primary result: Achieved average Jaccard similarity of 0.58 between predicted and real emotion distributions for group movie selection

## Executive Summary
This study proposes a multi-channel emotion recognition approach for group movie selection by analyzing emotions from movie posters, soundtracks, and descriptions. The method uses Jaccard similarity to match group preferences and achieved an average similarity coefficient of 0.58 between predicted and real emotion distributions. An example demonstrated that "Titanic" and "Me Before You" received the highest recommendation scores (0.8) for a sample group, while "Passengers" scored lowest (0.34).

## Method Summary
The approach extracts emotions from three channels: text descriptions using text2emotion, poster colors using fuzzy color mapping, and soundtracks using a pre-trained deep neural network. Emotion scores from each channel are aggregated using weighted sum (poster:1, soundtrack:2, description:3), then Jaccard similarity is computed between candidate movies and participants' favorite movies to identify the best group choices. The system recommends movies with highest average similarity scores, filtered by genre preferences.

## Key Results
- Average Jaccard similarity coefficient of 0.58 between predicted and real emotion distributions
- "Titanic" and "Me Before You" received highest recommendation scores (0.8) for sample group
- "Passengers" scored lowest (0.34) in the example group recommendation
- Method shows promise in enhancing group movie recommendation systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-channel emotion recognition from posters, soundtracks, and descriptions improves group movie selection by capturing complementary emotional dimensions
- Mechanism: Different media channels encode emotion differentlyâ€”visual color-emotion associations in posters, musical valence and tempo in soundtracks, and sentiment and thematic tone in descriptions. Aggregating these yields a richer emotional profile than any single channel
- Core assumption: Each media channel provides independent and non-redundant emotional information about a film
- Evidence anchors: [abstract] "Our research stands at the intersection of emotion recognition technology in music, text, color images, and group decision-making"; [section II.C] "We calculated the Pearson correlation coefficient between each emotion channel (text, colors, audio) and real human ratings to evaluate which emotion channel has the biggest impact"
- Break condition: If emotional scores from different channels are highly correlated (e.g., Pearson >0.8), the multi-channel benefit collapses into redundancy

### Mechanism 2
- Claim: Jaccard similarity between predicted emotion distributions and participants' preferred movie emotions enables quantitative consensus measurement
- Mechanism: By treating emotion categories as sets and computing Jaccard similarity, the method measures overlap between the emotional content of a candidate movie and the collective emotional preference of the group
- Core assumption: Participants' favorite movies accurately represent the emotional preferences of the group
- Evidence anchors: [section II.C] "We calculated the Jaccard similarity coefficient... between the emotional composition of each film in our database (set 1) and the best-loved film of each participant (set 2)"; [section III.B] "The set of films with the mean Jaccard value equal to the highest coefficient... was identified as the best choice for the group"
- Break condition: If participants have diverse favorite movies with disjoint emotion sets, Jaccard similarity will be low for all candidates, making ranking unreliable

### Mechanism 3
- Claim: Weighted averaging of emotion scores across channels, with soundtrack weighted highest, reflects the relative emotional impact of each media type
- Mechanism: Weights (poster=1, soundtrack=2, description=3) are applied to aggregated emotion scores, prioritizing text and audio over visual cues in final emotion profile
- Core assumption: The chosen weights reflect the true relative influence of each channel on emotional perception
- Evidence anchors: [section II.D.1] "We selected the following weights based on our subjective observations: ð‘¤ð‘=1, ð‘¤ð‘š=2, ð‘¤ð‘‘=3"; [section III.A] "The highest correlation is between human ratings and text description emotion channel (0.43)"
- Break condition: If correlation analysis shows a different ranking of channel importance, the fixed weights become suboptimal

## Foundational Learning

- Concept: Set similarity metrics (Jaccard, cosine)
  - Why needed here: To quantify overlap between predicted and preferred emotion distributions for ranking movies
  - Quick check question: Given sets A={Happy, Sad} and B={Happy, Angry}, what is the Jaccard similarity?

- Concept: Multi-modal data fusion and weighted averaging
  - Why needed here: To combine emotion scores from different sources (poster, soundtrack, description) into a single profile
  - Quick check question: If poster emotion score for "Happy" is 0.3, soundtrack is 0.6, and description is 0.9, what is the weighted sum with weights 1, 2, 3?

- Concept: Emotion representation in different modalities (color psychology, musical features, sentiment analysis)
  - Why needed here: To understand how emotion is extracted from each data source and why multi-channel helps
  - Quick check question: Name one color-emotion association used in the poster analysis method

## Architecture Onboarding

- Component map: Data Ingestion -> Emotion Extraction Modules -> Aggregation Layer -> Similarity Engine -> Recommendation Output
- Critical path:
  1. Extract emotion scores from all three channels for each candidate movie
  2. Aggregate scores using weighted sum
  3. Compute Jaccard similarity to each participant's favorite movie
  4. Average similarities across participants
  5. Rank and filter by genre
- Design tradeoffs:
  - Fixed vs. learned weights: Fixed weights are simple but may not reflect true channel importance; learned weights could overfit small datasets
  - Set-based vs. vector-based similarity: Jaccard is robust to score scale but ignores magnitude; cosine similarity preserves magnitude but may be sensitive to normalization
  - Emotion category granularity: Five categories balance expressiveness and data sparsity; more categories could capture nuance but require more training data
- Failure signatures:
  - Low average Jaccard similarity (<0.3) suggests poor alignment between candidate movies and group preferences
  - High correlation (>0.8) between emotion channels indicates redundancy and wasted computation
  - Disparate favorite movies among participants leading to no clear consensus
- First 3 experiments:
  1. Validate channel independence: Compute Pearson correlations between emotion scores from each channel across all movies; check if any exceed 0.7
  2. Test weight sensitivity: Run recommendation with different weight combinations (e.g., (1,1,1), (1,2,3), (2,2,1)) and compare top-3 movie overlap
  3. Ablation study: Remove one channel at a time and measure change in average Jaccard similarity to assess contribution of each modality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do individual film preferences affect collective decision-making in group movie selection?
- Basis in paper: [explicit] The paper aims to answer this specific research question as stated in the "Research Aim" section
- Why unresolved: The paper only provides a preliminary example with 4 participants and doesn't analyze how individual preferences aggregate or conflict during group selection
- What evidence would resolve it: Systematic studies comparing group decisions with individual preferences across multiple groups, analyzing patterns of consensus vs. disagreement

### Open Question 2
- Question: Which emotion channel (poster colors, soundtrack, or description) has the greatest impact on movie recommendations?
- Basis in paper: [explicit] This is explicitly stated as a research contribution question in the paper
- Why unresolved: The paper only provides subjective observations about weights (poster=1, soundtrack=2, description=3) but doesn't empirically validate which channel matters most
- What evidence would resolve it: Controlled experiments varying individual channels while keeping others constant, or statistical analysis of channel contributions

### Open Question 3
- Question: How can genre information be effectively integrated into the multi-channel emotion recognition approach?
- Basis in paper: [inferred] The paper mentions plans to integrate genre information in future work, suggesting this is currently unresolved
- Why unresolved: The current methodology doesn't incorporate genre data, and the paper acknowledges this limitation for future development
- What evidence would resolve it: Implementation of genre-aware aggregation methods and comparison of performance with and without genre integration

### Open Question 4
- Question: What is the optimal threshold for emotion score inclusion in the Jaccard similarity calculation?
- Basis in paper: [explicit] The paper uses a threshold of 0.1 but acknowledges this was selected based on observed quartiles rather than optimization
- Why unresolved: The threshold selection appears arbitrary and could significantly affect similarity calculations
- What evidence would resolve it: Sensitivity analysis testing different thresholds and their impact on recommendation accuracy

## Limitations
- Small dataset (12 movies) limits generalizability of results
- Subjective weight selection (1:2:3) lacks empirical justification through cross-validation
- Pre-trained deep neural network and fuzzy color mappings referenced but not fully specified

## Confidence
- Multi-channel emotion recognition mechanism: Medium confidence (correlation analysis supports channel independence but weight selection lacks validation)
- Jaccard similarity for group consensus: Medium confidence (limited sample size and reliance on favorite movies as preference proxies)
- Weighted aggregation approach: Low confidence (subjective weight selection without optimization)

## Next Checks
1. Validate channel independence by computing Pearson correlations between emotion scores from each channel across all movies; ensure no correlation exceeds 0.7
2. Test weight sensitivity by running recommendations with different weight combinations (e.g., equal weights vs. current weights) and comparing top-3 movie overlap
3. Conduct ablation study by removing one channel at a time and measuring change in average Jaccard similarity to quantify each modality's contribution