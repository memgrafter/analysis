---
ver: rpa2
title: 'Causal Discovery in Recommender Systems: Example and Discussion'
arxiv_id: '2409.10271'
source_url: https://arxiv.org/abs/2409.10271
tags:
- causal
- learning
- data
- recommender
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores causal discovery in recommender systems using
  observational data from the KuaiRand dataset. The authors build a causal graph (CG)
  by combining prior knowledge with data, applying Hill-Climbing algorithm with Bayesian
  Information Criterion scoring.
---

# Causal Discovery in Recommender Systems: Example and Discussion

## Quick Facts
- arXiv ID: 2409.10271
- Source URL: https://arxiv.org/abs/2409.10271
- Authors: Emanuele Cavenaghi; Fabio Stella; Markus Zanker
- Reference count: 24
- Primary result: Causal discovery using observational data from KuaiRand dataset reveals only a few variables effectively influence user feedback signals

## Executive Summary
This paper explores causal discovery in recommender systems using observational data from the KuaiRand dataset. The authors build a causal graph by combining prior knowledge with data, applying Hill-Climbing algorithm with Bayesian Information Criterion scoring. They then average 100 learned causal graphs to identify significant edges. The resulting graph shows that only a few variables (like video duration and upload type) effectively influence user feedback, contrasting with the trend of including many variables in large models.

## Method Summary
The authors preprocess the KuaiRand dataset by removing irrelevant features, discretizing continuous features, and defining prior knowledge using tiers. They then apply the Hill-Climbing algorithm with Bayesian Information Criterion scoring to learn 100 causal graphs from the preprocessed data and prior knowledge. Finally, they average the 100 learned graphs to identify significant edges (present in at least 90% of the graphs) and construct the final causal graph, focusing on feedback signals.

## Key Results
- The causal graph shows only a few variables effectively influence feedback signals
- Video duration and upload type are identified as key influential variables
- The approach contrasts with the trend of using massive models with many variables
- Results suggest focusing on essential factors rather than many potentially noisy ones

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The causal graph correctly identifies which variables actually influence feedback signals, despite being learned from observational data.
- Mechanism: The Hill-Climbing algorithm with Bayesian Information Criterion scoring searches through possible causal graph structures, evaluating each based on how well it explains the observed data while penalizing complexity. The BIC score balances goodness-of-fit with model simplicity, helping avoid overfitting to noise in the dataset.
- Core assumption: The underlying causal structure can be represented as a directed acyclic graph where edges represent direct causal relationships, and the data generation process satisfies the assumptions of conditional independence encoded in the graph structure.
- Evidence anchors:
  - [abstract] "The resulting causal graph shows that only a few variables effectively influence the analysed feedback signals."
  - [section] "we used the Hill-Climbing (HC) algorithm... selecting the optimal graph G* w.r.t. a goodness-of-fit function S, known as the scoring criterion."
  - [corpus] Weak evidence - corpus contains related causal discovery papers but no direct evidence about this specific HC+BIC approach's effectiveness.

### Mechanism 2
- Claim: Averaging multiple learned graphs (100 CGs) and selecting edges present in at least 90% produces a more stable and reliable final causal graph.
- Mechanism: Each run of the Hill-Climbing algorithm with BIC scoring may converge to slightly different local optima due to random initialization or data sampling variations. By learning 100 graphs and keeping only edges that appear in at least 90% of them, the approach filters out edges that are sensitive to these variations and keeps only the most robust relationships.
- Core assumption: Edges that consistently appear across multiple runs represent genuine causal relationships rather than artifacts of the learning process or noise in the data.
- Evidence anchors:
  - [section] "we learnt 100 CGs using the HC algorithm... Then, to obtain a single CG containing only significant edges, we averaged the learnt CGs by selecting only the edges present in at least 90% of the CGs."
  - [abstract] "we report all the steps followed to learn a CG, from data and prior knowledge to the final result, to inspire other researchers"
  - [corpus] Weak evidence - no direct evidence about ensemble methods for causal graph learning in the corpus.

### Mechanism 3
- Claim: The learned causal graph's identification of only a few relevant variables contrasts with and challenges the trend of using massive models with many variables in machine learning.
- Mechanism: By explicitly modeling causal relationships through a causal graph, the approach identifies which variables are necessary to explain the feedback signals (those in the Markov Blanket). This allows for simpler models that focus only on relevant variables, reducing data requirements and avoiding the noise introduced by irrelevant variables.
- Core assumption: The Markov Blanket concept correctly identifies all and only the variables that are relevant for predicting the feedback signals in the context of the causal relationships.
- Evidence anchors:
  - [abstract] "This contrasts with the recent trend in the machine learning community to include more and more variables in massive models, such as neural networks."
  - [section] "An MB is defined as a subset of variables that contains all the useful information to infer the value of a random variable."
  - [corpus] Weak evidence - corpus contains papers on causal inference but none specifically addressing the variable selection aspect in this context.

## Foundational Learning

- Concept: Bayesian Information Criterion (BIC)
  - Why needed here: BIC is the scoring function used by the Hill-Climbing algorithm to evaluate and compare different causal graph structures. Understanding BIC is essential to grasp why the algorithm selects certain edges over others.
  - Quick check question: How does BIC balance model fit and complexity, and why is this important for causal discovery?

- Concept: Markov Blanket
  - Why needed here: The Markov Blanket concept is used to identify the subset of variables that are relevant for predicting the feedback signals, allowing the researchers to focus on the most important parts of the causal graph.
  - Quick check question: What variables are included in a Markov Blanket and why are they sufficient for predicting the target variable?

- Concept: Hill-Climbing Algorithm
  - Why needed here: Hill-Climbing is the search algorithm used to find the optimal causal graph structure. Understanding its mechanics helps explain how the final graph is constructed from the data and prior knowledge.
  - Quick check question: What are the basic operations (add, delete, reverse edge) that Hill-Climbing performs, and how does it decide which operation to take?

## Architecture Onboarding

- Component map:
  Data preprocessing pipeline (feature removal, discretization) -> Prior knowledge specification (tiers for partial ordering) -> Structure learning module (Hill-Climbing with BIC scoring) -> Ensemble module (averaging 100 graphs, 90% threshold) -> Visualization and analysis tools (Markov Blanket extraction)

- Critical path:
  1. Load and preprocess KuaiRand dataset
  2. Define prior knowledge tiers
  3. Run Hill-Climbing 100 times with BIC scoring
  4. Average results to select edges present in â‰¥90% of graphs
  5. Extract Markov Blanket of feedback signals
  6. Visualize and analyze the final causal graph

- Design tradeoffs:
  - Computational cost vs. stability: Running 100 iterations of Hill-Climbing is computationally expensive but provides more stable results through ensemble averaging
  - Granularity vs. interpretability: Discretizing continuous features loses information but enables the use of algorithms designed for discrete data
  - Prior knowledge vs. data-driven discovery: The tiered approach constrains the search space based on domain knowledge but may exclude unexpected causal relationships

- Failure signatures:
  - If the final graph shows many edges with weak or no theoretical justification, it may indicate overfitting to noise
  - If the Markov Blanket contains variables that seem irrelevant to the feedback signals, it may suggest issues with the discretization or prior knowledge specification
  - If the ensemble averaging produces a very sparse graph (few edges), it may indicate high sensitivity to initialization or data sampling

- First 3 experiments:
  1. Run the complete pipeline on a subset of the KuaiRand data (e.g., 10% sample) to verify the basic workflow and check for obvious errors
  2. Vary the discretization scheme for one or two key features and observe how it affects the learned causal graph structure
  3. Modify the prior knowledge tiers to allow certain edges that were previously forbidden, and compare the resulting graphs to assess the impact of domain constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific variables beyond video duration and upload type should be considered essential for recommendation decisions?
- Basis in paper: [explicit] The paper suggests that only a few variables (like video duration and upload type) effectively influence user feedback, contrasting with the trend of including many variables in large models.
- Why unresolved: The paper identifies video duration and upload type as key variables but does not provide a comprehensive list of other potentially essential variables. This leaves open the question of what other factors might be crucial for effective recommendations.
- What evidence would resolve it: Further research could involve experiments that systematically test the impact of various variables on user feedback, potentially leading to a more complete list of essential factors for recommendations.

### Open Question 2
- Question: How can we effectively model the problem and collect necessary information to make informed decisions in recommender systems?
- Basis in paper: [explicit] The paper suggests that more emphasis should be placed on modelling the problem and collecting the necessary information to make informed decisions.
- Why unresolved: While the paper highlights the importance of modelling and data collection, it does not provide specific methodologies or frameworks for achieving this. This leaves open the question of how to best approach these aspects in practice.
- What evidence would resolve it: Developing and validating a comprehensive framework for problem modelling and data collection in recommender systems would provide evidence to resolve this question.

### Open Question 3
- Question: How can we balance the trade-off between model complexity and data requirements in recommender systems?
- Basis in paper: [inferred] The paper contrasts the trend of including more variables in massive models with the suggestion that only a few variables effectively influence user feedback, implying a potential trade-off.
- Why unresolved: The paper presents the idea that fewer variables might be sufficient but does not explore how to determine the optimal balance between model complexity and data requirements.
- What evidence would resolve it: Empirical studies comparing the performance of models with varying numbers of variables on different datasets could provide insights into the optimal balance between complexity and data requirements.

## Limitations
- The approach relies heavily on the quality of prior knowledge specification and assumptions of causal sufficiency
- Effectiveness of averaging 100 CGs to identify significant edges has not been rigorously validated against alternatives
- Causal discovery results are specific to the KuaiRand dataset and may not generalize to other recommender systems

## Confidence
- **High confidence** in the methodology's general approach (HC + BIC + ensemble averaging) as these are well-established techniques in causal discovery literature
- **Medium confidence** in the specific implementation details (discretization methods, tier specifications) due to limited documentation
- **Medium confidence** in the interpretation that fewer variables lead to better recommendations, as this requires additional empirical validation in a live system

## Next Checks
1. Perform ablation studies by removing different prior knowledge tiers to quantify their impact on the final causal graph structure
2. Validate the causal graph's predictions against held-out interventional data if available, or design quasi-experiments to test key causal relationships
3. Compare the performance of models trained on the Markov Blanket variables versus models using the full feature set to empirically test the hypothesis that simpler models generalize better