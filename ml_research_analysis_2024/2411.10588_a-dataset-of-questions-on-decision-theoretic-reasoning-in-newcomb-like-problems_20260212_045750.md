---
ver: rpa2
title: A dataset of questions on decision-theoretic reasoning in Newcomb-like problems
arxiv_id: '2411.10588'
source_url: https://arxiv.org/abs/2411.10588
tags:
- questions
- decision
- capabilities
- alice
- about
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a dataset of 537 decision-theoretic questions
  about Newcomb-like problems, including both capability questions (with unique correct
  answers) and attitude questions (assessing alignment with evidential or causal decision
  theory). The dataset was validated by experts and used to evaluate 78 language models
  across multiple providers.
---

# A dataset of questions on decision-theoretic reasoning in Newcomb-like problems

## Quick Facts
- arXiv ID: 2411.10588
- Source URL: https://arxiv.org/abs/2411.10588
- Reference count: 40
- 537 decision-theoretic questions on Newcomb-like problems evaluated across 78 language models

## Executive Summary
This paper introduces a novel dataset of 537 decision-theoretic questions designed to assess both the capability and attitudes of language models toward evidential and causal decision theories (EDT/CDT). The dataset includes capability questions with unique correct answers and attitude questions evaluating alignment with EDT or CDT. Through expert validation and systematic evaluation of 78 models from multiple providers, the study reveals that models exhibit varying decision-theoretic attitudes, with higher decision-theoretic capabilities correlating with EDT-aligned attitudes when chain-of-thought reasoning is enabled. The dataset provides a systematic framework for studying decision-theoretic reasoning in AI systems.

## Method Summary
The dataset was constructed through a multi-stage process involving literature review, iterative question refinement, and expert validation. Questions were categorized into capability questions (with unique correct answers) and attitude questions (assessing EDT/CDT alignment). Expert surveys with 14-19 participants validated ground truth answers for capability questions and consensus judgments for attitude questions. The dataset was then used to evaluate 78 language models across three settings: few-shot, chain-of-thought, and "apply EDT/CDT" prompts. Statistical analysis examined correlations between decision-theoretic capabilities and attitudes across models.

## Key Results
- Models show varying attitudes toward EDT/CDT, with high decision-theoretic capabilities correlating with EDT-aligned attitudes when chain-of-thought reasoning is allowed (Ï = 0.53, p = 5.4e-7)
- Model attitudes are consistent across different question types
- "Apply EDT" capabilities increase more steeply with overall capabilities than "apply CDT" capabilities

## Why This Works (Mechanism)
The dataset works by providing a structured framework for assessing decision-theoretic reasoning through carefully constructed questions that probe both knowledge and underlying decision-making principles. The distinction between capability and attitude questions allows for separate analysis of whether models can correctly apply decision theories versus whether they naturally align with them.

## Foundational Learning
1. **Decision Theory Concepts** - Understanding of EDT/CDT principles is needed to construct and evaluate questions. Quick check: Can distinguish between evidential and causal reasoning scenarios.

2. **Newcomb-like Problems** - Familiarity with predictor problems and their implications for decision theory. Quick check: Can explain why Newcomb's problem challenges CDT.

3. **Expert Validation Methods** - Knowledge of survey design and consensus-building for subjective questions. Quick check: Can design validation questions with clear answer criteria.

4. **Statistical Correlation Analysis** - Understanding of correlation metrics and significance testing. Quick check: Can interpret correlation coefficients and p-values.

5. **Language Model Evaluation** - Familiarity with few-shot, chain-of-thought, and prompt engineering techniques. Quick check: Can design prompts that elicit different reasoning patterns.

## Architecture Onboarding

**Component Map**: Question Construction -> Expert Validation -> Model Evaluation -> Statistical Analysis -> Correlation Assessment

**Critical Path**: The most critical component is the expert validation phase, as it establishes ground truth answers that all subsequent analysis depends on. Without reliable ground truth, the entire evaluation framework becomes unreliable.

**Design Tradeoffs**: The dataset focuses exclusively on Newcomb-like problems for consistency, but this limits generalizability to other decision-theoretic scenarios. Expert surveys provide validation but may not capture full diversity of opinions.

**Failure Signatures**: Incorrect ground truth answers from expert surveys would propagate errors throughout the analysis. Model-specific quirks in reasoning could create spurious correlations between capabilities and attitudes.

**First Experiments**:
1. Re-run expert validation surveys with larger participant pools to assess inter-expert agreement
2. Test model responses across multiple temperature settings to examine stochastic effects
3. Evaluate the same models on non-Newcomb decision problems to test generalizability

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Expert validation relied on relatively small sample sizes (14-19 participants), potentially missing diversity of expert opinions
- Dataset focuses specifically on Newcomb-like problems, limiting generalizability to broader decision-theoretic reasoning
- Fixed-temperature generation was used without exploring how temperature affects decision-theoretic reasoning outcomes

## Confidence

**Dataset validity and construction**: High confidence - The dataset creation process follows standard validation practices with expert surveys, and the distinction between capability and attitude questions is methodologically sound.

**Model capability assessment**: Medium confidence - While the evaluation methodology is rigorous, the binary coding of responses (correct/incorrect) may oversimplify the nuanced nature of decision-theoretic reasoning, particularly for attitude questions where multiple interpretations exist.

**Correlation findings**: Medium confidence - The statistical significance is strong, but the sample of 78 models, while substantial, may not fully represent the diversity of available language models or capture all relevant factors influencing decision-theoretic attitudes.

## Next Checks

1. Conduct additional expert surveys with larger, more diverse participant pools to validate the ground truth answers and assess inter-expert agreement rates for both capability and attitude questions.

2. Perform temperature sensitivity analysis by evaluating models across multiple temperature settings to determine how stochasticity affects decision-theoretic reasoning outcomes and whether reported correlations hold across different sampling strategies.

3. Expand the dataset to include non-Newcomb-like decision problems and test whether observed patterns in EDT/CDT alignment persist across different problem types, helping establish generalizability of the findings.