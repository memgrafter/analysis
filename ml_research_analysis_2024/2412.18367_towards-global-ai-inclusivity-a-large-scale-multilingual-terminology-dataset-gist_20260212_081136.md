---
ver: rpa2
title: 'Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset
  (GIST)'
arxiv_id: '2412.18367'
source_url: https://arxiv.org/abs/2412.18367
tags:
- translation
- terminology
- terms
- translations
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces GIST, the first large-scale multilingual AI
  terminology dataset containing 5,000 terms extracted from award-winning AI conference
  papers (2000-2023) and translated into Arabic, Chinese, French, Japanese, and Russian.
  The dataset was constructed using a hybrid framework combining LLM extraction with
  human expertise for translation.
---

# Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset (GIST)

## Quick Facts
- **arXiv ID**: 2412.18367
- **Source URL**: https://arxiv.org/abs/2412.18367
- **Reference count**: 40
- **Primary result**: Introduces GIST, the first large-scale multilingual AI terminology dataset with 5,000 terms translated into 5 languages, demonstrating improved translation quality through LLM-powered terminology integration

## Executive Summary
This paper introduces GIST, the first large-scale multilingual AI terminology dataset containing 5,000 terms extracted from award-winning AI conference papers (2000-2023) and translated into Arabic, Chinese, French, Japanese, and Russian. The dataset was constructed using a hybrid framework combining LLM extraction with human expertise for translation. Quality assessments demonstrated superior translation accuracy compared to existing resources through crowdsourced evaluation. The dataset was integrated into translation workflows using post-translation refinement methods, with LLM prompting consistently improving BLEU and COMET scores without requiring model retraining. A web demonstration on the ACL Anthology platform showcases the practical application for improving accessibility of AI research for non-English speakers.

## Method Summary
The authors developed a hybrid framework for terminology extraction and translation. LLMs (LLaMA-3-70B-Instruct) extracted candidate terms from award-winning AI papers, which were then filtered by human experts. Human annotators translated terms via MTurk, and GPT-4o selected the best candidate from multiple translations. For terminology integration, two methods were developed: LLM prompting refinement (using GPT-4o-mini to substitute terms from the dictionary) and word alignment substitution (using multilingual BERT for token-level alignment followed by LLM-based grammatical correction). The system was evaluated using automated metrics (BLEU, COMET, ChrF, TER) on benchmark datasets and real-world AI papers.

## Key Results
- GIST contains 5,000 AI-specific terms translated into Arabic, Chinese, French, Japanese, and Russian
- LLM prompting consistently improves translation quality (BLEU and COMET scores) without model retraining
- Word alignment substitution works better for morphologically simple languages (Chinese, Japanese) than complex ones (Arabic, French, Russian)
- GPT-4o candidate selection from multiple human translations achieves high accuracy
- Web demonstration on ACL Anthology platform successfully showcases practical application

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM prompting consistently improves translation quality by integrating domain-specific terminology without model retraining.
- Mechanism: The system uses GPT-4o-mini to refine translations by applying a predefined term dictionary. It scans machine-translated text, identifies source terms, and replaces them with the correct target-language equivalents from GIST. This leverages the LLM's instruction-following capabilities to ensure accurate, context-aware terminology translation.
- Core assumption: LLMs can reliably follow instructions to perform terminology substitution without introducing grammatical errors.
- Evidence anchors:
  - [abstract]: "LLM prompting consistently improves BLEU and COMET scores without requiring model retraining."
  - [section]: "The prompting-powered refinement method consistently outperforms direct translation across nearly all languages, models, and evaluation metrics."
- Break condition: If the LLM fails to maintain grammatical coherence during substitution, or if the term dictionary is incomplete or inaccurate.

### Mechanism 2
- Claim: Word alignment substitution works better for morphologically simple languages (Chinese, Japanese) but poorly for complex ones (Arabic, French, Russian).
- Mechanism: The system uses multilingual BERT to compute token-level alignments between source and target sentences. High-confidence alignments are then used to substitute terminology directly in the output. A post-hoc LLM prompt ensures morphological correctness.
- Core assumption: Simple morphology means term substitution doesn't disrupt surrounding syntax; complex morphology requires grammatical agreement that alignment alone can't handle.
- Evidence anchors:
  - [abstract]: "Word alignment and replacement... consistently improves BLEU and COMET scores."
  - [section]: "The word alignment method demonstrates mixed performance, showing improvements for Chinese and Japanese translations but leading to declines for Arabic, French, and Russian."
- Break condition: If target language requires grammatical agreement (gender, number, case) that isn't handled by simple substitution.

### Mechanism 3
- Claim: Hybrid human-LLM workflow ensures high-quality translations by combining scalable extraction with expert validation.
- Mechanism: LLMs (LLaMA-3-70B-Instruct) extract candidate terms from award-winning papers, which are then filtered by human experts. Human annotators translate terms via MTurk, and GPT-4o selects the best candidate from multiple translations. This combines scalability with quality control.
- Core assumption: LLMs can effectively extract relevant terminology when given clear instructions, and human expertise is necessary for final quality assurance.
- Evidence anchors:
  - [abstract]: "The terms are translated into Arabic, Chinese, French, Japanese, and Russian using a hybrid framework that combines LLMs for extraction with human expertise for translation."
  - [section]: "By combining the expertise of LLMs as verifiers with humans as input sources, we achieve efficient, accurate, and reliable translations."
- Break condition: If LLM extraction becomes unreliable due to domain shift, or if human validation becomes too costly at scale.

## Foundational Learning

- Concept: Terminology extraction and validation workflow
  - Why needed here: The dataset requires accurate identification of AI-specific terms from research papers, which demands understanding both the extraction process and validation criteria.
  - Quick check question: What are the three criteria used to define AI-specific terminology in the extraction process?

- Concept: Cross-lingual morphological differences
  - Why needed here: Different target languages have varying morphological complexity, affecting how terminology integration methods perform.
  - Quick check question: Which two languages in the dataset have minimal morphological variation in nouns and noun phrases?

- Concept: Machine translation evaluation metrics
  - Why needed here: The system's performance is measured using multiple metrics (BLEU, COMET, ChrF, ChrF++, TER), requiring understanding of what each metric captures.
  - Quick check question: Which metric specifically measures character-level n-gram precision between hypothesis and reference?

## Architecture Onboarding

- Component map: LLaMA-3-70B-Instruct → human filtering → POS tagging → MTurk annotators → GPT-4o candidate selection → term dictionary → Direct translation → LLM prompting refinement OR word alignment substitution → Evaluation pipeline
- Critical path: Term extraction → translation → integration → evaluation
- Design tradeoffs:
  - LLM-only extraction is fast but less accurate; hybrid approach adds quality but increases cost
  - Word alignment is fast but language-dependent; LLM prompting is slower but more robust
  - Post-hoc refinement avoids retraining but may miss some context; integrated approaches might be more consistent
- Failure signatures:
  - Poor translation quality: check term dictionary completeness and GPT-4o selection accuracy
  - Grammatical errors after integration: verify LLM prompting instructions and morphological handling
  - Low alignment confidence: examine BERT tokenization and similarity thresholds
- First 3 experiments:
  1. Run LLM prompting on a small sample of translations and compare BLEU scores against direct translation
  2. Test word alignment substitution on Chinese and Arabic samples to observe performance differences
  3. Evaluate GPT-4o candidate selection against majority voting on a subset of translated terms

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the GIST framework be effectively adapted for terminology extraction and translation in other specialized domains (e.g., medical, legal, or engineering)?
- Basis in paper: [inferred] The paper notes that "our methodology is tailored for AI terminology translation" and "expanding the terminology dataset automatically presents unique challenges" due to domain-specific variations in terminology collection and evaluation requirements.
- Why unresolved: The authors acknowledge that the LLM + Human hybrid framework could be broadly applicable but domain-specific challenges (terminology collection variations, need for domain-specific expertise) remain unexplored. The paper doesn't test or validate the framework outside AI.
- What evidence would resolve it: Experiments applying the GIST framework to at least two non-AI domains with comparative quality assessments against existing domain-specific terminology resources.

### Open Question 2
- Question: What is the optimal frequency and methodology for updating the GIST dataset to maintain currency with rapidly evolving AI terminology?
- Basis in paper: [explicit] The authors identify this as a limitation: "the rapidly evolving nature of the AI field requires frequent updates" and "identifying new, domain-relevant terms still depends heavily on human expertise."
- Why unresolved: The paper doesn't propose or test any systematic approach for continuous updates. It only acknowledges the challenge of balancing automated extraction (limited by knowledge cutoffs) with human expertise.
- What evidence would resolve it: A longitudinal study demonstrating different update strategies (frequency, automated vs. human-driven) and their impact on terminology coverage and translation quality over time.

### Open Question 3
- Question: How does the performance of terminology integration methods vary across different MT model architectures and sizes?
- Basis in paper: [explicit] The paper tests five models (gpt-4o-mini, hf-seamless-m4t-large, nllb-200-3.3B, aya-23-8B, aya-expanse-8B) but only reports results for prompting and word alignment methods. The authors note that "constrained beam search and token-level logits adjustment" were tested qualitatively but performed poorly.
- Why unresolved: The paper doesn't provide comprehensive quantitative comparison across all terminology integration methods for all tested models, nor does it explore whether model architecture (encoder-decoder vs. decoder-only) or parameter count affects integration effectiveness.
- What evidence would resolve it: Systematic quantitative evaluation of all terminology integration methods (prompting, word alignment, constrained decoding, logits adjustment) across a broader range of model architectures and sizes, with statistical significance testing.

## Limitations
- Dataset coverage may be biased toward ACL award-winning papers, potentially missing important AI terminology from other sources
- Hybrid human-LLM workflow increases costs and may not scale effectively for all target languages
- Evaluation relies primarily on automated metrics without comprehensive human judgment studies across all languages
- Five target languages exclude many other languages spoken by AI researchers globally

## Confidence
- **High Confidence**: LLM prompting superiority over direct translation for terminology integration; extraction methodology combining LLaMA-3-70B-Instruct with human filtering
- **Medium Confidence**: Language-dependent performance of word alignment method; effectiveness of hybrid human-LLM translation workflow
- **Low Confidence**: Claim of being "first large-scale multilingual AI terminology dataset"; impact assertions on global AI inclusivity

## Next Checks
1. Evaluate GIST-integrated translations on non-conference AI literature (textbooks, industry reports, blogs) to assess domain generalizability
2. Conduct detailed linguistic analysis of translation failures for Arabic/French/Russian to identify root causes and develop targeted mitigation strategies
3. Measure scalability of hybrid workflow by comparing translation quality and costs across different validation intensities to identify optimal resource allocation