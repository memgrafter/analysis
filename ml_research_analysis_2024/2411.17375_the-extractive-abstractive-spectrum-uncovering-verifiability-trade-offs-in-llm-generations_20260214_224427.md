---
ver: rpa2
title: 'The Extractive-Abstractive Spectrum: Uncovering Verifiability Trade-offs in
  LLM Generations'
arxiv_id: '2411.17375'
source_url: https://arxiv.org/abs/2411.17375
tags:
- response
- query
- information
- sources
- your
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the extractive-abstractive spectrum to analyze
  trade-offs in large language model (LLM) generation quality versus verifiability.
  The spectrum defines five operating points from extractive (direct source quotes)
  to abstractive (logical transformations) generations.
---

# The Extractive-Abstractive Spectrum: Uncovering Verifiability Trade-offs in LLM Generations

## Quick Facts
- arXiv ID: 2411.17375
- Source URL: https://arxiv.org/abs/2411.17375
- Reference count: 40
- Primary result: LLM generations show up to 200% utility improvement and 50% citation degradation when moving from extractive to abstractive operating points

## Executive Summary
This paper introduces the extractive-abstractive spectrum to analyze trade-offs between generation quality and verifiability in large language models. The spectrum defines five operating points ranging from purely extractive (direct source quotes) to highly abstractive (logical transformations). Through human evaluations across four query distributions, the study reveals that while abstractive generations demonstrate significantly higher perceived utility, they suffer from substantially lower proper citation rates and increased verification times. The findings suggest that different application settings require distinct operating points along the spectrum to balance these competing objectives.

## Method Summary
The authors defined five operating points along the extractive-abstractive spectrum and conducted human evaluations using Mechanical Turk workers. They evaluated LLM generations across four query distributions (simple, complex, ambiguous, and multi-hop) to assess perceived utility, proper citation rates, and verification time. The study specifically examined Gemini model generations and compared their performance across different points on the spectrum.

## Key Results
- Abstractive generations show up to 200% higher perceived utility compared to extractive generations
- Proper citation rates drop by up to 50% as generations become more abstractive
- Verification time triples when moving from extractive to abstractive operating points
- Gemini model properly cites only 15% of sentences despite high utility scores

## Why This Works (Mechanism)
The trade-offs observed in the extractive-abstractive spectrum stem from fundamental differences in how information is processed and presented at each operating point. Extractive generations preserve source fidelity through direct quotation, making verification straightforward but limiting expressiveness. Abstractive generations enable more natural, coherent responses through logical transformations, but this abstraction makes it harder to trace claims back to original sources and requires more cognitive effort for verification.

## Foundational Learning
- **Extractive vs Abstractive Generation**: Understanding the spectrum from direct quotation to logical transformation
  - Why needed: Forms the basis for analyzing verifiability trade-offs
  - Quick check: Can identify examples of both approaches in sample text

- **Citation Quality Metrics**: Framework for evaluating proper citation in LLM outputs
  - Why needed: Essential for measuring verifiability across operating points
- **Human Evaluation Methodology**: Best practices for assessing LLM output quality
  - Why needed: Ensures reliable measurement of utility and citation metrics
- **Query Distribution Types**: Simple, complex, ambiguous, and multi-hop query characteristics
  - Why needed: Different query types stress different aspects of the generation spectrum
- **Verification Time Measurement**: Methods for quantifying the effort required to verify claims
  - Why needed: Provides quantitative measure of verifiability trade-offs
- **Operating Point Definition**: Clear criteria for positioning along the spectrum
  - Why needed: Enables systematic comparison across different generation approaches

## Architecture Onboarding

**Component Map**: Input Query -> Retrieval System -> Generation Model -> Output Spectrum Position -> Human Evaluation

**Critical Path**: The retrieval system and generation model interaction determines the operating point selection, which directly impacts both utility and verifiability metrics measured in human evaluation.

**Design Tradeoffs**: The spectrum represents a fundamental tension between expressiveness (utility) and traceability (verifiability). Higher utility requires more abstraction, which inherently reduces citation quality and increases verification complexity.

**Failure Signatures**: When operating points are poorly chosen for a given application, systems experience either low utility (if too extractive) or poor verifiability (if too abstractive). Gemini's 15% proper citation rate exemplifies failure in the abstractive direction.

**3 First Experiments**:
1. Map sample queries to their optimal operating points based on domain requirements
2. Measure citation quality degradation when forcing abstractive generations on citation-heavy tasks
3. Test hybrid approaches that combine multiple operating points within single generations

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Human evaluations rely on Mechanical Turk workers who may lack domain expertise for complex queries
- Limited evaluation scope with only four query distributions tested
- Study focused exclusively on Gemini model generations, limiting generalizability

## Confidence
- Directional findings about utility-verifiability trade-offs: High confidence
- Specific quantitative estimates (200% utility, 50% citation drop): Medium confidence
- Gemini's 15% citation rate: High confidence
- Recommendations for distinct operating points: Medium confidence

## Next Checks
1. Replicate human evaluation with domain-expert annotators for complex and multi-hop queries
2. Test additional LLM architectures (GPT, Claude, etc.) across the same query distributions
3. Conduct longitudinal study tracking citation quality and verification time as models are fine-tuned for improved verifiability