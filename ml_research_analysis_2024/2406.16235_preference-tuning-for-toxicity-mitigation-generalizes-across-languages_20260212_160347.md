---
ver: rpa2
title: Preference Tuning For Toxicity Mitigation Generalizes Across Languages
arxiv_id: '2406.16235'
source_url: https://arxiv.org/abs/2406.16235
tags:
- toxicity
- toxic
- arxiv
- languages
- multilingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates cross-lingual generalization of preference
  tuning for toxicity mitigation in large language models. The study demonstrates
  that Direct Preference Optimization (DPO) trained on English-only data significantly
  reduces multilingual toxicity across 17 languages, with mGPT's toxic generation
  probability dropping from 46.8% to 3.9%.
---

# Preference Tuning For Toxicity Mitigation Generalizes Across Languages

## Quick Facts
- **arXiv ID**: 2406.16235
- **Source URL**: https://arxiv.org/abs/2406.16235
- **Reference count**: 40
- **Primary result**: English-only preference tuning reduces multilingual toxicity across 17 languages in multiple model families

## Executive Summary
This paper demonstrates that Direct Preference Optimization (DPO) trained on English toxic/non-toxic preference data significantly reduces multilingual toxic content generation across 17 languages without requiring cross-lingual training data. The key insight is that the "dual multilinguality" property of MLP layers enables toxic neurons to encode multilingual toxic concepts that can be suppressed through English-based preference tuning. The study validates this cross-lingual effectiveness across multiple multilingual models (mGPT, BLOOM, Llama3, Aya-23) and identifies bilingual sentence retrieval accuracy as a strong predictor (Pearson-r = 0.73) of detoxification effectiveness. Results show consistent toxicity reduction while maintaining fluency and diversity across languages.

## Method Summary
The study employs Direct Preference Optimization (DPO) with BCELoss to fine-tune multilingual language models using English-only toxic/non-toxic preference pairs. The training pipeline includes full model finetuning for smaller models (mGPT-1.3B, BLOOM-1.7B) and QLoRA adapters for larger models (Llama2-7B, Llama3-8B, Aya-23-8B) with rank 64, scaling 16, and dropout 0.05. Evaluation uses the RTP-LX multilingual toxic prompts dataset with 25 continuations per prompt generated using nucleus sampling (temp=0.9, top-p=0.8). Toxicity is measured using Perspective API across 17 languages, calculating Expected Maximum Toxicity (EMT), Toxicity Probability (ToxProb), and Average Toxicity (AvgTox). The study also analyzes bilingual sentence retrieval accuracy using 200 parallel toxic prompts to predict cross-lingual effectiveness.

## Key Results
- mGPT toxic generation probability drops from 46.8% to 3.9% after English DPO training
- Cross-lingual detoxification effectiveness correlates with bilingual sentence retrieval accuracy (Pearson-r = 0.73)
- Same toxic neurons are suppressed across all 17 languages after DPO training
- Consistent toxicity reduction observed across multiple model families (mGPT, BLOOM, Llama3, Aya-23)
- Fluency maintained with only moderate perplexity increases, diversity preserved across n-gram ranges

## Why This Works (Mechanism)
The cross-lingual generalization occurs through the "dual multilinguality" property of MLP layers, where toxic value vectors encode multilingual toxic concepts that respond to toxic prompts across different languages. When DPO suppresses these toxic neurons in English, the same neurons responsible for toxic generation in other languages are also suppressed, creating a zero-shot cross-lingual effect. This mechanism is supported by neuron-level analysis showing identical toxic neurons being suppressed across all languages, and the strong correlation between bilingual sentence retrieval accuracy and detoxification effectiveness suggests that language alignment in toxic subspaces is the key predictor of transferability.

## Foundational Learning
**Direct Preference Optimization (DPO)**: A fine-tuning method that learns from pairwise preference data without requiring explicit reward modeling - needed to understand how English preferences translate to multilingual behavior; quick check: verify BCELoss implementation and pairwise comparison logic.

**Dual Multilinguality**: The property where neural representations encode concepts that are shared across languages in MLP layers - needed to explain why suppressing toxic neurons in English affects all languages; quick check: examine neuron activation patterns across languages before/after training.

**Bilingual Sentence Retrieval**: A method for measuring semantic alignment between languages using parallel toxic prompts - needed to predict cross-lingual transferability of preference tuning; quick check: verify retrieval accuracy calculation and parallel prompt quality.

**Perspective API**: Google's toxicity detection service used for multilingual evaluation - needed to quantify toxicity across 17 languages consistently; quick check: validate API scores on known toxic/non-toxic examples.

**Nucleus Sampling**: A decoding strategy that samples from the smallest possible set of tokens whose cumulative probability exceeds a threshold - needed to generate diverse yet controlled continuations; quick check: verify temperature and top-p parameters in generation code.

## Architecture Onboarding

**Component Map**: RTP-LX prompts -> Generation (nucleus sampling) -> Toxicity Scoring (Perspective API) -> DPO Training (English pairs) -> Model Update -> Evaluation (EMT, ToxProb, AvgTox, Perplexity, Diversity)

**Critical Path**: The neuron-level toxic concept encoding in MLP layers forms the critical path for cross-lingual effectiveness. When DPO suppresses toxic neurons in English, these same neurons are responsible for toxic generation across all languages, making neuron suppression the key mechanism for zero-shot cross-lingual detoxification.

**Design Tradeoffs**: The study balances toxicity reduction against fluency (perplexity) and diversity (distinct n-grams). Higher learning rates achieve better toxicity reduction but worsen perplexity scores, while lower learning rates preserve fluency but reduce detoxification effectiveness. The choice of nucleus sampling parameters (temp=0.9, top-p=0.8) balances generation quality with computational efficiency.

**Failure Signatures**: 
- Insufficient toxicity reduction in low-resource languages (Hindi, Korean, Czech) indicates poor language alignment in toxic subspaces
- Model degeneration with high perplexity scores suggests excessive suppression of non-toxic content
- Training instability or divergence indicates hyperparameter misalignment

**3 First Experiments**:
1. Generate 25 continuations for a subset of RTP-LX prompts using baseline mGPT to establish toxicity baseline scores
2. Train DPO on English preference pairs and verify English toxicity reduction before evaluating cross-lingual effects
3. Calculate bilingual sentence retrieval accuracy for 200 parallel toxic prompts to predict cross-lingual effectiveness

## Open Questions the Paper Calls Out
**Open Question 1**: What specific linguistic or cultural factors explain why Hindi, Korean, and Czech showed the least reduction in toxicity levels after English DPO training? The paper suggests pretraining resources and alignment as possible reasons but lacks detailed linguistic analysis or controlled experiments to isolate specific factors.

**Open Question 2**: How do the trade-offs between toxicity reduction and fluency (measured by perplexity) vary across different multilingual models and what mechanisms explain these differences? The paper observes the trade-off exists but doesn't investigate whether different models exhibit different trade-off curves or what architectural factors might influence this relationship.

**Open Question 3**: What is the precise relationship between bilingual sentence retrieval accuracy and cross-lingual detoxification effectiveness across different language pairs and model scales? While a correlation is established, the paper doesn't explore whether this relationship holds across different model scales, whether the relationship is linear or non-linear, or what linguistic features drive the strongest correlations.

## Limitations
- Relies heavily on synthetic prompt generation which may not capture real-world usage patterns
- Toxicity evaluation using Perspective API may not perfectly align with human judgment across all 17 languages
- Analysis focuses primarily on mGPT and limited other models, potentially limiting universal applicability conclusions

## Confidence
- **High confidence** in core finding of cross-lingual detoxification effectiveness across multiple model families
- **Medium confidence** in bilingual sentence retrieval correlation as predictive metric (Pearson-r = 0.73)
- **Medium confidence** in safety-utility tradeoff conclusions without comprehensive bias analysis

## Next Checks
1. **Human evaluation study**: Conduct human-annotated toxicity assessments across all 17 languages to validate Perspective API results and quantify alignment between automated and human judgment
2. **Long-form generation analysis**: Extend toxicity evaluation to longer continuations (500+ tokens) to assess whether cross-lingual detoxification effectiveness persists in extended discourse contexts
3. **Cross-task performance evaluation**: Test the fine-tuned models on multilingual benchmark tasks (e.g., XNLI, MMLU, cross-lingual question answering) to quantify any performance tradeoffs introduced by detoxification