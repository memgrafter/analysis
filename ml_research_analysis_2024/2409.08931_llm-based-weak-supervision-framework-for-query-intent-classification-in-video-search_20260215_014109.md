---
ver: rpa2
title: LLM-based Weak Supervision Framework for Query Intent Classification in Video
  Search
arxiv_id: '2409.08931'
source_url: https://arxiv.org/abs/2409.08931
tags:
- query
- entity
- data
- search
- movies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of query intent classification
  in video search by introducing an LLM-based weak supervision framework. The authors
  leverage large language models (LLMs) with advanced prompt engineering techniques,
  including Chain of Thought and In-Context Learning, to automatically annotate a
  vast collection of user search queries.
---

# LLM-based Weak Supervision Framework for Query Intent Classification in Video Search

## Quick Facts
- arXiv ID: 2409.08931
- Source URL: https://arxiv.org/abs/2409.08931
- Reference count: 11
- Primary result: 113% improvement in recall for query intent classification using LLM-based weak supervision

## Executive Summary
This paper introduces an LLM-based weak supervision framework for query intent classification in video search. The authors leverage large language models with advanced prompt engineering techniques to automatically annotate user search queries, addressing the limitations of manual annotation and click data. By training a low-latency BERT model on LLM-generated data, the framework achieves significant improvements in recall and F1 score while maintaining real-time inference capabilities. The approach combines Chain of Thought reasoning, In-Context Learning, and a multi-agent persona-driven ensemble to enhance annotation accuracy and agreement with human annotations.

## Method Summary
The framework uses LLMs to automatically annotate user search queries through prompt engineering with Chain of Thought and In-Context Learning techniques. These annotations serve as training data for a low-latency BERT model optimized for real-time inference. A multi-agent persona-driven approach generates diverse responses, with a routing mechanism selecting the most appropriate personas for each query. The system is evaluated on a proprietary streaming service dataset, demonstrating substantial improvements over traditional NLU systems.

## Key Results
- 113% improvement in recall compared to traditional NLU systems
- 47.60% improvement in F1 score agreement between LLM predictions and human annotations
- 3.67% additional F1 score increase using the persona selection routing mechanism

## Why This Works (Mechanism)

### Mechanism 1
LLM-based weak supervision significantly improves query intent classification recall by automatically generating high-quality training data that aligns with human expectations, overcoming the limitations of manual annotation and click data.

### Mechanism 2
Chain of Thought and In-Context Learning prompt engineering techniques enhance LLM annotation accuracy by providing structured reasoning processes and domain-specific examples that improve the model's understanding of query intent classification tasks.

### Mechanism 3
The multi-agent persona-driven ensemble approach improves agreement rates between LLM predictions and human annotations by leveraging diverse perspectives and specialized knowledge through a strategic routing mechanism that selects the most relevant personas for each query.

## Foundational Learning

- **Query intent classification**: Understanding and categorizing user search queries in video search; needed to improve search functionality and user experience
- **Weak supervision**: Automatic annotation of data using LLMs; needed to overcome limitations of manual annotation and scale to large datasets
- **Prompt engineering techniques (CoT and ICL)**: Methods to enhance LLM prompt effectiveness; needed to improve annotation accuracy and query understanding

## Architecture Onboarding

- **Component map**: User queries → LLM annotation (CoT + ICL) → Persona-driven ensemble → BERT training → Real-time inference
- **Critical path**: LLM generates annotations → Training data preparation → BERT model training → Real-time inference
- **Design tradeoffs**: LLM-based annotation vs. manual annotation (cost, scalability, accuracy); real-time inference using BERT vs. LLMs (latency, computational overhead); multi-agent persona approach vs. single-agent (diversity, complexity)
- **Failure signatures**: Low agreement between LLM predictions and human annotations; poor BERT model performance on real-time inference; inefficient persona selection
- **First 3 experiments**: 
  1. Evaluate different LLM models on manually annotated dataset
  2. Conduct ablation study on prompt engineering techniques
  3. Test persona selection routing mechanism performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the persona selection router mechanism handle queries containing multiple intents from different entity categories? The paper mentions the router takes semantic embeddings but doesn't elaborate on multi-intent handling.

### Open Question 2
How does the multi-label entity classifier performance compare to other state-of-the-art models for query intent classification in video search? The paper demonstrates effectiveness against a baseline but lacks comprehensive comparative analysis.

### Open Question 3
How does the proposed approach scale to handle larger numbers of entities and more complex query patterns? The paper shows effectiveness for 20+ entities but doesn't explore scalability limitations.

## Limitations

- Relies on proprietary streaming service data that cannot be independently verified
- Performance improvements benchmarked against unspecified baseline systems without detailed comparative analysis
- Multi-agent persona approach introduces complexity without clear ablation studies demonstrating component necessity

## Confidence

- **High confidence**: Core methodology of using LLM-based weak supervision is technically sound
- **Medium confidence**: Specific performance improvements lack independent verification and detailed baseline specifications
- **Low confidence**: Multi-agent persona routing mechanism's contribution is difficult to evaluate without implementation details

## Next Checks

1. Conduct an ablation study comparing the full system against variants without persona routing, CoT prompting, and ICL
2. Evaluate the system on publicly available query intent classification datasets to assess generalizability
3. Implement latency analysis comparing BERT-based inference against direct LLM inference across different query volumes