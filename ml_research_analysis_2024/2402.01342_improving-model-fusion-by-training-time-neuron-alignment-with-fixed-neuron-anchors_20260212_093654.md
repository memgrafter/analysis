---
ver: rpa2
title: Improving Model Fusion by Training-time Neuron Alignment with Fixed Neuron
  Anchors
arxiv_id: '2402.01342'
source_url: https://arxiv.org/abs/2402.01342
tags:
- tna-pfn
- learning
- fusion
- vanilla
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving model fusion in deep
  learning by tackling neuron misalignment caused by permutation symmetry. The authors
  hypothesize that reducing permutation symmetries during training through partial
  neuron weight fixing (TNA-PFN) can enhance linear mode connectivity and model fusion.
---

# Improving Model Fusion by Training-time Neuron Alignment with Fixed Neuron Anchors

## Quick Facts
- arXiv ID: 2402.01342
- Source URL: https://arxiv.org/abs/2402.01342
- Reference count: 40
- One-line primary result: A method that improves model fusion by reducing permutation symmetry through partially fixed neuron weights during training, achieving state-of-the-art results in federated learning under heterogeneous settings.

## Executive Summary
This paper addresses the fundamental problem of neuron misalignment in deep learning model fusion caused by permutation symmetry. The authors propose Training-time Neuron Alignment with Partially Fixed Neurons (TNA-PFN), which reduces permutation symmetries during training by fixing some neuron weights as anchors. This approach constrains training to a permutation subspace, improving linear mode connectivity and enabling better model fusion across various applications including model soup, ColD fusion, and federated learning. The method demonstrates significant improvements over baseline fusion techniques and achieves state-of-the-art performance in federated learning scenarios.

## Method Summary
TNA-PFN reduces permutation symmetry by partially fixing neuron weights during training, using these fixed weights as anchors to constrain training within a permutation subspace. The method generates a random binary mask that determines which neurons remain fixed throughout training, with the mask ratio (proportion of fixed neurons) as a key hyperparameter. This approach breaks the network's permutation invariance while preserving expressiveness through overparameterization. The authors extend this to federated learning with two algorithms: FedPFN (using fixed masks) and FedPNU (using progressive neuron updating with alternating masks). The method is validated across multiple architectures including CNNs, ResNets, and transformers on diverse datasets.

## Key Results
- Reduces linear mode connectivity barriers by 60-90% across various neural architectures
- Improves model soup fusion accuracy by 1-2% on ViT-B/32 models
- Achieves state-of-the-art federated learning performance, outperforming FedAvg and FedProx by 2-5% in non-IID settings
- FedPNU demonstrates robustness to mask ratio variations, maintaining performance across a wider range of hyperparameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TNA-PFN reduces permutation symmetry by partially fixing neuron weights as anchors, thereby constraining training to a permutation subspace.
- Mechanism: During training, a fixed mask of neuron weights is applied such that some weights are never updated. This breaks the network's permutation symmetry, forcing models trained with the same mask to learn in the same effective subspace.
- Core assumption: DNNs are overparameterized, so partially freezing weights won't harm generalization and may act as regularization.
- Evidence anchors:
  - [abstract] "TNA-PFN utilizes partially fixed neuron weights as anchors to reduce the potential of training-time permutations"
  - [section III-C] "We propose to fix some neurons’ weights, which will also break the network symmetry to reduce the permutations while preserving the expressiveness power of networks."
  - [corpus] Weak: no direct corpus papers discussing fixed neuron anchors, but similar concepts appear in pruning literature.
- Break condition: If the mask ratio is too high, the network loses expressiveness and fails to train effectively.

### Mechanism 2
- Claim: Learning in the same permutation subspace improves linear mode connectivity (LMC) and model fusion performance.
- Mechanism: When different models are trained with the same fixed mask, their learned representations are more aligned in parameter space, reducing the loss barrier along linear interpolation paths.
- Core assumption: The primary cause of LMC barriers is permutation invariance, and constraining training to a shared subspace mitigates this.
- Evidence anchors:
  - [abstract] "It is found that pruning at initialization supports the hypothesis, but pruning will impair individual model performances."
  - [section III-B] "It is validated in Figure 2 that pruning can actually improve LMC compared with vanilla training, which supports our hypothesis."
  - [section III-C] "Due to the overparameterization property of DNNs, partially fixing some weights as TNA-PFN will not impede the optimization, instead, serving as regularization for better generalization."
- Break condition: If the mask changes between models or training runs, the alignment benefit is lost.

### Mechanism 3
- Claim: Progressive neuron updating (FedPNU) improves robustness to hyperparameter settings compared to fixed masking (FedPFN).
- Mechanism: FedPNU alternates between training with the fixed mask and its complement, ensuring all neurons are eventually updated while maintaining alignment benefits.
- Core assumption: Progressive exposure to different subspaces prevents any single neuron from being under-trained while still breaking symmetry.
- Evidence anchors:
  - [section V-B] "In FedPNU, we additionally consider a reversed mask ˆmt of mt. During training, the clients first train with mask mt according to Equation 11 for the half local training, i.e., int( E / 2 ) epochs; then, they train with the reversed mask ˆmt for the remaining E - int( E / 2 ) epochs."
  - [section V-C] "Similar reasons are also for why FedPNU is robust when the mask ratio is as high as 0.9 in Figure 10."
  - [corpus] Weak: no direct corpus papers on progressive neuron updating, but related to curriculum learning concepts.
- Break condition: If the alternation frequency is too low, the alignment benefit diminishes; if too high, training becomes unstable.

## Foundational Learning

- Concept: Permutation invariance in neural networks
  - Why needed here: Understanding why different models can have the same function but different parameter configurations is crucial for grasping the alignment problem.
  - Quick check question: If I permute the neurons in a hidden layer of a trained network, will the network's output change?

- Concept: Linear mode connectivity
  - Why needed here: LMC measures how well two models can be linearly interpolated without loss increase, which is fundamental to understanding model fusion barriers.
  - Quick check question: What happens to the loss when interpolating between two independently trained models with the same architecture but different random seeds?

- Concept: Overparameterization in deep learning
  - Why needed here: The method relies on the fact that networks have more parameters than needed, allowing some to be fixed without harming performance.
  - Quick check question: Why can we prune a large percentage of weights from a trained network without destroying its functionality?

## Architecture Onboarding

- Component map:
  - TNA-PFN: Random mask generation → Fixed weight application → SGD updates
  - FedPFN: Server generates mask → Clients apply mask during local training → Server aggregates
  - FedPNU: Same as FedPFN but with alternating mask strategy

- Critical path:
  1. Generate consistent random mask across all models/clients
  2. Apply mask before gradient computation
  3. Train with masked gradients
  4. Aggregate models (for federated learning)
  5. Generate new mask for next round

- Design tradeoffs:
  - Mask ratio vs. performance: Higher ratios provide better alignment but risk under-training
  - Fixed vs. progressive masking: Fixed is simpler but less robust; progressive is more complex but handles high ratios better
  - Random vs. magnitude-based selection: Random is simpler; magnitude-based can be more effective for pretrained models

- Failure signatures:
  - Training divergence: Mask ratio too high, causing under-training
  - No improvement in fusion: Mask not consistent across models
  - Increased barrier: Mask changing between training runs

- First 3 experiments:
  1. Implement TNA-PFN on a simple MLP for MNIST with mask ratio 0.4 and verify LMC improvement
  2. Test FedPFN on CIFAR-10 with 2 clients, comparing to FedAvg with same mask ratio
  3. Implement FedPNU and compare its robustness to different mask ratios against FedPFN on the same setup

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can TNA-PFN be extended to other deep learning architectures beyond CNNs, ResNets, and transformers, such as graph neural networks or recurrent neural networks?
- Basis in paper: [inferred] The paper mentions that previous post-training neuron alignment methods are not applicable to attention layers and layer normalizations in transformer blocks, and the authors suggest that the applicability of their method to new architectures like KAN and Mamba remains questionable.
- Why unresolved: The paper does not provide empirical evidence or theoretical analysis for the effectiveness of TNA-PFN on architectures beyond CNNs, ResNets, and transformers.
- What evidence would resolve it: Experimental results showing the performance of TNA-PFN on graph neural networks or recurrent neural networks, or a theoretical analysis of how the method can be adapted to these architectures.

### Open Question 2
- Question: How does the choice of mask ratio affect the performance of TNA-PFN in different federated learning scenarios, such as varying numbers of clients or data heterogeneity levels?
- Basis in paper: [explicit] The paper discusses the effects of mask ratios on TNA-PFN's performance in federated learning, noting that FedPFN is sensitive to the mask ratio while FedPNU is more robust. However, it does not provide a comprehensive analysis of how the mask ratio affects performance across different federated learning scenarios.
- Why unresolved: The paper does not explore the relationship between mask ratio and performance in detail, nor does it provide guidelines for choosing the optimal mask ratio in different federated learning scenarios.
- What evidence would resolve it: A study that systematically varies the mask ratio and evaluates the performance of TNA-PFN in different federated learning scenarios, providing insights into how the mask ratio affects performance and guidelines for choosing the optimal mask ratio.

### Open Question 3
- Question: Can TNA-PFN be combined with other techniques for improving model fusion, such as weight decay or ensemble distillation, to further enhance performance?
- Basis in paper: [explicit] The paper mentions that TNA-PFN is orthogonal to server-side model fusion techniques in federated learning, suggesting that it can be combined with other methods. However, it does not explore the potential benefits of combining TNA-PFN with other techniques for improving model fusion.
- Why unresolved: The paper does not investigate the potential synergies between TNA-PFN and other techniques for improving model fusion, nor does it provide empirical evidence for the benefits of such combinations.
- What evidence would resolve it: Experimental results showing the performance of TNA-PFN combined with other techniques for improving model fusion, such as weight decay or ensemble distillation, compared to the individual methods.

## Limitations

- The method relies heavily on a single hyperparameter (mask ratio) whose optimal value is dataset and architecture-dependent, requiring empirical tuning
- The approach has not been validated on extremely large-scale models (e.g., ResNet50, ViT-Large) or datasets (e.g., ImageNet), leaving questions about scalability
- While effective for CNNs, ResNets, and transformers, the method's applicability to other architectures like graph neural networks or recurrent neural networks remains unexplored

## Confidence

- **High confidence**: The mechanism of reducing permutation symmetry through fixed neuron weights is well-supported by both theory and empirical results. The LMC improvements are consistently observed across different architectures and datasets.
- **Medium confidence**: The federated learning improvements, while impressive, depend heavily on the non-IID data distribution setup. The robustness claims for FedPNU need further validation across diverse federated scenarios.
- **Medium confidence**: The transfer of fixed masks from pretrained models shows promise but lacks systematic analysis of how to optimally select which neurons to fix based on their initial magnitudes.

## Next Checks

1. **Ablation on mask selection strategy**: Compare random masking against magnitude-based masking for pretrained models across different model families to determine when each strategy is optimal.
2. **Scaling analysis**: Test TNA-PFN on larger models (ResNet50, ViT-Large) and datasets (ImageNet) to verify the method scales effectively to more challenging settings.
3. **Dynamic mask ratio**: Implement an adaptive mask ratio that changes during training based on convergence metrics to automatically find the optimal balance between alignment and expressiveness.