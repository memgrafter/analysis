---
ver: rpa2
title: Multiplicative Logit Adjustment Approximates Neural-Collapse-Aware Decision
  Boundary Adjustment
arxiv_id: '2409.17582'
source_url: https://arxiv.org/abs/2409.17582
tags:
- learning
- training
- following
- feature
- holds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper provides theoretical justification for multiplicative
  logit adjustment (MLA), a simple heuristic method for long-tailed recognition. The
  core method idea is to approximate optimal decision boundary adjustments derived
  from neural collapse analysis.
---

# Multiplicative Logit Adjustment Approximates Neural-Collapse-Aware Decision Boundary Adjustment

## Quick Facts
- arXiv ID: 2409.17582
- Source URL: https://arxiv.org/abs/2409.17582
- Reference count: 40
- Primary result: MLA achieves 52.9% accuracy on CIFAR100-LT and 52.6% on ImageNet-LT

## Executive Summary
This paper provides theoretical justification for multiplicative logit adjustment (MLA), a simple heuristic method for long-tailed recognition. The authors show that MLA approximates optimal decision boundary adjustments derived from neural collapse analysis by scaling logit values based on class sample sizes. Experimental results demonstrate that MLA achieves comparable accuracy to more complex methods while being significantly simpler to implement and tune.

## Method Summary
MLA is a post-processing technique that adjusts classifier logits during inference by multiplying them with factors proportional to n^{-γ}_k, where n_k is the number of training samples in class k and γ is a hyperparameter. The method approximates theoretically optimal decision boundary adjustments derived from neural collapse analysis, where features within each class converge to their class means and the feature spread scales inversely with the square root of class sample size.

## Key Results
- MLA achieves 52.9% test accuracy on CIFAR100-LT (ρ=100)
- MLA achieves 52.6% test accuracy on ImageNet-LT (ρ=100)
- MLA matches or exceeds performance of more complex methods like 1vs1Adjuster

## Why This Works (Mechanism)

### Mechanism 1
MLA approximates optimal decision boundary adjustments derived from neural collapse analysis by scaling logits based on class sample sizes. When neural collapse occurs, features within each class converge to their class means, and the feature spread is inversely proportional to the square root of the class sample size. MLA adjusts logits by a factor proportional to n^{-γ}_k, which approximates the theoretically optimal boundary adjustment between classes.

### Mechanism 2
MLA provides better approximation to optimal adjustments than ALA under long-tailed recognition settings. ALA adjusts logits additively based on log(n_k), which depends on feature norm and creates inconsistent decision boundaries across samples. MLA adjusts multiplicatively based on n^{-γ}_k, which maintains consistent decision boundaries regardless of feature norm.

### Mechanism 3
MLA hyperparameters γ should be approximately 0.5 when neural collapse fully occurs, but may vary when collapse is incomplete. When neural collapse fully occurs, feature spread is bounded to a smaller order than O(1/√n_k), requiring γ > 0.5. When collapse is incomplete, feature spread differences are smaller, requiring γ < 0.5.

## Foundational Learning

- **Neural Collapse (NC)**: When deep networks are trained to perfection, features from the same class collapse to their mean, class means form a simplex ETF structure, and decision boundaries align with nearest class mean. *Why needed*: NC provides the theoretical foundation for estimating feature spread and deriving optimal decision boundary adjustments that MLA approximates. *Quick check*: What are the four key phenomena that characterize neural collapse according to Papyan et al. [2020]?

- **Rademacher Complexity**: A measure of the richness of a function class that provides uniform convergence bounds for empirical processes. *Why needed*: Used to bound the deviation between empirical feature averages and expected feature values, which is crucial for proving the feature spread estimation theory. *Quick check*: How does Rademacher complexity typically scale with sample size n_k in the context of neural networks?

- **Equiangular Tight Frame (ETF)**: A set of unit vectors where the absolute value of the inner product between any two distinct vectors is constant. *Why needed*: The ETF structure of classifier weights under NC provides the geometric framework for optimal decision boundary placement between classes. *Quick check*: What is the inner product value between any two distinct weight vectors in an ETF classifier with K classes?

## Architecture Onboarding

- **Component map**: Feature extraction backbone (ResNet34/ResNeXt50/MLP) -> Linear classifier (ETF weights) -> MLA adjustment layer (multiplicative scaling) -> Loss function (cross-entropy) -> Regularization (weight decay, feature regularization)

- **Critical path**: Train backbone with cross-entropy loss and regularization -> Fix ETF classifier weights -> Apply MLA adjustment to logits during inference -> Evaluate classification accuracy

- **Design tradeoffs**: ETF classifier vs learned classifier: ETF promotes NC but may reduce flexibility; Feature regularization strength: Balances NC promotion vs feature diversity; γ tuning: Balances head vs tail class accuracy based on NC degree

- **Failure signatures**: Poor tail class accuracy: May indicate insufficient γ or incomplete NC; Degraded overall accuracy: May indicate over-regularization or incorrect ETF weights; High variance across runs: May indicate insufficient training or poor initialization

- **First 3 experiments**: Compare MLA vs baseline on CIFAR100-LT with default γ=0.5; Sweep γ values to find optimal setting for each dataset; Compare MLA vs ALA with tuned hyperparameters on ImageNet-LT

## Open Questions the Paper Calls Out

### Open Question 1
How does MLA perform on extremely long-tailed distributions with imbalance factors greater than 100? The paper only tests MLA on datasets with ρ = 100, while real-world scenarios may have much higher imbalance factors.

### Open Question 2
What is the optimal feature regularization strength for promoting neural collapse in different network architectures? The paper uses feature regularization (0.01 for image datasets, 0.001 for tabular data) but doesn't systematically explore its relationship with NC.

### Open Question 3
How does MLA's approximation quality vary with the number of classes in the dataset? The paper shows significant differences between MLA and 1vs1Adjuster on CIFAR10-LT (10 classes) but not on CIFAR100-LT (100 classes), suggesting class count matters.

## Limitations

- The theoretical framework relies heavily on neural collapse assumptions that may not hold in practical scenarios
- The core theory assumes feature spread scales as O(1/√n_k), but empirical evidence shows this relationship can vary significantly
- The analysis focuses on ETF classifiers, but most practical implementations use learned classifiers

## Confidence

- **High Confidence**: MLA achieves competitive empirical performance on standard benchmarks (CIFAR100-LT, ImageNet-LT)
- **Medium Confidence**: MLA provides better approximation than ALA under long-tailed settings
- **Medium Confidence**: Optimal γ values relate to degree of neural collapse realization
- **Low Confidence**: The theoretical approximation holds universally across different architectures and training conditions

## Next Checks

1. Test MLA on diverse architectures (CNNs, transformers, ViTs) to assess generalization beyond ResNet-based models

2. Systematically vary training duration, learning rates, and regularization strength to map the relationship between training dynamics and optimal γ values

3. Compare MLA performance when using learned classifiers versus fixed ETF weights to assess practical applicability