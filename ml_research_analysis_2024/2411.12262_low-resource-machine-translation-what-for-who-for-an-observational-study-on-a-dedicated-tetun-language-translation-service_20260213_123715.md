---
ver: rpa2
title: 'Low-resource Machine Translation: what for? who for? An observational study
  on a dedicated Tetun language translation service'
arxiv_id: '2411.12262'
source_url: https://arxiv.org/abs/2411.12262
tags:
- tetun
- language
- text
- translation
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study analyzes real-world usage patterns of tetun.org, a machine
  translation service for Tetun, the lingua franca of Timor-Leste. Using server logs
  from 100,000 translation requests, the researchers found that most users are likely
  Timorese students using mobile devices to translate educational content, particularly
  in science and healthcare domains, from high-resource languages into Tetun.
---

# Low-resource Machine Translation: what for? who for? An observational study on a dedicated Tetun language translation service

## Quick Facts
- arXiv ID: 2411.12262
- Source URL: https://arxiv.org/abs/2411.12262
- Authors: Raphael Merx; Adérito José Guterres Correia; Hanna Suominen; Ekaterina Vylomova
- Reference count: 22
- Most users are Timorese students using mobile devices to translate educational content from high-resource languages into Tetun

## Executive Summary
This study analyzes real-world usage patterns of tetun.org, a machine translation service for Tetun, the lingua franca of Timor-Leste. Using server logs from 100,000 translation requests, researchers found that most users are likely Timorese students using mobile devices to translate educational content, particularly in science and healthcare domains, from high-resource languages into Tetun. The analysis revealed a significant mismatch between the domains of user-translated text and existing Tetun corpora, which are dominated by news articles. The study recommends prioritizing domain coverage in education and healthcare, accuracy for high-resource-to-low-resource translation, and mobile-optimized solutions for low-resource language technology development.

## Method Summary
The study analyzed server logs from 100,000 translation requests collected between March and August 2024 from tetun.org, a dedicated Tetun language translation service. The logs contained timestamp, text input, MT output, source and target language codes, and device OS information. Researchers used Latent Dirichlet Allocation (LDA) and pre-trained models (Llama 3.1 8B) for topic and provenance classification, analyzing translation directions, text length distribution, and domain coverage. They compared domain distribution of MT inputs with available Tetun corpora, particularly the MADLAD-400 corpus, using translated versions to assess alignment with user needs.

## Key Results
- 70.6% of translation requests target Tetun as the destination language, with English→Tetun being the most common pair (46.7%)
- Most users are students using mobile devices, with peak usage during evenings before school days
- Significant domain mismatch exists between user-translated text and existing Tetun corpora, with users translating science, healthcare, and educational content while available corpora are dominated by news articles
- Language model perplexity on MT inputs (average 1,774) is much higher than on existing monolingual corpora (average 153), indicating domain coverage issues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tetun MT usage patterns reveal that most users are Timorese students using mobile devices for educational content translation.
- Mechanism: Server logs show high evening usage before school days, increased usage during academic terms, and domain analysis indicating heavy demand for science and healthcare educational material.
- Core assumption: Patterns in usage timing and content domain accurately reflect student behavior and educational needs.
- Evidence anchors:
  - [abstract] "users, many of them students on mobile devices, typically translate text from a high-resource language into Tetun across diverse domains including science, healthcare, and daily life"
  - [section 4.1] "demographics...most users are students who use tetun.org for educational purposes" supported by usage patterns during evenings before school days and school holidays
  - [corpus] Weak - corpus analysis shows mismatch between MT inputs and existing Tetun corpora, but doesn't directly confirm student usage
- Break condition: If usage patterns show no correlation with academic calendar or if domain analysis shows non-educational content dominance

### Mechanism 2
- Claim: Domain mismatch between user-translated text and existing Tetun corpora significantly impacts language model performance.
- Mechanism: MT inputs contain underrepresented domains (science, healthcare, education) compared to available corpora (news, government), leading to higher perplexity scores for MT inputs than for monolingual corpora.
- Core assumption: Language model perplexity correlates with domain coverage in training data and directly affects translation quality.
- Evidence anchors:
  - [abstract] "significant mismatch between the domains of user-translated text and existing Tetun corpora, which are dominated by news articles"
  - [section 4.4] "average perplexity of 1,774 on MT Tetun inputs, compared to an average of 153 for Labadain"
  - [corpus] Strong - perplexity measurements show consistent domain-dependent performance differences
- Break condition: If perplexity doesn't correlate with domain similarity or if other factors (like text length) dominate perplexity differences

### Mechanism 3
- Claim: High-resource-to-low-resource translation direction is more in demand than low-resource-to-high-resource direction for Tetun MT.
- Mechanism: Server logs show over 70% of requests target Tetun as the destination language, with English→Tetun being the most common pair (46.7% of requests).
- Core assumption: Translation direction preference reflects actual user needs rather than technical limitations or service design.
- Evidence anchors:
  - [abstract] "typically translate text from a high-resource language into Tetun"
  - [section 4.2] Table 2 showing 70.6% of requests have Tetun as target language
  - [corpus] Weak - corpus analysis doesn't directly address translation direction preferences
- Break condition: If future logs show changing direction patterns or if service expansion to more languages alters the balance

## Foundational Learning

- Concept: Domain classification in NLP
  - Why needed here: To understand what types of content users are translating and how this differs from available training data
  - Quick check question: What are the three components of domain according to Saunders (2022) methodology used in this paper?

- Concept: Perplexity as language model evaluation metric
  - Why needed here: To quantify how well language models handle the actual text users are translating versus existing corpora
  - Quick check question: If a language model has higher perplexity on MT inputs than on monolingual corpora, what does this indicate about domain coverage?

- Concept: Translation direction analysis
  - Why needed here: To identify which language pairs are most important for low-resource MT development
  - Quick check question: Why might high-resource-to-low-resource translation be more in demand than the reverse direction for institutionalized minority languages?

## Architecture Onboarding

- Component map: Data ingestion -> preprocessing (tokenization, cleaning) -> domain classification (LDA + LLM) -> provenance classification (LLM) -> genre analysis -> perplexity evaluation -> recommendations
- Critical path: Server log collection -> domain classification -> analysis of mismatch -> performance evaluation -> actionable recommendations
- Design tradeoffs: Using LLMs for classification provides better accuracy but increases computational cost; focusing on Tetun side of translations limits cross-language analysis capabilities
- Failure signatures: High variance in classification results, low correlation between perplexity and domain similarity, unexpected usage patterns outside academic calendar
- First 3 experiments:
  1. Validate domain classification accuracy by manually annotating a larger sample of server logs
  2. Test whether expanding domain categories improves classification performance
  3. Measure perplexity on MT inputs using different language models to confirm domain impact is consistent

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do domain coverage needs differ between institutional low-resource languages like Tetun versus non-institutionalized or endangered languages?
- Basis in paper: [explicit] The paper explicitly states that findings may extend to other institutionalized low-resource languages but are "less likely to apply to non-institutionalized or endangered ones."
- Why unresolved: The paper only provides data for Tetun, an institutionalized language with official status in Timor-Leste. The study doesn't include any non-institutionalized or endangered language comparisons to validate this distinction.
- What evidence would resolve it: Comparative observational studies of MT usage patterns across multiple language types (institutionalized, non-institutionalized, and endangered) would reveal whether domain coverage needs differ systematically based on institutional support and official status.

### Open Question 2
- Question: What specific educational domains within science and healthcare show the highest translation demand for Tetun, and how does this vary by education level?
- Basis in paper: [inferred] The study identifies "science & research" and "healthcare & medicine" as top domains (34.2% and 23.9% respectively), but doesn't break down which specific topics within these domains are most needed.
- Why unresolved: The domain classification uses broad categories that don't specify which particular educational subjects (biology, physics, nursing, public health, etc.) drive translation demand, nor whether primary, secondary, or tertiary education levels have different needs.
- What evidence would resolve it: Detailed analysis of the actual translated educational content with subject-level categorization and correlation with user demographics (age, education level) would identify specific curriculum gaps and inform targeted corpus development.

### Open Question 3
- Question: How does the performance of mobile-optimized MT solutions for Tetun compare to cloud-based services when accounting for internet connectivity constraints in Timor-Leste?
- Basis in paper: [explicit] The paper recommends "development of mobile-optimized MT solutions" due to high mobile usage and "high cost and low reliability of internet connections in Timor-Leste."
- Why unresolved: The study identifies the problem but doesn't evaluate whether on-device MT would actually improve user experience or translation accuracy under real-world connectivity conditions.
- What evidence would resolve it: Comparative user studies measuring translation speed, accuracy, and satisfaction between on-device and cloud-based MT under varying network conditions would quantify the practical benefits of mobile optimization for low-resource language contexts.

## Limitations

- The study period (March-August 2024) may not capture year-round usage patterns, particularly seasonal variations in educational demand
- Classification of domains using LDA and LLM approaches could be sensitive to the quality of the translated corpus and specific prompts used
- Conclusions about user demographics rely heavily on server log analysis, which may not capture the full spectrum of Tetun MT users

## Confidence

- High Confidence: The observed translation direction preferences (70.6% targeting Tetun, with English→Tetun being most common) and the domain mismatch between user-translated text and existing corpora
- Medium Confidence: The conclusion that most users are Timorese students based on usage timing patterns and mobile device preferences
- Low Confidence: The specific claim about language model perplexity being the primary factor limiting translation quality

## Next Checks

1. Conduct a larger-scale manual annotation study (minimum 1,000 samples) to validate the accuracy of domain and provenance classifications across different time periods and user segments
2. Extend the analysis period to cover at least one full academic year to confirm that usage patterns correlate consistently with school calendars and educational cycles
3. Perform controlled experiments comparing translation quality across different domain-specific training data subsets to quantify the impact of corpus domain coverage on actual translation performance