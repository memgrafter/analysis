---
ver: rpa2
title: 'GDDA: Semantic OOD Detection on Graphs under Covariate Shift via Score-Based
  Diffusion Models'
arxiv_id: '2410.17526'
source_url: https://arxiv.org/abs/2410.17526
tags:
- semantic
- factors
- detection
- representations
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of graph-level semantic OOD detection
  under covariate shift, where test data comes from unknown domains with both semantic
  and covariate shifts. The authors propose a two-phase framework called Graph Disentangled
  Diffusion Augmentation (GDDA).
---

# GDDA: Semantic OOD Detection on Graphs under Covariate Shift via Score-Based Diffusion Models

## Quick Facts
- arXiv ID: 2410.17526
- Source URL: https://arxiv.org/abs/2410.17526
- Reference count: 28
- Key outcome: Achieves 10.01% AUROC improvement on GOOD-CMNIST, 5.39% on GOOD-SST2, and 14.47% on ogbg-molbbbp over state-of-the-art OOD generalization baselines

## Executive Summary
This paper addresses the challenging problem of graph-level semantic OOD detection under covariate shift, where test data comes from unknown domains with both semantic and covariate shifts. The authors propose a two-phase framework called Graph Disentangled Diffusion Augmentation (GDDA) that first disentangles graph representations into domain-invariant semantic factors and domain-specific style factors, then uses distribution-shift-controlled score-based generative diffusion models to generate auxiliary pseudo-InD and pseudo-OOD graph representations. These representations enhance an energy-based semantic OOD detector, achieving significant performance improvements over state-of-the-art baselines on three benchmark datasets.

## Method Summary
GDDA is a two-phase framework that tackles graph-level semantic OOD detection under covariate shift. In the first phase, GDDA disentangles graph representations into domain-invariant semantic factors and domain-specific style factors using encoders and a decoder, learning to isolate invariant semantic information from domain-specific variations. In the second phase, a distribution-shift-controlled score-based generative diffusion model generates auxiliary pseudo-InD and pseudo-OOD graph representations by perturbing these disentangled factors, which are then used to enhance an energy-based semantic OOD detector. The framework is evaluated on three benchmark datasets, achieving significant performance improvements over state-of-the-art baselines.

## Key Results
- Improves AUROC scores by 10.01% on GOOD-CMNIST compared to best OOD generalization baselines
- Achieves 5.39% AUROC improvement on GOOD-SST2 dataset
- Demonstrates 14.47% AUROC improvement on ogbg-molbbbp dataset
- Successfully handles both semantic and covariate shifts in test data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Disentangling graph representations into domain-invariant semantic factors and domain-specific style factors enables robust OOD detection under covariate shift.
- Mechanism: The framework uses two encoders (Ec and Es) to separate graph representations into semantic factors (c) and style factors (s). By reconstructing the original representation from these disentangled factors and their perturbed versions, the model learns to isolate invariant semantic information from domain-specific variations.
- Core assumption: Domain-invariant semantic factors contain sufficient information for classification while style factors capture all domain-specific variations.

### Mechanism 2
- Claim: Distribution-shift-controlled score-based generative diffusion models can generate auxiliary pseudo-OOD and pseudo-InD representations beyond the training distribution.
- Mechanism: The framework applies diffusion models with controlled perturbations (λc and λs) to the disentangled factors. By setting different perturbation parameters, it generates representations that deviate from the original training distribution in semantic and/or style dimensions, creating synthetic OOD and InD samples.
- Core assumption: The diffusion model can effectively explore the latent space beyond the training distribution boundaries when appropriate perturbations are applied.

### Mechanism 3
- Claim: Energy-based semantic OOD detection enhanced with auxiliary pseudo representations improves performance on both semantic and covariate shifts.
- Mechanism: The framework uses the energy function to measure the likelihood of graph representations being OOD. By incorporating both pseudo-InD and pseudo-OOD representations generated through diffusion models, the energy function learns better decision boundaries that separate known classes from unknown ones under distribution shifts.
- Core assumption: The energy function can effectively distinguish between pseudo-InD and pseudo-OOD representations, thereby learning robust OOD detection boundaries.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their limitations under distribution shift
  - Why needed here: The paper builds on GNN representations but addresses their failure modes when encountering distribution shifts
  - Quick check question: What are the two types of distribution shifts that GNNs typically struggle with in OOD detection?

- Concept: Disentanglement learning and its role in domain generalization
  - Why needed here: The framework relies on separating semantic factors from style factors to handle covariate shifts
  - Quick check question: How does disentangling representations help in maintaining performance when domain-specific features change?

- Concept: Score-based generative diffusion models
  - Why needed here: The framework uses diffusion models to generate auxiliary samples beyond the training distribution
  - Quick check question: What is the key difference between standard diffusion models and distribution-shift-controlled diffusion models?

## Architecture Onboarding

- Component map: Graph → GNN → Disentanglement → Diffusion Perturbation → Pseudo Sample Generation → Energy Function → OOD Score
- Critical path: Graph → GNN → Disentanglement → Diffusion Perturbation → Pseudo Sample Generation → Energy Function → OOD Score
- Design tradeoffs:
  - Tradeoff between disentanglement quality and reconstruction accuracy: Too strict disentanglement may lose information needed for classification
  - Perturbation magnitude: Too small perturbations may not generate effective OOD samples; too large may create unrealistic samples
  - Number of pseudo samples: More samples improve training but increase computational cost
- Failure signatures:
  - Poor disentanglement: High reconstruction loss or similarity loss indicates the encoders are not properly separating semantic and style factors
  - Ineffective diffusion: If generated pseudo samples are too close to training distribution, perturbation parameters may need adjustment
  - Energy function failure: If OOD detection performance is poor, the energy margins or temperature parameter may need tuning
- First 3 experiments:
  1. Verify disentanglement quality by checking reconstruction loss and similarity loss on a small subset of data
  2. Test diffusion model generation by visualizing the distribution of generated samples compared to training data
  3. Evaluate energy-based detector performance with only original training data before adding pseudo samples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GDDA scale with increasing domain shifts in the test data, and what are the theoretical limits of its robustness?
- Basis in paper: The paper demonstrates GDDA's effectiveness on benchmark datasets but does not explore the limits of its robustness under extreme domain shifts.
- Why unresolved: The study does not provide theoretical analysis or empirical results on the performance degradation with increasing covariate and semantic shifts.
- What evidence would resolve it: Extensive experiments varying the magnitude of domain shifts in test data, combined with theoretical bounds on performance degradation.

### Open Question 2
- Question: Can the disentanglement phase of GDDA be generalized to other types of graph data, such as dynamic graphs or heterogeneous graphs?
- Basis in paper: The paper focuses on static homogeneous graphs, leaving the applicability to other graph types unexplored.
- Why unresolved: The methodology is not tested on dynamic or heterogeneous graphs, and no discussion on adapting the disentanglement approach is provided.
- What evidence would resolve it: Experiments applying GDDA to dynamic or heterogeneous graphs, with modifications to the disentanglement phase as needed.

### Open Question 3
- Question: What is the impact of different GNN architectures on the disentanglement and augmentation phases of GDDA?
- Basis in paper: The paper uses specific GNN backbones (GIN-Virtual and GIN) but does not explore the impact of alternative architectures.
- Why unresolved: No comparative analysis is provided to assess how different GNN architectures affect the disentanglement and augmentation processes.
- What evidence would resolve it: Systematic experiments comparing GDDA's performance using various GNN architectures, such as GCN, GAT, or GraphSAGE.

### Open Question 4
- Question: How sensitive is GDDA to the hyperparameters of the diffusion models, and can these be optimized automatically?
- Basis in paper: The paper mentions hyperparameters like λc and λs but does not discuss their sensitivity or optimization.
- Why unresolved: The study does not provide sensitivity analysis or explore automated hyperparameter tuning for the diffusion models.
- What evidence would resolve it: Sensitivity analysis and experiments with automated hyperparameter optimization techniques, such as Bayesian optimization or grid search.

## Limitations
- Limited evaluation to three specific graph datasets, which may not capture full range of challenges in graph-level OOD detection
- Relies heavily on assumption that semantic factors can be perfectly disentangled from style factors, but quality of disentanglement is difficult to verify
- Effectiveness of diffusion model in generating truly out-of-distribution samples is uncertain, as perturbations may not adequately explore latent space

## Confidence
- High confidence: Framework's overall architecture and potential benefits of disentanglement and diffusion augmentation for OOD detection
- Medium confidence: Specific implementation details and hyperparameter choices, as these are not fully specified in the paper
- Low confidence: Generalizability of results to other graph datasets and OOD detection scenarios

## Next Checks
1. Conduct extensive ablation studies to quantify impact of disentanglement quality on OOD detection performance and identify potential failure modes
2. Evaluate framework on wider range of graph datasets with varying characteristics to assess generalizability
3. Perform robustness analysis by testing framework under different levels of covariate shift and semantic shift to understand limitations and identify potential improvements