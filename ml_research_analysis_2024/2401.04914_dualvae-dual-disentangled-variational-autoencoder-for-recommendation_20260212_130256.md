---
ver: rpa2
title: 'DualVAE: Dual Disentangled Variational AutoEncoder for Recommendation'
arxiv_id: '2401.04914'
source_url: https://arxiv.org/abs/2401.04914
tags:
- items
- users
- user
- aspect
- disentangled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DualVAE, a novel method for collaborative
  filtering that addresses the limitations of existing models by incorporating disentangled
  representation learning with variational inference. The core idea is to infer multi-aspect
  latent representations of both users and items, capturing the diverse matching relationships
  behind their interactions.
---

# DualVAE: Dual Disentangled Variational AutoEncoder for Recommendation

## Quick Facts
- arXiv ID: 2401.04914
- Source URL: https://arxiv.org/abs/2401.04914
- Reference count: 30
- Key outcome: DualVAE significantly outperforms state-of-the-art baselines on three real-world datasets, demonstrating improved recommendation performance and interpretable disentangled representations.

## Executive Summary
This paper introduces DualVAE, a novel collaborative filtering method that addresses limitations of existing models by incorporating disentangled representation learning with variational inference. The core idea is to infer multi-aspect latent representations of both users and items, capturing diverse matching relationships behind their interactions. DualVAE employs an attention-aware dual disentanglement module, a disentangled variational inference module, and a joint generative module to achieve this. Additionally, a neighborhood-enhanced representation constraint module is designed to ensure correspondence and independence of the learned representations. Extensive experiments on three real-world datasets demonstrate that DualVAE significantly outperforms state-of-the-art baselines, showcasing its effectiveness in improving recommendation performance. Furthermore, the interpretability of the learned disentangled representations is empirically validated, providing insights into user behaviors.

## Method Summary
DualVAE is a collaborative filtering model that infers multi-aspect latent representations for both users and items using variational autoencoders. The method consists of four main modules: an attention-aware dual disentanglement (ADD) module that generates aspect probability matrices, a disentangled variational inference (DVI) module that infers aspect-level latent variables, a joint generative (JG) module that reconstructs interactions using aspect-weighted combinations, and a neighborhood-enhanced representation constraint (NRC) module that enforces independence among aspects through contrastive learning. The model is trained by optimizing a combination of VAE loss and contrastive loss, with hyperparameters tuned for each dataset.

## Key Results
- DualVAE significantly outperforms state-of-the-art baselines on three real-world datasets (MovieLens-1M, Amazon Kindle Store, Yelp) in terms of Recall@N and N@NDCG.
- The model demonstrates strong interpretability of learned disentangled representations, providing insights into user behaviors and item attributes.
- Dual disentanglement of both user and item representations is crucial for capturing fine-grained matching relationships, as evidenced by ablation studies.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual disentanglement of user and item representations captures multi-aspect matching relationships.
- Mechanism: DualVAE uses an attention-aware dual disentanglement module that independently infers multi-aspect latent representations for both users and items. This allows each user preference aspect to align with corresponding item attribute aspects.
- Core assumption: User-item interactions can be decomposed into independent aspect-level affinities between user preferences and item attributes.
- Evidence anchors:
  - [abstract] "the core idea is to infer multi-aspect latent representations of both users and items, capturing the diverse matching relationships behind their interactions"
  - [section] "we propose a dual disentangled generative model to generate the observed interaction that encourages multi-aspect disentanglement of both users and items"
- Break condition: If real-world items have non-disentangled or hidden attributes that cannot be captured by explicit aspect prototypes, the model's performance degrades.

### Mechanism