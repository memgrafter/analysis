---
ver: rpa2
title: Explaining Text Classifiers with Counterfactual Representations
arxiv_id: '2402.00711'
source_url: https://arxiv.org/abs/2402.00711
tags:
- which
- cfrs
- gender
- text
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a method for generating counterfactual representations
  (CFRs) of text documents by intervening in the representation space of neural encoders
  like BERT. The core idea is to linearly regress the representation component that
  contains information about the protected attribute (e.g., gender or race) onto the
  orthogonal component, which is minimally disrupted by the intervention.
---

# Explaining Text Classifiers with Counterfactual Representations

## Quick Facts
- arXiv ID: 2402.00711
- Source URL: https://arxiv.org/abs/2402.00711
- Authors: Pirmin Lemberger; Antoine Saillenfest
- Reference count: 24
- The paper introduces a method for generating counterfactual representations of text documents by intervening in the representation space of neural encoders like BERT.

## Executive Summary
This paper presents a method for generating counterfactual representations (CFRs) of text documents by intervening in the representation space of neural encoders like BERT. The approach involves linearly regressing the representation component containing information about a protected attribute onto the orthogonal component, creating minimally disruptive counterfactuals that align with Pearl's causal inference framework. The method is validated on synthetic and realistic datasets, demonstrating that CFRs can effectively mimic ground truth counterfactuals in classifier predictions and causal effect estimations.

## Method Summary
The method generates counterfactual representations by first extracting text representations using a frozen BERT encoder. It then computes an orthogonal projection matrix to remove linear information about the protected attribute from these representations. A linear regression is performed to generate counterfactual representations for each protected attribute value. The method is evaluated using synthetic ground truth counterfactuals and real-world bias metrics, with linear classifiers trained on original and counterfactual representations to assess similarity and effectiveness.

## Key Results
- CFRs achieve PIP scores exceeding 82% compared to ground truth counterfactuals on balanced training scenarios
- The method effectively reduces gender bias in the BiasInBios dataset through data augmentation with CFRs
- CFRs provide a computationally efficient alternative to explicit text-level counterfactual generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear regression in representation space allows minimally disruptive counterfactuals by preserving most information except that related to the protected attribute.
- Mechanism: The method projects the original representation onto the orthogonal complement of the protected attribute's column space, then regresses the protected component onto this orthogonal part using data where the attribute has the target value.
- Core assumption: The protected attribute information is linearly separable in the representation space.
- Evidence anchors: [abstract] "linearly regress the representation component that contains information about the protected attribute... onto the orthogonal component"
- Break condition: If the protected attribute information is not linearly separable in the representation space.

### Mechanism 2
- Claim: Counterfactual representations align with Pearl's causal inference framework when the underlying SCM has Gaussian distributions and linear relationships.
- Mechanism: The method constructs an SCM where the protected attribute Z, the orthogonal component X⊥, and the protected component X∥ have linear relationships with Gaussian noise.
- Core assumption: The data generation process can be modeled as a linear-Gaussian SCM with the specified causal structure.
- Evidence anchors: [section 3.3] "our CFR is nothing but the expectation of a counterfactual as defined in Pearl's causal inference framework"
- Break condition: If the true data distribution is non-Gaussian or the causal relationships are non-linear.

### Mechanism 3
- Claim: Counterfactual representations can effectively substitute for ground truth counterfactuals in classifier predictions and causal effect estimations.
- Mechanism: By intervening in the representation space rather than the text space, the method can generate counterfactuals even when explicit text interventions are impossible or costly.
- Core assumption: The classifier's behavior on CFRs closely approximates its behavior on ground truth counterfactuals.
- Evidence anchors: [section 5.1] "For the bZ classifier, in all cases PIPbZ > 0.9 and ATVbZ is close to 0"
- Break condition: If the classifier relies heavily on non-linear interactions or context that is lost in the representation space intervention.

## Foundational Learning

- Concept: Linear regression and orthogonal projection in high-dimensional spaces
  - Why needed here: The method fundamentally relies on projecting representations onto orthogonal complements and performing linear regressions to create counterfactuals
  - Quick check question: Given a representation X and protected attribute Z, can you derive the orthogonal projector P that nulls the column space of Cov[X,Z]?

- Concept: Pearl's causal inference framework and structural causal models (SCMs)
  - Why needed here: The method claims theoretical soundness by aligning with Pearl's counterfactual definition within a specific SCM
  - Quick check question: Can you explain the difference between intervention and counterfactual in Pearl's framework, and how the CFR method implements the latter?

- Concept: Classifier behavior and evaluation metrics (PIP, ATV, ATE)
  - Why needed here: The method is evaluated based on how well CFRs mimic ground truth counterfactuals in terms of classifier predictions and causal effect estimations
  - Quick check question: Given classifier predictions on original, counterfactual, and CFR representations, can you compute PIP and ATV metrics to assess similarity?

## Architecture Onboarding

- Component map: Representation extraction (BERT) -> Orthogonal projection -> Linear regression -> Counterfactual generation -> Classifier prediction -> Evaluation (PIP, ATV, ATE)

- Critical path: The critical path is representation extraction → counterfactual generation → classifier prediction → evaluation. The most computationally intensive step is typically the linear regression for counterfactual generation.

- Design tradeoffs: The method trades off between computational efficiency (linear operations) and expressiveness (linear assumptions). Using linear regression makes the method fast and interpretable but may miss non-linear relationships in the data.

- Failure signatures: If PIP and ATV metrics are low between CFRs and ground truth counterfactuals, or if causal effect estimations using CFRs diverge significantly from ground truth, the method is failing. This could indicate non-linear relationships or distributional assumptions not holding.

- First 3 experiments:
  1. Verify orthogonal projection correctly nulls protected attribute information by checking classifier performance on X⊥ vs X
  2. Test counterfactual generation on a simple synthetic dataset where ground truth counterfactuals are available
  3. Evaluate classifier prediction similarity between CFRs and ground truth counterfactuals using PIP and ATV metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well do non-linear regression methods for generating counterfactual representations compare to the linear regression approach proposed in this paper?
- Basis in paper: [inferred] The paper discusses the potential for future research to enhance CFRs using non-linear regressions and mentions that this would require exploring non-linear erasure methods, which is currently an open problem.
- Why unresolved: The paper only implements and validates the linear regression method, leaving the performance of non-linear methods unexplored.
- What evidence would resolve it: Empirical comparisons of non-linear regression methods against the linear approach on the same datasets, showing improvements or limitations in generating counterfactual representations.

### Open Question 2
- Question: Can the CFR method be effectively applied to text representations that are not derived from BERT or similar transformer models?
- Basis in paper: [inferred] The paper uses BERT for generating text representations but does not explore whether the CFR method generalizes to other types of text encoders or representation methods.
- Why unresolved: The paper focuses on BERT-based representations, so it is unclear if the method would work as well with other encoders like LSTM or GloVe embeddings.
- What evidence would resolve it: Testing the CFR method on text representations generated by different models (e.g., LSTM, GloVe) and comparing the quality and utility of the counterfactuals produced.

### Open Question 3
- Question: How does the computational cost of generating CFRs scale with the size and complexity of the text corpus?
- Basis in paper: [inferred] The paper mentions that CFRs are computationally inexpensive and easy to implement, but does not provide detailed analysis on how computational cost scales with dataset size or complexity.
- Why unresolved: The paper provides limited information on the scalability of the method, particularly for large-scale or more complex text corpora.
- What evidence would resolve it: Detailed benchmarking of the CFR method on datasets of varying sizes and complexities, including time and resource usage metrics, to assess scalability.

## Limitations

- The method relies on linear separability assumptions for protected attributes in representation space, which may not hold in real-world data
- Evaluation focuses primarily on synthetic datasets where ground truth counterfactuals are available, limiting confidence in real-world applicability
- The method's behavior on non-linear classifiers or when protected attributes have complex interactions with other features is not explored

## Confidence

- High confidence: The linear regression approach for counterfactual generation is well-specified and reproducible
- Medium confidence: Claims about CFR effectiveness as ground truth substitutes, based primarily on synthetic data
- Medium confidence: Theoretical alignment with Pearl's framework, though distributional assumptions are strong

## Next Checks

1. Test CFR performance on non-linear classifiers (e.g., BERT fine-tuned on downstream tasks) to verify if linear assumptions hold beyond logistic regression
2. Evaluate CFR quality when protected attributes have non-linear relationships with other features or when multiple protected attributes interact
3. Apply the method to a real-world dataset without synthetic ground truth counterfactuals to assess practical utility and identify potential failure modes