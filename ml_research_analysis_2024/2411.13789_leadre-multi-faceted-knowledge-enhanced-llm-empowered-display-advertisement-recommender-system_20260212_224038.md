---
ver: rpa2
title: 'LEADRE: Multi-Faceted Knowledge Enhanced LLM Empowered Display Advertisement
  Recommender System'
arxiv_id: '2411.13789'
source_url: https://arxiv.org/abs/2411.13789
tags:
- user
- llms
- advertising
- prompt
- leadre
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LEADRE addresses the challenge of integrating LLMs into large-scale
  display advertising systems, where conventional retrieval methods underutilize ad
  content information and struggle with sparse user behaviors and implicit user intent.
  The core method involves Intent-Aware Prompt Engineering to capture user interests
  using both long-term and short-term behaviors, Advertising-Specific Knowledge Alignment
  to bridge the knowledge gap between LLMs and the advertising system via auxiliary
  tasks and Direct Preference Optimization (DPO), and Latency-Aware Model Deployment
  using a hybrid architecture to ensure real-time responsiveness.
---

# LEADRE: Multi-Faceted Knowledge Enhanced LLM Empowered Display Advertisement Recommender System

## Quick Facts
- arXiv ID: 2411.13789
- Source URL: https://arxiv.org/abs/2411.13789
- Reference count: 40
- Key outcome: LEADRE increases GMV by 1.57% and 1.17% on Tencent WeChat Channels and Moments respectively

## Executive Summary
LEADRE addresses the challenge of integrating LLMs into large-scale display advertising systems, where conventional retrieval methods underutilize ad content information and struggle with sparse user behaviors and implicit user intent. The core method involves Intent-Aware Prompt Engineering to capture user interests using both long-term and short-term behaviors, Advertising-Specific Knowledge Alignment to bridge the knowledge gap between LLMs and the advertising system via auxiliary tasks and Direct Preference Optimization (DPO), and Latency-Aware Model Deployment using a hybrid architecture to ensure real-time responsiveness. Extensive offline experiments validate the effectiveness of LEADRE, and online A/B tests show a 1.57% and 1.17% increase in Gross Merchandise Value (GMV) for serviced users on Tencent WeChat Channels and Moments respectively. The system is currently deployed on both platforms, serving tens of billions of requests daily.

## Method Summary
LEADRE combines Intent-Aware Prompt Engineering, Advertising-Specific Knowledge Alignment, and Latency-Aware Model Deployment to create an LLM-powered display advertising recommender system. The approach uses semantic IDs (S-IDs) to represent ads, incorporates multi-faceted user knowledge into prompts, fine-tunes LLMs through auxiliary tasks and DPO to align with advertising objectives, and deploys using a hybrid architecture that separates latency-sensitive online inference from latency-tolerant nearline processing.

## Key Results
- 1.57% GMV increase on Tencent WeChat Channels
- 1.17% GMV increase on Tencent WeChat Moments
- Current deployment serving tens of billions of requests daily
- Outperforms conventional ID-based retrieval methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Intent-Aware Prompt Engineering effectively captures both long-term and short-term user interests, addressing the sparsity of user behaviors in display advertising.
- Mechanism: By integrating user profiles, historical behaviors, and recent interactions into structured prompts, the LLM receives enriched context to generate ads tailored to users' interests.
- Core assumption: Combining multi-faceted knowledge from both ad and content domains compensates for sparse ad-specific interactions and provides sufficient signal for intent modeling.
- Evidence anchors:
  - [abstract]: "Intent-Aware Prompt Engineering to capture user interests using both long-term and short-term behaviors"
  - [section]: "We build textual <Prompt, Response> pairs with user behavior sequences and ad descriptions as the corpus"
  - [corpus]: Weak evidence - no direct citations supporting this specific approach in the corpus
- Break condition: If user profiles or behavior sequences are missing or unreliable, the prompt construction fails to capture accurate intent.

### Mechanism 2
- Claim: Advertising-Specific Knowledge Alignment bridges the semantic gap between general LLMs and advertising systems through auxiliary tasks and DPO.
- Mechanism: Auxiliary tasks (explicit and implicit alignment) teach the LLM to understand ad-specific features and S-IDs, while DPO optimizes for business value by favoring higher ECPM ads.
- Core assumption: LLMs need specialized training on advertising semantics and business objectives to generate relevant, high-value ads rather than general text.
- Evidence anchors:
  - [abstract]: "Advertising-Specific Knowledge Alignment to bridge the knowledge gap between LLMs and the advertising system via auxiliary tasks and Direct Preference Optimization (DPO)"
  - [section]: "We employ Direct Preference Optimization (DPO) to encourage generating ads with higher business value"
  - [corpus]: Weak evidence - corpus contains related work but not this specific alignment strategy
- Break condition: If auxiliary tasks are poorly designed or DPO hyperparameters are misconfigured, the LLM may fail to align with advertising requirements.

### Mechanism 3
- Claim: Latency-Aware Model Deployment enables real-time LLM inference at scale through hybrid architecture and TensorRT acceleration.
- Mechanism: Separates latency-sensitive (online) and latency-tolerant (nearline) services, prioritizing GPU resources for high-value users and using TensorRT optimizations to reduce inference time.
- Core assumption: Display advertising systems require real-time responses, so LLM deployment must balance computational cost with latency requirements.
- Evidence anchors:
  - [abstract]: "Latency-Aware Model Deployment using a hybrid architecture to ensure real-time responsiveness"
  - [section]: "We implement a hybrid system by integrating latency tolerant service module and latency sensitive service module"
  - [corpus]: Weak evidence - corpus lacks specific citations about this deployment strategy
- Break condition: If GPU resources are insufficient or TensorRT optimizations fail, the system cannot maintain real-time performance.

## Foundational Learning

- Concept: Semantic ID (S-ID) encoding and trie-tree construction
  - Why needed here: Traditional ID-based retrieval underutilizes ad content information. S-IDs provide semantic representations that bridge the gap between human-understandable ad descriptions and machine-readable identifiers.
  - Quick check question: How does the RQ-VAE quantization process ensure that different ads with similar content get similar S-IDs while maintaining uniqueness?

- Concept: Direct Preference Optimization (DPO) for business alignment
  - Why needed here: Standard LLM fine-tuning focuses on general text quality, but display advertising requires optimization for business metrics like ECPM and GMV.
  - Quick check question: What is the mathematical relationship between the DPO loss function and the preference for higher-value ads?

- Concept: Constrained decoding with trie-trees
  - Why needed here: Unlike open-domain generation, advertising retrieval must generate valid ads from a predefined set, requiring constrained generation techniques.
  - Quick check question: How does the beam search algorithm in constrained decoding ensure both diversity and validity of generated ads?

## Architecture Onboarding

- Component map: User Server -> Mixer -> Latency-Sensitive Service -> User behavior update -> Latency-Tolerant Service -> User feature database update
- Critical path: User request → User Server query → Mixer → Latency-Sensitive Service response → User behavior update → Latency-Tolerant Service processing → User feature database update
- Design tradeoffs:
  - Hybrid architecture vs. full LLM deployment: Balances latency and computational cost
  - S-ID quantization vs. raw embeddings: Trade-off between semantic richness and computational efficiency
  - Beam search width: Higher diversity vs. increased computation time
- Failure signatures:
  - High latency in LLM inference → User experience degradation
  - Poor ad diversity → Information cocoon effect
  - Low GMV despite high click-through rate → Misalignment with business objectives
- First 3 experiments:
  1. A/B test comparing LEADRE with traditional ID-based retrieval on GMV metrics
  2. Offline evaluation of S-ID quantization quality using collision rate and semantic similarity
  3. Performance comparison of different LLM fine-tuning strategies (auxiliary tasks vs. DPO vs. combined)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of prompt template and user profile ordering affect the diversity and commercial value of generated ads in LEADRE?
- Basis in paper: [explicit] The paper discusses prompt engineering strategies, including multiple prompt templates and user profile reordering, to enhance the fine-tuning process and capture user intent.
- Why unresolved: The paper mentions the effectiveness of these strategies but does not provide quantitative comparisons of their impact on ad diversity and commercial value.
- What evidence would resolve it: Detailed ablation studies comparing the performance of different prompt templates and user profile orderings in terms of ad diversity metrics (e.g., concentration and abundance) and commercial value metrics (e.g., GMV).

### Open Question 2
- Question: What is the optimal sequence of tuning tasks (explicit alignment, implicit alignment, main task) for maximizing the performance of LEADRE?
- Basis in paper: [explicit] The paper presents results comparing different tuning task orders and their impact on performance metrics such as Hit Ratio and NDCG.
- Why unresolved: While the paper shows that the order matters, it does not explore all possible combinations or provide a theoretical justification for the optimal sequence.
- What evidence would resolve it: Comprehensive experiments testing all possible sequences of tuning tasks and analyzing the resulting performance to determine the optimal order.

### Open Question 3
- Question: How does the Adaptive Resource Distribution Strategy impact the overall efficiency and effectiveness of LEADRE in real-world deployment?
- Basis in paper: [explicit] The paper introduces the Adaptive Resource Distribution Strategy to allocate GPU resources based on user ARPU values, but does not provide detailed analysis of its impact.
- Why unresolved: The paper mentions the strategy but does not quantify its benefits in terms of computational efficiency, cost savings, or impact on ad generation quality for different user groups.
- What evidence would resolve it: A detailed analysis of the resource allocation strategy's performance, including comparisons of computational efficiency, cost savings, and ad generation quality for different user groups under various resource allocation scenarios.

## Limitations

- Implementation Specificity: The paper lacks detailed implementation specifications for critical components like TensorRT optimizations and DPO hyperparameters.
- Deployment Scale Validation: Limited operational metrics on system stability and performance under peak loads.
- Generalizability: Effectiveness in different cultural contexts or platforms with different user behaviors remains uncertain.

## Confidence

**High Confidence**: The core hypothesis that combining multi-faceted knowledge through Intent-Aware Prompt Engineering improves ad relevance is supported by significant GMV improvements in online A/B tests.

**Medium Confidence**: The effectiveness of Advertising-Specific Knowledge Alignment through auxiliary tasks and DPO is supported by offline metrics, but individual component contributions are not isolated.

**Low Confidence**: The scalability claims and latency guarantees of the hybrid deployment architecture are primarily based on the paper's description rather than detailed performance measurements under various load conditions.

## Next Checks

**Check 1**: Conduct A/B tests on a third platform with different user demographics and advertising patterns to validate the generalizability of LEADRE's performance improvements across diverse contexts.

**Check 2**: Perform ablation studies to isolate the individual contributions of Intent-Aware Prompt Engineering, Advertising-Specific Knowledge Alignment, and Latency-Aware Model Deployment to the overall system performance.

**Check 3**: Implement detailed monitoring of system performance under peak loads, measuring latency distributions, failure rates, and resource utilization across different user segments to validate the scalability claims of the hybrid architecture.