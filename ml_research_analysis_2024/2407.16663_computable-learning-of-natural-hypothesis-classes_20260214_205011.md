---
ver: rpa2
title: Computable learning of natural hypothesis classes
arxiv_id: '2407.16663'
source_url: https://arxiv.org/abs/2407.16663
tags:
- hypothesis
- cone
- class
- then
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the computability requirements for Probably
  Approximately Correct (PAC) learning, an intermediate notion between statistical
  learning theory (with no computational requirements) and efficient PAC learning
  (requiring polynomial-time algorithms). The authors address a fundamental question:
  when a hypothesis class is PAC learnable, must it also be computably PAC learnable?'
---

# Computable learning of natural hypothesis classes

## Quick Facts
- arXiv ID: 2407.16663
- Source URL: https://arxiv.org/abs/2407.16663
- Reference count: 5
- Primary result: Under mild assumptions, any "natural" PAC-learnable hypothesis class must also be computably PAC-learnable

## Executive Summary
This paper investigates the computability requirements for Probably Approximately Correct (PAC) learning, exploring an intermediate notion between statistical learning theory (no computational requirements) and efficient PAC learning (requiring polynomial-time algorithms). The authors address a fundamental question: when a hypothesis class is PAC learnable, must it also be computably PAC learnable? Previous work showed counterexamples of PAC-learnable but not computably PAC-learnable hypothesis classes, but these were considered "unnatural" because they depended on arbitrary choices like how formulas or programs are numbered. Using techniques from computability theory, specifically the "on-a-cone" machinery, the authors prove that under mild assumptions, any "natural" PAC-learnable hypothesis class must also be computably PAC-learnable.

## Method Summary
The authors use techniques from computability theory, particularly the "on-a-cone" machinery, to prove that under mild assumptions, any "natural" PAC-learnable hypothesis class must also be computably PAC-learnable. They establish three main results: (1) if a hypothesis class is computably enumerable and PAC learnable, it is properly computably PAC learnable; (2) if a hypothesis class is topologically closed and PAC learnable, it is properly computably PAC learnable; and (3) under the Axiom of Determinacy, if a hypothesis class is PAC learnable, it is improperly computably PAC learnable. The authors also provide negative results, showing that there exist natural PAC-learnable hypothesis classes that are not computably PAC learnable under certain conditions, particularly when the hypothesis classes are Fσ.

## Key Results
- If a hypothesis class is computably enumerable and PAC learnable, it is properly computably PAC learnable
- If a hypothesis class is topologically closed and PAC learnable, it is properly computably PAC learnable
- Under the Axiom of Determinacy, if a hypothesis class is PAC learnable, it is improperly computably PAC learnable
- There exist natural PAC-learnable hypothesis classes that are not computably PAC learnable when the hypothesis classes are Fσ

## Why This Works (Mechanism)
The paper's approach relies on computability theory concepts, particularly the "on-a-cone" machinery, to establish that natural PAC-learnable hypothesis classes must also be computably PAC-learnable. This framework allows the authors to bridge the gap between statistical learning theory and computational learning theory by showing that computability constraints don't limit the expressive power of PAC learning under natural assumptions.

## Foundational Learning
- **PAC Learning**: Probably Approximately Correct learning framework that provides probabilistic guarantees about learning accuracy
  - Why needed: Forms the theoretical foundation for understanding what can be learned
  - Quick check: Can you explain the difference between PAC learning and efficient PAC learning?
- **Computability Theory**: Study of which mathematical functions can be computed by algorithms
  - Why needed: Provides the mathematical tools to analyze computational requirements of learning
  - Quick check: What is the difference between computable and computably enumerable sets?
- **Topological Complexity**: Measures of how complex sets are in terms of their topological properties
  - Why needed: Helps characterize which hypothesis classes are "natural" and which are pathological
  - Quick check: What does it mean for a set to be Fσ?

## Architecture Onboarding

**Component Map**: PAC Learning Framework -> Computability Theory Analysis -> Naturalness Conditions -> Computable Learnability Results

**Critical Path**: Hypothesis Class Specification → PAC Learnability Verification → Naturalness Verification → Computability Analysis → Final Result Classification

**Design Tradeoffs**: The paper prioritizes mathematical rigor and generality over practical applicability, focusing on abstract hypothesis classes rather than specific machine learning algorithms.

**Failure Signatures**: When a hypothesis class fails to be computably PAC learnable despite being PAC learnable, this typically occurs when the class has high topological complexity (Fσ) or depends on arbitrary numbering schemes.

**3 First Experiments**:
1. Verify that common hypothesis classes used in practice (decision trees, linear classifiers, neural networks) satisfy the "natural" assumptions and are therefore computably learnable
2. Test whether the computability-theoretic techniques can be extended to other learning frameworks beyond PAC learning
3. Investigate whether the results hold under different computability models or weaker versions of the Axiom of Determinacy

## Open Questions the Paper Calls Out
None

## Limitations
- The paper's reliance on computability theory concepts may limit accessibility to the broader ML community
- The topological assumptions (closed sets, Fσ complexity) may not cover all practical hypothesis classes
- The Axiom of Determinacy assumption is particularly strong and non-constructive

## Confidence
- High confidence in the technical validity of computability-theoretic proofs
- Medium confidence in the practical relevance of the "natural" assumptions
- Low confidence in the real-world applicability given the abstract mathematical framework

## Next Checks
1. **Empirical validation**: Test whether commonly used hypothesis classes in practice satisfy the "natural" assumptions and are therefore computably learnable
2. **Alternative frameworks**: Investigate whether similar results hold under different computability models or learning frameworks (e.g., online learning)
3. **Complexity analysis**: Quantify the computational overhead introduced by the "proper computably PAC learnable" requirement compared to standard PAC learning