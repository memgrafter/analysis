---
ver: rpa2
title: Is In-Context Learning in Large Language Models Bayesian? A Martingale Perspective
arxiv_id: '2406.00793'
source_url: https://arxiv.org/abs/2406.00793
tags:
- bayesian
- martingale
- property
- learning
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether in-context learning (ICL) in large
  language models (LLMs) is Bayesian. The authors introduce the martingale property
  as a fundamental requirement of Bayesian learning systems for exchangeable data,
  and show it is necessary for unambiguous predictions and principled uncertainty
  quantification.
---

# Is In-Context Learning in Large Language Models Bayesian? A Martingale Perspective

## Quick Facts
- arXiv ID: 2406.00793
- Source URL: https://arxiv.org/abs/2406.00793
- Authors: Fabian Falck; Ziyu Wang; Chris Holmes
- Reference count: 40
- Primary result: In-context learning in LLMs like Llama2, Mistral, GPT-3.5 and GPT-4 violates the martingale property and deviates from Bayesian uncertainty scaling, falsifying the hypothesis that ICL is Bayesian

## Executive Summary
This paper investigates whether in-context learning (ICL) in large language models is Bayesian by introducing the martingale property as a fundamental requirement for Bayesian learning systems with exchangeable data. The authors show that the martingale property is necessary for unambiguous predictions and principled uncertainty quantification, and derive actionable diagnostics to check this property. Through three experiments with synthetic datasets, they provide evidence that state-of-the-art LLMs violate the martingale property and deviate from Bayesian scaling behavior of uncertainty, falsifying the hypothesis that ICL is Bayesian. This has important implications for the use of LLMs in exchangeable and safety-critical applications where trustworthy uncertainty estimates are vital.

## Method Summary
The authors develop diagnostics to test whether in-context learning is Bayesian by checking if LLMs satisfy the martingale property. They generate sample paths from LLMs using ICL on synthetic datasets (Bernoulli, Gaussian, and synthetic natural language) and compute test statistics that measure deviations from the martingale property and Bayesian scaling behavior of uncertainty. These test statistics are compared to bootstrap confidence intervals from a reference Bayesian model to determine violations. The experiments examine whether LLM uncertainty decreases as expected in Bayesian learning when more data is observed, and whether predictions remain unambiguous under missing data imputation.

## Key Results
- LLMs violate the martingale property, indicating they are "hallucinating" knowledge not present in observed data
- LLM uncertainty does not scale as expected under Bayesian inference when more data is observed
- These violations falsify the hypothesis that in-context learning is Bayesian, with implications for safety-critical applications

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The martingale property is a necessary condition for unambiguous predictions in exchangeable data settings.
- **Mechanism:** If the predictive distribution changes when imputing missing data from the population, the model is "hallucinating" and creating knowledge not present in the observed data.
- **Core assumption:** The underlying data distribution is exchangeable, meaning the order of observations does not affect the joint distribution.
- **Evidence anchors:**
  - [abstract] "We show that the martingale property is a necessary condition for unambiguous predictions in such scenarios"
  - [section] "If the predictive distribution for yn+1 changes on average, the model is 'creating new knowledge' when there is none: it is 'hallucinating'."
  - [corpus] Weak - corpus does not directly discuss martingale property or unambiguous predictions.
- **Break condition:** If the data is not exchangeable (e.g., time series with temporal dependencies), the martingale property is not required.

### Mechanism 2
- **Claim:** The martingale property enables a principled decomposition of uncertainty into epistemic and aleatoric components.
- **Mechanism:** Under the martingale property, the predictive distribution can be written as an integral over a "martingale posterior" parameter, separating uncertainty about this parameter (epistemic) from irreducible noise (aleatoric).
- **Core assumption:** The martingale property holds, allowing the predictive distribution to be expressed in a form similar to Bayesian posterior predictive.
- **Evidence anchors:**
  - [abstract] "it establishes a principled notion of the model's uncertainty vital in trustworthy, safety-critical systems"
  - [section] "Eq. (4) shows that the variation or uncertainty in the predictive distribution pM(Zn+1 = Â· |Z1:n) has two sources: 1. epistemic uncertainty... 2. aleatoric uncertainty..."
  - [corpus] Weak - corpus does not directly discuss uncertainty decomposition or epistemic/aletoropic uncertainty.
- **Break condition:** If the model does not satisfy the martingale property, the principled uncertainty decomposition is not valid.

### Mechanism 3
- **Claim:** Violations of the martingale property indicate that in-context learning is not Bayesian.
- **Mechanism:** Since the martingale property is a necessary condition for exchangeability, and exchangeability with conditionally i.i.d. observations is equivalent to Bayesian inference, violating the martingale property implies the learning is not Bayesian.
- **Core assumption:** The in-context learning setting assumes exchangeable (or i.i.d.) observations.
- **Evidence anchors:**
  - [abstract] "We provide evidence for violations of the martingale property... falsifying the hypothesis that ICL is Bayesian"
  - [section] "In conclusion, ICL on i.i.d. data corresponds to a Bayesian model... if and only if it defines an exchangeable sample sequence. Since the martingale property is a necessary condition for exchangeability, an ICL system not satisfying the martingale property cannot be Bayesian."
  - [corpus] Weak - corpus does not directly discuss the relationship between martingale property violations and non-Bayesian learning.
- **Break condition:** If the data is not exchangeable or the learning does not correspond to a Bayesian model, martingale property violations do not necessarily imply non-Bayesian learning.

## Foundational Learning

- **Concept:** Exchangeability
  - **Why needed here:** The martingale property is a necessary condition for exchangeability, and exchangeability is a key assumption in the paper's analysis of in-context learning.
  - **Quick check question:** Can you explain why exchangeability is a weaker assumption than i.i.d., and give an example where data is exchangeable but not i.i.d.?

- **Concept:** Martingale property
  - **Why needed here:** The martingale property is the central concept used to analyze whether in-context learning is Bayesian, and to derive diagnostics for checking this.
  - **Quick check question:** Can you state the martingale property mathematically and explain its intuitive meaning in the context of in-context learning?

- **Concept:** Epistemic vs Aleatoric uncertainty
  - **Why needed here:** The paper argues that the martingale property allows for a principled decomposition of uncertainty into these two components, which is important for understanding and interpreting model predictions.
  - **Quick check question:** Can you explain the difference between epistemic and aleatoric uncertainty, and give an example of how each might manifest in a real-world prediction task?

## Architecture Onboarding

- **Component map:** LLM -> ICL dataset -> Diagnostic functions -> Reference Bayesian model
- **Critical path:**
  1. Generate sample paths from the LLM using in-context learning on the ICL dataset
  2. Compute diagnostic test statistics on the sample paths
  3. Compare the test statistics to bootstrap confidence intervals from the reference Bayesian model
  4. If the test statistics fall outside the confidence intervals, the martingale property is violated and ICL is not Bayesian
- **Design tradeoffs:**
  - Short vs long sample paths: Short paths may not reveal violations, but long paths may be computationally expensive and may violate the martingale property due to expected deviations over many steps
  - Choice of diagnostic functions: Different functions may be more or less sensitive to violations, and may have different computational costs
- **Failure signatures:**
  - Test statistics falling outside bootstrap confidence intervals: Indicates violation of the martingale property and non-Bayesian learning
  - LLM generating unrealistic or inconsistent predictions: May indicate violations of the martingale property or other issues with the model
- **First 3 experiments:**
  1. Bernoulli experiment: ICL on binary data with known probability, check if LLM's predictions are consistent with Bayesian updating
  2. Gaussian experiment: ICL on continuous data with known mean and variance, check if LLM's uncertainty estimates are consistent with Bayesian inference
  3. Synthetic natural language experiment: ICL on text data representing a simple diagnostic task, check if LLM's predictions are consistent with Bayesian reasoning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs be trained or fine-tuned to better adhere to the martingale property in exchangeable data settings?
- Basis in paper: [explicit] The paper notes that finetuned models may demonstrate better adherence to the martingale property, but do not always pass the checks.
- Why unresolved: The paper does not explore extensive fine-tuning strategies or architectures designed to enforce martingale behavior.
- What evidence would resolve it: Systematic experiments comparing different fine-tuning objectives, model architectures, and training regimes on their ability to satisfy martingale property diagnostics.

### Open Question 2
- Question: How does the martingale property violation in LLMs manifest in more complex reasoning tasks beyond simple exchangeable data?
- Basis in paper: [inferred] The paper mentions the RCT example as a simple multi-step reasoning task and suggests investigating analogies to the identified hallucination behavior in more complex reasoning tasks like chain-of-thought prompting.
- Why unresolved: The paper focuses on synthetic experiments with simple data distributions and does not explore complex reasoning tasks.
- What evidence would resolve it: Experiments applying the martingale property diagnostics to LLMs performing complex reasoning tasks, such as chain-of-thought prompting or multi-step decision making.

### Open Question 3
- Question: What is the relationship between the martingale property violation and the emergence of non-Bayesian in-context learning in LLMs?
- Basis in paper: [explicit] The paper shows that LLMs violate the martingale property, which is a necessary condition for Bayesian learning in exchangeable data settings, thus falsifying the hypothesis that ICL is Bayesian.
- Why unresolved: The paper does not explore the deeper connection between martingale property violations and the broader phenomenon of non-Bayesian in-context learning.
- What evidence would resolve it: Further theoretical analysis and empirical studies investigating the mechanisms behind martingale property violations and their relationship to the emergence of non-Bayesian in-context learning in LLMs.

## Limitations
- Synthetic nature of evaluation datasets may not fully capture complexities of real-world in-context learning scenarios
- Interpretation of martingale property violations as definitive evidence against Bayesian ICL requires careful consideration
- Potential differences in how LLMs handle uncertainty compared to explicit Bayesian models

## Confidence
- High confidence in the theoretical framework connecting martingale properties to Bayesian learning
- Medium confidence in the experimental methodology and its ability to detect martingale violations
- Medium confidence in the interpretation of results as evidence against Bayesian ICL

## Next Checks
1. Test martingale properties on real-world datasets with known ground truth distributions to validate findings from synthetic experiments
2. Investigate whether fine-tuning LLMs on more diverse data distributions affects martingale property adherence
3. Compare martingale diagnostics across different prompting strategies and model sizes to identify potential mitigation approaches