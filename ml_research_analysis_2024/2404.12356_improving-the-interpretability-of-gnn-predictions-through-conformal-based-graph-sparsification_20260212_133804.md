---
ver: rpa2
title: Improving the interpretability of GNN predictions through conformal-based graph
  sparsification
arxiv_id: '2404.12356'
source_url: https://arxiv.org/abs/2404.12356
tags:
- ratio
- graph
- node
- accuracy
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CORES uses reinforcement learning with conformal-based rewards
  to train GNNs for graph classification by identifying the most predictive subgraph
  without assuming its structure. It jointly optimizes subgraph sparsity and classification
  performance using a bi-level approach with policy gradient methods.
---

# Improving the interpretability of GNN predictions through conformal-based graph sparsification

## Quick Facts
- arXiv ID: 2404.12356
- Source URL: https://arxiv.org/abs/2404.12356
- Reference count: 40
- CORES achieves competitive accuracy compared to baselines while relying on significantly sparser subgraphs, improving interpretability

## Executive Summary
This paper introduces CORES (Conformal-based Graph Sparsification), a method that improves the interpretability of Graph Neural Network (GNN) predictions by identifying the most predictive subgraphs for graph classification tasks. CORES uses reinforcement learning with conformal-based rewards to train GNNs without assuming the structure of the predictive subgraph. The method achieves this through a bi-level optimization approach that jointly optimizes subgraph sparsity and classification performance. Evaluated on nine graph classification datasets, CORES demonstrates that interpretability can be enhanced without sacrificing predictive performance, with the node removal mode (CORESN) generally achieving higher sparsity levels than the edge removal mode (CORESE).

## Method Summary
CORES employs reinforcement learning with policy gradient methods to identify the most predictive subgraph for graph classification. The method uses a conformal-based reward function that incorporates classifier uncertainty to guide the optimization process. CORES operates in two modes: node removal (CORESN) and edge removal (CORESE), both of which aim to create sparse subgraphs while maintaining classification accuracy. The approach uses a bi-level optimization framework where the inner level optimizes the GNN classifier and the outer level optimizes the subgraph selection policy. The conformal prediction component helps account for uncertainty in the classifier's predictions, making the reward signal more robust to variations in the graph structure.

## Key Results
- CORES achieves competitive accuracy compared to baseline methods on nine graph classification datasets
- The method identifies significantly sparser subgraphs than baseline approaches while maintaining performance
- CORESN (node removal mode) generally achieves higher sparsity levels than CORESE (edge removal mode)
- The conformal-based reward mechanism helps balance sparsity and accuracy by accounting for classifier uncertainty
- CORES outperforms sparse model baselines in both accuracy and sparsity rankings

## Why This Works (Mechanism)
CORES works by using reinforcement learning to identify the minimal yet predictive subgraph structure needed for accurate classification. The key insight is that not all nodes and edges in a graph contribute equally to classification performance. By using conformal prediction to create a reward signal that accounts for classifier uncertainty, CORES can identify which parts of the graph are truly predictive versus which are noise or redundant information. The bi-level optimization approach allows the method to jointly optimize both the subgraph selection and the classifier, ensuring that the identified sparse subgraphs remain effective for the downstream task.

## Foundational Learning
1. **Conformal Prediction** - A framework for uncertainty quantification that provides statistically valid prediction intervals. Needed to create reliable reward signals that account for classifier uncertainty. Quick check: Verify that the conformal scores properly calibrate uncertainty across different graph structures and sizes.

2. **Reinforcement Learning with Policy Gradients** - A method for optimizing policies through gradient-based updates. Required to learn the subgraph selection strategy without assuming its structure. Quick check: Ensure the policy gradient updates converge and that the learned policy generalizes across different graph types.

3. **Graph Neural Networks** - Neural networks designed to operate on graph-structured data. Essential for extracting features from the sparse subgraphs identified by CORES. Quick check: Confirm that the GNN architecture can effectively process the varying sizes and structures of the sparse subgraphs.

4. **Bi-level Optimization** - An optimization framework where one optimization problem is embedded within another. Necessary to jointly optimize both the classifier and the subgraph selection policy. Quick check: Verify that the inner and outer optimization loops are properly coordinated and that the overall optimization converges.

5. **Graph Sparsification** - The process of reducing graph complexity while preserving essential structural properties. Central to CORES's goal of improving interpretability through sparsity. Quick check: Ensure that the sparsification process preserves the predictive information needed for accurate classification.

## Architecture Onboarding

**Component Map:** Graph Dataset -> Graph Neural Network (Classifier) -> Conformal Prediction Module -> Reward Function -> Policy Gradient Optimizer -> Subgraph Selection Policy -> Sparse Subgraph -> Graph Neural Network (Classifier)

**Critical Path:** Graph Dataset → Subgraph Selection Policy → Sparse Subgraph → GNN Classifier → Conformal Prediction → Reward Function → Policy Updates

**Design Tradeoffs:** The method balances between sparsity (interpretability) and accuracy through the conformal-based reward function. Higher sparsity may reduce accuracy, while lower sparsity reduces interpretability benefits. The reinforcement learning approach trades computational complexity for flexibility in identifying predictive subgraph structures without prior assumptions.

**Failure Signatures:** Poor performance may indicate: 1) Conformal predictions are not properly calibrated, leading to ineffective reward signals; 2) Policy gradient updates are not converging, resulting in suboptimal subgraph selection; 3) The GNN architecture cannot effectively process the sparse subgraphs; 4) The bi-level optimization is not properly coordinated between inner and outer loops.

**3 First Experiments:**
1. Test CORES on a simple synthetic graph dataset with known predictive subgraphs to verify that the method can correctly identify these structures
2. Compare the conformal scores and sparsity levels across different graph sizes and types to validate the reward mechanism's effectiveness
3. Perform an ablation study removing the conformal component to assess its contribution to the overall performance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- The evaluation relies on nine graph classification datasets, which may not capture all real-world scenarios where GNN interpretability is critical
- The comparison with baseline methods is limited to specific sparse model approaches, potentially missing other relevant baselines
- The reinforcement learning approach introduces optimization challenges including potential convergence issues and sensitivity to reward function design
- The trade-off between sparsity and accuracy across different graph types and sizes is not fully explored

## Confidence
- **High Confidence**: CORES achieves competitive accuracy while improving interpretability through sparsity (well-supported by experimental results)
- **Medium Confidence**: CORES outperforms sparse model baselines in both accuracy and sparsity rankings (supported but could benefit from additional baseline comparisons)
- **Medium Confidence**: The conformal-based reward mechanism effectively accounts for classifier uncertainty (demonstrated but requires further validation)

## Next Checks
1. Evaluate CORES on additional graph classification datasets with varying structural characteristics to assess generalizability across different graph types and sizes
2. Conduct ablation studies to isolate the contribution of the conformal-based reward mechanism versus other components of the optimization framework
3. Test the method's robustness to different initial subgraph configurations and explore the impact of varying the sparsity targets on both accuracy and interpretability metrics