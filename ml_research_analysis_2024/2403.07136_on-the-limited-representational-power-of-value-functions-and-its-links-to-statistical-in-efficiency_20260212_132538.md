---
ver: rpa2
title: On the Limited Representational Power of Value Functions and its Links to Statistical
  (In)Efficiency
arxiv_id: '2403.07136'
source_url: https://arxiv.org/abs/2403.07136
tags:
- value
- linear
- lstd
- functions
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates when value-based reinforcement learning
  algorithms are statistically efficient. The authors argue that efficiency depends
  on whether the problem structure can be represented in the space of value functions.
---

# On the Limited Representational Power of Value Functions and its Links to Statistical (In)Efficiency

## Quick Facts
- arXiv ID: 2403.07136
- Source URL: https://arxiv.org/abs/2403.07136
- Reference count: 40
- Authors: David Cheikhi; Daniel Russo
- One-line primary result: Value-based RL methods are statistically efficient when there is no information loss in the value function representation, but can be severely inefficient when information loss exists

## Executive Summary
This paper investigates the statistical efficiency of value-based reinforcement learning algorithms by examining the representational power of value functions. The authors introduce the concept of "information loss" - when a class of models has the same value functions as a larger class, making it impossible for value-based methods to distinguish between them. Through theoretical analysis and case studies, they demonstrate that efficiency depends on whether the problem structure can be represented in the space of value functions. The paper shows that when information loss occurs, LSTD (least-squares temporal difference learning) behaves as if it's doing model-based estimation over a larger set of models, leading to unnecessary parameter estimation and sample inefficiency.

## Method Summary
The paper analyzes policy evaluation in Markov Reward Processes (MRPs) using value-based methods like LSTD. The authors examine when value-based estimators are statistically efficient by comparing them against model-based estimators across different model classes with specific structural constraints (diagonal dynamics, linear quadratic control, decoupled MRPs). They prove that LSTD is equivalent to model-based estimation on a larger class when information loss occurs, leading to inefficiency. The efficiency analysis uses asymptotic methods (Central Limit Theorems) to prove statistical inefficiency when information loss exists.

## Key Results
- Information loss occurs when multiple distinct transition kernels produce the same value functions, making structural constraints unrecoverable from value function data alone
- LSTD is statistically efficient (matches model-based efficiency) when there is no information loss, but suffers Θ(d) inefficiency when information loss exists in diagonal dynamics
- There is a perfect correlation between LSTD's relative statistical inefficiency and whether there is loss of information in the space of value functions across five case studies
- The gap in sample complexity between model-based and LSTD grows rapidly with the number of components in decoupled MRP examples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Information loss occurs when value functions cannot encode structural constraints on the transition dynamics
- Mechanism: Value functions are determined by reward function and transition kernel. When multiple distinct transition kernels produce the same value functions, the structure of the transition kernel is "lost" in the value function representation
- Core assumption: The class of models inducing the same value functions must be larger than the original class of models with the specific structure
- Evidence anchors: [abstract]: "information about the transition dynamics may be impossible to represent in the space of value functions"; [section]: Theorem 4.3 proves that for any separable value function and any transition kernel, there exists a reward vector making the value function separable

### Mechanism 2
- Claim: LSTD's statistical inefficiency arises because it implicitly estimates in a larger model class when information loss exists
- Mechanism: When information loss occurs, LSTD behaves as if it's doing model-based estimation over a larger set of models that shares the same value functions, leading to unnecessary parameter estimation and sample inefficiency
- Core assumption: LSTD only leverages knowledge of the value function class, not the underlying model structure
- Evidence anchors: [abstract]: "LSTD is equivalent to a model-based least-squares estimation procedure that operates in a much larger space of models"; [section]: Theorem 5.2 shows LSTD is equivalent to model-based estimation on a larger class in the diagonal dynamics case

### Mechanism 3
- Claim: The efficiency of model-free methods correlates perfectly with the presence of information loss in the value function space
- Mechanism: When there is no information loss, LSTD achieves the same statistical efficiency as model-based methods; when information loss exists, LSTD is severely outperformed
- Core assumption: The examples studied represent a complete characterization of when information loss occurs
- Evidence anchors: [abstract]: "there is a perfect correlation between LSTD's relative statistical inefficiency and whether there is loss of information in the space of value functions"; [section]: Table 1 summarizes five case studies showing perfect correlation

## Foundational Learning

- Concept: Markov Reward Processes (MRPs)
  - Why needed here: The paper's analysis is built on understanding value functions in MRPs and how they relate to transition dynamics and rewards
  - Quick check question: What is the relationship between the value function V(s) and the transition kernel P and reward distribution R in an MRP?

- Concept: Linear function approximation in RL
  - Why needed here: LSTD and the model-based estimators discussed all operate in linear function spaces, and the efficiency analysis depends on understanding when linear representations are sufficient
  - Quick check question: How does the choice of value function representation (e.g., linear vs. quadratic) affect what information about the model can be captured?

- Concept: Central Limit Theorems for statistical efficiency analysis
  - Why needed here: The paper uses asymptotic analysis (CLT) to prove the statistical inefficiency of LSTD when information loss occurs
  - Quick check question: How does the asymptotic variance of an estimator relate to its sample efficiency, and what does it mean for two estimators to have different asymptotic variances?

## Architecture Onboarding

- Component map: Value function representation space V -> Model class M with structural constraints -> Induced value function class {VM : M ∈ M} -> LSTD algorithm mapping (V, D) -> ˆV -> Model-based estimator for comparison
- Critical path: Identify problem structure -> Determine induced value function class -> Check for information loss -> Choose appropriate estimation method
- Design tradeoffs: Expressiveness of value function class vs. ability to capture model structure
- Failure signatures: LSTD performs poorly despite seemingly favorable problem structure (e.g., decoupled dynamics with additive rewards)
- First 3 experiments:
  1. Verify information loss in decoupled MRPs by checking if multiple transition kernels induce the same separable value functions
  2. Compare LSTD vs model-based efficiency in linear systems with diagonal dynamics
  3. Test whether explicitly encoding problem structure in the estimation algorithm (not just value function class) improves LSTD's efficiency

## Open Questions the Paper Calls Out

- Can we formally prove that value-based estimation procedures cannot adapt to problem structures based solely on value function representations when there is information loss?
- How can we design value-based estimation procedures that are tailored to specific problem structures like decoupled MRP structure to overcome information loss?
- What is the relationship between information loss in value functions and statistical efficiency gaps in other reinforcement learning settings beyond policy evaluation?

## Limitations
- The analysis focuses on specific model classes (diagonal dynamics, linear quadratic control, decoupled MRPs) and may not generalize to all possible information loss scenarios
- The proof techniques rely on separability arguments that may not generalize to nonlinear or non-separable function classes
- The asymptotic analysis assumes infinite data, which may not reflect practical finite-sample behavior where estimation errors could mask representational limitations

## Confidence

- **High Confidence**: The theoretical framework for defining information loss and its relationship to value function representation is sound and mathematically rigorous
- **Medium Confidence**: The correlation between information loss and LSTD inefficiency holds for the specific examples studied, but generalizability to broader classes of problems requires further investigation
- **Low Confidence**: The claim that information loss is the only factor determining LSTD's efficiency - there may be additional factors (such as regularization, initialization, or optimization dynamics) that affect practical performance

## Next Checks

1. **Generalization Test**: Examine whether information loss occurs in non-separable function classes (e.g., polynomial bases of degree > 1) and whether LSTD's efficiency correlates with information loss in these cases
2. **Finite-Sample Analysis**: Conduct experiments comparing LSTD and model-based methods across a range of sample sizes to understand when the asymptotic inefficiency manifests in practice
3. **Algorithmic Modifications**: Test whether incorporating problem structure directly into LSTD's update rule (rather than just the value function class) can recover efficiency even when information loss exists