---
ver: rpa2
title: A Comparison of Large Language Model and Human Performance on Random Number
  Generation Tasks
arxiv_id: '2408.09656'
source_url: https://arxiv.org/abs/2408.09656
tags:
- random
- human
- generation
- sequences
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares random number generation tasks (RNGTs) between
  ChatGPT-3.5 and humans to assess how well LLMs avoid predictable patterns. The research
  adapts a human RNGT into an LLM-compatible environment, generating 10,000 sequences
  from ChatGPT-3.5 and comparing them to human-generated sequences from prior studies.
---

# A Comparison of Large Language Model and Human Performance on Random Number Generation Tasks

## Quick Facts
- arXiv ID: 2408.09656
- Source URL: https://arxiv.org/abs/2408.09656
- Reference count: 40
- Primary result: ChatGPT-3.5 demonstrated notably lower frequencies of repeated digits and adjacent number sequences compared to humans in random number generation tasks

## Executive Summary
This study compares random number generation tasks (RNGTs) between ChatGPT-3.5 and humans to assess how well LLMs avoid predictable patterns. The research adapts a human RNGT into an LLM-compatible environment, generating 10,000 sequences from ChatGPT-3.5 and comparing them to human-generated sequences from prior studies. ChatGPT-3.5 demonstrated notably lower frequencies of repeated digits and adjacent number sequences compared to humans, with repeat frequencies of 0.001 versus 0.076 in humans, and adjacent sequence frequencies of 0.063/0.078 versus 0.154/0.169. While ChatGPT-3.5's outputs showed more uniformity than human sequences, they still deviated from perfect randomness.

## Method Summary
The study used the OpenAI API with gpt-3.5-turbo-0125 model and default parameters to generate 10,000 random number sequences. A prompt was adapted from human studies to specify target length, with sequences drawn from a normal distribution (N(269, 325Â²)) and capped at 2-922 digits. The generated sequences were cleaned to remove non-numeric characters and analyzed for pattern frequencies including repeat frequency, increase/decrease frequency, and digit distributions. These metrics were compared against human-generated sequences from prior studies to assess pattern avoidance and proximity to true randomness.

## Key Results
- ChatGPT-3.5 showed repeat frequencies of 0.001 compared to 0.076 in human-generated sequences
- Adjacent sequence frequencies for ChatGPT-3.5 were 0.063 (increase) and 0.078 (decrease) versus 0.154 and 0.169 for humans
- ChatGPT-3.5 outputs exhibited more uniformity than human sequences but still deviated from perfect randomness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs trained on human-generated text inherit human-like cognitive biases that manifest in random number generation tasks.
- Mechanism: The LLM's transformer architecture, trained on diverse human-generated text, learns implicit patterns of human behavior, including predictable tendencies in random number generation such as avoiding consecutive repetitions and favoring certain sequences.
- Core assumption: The LLM's training data contains sufficient examples of human-generated random sequences to capture these biases.
- Evidence anchors:
  - [abstract] "trained on human-generated text, exhibits human-like cognitive biases when generating random number sequences"
  - [section] "these models are inherently imbued with an extensive but implicit understanding of human language, cognition, and social norms"
  - [corpus] Weak evidence - corpus contains studies on AI behavioral science but lacks direct comparison of human and LLM RNG biases
- Break condition: If the LLM is trained on highly curated or synthetic data rather than naturally occurring human text, the inherited biases would be minimal or absent.

### Mechanism 2
- Claim: LLMs avoid certain human biases more effectively than humans in random number generation tasks.
- Mechanism: The algorithmic nature of LLMs, combined with attention mechanisms, allows them to systematically minimize repetitive and sequential patterns that humans naturally produce, resulting in lower frequencies of repeated digits and adjacent number sequences.
- Core assumption: The LLM's attention mechanism can detect and reduce predictable patterns in generated sequences.
- Evidence anchors:
  - [abstract] "ChatGPT-3.5 demonstrated notably lower frequencies of repeated digits and adjacent number sequences compared to humans"
  - [section] "ChatGPT significantly outperformed human capabilities in avoiding common human biases related to pattern repetition"
  - [corpus] Moderate evidence - related work on AI predicting pseudo-random numbers suggests transformers can learn patterns in sequential data
- Break condition: If the model's architecture or training objective prioritizes other features over randomness, the bias reduction may not occur.

### Mechanism 3
- Claim: LLM-generated sequences exhibit characteristics between human-like variability and computational randomness.
- Mechanism: While LLMs minimize human-like patterns, they don't achieve perfect randomness due to inherent algorithmic biases, creating an intermediate category of randomness that blends human variability with computational structure.
- Core assumption: LLMs cannot achieve true randomness because their outputs are deterministically generated based on learned patterns.
- Evidence anchors:
  - [abstract] "ChatGPT-3.5's outputs showed more uniformity than human sequences, they still deviated from perfect randomness"
  - [section] "This positions LLMs in a unique intermediate category, blending elements of both human-like variability and computational randomness"
  - [corpus] Moderate evidence - studies on LLM creativity and problem-solving suggest they exhibit hybrid behaviors between human and algorithmic approaches
- Break condition: If LLMs were designed with explicit randomness objectives or incorporated external random number generators, this intermediate behavior might not manifest.

## Foundational Learning

- Concept: Random Number Generation Tasks (RNGTs) and their use in psychological research
  - Why needed here: Understanding the context and methodology of RNGTs is essential for interpreting the study's comparison between LLM and human performance.
  - Quick check question: What cognitive functions do RNGTs typically assess in psychological research?
  - Answer: Executive functions related to the frontal lobes, such as inhibition, cognitive flexibility, and information monitoring.

- Concept: Transformer architecture and attention mechanisms in LLMs
  - Why needed here: The transformer architecture underlies how LLMs process sequential data and generate outputs, which is crucial for understanding their RNG behavior.
  - Quick check question: How does the attention mechanism in transformers contribute to pattern recognition in sequential data?
  - Answer: Attention mechanisms allow transformers to weigh the importance of different elements in a sequence, enabling them to detect and potentially minimize predictable patterns.

- Concept: Statistical measures for assessing randomness (repeat frequency, increase/decrease frequency)
  - Why needed here: These metrics are used to quantify and compare the randomness of LLM-generated sequences against human and theoretical random sequences.
  - Quick check question: What would be the expected repeat frequency for a perfectly random sequence of 10 digits?
  - Answer: 0.1 (10% of adjacent pairs would be identical in truly random sequences).

## Architecture Onboarding

- Component map:
  OpenAI API integration -> Prompt engineering -> Sequence generation -> Data cleaning -> Pattern frequency calculation -> Statistical comparison

- Critical path:
  1. API call to generate sequence
  2. Data cleaning and validation
  3. Pattern frequency calculation
  4. Statistical aggregation across 10,000 sequences
  5. Comparison with human and theoretical data

- Design tradeoffs:
  - Using default model settings vs. optimizing for randomness (temperature, top_p)
  - Fixed prompt length vs. variable length to match human study conditions
  - Computational cost of 10,000 sequences vs. statistical significance

- Failure signatures:
  - Sequences consistently below minimum length despite constraints
  - Pattern frequencies matching human biases too closely
  - API rate limiting or quota exhaustion during data collection

- First 3 experiments:
  1. Test sequence generation with varying temperature settings to assess impact on randomness metrics
  2. Compare different prompting strategies (persona-based, explicit instructions) on pattern avoidance
  3. Evaluate multiple LLM models (GPT-4, Claude, LLaMA) to identify model-agnostic vs. model-specific RNG behaviors

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different LLM architectures (transformers, RNNs, etc.) and training paradigms (supervised, self-supervised, reinforcement learning) affect the generation of random sequences compared to human performance?
- Basis in paper: [explicit] The paper discusses the potential for future work to explore different LLM models, including both proprietary and open-source alternatives, to understand model-agnostic vs. model-specific capabilities and limitations.
- Why unresolved: The current study focuses on a single model (ChatGPT-3.5), limiting the generalizability of findings to other LLM architectures and training paradigms.
- What evidence would resolve it: Comparative studies testing various LLM architectures and training paradigms on RNGTs, analyzing their performance against human-generated sequences and identifying common patterns or divergences.

### Open Question 2
- Question: Can LLMs be trained or prompted to specifically mimic human cognitive biases in RNGTs, and if so, what are the implications for understanding human decision-making and AI behavior?
- Basis in paper: [inferred] The paper notes that ChatGPT's performance deviates from human-like randomness, suggesting a potential algorithmic bias. This raises the question of whether LLMs can be intentionally engineered to replicate human cognitive biases.
- Why unresolved: The current study uses default settings and does not explore the impact of different prompting strategies or model parameters on the generation of human-like random sequences.
- What evidence would resolve it: Experiments manipulating LLM prompts and parameters to encourage the generation of sequences with human-like biases, analyzing the resulting patterns and comparing them to human-generated data.

### Open Question 3
- Question: How does the performance of LLMs on RNGTs change when using non-numeric text (letters, symbols) as the generation medium, and what insights does this provide into the nature of AI-generated randomness?
- Basis in paper: [explicit] The paper suggests exploring the generation of random sequences using non-numeric text, as LLMs are predominantly trained on linguistic data.
- Why unresolved: The current study focuses on numeric sequences, limiting the understanding of how LLMs handle randomness in other domains.
- What evidence would resolve it: Studies comparing LLM performance on RNGTs using both numeric and non-numeric text, analyzing the similarities and differences in the generated patterns and their alignment with human-like randomness.

## Limitations
- The comparison relies on datasets from prior studies without direct access to raw human data, limiting identical statistical analyses
- Default temperature settings (1.0) may not represent optimal conditions for random sequence generation
- The study doesn't explore how parameter tuning affects pattern avoidance

## Confidence
- High confidence: ChatGPT-3.5 generates lower frequencies of repeated digits and adjacent sequences compared to humans
- Medium confidence: LLMs represent an intermediate category between human-like variability and computational randomness
- Medium confidence: Inherited human cognitive biases require additional evidence

## Next Checks
1. Replicate with controlled human dataset: Generate new human RNGT data using identical prompts and procedures to enable direct statistical comparison with the same metrics and analysis pipeline.

2. Parameter sensitivity analysis: Systematically vary temperature and other generation parameters to determine their impact on pattern frequencies and assess whether the observed behavior is robust across different settings.

3. Cross-model comparison: Test multiple LLM architectures (GPT-4, Claude, LLaMA) to determine whether the pattern avoidance behavior is model-specific or represents a broader characteristic of transformer-based language models.