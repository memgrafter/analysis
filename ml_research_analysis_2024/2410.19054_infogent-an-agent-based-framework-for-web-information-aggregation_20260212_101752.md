---
ver: rpa2
title: 'Infogent: An Agent-Based Framework for Web Information Aggregation'
arxiv_id: '2410.19054'
source_url: https://arxiv.org/abs/2410.19054
tags:
- information
- access
- task
- infogent
- navigator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "INFOGENT is a modular web information aggregation framework that\
  \ combines three specialized components\u2014Navigator, Extractor, and Aggregator\u2014\
  to handle complex queries requiring data from multiple sources. It operates in two\
  \ access settings: Direct API-driven Access using text-only web data and Interactive\
  \ Visual Access requiring browser interaction via screenshots."
---

# Infogent: An Agent-Based Framework for Web Information Aggregation

## Quick Facts
- arXiv ID: 2410.19054
- Source URL: https://arxiv.org/abs/2410.19054
- Authors: Revanth Gangi Reddy; Sagnik Mukherjee; Jeonghwan Kim; Zhenhailong Wang; Dilek Hakkani-Tur; Heng Ji
- Reference count: 16
- Key outcome: INFOGENT improves over state-of-the-art baselines by 7% on FRAMES under Direct API access and 4.3% on AssistantBench under Interactive Visual Access

## Executive Summary
INFOGENT is a modular web information aggregation framework that combines three specialized components—Navigator, Extractor, and Aggregator—to handle complex queries requiring data from multiple sources. It operates in two access settings: Direct API-driven Access using text-only web data and Interactive Visual Access requiring browser interaction via screenshots. Experiments show INFOGENT improves over state-of-the-art baselines by 7% on FRAMES under Direct API access and 4.3% on AssistantBench under Interactive Visual Access, demonstrating effective multi-website information gathering.

## Method Summary
INFOGENT is a modular framework with three specialized components: Navigator (handles web navigation), Extractor (extracts relevant content), and Aggregator (evaluates and retains information). The framework operates in two modes—Direct API-driven Access using LLMs for text-only data and Interactive Visual Access using VLMs for browser interaction. A feedback-driven loop allows the Aggregator to guide the Navigator based on information gaps. The modular design enables specialized optimization for each component while maintaining flexibility across different web access scenarios.

## Key Results
- INFOGENT improves over state-of-the-art baselines by 7% on FRAMES under Direct API access
- INFOGENT improves over state-of-the-art baselines by 4.3% on AssistantBench under Interactive Visual Access
- The framework successfully handles complex queries requiring data from multiple sources across both access modes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The modular design with specialized Navigator, Extractor, and Aggregator components enables effective information aggregation by allowing each component to focus on its specific task.
- Mechanism: The Navigator handles web navigation, the Extractor extracts relevant content from webpages, and the Aggregator evaluates and retains the extracted information. This division of labor prevents overloading a single component and allows for specialized optimization.
- Core assumption: Each component can perform its designated task effectively without requiring knowledge of the internal workings of the other components.
- Evidence anchors:
  - [abstract] "INFOGENT is a modular web information aggregation framework that combines three specialized components—Navigator, Extractor, and Aggregator"
  - [section 4] "INFOGENT’s modular architecture is optimized for information aggregation and enhances adaptability across diverse scenarios by dividing responsibilities among distinct components"
- Break condition: If the components are not truly independent or if the information flow between them becomes a bottleneck, the modular design could fail to improve performance.

### Mechanism 2
- Claim: The feedback-driven navigation loop allows the agent to iteratively improve its information gathering by incorporating insights from the Aggregator.
- Mechanism: The Aggregator provides feedback to the Navigator about gaps in the aggregated information, guiding subsequent searches to address deficiencies. This creates a dynamic and adaptive information-seeking process.
- Core assumption: The Aggregator can accurately identify gaps in the aggregated information and provide actionable feedback to the Navigator.
- Evidence anchors:
  - [abstract] "INFOGENT’s modular framework featuring specialized aggregation and feedback modules"
  - [section 4] "Using F, AG can also instruct N G to finish the process once sufficient information has been gathered"
- Break condition: If the Aggregator's feedback is inaccurate or misleading, the Navigator could be guided down unproductive paths, wasting time and resources.

### Mechanism 3
- Claim: Supporting both Direct API-driven Access and Interactive Visual Access allows INFOGENT to handle a wider range of information aggregation tasks by adapting to different web information access scenarios.
- Mechanism: The framework can use text-only data extraction via APIs for easily accessible information and simulate human browsing for information behind paywalls or requiring interaction. This flexibility ensures that INFOGENT can gather information from diverse sources.
- Core assumption: The underlying models (LLM for Direct API and VLM for Interactive Visual) are capable of handling their respective access methods effectively.
- Evidence anchors:
  - [abstract] "It operates in two access settings: Direct API-driven Access using text-only web data and Interactive Visual Access requiring browser interaction via screenshots"
  - [section 3] "We consider web information aggregation from two different perspectives: (i) Direct API-driven Access... (ii) Interactive Visual Access..."
- Break condition: If the underlying models are not sufficiently capable for their respective access methods, the framework's ability to handle diverse information sources could be compromised.

## Foundational Learning

- Concept: Modular design and separation of concerns
  - Why needed here: INFOGENT's success relies on the effective collaboration of three specialized components. Understanding how to design and integrate such modules is crucial for implementing and extending the framework.
  - Quick check question: What are the potential drawbacks of a monolithic approach compared to INFOGENT's modular design for web information aggregation?

- Concept: Feedback loops and iterative improvement
  - Why needed here: The feedback-driven navigation loop is a key mechanism that allows INFOGENT to adaptively improve its information gathering. Understanding how to design and implement such loops is essential for optimizing the framework's performance.
  - Quick check question: How does the feedback from the Aggregator influence the Navigator's decision-making process, and what are the potential risks of inaccurate feedback?

- Concept: Multimodal AI and different access methods
  - Why needed here: INFOGENT supports both Direct API-driven Access and Interactive Visual Access, requiring an understanding of how to leverage different types of AI models (LLM and VLM) for different information access scenarios.
  - Quick check question: What are the key differences between using an LLM for text-only data extraction and using a VLM for simulating human browsing, and how do these differences impact the overall performance of INFOGENT?

## Architecture Onboarding

- Component map:
  - Navigator (N G) -> Extractor (ET) -> Aggregator (AG) -> Information Stack (S) -> Feedback (F) -> Navigator (N G)

- Critical path:
  1. User task is received
  2. Navigator searches for relevant websites
  3. Extractor extracts relevant information from a selected website
  4. Aggregator evaluates the extracted information and provides feedback
  5. Navigator uses the feedback to guide further navigation
  6. Steps 3-5 are repeated until sufficient information is gathered or the maximum number of iterations is reached

- Design tradeoffs:
  - Using a smaller, cost-efficient model for the Extractor to process webpage content, favoring extraction over summarization to avoid hallucination and maintain reliability
  - Allowing the Navigator to backtrack and transfer control to the Aggregator when aggregation is to be performed, enhancing its ability to handle information-seeking tasks
  - Employing the same aggregator component for both Direct API-driven Access and Interactive Visual Access, since the primary focus is on textual information aggregation

- Failure signatures:
  - Navigator failure: Incorrect actions, invalid assumptions during searches, ignoring aggregator feedback, repeatedly triggering identical actions
  - Extractor failure: Incorrectly judging information as task-relevant, particularly on information-dense pages with distractions
  - Aggregator failure: Providing open-ended or incorrect feedback, omitting relevant information from memory

- First 3 experiments:
  1. Evaluate INFOGENT on the FRAMES dataset under Direct API-driven Access to assess its performance on complex queries requiring various reasoning types
  2. Evaluate INFOGENT on the AssistantBench dataset under Interactive Visual Access to assess its ability to handle time-consuming online information-seeking tasks
  3. Conduct ablation experiments by replacing GPT-4o with GPT-4o-mini for each component (Navigator, Extractor, Aggregator) separately to investigate which component is most dependent on the underlying model's capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the INFOGENT framework be extended to handle real-world web information aggregation tasks that involve subjective information, where the definition of "sufficient" or "complete" information is not clearly defined?
- Basis in paper: Explicit
- Why unresolved: The paper mentions that real-world web information aggregation remains subjective and that current evaluation relies on multi-hop QA datasets due to the absence of real-world datasets capturing subjective aggregation nuances. The authors also note that designing appropriate evaluation metrics for such tasks remains complex.
- What evidence would resolve it: Development and evaluation of INFOGENT on a real-world dataset specifically designed for subjective information aggregation, along with the creation of evaluation metrics that capture the quality, diversity, and sufficiency of aggregated information in subjective contexts.

### Open Question 2
- Question: What is the impact of different web search APIs and scraping tools on the performance of INFOGENT under Direct API-Driven Access, and how can the framework be optimized for various web data sources?
- Basis in paper: Explicit
- Why unresolved: The paper uses Google Search API and automated scraping tools but does not explore the impact of different web data sources or compare the performance with alternative APIs and tools.
- What evidence would resolve it: Comparative experiments using different web search APIs and scraping tools, measuring the performance of INFOGENT in terms of accuracy, coverage, and efficiency across various data sources.

### Open Question 3
- Question: How can the feedback mechanism between the Aggregator and Navigator in INFOGENT be improved to provide more specific and actionable guidance, reducing the instances where the Aggregator provides open-ended feedback or omits relevant information?
- Basis in paper: Inferred
- Why unresolved: The paper identifies that the Aggregator often provides open-ended feedback, complicating further navigation, and in some cases gives incorrect feedback or omits relevant information from memory.
- What evidence would resolve it: Analysis of the current feedback mechanism's effectiveness, followed by the development and evaluation of enhanced feedback strategies, such as structured feedback templates or context-aware feedback generation, to improve the quality and specificity of guidance provided to the Navigator.

## Limitations

- The framework's performance significantly drops when using cost-efficient models like GPT-4o-mini instead of GPT-4o, though the paper doesn't investigate which component is most sensitive to model capability changes
- The feedback mechanism between Aggregator and Navigator lacks detailed specification, making it difficult to reproduce the exact implementation
- The evaluation focuses on task completion metrics without addressing potential privacy concerns or the framework's robustness to website structure changes

## Confidence

- **High confidence**: The modular architecture design and its separation of concerns (Navigator, Extractor, Aggregator) is well-supported by the paper's description and experimental results
- **Medium confidence**: The claim that INFOGENT improves over baselines by 7% on FRAMES and 4.3% on AssistantBench, as these results depend on specific implementation details not fully disclosed
- **Low confidence**: The assertion that supporting both Direct API-driven and Interactive Visual Access significantly enhances the framework's ability to handle diverse information sources, as the paper does not provide comparative analysis of performance gaps between these access methods

## Next Checks

1. Conduct ablation studies to determine which component (Navigator, Extractor, or Aggregator) is most dependent on the underlying model's capabilities by systematically replacing GPT-4o with GPT-4o-mini for each component separately
2. Test the framework's robustness by evaluating performance on websites with frequently changing structures or those implementing anti-bot measures to assess real-world applicability
3. Implement and compare alternative feedback mechanisms between the Aggregator and Navigator to determine if the current approach is optimal or if simpler methods could achieve similar performance