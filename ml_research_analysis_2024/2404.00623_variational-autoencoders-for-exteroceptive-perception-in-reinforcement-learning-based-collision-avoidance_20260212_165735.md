---
ver: rpa2
title: Variational Autoencoders for exteroceptive perception in reinforcement learning-based
  collision avoidance
arxiv_id: '2404.00623'
source_url: https://arxiv.org/abs/2404.00623
tags:
- agent
- path
- learning
- collision
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the use of Variational Autoencoders (VAEs)
  to improve Deep Reinforcement Learning (DRL) performance for autonomous marine vessel
  collision avoidance. VAEs are used to learn low-dimensional latent representations
  of high-fidelity LiDAR range sensor data, which is then fed into a DRL agent for
  path-following and collision avoidance.
---

# Variational Autoencoders for exteroceptive perception in reinforcement learning-based collision avoidance

## Quick Facts
- arXiv ID: 2404.00623
- Source URL: https://arxiv.org/abs/2404.00623
- Reference count: 29
- Primary result: VAE-based feature extraction improves DRL path-following performance for marine vessels but shows a slight increase in collision rate

## Executive Summary
This paper explores using Variational Autoencoders (VAEs) to extract low-dimensional latent representations from high-fidelity LiDAR sensor data for Deep Reinforcement Learning (DRL) in autonomous marine vessel collision avoidance. The authors compare shallow and deep VAE architectures with locked and unlocked encoder parameters against a baseline DRL agent. Results show that VAE-based feature extraction significantly improves path adherence and efficiency compared to the baseline, with the shallow VAE architecture with locked parameters performing best. However, a slight increase in collision rate was observed, indicating a potential trade-off between efficiency and safety that warrants further investigation.

## Method Summary
The method involves pre-training a VAE on LiDAR range data to learn a 12-dimensional latent representation, which is then used as input to a DRL agent trained with Proximal Policy Optimization (PPO). The approach includes a circular padding technique (CPTC-1D) to handle the cyclical nature of LiDAR data. The study compares shallow and deep VAE architectures with locked (frozen) and unlocked encoder parameters during DRL training, evaluating performance on synthetic marine navigation scenarios with static and dynamic obstacles.

## Key Results
- VAE-based feature extraction significantly improves path adherence and reduces navigation duration compared to baseline CNN agent
- Shallow VAE with locked parameters performs best, suggesting simpler models may be preferable for this task
- A slight increase in collision rate was observed with VAE-based approaches, indicating a potential efficiency-safety trade-off

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VAE-based feature extraction reduces input dimensionality, enabling faster and more effective DRL policy learning.
- Mechanism: LiDAR range data (180-dimensional) is encoded into a 12-dimensional latent vector, preserving salient environmental features while removing redundancy.
- Core assumption: The VAE captures sufficient information about obstacle positions and distances in the latent space for the DRL agent to make safe decisions.
- Evidence anchors:
  - [abstract]: "acquire a generalized, low-dimensional latent encoding of a high-fidelity range-finding sensor"
  - [section]: "the agent should be provided with a low-dimensional representation of its environment to increase the probability of the DRL algorithm finding a good policy"

### Mechanism 2
- Claim: Locked VAE encoder parameters prevent retraining instability and allow the DRL agent to focus on policy learning.
- Mechanism: After pre-training, the VAE encoder weights are fixed during PPO training, reducing the searchable parameter space.
- Core assumption: The pre-trained VAE encoder produces useful, stable features that do not require further adaptation for the downstream DRL task.
- Evidence anchors:
  - [section]: "locking the feature extractor's parameters substantially reduces the searchable parameter space... allow the agent to more effectively explore a larger portion of the parameter space"
  - [section]: "unlocking the (pre-trained) parameters... does not confer a significant advantage in the given context"

### Mechanism 3
- Claim: Circular padding in the VAE decoder preserves the cyclical nature of LiDAR sensor data.
- Mechanism: CPTC-1D ensures that the first and last elements of the reconstructed perception vector remain adjacent, avoiding edge artifacts.
- Core assumption: LiDAR measurements wrap around continuously; treating them as linear leads to discontinuities that harm reconstruction quality.
- Evidence anchors:
  - [section]: "the adoption of circular padding in both the encoder and decoder of the VAE addresses the inherent circularity of the perception vector"
  - [section]: "Applying the circular padding method significantly reduces these artifacts"

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) and the Evidence Lower Bound (ELBO)
  - Why needed here: Understanding how VAEs balance reconstruction accuracy with latent space regularization is critical for tuning the β parameter and preventing posterior collapse.
  - Quick check question: What happens to the latent space when β → 0 versus β → ∞?

- Concept: Reinforcement Learning with Proximal Policy Optimization (PPO)
  - Why needed here: PPO hyperparameters and reward shaping directly affect the agent's ability to learn safe and efficient navigation policies.
  - Quick check question: How does the clipping parameter in PPO help stabilize training?

- Concept: Maritime vessel dynamics and guidance features
  - Why needed here: The DRL agent's observation space includes vessel state (speed, heading error, cross-track error) and LiDAR perception, which must be correctly interpreted for effective control.
  - Quick check question: How does the look-ahead heading error influence the vessel's path-following behavior?

## Architecture Onboarding

- Component map:
  - LiDAR sensor suite → VAE encoder (pre-trained) → Latent vector + navigation features → PPO agent → Action (thrust, yaw)
  - Environment: stochastic simulation with static/dynamic obstacles and curved paths

- Critical path:
  1. Generate and preprocess LiDAR data
  2. Train VAE to learn latent representations
  3. Freeze VAE encoder, integrate into DRL pipeline
  4. Train PPO agent using learned features
  5. Evaluate performance (path progress, CTE, collision rate, duration)

- Design tradeoffs:
  - Shallow vs. deep VAE: shallow models are faster to train and often perform better for this task, but may lack capacity for very complex scenes.
  - Locked vs. unlocked encoder: locking stabilizes training but may limit adaptation; unlocking risks destabilizing feature extraction.
  - Latent dimension size: too small loses information, too large adds computational cost without benefit.

- Failure signatures:
  - High training loss but poor test performance: overfitting or poor generalization
  - Sudden increase in collision rate: latent features missing critical obstacle information
  - Posterior collapse: latent distributions collapse to the prior (all observations map to same point)

- First 3 experiments:
  1. Train a shallow VAE on LiDAR data, inspect reconstructions with and without CPTC-1D
  2. Integrate pre-trained shallow VAE encoder (locked) into DRL pipeline, compare against baseline
  3. Vary β in VAE pre-training, measure effect on DRL agent's path adherence and collision rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the increased collision rate observed with the shallow VAE model stem from inherent limitations in the VAE architecture or from the specific training configuration (e.g., locked parameters)?
- Basis in paper: [explicit] The authors note that the shallow VAE model exhibits slightly worse collision avoidance capabilities than the baseline, suggesting a potential trade-off between efficiency and safety.
- Why unresolved: The paper does not definitively attribute the increased collision rate to either the VAE architecture itself or the training configuration (locked parameters). Further experimentation is needed to isolate the cause.
- What evidence would resolve it: A controlled experiment comparing unlocked shallow VAE models against locked shallow VAE models and baseline models would clarify whether the increased collision rate is due to the architecture or the locked parameters.

### Open Question 2
- Question: How does the performance of the VAE-based feature extractor vary with different sizes of the latent space (i.e., different numbers of latent variables)?
- Basis in paper: [explicit] The authors mention that they tested latent space sizes of 1, 2, 6, 12, and 24, finding that matching the output size from the last convolutional layer yielded the best results. However, they do not provide detailed performance comparisons across these different sizes.
- Why unresolved: The paper only briefly mentions the different latent space sizes tested and does not provide a comprehensive analysis of their impact on performance.
- What evidence would resolve it: A systematic evaluation of the VAE-based feature extractor's performance across different latent space sizes would reveal the optimal size for balancing information content and computational efficiency.

### Open Question 3
- Question: How does the VAE-based feature extractor generalize to different types of sensor data, such as radar or sonar, beyond LiDAR?
- Basis in paper: [inferred] The paper focuses specifically on LiDAR data and does not explore the generalizability of the VAE-based feature extractor to other sensor modalities.
- Why unresolved: The paper does not investigate the performance of the VAE-based feature extractor with sensor data other than LiDAR, leaving open the question of its adaptability to different sensing technologies.
- What evidence would resolve it: Training and evaluating the VAE-based feature extractor on radar or sonar data and comparing its performance to the LiDAR-based results would demonstrate its generalizability across sensor modalities.

## Limitations
- The study is limited to simulation-based evaluation, with no validation on real vessels or sensor data
- The slight increase in collision rate raises concerns about safety that are not fully addressed
- The approach is specific to LiDAR data and may not generalize to other sensor modalities

## Confidence

**High Confidence**: The claim that VAE-based feature extraction improves DRL performance compared to raw CNN inputs is well-supported by the experimental results across multiple metrics (path progress, CTE, duration).

**Medium Confidence**: The assertion that circular padding (CPTC-1D) significantly improves reconstruction quality at sensor boundaries is supported by qualitative descriptions but lacks quantitative evidence.

**Low Confidence**: The claim that the slight increase in collision rate is an acceptable trade-off for improved efficiency lacks justification without understanding which safety-critical features may be lost in compression.

## Next Checks

1. **Latent Space Interpretability Analysis**: Conduct a feature importance analysis to identify which aspects of the LiDAR data are preserved or lost in the 12-dimensional latent space. Correlate latent dimensions with safety-critical features (obstacle proximity, angular distribution) to explain the collision rate increase.

2. **Real-World Transfer Validation**: Test the VAE-DRL pipeline on real vessel sensor data and in physical maritime environments to assess simulation-to-reality transfer. Compare performance degradation between VAE-based and baseline approaches when moving from simulation to reality.

3. **Robustness to Sensor Noise and Failure**: Systematically inject noise and simulate sensor failures (e.g., missing sectors, range errors) into the LiDAR input to evaluate how the VAE-based feature extraction affects the DRL agent's robustness compared to the baseline approach.