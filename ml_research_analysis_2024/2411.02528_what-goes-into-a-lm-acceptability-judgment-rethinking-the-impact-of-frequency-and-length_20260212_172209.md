---
ver: rpa2
title: What Goes Into a LM Acceptability Judgment? Rethinking the Impact of Frequency
  and Length
arxiv_id: '2411.02528'
source_url: https://arxiv.org/abs/2411.02528
tags:
- morcela
- judgments
- unigram
- slor
- acceptability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes MORCELA, a parameterized linking theory for
  mapping language model probabilities to human acceptability judgments. Unlike SLOR,
  which applies fixed corrections for length and unigram frequency, MORCELA learns
  optimal adjustment parameters from data.
---

# What Goes Into a LM Acceptability Judgment? Rethinking the Impact of Frequency and Length

## Quick Facts
- arXiv ID: 2411.02528
- Source URL: https://arxiv.org/abs/2411.02528
- Reference count: 39
- Key outcome: MORCELA linking function significantly outperforms SLOR baseline, with up to +0.17 correlation improvement across Pythia and OPT transformer models.

## Executive Summary
This paper addresses how to map language model probabilities to human acceptability judgments by proposing MORCELA, a parameterized linking theory that learns optimal adjustment parameters for length and unigram frequency effects. Unlike SLOR which applies fixed corrections, MORCELA learns these parameters from data, demonstrating significant performance improvements across multiple transformer models. The work reveals that larger language models are less susceptible to frequency effects because they better predict rare words in context, suggesting LMs may be more human-like in their acceptability judgments than previously estimated.

## Method Summary
The method compares two linking functions for mapping LM probabilities to human acceptability judgments: MORCELA (parameterized with learned β and γ) versus SLOR (with fixed parameters). Using the Sprouse et al. (2013) acceptability judgment dataset of 1450 sentences with z-normalized ratings, the authors evaluate Pythia (70M-12B parameters) and OPT (125M-30B parameters) models. MORCELA learns optimal adjustment parameters through regression while SLOR applies predetermined corrections. The study includes ablation analysis by optimizing either β or γ alone, and investigates frequency effects by correlating conditional log likelihood with unigram frequencies in training corpora.

## Key Results
- MORCELA achieves up to +0.17 correlation improvement over SLOR across all model sizes
- Larger models require less frequency adjustment (β decreases with model size) but still benefit from MORCELA
- SLOR overcorrects for frequency and length effects, leading to underestimation of LM-human correlation
- Better prediction of rare words in context explains larger models' reduced frequency susceptibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MORCELA learns optimal adjustment parameters for length and unigram frequency effects from data, rather than assuming fixed values as in SLOR.
- Mechanism: By parameterizing the adjustment coefficients β and γ in the linking function, MORCELA can learn the optimal relative importance of unigram frequency and the length-normalized intercept from human acceptability judgment data. This allows the model to automatically discover the appropriate degree of correction needed for each factor.
- Core assumption: The relationship between LM probabilities and acceptability is approximately log-linear, and the effects of length and frequency can be captured by linear adjustments to this relationship.
- Evidence anchors:
  - [abstract] "MORCELA learns optimal adjustment parameters from data via learned parameters for length and unigram frequency"
  - [section 2] "MORCELA relaxes these assumptions by allowing for arbitrary linear relationships between LM probabilities and unigram frequencies"
  - [corpus] Weak evidence - the corpus neighbors don't directly address MORCELA's mechanism, but they do discuss acceptability judgments and LM evaluations, suggesting the broader context is relevant.
- Break condition: If the log-linear relationship between LM probabilities and acceptability breaks down for certain types of sentences or for certain model architectures, MORCELA's learned parameters may not generalize well.

### Mechanism 2
- Claim: Larger LMs are more robust to unigram frequency effects because they are better at predicting rarer words in context.
- Mechanism: As LMs scale up, they develop better contextual representations that allow them to assign higher probabilities to rare words when given appropriate context. This reduces their dependence on unigram frequency as a predictor of acceptability.
- Core assumption: The ability to predict rare words in context is a key differentiator between larger and smaller LMs, and this ability directly impacts their susceptibility to frequency effects.
- Evidence anchors:
  - [abstract] "larger models require a lower relative degree of adjustment for unigram frequency, though a significant amount of adjustment is still necessary for all models"
  - [section 5] "larger LMs' lower susceptibility to frequency effects can be explained by an ability to better predict rarer words in context"
  - [corpus] Weak evidence - the corpus doesn't directly address this mechanism, but it does show that related work on acceptability judgments exists.
- Break condition: If rare words in context are not actually better predicted by larger LMs, or if other factors become more important as models scale, this mechanism may not hold.

### Mechanism 3
- Claim: SLOR overcorrects for length and frequency effects, leading to underestimation of LM-human correlation.
- Mechanism: By assuming equal weighting of LM probabilities and unigram frequencies (β=1) and no length-normalized intercept (γ=0), SLOR applies corrections that are too strong. MORCELA's learned parameters reveal that smaller adjustments are actually optimal.
- Core assumption: The assumed corrections in SLOR are based on incorrect estimates of the true impact of length and frequency on LM probabilities.
- Evidence anchors:
  - [abstract] "we demonstrate that the assumed degrees of adjustment in SLOR for length and unigram frequency overcorrect for these confounds"
  - [section 4.3] "the assumed impact of unigram frequency as used in SLOR is an overestimate"
  - [corpus] Weak evidence - the corpus doesn't directly address SLOR's assumptions, but it does suggest that related work on acceptability judgments and LM evaluations exists.
- Break condition: If the true impact of length and frequency on LM probabilities is actually closer to SLOR's assumptions than MORCELA's learned parameters suggest, then SLOR may not be overcorrecting.

## Foundational Learning

- Concept: Linking functions between LM probabilities and human acceptability judgments
  - Why needed here: To relate the continuous probability outputs of LMs to the discrete or continuous acceptability judgments provided by humans, we need a transformation that accounts for systematic differences between these measures.
  - Quick check question: What are the key assumptions made by SLOR about how length and frequency affect LM probabilities, and how does MORCELA relax these assumptions?

- Concept: Parameterized regression models
  - Why needed here: MORCELA uses a linear regression framework to learn the optimal values of β and γ from data. Understanding how to fit and evaluate such models is crucial for implementing MORCELA.
  - Quick check question: How are the optimal values of β and γ determined in MORCELA, and what criteria are used to evaluate the quality of the resulting linking function?

- Concept: Frequency effects in language models
  - Why needed here: The core contribution of this work is showing that larger LMs are less susceptible to frequency effects. Understanding what frequency effects are and how they manifest in LMs is key to grasping the significance of this finding.
  - Quick check question: Why do unigram frequency effects impact LM probabilities, and why might larger LMs be more robust to these effects?

## Architecture Onboarding

- Component map: LM (Pythia/OPT) -> unigram frequency estimator -> linking function (MORCELA/SLOR) -> human acceptability judgments
- Critical path: 1) Compute LM probabilities for each sentence, 2) Compute unigram probabilities, 3) Apply linking function to get acceptability scores, 4) Correlate with human judgments, 5) If using MORCELA, learn optimal β and γ via regression.
- Design tradeoffs: MORCELA adds two parameters compared to SLOR, which increases model complexity but allows for data-driven optimization. The unigrahams estimator trades off accuracy for the ability to estimate unigram frequencies without access to the training corpus.
- Failure signatures: Poor correlation with human judgments, learned β or γ values that are very different from expected, or failure of the unigrahams estimator to converge.
- First 3 experiments:
  1. Compare raw LM probabilities to human judgments to establish a baseline correlation.
  2. Implement and evaluate SLOR on the same data to confirm it overcorrects for frequency and length effects.
  3. Implement MORCELA and show it achieves higher correlation with human judgments than SLOR across all model sizes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact functional form of the relationship between LM probabilities and human acceptability judgments beyond the log-linear assumption?
- Basis in paper: [inferred] Meister et al. (2021) found evidence for a super-logarithmic relationship between LM probabilities and reading times, as well as binary acceptability judgments, suggesting the current log-linear assumption in MORCELA may be insufficient.
- Why unresolved: The paper only compares MORCELA (log-linear) to SLOR (also log-linear with fixed parameters), without exploring alternative functional forms that might better capture the relationship.
- What evidence would resolve it: Systematic comparison of different functional forms (e.g., super-logarithmic, polynomial, neural network mappings) using the same datasets to identify which best captures the LM-to-human acceptability relationship.

### Open Question 2
- Question: How do MORCELA's findings generalize to non-English languages and multilingual settings?
- Basis in paper: [explicit] The authors explicitly note that their evaluations are limited to two model families trained on predominantly English data and judgments of English sentences by English speakers.
- Why unresolved: The paper provides no cross-linguistic validation, leaving open whether the relationship between frequency effects, length normalization, and acceptability judgments is universal or language-specific.
- What evidence would resolve it: Replicating MORCELA experiments with models and acceptability judgment datasets from multiple languages to determine if the optimal parameter trends (β decreasing, γ increasing with model size) hold cross-linguistically.

### Open Question 3
- Question: What is the mechanism behind the apparent paradox where larger models show better acceptability judgment correlation but poorer reading time prediction?
- Basis in paper: [explicit] The authors hypothesize this may relate to the different roles of predictability in offline (acceptability) versus online (reading time) language processing, with frequency effects being more important for humans in reading times.
- Why unresolved: The paper only provides a hypothesis without testing it through controlled experiments that isolate the frequency and predictability components in both tasks.
- What evidence would resolve it: Controlled experiments manipulating word frequency and predictability independently in both acceptability and reading time prediction tasks to determine whether the same models show divergent performance patterns and why.

## Limitations

- The log-linear linking function may not capture all aspects of the relationship between LM probabilities and acceptability
- Unigram frequency estimates for OPT models depend on generated text samples that may not perfectly represent training corpus distributions
- Results only examine two model families (Pythia and OPT), limiting generalizability to other architectures

## Confidence

**High Confidence**: The claim that MORCELA outperforms SLOR across multiple model sizes is well-supported by the experimental results. The correlation improvements are consistent and statistically significant.

**Medium Confidence**: The explanation for why larger models require less frequency adjustment (better prediction of rare words in context) is plausible but requires further validation.

**Low Confidence**: The claim that SLOR "overcorrects" for length and frequency effects is based on the assumption that MORCELA's learned parameters represent the optimal adjustment.

## Next Checks

1. **Generalization Test**: Evaluate MORCELA on additional model families (e.g., GPT, BERT, LLaMA) to determine if the learned adjustment patterns hold across different architectures and training approaches.

2. **Alternative Linking Functions**: Test non-linear linking functions (e.g., polynomial, neural network) to determine if the log-linear assumption is appropriate or if more complex relationships better capture acceptability judgments.

3. **Error Analysis**: Conduct detailed error analysis on sentences where MORCELA performs poorly compared to SLOR (or vice versa) to identify systematic patterns and potential limitations of the current approach.