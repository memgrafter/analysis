---
ver: rpa2
title: 'Executing Natural Language-Described Algorithms with Large Language Models:
  An Investigation'
arxiv_id: '2403.00795'
source_url: https://arxiv.org/abs/2403.00795
tags:
- step
- increment
- last
- prev
- color
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) can
  execute natural language-described algorithms. The authors construct an algorithm
  test set from the widely-used textbook "Introduction to Algorithm" and design detailed
  natural language prompts for 30 algorithms.
---

# Executing Natural Language-Described Algorithms with Large Language Models: An Investigation

## Quick Facts
- arXiv ID: 2403.00795
- Source URL: https://arxiv.org/abs/2403.00795
- Authors: Xin Zheng; Qiming Zhu; Hongyu Lin; Yaojie Lu; Xianpei Han; Le Sun
- Reference count: 40
- One-line primary result: GPT-4 achieves perfect accuracy executing natural language-described algorithms, while GPT-3.5 models struggle with complex tasks.

## Executive Summary
This paper investigates whether large language models can execute algorithms described in natural language. The authors construct a test set from the "Introduction to Algorithms" textbook and evaluate three LLMs (GPT-3.5-Turbo, GPT-3.5, GPT-4) on 30 algorithms with 300 instances. GPT-4 demonstrates perfect accuracy across all tasks, successfully following control flow, performing precise calculations, and maintaining variable values. In contrast, the GPT-3.5 models show significant performance degradation on complex algorithms, particularly those involving graph algorithms and heavy numeric computation. The results indicate that GPT-4 can effectively interpret and execute natural language-described algorithms, mimicking core functions of the Von Neumann Machine.

## Method Summary
The authors construct an algorithm test set from the widely-used "Introduction to Algorithms" textbook, selecting 30 algorithms and generating 300 random instances. They design detailed natural language prompts for each algorithm, specifying input data, intermediate steps, and expected outputs. The prompts follow a structured format with sections for algorithm description, input, steps, and output. The evaluation is conducted using OpenAI's API with temperature=0 for deterministic outputs. Three LLMs are tested: GPT-3.5-Turbo, GPT-3.5, and GPT-4, with accuracy measured as the percentage of correctly executed algorithms.

## Key Results
- GPT-4 achieves perfect accuracy (100%) across all 30 algorithms and 300 instances tested
- GPT-3.5 models show significant performance degradation on complex algorithms, particularly graph algorithms and numeric-heavy computations
- Natural language prompts outperform Python code-only prompts, with GPT-4's accuracy declining substantially when using Python code-only format
- The models demonstrate ability to follow control flow, perform precise calculations, and maintain variable values through text output

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: GPT-4 can execute natural language-described algorithms because it successfully follows control flow, performs precise calculations, and maintains variable values across text output.
- **Mechanism**: The model interprets natural language prompts as executable instructions by parsing step-by-step commands, maintaining internal state through text generation, and applying logical operations sequentially.
- **Core assumption**: Natural language prompts can be structured with sufficient precision to eliminate ambiguity and guide deterministic execution.
- **Evidence anchors**:
  - [abstract]: "GPT-4 achieves perfect accuracy across all tasks, demonstrating its exceptional ability to follow control flow, perform precise calculations, and maintain variable values."
  - [section]: "They can accurately follow the control flow of the algorithm as per the prompt description, precisely execute each step, and perform the calculation."
- **Break condition**: If natural language prompts contain ambiguous references, missing context, or require heavy numeric computation beyond the model's generation capacity.

### Mechanism 2
- **Claim**: GPT-4 mimics the core functions of the Von Neumann Machine through natural language interpretation.
- **Mechanism**: The model simulates calculation (arithmetic operations), flow control (if/else, loops via goto statements), variable storage (maintaining state across generated text), and input-output understanding (parsing problem instances and producing results).
- **Core assumption**: The model's transformer architecture can maintain sufficient context to simulate sequential computation steps.
- **Evidence anchors**:
  - [abstract]: "mimic the core functions of the Von Neumann Machine, including calculation, flow control, variable storage, and input-output understanding."
  - [section]: "These models demonstrated astonishing performance in following control flow and performing precise calculations and operations. They also exhibited strong capabilities in maintaining and updating variable values via text output."
- **Break condition**: When context length limits prevent tracking state across many sequential steps, or when complex state dependencies exceed the model's ability to maintain coherence.

### Mechanism 3
- **Claim**: Natural language prompting is more effective than Python code prompting for algorithm execution.
- **Mechanism**: Natural language prompts with detailed step-by-step instructions trigger the model's reasoning process more reliably than uninterpreted Python code, which requires additional parsing.
- **Core assumption**: The model's instruction-following capability is better activated through natural language than through formal programming syntax.
- **Evidence anchors**:
  - [abstract]: "under Python Code only, the average performance of all three models declines."
  - [section]: "Compared with detailed instruction, under Python Code only, the average performance of all three models declines. Especially for GPT-4, only in relatively simple algorithms the model can get good accuracy, but as the complexity increases, the results drop."
- **Break condition**: If the model develops better code interpretation capabilities through training or fine-tuning specifically for formal language execution.

## Foundational Learning

- **Concept**: Control flow structures (sequence, selection, iteration)
  - Why needed here: Algorithms fundamentally rely on these structures, and the model must interpret and execute them correctly
  - Quick check question: Can you explain how a "for loop" in natural language would be interpreted by the model?

- **Concept**: State maintenance across sequential text generation
  - Why needed here: The model must track variable values and intermediate results through multiple generated steps
  - Quick check question: How does the model maintain the value of variable 'i' when generating step-by-step algorithm execution?

- **Concept**: Natural language instruction parsing and execution
  - Why needed here: The model must convert natural language commands into computational actions without additional parsing layers
  - Quick check question: What makes a natural language instruction unambiguous enough for the model to execute correctly?

## Architecture Onboarding

- **Component map**: Natural language prompt -> GPT-4 interpretation -> Step-by-step execution -> Text output generation
- **Critical path**: Prompt design -> Model interpretation -> Sequential step execution -> Result verification
- **Design tradeoffs**: Natural language prompts offer flexibility but require precision; Python code offers structure but may reduce execution reliability
- **Failure signatures**: Incomplete state tracking, incorrect intermediate calculations, premature termination of execution
- **First 3 experiments**:
  1. Test simple algorithm (e.g., binary search) with natural language prompt vs Python code prompt
  2. Vary problem size to test context length limits on complex algorithms
  3. Introduce numeric-heavy computation to identify model limitations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can GPT-4 accurately perform floating-point arithmetic operations with sufficient precision to execute complex numerical algorithms without external tools?
- Basis in paper: [explicit] The paper states that GPT-4 fails on CLRS-Numeric algorithms due to "miscalculation" and "inability to conduct the actual computation within the generation of a few tokens."
- Why unresolved: The paper doesn't test GPT-4 with external Python interpreter integration or evaluate its ability to break down complex calculations into smaller, verifiable steps.
- What evidence would resolve it: Experiments testing GPT-4 with Python interpreter integration for CLRS-Numeric algorithms, or tests showing GPT-4 can accurately perform multi-step floating-point calculations without external tools.

### Open Question 2
- Question: How does the performance of open-source LLMs compare to GPT-4 on natural language program execution tasks?
- Basis in paper: [inferred] The paper only tests GPT-3.5 and GPT-4, noting they are "not open-sourced and may only be accessed via API."
- Why unresolved: The study doesn't evaluate any open-source models like LLaMA, BLOOM, or others that might approach GPT-4's capabilities.
- What evidence would resolve it: Benchmarking popular open-source LLMs (Llama-2, Mistral, etc.) on the same CLRS algorithm test set used in the paper.

### Open Question 3
- Question: What is the maximum problem size at which GPT-4 can reliably execute algorithms described in natural language without exceeding context length limits?
- Basis in paper: [explicit] The paper adjusts problem sizes based on "context-length limit, generation time, and inference cost," but doesn't systematically explore this boundary.
- Why unresolved: The study uses fixed problem sizes (4-10) but doesn't investigate how GPT-4's accuracy degrades as problem complexity increases.
- What evidence would resolve it: Systematic scaling experiments increasing problem sizes for various algorithm types until GPT-4's accuracy drops below a threshold (e.g., 90%).

## Limitations
- Results based on a specific set of 30 algorithms from one textbook, limiting generalizability
- Does not address error recovery or handling of invalid inputs for real-world deployment
- Perfect accuracy claims for GPT-4 may not hold under different prompt engineering approaches or more complex scenarios

## Confidence

**High Confidence**: The observation that GPT-4 outperforms GPT-3.5 models significantly on algorithm execution tasks is well-supported by the experimental results. The systematic comparison across 30 algorithms provides robust evidence for this claim.

**Medium Confidence**: The claim that natural language prompts are more effective than Python code prompts requires additional validation. While the paper shows lower accuracy with Python-only prompts, the comparison could be influenced by prompt engineering quality rather than inherent model capabilities.

**Medium Confidence**: The mechanism explaining how GPT-4 mimics Von Neumann Machine functions is plausible but not definitively proven. The evidence shows the model can maintain state and execute steps, but the internal processes remain opaque.

## Next Checks
1. **Context Length Testing**: Systematically vary problem sizes and track when performance degrades to identify the model's context window limitations for algorithm execution.

2. **Cross-Domain Generalization**: Test the same prompting approach on algorithms from different domains (not just the "Introduction to Algorithms" textbook) to validate generalizability.

3. **Error Analysis**: Conduct detailed error analysis on GPT-4's incorrect responses to understand whether failures stem from reasoning errors, context tracking issues, or prompt interpretation problems.