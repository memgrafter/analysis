---
ver: rpa2
title: Training-Free Mitigation of Language Reasoning Degradation After Multimodal
  Instruction Tuning
arxiv_id: '2412.03467'
source_url: https://arxiv.org/abs/2412.03467
tags:
- language
- reasoning
- visual
- tasks
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether multimodal instruction tuning affects
  language reasoning capabilities in large multimodal models (MLLMs). The authors
  focus on LLaVA variants built on Vicuna and Mistral LLMs and evaluate them across
  eight language reasoning tasks.
---

# Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning

## Quick Facts
- **arXiv ID**: 2412.03467
- **Source URL**: https://arxiv.org/abs/2412.03467
- **Reference count**: 12
- **Primary result**: Model merging with small weight (0.05) recovers language reasoning performance in multimodal models

## Executive Summary
This paper investigates the impact of multimodal instruction tuning on language reasoning capabilities in large multimodal models (MLLMs), focusing on LLaVA variants built on Vicuna and Mistral LLMs. The authors find that multimodal instruction tuning causes inconsistent effects across base models - while Vicuna-based models maintain or improve performance, Mistral-based models experience significant degradation, particularly on mathematical reasoning tasks like GSM8K. Interestingly, all MLLMs show improved performance on commonsense reasoning tasks, suggesting that visual instruction tuning enhances certain knowledge applicable to text-only tasks.

To address language reasoning degradation, the authors propose a training-free model merging technique using task vectors from the base LLM to recover degraded language performance in Mistral-based MLLMs. Experiments demonstrate that a small merging weight (0.05) effectively recovers most language reasoning performance while even improving visual reasoning task results, making this a simple and effective mitigation strategy that avoids additional training costs.

## Method Summary
The authors evaluate LLaVA variants built on Vicuna and Mistral LLMs across eight language reasoning tasks to assess the impact of multimodal instruction tuning. They observe performance degradation in Mistral-based models, particularly on mathematical reasoning tasks, while Vicuna-based models remain stable or improve. To mitigate this degradation, they propose a training-free model merging approach that combines the tuned MLLM with its base LLM using task vectors. The merging process involves computing weighted averages of model parameters, where the weight parameter controls the contribution from the base LLM. Through systematic experimentation, they identify that a merging weight of 0.05 effectively recovers language reasoning performance while maintaining or improving visual reasoning capabilities.

## Key Results
- Multimodal instruction tuning causes inconsistent effects: Vicuna-based models maintain or improve, while Mistral-based models degrade significantly on mathematical reasoning
- All MLLMs show improved performance on commonsense reasoning tasks like CommonsenseQA after visual instruction tuning
- A small merging weight (0.05) effectively recovers language reasoning performance in Mistral-based MLLMs while improving visual reasoning tasks
- The training-free model merging approach provides a simple and effective mitigation strategy without additional training costs

## Why This Works (Mechanism)
The effectiveness of the model merging approach stems from leveraging the preserved language reasoning capabilities of the base LLM while maintaining the visual reasoning improvements gained through multimodal instruction tuning. When multimodal instruction tuning degrades certain capabilities, the base model's parameters contain the original, uncorrupted knowledge. By carefully combining these with the tuned model using task vectors, the method selectively recovers degraded language reasoning without losing visual improvements. The small merging weight (0.05) indicates that only a minimal contribution from the base model is needed to restore performance, suggesting that the degradation is relatively minor and localized rather than fundamental.

## Foundational Learning
- **Multimodal instruction tuning**: Process of fine-tuning language models on multimodal datasets combining text and images with instructions; needed to understand how visual training affects language-only reasoning; quick check: examine instruction datasets and tuning objectives
- **Model merging techniques**: Methods for combining parameters from different model versions to transfer capabilities; needed to understand the proposed mitigation strategy; quick check: verify parameter averaging and task vector usage
- **Task vectors**: Representations that capture specific capabilities or knowledge in model parameters; needed to understand how merging targets specific degraded capabilities; quick check: analyze how task vectors are computed and applied
- **Language reasoning tasks**: Evaluations that test logical deduction, mathematical problem-solving, and commonsense reasoning using only text; needed to benchmark performance degradation and recovery; quick check: review task datasets and evaluation metrics
- **GSM8K**: Grade School Math 8K dataset for mathematical reasoning; needed as a key benchmark showing degradation in Mistral-based models; quick check: examine problem types and solution patterns
- **CommonsenseQA**: Dataset testing commonsense knowledge and reasoning; needed to demonstrate that visual tuning can improve certain text tasks; quick check: analyze knowledge domains covered

## Architecture Onboarding

**Component map**: Base LLM -> Multimodal instruction tuning -> MLLM -> Model merging with task vectors -> Recovered MLLM

**Critical path**: Language reasoning evaluation → Identify degradation → Task vector extraction from base model → Parameter merging with weight 0.05 → Re-evaluation of language and visual tasks

**Design tradeoffs**: The approach trades minimal parameter modification (small merging weight) for performance recovery, avoiding full retraining. This prioritizes efficiency over potentially better but more expensive retraining solutions. The use of task vectors enables selective capability recovery but requires understanding of how different model components contribute to specific tasks.

**Failure signatures**: Language reasoning degradation manifests as incorrect mathematical solutions and logical errors in text-only tasks, while visual reasoning remains intact or improves. The degradation is asymmetric across base models (Vicuna vs Mistral), suggesting architecture-dependent vulnerabilities to multimodal fine-tuning.

**3 first experiments**:
1. Evaluate GSM8K performance on Mistral-based MLLM to confirm mathematical reasoning degradation
2. Apply model merging with weight 0.05 and re-evaluate GSM8K to verify recovery
3. Test CommonsenseQA performance before and after merging to ensure visual reasoning improvements are preserved

## Open Questions the Paper Calls Out
None

## Limitations
- Investigation limited to only two base LLM architectures (Vicuna and Mistral), leaving uncertainty about generalization to other models
- Model merging approach relies on a single merging weight (0.05) without exploring sensitivity to different values
- Evaluation focuses primarily on performance metrics without qualitative analysis of reasoning failure modes
- Does not explore whether degradation stems from knowledge loss, reasoning process disruption, or other mechanisms

## Confidence
- **High**: Language reasoning degradation after multimodal instruction tuning, improved commonsense reasoning in all MLLMs, effectiveness of 0.05 merging weight
- **Medium**: Generalizability of model merging approach across different architectures and tasks

## Next Checks
1. Test model merging approach across a broader range of base LLMs including Llama and GPT variants to assess generalizability
2. Conduct systematic ablation studies varying the merging weight parameter to identify optimal values and sensitivity
3. Perform qualitative error analysis on degraded reasoning tasks to understand whether failures stem from knowledge loss, reasoning process disruption, or other factors