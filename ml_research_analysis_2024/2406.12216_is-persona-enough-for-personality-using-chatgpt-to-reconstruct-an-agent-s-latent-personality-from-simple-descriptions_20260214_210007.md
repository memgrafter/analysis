---
ver: rpa2
title: Is persona enough for personality? Using ChatGPT to reconstruct an agent's
  latent personality from simple descriptions
arxiv_id: '2406.12216'
source_url: https://arxiv.org/abs/2406.12216
tags:
- personality
- dimensions
- reconstructed
- descriptions
- high
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines whether large language models (LLMs) like GPT-3.5
  and GPT-4 can accurately reconstruct human personality traits from simple persona
  descriptions using the HEXACO framework. The models were tested with 1000 and 100
  persona descriptions respectively, each containing socio-demographic and personality
  type information.
---

# Is persona enough for personality? Using ChatGPT to reconstruct an agent's latent personality from simple descriptions

## Quick Facts
- arXiv ID: 2406.12216
- Source URL: https://arxiv.org/abs/2406.12216
- Reference count: 40
- Primary result: GPT-3.5 achieved 71.88% consistency in maintaining specified personality scores from persona descriptions

## Executive Summary
This study investigates whether large language models (LLMs) like GPT-3.5 and GPT-4 can accurately reconstruct human personality traits from simple persona descriptions using the HEXACO framework. The research tests the models with varying numbers of persona descriptions (1000 for GPT-3.5, 100 for GPT-4) containing socio-demographic and personality type information. Results demonstrate that while LLMs show significant capability in personality reconstruction, achieving 71.88% consistency for GPT-3.5, they also exhibit notable limitations including defaulting to positive traits when personality dimensions are omitted and showing strong influence from socio-demographic factors on reconstructed personality dimensions.

## Method Summary
The study employed the HEXACO personality framework to test whether LLMs could accurately reconstruct personality traits from simple persona descriptions. GPT-3.5 was tested with 1000 persona descriptions while GPT-4 was tested with 100 descriptions, each containing socio-demographic information and explicit personality type data. The models were prompted to generate responses that would allow researchers to infer the latent personality dimensions, which were then compared against the originally specified traits to measure consistency rates. The evaluation focused on whether the reconstructed personality matched the intended personality scores provided in the persona descriptions.

## Key Results
- GPT-3.5 achieved 71.88% consistency in maintaining specified personality scores across 1000 persona descriptions
- GPT-4 showed similar performance to GPT-3.5 in personality reconstruction tasks
- Models consistently defaulted to positive traits when personality dimensions were omitted from descriptions
- Socio-demographic factors like age and number of children significantly influenced reconstructed personality dimensions

## Why This Works (Mechanism)
The mechanism underlying this research centers on the ability of LLMs to process and integrate multiple information streams from persona descriptions. The models leverage their training on vast text corpora to understand implicit relationships between socio-demographic factors and personality traits, allowing them to infer personality dimensions even when not explicitly stated. This capability stems from the models' ability to recognize patterns in how personality traits are typically described and associated with different demographic characteristics. The HEXACO framework provides a structured approach for measuring personality across six dimensions, enabling systematic evaluation of the models' reconstruction accuracy.

## Foundational Learning
- HEXACO Personality Framework: Why needed - Provides standardized six-dimensional model for personality assessment; Quick check - Ensure all six dimensions (Honesty-Humility, Emotionality, Extraversion, Agreeableness, Conscientiousness, Openness) are properly measured
- Persona Description Construction: Why needed - Creates controlled inputs for testing personality reconstruction; Quick check - Verify socio-demographic and personality information are clearly separated
- Personality Consistency Metrics: Why needed - Enables quantitative evaluation of reconstruction accuracy; Quick check - Confirm consistency calculations match intended personality scores
- LLM Prompt Engineering: Why needed - Optimizes model responses for personality inference; Quick check - Test multiple prompt variations to identify most effective formulations
- Cross-Model Comparison: Why needed - Identifies differences in reconstruction capabilities between model versions; Quick check - Run identical tests across GPT-3.5 and GPT-4
- Socio-Demographic Influence Analysis: Why needed - Reveals hidden biases in personality reconstruction; Quick check - Isolate demographic variables to measure their individual impact

## Architecture Onboarding
Component Map: Persona Descriptions -> LLM Processing -> HEXACO Dimension Extraction -> Consistency Evaluation
Critical Path: Persona input → Personality reconstruction → Dimension scoring → Consistency calculation → Result analysis
Design Tradeoffs: Large sample size (1000) for GPT-3.5 provides statistical power but increases computational cost, while smaller sample (100) for GPT-4 reduces resources but may miss edge cases
Failure Signatures: Defaulting to positive traits when dimensions omitted, over-inference from socio-demographic factors, inconsistent scoring across similar persona descriptions
Three First Experiments:
1. Test model with personas containing only socio-demographic information to measure baseline personality inference
2. Compare reconstruction accuracy when personality traits are explicitly stated vs implicitly suggested
3. Evaluate model performance with contradictory or ambiguous personality descriptions

## Open Questions the Paper Calls Out
None

## Limitations
- The HEXACO framework may not capture the full complexity of human personality beyond six dimensions
- Sample sizes of 1000 (GPT-3.5) and 100 (GPT-4) may not capture all potential edge cases and variations
- The study does not investigate cross-cultural validity of personality reconstruction results
- Default tendency toward positive traits when dimensions are omitted raises questions about underlying model biases

## Confidence
- High confidence: The observed consistency rates (71.88%) for GPT-3.5 in maintaining specified personality scores are reliable given the controlled experimental conditions and clear evaluation metrics
- Medium confidence: The findings regarding socio-demographic influences on personality reconstruction, while supported by data, require additional validation across different cultural contexts and demographic distributions
- Medium confidence: The default tendency toward positive traits when dimensions are omitted is a robust observation but needs investigation into whether this reflects model training biases or genuine personality patterns

## Next Checks
1. Conduct cross-cultural validation by testing the same persona reconstruction process with diverse cultural contexts and languages to assess whether socio-demographic influences remain consistent across different populations
2. Implement ablation studies where individual components of persona descriptions (socio-demographic vs personality type information) are systematically removed to quantify their specific contributions to the reconstruction accuracy
3. Test the models with more nuanced and overlapping personality descriptions that include contradictory traits or ambiguous statements to evaluate how well the LLMs handle complex human personality representations beyond the HEXACO framework