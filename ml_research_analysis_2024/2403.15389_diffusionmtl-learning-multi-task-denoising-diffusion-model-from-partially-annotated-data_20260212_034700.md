---
ver: rpa2
title: 'DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially
  Annotated Data'
arxiv_id: '2403.15389'
source_url: https://arxiv.org/abs/2403.15389
tags:
- multi-task
- prediction
- diffusion
- denoising
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of multi-task learning from partially
  annotated data, where each training sample is labeled for only a subset of tasks.
  This leads to noisy predictions in existing methods.
---

# DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data

## Quick Facts
- **arXiv ID:** 2403.15389
- **Source URL:** https://arxiv.org/abs/2403.15389
- **Authors:** Hanrong Ye; Dan Xu
- **Reference count:** 40
- **Primary result:** Novel multi-task denoising diffusion framework that significantly outperforms state-of-the-art methods on PASCAL, NYUD, and Cityscapes datasets

## Executive Summary
DiffusionMTL addresses the challenge of multi-task learning from partially annotated data, where each training sample is labeled for only a subset of tasks. This leads to noisy predictions in existing methods. The authors propose a novel multi-task denoising diffusion framework that reformulates multi-task dense prediction as a joint pixel-level diffusion and denoising process. DiffusionMTL employs a Multi-Task Denoising Diffusion Network (MTDNet) to denoise noisy multi-task predictions using two diffusion mechanisms - Prediction Diffusion and Feature Diffusion - to refine task signals in prediction and feature spaces. A Multi-Task Conditioning strategy is also introduced to exploit task consistency and improve denoising performance.

## Method Summary
DiffusionMTL reformulates multi-task dense prediction as a joint pixel-level diffusion and denoising process. The framework employs a Multi-Task Denoising Diffusion Network (MTDNet) that utilizes two diffusion mechanisms: Prediction Diffusion, which refines noisy predictions by diffusing them with Gaussian noise, and Feature Diffusion, which performs diffusion in the feature space to capture task relationships. A Multi-Task Conditioning strategy is introduced to leverage task consistency and enhance denoising performance. The model is trained end-to-end using partially annotated data, where each sample has labels for only a subset of tasks. During inference, the model generates clean predictions for all tasks simultaneously by reversing the diffusion process.

## Key Results
- Achieves significant improvements in multi-task performance metrics compared to state-of-the-art methods
- Demonstrates superior performance on three challenging datasets: PASCAL, NYUD, and Cityscapes
- Maintains high performance while using fewer model parameters than competing approaches

## Why This Works (Mechanism)
DiffusionMTL works by reframing multi-task dense prediction as a denoising problem. The key insight is that partially annotated data creates noisy predictions for unannotated tasks, and diffusion models are naturally suited for denoising. By applying diffusion in both prediction and feature spaces, the model can gradually refine noisy predictions while leveraging shared information across tasks. The Multi-Task Conditioning strategy further enhances this process by encouraging consistency between related tasks during the denoising iterations.

## Foundational Learning
- **Diffusion models**: Why needed - provide a principled framework for gradual denoising of noisy predictions; Quick check - understand the forward noising process and reverse denoising process
- **Multi-task learning**: Why needed - enables learning shared representations across related tasks; Quick check - grasp how tasks can share features while maintaining task-specific heads
- **Partially annotated data**: Why needed - realistic scenario where labeling all tasks is expensive; Quick check - recognize how missing labels create noisy predictions
- **Feature space diffusion**: Why needed - captures task relationships at a more abstract level than pixel predictions; Quick check - understand how diffusion operates on feature embeddings
- **Conditional generation**: Why needed - allows conditioning the denoising process on available task annotations; Quick check - see how conditioning guides the diffusion process

## Architecture Onboarding

**Component Map:** Input -> Backbone Feature Extractor -> MTDNet (Prediction Diffusion + Feature Diffusion) -> Multi-Task Conditioning -> Output Predictions

**Critical Path:** The critical path involves the iterative denoising process where predictions are progressively refined through multiple diffusion steps. Each step involves both prediction space diffusion (adding noise to current predictions) and feature space diffusion (refining shared features), followed by conditioning on available task labels.

**Design Tradeoffs:** The dual diffusion approach trades computational complexity for improved denoising performance. Alternative designs could include single-space diffusion or deterministic refinement instead of stochastic diffusion, but these would likely sacrifice the gradual refinement that makes diffusion effective for denoising.

**Failure Signatures:** The model may struggle when task relationships are weak or contradictory, when the diffusion process is not properly calibrated (too much noise vs. too little), or when the conditioning strategy fails to properly leverage available annotations.

**3 First Experiments:**
1. Ablation study comparing single-task vs. multi-task diffusion performance
2. Analysis of prediction vs. feature diffusion contributions to overall performance
3. Evaluation of conditioning strategy effectiveness with varying numbers of available annotations

## Open Questions the Paper Calls Out
None

## Limitations
- Requires careful tuning of multiple diffusion hyperparameters (sigma values, diffusion steps)
- Computational overhead from dual diffusion mechanisms may be significant during training and inference
- Assumes task relationships are well-captured through the diffusion process, which may not hold for highly heterogeneous task pairs

## Confidence
- **Primary Claims (High Confidence):** Experimental results showing DiffusionMTL outperforming baseline methods are well-supported with comprehensive metrics and statistical comparisons
- **Performance Claims (Medium Confidence):** Reported improvements in mIoU and task-specific metrics are substantial but depend on specific baseline implementations
- **Generalizability Claims (Low Confidence):** Claims about generalization beyond evaluated domains lack direct empirical support

## Next Checks
1. **Ablation study on diffusion hyperparameters:** Systematically evaluate how sensitive DiffusionMTL's performance is to variations in sigma values, diffusion steps, and the relative weighting of prediction vs. feature diffusion across different task combinations.

2. **Cross-dataset generalization test:** Evaluate DiffusionMTL on a dataset with different characteristics (e.g., outdoor vs. indoor, different object categories) than PASCAL, NYUD, and Cityscapes to assess real-world applicability beyond the current evaluation domains.

3. **Computational overhead analysis:** Conduct a comprehensive analysis of the additional computational cost (FLOPs, memory usage, inference time) introduced by the dual diffusion mechanisms compared to standard multi-task learning approaches, particularly at different input resolutions.