---
ver: rpa2
title: Simultaneous Training of First- and Second-Order Optimizers in Population-Based
  Reinforcement Learning
arxiv_id: '2408.15421'
source_url: https://arxiv.org/abs/2408.15421
tags:
- adam
- training
- learning
- population
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of optimizing hyperparameters
  in reinforcement learning (RL), which significantly impacts an agent's performance
  and learning efficiency. The authors propose enhancing Population-Based Training
  (PBT) by simultaneously utilizing both first-order (e.g., Adam) and second-order
  (e.g., K-FAC) optimizers within a single population.
---

# Simultaneous Training of First- and Second-Order Optimizers in Population-Based Reinforcement Learning

## Quick Facts
- **arXiv ID**: 2408.15421
- **Source URL**: https://arxiv.org/abs/2408.15421
- **Reference count**: 9
- **Primary result**: Mixed populations of Adam and K-FAC optimizers in PBT improved performance by up to 10% and increased stability in environments where Adam fails.

## Executive Summary
This paper addresses the challenge of optimizing hyperparameters in reinforcement learning (RL) by enhancing Population-Based Training (PBT) to simultaneously utilize both first-order (e.g., Adam) and second-order (e.g., K-FAC) optimizers within a single population. The authors conducted experiments using the TD3 algorithm across various MuJoCo environments. Their results demonstrate that combining K-FAC with Adam led to up to a 10% improvement in overall performance compared to PBT using only Adam. Additionally, in environments where Adam occasionally fails (e.g., Swimmer), the mixed population with K-FAC exhibited more reliable learning outcomes, offering a significant advantage in training stability without a substantial increase in computational time.

## Method Summary
The authors propose enhancing PBT by incorporating a mixed population of first-order and second-order optimizers. They use the TD3 algorithm with a population of agents, each using either Adam or K-FAC as their optimizer. The population undergoes periodic evaluation, replacement, and hyperparameter perturbation. Grid search is used for hyperparameter tuning, and experiments are conducted across multiple MuJoCo environments with population sizes of 4, 8, and 16 agents over 1 million training steps.

## Key Results
- Mixed populations of Adam and K-FAC optimizers in PBT improved performance by up to 10% compared to using only Adam.
- In environments where Adam occasionally fails (e.g., Swimmer), the mixed population with K-FAC exhibited more reliable learning outcomes.
- Increasing population size generally improved rewards, especially from four to eight agents, without a substantial increase in computational time.

## Why This Works (Mechanism)

### Mechanism 1
Mixing first-order (Adam) and second-order (K-FAC) optimizers in one PBT population improves overall performance and stability compared to using only Adam. Second-order methods like K-FAC capture curvature information of the loss landscape, enabling more precise parameter updates especially in later training stages. In PBT, agents with different optimizers can replace underperforming peers, allowing the population to benefit from second-order optimizer strengths when first-order ones struggle. Core assumption: The environment's reward landscape is sufficiently complex that curvature information helps, and that second-order updates are beneficial despite higher computational cost. Evidence anchors: [abstract] "Specifically, the combination of the K-FAC optimizer with Adam led to up to a 10% improvement in overall performance compared to PBT using only Adam." Break condition: If the second-order optimizer's damping is too low, Cholesky factorization fails and training stalls.

### Mechanism 2
Population size affects the benefit of mixing optimizers; larger populations improve robustness and performance. Larger populations provide more diverse hyperparameter and optimizer combinations, increasing the chance that at least one agent performs well in each environment. In PBT, poorly performing agents are replaced by better ones, so diversity improves survival of effective strategies. With mixed optimizers, diversity includes different curvature exploitation strategies, further stabilizing learning. Core assumption: Exploration-exploitation tradeoff is improved by optimizer diversity; computational overhead is acceptable. Evidence anchors: [section] "Results over one million training steps... showed that increasing population size generally improved rewards, especially from four to eight agents." Break condition: Beyond ~8 agents, marginal gains diminish; computational cost may outweigh benefits.

### Mechanism 3
Second-order optimizers help avoid complete failure in environments where Adam occasionally fails (e.g., Swimmer). Adam can get stuck in poor local minima or fail to converge in certain reward landscapes. Second-order optimizers like K-FAC, by incorporating curvature, can navigate more effectively around such pitfalls. In PBT, even if some agents fail, others with K-FAC can succeed and propagate their hyperparameters, rescuing the population. Core assumption: The Swimmer environment's reward landscape has regions where first-order methods struggle but second-order methods can succeed. Evidence anchors: [abstract] "in environments where Adam occasionally fails, such as the Swimmer environment, the mixed population with K-FAC exhibited more reliable learning outcomes." Break condition: If damping or step counts are not balanced, second-order agents may underperform, reducing reliability.

## Foundational Learning

- **Concept**: Population-Based Training (PBT) for hyperparameter optimization.
  - Why needed here: PBT allows dynamic adjustment of hyperparameters and optimizer choice during training, enabling adaptation to different learning stages and improving performance over static hyperparameter settings.
  - Quick check question: How does PBT decide which agents to replace and what hyperparameters to copy?

- **Concept**: First-order vs. second-order optimization methods.
  - Why needed here: Understanding the difference between Adam (first-order, uses gradients) and K-FAC (second-order, uses curvature/Fisher matrix) is essential to grasp why mixing them can help.
  - Quick check question: What is the computational trade-off between first-order and second-order methods?

- **Concept**: Fisher Information Matrix and Kronecker-Factored Approximate Curvature (K-FAC).
  - Why needed here: K-FAC approximates the Fisher matrix to enable efficient second-order updates; knowing this helps understand why K-FAC is computationally feasible for large networks.
  - Quick check question: How does K-FAC approximate the Fisher matrix to reduce computational complexity?

## Architecture Onboarding

- **Component map**: Population of RL agents (TD3) with diverse optimizers (Adam, Diag. GGN, K-FAC), hyperparameter search, periodic replacement and perturbation mechanism, evaluation pipeline.
- **Critical path**: Initialize population → Train agents in parallel → Periodically evaluate → Replace worst agents with best (copy weights/hyperparameters) → Perturb hyperparameters → Repeat until convergence.
- **Design tradeoffs**: Mixed optimizers increase computational cost (especially second-order); damping and step counts must be tuned to balance runtime; population size affects diversity vs. cost.
- **Failure signatures**: Cholesky factorization failure in K-FAC (damping too low); Adam failure in certain environments; low reward variance indicating all agents converge to same poor strategy.
- **First 3 experiments**:
  1. Run single-agent Adam vs. single-agent K-FAC to confirm baseline performance and optimizer tuning.
  2. Run PBT with Adam-only population to establish baseline.
  3. Run PBT with mixed Adam and K-FAC population, compare performance and stability.

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal ratio of first-order to second-order optimizers in a PBT population for different RL environments? Basis in paper: [explicit] The authors observed that mixed populations of Adam and K-FAC optimizers showed improved performance, with specific ratios (e.g., 6 Adam - 2 K-FAC) yielding better results in certain environments like Swimmer and Walker2d. Why unresolved: The paper tested various ratios but did not determine a universal optimal ratio applicable across all environments. The effectiveness of different ratios may depend on specific task characteristics. What evidence would resolve it: Systematic experiments varying the ratio of first-order to second-order optimizers across a broader range of environments, analyzing the performance trends to identify optimal ratios for different task types.

### Open Question 2
How does the inclusion of diverse first-order optimizers (e.g., Adam, SGD, RMSprop) alongside second-order optimizers affect the performance and stability of PBT-based RL? Basis in paper: [inferred] The authors suggest expanding the diversity of optimization strategies within a population could enhance performance and stability, but only tested Adam as the first-order optimizer. Why unresolved: The paper did not explore the effects of incorporating different first-order optimizers, leaving open the question of whether certain combinations might outperform others. What evidence would resolve it: Comparative experiments using populations with various combinations of first-order and second-order optimizers, measuring performance and stability across multiple environments.

### Open Question 3
What are the long-term effects of using mixed populations of first- and second-order optimizers on the generalization ability of RL agents? Basis in paper: [inferred] While the paper demonstrates improved performance and stability during training, it does not address whether these benefits translate to better generalization to unseen tasks or environments. Why unresolved: The experiments focused on training performance within specific environments, without evaluating generalization to new tasks or variations of the training environments. What evidence would resolve it: Training agents using mixed optimizer populations and then testing their performance on a suite of novel tasks or environments not seen during training, comparing generalization capabilities to agents trained with single optimizer types.

## Limitations

- The study relies on experimental results without strong external validation from the broader literature, as no corpus evidence directly supports the claims.
- Hyperparameters for K-FAC and Diag. GGN are not fully specified, which could impact reproducibility.
- The study does not address the computational cost trade-offs in detail, particularly for second-order methods like K-FAC.

## Confidence

- **High**: The claim that mixing optimizers in PBT improves performance and stability is supported by experimental results within the study.
- **Medium**: The assertion that second-order methods help in environments where Adam fails is based on observed outcomes but lacks broader validation.
- **Low**: The effectiveness of increasing population size beyond 8 agents is inferred from experiments without comprehensive analysis of diminishing returns.

## Next Checks

1. Conduct ablation studies to isolate the impact of each optimizer on performance and stability.
2. Perform cross-validation with different RL algorithms to assess generalizability of the findings.
3. Analyze computational overhead and scalability of mixed optimizer populations in larger environments.