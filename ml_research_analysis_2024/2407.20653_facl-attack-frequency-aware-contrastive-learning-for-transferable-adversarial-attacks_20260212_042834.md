---
ver: rpa2
title: 'FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial
  Attacks'
arxiv_id: '2407.20653'
source_url: https://arxiv.org/abs/2407.20653
tags:
- adversarial
- domain
- perturbation
- image
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'FACL-Attack improves adversarial transferability by leveraging
  frequency-domain techniques. It employs two modules: Frequency-Aware Domain Randomization
  (FADR) that randomizes domain-variant low- and high-frequency components while preserving
  mid-frequency components, and Frequency-Augmented Contrastive Learning (FACL) that
  contrasts domain-invariant mid-frequency features between clean and perturbed images.'
---

# FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks

## Quick Facts
- **arXiv ID**: 2407.20653
- **Source URL**: https://arxiv.org/abs/2407.20653
- **Reference count**: 24
- **Key outcome**: FACL-Attack improves adversarial transferability by leveraging frequency-domain techniques, achieving top-1 classification accuracy reductions of 44.05% (cross-domain) and 19.66% (cross-model) when trained on ImageNet-1K and tested on black-box domains and models.

## Executive Summary
FACL-Attack introduces a novel approach to generative adversarial attacks by leveraging frequency-domain analysis. The method employs two key modules: Frequency-Aware Domain Randomization (FADR) that randomizes domain-variant low- and high-frequency components while preserving mid-frequency components, and Frequency-Augmented Contrastive Learning (FACL) that contrasts domain-invariant mid-frequency features between clean and perturbed images. This approach effectively guides the perturbation generator to craft adversarial examples that transfer better across different domains and models, outperforming state-of-the-art methods while maintaining inference time complexity.

## Method Summary
FACL-Attack uses a two-module approach for transferable adversarial attacks. The FADR module applies DCT-based spectral decomposition to input images, then randomizes domain-variant low- and high-frequency components while preserving domain-invariant mid-frequency components. The generator crafts perturbations within an l∞ budget, and the FACL module performs contrastive learning on spectrally decomposed features, contrasting mid-band clean and perturbed feature pairs. The method is trained on ImageNet-1K using a combination of baseline attack loss and contrastive loss, achieving strong performance across cross-domain and cross-model evaluations.

## Key Results
- FACL-Attack achieves 44.05% top-1 classification accuracy reduction in cross-domain settings
- FACL-Attack achieves 19.66% top-1 classification accuracy reduction in cross-model settings
- The method outperforms state-of-the-art generative attack methods while maintaining inference time complexity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Frequency-Aware Domain Randomization (FADR) improves transferability by explicitly randomizing domain-variant frequency components while preserving domain-invariant ones.
- **Mechanism**: During training, FADR transforms input images to the frequency domain using DCT, applies random masked filtering to low- and high-frequency components (domain-variant), and preserves mid-frequency components (domain-invariant). This exposes the generator to diverse frequency-domain variations that simulate unseen domains.
- **Core assumption**: Low- and high-frequency components carry domain-specific information (like texture and color) while mid-frequency components capture domain-agnostic semantic structure.
- **Evidence anchors**:
  - [abstract] "FADR module to randomize domain-variant low- and high-range frequency components"
  - [section] "randomizes domain-variant low- and high-range frequency components while keeping the domain-invariant mid-FCs"
  - [corpus] Weak - corpus neighbors discuss transferability but not frequency-domain randomization explicitly

### Mechanism 2
- **Claim**: Frequency-Augmented Contrastive Learning (FACL) improves transferability by contrasting domain-invariant mid-frequency features while minimizing the importance of domain-specific features.
- **Mechanism**: After spectral decomposition, FACL contrasts mid-band clean and perturbed feature pairs to repel them (push apart), while attracting low/high-band pairs. This guides the generator to focus on domain-agnostic semantic content.
- **Core assumption**: Mid-frequency features contain domain-invariant semantic information that is transferable across models and domains, while low/high-frequency features are domain-specific.
- **Evidence anchors**:
  - [abstract] "FACL module to effectively separate domain-invariant mid-frequency features of clean and perturbed image"
  - [section] "FACL module seeks to apply feature contrast specifically in the domain-agnostic mid-frequency range"
  - [corpus] Weak - corpus neighbors don't discuss frequency-specific contrastive learning

### Mechanism 3
- **Claim**: The combination of FADR and FACL creates synergistic effects that enhance transferability beyond either method alone.
- **Mechanism**: FADR provides diverse frequency-domain training data that simulates unseen domains, while FACL learns to extract domain-agnostic features from this augmented data. Together they create a robust generator that generalizes across domains and models.
- **Core assumption**: Data augmentation (FADR) and feature learning (FACL) are complementary - randomization enables stable contrastive learning, while contrastive learning benefits from diverse training samples.
- **Evidence anchors**:
  - [section] "FADR and FACL are complementary since data augmentation through our FADR facilitates the stable feature contrastive learning"
  - [section] "Ours performs the best consistently"
  - [corpus] Weak - corpus neighbors don't discuss synergistic effects of frequency-based data augmentation and feature contrastive learning

## Foundational Learning

- **Concept**: Frequency domain analysis using DCT
  - **Why needed here**: The entire method relies on decomposing images into frequency components to identify domain-specific vs domain-invariant information
  - **Quick check question**: What frequency components (low, mid, high) contain domain-invariant semantic information according to FACL-Attack?

- **Concept**: Contrastive learning in feature space
  - **Why needed here**: FACL module uses contrastive learning to push apart domain-invariant mid-frequency feature pairs and attract domain-specific feature pairs
  - **Quick check question**: How does the contrastive loss in FACL-Attack differ from standard contrastive learning approaches?

- **Concept**: Adversarial attack transferability
  - **Why needed here**: The goal is to generate perturbations that transfer across unknown domains and models, which requires understanding what makes attacks transferable
  - **Quick check question**: Why are iterative attacks generally less transferable than generative attacks in black-box settings?

## Architecture Onboarding

- **Component map**: Clean image → FADR → Generator → Spectral decomposition → FACL → Loss → Backpropagation → Updated generator
- **Critical path**: Clean image → FADR → Generator → Spectral decomposition → FACL → Loss → Backpropagation → Updated generator
- **Design tradeoffs**:
  - Frequency thresholds (fl, fh): Too narrow loses information, too wide includes noise
  - Hyperparameters ρ, σ: Balance between sufficient randomization and training stability
  - Feature layer selection: Earlier layers capture more general features, later layers capture more specific features
  - Loss coefficients (λorig, λFACL): Balance between attack effectiveness and transferability
- **Failure signatures**:
  - Poor cross-domain performance: FADR not randomizing sufficiently or FACL not learning domain-agnostic features
  - Poor cross-model performance: Feature extraction layer not capturing transferable information
  - Training instability: FADR randomization too aggressive or contrastive loss too strong
  - Low image quality: Perturbation budget too small or FACL pushing features too far apart
- **First 3 experiments**:
  1. Baseline comparison: Train with Lorig only (no FADR, no FACL) to establish baseline performance
  2. FADR only: Add frequency-aware randomization but keep baseline contrastive loss to measure impact of data augmentation
  3. FACL only: Keep original data but add frequency-augmented contrastive learning to measure impact of feature learning

## Open Questions the Paper Calls Out
None

## Limitations
- The paper's claims about frequency-based domain separation are built on assumptions about DCT frequency components that are not empirically validated
- The choice of Maxpool.3 for feature extraction is presented as optimal without thorough ablation studies comparing different layers or models
- The specific values for loss coefficients λorig and λFACL are not specified, which could significantly impact results

## Confidence
- **High confidence**: The general framework combining frequency randomization with contrastive learning is technically sound and the reported performance improvements over baseline methods are well-documented through experiments
- **Medium confidence**: The claim that FADR and FACL are complementary mechanisms relies on limited ablation studies and could benefit from more rigorous analysis of their individual and joint contributions
- **Medium confidence**: The assumption about frequency-domain alignment with domain-specific information is theoretically motivated but lacks empirical validation across diverse datasets and domain shifts

## Next Checks
1. **Frequency Component Analysis**: Conduct experiments to verify that low/high frequency components actually contain domain-specific information and mid-frequency components contain domain-invariant semantic information across different dataset pairs
2. **Loss Coefficient Sensitivity**: Systematically vary λorig and λFACL values to understand their impact on performance and identify robust ranges for different attack scenarios
3. **Layer Ablation Study**: Compare performance when extracting features from different layers of the surrogate model (early, middle, late layers) to determine optimal feature extraction points for transferability