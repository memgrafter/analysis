---
ver: rpa2
title: 'SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised
  Learning'
arxiv_id: '2402.11933'
source_url: https://arxiv.org/abs/2402.11933
tags:
- memory
- anomaly
- detection
- slade
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SLADE addresses the challenge of unsupervised dynamic anomaly detection
  in edge streams, where real-world graphs evolve over time. The core idea is to use
  self-supervised learning to train a deep neural network that detects shifts in node
  states by observing deviations in their interaction patterns.
---

# SLADE: Detecting Dynamic Anomalies in Edge Streams without Labels via Self-Supervised Learning

## Quick Facts
- arXiv ID: 2402.11933
- Source URL: https://arxiv.org/abs/2402.11933
- Reference count: 40
- Key outcome: SLADE outperforms nine competing methods in unsupervised dynamic anomaly detection, achieving 12.80% and 4.23% average AUC improvement over best unsupervised and supervised baselines respectively

## Executive Summary
SLADE addresses the challenge of unsupervised dynamic anomaly detection in edge streams where real-world graphs evolve over time. The core innovation is using self-supervised learning to train a deep neural network that detects shifts in node states by observing deviations in their interaction patterns. SLADE employs two self-supervised tasks: minimizing drift in node representations and generating long-term interaction patterns from short-term ones. The method achieves constant inference time per edge through careful architectural design, making it scalable to large graphs. In experiments across four real-world datasets, SLADE demonstrates superior performance compared to both unsupervised and supervised baselines.

## Method Summary
SLADE uses self-supervised learning to detect dynamic anomalies in edge streams without labeled data. The method trains a neural network using two tasks: minimizing drift in node representations over short time intervals (temporal contrast) and generating long-term interaction patterns from short-term ones (memory generation). Nodes that fail these tasks are flagged as anomalies. The architecture achieves constant inference time per edge through GRU-based memory updates and TGAT-based memory generation, with complexity independent of graph size. The model is trained assuming all nodes in the training set are normal, leveraging the prevalence of normal patterns to learn anomaly detection without supervision.

## Key Results
- Achieves 12.80% average AUC improvement over best-performing unsupervised competitor
- Outperforms supervised methods with 4.23% average AUC improvement over best-performing supervised competitor
- Demonstrates constant-time inference per edge regardless of graph size
- Validated across four real-world datasets: Wikipedia, Reddit, Bitcoin-alpha, and Bitcoin-OTC

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SLADE uses self-supervised learning to detect dynamic anomalies without labeled data by contrasting long-term and short-term interaction patterns.
- Mechanism: The model trains a neural network to perform two tasks: minimizing drift in node representations over short time intervals (temporal contrast) and generating long-term interaction patterns from short-term ones (memory generation). Nodes that fail these tasks are flagged as anomalies.
- Core assumption: Nodes in normal states exhibit stable long-term interaction patterns with minimal variation in short intervals, and these patterns can be regenerated from recent interactions.
- Evidence anchors:
  - [abstract]: "SLADE detects the shifts of nodes into abnormal states by observing deviations in their interaction patterns over time."
  - [section]: "We consider two key assumptions: (a) Stable Long-Term Interaction Patterns... (b) Potential for Restoration of Patterns..."
- Break condition: If real-world node behaviors frequently deviate from stable patterns even when normal, or if short-term interactions cannot reliably predict long-term patterns, the assumptions fail.

### Mechanism 2
- Claim: SLADE achieves constant inference time per edge regardless of graph size through careful architectural design.
- Mechanism: Memory updates and anomaly scoring operations are designed to be O(k·d_s² + d_s·d_m), where k is the number of recent neighbors, d_s is memory dimension, and d_m is message dimension. This complexity is independent of total graph size.
- Core assumption: The number of recent neighbors considered (k) and the memory/message dimensions remain bounded, ensuring constant-time operations per edge.
- Evidence anchors:
  - [section]: "The time complexity for both tasks is O(k·d_s² + d_s·d_m), which is constant with respect to the graph size."
  - [section]: "Memory Update: Given a newly arriving edge, SLADE updates the memory vector of each endpoint using GRU. The total time complexity is dominated by that of GRU, which is O(d_s² + d_s·d_m)."
- Break condition: If k or the dimensions grow unboundedly with graph size, or if the underlying operations cannot maintain constant time complexity.

### Mechanism 3
- Claim: SLADE outperforms supervised methods despite having no label information by effectively learning normal patterns from majority data.
- Mechanism: The model is trained assuming all nodes in the training set are normal, leveraging the fact that normal patterns constitute the majority. It learns to distinguish normal from abnormal by identifying deviations from learned normal patterns.
- Core assumption: Normal interaction patterns are prevalent enough in the training data that the model can learn them effectively without supervision, and anomalies are sufficiently distinct from these patterns.
- Evidence anchors:
  - [abstract]: "In dynamic anomaly detection across four real-world datasets, SLADE outperforms nine competing methods, even those leveraging label supervision."
  - [section]: "Note that, since anomaly labels are assumed to be unavailable, SLADE is trained with the assumption that the state of all nodes appearing in the training set is normal, irrespective of their actual states."
- Break condition: If anomalies are too prevalent in the training data or if normal and abnormal patterns are too similar to distinguish without labels.

## Foundational Learning

- Concept: Graph neural networks and their ability to capture structural information
  - Why needed here: SLADE uses graph attention networks (TGAT) to aggregate information from neighboring nodes and capture temporal patterns in the graph structure.
  - Quick check question: Can you explain how graph attention mechanisms differ from simple averaging when aggregating neighbor information?

- Concept: Recurrent neural networks for temporal modeling
  - Why needed here: GRU units are used to update memory vectors over time, capturing how node interactions evolve.
  - Quick check question: What is the key advantage of using GRU over simple RNNs for maintaining state over long sequences?

- Concept: Self-supervised learning objectives and contrastive learning
  - Why needed here: SLADE uses temporal contrast loss and memory generation loss as self-supervised objectives to train the model without labels.
  - Quick check question: How does minimizing temporal contrast loss encourage the model to learn stable node representations?

## Architecture Onboarding

- Component map:
  Memory Module -> Memory Updater (GRU) -> Memory Generator (TGAT) -> Loss Functions (Temporal Contrast + Memory Generation) -> Anomaly Scoring

- Critical path: Edge arrival → Update memory vectors using GRU → Generate reconstructed memory using TGAT → Compute anomaly scores → Output results

- Design tradeoffs:
  - Memory dimension vs. computational cost: Higher dimensions capture more information but increase computation
  - Number of recent neighbors (k) vs. accuracy: More neighbors provide better context but increase computation
  - Batch size vs. temporal resolution: Larger batches improve efficiency but may reduce sensitivity to short-term patterns

- Failure signatures:
  - High false positives: Model too sensitive to normal variations
  - High false negatives: Model fails to detect clear anomalies
  - Slow performance: Operations not truly constant time as claimed
  - Poor convergence: Learning rate too high/low or architecture mismatch

- First 3 experiments:
  1. Implement the memory update component with GRU and verify it processes edges in constant time
  2. Implement the memory generation component with TGAT and test it reconstructs memory from recent neighbors
  3. Combine both components and train on a small synthetic dataset to verify anomaly scores behave as expected

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several emerge from the work:

### Open Question 1
- Question: How would SLADE perform on graphs with different types of dynamic anomalies beyond those explored in the paper?
- Basis in paper: [inferred] The paper discusses SLADE's effectiveness in detecting various types of anomalies (hijacked, new/rarely-interacting, and consistent anomalies) but only evaluates on specific datasets and synthetic anomalies.
- Why unresolved: The paper does not provide empirical evidence for SLADE's performance on a broader range of anomaly types.
- What evidence would resolve it: Testing SLADE on datasets with diverse and novel types of dynamic anomalies and comparing its performance to existing methods.

### Open Question 2
- Question: Can SLADE be extended to handle dynamic graphs with node attributes or edge attributes?
- Basis in paper: [explicit] The paper focuses on SLADE's performance on graphs without node or edge attributes, using zero vectors as substitutes in datasets that lack such information.
- Why unresolved: The paper does not explore SLADE's capability to incorporate node or edge attributes in its anomaly detection process.
- What evidence would resolve it: Modifying SLADE to handle node or edge attributes and evaluating its performance on datasets with such attributes.

### Open Question 3
- Question: How does the performance of SLADE scale with the size of the graph and the number of nodes?
- Basis in paper: [explicit] The paper demonstrates SLADE's constant time complexity per edge, but does not provide extensive empirical evidence on its performance with varying graph sizes.
- Why unresolved: The paper does not explore SLADE's performance on very large graphs or graphs with a high number of nodes.
- What evidence would resolve it: Conducting experiments on large-scale graphs with varying numbers of nodes and edges to assess SLADE's performance and scalability.

## Limitations

- Limited transparency around hyperparameter optimization, particularly for the SLADE-HP variant
- Complex preprocessing steps for Bitcoin-alpha/OTC datasets not fully detailed
- Does not address cases where normal and anomalous patterns significantly overlap
- Sensitivity to memory and message dimension choices not thoroughly explored

## Confidence

- **High confidence**: The core mechanism of using self-supervised learning for anomaly detection without labels is well-founded, and the constant-time complexity claim is mathematically justified
- **Medium confidence**: The experimental results showing superior performance are compelling but rely on undisclosed hyperparameter tuning strategies that may significantly impact outcomes
- **Low confidence**: The paper doesn't fully address how SLADE handles cases where normal and anomalous patterns overlap significantly, or how sensitive the model is to the choice of memory and message dimensions

## Next Checks

1. **Ablation study on self-supervised tasks**: Remove either the temporal contrast loss or memory generation loss individually to quantify their independent contributions to anomaly detection performance
2. **Sensitivity analysis of hyperparameters**: Systematically vary memory dimension, message dimension, and number of recent neighbors (k) to identify performance thresholds and computational trade-offs
3. **Cross-dataset generalization test**: Train SLADE on one dataset type (e.g., social networks) and evaluate on another (e.g., financial networks) to assess how well the self-supervised learning transfers across domains with different interaction patterns