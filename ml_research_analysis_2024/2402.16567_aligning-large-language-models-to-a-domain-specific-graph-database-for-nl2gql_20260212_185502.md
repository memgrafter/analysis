---
ver: rpa2
title: Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL
arxiv_id: '2402.16567'
source_url: https://arxiv.org/abs/2402.16567
tags:
- graph
- schema
- llms
- data
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for converting natural language
  queries into graph query language (NL2GQL) for domain-specific graph databases.
  The key challenge addressed is the lack of domain-specific training data for this
  task.
---

# Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL

## Quick Facts
- arXiv ID: 2402.16567
- Source URL: https://arxiv.org/abs/2402.16567
- Reference count: 14
- Key outcome: Method achieves 5.90-6.36 absolute points improvement on exact match and 6.00-7.09 absolute points on execution accuracy for NL2GQL conversion

## Executive Summary
This paper addresses the challenge of converting natural language queries to graph query language (GQL) for domain-specific graph databases, focusing on the lack of training data for this task. The authors propose a method that uses ChatGPT to generate NL-GQL pairs from a given graph database schema, fine-tunes large language models (LLMs) on these pairs using LoRA, and extracts relevant schema items as context during inference. The approach is evaluated on financial and medical domain datasets, demonstrating significant improvements over baseline methods with 5.90-6.36 absolute points on exact match and 6.00-7.09 absolute points on execution accuracy.

## Method Summary
The proposed method consists of three main stages: (1) Data generation using self-instruction with Chain-of-Thought verification, where ChatGPT generates NL-GQL pairs and verifies their consistency through GQL2NL conversion, (2) LoRA-based fine-tuning of LLMs on the generated NL-GQL pairs with schema as context, and (3) Inference with relevant schema extraction, where the system identifies named entities in NL queries, links them to graph database labels, finds shortest paths between them, and uses this subgraph as context for prompting the fine-tuned LLM. The method was evaluated on FinGQL (financial) and MediGQL (medical) datasets using Exact Match (EM) and Execution Accuracy (EX) metrics.

## Key Results
- The proposed method achieves 5.90-6.36 absolute points improvement on exact match compared to baselines
- Execution accuracy improves by 6.00-7.09 absolute points over baseline methods
- Relevant schema extraction improves inference accuracy by 0.80-1.14 absolute points on exact match and 0.60-1.13 on execution accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-instruct with Chain-of-Thought verification improves NL-GQL template generation quality
- Mechanism: Two-step ChatGPT prompting where step 1 generates candidate NL-GQL pairs and step 2 verifies them via CoT-based GQL2NL conversion, filtering out inconsistent pairs
- Core assumption: CoT-based GQL2NL can reliably verify semantic consistency between generated NL and GQL
- Evidence anchors: [abstract] "Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB"; [section 4.1] "To ensure the consistency of L and Q across all data entries, we compare encode them via the sequence matching encoder and compare their similarities"

### Mechanism 2
- Claim: Extracting relevant schema items improves LLM inference accuracy for NL2GQL
- Mechanism: During inference, identify named entities in NL, link to graph DB labels, find shortest paths between them, and use this subgraph as context for LLM prompting
- Core assumption: Relevant schema context provides sufficient information for accurate GQL generation while reducing noise from irrelevant schema items
- Evidence anchors: [abstract] "Moreover, we find the importance of relevant schema in efficiently generating accurate GQLs. Thus, we introduce a method to extract relevant schema as the input context"; [section 4.3] "Specifically, we extract the key schema items that are relevant to the NL rather than the entire schema as the context"

### Mechanism 3
- Claim: LoRA fine-tuning with NL-GQL instruction pairs aligns LLMs to domain-specific graph databases
- Mechanism: Supervised fine-tuning using NL-GQL pairs where schema items are extracted from GQL as context for NL, training LLM to generate accurate GQLs
- Core assumption: LoRA fine-tuning can effectively transfer graph DB knowledge to foundation LLMs without catastrophic forgetting
- Evidence anchors: [abstract] "Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB"; [section 4.2] "Specifically, we feed the NL-GQL pairs obtained from Section 4.1 into the LLMs... the fine-tuned LLMs learn the schema of the domain-specific graph DB"

## Foundational Learning

- Concept: Graph database schema structure and property graph model
  - Why needed here: Understanding nodes, edges, properties, and relationships is essential for extracting relevant schema and generating correct GQLs
  - Quick check question: What is the difference between node properties and edge properties in a property graph?

- Concept: Natural language understanding and semantic parsing
  - Why needed here: Converting NL queries to structured GQL requires understanding entity mentions, attributes, relationships, and numerical comparisons
  - Quick check question: How would you identify numerical sorting requirements in a natural language query?

- Concept: Chain-of-Thought reasoning and self-instruct techniques
  - Why needed here: CoT is used to verify NL-GQL pair consistency, while self-instruct extends the dataset through iterative generation
  - Quick check question: What is the purpose of breaking down GQL into individual keywords and function clauses during CoT verification?

## Architecture Onboarding

- Component map: Schema extraction -> Template collection -> Self-instruct generation -> CoT verification -> DB grounding -> LoRA fine-tuning -> Aligned LLM -> NL input -> Entity linking -> Join-table linking -> Schema extraction -> Prompt generation -> GQL output
- Critical path: NL query -> Entity linking -> Schema extraction -> LLM inference -> GQL execution
- Design tradeoffs: Using LoRA instead of full fine-tuning reduces parameter updates but may limit maximum performance; extracting relevant schema reduces prompt size but risks missing necessary information
- Failure signatures: Incorrect entity linking leads to wrong schema extraction; insufficient training data leads to poor generalization; CoT verification threshold too strict/loose affects data quality
- First 3 experiments:
  1. Generate NL-GQL pairs using self-instruct with varying CoT verification thresholds (0.7, 0.8, 0.9) and measure consistency rates
  2. Compare inference accuracy with full schema vs. relevant schema vs. no schema context on a small test set
  3. Fine-tune base LLM with different proportions of NL-GQL pairs (10%, 50%, 100%) and measure performance on dev set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the two-step self-instruct approach with CoT verification affect the quality and diversity of generated NL-GQL pairs compared to single-step generation?
- Basis in paper: [explicit] The paper describes a two-step process where ChatGPT first generates NL-GQL pairs, then CoT-based GQL2NL verifies consistency between NL and GQL
- Why unresolved: While the paper claims this improves quality, it doesn't provide direct comparisons between single-step and two-step generation methods
- What evidence would resolve it: Controlled experiments comparing single-step vs two-step generation approaches on the same datasets with quantitative quality metrics

### Open Question 2
- Question: What is the optimal balance between relevant schema inclusion and inference speed for different model sizes?
- Basis in paper: [inferred] The paper mentions relevant schema improves accuracy but increases inference time slightly, while full schema significantly increases time
- Why unresolved: The paper doesn't explore how different amounts of schema context affect various model sizes or identify specific thresholds
- What evidence would resolve it: Systematic experiments varying schema amounts across different model sizes with corresponding accuracy and timing measurements

### Open Question 3
- Question: How generalizable is the proposed method to graph databases with significantly different schema structures or more complex relationships?
- Basis in paper: [explicit] The method was tested on finance and medical domains with specific schema types and properties
- Why unresolved: The paper doesn't explore performance on graph databases with different structural characteristics or relationship complexities
- What evidence would resolve it: Experiments applying the method to diverse graph database types (e.g., social networks, knowledge graphs) with varying structural complexity

## Limitations
- Dataset composition: The exact number of training examples and their distribution across query types is unclear
- Verification mechanism effectiveness: Limited quantitative evidence of how many inconsistent pairs were filtered out
- Generalizability: Evaluation limited to two domain-specific datasets (finance and medicine)

## Confidence

- **High confidence**: The overall framework design (self-instruct generation, LoRA fine-tuning, schema extraction) is technically sound and follows established practices in the field
- **Medium confidence**: The reported quantitative improvements are significant but may be influenced by dataset composition and hyperparameter choices that aren't fully specified
- **Low confidence**: The effectiveness of the CoT verification mechanism and the quality of the generated training data cannot be independently assessed without more details

## Next Checks

1. **Dataset analysis**: Request the exact number of NL-GQL pairs generated for each query type and domain, and conduct ablation studies to isolate the contribution of data generation vs. fine-tuning

2. **Verification mechanism validation**: Implement the CoT verification step independently and measure the consistency rate of generated pairs before and after verification, along with qualitative analysis of rejected pairs

3. **Cross-domain generalization**: Apply the trained models to a held-out domain (e.g., academic publications or social networks) and measure performance degradation to assess the method's robustness to schema variations