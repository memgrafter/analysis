---
ver: rpa2
title: Using Degeneracy in the Loss Landscape for Mechanistic Interpretability
arxiv_id: '2405.10927'
source_url: https://arxiv.org/abs/2405.10927
tags:
- loss
- network
- lfinal
- layer
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates degeneracy in neural networks and proposes
  methods to exploit it for mechanistic interpretability. It introduces the concept
  of the effective parameter count, which quantifies the number of computationally-relevant
  parameters in a network by considering degeneracies in the loss landscape.
---

# Using Degeneracy in the Loss Landscape for Mechanistic Interpretability

## Quick Facts
- arXiv ID: 2405.10927
- Source URL: https://arxiv.org/abs/2405.10927
- Authors: Lucius Bushnaq; Jake Mendel; Stefan Heimersheim; Dan Braun; Nicholas Goldowsky-Dill; Kaarel Hänni; Cindy Wu; Marius Hobbhahn
- Reference count: 25
- Primary result: Introduces effective parameter count and Interaction Basis to exploit degeneracies for mechanistic interpretability

## Executive Summary
This paper investigates degeneracy in neural networks and proposes methods to exploit it for mechanistic interpretability. The authors introduce the concept of effective parameter count, which quantifies the number of computationally-relevant parameters by considering degeneracies in the loss landscape. They identify three sources of degeneracy—linear dependence between activations, linear dependence between gradients, and synchronized nonlinearities—and develop the Interaction Basis technique to obtain a representation invariant to these degeneracies, resulting in sparser interactions that are more interpretable.

## Method Summary
The authors propose a method to quantify degeneracy through the effective parameter count, which considers the true dimensionality of the loss landscape rather than nominal parameter count. They develop the Interaction Basis by diagonalizing Gram matrices of activations and Jacobians to find coordinate transformations that eliminate degenerate parameters. The method involves computing these matrices for each layer, finding their eigendecompositions, and transforming the network to this new basis. This transformation reveals a sparser interaction graph that is more amenable to interpretability analysis, particularly for modular networks which the authors argue are more degenerate.

## Key Results
- Introduces effective parameter count (Neff) as a measure of computationally-relevant parameters accounting for degeneracies
- Develops Interaction Basis technique that sparsifies interactions by exploiting degeneracy in activations and Jacobians
- Provides heuristic argument that modular networks are more degenerate and proposes modularity metrics based on this connection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low-dimensional activation spaces create free parameters that can be exploited for a sparser representation.
- Mechanism: When activation vectors in a layer span a low-dimensional subspace, the weight matrices connecting to that layer have redundant degrees of freedom. By transforming to a basis aligned with the principal components of the activations, these redundant parameters can be set to zero, eliminating connections in the interaction graph.
- Core assumption: The loss landscape around the trained network is locally quadratic in the directions corresponding to the redundant parameters.
- Evidence anchors:
  - [abstract] "We identify 3 ways that network parameters can be degenerate: linear dependence between activations in a layer..."
  - [section] "If there is linear dependence between the activations on the dataset, some of the singular values (eigenvalues of Gl) will be zero... For every degree of linear dependence we may have had in layer 1, we now have d(2) weights set to zero"
  - [corpus] Weak evidence - related work discusses degeneracy but not the specific mechanism of exploiting low-rank activations for sparsity.
- Break condition: If the network has not converged to a local minimum, or if the loss landscape has significant higher-order terms in the directions of the redundant parameters, the assumption of local quadratic behavior fails.

### Mechanism 2
- Claim: Synchronized neurons (neurons with identical firing patterns) create additional free parameters that can be used to sparsify interactions.
- Mechanism: When neurons in a layer fire on the same subset of data points, their pre-activations are linearly dependent. This allows for a coordinate transformation that sets certain weights to zero, eliminating interactions between the synchronized neurons and other parts of the network.
- Core assumption: Neuron synchronization is a common phenomenon in trained networks, and the degree of synchronization can be quantified.
- Evidence anchors:
  - [abstract] "ReLUs which fire on the same subset of datapoints" is listed as a source of degeneracy.
  - [section] "In a dense layer with piecewise linear activation functions (ReLU or LeakyReLU), the effective parameter count is reduced if two neurons have the same set of data points for which they are 'on' and 'off'... For each pair of synchronized neurons... we can set a pair of off-diagonal entries Ck,k′, Ck′,k in C to arbitrary positive values"
  - [corpus] Weak evidence - related work discusses modularity but not the specific mechanism of exploiting synchronized neurons for sparsity.
- Break condition: If neuron synchronization is rare or the degree of synchronization is very small, the potential for sparsifying interactions through this mechanism is limited.

### Mechanism 3
- Claim: Modular networks are more degenerate and thus have lower effective parameter counts, making them easier to interpret.
- Mechanism: If modules in a network interact less (i.e., the network is more modular), their degeneracies are independent, leading to a higher total degeneracy and a lower effective parameter count. This is because degeneracies within each module do not interact with degeneracies in other modules.
- Core assumption: Real neural networks have modular structures, and the degree of modularity can be quantified.
- Evidence anchors:
  - [abstract] "We also present a heuristic argument that modular networks are likely to be more degenerate, and we develop a metric for identifying modules in a network that is based on this argument."
  - [section] "We argue that if modules in a network interact less (i.e the network is more modular) this yields a higher total degeneracy and thus a lower LLC... Therefore, networks which have non- or weakly- interacting modules typically have more degeneracy and thus a lower LLC, which means that neural networks are biased towards solutions which are modular."
  - [corpus] Weak evidence - related work discusses modularity but not the specific mechanism of how modularity affects degeneracy.
- Break condition: If the assumption that modular networks have lower effective parameter counts is incorrect, or if real neural networks do not have low-loss modular solutions, this mechanism fails.

## Foundational Learning

- Concept: Singular Learning Theory (SLT)
  - Why needed here: SLT provides the theoretical foundation for understanding degeneracy in neural networks and how it relates to generalization and interpretability.
  - Quick check question: What is the local learning coefficient (LLC) in SLT, and how does it quantify degeneracy in the loss landscape?

- Concept: Effective Parameter Count
  - Why needed here: The effective parameter count is a measure of the number of computationally-relevant parameters in a network, which is crucial for understanding the impact of degeneracy on interpretability.
  - Quick check question: How is the effective parameter count related to the local learning coefficient, and why is it a more useful metric than the nominal parameter count for interpretability?

- Concept: Interaction Basis
  - Why needed here: The interaction basis is a technique for representing a neural network in a way that is invariant to reparameterizations that exploit degeneracies, which is the core contribution of this paper.
  - Quick check question: How does the interaction basis exploit degeneracies in activations and Jacobians to sparsify interactions between layers?

## Architecture Onboarding

- Component map: Input -> Hidden layers (with activations and Jacobians) -> Output layer -> Interaction Basis transformation -> Sparsified interaction graph
- Critical path:
  1. Train a neural network on a task
  2. Compute the Gram matrices of activations and Jacobians for each layer
  3. Diagonalize these matrices to find the interaction basis
  4. Transform the network to the interaction basis
  5. Analyze the sparsified interaction graph for interpretability
- Design tradeoffs:
  - The interaction basis is only invariant to linear transformations, not nonlinear ones
  - The basis may not perfectly diagonalize interactions in all cases, especially for deep networks
  - The computational cost of finding the interaction basis may be high for large networks
- Failure signatures:
  - If the network has not converged to a local minimum, the interaction basis may not be well-defined
  - If the network has very high-dimensional activations or Jacobians, the interaction basis may not lead to significant sparsity
  - If the network is not modular, the interaction basis may not reveal interpretable structures
- First 3 experiments:
  1. Apply the interaction basis to a simple linear network and verify that it diagonalizes the weight matrices
  2. Apply the interaction basis to a ReLU network with synchronized neurons and verify that it sparsifies interactions
  3. Apply the interaction basis to a modular network and verify that it reveals the modular structure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we choose an appropriate cutoff for the behavioral loss in finite data SLT?
- Basis in paper: [explicit]
- Why unresolved: The paper mentions that choosing an appropriate cutoff is an open problem, and suggests that researchers might choose the value based on the specific question they want to answer, such as the variance between different training seeds. However, it doesn't provide a concrete method for determining this cutoff.
- What evidence would resolve it: Developing a principled method for determining the behavioral loss cutoff, perhaps based on statistical properties of the network's performance or the specific task at hand.

### Open Question 2
- Question: Are there additional sources of degeneracy in neural networks beyond the three identified in the paper?
- Basis in paper: [inferred]
- Why unresolved: The paper acknowledges that the three sources of degeneracy (linear dependence between activations, linear dependence between gradients, and synchronized nonlinearities) are likely not a complete account of all degeneracy in real networks. It calls them a "starting point" for relating degeneracy to computational structure.
- What evidence would resolve it: Identifying and characterizing additional sources of degeneracy in neural networks through empirical studies or theoretical analysis.

### Open Question 3
- Question: How can we develop a practical technique for selecting a basis that sparsifies interactions without the assumptions made in the Interaction Basis?
- Basis in paper: [explicit]
- Why unresolved: The paper introduces the Interaction Basis as a technique to sparsify interactions, but acknowledges that it relies on simplifying assumptions about the independence of activations and Jacobians. It suggests that future work might investigate alternative techniques without these assumptions.
- What evidence would resolve it: Developing and testing new techniques for selecting a basis that sparsifies interactions, perhaps leveraging overcomplete bases or alternative mathematical frameworks.

## Limitations

- The Interaction Basis is only invariant to linear transformations, potentially missing important nonlinear degeneracies
- Empirical validation across diverse architectures and tasks remains limited
- The heuristic argument connecting modularity to degeneracy lacks rigorous proof

## Confidence

- Effective parameter count and degeneracy identification: High confidence
- Interaction Basis utility for interpretability: Medium confidence
- Modular networks being more degenerate: Medium confidence

## Next Checks

1. **Ablation study on basis choice**: Systematically compare the Interaction Basis against alternative transformation methods (e.g., random orthogonal transformations) to quantify the specific contribution of degeneracy-aware transformations to interpretability gains.

2. **Generalization across architectures**: Apply the Interaction Basis to transformer architectures and other modern deep learning models to test whether the identified degeneracies and sparsity benefits extend beyond MLPs.

3. **Quantitative interpretability metrics**: Develop and apply quantitative metrics for interpretability (beyond qualitative inspection) to measure whether the sparser interaction graphs produced by the Interaction Basis actually improve human understanding of network behavior.