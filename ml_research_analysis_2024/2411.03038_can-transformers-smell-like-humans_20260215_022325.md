---
ver: rpa2
title: Can Transformers Smell Like Humans?
arxiv_id: '2411.03038'
source_url: https://arxiv.org/abs/2411.03038
tags:
- uni0000011e
- uni00000102
- uni0000015d
- uni0000018c
- uni0000019a
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether representations learned by transformers
  trained on chemical structures align with human olfactory perception. The authors
  use MoLFormer, a self-supervised transformer model pre-trained on chemical structures,
  to encode representations of odorants and evaluate their alignment with human perceptual
  data.
---

# Can Transformers Smell Like Humans?

## Quick Facts
- arXiv ID: 2411.03038
- Source URL: https://arxiv.org/abs/2411.03038
- Reference count: 40
- Primary result: MoLFormer transformer representations of odorant chemical structures align with human olfactory perception across multiple perceptual tasks

## Executive Summary
This paper investigates whether transformer models trained on chemical structures can capture representations that align with human olfactory perception. The authors use MoLFormer, a self-supervised transformer pre-trained on general chemical structures, to encode odorant representations and evaluate their alignment with human perceptual data across three datasets. They demonstrate that MoLFormer can predict expert-assigned labels, continuous perceptual ratings, and similarity ratings between odorants, despite not being explicitly trained for these tasks. The results show high alignment with perceptual similarity ratings and physicochemical descriptors, suggesting that transformer models can capture meaningful representations of olfactory perception from chemical structures alone.

## Method Summary
The study uses MoLFormer, a self-supervised transformer model pre-trained on chemical structures, to encode representations of odorants. The model takes SMILES strings as input and produces 768-dimensional embeddings from the last layer. For mixture compounds (MC-odorants), representations are averaged across component molecules. The authors evaluate alignment with human perception through three tasks: predicting expert-assigned labels (GS-LF dataset), predicting continuous perceptual ratings (Sagar and Keller datasets), and predicting similarity ratings between odorant pairs (Ravia and Snitz datasets). Linear models (logistic regression and Lasso regression) are trained with 5-fold cross-validation and 30 train-test splits using 80%-20% splits.

## Key Results
- MoLFormer successfully predicts expert-assigned labels with micro-averaged ROC-AUC across multiple descriptors
- The model demonstrates high alignment in predicting continuous perceptual ratings, outperforming or matching the Open-POM model
- MoLFormer shows strong correlation with human perceptual similarity ratings between odorant pairs
- Representational alignment improves with increasing layer depth, with deeper layers showing better alignment with high-level perceptual representations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: MoLFormer's pre-trained representations capture latent chemical-to-perceptual mappings without explicit olfactory supervision.
- **Mechanism**: The transformer's self-supervised training on diverse chemical structures induces a high-dimensional latent space that implicitly encodes physicochemical properties relevant to smell. These properties correlate with human perceptual dimensions (e.g., similarity, descriptors), allowing linear mapping to human perceptual ratings.
- **Core assumption**: The chemical space learned by MoLFormer preserves relevant physicochemical features (e.g., molecular weight, functional groups) that humans use to judge olfactory similarity and descriptors.
- **Evidence anchors**:
  - "representations encoded from transformers pre-trained on general chemical structures are highly aligned with human olfactory perception."
  - "MoLformer demonstrates a high degree of alignment in predicting these values. Out of the 15 physicochemical descriptors, MoLformer successfully predicts the values for 13 descriptors as well as or better than the Open-POM model."
- **Break condition**: If MoLFormer's latent space collapses to purely syntactic chemical features unrelated to perceptual dimensions, or if key physicochemical features for smell are not preserved in early layers.

### Mechanism 2
- **Claim**: The alignment improves with model depth because deeper layers extract abstract, high-level perceptual features from chemical structures.
- **Mechanism**: Lower transformer layers encode low-level chemical patterns (e.g., atom types, bonds), while higher layers aggregate these into abstract representations that correlate with human-perceived similarity. This mirrors the hierarchy seen in vision models (edges → shapes → objects).
- **Core assumption**: There is a meaningful hierarchical progression in the transformer that mirrors the abstraction from chemical detail to perceptual relevance.
- **Evidence anchors**:
  - "representational alignment improves with increasing layer depth, indicating that deeper layers of the transformer are more aligned with high-level perceptual representations."
  - "as we go through the layers, we observe a decrease in alignment with physicochemical descriptors despite an increase in alignment with perception."
- **Break condition**: If layer-wise alignment does not improve monotonically, or if shallow layers unexpectedly outperform deeper layers for perceptual tasks.

### Mechanism 3
- **Claim**: MoLFormer's high alignment is partly due to its coverage of physicochemical descriptors known to be relevant for smell, even though it is not trained to predict them.
- **Mechanism**: The transformer's pretraining objective (masked token prediction) encourages learning a broad, generalizable chemical representation space. This space preserves features that map well to both physicochemical descriptors (used in DAM) and human perceptual ratings.
- **Core assumption**: Masked token prediction on chemical structures yields representations that span the relevant physicochemical subspace for olfaction.
- **Evidence anchors**:
  - "Finally, we evaluate the extent to which this alignment is associated with physicochemical features of odorants known to be relevant for olfactory decoding."
  - "MoLformer demonstrates a high degree of alignment in predicting these values. Out of the 15 physicochemical descriptors, MoLformer successfully predicts the values for 13 descriptors as well as or better than the Open-POM model."
- **Break condition**: If MoLFormer's pretraining does not preserve the specific physicochemical descriptors critical for smell, or if the mapping to perception requires nonlinear transformations beyond linear models.

## Foundational Learning

- **Concept**: Chemical structure encoding via SMILES and transformer tokenization
  - **Why needed here**: The paper relies on converting molecular structures into tokenized input for MoLFormer; understanding SMILES syntax and tokenization is essential for reproducing the encoding pipeline.
  - **Quick check question**: Given the SMILES string "CC(=O)O", what are the token boundaries when fed to MoLFormer?

- **Concept**: Linear mapping and evaluation metrics (Pearson correlation, NRMSE)
  - **Why needed here**: The study uses linear regression to map chemical representations to perceptual ratings; knowing how to interpret correlation vs. NRMSE is crucial for assessing model performance.
  - **Quick check question**: If predicted ratings have a Pearson correlation of 0.25 with true ratings, what does this imply about the linear model's alignment?

- **Concept**: Representational similarity analysis (RSA) and cosine similarity
  - **Why needed here**: RSA is used to compare odorant similarity matrices from humans and models; understanding cosine similarity computation between high-dimensional vectors is necessary for replicating the analysis.
  - **Quick check question**: If two odorants have cosine similarity 0.8 in MoLFormer space but 0.4 in human ratings, what does this say about the model's alignment?

## Architecture Onboarding

- **Component map**: SMILES strings -> MoLFormer encoding -> Linear model training -> Evaluation
- **Critical path**: SMILES → MoLFormer encoding → linear model training → evaluation
- **Design tradeoffs**:
  - Using a general-purpose transformer (MoLFormer) vs. a supervised model (Open-POM): trade-off between generalization and task-specific performance.
  - Linear mapping vs. nonlinear models: linear models are interpretable but may underfit complex perceptual mappings.
- **Failure signatures**:
  - Poor correlation with perceptual ratings despite high alignment with physicochemical descriptors → misalignment between chemical features and human perception.
  - Degradation of alignment in deeper layers → loss of relevant perceptual information in high-level abstractions.
  - High variance across train-test splits → instability in linear mapping or limited sample size.
- **First 3 experiments**:
  1. Encode a small set of odorants with MoLFormer and visualize the 768-dim vectors via PCA; check for clustering by known descriptors.
  2. Train a simple logistic regression on GS-LF labels using MoLFormer encodings; report ROC-AUC per descriptor.
  3. Compute pairwise cosine similarities for a held-out odorant set and correlate with human similarity ratings from Ravia/Snitz datasets.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the depth of MoLFormer layers affect the alignment with human olfactory perception?
- **Basis in paper**: [explicit] The paper discusses that representational alignment improves with increasing layer depth.
- **Why unresolved**: While the paper shows that alignment improves with depth, it does not provide a detailed analysis of how each layer contributes to this alignment or what specific features are extracted at different depths.
- **What evidence would resolve it**: A detailed analysis of feature extraction at each layer, showing the types of features that become more aligned with human perception as depth increases.

### Open Question 2
- **Question**: Can the intensity or concentration of individual molecules within a mixture be incorporated to improve alignment?
- **Basis in paper**: [inferred] The paper mentions that current work does not consider the intensity or concentration of molecules within a mixture.
- **Why unresolved**: The paper does not explore how incorporating intensity or concentration might affect the model's ability to predict human olfactory perception.
- **What evidence would resolve it**: Experiments that incorporate intensity or concentration data into the model and compare the results with the current approach.

### Open Question 3
- **Question**: How does the variability in human participants' ratings affect the alignment of the model?
- **Basis in paper**: [explicit] The paper notes that datasets with average continuous ratings from human participants present more challenges due to variability among non-expert participants' ratings.
- **Why unresolved**: The paper does not analyze the impact of this variability on the model's performance or explore methods to mitigate it.
- **What evidence would resolve it**: An analysis of how individual participant variability affects the model's predictions and the development of methods to account for this variability.

## Limitations

- The mechanistic explanation remains largely correlational rather than causal, with unclear pathway from chemical structure to human perception
- Reliance on linear mapping models may underestimate the complexity of olfactory perception mapping
- Self-supervised pretraining objective may capture general chemical structure information that happens to correlate with human perception rather than domain-specific olfactory features

## Confidence

- **High confidence**: Empirical alignment results (MoLFormer predictions correlate with human ratings across multiple datasets and tasks)
- **Medium confidence**: Mechanism explanations (self-supervised pretraining captures relevant chemical features; deeper layers extract more abstract perceptual information)
- **Low confidence**: Claims about generality of approach for olfactory modeling without further validation on diverse chemical spaces and perceptual dimensions

## Next Checks

1. Conduct ablation studies removing specific physicochemical descriptors from the representation space to identify which features are most critical for perceptual alignment
2. Test the model's generalization to chemically novel odorants not well-represented in the training chemical space
3. Compare MoLFormer's alignment with human perception against other transformer architectures trained on different chemical prediction tasks to isolate what aspects of pretraining matter most