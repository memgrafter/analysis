---
ver: rpa2
title: Knowledge Graph-based Session Recommendation with Adaptive Propagation
arxiv_id: '2402.11302'
source_url: https://arxiv.org/abs/2402.11302
tags:
- item
- session
- graph
- items
- sessions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a session-based recommendation framework
  that leverages knowledge graphs with session-adaptive propagation to enhance recommendation
  performance. By constructing a knowledge graph with multi-typed edges (co-view,
  co-add-to-cart, and co-view-add-to-cart) and implementing session-adaptive propagation,
  the framework dynamically aggregates neighbor information based on session context,
  addressing the limitations of existing models that either ignore session context
  or use a single interaction type.
---

# Knowledge Graph-based Session Recommendation with Adaptive Propagation

## Quick Facts
- arXiv ID: 2402.11302
- Source URL: https://arxiv.org/abs/2402.11302
- Reference count: 40
- Primary result: Improves session-based recommendation by 10%-20% over baselines by leveraging knowledge graphs with session-adaptive propagation

## Executive Summary
This paper introduces a novel session-based recommendation framework that leverages knowledge graphs with session-adaptive propagation to enhance recommendation performance. The framework constructs a knowledge graph with multi-typed edges (co-view, co-add-to-cart, and co-view-add-to-cart) and implements session-adaptive propagation to dynamically aggregate neighbor information based on session context. By addressing the limitations of existing models that either ignore session context or use a single interaction type, the proposed method demonstrates significant performance gains of 10%-20% over three representative backbones (GRU4Rec, SASRec, and KGHT) across multiple datasets.

## Method Summary
The framework constructs a knowledge graph from historical session data with three types of edges: co-view, co-add-to-cart, and co-view-add-to-cart. Item embeddings are initialized using various meta-attributes (title, category, price, etc.). For each session, the model generates contextual embeddings using a transformer, then performs session-adaptive GNN message passing where the contextual embeddings guide neighbor aggregation. The aggregated embeddings are fed into a second transformer to predict the next item. The entire framework is optimized end-to-end using cross-entropy loss, allowing the model to capture both global item relationships and session-specific intentions.

## Key Results
- Improves upon three representative backbones (GRU4Rec, SASRec, and KGHT) by 10%-20% on NDCG@10 and MRR@10 metrics
- Industrial case study with The Home Depot shows 2% improvement over a well-deployed model
- Effectively captures global transitional patterns and adapts to session-specific intentions
- Demonstrates consistent performance across multiple datasets (Diginetica, Yoochoose 1/64, and THD)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework improves recommendation performance by 10%-20% by adaptively aggregating neighbor information based on session context.
- Mechanism: Session-adaptive propagation dynamically adjusts the attention coefficients for neighbor items based on the contextual embedding of the current session, allowing the model to prioritize relevant neighbors that align with the session's unique intention.
- Core assumption: The contextual embedding derived from the transformer model accurately captures the session's intention and can be used to differentiate between relevant and irrelevant neighbors for each item.
- Evidence anchors:
  - [abstract]: "The proposed method improves upon three representative backbones (GRU4Rec, SASRec, and KGHT) by 10%-20%, demonstrating significant performance gains."
  - [section 3.2]: "With the contextual embedding cáµ¢áµ as the query, inspired by [11], we perform heterogeneous graph transformer-based propagation to adaptively aggregate ð‘£áµ¢'s neighbors' information relevant to the current session intention."
- Break condition: If the contextual embedding fails to accurately represent the session intention, or if the attention mechanism becomes too uniform across neighbors, the adaptive propagation will not provide meaningful differentiation.

### Mechanism 2
- Claim: Multi-typed edges in the knowledge graph capture diverse user-item interactions, leading to better recommendations.
- Mechanism: By constructing edges for co-view, co-add-to-cart, and co-view-add-to-cart interactions, the framework can distinguish between substitution and complementary item relationships, which are captured through different edge types and aggregated accordingly.
- Core assumption: Different types of user-item interactions (e.g., viewing vs. adding to cart) represent distinct relationships between items that should be modeled separately rather than uniformly.
- Evidence anchors:
  - [abstract]: "By constructing a knowledge graph with multi-typed edges (co-view, co-add-to-cart, and co-view-add-to-cart) and implementing session-adaptive propagation, the framework dynamically aggregates neighbor information based on session context."
  - [section 3.1]: "As items typically exhibit two types of correlations, substitution and complementary [44], we extract three distinct types of edges, as depicted in Figure 2(a)-(c), by examining whether two items co-occur within the same session: co-view, co-ATC, and co-view-ATC edges."
- Break condition: If the distinction between interaction types becomes less meaningful in certain domains, or if the model cannot effectively differentiate between the edge types during aggregation, the benefit of multi-typed edges will diminish.

### Mechanism 3
- Claim: The session-adaptive propagation learns different attention weights for the same item in different sessions, improving personalization.
- Mechanism: The same item can have different contextual embeddings in different sessions, leading to different attention coefficients when aggregating neighbors, which allows the model to capture session-specific intentions even for identical items.
- Core assumption: The same item can have different meanings or intentions in different sessions, and the model can learn to capture these differences through contextual embeddings and adaptive attention.
- Evidence anchors:
  - [abstract]: "By our proposed session-adaptive propagation, the flower aggregates more information from the lopper/watering can in (b) while more information from the sink/table in (c)."
  - [section 3.2]: "Since different session contexts provide different contextual embeddings cáµ¢áµ â‰  cáµ¢áµ', the calculated attention coefficients would also be different, i.e., Î±â‚•,â‚—,â‚œ,â‚˜áµ¢â†â±¼ â‰  Î±â‚•,â‚—,â‚œ,â‚˜'áµ¢â†â±¼."
  - [section 4.7.2]: "We further visualize the graph attention learned by our session-adaptive propagation in Figure 4(b)-(c). Clearly, users generating these two sequences (b)-(c) intend to clean their own gardens and successfully, the model learns to aggregate less information from irrelevant neighbors."
- Break condition: If the model fails to learn meaningful contextual differences between sessions, or if the attention mechanism becomes too rigid, the personalization benefit will be lost.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their message-passing mechanism
  - Why needed here: The framework uses GNNs to aggregate information from neighboring items in the knowledge graph, which is fundamental to understanding how the model captures global item relationships.
  - Quick check question: Can you explain how message passing in GNNs differs from traditional neural network operations, and why it's particularly suited for graph-structured data?

- Concept: Transformer architecture and self-attention
  - Why needed here: The framework uses transformers to capture session context and generate contextual embeddings, which are then used to guide the GNN's message passing. Understanding transformers is crucial for grasping how session information is encoded.
  - Quick check question: How does self-attention in transformers allow for modeling long-range dependencies in sequential data, and why is this important for session-based recommendation?

- Concept: Heterogeneous graph representation learning
  - Why needed here: The knowledge graph contains multiple types of edges, requiring the model to handle different relationship types. Understanding heterogeneous graph learning is essential for grasping how the model differentiates between edge types during aggregation.
  - Quick check question: What challenges arise when learning representations from heterogeneous graphs compared to homogeneous graphs, and how does the framework address these challenges?

## Architecture Onboarding

- Component map:
  - Item Knowledge Graph (co-view, co-ATC, co-view-ATC edges) -> Session-Adaptive Propagation Layer (transformer-generated contextual embeddings guide GNN message passing) -> Prediction Model (transformer-based model that predicts next item)

- Critical path:
  1. Construct knowledge graph from historical session data
  2. Initialize item embeddings using meta-attributes
  3. For each session:
     a. Generate contextual embeddings using first transformer
     b. Perform session-adaptive GNN message passing
     c. Feed aggregated embeddings into second transformer
     d. Predict next item using cross-entropy loss
  4. Optimize entire framework end-to-end

- Design tradeoffs:
  - GNN vs. pure transformer: GNNs capture global item relationships but may struggle with session context; transformers capture session context but miss global patterns
  - Multi-typed edges vs. single edge type: More expressive but increases complexity; single edge type simpler but may miss important relationship distinctions
  - Session-adaptive vs. static propagation: More personalized but requires additional computation; static simpler but may not capture session-specific intentions

- Failure signatures:
  - Poor performance on sessions with cold-start items: May indicate issues with meta-attribute embedding or insufficient neighbor information
  - Over-smoothing in GNN layers: May manifest as similar embeddings for diverse items, suggesting too many propagation layers or insufficient edge differentiation
  - Attention collapse: If attention coefficients become too uniform across neighbors, may indicate issues with contextual embedding quality or GNN architecture

- First 3 experiments:
  1. Ablation study: Remove session-adaptive propagation and compare performance to full model to quantify the benefit of adaptive neighbor selection
  2. Edge type analysis: Remove each edge type (co-view, co-ATC, co-view-ATC) individually and measure performance impact to understand which relationships are most valuable
  3. Sparsity analysis: Group sessions by average item sparsity and measure performance differences to understand how well the model handles sessions with varying levels of global connectivity

## Open Questions the Paper Calls Out
The paper mentions considering other node types (e.g., users) as future work but does not explicitly call out specific open questions. The limitations section discusses the need for further exploration of the framework's scalability and performance on datasets with different characteristics.

## Limitations
- Effectiveness of session-adaptive propagation depends heavily on the quality of contextual embeddings, which may struggle with highly diverse or ambiguous session intentions
- Multi-typed edge approach assumes clear distinctions between interaction types across domains, which may not generalize well to datasets with different user behavior patterns
- Model's performance on extremely long sessions or sessions with high item turnover remains unexplored

## Confidence
- Performance improvement claims (10%-20% over baselines): Medium confidence - results are reported on three datasets but lack statistical significance testing
- Session-adaptive propagation mechanism: Medium confidence - theoretical justification is sound but limited empirical validation of the mechanism itself
- Industrial case study results: Low confidence - limited details provided about implementation and comparison conditions

## Next Checks
1. Conduct statistical significance testing across all reported improvements to verify the robustness of the performance gains
2. Perform ablation studies isolating the impact of each edge type and the session-adaptive mechanism to quantify their individual contributions
3. Test the framework on additional datasets with different domain characteristics to evaluate generalizability beyond the current e-commerce focus