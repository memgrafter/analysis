---
ver: rpa2
title: 'Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box
  Models'
arxiv_id: '2408.03636'
source_url: https://arxiv.org/abs/2408.03636
tags:
- methods
- time-frequency
- time-series
- time
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SpectralX, a framework for explaining black-box
  time-series classifiers using time-frequency analysis. Unlike existing methods that
  focus solely on time-domain features, SpectralX leverages both time and frequency
  components by applying Short-Time Fourier Transform (STFT) and perturbation-based
  XAI methods.
---

# Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models

## Quick Facts
- arXiv ID: 2408.03636
- Source URL: https://arxiv.org/abs/2408.03636
- Reference count: 40
- Introduces SpectralX, a framework for explaining black-box time-series classifiers using time-frequency analysis with improved explanation quality metrics

## Executive Summary
This paper addresses the challenge of explaining black-box time-series classifiers by introducing SpectralX, a novel framework that leverages time-frequency analysis through Short-Time Fourier Transform (STFT) combined with perturbation-based XAI methods. Unlike traditional approaches that focus solely on time-domain features, SpectralX captures both temporal and spectral characteristics of time-series data, providing more comprehensive explanations for model predictions.

The authors propose Feature Importance Approximations (FIA) that outperform existing methods like LIME and KernelSHAP, achieving better faithfulness scores and demonstrating superior performance in human evaluations. The framework is validated across multiple synthetic and real-world UCR time-series datasets, showing consistent improvements in explanation quality while maintaining a flexible plug-and-play architecture compatible with various model architectures.

## Method Summary
SpectralX introduces a time-frequency explanation framework that combines Short-Time Fourier Transform with perturbation-based XAI techniques to explain black-box time-series classifiers. The method transforms time-series data into the time-frequency domain using STFT, then applies existing perturbation methods (LIME, SHAP, RISE) to generate explanations. A key innovation is the Feature Importance Approximations (FIA) approach, which includes insertion, deletion, and combined methods for determining important features. The framework supports various classifier architectures including LSTM, CNN, and Transformer models through a modular design. Evaluation demonstrates superior performance compared to existing methods, with the combined FIA method achieving 46.6% rank-1 preference in human evaluations across seven datasets and 19 classes.

## Key Results
- FIA achieves 0.154 average Faithfulness score in time-frequency domain, outperforming LIME (0.146) and KernelSHAP (0.128)
- Combined FIA method shows 46.6% rank-1 preference in human evaluation across seven datasets and 19 classes
- Framework demonstrates consistent improvements across both synthetic and real-world UCR time-series datasets
- Plug-and-play architecture successfully supports LSTM, CNN, and Transformer classifiers with various perturbation techniques

## Why This Works (Mechanism)
The effectiveness of SpectralX stems from its ability to capture both temporal and spectral patterns in time-series data, which traditional time-domain methods miss. By applying STFT, the framework transforms time-series into a time-frequency representation that reveals periodic patterns, transient events, and frequency-specific behaviors that are crucial for understanding model decisions. This dual-domain analysis provides more comprehensive feature importance assessments compared to single-domain approaches. The perturbation-based XAI methods applied in this transformed space can better identify which specific time-frequency components drive model predictions, leading to more accurate and interpretable explanations that align with human understanding of time-series patterns.

## Foundational Learning

**Short-Time Fourier Transform (STFT)** - Time-frequency analysis technique that divides signals into short segments and applies Fourier transform to each segment, revealing how frequency content changes over time. Why needed: Essential for capturing both temporal and spectral characteristics of time-series data. Quick check: Verify STFT parameters (window size, overlap) are appropriate for the specific time-series characteristics.

**Perturbation-based XAI Methods** - Techniques like LIME, SHAP, and RISE that generate explanations by systematically perturbing input features and observing model output changes. Why needed: Provides model-agnostic approach to feature importance estimation without requiring model internals. Quick check: Ensure perturbation methods preserve the statistical properties of time-series data during feature masking.

**Faithfulness Metrics** - Quantitative measures of explanation quality that assess how well feature importance scores align with actual model behavior. Why needed: Enables objective comparison between different explanation methods and validation of their accuracy. Quick check: Compare faithfulness scores across multiple datasets and model architectures to ensure robustness.

**Human Evaluation Protocols** - Structured methods for assessing explanation quality through human judgment and preference studies. Why needed: Complements quantitative metrics with subjective assessment of explanation interpretability and usefulness. Quick check: Verify participant diversity and evaluation task design capture meaningful aspects of explanation quality.

## Architecture Onboarding

Component Map: Time-series data -> STFT transformation -> Perturbation module -> Black-box classifier -> Explanation output

Critical Path: Input data undergoes STFT → Perturbation-based feature masking → Classifier predictions → Feature importance calculation via FIA methods → Final explanation visualization

Design Tradeoffs: Time-frequency analysis increases computational complexity but provides richer explanations; plug-and-play architecture offers flexibility but requires careful integration with different perturbation methods; combined FIA methods improve accuracy but add implementation complexity.

Failure Signatures: Poor explanation quality may indicate inappropriate STFT parameters for the data characteristics, insufficient perturbation coverage in feature masking, or model architectures poorly suited to time-frequency analysis. Low faithfulness scores could suggest the classifier relies heavily on temporal dependencies that are lost during frequency transformation.

First Experiments:
1. Apply SpectralX to simple synthetic time-series datasets with known periodic patterns to verify time-frequency explanations capture expected features
2. Compare faithfulness scores of STFT-based explanations against time-domain only methods on benchmark datasets
3. Test framework compatibility with additional perturbation methods (e.g., KernelSHAP) to validate plug-and-play architecture claims

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation focused primarily on UCR time-series datasets, which may not represent complexity of real-world domains like healthcare or finance
- Human evaluation study sample size and participant demographics not specified, limiting generalizability of usability claims
- Comparative performance analysis could be affected by implementation-specific factors in perturbation techniques
- Real-world applicability assertions lack domain-specific validation for critical applications

## Confidence

High confidence in methodological innovation combining time-frequency analysis with XAI techniques, demonstrating clear technical advancement in time-series explanation methods.

Medium confidence in comparative performance claims due to limited dataset diversity, with primary evaluation on UCR datasets that may not capture real-world complexity.

Medium confidence in user study conclusions given unspecified sample characteristics and participant demographics that could affect result interpretation.

Low confidence in real-world applicability assertions without domain-specific validation for critical applications in healthcare, finance, and other high-stakes domains.

## Next Checks

1. Evaluate SpectralX on domain-specific time-series datasets from healthcare (ECG signals) and finance (stock market data) to assess cross-domain robustness and real-world applicability.

2. Conduct larger-scale human evaluation studies with diverse participant backgrounds and specified sample sizes to strengthen usability claims and validate explanation interpretability across different user groups.

3. Test framework compatibility with additional model architectures (e.g., Temporal Convolutional Networks, attention-based models) and perturbation methods to validate plug-and-play architecture claims and ensure broad applicability.