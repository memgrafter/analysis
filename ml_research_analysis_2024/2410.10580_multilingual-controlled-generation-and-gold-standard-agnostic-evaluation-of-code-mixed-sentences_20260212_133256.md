---
ver: rpa2
title: Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of
  Code-Mixed Sentences
arxiv_id: '2410.10580'
source_url: https://arxiv.org/abs/2410.10580
tags:
- english
- sentence
- code-mixed
- word
- hindi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Controlled Generation, a method for generating
  semantically equivalent code-mixed sentences by parameterizing the Code-Mixing Degree
  (CMD), allowing control over the degree of code-mixing. It also proposes GAME, a
  gold-standard-agnostic evaluation metric for code-mixed sentences that does not
  require human-annotated reference data.
---

# Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences

## Quick Facts
- arXiv ID: 2410.10580
- Source URL: https://arxiv.org/abs/2410.10580
- Reference count: 40
- Introduces Controlled Generation method with CMD parameterization and GAME evaluation metric for code-mixed sentences

## Executive Summary
This paper addresses the challenge of generating and evaluating code-mixed sentences by introducing two key contributions: Controlled Generation (CG) and GAME. CG allows generation of semantically equivalent code-mixed sentences by parameterizing the Code-Mixing Degree (CMD), enabling control over the degree of code-mixing. GAME is a gold-standard-agnostic evaluation metric that doesn't require reference code-mixed sentences, instead reconstructing English references from code-mixed text for evaluation. The authors release a dataset of 1506 gold-standard code-mixed sentences across four language pairs and demonstrate that GAME provides more consistent evaluation scores compared to BLEU, with significantly lower standard deviation for semantically equivalent sentences.

## Method Summary
The paper proposes Controlled Generation, which parameterizes code-mixing degree (CMD ∈ [0,1]) to generate semantically equivalent code-mixed sentences by replacing English words with matrix language words based on real-world frequency trends. The method uses LLM prompts to translate English sentences to matrix languages, identify replaceable words through POS tagging, and perform word replacements prioritizing higher frequency scores. GAME evaluates code-mixed sentences by detecting English words, translating them back to the reference language, reconstructing the English sentence, and computing semantic similarity between the reconstructed and reference sentences using the Universal Sentence Encoder. Both methods are implemented using Gemini Pro LLM, WordNet, Spacy, and Google Translate.

## Key Results
- GAME achieves average standard deviations of 7.94, 6.50, and 1.71 for Hinglish, English-Bengali, and English-Spanish test data respectively, compared to BLEU's 43.53, 25.41, and 24.84
- GAME scores for gold-standard sentences: 76.30 (English-Hindi), 88.35 (English-French), 84.39 (English-Spanish), 76.08 (English-Bengali)
- Controlled Generation successfully produces semantically equivalent code-mixed sentences across four language pairs with varying CMD values
- GAME demonstrates gold-standard-agnostic evaluation capability without requiring reference code-mixed sentences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Controlled Generation can generate semantically equivalent code-mixed sentences by parameterizing Code-Mixing Degree (CMD).
- Mechanism: CMD ∈ [0,1] controls the fraction of English words to be replaced with matrix language words based on real-world frequency trends.
- Core assumption: Lower frequency of a Hindi word in code-mixed data implies higher preference for its English counterpart.
- Evidence anchors:
  - [abstract] "Controlled Generation, which parameterizes the code-mixing degree (CMD) and enables the generation of multiple semantically equivalent code-mixed sentences"
  - [section 4] "According to the value of the CMD parameter, the fraction of words to be replaced is chosen from the list W, with higher scores s prioritized."
- Break condition: If real-world frequency data is unavailable or unrepresentative, the replacement strategy may produce unnatural code-mixing patterns.

### Mechanism 2
- Claim: GAME evaluates code-mixed sentences without requiring gold-standard code-mixed references.
- Mechanism: GAME reconstructs the English reference by translating detected English words in the code-mixed sentence, then compares semantic similarity between the reconstructed and reference sentences.
- Core assumption: If the code-mixed sentence accurately conveys the meaning of the English reference, its reconstruction will be semantically similar to the original reference.
- Evidence anchors:
  - [abstract] "GAME is both language-agnostic and gold-standard-agnostic, i.e. unlike other metrics, GAME does not require gold-standard code-mixed sentences for evaluation"
  - [section 5.1.2] "The score q returned by GAME is the semantic similarity between sr and sen"
- Break condition: If the translation/reconstruction process introduces significant errors, the semantic similarity score may not accurately reflect the quality of the code-mixed sentence.

### Mechanism 3
- Claim: GAME assigns more consistent scores to semantically equivalent code-mixed sentences compared to BLEU.
- Mechanism: GAME's semantic similarity measure is less sensitive to variations in n-gram overlap that arise from different code-mixing patterns.
- Core assumption: Semantically equivalent code-mixed sentences should receive similar scores regardless of their specific code-mixing patterns.
- Evidence anchors:
  - [abstract] "When used to evaluate semantically equivalent code-mixed sentences, we find that GAME scores have a lower standard deviation than BLEU scores"
  - [section 5.2.1] "Average standard deviations of GAME for Hinglish, English-Bengali and English-Spanish test data are 7.94, 6.50, and 1.71 respectively while for BLEU, these numbers are 43.53, 25.41 and 24.84"
- Break condition: If the semantic similarity measure is not robust to certain types of code-mixing variations, the consistency advantage over BLEU may not hold.

## Foundational Learning

- Concept: Code-mixing and its challenges