---
ver: rpa2
title: Artificial Agency and Large Language Models
arxiv_id: '2407.16190'
source_url: https://arxiv.org/abs/2407.16190
tags:
- agents
- agent
- what
- these
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a theoretical model to evaluate whether Large\
  \ Language Models (LLMs) can be considered genuine artificial agents. The model\
  \ defines agents as systems whose actions and goals are influenced by a dynamic\
  \ framework of factors\u2014accessible history, adaptive repertoire, and external\
  \ environment\u2014that reciprocally affect each other."
---

# Artificial Agency and Large Language Models

## Quick Facts
- arXiv ID: 2407.16190
- Source URL: https://arxiv.org/abs/2407.16190
- Authors: Maud van Lier; Gorka Muñoz-Gil
- Reference count: 1
- The paper introduces a theoretical model to evaluate whether Large Language Models (LLMs) can be considered genuine artificial agents.

## Executive Summary
This paper proposes a theoretical framework for evaluating whether Large Language Models can be considered genuine artificial agents. The authors define agents as systems whose actions and goals are shaped by a dynamic framework of accessible history, adaptive repertoire, and external environment. They argue that while current LLM architectures exhibit some agent-like qualities, they fall short of being full agents due to limitations in memory persistence and module adaptability. The paper suggests that combining existing agent architectures with advanced memory and module systems could provide a path toward artificial agency.

## Method Summary
The paper employs a theoretical modeling approach, analyzing LLM architectures against a proposed framework of agentive autonomy. The method involves defining key components of agency (accessible history, adaptive repertoire, and external environment), evaluating current LLM systems against these criteria, and proposing potential architectural improvements. The authors draw on existing research including the agent architecture from Park et al. (2023) and the Coscientist from Boiko et al. (2023) to inform their analysis.

## Key Results
- Current LLM agents are not genuine agents because they lack persistent, self-shaping accessible history tied to individual identity
- The proposed framework identifies three critical factors for agency: accessible history, adaptive repertoire, and external environment
- A combination of Park et al.'s agent architecture with Boiko et al.'s module approach is suggested as a potential path to artificial agency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM agents are not genuine agents because they lack an evolving accessible history tied to individual identity.
- Mechanism: Current LLM agents are fine-tuned or prompted for specific tasks, resetting memory each session; no individual learning trajectory accumulates over time.
- Core assumption: Agency requires a persistent, self-shaping accessible history that reflects individual experiences.
- Evidence anchors:
  - [abstract] "current LLMs are not agents yet, but that there are elements to them that suggest a way forward"
  - [section 3] "the Coscientist's memory stream does not go beyond the experiment it runs... the planner's pre-prompting is completely reset to an initial state"
  - [corpus] "Autonomous chemical research with large language models" (Boiko et al., 2023) demonstrates task-specific, resettable memory
- Break condition: If an LLM architecture is introduced that retains and updates a continuous accessible history across tasks without reset, this mechanism no longer blocks agency attribution.

### Mechanism 2
- Claim: Genuine agency requires adaptive repertoire—modules or skills that the agent can reconfigure or extend autonomously.
- Mechanism: Current LLM agents use static, pre-defined modules (web search, code execution, etc.) that cannot be altered or expanded by the agent itself.
- Core assumption: An adaptive repertoire means the agent can modify its own toolset based on experience.
- Evidence anchors:
  - [abstract] "a combination of the agent architecture presented in Park et al. (2023) together with the use of modules like the Coscientist in Boiko et al. (2023)"
  - [section 3.1] "An individual LLM agent should thus have an architecture like that of the Coscientist, but with the ability to adapt modules"
  - [corpus] "Voyager: An open-ended embodied agent with large language models" (Wang et al., 2023) shows skill recombination but not autonomous module generation
- Break condition: If the agent can autonomously design, integrate, or discard modules in response to new environments, this mechanism no longer applies.

### Mechanism 3
- Claim: Agents must have goals that emerge from the interaction of accessible history, adaptive repertoire, and environment—not just pre-set task directives.
- Mechanism: LLM agents currently operate from human-set prompts and fixed reward functions; no emergent goal formation tied to personal trajectory.
- Core assumption: Purposeful agency includes self-directed goal development informed by accumulated experience.
- Evidence anchors:
  - [abstract] "actions and goals are always influenced by a dynamic framework of factors that consists of the agent's accessible history, its adaptive repertoire and its external environment"
  - [section 2.2] "we claim that agents are purposive systems in the sense that they can develop additional goals, aims, intentions, or plans"
  - [corpus] "Generative agents: Interactive simulacra of human behavior" (Park et al., 2023) shows goal adaptation within simulation but no transfer to open-world learning
- Break condition: If the agent demonstrates autonomous goal formation shaped by its unique history and repertoire, this mechanism no longer blocks agency attribution.

## Foundational Learning

- Concept: Dynamic frameworks in agent modeling
  - Why needed here: The paper's core argument rests on a three-factor framework (accessible history, adaptive repertoire, environment) that jointly shapes agent behavior.
  - Quick check question: Can you list the three factors and explain how each influences the agent's next action?

- Concept: Difference between autonomy as self-driving vs. autonomy as authenticity
  - Why needed here: The authors distinguish mere operational autonomy from authentic autonomy, which is central to their critique of current LLM agents.
  - Quick check question: Why does the paper argue that self-driving systems are not sufficient for agency?

- Concept: Threshold conceptions vs. dimensional accounts of agency
  - Why needed here: The authors reject traditional threshold models in favor of a framework that allows for degrees of agency and artificial realizations.
  - Quick check question: What is the key philosophical motivation for avoiding a human-centric threshold model?

## Architecture Onboarding

- Component map:
  - LLM core (e.g., GPT-4, LLaMA) -> Module suite -> Memory stream component -> Reflection engine -> Goal planner -> Seed memory

- Critical path:
  1. Receive prompt → seed memory + current state → memory retrieval → plan formation
  2. Execute plan using modules → observe environment → log action & outcome to memory
  3. Reflect periodically → update self-understanding → adjust future plans

- Design tradeoffs:
  - Memory size vs. retrieval speed: larger accessible history increases authenticity but slows response
  - Module rigidity vs. adaptability: static modules are reliable but prevent autonomous evolution
  - Prompt specificity vs. autonomy: detailed instructions reduce emergent behavior

- Failure signatures:
  - Hallucination or irrelevant memory retrieval (history corruption)
  - Repeated failure to achieve goals (repertoire mismatch with environment)
  - Inability to adapt plans after environmental change (goal rigidity)

- First 3 experiments:
  1. Implement a persistent memory stream in a simple LLM agent; log all actions and environmental observations; test retrieval accuracy after 100 interactions.
  2. Add a reflection module that summarizes recent activity; measure whether reflections improve plan coherence in subsequent tasks.
  3. Create a module-swapping interface; test if the agent can replace a failed module with an alternative and maintain task performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural components and pre-prompt structures would be necessary to create an LLM agent that truly meets the proposed theoretical model of artificial agency?
- Basis in paper: [explicit] The paper proposes combining the agent architecture from Park et al. (2023) with modules like the Coscientist from Boiko et al. (2023), but acknowledges this remains an open challenge requiring further research.
- Why unresolved: While the paper identifies promising architectural elements (adaptive modules, accessible history via memory streams, goal formation), it does not specify exact implementation details for creating a complete agent that meets all criteria of the theoretical model.
- What evidence would resolve it: A working prototype LLM agent that demonstrates all key features of the theoretical model (adaptive repertoire, accessible history, external environment interaction, and authentic goal development) would provide definitive evidence.

### Open Question 2
- Question: How should seed memories be designed to ensure artificial agents develop in alignment with human values while maintaining their authentic agency?
- Basis in paper: [explicit] The paper identifies seed memory as a key challenge, noting it can play a crucial role in ensuring the agent's worldview aligns with human values, but acknowledges uncertainty about how much information should be included and how explicit instructions should be.
- Why unresolved: There is a tension between providing enough guidance to ensure ethical alignment versus allowing sufficient autonomy for authentic agency development. The optimal balance remains unclear.
- What evidence would resolve it: Empirical studies comparing different seed memory designs and their effects on agent behavior and value alignment over time would help establish best practices.

### Open Question 3
- Question: What are the broader societal implications and ethical considerations of creating artificial agents with authentic agency?
- Basis in paper: [explicit] The paper concludes by reflecting on the challenges of building artificial agents and their potential integration into society, questioning whether the benefits outweigh the costs and whether we should focus instead on building autonomous but instrumental systems.
- Why unresolved: The creation of artificial agents raises complex questions about their rights, responsibilities, and role in society that extend beyond technical feasibility to philosophical and ethical domains.
- What evidence would resolve it: Ongoing interdisciplinary research combining technical development with philosophical analysis and social impact studies would be needed to fully address these implications.

## Limitations
- The theoretical model relies heavily on philosophical distinctions that may be contested by other frameworks in AI ethics and cognitive science.
- The claim that current LLM agents lack genuine agency is plausible but difficult to empirically verify.
- The proposed path to artificial agency through combining specific architectures remains largely speculative.

## Confidence
- **High confidence**: The theoretical framework of agentive autonomy based on accessible history, adaptive repertoire, and external environment is internally consistent and well-articulated.
- **Medium confidence**: The critique of current LLM agents as not meeting agency criteria is reasonable but depends on accepting the paper's specific definition of agency.
- **Low confidence**: The proposed technical path to achieving artificial agency through combining specific architectures is highly speculative and not yet demonstrated.

## Next Checks
1. Implement a prototype LLM agent with persistent memory stream and measure whether it develops unique behavioral patterns over time that differ from other agents with different histories.

2. Submit the agency framework to peer review by philosophers of AI to assess whether the three-factor model adequately captures the essence of agency or whether alternative frameworks might challenge the conclusions.

3. Conduct a systematic survey of current LLM architectures to identify which components of the proposed agency-enabling architecture are already technically feasible and which remain theoretical challenges.