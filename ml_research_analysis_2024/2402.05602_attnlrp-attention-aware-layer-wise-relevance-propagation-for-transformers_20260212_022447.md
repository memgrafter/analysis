---
ver: rpa2
title: 'AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for Transformers'
arxiv_id: '2402.05602'
source_url: https://arxiv.org/abs/2402.05602
tags:
- rule
- input
- relevance
- attnlrp
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating faithful and computationally
  efficient explanations for large transformer models, including large language models
  (LLMs) and vision transformers. The authors propose AttnLRP, an extension of Layer-wise
  Relevance Propagation (LRP) that introduces novel rules for handling non-linear
  operations in transformers, such as softmax, matrix multiplication, and normalization
  layers.
---

# AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for Transformers

## Quick Facts
- arXiv ID: 2402.05602
- Source URL: https://arxiv.org/abs/2402.05602
- Reference count: 40
- AttnLRP provides faithful and efficient explanations for large transformer models

## Executive Summary
This paper introduces AttnLRP, an extension of Layer-wise Relevance Propagation (LRP) specifically designed for transformer architectures. AttnLRP introduces novel propagation rules for handling transformer-specific operations including softmax, matrix multiplication, and normalization layers, all derived within the Deep Taylor Decomposition framework. The method enables both input and latent representation explanations, facilitating understanding of model-internal reasoning and concept-based explanations. Extensive evaluations demonstrate significant improvements in faithfulness and computational efficiency compared to state-of-the-art explanation methods across multiple model architectures including LLaMa 2, Mixtral 8x7b, and vision transformers.

## Method Summary
AttnLRP extends the LRP framework by developing specialized rules for transformer operations. The core innovation lies in the introduction of attention-aware propagation rules that handle non-linear operations like softmax and normalization layers while maintaining faithfulness guarantees through the Deep Taylor Decomposition framework. The method provides a systematic approach to backpropagate relevance scores through the transformer architecture, enabling explanations at both input and intermediate representation levels. This allows for holistic explanations of model behavior and identification of knowledge neurons that can be manipulated to modify model outputs.

## Key Results
- AttnLRP significantly outperforms state-of-the-art explanation methods in faithfulness metrics across multiple transformer architectures
- The method demonstrates superior computational efficiency while maintaining high explanation quality
- AttnLRP enables successful identification and manipulation of knowledge neurons, demonstrating practical utility for model control

## Why This Works (Mechanism)
AttnLRP works by extending the LRP framework with specialized propagation rules for transformer operations. The key insight is that traditional LRP rules are insufficient for capturing the complex interactions in transformer architectures, particularly the attention mechanism and normalization layers. By deriving new rules within the Deep Taylor Decomposition framework, AttnLRP ensures that relevance is propagated faithfully through these operations. The attention-aware rules specifically account for the multiplicative interactions in attention heads, while the normalization-aware rules handle the complex dependencies introduced by layer normalization. This comprehensive treatment of transformer operations enables AttnLRP to provide accurate explanations of both input features and latent representations.

## Foundational Learning

Attention Mechanism: Non-linear operation that computes weighted combinations of values based on query-key interactions
- Why needed: Core component of transformers that enables context-dependent feature extraction
- Quick check: Verify that attention weights sum to 1 for each token

Layer Normalization: Normalization technique that stabilizes training by normalizing activations across feature dimensions
- Why needed: Essential for deep network training but introduces complex dependencies for explanation methods
- Quick check: Confirm mean ≈ 0 and variance ≈ 1 for normalized outputs

Deep Taylor Decomposition: Framework for generating heatmaps by decomposing model output at each neuron
- Why needed: Provides theoretical foundation for faithful relevance propagation
- Quick check: Verify that relevance conservation holds at each layer

Softmax Function: Normalizes logits into probability distributions
- Why needed: Critical for attention and classification layers in transformers
- Quick check: Ensure output values are positive and sum to 1

Matrix Multiplication: Fundamental operation for linear transformations in neural networks
- Why needed: Backbone of all linear layers in transformers
- Quick check: Validate that matrix dimensions are compatible for multiplication

## Architecture Onboarding

Component Map: Input Embeddings -> Attention Layers -> Feed-Forward Networks -> Output Layer
Critical Path: Token embeddings → Attention mechanism → Residual connections → Layer normalization → Feed-forward networks → Final output
Design Tradeoffs: Faithful explanations vs. computational efficiency; granularity of explanations vs. interpretability
Failure Signatures: Vanishing relevance in attention layers; incorrect propagation through normalization layers
First Experiments:
1. Verify relevance conservation across a single transformer layer
2. Compare AttnLRP explanations with gradient-based methods on a simple classification task
3. Test knowledge neuron identification on a controlled synthetic dataset

## Open Questions the Paper Calls Out

The paper identifies several open questions including the scalability of AttnLRP to extremely large models, the method's sensitivity to hyperparameters, and the need for validation across diverse knowledge domains and multilingual tasks. The authors also note the potential for extending AttnLRP to other model architectures beyond transformers.

## Limitations

- Limited evaluation on frontier models at GPT-4 scale
- Potential sensitivity to hyperparameters in the Deep Taylor Decomposition framework
- Focus primarily on English language tasks with limited cross-lingual validation

## Confidence

High: Technical correctness of mathematical formulation within Deep Taylor Decomposition framework
High: Extensive evaluations across multiple model architectures demonstrating improvements
Medium: Claims about concept-based explanations and holistic explanations lack comprehensive quantitative analysis
Medium: Effectiveness of knowledge neuron manipulation demonstrated in specific cases but lacks systematic validation

## Next Checks

1. Conduct systematic ablation studies on hyperparameter sensitivity across different transformer architectures
2. Validate AttnLRP's effectiveness on multilingual tasks and diverse knowledge domains beyond the examples provided
3. Compare AttnLRP's computational efficiency and faithfulness on frontier models (GPT-4, Claude) against specialized large model explainers