---
ver: rpa2
title: Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference
  Systems
arxiv_id: '2403.02419'
source_url: https://arxiv.org/abs/2403.02419
tags:
- performance
- calls
- number
- vote
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how the number of LLM calls affects the performance
  of compound AI systems, specifically Vote and Filter-Vote strategies. It finds that
  increasing the number of LLM calls can lead to non-monotonic performance: first
  improving but then degrading accuracy.'
---

# Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems

## Quick Facts
- arXiv ID: 2403.02419
- Source URL: https://arxiv.org/abs/2403.02419
- Reference count: 40
- Key outcome: Compound AI systems exhibit non-monotonic performance scaling with LLM calls—improving on easy queries but degrading on hard ones—enabling analytical prediction of optimal call counts.

## Executive Summary
This paper investigates how the number of LLM calls affects the performance of compound AI systems using Vote and Filter-Vote strategies. The key finding is that increasing LLM calls leads to non-monotonic accuracy: performance first improves but then degrades as the number of calls increases. This occurs because more calls improve performance on "easy" queries but worsen it on "hard" queries. The paper proposes an analytical scaling model based on query difficulty that can predict the optimal number of LLM calls for maximum accuracy, validated across multiple datasets using GPT-3.5.

## Method Summary
The study uses MMLU PHYSICS, TRUTHFULQA, GPQA, and AVERITEC datasets with GPT-3.5-turbo-0125. Vote systems generate K responses using the LLM and apply majority voting, while Filter-Vote adds an optional filtering step before voting. The authors analyze scaling behavior by varying K from 2 to 1000 calls, developing an analytical model that characterizes query difficulty and predicts optimal call counts. They empirically validate the model's predictions and demonstrate its ability to identify optimal K values for different tasks.

## Key Results
- Compound AI systems show non-monotonic scaling: performance increases then decreases as LLM calls increase
- Vote systems perform better on easy queries but worse on hard queries with more calls
- The analytical scaling model accurately predicts optimal LLM call counts from small samples
- Filter-Vote can exhibit opposite scaling behavior compared to simple Vote, sometimes decreasing before increasing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Performance of compound AI systems using majority voting exhibits non-monotonic scaling as LLM calls increase
- Mechanism: Query difficulty heterogeneity causes easy queries to converge to correct answers while hard queries converge to incorrect ones, with net performance depending on the balance between query types
- Core assumption: Individual query accuracy can be characterized by a query difficulty indicator d(x) determining asymptotic behavior
- Evidence anchors:
  - Abstract states more LM calls improve easy queries but worsen hard ones
  - Theorem 2 connects query difficulty with performance landscape
  - Corpus neighbors discuss related topics but don't directly address query difficulty heterogeneity
- Break condition: If all queries have similar difficulty (all easy or all hard), performance becomes monotonic

### Mechanism 2
- Claim: Analytical scaling model accurately predicts optimal LLM call counts for maximizing accuracy
- Mechanism: Model uses exponential decay/growth functions parameterized by query-specific constants c1(x), c2(x), c3(x) that capture performance changes with additional calls
- Core assumption: Performance follows predictable exponential forms that can be approximated and aggregated
- Evidence anchors:
  - Section states model can accurately predict Vote and Filter-Vote performance
  - Experiments validate predictions for optimal LLM calls
  - Corpus includes "Scaling Law in LLM Simulated Personality" suggesting scaling laws apply to LLM behavior
- Break condition: If actual performance deviates significantly from assumed exponential form or query difficulty is too complex

### Mechanism 3
- Claim: Filter-Vote exhibits opposite scaling behavior compared to simple Vote, sometimes decreasing then increasing
- Mechanism: Filtering changes effective query difficulty by removing candidate answers, potentially transforming hard queries into easier ones or vice versa
- Core assumption: Filter quality affects distribution of remaining answers and thus reduced problem difficulty
- Evidence anchors:
  - Abstract notes Filter-Vote can first increase then decrease as LLM calls increase
  - Section provides conditions for non-monotone scaling on datasets with both easy and difficult queries
  - Corpus neighbors don't discuss filtering effects on scaling behavior
- Break condition: If filter is perfect (always keeps correct answers) or useless (keeps answers randomly)

## Foundational Learning

- Concept: Query difficulty indicator and its mathematical definition
  - Why needed here: Fundamental to understanding non-monotonic scaling and predicting optimal LLM call counts
  - Quick check question: If a query has d(x) > 0, what happens to its accuracy as K → ∞ in majority voting?

- Concept: Beta function and its application in analyzing binomial distributions
  - Why needed here: Exact performance formula for binary answer spaces involves regularized incomplete beta functions
  - Quick check question: For K odd and binary answers, what is the exact formula for Vote accuracy on a query with individual LLM accuracy p?

- Concept: Exponential decay/growth models for performance scaling
  - Why needed here: Analytical scaling model approximates performance using exponential functions to predict optimal call counts
  - Quick check question: How does the model represent performance curves for easy queries versus hard queries?

## Architecture Onboarding

- Component map: Generator G(x, θ) → Voter V → Filter Φ (optional) → Final answer
- Critical path: Query → Generator (K times) → Filter (optional) → Voter → Final answer
  - Performance prediction depends on understanding how each component affects query difficulty and convergence
- Design tradeoffs:
  - More LLM calls improve easy queries but degrade hard ones - tradeoff between coverage and precision
  - Filter quality affects whether difficult queries become easier or harder
  - Model complexity vs. prediction accuracy in scaling law estimation
- Failure signatures:
  - Non-monotonic performance indicates query difficulty heterogeneity
  - Persistent monotonic behavior suggests uniform query difficulty
  - Poor prediction accuracy may indicate model assumptions don't hold for the dataset
- First 3 experiments:
  1. Measure individual LLM accuracy on easy vs. hard query subsets to estimate d(x) distribution
  2. Test Vote performance with varying K on controlled bi-level difficulty dataset
  3. Fit scaling model parameters using small samples and validate predictions against full experiments

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does optimal number of LLM calls vary across different model families and how does this affect generalizability of scaling laws?
- Basis in paper: Paper uses GPT-3.5 but notes different LMs could be used and filter quality affects scaling behavior
- Why unresolved: Only tests with GPT-3.5, so model-specific behavior remains unexplored
- What evidence would resolve it: Experiments comparing Vote/Filter-Vote scaling across multiple LLM families with varying capabilities

### Open Question 2
- Question: Can scaling laws be extended to handle tasks with continuous or open-ended outputs rather than multiple-choice questions?
- Basis in paper: Paper explicitly focuses on tasks with small number of possible answers that support majority voting
- Why unresolved: Theoretical framework relies on discrete answer spaces and majority voting
- What evidence would resolve it: Modified scaling models working with continuous output spaces and alternative aggregation strategies

### Open Question 3
- Question: What is computational trade-off between making more LLM calls versus using larger/more capable models?
- Basis in paper: Paper notes it does not discuss cost of LLM calls, which is an important practical dimension
- Why unresolved: Analysis focuses purely on accuracy scaling without considering resource costs
- What evidence would resolve it: Empirical studies comparing compound systems varying both number of calls and model size

## Limitations

- Query difficulty indicator d(x) is mathematically defined but challenging to estimate practically from real data
- Model assumptions about exponential decay/growth forms may not hold across all problem domains or LLM architectures
- Experiments focus on GPT-3.5 and specific datasets, limiting generalizability to other LLMs or task types

## Confidence

**High Confidence**: Empirical observation of non-monotonic scaling behavior is well-supported by experimental results across multiple datasets, with logically sound mechanism matching observed patterns.

**Medium Confidence**: Analytical scaling model's ability to predict optimal LLM call counts is validated on tested datasets, but limited exploration of model assumptions and parameter estimation sensitivity introduces uncertainty about robustness.

**Low Confidence**: Claim that Filter-Vote exhibits opposite scaling behavior compared to simple Vote is supported by theory but has limited experimental validation, with insufficient exploration of conditions under which filtering creates meaningful changes.

## Next Checks

1. **Cross-architecture validation**: Test scaling model's predictions on multiple LLM architectures (GPT-4, Claude, Llama) to assess generalizability beyond GPT-3.5 and identify architecture-specific patterns.

2. **Parameter sensitivity analysis**: Systematically vary sample size used for parameter estimation in analytical model and measure prediction accuracy degradation to establish minimum viable sample requirements.

3. **Difficulty distribution complexity**: Create synthetic datasets with more complex difficulty distributions (multi-modal, continuous spectra) to test whether current model can capture scaling behavior beyond assumed exponential forms.