---
ver: rpa2
title: Language Models as Causal Effect Generators
arxiv_id: '2411.08019'
source_url: https://arxiv.org/abs/2411.08019
tags:
- causal
- data
- methods
- language
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose sequence-driven structural causal models (SD-SCMs),
  a framework that uses pre-trained language models to parameterize causal models
  with user-specified DAGs. Their method iteratively samples data in topological order
  using domain-restricted sampling and parent-only concatenation, enabling controlled
  generation of observational, interventional, and counterfactual data.
---

# Language Models as Causal Effect Generators

## Quick Facts
- arXiv ID: 2411.08019
- Source URL: https://arxiv.org/abs/2411.08019
- Authors: Lucius E. J. Bynum; Kyunghyun Cho
- Reference count: 40
- Pre-trained language models can parameterize causal models with user-specified DAGs for generating observational, interventional, and counterfactual data

## Executive Summary
This paper introduces sequence-driven structural causal models (SD-SCMs), a framework that uses pre-trained language models to generate data with controllable causal structure. The method iteratively samples variables in topological order using domain-restricted sampling and parent-only concatenation, enabling the creation of synthetic datasets for benchmarking causal inference methods. The authors demonstrate this approach by creating a breast cancer benchmark with 1,000 datasets across two language models (GPT-2 and Llama-3-8b), testing causal estimation methods for CATE and ITE.

## Method Summary
The SD-SCM framework uses pre-trained language models to parameterize causal models specified by user-defined DAGs. For each variable, the LM is queried conditioned only on its parents' values (parent-only concatenation), and the output probabilities are restricted to the variable's sample space (domain-restricted sampling). The method iteratively samples variables in topological order, storing exogenous variables and upstream evidence to enable exact counterfactual reconstruction. This generates observational, interventional, and counterfactual data with the desired causal structure.

## Key Results
- SD-SCMs enable controlled generation of observational, interventional, and counterfactual data using pre-trained LMs
- Benchmark with 1,000 datasets shows causal methods outperform non-causal baselines for CATE and ITE estimation
- Even state-of-the-art approaches struggle with individualized effect estimation, particularly under hidden confounding
- The method provides a flexible tool for generating sequential data with controllable causal structure

## Why This Works (Mechanism)

### Mechanism 1
Language models can parameterize causal mechanisms when queried in topological order. The model is iteratively queried for each variable conditioned only on its parents' values, ensuring the joint distribution factorizes according to the user-specified DAG. Core assumption: LM's conditional distributions over tokens contain sufficient causal signal. Break condition: If LM's internal correlations don't align with DAG's causal structure, generated data violates conditional independences.

### Mechanism 2
Domain-restricted sampling enforces valid distributions over finite sequence spaces. For each variable, LM's output probabilities over all tokens are tabulated, normalized only over the variable's sample space, and a multinomial draw selects the sequence. Core assumption: LM's token-level probabilities can be meaningfully aggregated into sequence-level probabilities without destroying causal structure. Break condition: If sample space contains sequences LM assigns zero probability to, sampling fails or is biased.

### Mechanism 3
Bookkeeping during generation enables unique counterfactuals by inverting structural equations. By storing exogenous variables and upstream evidence during observational sampling, the framework can reconstruct the noise that produced each observation, allowing exact counterfactual interventions. Core assumption: LM's generative process is effectively invertible with respect to noise variables. Break condition: If LM's sequence generation is non-deterministic or involves unstorable randomness, exact counterfactuals cannot be recovered.

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs) and d-separation
  - Why needed here: DAG defines which variables can be parents of which, determining factorization of joint distribution and valid conditional independences
  - Quick check question: If A → B ← C in a DAG, what is the conditioning relationship between A and C given B?

- Concept: Counterfactual inference and abduction-action-prediction
  - Why needed here: Framework generates counterfactuals by first "abducting" exogenous variables that produced an observation, then "acting" by intervening, and finally "predicting" the outcome
  - Quick check question: In a three-step counterfactual computation, what is the role of the "abduction" step?

- Concept: Treatment effect estimation (ATE, CATE, ITE)
  - Why needed here: Benchmark evaluates causal inference methods by comparing estimated effects to ground-truth effects embedded in generated data
  - Quick check question: How does the CATE differ from the ITE in terms of conditioning?

## Architecture Onboarding

- Component map: User-specified DAG → topological ordering → parent-only concatenation logic → Pre-trained LM + domain-restricted sampling → sequence generation per variable → Bookkeeping store → exogenous variables for counterfactual reconstruction → Benchmark harness → runs causal inference methods, computes R²/PEHE/coverage

- Critical path: 1) Parse DAG → generate topological order 2) For each variable in order: concatenate parent sequences, sample from LM restricted to variable's sample space 3) Store exogenous variables and upstream evidence during sampling 4) For counterfactuals: restore stored variables, intervene, regenerate descendants 5) Output dataset + true effects for benchmarking

- Design tradeoffs: Using fixed pre-trained LM gives data realism but limits control over structural equations; Domain restriction ensures valid distributions but may discard valid LM outputs; Bookkeeping enables exact counterfactuals but increases memory usage linearly with dataset size

- Failure signatures: Generated data violates conditional independences implied by DAG → LM not aligned with structure; Sampling fails with zero probabilities → sample space includes sequences LM cannot generate; Counterfactuals inconsistent with observed outcomes → bookkeeping lost or LM non-invertible

- First 3 experiments: 1) Toy DAG with known conditional independences; verify generated data matches using independence tests 2) Simple intervention benchmark; confirm observational vs interventional distributions differ as expected 3) Hidden confounding scenario; confirm causal methods outperform naive baselines on CATE estimation

## Open Questions the Paper Calls Out

1. How can SD-SCMs be used to train language models for causal reasoning rather than just generating data from pre-trained models? (Future work section mentions this as direction)

2. How sensitive are SD-SCM-generated datasets to the choice of phrasings for sequence variables, and can this sensitivity be automated? (Paper acknowledges manual effort required but doesn't investigate impact)

3. How do SD-SCMs perform for causal discovery tasks beyond effect estimation, such as identifying causal structure between variables? (Mentioned as future interest without testing)

## Limitations

- Reliance on pre-trained language models creates a "black box" dependency where true structural equations are unknown and may not align with user-specified DAG
- Domain-restricted sampling may discard valid LM outputs if sample space contains sequences the model assigns zero probability to, potentially introducing bias
- The benchmark focuses on a single breast cancer scenario with 14 variables, limiting generalizability to other domains and DAG structures

## Confidence

- **High Confidence**: Core SD-SCM framework for generating observational, interventional, and counterfactual data using topological ordering and parent-only concatenation
- **Medium Confidence**: Claim that SD-SCMs can audit language models for encoded causal effects (theoretically sound but limited empirical validation)
- **Low Confidence**: Generalizability of breast cancer benchmark to other domains and DAG structures (single scenario, performance degradation under hidden confounding)

## Next Checks

1. **Structural Validity Test**: Generate data using a simple DAG with known conditional independences (e.g., collider structure) and verify using statistical independence tests that generated data matches specified causal structure

2. **Cross-Domain Benchmark**: Apply SD-SCM framework to completely different domain (e.g., economics or education) with different DAG structure and variable types; compare performance of causal inference methods across domains

3. **Sample Space Sensitivity Analysis**: Systematically vary sample space size and composition for given variable and measure impact on causal effect estimation accuracy to reveal whether domain restriction introduces systematic bias