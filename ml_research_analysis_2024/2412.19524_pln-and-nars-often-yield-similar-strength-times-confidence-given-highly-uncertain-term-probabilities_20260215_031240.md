---
ver: rpa2
title: PLN and NARS Often Yield Similar strength $\times$ confidence Given Highly
  Uncertain Term Probabilities
arxiv_id: '2412.19524'
source_url: https://arxiv.org/abs/2412.19524
tags:
- nars
- term
- probabilities
- dence
- induction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper compares the uncertainty handling of Probabilistic Logic
  Networks (PLN) and the Non-Axiomatic Reasoning System (NARS) when term probabilities
  are highly uncertain. It focuses on comparing the "power" (product of strength and
  confidence) for inference conclusions in both systems.
---

# PLN and NARS Often Yield Similar strength $\times$ confidence Given Highly Uncertain Term Probabilities

## Quick Facts
- arXiv ID: 2412.19524
- Source URL: https://arxiv.org/abs/2412.19524
- Reference count: 1
- Primary result: PLN and NARS yield similar inference power values when term probabilities are highly uncertain

## Executive Summary
This paper compares the uncertainty handling of Probabilistic Logic Networks (PLN) and Non-Axiomatic Reasoning System (NARS) when term probabilities are highly uncertain. The analysis focuses on the "power" (product of strength and confidence) for inference conclusions in both systems. Through heuristic analysis and numerical examples for deduction, induction, and abduction, the paper finds that PLN and NARS often yield similar power values in high-uncertainty scenarios, despite using different mechanisms. The similarity arises because both systems rely more on relationship strengths and confidences when term probabilities are uncertain.

## Method Summary
The paper employs heuristic analysis and elementary numerical computations to compare PLN and NARS inference formulas under high term probability uncertainty. The comparison focuses on deduction, induction, and abduction rules, calculating the product of strength and confidence (power) for inference conclusions. The analysis examines simplified versions of the formulas when term probabilities are highly uncertain, identifying conditions under which the systems converge and diverge.

## Key Results
- PLN and NARS often yield similar power values (s×c) when term probabilities are highly uncertain
- The convergence is strongest for deduction but less pronounced for abduction
- When term probabilities are confident, PLN's Bayesian components dominate and divergence increases
- NARS's experience parameter k and PLN's term probability uncertainty create functionally similar confidence modulation effects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: When term probabilities are highly uncertain, the power (s x c in PLN and f x c in NARS) converges because both systems rely more on relationship strengths and confidences.
- Mechanism: High uncertainty in term probabilities reduces their influence in the inference formulas, causing both systems to fall back on relationship-level information.
- Core assumption: Term probabilities can be considered "highly uncertain" when their confidence values are low or their variance is wide.
- Evidence anchors:
  - [abstract] "We find that in many practical situations with high term probability uncertainty, PLN and NARS formulas give very similar results for the power of an inference conclusion"
  - [section] "Under certain assumptions – specifically, when term probabilities in PLN are highly uncertain – the inference mechanisms of PLN may exhibit behaviors that resemble those of NARS."
  - [corpus] No direct evidence found in corpus about this convergence mechanism
- Break condition: When term probabilities become confident and well-known, PLN's Bayesian components dominate and divergence increases

### Mechanism 2
- Claim: The similarity in power values occurs despite different underlying mechanisms because PLN's term probability contributions become negligible.
- Mechanism: In PLN, the formulas simplify when term probabilities are uncertain, reducing to products of relationship strengths and confidences that closely match NARS's structure.
- Core assumption: The simplification occurs when term probabilities are treated as having minimal influence on the inference outcome.
- Evidence anchors:
  - [section] "PLN's default conﬁdence formulas also reduce to a simple form cAC ≈ cBAcBC so the power s × c comes out to: sAC × cAC ≈ sBAsBC × cBAcBC"
  - [corpus] No direct evidence found in corpus about this simplification mechanism
- Break condition: When term probabilities have non-negligible influence, PLN's unique treatment of term probabilities creates divergence

### Mechanism 3
- Claim: The experience parameter k in NARS acts as a confidence modulator that approximates PLN's handling of uncertain term probabilities.
- Mechanism: NARS's experience parameter k adjusts confidence based on accumulated evidence, providing a similar dampening effect to PLN's uncertain term probabilities.
- Core assumption: The experience parameter k serves a functionally similar role to PLN's uncertainty about term probabilities.
- Evidence anchors:
  - [section] "NARS includes an experience parameter k in the denominator, which affects the conﬁdence based on accumulated experience"
  - [corpus] No direct evidence found in corpus about this functional equivalence
- Break condition: When the experience parameter k is very small or very large, the approximation breaks down

## Foundational Learning

- Concept: Term probabilities vs. relationship probabilities
  - Why needed here: The paper hinges on comparing how PLN and NARS handle these different types of uncertainty
  - Quick check question: What is the fundamental difference between how PLN and NARS represent uncertainty about terms versus relationships?

- Concept: Power calculation (s x c vs f x c)
  - Why needed here: The paper's main comparison metric is the product of strength and confidence
  - Quick check question: Why does the paper focus on the product of strength and confidence rather than these values individually?

- Concept: Bayesian reasoning vs. non-axiomatic reasoning
  - Why needed here: PLN aims to combine NARS-like behavior with Bayesian reasoning, which is central to understanding their divergence
  - Quick check question: How does PLN's approach to induction and abduction differ from NARS when term probabilities are known with high confidence?

## Architecture Onboarding

- Component map:
  - Truth value representations: PLN uses (strength, confidence) pairs with term and relationship probabilities; NARS uses (frequency, confidence) pairs with only relationship probabilities
  - Inference rules: Both systems have deduction, induction, and abduction rules with different truth value formulas
  - Uncertainty handling: PLN has Bayesian components that activate with confident term probabilities; NARS uses experience parameters for confidence modulation

- Critical path: For comparing PLN and NARS outputs, the critical path involves: 1) Determining term probability uncertainty levels, 2) Applying the appropriate inference rule formulas, 3) Calculating power values (s x c or f x c), 4) Comparing the results

- Design tradeoffs: PLN trades off complexity and expressiveness (handling term probabilities) for potentially more accurate reasoning when term probabilities are known; NARS trades off expressiveness for simplicity and robustness in uncertain environments

- Failure signatures: Divergence between PLN and NARS outputs when term probabilities are confident; PLN's concept geometry-based formulas produce different normalization than NARS; NARS's experience parameter k creates different confidence scaling than PLN's approach

- First 3 experiments:
  1. Implement both PLN and NARS deduction rules and verify the convergence shown in Example 1 under high term probability uncertainty
  2. Vary the experience parameter k in NARS and observe its effect on power values compared to PLN
  3. Create scenarios with gradually increasing term probability confidence and measure the divergence between PLN and NARS outputs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions do PLN and NARS inference rules produce nearly identical power values, and how does this relationship change as term probability uncertainty varies?
- Basis in paper: [explicit] The paper shows that PLN and NARS produce similar s×c products under high term probability uncertainty, particularly for deduction.
- Why unresolved: The paper only provides heuristic analysis and a few numerical examples. A comprehensive mathematical characterization of the conditions under which the similarity holds is missing.
- What evidence would resolve it: A rigorous mathematical proof or extensive numerical simulations mapping the parameter space where the similarity holds, including transition boundaries as term probability confidence increases.

### Open Question 2
- Question: Does the normalization factor in PLN's concept-geometry-based deduction formula capture meaningful information that NARS lacks, or is it an artifact of PLN's specific assumptions?
- Basis in paper: [explicit] The paper notes that PLN's concept-geometry deduction includes a normalization factor absent in NARS, leading to different results.
- Why unresolved: The paper suggests this might be because concept shape assumptions in PLN have no analogue in NARS, but doesn't explore this possibility systematically.
- What evidence would resolve it: Comparative studies showing whether the normalization factor improves inference accuracy in domains where concept geometry is meaningful, or empirical evidence that NARS performs comparably without it.

### Open Question 3
- Question: How do PLN and NARS differ in their holistic reasoning performance when term probabilities are highly uncertain versus well-known?
- Basis in paper: [explicit] The paper suggests that when term probabilities are confident, PLN diverges significantly from NARS, especially in induction and abduction.
- Why unresolved: The paper focuses on individual inference rules rather than complete reasoning networks, and acknowledges this as a limitation.
- What evidence would resolve it: Empirical comparisons of complete inference networks built with both systems on realistic problems, measuring final conclusion accuracy and consistency across varying levels of term probability uncertainty.

## Limitations
- The analysis relies on heuristic comparisons rather than comprehensive empirical validation across diverse scenarios
- Limited experimental verification of convergence mechanisms in practical applications
- Focus on individual inference rules rather than complete reasoning networks

## Confidence

- **High Confidence**: The mathematical derivations showing PLN and NARS formulas under high term probability uncertainty, and the observation that deduction rules converge more strongly than abduction rules
- **Medium Confidence**: The general claim that PLN and NARS yield similar power values under high uncertainty, as this depends on specific parameter choices in the numerical examples
- **Low Confidence**: The specific mechanisms explaining why the convergence occurs (particularly the role of the experience parameter k in NARS and its functional equivalence to PLN's uncertainty handling)

## Next Checks
1. Implement a systematic parameter sweep varying term probability uncertainties, relationship strengths, and experience parameters to quantify the convergence conditions more precisely
2. Test the convergence claims with real-world datasets where term probabilities are genuinely uncertain, rather than synthetic examples
3. Investigate scenarios where term probabilities become increasingly confident to measure the divergence between PLN and NARS outputs as predicted by the theory