---
ver: rpa2
title: Tackling prediction tasks in relational databases with LLMs
arxiv_id: '2411.11829'
source_url: https://arxiv.org/abs/2411.11829
tags:
- nrel
- ninc
- tasks
- relational
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that large language models (LLMs) can effectively
  tackle predictive tasks in relational databases without requiring additional fine-tuning.
  The authors propose a novel approach that constructs information-rich documents
  by traversing links between database tables and serializing entities as JSONs, allowing
  LLMs to make predictions competitive with specialized relational deep learning methods.
---

# Tackling prediction tasks in relational databases with LLMs

## Quick Facts
- arXiv ID: 2411.11829
- Source URL: https://arxiv.org/abs/2411.11829
- Reference count: 30
- One-line primary result: Base LLMs can achieve competitive performance on relational database prediction tasks without fine-tuning through JSON document construction and metric-aware inference.

## Executive Summary
This paper demonstrates that large language models can effectively tackle predictive tasks in relational databases without requiring additional fine-tuning. The authors propose a novel approach that constructs information-rich documents by traversing links between database tables and serializing entities as JSONs, allowing LLMs to make predictions competitive with specialized relational deep learning methods. Using the RelBench benchmark, their results show that even straightforward LLM application achieves performance close to relational deep learning approaches, with metric-aware inference and trained MLP heads further improving results. The findings establish LLMs as a promising new baseline for machine learning on relational databases, potentially offering reduced resource requirements and advantages in low-data regimes.

## Method Summary
The method involves constructing JSON documents by traversing links between database tables and serializing entities. For each prediction task, the approach generates documents containing the target entity, in-context examples from training data, and related examples linked to the same primary keys. The documents are fed to base LLMs (Llama 3.2 1B/3B) which generate predictions through metric-aware inference using token probability distributions. An optional small MLP head can be trained on a subset of training documents for improved performance. The approach compares against LightGBM and Relational Deep Learning (RDL) baselines on the RelBench benchmark containing 7 datasets with 30 predictive tasks.

## Key Results
- Base LLMs without fine-tuning achieve competitive performance close to relational deep learning approaches on the RelBench benchmark
- Metric-aware inference using base LLMs with token probability distributions improves performance over direct prediction methods
- Training small MLP heads on subsets of training documents further enhances prediction accuracy, particularly for regression tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Denormalizing relational data into JSON documents preserves necessary structural relationships for LLMs to reason about predictions.
- Mechanism: The traversal process follows foreign key to primary key links, recursively gathering related entities up to a specified depth, then serializes them into JSON format. This creates a flat representation that maintains entity relationships.
- Core assumption: JSON serialization is sufficient for LLMs to interpret the relational structure and make predictions without requiring explicit graph neural networks.
- Evidence anchors:
  - [section] "We apply a denormalization process to every entity added to the document, following links from a foreign key to a primary key. We gather links related to all entities joined in the process of denormalization."
  - [abstract] "constructs information-rich documents by traversing links between database tables and serializing entities as JSONs"

### Mechanism 2
- Claim: Metric-aware inference using base LLMs with token probability distributions can achieve competitive performance without fine-tuning.
- Mechanism: Instead of direct prediction, the approach samples token probabilities and applies task-specific transformations (e.g., median for MAE, monotone transformation for AUROC) to extract predictions from the LLM's conditional distribution P(y|x).
- Core assumption: Base LLMs trained with next-token prediction loss implicitly learn the true conditional distribution needed for metric optimization.
- Evidence anchors:
  - [section] "we use base models and examine the probability distribution of possible subsequent tokens. Under the assumption that a base model is trained only with the next-token prediction task using crossentropy loss, the minimizer under an unrestricted hypothesis class is the true conditional distribution P(y|x)"
  - [abstract] "even straightforward LLM application achieves performance close to relational deep learning approaches, with metric-aware inference and trained MLP heads further improving results"

### Mechanism 3
- Claim: Providing in-context and related examples improves LLM performance by demonstrating the task structure and relevant patterns.
- Mechanism: Documents include task context, ninc in-context examples from training data, and nrel related examples linked to the same primary keys, all with timestamps before the prediction time to prevent information leakage.
- Core assumption: LLMs can effectively learn from demonstration through in-context examples without requiring gradient updates.
- Evidence anchors:
  - [section] "The document consists of three parts. First, we include the task context... next part can consist of ninc, a specified number of in-context examples... followed by the maximum nrel latest related examples"
  - [section] "We found that using a base version of LLM to simply fill out the tokens representing the target or asking for an instruct version for prediction is not working well for such generated documents."

## Foundational Learning

- Concept: Relational database structure (primary keys, foreign keys, one-to-many relationships)
  - Why needed here: Understanding how to traverse links between tables and what information is preserved through denormalization
  - Quick check question: What is the difference between a primary key and a foreign key, and how do they enable table relationships?

- Concept: Graph neural networks vs. transformer-based approaches
  - Why needed here: Comparing the proposed LLM approach with RDL (Relational Deep Learning) which uses GNNs to understand the architectural tradeoffs
  - Quick check question: How do GNNs iteratively update node embeddings based on neighbors, and why might LLMs be able to achieve similar results through different mechanisms?

- Concept: Metric optimization and decision theory
  - Why needed here: Understanding why metric-aware inference works (e.g., median for MAE, monotone transformations for AUROC)
  - Quick check question: What is the optimal prediction for MAE, and how does it relate to the median of the conditional distribution P(y|x)?

## Architecture Onboarding

- Component map: Document generation pipeline → LLM inference → (Optional) MLP head training
  - Database traversal and denormalization
  - JSON serialization of entities and examples
  - Tokenization and LLM inference
  - Probability distribution analysis for metric-aware prediction
  - MLP head training (if used)

- Critical path: Document generation → LLM inference → Prediction extraction
  - The document generation must complete before inference
  - Inference must complete before metric-aware transformation
  - MLP training (if used) requires a separate document generation pass

- Design tradeoffs: Context length vs. information completeness
  - Longer documents with more examples and nested rows provide more information but may exceed LLM context limits
  - Shallower traversal preserves context budget but may miss important relationships
  - More in-context examples improve demonstration quality but reduce space for the target entity

- Failure signatures:
  - Out-of-memory errors during document generation indicate context length issues
  - Poor performance with ninc=0 suggests LLMs need demonstration examples
  - Performance degradation with deep nesting may indicate multi-hop reasoning limitations

- First 3 experiments:
  1. Generate documents with varying ninc (0, 8, 16) on a small task to verify the document structure and LLM input format
  2. Test metric-aware inference vs. direct prediction on a binary classification task to confirm the approach works
  3. Compare performance with and without MLP head on a regression task to validate the need for specialized prediction heads

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLMs on relational databases scale with increasing context window sizes beyond 128k tokens?
- Basis in paper: [inferred] The authors note that "the size of documents quickly grows with the number of examples included and the depth of nesting entities" and mention that "Due to the limited context sizes of LLMs, a more intelligent selection of information... may improve predictive performance as well as reduce computational cost."
- Why unresolved: The paper only tested Llama 3.2 models with 128k token context limits. Larger context windows could allow more comprehensive document construction without aggressive information filtering.
- What evidence would resolve it: Comparative results using models with larger context windows (e.g., 256k, 512k tokens) on the same RelBench tasks, showing whether performance continues to improve or plateaus.

### Open Question 2
- Question: Which information selection strategy (e.g., feature selection, link prioritization) yields optimal performance while minimizing document size?
- Basis in paper: [explicit] The authors state "we have selected the best combination of document generation parameters through a naive search" and suggest "a more intelligent selection of information (e.g., which columns to include and links to follow) may improve predictive performance as well as reduce computational cost."
- Why unresolved: The paper used exhaustive parameter search rather than intelligent feature/link selection strategies, leaving open the question of whether smarter document construction could improve results.
- What evidence would resolve it: Experiments comparing various information selection strategies (e.g., mutual information-based feature selection, link importance scoring) against the current approach, measuring both performance and computational efficiency.

### Open Question 3
- Question: How does fine-tuning LLMs specifically on tabular and relational data compare to the proposed in-context learning approach?
- Basis in paper: [explicit] The authors hypothesize that "training models on tabular and relational data (similar to works of Tran et al. (2024); Li et al. (2024b)) may further enhance the performance of the proposed approach."
- Why unresolved: The paper only used pre-trained LLMs without any tabular or relational fine-tuning, leaving open whether specialized training would improve results.
- What evidence would resolve it: Comparative results using LLMs that have been fine-tuned on large tabular/relational datasets versus the in-context learning approach on the same RelBench tasks.

## Limitations
- The evaluation relies on a single benchmark (RelBench) with only 30 tasks, limiting statistical power for conclusions about LLM superiority across diverse database scenarios.
- The document construction approach assumes well-structured foreign key relationships and may struggle with more complex schemas or self-referential tables.
- Performance improvements from MLP heads require additional training data and computational resources that may offset the benefits of avoiding fine-tuning.

## Confidence

- High confidence: The core finding that base LLMs without fine-tuning can achieve competitive performance on relational prediction tasks
- Medium confidence: Claims about metric-aware inference being universally superior to direct prediction methods, as performance varies by task
- Low confidence: The assertion that LLMs are "particularly advantageous" in low-data regimes, as this was not systematically tested against alternatives

## Next Checks

1. **Cross-benchmark validation**: Test the document generation and LLM inference approach on at least two additional relational database benchmarks with different schema complexities to assess generalizability beyond RelBench.

2. **Ablation on traversal depth**: Systematically evaluate performance across different traversal depths (d=1, 2, 3) on the same tasks to quantify the marginal value of multi-hop relationships and identify the optimal balance between information completeness and context length.

3. **Resource efficiency comparison**: Conduct a comprehensive analysis comparing the total computational cost (including document generation, inference, and optional MLP training) against traditional relational deep learning methods across multiple data scales to verify claims about resource efficiency.