---
ver: rpa2
title: 'MedSyn: LLM-based Synthetic Medical Text Generation Framework'
arxiv_id: '2408.02056'
source_url: https://arxiv.org/abs/2408.02056
tags:
- data
- synthetic
- medical
- clinical
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces MedSyn, a novel framework that combines large
  language models with a Medical Knowledge Graph to generate synthetic clinical notes
  for the Russian language. The framework addresses data scarcity in healthcare by
  leveraging disease-specific symptoms from the knowledge graph and real clinical
  note examples to guide LLM generation.
---

# MedSyn: LLM-based Synthetic Medical Text Generation Framework

## Quick Facts
- arXiv ID: 2408.02056
- Source URL: https://arxiv.org/abs/2408.02056
- Reference count: 40
- Primary result: Framework generates synthetic clinical notes in Russian using LLM + Medical Knowledge Graph, improving ICD code prediction accuracy by up to 17.8%

## Executive Summary
MedSyn introduces a novel framework for generating synthetic clinical notes in Russian by combining large language models with a Medical Knowledge Graph. The framework addresses data scarcity in healthcare by leveraging disease-specific symptoms from the knowledge graph and real clinical note examples to guide LLM generation. Researchers created a dataset of over 41,000 synthetic clinical notes covering 219 ICD-10 codes. Experiments demonstrate that synthetic data can improve ICD code prediction accuracy by up to 17.8% for vital and challenging codes compared to using only real data. The framework shows promise for generating clinically valuable data, particularly for rare diseases, and offers a potential solution for expanding clinical decision support systems.

## Method Summary
The MedSyn framework integrates a Medical Knowledge Graph (MKG) with large language models to generate synthetic clinical notes in Russian. The process involves sampling symptoms from the MKG for target ICD codes, building prompts that combine disease information with real clinical note examples, and using either GPT-4 or a fine-tuned LLaMA-7B model to generate synthetic notes. The researchers fine-tuned LLaMA-7B using LoRA on an instruction-following dataset of 152k samples, achieving performance comparable to GPT-4. The framework was evaluated by measuring its impact on ICD code prediction accuracy using RuBioRoBERTa classifiers, with synthetic data upsampling shown to improve performance for rare disease codes.

## Key Results
- Synthetic data improved ICD code prediction accuracy by up to 17.8% for vital and challenging codes
- Generated dataset contains 41,312 synthetic clinical notes covering 219 ICD-10 codes
- Fine-tuned LLaMA-7B achieved performance on par with or surpassing GPT-4 for clinical note generation
- Framework effectively addresses data scarcity for rare diseases in Russian medical datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating a Medical Knowledge Graph (MKG) with LLM prompts increases factual accuracy of generated clinical notes.
- Mechanism: MKG provides structured, verified medical relationships (disease-symptom, disease-drug) that guide LLM generation toward realistic symptom-disease pairings rather than hallucinated content.
- Core assumption: Symptom-disease relationships in MKG are complete and correct enough to constrain LLM output without reducing diversity.
- Evidence anchors:
  - [abstract] "We use MKG to sample prior medical information for the prompt and generate synthetic clinical notes..."
  - [section] "Exploiting Medical Knowledge Graphs (MKGs) [...] is a way to mitigate the problem [of hallucinations]."

### Mechanism 2
- Claim: Fine-tuning a smaller open-source LLM (LLaMA-7B) on domain-specific instruction data can match or exceed GPT-4 performance in medical text generation.
- Mechanism: Supervised fine-tuning on instruction-following datasets tailored to Russian medical language adapts the base model's general knowledge to clinical style and terminology, compensating for limited pre-training data in that domain.
- Core assumption: The instruction dataset captures sufficient variety of clinical note structures and symptom patterns to generalize beyond its examples.
- Evidence anchors:
  - [abstract] "Experiments demonstrate that synthetic data can improve ICD code prediction accuracy by up to 17.8% [...] and show that an open-sourced model fine-tuned on a specific dataset can perform on par with or surpass GPT-4's performance."
  - [section] "We employed a model based on the LLaMA 2 family [...] fine-tuned the model with 7 billion parameters using a learning rate 2e-5 [...] to fine-tune our model..."

### Mechanism 3
- Claim: Synthetic data upsampling of rare ICD codes improves classification accuracy for those codes without degrading performance on common codes.
- Mechanism: Generating additional synthetic examples for underrepresented disease categories balances the training distribution, allowing models to learn discriminative features for rare conditions.
- Core assumption: Generated synthetic examples are valid and diverse enough to represent the underlying class distribution, not just repeat limited patterns.
- Evidence anchors:
  - [abstract] "Our research indicates that synthetic data can increase the classification accuracy of vital and challenging codes by up to 17.8% compared to settings without synthetic data."
  - [section] "Generating Data Out of the Training Set [...] We selected two vital ICD codes [...] The first is cholecystitis [...] The second code denotes a type of heart disease, one of the most common causes of death."

## Foundational Learning

- Concept: Medical Knowledge Graphs (MKGs)
  - Why needed here: MKGs encode structured relationships (disease-symptom, disease-drug) that constrain LLM outputs toward medically plausible content.
  - Quick check question: What are the three node types in the MedSyn MKG and how are symptoms extracted from clinical manifestations?

- Concept: Instruction-following fine-tuning
  - Why needed here: Adapts a general-purpose LLM to generate clinical notes in Russian by training on domain-specific prompts and outputs.
  - Quick check question: Why does MedSyn use a logarithmic weighting function when sampling ICD codes for generation?

- Concept: Synthetic data upsampling
  - Why needed here: Addresses class imbalance in ICD code prediction by generating more examples for rare diseases, improving model performance on those codes.
  - Quick check question: How does MedSyn ensure that generated notes for rare codes do not leak real patient data?

## Architecture Onboarding

- Component map:
  - Medical Knowledge Graph (MKG) → Symptom sampler → Prompt builder → LLM (GPT-4 or fine-tuned LLaMA-7B) → Synthetic clinical note generator
  - Instruction-following dataset → LoRA fine-tuning pipeline → Model checkpoint
  - Real clinical notes + synthetic notes → ICD code prediction model (e.g., RuBioRoBERTa)

- Critical path:
  1. Sample symptoms from MKG for target ICD code.
  2. Build prompt combining disease name, sampled symptoms, and real note example.
  3. Run LLM inference to generate synthetic note.
  4. (Optional) Fine-tune LLaMA-7B on instruction dataset.
  5. Evaluate synthetic data impact on ICD code prediction.

- Design tradeoffs:
  - MKG completeness vs. prompt complexity: richer MKG → more realistic prompts but more data engineering.
  - Model size vs. fine-tuning cost: smaller LLaMA-7B cheaper to fine-tune but may capture less nuance than GPT-4.
  - Synthetic data volume vs. quality: more data helps rare classes but risks including corrupted samples.

- Failure signatures:
  - Generated notes with irrelevant or contradictory symptoms → MKG or symptom sampler bug.
  - Model performance drops when adding synthetic data → synthetic samples are invalid or too noisy.
  - Generated text closely mirrors the example note → over-reliance on example in prompt, insufficient symptom guidance.

- First 3 experiments:
  1. Generate 100 synthetic notes for a single ICD code using GPT-4 baseline prompt (disease name only) vs. full prompt (with MKG symptoms). Compare symptom usage ratio and BERT-score.
  2. Fine-tune LLaMA-7B on the MedSyn instruction dataset. Generate notes for same ICD code and compare quality to GPT-4 outputs.
  3. Upsample a rare ICD code (e.g., K81) by adding 30 synthetic notes to training set. Measure hit@5 change for that code using RuBioRoBERTa classifier.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but the research raises several important areas for future investigation:

### Open Question 1
- Question: How can we evaluate the long-term reliability and safety of clinical decision support systems that use synthetic medical data for rare diseases?
- Basis in paper: [inferred] The paper mentions plans to use the framework for rare disease note generation to scale their clinical decision support system, but doesn't address evaluation methods for such critical applications.
- Why unresolved: While the paper demonstrates improvements in classification accuracy, it doesn't discuss longitudinal studies or safety validation needed for medical systems that directly impact patient care.
- What evidence would resolve it: Clinical trials comparing outcomes between systems using synthetic data versus real data for rare diseases, with tracking of diagnostic accuracy and patient outcomes over extended periods.

### Open Question 2
- Question: What is the optimal balance between synthetic and real data for training medical AI systems across different clinical specialties?
- Basis in paper: [explicit] The paper shows synthetic data can improve classification accuracy by up to 17.8% but doesn't explore how this ratio might vary by medical domain or task complexity.
- Why unresolved: The experiments use a fixed ratio of synthetic to real data, but different medical specialties likely have different requirements for data quality versus quantity.
- What evidence would resolve it: Systematic studies varying the synthetic-to-real data ratio across multiple medical specialties, measuring performance trade-offs and identifying optimal ratios for different clinical contexts.

### Open Question 3
- Question: How can we develop automated methods to detect and filter corrupted or factually incorrect synthetic medical samples?
- Basis in paper: [explicit] The paper acknowledges that synthetic datasets likely contain corrupted samples and discusses the need for advanced filtration algorithms, but doesn't propose specific solutions.
- Why unresolved: Current evaluation uses coarse filtering based on model predictions, which may miss subtle errors that wouldn't affect classification but could impact clinical applications.
- What evidence would resolve it: Development and validation of automated quality assessment tools that can reliably distinguish high-quality synthetic medical text from problematic samples, tested against human expert evaluation.

## Limitations

- MKG coverage uncertainty: The framework's effectiveness depends on the completeness of the Medical Knowledge Graph, but coverage percentage across all 219 ICD codes is not specified.
- Limited quality validation: The paper lacks detailed human evaluation of clinical accuracy and safety of generated synthetic notes beyond automated metrics.
- Privacy concerns: The use of real clinical note examples in prompts raises potential privacy leakage risks, but the paper does not explicitly verify synthetic notes cannot be reverse-engineered to identify patients.

## Confidence

**High Confidence**: The core mechanism of integrating Medical Knowledge Graphs with LLM prompts to improve factual accuracy is well-supported by the evidence provided. The experimental results showing improved ICD code prediction accuracy with synthetic data are clearly demonstrated.

**Medium Confidence**: The claim that fine-tuned LLaMA-7B can match or exceed GPT-4 performance is supported but limited to specific experimental conditions. The comparison is based on classification accuracy rather than direct quality comparison of generated notes.

**Low Confidence**: The framework's effectiveness for extremely rare diseases (beyond the two tested examples) and its ability to maintain clinical safety in generated content are not sufficiently validated. The long-term reliability of synthetic data for clinical decision support systems remains unproven.

## Next Checks

1. **Clinical Expert Review**: Conduct blind evaluation of 100 randomly selected synthetic notes by medical professionals to assess clinical accuracy, relevance, and safety. Compare error rates between GPT-4 baseline and MKG-guided generation to quantify the factual accuracy improvement.

2. **Rare Disease Generalization**: Test the framework on 10 additional rare ICD codes not covered in the original study. Generate synthetic notes and measure classification accuracy improvement compared to baseline, documenting any failure patterns or quality degradation.

3. **Privacy Leakage Assessment**: Perform membership inference attacks on the synthetic dataset using the real clinical notes. Calculate the probability of correctly identifying whether a real patient's data was used in training the synthetic generation model, and implement additional de-identification safeguards if leakage is detected.