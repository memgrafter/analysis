---
ver: rpa2
title: Leveraging Entailment Judgements in Cross-Lingual Summarisation
arxiv_id: '2408.00675'
source_url: https://arxiv.org/abs/2408.00675
tags:
- summary
- faithfulness
- language
- document
- summaries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes to leverage cross-lingual Natural Language Inference
  (X-NLI) to evaluate the faithfulness of reference and model generated summaries
  in cross-lingual summarisation. We show that cross-lingual NLI-based evaluation
  can approximate human judgements of summary faithfulness.
---

# Leveraging Entailment Judgements in Cross-Lingual Summarisation

## Quick Facts
- arXiv ID: 2408.00675
- Source URL: https://arxiv.org/abs/2408.00675
- Reference count: 38
- This work proposes using cross-lingual NLI to evaluate faithfulness in cross-lingual summarization and shows that faithfulness-aware training improves summary quality.

## Executive Summary
This paper addresses the challenge of generating faithful summaries in cross-lingual abstractive summarization (CLS) by proposing a novel evaluation framework based on cross-lingual Natural Language Inference (X-NLI). The authors demonstrate that X-NLI can effectively approximate human judgments of summary faithfulness across multiple language pairs, and use this to automatically annotate training data for faithfulness-aware model training. Their approach significantly improves faithfulness metrics while maintaining informativeness, offering a practical solution for CLS systems that could also be applied to Large Language Model-generated summaries.

## Method Summary
The method leverages cross-lingual NLI models to evaluate the faithfulness of summaries by treating document sentences as premises and summary sentences as hypotheses. Based on these faithfulness scores, three training approaches are proposed: Clean (removing low-scoring pairs), Mask (replacing unfaithful content with masks), and Unlike PR (using unlikelihood loss to discourage generation of unfaithful content). The authors fine-tune mBART50 models using these approaches and evaluate on the XWikis dataset across multiple language pairs, measuring both faithfulness (via INFUSE and UniEval) and informativeness (via ROUGE-L and LaBSE).

## Key Results
- Faithfulness-aware training approaches significantly improve faithfulness metrics while maintaining or improving informativeness across all tested language pairs
- The Unlike PR variant outperforms other approaches by explicitly discouraging generation of unfaithful content through unlikelihood loss
- Cross-lingual NLI-based evaluation provides reliable faithfulness scores that correlate well with human judgments across diverse language pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual NLI can approximate human judgements of summary faithfulness in CLS.
- Mechanism: X-NLI models detect entailment between document sentences (premises) and summary sentences (hypotheses). High entailment scores indicate faithfulness; low scores suggest hallucinations.
- Core assumption: X-NLI models transfer well from zero-shot cross-lingual scenarios to CLS domains.
- Evidence anchors:
  - [abstract] "We propose to use off-the-shelf cross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness of reference and model generated summaries."
  - [section 2] "Table 1 shows results for the multi- and cross-lingual scenarios. The performance in the cross-lingual scenario is still competitive..."
  - [corpus] Weak - no direct corpus evidence that X-NLI scores correlate with human labels beyond the small annotated validation set.
- Break condition: If cross-lingual transfer degrades sharply, or if summaries require more context than single sentences can provide, X-NLI scores may become unreliable.

### Mechanism 2
- Claim: Removing or down-weighting unfaithful training pairs improves faithfulness of generated summaries without sacrificing informativeness.
- Mechanism: Training with cleaner data reduces the model's exposure to hallucinated content, steering it toward generating summaries grounded in the document.
- Core assumption: The faithfulness signal from X-NLI is sufficiently accurate to guide data cleaning.
- Evidence anchors:
  - [abstract] "...we show that by considering faithfulness during training models can generate more faithful summaries while maintaining informativeness."
  - [section 6] "For all language pairs, faithfulness aware approaches outperform the Vanilla variant trained on the original dataset in terms of faithfulness."
  - [corpus] Weak - limited validation shows gains but no large-scale ablation of data quality impact.
- Break condition: If X-NLI annotations are noisy, aggressive filtering may remove too much useful data, harming performance.

### Mechanism 3
- Claim: Cross-lingual faithfulness evaluation can be applied to assess LLM-generated summaries.
- Mechanism: The X-NLI based evaluation is language-agnostic, relying on multilingual sentence embeddings. It can score any CLS output without needing reference summaries in the target language.
- Core assumption: The X-NLI model generalizes to diverse CLS domains and can handle longer summaries if processed sentence-by-sentence.
- Evidence anchors:
  - [abstract] "Our cross-lingual faithfulness evaluation and faithfulness aware training approaches are relevant in the context of CLS with Large Language Models."
  - [section 6] "Unlike PR (and to a lesser extent Mask) outperform the Vanilla baseline in terms of faithfulness while being comparable (zh-en) or better (fr-en) in terms of informativeness."
  - [corpus] Weak - no explicit corpus-level validation on LLM-generated summaries.
- Break condition: If LLMs generate highly abstractive summaries that require cross-sentence reasoning, single-sentence X-NLI may miss hallucinations.

## Foundational Learning

- Concept: Cross-lingual NLI and entailment scoring
  - Why needed here: Central to both faithfulness evaluation and guiding training.
  - Quick check question: What is the difference between entailment and contradiction in NLI?
- Concept: Unlikelihood training and negative sampling
  - Why needed here: Core of the "Unlike PR" variant to discourage unfaithful content generation.
  - Quick check question: How does unlikelihood loss differ from standard cross-entropy loss?
- Concept: Multi-reference evaluation with cross-lingual similarity metrics
  - Why needed here: Assess informativeness when references exist in multiple languages.
  - Quick check question: Why might LaBSE be preferred over ROUGE in cross-lingual settings?

## Architecture Onboarding

- Component map: Document → X-NLI/INFUSE → faithfulness scores → training data filtering/loss shaping → model fine-tuning → generation → evaluation
- Critical path: Document → X-NLI/INFUSE → faithfulness scores → training data filtering/loss shaping → model fine-tuning → generation → evaluation
- Design tradeoffs:
  - Filtering vs. masking vs. unlikelihood: simpler filtering may remove too much data; masking is easier but less explicit; unlikelihood is more targeted but adds complexity.
  - Sentence-level vs. summary-level annotation: more granular but may miss cross-sentence coherence.
- Failure signatures:
  - Low entailment scores across all pairs may indicate poor cross-lingual transfer.
  - Overfitting to faithfulness signal may hurt informativeness.
  - Inconsistent human vs. automatic annotations suggest X-NLI noise.
- First 3 experiments:
  1. Run INFUSE on a held-out CLS test set and compare scores to human labels.
  2. Fine-tune mBart50 with Clean variant (remove 10% lowest-scoring pairs) and evaluate faithfulness gain.
  3. Implement Unlike PR and test if segment embeddings improve over plain unlikelihood.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal threshold for filtering unfaithful document-summary pairs during training, and how does it vary across languages and datasets?
- Basis in paper: [explicit] The authors mention using a threshold value of 10 for de-en, fr-en, and cs-en; and 20 for zh-en and en-en, determined through grid search and analysis of average entailment scores.
- Why unresolved: The optimal threshold likely depends on factors such as the prevalence of hallucinations in the dataset, the performance of the NLI model, and the characteristics of the language pair.
- What evidence would resolve it: A comprehensive study varying the threshold across a wider range and multiple datasets, analyzing the trade-off between faithfulness and informativeness.

### Open Question 2
- Question: How does the performance of faithfulness-aware training approaches generalize to other cross-lingual summarization datasets and languages beyond the ones studied?
- Basis in paper: [inferred] The authors evaluate their approaches on the XWikis dataset and extend it with Chinese, but do not explore other datasets or languages.
- Why unresolved: The XWikis dataset and the added Chinese subset may have specific characteristics that make the faithfulness-aware approaches effective.
- What evidence would resolve it: Experiments on multiple cross-lingual summarization datasets covering a diverse range of languages, domains, and data characteristics.

### Open Question 3
- Question: How do the faithfulness-aware training approaches compare to other methods for improving faithfulness in cross-lingual summarization, such as those based on contrastive learning or reinforcement learning?
- Basis in paper: [inferred] The authors focus on faithfulness-aware training approaches using unlikelihood loss and data filtering, without comparing to other techniques like CLIFF or CAPE.
- Why unresolved: There are various methods for improving faithfulness in summarization, and it is unclear how the faithfulness-aware training approaches compare to these alternatives.
- What evidence would resolve it: A comprehensive comparison of faithfulness-aware training approaches with other state-of-the-art methods for improving faithfulness in cross-lingual summarization.

## Limitations
- The core assumption that cross-lingual NLI generalizes well to CLS domains remains largely unproven beyond the XNLI benchmark
- Faithfulness evaluation relies on sentence-level scoring, which may miss cross-sentence hallucinations or require summary-level context
- The training data filtering approaches depend on the quality of automatic faithfulness annotations, which hasn't been extensively validated against human judgments

## Confidence
- **High Confidence**: Faithfulness-aware training approaches improve faithfulness metrics while maintaining informativeness
- **Medium Confidence**: Cross-lingual NLI approximates human faithfulness judgements in CLS domains
- **Low Confidence**: The approach is directly applicable to LLM-generated summaries

## Next Checks
1. Test X-NLI faithfulness scores on a held-out CLS test set with human-annotated faithfulness labels to quantify correlation between automatic and human judgements
2. Extend INFUSE to handle summary-level evaluation rather than sentence-by-sentence scoring, then compare results
3. Apply X-NLI faithfulness evaluation to summaries generated by a state-of-the-art LLM for CLS tasks to validate relevance for LLM contexts