---
ver: rpa2
title: 'The Local Interaction Basis: Identifying Computationally-Relevant and Sparsely
  Interacting Features in Neural Networks'
arxiv_id: '2405.10928'
source_url: https://arxiv.org/abs/2405.10928
tags:
- features
- basis
- layer
- interaction
- activations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Local Interaction Basis (LIB), a method
  to find a more interpretable basis for neural network activations by removing irrelevant
  directions and aligning with singular vectors of Jacobian matrices between adjacent
  layers. LIB aims to identify computationally-relevant features and interactions
  by transforming activations into a new basis and creating interaction graphs using
  integrated gradients.
---

# The Local Interaction Basis: Identifying Computationally-Relevant and Sparsely Interacting Features in Neural Networks

## Quick Facts
- arXiv ID: 2405.10928
- Source URL: https://arxiv.org/abs/2405.10928
- Reference count: 40
- Key outcome: LIB finds more interpretable and sparse features than PCA on toy models but not on language models

## Executive Summary
This paper introduces the Local Interaction Basis (LIB), a method to identify computationally-relevant and sparsely interacting features in neural networks. LIB removes irrelevant activation directions and aligns the basis with singular vectors of Jacobian matrices between adjacent layers. The method was evaluated on modular addition and CIFAR-10 models, showing improved feature interpretability and sparsity compared to PCA. However, on language models like GPT2-small and TinyStories-1M, LIB did not significantly improve interpretability or interaction sparsity, suggesting limitations in its applicability to larger, more complex models.

## Method Summary
LIB is a two-step basis transformation method that first applies PCA to remove irrelevant directions and whiten activations, then aligns the basis with right singular vectors of Jacobian matrices between adjacent layers. This alignment minimizes interactions between features in adjacent layers. Integrated gradients are used to quantify feature interactions, creating an interaction graph that reveals the network's computational structure. Edge ablation experiments measure interaction sparsity by removing edges while maintaining performance thresholds.

## Key Results
- LIB features were more interpretable and interactions sparser than PCA features on modular addition and CIFAR-10 models
- LIB did not improve interpretability or sparsity for GPT2-small and TinyStories-1M language models
- Edge ablation showed LIB produced sparser interactions than PCA in some layers of language models, but the improvement was not consistent
- Modularity analysis revealed feature communities in interaction graphs, though these were not always more interpretable than PCA communities

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Removing degenerate activation directions and aligning the basis with singular vectors of Jacobian matrices produces a representation where features interact more sparsely.
- **Mechanism**: The Local Interaction Basis (LIB) first applies PCA to drop directions with near-zero variance and whiten activations. Then, it computes Jacobians between adjacent layers and aligns the basis with right singular vectors of these Jacobians. This alignment minimizes interactions between features in adjacent layers by ensuring each feature direction corresponds to a direction of maximum independent influence.
- **Core assumption**: Features in neural networks are represented in a non-overcomplete basis, and the primary sources of freedom in the loss landscape are linear dependencies in activations and gradients between layers.
- **Evidence anchors**:
  - [abstract]: "Our method drops irrelevant activation directions and aligns the basis with the singular vectors of the Jacobian matrix between adjacent layers."
  - [section 2.1]: "The second rotation achieves multiple goals... Secondly, the rotation into the SVD basis should make the interactions between features in adjacent layers as sparse as possible."
  - [corpus]: Weak evidence - related works focus on SAEs and sparse coding, but none directly test Jacobian-based basis alignment.
- **Break condition**: If the model represents features in superposition (overcomplete basis) rather than a linear non-overcomplete basis, this mechanism fails to produce interpretable features.

### Mechanism 2
- **Claim**: Integrated gradients attribution method provides a principled way to quantify interactions between LIB features across layers.
- **Mechanism**: Integrated gradients are used to attribute the influence of one feature in layer l on another feature in layer l+1. By averaging these attributions over the dataset (using RMS), the method creates an interaction graph that represents computationally-relevant connections. The method satisfies properties like implementation invariance, completeness, and robustness to basis transformations.
- **Core assumption**: Integrated gradients uniquely satisfy the desired properties for attribution methods and accurately capture the influence between features in the transformed basis.
- **Evidence anchors**:
  - [abstract]: "It also scales features based on their importance for downstream computation, producing an interaction graph that shows all computationally-relevant features and interactions in a model."
  - [section 2.2]: "Integrated gradients [IGs, Friedman, 2004] have been previously used to attribute neural network outputs to inputs... We employ IGs to represent the full network as an interaction graph to reveal hidden structure in neural networks."
  - [corpus]: Strong evidence - Integrated gradients are well-established with theoretical guarantees for attribution.
- **Break condition**: If the activation functions are highly non-linear or the dataset is too small, the integrated gradients approximation may not accurately capture feature interactions.

### Mechanism 3
- **Claim**: Sparsity of interactions can be quantitatively measured by edge ablation experiments, where edges are removed starting from the smallest until a performance threshold is reached.
- **Mechanism**: The edge ablation test measures how many interactions can be removed while maintaining a given accuracy or loss threshold. This provides a quantitative metric for interaction sparsity - fewer edges needed to maintain performance indicates sparser interactions. The method assumes edge size is a good proxy for interaction importance.
- **Core assumption**: The magnitude of integrated gradient attributions accurately reflects the importance of feature interactions for model performance.
- **Evidence anchors**:
  - [section 2.3]: "To test the sparsity of a layer in a given basis we sort all edges by their size... and then remove as many edges as possible, starting with the smallest ones, while maintaining a given accuracy or loss."
  - [section 3.1.3]: "As our main metric for interaction sparsity we use edge ablations... We measure how many interactions between features can be ablated while maintaining a classification accuracy that is within 0.1 percentage points of the original model's accuracy."
  - [corpus]: Moderate evidence - Edge ablation is commonly used in mechanistic interpretability but its validity as a sparsity metric is not universally established.
- **Break condition**: If important interactions have small attribution magnitudes due to cancellation effects or if the model has redundant pathways, this metric may not accurately reflect true interaction sparsity.

## Foundational Learning

- **Concept**: Singular Value Decomposition (SVD) and its application to Jacobians
  - Why needed here: LIB uses SVD of Jacobian matrices between layers to find a basis that minimizes feature interactions. Understanding SVD helps explain why aligning with right singular vectors produces sparse interactions.
  - Quick check question: If you have a Jacobian matrix J between two layers, what do the right singular vectors represent in terms of feature interactions?

- **Concept**: Principal Component Analysis (PCA) and whitening transformations
  - Why needed here: LIB starts with PCA to remove irrelevant directions and whiten activations before the second transformation. Understanding PCA is essential to grasp why the first step removes noise and prepares for the Jacobian-based alignment.
  - Quick check question: Why does removing directions with near-zero principal values help in finding computationally-relevant features?

- **Concept**: Integrated gradients attribution method
  - Why needed here: The paper uses integrated gradients to quantify interactions between features in the LIB basis. Understanding this method is crucial for interpreting the interaction graphs and sparsity measurements.
  - Quick check question: What are the key properties that make integrated gradients suitable for measuring feature interactions compared to other attribution methods?

## Architecture Onboarding

- **Component map**: PCA transformation -> Jacobian SVD alignment -> Integrated gradient interaction graph -> Edge ablation analysis -> Modularity detection
- **Critical path**: 
  1. Compute PCA basis for each layer (center, rotate to principal components, drop near-zero variance directions, rescale)
  2. Recursively compute LIB basis from final layer backward (compute Jacobians, SVD, align and rescale)
  3. Calculate integrated gradients between adjacent LIB-transformed layers
  4. Build interaction graph and analyze sparsity/modularity
- **Design tradeoffs**:
  - Computational cost vs. accuracy: Using stochastic sources reduces Jacobian computation cost but introduces approximation error
  - Dataset size: Larger datasets improve LIB basis quality but increase computational requirements
  - Layer selection: Including too few layers misses network structure; too many increases complexity
  - Basis choice: LIB vs. GIB (global interaction basis) - LIB is computationally cheaper but both yield similar results
- **Failure signatures**:
  - LIB features not more interpretable than PCA features (especially in language models)
  - Interaction graphs remain dense even after LIB transformation
  - Edge ablation requires nearly all edges to maintain performance (low sparsity)
  - Modularity algorithm fails to find meaningful modules in interaction graphs
  - Computational cost becomes prohibitive for large models with many layers
- **First 3 experiments**:
  1. Apply LIB to a simple MLP on MNIST: Compare interpretability and sparsity against PCA, verify that edge ablation shows LIB is sparser
  2. Run edge ablation on a small transformer on modular addition: Test if LIB finds sparser interactions than PCA in attention and MLP layers
  3. Visualize LIB vs PCA features on CIFAR-10: Check if LIB isolates interpretable features (like animal vs vehicle) better than PCA

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Local Interaction Basis (LIB) method improve interpretability of features in large language models (LLMs) beyond what is achievable with Principal Component Analysis (PCA)?
- Basis in paper: [explicit] The paper found that LIB features in GPT2-small and TinyStories-1M were not more interpretable than PCA features.
- Why unresolved: While the paper tested LIB on GPT2-small and TinyStories-1M, these are still relatively small language models. It is unclear if LIB would be effective on larger, more complex LLMs like GPT-3 or PaLM.
- What evidence would resolve it: Applying LIB to larger language models and comparing the interpretability of LIB features to PCA features. If LIB consistently produces more interpretable features, it would suggest the method is effective for LLMs.

### Open Question 2
- Question: Can the LIB method be extended to handle overcomplete bases of features, where the number of features exceeds the number of dimensions in the activation space?
- Basis in paper: [inferred] The paper assumes features are represented in a non-overcomplete basis, but acknowledges that features could be represented in superposition using sparse coding.
- Why unresolved: The current LIB method is not designed to handle overcomplete bases. If features are indeed represented in superposition, LIB would not be able to identify them.
- What evidence would resolve it: Developing a generalization of LIB that can handle overcomplete bases and testing it on models where features are known to be represented in superposition.

### Open Question 3
- Question: Does the LIB method lead to more sparsely interacting features in language models compared to PCA?
- Basis in paper: [explicit] The paper found that LIB produced more sparsely interacting representations than PCA in some layers of GPT2-small and TinyStories-1M.
- Why unresolved: The improvement in sparsity was not consistent across all layers and models tested. It is unclear if LIB would consistently produce sparser interactions in other language models or if the improvement is marginal.
- What evidence would resolve it: Applying LIB to a wider range of language models and measuring the sparsity of interactions compared to PCA. If LIB consistently produces significantly sparser interactions, it would suggest the method is effective for this purpose.

## Limitations
- LIB shows no clear advantage over PCA for language models despite working well on toy tasks
- Computational cost of Jacobian calculations could become prohibitive for very deep networks
- The method assumes features are represented in a non-overcomplete basis, which may not hold for all models

## Confidence
- **High confidence**: LIB's mechanism on toy models (modular addition, CIFAR-10) - the results are clear and reproducible with strong quantitative evidence
- **Medium confidence**: The theoretical justification for LIB's two-step transformation - the reasoning is sound but not extensively validated on complex models
- **Low confidence**: Claims about LIB's applicability to large language models - the empirical results directly contradict the potential shown on simpler tasks

## Next Checks
1. Test LIB on a larger-scale toy task that bridges modular arithmetic and language, such as arithmetic word problems, to identify where the method begins to fail
2. Implement computational optimizations for Jacobian calculation (e.g., randomized SVD or layer-wise approximation) and measure the tradeoff between accuracy and efficiency
3. Conduct ablation studies removing either the PCA or Jacobian alignment step to quantify each component's contribution to LIB's performance