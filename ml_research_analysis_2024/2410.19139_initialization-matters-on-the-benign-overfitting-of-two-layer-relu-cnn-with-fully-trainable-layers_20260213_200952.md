---
ver: rpa2
title: 'Initialization Matters: On the Benign Overfitting of Two-Layer ReLU CNN with
  Fully Trainable Layers'
arxiv_id: '2410.19139'
source_url: https://arxiv.org/abs/2410.19139
tags:
- lemma
- have
- first
- inequality
- output
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies benign overfitting in two-layer ReLU convolutional
  neural networks with fully trainable layers. The authors analyze how the initialization
  scale of the output layer affects training dynamics and generalization.
---

# Initialization Matters: On the Benign Overfitting of Two-Layer ReLU CNN with Fully Trainable Layers

## Quick Facts
- arXiv ID: 2410.19139
- Source URL: https://arxiv.org/abs/2410.19139
- Authors: Shuning Shang; Xuran Meng; Yuan Cao; Difan Zou
- Reference count: 40
- Primary result: Identifies sharp conditions on output layer initialization for benign overfitting in two-layer ReLU CNNs

## Executive Summary
This paper studies benign overfitting in two-layer ReLU convolutional neural networks with fully trainable layers. The authors analyze how the initialization scale of the output layer affects training dynamics and generalization. They show that large output initialization leads to fixed-output-like behavior with independent layer growth, while small initialization causes complex interactions with balanced layer growth. Under specific conditions on dimension, sample size, network width, and initialization scales, the authors establish nearly matching upper and lower bounds on test errors.

## Method Summary
The study uses a synthetic data model combining signal and noise patches, where inputs contain one patch as y·µ (signal) and another as ξ (noise). A two-layer ReLU CNN is implemented with both hidden and output layers trainable via gradient descent on logistic loss. The hidden layer is initialized from N(0, σ₀²) and output layer with constant v₀. Training runs for T = 200 iterations with learning rate η = 0.01, and test error is evaluated on 1000 i.i.d. test examples to analyze phase transitions by varying v₀ and ∥µ‖₂.

## Key Results
- Large output initialization (v₀) causes dynamics similar to fixed-output-layer models with rapid hidden layer growth
- Small output initialization creates balanced layer growth and more complex interactions between layers
- Sharp phase transitions identified between benign and harmful overfitting based on initialization scale and signal-to-noise ratio
- Nearly matching upper and lower bounds on test errors established under specific conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Output layer initialization scale determines whether training mimics fixed-output models or exhibits complex layer interactions
- Mechanism: Large v₀ keeps output updates small relative to hidden layer, creating fixed-output-like dynamics. Small v₀ causes balanced growth between layers.
- Core assumption: Weight change ratio depends critically on output initialization scale
- Evidence anchors:
  - [abstract] "large scales make the model training behave similarly to that with the fixed output, the hidden layer grows rapidly while the output layer remains largely unchanged; in contrast, small scales result in more complex layer interactions"
  - [section 3] "When v0 ≥ ev, if ∥µ∥4 2/σ4 p =eΩ(d/n), the trained CNN will generalize with small classification error"

### Mechanism 2
- Claim: Phase transition in benign overfitting based on output layer initialization scale
- Mechanism: For large v₀, benign overfitting requires ∥µ∥4 2/σ4 p =eΩ(d/n). For small v₀, requires mv²₀∥µ∥²₂/σₚ =eΩ(1).
- Claim: Balanced layer growth constrains signal learning and noise memorization rates
- Mechanism: When layers are balanced, growth rates are constrained, preventing excessive noise memorization while allowing signal learning
- Core assumption: Balanced growth ratio creates stable regime preventing harmful overfitting
- Evidence anchors:
  - [abstract] "under specific conditions on dimension, sample size, network width, and initialization scales, the authors establish nearly matching upper and lower bounds on test errors"
  - [section 4.3] "there exists a phase transition when the initialization scale of the output layer is small and the ratio of two layers(i.e.⟨w(t) yi,r, ξi⟩/v(t) yi,r,2) will remain consistent in the second phase"

### Mechanism 3
- Claim: Two-stage analysis captures distinct signal learning and noise memorization dynamics
- Mechanism: Stage 1 (constant loss derivative) captures initial growth; Stage 2 (loss optimization) captures convergence with bounded coefficients
- Core assumption: Constant loss derivative in Stage 1 allows clean characterization before complex interactions dominate
- Evidence anchors:
  - [section 4.2] "we divide the whole training process into two stages, where in Stage 1 the loss derivative is at constant order on all training samples and in Stage 2 the training loss is optimized to be arbitrarily small"
  - [section 4.3] "we also use two-stage analysis, but the process of the first stage is more complicated as two layers will become balanced before the end of this stage"

## Foundational Learning

- Concept: Signal-noise decomposition in neural networks
  - Why needed here: Paper relies on decomposing network weights into signal and noise components to analyze generalization
  - Quick check question: Can you explain why decomposing w(t) j,r = w(0) j,r + j · γ(t) j,r · ∥µ∥−2 2 · µ + Σ ρ(t) j,r,i · ∥ξi∥−2 2 · ξi helps analyze generalization?

- Concept: Balanced growth in interconnected dynamical systems
  - Why needed here: Paper uses balanced growth between hidden and output layers to characterize training dynamics
  - Quick check question: What conditions must be satisfied for two intertwined sequences to reach a balanced state where their ratio remains constant?

- Concept: Phase transitions in overparameterized models
  - Why needed here: Paper identifies sharp phase transitions between benign and harmful overfitting based on initialization scales
  - Quick check question: How does changing the output layer initialization v0 shift the phase boundary between benign and harmful overfitting?

## Architecture Onboarding

- Component map: Input features x (containing y·µ signal patch and ξ noise patch) -> Two-layer ReLU CNN (hidden filters wj,r with ReLU, output weights vj,r,p) -> Logits Fj(W, v; x) -> Logistic loss

- Critical path:
  1. Initialize hidden layer with N(0, σ²₀) and output layer with v₀
  2. Compute gradients for both layers using logistic loss
  3. Update both layers simultaneously via gradient descent
  4. Monitor training loss and test error
  5. Identify phase transition based on initialization scale

- Design tradeoffs:
  - Large v₀: Simpler dynamics, fixed-output-like behavior, but may require stronger signal strength for benign overfitting
  - Small v₀: More complex interactions, potentially better benign overfitting with weaker signals, but harder to analyze theoretically

- Failure signatures:
  - Training loss doesn't converge: Check if Condition 3.1 bounds are satisfied
  - Test error remains high despite perfect training fit: May indicate harmful overfitting due to initialization scale or signal-to-noise ratio
  - Numerical instability: Verify that learning rate and initialization scales satisfy technical conditions

- First 3 experiments:
  1. Verify phase transition by sweeping v₀ and measuring test accuracy across different ∥µ∥₂ values
  2. Test balanced growth by monitoring the ratio ⟨w(t) j,r, ξk⟩/v(t) j,r,2 during training
  3. Validate two-stage analysis by checking if loss derivative remains constant in early training stages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do initialization scale bounds for benign overfitting generalize to deeper networks with more than two layers?
- Basis in paper: [inferred] Paper establishes sharp conditions for two-layer networks but analysis relies on tractable dynamics that may not extend to deeper architectures
- Why unresolved: Theoretical framework specifically designed for two-layer networks where interaction between hidden and output layers can be precisely characterized
- What evidence would resolve it: Theoretical analysis showing how initialization scale bounds scale with network depth, or empirical results demonstrating similar phase transitions in deeper networks

### Open Question 2
- Question: What is the impact of non-Gaussian data distributions on the benign overfitting phenomenon studied in this paper?
- Basis in paper: [inferred] Paper uses Gaussian noise model and Rademacher labels, but real-world data often follows different distributions
- Why unresolved: Theoretical results rely heavily on Gaussianity of noise component for concentration inequalities and analysis tractability
- What evidence would resolve it: Experimental results on benign overfitting with various non-Gaussian data distributions, or theoretical bounds that hold under broader distributional assumptions

### Open Question 3
- Question: How do alternative optimizers (e.g., Adam, SGD with momentum) affect the phase transition between benign and harmful overfitting identified in this work?
- Basis in paper: [explicit] Paper uses gradient descent with fixed learning rate but states "it is also interesting to investigate more practical neural network models, such as the model with skip connection and the model with the normalization layer"
- Why unresolved: Different optimizers have distinct update rules that could change relative growth rates of hidden and output layers
- What evidence would resolve it: Comparative experiments showing how phase transition boundary changes under different optimizers, or theoretical analysis of optimizer-specific dynamics

## Limitations
- Analysis relies heavily on specific signal-noise data model and Gaussian initialization assumptions
- Theoretical guarantees may not extend to more complex data distributions or non-Gaussian initialization schemes
- Two-stage analysis may miss subtle interactions during transition between stages
- Conditions on initialization scales and signal-to-noise ratios are sharp but may be difficult to verify in practice

## Confidence
- **High Confidence**: Identification of phase transitions based on output initialization scale (Mechanism 2)
- **Medium Confidence**: Balanced growth analysis and its connection to benign overfitting (Mechanism 1)
- **Low Confidence**: Two-stage decomposition's ability to capture all relevant training dynamics (Mechanism 3)

## Next Checks
1. Test robustness of phase transitions by introducing correlated noise in data model and measuring shifts in the v₀ boundary
2. Implement numerical verification of balanced growth ratios during training across different initialization scales
3. Extend analysis to include momentum-based optimization methods and compare phase transition boundaries with vanilla gradient descent