---
ver: rpa2
title: Cross-Domain Continual Learning via CLAMP
arxiv_id: '2405.07142'
source_url: https://arxiv.org/abs/2405.07142
tags:
- domain
- learning
- https
- clamp
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the cross-domain continual learning problem,
  where a model must learn from a sequence of tasks across two different but related
  domains (source and target) without forgetting previous knowledge. CLAMP, the proposed
  solution, integrates class-aware adversarial domain adaptation with an assessor-guided
  learning process.
---

# Cross-Domain Continual Learning via CLAMP

## Quick Facts
- arXiv ID: 2405.07142
- Source URL: https://arxiv.org/abs/2405.07142
- Authors: Weiwei Weng; Mahardhika Pratama; Jie Zhang; Chen Chen; Edward Yapp Kien Yee; Ramasamy Savitha
- Reference count: 40
- Primary result: CLAMP achieves at least 10% improvement over baselines on cross-domain continual learning benchmarks

## Executive Summary
This paper addresses the challenging problem of cross-domain continual learning, where a model must learn from a sequence of tasks across two different but related domains (source and target) without forgetting previous knowledge. The proposed solution, CLAMP, integrates class-aware adversarial domain adaptation with an assessor-guided learning process. The assessors assign weights to samples and loss functions to balance stability and plasticity, preventing catastrophic forgetting. Meta-learning is used to train the assessors, with one focusing on the source domain and the other on the target domain. Theoretical analysis and extensive experiments demonstrate that CLAMP significantly outperforms established baselines by at least 10% across various benchmarks.

## Method Summary
CLAMP is a continual learning approach that addresses both catastrophic forgetting and domain shifts simultaneously. The method integrates class-aware adversarial domain adaptation to align source and target domains while preserving class discriminability. Two assessors are trained using meta-learning: one for the source domain to prevent negative transfer, and one for the target domain to handle noisy pseudo-labels. The base learner is optimized using a bi-level optimization framework where assessors guide the learning process through weighted loss functions. The method employs episodic memories for replay and uses gradient reversal for domain alignment. Training involves alternating between unsupervised domain adaptation, source domain training with assessor-guided weighting, and target domain training with pseudo-labeling and assessor-guided weighting.

## Key Results
- CLAMP achieves at least 10% improvement over established baselines across all tested benchmarks (MNIST/USPS, Office-31, Office-Home, VisDA)
- Performance is measured as average classification accuracy across all tasks on the unlabelled target domain
- Ablation studies demonstrate the effectiveness of each component, with the dual assessor mechanism being particularly critical for performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CLAMP's dual meta-training loop in source and target domains effectively balances plasticity and stability by dynamically adjusting sample weights and loss function contributions.
- Mechanism: The assessor networks generate a set of three weights for each sample, controlling the influence of the cross-entropy loss, DER loss, and distillation loss. This soft-weighting approach allows the model to focus on relevant samples and minimize the impact of noisy pseudo-labels or negative transfer.
- Core assumption: The assessors can accurately differentiate between useful and harmful samples in both domains through meta-learning.
- Evidence anchors:
  - [abstract]: "Both assessors are trained in the meta-learning approach using random transformation techniques and similar samples of the source domain."
  - [section 4.1]: "The meta-weighting approach to the three loss functions is applied here to achieve proper tradeoff between the plasticity and the stability."
- Break condition: If the assessors fail to properly identify relevant samples, the soft-weighting becomes ineffective, leading to either excessive plasticity (forgetting) or excessive stability (inability to learn new tasks).

### Mechanism 2
- Claim: Class-aware adversarial domain adaptation in CLAMP aligns the source and target domains while preserving class discriminability.
- Mechanism: The feature extractor is trained adversarially against a domain classifier to produce domain-invariant features. Simultaneously, pseudo-labeling of the target domain ensures class alignment, and the target assessor filters out noisy pseudo-labels.
- Core assumption: The domain adaptation can effectively minimize the domain discrepancy while the pseudo-labeling process remains accurate enough for meaningful class alignment.
- Evidence anchors:
  - [abstract]: "Our approach, namely continual learning approach for many processes (CLAMP), integrates a class-aware adversarial domain adaptation strategy to align a source domain and a target domain."
  - [section 4.2]: "Our approach makes use of the class-aware adversarial domain adaptation strategy... deploying the domain classifier... to classify the origin of features generated by the feature extractor."
- Break condition: If the domain discrepancy is too large or the pseudo-labeling accuracy is too low, the adversarial alignment may fail, leading to poor cross-domain generalization.

### Mechanism 3
- Claim: The bi-level optimization framework in CLAMP ensures that both the base learner and assessors are optimized collaboratively, leading to improved generalization.
- Mechanism: The base learner is updated using the training set in the outer loop, while the assessors are updated using the validation set in the inner loop. This meta-learning approach allows the assessors to guide the learning process of the base learner based on validation performance.
- Core assumption: The validation set is representative enough to provide meaningful feedback for assessor optimization.
- Evidence anchors:
  - [section 4.1]: "The meta-learning approach is adopted to train both the base learner and the assessor... The training process of the base learner and the assessor is formulated as a bi-level optimization problem."
  - [section 4.3]: "The meta training process is carried out similarly as the training strategy of the source domain where the bi-level optimization strategy is formulated."
- Break condition: If the validation set is not representative or the meta-learning process is not properly tuned, the assessors may provide misleading guidance, leading to suboptimal base learner performance.

## Foundational Learning

- Concept: Continual Learning
  - Why needed here: The cross-domain continual learning problem involves learning a sequence of tasks across two different but related domains without forgetting previous knowledge.
  - Quick check question: What are the key challenges in continual learning, and how do they manifest in the cross-domain setting?

- Concept: Domain Adaptation
  - Why needed here: The source and target domains are different but related, requiring techniques to align their distributions and enable knowledge transfer.
  - Quick check question: What are the main approaches to domain adaptation, and how do they differ in handling labeled and unlabeled target data?

- Concept: Meta-Learning
  - Why needed here: The assessors in CLAMP are trained using a meta-learning approach to guide the learning process of the base learner based on validation performance.
  - Quick check question: How does meta-learning differ from traditional learning, and what are its key advantages in the context of continual learning?

## Architecture Onboarding

- Component map: feature extractor (fŒ∏) -> classifier (gœÜ) -> domain classifier (Œæœà) ; source assessor (Œ∫S) ; target assessor (Œ∫T) ; episodic memories

- Critical path: 1. Unsupervised domain adaptation (feature alignment) 2. Source domain training (with assessor-guided weighting) 3. Target domain training (with pseudo-labeling and assessor-guided weighting)

- Design tradeoffs:
  - Memory vs. performance: Larger episodic memories improve performance but increase memory usage
  - Assessor complexity vs. training time: More complex assessors may provide better guidance but increase training time
  - Domain adaptation strength vs. class discriminability: Stronger domain alignment may reduce class discriminability

- Failure signatures:
  - Poor cross-domain performance: Domain adaptation may not be effective
  - Catastrophic forgetting: Assessor weighting may not be properly tuned
  - Slow convergence: Meta-learning hyperparameters may need adjustment

- First 3 experiments:
  1. Ablation study: Remove one component (e.g., source assessor) and compare performance
  2. Memory analysis: Vary episodic memory size and measure impact on performance
  3. Sensitivity analysis: Tune learning rates and other hyperparameters to find optimal settings

## Open Questions the Paper Calls Out

- Open Question 1: How does CLAMP perform under source-free domain adaptation, where no source domain samples are available during target domain learning?
  - Basis in paper: [inferred] The paper acknowledges this as a limitation, noting that CLAMP requires access to source domain samples for domain adaptation.
  - Why unresolved: The current framework relies on source samples for domain alignment, and the paper does not explore modifications for source-free scenarios.
  - What evidence would resolve it: Experiments comparing CLAMP's performance in source-free vs. source-available settings on cross-domain continual learning benchmarks.

- Open Question 2: What is the impact of varying the pseudo-label selection threshold (ùõæ) on CLAMP's performance in highly imbalanced cross-domain scenarios?
  - Basis in paper: [explicit] The paper reports sensitivity analysis on ùõæ, finding it affects performance by ~1%, but does not explore extreme class imbalance.
  - Why unresolved: The analysis is limited to balanced class settings, and extreme imbalance is common in real-world cross-domain scenarios.
  - What evidence would resolve it: Experiments evaluating CLAMP's accuracy and robustness across varying ùõæ values in highly imbalanced datasets.

- Open Question 3: Can CLAMP's assessor-guided learning mechanism be extended to handle partial, open-set, or universal domain adaptation scenarios?
  - Basis in paper: [explicit] The paper identifies this as a limitation, noting the current setting assumes identical label spaces across domains.
  - Why unresolved: The current dual assessor framework is designed for closed-set alignment and does not address label space discrepancies.
  - What evidence would resolve it: Modified CLAMP implementations tested on partial, open-set, or universal domain adaptation benchmarks with varying label space overlaps.

## Limitations

- The method requires access to source domain samples during target domain learning, limiting its applicability to source-free scenarios
- The approach assumes identical label spaces across source and target domains, not addressing partial, open-set, or universal domain adaptation
- The computational overhead of maintaining two separate meta-learning loops and episodic memories for both domains is not thoroughly analyzed

## Confidence

- High confidence: The effectiveness of combining domain adaptation with continual learning for cross-domain scenarios, supported by consistent performance improvements across all four benchmarks
- Medium confidence: The specific contributions of each component (assessors, dual memory, adversarial alignment), as ablation studies show combined performance but individual component impacts are not isolated
- Low confidence: The generalizability to scenarios with larger domain gaps or when source domain labels are partially available, as the paper focuses on fully labeled source and unlabeled target domains

## Next Checks

1. Perform a detailed ablation study isolating each assessor's contribution by training CLAMP with only source assessor, only target assessor, and both assessors disabled
2. Conduct experiments varying the pseudo-labeling threshold to quantify the sensitivity of performance to target domain label noise
3. Test CLAMP on datasets with more extreme domain shifts (e.g., synthetic to real images) to evaluate the limits of the adversarial domain alignment mechanism