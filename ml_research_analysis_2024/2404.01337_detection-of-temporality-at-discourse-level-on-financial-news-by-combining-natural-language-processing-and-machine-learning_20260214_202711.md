---
ver: rpa2
title: Detection of Temporality at Discourse Level on Financial News by Combining
  Natural Language Processing and Machine Learning
arxiv_id: '2404.01337'
source_url: https://arxiv.org/abs/2404.01337
tags:
- news
- features
- future
- temporal
- ticker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach for detecting the temporality
  of key statements in financial news at the discourse level, distinguishing between
  past events and future predictions. The method combines NLP techniques (dependency
  parsing, verb proximity analysis) with machine learning algorithms to extract temporal
  features from text, including syntactic and semantic dependencies.
---

# Detection of Temporality at Discourse Level on Financial News by Combining Natural Language Processing and Machine Learning

## Quick Facts
- arXiv ID: 2404.01337
- Source URL: https://arxiv.org/abs/2404.01337
- Reference count: 26
- The system achieves >80% precision and recall for classifying past vs. future temporality in financial news using dependency parsing and verb proximity features.

## Executive Summary
This paper presents a novel approach for detecting temporality in financial news discourse by combining natural language processing techniques with machine learning. The method distinguishes between statements describing past events and future predictions, addressing a critical need for market screening applications. By analyzing syntactic and semantic dependencies through dependency parsing and verb proximity analysis, the system extracts temporal features from text. The approach was validated on a manually annotated dataset of 600 financial news articles, achieving strong performance metrics that significantly outperformed rule-based baselines.

## Method Summary
The approach combines dependency parsing and verb proximity analysis with machine learning algorithms to extract temporal features from financial news text. The system analyzes syntactic and semantic dependencies to identify temporal patterns at the discourse level, distinguishing between past events and future predictions. A manually annotated dataset of 600 financial news articles was used for training and evaluation. The method employs feature engineering based on dependency relationships and verb proximity, then applies an SVC classifier to achieve high precision and recall for both temporal classes.

## Key Results
- Achieved over 80% precision and recall for both past and future temporal classifications
- Significantly outperformed rule-based baseline systems with 8-10% improvement across all metrics
- Demonstrated effectiveness on manually annotated dataset of 600 financial news articles

## Why This Works (Mechanism)
The approach leverages dependency parsing to capture syntactic relationships and verb proximity analysis to identify temporal patterns in financial discourse. By combining these NLP techniques with machine learning, the system can effectively distinguish between past events and future predictions at the discourse level. The manual annotation of 600 articles provides a robust training dataset that captures the complexity of financial news language. The feature engineering process extracts meaningful temporal signals from text structure, while the SVC classifier learns to classify these patterns with high accuracy.

## Foundational Learning
- Dependency Parsing: Why needed - To capture syntactic relationships between words; Quick check - Verify parsing accuracy on financial domain-specific sentences
- Verb Proximity Analysis: Why needed - To identify temporal patterns based on verb relationships; Quick check - Test on sentences with varying verb distances
- Feature Engineering: Why needed - To extract meaningful temporal signals from text structure; Quick check - Analyze feature importance scores from trained model
- Manual Annotation: Why needed - To create a reliable ground truth for training and evaluation; Quick check - Inter-annotator agreement scores
- SVC Classification: Why needed - To learn patterns from engineered features for temporal classification; Quick check - Compare with alternative classification algorithms

## Architecture Onboarding

**Component Map:** Text Preprocessing -> Dependency Parsing -> Feature Extraction -> Classification -> Evaluation

**Critical Path:** The core pipeline flows from dependency parsing through feature extraction to SVC classification, with manual annotation providing the ground truth for training and evaluation.

**Design Tradeoffs:** The approach prioritizes feature engineering and traditional ML over deep learning methods, potentially sacrificing some performance for interpretability and reduced computational requirements. The manual annotation process ensures high-quality training data but limits scalability.

**Failure Signatures:** Performance may degrade on complex sentence structures or domain-specific terminology not captured in the feature engineering. The reliance on syntactic dependencies could miss nuanced temporal expressions that don't follow typical patterns.

**First 3 Experiments to Run:**
1. Test classification accuracy on sentences with varying syntactic complexity
2. Evaluate performance on domain-specific financial terminology and jargon
3. Assess impact of different dependency parsing configurations on temporal detection accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- The validation methodology lacks details on cross-validation or test set separation, raising concerns about potential overfitting
- The approach is not benchmarked against more recent transformer-based models that could provide context for its relative performance
- The feature engineering approach may not capture nuanced temporal expressions or complex sentence structures common in financial discourse

## Confidence
- High: The overall approach combining NLP and ML for temporal detection is technically sound and addresses a real problem in financial news analysis
- Medium: The reported >80% precision/recall metrics, pending clarification on validation methodology and comparison with more recent approaches
- Low: Claims about significant improvement over rule-based systems without detailed baseline methodology or more comprehensive comparative analysis

## Next Checks
1. Conduct k-fold cross-validation with the 600-article dataset to verify the stability of performance metrics across different data splits
2. Compare the approach against modern transformer-based models (BERT, RoBERTa) fine-tuned for temporal classification on the same dataset to establish relative performance
3. Perform ablation studies to quantify the contribution of individual feature types (dependency parsing, verb proximity) to overall classification accuracy