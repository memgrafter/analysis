---
ver: rpa2
title: Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats
  and Dogs Dataset
arxiv_id: '2401.04666'
source_url: https://arxiv.org/abs/2401.04666
tags:
- accuracy
- dataset
- adamax
- loss
- keras
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks ten pre-trained deep learning models on the
  ASSIRA Cats and Dogs dataset, comparing their performance under various optimizers,
  loss functions, and GPU architectures. Using transfer learning with data augmentation,
  the authors fine-tune models pre-trained on ImageNet.
---

# Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset

## Quick Facts
- arXiv ID: 2401.04666
- Source URL: https://arxiv.org/abs/2401.04666
- Authors: Galib Muhammad Shahriar Himel; Md. Masudul Islam
- Reference count: 40
- Primary result: NASNetLarge with Adamax optimizer and Binary Cross Entropy loss achieves 99.65% accuracy on ASSIRA Cats and Dogs dataset

## Executive Summary
This study benchmarks ten pre-trained deep learning models on the ASSIRA Cats and Dogs dataset, evaluating their performance under various optimizers, loss functions, and GPU architectures. Using transfer learning with data augmentation, the authors fine-tune models pre-trained on ImageNet and systematically test four optimizers and four loss functions across all models. Results show NASNetLarge with Adamax optimizer and Binary Cross Entropy loss achieves the highest accuracy of 99.65%, while Binary Cross Entropy and Hinge loss functions generally yield the best results. The study finds no linear correlation between model complexity and accuracy, and accuracy slightly improves with larger input images.

## Method Summary
The study uses transfer learning with ten pre-trained deep learning models (Xception, VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, MobileNet, MobileNetV2, DenseNet121, NASNetLarge) fine-tuned on the ASSIRA Cats and Dogs dataset. Models are pre-trained on ImageNet and fine-tuned using data augmentation including rescale, zoom range 0.3, rotation range 15, and horizontal flip. The evaluation tests four optimizers (Adam, Adamax, RMSprop, SGD) and four loss functions (Binary Cross Entropy, Categorical Cross Entropy, Hinge, KL Divergence) across three GPU architectures. Models are trained for 25 epochs with batch size 32 and learning rate 0.0001, with performance measured by accuracy, ROC-AUC, precision/recall/F1 scores, and training/validation loss curves.

## Key Results
- NASNetLarge with Adamax optimizer and Binary Cross Entropy loss achieves highest accuracy of 99.65%
- Binary Cross Entropy and Hinge loss functions generally yield the best results across models
- No linear correlation between model complexity and accuracy observed
- Accuracy slightly improves with larger input images up to hardware memory limits
- GPU architecture affects runtime but not accuracy

## Why This Works (Mechanism)

### Mechanism 1
Transfer learning from ImageNet pre-trained models yields high accuracy even with modest data augmentation. Pre-trained weights encode generic visual features (edges, textures) learned from 14M+ images. Fine-tuning on a small domain-specific dataset adapts these features without starting from random initialization. The target dataset (Cats vs Dogs) shares sufficient low-level visual statistics with ImageNet for weight reuse. Break condition: If domain shift is too large (e.g., medical imaging vs. natural images), fine-tuning may underperform training from scratch.

### Mechanism 2
Optimizer choice (Adamax) and loss function (Binary Cross Entropy) combination maximizes convergence speed and accuracy for binary classification. Adamax adapts learning rates using the infinity norm, providing stable updates for sparse gradients. Binary Cross Entropy directly models the probability of class membership in a two-class setting. The loss surface for binary classification is well-conditioned for Adamax; Binary Cross Entropy is the correct likelihood model. Break condition: If dataset becomes multi-class or highly imbalanced, BCE may not be optimal and Adamax benefits may diminish.

### Mechanism 3
Larger input resolution improves accuracy up to a hardware memory threshold. Higher resolution preserves fine-grained features (e.g., fur texture, eye shape) that are discriminative for cat/dog classes, while GPU memory limits maximum feasible resolution. Feature discriminability increases monotonically with resolution before GPU memory becomes the bottleneck. Break condition: When resolution exceeds GPU memory, batch size must shrink, potentially hurting convergence and negating accuracy gains.

## Foundational Learning

- Concept: Transfer learning in computer vision
  - Why needed here: Enables reuse of ImageNet-trained feature extractors, reducing training time and data requirements.
  - Quick check question: What is the difference between feature extraction and fine-tuning in transfer learning?

- Concept: Loss functions for binary classification
  - Why needed here: Binary Cross Entropy directly models class probabilities for two-class problems, yielding better gradients than multi-class losses.
  - Quick check question: Why is BCE preferred over categorical cross-entropy for binary tasks?

- Concept: GPU memory management and batch sizing
  - Why needed here: Determines maximum input resolution and batch size; impacts training speed and convergence.
  - Quick check question: How does increasing image resolution affect maximum batch size on a given GPU?

## Architecture Onboarding

- Component map: Dataset → Data Augmentation → Pre-trained Model (10 options) → Custom Output Layer → Optimizer (4) × Loss Function (4) → GPU Trainer (3 configs) → Evaluation (Accuracy, ROC, Confusion Matrix)
- Critical path: Data → Augmentation → Model Selection → Hyperparameter Tuning → GPU Execution → Metrics
- Design tradeoffs: Larger models (NASNetLarge) give best accuracy but require more memory/time; simpler models (MobileNetV2) trade accuracy for speed.
- Failure signatures: Training loss diverges → learning rate too high; validation loss plateaus → overfitting or insufficient data augmentation; GPU OOM → reduce resolution or batch size.
- First 3 experiments:
  1. Xception + Adamax + BCE at 224px resolution on RTX 3080Ti.
  2. NASNetLarge + Adamax + BCE at 331px resolution on RTX 3090.
  3. MobileNetV2 + RMSprop + BCE at 224px resolution on GTX 1070.

## Open Questions the Paper Calls Out

### Open Question 1
How do the performance characteristics of these pre-trained models on the ASSIRA Cats and Dogs dataset compare to their performance on the original ImageNet dataset? The study focuses solely on performance on the ASSIRA dataset and doesn't include ImageNet benchmark comparisons. Direct comparison of model accuracy and other metrics on both the ImageNet validation set and the ASSIRA dataset would resolve this.

### Open Question 2
What is the impact of different image preprocessing techniques on model performance, beyond the basic normalization and augmentation used in this study? The study uses standard normalization and augmentation but doesn't investigate alternative preprocessing techniques like histogram equalization or color space transformations. Systematic comparison of various preprocessing techniques while keeping all other variables constant would resolve this.

### Open Question 3
How does the performance of these models change when fine-tuning more layers of the pre-trained networks, rather than just the final classification layer? The study uses a limited fine-tuning approach and doesn't investigate the effects of unfreezing and training more layers. Comparative analysis of model performance with different levels of fine-tuning (e.g., last layer only vs. last 5 layers vs. full network) would resolve this.

## Limitations
- Exact random seed and reproducibility settings are not specified, which could affect result variability
- Implementation details for 5-fold cross-validation (fold sizes, stratification) are incomplete, potentially impacting model evaluation consistency
- NASNetLarge's highest accuracy (99.65%) may reflect dataset-specific characteristics rather than general superiority across domains

## Confidence
- High confidence: Transfer learning effectiveness and data augmentation benefits are well-established in computer vision literature and supported by the reported results.
- Medium confidence: Optimizer and loss function combinations show consistent performance patterns, but the superiority of Adamax + Binary Cross Entropy may not generalize to all binary classification tasks.
- Low confidence: The claim that "no linear correlation between model complexity and accuracy" is supported by the specific dataset results but may not hold for more complex or diverse image classification tasks.

## Next Checks
1. Implement exact random seeds and verify result stability across multiple runs with the same hyperparameters.
2. Test the same model/optimizer combinations on a different binary classification dataset (e.g., medical imaging) to assess generalization.
3. Systematically vary input resolution and batch size on different GPU architectures to quantify the accuracy gains versus memory constraints.