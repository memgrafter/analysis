---
ver: rpa2
title: Out-of-Distribution Detection with Attention Head Masking for Multimodal Document
  Classification
arxiv_id: '2408.11237'
source_url: https://arxiv.org/abs/2408.11237
tags:
- documents
- data
- detection
- attention
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces attention head masking (AHM), a novel approach
  for out-of-distribution (OOD) detection in multimodal document classification. AHM
  improves feature separation between in-distribution (ID) and OOD data by selectively
  masking attention heads in transformer models during inference.
---

# Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification

## Quick Facts
- arXiv ID: 2408.11237
- Source URL: https://arxiv.org/abs/2408.11237
- Reference count: 25
- Introduces attention head masking (AHM) for improved OOD detection in multimodal document classification

## Executive Summary
This paper introduces Attention Head Masking (AHM), a novel approach for out-of-distribution detection in multimodal document classification. AHM improves feature separation between in-distribution and OOD data by selectively masking attention heads in transformer models during inference. The method is evaluated on two datasets—Tobacco3482 and FinanceDocs—achieving significant improvements in OOD detection performance, including up to 7.5% reduction in false positive rates and increased AUROC compared to state-of-the-art methods.

## Method Summary
The method involves fine-tuning a LayoutLMv3 transformer model on in-distribution data, then applying random attention head masking during inference. Multiple random masks are generated and embeddings are extracted for each configuration. Similarity scores between ID training and evaluation sets are computed using k-nearest neighbors, and the top F masks are selected based on these scores. An ensemble of the selected masks generates final embeddings that are fed into distance-based OOD detection methods like Mahalanobis or kNN.

## Key Results
- AHM reduces false positive rates by up to 7.5% compared to state-of-the-art methods
- Achieves higher AUROC scores on both Tobacco3482 and FinanceDocs datasets
- Introduces FinanceDocs, a high-quality multimodal document dataset for OOD detection research

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Masking specific attention heads increases the distance between ID and OOD embeddings.
- **Mechanism**: Attention heads capture different patterns in input sequences. By masking heads that are less relevant for distinguishing ID from OOD, the remaining heads amplify the feature differences.
- **Core assumption**: Certain attention heads contribute more to semantic separation than others.
- **Evidence anchors**:
  - [abstract]: "By identifying masks that enhance similarity between ID training and evaluation features, we generate robust representations that improve the separation of ID and OOD data."
  - [section]: "we discovered that consistent masking could be achieved by selectively masking attention heads within different layers of the encoder."
- **Break condition**: If all attention heads are equally important for ID/OOD separation, masking would degrade rather than improve detection.

### Mechanism 2
- **Claim**: Random attention head masking followed by selection creates an ensemble that generalizes better.
- **Mechanism**: Random masking explores the space of possible feature representations. Selection based on ID similarity ensures the ensemble retains only the most discriminative patterns.
- **Core assumption**: The space of possible attention head configurations contains some that improve OOD detection.
- **Evidence anchors**:
  - [abstract]: "We propose a multi-head attention masking mechanism for transformer-based models applied post-fine-tuning."
  - [section]: "For each random mask, we extract dense hidden representations... The attention head masks are then ranked based on these aggregated similarity scores."
- **Break condition**: If the optimal configuration is unique and not captured by random exploration, ensemble averaging could dilute performance.

### Mechanism 3
- **Claim**: AHM improves the effectiveness of distance-based OOD detection methods like Mahalanobis.
- **Mechanism**: By creating embeddings with better ID/OOD separation, distance metrics become more discriminative. The Mahalanobis distance, which accounts for feature covariance, benefits from tighter ID clusters and better separation.
- **Core assumption**: Distance-based methods are sensitive to the quality of the embedding space.
- **Evidence anchors**:
  - [abstract]: "Our empirical results demonstrate that the proposed AHM method outperforms all state-of-the-art approaches and significantly decreases the false positive rate (FPR)."
  - [section]: "Our approach focuses on identifying more robust class-agnostic scores from the feature space, and as such, we conduct our experiments using distance/density-based OOD techniques."
- **Break condition**: If the embedding space becomes too sparse or distorted, distance metrics may become unreliable even if separation appears larger.

## Foundational Learning

- **Concept**: Transformer attention mechanism and multi-head attention
  - **Why needed here**: AHM operates by masking specific attention heads. Understanding how attention heads work and what they capture is essential to grasp why selective masking helps.
  - **Quick check question**: What is the difference between multi-head attention and single-head attention in transformers?

- **Concept**: Out-of-distribution detection metrics (AUROC, FPR)
  - **Why needed here**: The paper evaluates AHM using these metrics. Understanding what they measure is crucial for interpreting results.
  - **Quick check question**: What does an FPR of 0.071 at 95% TPR mean in practical terms?

- **Concept**: Distance-based OOD detection methods (Mahalanobis, kNN)
  - **Why needed here**: AHM generates embeddings that are fed into these methods. Understanding how they work explains why better embeddings lead to better detection.
  - **Quick check question**: How does Mahalanobis distance differ from Euclidean distance in OOD detection?

## Architecture Onboarding

- **Component map**: Fine-tuned transformer model -> Attention head masking layer -> Embedding extraction layer -> Distance-based OOD detection module -> Ensemble averaging layer

- **Critical path**:
  1. Fine-tune transformer on ID data
  2. Generate random attention head masks
  3. Extract embeddings for each mask configuration
  4. Compute similarity scores between ID training and validation sets
  5. Select top F attention head masks based on similarity scores
  6. Generate final embeddings using selected masks
  7. Apply distance-based OOD detection

- **Design tradeoffs**:
  - Masking percentage (p): Higher masking explores more configurations but may degrade baseline performance
  - Number of neighbors (K): Affects similarity score reliability
  - Budget (T): More trials improve mask selection but increase computation
  - Top masks (F): More masks in ensemble reduce variance but may include suboptimal configurations

- **Failure signatures**:
  - AUROC drops significantly when applying AHM (masking is harming rather than helping)
  - Similarity scores between ID training and validation data are inconsistent
  - Selected masks show high variance across runs (instability in mask selection)

- **First 3 experiments**:
  1. **Baseline verification**: Run kNN and Mahalanobis on fine-tuned model without AHM to establish baseline AUROC and FPR
  2. **Masking sensitivity**: Apply random masks with varying p values (0.1, 0.2, 0.3) and measure impact on ID classification accuracy
  3. **Ensemble size tuning**: Test different values of F (1, 3, 5, 7) to find optimal ensemble size for stability and performance

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the AHM method's performance vary across different transformer architectures beyond LayoutLMv3, particularly in non-document multimodal settings?
- **Open Question 2**: What is the computational overhead introduced by the AHM method during inference, and how does it scale with larger models and datasets?
- **Open Question 3**: How sensitive is AHM's performance to the choice of hyperparameters (masking percentage p, number of neighbors K, exploration budget T) across different datasets and OOD scenarios?

## Limitations
- Results are validated only on two document datasets, limiting generalizability to other domains
- Computational overhead of multiple inference passes and ensemble generation is not quantified
- Limited empirical evidence on which specific attention heads contribute most to semantic separation

## Confidence
- **High Confidence**: Empirical results showing AUROC improvements and FPR reduction are well-documented with specific metrics and statistical significance
- **Medium Confidence**: Architectural design of AHM is clearly specified, but theoretical justification for why selective head masking works remains incomplete
- **Low Confidence**: Claims about general applicability to other transformer architectures and domains lack supporting evidence

## Next Checks
1. **Attention Head Ablation Study**: Systematically analyze which attention heads contribute most to OOD detection by varying which heads are masked, rather than random selection, to identify patterns in head importance.
2. **Cross-Domain Generalization**: Test AHM on document datasets from different domains (medical records, legal documents, academic papers) to assess robustness beyond the two datasets used in the paper.
3. **Computational Efficiency Analysis**: Measure wall-clock time for AHM inference compared to baseline methods and calculate the performance-to-cost ratio to determine practical viability for production systems.