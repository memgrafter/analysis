---
ver: rpa2
title: 'Show, Don''t Tell: Evaluating Large Language Models Beyond Textual Understanding
  with ChildPlay'
arxiv_id: '2407.11068'
source_url: https://arxiv.org/abs/2407.11068
tags:
- game
- code
- quantity
- gpt-4
- gpt-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models are primarily evaluated on linguistic tasks,
  which may not fully capture their general reasoning abilities. To address this,
  the authors developed ChildPlay, a benchmark suite using non-language-based games
  like Tic-Tac-Toe, Connect Four, Battleship, LEGO Connect Language (LCL), and Shape
  Recognition to test strategic thinking, spatial reasoning, and generalization.
---

# Show, Don't Tell: Evaluating Large Language Models Beyond Textual Understanding with ChildPlay

## Quick Facts
- arXiv ID: 2407.11068
- Source URL: https://arxiv.org/abs/2407.11068
- Reference count: 40
- Primary result: Current LLMs exhibit limited cognitive flexibility and generalization when evaluated on non-linguistic reasoning tasks

## Executive Summary
This study challenges the adequacy of traditional linguistic benchmarks for evaluating large language models by introducing ChildPlay, a suite of non-language-based games designed to test strategic thinking, spatial reasoning, and generalization abilities. The benchmark includes games like Tic-Tac-Toe, Connect Four, Battleship, LEGO Connect Language (LCL), and Shape Recognition, all encoded in ASCII to minimize training data contamination. Testing GPT-3.5 and GPT-4 across different temperature settings revealed significant limitations in strategic gameplay and spatial reasoning, with models performing poorly compared to baseline approaches.

The research demonstrates that while LLMs can understand rules and generate basic responses, they struggle with tasks requiring genuine cognitive flexibility and generalization beyond language. Neither model could play Battleship correctly, both had difficulty with LCL assembly and validity detection, and performance on other games was inconsistent. The findings caution against claims of emergent intelligence in current LLMs and highlight the need for evaluation methods that test reasoning capabilities beyond linguistic understanding.

## Method Summary
The authors developed ChildPlay, a benchmark suite that evaluates LLMs on non-linguistic tasks through ASCII-encoded games. The suite includes five games: Tic-Tac-Toe, Connect Four, Battleship, LEGO Connect Language (LCL), and Shape Recognition. Each game tests different cognitive abilities including strategic thinking, spatial reasoning, and generalization. The ASCII encoding was specifically chosen to minimize contamination from training data. The benchmark was tested on GPT-3.5 and GPT-4 across different temperature settings, with results compared against a minimax baseline to assess strategic capabilities.

## Key Results
- Neither GPT-3.5 nor GPT-4 could play Battleship correctly despite understanding the rules
- Both models struggled significantly with LCL assembly and validity detection tasks
- GPT-4 showed some success in shape recognition while GPT-3.5 performed at chance level
- Performance was highly temperature-sensitive, indicating inconsistency in model responses

## Why This Works (Mechanism)
The ASCII encoding approach effectively isolates reasoning capabilities from language understanding by representing game states and actions through non-linguistic symbols. This design choice prevents models from relying on pattern matching from training data and forces them to engage with the underlying logical and spatial structures of the tasks. The temperature sensitivity observed suggests that current LLMs operate in a stochastic regime where reasoning quality varies significantly with sampling parameters.

## Foundational Learning
- ASCII encoding for game representation (why needed: prevents contamination from training data; quick check: verify ASCII mappings are consistent across all games)
- Minimax algorithm as strategic baseline (why needed: provides ground truth for optimal play; quick check: confirm minimax implementation covers all game states)
- Temperature scaling in LLM inference (why needed: affects stochasticity of outputs; quick check: measure variance across temperature settings)
- Spatial reasoning evaluation metrics (why needed: quantifies geometric understanding; quick check: validate metrics against human performance)
- Generalization testing through novel game configurations (why needed: assesses transfer learning; quick check: ensure configurations are unseen during training)
- Rule understanding vs. strategic execution (why needed: distinguishes comprehension from application; quick check: test rule explanation separately from gameplay)

## Architecture Onboarding

Component Map: ASCII Encoding -> LLM Inference -> Game State Evaluation -> Strategic Response Generation

Critical Path: ASCII representation → Model prompt processing → Output generation → Game state validation → Strategic decision making

Design Tradeoffs: ASCII encoding maximizes data hygiene but may introduce representation overhead; temperature sensitivity enables exploration but reduces reliability; baseline comparisons provide ground truth but may not reflect human-like reasoning patterns.

Failure Signatures: Inability to maintain game state consistency across turns, failure to recognize winning positions, inconsistent rule application, and inability to plan multi-step strategies.

First Experiments:
1. Test model performance on rule comprehension before gameplay to isolate understanding from execution
2. Evaluate human performance on the same tasks to establish baseline capabilities
3. Run models at extreme temperature settings (0.0 and 1.0) to map the full performance spectrum

## Open Questions the Paper Calls Out
None

## Limitations
- ASCII encoding may introduce representation challenges that affect model performance independently of reasoning capabilities
- Temperature sensitivity suggests current evaluation methods may not capture consistent model capabilities
- Performance differences between GPT-3.5 and GPT-4 were less pronounced than expected given their relative language task capabilities

## Confidence

High: Models demonstrate poor strategic gameplay and spatial reasoning capabilities across multiple game-based tasks. This is consistently observed across different models and temperature settings.

Medium: The claim that current LLMs exhibit limited cognitive flexibility and generalization. While supported by game performance data, the extent to which ASCII encoding affects these results is unclear.

Medium: The conclusion about the need for non-linguistic benchmarks. While the study provides compelling evidence, the specific choice of games and their encoding method may influence the generalizability of this claim.

## Next Checks
1. Replicate the benchmark using both ASCII and visual representations to isolate the impact of encoding method on performance.
2. Test additional model variants and sizes to determine if the observed limitations are consistent across the LLM landscape.
3. Implement a human performance baseline on the same tasks to contextualize the gap between current models and human-level reasoning capabilities.