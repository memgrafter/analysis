---
ver: rpa2
title: Nature-Inspired Local Propagation
arxiv_id: '2402.05959'
source_url: https://arxiv.org/abs/2402.05959
tags:
- equation
- learning
- which
- equations
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a biologically inspired learning approach for
  recurrent neural networks that aims to overcome the limitations of backpropagation
  by incorporating spatiotemporal locality into the learning process. The core method
  involves formulating learning as an optimal control problem and deriving Hamilton's
  equations, which naturally lead to local computations in both space and time.
---

# Nature-Inspired Local Propagation

## Quick Facts
- arXiv ID: 2402.05959
- Source URL: https://arxiv.org/abs/2402.05959
- Authors: Alessandro Betti; Marco Gori
- Reference count: 9
- Primary result: A biologically inspired learning approach for recurrent neural networks that reduces to backpropagation in the limit of infinite signal propagation speed while enabling local learning rules for finite speeds.

## Executive Summary
This paper proposes a novel learning approach for recurrent neural networks that overcomes backpropagation's limitations by incorporating spatiotemporal locality. The method formulates learning as an optimal control problem and derives Hamilton's equations, which naturally lead to local computations in both space and time. The approach reduces to backpropagation when signal propagation speed approaches infinity, while enabling biologically plausible online learning with finite propagation speeds.

## Method Summary
The method formulates recurrent neural network learning as an optimal control problem, where the goal is to minimize a cost functional combining weight change regularization and prediction error. By applying optimal control theory and deriving Hamilton's equations, the authors obtain local update rules that depend only on a neuron's immediate neighbors in the network graph. The Hamiltonian Sign Flip (HSF) strategy enables online learning by approximating boundary conditions with initial conditions through periodic sign flipping of the costate equations.

## Key Results
- The proposed method reduces to backpropagation when propagation speed approaches infinity
- Learning rules are spatially local, with updates depending only on immediate neighbors
- Hamiltonian Sign Flip strategy enables online learning while respecting biological constraints

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed method reduces to backpropagation in the limit of infinite signal propagation speed.
- Mechanism: As propagation speed parameter $c$ approaches infinity, costate equations simplify to backpropagation delta rule update with local computations.
- Core assumption: Network structure and activation functions satisfy conditions for reduction to hold (differentiable cost function and sigmoid-like activations).
- Evidence anchors:
  - [abstract]: "reduces to Backpropagation when the speed of propagation goes to infinity"
  - [section]: "Corollary 1 (Reduction to Backprop)" shows formal limit as $c \rightarrow \infty$
  - [corpus]: No direct evidence in corpus; this is a novel theoretical contribution
- Break condition: Non-differentiable activation functions or non-differentiable cost function may prevent reduction.

### Mechanism 2
- Claim: Learning rules are spatially local, with each neuron's update depending only on immediate neighbors.
- Mechanism: Hamiltonian formulation naturally leads to local update rules where each neuron's costate depends only on its children in the network graph.
- Core assumption: Network graph structure is fixed and update rules involve only local variables as defined by graph topology.
- Evidence anchors:
  - [abstract]: "enables local learning rules for finite propagation speeds"
  - [section]: "Theorem 2" and "Proposition 2" show spatially local structure of update rules
  - [corpus]: No direct evidence in corpus; this is a novel theoretical contribution
- Break condition: Recurrent connections creating long-range dependencies may violate spatial locality.

### Mechanism 3
- Claim: Hamiltonian Sign Flip (HSF) strategy enables online learning by approximating boundary conditions with initial conditions.
- Mechanism: Periodic sign flipping of costate equations stabilizes learning dynamics and approximates required boundary conditions for optimality.
- Core assumption: Flipping frequency and boundedness of Hamiltonian track are sufficient to approximate true solution.
- Evidence anchors:
  - [abstract]: "opens up the possibility for online learning schemes that respect biological constraints"
  - [section]: "Example 1" and "Example 2" illustrate problem and solution with HSF
  - [corpus]: No direct evidence in corpus; this is a novel theoretical contribution
- Break condition: Too low flipping frequency or improper Hamiltonian track bounding may cause poor approximation and learning divergence.

## Foundational Learning

- Concept: Optimal Control Theory
  - Why needed here: Formulates learning as an optimal control problem, deriving Hamilton's equations for learning dynamics
  - Quick check question: What is the relationship between value function in optimal control and costate variables in Hamilton's equations?

- Concept: Hamiltonian Mechanics
  - Why needed here: Uses Hamiltonian equations to derive local learning rules, drawing inspiration from physics
  - Quick check question: How do Hamilton's equations ensure conservation of energy in physical systems, and how is this related to stability of learning dynamics?

- Concept: Recurrent Neural Networks (RNNs)
  - Why needed here: Applies local propagation method to RNNs, requiring understanding of their dynamics and learning algorithms
  - Quick check question: What are key differences between backpropagation through time (BPTT) and real-time recurrent learning (RTRL) in terms of locality and causality?

## Architecture Onboarding

- Component map: Input -> Hidden Layers (Graph structure) -> Output, with weights w(t) and costates p(t) evolving according to Hamilton's equations

- Critical path:
  1. Define network graph and activation functions
  2. Choose cost function and propagation speed
  3. Initialize network state and costates
  4. Apply HSF policy for online learning
  5. Monitor Hamiltonian track for stability

- Design tradeoffs:
  - Locality vs. accuracy: Higher propagation speeds lead to more accurate but less local updates
  - Flipping frequency vs. stability: Higher frequencies improve stability but may introduce noise
  - Regularization vs. overfitting: Stronger regularization prevents overfitting but may slow learning

- Failure signatures:
  - Divergence: Network state or costates grow unbounded
  - Oscillations: Network state or costates oscillate without converging
  - Poor performance: Network fails to learn desired function despite stable dynamics

- First 3 experiments:
  1. Test reduction to backpropagation with simple feedforward network and infinite propagation speed
  2. Verify spatial locality of updates with small RNN and finite propagation speed
  3. Assess stability and performance of HSF policy with toy tracking problem

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Hamilton's equations with boundary conditions be approximated using only initial conditions in a stable and efficient manner?
- Basis in paper: [explicit] Paper discusses challenge of solving Hamilton's equations with boundary conditions and proposes HSF strategy and time reversal to approximate solution with Cauchy's initial conditions.
- Why unresolved: While HSF strategy is proposed as potential solution, paper acknowledges it needs further investigation and refinement for real-world problems.
- What evidence would resolve it: Experimental results demonstrating effectiveness of HSF strategy or alternative approaches for approximating Hamilton's equations with initial conditions in various learning tasks.

### Open Question 2
- Question: What are theoretical guarantees for convergence and stability of proposed local spatiotemporal learning algorithm?
- Basis in paper: [inferred] Paper introduces local spatiotemporal learning algorithm inspired by Hamilton's equations but does not provide rigorous theoretical analysis of convergence and stability properties.
- Why unresolved: Paper focuses on derivation and interpretation of algorithm, but thorough theoretical analysis of behavior is missing.
- What evidence would resolve it: Theoretical proofs establishing convergence and stability of algorithm under various conditions (different network architectures, loss functions, learning rates).

### Open Question 3
- Question: How does proposed local spatiotemporal learning algorithm compare to other biologically plausible learning algorithms like Equilibrium Propagation and Hebbian learning?
- Basis in paper: [inferred] Paper mentions related biologically inspired learning algorithms but does not provide comprehensive comparison with proposed approach.
- Why unresolved: Paper introduces new learning algorithm but does not evaluate its performance against existing biologically plausible methods.
- What evidence would resolve it: Experimental results comparing proposed algorithm with other biologically plausible learning algorithms on benchmark tasks, analyzing convergence speed, accuracy, and biological plausibility.

### Open Question 4
- Question: Can proposed local spatiotemporal learning algorithm be extended to handle more complex network architectures like CNNs and GNNs?
- Basis in paper: [inferred] Paper focuses on RNNs but does not explore applicability of proposed algorithm to other network architectures.
- Why unresolved: Paper demonstrates effectiveness of algorithm for recurrent networks but does not investigate potential for other architectures commonly used in deep learning.
- What evidence would resolve it: Successful application of proposed algorithm to train CNNs and GNNs on relevant tasks, showcasing versatility and effectiveness across different architectures.

### Open Question 5
- Question: What are computational advantages and disadvantages of proposed local spatiotemporal learning algorithm compared to backpropagation?
- Basis in paper: [explicit] Paper claims proposed algorithm is local in both space and time, which could lead to computational advantages over backpropagation.
- Why unresolved: While paper highlights potential benefits of proposed algorithm, it does not provide detailed analysis of computational complexity and efficiency compared to backpropagation.
- What evidence would resolve it: Comparative analysis of computational complexity, memory requirements, and runtime performance of proposed algorithm and backpropagation on various tasks and network sizes.

## Limitations
- Limited experimental validation with no results shown for proposed local learning rules on real-world problems
- Key implementation details like Hamiltonian track set S and regularization terms V(u,s) are underspecified
- Theoretical novelty of HSF mechanism requires further empirical validation

## Confidence
- High: Theoretical derivations (Theorem 1, 2 and Corollary 1) follow standard optimal control methodology
- Medium: Practical utility since key implementation details are underspecified
- Low: Empirical benefits of online learning scheme without experimental validation

## Next Checks
1. Implement the exact Hamiltonian track set S and test stability across different network sizes and topologies
2. Compare learning performance against BPTT on standard sequence modeling benchmarks with finite propagation speeds
3. Analyze approximation error between HSF online learning and optimal offline solution as a function of flipping frequency