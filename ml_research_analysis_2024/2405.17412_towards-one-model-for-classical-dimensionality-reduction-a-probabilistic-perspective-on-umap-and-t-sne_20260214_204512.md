---
ver: rpa2
title: 'Towards One Model for Classical Dimensionality Reduction: A Probabilistic
  Perspective on UMAP and t-SNE'
arxiv_id: '2405.17412'
source_url: https://arxiv.org/abs/2405.17412
tags:
- umap
- t-sne
- matrix
- inference
- algorithms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a probabilistic interpretation of UMAP and
  t-SNE as maximum a posteriori (MAP) inference methods within a generalized Wishart-based
  model. The model describes graph Laplacians (estimates of data precision matrices)
  using a Wishart distribution with a mean given by a non-linear covariance function
  evaluated on latent variables.
---

# Towards One Model for Classical Dimensionality Reduction: A Probabilistic Perspective on UMAP and t-SNE

## Quick Facts
- arXiv ID: 2405.17412
- Source URL: https://arxiv.org/abs/2405.17412
- Reference count: 32
- This paper presents a probabilistic interpretation of UMAP and t-SNE as maximum a posteriori (MAP) inference methods within a generalized Wishart-based model.

## Executive Summary
This paper presents a probabilistic interpretation of UMAP and t-SNE as maximum a posteriori (MAP) inference methods within a generalized Wishart-based model. The model describes graph Laplacians (estimates of data precision matrices) using a Wishart distribution with a mean given by a non-linear covariance function evaluated on latent variables. The authors show that inference with this model approximately recovers UMAP and t-SNE-like algorithms. They demonstrate that embeddings obtained using this model closely align with those from standard implementations of UMAP and t-SNE on various datasets, including MNIST. The work provides deeper theoretical insights into these dimensionality reduction methods and introduces tools for studying similar algorithms, unifying them under a common probabilistic framework.

## Method Summary
The authors develop a probabilistic model that frames dimensionality reduction as inference in a Wishart-based distribution over graph Laplacians. The model uses a non-linear covariance function evaluated on latent variables to define the mean of the Wishart distribution. By performing MAP inference in this model, they show that UMAP and t-SNE-like algorithms can be recovered as approximate solutions. The framework provides a unified theoretical perspective that connects these seemingly distinct methods through shared probabilistic foundations.

## Key Results
- The probabilistic model approximately recovers UMAP and t-SNE-like algorithms through MAP inference
- Embeddings obtained from the model closely align with those from standard UMAP and t-SNE implementations on MNIST and other datasets
- The work provides a unified theoretical framework connecting these dimensionality reduction methods through Wishart-based distributions over graph Laplacians

## Why This Works (Mechanism)
The mechanism works by establishing a probabilistic foundation where graph Laplacians (which capture local neighborhood structure) are modeled as samples from a Wishart distribution. The mean of this distribution is determined by a non-linear covariance function evaluated at latent positions. This formulation naturally captures the local structure preservation that both UMAP and t-SNE aim to achieve, while providing a principled framework for inference. The MAP approach then finds latent positions that maximize the posterior probability, which corresponds to finding embeddings that best explain the observed graph structure under the assumed probabilistic model.

## Foundational Learning
- **Wishart distribution**: A multivariate generalization of the chi-squared distribution used for modeling covariance matrices; needed to model the distribution of graph Laplacians
- **Graph Laplacians**: Matrix representations of graph structure that encode local neighborhood relationships; needed as the primary observable in the probabilistic model
- **Gaussian process covariance functions**: Non-linear functions that define relationships between data points; needed to specify the mean structure of the Wishart distribution
- **Maximum a posteriori (MAP) inference**: A Bayesian approach to parameter estimation that combines likelihood with prior information; needed to find optimal latent positions
- **Dimensionality reduction objectives**: The specific goals of preserving local structure in lower-dimensional spaces; needed to understand what properties the model aims to capture

## Architecture Onboarding

**Component map:**
Data points -> Graph Laplacian computation -> Wishart likelihood -> Non-linear covariance function -> MAP inference -> Latent embeddings

**Critical path:**
The critical path flows from computing the graph Laplacian from data, through evaluating the Wishart likelihood with the non-linear covariance function, to performing MAP inference to obtain the final latent embeddings.

**Design tradeoffs:**
The primary tradeoff is between model complexity and interpretability. While the Wishart-based formulation provides a principled probabilistic foundation, it introduces significant mathematical complexity compared to the original algorithmic descriptions of UMAP and t-SNE. The approximation nature of the recovery also represents a tradeoff between theoretical elegance and practical exactness.

**Failure signatures:**
The model may fail when the underlying data structure doesn't conform to the assumptions of the Wishart distribution or when the non-linear covariance function cannot adequately capture the relationships in the data. Additionally, the MAP inference could get trapped in local optima, particularly for complex, high-dimensional datasets.

**3 first experiments:**
1. Verify that the model recovers known synthetic manifolds (e.g., Swiss roll, S-curve) with appropriate embedding quality
2. Test the sensitivity of embeddings to the choice of non-linear covariance function parameters
3. Compare the probabilistic model's embeddings against standard UMAP/t-SNE on datasets with varying cluster densities and separations

## Open Questions the Paper Calls Out
None

## Limitations
- The probabilistic interpretation is presented as an approximation rather than an exact correspondence with UMAP and t-SNE
- Validation relies primarily on qualitative visual comparisons rather than rigorous quantitative metrics
- The theoretical framework requires advanced mathematical background in Gaussian processes and Wishart distributions, limiting accessibility

## Confidence
- **High confidence**: The mathematical formulation and derivation of the probabilistic model are rigorous and well-explained
- **Medium confidence**: The approximate recovery of UMAP/t-SNE behavior is supported by empirical demonstrations, though quantitative validation is limited
- **Medium confidence**: The claim of providing deeper theoretical insights is reasonable given the unified framework, but the practical implications remain somewhat unclear

## Next Checks
1. Conduct quantitative comparison of embeddings using established metrics (e.g., trustworthiness, continuity, or nearest neighbor preservation) to supplement the qualitative visual assessments
2. Perform ablation studies varying the non-linear covariance function to understand how sensitive the recovered algorithms are to model specification
3. Test the framework on datasets with known manifold structure to evaluate whether the probabilistic interpretation provides additional insights into the embedding quality or failure modes