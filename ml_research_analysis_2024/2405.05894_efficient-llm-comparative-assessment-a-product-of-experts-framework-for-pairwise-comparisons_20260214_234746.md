---
ver: rpa2
title: 'Efficient LLM Comparative Assessment: a Product of Experts Framework for Pairwise
  Comparisons'
arxiv_id: '2405.05894'
source_url: https://arxiv.org/abs/2405.05894
tags:
- comparisons
- probability
- comparative
- assessment
- experts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Product of Experts (PoE) framework for
  efficient LLM comparative assessment. By treating each pairwise comparison as an
  expert providing information on score differences, the framework combines these
  experts to predict text scores using only a subset of comparisons.
---

# Efficient LLM Comparative Assessment: a Product of Experts Framework for Pairwise Comparisons

## Quick Facts
- **arXiv ID:** 2405.05894
- **Source URL:** https://arxiv.org/abs/2405.05894
- **Reference count:** 40
- **Primary result:** PoE framework achieves similar performance to using all comparisons while using as few as 2% of comparisons for large N.

## Executive Summary
This paper introduces a Product of Experts (PoE) framework for efficient LLM comparative assessment that combines pairwise comparison information to predict text scores. By treating each pairwise comparison as an expert providing information on score differences, the framework can generate accurate score predictions using only a small subset of all possible comparisons. Experiments on NLG tasks demonstrate that the PoE approach significantly outperforms baseline methods while achieving computational efficiency gains of up to 98%.

## Method Summary
The method constructs a comparison matrix from pairwise LLM judgments, where each comparison provides probabilistic information about score differences between two texts. Under Gaussian assumptions, the framework computes optimal scores using a closed-form solution involving matrix inversion. The approach selects informative comparisons through greedy approximation, combining comparison outcomes using the PoE framework to generate final score predictions that correlate with human judgments.

## Key Results
- PoE framework achieves performance within 1-2 SCC of full comparison set using only 20% of comparisons
- Outperforms baseline methods like win-ratio and average probability across multiple NLG tasks
- Demonstrates efficiency gains of up to 98% in comparison usage while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Product of Experts (PoE) framework can effectively combine pairwise comparison information to predict text scores with high accuracy.
- Mechanism: Each pairwise comparison is treated as an expert that provides information about the score difference between two texts. The PoE framework combines these experts by taking their product and normalizing the result, yielding an expression that can be maximized to determine the optimal ranking.
- Core assumption: Each comparison provides independent information about the score difference between two texts.
- Evidence anchors:
  - [abstract]: "By treating each pairwise comparison as an expert providing information on score differences, the framework combines these experts to predict text scores using only a subset of comparisons."
  - [section 3.3]: "In this work, we explore reformulating the scores as a PoE. One may consider the information gained from each comparison as independent experts, which enables the probability of a set of scores to be written in the form of a PoE."
  - [corpus]: Weak evidence - the corpus contains related papers but no direct confirmation of this specific PoE mechanism.

### Mechanism 2
- Claim: Using Gaussian experts in the PoE framework yields closed-form solutions for optimal rankings and expressions for selecting the most informative comparisons.
- Mechanism: When Gaussian experts are used, the PoE framework yields a closed-form solution for the optimal candidate ranking. Additionally, under Gaussian assumptions, expressions can be derived for selecting which comparisons should be made to maximize the probability of the optimal ranking.
- Core assumption: The underlying distribution of score differences can be well-approximated by Gaussian distributions.
- Evidence anchors:
  - [abstract]: "When Gaussian experts are used one can derive simple closed-form solutions for the optimal candidate ranking, and expressions for selecting which comparisons should be made to maximize the probability of this ranking."
  - [section 3.4]: "If the underlying distribution is assumed to be Gaussian...then by representing the scores in vector form, one can express the distribution as...which can be rearranged to provide the probability for a given set of scores, yielding the expression of the maximum probability solution."
  - [corpus]: Weak evidence - related papers exist but do not specifically confirm Gaussian assumptions in this context.

### Mechanism 3
- Claim: The PoE framework enables efficient comparative assessment by achieving similar performance to using all comparisons while using only a small subset of comparisons.
- Mechanism: By combining the information from a subset of comparisons using the PoE framework, score predictions can be generated that correlate well with human judgments. This allows for considerable computational savings while maintaining performance.
- Core assumption: A small subset of informative comparisons can provide sufficient information to accurately rank the texts.
- Evidence anchors:
  - [abstract]: "Our approach enables efficient comparative assessment, where by using only a small subset of the possible comparisons, one can generate score predictions that correlate as well to human judgements as the predictions when all comparisons are used."
  - [section 5.2]: "With these methods, when using only 20% of the comparisons, one can achieve performance very close to when using the full comparison set (within 1-2 SCC) which would otherwise have had large degradations when using the naive win-ratio (up to 10 SCC)."
  - [corpus]: Weak evidence - related papers discuss efficiency but do not specifically confirm the PoE framework's efficiency claims.

## Foundational Learning

- Concept: Product of Experts (PoE) framework
  - Why needed here: The PoE framework is the core theoretical foundation that allows combining multiple pairwise comparisons to predict text scores. It provides a principled way to aggregate information from multiple experts (comparisons) to form a joint distribution over the scores.
  - Quick check question: How does the PoE framework combine multiple experts to form a joint distribution?

- Concept: Gaussian distribution and its properties
  - Why needed here: The Gaussian distribution is used as the expert distribution in the PoE framework, which allows for closed-form solutions for the optimal ranking and expressions for selecting informative comparisons. Understanding the properties of Gaussian distributions is crucial for implementing and extending the PoE approach.
  - Quick check question: What are the key properties of Gaussian distributions that make them useful in the PoE framework?

- Concept: Linear algebra and optimization
  - Why needed here: The PoE framework involves matrix operations, such as computing the inverse of matrices and solving linear systems, to find the optimal ranking. Additionally, optimization techniques are used to maximize the likelihood of the observed comparisons given the scores.
  - Quick check question: How do matrix operations and optimization techniques enable finding the optimal ranking in the PoE framework?

## Architecture Onboarding

- Component map:
  Input -> Comparison Selection -> LLM Calls -> PoE Framework -> Output

- Critical path:
  1. Select a subset of informative pairwise comparisons
  2. Generate comparison outcomes using an LLM
  3. Apply the PoE framework with Gaussian experts to combine comparison information
  4. Compute the optimal ranking using the closed-form solution
  5. Evaluate the predicted ranking against ground truth

- Design tradeoffs:
  - Number of comparisons: Using more comparisons increases accuracy but also computational cost
  - Expert distribution: Gaussian assumptions enable closed-form solutions but may not always be appropriate
  - Comparison selection: Random selection is simple but may not be optimal; greedy selection can be more informative but computationally expensive

- Failure signatures:
  - Poor correlation between predicted and ground truth rankings
  - High variance in performance across different runs or datasets
  - Slow convergence or numerical instability in matrix operations

- First 3 experiments:
  1. Implement the PoE framework with Gaussian experts and verify that it produces reasonable rankings on a small dataset with known ground truth.
  2. Compare the performance of the PoE framework with random comparison selection versus greedy optimal selection on a larger dataset.
  3. Investigate the impact of using different expert distributions (e.g., Laplace) on the performance and computational efficiency of the PoE framework.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the Product of Experts framework vary with different LLM architectures (e.g., decoder-only, encoder-decoder, hybrid models) for comparative assessment tasks?
- Basis in paper: [inferred] The paper evaluates the framework using FlanT5 and Llama2-chat, but does not explore the impact of different LLM architectures.
- Why unresolved: The paper focuses on specific LLM models, leaving open the question of how other architectures might perform within the PoE framework.
- What evidence would resolve it: Conducting experiments with a diverse set of LLM architectures, such as GPT-4, BERT, and T5, and comparing their performance within the PoE framework.

### Open Question 2
- Question: What is the impact of dataset size and distribution on the efficiency and accuracy of the Product of Experts framework for comparative assessment?
- Basis in paper: [inferred] The paper uses SummEval, TopicalChat, and CMCQRD datasets, but does not systematically investigate the effect of dataset characteristics on the framework's performance.
- Why unresolved: The paper does not explore how varying dataset sizes, distributions, or characteristics might influence the framework's efficiency and accuracy.
- What evidence would resolve it: Conducting experiments with datasets of varying sizes, distributions, and characteristics, and analyzing the framework's performance across these variations.

### Open Question 3
- Question: How does the Product of Experts framework handle comparisons involving texts with significant quality differences or outliers?
- Basis in paper: [inferred] The paper mentions the possibility of outlier comparisons affecting the predicted scores, but does not provide a detailed analysis of how the framework handles such cases.
- Why unresolved: The paper does not delve into the framework's robustness to comparisons involving texts with large quality differences or outliers.
- What evidence would resolve it: Conducting experiments with datasets containing texts with significant quality differences or outliers, and analyzing the framework's performance in these scenarios.

### Open Question 4
- Question: Can the Product of Experts framework be extended to handle multi-dimensional quality assessments, where texts are evaluated on multiple attributes simultaneously?
- Basis in paper: [explicit] The paper focuses on single-attribute assessments, but mentions the possibility of extending the framework to handle multiple attributes.
- Why unresolved: The paper does not explore the practical implementation and performance of the framework for multi-dimensional quality assessments.
- What evidence would resolve it: Developing and evaluating the framework's performance on datasets with multi-dimensional quality assessments, such as evaluating texts on fluency, coherence, and relevance simultaneously.

## Limitations
- Performance claims rely on synthetic comparison probabilities rather than actual LLM outputs, creating a gap between demonstrated and deployable performance.
- Gaussian assumption for expert distributions may not hold for all LLM comparison distributions, particularly with asymmetric preferences or multimodal score distributions.
- Comparison selection algorithm depends on greedy approximation without provided error bounds or convergence guarantees.

## Confidence
- **High confidence:** Mathematical framework and closed-form solutions under Gaussian assumptions are well-established and reproducible.
- **Medium confidence:** Efficiency claims and performance improvements over baselines are demonstrated but rely on synthetic data.
- **Low confidence:** Long-term stability across different dataset sizes and robustness to variations in LLM judge quality remain unproven.

## Next Checks
1. **Real LLM Output Validation:** Implement the framework using actual LLM outputs for pairwise comparisons and measure performance degradation compared to synthetic results.
2. **Distribution Assumption Testing:** Evaluate framework performance with non-Gaussian expert distributions (e.g., Laplace or empirical distributions) to assess sensitivity to distributional assumptions.
3. **Scaling Analysis:** Test performance and efficiency across datasets of varying sizes (N=50, N=500, N=5000) to identify scaling limitations and practical upper bounds.