---
ver: rpa2
title: Enhancing Feature Selection and Interpretability in AI Regression Tasks Through
  Feature Attribution
arxiv_id: '2409.16787'
source_url: https://arxiv.org/abs/2409.16787
tags:
- feature
- features
- methods
- selection
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates the effectiveness of using feature attribution
  methods for feature selection in regression tasks to improve the performance and
  interpretability of deep learning models. By combining Integrated Gradients with
  k-means clustering, the proposed pipeline successfully identifies the most relevant
  features from a high-dimensional dataset related to blade vibration analysis in
  turbomachinery.
---

# Enhancing Feature Selection and Interpretability in AI Regression Tasks Through Feature Attribution

## Quick Facts
- arXiv ID: 2409.16787
- Source URL: https://arxiv.org/abs/2409.16787
- Reference count: 40
- Primary result: Proposed pipeline combining Integrated Gradients with k-means clustering outperforms classical feature selection methods, achieving lower MSE and higher model stability in blade vibration prediction

## Executive Summary
This study introduces a novel feature selection pipeline that combines Integrated Gradients (IG) with k-means clustering to identify the most relevant features for deep learning regression models. Applied to turbomachinery blade vibration analysis, the method successfully reduces 86 input features to a smaller subset while improving prediction accuracy and model interpretability. The approach demonstrates that gradient-based feature attribution can serve as an effective embedded feature selection technique, outperforming traditional methods like Pearson correlation and Lasso regression. The results validate the potential of AI-driven methods to complement traditional engineering approaches in complex domains.

## Method Summary
The pipeline integrates model-specific gradient information through Integrated Gradients to identify influential features, then uses k-means clustering to group these features by importance levels. For each cluster configuration (k from 2 to 10), the least important cluster is removed iteratively to generate candidate feature subsets. Neural networks are then re-tuned on each subset using spotpython's Gaussian process-based hyperparameter optimization. The method is evaluated on a turbomachinery dataset with 27,857 samples and 86 input features, comparing performance against baseline methods including linear regression, Pearson correlation, Lasso, and KernelSHAP using 5-fold cross-validation.

## Key Results
- Outperforms classical feature selection methods with lower mean squared error
- Achieves higher model stability and robustness through reduced feature dimensionality
- Successfully identifies physically meaningful features that domain experts may overlook
- Validates feature attribution as a valuable embedded feature selection technique for neural networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The pipeline uses model-specific gradient information (IG) to identify features that actually influence predictions, outperforming generic statistical filters.
- Mechanism: IG integrates the gradient of the model output with respect to input features along a path from a baseline to the actual input. This captures both magnitude and direction of feature influence on the model's predictions. By using the neural network's own gradients, it can detect complex, non-linear feature interactions that filter methods miss.
- Core assumption: The neural network has learned meaningful representations and achieves sufficient prediction accuracy for IG attributions to be reliable.
- Evidence anchors:
  - [abstract] "We argue that models can identify patterns in the data that may be unknown to domain experts."
  - [section] "The information provided by the gradient-based attribution method is only as valuable as the prediction quality of our model."
- Break condition: If the neural network performs poorly or overfits, IG attributions will reflect noise rather than true feature importance.

### Mechanism 2
- Claim: K-means clustering of attribution values groups features by importance levels without requiring arbitrary thresholds, creating multiple candidate feature subsets.
- Mechanism: After computing global mean attribution values across the dataset, k-means clusters these values into discrete groups. The least important cluster is removed iteratively for different k values, generating several feature subsets for evaluation.
- Core assumption: Features with similar attribution magnitudes share similar importance levels for the prediction task.
- Evidence anchors:
  - [section] "The number of clusters (k) is varied to categorize the features into different importance classes."
  - [section] "This approach represents a data-driven method for filtering features based on their importance in predicting the target variable."
- Break condition: If attribution values are multimodal or have no clear clustering structure, the approach may select suboptimal feature subsets.

### Mechanism 3
- Claim: Re-tuning neural networks on each candidate feature subset ensures fair comparison and leverages the model's capacity to adapt to reduced feature spaces.
- Mechanism: After feature selection, each subset is used to re-optimize the neural network architecture and hyperparameters. This prevents penalizing feature subsets simply because the original architecture wasn't optimized for them.
- Core assumption: Different feature subsets may require different network architectures for optimal performance.
- Evidence anchors:
  - [section] "Following the feature selection process, the models are re-tuned using each of the distinct feature subsets."
  - [section] "This crucial step ensures a fair comparison among models based on different feature combinations."
- Break condition: If the hyperparameter space is too large or computationally expensive, this step may not be feasible in practice.

## Foundational Learning

- Concept: Integrated Gradients
  - Why needed here: IG provides the theoretical foundation for computing feature attributions that satisfy sensitivity and implementation invariance axioms.
  - Quick check question: What are the two axioms that IG satisfies, and why are they important for reliable feature attribution?

- Concept: K-means clustering
  - Why needed here: Clustering attribution values allows automatic categorization of features by importance without manual threshold setting.
  - Quick check question: How does varying k in k-means help generate multiple candidate feature subsets for evaluation?

- Concept: Neural network hyperparameter optimization
  - Why needed here: The quality of feature attribution depends on model performance; proper tuning ensures reliable attributions.
  - Quick check question: Why is it important to re-tune the network after feature selection rather than using the original architecture?

## Architecture Onboarding

- Component map: Data preprocessing → Neural network training → IG attribution → K-means clustering → Feature subset generation → Re-tuning → Cross-validation → Performance comparison
- Critical path: Feature selection pipeline (IG + k-means) → Model re-tuning → Performance evaluation
- Design tradeoffs: Computational cost of re-tuning vs. accuracy gains; number of k values to try vs. completeness of search
- Failure signatures: Poor initial model performance → unreliable attributions; noisy attributions → unstable clustering; over-pruning → loss of predictive power
- First 3 experiments:
  1. Run pipeline on dummy data with known ground truth to validate IG can recover true feature importance
  2. Apply full pipeline to real data with all 86 features, record baseline MSE and attribution patterns
  3. Test feature subsets generated from k-means clustering, identify optimal number of features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of baseline in Integrated Gradients affect feature importance rankings and subsequent feature selection outcomes in regression tasks?
- Basis in paper: [explicit] The paper mentions that the baseline can be viewed as a state where all features are absent, but also notes that changing the baseline to a state of expected vibration would be more appropriate for explaining individual predictions that deviate from expected behavior.
- Why unresolved: The paper uses a null vector baseline but does not explore how different baseline choices might affect the feature selection results or the stability of the selected features.
- What evidence would resolve it: Systematic comparison of feature selection outcomes using different baseline choices (null vector, expected vibration state, random baselines) applied to the same dataset and evaluated against model performance metrics.

### Open Question 2
- Question: What is the optimal number of clusters (k) for K-Means clustering when used in conjunction with Integrated Gradients for feature selection in high-dimensional regression problems?
- Basis in paper: [inferred] The paper performs clustering with k values ranging from 2 to 10 and notes that some clusterings produce identical results, but does not establish a principled method for determining the optimal k value.
- Why unresolved: The clustering process is heuristic and the paper does not provide criteria for selecting the optimal number of clusters beyond observing similar results for different k values.
- What evidence would resolve it: Development and validation of a method to determine optimal k values based on clustering quality metrics, stability of selected features across different k values, or model performance after feature selection.

### Open Question 3
- Question: How does the feature selection performance of Integrated Gradients compare to other gradient-based attribution methods (e.g., DeepLIFT, LRP) in regression tasks?
- Basis in paper: [explicit] The paper compares IG with KernelSHAP and classical methods like Pearson correlation and Lasso, but does not compare it with other gradient-based methods.
- Why unresolved: While the paper establishes IG's superiority over some methods, it does not provide a comprehensive comparison with the full range of gradient-based attribution methods available for regression tasks.
- What evidence would resolve it: Direct comparison of feature selection performance across multiple gradient-based attribution methods (IG, DeepLIFT, LRP, etc.) using the same dataset and evaluation metrics to determine relative effectiveness.

## Limitations
- Computational cost of re-tuning neural networks for each feature subset limits scalability to very high-dimensional datasets
- Method's reliance on gradient-based attributions inherits IG limitations including sensitivity to baseline selection
- Attribution quality directly tied to model performance, but robustness to model misspecification not explored

## Confidence

**High**: The effectiveness of the pipeline in reducing feature dimensionality while maintaining or improving prediction accuracy is well-supported by the experimental results.

**Medium**: The interpretability claims are supported, but could be strengthened by domain expert validation of the selected features' physical relevance.

**Low**: The generalizability to other regression domains beyond turbomachinery is assumed but not empirically tested.

## Next Checks

1. **Baseline sensitivity analysis**: Evaluate the impact of different baseline choices (e.g., mean input vs. random baseline) on feature attribution patterns and selection outcomes.

2. **Cross-domain application**: Apply the pipeline to at least two additional regression tasks from different domains to test generalizability and identify domain-specific limitations.

3. **Scalability benchmark**: Measure the computational overhead of re-tuning versus the performance gains across varying dataset sizes (10² to 10⁶ samples) to establish practical scaling limits.