---
ver: rpa2
title: Enhancing Compositional Generalization via Compositional Feature Alignment
arxiv_id: '2402.02851'
source_url: https://arxiv.org/abs/2402.02851
tags:
- domain
- training
- feature
- compositional
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles compositional generalization in multi-domain,
  multi-class setups, where models must generalize to unseen domain-class combinations.
  The authors identify that standard pretraining-finetuning methods like CLIP and
  DINOv2 struggle with this challenge.
---

# Enhancing Compositional Generalization via Compositional Feature Alignment

## Quick Facts
- **arXiv ID**: 2402.02851
- **Source URL**: https://arxiv.org/abs/2402.02851
- **Reference count**: 40
- **Primary result**: CFA improves compositional generalization performance on CG-Bench compared to standard finetuning methods

## Executive Summary
This paper addresses compositional generalization in multi-domain, multi-class settings where models must generalize to unseen domain-class combinations. Standard pretraining-finetuning methods like CLIP and DINOv2 struggle with this challenge. The authors propose Compositional Feature Alignment (CFA), a two-stage finetuning approach that learns orthogonal linear heads for class and domain prediction, then fine-tunes the encoder with these heads frozen. Theoretical analysis and experiments on CG-Bench demonstrate that CFA improves compositional generalization performance while maintaining in-distribution accuracy, and shows robustness even with partial domain label availability.

## Method Summary
Compositional Feature Alignment (CFA) is a two-stage finetuning approach for vision foundation models. Stage 1 learns two orthogonal linear heads (W1 for class, W2 for domain) with an orthogonality constraint W1W2^T = 0, while normalizing both features and heads to unit norm. Stage 2 fine-tunes the encoder with these frozen heads to align features with the compositional structure. The method uses multi-label cross-entropy loss to simultaneously predict class and domain labels, and leverages neural collapse behavior to guide feature alignment. CFA addresses the compositional generalization challenge by forcing the encoder to separate class and domain features into orthogonal subspaces.

## Key Results
- CFA outperforms standard fine-tuning, linear probing, and reweighting methods on compositional generalization benchmarks
- CFA maintains competitive in-distribution accuracy while improving out-of-distribution performance
- The method demonstrates robustness with partial domain label availability
- Feature visualization shows CFA-finetuned features conform to the desired compositional structure

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Orthogonally aligned linear heads force the encoder to separate class and domain features into orthogonal subspaces
- **Mechanism**: Stage 1 learns two linear heads W1 (class) and W2 (domain) with an orthogonality constraint W1W2^T = 0. When frozen, these heads act as feature alignment targets that guide the encoder during Stage 2 to decompose features into class-relevant and domain-relevant components that live in orthogonal subspaces
- **Core assumption**: The compositional structure of the data allows class and domain information to be disentangled into orthogonal feature subspaces
- **Evidence anchors**:
  - [abstract]: "learns two orthogonal linear heads on a pretrained encoder with respect to class and domain labels"
  - [section 2.1]: "We therefore introduce an auxiliary head, W2, for domain prediction, alongside the original class prediction head denoted as W1. Thus, for a sample x, the encoder, W1, and W2 predict the class and domain labels based on the feature Φ(x). Definition 1 implicitly poses an orthogonality requirement on domain-related and class-related features since R is an orthonormal matrix. To meet this feature orthogonality requirement, we impose an orthogonality constraint on the two heads (i.e., W1W2^T = 0)"
  - [corpus]: No direct evidence found for this specific orthogonality mechanism
- **Break condition**: If class and domain information cannot be meaningfully separated (e.g., when domain features are highly predictive of class), the orthogonality constraint may harm performance

### Mechanism 2
- **Claim**: Feature normalization + head normalization enables neural collapse behavior that aligns features with the frozen heads
- **Mechanism**: By normalizing both features (from encoder) and heads to unit norm, the optimization landscape becomes more amenable to neural collapse phenomena where features align with the directions defined by the frozen linear heads. This alignment ensures that features from different domain-class combinations occupy predictable regions in feature space
- **Core assumption**: The theoretical results from neural collapse literature extend to the multi-head setting with class and domain predictions
- **Evidence anchors**:
  - [section 2.1]: "we find that the head-freezing technique does not compromise the model's performance compared to end-to-end finetuning" and "we empirically observe that the head-freezing technique does not compromise the model's performance compared to end-to-end finetuning"
  - [section 2.2]: "Leveraging tools from the neural collapse literature, we theoretically prove that CFA can effectively align features with the compositional feature structure under mild assumptions"
  - [corpus]: No direct evidence found for this specific normalization mechanism
- **Break condition**: If the data distribution is too imbalanced or if the class/domain separation is not meaningful, neural collapse may not occur as expected

### Mechanism 3
- **Claim**: Multi-label cross-entropy loss with frozen heads enables learning of features that generalize to unseen domain-class combinations
- **Mechanism**: The two-stage process first establishes a compositional feature structure through linear probing (Stage 1), then fine-tunes the encoder to produce features that conform to this structure (Stage 2). The frozen heads act as anchors that prevent the model from overfitting to the training distribution and instead encourage learning features that capture the underlying compositional structure
- **Core assumption**: The compositional structure learned on training domain-class combinations will generalize to unseen combinations
- **Evidence anchors**:
  - [abstract]: "fine-tunes the encoder with the newly learned head frozen" and "theoretically and empirically justify that CFA encourages compositional feature learning of pretrained models"
  - [section 2.1]: "Inspired by these, we devise the two-stage strategy where the Stage 1 determines the optimal head weights for our compositional feature structure, and the Stage 2 finetunes the encoder with frozen head weights to align the features with the feature structure"
  - [section 3.3]: Feature visualization shows that CFA-finetuned features conform to the desired compositional structure while pretrained features do not
  - [corpus]: No direct evidence found for this specific multi-stage mechanism
- **Break condition**: If the training data lacks sufficient diversity in domain-class combinations, the learned compositional structure may not generalize

## Foundational Learning

- **Concept**: Orthogonal linear algebra and feature subspace decomposition
  - **Why needed here**: The method relies on understanding how features can be decomposed into orthogonal subspaces for class and domain information
  - **Quick check question**: Can you explain why forcing W1 and W2 to be orthogonal helps separate class and domain features in the encoder output?

- **Concept**: Neural collapse and feature alignment phenomena
  - **Why needed here**: The theoretical justification relies on understanding how frozen heads can guide feature alignment through neural collapse-like behavior
  - **Quick check question**: What happens to feature distributions when training with a frozen linear classifier versus a trainable one?

- **Concept**: Multi-label classification and cross-entropy loss
  - **Why needed here**: The method uses multi-label cross-entropy loss to simultaneously predict class and domain labels, which is non-standard
  - **Quick check question**: How does multi-label cross-entropy differ from standard single-label cross-entropy in terms of optimization dynamics?

## Architecture Onboarding

- **Component map**: Encoder (frozen during Stage 1, fine-tuned during Stage 2) → Two linear heads (W1 for class, W2 for domain) → Orthogonality constraint → Cross-entropy losses
- **Critical path**: Stage 1: Linear probing with orthogonality constraint → Stage 2: Encoder fine-tuning with frozen heads
- **Design tradeoffs**: 
  - Orthogonal heads vs. non-orthogonal: Orthogonal forces cleaner separation but may lose information if classes and domains are correlated
  - Frozen heads vs. trainable heads in Stage 2: Frozen provides stability and alignment but may limit adaptation
  - Feature normalization: Helps with neural collapse but may discard useful magnitude information
- **Failure signatures**:
  - Poor OOD performance despite good ID performance: Likely insufficient feature alignment or orthogonality constraint too restrictive
  - Degradation in ID performance: Possible overfitting to orthogonality constraint or insufficient fine-tuning
  - Training instability: May indicate learning rate issues or orthogonality constraint too strong
- **First 3 experiments**:
  1. Implement Stage 1 with orthogonality constraint on a simple dataset (e.g., Color-CIFAR) and visualize learned head directions
  2. Test feature alignment by freezing heads and fine-tuning encoder, then measure class/domain prediction accuracy
  3. Compare CFA against standard fine-tuning on a compositional generalization benchmark with varying amounts of training data

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does CFA perform when the number of domains is much larger than in the tested datasets?
- **Basis in paper**: [explicit] The paper mentions that CFA works well with partial domain label availability but does not explore scenarios with very large numbers of domains
- **Why unresolved**: The current experiments only use datasets with 4-6 domains, which may not reflect the scalability of CFA to datasets with hundreds or thousands of domains
- **What evidence would resolve it**: Testing CFA on datasets with a significantly larger number of domains (e.g., 50+) and comparing its performance to other methods would provide insights into its scalability

### Open Question 2
- **Question**: Can CFA be effectively adapted for use with non-image data modalities, such as text or audio?
- **Basis in paper**: [inferred] The paper focuses on vision foundation models (CLIP and DINOv2) and does not explore other data types. The compositional generalization challenge may manifest differently in other modalities
- **Why unresolved**: The method's reliance on visual feature extraction and orthogonality constraints may not directly translate to other modalities with different feature representations
- **What evidence would resolve it**: Applying CFA to text or audio classification tasks and evaluating its performance on compositional generalization would demonstrate its generalizability

### Open Question 3
- **Question**: How does the performance of CFA change with varying levels of class imbalance in the training data?
- **Basis in paper**: [explicit] The paper mentions that normalizing features and weights addresses data imbalance issues, but does not provide extensive experiments on varying imbalance levels
- **Why unresolved**: The impact of class imbalance on CFA's ability to learn compositional features and generalize to unseen domain-class combinations is not fully explored
- **What evidence would resolve it**: Conducting experiments with controlled class imbalance ratios and measuring CFA's performance on compositional generalization tasks would reveal its robustness to imbalance

## Limitations
- Unknown hyperparameter values (regularization coefficients, learning rates, batch sizes) make exact reproduction challenging
- Theoretical analysis relies on assumptions about neural collapse behavior extending to the multi-head setting
- Method's effectiveness depends on meaningful separability of class and domain information
- Performance may degrade when domains are highly predictive of classes

## Confidence

**High Confidence**: The core empirical results showing CFA's superiority over baseline methods on CG-Bench are well-supported with multiple datasets and ablation studies

**Medium Confidence**: The theoretical justification through neural collapse literature is plausible but relies on assumptions that need empirical validation across diverse datasets

**Medium Confidence**: The claim that CFA works with only partial domain labels is demonstrated but requires further testing on more extreme label scarcity scenarios

## Next Checks

1. **Orthogonality Constraint Sensitivity**: Systematically vary the regularization coefficient for the orthogonality constraint in Stage 1 and measure its impact on both ID and OOD performance to identify optimal values

2. **Domain-Class Correlation Analysis**: Measure the correlation between domain and class labels in the training data and test whether CFA's performance degrades as this correlation increases, revealing limitations of the orthogonality assumption

3. **Generalization to Other Architectures**: Apply CFA to vision transformer architectures beyond the pretrained models tested and evaluate whether the method's benefits transfer to different backbone structures