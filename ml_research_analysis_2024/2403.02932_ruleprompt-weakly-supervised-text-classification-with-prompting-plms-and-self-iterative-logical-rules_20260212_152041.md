---
ver: rpa2
title: 'RulePrompt: Weakly Supervised Text Classification with Prompting PLMs and
  Self-Iterative Logical Rules'
arxiv_id: '2403.02932'
source_url: https://arxiv.org/abs/2403.02932
tags:
- words
- text
- category
- each
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach RulePrompt for weakly supervised
  text classification, which leverages prompting pre-trained language models (PLMs)
  and self-iterative logical rules to characterize category meanings. The core idea
  is to mine logical rules from pseudo-labeled texts using frequent pattern mining,
  and iteratively refine the rules and pseudo labels to mutually enhance each other.
---

# RulePrompt: Weakly Supervised Text Classification with Prompting PLMs and Self-Iterative Logical Rules

## Quick Facts
- arXiv ID: 2403.02932
- Source URL: https://arxiv.org/abs/2403.02932
- Authors: Miaomiao Li; Jiaqi Zhu; Yang Wang; Yi Yang; Yilin Li; Hongan Wang
- Reference count: 40
- Primary result: Outperforms state-of-the-art weakly supervised methods on four datasets

## Executive Summary
This paper proposes RulePrompt, a novel approach for weakly supervised text classification that leverages prompting pre-trained language models (PLMs) and self-iterative logical rules. The method characterizes category meanings through logical rules mined from pseudo-labeled texts, creating a closed loop where rules and pseudo labels mutually enhance each other. RulePrompt consists of three modules: rule mining, rule-enhanced pseudo label generation, and self-supervised fine-tuning, and consistently outperforms existing weakly supervised methods while producing interpretable category rules.

## Method Summary
RulePrompt addresses weakly supervised text classification by iteratively refining pseudo labels and logical rules. It starts with label names to generate initial pseudo labels, mines logical rules from high-confidence texts using frequent pattern mining, and uses these rules to improve classification. The approach constructs disjunctive and conjunctive sub-rules representing category-indicative words, injects them into PLM-based classification models, and refines the PLM through self-supervised fine-tuning. This creates a self-iterative closed loop where rule acquisition and utilization mutually enhance each other.

## Key Results
- Consistently outperforms state-of-the-art weakly supervised methods across four datasets
- Yields interpretable category rules that disambiguate easily-confused categories
- Achieves improved performance through mutual enhancement of pseudo labels and logical rules

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mutual enhancement between pseudo labels and logical rules creates a self-iterative closed loop that improves both over time
- Core assumption: Imperfect pseudo labels still contain enough signal to identify high-confidence texts for rule mining
- Evidence anchors: [abstract], [section 4.2]

### Mechanism 2
- Claim: Distinguishing effects of category-indicative words through logical operations enables more precise category understanding
- Core assumption: Some words are strong enough to indicate categories independently while others need conjunction to disambiguate
- Evidence anchors: [abstract], [section 4.1]

### Mechanism 3
- Claim: Self-supervised fine-tuning of PLMs using high-confidence pseudo labels adapts the model to the specific task
- Core assumption: The PLM's capabilities can be adapted through self-supervised learning using current pseudo labels
- Evidence anchors: [abstract], [section 4.5]

## Foundational Learning

- Concept: Prompt engineering and cloze-style tasks
  - Why needed here: Fundamental to estimating category likelihoods and generating signal words
  - Quick check question: What is the purpose of the [MASK] token in prompt-based classification?

- Concept: Frequent pattern mining and association rules
  - Why needed here: Essential for extracting frequent itemsets to construct logical rules
  - Quick check question: How does the support threshold affect which itemsets are considered frequent?

- Concept: Self-supervised learning and entropy minimization
  - Why needed here: Used in fine-tuning module to sharpen probability distributions
  - Quick check question: Why does minimizing entropy help sharpen the probability distribution?

## Architecture Onboarding

- Component map: Rule Mining Module -> Rule-Enhanced Pseudo Label Generation Module -> Self-Supervised Fine-Tuning Module
- Critical path: Initial pseudo labels → Rule mining → Rule-enhanced pseudo label generation → Self-supervised fine-tuning → Repeat
- Design tradeoffs: Conjunction only on 2-itemsets keeps rules interpretable; clustering by confidence adapts to dataset characteristics; averaging three perspectives provides robustness
- Failure signatures: Poor performance improvement suggests inadequate rule mining; high variance indicates imbalance issues; fine-tuning degradation suggests systematic errors
- First 3 experiments:
  1. Run one iteration without fine-tuning to verify rule mining produces meaningful rules
  2. Compare classification using only verbalizer-based unit versus all three units
  3. Test with different support thresholds on a small subset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed logical rules compare to other knowledge representation methods in terms of effectiveness and interpretability?
- Basis in paper: [explicit] The paper proposes novel rule-based knowledge and compares to existing methods
- Why unresolved: No direct comparison with other knowledge representation methods provided
- What evidence would resolve it: Comparative study between proposed logical rules and other knowledge representation methods

### Open Question 2
- Question: How does the approach handle multi-label text classification tasks?
- Basis in paper: [inferred] Paper focuses on single-label tasks without discussing multi-label extension
- Why unresolved: No insights or experiments on multi-label scenarios provided
- What evidence would resolve it: Extension to multi-label tasks with experiments on multi-label datasets

### Open Question 3
- Question: How does the approach perform in domains with limited or no available pre-trained language models?
- Basis in paper: [inferred] Relies on strong capabilities of pre-trained language models
- Why unresolved: No discussion of performance in domains without pre-trained models
- What evidence would resolve it: Experiments in low-resource languages or specialized domains

## Limitations
- Evaluation limited to four English datasets with maximum 3 iterations
- Computational cost of rule mining and pseudo label generation not discussed
- No detailed ablation studies showing individual component contributions
- Performance on highly imbalanced datasets not explicitly evaluated

## Confidence
- **High Confidence**: Core mechanism of prompting PLMs and self-supervised fine-tuning are well-established
- **Medium Confidence**: Effectiveness of mutual enhancement supported by results but theoretical justification incomplete
- **Low Confidence**: Claim of consistent outperformance based on limited comparison set and specific datasets

## Next Checks
1. Run RulePrompt with each component disabled to quantify individual contributions
2. Track variance and convergence of pseudo labels and rules across iterations on validation set
3. Evaluate RulePrompt on a highly imbalanced dataset to assess robustness to class imbalance