---
ver: rpa2
title: Conditional Pseudo-Reversible Normalizing Flow for Surrogate Modeling in Quantifying
  Uncertainty Propagation
arxiv_id: '2404.00502'
source_url: https://arxiv.org/abs/2404.00502
tags:
- pr-nf
- conditional
- distribution
- uncertainty
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a conditional pseudo-reversible normalizing
  flow (PR-NF) model for surrogate modeling in uncertainty quantification. The PR-NF
  directly learns conditional probability density functions from noisy physical models
  without requiring prior knowledge of noise or underlying functions.
---

# Conditional Pseudo-Reversible Normalizing Flow for Surrogate Modeling in Quantifying Uncertainty Propagation

## Quick Facts
- arXiv ID: 2404.00502
- Source URL: https://arxiv.org/abs/2404.00502
- Authors: Minglei Yang; Pengjun Wang; Ming Fan; Dan Lu; Yanzhao Cao; Guannan Zhang
- Reference count: 32
- Key outcome: PR-NF achieves good accuracy in capturing forward and inverse uncertainty propagation with average KL divergence below 0.06 across various test cases.

## Executive Summary
This paper introduces a conditional pseudo-reversible normalizing flow (PR-NF) model for surrogate modeling in uncertainty quantification. The PR-NF directly learns conditional probability density functions from noisy physical models without requiring prior knowledge of noise or underlying functions. The model uses a pseudo-reversible architecture with independent forward and inverse networks, enforcing reversibility through a soft constraint in the loss function. The method is demonstrated on benchmark problems and a real-world geologic carbon storage application, showing significant acceleration compared to traditional reservoir simulation approaches.

## Method Summary
The PR-NF model learns conditional probability density functions p(y|x) from noisy physical models Y = f(X) + ε(X) using a pseudo-reversible architecture. The model employs two independent fully-connected neural networks for encoding (h) and decoding (g) transport maps, with a soft reversibility constraint ∥cW − W∥²₂ incorporated into the loss function. The loss combines negative log-likelihood and pseudo-reversibility terms, enabling the use of fully-connected networks while approximating the target conditional distribution. The model is trained on input-output pairs from physical models and can generate samples for uncertainty quantification without requiring prior knowledge of noise characteristics.

## Key Results
- PR-NF achieves average KL divergence values below 0.06 across various test cases
- The model maintains performance in high-dimensional settings up to 20 input dimensions
- PR-NF significantly accelerates forecasting compared to traditional reservoir simulation approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PR-NF directly learns conditional probability density functions from noisy physical models without requiring prior knowledge of noise or underlying functions.
- Mechanism: The model uses a pseudo-reversible architecture with independent forward and inverse networks, enforcing reversibility through a soft constraint in the loss function. This allows the model to learn the full conditional distribution including noise effects.
- Core assumption: The training data pairs (x, y) where y = f(x) + ε(x) contain sufficient information to learn the conditional distribution p(y|x).
- Evidence anchors:
  - [abstract] "The PR-NF directly learns conditional probability density functions from noisy physical models without requiring prior knowledge of noise or underlying functions."
  - [section 3.2] "The loss function consists of two components, i.e., (3.7) L = L1 + λL2, where L1 is the negative log-likelihood loss and L2 is the pseudo-reversibility loss."

### Mechanism 2
- Claim: The pseudo-reversibility allows use of fully-connected neural networks, simplifying implementation and enabling theoretical analysis.
- Mechanism: By using independent forward and inverse networks with a soft reversibility constraint rather than exact reversibility, the model avoids architectural constraints of standard normalizing flows while still approximating the target conditional distribution.
- Core assumption: The soft reversibility constraint is sufficient to approximate the true inverse relationship.
- Evidence anchors:
  - [abstract] "The pseudo-reversibility feature allows for the use of fully-connected neural network architectures, which simplifies the implementation and enables theoretical analysis."
  - [section 3.1] "In PR-NF, h and g are defined by two independent fully-connected neural networks and the pseudo-reversibility is enforced by incorporating a soft constraint ∥cW − W∥2 into the loss function."

### Mechanism 3
- Claim: The model achieves convergence to the target conditional probability density function as measured by KL divergence.
- Mechanism: The rigorous convergence analysis shows that with sufficient training samples and appropriate network architecture, the PR-NF model minimizes the KL divergence between the learned and true conditional distributions.
- Core assumption: The target conditional distribution p(y|x) can be approximated by a normalizing flow with sufficient capacity.
- Evidence anchors:
  - [abstract] "We provide a rigorous convergence analysis of the conditional pseudo-reversible normalizing flow model, showing its ability to converge to the target conditional probability density function using the Kullback-Leibler divergence."
  - [section 4] "Theorem 4.8. Under the assumptions of Lemma 4.3, Theorem 4.6 and Assumption 4.7, for any given ε > 0, with sufficient training samples, there exist two neural networks h and g such that E[∫DXDKL(pY|X ∥p bY |X)dx] < ε."

## Foundational Learning

- Concept: Normalizing Flows
  - Why needed here: Normalizing flows provide the mathematical framework for transforming simple distributions into complex ones, which is essential for learning conditional probability distributions.
  - Quick check question: What is the change of variables formula used in normalizing flows and how does it relate to the Jacobian determinant?

- Concept: KL Divergence
  - Why needed here: KL divergence serves as the convergence metric to measure how well the learned conditional distribution approximates the true distribution.
  - Quick check question: How does minimizing KL divergence relate to maximum likelihood estimation in the context of training normalizing flows?

- Concept: Pseudo-reversibility vs Exact Reversibility
  - Why needed here: Understanding the difference between these concepts is crucial for grasping why PR-NF can use fully-connected networks while standard normalizing flows cannot.
  - Quick check question: What architectural constraints does exact reversibility impose on normalizing flow models that pseudo-reversibility avoids?

## Architecture Onboarding

- Component map:
  Input: x (parameters) and y (observations) from physical model -> Encoding network h: Maps (x,y) to latent space Z -> Decoding network g: Maps latent space Z back to (x,b y) -> Loss function: Combines negative log-likelihood (L1) and pseudo-reversibility (L2) -> Output: Conditional distribution p(by|x) that approximates p(y|x)

- Critical path:
  1. Prepare training data {x(n), y(n)} where y(n) = f(x(n)) + ε(x(n))
  2. Initialize PR-NF with two independent fully-connected networks
  3. Train using combined loss L = L1 + λL2
  4. Evaluate convergence using KL divergence
  5. Use trained model to generate samples from p(y|x) for new x values

- Design tradeoffs:
  - Soft reversibility constraint vs exact reversibility: Allows more flexible architectures but requires careful tuning of λ
  - Single hidden layer vs deeper networks: Simpler implementation but may limit expressivity for very complex distributions
  - Computational cost of Jacobian determinant: QR decomposition is O(s³) but acceptable for moderate dimensions

- Failure signatures:
  - Poor KL divergence indicates inadequate training data coverage or insufficient network capacity
  - High reversibility loss suggests the networks are not learning good inverse mappings
  - Divergence during training may indicate inappropriate learning rate or λ value

- First 3 experiments:
  1. Test on synthetic problem with known analytical solution (e.g., y = sin(2πx) + ε(x)) to verify KL divergence performance
  2. Vary λ hyperparameter to find optimal balance between likelihood and reversibility terms
  3. Test on high-dimensional case (d=20, s=5) to verify scalability and compare to traditional methods

## Open Questions the Paper Calls Out
No specific open questions were called out in the paper.

## Limitations
- The pseudo-reversibility constraint λ requires careful tuning; too small may fail to enforce invertibility, too large may over-constrain the model
- Performance outside the training domain [0,1] is not guaranteed, as the model may not generalize beyond its training distribution
- The convergence proof relies on assumptions about the target conditional distribution being representable by a normalizing flow with sufficient capacity

## Confidence
- High confidence: KL divergence as a valid convergence metric and the overall architecture of PR-NF
- Medium confidence: The effectiveness of the soft reversibility constraint in practice and computational scalability for high-dimensional problems
- Medium confidence: The rigorous convergence analysis, though dependent on stated assumptions

## Next Checks
1. Test the model on a synthetic problem with known analytical solution (e.g., y = sin(2πx) + ε(x)) and verify KL divergence performance across different noise levels
2. Perform systematic sensitivity analysis of the λ hyperparameter to identify optimal values for balancing likelihood and reversibility objectives
3. Evaluate the model's extrapolation capability by testing on inputs outside the [0,1] training domain to assess generalization limits