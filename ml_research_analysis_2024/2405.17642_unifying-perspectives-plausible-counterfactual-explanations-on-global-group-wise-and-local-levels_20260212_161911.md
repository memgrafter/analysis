---
ver: rpa2
title: 'Unifying Perspectives: Plausible Counterfactual Explanations on Global, Group-wise,
  and Local Levels'
arxiv_id: '2405.17642'
source_url: https://arxiv.org/abs/2405.17642
tags:
- global
- counterfactual
- explanations
- group
- plausibility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a unified gradient-based optimization method
  for generating counterfactual explanations at local, group-wise, and global levels.
  The method combines instance grouping and counterfactual generation into a single
  efficient process, replacing traditional two-step approaches.
---

# Unifying Perspectives: Plausible Counterfactual Explanations on Global, Group-wise, and Local Levels

## Quick Facts
- arXiv ID: 2405.17642
- Source URL: https://arxiv.org/abs/2405.17642
- Reference count: 40
- Key outcome: Introduces unified gradient-based optimization for generating counterfactual explanations at local, group-wise, and global levels, outperforming state-of-the-art baselines in validity and plausibility

## Executive Summary
This paper presents a unified gradient-based optimization method for generating counterfactual explanations across multiple levels of abstraction. The approach combines instance grouping and counterfactual generation into a single efficient process, eliminating the need for separate clustering steps. By incorporating probabilistic plausibility constraints using normalizing flows, the method ensures generated explanations are both valid (change the prediction) and realistic (maintain data density). The unified framework supports global, group-wise, and local counterfactual generation through a single optimization process, demonstrating superior performance across multiple datasets and classification models.

## Method Summary
The method employs gradient-based optimization to simultaneously determine instance groupings and generate counterfactual explanations. It uses sparsemax activation for differentiable group assignment, normalizing flows for density-based plausibility constraints, and determinant-based regularization for group diversity. The approach works with differentiable classification models and can generate global, group-wise, and local counterfactuals through a unified framework. The optimization minimizes a composite loss function balancing validity, plausibility, sparsity, group count, and diversity objectives.

## Key Results
- Achieves perfect validity scores (100%) across multiple datasets and model types
- Significantly higher plausibility scores compared to state-of-the-art baselines
- Maintains competitive proximity metrics while ensuring counterfactuals are realistic and actionable
- Outperforms traditional two-step clustering-then-optimization approaches in both efficiency and quality

## Why This Works (Mechanism)

### Mechanism 1: Unified Gradient-Based Optimization
- The method integrates grouping and counterfactual generation into a single optimization step
- Differentiable approximation of group assignments via sparsemax enables joint optimization
- Core assumption: Sparsemax provides sufficient representational power for meaningful groupings
- Evidence: Abstract states it "replaces traditional two-step methods" and section 4.2 describes the novel unified approach

### Mechanism 2: Probabilistic Plausibility Constraints
- Normalizing flows model conditional density p(x'|y') for plausibility evaluation
- Density-based constraint penalizes counterfactuals below probability threshold δ
- Core assumption: Normalizing flow accurately captures true data distribution
- Evidence: Abstract mentions "integration of plausibility criteria" and section 4.3 details the density-based formulation

### Mechanism 3: Group Diversity Regularization
- Determinant-based regularization encourages linear independence among group shifting vectors
- Maximizes volume spanned by group shifting vectors to promote distinct groups
- Core assumption: Maximizing determinant effectively encourages meaningful diversity
- Evidence: Section 4.5 explicitly describes the determinant-based regularization for diversity

## Foundational Learning

- Concept: Gradient-based optimization for differentiable models
  - Why needed here: Required for simultaneous optimization of grouping decisions and counterfactual generation
  - Quick check question: What happens if we try to use this method with a non-differentiable model like a decision tree?

- Concept: Normalizing flows for density estimation
  - Why needed here: Provides flexible, non-parametric density modeling for plausibility constraints
  - Quick check question: Why use normalizing flows instead of simpler density estimation methods like kernel density estimation?

- Concept: Sparsemax activation for differentiable one-hot selection
  - Why needed here: Enables differentiable approximation of discrete group assignment decisions
  - Quick check question: How does sparsemax differ from softmax in terms of the sparsity of its outputs?

## Architecture Onboarding

- Component map:
  - Input data matrix X0 (N × D) -> Group assignment matrix P (N × K) via sparsemax -> Base shifting vectors DGW (K × D) -> Magnitude matrix K (diagonal N × N) -> Normalizing flow model -> Classification model h -> Loss components (validity, plausibility, sparsity, group count, diversity)

- Critical path:
  1. Initialize P, DGW, K randomly
  2. Compute counterfactuals X'GW = X0 + KSDGW
  3. Evaluate loss components
  4. Backpropagate gradients to update P, DGW, K
  5. Iterate until convergence

- Design tradeoffs:
  - Computational cost vs. explanation quality (more groups = better fit but slower)
  - Plausibility vs. proximity (stricter density constraints may require larger changes)
  - Automatic vs. manual group selection (λk hyperparameter control)

- Failure signatures:
  - All instances assigned to single group → check sparsemax initialization or λs regularization
  - Poor validity scores → check classification loss weight λ or model differentiability
  - Extremely large counterfactual distances → check plausibility threshold δ or normalizing flow quality

- First 3 experiments:
  1. Simple synthetic dataset (e.g., Moons) with small K to verify basic functionality
  2. Compare CPU vs GPU execution times on moderate-sized dataset
  3. Ablation study varying λd to observe group diversity effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the unified gradient-based optimization method scale with dataset size and dimensionality for real-time applications?
- Basis in paper: The paper discusses efficiency but lacks detailed scalability analysis
- Why unresolved: Experiments focus on cross-validation rather than single-instance processing times
- What evidence would resolve it: Benchmarks showing processing times for single instances and scalability tests with increasing dataset sizes

### Open Question 2
- Question: What is the impact of the density threshold δ on the trade-off between plausibility and actionability of generated counterfactuals?
- Basis in paper: Paper mentions δ is user-defined but doesn't explore threshold effects systematically
- Why unresolved: No systematic analysis of how varying δ values influence explanation quality
- What evidence would resolve it: Experimental results showing relationships between δ values and validity/proximity/plausibility metrics

### Open Question 3
- Question: How does the method handle categorical features or mixed-type datasets?
- Basis in paper: Explicitly states method doesn't support categorical variables due to gradient-based optimization
- Why unresolved: Acknowledges limitation but doesn't explore potential extensions
- What evidence would resolve it: Proposed extensions or preprocessing methods for categorical features with experimental validation

## Limitations

- Method doesn't support categorical features due to reliance on gradient-based optimization
- Computational complexity scales with both number of instances and groups, potentially limiting scalability
- Effectiveness depends heavily on quality of normalizing flow density estimation, which may struggle with high-dimensional data

## Confidence

**High Confidence:** Core gradient-based optimization framework and integration of grouping with counterfactual generation are well-supported by experimental results showing superiority in validity and plausibility metrics.

**Medium Confidence:** Normalizing flow implementation for plausibility constraints is theoretically sound but lacks exploration of failure modes when flow model poorly captures data distribution.

**Low Confidence:** Performance on very high-dimensional datasets (>64 features) or with non-differentiable models is not explored; computational complexity claims need verification on larger-scale problems.

## Next Checks

1. **Robustness Testing:** Evaluate performance when normalizing flow model is deliberately mis-specified or trained with limited data to assess sensitivity to density estimation quality.

2. **Scalability Assessment:** Test algorithm on larger datasets (N > 10,000) and higher-dimensional feature spaces to verify claimed computational efficiency and identify practical limits.

3. **Ablation Studies:** Systematically remove or modify each key component (sparsemax grouping, normalizing flow plausibility, diversity regularization) to quantify individual contributions to overall performance.