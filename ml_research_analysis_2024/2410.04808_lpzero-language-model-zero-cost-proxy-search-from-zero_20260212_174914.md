---
ver: rpa2
title: 'LPZero: Language Model Zero-cost Proxy Search from Zero'
arxiv_id: '2410.04808'
source_url: https://arxiv.org/abs/2410.04808
tags:
- search
- proxies
- proxy
- lpzero
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LPZero automatically designs zero-cost (ZC) proxies for language
  models without expert knowledge or retraining. It uses genetic programming to evolve
  symbolic expressions over a unified search space containing existing ZC proxies.
---

# LPZero: Language Model Zero-cost Proxy Search from Zero

## Quick Facts
- arXiv ID: 2410.04808
- Source URL: https://arxiv.org/abs/2410.04808
- Authors: Peijie Dong; Lujun Li; Xiang Liu; Zhenheng Tang; Xuebo Liu; Qiang Wang; Xiaowen Chu
- Reference count: 29
- Key outcome: LPZero automatically designs zero-cost proxies for language models without expert knowledge or retraining, achieving the highest ranking consistency compared to human-designed proxies.

## Executive Summary
LPZero introduces a novel approach to automatically discover zero-cost proxies for language model architecture search. Using genetic programming with a rule-based pruning strategy, LPZero evolves symbolic expressions over a unified search space containing existing ZC proxies. The method significantly reduces search time compared to prior NAS approaches while maintaining competitive accuracy. Experiments on FlexiBERT, GPT-2, and LLaMA-7B demonstrate superior ranking ability and downstream task performance.

## Method Summary
LPZero employs genetic programming to evolve zero-cost proxies through a unified search space containing existing ZC proxies. The system uses tournament selection, crossover, and mutation operations on symbolic expressions representing proxy formulas. A rule-based pruning strategy eliminates unpromising candidates early in the search process. The method evaluates proxies based on their ranking consistency with ground truth performance using Spearman's ρ and Kendall's τ metrics, requiring only 10 GPU hours for the complete search process.

## Key Results
- LPZero achieves Spearman's ρ = 0.748 on FlexiBERT benchmark, outperforming human-designed proxies
- On GPT-2, LPZero achieves SOTA performance with τ = 0.87 and ρ = 0.98
- LPZero requires only 0.5 GPU hours for searching, compared to 2.5 GPU hours for LoNAS, while achieving similar average scores

## Why This Works (Mechanism)

### Mechanism 1
LPZero improves ranking consistency by automatically discovering zero-cost proxies that better capture the relationship between architecture structure and performance than manually crafted proxies. Genetic programming searches a unified proxy search space containing existing zero-cost proxies, evolving symbolic expressions that combine unary and binary operations over six types of inputs. The Rule-based Pruning Strategy eliminates unpromising proxies early, reducing search space and improving efficiency.

### Mechanism 2
LPZero significantly reduces search time compared to prior NAS methods while maintaining competitive accuracy. By using zero-cost proxies that avoid actual training, LPZero can evaluate many architectures with only a single forward pass, requiring only 10 GPU hours for the entire search process.

### Mechanism 3
LPZero's searched proxies generalize across different language model benchmarks (FlexiBERT, GPT-2, LLaMA). The unified proxy search space encompasses existing ZC proxies for different transformer architectures, allowing LPZero to discover proxies that capture architecture-specific characteristics while maintaining broad applicability.

## Foundational Learning

- Concept: Genetic programming and symbolic regression
  - Why needed here: LPZero uses genetic programming to evolve symbolic expressions representing zero-cost proxies
  - Quick check question: What are the key components of a genetic programming system, and how would you represent a mathematical expression as a tree structure?

- Concept: Zero-cost proxy methods and their mathematical foundations
  - Why needed here: LPZero builds upon existing zero-cost proxies, requiring understanding of the mathematical operations and their relationship to architecture performance
  - Quick check question: How do different zero-cost proxy formulas (like SNIP, Fisher, Synflow) capture different aspects of network architecture, and what mathematical operations do they employ?

- Concept: Neural architecture search benchmarks and evaluation metrics
  - Why needed here: LPZero is evaluated on FlexiBERT, GPT-2, and LLaMA benchmarks
  - Quick check question: What is the difference between Kendall's tau and Spearman's rho as ranking correlation metrics, and why are they appropriate for evaluating zero-cost proxies?

## Architecture Onboarding

- Component map: Proxy Search Space -> Genetic Programming Engine -> Evaluation Framework -> Benchmarks
- Critical path: Initialize population of random proxies → Evaluate each proxy's ranking consistency → Select promising proxies via tournament selection → Apply crossover and mutation → Apply RPS to eliminate unpromising candidates → Repeat until convergence → Return proxy with highest ranking correlation
- Design tradeoffs: Search space size vs. computational efficiency; RPS strictness vs. exploration; number of unary operations vs. expressiveness
- Failure signatures: Population convergence to poor solutions; rapid population collapse; no improvement over iterations
- First 3 experiments:
  1. Reproduce baseline results on FlexiBERT benchmark with default parameters and verify it achieves Spearman's ρ ≈ 0.748
  2. Ablation study on RPS: Run LPZero with and without RPS on GPT-2 benchmark to measure impact on search efficiency and final proxy quality
  3. Parameter sensitivity: Vary initial population size (80, 100, 200) and measure impact on convergence speed and final proxy performance on LLaMA benchmark

## Open Questions the Paper Calls Out

- Question: How does LPZero's performance scale with larger language models beyond 7B parameters?
  - Basis in paper: The paper mentions LPZero was tested on LLaMA-7B and suggests it could be applied to larger models
  - Why unresolved: Experiments only cover models up to 7B parameters
  - What evidence would resolve it: Running LPZero on larger language models (e.g., 30B, 70B parameters) and comparing its ranking consistency and search efficiency to baseline methods

- Question: How robust is LPZero to different search space configurations and primitive operation sets?
  - Basis in paper: The paper discusses the impact of the number of unary operations on performance but does not extensively explore alternative search space designs
  - Why unresolved: The current study uses a specific search space and primitive operation set
  - What evidence would resolve it: Systematically varying the search space size, types of operations included, and evaluating LPZero's performance across these configurations

- Question: Can LPZero be adapted to optimize for functional capabilities beyond architectural ranking, such as inference efficiency or reasoning ability?
  - Basis in paper: The paper acknowledges that its framework focuses on architectural optimization and suggests this as a limitation and future research direction
  - Why unresolved: The current LPZero framework is designed to optimize architectural ranking consistency
  - What evidence would resolve it: Extending LPZero to incorporate functional metrics (e.g., inference speed, reasoning accuracy) into the proxy search objective and evaluating performance on these metrics

## Limitations

- The rule-based pruning strategy (RPS) implementation details are not fully specified in the main text
- Evaluation relies heavily on ranking correlation metrics rather than direct validation of whether LPZero finds genuinely better architectures
- Generalizability to other transformer architectures or tasks beyond the three specific benchmarks tested remains unproven

## Confidence

- **High Confidence**: LPZero's ability to improve ranking consistency on the tested benchmarks compared to existing zero-cost proxies
- **Medium Confidence**: LPZero's computational efficiency claims relative to prior NAS methods
- **Medium Confidence**: The downstream task performance improvements on LLaMA-7B

## Next Checks

1. Implement and test the rule-based pruning strategy in isolation to verify it correctly identifies and eliminates unpromising proxies early without removing potentially valuable candidates
2. Apply LPZero-discovered proxies to an additional transformer architecture (e.g., RoBERTa or T5) not included in the original benchmarks to test whether the evolved proxies generalize
3. Beyond ranking correlation, actually train the top-5 architectures identified by LPZero and existing proxies on the FlexiBERT benchmark to verify that LPZero identifies architectures with superior true performance