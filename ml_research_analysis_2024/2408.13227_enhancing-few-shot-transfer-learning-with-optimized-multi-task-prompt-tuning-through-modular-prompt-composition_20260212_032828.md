---
ver: rpa2
title: Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning
  through Modular Prompt Composition
arxiv_id: '2408.13227'
source_url: https://arxiv.org/abs/2408.13227
tags:
- prompt
- source
- prompts
- tasks
- private
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses few-shot transfer learning in multi-task settings,\
  \ where catastrophic forgetting and negative interference hinder performance. It\
  \ proposes ComPT, a framework that constructs each target task\u2019s prompt as\
  \ a weighted combination of shared source prompts and a task-specific private prompt."
---

# Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition

## Quick Facts
- **arXiv ID**: 2408.13227
- **Source URL**: https://arxiv.org/abs/2408.13227
- **Reference count**: 26
- **Primary result**: ComPT improves few-shot transfer learning by composing shared and private prompts, outperforming standard prompt tuning on GLUE and SET2 benchmarks.

## Executive Summary
This paper introduces ComPT, a compositional prompt tuning framework for few-shot multi-task learning. It addresses catastrophic forgetting and negative interference by constructing each target task’s prompt as a weighted combination of shared source prompts and a task-specific private prompt. The approach uses attention weights and learnable gating coefficients to balance shared and private contributions, enabling flexible knowledge transfer and task specialization. Evaluated on GLUE and SET2, ComPT achieves higher accuracy and robustness in few-shot settings while being parameter-efficient and modular.

## Method Summary
ComPT decomposes each target task’s prompt into a combination of shared source prompts and a task-specific private prompt. Shared prompts encode transferable knowledge, while the private prompt allows task specialization. An attention module learns weights to dynamically prioritize relevant source prompts, and gating coefficients control the balance between shared and private contributions. All components—source prompts, private prompts, attention module, and gating—are learned jointly from scratch via multi-task training, without relying on large-scale pretraining. The framework supports different normalization strategies (sigmoid, softmax, sparsemax) to optimize prompt composition based on task similarity and number of source prompts.

## Key Results
- ComPT outperforms standard prompt tuning and related baselines in few-shot scenarios across GLUE and SET2 benchmarks.
- The compositional design enables higher accuracy and robustness while requiring significantly less training data.
- The approach is modular, parameter-efficient, and generalizes to other modalities such as vision and multimodal tasks.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weighted composition of shared and private prompts mitigates catastrophic forgetting and negative interference in few-shot multi-task settings.
- Mechanism: The target prompt for each task is a learned weighted combination of multiple shared source prompts (transferable knowledge) and a task-specific private prompt (specialization). Attention weights dynamically prioritize relevant source prompts, while gating coefficients control the balance between shared and private contributions.
- Core assumption: Different tasks have overlapping but distinct knowledge needs, and selective combination allows optimal trade-off between generalization and specialization.
- Evidence anchors:
  - [abstract]: "Our proposed approach decomposes the prompt for each target task into a combination of shared prompts (source prompts) and a task-specific prompt (private prompt)."
  - [section]: "Unlike vanilla prompt tuning—which assigns an independent prompt to each task—our approach enables parameter sharing by decomposing each target prompt into a weighted combination of shared and private components."
  - [corpus]: Weak evidence. Related papers discuss multi-task transfer learning but do not clearly anchor to weighted prompt decomposition. "Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning" uses Bayesian approaches but does not describe compositional decomposition as proposed here.
- Break condition: If attention weights converge to uniform or extreme values across tasks, the system may lose task-specific adaptation or fail to transfer useful knowledge, leading to performance similar to single-task tuning.

### Mechanism 2
- Claim: Joint learning of source prompts, private prompts, and attention weights from scratch (without pretraining) is effective in few-shot settings.
- Mechanism: All components—source prompts, private prompts, attention module—are initialized randomly and learned together through multi-task training. This avoids dependency on large-scale pretraining and allows the model to adapt dynamically to the specific set of tasks.
- Core assumption: In low-data regimes, learning from scratch can be more effective than transferring suboptimal prompts from unrelated tasks.
- Evidence anchors:
  - [section]: "Unlike vanilla prompt tuning—which assigns an independent prompt to each task—our approach enables parameter sharing by decomposing each target prompt into a weighted combination of shared and private components. The parameters of the shared prompts, private prompts, and their combination mechanism (e.g., attention weights) are learned jointly via backpropagation."
  - [corpus]: Weak evidence. Related works like "CrossPT" and "Task Prompt Vectors" discuss transfer but focus on initialization from pretraining rather than learning from scratch.
- Break condition: If the number of tasks or prompts becomes too large relative to the few-shot data, joint learning may overfit, and separate pretraining of source prompts could become more effective.

### Mechanism 3
- Claim: Different normalization strategies for attention weights (sigmoid, softmax, sparsemax) optimize prompt composition based on task similarity and number of source prompts.
- Mechanism: Sigmoid is used for single source prompts to allow flexible inclusion, softmax for moderate numbers of sources to introduce competition, and sparsemax for large numbers to enforce sparsity and reduce noise.
- Core assumption: The number and nature of source prompts affect the optimal normalization to balance task relevance and generalization.
- Evidence anchors:
  - [section]: "Normalization.To reflect the relevance of source prompts to the target task, we evaluated several normalization strategies.Softmaxoffers smooth gradients and introduces competition among source prompts...sparsemax[13] often performs better by assigning exact zeros to irrelevant sources...In contrast,sigmoidtreats each source independently."
  - [corpus]: Weak evidence. Related works do not explicitly discuss attention normalization strategies in prompt tuning.
- Break condition: If task relationships are highly complex or tasks are dissimilar, even adaptive normalization may not prevent interference, and task-specific prompts may dominate, reducing the benefit of shared prompts.

## Foundational Learning

- Concept: Prompt tuning as a parameter-efficient adaptation method.
  - Why needed here: Understanding how soft prompts steer frozen language models without updating weights is essential to grasp the modularity and efficiency of the proposed approach.
  - Quick check question: How does prompt tuning differ from full fine-tuning in terms of model parameters updated?
- Concept: Multi-task learning challenges (catastrophic forgetting, negative interference).
  - Why needed here: The paper explicitly addresses these issues and proposes compositional prompt tuning as a solution; recognizing these problems is key to understanding the motivation.
  - Quick check question: What happens to performance on task A when training on task B in standard multi-task learning without mitigation?
- Concept: Attention mechanisms and normalization functions.
  - Why needed here: The method uses learned attention to weigh source prompts and applies different normalization (sigmoid, softmax, sparsemax) depending on context; understanding these is crucial for interpreting the design choices.
  - Quick check question: How does sparsemax differ from softmax in terms of output sparsity?

## Architecture Onboarding

- Component map:
  T5-base language model (frozen) -> Prompt encoder (MLP) for source and private prompts -> Attention module (with normalization) -> Gating coefficients (α, β) -> Multi-task training loop with task-specific prefixes
- Critical path:
  1. Generate input with task prefix
  2. Compute source prompt weights via attention module
  3. Compose target prompt (weighted sum or concatenation of source and private prompts)
  4. Append composed prompt to input
  5. Forward pass through frozen T5
  6. Compute loss and backpropagate to update only prompts and attention/gating
- Design tradeoffs:
  - Shorter prompts (5 tokens) improve stability but may limit expressiveness
  - Summation (SPP) vs concatenation (SCP) affects prompt length and interaction
  - Learned vs fixed attention weights and gating coefficients balance flexibility and simplicity
  - Different learning rates for source vs private prompts control transfer vs specialization
- Failure signatures:
  - Attention weights collapse to zero or one for all tasks → loss of compositionality
  - Private prompts dominate or source prompts dominate → loss of balance
  - Overfitting to few-shot data → poor generalization
  - Poor normalization choice → noisy or ineffective prompt combinations
- First 3 experiments:
  1. Implement single-task prompt tuning baseline (PT) and verify it works on a single GLUE task.
  2. Implement multi-task shared prompt baseline (MST) and compare with PT on GLUE tasks.
  3. Implement ComPT with SPP variant and test on two GLUE tasks with 8-shot data, comparing with baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ComPT scale when applied to more than eight source tasks in a multi-task learning setting?
- Basis in paper: [inferred] The paper tests ComPT with up to eight GLUE tasks but does not explore scaling to larger task sets.
- Why unresolved: The paper only provides empirical results for a limited number of tasks, leaving open the question of performance degradation or improvement with increased task complexity.
- What evidence would resolve it: Systematic experiments varying the number of source tasks, including tasks from multiple domains (NLP, vision, multimodal), would clarify scalability and robustness.

### Open Question 2
- Question: What is the impact of using pretrained source prompts versus learning all prompts from scratch on final task performance?
- Basis in paper: [explicit] The paper states that learning all components from scratch yields strong performance but does not compare against using pretrained source prompts.
- Why unresolved: The ablation of pretraining effects is not performed, so the trade-off between initialization quality and adaptation flexibility remains unclear.
- What evidence would resolve it: A controlled experiment comparing ComPT variants with and without pretrained source prompts would quantify the benefit of initialization.

### Open Question 3
- Question: How does ComPT's performance vary when applied to tasks with highly dissimilar label spaces or task objectives?
- Basis in paper: [inferred] The paper mentions that tasks like CoLA and SST-2 are hard to align and rely mostly on private prompts, but broader analysis across diverse task types is missing.
- Why unresolved: Limited discussion on cross-task interference in extreme label space mismatches leaves uncertainty about generalizability.
- What evidence would resolve it: Evaluations on heterogeneous benchmarks (e.g., combining NLI, summarization, QA) with explicit analysis of label space alignment effects would clarify robustness.

## Limitations

- The method’s effectiveness with more than eight source tasks or highly dissimilar tasks is not validated.
- The paper does not test ComPT in sequential or lifelong learning scenarios to directly measure catastrophic forgetting.
- Generalization to vision and multimodal tasks is claimed but not empirically demonstrated.

## Confidence

- **High confidence**: The compositional prompt framework is novel and clearly described; the modular architecture is sound and implementable.
- **Medium confidence**: ComPT outperforms baselines in few-shot settings, but improvements are modest and normalization-dependent; learning from scratch is plausible but not rigorously tested against pretraining.
- **Low confidence**: The claim of robustly avoiding catastrophic forgetting is not directly validated; generalization to other modalities is stated but not shown.

## Next Checks

1. **Sequential Task Evaluation**: Apply ComPT to a sequence of tasks and measure performance degradation on earlier tasks after training on later ones to test catastrophic forgetting claims.
2. **Attention Interpretability Study**: Analyze learned attention weights for correlation with known task similarities and visualize attention distributions to assess compositional transfer.
3. **Scaling and Robustness Test**: Evaluate ComPT with a larger set of source prompts and more dissimilar tasks, and measure performance as the number of shots increases to test scalability and robustness.