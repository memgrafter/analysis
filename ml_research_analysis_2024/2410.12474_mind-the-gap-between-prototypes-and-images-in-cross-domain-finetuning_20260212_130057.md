---
ver: rpa2
title: Mind the Gap Between Prototypes and Images in Cross-domain Finetuning
arxiv_id: '2410.12474'
source_url: https://arxiv.org/abs/2410.12474
tags:
- copa
- prototype
- image
- prototypes
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies a gap between prototype and image instance
  embeddings in cross-domain few-shot classification and proposes a method called
  contrastive prototype-image adaptation (CoPA) to address it. CoPA adapts different
  transformation heads for prototypes and images using a symmetric cross-entropy loss,
  treating prototypes as text prompts similar to CLIP.
---

# Mind the Gap Between Prototypes and Images in Cross-domain Finetuning

## Quick Facts
- arXiv ID: 2410.12474
- Source URL: https://arxiv.org/abs/2410.12474
- Reference count: 40
- Key outcome: CoPA achieves state-of-the-art performance on cross-domain few-shot classification by preserving the gap between prototype and image embeddings through separate transformation heads

## Executive Summary
This paper identifies a critical gap shrinkage problem in cross-domain few-shot classification when using shared transformations for prototypes and images. The authors propose Contrastive Prototype-Image Adaptation (CoPA), which uses separate transformation heads for prototypes and images, treating prototypes as text prompts similar to CLIP. CoPA preserves the natural modality gap between these representations, leading to better generalization and state-of-the-art performance on Meta-Dataset. The method is particularly effective when combined with other learning modules like TSA.

## Method Summary
CoPA addresses the gap shrinkage problem by using two separate linear transformation heads: hθP for prototypes and hθI for image instances. During adaptation, prototypes are computed by averaging support set embeddings for each class. The method employs symmetric cross-entropy (SCE) loss with a temperature coefficient τ to align transformed representations while preserving the gap between them. The SCE loss maximizes instance-prototype similarity while minimizing instance-instance similarity, acting as a regularizer. CoPA is trained using Adam with separate learning rates for the two transformation heads, optimized for a fixed number of iterations per episode.

## Key Results
- CoPA achieves state-of-the-art performance on Meta-Dataset, outperforming previous methods by significant margins
- The gap between prototype and image representations is preserved and even enlarged during training, which correlates with better generalization
- CoPA benefits from extra learning modules like TSA, showing improved performance when combined with complementary approaches
- Theoretical analysis reveals that the global minimum of validation loss occurs at the enlarged gap, indicating optimal generalization performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Applying the same transformation to both prototype and image instance embeddings shrinks the natural "modality gap" between them.
- Mechanism: Shared linear transformation conflates instance-level and class-level information, reducing their representational separation.
- Core assumption: Prototype and image instance embeddings encode different levels of abstraction and should be transformed differently.
- Evidence anchors:
  - [abstract] "simply applying the same transformation during the adaptation phase constrains exploring the optimal representations and shrinks the gap between prototype and image representations"
  - [section 3.2] "the shared representation transformation tends to shrink the gap between the learned prototype and image instance representations"
  - [corpus] Weak - no direct evidence in corpus
- Break condition: If the modality gap is artificially widened beyond the optimal range, generalization performance degrades.

### Mechanism 2
- Claim: Different transformations for prototypes and images preserve discriminative gradient information.
- Mechanism: Separate transformation heads allow gradients to encode distinct similarity metrics for instance-prototype vs prototype-instance comparisons.
- Core assumption: The gradients from instance-prototype and prototype-instance similarities contain complementary discriminative information.
- Evidence anchors:
  - [section 3.3] "the gradients of ΘP depict the similarity between instance representations and prototype embeddings while the gradients of ΘI depict the similarity between prototype representations and instance embeddings"
  - [abstract] "CoPA adapts different transformations respectively for prototypes and images similarly to CLIP by treating prototypes as text prompts"
  - [corpus] Weak - no direct evidence in corpus
- Break condition: If the two transformations become too dissimilar, alignment between prototypes and instances may fail.

### Mechanism 3
- Claim: Symmetric cross-entropy loss with different transformations enables better representation alignment and prevents overfitting.
- Mechanism: SCE loss maximizes instance-prototype similarity while minimizing instance-instance similarity, with different transformations exploring optimal distributions.
- Core assumption: The second term in SCE loss (minimizing instance-instance similarity) acts as a regularizer that prevents overfitting to prototypes.
- Evidence anchors:
  - [section 5.2.2] "minimizing SCE loss tends to reduce such similarities. Thus, the gap enlargement also functions as a regularization to alleviate overfitting"
  - [abstract] "CoPA achieves the state-of-the-art performance more efficiently" and "learn better representation clusters"
  - [corpus] Weak - no direct evidence in corpus
- Break condition: If the temperature coefficient is poorly tuned, the balance between alignment and regularization may break.

## Foundational Learning

- Concept: **Contrastive learning and modality gap preservation**
  - Why needed here: Understanding how modality gaps contribute to generalization is central to CoPA's design rationale.
  - Quick check question: Why does preserving the gap between prototype and image embeddings improve downstream performance?

- Concept: **Episodic meta-learning and vary-way vary-shot tasks**
  - Why needed here: CoPA operates in the meta-learning framework where tasks are sampled with varying class and shot counts.
  - Quick check question: How does the vary-way vary-shot setting differ from standard few-shot classification?

- Concept: **Nearest centroid classifier and prototype calculation**
  - Why needed here: The NCC loss and prototype averaging are fundamental to how CoPA aligns representations.
  - Quick check question: What is the mathematical relationship between instance embeddings and their class prototype?

## Architecture Onboarding

- Component map:
  Frozen pre-trained backbone (ResNet-18) -> Two transformation heads (hθP for prototypes, hθI for instances) -> Symmetric cross-entropy loss with temperature τ

- Critical path:
  1. Extract embeddings from frozen backbone
  2. Compute class prototypes via averaging
  3. Apply respective transformations to prototypes and instances
  4. Compute SCE loss between transformed representations
  5. Backpropagate through both transformation heads

- Design tradeoffs:
  - More parameters (2x linear heads) vs. better representation separation
  - SCE loss vs. NCC loss: alignment quality vs. simplicity
  - Temperature tuning: balance between alignment and regularization

- Failure signatures:
  - Overfitting: validation loss decreases then increases during adaptation
  - Underfitting: both prototype and instance representations remain scattered
  - Gap shrinkage: prototype and instance clusters collapse together

- First 3 experiments:
  1. Run URL baseline vs. CoPA on a single dataset to observe gap behavior
  2. Test SCE vs. NCC loss on CoPA to verify regularization effect
  3. Compare 1-head vs. 2-head variants to isolate parameter effect

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the exact limits of CoPA's performance when the batch size becomes extremely small?
- Basis in paper: [explicit] The paper mentions that CoPA may fail to achieve good generalization performance with extremely few data samples, as seen in the 5-way 1-shot experiments.
- Why unresolved: The paper only briefly touches on this limitation and does not provide a concrete threshold or detailed analysis of how performance degrades with decreasing batch size.
- What evidence would resolve it: Detailed experiments showing CoPA's performance across a range of batch sizes, particularly very small ones, would clarify the limits of its effectiveness.

### Open Question 2
- Question: How does the performance of CoPA compare to other methods when applied to tasks with more than 5-way classification?
- Basis in paper: [inferred] The paper primarily focuses on 5-way classification tasks and does not extensively explore higher-way classification.
- Why unresolved: The paper does not provide results or analysis for tasks with more than 5 classes, leaving uncertainty about CoPA's scalability to more complex classification problems.
- What evidence would resolve it: Experiments evaluating CoPA on tasks with 10-way, 20-way, or higher classification would provide insights into its scalability and performance in more complex scenarios.

### Open Question 3
- Question: What is the impact of using different backbone architectures (e.g., ResNet-50, EfficientNet) on CoPA's performance?
- Basis in paper: [explicit] The paper uses a ResNet-18 backbone but mentions that CoPA is not sensitive to the complexity of model architectures, suggesting potential flexibility.
- Why unresolved: The paper does not explore the effects of using different backbone architectures, leaving questions about the optimal choice for various datasets and tasks.
- What evidence would resolve it: Comparative experiments using different backbone architectures would clarify how the choice of backbone influences CoPA's performance and generalization capabilities.

## Limitations
- The method requires careful tuning of the temperature coefficient in the SCE loss to balance alignment and regularization
- CoPA's performance may degrade when applied to tasks with extremely small batch sizes (e.g., 5-way 1-shot)
- The paper does not extensively explore CoPA's effectiveness on tasks with more than 5-way classification

## Confidence

**Major Uncertainties:**
The paper's core claims rely heavily on empirical observations without strong theoretical guarantees. While the analysis suggests that gap enlargement leads to better generalization, the exact mechanism remains partially speculative. The paper acknowledges that "simply enlarging the gap is not the whole story" and that "the enlarged gap is only a by-product of optimizing SCE loss," indicating that other factors may contribute to the observed improvements. Additionally, the claim that SCE loss functions as a regularizer through gap enlargement is supported by correlation but lacks direct causal evidence.

**Confidence Labels:**
- High confidence: The empirical results showing CoPA's state-of-the-art performance on Meta-Dataset (claims about accuracy improvements)
- Medium confidence: The mechanism explaining why different transformations preserve discriminative information (Mechanism 2)
- Low confidence: The regularization effect of SCE loss through gap enlargement (Mechanism 3)

## Next Checks

1. **Ablation on gap dynamics**: Track the gap size throughout training and correlate it with validation loss trends across multiple runs to verify that gap enlargement consistently precedes performance improvements.

2. **Cross-loss comparison**: Implement a variant that uses NCC loss with forced gap maintenance (e.g., through explicit regularization) to isolate whether the gap itself or the SCE loss formulation drives performance.

3. **Transformation head analysis**: Compare gradient magnitudes and directions from prototype vs instance transformation heads to quantify how differently they encode similarity information during optimization.