---
ver: rpa2
title: Teaching Large Language Models an Unseen Language on the Fly
arxiv_id: '2402.19167'
source_url: https://arxiv.org/abs/2402.19167
tags:
- zhuang
- dipmt
- translation
- language
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes teaching large language models (LLMs) to translate
  an unseen language on the fly using in-context learning. It introduces DIPMT++,
  a framework that enhances LLMs by incorporating lexical coverage through dictionary
  expansion, fuzzy matching, and synonym expansion, as well as retrieving syntactically
  relevant exemplars from parallel corpora.
---

# Teaching Large Language Models an Unseen Language on the Fly

## Quick Facts
- arXiv ID: 2402.19167
- Source URL: https://arxiv.org/abs/2402.19167
- Authors: Chen Zhang; Xiao Liu; Jiuheng Lin; Yansong Feng
- Reference count: 23
- Primary result: DIPMT++ enables GPT-4 to translate unseen Zhuang language with 16 BLEU score

## Executive Summary
This paper presents DIPMT++, a framework that enables large language models to translate unseen languages on the fly using in-context learning. The approach combines dictionary expansion techniques (fuzzy matching, bilingual lexicon induction, synonym expansion) with exemplar retrieval from parallel corpora to teach LLMs new languages without parameter updates. The method is evaluated on Zhuang and Kalamang, demonstrating significant improvements over baselines and showing potential for preserving linguistic diversity in low-resource languages.

## Method Summary
DIPMT++ uses in-context learning where LLMs are provided with dictionary entries and parallel corpus exemplars to translate unseen languages. The framework enhances lexical coverage through three dictionary expansion strategies and retrieves syntactically relevant exemplars to help the model learn language structure. During inference, the system maps source words using the expanded dictionary and generates translations by mimicking exemplars with similar syntactic patterns.

## Key Results
- GPT-4 achieves 16 BLEU for Chinese-to-Zhuang translation and 32 BLEU for Zhuang-to-Chinese
- DIPMT++ significantly outperforms direct prompting and few-shot baselines across multiple LLMs
- The approach improves human translation efficiency and quality in user studies
- Dictionary expansion and exemplar retrieval are shown to be essential components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: In-context learning with dictionary lookup and exemplar retrieval enables LLMs to translate unseen languages.
- Mechanism: The LLM uses provided dictionary translations to map source words to target words, and exemplars to infer syntax patterns, enabling it to generate target language sentences without parameter updates.
- Core assumption: The LLM has sufficient reasoning and mimicry ability to generalize from a small number of exemplars and dictionary entries to unseen sentences.
- Evidence anchors:
  - [abstract]: "Using a dictionary and 5K parallel sentences only, DIPMT++ significantly enhances the performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation"
  - [section]: "Built upon DIPMT, our method provides models with the meanings of words appearing in the source sentence"
  - [corpus]: Weak - no explicit model capability tests reported in the corpus

### Mechanism 2
- Claim: Fuzzy matching, bilingual lexicon induction, and synonym expansion improve lexical coverage for unseen languages.
- Mechanism: These strategies recover word translations not present in the original dictionary by matching morphological variants, mining parallel corpora, and expanding via synonyms, increasing the number of source words that can be translated.
- Core assumption: The dictionary is incomplete but the parallel corpus and synonym lists contain recoverable translations for out-of-vocabulary words.
- Evidence anchors:
  - [abstract]: "we enhance the lexical coverage by revisiting traditional techniques like bilingual lexicon induction and synonym expansion"
  - [section]: "we use the following three strategies: Fuzzy Matching, Bilingual Lexicon Induction, Synonym Expansion"
  - [corpus]: Weak - no quantitative comparison of coverage before/after these strategies

### Mechanism 3
- Claim: Retrieval of syntactically relevant exemplars helps LLMs learn syntax of unseen languages.
- Mechanism: By retrieving sentences with similar POS sequences or lexical content, the LLM can infer word order and grammatical structure patterns from the exemplars.
- Core assumption: Sentences with similar POS sequences share syntactic structures that the LLM can learn from.
- Evidence anchors:
  - [abstract]: "To aid models in grasping basic syntax, we retrieve closely related exemplars from parallel corpora"
  - [section]: "For a testing instance, its exemplars are retrieved from a parallel corpus"
  - [corpus]: Weak - the corpus doesn't report syntactic similarity metrics between retrieved and test sentences

## Foundational Learning

- Concept: In-context learning
  - Why needed here: The LLM needs to learn a new language without parameter updates, so it must generalize from a few examples in the prompt.
  - Quick check question: What happens if you remove the exemplars from the prompt?

- Concept: Bilingual dictionary lookup
  - Why needed here: The LLM has no prior knowledge of the unseen language, so it needs explicit word mappings.
  - Quick check question: How many source words in the test set are not found in the dictionary?

- Concept: Morphological variation and fuzzy matching
  - Why needed here: Words in the test set may have morphological forms not present in the dictionary.
  - Quick check question: What percentage of source words are recovered by fuzzy matching vs. exact dictionary lookup?

## Architecture Onboarding

- Component map: Dictionary expansion module -> Exemplar retrieval module -> Prompt construction module -> LLM inference module
- Critical path: Dictionary expansion → Exemplar retrieval → Prompt construction → LLM inference
- Design tradeoffs: More dictionary entries vs. prompt length; more exemplars vs. LLM context window; BM25 vs. POS-based retrieval accuracy
- Failure signatures: Zero BLEU scores indicate LLM cannot translate; low lexical coverage indicates dictionary expansion failure; poor exemplar retrieval indicates syntax learning failure
- First 3 experiments:
  1. Test LLM performance with only dictionary entries, no exemplars
  2. Test exemplar retrieval with random sampling vs. BM25
  3. Test dictionary expansion strategies individually (fuzzy matching, bilingual lexicon induction, synonym expansion)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is the approach for languages with significantly different grammatical structures from Zhuang?
- Basis in paper: [explicit] The authors acknowledge that Zhuang and Chinese share similarities, and suggest that more research on languages with larger differences would provide a more comprehensive understanding.
- Why unresolved: The current evaluation is limited to Zhuang, a language that shares similarities with Chinese. The effectiveness of the approach for languages with significantly different grammatical structures is unknown.
- What evidence would resolve it: Conducting experiments on a wider range of languages with diverse grammatical structures, including those with complex morphological systems or different word orders, would provide evidence of the approach's generalizability.

### Open Question 2
- Question: Can the approach be extended to incorporate explicit syntactic rules beyond the order of modifiers and modified elements?
- Basis in paper: [explicit] The authors explore the potential of explicitly teaching syntactic rules through chain-of-thought reasoning, but acknowledge that understanding grammar rules is a complex procedure and still presents significant challenges to current LLMs.
- Why unresolved: The pilot study focuses on a specific syntactic phenomenon (the order of modifiers and modified elements) and uses a limited approach (chain-of-thought reasoning). The effectiveness of incorporating more complex syntactic rules or using alternative methods is unknown.
- What evidence would resolve it: Developing and evaluating methods for incorporating a wider range of syntactic rules, such as those related to verb conjugation, noun declension, or sentence structure, would provide evidence of the approach's ability to handle more complex grammatical phenomena.

### Open Question 3
- Question: How does the approach perform on languages with limited or no available parallel corpora?
- Basis in paper: [inferred] The current approach relies on a parallel corpus for exemplar retrieval and bilingual lexicon induction. The effectiveness of the approach for languages with limited or no parallel corpora is unknown.
- Why unresolved: The experiments are conducted on Zhuang, which has a parallel corpus of 5K sentences. The performance of the approach on languages with limited or no parallel corpora is unknown.
- What evidence would resolve it: Conducting experiments on languages with limited or no parallel corpora, and exploring alternative methods for obtaining linguistic resources, such as using monolingual corpora or leveraging other types of linguistic data, would provide evidence of the approach's effectiveness in low-resource settings.

## Limitations

- The approach's effectiveness for languages with significantly different grammatical structures from Zhuang remains unproven
- Computational costs and context window limitations for practical deployment are not addressed
- The framework relies on having parallel corpora, which may not be available for many endangered languages

## Confidence

**High Confidence:** The fundamental claim that LLMs can translate unseen languages using in-context learning with dictionary support and exemplars. The experimental results show consistent improvements over baselines across multiple LLM models.

**Medium Confidence:** The specific mechanisms of dictionary expansion and exemplar retrieval significantly improve translation quality. While improvements are demonstrated, the relative contribution of each component is not clearly isolated.

**Low Confidence:** The scalability and practical deployment considerations of DIPMT++. The paper doesn't address computational costs, context window limitations, or performance with extremely limited parallel corpora.

## Next Checks

**Validation Check 1:** Conduct ablation studies to isolate the contribution of each dictionary expansion strategy (fuzzy matching, bilingual lexicon induction, synonym expansion) and exemplar retrieval method (BM25 vs. POS-based vs. random).

**Validation Check 2:** Test the framework on a diverse set of 3-5 additional low-resource languages with varying typological features (e.g., morphologically rich languages, languages with non-Latin scripts, tone languages).

**Validation Check 3:** Perform a detailed error analysis on the translations to identify systematic failure modes (e.g., consistent errors in specific syntactic constructions, morphological forms, or semantic domains).