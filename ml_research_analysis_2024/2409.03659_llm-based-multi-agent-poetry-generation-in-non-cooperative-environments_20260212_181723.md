---
ver: rpa2
title: LLM-based multi-agent poetry generation in non-cooperative environments
arxiv_id: '2409.03659'
source_url: https://arxiv.org/abs/2409.03659
tags:
- agents
- generation
- learning
- prompting
- poetry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a social learning framework for LLM-based
  multi-agent poetry generation in non-cooperative environments. The authors design
  a signed social network where agents interact both cooperatively and non-cooperatively,
  and propose two learning strategies for TRAINING-BASED agents (GPT-2) and PROMPTING-BASED
  agents (GPT-3.5 and GPT-4).
---

# LLM-based multi-agent poetry generation in non-cooperative environments

## Quick Facts
- arXiv ID: 2409.03659
- Source URL: https://arxiv.org/abs/2409.03659
- Authors: Ran Zhang; Steffen Eger
- Reference count: 34
- Key outcome: Negative decoding combined with positive finetuning increases diversity by 3.0-3.7 percentage points and novelty by 5.6-11.3 percentage points

## Executive Summary
This paper introduces a social learning framework for LLM-based multi-agent poetry generation in non-cooperative environments. The authors design a signed social network where agents interact both cooperatively and non-cooperatively, and propose two learning strategies for TRAINING-BASED agents (GPT-2) and PROMPTING-BASED agents (GPT-3.5 and GPT-4). For TRAINING-BASED agents, experiments show that negative decoding combined with positive finetuning increases diversity by 3.0-3.7 percentage points and novelty by 5.6-11.3 percentage points according to distinct and novel n-grams. These agents also exhibit group divergence in lexicons, styles and semantics. For PROMPTING-BASED agents, non-cooperative environments benefit diversity, with a 7.0-17.5 percentage point increase, and heterogeneous model ensembles further enhance diversity. However, PROMPTING-BASED agents show decreasing lexical diversity over time and lack group-based divergence.

## Method Summary
The framework uses a signed social network with M=4 agents divided into two groups (A and B) with positive and negative interactions. TRAINING-BASED agents use GPT-2 with finetuning and decoding strategies, while PROMPTING-BASED agents use GPT-3.5 and GPT-4 with chain-prompting and joint-prompting strategies. The learning process involves iterative generation and evaluation over T iterations, with diversity measured through distinct and novel n-grams. The contrastive loss formulation pulls closer semantic representations of in-group samples and pushes apart out-group samples to create group divergence.

## Key Results
- Negative decoding combined with positive finetuning increases diversity by 3.0-3.7 percentage points and novelty by 5.6-11.3 percentage points
- Training-based agents exhibit group divergence in lexicons, styles, and semantics over iterations
- Heterogeneous model ensembles (GPT-4 + GPT-3.5 + LlaMa3-7b) further enhance diversity with 9.8 pp increase in distinct-1 and 7.3 pp increase in distinct-2

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Negative decoding combined with positive finetuning increases diversity by 3.0-3.7 percentage points and novelty by 5.6-11.3 percentage points.
- Mechanism: The decoding strategy uses reranking of next-token probability distributions from multiple agents, where the target agent's probability is combined with in-group agents' probabilities (to encourage similarity) and out-group agents' probabilities (to encourage dissimilarity). The scaling parameter α controls the strength of negative influence.
- Core assumption: The probability distributions from different agents capture meaningful stylistic differences that can be leveraged through reranking to create more diverse outputs.
- Evidence anchors:
  - [abstract]: "negative decoding combined with positive finetuning increases diversity by 3.0-3.7 percentage points and novelty by 5.6-11.3 percentage points"
  - [section]: "The next token xtg is assigned with high probability if the probability is high under both PAi and P∗+ and low under P∗−"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism
- Break condition: If the scaling parameter α is set too high, the negative influence could dominate and produce outputs that are too dissimilar to be coherent poetry.

### Mechanism 2
- Claim: Training-based agents exhibit group divergence in lexicons, styles, and semantics over iterations.
- Mechanism: The social network structure with positive (in-group) and negative (out-group) relationships creates selective pressure where agents learn to differentiate from out-group members while maintaining similarity with in-group members. This is implemented through contrastive loss and decoding strategies.
- Core assumption: The group structure in the social network translates to meaningful stylistic differences in generated poetry.
- Evidence anchors:
  - [abstract]: "The generated poetry from TRAINING-BASED agents also exhibits group divergence in terms of lexicons, styles and semantics"
  - [section]: "The C ONTRASTIVE loss is thus LCL(Ai, (hj, hj+, hj−)) = − log esim(hj ,h+j )/τ/PQk=1 [esim(hj ,h+k )/τ + esim(hj ,h−k )/τ]"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism
- Break condition: If the initial agents are too similar or the training data lacks sufficient stylistic variation, the group divergence may not emerge.

### Mechanism 3
- Claim: Heterogeneous model ensembles (GPT-4 + GPT-3.5 + LlaMa3-7b) further enhance diversity with 9.8 pp increase in distinct-1 and 7.3 pp increase in distinct-2.
- Mechanism: Different base models have different pretraining data and architectural biases, which create complementary strengths when combined through the multi-agent framework.
- Core assumption: The diversity benefits from heterogeneous models compound with the social learning framework's existing diversity mechanisms.
- Evidence anchors:
  - [abstract]: "a more diverse ensemble of models with non-homogeneous agents has the potential to further enhance diversity, with an increase of 7.0-17.5 pp"
  - [section]: "Incorporating LlaMa3-7b along with GPT-4 and GPT-3.5 further enhances the diversity, with distinct-1 increasing by an additional 9.8 pp"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism
- Break condition: If the models are too dissimilar in capabilities, the ensemble may produce incoherent or low-quality outputs.

## Foundational Learning

- Concept: Signed social networks with cooperative (+) and non-cooperative (-) relationships
  - Why needed here: The signed network structure is the foundation for implementing both positive and negative learning strategies in the multi-agent poetry generation system
  - Quick check question: In the social network design, what type of relationship exists between agents from different groups (a1 with b1)?

- Concept: Contrastive learning with positive and negative samples
  - Why needed here: Contrastive loss is used to pull closer semantic representations of in-group samples and push apart out-group samples, creating the desired group divergence
  - Quick check question: In the contrastive loss formulation, what types of poems are used as positive samples versus negative samples?

- Concept: Controlled text generation through decoding reranking
  - Why needed here: The decoding strategy reweights next-token probabilities from multiple agents to control the style and diversity of generated poetry
  - Quick check question: In the decoding strategy, how is the next token probability distribution computed from multiple agents?

## Architecture Onboarding

- Component map: Social network layer -> Learning strategy layer -> Generation layer -> Evaluation layer
- Critical path: Social network initialization -> Agent initialization (pretrained LLMs) -> Iterative learning process (T iterations) -> Poetry generation -> Evaluation
- Design tradeoffs: 
  - Training-based agents offer better control and diversity but require computational resources for finetuning
  - Prompting-based agents are more efficient but show decreasing diversity over time and lack group divergence
  - Heterogeneous ensembles improve diversity but may introduce quality inconsistencies
- Failure signatures:
  - Diversity metrics plateau or decrease after initial iterations
  - Semantic similarity between in-group and out-group agents converges rather than diverges
  - Generated poetry lacks coherent poetic structure or contains excessive grammatical errors
- First 3 experiments:
  1. Run with α=0 (positive finetuning only) to establish baseline "echo chamber" performance
  2. Run with α=2, #A=2, LCE to test negative decoding combined with positive finetuning
  3. Run with α=2, #A=4, LCE to test the effect of increasing the number of interactive agents

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of PROMPTING-BASED agents change when using a more diverse ensemble of base models, including smaller or domain-specific LLMs?
- Basis in paper: [explicit] The authors mention that combining GPT-4 with GPT-3.5 and LLaMA3-7b leads to increased diversity in generated poetry, with distinct-1 increasing by 9.8 pp and distinct-2 by 7.3 pp compared to GPT-4 alone.
- Why unresolved: The experiments only tested a limited combination of models (GPT-4, GPT-3.5, LLaMA3-7b). The impact of using even more diverse or smaller models is not explored.
- What evidence would resolve it: Experiments testing PROMPTING-BASED agents with various combinations of diverse LLMs, including smaller or domain-specific models, and measuring their impact on poetry diversity and quality.

### Open Question 2
- Question: Can the group-based divergence observed in TRAINING-BASED agents be achieved in PROMPTING-BASED agents by modifying the initialization process or using more contrastive prompts?
- Basis in paper: [inferred] The authors found that PROMPTING-BASED agents do not exhibit group-based divergence, even when initialized with poems of contrasting styles (e.g., Edgar Allan Poe vs. school children). This suggests that the initialization process or prompting strategy may be insufficient to induce group-based behavior.
- Why unresolved: The experiments only tested a limited number of initialization methods and prompting strategies. The impact of more sophisticated initialization or prompting techniques is not explored.
- What evidence would resolve it: Experiments testing PROMPTING-BASED agents with various initialization methods (e.g., using more contrastive or domain-specific poems) and prompting strategies (e.g., using more detailed or nuanced prompts) to induce group-based behavior.

### Open Question 3
- Question: How does the performance of the proposed framework change when applied to other creative tasks beyond poetry generation, such as story writing or song lyrics?
- Basis in paper: [explicit] The authors argue that their framework could be applied to other creative tasks, stating that "a more human-like (network-structured) social learning process that emphasizes non-cooperative interaction can bring in more diversity and novelty."
- Why unresolved: The experiments only tested the framework on poetry generation. The performance on other creative tasks is not evaluated.
- What evidence would resolve it: Experiments applying the proposed framework to other creative tasks, such as story writing or song lyrics, and measuring its impact on diversity, novelty, and quality of generated content.

### Open Question 4
- Question: How does the stability of the simulation results change when using different random seeds or conducting multiple runs?
- Basis in paper: [explicit] The authors mention that due to resource constraints, they did not conduct multiple runs for all experiments. Instead, they studied the stability of their experiments using two settings for TRAINING-BASED agents and one setting for PROMPTING-BASED agents.
- Why unresolved: The stability results are based on a limited number of runs and settings. The impact of using different random seeds or conducting more runs is not explored.
- What evidence would resolve it: Experiments conducting multiple runs with different random seeds and settings for all experiments, and measuring the stability of the simulation results across runs.

## Limitations
- Limited corpus evidence with weak direct evidence for key mechanisms
- Several core mechanisms lack detailed specification in prompt templates and contrastive loss implementation
- Training stability concerns not fully addressed for training-based agents

## Confidence
- High Confidence: Social network framework design, diversity metrics improvements with negative decoding + positive finetuning, heterogeneous model ensembles
- Medium Confidence: Group divergence claims for training-based agents, non-cooperative environment benefits for prompting-based agents, contrastive learning formulation
- Low Confidence: Persistence of diversity gains over extended iterations, practical significance for actual poetry quality, robustness across different poetry styles

## Next Checks
1. Conduct blind human evaluation comparing poems from cooperative vs. non-cooperative environments to verify that diversity metrics correlate with perceived poetic quality and stylistic distinctiveness.
2. Systematically vary the social network topology to determine whether the observed effects are robust to network configuration changes.
3. Extend the iteration count beyond the reported range and monitor whether diversity metrics plateau, decrease, or remain stable to assess the sustainability of the learning process.