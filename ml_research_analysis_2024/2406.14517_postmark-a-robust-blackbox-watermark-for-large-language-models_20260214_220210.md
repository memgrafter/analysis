---
ver: rpa2
title: 'PostMark: A Robust Blackbox Watermark for Large Language Models'
arxiv_id: '2406.14517'
source_url: https://arxiv.org/abs/2406.14517
tags:
- mark
- text
- post
- words
- watermark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces POST MARK, a post-hoc watermarking method
  for detecting LLM-generated text that does not require access to model logits. The
  approach uses a semantic embedding model to select input-dependent watermark words
  from a secret table, then employs an instruction-following LLM to insert these words
  into the text.
---

# PostMark: A Robust Blackbox Watermark for Large Language Models

## Quick Facts
- **arXiv ID**: 2406.14517
- **Source URL**: https://arxiv.org/abs/2406.14517
- **Reference count**: 30
- **Primary result**: PostMark achieves higher robustness to paraphrasing attacks than existing watermarking methods while not requiring access to model logits.

## Executive Summary
PostMark introduces a post-hoc watermarking method for detecting LLM-generated text that operates without access to model logits. The approach uses semantic embeddings to select watermark words from a secret table and an instruction-following LLM to insert these words into the text. Experiments across eight baseline algorithms, five base LLMs, and three datasets demonstrate that PostMark achieves significantly higher robustness to paraphrasing attacks, particularly on low-entropy models aligned with human preferences. The method maintains strong detection rates (>90%) before paraphrasing and outperforms baselines after paraphrasing, while human evaluations confirm inserted words are difficult to detect and watermarking preserves text quality reasonably well.

## Method Summary
PostMark is a post-hoc watermarking method that embeds watermark words into text generated by LLMs without requiring access to model logits. The system uses three main components: an embedding model (EMBEDDER) to compute semantic embeddings of the input text, a secret word embedding table (SECTABLE) that maps vocabulary to document embeddings, and an insertion model (INSERTER) that rewrites the text to incorporate selected watermark words. The watermark word selection is based on cosine similarity between the input text embedding and word embeddings in the secret table. During detection, the process is repeated and watermark words are checked for presence using a similarity threshold. The method operates with an insertion ratio parameter that controls the number of watermark words added to the text.

## Key Results
- PostMark achieves significantly higher robustness to paraphrasing attacks than existing watermarking methods, particularly on low-entropy models aligned with human preferences.
- The method maintains true positive rates above 90% before paraphrasing and outperforms baselines after paraphrasing attacks.
- Human evaluations show that inserted watermark words are difficult to detect and that watermarking preserves text quality reasonably well.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PostMark achieves higher robustness to paraphrasing attacks than existing methods by leveraging semantic embeddings that remain stable under paraphrasing.
- Mechanism: The watermark word selection is based on cosine similarity between the input text embedding and word embeddings in a secret table. Since paraphrasing aims to preserve meaning while changing surface form, the semantic embedding of the text changes minimally, ensuring consistent watermark word selection.
- Core assumption: Paraphrasing changes surface form more than semantic content, so text embeddings remain stable across paraphrasing.
- Evidence anchors:
  - [abstract]: "POST MARK is more robust to paraphrasing attacks than existing watermarking methods"
  - [section]: "the intuition that a text's semantics should not drastically change after watermarking or paraphrasing"
  - [corpus]: Weak - the corpus contains recent watermarking papers but no direct evidence about semantic stability under paraphrasing
- Break condition: If paraphrasing significantly alters semantic content or if the embedding model fails to capture semantic invariance, the watermark word selection becomes inconsistent.

### Mechanism 2
- Claim: PostMark maintains effectiveness on low-entropy models aligned with human preferences.
- Mechanism: Unlike logit-based methods that depend on modifying next-token probability distributions, PostMark operates solely on text outputs. Low-entropy models (like those aligned with RLHF) have more peaked distributions, making logit-based methods less effective, but PostMark's semantic embedding approach remains unaffected.
- Core assumption: Low-entropy models produce more deterministic outputs, reducing the effectiveness of methods that rely on manipulating token probabilities.
- Evidence anchors:
  - [abstract]: "particularly on low-entropy models aligned with human preferences"
  - [section]: "logit-based baselines (i.e., all baselines except Blackbox) generally perform worse on aligned models"
  - [corpus]: Weak - corpus contains related watermarking work but no specific evidence about low-entropy model performance
- Break condition: If semantic embeddings themselves become less informative in low-entropy models, or if the insertion model fails to maintain coherence in highly deterministic text.

### Mechanism 3
- Claim: PostMark's modular design allows flexible component substitution while maintaining robustness.
- Mechanism: The system decouples three components: an embedding model (EMBEDDER), a secret word embedding table (SECTABLE), and an insertion model (INSERTER). This separation allows substituting different models for each component based on availability, cost, or performance requirements.
- Core assumption: The watermarking effectiveness depends on the interaction between components rather than any single component's specific implementation.
- Evidence anchors:
  - [abstract]: "POST MARK requires access to just the text generated by the underlying LLM, not the next-token distributions"
  - [section]: "the modular design of POST MARK allows for flexible experimentation with various components"
  - [corpus]: Weak - corpus contains related work but no direct evidence about modular substitution effects
- Break condition: If components are too tightly coupled or if performance degrades significantly when substituting components.

## Foundational Learning

- **Concept: Semantic embeddings and cosine similarity**
  - Why needed here: PostMark relies on computing cosine similarity between text embeddings and word embeddings to select watermark words. Understanding how embeddings capture semantic meaning and how cosine similarity measures semantic relatedness is crucial.
  - Quick check question: How would you explain why cosine similarity is preferred over Euclidean distance for comparing semantic embeddings?

- **Concept: Text generation and decoding processes**
  - Why needed here: Understanding how LLMs generate text through decoding steps helps appreciate why PostMark's post-hoc approach differs from watermarking methods that require logit access during generation.
  - Quick check question: What's the key difference between PostMark's approach and traditional watermarking methods in terms of when they modify the text generation process?

- **Concept: Paraphrasing and semantic preservation**
  - Why needed here: PostMark's robustness relies on the assumption that paraphrasing preserves semantic content while changing surface form. Understanding different types of paraphrasing and their effects on meaning is important.
  - Quick check question: Can you think of scenarios where paraphrasing might significantly alter semantic content, potentially breaking PostMark's assumptions?

## Architecture Onboarding

- **Component map**: EMBEDDER (semantic embedding model) -> SECTABLE (secret word embedding table) -> INSERTER (instruction-following LLM) -> Detection pipeline

- **Critical path**:
  1. Generate input text embedding using EMBEDDER
  2. Compute cosine similarity with SECTABLE and select watermark words
  3. Instruct INSERTER to rewrite text incorporating selected words
  4. During detection, repeat steps 1-2 and check for word presence

- **Design tradeoffs**:
  - Open vs closed components: Using closed-source models (like GPT-4) provides better performance but increases costs and dependencies; open-source alternatives reduce costs but may sacrifice robustness
  - Insertion ratio: Higher ratios increase robustness but degrade quality; lower ratios improve quality but reduce detection reliability
  - Exact vs fuzzy matching: Exact matching is faster but less robust to paraphrasing; fuzzy matching using semantic similarity handles paraphrasing better but increases computational cost

- **Failure signatures**:
  - Low TPR after paraphrasing: May indicate semantic embeddings aren't stable enough under paraphrasing attacks
  - Poor text quality: May indicate INSERTER isn't effectively incorporating watermark words while maintaining coherence
  - High false positives: May indicate watermark word selection is too common or detection threshold is too low

- **First 3 experiments**:
  1. Run PostMark@12 on a small set of OpenGen examples and verify TPR before and after paraphrasing is within expected ranges
  2. Test PostMark with different insertion ratios (e.g., 6%, 12%, 20%) on the same examples to observe quality-robustness tradeoff
  3. Substitute LLAMA-3-70B-INST for GPT-4 O as INSERTER and measure impact on robustness and quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PostMark perform against other types of attacks beyond paraphrasing, such as copy-paste attacks or recursive paraphrasing?
- Basis in paper: [inferred] from "Our work focuses on evaluating robustness of various watermarking methods against paraphrasing attacks. However, there are many other interesting and practical attacks that we do not consider, such as the copy-paste attack and the recursive paraphrasing attack discussed in Section 5."
- Why unresolved: The paper explicitly states that it does not evaluate PostMark against these other types of attacks, leaving the question open for future research.
- What evidence would resolve it: Experiments testing PostMark's robustness against copy-paste attacks and recursive paraphrasing, comparing its performance to other watermarking methods under these attack scenarios.

### Open Question 2
- Question: What is the optimal insertion ratio (r) for PostMark that balances watermark robustness and text quality?
- Basis in paper: [explicit] from "How many words should we insert into a given text? We define a hyperparameter called the insertion ratio r that determines this number."
- Why unresolved: While the paper tests several values of r (6, 8, 12, 15, 20, and 30), it does not definitively determine the optimal value. The choice of r is presented as a trade-off between quality and robustness.
- What evidence would resolve it: A comprehensive study varying r across a wider range of values and measuring both watermark robustness (TPR at 1% FPR) and text quality (using automated metrics and human evaluations) to find the optimal balance point.

### Open Question 3
- Question: How does the choice of embedding model (EMBEDDER) affect PostMark's performance?
- Basis in paper: [explicit] from "The EMBEDDER needs to be capable of projecting both words and documents into a high-dimensional latent space. In our main experiments, we use OpenAI's TEXT-EMBEDDING-3-LARGE... However, any embedding model can be used here."
- Why unresolved: The paper only tests two embedding models (OpenAI's TEXT-EMBEDDING-3-LARGE and NOMIC-EMBED) and does not explore the impact of using different embedding models on PostMark's performance.
- What evidence would resolve it: Experiments testing PostMark with various embedding models (e.g., different sizes of OpenAI's embeddings, open-source alternatives like Sentence-BERT) and measuring the impact on watermark robustness, text quality, and runtime.

### Open Question 4
- Question: Can PostMark be made more efficient to reduce runtime and API costs?
- Basis in paper: [inferred] from "The POST MARK implementation used in all our main experiments relies on closed-source models from OpenAI... As a result, the runtime and costs of running POST MARK are heavily dependent on the API provider."
- Why unresolved: The paper acknowledges the high runtime and costs associated with the current implementation but does not explore optimization strategies.
- What evidence would resolve it: Development and testing of optimized implementations of PostMark, such as using smaller embedding models, more efficient watermark word selection algorithms, or open-source alternatives for the INSERTER model, while measuring the impact on performance, runtime, and costs.

## Limitations

- The evaluation framework has several notable limitations, including underspecified secret table construction details that make it difficult to assess potential biases or vulnerabilities.
- Robustness evaluation focuses primarily on a single paraphrasing attack model (GPT-3.5-TURBO), leaving uncertainty about performance against other attack strategies.
- The human evaluation sample size (20 texts) is relatively small for drawing strong conclusions about watermark detectability.

## Confidence

**High confidence**: PostMark achieves significantly higher robustness than baseline methods on aligned models after paraphrasing attacks, as demonstrated by consistent TPR improvements across multiple datasets and base models.

**Medium confidence**: PostMark maintains effectiveness on low-entropy models aligned with human preferences, though this claim relies more heavily on relative comparisons with logit-based methods rather than absolute performance benchmarks.

**Medium confidence**: The modular design provides meaningful flexibility for component substitution, though the evidence primarily demonstrates that PostMark works with different open-source components rather than systematically quantifying performance trade-offs.

## Next Checks

1. **Cross-attack robustness testing**: Evaluate PostMark's performance against diverse paraphrasing attacks including synonym replacement, grammatical restructuring, and meaning-preserving transformations using multiple attack models beyond GPT-3.5-TURBO.

2. **Secret table sensitivity analysis**: Systematically test how different SECTABLE construction parameters (vocabulary size, word frequency thresholds, embedding dimensions) affect watermark robustness, detectability, and false positive rates.

3. **Real-world deployment simulation**: Conduct a longitudinal study where PostMark-watermarked text undergoes multiple rounds of editing, paraphrasing, and redistribution to assess degradation patterns and identify potential failure cascades in practical scenarios.