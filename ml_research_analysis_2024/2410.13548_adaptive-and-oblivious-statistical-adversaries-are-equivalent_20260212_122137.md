---
ver: rpa2
title: Adaptive and oblivious statistical adversaries are equivalent
arxiv_id: '2410.13548'
source_url: https://arxiv.org/abs/2410.13548
tags:
- adversary
- adaptive
- distribution
- oblivious
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work resolves a fundamental open question about the relative
  power of statistical adversaries, proving that adaptive adversaries (which can view
  data before corrupting it) and oblivious adversaries (which must corrupt data before
  seeing it) are equivalent up to polynomial factors in sample size. The key insight
  is that adaptive adversaries can be simulated by oblivious adversaries through a
  simple subsampling technique.
---

# Adaptive and oblivious statistical adversaries are equivalent

## Quick Facts
- arXiv ID: 2410.13548
- Source URL: https://arxiv.org/abs/2410.13548
- Authors: Guy Blanc; Gregory Valiant
- Reference count: 40
- Primary result: Adaptive and oblivious statistical adversaries are equivalent up to polynomial factors in sample size

## Executive Summary
This work resolves a fundamental open question about the relative power of statistical adversaries by proving that adaptive adversaries (which can view data before corrupting it) and oblivious adversaries (which must corrupt data before seeing it) are equivalent up to polynomial factors in sample size. The key insight is that adaptive adversaries can be simulated by oblivious adversaries through a simple subsampling technique. Specifically, given any algorithm that succeeds against oblivious adversaries, running it on a uniformly random subsample of a larger dataset yields an algorithm that succeeds against adaptive adversaries. This equivalence holds across many common corruption models including strong contamination, agnostic noise, subtractive contamination, and additive contamination.

## Method Summary
The core method is a subsampling technique where algorithm A that works against oblivious adversaries is transformed into algorithm A' that works against adaptive adversaries by running A on a uniformly random subsample of a larger dataset. The sample size increase needed depends on the "degree" of the corruption cost function, a measure of how many corruptions the adversary can make per input point. The proof uses correlation rounding techniques from semidefinite programming combined with careful rounding steps to ensure the simulated oblivious adversary is valid. The construction maintains computational efficiency and the polynomial sample size increase is shown to be necessary and optimal.

## Key Results
- Adaptive and oblivious adversaries are equivalent up to polynomial factors in sample size for bounded-degree cost functions
- The subsampling technique provides a constructive transformation from algorithms against oblivious adversaries to algorithms against adaptive adversaries
- Polynomial sample size increases are necessary, and the dependence on cost function degree is optimal
- The equivalence holds for multiple corruption models including strong contamination, agnostic noise, subtractive contamination, and additive contamination

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Subsampling neutralizes the adaptivity advantage by simulating adaptive adversaries with oblivious ones through randomization
- **Mechanism**: When running algorithm A on a uniformly random subsample of a larger dataset, the adaptive adversary's ability to see the full sample before corrupting becomes irrelevant. The subsampling filter Φm→n creates a distribution over corrupted samples that matches what an oblivious adversary could produce, up to polynomial factors in sample size and polylogarithmic factors in domain size.
- **Core assumption**: The degree of the cost function (how many corruptions per input point) is bounded and relatively small compared to the total sample size.
- **Break condition**: If the cost function degree grows with the domain size or if the corruption budget allows the adversary to corrupt a polynomial fraction of the sample, the polynomial sample size increase may become impractical.

### Mechanism 2
- **Claim**: Adaptive and oblivious adversaries are equivalent up to polynomial factors because the adaptive adversary's knowledge advantage can be simulated through randomization
- **Mechanism**: The proof uses correlation rounding techniques from semidefinite programming combined with careful rounding to ensure the simulated oblivious adversary is valid. The key insight is that even though adaptive adversaries can create distributions far from any single oblivious adversary, they can be expressed as mixtures of oblivious adversaries.
- **Core assumption**: The correlation structure between points in the corrupted sample can be sufficiently "rounded" to approximate a product distribution (which characterizes oblivious adversaries).
- **Break condition**: If the cost function has very high degree (exponential in the domain size) or if the base distribution has high entropy, the correlation rounding technique may fail to produce a valid oblivious corruption within the required distance.

### Mechanism 3
- **Claim**: The equivalence is constructive and preserves computational efficiency
- **Mechanism**: The transformation from an algorithm A that works against oblivious adversaries to one A' that works against adaptive adversaries is simply running A on a random subsample of a larger dataset. This preserves the statistical and computational efficiency of A up to polynomial factors.
- **Core assumption**: The original algorithm A remains effective when run on a random subsample of its input, which is true for most statistical learning algorithms.
- **Break condition**: If the algorithm A is extremely sensitive to sample size or if the subsampling introduces too much variance, the computational efficiency preservation may not hold.

## Foundational Learning

- **Concept**: Statistical query (SQ) algorithms and their limitations
  - **Why needed here**: The paper references prior work showing that SQ algorithms can be upgraded to handle adaptive adversaries, but this approach has limitations compared to the general subsampling technique presented.
  - **Quick check question**: Why can't we always cast an arbitrary statistical learning algorithm into the SQ framework?

- **Concept**: Total variation distance and its properties
  - **Why needed here**: The proof relies heavily on total variation distance as a measure of statistical distance between distributions, using properties like the triangle inequality and convexity.
  - **Quick check question**: How does total variation distance relate to KL divergence through Pinsker's inequality?

- **Concept**: Correlation rounding and its application to adversary simulation
  - **Why needed here**: The proof uses correlation rounding techniques to show that the average group of corrupted samples is close to a product distribution, which is crucial for simulating adaptive adversaries with oblivious ones.
  - **Quick check question**: What is the relationship between multivariate total correlation and mutual information in the correlation rounding proof?

## Architecture Onboarding

- **Component map**: Sample generation -> Subsampling filter Φm→n -> Algorithm execution -> Success probability analysis
- **Critical path**: The subsampling filter is the most critical component as it enables the entire equivalence proof
- **Design tradeoffs**:
  - Polynomial vs exponential sample size increase: The algorithm requires polynomially more samples but this is optimal up to constants
  - Domain size dependence: The sample size increase depends on the degree of the cost function rather than the full domain size, making it practical for many applications
  - Computational overhead: The subsampling is computationally efficient and preserves the original algorithm's complexity
- **Failure signatures**:
  - If the cost function degree is too high (grows with domain size), the polynomial sample size increase may become impractical
  - If the base distribution has high entropy, the correlation rounding may not produce a valid oblivious corruption
  - If the original algorithm is extremely sensitive to sample size, subsampling may introduce too much variance
- **First 3 experiments**:
  1. Implement the subsampling filter Φm→n and verify it produces uniform random subsamples without replacement
  2. Test the equivalence for simple cost functions (e.g., ρ(x,y) = 1/η for x≠y) on synthetic data with known distributions
  3. Measure the actual sample size increase needed for different cost function degrees and compare against the theoretical bounds

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What is the tight polynomial dependence between the sample sizes for adaptive and oblivious adversaries across all corruption models?
- **Basis in paper**: The paper proves polynomial sample size increases are necessary (Theorem 4) and sufficient (Theorem 3), but the exact optimal dependence remains unclear.
- **Why unresolved**: While the paper establishes bounds (n^4(ln d)^2/ε^4), it doesn't prove this is optimal for all adversary models.
- **What evidence would resolve it**: A lower bound matching the upper bound's polynomial dependence, or a counterexample showing a tighter bound for specific adversary models.

### Open Question 2
- **Question**: How does the equivalence between adaptive and oblivious adversaries extend to partially-adaptive adversaries beyond malicious noise and non-iid adversaries?
- **Basis in paper**: Section 3.1 mentions other partially-adaptive adversaries but only proves equivalence for malicious noise and non-iid adversaries.
- **Why unresolved**: The paper only provides a framework for proving equivalence but doesn't apply it to other partially-adaptive models.
- **What evidence would resolve it**: Proofs showing equivalence for other partially-adaptive models like nasty classification noise or semi-adaptive contamination.

### Open Question 3
- **Question**: What is the computational complexity of the subsampling filter for continuous domains, and how does discretization affect the equivalence results?
- **Basis in paper**: Remark 2 discusses discretization for continuous domains but doesn't analyze computational complexity.
- **Why unresolved**: The paper assumes computational efficiency but doesn't quantify how discretization impacts runtime or precision requirements.
- **What evidence would resolve it**: Analysis of the computational overhead for discretization and its effect on the polynomial sample size bounds.

## Limitations
- The equivalence holds only up to polynomial factors in sample size, and these factors depend on the degree of the cost function
- For cost functions with high degree (growing with domain size), the required sample size increase may become impractical
- The proof relies heavily on correlation rounding techniques whose behavior in high-dimensional settings is not fully characterized

## Confidence
- **High confidence**: The core equivalence result between adaptive and oblivious adversaries for bounded-degree cost functions
- **Medium confidence**: The tightness of the polynomial sample size bounds and their dependence on cost function degree
- **Low confidence**: The practical implications for extremely high-dimensional domains or algorithms with unusual sample size sensitivity

## Next Checks
1. Implement the subsampling filter and test the equivalence theorem on synthetic data with varying cost function degrees to verify the polynomial sample size bounds empirically
2. Test whether common statistical learning algorithms (like mean estimation, linear regression) maintain their error rates when run on random subsamples of their input
3. Analyze the distribution of corrupted samples for different cost functions to verify that the correlation rounding techniques produce valid oblivious corruptions within the required total variation distance bounds