---
ver: rpa2
title: Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic Approximations
  with Markovian Noise
arxiv_id: '2409.19546'
source_url: https://arxiv.org/abs/2409.19546
tags:
- lemma
- have
- almost
- convergence
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proves almost sure convergence of tabular average reward
  temporal difference (TD) learning, a long-standing open problem in reinforcement
  learning. The key challenge was that standard ODE-based stability analysis fails
  due to the lack of a discount factor in average reward settings.
---

# Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic Approximations with Markovian Noise

## Quick Facts
- **arXiv ID:** 2409.19546
- **Source URL:** https://arxiv.org/abs/2409.19546
- **Reference count:** 40
- **Key outcome:** This paper proves almost sure convergence of tabular average reward temporal difference (TD) learning, resolving a 25-year-old open problem in reinforcement learning.

## Executive Summary
This paper establishes almost sure convergence for stochastic Krasnoselskii-Mann (SKM) iterations with Markovian and additive noise, a significant generalization of existing results that were limited to contractive operators or i.i.d. noise settings. The key innovation is a novel analysis framework that handles nonexpansive operators through fox-and-hare racing models and carefully decomposes Markovian noise using Poisson equations. As a major application, the authors resolve the long-standing open problem of proving almost sure convergence for tabular average reward TD learning, demonstrating that the iterates converge to a single fixed point despite the lack of a discount factor that typically enables standard ODE-based stability analysis.

## Method Summary
The authors develop a general stochastic approximation framework for nonexpansive operators with Markovian noise by extending recent advances in SKM iterations. They introduce a decomposition of the stochastic operator H(x,Y) - h(x) = ν(x,y) - (Pν)(x,y) via Poisson's equation, which separates the update into Martingale difference noise and bounded error terms. Under mild conditions including 1-Lipschitz continuity of the operator h and ergodicity of the underlying Markov chain, they prove almost sure convergence to a sample-path dependent fixed point. The analysis provides finite sample bounds on convergence rates by carefully controlling all noise components through specific learning rate schedules.

## Key Results
- Proves almost sure convergence of tabular average reward TD learning, resolving a 25-year-old open problem
- Establishes convergence guarantees for SKM iterations with Markovian noise under minimal assumptions
- Introduces novel techniques for bounding noise terms from Poisson equations that may be useful for analyzing other RL algorithms
- Provides both asymptotic and finite sample analysis with explicit convergence rate bounds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The nonexpansive operator h allows almost sure convergence to a single fixed point despite lack of contraction.
- Mechanism: By extending the fox-and-hare racing model from Cominetti et al. (2014) to Markovian noise settings, the analysis shows that iterates approach a sample-path dependent fixed point through controlled noise terms bounded by Lipschitz continuity.
- Core assumption: The operator h is 1-Lipschitz continuous in ∥·∥∞ (Assumption 4.2) and Markovian noise can be decomposed via Poisson's equation into Martingale and bounded error terms.
- Evidence anchors:
  - [abstract] "built on recent advances in stochastic Krasnoselskii-Mann iterations"
  - [section] "The operator h is a nonexpansive mapping w.r.t. ∥·∥∞ (Lemma 3)"
  - [corpus] Weak - no direct evidence about fox-and-hare extension to Markovian noise

### Mechanism 2
- Claim: Finite sample analysis succeeds by bounding all noise components separately with specific rates.
- Mechanism: The additive noise ǫ(1) has bounded L2 convergence rate O(1/n), Markovian noise from Poisson equation is controlled by Lipschitz continuity, and Martingale difference noise has finite variance through careful chaining of learning rates.
- Core assumption: Learning rates follow αn = 1/(n+1)^b with b ∈ (4/5, 1] ensuring summability conditions for noise bounds.
- Evidence anchors:
  - [abstract] "providing both asymptotic and finite sample analysis"
  - [section] "we impose a condition on the second moment of this noise, requiring it to converge at the rate O(1/n)"
  - [corpus] Weak - corpus lacks specific finite sample bounds for this setup

### Mechanism 3
- Claim: The decomposition H(x,Y) - h(x) = ν(x,y) - (Pν)(x,y) enables treating Markovian noise within SKM framework.
- Mechanism: Poisson's equation provides a representation where the difference between stochastic and expected updates becomes a Martingale plus bounded error terms, allowing application of stochastic approximation convergence theorems.
- Core assumption: Finite state space ensures existence of Poisson equation solution and Markov chain ergodicity guarantees bounded fundamental matrix.
- Evidence anchors:
  - [abstract] "Key to our analysis are novel bounds of noise terms resulting from the Poisson equation"
  - [section] "it is well known (see, e.g., Theorem 17.4.2 of Meyn & Tweedie) that there exists a function ν(x,y)"
  - [corpus] Weak - corpus lacks evidence about Poisson equation bounds in this context

## Foundational Learning

- Concept: Stochastic approximation with nonexpansive operators
  - Why needed here: Standard ODE-based methods fail because h is nonexpansive (not contractive) in average reward TD
  - Quick check question: Why can't we use standard ODE stability analysis for average reward TD?

- Concept: Markovian noise decomposition via Poisson equation
  - Why needed here: The stochastic updates depend on Markovian samples, requiring decomposition into Martingale and bounded error terms
  - Quick check question: What role does the finite state space assumption play in enabling Poisson equation decomposition?

- Concept: Fox-and-hare racing model for SKM iterations
  - Why needed here: Provides convergence framework for nonexpansive operators that standard Lyapunov methods cannot handle
  - Quick check question: How does the fox-and-hare model differ from traditional Lyapunov stability analysis?

## Architecture Onboarding

- Component map:
  Learning rate scheduler (αn = 1/(n+1)^b) -> Markovian noise generator (finite MDP transitions) -> Value function updater (vt+1 = vt + αt+1(H(vt,Yt+1) - vt + ǫt+1)) -> Noise decomposition module (Poisson equation solver) -> Convergence monitor (τn accumulation and bounds)

- Critical path:
  1. Initialize vt, Jt, learning rates
  2. Sample next state-action pair (Yt+1)
  3. Compute H(vt,Yt+1) and ǫt+1
  4. Update vt using SKM iteration
  5. Monitor noise bounds and convergence

- Design tradeoffs:
  - Choice of b ∈ (4/5, 1] balances noise control vs. convergence speed
  - Finite vs. infinite state space affects Poisson equation solvability
  - Synchronous vs. asynchronous updates impact applicability of SKM methods

- Failure signatures:
  - If ∥vt+1 - vt∥ doesn't decrease: learning rate too large or noise too high
  - If iterates diverge: Lipschitz constant > 1 or Markov chain non-ergodic
  - If convergence stalls: Insufficient exploration or poor choice of b

- First 3 experiments:
  1. Verify Lipschitz continuity of H on small MDP with known fixed point
  2. Test Poisson equation decomposition on sample trajectories
  3. Validate learning rate decay schedule with simulated Markov chain

## Open Questions the Paper Calls Out

- Question: Can SKM iterations be extended to L_p spaces beyond almost sure convergence?
- Basis in paper: [inferred] from the conclusion stating "Do SKM iterations converge in Lp?"
- Why unresolved: The paper only establishes almost sure convergence for SKM with Markovian noise, leaving convergence in other probability spaces unexplored.
- What evidence would resolve it: Prove convergence rates in L_p for p≠1,2 and demonstrate bounds on moments of the iterates.

- Question: Do SKM iterations satisfy a central limit theorem or law of the iterated logarithm?
- Basis in paper: [inferred] from the conclusion asking "Do they follow a central limit theorem or a law of the iterated logarithm?"
- Why unresolved: The paper focuses on almost sure convergence without analyzing the asymptotic distribution or fluctuation properties of the iterates.
- What evidence would resolve it: Establish a central limit theorem for SKM iterates or prove a functional law of the iterated logarithm.

- Question: Can SKM iterations be extended to two-timescale settings?
- Basis in paper: [inferred] from the conclusion asking "Can they be extended to two-timescale settings?"
- Why unresolved: The paper analyzes single-timescale SKM with Markovian noise but doesn't explore scenarios where different components evolve at different speeds.
- What evidence would resolve it: Develop a framework for two-timescale SKM and prove convergence when components have different learning rates.

## Limitations

- The analysis critically depends on the Lipschitz continuity of the operator H, which may not hold for more complex function approximations beyond tabular settings
- The finite state space assumption enabling Poisson equation decomposition is essential but limits applicability to infinite-horizon problems
- The learning rate schedule b ∈ (4/5, 1] is restrictive and may not be optimal for practical implementations

## Confidence

- **High Confidence**: Almost sure convergence to sample-path dependent fixed point (supported by rigorous SKM framework extension)
- **Medium Confidence**: Finite sample bounds on convergence rates (theoretical bounds exist but empirical validation is limited)
- **Medium Confidence**: Poisson equation noise decomposition (existence guaranteed but practical implementation challenges)

## Next Checks

1. **Empirical Validation**: Implement the algorithm on benchmark MDPs with known fixed points to verify convergence behavior matches theoretical predictions, particularly focusing on learning rate sensitivity.

2. **Robustness Testing**: Test the algorithm under violations of key assumptions (e.g., near-Lipschitz operators, near-Markovian noise) to understand practical failure modes and identify breaking points.

3. **Scalability Assessment**: Extend numerical experiments to larger state spaces to evaluate whether the theoretical guarantees translate to practical performance gains over existing TD methods in average reward settings.