---
ver: rpa2
title: Space Decomposition for Sentence Embedding
arxiv_id: '2406.03125'
source_url: https://arxiv.org/abs/2406.03125
tags:
- sentence
- mixsp
- lower-range
- upper-range
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes MixSP, a novel embedding space decomposition
  method that treats upper-range and lower-range sentence similarity samples separately
  using a routing network and specialized projectors. The method achieves state-of-the-art
  results on STS benchmarks (average Spearman correlation 85.39) and zero-shot tasks,
  significantly reducing overlap between upper-range and lower-range classes while
  improving ranking performance within each class.
---

# Space Decomposition for Sentence Embedding

## Quick Facts
- arXiv ID: 2406.03125
- Source URL: https://arxiv.org/abs/2406.03125
- Reference count: 23
- Primary result: MixSP achieves state-of-the-art STS benchmarks (85.39 average Spearman correlation) by separately processing upper-range and lower-range similarity samples

## Executive Summary
This paper introduces MixSP, a novel sentence embedding method that addresses a fundamental limitation in existing embedding spaces: the mixing of semantically distant and similar sentence pairs. The method decomposes the embedding space into upper-range (dissimilar sentences) and lower-range (similar sentences) components using a routing network and specialized projectors. MixSP achieves state-of-the-art performance on semantic textual similarity benchmarks while demonstrating strong zero-shot task capabilities, representing a significant advance in sentence embedding methodology.

## Method Summary
MixSP employs a routing network to classify sentence pairs into upper-range (dissimilar) and lower-range (similar) categories based on their similarity scores. Each category is processed by specialized projectors that optimize the embedding space for their respective similarity ranges. The routing network uses learned decision boundaries to separate sentence pairs, while the projectors employ contrastive learning objectives tailored to either preserving distances in upper-range pairs or maximizing similarity in lower-range pairs. This decomposition approach allows MixSP to simultaneously optimize for both fine-grained similarity distinctions and clear separation between dissimilar sentences, addressing the inherent trade-off in traditional single-space embedding methods.

## Key Results
- Achieves state-of-the-art performance on STS benchmarks with 85.39 average Spearman correlation
- Demonstrates 3-5% absolute improvement over previous best methods on several STS tasks
- Shows significant reduction in overlap between upper-range and lower-range classes while maintaining strong intra-class ranking performance

## Why This Works (Mechanism)
MixSP works by recognizing that sentence embeddings face competing optimization objectives: dissimilar sentences need to be far apart in embedding space while similar sentences need to be close together. Traditional methods use a single embedding space attempting to satisfy both requirements simultaneously, leading to suboptimal performance at both ends. By decomposing the space and using specialized projectors for each similarity range, MixSP can optimize each projector for its specific objective without compromise. The routing network ensures that each sentence pair is processed by the most appropriate projector based on its true similarity, allowing for more precise control over embedding geometry.

## Foundational Learning
- **Embedding space decomposition**: Why needed - to separate competing optimization objectives; Quick check - visualize distance distributions before/after decomposition
- **Routing networks**: Why needed - to dynamically assign samples to specialized processors; Quick check - examine routing accuracy on validation data
- **Specialized projectors**: Why needed - to optimize different similarity ranges independently; Quick check - compare similarity distributions from each projector
- **Contrastive learning objectives**: Why needed - to preserve relationships within each similarity range; Quick check - measure intra-class and inter-class distances
- **Similarity score calibration**: Why needed - to ensure consistent similarity interpretations across decomposed spaces; Quick check - correlate predicted and true similarity scores
- **Spearman correlation metric**: Why needed - to evaluate ranking quality rather than absolute distance; Quick check - compute correlation across different similarity thresholds

## Architecture Onboarding

Component map: Input sentence pairs -> Routing network -> Upper-range projector / Lower-range projector -> Merged embeddings -> Similarity calculation

Critical path: Routing network classification → Specialized projector processing → Embedding space merging

Design tradeoffs:
- Routing network complexity vs. classification accuracy
- Number of specialized projectors vs. model capacity
- Similarity range boundaries vs. optimization granularity
- Training stability vs. decomposition effectiveness

Failure signatures:
- Poor routing accuracy leading to misclassified sentence pairs
- Overlapping embeddings between upper-range and lower-range classes
- Inconsistent similarity scaling across decomposed spaces
- Degradation in zero-shot task performance despite STS benchmark gains

First experiments:
1. Train routing network alone and evaluate classification accuracy on STS validation sets
2. Test specialized projectors independently with fixed routing assignments
3. Evaluate merged embedding quality with synthetic similarity pairs before full integration

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Potential overfitting to STS benchmark datasets, with uncertain generalization to other domains
- Routing network sensitivity to dataset characteristics and decision boundary stability
- Increased architectural complexity may impact scalability and real-time deployment feasibility
- Limited ablation studies on routing mechanism sensitivity to different threshold configurations

## Confidence

High confidence in:
- STS benchmark quantitative results showing consistent improvements

Medium confidence in:
- Zero-shot task performance claims (mentioned but not extensively validated)

Lower confidence in:
- Generalization to domains outside STS benchmarks
- Robustness of routing network decision boundaries across different datasets

## Next Checks
1. Test MixSP's generalization performance on semantic similarity tasks from different domains (biomedical, legal, technical) not represented in STS benchmarks
2. Conduct ablation studies specifically on the routing network's decision boundary to quantify sensitivity to different threshold configurations
3. Evaluate computational overhead and scalability of the routing mechanism and specialized projectors in large-scale production environments with millions of sentence pairs