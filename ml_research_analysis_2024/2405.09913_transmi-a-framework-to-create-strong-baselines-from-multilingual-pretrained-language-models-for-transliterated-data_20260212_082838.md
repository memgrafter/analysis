---
ver: rpa2
title: 'TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained
  Language Models for Transliterated Data'
arxiv_id: '2405.09913'
source_url: https://arxiv.org/abs/2405.09913
tags:
- glot500
- latn5
- transliterated
- max-merge
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of adapting multilingual pretrained
  language models (mPLMs) to handle transliterated data without expensive retraining.
  The authors propose a simple three-stage framework called TransMI (Transliterate-Merge-Initialize)
  that modifies an existing mPLM's vocabulary and embeddings to support Latin-script
  transliterated text.
---

# TransMI: A Framework to Create Strong Baselines from Multilingual Pretrained Language Models for Transliterated Data

## Quick Facts
- arXiv ID: 2405.09913
- Source URL: https://arxiv.org/abs/2405.09913
- Reference count: 38
- This paper proposes TransMI, a three-stage framework that adapts multilingual pretrained language models to handle transliterated data without retraining, achieving 3% to 34% improvements on transliterated evaluation data while maintaining performance on original scripts.

## Executive Summary
This paper addresses the challenge of adapting multilingual pretrained language models (mPLMs) to handle transliterated data without expensive retraining. The authors propose TransMI (Transliterate-Merge-Initialize), a simple three-stage framework that modifies an existing mPLM's vocabulary and embeddings to support Latin-script transliterated text. The method first transliterates the original vocabulary, then merges new transliterated subwords using different strategies, and finally initializes embeddings for the new subwords. Experiments on three strong mPLMs (XLM-R, Glot500, FURINA) across multiple tasks show consistent improvements on transliterated data while maintaining performance on original scripts.

## Method Summary
TransMI is a three-stage framework that adapts multilingual pretrained language models to handle transliterated data without retraining. First, it transliterates the original vocabulary subwords from non-Latin scripts to Latin script using Uroman. Second, it merges the new transliterated subwords with the original vocabulary using one of three strategies: Min-Merge (preserves low-frequency meanings), Average-Merge (balances between meanings), or Max-Merge (preserves high-frequency meanings). Third, it initializes embeddings for the new subwords by copying or averaging from the original model's embeddings based on the merge strategy. The framework is evaluated zero-shot on sentence retrieval, text classification, and sequence labeling tasks, showing improvements of 3% to 34% on transliterated data while maintaining performance on non-transliterated data.

## Key Results
- 3% to 34% improvements on transliterated evaluation data across multiple mPLMs and tasks
- Consistent performance maintenance on non-transliterated data
- Max-Merge strategy performs best overall, while Min-Merge better supports tail languages
- Improvements are particularly pronounced for phonetic scripts like Cyrillic and Devanagari
- FURINA shows smallest improvements due to being fine-tuned on transliterated data

## Why This Works (Mechanism)

### Mechanism 1
Transliteration creates Latin-script subwords that overlap lexically across scripts, enabling better crosslingual transfer without retraining. By converting non-Latin subwords into Latin transliterations, the method increases shared vocabulary between languages that use different scripts. The modified tokenizer then generates subwords that correspond to natural linguistic units rather than arbitrary character sequences. Core assumption: Transliteration is deterministic and reversible enough that semantic meaning is preserved sufficiently for transfer tasks.

### Mechanism 2
The merge strategies (Min-Merge, Average-Merge, Max-Merge) allow control over which subword meanings dominate when transliteration creates ambiguity. When multiple original subwords map to the same Latin transliteration, the merge strategy determines which original subword's embedding and tokenization behavior is preserved. Max-Merge preserves high-frequency meanings, Min-Merge preserves low-frequency meanings, and Average-Merge balances between them. Core assumption: Log probabilities from the original tokenizer accurately reflect the importance of each subword for its script.

### Mechanism 3
Initializing new subword embeddings by copying or averaging from original embeddings preserves semantic knowledge without requiring training. New subwords created through transliteration are initialized using the embeddings of their source subwords. For unambiguous transliterations, direct copying is used. For ambiguous cases, the merge strategy determines whether to copy the highest/lowest scoring embedding or use an average. Core assumption: The original embeddings contain sufficient semantic information that can be transferred through transliteration.

## Foundational Learning

- Concept: Tokenization and subword vocabularies
  - Why needed here: Understanding how subword vocabularies are built and manipulated is essential for modifying the tokenizer without breaking functionality.
  - Quick check question: How does SentencePiece Unigram tokenization differ from BPE, and why is this relevant for TransMI?

- Concept: Transliteration systems and their limitations
  - Why needed here: The method depends on reliable transliteration from non-Latin to Latin scripts, which can introduce ambiguity.
  - Quick check question: What are the main sources of ambiguity in transliteration, and how does TransMI attempt to handle them?

- Concept: Embedding initialization and transfer learning
  - Why needed here: The method initializes new embeddings without training, relying on the assumption that original embeddings contain transferable semantic knowledge.
  - Quick check question: Under what conditions would copying embeddings from source subwords be insufficient for the transliterated versions?

## Architecture Onboarding

- Component map:
  Original mPLM tokenizer and vocabulary -> Transliteration tool (Uroman) -> Merge strategy module (Min-Merge, Average-Merge, Max-Merge) -> Embedding initialization module -> Modified tokenizer and embedding matrix

- Critical path:
  1. Transliterate original vocabulary subwords to Latin script
  2. Merge transliterated subwords with original vocabulary using chosen strategy
  3. Initialize embeddings for new subwords
  4. Validate tokenization behavior on transliterated and original data

- Design tradeoffs:
  - Memory vs. performance: Adding more transliterated subwords improves coverage but increases model size
  - Ambiguity resolution: Different merge strategies favor different language groups (head vs. tail languages)
  - Training vs. initialization: Using copied embeddings avoids training but may limit performance compared to fine-tuning

- Failure signatures:
  - Tokenizer produces nonsensical strings for transliterated text
  - Performance degrades significantly on original (non-transliterated) data
  - Ambiguous transliterations cause incorrect tokenization
  - Embeddings initialized from wrong source subwords

- First 3 experiments:
  1. Apply TransMI with Max-Merge to XLM-R and test on transliterated evaluation data vs original model
  2. Compare performance of all three merge strategies on a single language pair to identify which works best
  3. Measure sequence length changes before and after transliteration to verify tokenizer behavior is preserved

## Open Questions the Paper Calls Out

### Open Question 1
How would TRANS MI perform with language-specific transliteration tools rather than the universal Uroman tool, particularly for languages like Chinese where Uroman removes tones? The authors acknowledge that Uroman is not optimal for every language, specifically noting that Chinese tones are removed, introducing substantial ambiguity and negatively influencing performance. They state that better language-specific transliteration tools could improve results when focusing on smaller groups of related languages.

### Open Question 2
How does TRANS MI's performance compare to continued pretraining or fine-tuning approaches when adapting mPLMs to transliterated data, particularly in terms of computational efficiency and final accuracy? The authors position TRANS MI as creating strong baselines without training, contrasting it with methods that require training or parameter updates. They mention that FURINA, which was fine-tuned on transliterated data, shows smaller improvements with TRANS MI, suggesting that training approaches can achieve better results.

### Open Question 3
How would TRANS MI perform with tokenizers other than SentencePiece Unigram, such as WordPiece (used in mBERT) or BPE-based tokenizers? The authors note they only tested with SentencePiece Unigram tokenizers because recent strong mPLMs favor this choice, but state that extending TRANS MI to other tokenizer types should be straightforward by adapting the merge operation.

### Open Question 4
What is the impact of different merge modes (Min-Merge, Average-Merge, Max-Merge) on long-range dependency tasks versus token-level tasks when processing transliterated data? While the paper reports overall performance differences between merge modes, it does not investigate how these differences manifest across different task types or what this implies for model behavior.

## Limitations

- Limited evaluation of transliteration quality: The method heavily depends on Uroman's transliteration quality, but the paper doesn't systematically evaluate how transliteration errors affect downstream performance.

- Merge strategy trade-offs not fully characterized: While the paper identifies that Max-Merge favors head languages and Min-Merge favors tail languages, it doesn't provide clear guidelines for selecting the optimal strategy based on target language families or data characteristics.

- Potential overfitting to evaluation tasks: The evaluation focuses on sentence retrieval, text classification, and sequence labeling, but doesn't explore more complex tasks like machine translation or summarization where transliteration ambiguities might have more severe consequences.

## Confidence

- High confidence: The claim that TransMI improves performance on transliterated data (3%-34% gains) is well-supported by the experimental results across multiple mPLMs and tasks.

- Medium confidence: The claim that performance is maintained on non-transliterated data is supported but could be strengthened with more extensive analysis of where and why any degradation occurs.

- Low confidence: The claim that TransMI creates "strong baselines" for transliterated data is somewhat vague and depends on comparison with potentially weaker baselines.

## Next Checks

1. Systematic transliteration ambiguity analysis: Quantify the distribution of 1-to-1, 1-to-many, and many-to-1 transliteration mappings across the vocabulary and correlate these with performance changes.

2. Cross-script transfer effectiveness: Design experiments that specifically test whether transliterated subwords actually improve crosslingual transfer between languages using different scripts (e.g., Hindi-to-English vs. Hindi-to-Russian).

3. Long-range sequence behavior: Evaluate model performance on tasks requiring long-range dependencies (like document classification or multi-sentence reasoning) to verify that transliteration-based tokenization doesn't break the model's ability to capture long-distance relationships.