---
ver: rpa2
title: Causal inference through multi-stage learning and doubly robust deep neural
  networks
arxiv_id: '2407.08560'
source_url: https://arxiv.org/abs/2407.08560
tags:
- where
- learning
- estimation
- function
- dnns
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of deep neural networks (DNNs)
  for causal inference in high-dimensional settings. It addresses the challenge of
  estimating causal effects when direct estimation is impossible due to missing potential
  outcomes, requiring multi-stage learning procedures.
---

# Causal inference through multi-stage learning and doubly robust deep neural networks

## Quick Facts
- arXiv ID: 2407.08560
- Source URL: https://arxiv.org/abs/2407.08560
- Reference count: 40
- One-line primary result: This paper establishes theoretical guarantees for deep neural networks in multi-stage causal inference problems with growing dimensionality

## Executive Summary
This paper develops a framework for causal inference using deep neural networks in high-dimensional settings where traditional methods struggle. The authors address the challenge of estimating causal effects like conditional average treatment effect (CATE) and dynamic treatment effects (DTE) when potential outcomes are missing. Their approach uses DNNs in a doubly robust manner across sequential stages, with each stage building upon the previous ones to estimate complex causal parameters. The framework provides theoretical guarantees for consistency and asymptotic normality even when the dimension of covariates grows with sample size.

## Method Summary
The method employs a two-stage learning procedure for CATE estimation and a three-stage procedure for DTE estimation. In the first stage, nuisance functions (propensity scores and outcome regressions) are estimated using flexible machine learning methods. The second stage constructs doubly robust representations of the causal parameters using these first-stage estimates. A nested DNN is then trained to estimate the final causal effect. The framework uses cross-fitting to reduce bias from nuisance estimation, splitting data into folds and estimating nuisances on one fold while predicting on another. This sequential estimation approach is shown to be effective for high-dimensional causal inference problems where the dimensionality p expands with the sample size.

## Key Results
- Establishes theoretical guarantees for DNNs in multi-stage causal inference with growing dimensionality
- Achieves near-optimal convergence rates (n^(-2β/(2β+q))) for approximating sparse smooth functions
- Provides consistency and asymptotic normality results for CATE and DTE estimators under mild assumptions
- Demonstrates that DNNs can outperform traditional non-parametric methods in high-dimensional settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Doubly robust score functions satisfy generalized Neyman orthogonality, which makes first-order estimation errors have zero conditional mean, so only second-order errors affect convergence rate.
- Mechanism: The score function is constructed such that its Gateaux derivative with respect to nuisance parameters is zero, causing the linear term in the error decomposition to vanish in expectation.
- Core assumption: The score function satisfies condition (1.3) and nuisance estimates are consistent enough that the remainder term is small.
- Evidence anchors:
  - [abstract]: "To mitigate the impact of estimation errors from early stages on subsequent ones, we integrate DNNs in a doubly robust manner."
  - [section]: "When the condition (1.3) is fulfilled, ∆1 exhibits a conditional mean of zero and can be regarded as additional noise in the second learning stage."
  - [corpus]: Weak evidence - no corpus neighbors directly discuss generalized Neyman orthogonality.
- Break condition: If the score function does not satisfy the generalized Neyman orthogonality condition, or if nuisance estimates are inconsistent, the first-order error term no longer vanishes, slowing convergence.

### Mechanism 2
- Claim: Sparse smooth functions can be approximated efficiently by deep neural networks even when covariate dimension grows with sample size.
- Mechanism: Deep neural networks with ReLU activation can approximate sparse smooth functions with error decreasing as n^(-2β/(2β+q)), where β is smoothness and q is sparsity, without requiring low-dimensional structure on the marginal distribution.
- Core assumption: The true conditional mean function can be approximated by a sparse smooth function and the network architecture is chosen appropriately.
- Evidence anchors:
  - [abstract]: "Our study offers theoretical assurances regarding the effectiveness of DNNs in settings where the dimensionality p expands with the sample size."
  - [section]: "Unlike Schmidt-Hieber [2020a], we do not require additional constraints to bound the weights of the DNNs, simplifying the optimization procedure."
  - [corpus]: Weak evidence - corpus contains related doubly robust methods but not sparse DNN approximation theory.
- Break condition: If the true function is not approximately sparse or smooth, or if network architecture is poorly chosen, approximation error will dominate and convergence will be slow.

### Mechanism 3
- Claim: Cross-fitting and sample splitting reduce bias from nuisance estimation in multi-stage learning.
- Mechanism: By splitting data into folds and estimating nuisance functions on one fold while predicting on another, we avoid overfitting and reduce the correlation between nuisance estimates and predictions.
- Core assumption: Sample splitting is implemented correctly and folds are independent.
- Evidence anchors:
  - [section]: "Given that the function θ(x) resides in a significantly more complex space, estimating such a function presents greater challenges than estimating a one-dimensional parameter... Rather than simply taking the empirical average over the estimated score functions ψ(Zi;bη), specific regression methods are required to estimate the conditional mean function, utilizing the first-stage estimates bη."
  - [section]: "In this work, our particular focus is on employing state-of-the-art DNNs, known for their exceptional empirical performance."
  - [corpus]: Weak evidence - corpus neighbors discuss doubly robust methods but not cross-fitting specifically.
- Break condition: If sample splitting is not implemented properly or folds are too small, bias from nuisance estimation may persist and affect convergence.

## Foundational Learning

- Concept: Potential outcomes framework and missing data problem
  - Why needed here: The paper addresses causal inference where we cannot observe all potential outcomes for each unit, requiring multi-stage estimation.
  - Quick check question: What is the fundamental difference between causal inference and standard prediction problems?

- Concept: Doubly robust estimation and generalized Neyman orthogonality
  - Why needed here: These concepts allow the method to remain consistent even when one of the nuisance models is misspecified.
  - Quick check question: Why does the generalized Neyman orthogonality condition make the first-order error term have zero conditional mean?

- Concept: Deep neural network approximation theory for sparse smooth functions
  - Why needed here: Understanding how DNNs can approximate high-dimensional functions with sparse structure is crucial for the theoretical guarantees.
  - Quick check question: What is the convergence rate for approximating a sparse smooth function with a deep neural network?

## Architecture Onboarding

- Component map:
  Data preprocessing and splitting module -> First-stage nuisance estimation -> Doubly robust outcome construction module -> Second-stage (and third-stage) DNN regression module -> Cross-fitting coordination module -> Theoretical analysis and convergence checking module

- Critical path: Data → Split → First-stage estimation → Doubly robust outcome construction → Second-stage DNN → Final estimate
- Design tradeoffs:
  - Network depth vs width vs approximation error
  - Sample splitting ratio vs estimation variance
  - Regularization vs bias-variance tradeoff
  - Computational cost vs theoretical guarantees

- Failure signatures:
  - Slow convergence or divergence: likely issues with network architecture or optimization
  - High variance in estimates: may indicate insufficient sample splitting or overfitting
  - Bias in estimates: could be due to misspecified score functions or poor nuisance estimation

- First 3 experiments:
  1. Verify doubly robust property: Implement with known nuisance functions and check that estimator remains consistent when one nuisance is misspecified
  2. Test approximation capability: Generate data from sparse smooth functions and measure DNN approximation error as dimension grows
  3. Validate cross-fitting: Compare performance with and without cross-fitting on a simple causal inference problem

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the theoretical guarantees for DNNs in multi-stage causal inference scale when the number of stages increases beyond three?
- Basis in paper: [explicit] The paper mentions that the framework can be extended to more general situations with more than three learning stages, but additional proofs would be required.
- Why unresolved: The authors only present results for two- and three-stage learning problems, leaving the scalability of the approach for more stages unexplored.
- What evidence would resolve it: Theoretical analysis and empirical validation of DNN performance in causal inference problems requiring four or more stages.

### Open Question 2
- Question: What is the impact of model misspecification on the performance of DNNs in multi-stage causal inference?
- Basis in paper: [inferred] The paper focuses on smoothness and sparsity conditions but does not explicitly address model misspecification, which is a common issue in causal inference.
- Why unresolved: The theoretical framework assumes certain conditions on the underlying functions but does not explore how violations of these assumptions affect the DNN estimates.
- What evidence would resolve it: Simulation studies or real-world applications where the true data generating process deviates from the assumed models, examining the robustness of DNN estimates.

### Open Question 3
- Question: How do the proposed DNN methods compare to other non-parametric approaches in high-dimensional causal inference settings?
- Basis in paper: [inferred] The paper emphasizes the advantages of DNNs over traditional non-parametric methods in high dimensions but does not provide a direct comparison with other modern approaches like random forests or boosting.
- Why unresolved: The authors focus on establishing theoretical guarantees for DNNs but do not benchmark their performance against other state-of-the-art methods.
- What evidence would resolve it: Empirical studies comparing the proposed DNN methods to other non-parametric approaches on various causal inference tasks in high-dimensional settings.

## Limitations

- The theoretical analysis assumes the product rate condition δN = o(1) for nuisance function estimation, but practical implementation details for achieving this condition are not fully specified.
- The method relies on sparse smooth function assumptions for the true causal parameters, which may not hold for all causal inference problems.
- The paper does not provide comprehensive guidance on hyperparameter tuning and regularization choices that would ensure theoretical requirements are met in finite samples.

## Confidence

**High Confidence**: The doubly robust framework and generalized Neyman orthogonality mechanism for reducing first-order estimation errors. This is well-established theory with strong theoretical foundations.

**Medium Confidence**: The DNN approximation results for sparse smooth functions in high dimensions. While the theoretical framework is sound, the practical implications depend heavily on proper network architecture selection and may be sensitive to the choice of hyperparameters.

**Low Confidence**: The finite-sample performance of the method without careful hyperparameter tuning. The paper provides theoretical guarantees but doesn't offer comprehensive guidance on practical implementation details that would be needed for consistent performance across different datasets and problem settings.

## Next Checks

1. **Sensitivity Analysis to Sparsity and Smoothness Assumptions**: Implement the CATE estimation algorithm on simulated data where the true function deviates from the assumed sparse smooth structure. Measure how estimation accuracy degrades as the true function becomes less sparse or smooth, and determine practical thresholds for when the method remains reliable.

2. **Cross-fitting Implementation Validation**: Conduct controlled experiments comparing the proposed method with and without proper cross-fitting implementation. Use a simple causal inference problem where the ground truth is known, and verify that cross-fitting reduces bias in the final estimates compared to naive implementation without sample splitting.

3. **Hyperparameter Robustness Study**: Systematically vary the network architecture parameters (depth L, width H) and nuisance function estimation methods across a range of realistic settings. Quantify how sensitive the final causal effect estimates are to these choices, and identify which parameters have the most significant impact on performance.