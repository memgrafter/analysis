---
ver: rpa2
title: 'DeSplat: Decomposed Gaussian Splatting for Distractor-Free Rendering'
arxiv_id: '2411.19756'
source_url: https://arxiv.org/abs/2411.19756
tags:
- desplat
- splatfacto
- spotlesssplats
- ours
- ground
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DeSplat introduces a decomposed Gaussian splatting approach that
  explicitly separates static scene elements from distractors in 3D reconstruction.
  The method initializes per-view distractor Gaussians alongside global static Gaussians,
  optimizing them jointly through volume rendering while maintaining fast rendering
  speeds comparable to vanilla 3DGS.
---

# DeSplat: Decomposed Gaussian Splatting for Distractor-Free Rendering

## Quick Facts
- arXiv ID: 2411.19756
- Source URL: https://arxiv.org/abs/2411.19756
- Reference count: 40
- DeSplat achieves state-of-the-art performance on RobustNeRF benchmark with up to 1.45 dB PSNR improvement

## Executive Summary
DeSplat introduces a decomposed Gaussian splatting approach that explicitly separates static scene elements from distractors in 3D reconstruction. The method initializes per-view distractor Gaussians alongside global static Gaussians, optimizing them jointly through volume rendering while maintaining fast rendering speeds comparable to vanilla 3DGS. By decomposing the alpha-compositing stage, DeSplat enables explicit scene separation without requiring external semantic models or pre-trained networks. Experiments on RobustNeRF, On-the-go, and Photo Tourism datasets show DeSplat achieves state-of-the-art or competitive performance, with PSNR improvements up to 1.45 dB over baselines on scenes like Yoda and Crab, while producing cleaner background reconstructions and effective distractor removal in real-world scenarios.

## Method Summary
DeSplat extends 3D Gaussian Splatting by introducing per-view distractor Gaussians that are initialized near the camera plane for each image. The method jointly optimizes static and distractor Gaussians through a modified volume rendering pipeline that decomposes the alpha-compositing stage. Static Gaussians are initialized from a globally consistent point cloud obtained via COLMAP, while distractor Gaussians are initialized per view to handle scene-specific transient elements. The optimization includes regularization terms on alpha-blending weights to prevent distractor Gaussians from explaining static objects and vice versa. Adaptive Density Control is applied to distractor Gaussians to handle varying numbers and sizes of transient elements across views.

## Key Results
- Achieves state-of-the-art PSNR of 30.18 dB on RobustNeRF Yoda scene, improving by 1.45 dB over baselines
- Maintains rendering speeds comparable to vanilla 3DGS while adding distractor separation capability
- Effectively removes transient elements from static reconstructions in real-world datasets like On-the-go and Photo Tourism

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DeSplat's decomposition into static and per-view distractor Gaussians enables explicit scene separation without semantic priors.
- Mechanism: By initializing per-view distractor Gaussians near the camera plane and jointly optimizing them with static Gaussians, DeSplat can isolate transient elements using only photometric consistency. The alpha-compositing stage allows independent rendering of static and distractor components.
- Core assumption: Distractors are primarily view-dependent effects that do not require global consistency across views.
- Evidence anchors:
  - [abstract] "We propose a novel method, DeSplat, that directly separates distractors and static scene elements purely based on volume rendering of Gaussian primitives."
  - [section 3.1] "We initialize Gaussians within each camera view for reconstructing the view-specific distractors to separately model the static 3D scene and distractors in the alpha compositing stages."
- Break condition: If distractors persist across many views or exhibit minimal motion between frames, DeSplat may incorrectly classify them as static elements due to their apparent consistency.

### Mechanism 2
- Claim: Regularization terms on alpha-blending weights prevent static Gaussians from explaining distractor regions.
- Mechanism: The loss function includes terms λs|1 − αs| and λd|αd| that discourage distractor Gaussians from reconstructing static objects and encourage static Gaussian accumulation to approach unity, reducing holes in the background.
- Core assumption: Explicit regularization on blending weights can guide the model toward cleaner separation without requiring semantic segmentation.
- Evidence anchors:
  - [section 3.1] "The final loss function is defined as Ltot = LGS + λs|1 − αs| + λd|αd|"
  - [section 4.2] "These terms discourage from using distractor Gaussians to reconstruct static objects and encourage the accumulation of static Gaussians being equal to one"
- Break condition: If the regularization weights are set too high, the model may under-reconstruct parts of the scene; if too low, distractors may leak into the static component.

### Mechanism 3
- Claim: Per-view densification of distractor Gaussians handles varying numbers and sizes of transient elements across views.
- Mechanism: Adaptive Density Control (ADC) is applied to distractor Gaussians after each view has been trained S times, allowing the model to adjust the number of distractor Gaussians based on the specific needs of each view.
- Core assumption: The distribution and density of distractors vary across views and can be effectively managed through view-specific densification.
- Evidence anchors:
  - [section 3.1] "Unlike the ADC in 3DGS that densifies Gaussian points after every T iteration, we densify the distractor Gaussians when their corresponding image has been trained S times."
  - [section 4.2] "With ADC enabled for our distractor Gaussians, we demonstrate robustness to various clutter ratios."
- Break condition: If distractors appear in a highly irregular pattern across views, the fixed densification schedule may not adapt quickly enough, leading to either over- or under-reconstruction of transient elements.

## Foundational Learning

- Concept: Alpha-compositing in volume rendering
  - Why needed here: DeSplat relies on decomposing the alpha-compositing equation to separate static and distractor contributions
  - Quick check question: What happens to the rendered color when the alpha value of a Gaussian approaches zero?

- Concept: Structure-from-Motion (SfM) and point cloud initialization
  - Why needed here: Static Gaussians are initialized from a sparse point cloud obtained via COLMAP, which provides the initial geometry for the scene
  - Quick check question: Why is it important to initialize static Gaussians from a globally consistent point cloud rather than per-view?

- Concept: Regularization in optimization
  - Why needed here: The regularization terms on alpha-blending weights are crucial for preventing distractor Gaussians from explaining static objects
  - Quick check question: How would removing the regularization terms affect the separation between static and distractor components?

## Architecture Onboarding

- Component map: Static Gaussians (COLMAP initialization) -> Per-view distractor Gaussians (camera-plane initialization) -> Joint optimization with regularization -> Decomposed alpha-compositing -> Separate static and distractor rendering

- Critical path: Initialization → Per-view distractor Gaussian placement → Joint optimization with static Gaussians → Alpha-compositing → Regularization → Rendering

- Design tradeoffs:
  - Memory vs. separation quality: More distractor Gaussians improve separation but increase memory usage
  - Regularization strength vs. reconstruction accuracy: Stronger regularization improves separation but may reduce overall reconstruction quality
  - View-specific vs. global distractors: Per-view distractors handle transient effects better but require more storage

- Failure signatures:
  - Holes in static background: Indicates distractor Gaussians are over-explaining static regions
  - Persistent distractor artifacts: Suggests distractor Gaussians are not being properly separated
  - Inconsistent static objects: May indicate static Gaussians are being incorrectly explained by distractor components

- First 3 experiments:
  1. Run DeSplat with only static Gaussians (disable distractor initialization) to establish baseline performance
  2. Enable distractor Gaussians without regularization to observe separation quality without guidance
  3. Vary the number of distractor Gaussians per view to find the optimal balance between separation quality and memory usage

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness on scenes with highly dynamic objects that occupy large portions of the view remains unclear
- Performance on extremely cluttered scenes with hundreds of transient objects per view has not been thoroughly evaluated
- Fixed regularization weights (λs, λd) may not generalize optimally across different scene types and distractor densities

## Confidence
- **High Confidence:** DeSplat achieves comparable rendering speeds to vanilla 3DGS while adding distractor separation capability
- **Medium Confidence:** The method's effectiveness on real-world datasets (On-the-go, Photo Tourism) given limited quantitative metrics in these scenarios
- **Medium Confidence:** Claims about generalization to various clutter ratios based on the single Crab scene evaluation

## Next Checks
1. Test DeSplat on synthetic scenes with controlled clutter levels (0%, 25%, 50%, 75%, 100%) to quantify the relationship between distractor density and separation quality
2. Evaluate performance when distractors persist across multiple consecutive frames to assess robustness to semi-static elements
3. Compare with alternative approaches that use semantic priors (e.g., semantic segmentation networks) to isolate the benefit of DeSplat's prior-free decomposition approach