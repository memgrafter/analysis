---
ver: rpa2
title: Measuring Sharpness in Grokking
arxiv_id: '2402.08946'
source_url: https://arxiv.org/abs/2402.08946
tags:
- grokking
- sharpness
- accuracy
- relative
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a robust technique for measuring grokking
  by fitting an error function to training and validation accuracy curves. The method
  quantifies grokking sharpness and jump timing through curve-fitting parameters.
---

# Measuring Sharpness in Grokking
## Quick Facts
- arXiv ID: 2402.08946
- Source URL: https://arxiv.org/abs/2402.08946
- Authors: Jack Miller; Patrick Gleeson; Charles O'Neill; Thang Bui; Noam Levi
- Reference count: 21
- Primary result: Introduced a curve-fitting method to quantify grokking sharpness and validated it across linear student-teacher models and MLPs on parity tasks, finding consistent trends between grokking gap and sharpness

## Executive Summary
This paper addresses the challenge of quantifying grokking by introducing a curve-fitting approach to measure grokking sharpness. The authors propose using exponential and linear functions to fit training and validation accuracy curves, extracting parameters that capture the timing and sharpness of grokking transitions. Through experiments in both theoretical and practical settings, they demonstrate that their method produces consistent trends between grokking gap and sharpness measures across different architectures.

The study provides empirical evidence that absolute and relative measures of sharpness yield similar trends, suggesting common underlying mechanisms influence grokking sharpness across different learning scenarios. The methodology offers a systematic way to analyze grokking phenomena that could be applied to larger-scale models and real-world datasets.

## Method Summary
The authors develop a curve-fitting methodology to quantify grokking sharpness by fitting exponential and linear functions to training and validation accuracy curves. The approach extracts parameters that capture the timing and sharpness of grokking transitions, allowing for systematic comparison across different settings. The method is validated in two contexts: a theoretical linear student-teacher model and two-layer MLPs trained on parity prediction tasks with varying levels of "concealment." By comparing absolute and relative measures of sharpness, the authors investigate whether similar trends emerge across different architectures and learning scenarios.

## Key Results
- Introduced a curve-fitting approach using exponential and linear functions to quantify grokking sharpness through timing and sharpness parameters
- Demonstrated consistent trends between grokking gap and sharpness measures across both linear student-teacher models and MLPs on parity tasks
- Showed that absolute and relative measures of sharpness produce similar trends, suggesting common underlying mechanisms

## Why This Works (Mechanism)
The curve-fitting approach works by capturing the characteristic S-shaped transition that occurs during grokking, where validation accuracy suddenly jumps from near-random performance to near-perfect generalization. The exponential function models the initial slow progress followed by rapid generalization, while the linear component captures the final plateau phase. This mathematical decomposition allows for precise quantification of when the jump occurs and how sharp it is, providing objective metrics that can be compared across different training runs and architectures.

## Foundational Learning
- Curve fitting with exponential and linear functions - needed to model the characteristic S-shaped transition in grokking; quick check: verify the fitted curves accurately capture the training/validation accuracy patterns
- Sharpness quantification through parameter extraction - needed to objectively measure the timing and abruptness of generalization jumps; quick check: ensure extracted parameters correlate with intuitive notions of sharpness
- Comparison of absolute vs relative measures - needed to understand whether measurement scale affects observed trends; quick check: verify similar trends persist across different scaling approaches
- Theoretical linear student-teacher models - needed as a controlled setting to validate methodology; quick check: confirm the model exhibits clear grokking behavior
- Practical MLP implementations on parity tasks - needed to bridge theory with realistic learning scenarios; quick check: ensure parity tasks show genuine grokking rather than simple memorization

## Architecture Onboarding
Component map: Data -> Model (MLP/Linear) -> Training Loop -> Accuracy Tracking -> Curve Fitting -> Sharpness Metrics
Critical path: Training data generation → Model initialization → Iterative training → Accuracy recording → Curve fitting → Parameter extraction → Analysis
Design tradeoffs: Simplified parity tasks vs real-world complexity; theoretical models vs practical implementations; absolute vs relative sharpness measures
Failure signatures: Poor curve fitting indicating non-standard grokking behavior; inconsistent parameter extraction across runs; lack of clear generalization jumps
First experiments: 1) Verify curve fitting accurately captures known grokking patterns in synthetic data, 2) Compare sharpness metrics across different learning rates, 3) Test methodology on a simple image classification task

## Open Questions the Paper Calls Out
None

## Limitations
- Methodology depends on curve-fitting assumptions that may not capture all grokking behaviors, especially in complex or noisy scenarios
- Experimental validation limited to simplified settings (linear models and small MLPs) that may not represent real-world grokking phenomena
- Potential measurement artifacts in the curve-fitting process could affect the reliability of absolute and relative sharpness comparisons

## Confidence
- Consistent trends across settings: Medium
- Absolute vs relative measures similarity: Medium
- Generalizability to larger architectures: Low

## Next Checks
1. Validate the curve-fitting approach on larger, more complex architectures (e.g., transformers, CNNs) trained on real-world datasets to test generalizability
2. Conduct ablation studies on the choice of fitting functions and parameter estimation methods to assess robustness of the sharpness quantification
3. Design controlled experiments to isolate and verify the specific mechanisms that drive the observed relationship between grokking gap and sharpness across different settings