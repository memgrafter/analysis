---
ver: rpa2
title: Treatment of Epistemic Uncertainty in Conjunction Analysis with Dempster-Shafer
  Theory
arxiv_id: '2402.00060'
source_url: https://arxiv.org/abs/2402.00060
tags:
- uncertainty
- event
- cdms
- time
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses epistemic uncertainty in conjunction analysis
  using Dempster-Shafer Theory (DSt) applied to Conjunction Data Messages (CDMs).
  The method models epistemic uncertainty in CDMs by constructing probability boxes
  using the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality, which are then used to build
  DSt structures.
---

# Treatment of Epistemic Uncertainty in Conjunction Analysis with Dempster-Shafer Theory

## Quick Facts
- arXiv ID: 2402.00060
- Source URL: https://arxiv.org/abs/2402.00060
- Reference count: 33
- Primary result: Method achieves no false negatives on synthetic database while recommending similar number of maneuvers as ESA but identifying 6-15× more uncertain cases

## Executive Summary
This paper addresses epistemic uncertainty in space conjunction analysis by applying Dempster-Shafer Theory to Conjunction Data Messages (CDMs). The method constructs probability boxes using the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality to model uncertainty in CDM observations, then builds Dempster-Shafer structures to compute belief and plausibility values for probability of collision (PoC) thresholds. The approach is tested on synthetic and real conjunction scenarios, demonstrating improved uncertainty quantification compared to ESA and CNES practices while maintaining similar maneuver recommendations.

## Method Summary
The method processes time series of CDMs to construct probability boxes using DKW inequality bounds, which are then optimized into p-box functions. These p-boxes undergo α-cuts to generate intervals for uncertain variables (miss distance, covariance components), which are combined via Cartesian products to form Dempster-Shafer focal elements with assigned basic probability assignments. Belief and plausibility values are computed for PoC thresholds, and events are classified into six categories based on time to TCA, Pl at PoC0, and area between Pl/Bel curves. The classification distinguishes high-risk, low-risk, and uncertain events for operational decision-making.

## Key Results
- On synthetic database: Zero false negatives while maintaining reasonable false positive rates
- On real mission database: Similar number of collision avoidance maneuvers as ESA approach
- Identified 6-15 times more uncertain cases requiring further analysis compared to ESA method

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method models epistemic uncertainty by constructing probability boxes (p-boxes) using the DKW inequality, which bounds the set of possible distributions from which CDM observations are drawn.
- Mechanism: The DKW inequality creates robust confidence bands around the empirical cumulative distribution function (eCDF) of CDM samples, defining upper and lower bounds on possible distributions. These bounds form p-boxes that capture epistemic uncertainty without assuming a specific underlying distribution.
- Core assumption: CDM observations are samples drawn from an unknown family of distributions with epistemic uncertainty in the mean, covariance, and distribution shape.
- Evidence anchors:
  - [abstract]: "The Dvoretzky-Kiefer-Wolfowitz (DKW) inequality is used to construct robust bounds on such a family of unknown distributions starting from a time series of CDMs."
  - [section III]: "The Dvoretzky–Kiefer–Wolfowitz (DKW) inequality[20], defines the following upper and a lower bounds around the empirical Cumulative Distribution Function (eCDF)"

### Mechanism 2
- Claim: The Dempster-Shafer Theory structure enables computation of belief and plausibility values for probability of collision (PoC) thresholds, distinguishing between high-risk, low-risk, and uncertain events.
- Mechanism: By assigning basic probability assignments (bpas) to focal elements derived from p-box intervals, the method computes Bel and Pl values for PoC thresholds. These values quantify confidence in collision predictions and distinguish cases where uncertainty prevents confident classification.
- Core assumption: Epistemic independence among uncertain variables (miss distance, covariance components) allows Cartesian product construction of focal elements.
- Evidence anchors:
  - [abstract]: "A DSt structure is then derived from the probability boxes constructed with DKW inequality. The DSt structure encapsulates the uncertainty in the CDMs at every point along the time series and allows the computation of the belief and plausibility in the realisation of a given probability of collision."
  - [section II]: "The idea proposed in [16], was to use DSt to compute the level of confidence in the correctness of the value of the PoC, given the available evidence on the sources of information."

### Mechanism 3
- Claim: The method distinguishes between cases requiring collision avoidance maneuvers and uncertain cases by combining PoC thresholds, belief/plausibility values, and uncertainty quantification.
- Mechanism: A six-class classification system uses thresholds for time to TCA, Pl at PoC0, and area between Pl/Bel curves (APl,Bel) to categorize events. This distinguishes high-risk events (Class 1-2), uncertain events (Class 0-3), and low-risk events (Class 4-5).
- Core assumption: Operational constraints can be captured through threshold tuning based on mission requirements and historical performance.
- Evidence anchors:
  - [abstract]: "The classification system proposed in this paper is more conservative than the approach taken by the European Space Agency but provides an added quantification of uncertainty in the probability of collision."
  - [section IV.B]: "From Table 3, some conclusions can be derived. The number of manoeuvres proposed by the evidence-based approach is similar to the number of CAMs proposed by the ESA operators."

## Foundational Learning

- Concept: Probability boxes (p-boxes) and interval analysis
  - Why needed here: The method relies on constructing p-boxes from DKW bounds to represent epistemic uncertainty without assuming specific distributions.
  - Quick check question: How does a p-box differ from a traditional confidence interval in representing uncertainty?

- Concept: Dempster-Shafer Theory and belief functions
  - Why needed here: The method uses DSt to compute belief and plausibility values for PoC thresholds, enabling uncertainty quantification beyond traditional probability.
  - Quick check question: What is the difference between belief and plausibility in DSt, and how do they relate to confidence in collision predictions?

- Concept: Conjunction data message (CDM) structure and propagation uncertainty
  - Why needed here: Understanding CDM contents and sources of uncertainty is essential for applying the method to real conjunction scenarios.
  - Quick check question: What are the three main sources of epistemic uncertainty in CDMs according to the paper?

## Architecture Onboarding

- Component map: CDM time series → DKW bounds → p-boxes → intervals → focal elements → Bel/Pl → classification
- Critical path: CDM time series → DKW bounds → p-boxes → intervals → focal elements → Bel/Pl → classification
- Design tradeoffs: Independence assumption vs. computational complexity; number of α-cuts vs. refinement level; threshold tuning vs. false positive/negative rates
- Failure signatures: High APl,Bel values indicating uncertainty; low Pl at PoC0 suggesting insufficient evidence; computational bottlenecks with many focal elements
- First 3 experiments:
  1. Apply DKW bounds to synthetic CDM sequences with known distributions to validate p-box construction
  2. Test classification system on synthetic scenarios with varying uncertainty levels to tune thresholds
  3. Compare method performance against ESA/CNES approaches on real CDM databases to validate operational relevance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of α-cuts per variable for constructing the DSt structure that balances computational cost and classification accuracy?
- Basis in paper: [explicit] The paper discusses the use of different numbers of α-cuts (from 1 to 7) in the analysis but does not determine the optimal number.
- Why unresolved: The paper shows that increasing the number of α-cuts refines the curves but does not significantly change the classification outcome. The trade-off between computational cost and accuracy is not fully explored.
- What evidence would resolve it: A systematic study comparing classification performance and computational time for different numbers of α-cuts across a large dataset of conjunction events.

### Open Question 2
- Question: How does the proposed evidence-based classification system perform compared to other uncertainty quantification methods in conjunction analysis?
- Basis in paper: [explicit] The paper compares the proposed method to ESA and CNES practices but does not compare it to other uncertainty quantification methods like fuzzy logic or Bayesian networks.
- Why unresolved: The paper focuses on demonstrating the advantages of the proposed method over existing practices but does not explore how it compares to other uncertainty quantification approaches in the literature.
- What evidence would resolve it: A comparative study of the proposed method against other uncertainty quantification methods using a common dataset of conjunction events and standardized performance metrics.

### Open Question 3
- Question: Can the proposed method be extended to handle dependent variables in the construction of focal elements?
- Basis in paper: [inferred] The paper assumes independence among variables when constructing focal elements, which may lead to over-conservative results.
- Why unresolved: The paper acknowledges that variables are not truly independent but does not explore methods to address this limitation or quantify the impact of the independence assumption on classification accuracy.
- What evidence would resolve it: A study comparing the classification performance of the proposed method with and without the independence assumption, using synthetic and real conjunction event data that exhibit variable dependencies.

## Limitations
- P-box construction may be overly conservative with sparse CDM data or strong dependencies
- Independence assumption in focal element construction may underestimate correlation effects
- Threshold calibration requires mission-specific tuning and validation across diverse operational contexts

## Confidence

- Novelty and Contribution: High
- Method Effectiveness: Medium
- Classification System Practicality: Medium

## Next Checks

1. Apply the method to conjunction scenarios with varying levels of CDM data sparsity and correlation to assess robustness under realistic operational constraints.

2. Systematically vary classification thresholds across a range of mission profiles to identify optimal settings and quantify sensitivity to threshold choices.

3. Conduct head-to-head comparisons with additional uncertainty quantification approaches (e.g., Bayesian methods) on the same real conjunction databases to validate relative performance.