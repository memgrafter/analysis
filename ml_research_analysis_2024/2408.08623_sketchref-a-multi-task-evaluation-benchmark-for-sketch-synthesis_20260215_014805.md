---
ver: rpa2
title: 'SketchRef: a Multi-Task Evaluation Benchmark for Sketch Synthesis'
arxiv_id: '2408.08623'
source_url: https://arxiv.org/abs/2408.08623
tags:
- sketch
- sketches
- human
- recognizability
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of evaluating sketch synthesis
  methods, which currently lack a unified benchmark and fair evaluation metrics. The
  authors propose SketchRef, a comprehensive multi-task evaluation benchmark for sketch
  synthesis.
---

# SketchRef: a Multi-Task Evaluation Benchmark for Sketch Synthesis

## Quick Facts
- arXiv ID: 2408.08623
- Source URL: https://arxiv.org/abs/2408.08623
- Reference count: 15
- Key outcome: Proposes SketchRef benchmark with structure-level recognizability (mOKS) and simplicity-constrained metrics (mRS, mRC) for fair sketch synthesis evaluation

## Executive Summary
This paper addresses the critical gap in sketch synthesis evaluation by introducing SketchRef, a comprehensive multi-task benchmark that evaluates both category-level and structure-level recognizability. The benchmark introduces novel metrics including mean Object Keypoint Similarity (mOKS) for structural assessment and simplicity-constrained recognizability measures (mRS, mRC) to ensure fair comparison across sketches with different abstraction levels. Through extensive human evaluation with 7,920 responses, the authors validate their approach and demonstrate its effectiveness in evaluating eight existing sketch synthesis methods across four sub-datasets.

## Method Summary
SketchRef evaluates sketch synthesis through three main components: category-level recognizability using CLIP embedding similarity (SCLIP), structure-level recognizability using pose-estimation-based keypoint matching (mOKS), and simplicity measurement via relative Simplicity Ratio (SR). The benchmark constrains recognizability evaluation by simplicity thresholds (α = 0.75, 1.75) to ensure fair comparison across different abstraction levels, producing metrics mRS and mRC. The method leverages existing pose estimation models (RTMPose) and CLIP embeddings without requiring additional training.

## Key Results
- mOKS effectively captures structural consistency between sketches and reference photos using shared keypoints
- Simplicity-constrained metrics (mRS, mRC) enable fair evaluation across sketches with different abstraction levels
- Human study with 7,920 responses validates the effectiveness of the proposed evaluation framework
- CLIPasso demonstrates superior performance in category-level recognizability across multiple simplification thresholds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using shared visual keypoints between sketches and reference photos enables structure-level recognizability assessment.
- Mechanism: By leveraging pose estimation models (RTMPose) to detect keypoints in both reference photos and sketches, the benchmark establishes a common structural reference frame. This allows quantitative comparison via mean Object Keypoint Similarity (mOKS), which measures how well structural elements align between sketch and reference.
- Core assumption: Pose estimation models trained on real photos generalize to detect corresponding keypoints in sketches with sufficient accuracy for meaningful structural comparison.
- Evidence anchors:
  - [abstract]: "Recognizing the inherent trade-off between recognizability and simplicity in sketches, we are the first to quantify this balance by introducing a recognizability calculation method constrained by simplicity, mRS, ensuring fair and meaningful evaluations."
  - [section]: "For sketches of the human body, human face, and animals, it means retaining the keypoints from the reference photo, which contains necessary pose information. We use RTMPose (Jiang et al. 2023), a general pose estimation model, to predict these keypoints in the sketch."
  - [corpus]: Weak evidence. The corpus contains related papers on sketch synthesis but no direct evidence about pose estimation model generalization to sketches.
- Break condition: If pose estimation models fail to reliably detect keypoints in sketches due to the abstract nature of line drawings, mOKS would become meaningless and structure-level assessment would fail.

### Mechanism 2
- Claim: Simplicity-constrained recognizability metrics (mRS, mRC) enable fair evaluation across sketches with different abstraction levels.
- Mechanism: By measuring the relative Simplicity Ratio (SR) between sketch and reference photo, and only evaluating recognizability metrics (mOKS for structure, SCLIP for category) on sketches above a simplification threshold, the benchmark normalizes for abstraction level. This prevents highly simplified sketches from being unfairly penalized.
- Core assumption: The relative simplicity between sketch and reference photo can be meaningfully quantified and correlates with human perception of abstraction level.
- Evidence anchors:
  - [abstract]: "To ensure fair evaluation sketches with different simplification levels, we propose a recognizability calculation method constrained by simplicity."
  - [section]: "We propose a method to measure simplicity, which involves comparing the sketch xskt to its reference photo xref, defined as relative Simplicity Ratio (SR)."
  - [section]: "Although this influence of simplicity on recognizability is acknowledged, previous work overlooks simplicity when evaluating sketches and focuses solely on recognizability."
- Break condition: If the simplicity metric fails to correlate with human perception of abstraction (as indicated by weak correlation in some experiments), the fairness constraint becomes ineffective.

### Mechanism 3
- Claim: Category-level recognizability using CLIP embeddings captures semantic consistency beyond structural alignment.
- Mechanism: By computing cosine similarity between CLIP text embeddings of class names and CLIP image embeddings of sketches (SCLIP), the benchmark measures whether sketches retain category-relevant visual information even when structural details are lost.
- Core assumption: CLIP embeddings preserve semantic category information in a way that correlates with human category recognition, even for abstract sketches.
- Evidence anchors:
  - [abstract]: "To address the limitation of category-level recognizability in capturing the structural features of sketches, we introduce the concept of structure-level recognizability."
  - [section]: "Following previous works (Vinker et al. 2022; Mukherjee et al. 2024), we compute the average cosine similarity between the CLIP embeddings of the class names and the images (Radford et al. 2021)."
  - [section]: "CLIPasso emerges as the top performer in terms of category-level recognizability on both datasets at simplification thresholds α of 0.75 and 1.75. This consistent performance can be attributed to CLIPasso's consideration of semantic loss during training."
- Break condition: If CLIP embeddings fail to capture category-relevant features in highly abstract sketches, SCLIP would not correlate with human category recognition.

## Foundational Learning

- Concept: Pose estimation and keypoint detection
  - Why needed here: Essential for understanding how structure-level recognizability (mOKS) is computed by comparing predicted keypoints between sketches and reference photos
  - Quick check question: How does the Hungarian algorithm enable matching predicted keypoints to ground truth when the number of predictions differs from the number of actual keypoints?

- Concept: CLIP embedding similarity and semantic representation
  - Why needed here: Critical for understanding how category-level recognizability (SCLIP) measures semantic consistency between sketches and their class labels
  - Quick check question: Why might CLIP embeddings be more effective than traditional classification accuracy for evaluating sketch recognizability across different abstraction levels?

- Concept: Image complexity assessment methods
  - Why needed here: Important for understanding how relative simplicity ratio (SR) quantifies the abstraction level of sketches for fair evaluation
  - Quick check question: What makes compression ratio a suitable metric for measuring image complexity in the context of comparing sketches to their reference photos?

## Architecture Onboarding

- Component map: Reference photo collection and preprocessing -> Sketch synthesis methods -> Annotation generation -> Pose estimation models -> CLIP model -> Complexity assessment methods -> Evaluation metrics -> Human evaluation collection -> Visualization and analysis tools

- Critical path: Reference photo → Sketch synthesis → Keypoint annotation → Pose estimation → mOKS calculation → Complexity assessment → SR calculation → mRS/mRC evaluation → Benchmark results

- Design tradeoffs:
  - Using general pose estimation models vs. training specialized sketch models: General models enable broader applicability but may sacrifice accuracy on sketches
  - Fixed simplification thresholds (α=0.75, 1.75) vs. adaptive thresholds: Fixed thresholds provide consistency but may not capture all meaningful variation in abstraction levels
  - Human evaluation sample size (7,920 responses) vs. cost: Large sample ensures statistical significance but requires significant resources

- Failure signatures:
  - mOKS values near zero across all methods suggests pose estimation models fail on sketches
  - High correlation between SR and recognizability without simplification constraints indicates the fairness mechanism isn't working
  - Low correlation between any metrics and human evaluation suggests fundamental measurement issues

- First 3 experiments:
  1. Run RTMPose on a subset of sketches and reference photos to verify keypoint detection quality and calculate mOKS manually for verification
  2. Compute SR values for all sketches and plot against human simplicity ratings to verify correlation
  3. Calculate mRS and mRC at different α thresholds for a single sketch method to understand how simplification constraints affect evaluation outcomes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop a unified evaluation framework that combines both category-level and structure-level recognizability metrics for sketch synthesis?
- Basis in paper: [explicit] The paper identifies the lack of a unified benchmark and the need to evaluate both category-level and structure-level recognizability in sketch synthesis.
- Why unresolved: The current evaluation methods rely on separate metrics for category-level and structure-level recognizability, making it difficult to compare methods comprehensively.
- What evidence would resolve it: A study that demonstrates the effectiveness of a unified evaluation framework in comparing different sketch synthesis methods and aligning with human perception.

### Open Question 2
- Question: Can the mOKS metric be further improved to better capture the nuances of structural consistency between sketches and reference photos?
- Basis in paper: [explicit] The paper introduces the mOKS metric as a novel way to quantify structure-level recognizability, but acknowledges the need for further improvement.
- Why unresolved: The effectiveness of mOKS in capturing the subtle details of structural consistency has not been thoroughly validated, especially for complex sketches.
- What evidence would resolve it: A comprehensive study that compares mOKS with human assessments of structural consistency and identifies areas for improvement.

### Open Question 3
- Question: How can we develop a more sophisticated method for measuring simplicity in sketches that accounts for both stroke-based and pixel-based representations?
- Basis in paper: [explicit] The paper proposes the relative Simplicity Ratio (SR) as a method for measuring simplicity, but acknowledges the limitations of this approach, particularly for pixel-based sketches.
- Why unresolved: The current method for measuring simplicity may not fully capture the complexity of sketches, especially those with intricate details or varying levels of abstraction.
- What evidence would resolve it: A study that develops and validates a more comprehensive method for measuring simplicity in sketches, taking into account both stroke-based and pixel-based representations.

## Limitations
- The benchmark relies on general pose estimation models that may fail to detect keypoints in highly abstract sketches
- Fixed simplification thresholds (α = 0.75, 1.75) may not capture the full spectrum of abstraction levels across different sketch styles
- Human evaluation may be subject to cultural and individual biases in recognizing abstract sketches

## Confidence
- High confidence: The mechanism for simplicity-constrained recognizability (mRS, mRC) is well-grounded in the tradeoff between abstraction and recognizability, with clear mathematical formulation and empirical validation through human studies
- Medium confidence: The structure-level recognizability via mOKS depends on the assumption that general pose estimation models generalize to sketches, which is reasonable but not extensively validated across all abstraction levels
- Medium confidence: The category-level recognizability using CLIP embeddings assumes semantic consistency is preserved in abstract sketches, which works for moderate simplification but may break down for highly abstract representations

## Next Checks
1. Run RTMPose on a stratified sample of sketches across different abstraction levels and compare keypoint detection accuracy to human-annotated keypoints on the same images
2. Conduct a controlled human study specifically focused on simplicity perception, asking participants to rate sketch abstraction levels and correlate these ratings with the computed SR values
3. Apply the SketchRef evaluation to a broader range of sketch synthesis methods, including those from different research groups, to test the benchmark's generalizability and identify any systematic biases in the evaluation framework