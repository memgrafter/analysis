---
ver: rpa2
title: Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts
arxiv_id: '2405.18861'
source_url: https://arxiv.org/abs/2405.18861
tags:
- domain
- disam
- generalization
- loss
- convergence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DISAM, a method to address the degradation
  of SAM under domain shifts. SAM's perturbation generation is biased towards domains
  with larger gradients, disrupting convergence and harming generalization.
---

# Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts

## Quick Facts
- arXiv ID: 2405.18861
- Source URL: https://arxiv.org/abs/2405.18861
- Reference count: 40
- Primary result: DISAM improves out-of-domain accuracy by 1.9-2.1% on DomainBed benchmarks over state-of-the-art methods

## Executive Summary
This paper addresses a critical limitation of Sharpness-Aware Minimization (SAM) when applied to domain generalization tasks. SAM's standard perturbation generation mechanism tends to favor domains with larger gradients, leading to biased optimization that can harm generalization under domain shifts. The authors propose Domain-Inspired Sharpness-Aware Minimization (DISAM), which introduces a domain-level convergence consistency constraint that minimizes the variance of domain losses during perturbation generation. This approach adaptively adjusts perturbation directions to focus more on well-converged domains while being milder on less optimized ones, ultimately improving both convergence speed and generalization performance.

## Method Summary
DISAM modifies the standard SAM algorithm by incorporating domain-level awareness into the perturbation generation process. The key innovation is a variance minimization term that operates across domain losses during the inner maximization step of SAM. By minimizing the variance of domain losses when generating perturbations, DISAM ensures that the optimization process treats all domains more consistently, rather than being dominated by domains with larger gradients. This is achieved through a domain-specific perturbation direction that balances the needs of different domains based on their current optimization status. The method maintains SAM's core principle of seeking flat minima while adapting it to the multi-domain setting characteristic of domain generalization problems.

## Key Results
- Achieves average 1.9-2.1% improvement in out-of-domain accuracy across DomainBed benchmarks compared to state-of-the-art methods
- Demonstrates theoretical guarantees for faster convergence and improved generalization under domain shifts
- Shows superior performance in parameter-efficient fine-tuning scenarios with large models like CLIP
- Maintains computational efficiency despite additional domain-level calculations

## Why This Works (Mechanism)
DISAM works by addressing the fundamental bias in SAM's perturbation generation mechanism. When domains have different gradient magnitudes, standard SAM tends to generate perturbations primarily guided by domains with larger gradients, neglecting the optimization needs of other domains. DISAM's variance minimization constraint forces the perturbation generation to consider all domains more equally by reducing the spread of domain losses. This creates a more balanced optimization trajectory that converges to solutions that perform well across all domains rather than overfitting to the most prominent gradient signals. The domain-level convergence consistency ensures that the model doesn't get stuck in solutions that are sharp with respect to some domains while being flat for others.

## Foundational Learning
- Sharpness-Aware Minimization (SAM): A gradient-based optimization method that seeks flat minima by considering perturbations in weight space. Why needed: Provides the foundation for understanding how DISAM modifies standard optimization. Quick check: Verify understanding of inner maximization step in SAM.
- Domain Generalization: The task of training models that generalize well to unseen domains. Why needed: Contextualizes why domain-level optimization matters. Quick check: Distinguish from domain adaptation and multi-task learning.
- Variance Minimization: A technique for reducing spread in loss values across domains. Why needed: Core mechanism by which DISAM balances optimization across domains. Quick check: Understand how variance relates to optimization stability.
- Convergence Guarantees: Theoretical bounds on optimization speed and solution quality. Why needed: Validates the effectiveness of DISAM's modifications. Quick check: Review basic convergence analysis in optimization theory.
- Gradient Decomposition: The ability to separate gradients by domain. Why needed: Enables domain-level optimization strategies. Quick check: Understand how domain-specific gradients are computed in practice.

## Architecture Onboarding

Component map: Input data -> Domain classifier -> Domain-specific gradients -> Variance minimization -> Perturbation generation -> Model update

Critical path: The core optimization loop consists of (1) computing domain-specific gradients, (2) calculating variance across domain losses, (3) generating domain-aware perturbations, and (4) updating model parameters. The variance minimization component is critical as it directly influences the perturbation direction and ultimately determines the quality of the converged solution.

Design tradeoffs: DISAM trades computational overhead (maintaining domain statistics and variance calculations) for improved generalization performance. The method requires domain labels during training, which may not always be available. The variance minimization parameter needs tuning to balance between domain consistency and optimization effectiveness.

Failure signatures: DISAM may underperform when domain boundaries are ambiguous or when domains overlap significantly. It could also struggle with highly imbalanced domain distributions where some domains have very few samples. The method assumes that domain losses can be meaningfully decomposed, which might not hold for certain complex datasets.

First experiments:
1. Test DISAM on a simple multi-domain synthetic dataset where domain boundaries are clearly defined
2. Compare DISAM's convergence trajectory against standard SAM on a single domain to isolate the domain-awareness benefits
3. Evaluate DISAM with varying levels of domain imbalance to understand its robustness to distribution shifts

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, focusing instead on demonstrating the effectiveness of the proposed method.

## Limitations
- Computational overhead from maintaining and updating domain-specific statistics during training
- Reliance on accurate domain labels, which may not be available in all practical scenarios
- Performance improvements, while statistically significant, may not justify additional computational cost in all applications
- Theoretical analysis assumes well-behaved domain-wise loss functions that may not hold in practice

## Confidence
- Theoretical convergence guarantees: High
- Practical performance improvements: Medium
- Computational efficiency claims: Medium

## Next Checks
1. Test DISAM's performance when domain boundaries are ambiguous or overlapping, using datasets where domain labels are noisy or incomplete
2. Evaluate the method's behavior with non-IID domain distributions and varying domain imbalance ratios
3. Conduct ablation studies to quantify the individual contributions of the variance minimization component versus other design choices