---
ver: rpa2
title: Handling Large-scale Cardinality in building recommendation systems
arxiv_id: '2401.09572'
source_url: https://arxiv.org/abs/2401.09572
tags:
- systems
- recommendation
- size
- performance
- sharing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of incorporating high-cardinality
  features, such as UUIDs, in recommendation systems by proposing a bag-of-words approach
  combined with layer sharing. The bag-of-words approach replaces user UUIDs with
  a proxy based on the user's previously ordered stores, significantly reducing model
  size and improving training efficiency.
---

# Handling Large-scale Cardinality in building recommendation systems

## Quick Facts
- arXiv ID: 2401.09572
- Source URL: https://arxiv.org/abs/2401.09572
- Reference count: 3
- Primary result: Proposed bag-of-words approach with layer sharing reduces model size by 25x and improves Hit Rate@500 by 10%

## Executive Summary
This paper addresses the challenge of incorporating high-cardinality features like UUIDs in recommendation systems by proposing a bag-of-words approach combined with layer sharing. The bag-of-words approach replaces user UUIDs with a proxy based on the user's previously ordered stores, significantly reducing model size and improving training efficiency. Layer sharing between query and item towers allows for information exchange and more efficient learning. Offline experiments on Uber Eats data demonstrate that the proposed models outperform the baseline model, achieving a 10% improvement in Hit Rate@500 and up to 30% improvement in lower recall values.

## Method Summary
The method replaces high-cardinality user UUIDs with a bag-of-words representation based on previously ordered stores, reducing model size by 25x. Three models are compared: a Deep Matrix Factorization baseline, a Bag of Words (BoW) model, and a BoW model with layer sharing between query and item towers. The models are trained on four months of Uber Eats order data with 30% user sampling, using AdaGrad optimizer. Evaluation is performed on one week of validation data using Hit Rate metrics at various k values.

## Key Results
- 10% improvement in Hit Rate@500 compared to baseline model
- Up to 30% improvement in lower recall values (Hit Rate@5, Hit Rate@20)
- BoW model with layer sharing converges 10x faster (2000 steps vs 20k steps) to hit rate@20 threshold of 0.35
- 25x reduction in model size through bag-of-words approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Bag-of-Words approach replaces high-cardinality user UUIDs with a lower-cardinality proxy based on the user's ordered stores, reducing model size by 25x.
- Mechanism: By aggregating a user's historical store interactions into a fixed-length sequence, the model shifts from learning sparse embeddings for millions of unique users to learning embeddings for a smaller set of stores.
- Core assumption: A user's store ordering history is a sufficiently rich proxy for the user's identity and preferences.
- Evidence anchors: Abstract states bag-of-words approach replaces user UUIDs with proxy based on previously ordered stores, significantly reducing model size.

### Mechanism 2
- Claim: Layer sharing between query and item towers allows information exchange and more efficient learning, improving model performance.
- Mechanism: By enforcing the same embedding table for UUID features across both towers, the model ensures that the same latent representation is used for the same entity, regardless of whether it appears as a query or item.
- Core assumption: The optimal representation of a store (or user) is the same whether it is being queried or being recommended.
- Evidence anchors: Section states layer sharing is enforced for UUID features between the two towers, allowing them to share information.

### Mechanism 3
- Claim: The combination of BoW and layer sharing accelerates convergence, achieving hit rate@20 threshold in 2000 steps vs. 20k steps for BoW alone.
- Mechanism: The BoW approach reduces the parameter space and sparsity, while layer sharing reduces redundancy. Together, they create a more stable, information-rich optimization landscape that gradients can traverse more quickly.
- Core assumption: The reduced parameter space and shared embeddings create a smoother, more generalizable loss surface.
- Evidence anchors: Section states BoW model with layer sharing achieved convergence to hit rate@20 threshold within 2000 steps, whereas simple BoW model took around 20k steps.

## Foundational Learning

- Concept: Embedding tables for high-cardinality features
  - Why needed here: Understanding why UUID features require large embedding tables and how sparsity affects learning.
  - Quick check question: What happens to the embedding table size if we add a UUID feature with cardinality 10 million and embedding dimension 32?

- Concept: Two-tower architecture and its training dynamics
  - Why needed here: To grasp how query and item towers are trained jointly but deployed separately, and how layer sharing modifies this.
  - Quick check question: In a standard two-tower model, can the query tower see item features during training?

- Concept: Bag-of-words representations and their tradeoffs
  - Why needed here: To evaluate when replacing a user with their store history is appropriate and what information may be lost.
  - Quick check question: What kind of user behavior might a BoW approach fail to capture that a direct UUID embedding would?

## Architecture Onboarding

- Component map: eater_uuid → BoW sequence of store_uuids (fixed length) → Shared embedding table for store_uuids → Query tower and Item tower → Dot product of normalized embeddings → Ranking score

- Critical path: 1. Convert eater_uuid to BoW store sequence 2. Look up shared store embeddings 3. Process through respective towers 4. Compute dot product and loss

- Design tradeoffs:
  - Model size vs. expressiveness: BoW reduces parameters but may lose individual user nuance
  - Latency vs. accuracy: Layer sharing reduces inference time but may limit tower specialization
  - Training speed vs. convergence stability: Shared embeddings speed up training but may create conflicting gradients

- Failure signatures:
  - High training loss but low validation loss: Possible overfitting to BoW representation
  - Degraded recall at high k values: Layer sharing may be overly constraining representation capacity
  - Slow convergence: Embedding sharing conflicts or BoW sequence length too short

- First 3 experiments:
  1. Compare BoW sequence length (e.g., 50, 100, 200 stores) and measure recall@500
  2. Toggle layer sharing on/off and measure training speed and recall@20
  3. Add store frequency weighting to BoW and measure impact on low-cardinality store performance

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Unknown preprocessing pipeline for converting UUIDs to BoW sequences
- Unclear implementation details of layer sharing between towers
- No ablation studies or error analysis presented
- Limited direct precedent with only 8 relevant neighbors found

## Confidence
- High confidence: The 25x reduction in model size claim (directly stated and measurable)
- Medium confidence: The 10% Hit Rate@500 improvement (stated but lacks detailed validation)
- Low confidence: The 30% improvement in lower recall values and convergence speed claims (stated but not independently verified)

## Next Checks
1. Ablation study on BoW sequence length: Systematically vary the number of historical stores in the BoW representation and measure recall@500 to determine optimal sequence length and identify potential information loss thresholds.

2. Layer sharing necessity test: Train identical models with and without layer sharing on the same dataset, measuring both training convergence speed and final recall@500 to isolate the impact of shared embeddings.

3. User preference reconstruction test: For a sample of users, compare the BoW-based predictions against their actual ordering patterns to quantify information loss from replacing UUIDs with store histories, identifying failure cases where this proxy breaks down.