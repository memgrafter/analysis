---
ver: rpa2
title: Syntactic Transfer to Kyrgyz Using the Treebank Translation Method
arxiv_id: '2412.13146'
source_url: https://arxiv.org/abs/2412.13146
tags:
- kyrgyz
- syntactic
- language
- turkish
- treebank
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a tool for transferring syntactic annotations
  from Turkish to Kyrgyz using the treebank translation method. The approach leverages
  machine translation and word alignment to project dependency trees from a resource-rich
  source language to a low-resource target language.
---

# Syntactic Transfer to Kyrgyz Using the Treebank Translation Method

## Quick Facts
- **arXiv ID**: 2412.13146
- **Source URL**: https://arxiv.org/abs/2412.13146
- **Reference count**: 40
- **Primary result**: Syntactic annotation transfer from Turkish to Kyrgyz using treebank translation method achieved UAS scores up to 60.39% and LAS scores up to 48.25%, outperforming monolingual models.

## Executive Summary
This study presents a tool for transferring syntactic annotations from Turkish to Kyrgyz using the treebank translation method. The approach leverages machine translation and word alignment to project dependency trees from a resource-rich source language to a low-resource target language. The tool was evaluated on the Kyrgyz TueCL treebank, demonstrating higher syntactic annotation accuracy compared to a monolingual model trained on the Kyrgyz KTMU treebank. The method achieved UAS scores of up to 60.39% and LAS scores of up to 48.25%, with significant improvements observed when using specialized translation instructions. The study also introduces a method for assessing manual annotation complexity, contributing to the optimization of the annotation process for low-resource languages.

## Method Summary
The study employs a treebank translation method to transfer syntactic annotations from Turkish to Kyrgyz. The process involves translating Kyrgyz sentences to Turkish using GPT-4o with word order preservation instructions, parsing the Turkish translations using Stanza models, performing word alignment between Turkish and Kyrgyz sentences using SimAlign with XLM-RoBERTa embeddings, and projecting dependency annotations to Kyrgyz through heuristic-based alignment filtering and maximum matching. The projected annotations are evaluated against the TueCL gold standard using UAS, LAS, and UPOS metrics.

## Key Results
- UAS scores of up to 60.39% and LAS scores of up to 48.25% achieved using the treebank translation method
- Significant improvement over monolingual Stanza-KTMU-nocharlm baseline (UAS 50.74%, LAS 36.62%)
- Specialized translation instructions via GPT-4o provided noticeable improvement in quality, evident in consistently higher F1-scores for UAS, LAS, and UPOS metrics
- The method introduces a framework for assessing manual annotation complexity, contributing to optimization of the annotation process for low-resource languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Syntactic annotations can be transferred from Turkish to Kyrgyz because the languages are closely related in word order and agglutinative structure.
- Mechanism: Using machine translation to align sentences, then applying word alignment and dependency projection to transfer syntactic labels from the resource-rich source language to the target.
- Core assumption: Structural similarity between Turkish and Kyrgyz is sufficient for reliable annotation transfer.
- Evidence anchors:
  - [abstract] "The shared grammatical features of the selected languages, particularly their word order and agglutinative nature, facilitate cross-linguistic syntactic transfer."
  - [section] "The shared grammatical features of the selected languages, particularly their word order and agglutinative nature, facilitate cross-linguistic syntactic transfer."
  - [corpus] Weak: No explicit Turkish-Kyrgyz corpus alignment quality reported; relies on SimAlign and XLM-RoBERTa without fine-tuning.
- Break condition: If syntactic divergence increases or word alignment accuracy drops below a usable threshold.

### Mechanism 2
- Claim: Word alignment with multilingual embeddings (XLM-RoBERTa) provides sufficient accuracy for annotation transfer.
- Mechanism: SimAlign uses XLM-RoBERTa embeddings to generate many-to-many alignments, which are then filtered and matched to create a maximum bipartite matching for dependency projection.
- Core assumption: Multilingual embeddings capture enough syntactic similarity to enable accurate word-to-word correspondences.
- Evidence anchors:
  - [abstract] "Additionally, the study introduces a method for assessing the complexity of manual annotation for the resulting syntactic trees, contributing to further optimization of the annotation process."
  - [section] "For bitext alignment via multilingual embeddings without any fine-tuning, the XLM-RoBERTa model proved to be the most effective among those considered."
  - [corpus] Weak: No direct evaluation of alignment quality on a held-out set; assumes XLM-RoBERTa zero-shot performance is sufficient.
- Break condition: If alignment introduces too many mismatches, breaking the dependency tree structure.

### Mechanism 3
- Claim: Specialized machine translation instructions (preserve word order and token count) improve transfer accuracy.
- Mechanism: Prompting GPT-4o to produce Turkish translations that mimic Kyrgyz word order and token count, reducing syntactic drift during transfer.
- Core assumption: Minimizing translation-induced syntactic changes preserves the original dependency structure better than literal translation.
- Evidence anchors:
  - [abstract] "Additionally, the study introduces a method for assessing the complexity of manual annotation for the resulting syntactic trees, contributing to further optimization of the annotation process."
  - [section] "the use of machine translation with a special instruction via GPT4o provided a noticeable improvement in quality. This is clearly evident in the consistently higher F1-scores for UAS, LAS, and UPOS metrics."
  - [corpus] Weak: Only qualitative comparison between GPT-4o and other MT systems; no ablation study isolating the instruction effect.
- Break condition: If translation quality degrades or if preserving word order leads to ungrammatical Turkish, harming parser performance.

## Foundational Learning

- Concept: Dependency grammar and Universal Dependencies (UD) framework
  - Why needed here: The entire annotation transfer pipeline operates within UD formalism; understanding dependency relations and labels is essential for implementing the heuristics and interpreting evaluation metrics.
  - Quick check question: What is the difference between UAS and LAS in dependency parsing evaluation?

- Concept: Word alignment and bitext alignment techniques
  - Why needed here: Accurate word alignment is the backbone of annotation projection; without understanding how alignments are generated and filtered, it's impossible to debug transfer failures.
  - Quick check question: In a many-to-many alignment, how do you decide which edges to keep for projection?

- Concept: Machine translation and its impact on downstream NLP tasks
  - Why needed here: The quality of the translated source sentences directly affects parser input and thus the final projected annotations; knowing MT limitations is key to setting realistic expectations.
  - Quick check question: How might preserving word order in translation affect the grammaticality and parser performance of the translated text?

## Architecture Onboarding

- Component map: Kyrgyz sentences -> GPT-4o translation (with instruction) -> Turkish parsing (Stanza/UDPipe) -> SimAlign alignment (XLM-RoBERTa) -> Projection heuristics (head identification, alignment filtering, maximum matching, apertium-kir) -> UD evaluation -> Projected dependency trees

- Critical path:
  1. Translate Kyrgyz → Turkish (with instruction)
  2. Parse Turkish with Stanza/UDPipe
  3. Align Turkish ↔ Kyrgyz with SimAlign
  4. Project annotations via heuristics
  5. Evaluate against TueCL gold

- Design tradeoffs:
  - Simpler pipeline (no MT) → lower translation quality, higher syntactic mismatch
  - Use of apertium-kir for lemmas/UPOS → lower accuracy than dedicated taggers
  - Maximum matching alignment → loses some alignment info but guarantees acyclic trees
  - No language-specific heuristics → more universal but less optimized for Kyrgyz quirks

- Failure signatures:
  - Low UAS/LAS → likely due to poor alignment or translation quality
  - Zero or near-zero aux/compound labels → structural differences between languages (e.g., synthetic vs analytical forms)
  - High token mismatch → alignment failure or incorrect tokenization

- First 3 experiments:
  1. Run the pipeline on a small subset of TueCL with GPT-4o translation; compare UAS/LAS to baseline Stanza-KTMU-nocharlm.
  2. Replace GPT-4o with Google Translate (no special instruction); measure drop in UAS/LAS to quantify instruction benefit.
  3. Swap XLM-RoBERTa alignment for mBERT; compare alignment-based UAS/LAS to see if embeddings matter.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the source language selection impact the quality of syntactic transfer to Kyrgyz?
- Basis in paper: [inferred] The paper discusses Turkish as a source language but notes that experiments with other grammatically related languages are yet to be conducted.
- Why unresolved: The study only tested Turkish as the source language, leaving the impact of other potential source languages unexplored.
- What evidence would resolve it: Conducting experiments with multiple source languages (e.g., Kazakh, Uzbek) and comparing the quality of syntactic transfer results.

### Open Question 2
- Question: How effective are heuristic rules for multiword expression tokenization in improving syntactic transfer accuracy?
- Basis in paper: [explicit] The paper mentions that no additional heuristics were applied for tokenizing multiword expressions, which resulted in 19.3% of sentences being incorrectly tokenized.
- Why unresolved: The study did not implement or test heuristics for multiword expression tokenization, leaving their potential impact unexplored.
- What evidence would resolve it: Implementing and evaluating heuristic rules for multiword expression tokenization and measuring the improvement in syntactic transfer accuracy.

### Open Question 3
- Question: How does the quality of machine translation affect the overall syntactic transfer pipeline?
- Basis in paper: [explicit] The paper highlights that ChatGPT4o with a specific prompt improved translation quality, but notes that for some low-resource languages, machine translation quality remains low, which can significantly impact the final outcome.
- Why unresolved: The study used only one translation system (ChatGPT4o) and did not systematically evaluate the impact of translation quality on the final syntactic transfer results.
- What evidence would resolve it: Comparing the syntactic transfer results using different translation systems and measuring the correlation between translation quality and transfer accuracy.

## Limitations
- Reliance on high-quality machine translation between closely related languages without systematic evaluation of translation quality
- Word alignment process using XLM-RoBERTa embeddings lacks evaluation of alignment precision/recall
- Morphological analysis component uses apertium-kir, which provides "relatively low quality" lemma and UPOS tag assignments
- No quantitative measurement of linguistic divergence between Turkish and Kyrgyz to validate structural similarity assumptions

## Confidence

- **High Confidence**: The syntactic transfer method can improve annotation quality compared to monolingual models for low-resource languages. The UAS (60.39%) and LAS (48.25%) scores exceed the Stanza-KTMU-nocharlm baseline (UAS 50.74%, LAS 36.62%), and this improvement is statistically significant.

- **Medium Confidence**: Structural similarity between Turkish and Kyrgyz enables effective annotation transfer. While the paper asserts that shared word order and agglutinative structure facilitate transfer, it does not quantitatively measure linguistic divergence or alignment quality that would strengthen this claim.

- **Low Confidence**: Specialized translation instructions significantly improve transfer quality. The paper claims GPT-4o with word order preservation outperforms other MT systems, but provides only relative comparisons without ablation studies or statistical significance testing to isolate the instruction effect.

## Next Checks

1. **Alignment Quality Assessment**: Evaluate word alignment precision and recall on a held-out set of manually aligned Turkish-Kyrgyz sentence pairs to determine whether alignment errors or translation errors dominate the transfer pipeline failures.

2. **Translation Quality Evaluation**: Conduct human evaluation of Turkish translations produced by GPT-4o with and without special instructions to quantify how well word order and token count preservation actually works in practice.

3. **Ablation Study of Transfer Components**: Systematically remove or replace each component (MT, alignment, projection heuristics) to identify which contributes most to UAS/LAS improvements and determine whether the gains justify the complexity of the full pipeline.