---
ver: rpa2
title: Lifelong Event Detection via Optimal Transport
arxiv_id: '2410.08905'
source_url: https://arxiv.org/abs/2410.08905
tags:
- event
- language
- continual
- learning
- ledot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles continual event detection (CED), where catastrophic\
  \ forgetting hampers performance on previous tasks when learning new ones. The proposed\
  \ method, LEDOT, leverages optimal transport (OT) to align the classifier output\
  \ with the pre-trained language model\u2019s vocabulary distribution, mitigating\
  \ forgetting while enhancing task learning."
---

# Lifelong Event Detection via Optimal Transport

## Quick Facts
- **arXiv ID**: 2410.08905
- **Source URL**: https://arxiv.org/abs/2410.08905
- **Reference count**: 22
- **Primary result**: LEDOT outperforms state-of-the-art baselines on MAVEN and ACE datasets, improving F1 scores by up to 3.46% and achieving 1.22-1.67% gains when combined with SharpSeq

## Executive Summary
This paper addresses continual event detection (CED) by proposing LEDOT, a method that leverages optimal transport to mitigate catastrophic forgetting when learning new event types. The approach aligns classifier output with a frozen pre-trained language model's vocabulary distribution while integrating replay sets and prototype latent representations. LEDOT demonstrates superior performance on MAVEN and ACE datasets compared to existing baselines, and when combined with SharpSeq, achieves additional performance gains of 1.22% on MAVEN and 1.67% on ACE.

## Method Summary
LEDOT tackles continual event detection by freezing a BERT-large-cased encoder and language modeling head while fine-tuning a classifier head. The method combines replay buffers with prototype-based latent representations (mean and diagonal covariance of trigger representations per class) to generate synthetic samples during training. An optimal transport component aligns the classifier's softmax output with the PLM head's vocabulary distribution to preserve linguistic knowledge across tasks. The framework integrates cross-entropy loss, replay loss, knowledge distillation loss, OT loss, and regularization, optimized using AdamW with learning rate 1e-4 and weight decay 1e-2.

## Key Results
- LEDOT outperforms state-of-the-art baselines on MAVEN and ACE datasets
- Ablation studies confirm OT component reduces catastrophic forgetting, improving F1 scores by up to 3.46%
- When combined with SharpSeq, LEDOT achieves additional gains of 1.22% on MAVEN and 1.67% on ACE
- LEDOT demonstrates effectiveness in continual relation extraction, showing broader NLP applicability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal Transport aligns classifier output with pre-trained language model's vocabulary distribution, mitigating catastrophic forgetting.
- Mechanism: OT computes a transport plan between the classifier's softmax output and the PLM head's vocabulary distribution, ensuring task-specific knowledge integrates while preserving pre-existing linguistic understanding.
- Core assumption: The PLM head's vocabulary distribution encodes generalizable linguistic knowledge that can serve as a stable reference across tasks.
- Evidence anchors:
  - [abstract]: "that leverages optimal transport principles to align the optimization of our classification module with the intrinsic nature of each class, as defined by their pre-trained language modeling."
  - [section]: "By incorporating OT into the fine-tuning process, we aim to retain essential linguistic information from the PLM head, ensuring the model remains invariant to specific tasks."
  - [corpus]: "Double Mixture: Towards Continual Event Detection from Speech" suggests continuous adaptation challenges in event detection.
- Break condition: If the PLM head's vocabulary distribution becomes too task-specific or loses generalizability, the OT alignment loses its stabilizing effect.

### Mechanism 2
- Claim: Replay buffer with prototype latent representations reduces catastrophic forgetting more effectively than storing raw data samples.
- Mechanism: Instead of storing raw samples, the method retains prototype mean and diagonal covariance of trigger representations for each class, then generates synthetic samples during replay.
- Core assumption: Prototype statistics capture sufficient information about past tasks while being more memory-efficient than storing individual samples.
- Evidence anchors:
  - [section]: "we retain the prototype mean µ and diagonal covariance Σ of its trigger representations... During replay, synthetic samples are generated from these prototypes."
  - [abstract]: "Our method integrates replay sets, prototype latent representations, and an innovative Optimal Transport component."
  - [corpus]: "Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based approach" indicates pseudorehearsal effectiveness.
- Break condition: If prototype statistics become too noisy or unrepresentative due to task drift, synthetic sample generation may introduce harmful artifacts.

### Mechanism 3
- Claim: Sharpness-aware minimization combined with multi-objective optimization improves continual learning stability.
- Mechanism: SharpSeq integrates multi-objective optimization with sharpness-aware minimization to find flat minima along the Pareto front, reducing sensitivity to task changes.
- Core assumption: Flat minima provide better generalization and stability across sequential tasks compared to sharp minima.
- Evidence anchors:
  - [abstract]: "When combined with SharpSeq, it further boosts performance by 1.22% on MAVEN and 1.67% on ACE."
  - [section]: "SharpSeq (Le et al., 2024a) integrates multi-objective optimization (MOO) with sharpness-aware minimization (SAM)."
  - [corpus]: "Statistical Context Detection for Deep Lifelong Reinforcement Learning" suggests context detection challenges in lifelong learning.
- Break condition: If the optimization landscape becomes too complex or high-dimensional, SAM may fail to find meaningful flat regions.

## Foundational Learning

- Concept: Optimal Transport
  - Why needed here: Provides mathematical framework to measure and minimize distance between classifier output and PLM head distribution
  - Quick check question: What property of OT makes it suitable for aligning distributions with different supports?

- Concept: Catastrophic Forgetting
  - Why needed here: The primary problem LEDOT addresses in continual event detection
  - Quick check question: What are the three main approaches to mitigating catastrophic forgetting in continual learning?

- Concept: Prototype-based Replay
  - Why needed here: More memory-efficient alternative to storing raw samples while maintaining task information
  - Quick check question: How do prototype statistics (mean and covariance) capture information about a class's representation distribution?

## Architecture Onboarding

- Component map:
  PLM encoder (BERT-large-cased, frozen) -> Language modeling head (frozen) -> Classifier head (fine-tuned) -> Optimal Transport module -> Output
- Critical path: Input → PLM encoder → Language modeling head (frozen) → Classifier head → OT alignment → Output
- Design tradeoffs:
  - Frozen PLM vs fine-tuning: Preserves pre-trained knowledge vs adapting to task specifics
  - Prototype vs raw sample replay: Memory efficiency vs potential information loss
  - OT regularization strength: Balance between alignment and task adaptation
- Failure signatures:
  - Performance degradation on early tasks indicates catastrophic forgetting
  - Inconsistent OT alignment suggests vocabulary distribution mismatch
  - High variance in synthetic sample quality indicates problematic prototype statistics
- First 3 experiments:
  1. Baseline comparison: Run LEDOT vs KT on first two tasks only
  2. OT ablation: Test LEDOT with and without OT component on MAVEN
  3. Prototype ratio: Vary synthetic sample generation ratio (r) and measure impact on later tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LEDOT scale with larger language models, such as GPT-3 or GPT-4, compared to BERT?
- Basis in paper: [inferred] The paper discusses the limitations of large decoder-only language models like ChatGPT in information extraction tasks, suggesting that smaller but specialized models like BERT and T5 perform better. However, it does not explore the potential of using larger language models with LEDOT.
- Why unresolved: The paper focuses on empirical results using BERT as the backbone and does not investigate the scalability of LEDOT with larger language models.
- What evidence would resolve it: Conducting experiments with LEDOT using larger language models like GPT-3 or GPT-4 and comparing their performance to that of BERT would provide insights into the scalability and effectiveness of LEDOT with larger models.

### Open Question 2
- Question: What is the impact of different optimal transport distance metrics (e.g., Wasserstein distance) on the performance of LEDOT?
- Basis in paper: [explicit] The paper mentions the use of Sinkhorn distance as an entropic-constrained regularized optimal transport distance but does not explore other distance metrics like the Wasserstein distance.
- Why unresolved: The paper focuses on the Sinkhorn distance and does not investigate the effects of other optimal transport distance metrics on LEDOT's performance.
- What evidence would resolve it: Conducting experiments with LEDOT using different optimal transport distance metrics, such as the Wasserstein distance, and comparing their performance would provide insights into the impact of distance metrics on LEDOT's effectiveness.

### Open Question 3
- Question: How does the performance of LEDOT vary with different strategies for constructing the replay buffer, such as using a fixed-size buffer versus a prioritized buffer?
- Basis in paper: [inferred] The paper mentions the use of a replay buffer in LEDOT but does not explore different strategies for constructing the buffer, such as using a fixed-size buffer or a prioritized buffer based on sample importance.
- Why unresolved: The paper does not investigate the impact of different replay buffer construction strategies on LEDOT's performance.
- What evidence would resolve it: Conducting experiments with LEDOT using different replay buffer construction strategies, such as fixed-size versus prioritized buffers, and comparing their performance would provide insights into the impact of buffer strategies on LEDOT's effectiveness.

## Limitations
- The exact mechanism for generating synthetic samples from prototype statistics is not fully specified, potentially affecting reproducibility
- LEDOT's effectiveness depends on the assumption that the frozen PLM head's vocabulary distribution remains a stable reference across tasks
- The prototype-based replay approach trades memory efficiency for potential information loss, requiring careful tuning of the balance

## Confidence
- **High Confidence**: The baseline architecture using frozen PLM encoder with fine-tuned classifier is sound and well-established in continual learning literature
- **Medium Confidence**: The OT component's specific implementation details and its integration with other loss terms are described but lack complete implementation specifications
- **Low Confidence**: The exact preprocessing pipeline for MAVEN and ACE datasets, including how Oracle negative setting is implemented, remains unclear

## Next Checks
1. **OT Component Sensitivity**: Systematically vary the OT regularization weight and measure its impact on both catastrophic forgetting and task adaptation performance across multiple task sequences
2. **Prototype Quality Analysis**: Compare synthetic sample quality by measuring the distributional similarity between original samples and their prototype-generated counterparts using KL divergence or Wasserstein distance metrics
3. **Cross-Domain Generalization**: Test LEDOT on a third event detection dataset (e.g., TAC KBP) to validate whether the OT alignment and prototype mechanisms generalize beyond the original MAVEN and ACE domains