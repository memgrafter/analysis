---
ver: rpa2
title: 'Locally Measuring Cross-lingual Lexical Alignment: A Domain and Word Level
  Perspective'
arxiv_id: '2410.07239'
source_url: https://arxiv.org/abs/2410.07239
tags:
- alignment
- languages
- word
- lexical
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel methodology for analyzing cross-lingual
  lexical alignment at both the word and domain levels, using contextualized embeddings.
  The authors compare various metrics, including a novel approach based on contextualized
  word representations (SNC-CLOUD), and validate them against synthetic and naturalistic
  benchmarks, including a novel resource on lexical gaps in the kinship domain.
---

# Locally Measuring Cross-lingual Lexical Alignment: A Domain and Word Level Perspective

## Quick Facts
- arXiv ID: 2410.07239
- Source URL: https://arxiv.org/abs/2410.07239
- Reference count: 40
- Primary result: This paper proposes a novel methodology for analyzing cross-lingual lexical alignment at both the word and domain levels, using contextualized embeddings.

## Executive Summary
This paper introduces a novel approach to measuring cross-lingual lexical alignment that moves beyond global space alignment to examine local semantic neighborhoods. The authors propose the Semantic Neighborhood Comparison (SNC) framework, which compares the semantic neighborhoods of translation pairs across languages using contextualized embeddings. Their analysis spans 16 diverse languages and demonstrates substantial differences in alignment across semantic domains, with Quantity, Time, and Kinship showing the highest alignment. The study validates these metrics using both synthetic benchmarks and a novel naturalistic resource on lexical gaps in the kinship domain, revealing that contextualized embeddings provide more nuanced insights than static methods.

## Method Summary
The methodology involves computing cross-lingual alignment metrics using k-nearest neighbors (k=100) for words in source languages, translating these neighbors to target languages using the NorthEuraLex dataset, and calculating alignment through correlation between distance vectors. The paper implements multiple variants including SNC-STATIC (using fastText embeddings), SNC-AVE (averaging mBERT layers), and SNC-CLOUD (using contextualized embeddings with GMM clustering). Results are aggregated at both word and domain levels, with validation through synthetic shuffle baselines, sensitivity analysis, and comparison against lexical gaps in the kinship domain.

## Key Results
- Domain-level correlations between alignment metrics are consistently high (r = 0.93) across language pairs
- Quantity, Time, and Kinship domains show the highest lexical alignment scores, while Food, Politics, and Religion show the lowest
- Words undergoing faster lexical change show lower cross-lingual alignment, with a negative correlation between change rate and alignment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Semantic Neighborhood Comparison (SNC) approach leverages local distributional semantics to measure cross-lingual lexical alignment more effectively than global space alignment.
- Mechanism: SNC compares the semantic neighborhoods of translation pairs by measuring the correlation between the nearest neighbors of a word in one language and the translated nearest neighbors in another language. This captures subtle meaning variations that global alignment methods may smooth over.
- Core assumption: The semantic neighborhood structure of a word is preserved across languages to a degree that reflects lexical alignment.
- Evidence anchors:
  - [abstract] "cognitive science has long focused on a local perspective, investigating whether translation equivalents truly share the same meaning"
  - [section 2] "Global optimal alignment (one that minimizes the distance between the image of one language in the space of another language) may distort the alignment of some words subsets, in the interest of improving the alignment of other, larger word sets."
  - [corpus] Weak evidence - corpus analysis shows that nearest neighbor sets vary significantly across languages for semantically complex words, supporting the need for local comparison methods.
- Break condition: If translation equivalents have fundamentally different semantic neighborhood structures across languages due to cultural or conceptual differences, the correlation measure may not accurately reflect alignment.

### Mechanism 2
- Claim: Contextualized word embeddings provide more nuanced cross-lingual alignment measurements than static embeddings.
- Mechanism: By using contextualized representations, the alignment metrics can capture meaning variations that depend on context, which static embeddings cannot represent. This allows the SNC approach to better handle polysemy and context-dependent meaning differences.
- Core assumption: Contextualized embeddings preserve sufficient cross-lingual semantic consistency while capturing context-dependent variations.
- Evidence anchors:
  - [abstract] "our analysis spans 16 diverse languages, demonstrating that there is substantial room for improvement with the use of newer language models"
  - [section 4.2] "we introduce novel metrics based on contextualized word embedding"
  - [corpus] Moderate evidence - corpus analysis of mBERT embeddings shows that contextual information captures semantic nuances that static embeddings miss, particularly for words with multiple senses.
- Break condition: If contextualized embeddings introduce too much language-specific variation or fail to maintain consistent semantic relationships across languages, the alignment metrics may become unreliable.

### Mechanism 3
- Claim: Domain-level analysis provides more stable cross-lingual alignment measurements than word-level analysis.
- Mechanism: Aggregating alignment scores at the domain level reduces noise from individual word variations and reveals more consistent patterns of semantic alignment across languages. This stability makes domain-level analysis more suitable for drawing conclusions about cross-linguistic semantic similarity.
- Core assumption: Semantic domains represent coherent semantic spaces where alignment patterns are more consistent than at the individual word level.
- Evidence anchors:
  - [abstract] "domain-level correlations are high, suggesting domain-level analysis is more stable"
  - [section 6.1] "at the domain-level there is substantial similarity between the methods and that it offers a more stable level for such analysis"
  - [corpus] Strong evidence - corpus analysis shows high domain-level correlations (r = 0.93) between different alignment metrics, while word-level correlations remain moderate.
- Break condition: If semantic domains are not well-defined or contain words with fundamentally different alignment patterns, domain-level aggregation may obscure important variation.

## Foundational Learning

- Concept: Distributional semantics and the distributional hypothesis
  - Why needed here: The SNC approach fundamentally relies on the idea that word meaning can be characterized by the company it keeps - that words appearing in similar contexts have related meanings.
  - Quick check question: Why might two translation equivalents have different nearest neighbors in their respective languages, even if they refer to the same concept?

- Concept: Cross-lingual word embedding alignment techniques
  - Why needed here: Understanding both global (space alignment) and local (neighborhood comparison) approaches to cross-lingual alignment is crucial for appreciating why SNC offers advantages for lexical alignment.
  - Quick check question: What is the key difference between aligning entire embedding spaces versus comparing semantic neighborhoods of individual words?

- Concept: Polysemy and its impact on cross-lingual alignment
  - Why needed here: The paper discusses how polysemy affects alignment measurements and introduces metrics for quantifying polysemy based on word representations.
  - Quick check question: How might the polysemy of a word affect its cross-lingual alignment, and why would this be more problematic for static embeddings than contextualized ones?

## Architecture Onboarding

- Component map: Data preprocessing and concept mapping using NEL dataset -> Embedding extraction (static or contextualized) -> SNC metric computation with nearest neighbor search and correlation calculation -> Domain-level aggregation -> Validation using synthetic and naturalistic benchmarks
- Critical path: Concept mapping → Embedding extraction → Nearest neighbor computation → Correlation calculation → Domain aggregation → Validation comparison
- Design tradeoffs: The choice between static and contextualized embeddings involves a tradeoff between computational efficiency and semantic nuance capture. Domain-level aggregation trades granularity for stability. The k-nearest neighbors parameter involves a precision-recall tradeoff.
- Failure signatures: Low correlations between languages may indicate poor embedding quality or fundamentally different semantic structures. High variance in word-level results but low domain-level correlations may suggest domain definitions are too coarse or noisy.
- First 3 experiments:
  1. Implement SNC-STATIC with fastText embeddings on a small language pair (e.g., English-Spanish) and verify correlation calculations.
  2. Add SNC-CLOUD using mBERT embeddings and compare results with SNC-STATIC on the same language pair.
  3. Implement domain-level aggregation and test whether it stabilizes the correlation results compared to word-level analysis.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specific linguistic features (e.g., polysemy, frequency, concreteness) interact with cross-lingual alignment across different semantic domains?
- Basis in paper: [explicit] The paper shows that words undergoing faster lexical change are less aligned across languages, and that frequency and concreteness have varying effects on alignment metrics.
- Why unresolved: While the paper identifies correlations between lexical features and alignment, it does not explore the underlying mechanisms or how these features interact differently across domains.
- What evidence would resolve it: Detailed analysis of lexical feature distributions within each semantic domain, coupled with alignment metrics, could reveal domain-specific patterns and interactions.

### Open Question 2
- Question: Can the proposed alignment metrics be effectively extended to capture cultural knowledge encoded in large language models (LLMs)?
- Basis in paper: [explicit] The paper discusses the potential to use cross-lingual alignment to investigate cultural knowledge in LLMs, but does not provide concrete methods or results.
- Why unresolved: The paper establishes the groundwork for analyzing cross-lingual alignment but does not address how this approach can be adapted to assess cultural knowledge in LLMs, which often have different architectures and training data.
- What evidence would resolve it: Experiments applying the alignment metrics to LLMs and comparing results with traditional methods could demonstrate the feasibility and effectiveness of this extension.

### Open Question 3
- Question: How do different word embedding architectures (e.g., static vs. contextualized, autoregressive vs. non-autoregressive) impact the measurement of cross-lingual lexical alignment?
- Basis in paper: [explicit] The paper compares static and contextualized embeddings but does not explore the impact of autoregressive models like GPT.
- Why unresolved: The paper acknowledges the limitation of not being able to apply the metrics to autoregressive models and suggests future work in this direction, but does not provide insights into the potential differences in alignment measurements.
- What evidence would resolve it: Experiments applying the alignment metrics to autoregressive models and comparing results with non-autoregressive models could reveal the impact of architecture on alignment measurements.

## Limitations

- The NEL dataset's focus on the North Eurasian region may not generalize to non-Eurasian languages
- The contextual embedding approach (SNC-CLOUD) requires substantial computational resources due to sentence extraction and clustering requirements
- The reliance on back-translation for nearest neighbor comparison introduces uncertainty based on translation quality

## Confidence

**High Confidence (Strong empirical support):**
- Domain-level correlations between alignment metrics are consistently high across language pairs
- Quantity, Time, and Kinship domains show the highest lexical alignment scores
- Static and contextualized embeddings yield different alignment patterns for individual words

**Medium Confidence (Supported but with caveats):**
- The negative correlation between lexical change rate and alignment holds across most language pairs
- Contextualized embeddings provide more nuanced alignment measurements than static methods
- Domain-level analysis offers more stable insights than word-level analysis

**Low Confidence (Preliminary or methodologically constrained):**
- The extent to which SNC-CLOUD outperforms other metrics across all domains
- Generalizability of findings to languages outside the North Eurasian region
- The impact of varying k-nearest neighbors parameters on alignment stability

## Next Checks

1. **Cross-linguistic generalizability test**: Apply the SNC methodology to language pairs from non-Eurasian regions (e.g., Austronesian or Afro-Asiatic families) to assess whether the observed alignment patterns hold across different linguistic areas.

2. **Temporal stability validation**: Track alignment metrics over time using diachronic corpora to verify whether domains with higher lexical change rates show the predicted lower alignment scores, and whether these patterns remain consistent across historical periods.

3. **Human judgment benchmark**: Conduct a controlled study with bilingual speakers rating translation equivalence for randomly selected word pairs from high and low alignment domains to validate whether the SNC metrics accurately reflect human intuitions about cross-lingual semantic similarity.