---
ver: rpa2
title: Deep Bayesian Active Learning for Preference Modeling in Large Language Models
arxiv_id: '2406.10023'
source_url: https://arxiv.org/abs/2406.10023
tags:
- preference
- uncertainty
- learning
- bal-pm
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of reducing the human feedback
  required for preference modeling in Large Language Models (LLMs). The authors propose
  BAL-PM, a novel Bayesian Active Learning method that combines task-dependent epistemic
  uncertainty from a preference model with task-agnostic entropy estimation in the
  LLM's feature space.
---

# Deep Bayesian Active Learning for Preference Modeling in Large Language Models

## Quick Facts
- arXiv ID: 2406.10023
- Source URL: https://arxiv.org/abs/2406.10023
- Authors: Luckeciano C. Melo; Panagiotis Tigas; Alessandro Abate; Yarin Gal
- Reference count: 40
- Primary result: Reduces preference labels by 33%-68% compared to random sampling

## Executive Summary
This paper addresses the challenge of reducing human feedback requirements for preference modeling in Large Language Models (LLMs). The authors propose BAL-PM, a novel Bayesian Active Learning method that combines task-dependent epistemic uncertainty from a preference model with task-agnostic entropy estimation in the LLM's feature space. By maximizing the entropy of the acquired prompt distribution, BAL-PM encourages diversity and prevents the acquisition of redundant samples. The method demonstrates significant improvements in sample efficiency, reducing the number of preference labels needed by 33% to 68% compared to random sampling across two benchmark datasets.

## Method Summary
BAL-PM introduces a Bayesian Active Learning framework specifically designed for preference modeling in LLMs. The approach combines two key components: task-dependent epistemic uncertainty estimation from a Bayesian preference model and task-agnostic entropy estimation in the LLM's feature space. The method employs an ensemble of adapters trained on top of a pre-trained LLM to capture uncertainty, while entropy maximization ensures diversity in the acquired prompt distribution. The algorithm scales effectively to very large LLMs (7B, 70B, and 140B parameters) and maintains high diversity throughout the active learning process by preventing redundant sample acquisition.

## Key Results
- Reduces required preference labels by 33%-68% compared to random sampling on Reddit TL;DR and CNN/DM datasets
- Outperforms other Bayesian stochastic acquisition policies in terms of log-likelihood of learned preference models
- Maintains high ratio of unique prompts throughout training, demonstrating effective diversity preservation

## Why This Works (Mechanism)
BAL-PM works by leveraging two complementary uncertainty estimation strategies. The task-dependent component captures epistemic uncertainty specific to the preference modeling task through an ensemble of adapters on the LLM, allowing the system to identify ambiguous preference instances. The task-agnostic component estimates entropy in the LLM's feature space, which encourages the acquisition of diverse prompts that cover the input space more broadly. By combining these approaches, BAL-PM can identify both difficult preference decisions and novel prompt types, leading to more efficient learning with fewer human labels required.

## Foundational Learning
- **Epistemic Uncertainty**: Uncertainty due to limited data that can be reduced with more information. Needed to identify ambiguous preference instances that would be most informative for the model. Quick check: Verify that ensemble members disagree more on uncertain samples.
- **Entropy Maximization**: A measure of uncertainty or information content in a distribution. Needed to ensure diversity in acquired prompts and prevent redundant sampling. Quick check: Confirm that entropy of acquired prompt distribution increases over time.
- **Adapter Networks**: Small neural networks trained on top of frozen pre-trained models. Needed to efficiently adapt large LLMs to specific tasks without full fine-tuning. Quick check: Verify that adapter training converges faster than full model fine-tuning.
- **Active Learning**: Machine learning paradigm where the model selects which data to label. Needed to reduce human labeling effort by focusing on most informative samples. Quick check: Compare performance with random sampling baseline.
- **Feature Space Representation**: The embedding space where inputs are represented before classification/regression. Needed for computing semantic similarity and entropy in prompt space. Quick check: Visualize t-SNE embeddings of acquired vs. non-acquired prompts.
- **Ensemble Methods**: Multiple models trained to capture different aspects of uncertainty. Needed to provide robust uncertainty estimates for active learning acquisition. Quick check: Verify that ensemble predictions show higher variance on uncertain samples.

## Architecture Onboarding

Component Map:
Input Prompts -> LLM Feature Extractor -> Adapter Ensemble -> Epistemic Uncertainty Estimation -> Entropy Calculation -> Acquisition Function -> Selected Prompts

Critical Path:
Prompt → LLM Embeddings → Adapter Ensemble Predictions → Uncertainty Estimation → Entropy Calculation → BAL-PM Acquisition Score → Sample Selection

Design Tradeoffs:
The paper trades computational complexity (running multiple adapters and entropy calculations) for sample efficiency gains. Using adapters instead of full model fine-tuning reduces memory requirements but may limit the model's capacity to capture complex preference patterns. The entropy term introduces an additional hyperparameter (β) that requires tuning but enables diversity maintenance.

Failure Signatures:
- Poor uncertainty estimation due to inadequate ensemble training or feature representation quality
- Insufficient diversity in acquired prompts if entropy estimation is not properly implemented
- Computational bottlenecks when scaling to very large LLMs due to multiple forward passes

First Experiments:
1. Verify that the adapter ensemble produces meaningful uncertainty estimates by checking prediction variance on known ambiguous samples
2. Test entropy calculation in LLM feature space by comparing diversity metrics of BAL-PM vs. random acquisition
3. Run a small-scale active learning loop to confirm that BAL-PM converges faster than random sampling

## Open Questions the Paper Calls Out
None

## Limitations
- Implementation details of adapter network architecture and training procedure remain underspecified
- Hyperparameter tuning methodology for entropy term (β, k, dX) and baseline methods is not fully detailed
- Computational requirements for scaling to very large LLMs are not comprehensively characterized

## Confidence
- Claim cluster "33%-68% reduction in preference labels required": High confidence (supported by experimental results on two datasets)
- Claim cluster "outperforms other Bayesian stochastic acquisition policies": Medium confidence (benchmarked against multiple methods but lacks statistical significance testing)
- Claim cluster "maintains high ratio of unique prompts throughout training": Medium confidence (metric reported but no comparison to baseline diversity metrics)

## Next Checks
1. Implement ablation studies to quantify the individual contributions of task-dependent uncertainty versus task-agnostic entropy terms to the overall performance gain
2. Test BAL-PM on additional datasets beyond Reddit TL;DR and CNN/DM to verify generalizability across different preference modeling tasks
3. Conduct runtime and memory usage analysis for the different model scales (7B, 70B, 140B) to better characterize the computational overhead of the active learning framework