---
ver: rpa2
title: GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person Perspective
arxiv_id: '2408.13718'
source_url: https://arxiv.org/abs/2408.13718
tags:
- gpt-4
- appraisal
- emotion
- emotions
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how Large Language Models (LLMs) process emotions
  by comparing their performance to human judgments in two studies. The first study
  uses carefully crafted emotion-evoking stimuli to test GPT-4's ability to predict
  human appraisals and emotions, finding that GPT-4 aligns more closely with third-person
  perspectives than self-reported emotions.
---

# GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person Perspective

## Quick Facts
- arXiv ID: 2408.13718
- Source URL: https://arxiv.org/abs/2408.13718
- Reference count: 40
- GPT-4 aligns more closely with third-person emotional judgments than self-reported emotions

## Executive Summary
This paper investigates how Large Language Models process emotions by comparing GPT-4's performance to human judgments. Through two studies using different datasets, the researchers find that GPT-4's emotional interpretations align more closely with third-person observer perspectives than with self-reported emotions. The findings suggest that GPT-4 may be better suited for tasks requiring an average observer's perspective, such as social perception, rather than individual emotional recognition. This insight has important implications for deploying LLMs in applications involving emotional reasoning.

## Method Summary
The study employs zero-shot in-context learning with GPT-4, using carefully engineered prompts to elicit ratings on appraisal and emotion dimensions. Study 1 uses 200 crafted emotion-evoking stimuli with human ratings, while Study 2 uses the crowd-enVENT dataset with both author and reader annotations. The evaluation pipeline includes prompt engineering, feature selection to reduce appraisal space, correlation analysis between GPT-4 and human ratings, and classification tasks to assess prediction accuracy.

## Key Results
- GPT-4 outperforms humans in attributing emotions to crafted stimuli as intended by researchers
- GPT-4's appraisal-to-emotion mapping aligns with human observer patterns rather than self-reported emotions
- GPT-4 shows remarkable match with human appraisal-to-emotion mapping behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4's performance aligns more closely with third-person perspective judgments because it has internalized average human observational patterns rather than individual-specific emotional experiences.
- Mechanism: GPT-4 is trained on large-scale text corpora containing social perceptions and observations about emotions in others, embedding a "general observer" model of emotional attribution.
- Core assumption: GPT-4's training data includes sufficient examples of third-person emotional descriptions and judgments.
- Evidence anchors: [abstract] "GPT-4's interpretations align more closely with human judgments about the emotions of others than with self-assessments."
- Break condition: If GPT-4's training corpus contains proportionally more first-person emotional narratives than third-person observations.

### Mechanism 2
- Claim: GPT-4 excels at recognizing emotions in carefully crafted stereotypical scenarios more than in spontaneous free-form self-reports because the crafted stimuli encode emotion-eliciting patterns that match learned associations.
- Mechanism: Carefully crafted stimuli are designed with explicit patterns that map to specific emotions through appraisal variables, which GPT-4 recognizes from training data.
- Core assumption: The crafted stimuli encode emotion-eliciting patterns representative of patterns in GPT-4's training corpus.
- Evidence anchors: [abstract] "We show that GPT-4 is especially accurate in reasoning about such stimuli."
- Break condition: If the crafted stimuli patterns are too artificial or don't reflect natural language patterns GPT-4 encountered during training.

### Mechanism 3
- Claim: GPT-4's appraisal-to-emotion mapping aligns with appraisal theory because it has learned the statistical regularities between situational descriptions and emotional outcomes present in training data.
- Mechanism: GPT-4 has been exposed to vast amounts of text describing situations and associated emotions, implicitly learning which appraisal patterns lead to which emotions.
- Core assumption: Training data contains sufficient examples of situations described with both appraisal-relevant details and emotional outcomes.
- Evidence anchors: [abstract] "GPT-4's interpretations align more closely with human judgments about the emotions of others than with self-assessments."
- Break condition: If GPT-4's training data lacks sufficient diversity in situational descriptions and emotional outcomes.

## Foundational Learning

- Concept: Appraisal Theory
  - Why needed here: Understanding appraisal theory is crucial because the paper uses it as the theoretical framework for comparing human and LLM emotional reasoning.
  - Quick check question: What are the key appraisal variables mentioned in the paper that GPT-4 was evaluated on, and how do they theoretically relate to specific emotions?

- Concept: Zero-shot In-context Learning
  - Why needed here: The paper evaluates GPT-4 using zero-shot in-context learning with carefully engineered prompts.
  - Quick check question: How does zero-shot in-context learning differ from fine-tuning, and why might this approach be particularly suitable for evaluating emotional reasoning in LLMs?

- Concept: Third-person vs. First-person Perspective in Emotion Attribution
  - Why needed here: The paper's key finding is that GPT-4 aligns more with third-person perspective judgments.
  - Quick check question: What are the main differences between first-person self-reported emotions and third-person observer judgments, and why might these differences matter for LLM applications?

## Architecture Onboarding

- Component map: Stimulus preparation -> Prompt engineering -> GPT-4 rating generation -> Human rating comparison -> Appraisal-to-emotion mapping analysis
- Critical path: The prompt engineering step is most critical as it directly determines what information GPT-4 receives and how it processes the scenarios.
- Design tradeoffs: Using carefully crafted stimuli provides controlled conditions but may not reflect real-world complexity; using self-reported narratives captures authenticity but introduces individual variability.
- Failure signatures: Low correlation between GPT-4 and human ratings could indicate prompt engineering issues or fundamental differences in emotional processing.
- First 3 experiments:
  1. Replicate the appraisal derivation analysis with different prompt formulations to test sensitivity to prompt engineering.
  2. Test GPT-4's performance on stimuli with varying levels of contextual detail to understand information needs for accurate emotion recognition.
  3. Compare GPT-4's appraisal-to-emotion mapping with different computational models of emotion to identify specific areas of alignment and divergence.

## Open Questions the Paper Calls Out

- To what extent do cultural and demographic differences influence how LLMs like GPT-4 interpret emotional situations, and how can these models be adapted to account for such variations?
- How can individual variability in emotional experiences be better incorporated into LLMs to improve their accuracy in personal contexts?
- What are the potential ethical implications of using third-person perspectives in emotional reasoning by LLMs, and how can these models be designed to avoid perpetuating biases in social perceptions?

## Limitations

- The carefully engineered nature of the stimuli may not generalize to real-world emotional reasoning scenarios.
- The comparison between GPT-4 and human ratings relies on specific prompt formulations whose exact details are not fully specified.
- The study primarily focuses on general patterns of emotional cognition and does not delve into cultural or demographic nuances.

## Confidence

- High confidence: The core finding that GPT-4 aligns more closely with third-person observer judgments than self-assessments
- Medium confidence: The interpretation that GPT-4 has internalized average human observational patterns
- Medium confidence: The claim that GPT-4 excels at recognizing emotions in crafted scenarios more than spontaneous self-reports

## Next Checks

1. **Prompt sensitivity analysis**: Systematically vary the prompt formulations used to elicit ratings from GPT-4 to determine how robust the findings are to different phrasings and instructions.

2. **Cross-cultural generalization test**: Evaluate GPT-4's performance on emotion recognition tasks using stimuli from different cultural contexts to determine whether its third-person perspective is culturally specific or universal.

3. **Temporal dynamics investigation**: Test GPT-4's ability to track emotional changes over time by presenting scenarios that evolve and require tracking of both situational changes and resulting emotional shifts.