---
ver: rpa2
title: Lifelong Learning and Selective Forgetting via Contrastive Strategy
arxiv_id: '2405.18663'
source_url: https://arxiv.org/abs/2405.18663
tags:
- classes
- forgetting
- learning
- class
- deleted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a contrastive strategy for learning with selective
  forgetting (LSF). The method makes features of preserved classes compacted while
  features of deleted classes are dispersed and irregular, enabling selective forgetting.
---

# Lifelong Learning and Selective Forgetting via Contrastive Strategy

## Quick Facts
- arXiv ID: 2405.18663
- Source URL: https://arxiv.org/abs/2405.18663
- Authors: Lianlei Shan; Wenzhang Zhou; Wei Li; Xingyu Ding
- Reference count: 23
- Primary result: Achieves new state-of-the-art results for lifelong selective forgetting (LSF) on three classification and one segmentation benchmark datasets

## Executive Summary
This paper introduces a novel contrastive strategy for learning with selective forgetting (LSF) in lifelong learning scenarios. The method achieves selective forgetting by compacting features of preserved classes while dispersing and irregularizing features of deleted classes. The approach demonstrates superior performance across multiple benchmarks, outperforming existing methods in terms of the harmonic mean of average accuracy for preserved classes and forgetting measure for deleted classes. Notably, the method is described as effective, efficient, and universal since it operates directly on the feature extraction part of neural networks.

## Method Summary
The proposed method employs a contrastive learning strategy to achieve selective forgetting in lifelong learning scenarios. By manipulating the feature space during training, the approach ensures that preserved classes maintain compact feature representations while deleted classes have dispersed and irregular representations. This contrastive manipulation enables the model to retain knowledge about preserved classes while effectively forgetting information about deleted classes. The method operates directly on the feature extraction components of neural networks, making it applicable across various architectures without requiring modifications to the classification head or other network components.

## Key Results
- Achieves new state-of-the-art performance for LSF on three classification and one segmentation benchmark datasets
- Outperforms existing methods in terms of harmonic mean of average accuracy for preserved classes
- Demonstrates superior forgetting measure for deleted classes compared to baseline approaches

## Why This Works (Mechanism)
The contrastive strategy works by creating a deliberate separation in the feature space between preserved and deleted classes. For preserved classes, the method encourages feature compactness, meaning similar samples from the same class are mapped close together in the feature space. Conversely, for deleted classes, the method promotes feature dispersion and irregularity, pushing samples from these classes to occupy disparate regions in the feature space. This architectural manipulation during training effectively encodes the selective forgetting behavior into the model's feature extractor. The contrastive loss functions guide the network to strengthen representations for preserved classes while weakening and scattering representations for deleted classes, achieving the desired selective forgetting without requiring explicit negative data sampling from deleted classes.

## Foundational Learning
- Lifelong Learning: The ability of models to learn continuously from sequential tasks while maintaining performance on previous tasks; needed to understand the broader context of sequential learning challenges
- Selective Forgetting: The capability to deliberately erase knowledge about specific classes or tasks while preserving others; critical for privacy, model maintenance, and adapting to changing requirements
- Contrastive Learning: A training paradigm that learns representations by comparing similar and dissimilar pairs; essential for understanding how the method manipulates feature spaces
- Feature Compactness: The property of similar samples being mapped close together in feature space; key to understanding how preserved classes maintain their integrity
- Feature Dispersion: The spreading of dissimilar samples across feature space; important for understanding how deleted class information becomes inaccessible
- Harmonic Mean in Evaluation: A metric that balances precision and recall; used here to fairly assess both preservation of useful knowledge and successful forgetting

## Architecture Onboarding

**Component Map:**
Input -> Feature Extractor -> Contrastive Loss (for both preserved and deleted classes) -> Classifier Head

**Critical Path:**
The critical path flows through the feature extractor where the contrastive strategy is applied, as this is where the selective forgetting behavior is encoded. The contrastive losses for preserved and deleted classes are computed on the feature representations before classification.

**Design Tradeoffs:**
The method trades computational complexity during training (additional contrastive loss computation) for improved lifelong learning performance and selective forgetting capability. The approach requires careful balancing of contrastive loss weights to ensure effective forgetting without compromising preservation of important knowledge.

**Failure Signatures:**
- If the contrastive loss for deleted classes is too weak, selective forgetting may be incomplete
- If the contrastive loss for preserved classes is too strong, the model may become overly specialized and lose generalization ability
- Imbalance between preserved and deleted class samples could lead to suboptimal feature space manipulation

**First 3 Experiments to Run:**
1. Ablation study varying the strength of contrastive loss for preserved vs. deleted classes to find optimal balance
2. Evaluation on a held-out dataset to test for unintended forgetting of non-target information
3. Runtime comparison between standard training and contrastive strategy training to quantify computational overhead

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness across diverse domains and architectures remains to be thoroughly evaluated, as experiments primarily focus on classification and segmentation with standard CNN architectures
- Computational efficiency gains are not quantified, raising questions about scalability to larger models and datasets
- Method's behavior with overlapping classes between preserved and deleted sets is not addressed, which could be critical for practical applications

## Confidence
High - The method's core contribution and experimental results are well-documented and reproducible.
Medium - The claims about universality and computational efficiency require further validation.
Low - The long-term effects of selective forgetting and behavior with overlapping classes need investigation.

## Next Checks
1. Test the method on diverse architectures (transformers, recurrent networks) and non-image domains to verify universality claims.
2. Conduct experiments with overlapping classes between preserved and deleted sets to assess robustness in practical scenarios.
3. Perform ablation studies to quantify the contribution of the contrastive strategy component and assess computational overhead compared to baseline methods.