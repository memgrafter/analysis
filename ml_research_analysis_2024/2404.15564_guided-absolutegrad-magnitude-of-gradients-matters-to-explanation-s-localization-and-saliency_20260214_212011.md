---
ver: rpa2
title: 'Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation''s Localization
  and Saliency'
arxiv_id: '2404.15564'
source_url: https://arxiv.org/abs/2404.15564
tags:
- saliency
- gradient
- area
- noise
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Guided AbsoluteGrad, a gradient-based XAI method
  that leverages both positive and negative gradient magnitudes to improve saliency
  map explanations. The method uses gradient variance as a guide to filter noise,
  producing more accurate and visually cleaner explanations.
---

# Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency

## Quick Facts
- arXiv ID: 2404.15564
- Source URL: https://arxiv.org/abs/2404.15564
- Reference count: 33
- Key outcome: Guided AbsoluteGrad outperforms seven state-of-the-art gradient-based methods in RCAP and other metrics by leveraging both positive and negative gradient magnitudes and gradient variance for noise reduction.

## Executive Summary
This paper proposes Guided AbsoluteGrad, a gradient-based XAI method that improves saliency map explanations by utilizing both positive and negative gradient magnitudes and gradient variance to filter noise. The method introduces a novel evaluation metric, ReCover And Predict (RCAP), which jointly assesses localization and visual noise level objectives. Experiments across three datasets (ImageNet-S, ISIC, Places365) with three models (ResNet50, EfficientNet, DenseNet161) demonstrate that Guided AbsoluteGrad outperforms seven state-of-the-art gradient-based methods in terms of RCAP and other metrics, validating the effectiveness of using gradient magnitude for feature attribution.

## Method Summary
Guided AbsoluteGrad processes gradients by modifying inputs with Gaussian noise, computing absolute gradients, calculating gradient variance as a guide, filtering with variance guide at a percentile threshold, and aggregating filtered gradients. The method leverages both positive and negative gradient magnitudes while using gradient variance to distinguish important areas from noise. The novel RCAP metric evaluates explanations by recovering features in partitions ordered by saliency and combining saliency ratio with prediction confidence, providing a comprehensive assessment of localization and visual noise.

## Key Results
- Guided AbsoluteGrad surpasses seven state-of-the-art gradient-based methods across three datasets and three model architectures
- The method demonstrates superior performance in RCAP metric, which jointly evaluates localization and visual noise level
- Gradient magnitude proves more informative than gradient sign alone for feature importance, validated through theoretical propositions and empirical results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient magnitude (both positive and negative) is a better feature importance indicator than gradient sign alone.
- Mechanism: Uses |∇fc| to measure feature influence regardless of sign, avoiding discarding potentially important negative contributions.
- Core assumption: Gradient magnitude correlates with feature importance even when sign is negative.
- Evidence anchors: [abstract] "We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction." [section 2.1] "the magnitude may be far more telling feature importance than the direction of the gradient."

### Mechanism 2
- Claim: Gradient variance can act as a guide to filter out noise and highlight stable, important features.
- Mechanism: Features with high gradient variance across perturbations are considered more important due to their sensitivity to modifications.
- Core assumption: More important features show larger gradient variation when input is perturbed.
- Evidence anchors: [section 3.2] "We leverage the variance of Mnc(x,γ) to filter the features. This is based on the idea that features with fierce gradient variation determine if they are important or not."

### Mechanism 3
- Claim: RCAP metric jointly evaluates localization and visual noise by combining saliency ratio and prediction confidence.
- Mechanism: Recovers features in saliency-ordered partitions, then multiplies partition saliency ratio by prediction confidence on recovered image.
- Core assumption: Prediction confidence on recovered images approximates overlap between saliency map's focus area and ground truth area.
- Evidence anchors: [section 4.2] "RCAP (M) = 1/j Σ [ (P Mpk / P M) × σ(fc(Ipk)) ]" and explanation that this combines visual noise level and localization.

## Foundational Learning

- Concept: Gradient-based saliency maps
  - Why needed here: The entire method builds on gradient-based XAI techniques, so understanding how gradients are computed and used for feature attribution is essential.
  - Quick check question: What is the difference between Vanilla Gradient and SmoothGrad in how they compute saliency maps?

- Concept: Feature importance and noise in explanations
  - Why needed here: The paper argues that both magnitude and variance of gradients matter for distinguishing important features from noise.
  - Quick check question: Why might a high-magnitude gradient not always indicate a truly important feature?

- Concept: Evaluation metrics for saliency maps
  - Why needed here: RCAP is a novel metric, so understanding the limitations of existing metrics (like DAUC/IAUC and ROAR) is key to appreciating its contribution.
  - Quick check question: What is the main limitation of DAUC/IAUC when evaluating saliency maps?

## Architecture Onboarding

- Component map: Input modification (γ) -> Gradient computation -> Absolute gradient -> Variance calculation -> Variance guide -> Aggregation -> Normalization
- Critical path: 1. Modify input multiple times 2. Compute gradients for each modification 3. Take absolute gradients and compute variance 4. Apply variance guide 5. Aggregate and normalize for final saliency map
- Design tradeoffs: Using absolute gradients increases noise sensitivity; variance guide mitigates this. More modifications improve variance estimation but increase compute cost. Threshold percentile must be tuned per dataset/model.
- Failure signatures: Saliency map is blank (variance guide threshold too high); Saliency map is noisy (variance guide threshold too low); RCAP is low despite good-looking saliency (prediction confidence doesn't correlate with ground truth coverage).
- First 3 experiments: 1. Run Guided AbsoluteGrad with p=0 and p=85 on ImageNet-S subset; compare RCAP and visual quality. 2. Compare RCAP vs DAUC/IAUC on saliency maps with known noise levels. 3. Swap high and low saliency values in good saliency map and check if RCAP decreases as predicted.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does Guided AbsoluteGrad maintain performance advantage across different model architectures beyond ResNet50, EfficientNet, and DenseNet161?
- Basis in paper: [explicit] Authors state method "surpasses other gradient-based approaches" across three datasets and three models, but don't test broader range of architectures.
- Why unresolved: Evaluation limited to three specific model architectures, leaving uncertainty about generalizability.
- What evidence would resolve it: Testing on wider variety of architectures (Vision Transformers, MobileNet, VGG) while maintaining performance advantages.

### Open Question 2
- Question: How does Guided AbsoluteGrad perform on datasets with significantly different characteristics than those tested?
- Basis in paper: [explicit] Authors test on three specific datasets but acknowledge need to evaluate across different data contexts in discussion of negative gradient interpretations.
- Why unresolved: Evaluation limited to three similar datasets, leaving uncertainty about performance on very different data types.
- What evidence would resolve it: Testing on datasets with significantly different properties (texture, resolution, domain) while maintaining performance advantages.

### Open Question 3
- Question: What is the computational overhead of Guided AbsoluteGrad compared to other gradient-based methods?
- Basis in paper: [inferred] Authors describe using 20 modifications per sample and additional processing steps but don't provide runtime comparisons.
- Why unresolved: Paper focuses on accuracy metrics but doesn't discuss computational cost or efficiency implications.
- What evidence would resolve it: Empirical measurements of computation time per sample for Guided AbsoluteGrad versus other gradient-based methods under identical hardware conditions.

## Limitations
- Performance evaluation limited to three model architectures, leaving generalizability uncertain
- No computational efficiency analysis provided for the additional processing steps
- RCAP's assumption about prediction confidence approximating ground truth coverage is plausible but unverified across diverse object types

## Confidence

- **High**: Guided AbsoluteGrad outperforms existing gradient-based methods in RCAP and other metrics across multiple datasets and models
- **Medium**: Gradient magnitude is more informative than gradient sign for feature importance; gradient variance effectively filters noise
- **Low**: RCAP perfectly balances localization and visual noise objectives in all scenarios

## Next Checks

1. **Ablation on gradient magnitude vs sign**: Run Guided AbsoluteGrad with and without absolute value on gradient computation, keeping all else equal, to directly measure contribution of magnitude over sign.

2. **Robustness of RCAP to object diversity**: Evaluate RCAP on datasets with varying object sizes, textures, and occlusion patterns to test whether prediction confidence consistently reflects ground truth coverage.

3. **Variance guide sensitivity analysis**: Systematically vary percentile threshold (p) in variance guide across wider range (50-95) and measure impact on RCAP and visual quality to identify optimal settings per dataset/model.