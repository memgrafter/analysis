---
ver: rpa2
title: MGDA Converges under Generalized Smoothness, Provably
arxiv_id: '2405.19440'
source_url: https://arxiv.org/abs/2405.19440
tags:
- have
- distance
- gradient
- where
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the convergence of the fundamental multiple\
  \ gradient descent algorithm (MGDA) for multi-objective optimization (MOO) under\
  \ a generalized \u2113-smoothness condition, which is more general and realistic\
  \ than the standard smoothness assumptions used in prior work. The authors analyze\
  \ both deterministic and stochastic variants of MGDA, including a warm start process\
  \ and an efficient variant (MGDA-FA) that reduces computational and memory costs\
  \ from O(K) to O(1) without sacrificing performance guarantees."
---

# MGDA Converges under Generalized Smoothness, Provably

## Quick Facts
- arXiv ID: 2405.19440
- Source URL: https://arxiv.org/abs/2405.19440
- Authors: Qi Zhang; Peiyao Xiao; Shaofeng Zou; Kaiyi Ji
- Reference count: 40
- Key outcome: MGDA converges to ϵ-accurate Pareto stationary point with ϵ-level average CA distance under generalized smoothness, requiring O(ϵ⁻²) deterministic and O(ϵ⁻⁴) stochastic samples

## Executive Summary
This paper establishes convergence guarantees for the Multiple Gradient Descent Algorithm (MGDA) under a generalized ℓ-smoothness condition, which is more general than standard smoothness assumptions. The authors analyze both deterministic and stochastic variants of MGDA, including a warm start process and an efficient MGDA-FA variant that reduces computational complexity. They prove convergence to Pareto stationary points with bounded conflict-avoidant (CA) distances, validated through experiments on Cityscapes and NYU-v2 datasets showing improved multi-task performance.

## Method Summary
The method involves a warm start process using projected gradient descent to initialize weights close to optimal, followed by MGDA iterations that update model parameters along the CA direction and weights via gradient-based optimization. The algorithm operates under generalized ℓ-smoothness, where the Lipschitz constant can be unbounded but relates to gradient norms. MGDA-FA uses Taylor approximation to reduce computational and memory costs from O(K) to O(1) while maintaining performance guarantees. The stochastic variant employs double sampling for unbiased gradient estimates.

## Key Results
- MGDA converges to ϵ-accurate Pareto stationary point with ϵ-level average CA distance
- Deterministic setting requires O(ϵ⁻²) samples; stochastic setting requires O(ϵ⁻⁴) samples
- With warm start, iteration-wise CA distance achieves O(ϵ) at cost of O(ϵ⁻¹¹) deterministic and O(ϵ⁻¹⁷) stochastic samples
- MGDA-FA variant achieves same performance guarantee with O(1) time and space complexity
- Experiments show MGDA-warm start achieves more balanced performance on Cityscapes and NYU-v2 datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Warm start achieves bounded CA distance by initializing weights close to optimal
- **Mechanism:** Uses projected gradient descent to find weight close to optimal, reducing initial CA distance and maintaining small CA distance throughout iterations
- **Core assumption:** Warm start can find weight close to optimal within reasonable iterations
- **Evidence anchors:** Abstract mentions warm start for aggressive ϵ-level iteration-wise CA distance; section explains how random initialization leads to constant CA distance initially
- **Break condition:** Warm start fails to find optimal weight, CA distance remains unbounded

### Mechanism 2
- **Claim:** Convergence under generalized smoothness via bounded function values implying bounded gradient norms
- **Mechanism:** Uses induction to show selected parameters lead to bounded function values, which implies bounded gradient norms, handling potentially unbounded Lipschitz constant
- **Core assumption:** Function values bounded for selected parameters
- **Evidence anchors:** Abstract states vanilla MGDA converges to ϵ-accurate Pareto stationary point; section explains bounded function value implies bounded gradient norm via induction
- **Break condition:** Function values unbounded for selected parameters, gradient norms unbounded, algorithm diverges

### Mechanism 3
- **Claim:** MGDA-FA achieves same performance with reduced computational costs
- **Mechanism:** Uses Taylor approximation to approximate gradient for weight updates, reducing need to compute/store all task gradients
- **Core assumption:** Taylor approximation accurate enough to maintain performance guarantee
- **Evidence anchors:** Abstract states MGDA-FA uses O(1) time and space while achieving same performance; section describes FA using gradient of F(xt)wt and forward processes for F(xt+1)
- **Break condition:** Taylor approximation inaccurate, performance guarantee not maintained

## Foundational Learning

- **Concept:** Generalized smoothness
  - **Why needed here:** Handles potentially unbounded Lipschitz constant in generalized smoothness setting
  - **Quick check question:** What is the difference between standard L-smoothness and generalized ℓ-smoothness?

- **Concept:** Pareto stationary point
  - **Why needed here:** Algorithm aims to find point where no objective can be improved without compromising others
  - **Quick check question:** What is the definition of a Pareto stationary point?

- **Concept:** Conflict-avoidant (CA) direction
  - **Why needed here:** Maximizes minimum improvement among objectives, mitigating gradient conflict
  - **Quick check question:** What is the definition of a CA direction?

## Architecture Onboarding

- **Component map:** Warm start process -> Main MGDA loop (weight update + model parameter update) -> Optional MGDA-FA approximation
- **Critical path:** Main loop updating weight and model parameters using CA direction
- **Design tradeoffs:** MGDA-FA trades computational/memory costs for performance; warm start trades additional computation for improved performance
- **Failure signatures:** Unbounded function values leading to gradient norm issues; warm start failing to find optimal weight; inaccurate Taylor approximation
- **First 3 experiments:**
  1. Run algorithm on simple multi-objective problem with known Pareto points to verify convergence
  2. Vary parameters (step sizes, regularization) to study impact on performance and convergence
  3. Compare MGDA-FA performance to vanilla MGDA on large-scale multi-objective problem

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does MGDA-FA achieve same iteration-wise CA distance guarantees as vanilla MGDA with warm start under generalized ℓ-smoothness?
- **Basis in paper:** Theorem 5 states MGDA-FA achieves ∥∇F(xt)wt − ∇F(xt)w*t∥ = O(ϵ) with warm start, matching Theorem 3 guarantees
- **Why unresolved:** Paper proves MGDA-FA achieves same bound but doesn't empirically verify or compare convergence behavior
- **What evidence would resolve it:** Experimental comparison showing equivalent iteration-wise CA distance behavior with convergence curves

### Open Question 2
- **Question:** Can sample complexity for iteration-wise CA distance be reduced below O(ϵ⁻¹⁷) in stochastic setting?
- **Basis in paper:** Achieving iteration-wise CA distance requires mini-batching with ns = Ω(ϵ⁻⁶), increasing complexity to O(ϵ⁻¹⁷)
- **Why unresolved:** Authors identify mini-batching necessity but don't explore alternatives that might reduce overhead
- **What evidence would resolve it:** Analysis of stochastic variants using variance reduction, control variates, or adaptive mini-batching with lower sample complexity

### Open Question 3
- **Question:** How does MGDA convergence rate under generalized ℓ-smoothness compare to specialized methods for specific ℓ-smooth functions?
- **Basis in paper:** Analyzes most general ℓ-smooth setting without investigating potential rate penalties versus exploiting specific function structure
- **Why unresolved:** Analysis works for any continuous non-decreasing ℓ function but generality may obscure improvements from knowing specific form
- **What evidence would resolve it:** Comparative convergence rate analysis showing when specialized algorithms outperform general MGDA

## Limitations
- Generalized smoothness assumption's practical applicability across diverse multi-task scenarios remains unverified
- Double sampling strategy implementation details for stochastic gradients are not fully specified
- MGDA-FA algorithm details referenced but not fully provided in main paper

## Confidence
- Theoretical claims (deterministic): High confidence (clear proof strategy following standard optimization analysis)
- Theoretical claims (stochastic): Medium confidence (complexity of unbiased gradient estimates with incomplete implementation details)
- Warm start effectiveness: High confidence (explicit mathematical analysis for O(ϵ) iteration-wise CA distance)
- MGDA-FA convergence guarantee: Medium confidence (conceptually sound but incomplete approximation error bounds)

## Next Checks
1. **Smoothness Verification**: Systematically measure local smoothness constants and gradient norms across all task pairs on both datasets to empirically validate (L₀, L₁)-smoothness pattern
2. **Stochastic Sampling Implementation**: Implement and test double sampling strategy with controlled variance reduction experiments to verify unbiased gradient estimates and convergence stability
3. **Algorithm 4 Reconstruction**: Fully implement MGDA-FA from referenced Algorithm 4, comparing computational efficiency and convergence properties against vanilla MGDA on benchmark multi-task problem