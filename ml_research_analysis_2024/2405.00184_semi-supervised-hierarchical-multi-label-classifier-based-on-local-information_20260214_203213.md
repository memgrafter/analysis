---
ver: rpa2
title: Semi-Supervised Hierarchical Multi-Label Classifier Based on Local Information
arxiv_id: '2405.00184'
source_url: https://arxiv.org/abs/2405.00184
tags:
- hierarchical
- labeled
- data
- instances
- unlabeled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of semi-supervised hierarchical
  multi-label classification, focusing on the most difficult case where the hierarchy
  is a Directed Acyclic Graph (DAG) and instances can be associated with multiple
  paths of labels. The authors propose SSHMC-BLI, a method that pseudo-labels unlabeled
  data by leveraging the labels of its labeled neighbors while considering the similarity
  between instances.
---

# Semi-Supervised Hierarchical Multi-Label Classifier Based on Local Information

## Quick Facts
- **arXiv ID**: 2405.00184
- **Source URL**: https://arxiv.org/abs/2405.00184
- **Reference count**: 33
- **Primary result**: SSHMC-BLI outperforms supervised hierarchical classifiers on Gene Ontology datasets in semi-supervised settings

## Executive Summary
This paper introduces SSHMC-BLI, a semi-supervised hierarchical multi-label classification method designed for Directed Acyclic Graph (DAG) label hierarchies where instances can have multiple label paths. The method addresses the challenging scenario where only a small fraction of training data is labeled, using pseudo-labeling of unlabeled instances based on their similarity to labeled neighbors while respecting hierarchical constraints. Experiments on 12 Gene Ontology datasets demonstrate significant improvements over both standard semi-supervised methods and supervised baselines when labeled data is limited.

## Method Summary
SSHMC-BLI leverages local information by pseudo-labeling unlabeled instances based on the labels of their labeled neighbors while considering instance similarity. The method operates in a semi-supervised framework where a small set of labeled instances is augmented with pseudo-labels for unlabeled data. For hierarchical multi-label classification with DAG structures, it ensures that assigned labels respect the hierarchical constraints by maintaining consistency across parent-child relationships in the label tree. The pseudo-labeling process considers both the similarity between instances and the hierarchical structure to generate appropriate multi-label predictions for unlabeled data, which are then used to train the final classifier.

## Key Results
- SSHMC-BLI outperforms supervised hierarchical classifiers trained only on labeled data across 12 Gene Ontology datasets
- Statistical analysis confirms SSHMC-BLI variants achieve significantly better performance than standard semi-supervised methods
- The method is particularly effective when the amount of labeled data is limited, demonstrating the value of incorporating unlabeled data in hierarchical multi-label settings

## Why This Works (Mechanism)
SSHMC-BLI works by exploiting the structure of both the data manifold and the label hierarchy simultaneously. By considering labeled neighbors of unlabeled instances, the method captures local similarity patterns that are informative for label assignment. The hierarchical constraints ensure that pseudo-labels respect the DAG structure, preventing inconsistent label assignments. This combination allows the model to effectively propagate label information from the small labeled set to the larger unlabeled set while maintaining structural coherence in the multi-label space.

## Foundational Learning
- **Directed Acyclic Graph (DAG) hierarchies**: Understanding that label hierarchies can have multiple parent-child relationships rather than strict tree structures - needed to handle complex biological ontologies where terms can have multiple parents; quick check: verify the Gene Ontology DAG structure allows multiple inheritance paths
- **Semi-supervised learning principles**: Recognizing that unlabeled data can improve model performance when labeled data is scarce - needed to justify the approach of using pseudo-labels; quick check: confirm that labeled:unlabeled ratio is low enough to benefit from semi-supervised approaches
- **Multi-label classification**: Handling instances that can be associated with multiple labels simultaneously - needed because biological entities often have multiple functional annotations; quick check: verify that evaluation metrics properly account for multi-label nature
- **Hierarchical classification constraints**: Maintaining consistency between parent and child labels in the hierarchy - needed to ensure valid predictions in the DAG structure; quick check: validate that pseudo-labels respect ancestor-descendant relationships
- **Instance similarity measures**: Quantifying how similar instances are to determine pseudo-label candidates - needed for the local information exploitation mechanism; quick check: examine similarity metric choice and its impact on pseudo-label quality
- **Pseudo-labeling strategies**: Generating artificial labels for unlabeled data based on available information - needed as the core mechanism for leveraging unlabeled instances; quick check: analyze pseudo-label confidence thresholds and their effect on final performance

## Architecture Onboarding

**Component map**: Data -> Similarity Computation -> Pseudo-label Generation -> Classifier Training -> Evaluation

**Critical path**: The most critical components are the similarity computation (determines which labeled instances influence unlabeled ones) and the pseudo-label generation (which must respect hierarchical constraints). These directly impact the quality of the augmented training set.

**Design tradeoffs**: The method trades computational overhead of similarity calculations and pseudo-label generation against improved performance with limited labeled data. It also balances between exploiting local structure (potentially missing global patterns) and maintaining hierarchical consistency.

**Failure signatures**: Poor similarity measures will propagate incorrect labels to unlabeled instances, degrading performance. Overly strict or loose hierarchical constraints may either eliminate useful label information or create inconsistencies. The method may struggle if the labeled set doesn't adequately represent the data distribution.

**First experiments to run**: 1) Vary the percentage of labeled data to determine the break-even point where semi-supervised benefits diminish; 2) Test different similarity metrics (cosine, Euclidean, learned) to identify optimal choices for biological data; 3) Evaluate performance with different hierarchical constraint strictness levels to find optimal balance between flexibility and consistency.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Evaluation is limited to Gene Ontology datasets, potentially restricting generalizability to other domains or hierarchical structures
- Method's performance on different DAG structures or hierarchy depths remains untested
- Scalability with increasing numbers of labels or instances is not addressed

## Confidence

**High confidence**: The method's effectiveness compared to supervised baselines on the tested Gene Ontology datasets is well-supported by experimental results.

**Medium confidence**: Comparative performance against other semi-supervised methods is supported by statistical analysis, though the specific baselines and comparison methodology could be more thoroughly examined.

**Low confidence**: Claims about the method's effectiveness in non-biological domains or with different DAG structures are not substantiated by the current evaluation.

## Next Checks

1. Test SSHMC-BLI on non-biological hierarchical multi-label datasets (such as text classification with topic hierarchies or image classification with object hierarchies) to assess domain generalizability beyond Gene Ontology.

2. Evaluate the method's sensitivity to different DAG structures by testing with varying numbers of parent-child relationships, hierarchy depths, and branching factors to understand structural limitations.

3. Compare performance when varying the proportion of labeled versus unlabeled data (e.g., 1%, 5%, 10%, 25%, 50%) to understand scalability limits and identify the minimum labeled data threshold where semi-supervised benefits diminish.