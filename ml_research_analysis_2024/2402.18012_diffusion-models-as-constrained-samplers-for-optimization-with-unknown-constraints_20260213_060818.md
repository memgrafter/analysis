---
ver: rpa2
title: Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints
arxiv_id: '2402.18012'
source_url: https://arxiv.org/abs/2402.18012
tags:
- optimization
- diffusion
- sampling
- distribution
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles optimization problems with unknown constraints
  by learning the feasible space from data using diffusion models. The authors propose
  DiffOPT, which reformulates the problem as sampling from the product of the data
  distribution and a Boltzmann distribution defined by the objective function.
---

# Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints

## Quick Facts
- arXiv ID: 2402.18012
- Source URL: https://arxiv.org/abs/2402.18012
- Authors: Lingkai Kong; Yuanqi Du; Wenhao Mu; Kirill Neklyudov; Valentin De Bortoli; Dongxia Wu; Haorui Wang; Aaron Ferber; Yi-An Ma; Carla P. Gomes; Chao Zhang
- Reference count: 40
- Primary result: DiffOPT achieves state-of-the-art performance on optimization with unknown constraints, particularly excelling in molecule optimization with 94.4% validity

## Executive Summary
This paper introduces DiffOPT, a novel approach to optimization with unknown constraints by leveraging diffusion models to learn the feasible space from data. The method reformulates the problem as sampling from the product of the data distribution and a Boltzmann distribution defined by the objective function. For differentiable objectives, DiffOPT employs a two-stage sampling approach combining guided diffusion for warm-up and Langevin dynamics for correction. For non-differentiable objectives, it uses iterative importance sampling with diffusion models. The approach demonstrates superior sample efficiency and consistently outperforms baselines across various benchmarks.

## Method Summary
DiffOPT addresses optimization problems with unknown constraints by learning the feasible space from data using diffusion models. The core idea is to reformulate the constrained optimization problem as sampling from a product distribution of the data distribution and a Boltzmann distribution defined by the objective function. For differentiable objectives, the method employs a two-stage sampling approach: guided diffusion for initial sampling from the data distribution, followed by Langevin dynamics for correction towards the Boltzmann distribution. For non-differentiable objectives, DiffOPT uses iterative importance sampling, where samples from the data distribution are weighted by their objective function values. The approach is theoretically grounded and demonstrates superior performance in both synthetic and real-world optimization tasks, particularly in molecule optimization where it achieves high validity rates.

## Key Results
- DiffOPT achieves state-of-the-art performance on both synthetic and real-world optimization tasks
- In molecule optimization, DiffOPT achieves 94.4% validity compared to 63.6% for the next best method
- The method demonstrates superior sample efficiency across various benchmarks
- DiffOPT consistently outperforms baselines in optimization tasks with unknown constraints

## Why This Works (Mechanism)
DiffOPT works by leveraging the powerful generative capabilities of diffusion models to learn the feasible space from data, then using this learned distribution to guide optimization. The key insight is that by treating the objective function as a Boltzmann distribution, optimization becomes a sampling problem. For differentiable objectives, the two-stage approach first uses guided diffusion to explore the feasible space, then refines samples using Langevin dynamics to optimize the objective. This combination allows efficient exploration while ensuring convergence to optimal solutions. For non-differentiable objectives, iterative importance sampling provides a way to optimize without requiring gradient information, making the approach more widely applicable.

## Foundational Learning
- **Diffusion Models**: Why needed - To learn the feasible space distribution from data samples; Quick check - Can generate samples that respect the learned constraints
- **Boltzmann Distribution**: Why needed - To incorporate the objective function into the sampling framework; Quick check - Ensures samples are biased towards higher objective values
- **Langevin Dynamics**: Why needed - To refine samples and optimize the objective function; Quick check - Converges to the target distribution under certain conditions
- **Importance Sampling**: Why needed - To handle non-differentiable objective functions; Quick check - Provides unbiased estimates of expectations

## Architecture Onboarding

**Component Map:**
Diffusion Model -> Guided Sampling -> Langevin Dynamics -> Optimized Samples
Diffusion Model -> Importance Sampling -> Optimized Samples

**Critical Path:**
For differentiable objectives: Diffusion Model -> Guided Sampling -> Langevin Dynamics
For non-differentiable objectives: Diffusion Model -> Importance Sampling

**Design Tradeoffs:**
The two-stage approach for differentiable objectives balances exploration (guided diffusion) with exploitation (Langevin dynamics), trading off computational efficiency for improved convergence. The choice between differentiable and non-differentiable approaches depends on the nature of the objective function, with the differentiable method generally being more efficient but less broadly applicable.

**Failure Signatures:**
- Poor performance on complex constraint landscapes due to insufficient data
- Computational inefficiency in high-dimensional spaces
- Suboptimal results when the learned feasible distribution significantly differs from the true distribution

**3 First Experiments:**
1. Synthetic optimization tasks with known constraints to validate the approach
2. Molecule optimization benchmarks to demonstrate real-world applicability
3. Ablation studies comparing the two-stage approach with alternative sampling methods

## Open Questions the Paper Calls Out
None

## Limitations
- Performance claims primarily supported by synthetic experiments and a single real-world application (molecule optimization), limiting generalizability
- Comparison to existing methods is somewhat limited, not extensively benchmarking against all relevant optimization techniques
- Assumes the constraint function can be learned effectively from data, which may not hold in all scenarios

## Confidence
- State-of-the-art performance claims: Medium
- Superiority in molecule optimization: High
- Generalizability to other domains: Low
- Computational efficiency claims: Low

## Next Checks
1. Test DiffOPT on a broader range of real-world optimization problems beyond molecule optimization to assess its generalizability and robustness across different domains
2. Conduct ablation studies to quantify the impact of each component of the DiffOPT framework on overall performance
3. Evaluate the computational efficiency of DiffOPT compared to traditional optimization methods, particularly in scenarios with high-dimensional search spaces or complex constraint functions