---
ver: rpa2
title: 'Understanding the User: An Intent-Based Ranking Dataset'
arxiv_id: '2408.17103'
source_url: https://arxiv.org/abs/2408.17103
tags:
- intents
- intent
- query
- user
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DL-MIA, a new dataset designed to capture
  the gap between user intent and machine intent in information retrieval. The dataset
  focuses on 24 queries from TREC-DL-21 and TREC-DL-22, providing fine-grained intent
  annotations along with relevant passages.
---

# Understanding the User: An Intent-Based Ranking Dataset

## Quick Facts
- **arXiv ID**: 2408.17103
- **Source URL**: https://arxiv.org/abs/2408.17103
- **Authors**: Abhijit Anand; Jurek Leonhardt; V Venktesh; Avishek Anand
- **Reference count**: 32
- **Primary result**: DL-MIA dataset captures user intent-machine intent gap using LLM-generated and human-validated intents, improving ranking performance

## Executive Summary
This paper introduces DL-MIA, a new dataset designed to capture the gap between user intent and machine intent in information retrieval. The dataset focuses on 24 queries from TREC-DL-21 and TREC-DL-22, providing fine-grained intent annotations along with relevant passages. User intents are generated using an LLM and refined through crowdsourcing. DL-MIA can be used for tasks like intent-based ranking, diversity, and query rewriting. Experiments with BM25, BERT, and ColBERTv2 show that specifying user intents as queries improves ranking performance, with ColBERTv2 achieving the best results. The dataset is publicly available and aims to enhance understanding of user needs in search systems.

## Method Summary
DL-MIA was created through a multi-stage process involving passage retrieval from TREC-DL benchmarks, clustering of similar passages using Sentence-BERT embeddings, LLM-based intent generation using GPT-4, and human validation through crowdsourcing. The methodology generates candidate intents from query-passage pairs, clusters similar intents, and refines them through annotator feedback. The final dataset consists of fine-grained intent annotations with relevance judgments for passages, enabling evaluation of user intent alignment in ranking systems.

## Key Results
- DL-MIA dataset contains fine-grained intent annotations for 24 TREC-DL queries
- Using user intents as queries improves ranking performance across BM25, BERT, and ColBERTv2 models
- ColBERTv2 achieves the best results when using user intents as queries
- The dataset is publicly available for research purposes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using LLM-generated intents followed by human refinement captures the gap between user and machine intent.
- Mechanism: The LLM analyzes implicit intent in queries by processing clustered relevant passages, generating candidate intents that are then validated and refined through crowdsourcing, ensuring both breadth and accuracy of intent coverage.
- Core assumption: The LLM can accurately infer implicit user intent from query-passage pairs, and human annotators can reliably validate and refine these intents.
- Evidence anchors:
  - [abstract] "Our methodology involves utilizing state-of-the-art LLMs to analyze and comprehend the implicit intent within individual queries from benchmark datasets."
  - [section 3.1.1] "We employ the GPT-4 model with the prompt given below... to generate five distinct intents relevant to the query-passage pairs."
  - [corpus] Weak: No direct corpus evidence comparing LLM-generated intents vs. human-only intent generation.

### Mechanism 2
- Claim: Clustering passages before intent generation reduces redundancy and improves intent quality.
- Mechanism: Passages are clustered using cosine similarity with Sentence-BERT embeddings, ensuring that the LLM processes distinct information contexts rather than redundant similar passages, leading to more diverse and accurate intents.
- Core assumption: Similar passages contain redundant information, and clustering them will help the LLM focus on distinct aspects of the query.
- Evidence anchors:
  - [section 3.1.1] "We then cluster similar passages per query... To achieve this, we first obtain passage embeddings using Sentence-BERT [16] and then group passages into the same cluster if their pairwise cosine similarity exceeds a threshold of 0.8."
  - [section B] "We perform clustering both before (passage clustering) and after (intent clustering) intent generation using a large language model (LLM) to eliminate redundancy."
  - [corpus] Weak: No direct corpus evidence showing performance difference with/without passage clustering.

### Mechanism 3
- Claim: Fine-grained intent annotation enables better evaluation of user intent alignment in ranking systems.
- Mechanism: By annotating specific user intents with relevant passages, the dataset allows evaluation of whether ranking systems can surface documents relevant to particular user intents rather than just matching query keywords.
- Core assumption: Specific intent annotations provide more granular evaluation than traditional relevance judgments alone.
- Evidence anchors:
  - [abstract] "DL-MIA mainly aims at measuring the gap between user intent and query by fine-grained intent annotation, but can be used in multiple ranking scenarios..."
  - [section 3.3] "Intent-based ranking aims at improving the document ranking by understanding different user intents and ensuring that the returned documents are relevant to the intent."
  - [corpus] Moderate: Experiments show that using user intents as queries improves ranking performance (Table 1).

## Foundational Learning

- **Concept**: Sentence-BERT and cosine similarity for semantic clustering
  - Why needed here: Used to group similar passages and intents, reducing redundancy and improving the quality of LLM-generated intents.
  - Quick check question: What is the cosine similarity threshold used for clustering passages vs. intents in this work?

- **Concept**: Large Language Model (LLM) prompting for intent generation
  - Why needed here: The LLM is used to generate candidate user intents from query-passage pairs, which forms the basis of the dataset.
  - Quick check question: What temperature value is used when generating intents with GPT-4 to control randomness?

- **Concept**: Crowdsourcing for human validation of machine-generated content
  - Why needed here: Human annotators validate and refine LLM-generated intents, ensuring quality and adding custom intents when necessary.
  - Quick check question: How many annotators review each query or subquery in the annotation process?

## Architecture Onboarding

- **Component map**: Query processing → Passage retrieval → Passage clustering → LLM intent generation → Intent clustering → Human annotation → Intent refinement → QRel file creation
- **Key components**: TREC-DL test sets, Sentence-BERT model, GPT-4 LLM, crowdsourcing platform (oTree), PostgreSQL database
- **Critical path**: 1. Retrieve relevant passages for each query, 2. Cluster passages to reduce redundancy, 3. Generate candidate intents using LLM, 4. Cluster and manually refine intents, 5. Crowdsource annotations for intent-passage relevance, 6. Merge similar intents and create final QRel file
- **Design tradeoffs**:
  - Passage clustering threshold (0.8) vs. intent diversity: Higher threshold means more clusters but potentially less coherent intents
  - LLM temperature (0.6) vs. intent variety: Higher temperature generates more diverse but potentially less focused intents
  - Number of annotators per query vs. annotation quality: More annotators increase reliability but also cost and time
- **Failure signatures**: If intents are consistently irrelevant or hallucinated, check LLM prompt quality and passage clustering; If annotators cannot reach consensus, check if intents are too granular or ambiguous; If final dataset is too small, check if clustering thresholds are too restrictive
- **First 3 experiments**:
  1. Compare ranking performance using original queries vs. user intents as queries on a small subset of DL-MIA
  2. Test different passage clustering thresholds (0.7, 0.8, 0.9) and measure impact on intent quality
  3. Evaluate different LLM prompting strategies (e.g., CAQE method vs. batch processing) on intent generation quality

## Open Questions the Paper Calls Out
None

## Limitations
- The dataset covers only 24 queries from TREC-DL-21/22, limiting generalizability to the broader query space
- The LLM-based intent generation may introduce systematic biases based on the model's training data and prompt design
- The dataset's focus on passage retrieval means it may not capture the full complexity of user intent in other IR tasks like document ranking or question answering

## Confidence

*High Confidence*: The methodology for intent generation and validation is clearly described and follows established IR practices. The experimental results showing performance improvements when using user intents as queries are straightforward and reproducible.

*Medium Confidence*: The claim that DL-MIA captures the "gap between user intent and machine intent" is supported by methodology but requires further validation across diverse query types and domains. The effectiveness of passage clustering at threshold 0.8 is reasonable but not empirically validated against alternatives.

*Low Confidence*: The dataset's ability to generalize to real-world search scenarios beyond the TREC-DL benchmark remains untested. The long-term utility of fine-grained intent annotations for improving ranking systems needs broader evaluation.

## Next Checks
1. **External domain validation**: Test whether DL-MIA improves ranking performance on queries from other domains (e.g., web search, e-commerce) to assess generalizability beyond the TREC-DL domain.
2. **Intent clustering sensitivity analysis**: Systematically vary the cosine similarity threshold for intent clustering (0.7, 0.8, 0.9) and measure impact on downstream ranking performance to determine optimal granularity.
3. **Human intent annotation comparison**: Conduct a small-scale study where human experts generate intents from scratch (without LLM assistance) for a subset of queries and compare intent quality, diversity, and downstream ranking performance against LLM-generated intents.