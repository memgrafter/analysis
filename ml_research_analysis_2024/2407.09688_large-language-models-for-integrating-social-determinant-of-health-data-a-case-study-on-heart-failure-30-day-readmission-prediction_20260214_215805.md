---
ver: rpa2
title: 'Large Language Models for Integrating Social Determinant of Health Data: A
  Case Study on Heart Failure 30-Day Readmission Prediction'
arxiv_id: '2407.09688'
source_url: https://arxiv.org/abs/2407.09688
tags:
- sdoh
- data
- variable
- domain
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper demonstrates that large language models (LLMs) can effectively
  and efficiently automate the annotation of social determinants of health (SDOH)
  variables for clinical prediction tasks. By framing SDOH variable classification
  as a text classification task and leveraging open-source LLMs with zero-shot prompting,
  the authors show that domain-specific SDOH data from unannotated sources like NaNDA
  can be integrated with clinical EHR data to improve heart failure 30-day readmission
  prediction.
---

# Large Language Models for Integrating Social Determinant of Health Data: A Case Study on Heart Failure 30-Day Readmission Prediction

## Quick Facts
- **arXiv ID**: 2407.09688
- **Source URL**: https://arxiv.org/abs/2407.09688
- **Reference count**: 40
- **Primary result**: LLMs can automate SDOH annotation with Micro F1 scores up to 0.825, improving heart failure readmission prediction by +0.028 AUROC

## Executive Summary
This paper demonstrates that large language models (LLMs) can effectively automate the annotation of social determinants of health (SDOH) variables from unannotated public datasets. By framing SDOH variable classification as a text classification task and leveraging open-source LLMs with zero-shot prompting, the authors show that domain-specific SDOH data can be integrated with clinical EHR data to improve heart failure 30-day readmission prediction. The approach offers a scalable solution to expedite SDOH data integration without requiring task-specific fine-tuning.

## Method Summary
The study combines unannotated SDOH variables from NaNDA with annotated AHRQ SDOH data and clinical EHR records. SDOH variables are classified into five domains using LLM zero-shot and one-shot prompting with various metadata combinations (variable name, description, data source). Flan-T5 models achieved the highest performance for domain classification, with Micro F1 scores up to 0.825. The annotated SDOH features were then integrated with clinical data for heart failure readmission prediction using logistic regression with 10-fold cross-validation.

## Key Results
- Flan-T5 models achieved Micro F1 scores up to 0.825 for SDOH domain classification
- Integrating LLM-annotated neighborhood and built environment variables yielded the best prediction performance (+0.028 AUROC improvement)
- Variable name (A) and variable description (B) metadata combinations provided the most robust performance across models and datasets

## Why This Works (Mechanism)
Assumption: The effectiveness stems from LLMs' ability to understand contextual relationships between variable metadata and SDOH domains, leveraging pre-trained knowledge about social determinants to classify variables accurately without task-specific fine-tuning.

## Foundational Learning
- **SDOH domain classification**: Understanding the five SDOH domains (Social and Community Context, Economic Stability, Education Access and Quality, Neighborhood and Built Environment, Healthcare Access and Quality) is essential for framing the annotation task and interpreting results
- **LLM zero-shot prompting**: The ability of LLMs to classify text without task-specific fine-tuning enables rapid annotation of unannotated SDOH variables
- **Metadata combinations**: The systematic evaluation of different metadata combinations (A, B, C, AB, AC, BC, ABC) reveals how LLMs leverage different types of information for domain classification

## Architecture Onboarding

**Component Map**: NaNDA SDOH variables -> LLM prompting framework -> Domain classification -> Integration with EHR data -> Logistic regression model -> Heart failure readmission prediction

**Critical Path**: SDOH variable metadata → LLM inference → Domain classification → Feature integration → Predictive modeling

**Design Tradeoffs**: The choice between zero-shot and one-shot prompting involves balancing ease of implementation against potential performance gains, while the selection of metadata combinations affects both LLM performance and computational requirements.

**Failure Signatures**: LLMs may not follow the specified prompt format, leading to non-response or refusal rates that vary across models and metadata combinations.

**First Experiments**:
1. Evaluate LLM performance using only variable names (A) vs. variable descriptions (B) vs. data source descriptions (C)
2. Compare zero-shot vs. one-shot prompting performance across different open-source LLM models
3. Test the impact of different metadata combinations (AB, AC, BC, ABC) on classification accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What is the optimal metadata combination for LLM-based SDOH domain annotation?
- **Basis**: The paper systematically evaluates 7 different metadata combinations but leaves open whether optimal choice depends on specific dataset characteristics
- **Evidence needed**: Direct comparison studies testing different combinations across diverse SDOH datasets

### Open Question 2
- **Question**: How do open-source LLMs compare to proprietary models like GPT-4 for SDOH annotation?
- **Basis**: The paper only evaluates open-source LLMs while noting most previous works used closed-source GPT models
- **Evidence needed**: Head-to-head comparison studies using identical SDOH datasets across both open-source and proprietary models

### Open Question 3
- **Question**: What is the long-term performance and adaptation capability of LLMs for SDOH annotation?
- **Basis**: The study uses static datasets without evaluating performance on evolving SDOH frameworks and new data sources
- **Evidence needed**: Longitudinal studies tracking LLM performance across multiple iterations of SDOH data sources

### Open Question 4
- **Question**: How do different prompting strategies affect SDOH annotation performance?
- **Basis**: The paper limits itself to zero-shot and one-shot prompting, not exploring Chain-of-Thought or other sophisticated approaches
- **Evidence needed**: Systematic evaluation of various prompting strategies on the same SDOH annotation task

## Limitations
- Exact variable names, descriptions, and data source details from NaNDA and AHRQ SDOH databases are not fully specified, creating barriers to exact reproduction
- Reliance on census tract-level SDOH data may limit generalizability to other geographic aggregation levels
- Manual annotation by a single annotator may introduce bias in the ground truth labels

## Confidence
- **High confidence** in the general approach and methodology for LLM-based SDOH annotation
- **Medium confidence** in exact reproduction due to unspecified variable details
- **Medium confidence** in generalizability beyond the specific datasets and geographic levels used

## Next Checks
1. Verify exact variable names, descriptions, and data source descriptions from NaNDA and AHRQ SDOH databases to ensure faithful reproduction of metadata combinations
2. Replicate LLM inference process using specified open-source models with zero-shot and one-shot settings to confirm reported performance metrics
3. Apply methodology to SDOH data at different geographic aggregation levels (e.g., county or zip code) to assess robustness beyond census tract-level data