---
ver: rpa2
title: What External Knowledge is Preferred by LLMs? Characterizing and Exploring
  Chain of Evidence in Imperfect Context for Multi-Hop QA
arxiv_id: '2412.12632'
source_url: https://arxiv.org/abs/2412.12632
tags:
- knowledge
- llms
- external
- question
- keywords
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Chain of Evidence (CoE) concept from
  criminal procedural law to characterize preferred external knowledge for Large Language
  Models (LLMs) in multi-hop Question Answering (QA). The authors define CoE as knowledge
  that is both relevant to the question (containing intent) and mutually supportive
  among knowledge pieces (containing keywords and relations).
---

# What External Knowledge is Preferred by LLMs? Characterizing and Exploring Chain of Evidence in Imperfect Context for Multi-Hop QA

## Quick Facts
- arXiv ID: 2412.12632
- Source URL: https://arxiv.org/abs/2412.12632
- Authors: Zhiyuan Chang; Mingyang Li; Xiaojun Jia; Junjie Wang; Yuekai Huang; Qing Wang; Yihao Huang; Yang Liu
- Reference count: 24
- Primary result: Chain of Evidence (CoE) knowledge significantly improves LLM performance in multi-hop QA (92.0% accuracy vs 69.5-75.7% for Non-CoE)

## Executive Summary
This paper introduces the Chain of Evidence (CoE) concept from criminal procedural law to characterize what external knowledge Large Language Models (LLMs) prefer in multi-hop Question Answering (QA). The authors define CoE as knowledge that is both relevant to the question (containing intent) and mutually supportive among knowledge pieces (containing keywords and relations). They propose an automated CoE discrimination approach to identify such knowledge from external contexts. Through extensive experiments across five state-of-the-art LLMs, the study demonstrates that CoE significantly improves LLM accuracy, faithfulness, and robustness against misinformation, while also enhancing RAG performance through a CoE-guided retrieval strategy (ScopeCoE).

## Method Summary
The authors construct datasets with CoE and Non-CoE samples from HotpotQA and 2WikiMultihopQA using a CoE discrimination approach that extracts question intent, keywords, and relations, then checks their presence in external knowledge. They evaluate LLM performance across four dimensions: effectiveness (accuracy under various conditions), faithfulness (following rate), robustness (against knowledge conflicts), and usability (via ScopeCoE retrieval strategy). The study compares five LLMs (GPT-3.5, GPT-4, Llama2-13B, Llama3-70B, Qwen2.5-32B) across these datasets and conditions.

## Key Results
- CoE significantly improves LLM accuracy: 92.0% vs 69.5-75.7% for Non-CoE
- CoE enhances faithfulness: 85.4% vs 64.8-69.0% following rate for Non-CoE
- CoE improves robustness against misinformation: 84.1% vs 62.8-68.8% for Non-CoE
- ScopeCoE retrieval strategy enhances RAG accuracy by 10.4-28.7%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CoE improves LLM performance by providing contextually coherent knowledge that satisfies both relevance and mutual support properties.
- Mechanism: The Chain of Evidence (CoE) characterization identifies knowledge that contains intent (relevance to question), keywords (specific details), and relations (interconnectivity). When external knowledge forms a CoE, it provides a structured, internally consistent context that guides LLMs toward correct answers despite noise.
- Core assumption: LLMs preferentially use knowledge that forms coherent, mutually supportive chains rather than isolated facts.
- Evidence anchors:
  - [abstract] "knowledge preferred by LLMs should maintain both relevance to the question and mutual support among knowledge pieces"
  - [section 3.1] "We consider that the preferred knowledge should show relevance to the question (relevance) and mutual support and complementarity among knowledge pieces in addressing the question (interconnectivity)"
  - [corpus] Weak evidence - no direct corpus support for LLMs' preference for coherent knowledge chains
- Break condition: If LLM reasoning capabilities are too weak to process interconnected evidence, or if CoE contains systematic errors that override individual corrections.

### Mechanism 2
- Claim: CoE enhances robustness against knowledge conflicts by providing a dominant, internally consistent narrative.
- Mechanism: When misinformation is injected, CoE's internal consistency creates a stronger signal that LLMs follow, even when conflicting information exists. The mutual support among CoE elements makes it more resistant to contradictory evidence.
- Core assumption: LLMs weight internally consistent knowledge higher than isolated contradictory facts when making decisions.
- Evidence anchors:
  - [abstract] "LLMs exhibit higher robustness against knowledge conflict (than Non-CoE) if the external knowledge is equipped with CoE"
  - [section 7.2 Finding-5] "LLMs augmented with CoE exhibit higher robustness against knowledge conflict than Non-CoE"
  - [corpus] Moderate evidence - related work on knowledge conflicts supports this mechanism but doesn't specifically test CoE structure
- Break condition: If misinformation volume overwhelms the CoE signal, or if LLM reasoning is strong enough to independently evaluate each fact regardless of context.

### Mechanism 3
- Claim: CoE-guided retrieval (ScopeCoE) improves RAG performance by selecting minimal, complete knowledge sets that cover all CoE features.
- Mechanism: ScopeCoE identifies the smallest set of knowledge snippets that collectively contain all CoE features (intent, keywords, relations), reducing noise while maintaining completeness. This focused retrieval improves LLM accuracy compared to naive top-K relevance ranking.
- Core assumption: Minimal complete sets of knowledge are more effective than larger, potentially redundant sets for LLM reasoning.
- Evidence anchors:
  - [abstract] "a CoE-guided retrieval strategy (ScopeCoE) enhances a naive RAG framework by 10.4-28.7% in accuracy"
  - [section 8.4 Finding-7] "RAG+ScopeCoE achieves average ACC of 77.8% and 81.6% on HotpotQA and 2WikiMultihopQA respectively, outperforming RAG by 10.4% and 28.7%"
  - [corpus] Weak evidence - no corpus support for minimal coverage retrieval strategies
- Break condition: If the CoE feature extraction is inaccurate, or if the minimal set misses critical implicit information needed for reasoning.

## Foundational Learning

- Concept: Chain of Evidence (CoE) theory from criminal procedural law
  - Why needed here: Provides the theoretical foundation for characterizing what makes knowledge "preferred" by LLMs - relevance to the case and mutual support among evidence pieces
  - Quick check question: Can you explain how CoE theory maps to the LLM knowledge preference problem in your own words?

- Concept: Information extraction and entailment
  - Why needed here: The CoE discrimination approach relies on extracting intent, keywords, and relations from questions, then determining whether external knowledge contains these features through entailment reasoning
  - Quick check question: What's the difference between keyword matching and relation entailment in the context of CoE discrimination?

- Concept: Knowledge conflict and misinformation injection
  - Why needed here: Understanding how to construct knowledge conflicts is essential for testing robustness, which is one of the four evaluation dimensions for CoE
  - Quick check question: How would you generate misinformation that both contains factual errors and conflicts with correct knowledge?

## Architecture Onboarding

- Component map: Question → Information extraction (intent, keywords, relations) → CoE discrimination on external knowledge → Feature coverage evaluation → LLM generation → Answer evaluation. For RAG applications, add retrieval and ScopeCoE minimal coverage search before LLM generation.

- Critical path: Question → Information extraction (intent, keywords, relations) → CoE discrimination on external knowledge → Feature coverage evaluation → LLM generation → Answer evaluation. For RAG applications, add retrieval and ScopeCoE minimal coverage search before LLM generation.

- Design tradeoffs: The system trades computational complexity (multiple LLM calls for discrimination) for improved knowledge quality. The perturbation strategies for Non-CoE construction balance information loss vs. feature destruction. The ScopeCoE strategy trades completeness for minimal coverage.

- Failure signatures: If CoE discrimination is too strict, few samples will qualify as CoE. If perturbations are too aggressive, Non-CoE samples won't be meaningful comparisons. If ScopeCoE coverage is incomplete, RAG performance may degrade despite theoretical advantages.

- First 3 experiments:
  1. Test CoE discrimination approach on a small set of manually labeled examples to verify accuracy
  2. Run effectiveness assessment with varying irrelevant information proportions to observe performance trends
  3. Implement and test ScopeCoE on a simple RAG setup with ground truth knowledge availability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the individual features of CoE (intent, keywords, and relations) contribute to LLM performance separately, and what is their relative importance?
- Basis in paper: [inferred] The paper mentions that intent, keywords, and relations within CoE are interdependent, making it challenging to isolate any single feature. The study focuses on examining the overall impact of CoE on LLM performance rather than individual feature contributions.
- Why unresolved: The interdependent nature of CoE features makes it difficult to design experiments that can isolate the impact of each feature without affecting the others.
- What evidence would resolve it: Controlled experiments that systematically vary one feature while holding others constant, or ablation studies that measure performance degradation when each feature is removed separately.

### Open Question 2
- Question: Can the CoE discrimination approach be effectively adapted for vector-based RAG scenarios where external knowledge is converted into vectors and stored in vector databases?
- Basis in paper: [explicit] The limitations section explicitly states that the usability of the proposed retrieval strategy (ScopeCoE) has inherent constraints across RAG scenarios, particularly mentioning that some RAG scenarios convert external knowledge into vectors and store them in vector databases, making the text-based approach unsuitable.
- Why unresolved: The paper only explores CoE at the textual level and does not investigate how CoE features could be extracted or utilized in vector-based retrieval systems.
- What evidence would resolve it: Successful adaptation of CoE feature extraction to vector representations, or demonstration of CoE-like properties in vector space similarity measures.

### Open Question 3
- Question: How does CoE theory apply to scenarios beyond RAG, such as retrieval corpus construction and retriever optimization, and what are the potential benefits and limitations?
- Basis in paper: [explicit] The conclusion mentions exploring broader applications of CoE in RAG scenarios, including retrieval corpus construction and retriever optimization, but does not provide empirical evidence or detailed analysis.
- Why unresolved: The paper only briefly mentions potential applications without conducting experiments or providing detailed analysis of how CoE could be applied to these areas.
- What evidence would resolve it: Empirical studies demonstrating improved retrieval corpus quality or retriever performance when guided by CoE principles, along with analysis of trade-offs and limitations.

### Open Question 4
- Question: What are the implications of CoE's content safety concerns, particularly regarding adversaries exploiting CoE to generate targeted manipulations?
- Basis in paper: [explicit] The conclusion section mentions that content safety of CoE should be a concern considering the faithfulness findings, as adversaries can exploit CoE to generate targeted manipulations, but does not explore this issue in depth.
- Why unresolved: The paper acknowledges the potential security risk but does not investigate the extent of this vulnerability or propose mitigation strategies.
- What evidence would resolve it: Security analysis demonstrating specific attack vectors using CoE, along with proposed defense mechanisms or evaluation of existing countermeasures against CoE-based manipulation attacks.

## Limitations
- The CoE discrimination approach relies heavily on the accuracy of information extraction and entailment reasoning, which may be sensitive to prompt engineering and model capabilities
- The perturbation strategies for constructing Non-CoE samples may not fully capture the complexity of real-world imperfect contexts
- The evaluation focuses on specific multi-hop QA datasets, which may limit generalizability to other QA formats or domains

## Confidence
- **High confidence**: The observation that CoE improves LLM accuracy and faithfulness in controlled experiments, as this is directly measurable from the constructed datasets
- **Medium confidence**: The effectiveness of the ScopeCoE retrieval strategy, as it shows strong results on the specific datasets but may not generalize to all RAG scenarios
- **Low confidence**: The theoretical claims about why CoE works (mechanisms 1-3), as these rely on indirect evidence and assumptions about LLM reasoning that are difficult to verify empirically

## Next Checks
1. **Cross-domain validation**: Test the CoE discrimination approach and ScopeCoE retrieval strategy on datasets from different domains (e.g., biomedical, legal, or financial QA) to assess generalizability beyond multi-hop Wikipedia-style questions

2. **Human evaluation of CoE quality**: Conduct human assessments of whether the automatically identified CoE samples truly exhibit the claimed properties of relevance and mutual support, to validate the discrimination approach's accuracy

3. **Ablation studies on CoE features**: Systematically remove individual features (intent, keywords, relations) from the CoE discrimination process to determine which components are most critical for the observed performance improvements