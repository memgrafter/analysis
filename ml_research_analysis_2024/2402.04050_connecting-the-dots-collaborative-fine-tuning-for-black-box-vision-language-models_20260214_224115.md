---
ver: rpa2
title: 'Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language
  Models'
arxiv_id: '2402.04050'
source_url: https://arxiv.org/abs/2402.04050
tags:
- black-box
- craft
- training
- module
- refinement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of fine-tuning large pretrained
  vision-language models (VLMs) in a black-box setting, where only input prompts and
  output predictions are accessible, and model parameters cannot be modified. The
  proposed Collaborative Fine-Tuning (CraFT) method introduces a prompt generation
  module that learns global text prompts via derivative-free optimization (CMA-ES)
  and a prediction refinement module that enhances the model's output predictions
  in residual style.
---

# Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models

## Quick Facts
- **arXiv ID**: 2402.04050
- **Source URL**: https://arxiv.org/abs/2402.04050
- **Reference count**: 17
- **Primary result**: 12% performance gain over zero-shot CLIP with 16-shot datasets using 8,000 queries

## Executive Summary
This paper addresses the challenge of fine-tuning large vision-language models (VLMs) in black-box settings where only input prompts and output predictions are accessible, not model parameters. The proposed Collaborative Fine-Tuning (CraFT) method introduces a two-module framework: a prompt generation module that learns global text prompts via derivative-free optimization (CMA-ES), and a prediction refinement module that enhances output predictions in residual style. A collaborative training algorithm with prediction-consistent loss enables joint optimization of these modules. Experiments on 15 datasets demonstrate significant improvements over zero-shot CLIP while maintaining computational efficiency.

## Method Summary
CraFT operates by jointly optimizing two modules: a prompt generation module using CMA-ES optimizer with random projection to lower-dimensional subspaces, and a prediction refinement module implemented as a 3-layer MLP with residual connections. The collaborative training algorithm alternates between optimizing these modules using cross-entropy loss and KL divergence consistency terms. The method achieves competitive performance with only 8,000 API queries and 16-shot examples per class, demonstrating 80x memory efficiency compared to white-box fine-tuning approaches while maintaining near state-of-the-art accuracy.

## Key Results
- Achieves 12% performance gain over zero-shot CLIP on 16-shot datasets with 8,000 queries
- Demonstrates 80x memory efficiency compared to white-box fine-tuning methods
- Shows only 1.62% accuracy drop compared to white-box CoOp baseline
- Validated across 15 diverse datasets including ImageNet variants and robustness benchmarks

## Why This Works (Mechanism)
The collaborative approach works by decomposing the fine-tuning problem into two complementary components: prompt optimization and prediction refinement. The prompt generation module learns optimal text embeddings that guide the VLM's attention, while the prediction refinement module corrects systematic biases in the model's output. The alternating optimization with prediction-consistent loss ensures that both modules work synergistically rather than redundantly, with the consistency term preventing drift between predicted and refined outputs.

## Foundational Learning
- **CMA-ES optimization**: Needed for derivative-free optimization of text prompts in black-box settings; quick check is population convergence within 8,000 queries
- **Random projection matrices**: Used to reduce dimensionality of prompt space; quick check is projection preserving variance above 95%
- **Residual connections in MLPs**: Enable stable training of prediction refinement module; quick check is avoiding vanishing gradients in deep networks
- **KL divergence consistency loss**: Prevents drift between predicted and refined outputs; quick check is symmetric KL divergence staying below 0.1
- **Cross-entropy loss for classification**: Standard approach for supervised learning; quick check is decreasing training loss over epochs
- **Black-box vs white-box fine-tuning**: Differentiable vs non-differentiable optimization paradigms; quick check is parameter access restrictions

## Architecture Onboarding

Component Map: Data -> Prompt Generation (CMA-ES) -> VLM API -> Prediction Refinement (MLP) -> Refined Predictions -> Loss Computation

Critical Path: Prompt generation and refinement modules must be optimized collaboratively, with each module's output serving as input to the other's optimization objective.

Design Tradeoffs: Memory efficiency (80x gain) vs accuracy (1.62% drop from white-box), derivative-free vs gradient-based optimization, global vs local prompt optimization.

Failure Signatures: CMA-ES convergence failure (fitness landscape plateaus), prediction refinement divergence (training loss increases), inconsistent outputs between predicted and refined predictions (KL divergence spikes).

First Experiments:
1. Implement and validate 3-layer MLP architecture for prediction refinement with proper residual connections and monitor convergence behavior
2. Verify CMA-ES optimization parameters including population size 40, query budget of 8,000, and step-size adaptation through multiple runs
3. Test collaborative training algorithm's alternating optimization between CMA-ES and AdamW on smaller dataset subset to verify prediction-consistent loss implementation

## Open Questions the Paper Calls Out
None identified in the paper.

## Limitations
- 1.62% accuracy drop compared to white-box fine-tuning methods due to inability to directly modify model parameters
- Requires 8,000 API queries which may be costly for large-scale deployment
- Performance depends on quality of random projection matrix and CMA-ES initialization

## Confidence
High confidence in 12% accuracy gain over zero-shot CLIP and 80x memory efficiency claims based on clear experimental setup and comparison framework. Medium confidence in 1.62% accuracy drop vs white-box methods due to unknown implementation details of prediction refinement module architecture and exact collaborative training algorithm alternation.

## Next Checks
1. Implement and validate the exact 3-layer MLP architecture for the prediction refinement module with proper residual connections and monitor convergence behavior
2. Verify the CMA-ES optimization parameters including population size 40, query budget of 8,000, and step-size adaptation through multiple runs to ensure consistent convergence across different datasets
3. Test the collaborative training algorithm's alternating optimization between CMA-ES and AdamW on a smaller dataset subset to verify the prediction-consistent loss implementation and batch processing logic before scaling to full experiments