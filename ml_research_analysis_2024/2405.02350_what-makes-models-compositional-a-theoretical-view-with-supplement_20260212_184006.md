---
ver: rpa2
title: 'What makes Models Compositional? A Theoretical View: With Supplement'
arxiv_id: '2405.02350'
source_url: https://arxiv.org/abs/2405.02350
tags:
- compositional
- cdag
- nodes
- node
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a formal definition of compositional functions
  in sequence processing models, describing how input tokens are hierarchically composed
  through a computation DAG. The authors define compositional complexity using the
  locus of influence (LoI), which quantifies how much each input token affects the
  final output.
---

# What makes Models Compositional? A Theoretical View: With Supplement

## Quick Facts
- arXiv ID: 2405.02350
- Source URL: https://arxiv.org/abs/2405.02350
- Authors: Parikshit Ram; Tim Klinger; Alexander G. Gray
- Reference count: 40
- Primary result: Input-agnostic compositional models (fixed DAG structure) cannot approximate input-dependent compositional functions (variable DAG structure) well when compositional complexity is high.

## Executive Summary
This paper introduces a formal framework for analyzing compositional functions in sequence processing models through computation directed acyclic graphs (cDAGs) and locus of influence (LoI) metrics. The authors establish theoretical bounds on the approximation error between input-agnostic and input-dependent models, showing that fixed DAG structures struggle with high-compositional-complexity functions. They apply this framework to analyze RNNs, CNNs, and Transformers, computing their compositional complexity and providing generalization guarantees that explicitly depend on the proposed compositional complexity measures.

## Method Summary
The paper defines compositional functions using four components: token encoder e, cDAG function D, span processor g, and readout function h. It introduces the locus of influence (LoI) metric to quantify how much each input token affects the final output, distinguishing between absolute influence (δ) and relative influence (β). The framework expresses existing models in this notation and computes their compositional complexity. Theoretical proofs establish bounds on approximation error between input-agnostic and input-dependent cDAGs, and systematic generalization guarantees are provided for learned compositional functions.

## Key Results
- Compositional complexity (δ and β) can be computed for various models including RNNs, CNNs, and Transformers
- Input-agnostic compositional models cannot approximate input-dependent compositional functions well when compositional complexity is high
- Systematic generalization guarantees bound the difference between true risk and empirical risk, with compositional complexity δ appearing as a multiplicative factor
- The framework provides a theoretical explanation for why some models struggle with compositional generalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Input-agnostic compositional models (fixed DAG structure) cannot approximate input-dependent compositional functions (variable DAG structure) well when compositional complexity is high.
- Mechanism: The theoretical framework establishes that compositional complexity (quantified by LoI) determines the approximation error between models with fixed vs. variable DAGs. Higher LoI values in input-dependent functions create approximation barriers that fixed DAG models cannot overcome.
- Core assumption: The smoothness constant c in the LoI definition captures the true complexity of the span processor function g, and the cDAG structure directly reflects the computational requirements of the function being modeled.
- Evidence anchors: [abstract] "input-agnostic compositional models (those with fixed DAG structure) cannot approximate input-dependent compositional functions (those with variable DAG structure) well when the compositional complexity is high"

### Mechanism 2
- Claim: The locus of influence (LoI) quantifies how much each input token affects the final output, directly impacting a model's ability to generalize compositionally.
- Mechanism: LoI measures both the absolute influence (δ) through path lengths and the relative influence (β) through distribution across tokens. Models with high absolute LoI or skewed relative LoI struggle with generalization because they cannot capture the appropriate token dependencies.
- Core assumption: The LoI metric accurately captures the computational sensitivity of the model to input perturbations, and this sensitivity directly translates to generalization performance.
- Evidence anchors: [abstract] "They apply this framework to analyze various existing models including RNNs, CNNs, and Transformers, computing their compositional complexity"

### Mechanism 3
- Claim: Systematic generalization guarantees bound the difference between true risk and empirical risk, with compositional complexity δ appearing as a multiplicative factor that degrades performance.
- Mechanism: The theoretical analysis shows that generalization error scales with compositional complexity δ, creating a direct relationship between model architecture choices and generalization bounds. Higher δ leads to looser generalization guarantees.
- Core assumption: The clean-separability assumption (q=1) accurately represents the compositional structure of the target functions, and the learning algorithm can effectively learn the span encoder and readout function given the fixed cDAG and token encoder.
- Evidence anchors: [abstract] "provide theoretical guarantees for the expressivity and systematic generalization of compositional models that explicitly depend on our proposed definition"

## Foundational Learning

- Concept: Directed Acyclic Graph (DAG) computation traces
  - Why needed here: The cDAG structure is fundamental to understanding how input tokens are hierarchically composed in compositional functions. Without grasping DAG concepts, the distinction between input-dependent and input-agnostic models cannot be understood.
  - Quick check question: Given a DAG with nodes representing computations and edges representing data flow, can you trace the path from input nodes to output nodes and explain how changes at different levels affect the final output?

- Concept: Smoothness and Lipschitz continuity
  - Why needed here: The smoothness constant c in the LoI definition and the Lipschitz constant of the readout function are critical for establishing the bounds in the theoretical analysis. Understanding these concepts is essential for interpreting the approximation and generalization results.
  - Quick check question: For a function f with Lipschitz constant L, can you prove that |f(x) - f(y)| ≤ L||x - y|| for all x, y in the domain?

- Concept: Systematic vs. compositional generalization
  - Why needed here: The paper distinguishes between these two forms of generalization, with systematic generalization being a specific case of compositional generalization under clean-separability assumptions. This distinction is crucial for understanding the theoretical guarantees.
  - Quick check question: Can you explain the difference between a model that generalizes compositionally versus one that generalizes systematically, and provide an example where these two forms of generalization would differ?

## Architecture Onboarding

- Component map: Token encoder e → cDAG function D → span processor g → readout function h
- Critical path: For input-dependent models, compute appropriate cDAG for each input, then apply recursive composition using g. For input-agnostic models, use fixed cDAG and only compute recursive composition.
- Design tradeoffs: Input-dependent models capture more complex compositional structures but require more computation to determine cDAG. Input-agnostic models are computationally simpler but may struggle with high-compositional-complexity functions.
- Failure signatures: Poor performance on compositional generalization benchmarks, particularly on tasks requiring different DAG structures for different inputs. High approximation error when comparing against input-dependent ground truth functions.
- First 3 experiments:
  1. Implement a simple unidirectional RNN and compute its LoI for various input lengths to verify the exponential relationship with input length.
  2. Create a synthetic dataset with ground truth functions that have input-dependent cDAGs, then compare the approximation error of input-agnostic vs. input-dependent models.
  3. Train a model on a compositional generalization benchmark and analyze the learned cDAG structure to determine if it adapts to different input patterns or remains fixed.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different forms of compositionality (hierarchical vs non-hierarchical) affect the ability of models to generalize to unseen combinations of known parts?
- Basis in paper: [explicit] The paper distinguishes between input-dependent and input-agnostic cDAGs and their ability to approximate each other, particularly in the context of compositionality.
- Why unresolved: While the paper provides theoretical bounds on approximation errors, it doesn't empirically compare the generalization performance of models with different cDAG structures on compositional tasks.
- What evidence would resolve it: Empirical studies comparing the performance of models with hierarchical (e.g., tree-based) and non-hierarchical (e.g., fully connected) cDAGs on compositional generalization benchmarks.

### Open Question 2
- Question: What is the impact of the span processor's complexity (e.g., smoothness parameter c) on the compositional complexity and generalization ability of models?
- Basis in paper: [explicit] The paper defines the compositional complexity using the locus of influence (LoI), which incorporates the smoothness of the span processor g.
- Why unresolved: The paper provides theoretical bounds on the approximation error based on the smoothness parameter c, but doesn't explore how different choices of span processors affect the model's ability to generalize compositionally.
- What evidence would resolve it: Experiments varying the smoothness of the span processor g in different models and measuring their compositional generalization performance on benchmarks.

### Open Question 3
- Question: How does the presence of input-dependent cDAGs in models influence their ability to handle tasks requiring strict multi-step computations?
- Basis in paper: [explicit] The paper discusses how input-dependent cDAGs can arise from selective pooling operations and sparse attention mechanisms, and how they relate to the complexity of composition.
- Why unresolved: While the paper provides theoretical insights into the expressiveness of input-dependent cDAGs, it doesn't empirically investigate their impact on tasks requiring complex compositional reasoning.
- What evidence would resolve it: Comparative studies evaluating the performance of models with input-dependent cDAGs (e.g., with sparse attention) versus input-agnostic DAGs (e.g., with dense attention) on tasks requiring multi-step reasoning.

## Limitations

- The framework assumes clean-separability (q=1) which may not accurately represent complex real-world compositional tasks
- Empirical validation on real-world compositional generalization benchmarks is limited
- Computing input-dependent cDAGs for each input may be computationally prohibitive for long sequences

## Confidence

**High confidence** in the theoretical framework's mathematical consistency and the core proposition that input-agnostic models cannot perfectly approximate input-dependent functions with high compositional complexity.

**Medium confidence** in the practical relevance of the compositional complexity bounds, as the translation from theoretical LoI values to actual generalization performance on real benchmarks requires further empirical validation.

**Low confidence** in the completeness of the model analyses, as some propositions (particularly for CNNs and Transformers) are referenced but not fully detailed in the provided text.

## Next Checks

1. **Empirical validation on compositional benchmarks**: Implement the framework and test on established compositional generalization benchmarks (e.g., SCAN, CFQ) to verify that models with higher estimated compositional complexity indeed show better performance on unseen compositional patterns.

2. **LoI sensitivity analysis**: Systematically vary input-dependent ground truth functions with different δ values and measure the approximation error of fixed-DAG models to empirically verify the theoretical bounds between input-agnostic and input-dependent cDAGs.

3. **Architectural ablation study**: Compare models with different cDAG structures (fixed vs. input-dependent) on tasks with known compositional complexity requirements, measuring both absolute performance and relative performance gaps as compositional complexity increases.