---
ver: rpa2
title: 'Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision
  Language Models'
arxiv_id: '2410.00309'
source_url: https://arxiv.org/abs/2410.00309
tags:
- contact
- dataset
- data
- images
- interactions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of data scarcity for close human
  interactions in Human Mesh Estimation (HME) by introducing a novel data generation
  method that leverages Large Vision Language Models (LVLMs) to automatically annotate
  contact maps and guide test-time optimization. The authors curate the Ask Pose Unite
  (APU) dataset, comprising over 6,200 human mesh pairs in contact, sourced from in-the-wild
  images depicting naturalistic person-to-person scenes.
---

# Ask, Pose, Unite: Scaling Data Acquisition for Close Interactions with Vision Language Models

## Quick Facts
- arXiv ID: 2410.00309
- Source URL: https://arxiv.org/abs/2410.00309
- Reference count: 40
- Primary result: 5.9% improvement in PA-MPJPE on close interactions test set of NTU RGB+D 120 compared to state-of-the-art method BUDDI

## Executive Summary
This paper addresses the critical challenge of data scarcity for close human interactions in Human Mesh Estimation (HME). The authors introduce a novel data generation method that leverages Large Vision Language Models (LVLMs) to automatically annotate contact maps and guide test-time optimization. They curate the Ask Pose Unite (APU) dataset, comprising over 6,200 human mesh pairs in contact, sourced from in-the-wild images depicting naturalistic person-to-person scenes. By training a diffusion-based contact prior with their dataset, they demonstrate significant improvements in mesh estimation accuracy on unseen interactions, particularly for less common interaction types.

## Method Summary
The authors present a three-step pipeline to generate high-quality contact data for close human interactions. First, they use GPT-4V to automatically generate contact maps from images depicting close interactions. Second, they perform constrained optimization to generate pseudo-ground truth meshes by imposing contact constraints from the LVLM-generated contact maps. Finally, they train a diffusion-based contact prior on the curated APU dataset to improve HME performance during test-time optimization. The key innovation lies in leveraging LVLMs for automatic contact annotation, which scales data acquisition without manual labeling while addressing the data scarcity problem for close interactions.

## Key Results
- 5.9% improvement in PA-MPJPE on close interactions test set of NTU RGB+D 120 compared to state-of-the-art method BUDDI
- The APU dataset contains over 6,200 human mesh pairs in contact, representing a significant increase in data diversity for close interactions
- The contact prior benefits from in-domain training data, performing better than BUDDI on all interaction classes in the close interactions test set

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large Vision Language Models can generate reliable contact maps for human mesh optimization by exploiting their ability to interpret spatial relationships from 2D images.
- Mechanism: The LVLM is prompted with in-context examples and asked to describe which body parts are in contact. These textual descriptions are then converted into contact maps that guide the mesh optimization process.
- Core assumption: LVLMs have sufficient spatial reasoning capability to accurately identify contact points between people in 2D images, despite the inherent ambiguity of 2D projections.
- Evidence anchors: [abstract] "we introduce a novel data generation method that utilizes Large Vision Language Models (LVLMs) to annotate contact maps which guide test-time optimization"; [section] "We employ a LVLM to automatically generate C. The inherent challenge of using LVLMs for this task lies in their low performance when grounding complex spatial relationships depicted in 2D images"
- Break condition: The LVLM produces hallucinated or missing contacts, leading to degenerate mesh predictions that fail the automatic filtering threshold.

### Mechanism 2
- Claim: The denoising of contact maps using 2D keypoint chirality significantly improves the accuracy of the LVLM-generated contact maps by resolving laterality ambiguities.
- Mechanism: After the LVLM predicts body parts in contact with their sides (left/right/both), the normalized distance between corresponding 2D keypoints is used to determine the correct chirality, selecting the combination with the closest normalized distance.
- Core assumption: The predicted 2D keypoints have sufficient accuracy and alignment with the body regions to resolve laterality conflicts in the LVLM's output.
- Evidence anchors: [section] "We observe that even with contextual clues, LVLMs are unreliable when predicting the laterality of the body parts... To correct these mistakes, we exploit the commonalities between estimated 2D pose keypoints and surface body regions"; [section] "Due to the difference in appearance between same-side and opposite-side contacts, we only compare the combinations that match the description"
- Break condition: The 2D keypoint estimation fails or is significantly misaligned with the body regions, making the chirality correction unreliable.

### Mechanism 3
- Claim: Training a diffusion-based contact prior on a diverse dataset of pseudo-ground truth meshes improves HME performance on unseen interaction types by learning a more comprehensive representation of human contacts.
- Mechanism: The APU dataset, with its wide variety of interaction types and subjects, is used to train a diffusion model that conditions on initial mesh estimates. This trained prior is then used during test-time optimization to regularize the mesh parameters.
- Core assumption: The diversity in the APU dataset translates to better generalization of the contact prior to unseen interaction scenarios.
- Evidence anchors: [abstract] "We empirically show that using our dataset to train a diffusion-based contact prior, used as guidance during optimization, improves mesh estimation on unseen interactions"; [section] "Table 3 shows the results for the close interaction categories of the NTU RGB+D 120 test set. The contact prior benefits from the in-domain training data, performing better than BUDDI on all classes"
- Break condition: The diversity in the APU dataset does not translate to meaningful improvements in the contact prior's representation space, or the pseudo-ground truth meshes contain too many errors to learn from effectively.

## Foundational Learning

- Concept: Contact map formulation as a matching problem between surface body regions
  - Why needed here: Understanding how contact maps work is essential for comprehending the data generation method and the diffusion prior approach
  - Quick check question: What is the difference between a binary contact matrix and the soft contact loss proposed in this work?

- Concept: Diffusion models for image generation and their adaptation to 3D mesh estimation
  - Why needed here: The contact prior is implemented as a diffusion model, so understanding the basic principles of diffusion models is crucial
  - Quick check question: How does the noise level schedule in the diffusion model affect the training and inference process?

- Concept: Parametric human body models (SMPL-XA) and their parameter spaces
  - Why needed here: The mesh optimization process involves estimating parameters of the SMPL-XA model, so understanding the model's structure is important
  - Quick check question: What are the main components of the SMPL-XA parameter vector, and how do they affect the final mesh?

## Architecture Onboarding

- Component map: Image → GPT-4V → Contact map generation → VitPose/OpenPose → 2D keypoint estimation → Chirality denoising → SMPL-XA → Constrained optimization → Pseudo-ground truth mesh → Diffusion model → Contact prior → Test-time optimization → Improved mesh estimation

- Critical path:
  1. Image → LVLM query → contact map generation
  2. Contact map + image → 2D keypoint denoising → corrected contact map
  3. Corrected contact map + initial mesh estimates → constrained optimization → pseudo-ground truth mesh
  4. APU dataset → diffusion model training → improved contact prior
  5. Contact prior + image → test-time optimization → improved mesh estimation

- Design tradeoffs:
  - Using LVLMs for contact annotation trades annotation cost for potential hallucination errors
  - The soft contact loss provides robustness to uncertain contacts but may be less precise than hard constraints
  - Training on pseudo-ground truth meshes introduces noise but enables scaling to diverse interaction types

- Failure signatures:
  - Incorrect contact maps leading to unrealistic mesh reconstructions
  - Poor 2D keypoint estimation causing chirality denoising failures
  - Diffusion prior overfitting to APU dataset and failing on truly novel interactions
  - Constrained optimization failing to converge or producing implausible meshes

- First 3 experiments:
  1. Validate LVLM contact map generation on a small manually annotated dataset to measure accuracy and hallucination rates
  2. Test the chirality denoising method on LVLM-generated contact maps with known ground truth to measure improvement
  3. Train the diffusion prior on a subset of APU and evaluate on NTU RGB+D 120 to measure performance gains before full-scale training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using multiple LVLM outputs per image on the robustness and diversity of the contact maps generated?
- Basis in paper: [explicit] The paper mentions that querying a single LVLM once per image may replicate existing biases and suggests that producing multiple outputs per image and querying multiple LVLMs could provide a measure of uncertainty to the predicted contacts.
- Why unresolved: The authors did not implement this approach due to budget constraints, so the potential benefits and drawbacks of using multiple LVLM outputs are not empirically validated.
- What evidence would resolve it: Conducting experiments with multiple LVLM outputs per image and comparing the performance of the contact prior trained on this data to the current approach.

### Open Question 2
- Question: How does the performance of the contact prior vary across different interaction types, and what are the most challenging interactions for the model?
- Basis in paper: [inferred] The paper shows that the contact prior trained on the APU dataset improves accuracy for less common interaction scenarios, but does not provide a detailed breakdown of performance across all interaction types.
- Why unresolved: The paper does not analyze the performance of the contact prior for each individual interaction type, making it difficult to identify the most challenging interactions.
- What evidence would resolve it: Analyzing the PA-MPJPE results for each interaction type separately and identifying the interactions with the highest errors.

### Open Question 3
- Question: How does the diversity of the APU dataset compare to other datasets that focus on close interactions, and what is the impact of this diversity on the performance of HME models?
- Basis in paper: [explicit] The paper shows that the APU dataset contains a wider range of interaction types compared to existing datasets, but does not provide a comprehensive comparison of dataset diversity.
- Why unresolved: The paper does not quantify the diversity of the APU dataset in terms of specific metrics or compare it to other datasets using standardized measures.
- What evidence would resolve it: Conducting a detailed analysis of dataset diversity using metrics such as the number of unique interaction types, the distribution of interaction types, and the visual similarity between interaction types across different datasets.

## Limitations

- The reliance on pseudo-ground truth meshes introduces potential bias, as errors in the initial optimization could propagate through the diffusion training process
- The effectiveness of LVLM-generated contact maps remains uncertain due to potential hallucination and the inherent ambiguity of 2D-to-3D reasoning
- The 5.9% PA-MPJPE improvement is evaluated on a relatively small test set, and generalizability to truly novel interaction types remains untested

## Confidence

**High Confidence:** The methodological framework for integrating LVLMs with contact map generation and constrained optimization is well-articulated and technically sound. The core innovation of using LVLMs for automatic annotation represents a significant advancement in addressing data scarcity for close interactions.

**Medium Confidence:** The quantitative results showing 5.9% improvement in PA-MPJPE are compelling but based on a limited test set. The effectiveness of the chirality denoising mechanism, while theoretically justified, depends heavily on the quality of 2D keypoint estimation, which varies across images.

**Low Confidence:** The long-term scalability of the approach to diverse, real-world interaction scenarios and the potential for LVLM hallucination to introduce systematic biases in the generated dataset remain significant concerns that require further validation.

## Next Checks

1. **LVLM Accuracy Validation:** Manually annotate a subset of 100 images with ground truth contact maps and measure the precision, recall, and hallucination rate of the LVLM-generated contact maps. This will provide quantitative bounds on the reliability of the automatic annotation process.

2. **Generalization Stress Test:** Evaluate the trained contact prior on a curated test set containing interaction types that are completely absent from the APU dataset. Measure performance degradation to quantify the true generalization capability of the learned prior.

3. **Ablation on Pseudo-Ground Truth Quality:** Generate multiple versions of the APU dataset using different optimization seeds and measure the variance in contact prior performance. This will help quantify the sensitivity of the approach to noise in the pseudo-ground truth meshes.