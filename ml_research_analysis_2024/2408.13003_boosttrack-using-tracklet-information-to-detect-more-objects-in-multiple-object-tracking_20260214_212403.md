---
ver: rpa2
title: 'BoostTrack++: using tracklet information to detect more objects in multiple
  object tracking'
arxiv_id: '2408.13003'
source_url: https://arxiv.org/abs/2408.13003
tags:
- dence
- similarity
- detection
- boost
- tracking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper identifies limitations in the detection confidence boosting
  technique used in BoostTrack for multiple object tracking (MOT), specifically issues
  with false positives, identity switches, and new ID creation. To address these,
  the authors propose several improvements: a novel soft Buffered IoU (soft BIoU)
  similarity measure that accounts for tracklet uncertainty, an average similarity
  measure combining soft BIoU, Mahalanobis distance, and shape similarity for better
  object detection, a soft detection confidence boost that considers original detection
  confidence scores, and a varying similarity threshold based on the number of frames
  since a tracklet''s last update.'
---

# BoostTrack++

## Quick Facts
- arXiv ID: 2408.13003
- Source URL: https://arxiv.org/abs/2408.13003
- Authors: Vukašin Stanojević; Branimir Todorović
- Reference count: 40
- The paper proposes BoostTrack++, an improved TBD MOT algorithm that achieves near state-of-the-art results on MOT17 and sets new state-of-the-art HOTA and IDF1 scores on MOT20.

## Executive Summary
The paper addresses limitations in BoostTrack's detection confidence boosting technique for multiple object tracking, which suffers from false positives, identity switches, and unnecessary new ID creation. To solve these issues, the authors propose three independent improvements: a soft BIoU similarity measure that accounts for tracklet uncertainty, a soft detection confidence boost that considers original detection confidence scores, and a varying similarity threshold based on frames since last tracklet update. When combined with the BoostTrack+ baseline, BoostTrack++ achieves near state-of-the-art performance on MOT17 and new state-of-the-art HOTA and IDF1 scores on MOT20.

## Method Summary
BoostTrack++ extends the BoostTrack+ TBD MOT algorithm with three key improvements. First, it introduces a soft BIoU similarity measure that scales bounding boxes according to tracklet uncertainty, enabling better matching for low-confidence detections. Second, it implements a soft detection confidence boost that incorporates original detection confidence into the boosting calculation, preventing low-confidence detections from being boosted based solely on high similarity. Third, it uses a varying similarity threshold that starts high (0.95) and decreases to 0.8 over 20 frames since last tracklet update, accounting for prediction quality degradation over time. Each modification is independent and can be combined with any TBD MOT algorithm.

## Key Results
- BoostTrack++ achieves near state-of-the-art results on MOT17 test set
- BoostTrack++ sets new state-of-the-art HOTA (+3.4) and IDF1 (+2.6) scores on MOT20 test set
- The varying threshold technique (VT) combined with BoostTrack+ achieves 78.7 HOTA and 80.7 IDF1 on MOT17 validation set

## Why This Works (Mechanism)

### Mechanism 1
The soft BIoU similarity measure improves detection confidence boosting by scaling bounding boxes according to tracklet uncertainty, enabling better matching for low-confidence detections that would otherwise be discarded. Soft BIoU scales both detection and tracklet bounding boxes inversely proportional to tracklet confidence. When a tracklet hasn't been updated for many frames, its confidence is low, so the scaling factor is large, effectively enlarging the tracklet box to compensate for prediction drift. This creates a more forgiving similarity measure for difficult matches. The core assumption is that tracklet confidence is a reliable indicator of prediction quality, and scaling boxes proportionally improves association for low-confidence detections.

### Mechanism 2
The soft detection confidence boost technique addresses the flaw where detections with very low and relatively high confidence are treated equally, by incorporating original detection confidence into the boost calculation. Instead of simply taking the maximum of current confidence and a similarity-based boost, the new formula uses a weighted combination: α * current_confidence + (1-α) * (max_similarity^q). This means low-confidence detections require much higher similarity to be boosted, while high-confidence detections need only moderate similarity. The core assumption is that there's a positive correlation between detection confidence scores and the likelihood of being a true positive, which can be leveraged to make the boosting process more selective.

### Mechanism 3
The varying similarity threshold based on frames since last tracklet update addresses the issue that fixed thresholds don't account for prediction quality degradation over time. The threshold βj for each tracklet starts high (βhigh = 0.95) and linearly decreases to βlow (0.8) over 20 frames since last update. This means newly updated tracklets require very high similarity to boost detections, while stale tracklets accept lower similarity, accounting for their degraded prediction quality. The core assumption is that IoU values naturally decrease as the number of frames since last update increases, and this decrease is predictable enough to set appropriate thresholds.

## Foundational Learning

- **Kalman filter prediction and update cycle**: The paper uses Kalman filters for tracklet state prediction, and understanding how prediction error covariance grows over time is crucial for understanding why the varying threshold mechanism works. Quick check: How does the error covariance P change after n consecutive prediction steps without an update, assuming no process noise?

- **Hungarian algorithm for bipartite matching**: The paper uses Hungarian algorithm for associating detections with tracklets, and understanding how the cost matrix is constructed from similarity measures is important for grasping the overall tracking pipeline. Quick check: What is the relationship between the similarity matrix S and the cost matrix C used by the Hungarian algorithm in this context?

- **Multiple object tracking metrics (HOTA, IDF1, MOTA)**: The paper evaluates performance using these metrics, and understanding what each metric measures is important for interpreting the results and ablation study. Quick check: Which metric would be most sensitive to identity switches, and which would be most sensitive to missed detections?

## Architecture Onboarding

- **Component map**: Detector (YOLOX-X) → Detections with confidence scores → Kalman filter module → Tracklet state predictions and covariances → Similarity computation module → Computes IoU, Mahalanobis distance, shape similarity, soft BIoU → Confidence boosting module → Applies soft boost and varying threshold logic → Association module → Hungarian algorithm with cost matrix from similarities → Post-processing (GBI) → Final trajectory refinement

- **Critical path**: Detector → Similarity computation → Confidence boosting → Association → Kalman update. The confidence boosting must happen before association to influence which detections are considered.

- **Design tradeoffs**: Single-stage vs multi-stage association: The paper chooses single-stage to avoid identity switches, trading off some recall for precision. Fixed vs adaptive thresholds: Varying thresholds add complexity but handle prediction drift better than fixed thresholds. Multiple similarity measures: Using average of three measures adds robustness but increases computation.

- **Failure signatures**: Rapidly increasing IDs with no corresponding increase in IDSWs: Likely indicates the confidence boosting is creating false new tracks. Decreasing HOTA with increasing MOTA: Indicates the method is selecting more detections but with worse association quality. High variance in tracking performance across different MOT sequences: May indicate the hyperparameters aren't robust to different scenarios.

- **First 3 experiments**:
  1. Implement the soft BIoU similarity measure alone (without confidence boost or varying threshold) and compare IoU values on MOT validation set to baseline IoU
  2. Implement the soft confidence boost with fixed threshold and varying threshold separately, measuring the change in selected detections and their confidence distributions
  3. Combine all three proposed methods and run ablation study on MOT17 validation set, measuring HOTA, IDF1, IDSWs, and IDs to verify the claimed improvements

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but several important questions remain unresolved based on the content:

### Open Question 1
How does the varying similarity threshold (VT) perform when combined with detection confidence boosting methods other than BoostTrack? The authors state "Each of the proposed modifications is independent to the others and can be combined and used in any MOT algorithm," but only evaluate VT in combination with BoostTrack+, not with other state-of-the-art MOT algorithms like ByteTrack or FairMOT. An ablation study showing the impact of VT on tracking performance (HOTA, IDF1, IDSWs) when combined with different baseline MOT algorithms would resolve this.

### Open Question 2
What is the optimal value of the power parameter q in the soft detection confidence boost formula for different MOT datasets and scenarios? The authors mention "We run a grid search to find optimal parameters q and α" but only provide the best values found for MOT17. The optimal value of q may depend on factors like dataset characteristics (e.g., crowd density, camera motion) and baseline MOT algorithm used. A comprehensive study varying q across multiple MOT datasets and baseline algorithms would determine the relationship between q and tracking performance.

### Open Question 3
How does the performance of BoostTrack++ compare to state-of-the-art offline MOT methods on MOT17 and MOT20? The authors only compare BoostTrack++ to online MOT methods, stating "Among online trackers, BoostTrack++ ranks first in HOTA score on the MOT17 test set." The paper does not provide a direct comparison of BoostTrack++ with offline methods, which are generally considered to be more accurate due to their ability to process entire videos. A table comparing the performance of BoostTrack++ and state-of-the-art offline MOT methods on MOT17 and MOT20 test sets using metrics like HOTA, IDF1, and MOTA would resolve this.

## Limitations
- The hyperparameter values for soft detection confidence boost (α and q) were determined through grid search but not explicitly reported, making precise reproduction challenging.
- The evaluation relies heavily on MOT17 and MOT20 benchmarks, which may not generalize to other tracking scenarios or object classes.
- The performance gains on MOT20 (HOTA +3.4, IDF1 +2.6) are impressive but come from a single dataset, raising questions about robustness across different tracking conditions.

## Confidence
- **High confidence**: The identification of BoostTrack's limitations (false positives, identity switches, new ID creation) is well-supported by the analysis of the original method's behavior and aligns with known issues in detection confidence boosting approaches.
- **Medium confidence**: The proposed soft BIoU similarity measure is theoretically sound and the mechanism (scaling boxes by tracklet uncertainty) is clearly explained, but lacks direct empirical validation in isolation.
- **Low confidence**: The claim that combining all three improvements achieves near state-of-the-art on MOT17 and new state-of-the-art on MOT20 requires careful scrutiny of the ablation study and comparison methodology, as the exact implementation details and hyperparameters significantly impact results.

## Next Checks
1. Implement and validate the soft BIoU similarity measure independently on MOT validation data to confirm that scaling by tracklet confidence improves matching rates for low-confidence detections compared to standard IoU.

2. Conduct an ablation study isolating the soft detection confidence boost with varying thresholds versus fixed thresholds, measuring the impact on false positive rates and identity switches to verify the claimed improvements.

3. Test the complete BoostTrack++ pipeline on a third MOT dataset (e.g., MOT15 or DanceTrack) to assess generalizability beyond the two benchmark datasets used in the paper.