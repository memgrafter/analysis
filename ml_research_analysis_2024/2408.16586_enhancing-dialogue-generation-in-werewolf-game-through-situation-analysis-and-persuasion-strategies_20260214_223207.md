---
ver: rpa2
title: Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and
  Persuasion Strategies
arxiv_id: '2408.16586'
source_url: https://arxiv.org/abs/2408.16586
tags:
- agent
- werewolf
- game
- seer
- dialogue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study develops a large language model (LLM)-based AI for the
  Werewolf Game, employing situation analysis to guide dialogue generation and enhancing
  the werewolf role's persuasion skills through logical, credibility, and emotional
  appeals. The system architecture integrates task descriptions, game rules, dialogue
  history, and situation analysis to generate contextually coherent and logically
  sound responses.
---

# Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies

## Quick Facts
- arXiv ID: 2408.16586
- Source URL: https://arxiv.org/abs/2408.16586
- Reference count: 5
- The AI demonstrated effectiveness in persuading players to align with its voting behavior, achieving the highest win rate when playing the werewolf role in both English and Japanese tracks of the AIWolfDial2024 competition.

## Executive Summary
This study presents an LLM-based AI for the Werewolf Game that leverages situation analysis to guide dialogue generation and enhances persuasion strategies for the werewolf role. The system architecture integrates task descriptions, game rules, dialogue history, and situation analysis to generate contextually coherent and logically sound responses. By employing a three-stage persuasion sequence—logical, credibility, and emotional appeals—the werewolf role effectively influences voting behavior. The approach achieved top performance in the AIWolfDial2024 competition, demonstrating the success of context-based dialogue generation in games with incomplete information.

## Method Summary
The method employs an LLM-based approach with situation analysis to generate contextually coherent and logically sound responses for all roles. The werewolf role's persuasive skills are enhanced through logical, credibility, and emotional appeals. The system architecture includes input layers for task descriptions, game rules, and dialogue history; a situation analysis module; role-specific response generation; and a voting module using Zero-shot Chain-of-Thought reasoning. The approach was evaluated in the AIWolfDial2024 competition, demonstrating effectiveness in persuading players to align with the werewolf's voting behavior.

## Key Results
- Achieved the highest win rate for the werewolf role in both English and Japanese tracks of the AIWolfDial2024 competition.
- Demonstrated effectiveness in persuading players to align with its voting behavior.
- Confirmed the success of context-based dialogue generation in games with incomplete information.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Situation analysis improves response quality by synthesizing game state into structured context.
- Mechanism: LLM ingests task description, rules, and dialogue history, then generates a "Situational Analysis" that explicitly captures role dynamics, conflicting claims, and strategic implications.
- Core assumption: The LLM can reliably extract game-theoretic insights (e.g., "if there are two seer claims, one must be lying") and translate them into actionable response guidance.
- Evidence anchors:
  - [abstract]: "where each role is supported by situation analysis to aid response generation."
  - [section 4.1]: "this module is configured to take the Task Description, Werewolf Game Rules, and Dialogue History as inputs, processing these through a LLM."
  - [corpus]: Weak support; related papers focus on reasoning modules, not structured situation analysis.
- Break condition: If the LLM misidentifies key facts (e.g., misattributes the true seer), the downstream persuasion will be based on false premises.

### Mechanism 2
- Claim: Persuasive responses are more effective when grounded in logical, credibility, and emotional appeals.
- Mechanism: The werewolf role follows a three-stage sequence—logical appeal → credibility appeal → emotional appeal—targeting the same opponent to maximize persuasion across multiple turns.
- Core assumption: Multi-turn persuasion using varied appeals is more effective than a single persuasive tactic, especially in incomplete-information games.
- Evidence anchors:
  - [abstract]: "various persuasion strategies, including logical appeal, credibility appeal, and emotional appeal, are employed to effectively persuade other players to align with its actions."
  - [section 4.3]: "we identified three core persuasive strategies: Logical Appeal, Credibility Appeal, and Emotional Appeal."
  - [corpus]: Related work on persuasive dialogue (e.g., "Verbalized Bayesian Persuasion") supports multi-strategy persuasion.
- Break condition: If players detect inconsistency or if the werewolf's identity is exposed, credibility appeal collapses and emotional appeal backfires.

### Mechanism 3
- Claim: LLM-based voting decisions benefit from Zero-shot Chain-of-Thought reasoning over situation analysis and dialogue content.
- Mechanism: During voting, the LLM processes survivor list, situation analysis, and own statements via step-by-step reasoning to select a target consistent with the persuasion narrative.
- Core assumption: Step-by-step reasoning reduces randomness and aligns voting with the narrative built during the day.
- Evidence anchors:
  - [section 4.4]: "we employ the prompt shown in Figure 6 to guide the LLM in selecting a player to vote for from the current survivors. We also utilize Zero-shot Chain-of-Thought Prompting..."
  - [abstract]: "The AI demonstrated effectiveness in persuading players to align with its voting behavior."
  - [corpus]: Limited; related works focus on reasoning modules but not specifically Chain-of-Thought for voting.
- Break condition: If the LLM's reasoning is truncated or corrupted by noise in the dialogue, voting may become random or misaligned.

## Foundational Learning

- Concept: Game-theoretic reasoning in incomplete information settings.
  - Why needed here: Werewolf Game is a social deduction game where players infer roles from limited data; correct inference drives persuasion and survival.
  - Quick check question: If two players claim to be the seer and one divined you as human while the other as werewolf, which claim is more likely truthful if you know you are a villager?

- Concept: Persuasive strategy taxonomy (logos, ethos, pathos).
  - Why needed here: The werewolf must mask its identity and sway votes; each appeal type targets different cognitive/emotional levers in players.
  - Quick check question: Which appeal type relies on establishing speaker credibility, and why is that critical for the werewolf role?

- Concept: Prompt engineering with Chain-of-Thought for multi-step reasoning.
  - Why needed here: LLMs must integrate multiple data sources (rules, history, analysis) and output contextually coherent responses; CoT helps avoid hallucination and improves consistency.
  - Quick check question: What is the role of the "Let's think step by step" instruction in the situation analysis prompt?

## Architecture Onboarding

- Component map:
  Input layer: Task description, game rules, dialogue history.
  Situation analysis module: LLM processes inputs → structured game state.
  Role-specific response module: Generates dialogue using analysis.
  Werewolf persuasion module: Applies sequential logical → credibility → emotional appeals.
  Voting module: LLM selects target using CoT over analysis + statements.
  Output layer: Final dialogue and voting actions.

- Critical path:
  1. Situation analysis → accurate game state.
  2. Persuasion generation → influence voting.
  3. Voting alignment → coherent actions.

- Design tradeoffs:
  - Complexity vs. latency: More elaborate analysis increases accuracy but adds inference time.
  - Persuasiveness vs. detectability: Stronger persuasion risks exposure; weaker persuasion may fail to sway.
  - LLM model size vs. cost: Larger models may yield better reasoning but increase deployment expense.

- Failure signatures:
  - Misalignment between situation analysis and actual game state → illogical dialogue.
  - Repetitive or off-topic responses → poor prompt or analysis quality.
  - Inconsistent voting → broken reasoning chain or ignored persuasion output.

- First 3 experiments:
  1. Self-play baseline without situation analysis; compare win rates and coherence.
  2. Unit test persuasion sequence: feed controlled dialogue and verify each appeal type is triggered in order.
  3. Voting consistency check: run same dialogue scenario with multiple seeds; measure variance in chosen targets.

## Open Questions the Paper Calls Out
None

## Limitations
- The proprietary nature of the LLM used and specific prompts for situation analysis and persuasion generation makes exact reproduction difficult.
- The study lacks quantitative metrics for evaluating the quality of situation analysis outputs or alignment between analysis and persuasive dialogue.
- Reported success in competition settings may be influenced by opponent strength, which is not fully characterized.

## Confidence

- **High confidence**: The core architecture (situation analysis → response generation → persuasion module) is clearly defined and logically sound. The use of Chain-of-Thought for voting decisions is well-supported by recent LLM literature.
- **Medium confidence**: The effectiveness of the three-stage persuasion sequence (logical → credibility → emotional appeal) is plausible given social psychology principles, but lacks direct empirical validation in the Werewolf context.
- **Low confidence**: The generalizability of the approach beyond the competition environment and its robustness against diverse opponent strategies remain untested.

## Next Checks

1. **Prompt Sensitivity Analysis**: Systematically vary the situation analysis and persuasion prompts to measure their impact on response coherence and win rates. This will clarify the sensitivity of outcomes to prompt engineering.

2. **Adversarial Testing**: Deploy the AI against a battery of opponent strategies designed to detect deception (e.g., aggressive questioning, cross-examination of claims). Measure win rate degradation and identify failure modes.

3. **Ablation Study**: Remove the situation analysis module and replace it with a baseline that uses raw dialogue history. Compare win rates and dialogue quality to quantify the contribution of structured situation analysis.