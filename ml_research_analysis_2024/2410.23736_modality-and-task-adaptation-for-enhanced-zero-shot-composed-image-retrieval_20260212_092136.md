---
ver: rpa2
title: Modality and Task Adaptation for Enhanced Zero-shot Composed Image Retrieval
arxiv_id: '2410.23736'
source_url: https://arxiv.org/abs/2410.23736
tags:
- image
- task
- mota-adapter
- text
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the inherent task and modality discrepancies
  in zero-shot composed image retrieval (ZS-CIR) inversion-based methods. The authors
  propose MoTa-Adapter, a lightweight post-hoc framework that adapts dual encoders
  to the CIR task using automatically constructed text-anchored triplets.
---

# Modality and Task Adaptation for Enhanced Zero-shot Composed Image Retrieval

## Quick Facts
- arXiv ID: 2410.23736
- Source URL: https://arxiv.org/abs/2410.23736
- Authors: Haiwen Li; Fei Su; Zhicheng Zhao
- Reference count: 12
- Primary result: Introduces MoTa-Adapter that achieves state-of-the-art performance on four ZS-CIR benchmarks by addressing task and modality discrepancies with minimal trainable parameters

## Executive Summary
This paper addresses the fundamental task and modality discrepancies in zero-shot composed image retrieval (ZS-CIR) inversion-based methods. The authors propose MoTa-Adapter, a lightweight post-hoc framework that adapts dual encoders to the CIR task using automatically constructed text-anchored triplets. By employing Mixture-of-Experts task prompts on the text side and Modality Distribution Modulation on the image side, MoTa-Adapter significantly improves performance over existing inversion-based methods while introducing minimal trainable parameters and inference overhead.

## Method Summary
MoTa-Adapter is a post-hoc framework that adapts frozen dual encoders to ZS-CIR by addressing task and modality discrepancies. It uses text-anchored triplets automatically generated via LLM and MLLM, then fine-tunes a small set of parameters through Mixture-of-Experts Task Prompt Tuning (MoE-TPT) for the text encoder and Modality Distribution Modulation (MDM) for the image encoder. The method employs entropy-based optimization to focus on challenging samples during adaptation, achieving state-of-the-art performance with minimal computational overhead.

## Key Results
- Significantly improves R@10 performance over inversion-based methods: +17.3 on CIRR, +4.0 on FashionIQ, +11.4 on CIRCO, +4.3 on GeneCIS
- Introduces only 2.05% additional trainable parameters compared to frozen dual encoders
- Outperforms specialized adapters and full fine-tuning methods while maintaining zero-shot capability
- MoE-TPT and MDM components each contribute 1.1-3.4 points of improvement across benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task discrepancy arises because inversion training aligns pseudo-word tokens with single inputs (image or text), but CIR inference requires composing a query from both reference image and relative caption.
- Mechanism: MoTa-Adapter introduces Mixture-of-Experts Task Prompt Tuning (MoE-TPT) that learns to integrate the reference image features and relative caption through task-specific prompts, effectively bridging the gap between training and inference objectives.
- Core assumption: The dual-encoder structure inherently creates a task gap that cannot be resolved by fine-tuning only one side of the model.
- Evidence anchors:
  - [abstract] "The task discrepancy arises on the query-side, as the inversion training does not involve the integration of Ir and Tc."
  - [section] "we argue that the discrepancy lies in the dual-encoder structure... the integration of the reference image Ir and the relative caption Tc on the query side is essential"
  - [corpus] Weak - corpus neighbors discuss task discrepancy but don't specifically anchor to the MoE-TPT mechanism described here.
- Break condition: If the relative captions are too diverse or complex for a fixed set of experts to capture effectively, or if the pseudo-word representation es* fails to provide sufficient context for expert routing.

### Mechanism 2
- Claim: Modality discrepancy exists because inversion training lacks the image modality when using text-based methods, creating a feature distribution mismatch at inference.
- Mechanism: Modality Distribution Modulation (MDM) uses learnable scale and shift parameters to align the image feature distribution from the image encoder with the textual embedding space expected by the inversion network.
- Core assumption: Despite CLIP's cross-modal alignment, internal covariance and scale differences persist between visual and textual modalities that require explicit modulation.
- Evidence anchors:
  - [abstract] "the modality discrepancy arises from the input feature distribution mismatch between training and inference"
  - [section] "MDM not only reduces the modality discrepancy but also integrates the internal information of the image features"
  - [corpus] Missing - corpus neighbors don't provide specific evidence for the MDM mechanism.
- Break condition: If the learnable parameters γ and β overfit to the specific training distribution and fail to generalize to unseen image distributions, or if the modulation disrupts the learned cross-modal alignment.

### Mechanism 3
- Claim: Entropy-based optimization improves adaptation efficiency by focusing on samples where the base model has high predictive uncertainty.
- Mechanism: Samples are weighted by the entropy of their predicted similarity distribution, with higher entropy samples receiving greater weight during adaptation.
- Core assumption: Challenging samples that the base model struggles with provide more informative gradients for adaptation than easy samples the model already handles well.
- Evidence anchors:
  - [section] "we propose an entropy-based optimization strategy that assigns greater attention to challenging samples"
  - [section] "A larger entropy H i c2t indicates higher predictive uncertainty of the base model for f i c"
  - [corpus] Weak - corpus neighbors don't provide evidence for this specific entropy-based weighting approach.
- Break condition: If the entropy calculation becomes dominated by noise in the similarity predictions, or if the exponential smoothing hyperparameter β is set too high causing the loss to focus too narrowly on a few difficult samples.

## Foundational Learning

- Concept: Cross-modal alignment and embedding spaces
  - Why needed here: Understanding how CLIP aligns image and text features in a joint embedding space is fundamental to grasping why inversion-based methods work and where they fail
  - Quick check question: Why does CLIP use cosine similarity rather than Euclidean distance for matching image and text embeddings?

- Concept: Parameter-efficient fine-tuning (PEFT) methods
  - Why needed here: MoTa-Adapter builds on PEFT principles by only updating a small set of parameters rather than full model fine-tuning, which is crucial for efficiency
  - Quick check question: How does LoRA differ from adapter-based methods in terms of parameter updates and computational overhead?

- Concept: Mixture-of-Experts (MoE) architectures
  - Why needed here: The MoE-TPT component uses multiple expert prompt sets with a routing mechanism, requiring understanding of how MoE layers function and are trained
  - Quick check question: What is the role of the gating network in a standard MoE layer, and how does it differ from the routing function used in MoE-TPT?

## Architecture Onboarding

- Component map:
  Image encoder (frozen CLIP ViT) → MDM → Inversion Network (frozen) → Pseudo-word → MoE-TPT → Text Encoder (frozen CLIP Transformer) → Composed Feature → Contrastive Loss

- Critical path: Image → MDM → Inversion Network → Pseudo-word → MoE-TPT → Text Encoder → Composed Feature → Contrastive Loss

- Design tradeoffs:
  - MoE vs single prompt set: MoE captures diverse modification types but adds routing complexity; single prompts are simpler but may not handle all modification types effectively
  - MDM modulation vs feature alignment: MDM provides explicit distribution matching but adds parameters; alignment could be learned implicitly but may be less effective
  - Entropy weighting vs uniform weighting: Entropy focuses on challenging samples but may overfit to difficult cases; uniform weighting is more stable but less sample-efficient

- Failure signatures:
  - Performance degrades on FashionIQ but improves on other datasets → Domain mismatch between MoTa-CIR dataset and FashionIQ distribution
  - Training loss plateaus early → Entropy weighting may be too aggressive or the expert routing isn't learning meaningful patterns
  - Inference speed significantly slower than baseline → MDM parameters too large or routing computation inefficient

- First 3 experiments:
  1. Ablation test: Remove MDM and retrain - expect performance drop on real-world datasets but minimal change on FashionIQ, confirming modality discrepancy importance
  2. Routing analysis: Visualize expert activation patterns across different relative caption types - should show experts specializing in attribute manipulation, substitution, and removal
  3. Entropy sensitivity: Vary β hyperparameter in entropy weighting - should find an optimal range where challenging samples are emphasized without overfitting to noise

## Open Questions the Paper Calls Out

- **Question**: What is the impact of domain-specific triplet datasets on generalization across different ZS-CIR benchmarks?
- **Basis in paper**: [explicit] The authors note that their MoTa-CIR dataset (constructed from CC3M-595k) slightly underperforms RTD on FashionIQ, which is trained with textual supervision, and suggest constructing multi-domain triplet datasets
- **Why unresolved**: While the authors identify this limitation and suggest multi-domain datasets as a future direction, they don't empirically test how domain-specific versus multi-domain training data affects generalization
- **What evidence would resolve it**: Experiments comparing MoTa-Adapter trained on domain-specific triplets (fashion, real-world, etc.) versus multi-domain triplets across all ZS-CIR benchmarks

## Limitations

- The entropy-based optimization strategy lacks rigorous theoretical justification and could be sensitive to hyperparameter settings
- The automatic triplet generation pipeline depends heavily on the quality of LLaMA3-8B and Qwen2.5-VL-32B outputs without thorough quality analysis
- Limited empirical validation of the modality discrepancy claim despite theoretical reasoning

## Confidence

**High confidence** in claims about task discrepancy and the general effectiveness of MoTa-Adapter, supported by consistent performance improvements across all four benchmarks (average R@10 improvements of 4.0-17.3 points).

**Medium confidence** in the specific mechanisms of MDM and MoE-TPT effectiveness, as the paper lacks detailed analysis of feature distributions and routing behavior.

**Low confidence** in the generalizability of results to other domains or more complex relative captions, given the limited analysis of triplet quality and potential for domain-specific overfitting.

## Next Checks

1. **Feature Distribution Analysis**: Quantitatively measure and visualize the feature distribution shifts between the image and text modalities before and after MDM application, comparing cosine similarity distributions and internal covariance matrices across multiple datasets.

2. **Expert Routing Analysis**: Conduct a systematic analysis of MoE-TPT routing patterns by categorizing relative captions into modification types (attribute addition, removal, substitution) and measuring expert activation consistency across semantically similar queries.

3. **Triplet Quality Assessment**: Evaluate the quality and diversity of automatically generated triplets by measuring inter-annotator agreement, checking for systematic biases in modification types, and testing model robustness to noisy or ambiguous triplets through controlled experiments.