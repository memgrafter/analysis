---
ver: rpa2
title: Demographic Predictability in 3D CT Foundation Embeddings
arxiv_id: '2412.00110'
source_url: https://arxiv.org/abs/2412.00110
tags:
- embeddings
- race
- regression
- demographic
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether self-supervised 3D CT embeddings
  capture demographic information such as age, sex, and race. Using embeddings from
  the CT Foundation model trained on the NLST dataset, multiple classifiers were evaluated
  for demographic prediction.
---

# Demographic Predictability in 3D CT Foundation Embeddings

## Quick Facts
- arXiv ID: 2412.00110
- Source URL: https://arxiv.org/abs/2412.00110
- Reference count: 7
- Self-supervised CT embeddings effectively encode age and sex, with limited race prediction capability

## Executive Summary
This study investigates whether self-supervised 3D CT embeddings capture demographic information such as age, sex, and race. Using embeddings from the CT Foundation model trained on the NLST dataset, multiple classifiers were evaluated for demographic prediction. The results show that embeddings effectively encode age and sex, with a linear regression model achieving a root mean square error (RMSE) of 3.8 years for age prediction and a softmax regression model attaining an AUC of 0.998 for sex classification. However, race prediction was less effective, with an AUC of 0.878, likely due to the dataset's demographic composition. These findings highlight the need for further exploration into the information encoded in self-supervised learning frameworks to ensure fairness, privacy, and responsible use in healthcare AI applications.

## Method Summary
The study utilized embeddings from a self-supervised CT Foundation model trained on the National Lung Screening Trial (NLST) dataset. These embeddings were extracted from chest CT scans and used as input features for demographic prediction. Three demographic attributes were targeted: age, sex, and race. For age prediction, a linear regression model was trained on the embeddings, achieving an RMSE of 3.8 years. Sex classification was performed using a softmax regression model, which achieved an AUC of 0.998. Race prediction, however, was less successful, with an AUC of 0.878. The authors attribute the lower performance in race prediction to the demographic bias in the NLST dataset. The study emphasizes the need for further exploration into the fairness, privacy, and responsible use of self-supervised learning frameworks in healthcare applications.

## Key Results
- Linear regression model achieved RMSE of 3.8 years for age prediction
- Softmax regression model attained AUC of 0.998 for sex classification
- Race prediction showed lower performance with AUC of 0.878

## Why This Works (Mechanism)
The effectiveness of demographic prediction from CT embeddings can be attributed to the self-supervised learning framework's ability to capture anatomical and physiological features that correlate with demographic attributes. Age-related changes in lung structure, density, and volume are likely encoded in the embeddings, enabling accurate age prediction. Similarly, sex differences in lung anatomy, such as size and shape, are captured, facilitating sex classification. However, race prediction is less effective due to the limited demographic diversity in the NLST dataset, which may not adequately represent the broader population. This highlights the importance of dataset diversity in ensuring fair and accurate demographic predictions.

## Foundational Learning
1. **Self-supervised Learning**: Why needed - To learn useful representations from unlabeled data. Quick check - Verify that the model can reconstruct or predict masked inputs.
2. **3D CT Embeddings**: Why needed - To capture spatial and anatomical features from volumetric medical images. Quick check - Ensure embeddings retain relevant anatomical information.
3. **Demographic Prediction**: Why needed - To assess the presence of sensitive information in embeddings. Quick check - Evaluate classifier performance on known demographic labels.
4. **Fairness and Bias**: Why needed - To ensure equitable performance across diverse populations. Quick check - Analyze model performance across different demographic groups.
5. **Privacy Concerns**: Why needed - To prevent unintended disclosure of sensitive information. Quick check - Assess the potential for re-identification from embeddings.
6. **Dataset Diversity**: Why needed - To improve generalizability and reduce bias. Quick check - Compare performance across datasets with varying demographics.

## Architecture Onboarding
- **Component Map**: CT scan -> CT Foundation model -> Embeddings -> Demographic classifiers (age, sex, race)
- **Critical Path**: The embeddings extraction from CT scans is the critical component, as it directly influences the performance of all downstream classifiers.
- **Design Tradeoffs**: The use of self-supervised learning avoids the need for labeled data but may encode unintended demographic information, raising privacy and fairness concerns.
- **Failure Signatures**: Poor demographic prediction performance may indicate issues with embedding quality, dataset bias, or insufficient representation of certain demographic groups.
- **Three First Experiments**:
  1. Validate embeddings by testing reconstruction or prediction tasks.
  2. Evaluate classifier performance on a holdout set to assess generalization.
  3. Analyze embedding features to identify demographic-related patterns.

## Open Questions the Paper Calls Out
None

## Limitations
- Demographic bias in the NLST dataset limits generalizability and race prediction performance.
- Focus on chest CT scans may not extend to other anatomical regions or imaging modalities.
- Absence of ablation studies to identify specific features driving demographic predictions.

## Confidence
- **High confidence**: Effectiveness of CT Foundation embeddings for age and sex prediction (RMSE 3.8 years for age, AUC 0.998 for sex).
- **Medium confidence**: Race prediction being less effective (AUC 0.878) due to dataset bias.
- **Medium confidence**: Need for further exploration into fairness, privacy, and responsible use.

## Next Checks
1. Replicate the study using a more demographically diverse CT dataset to determine if race prediction performance improves and to assess generalizability across different populations.
2. Conduct an ablation study or feature importance analysis to identify which specific aspects of the embeddings are driving demographic predictions and whether these features are clinically relevant or represent potential biases.
3. Evaluate the impact of demographic encoding on downstream clinical tasks by comparing model performance on clinically relevant predictions (e.g., disease detection) when controlling for or removing demographic information from the embeddings.