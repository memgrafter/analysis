---
ver: rpa2
title: Leveraging Large Language Models for Semantic Query Processing in a Scholarly
  Knowledge Graph
arxiv_id: '2405.15374'
source_url: https://arxiv.org/abs/2405.15374
tags:
- query
- knowledge
- research
- information
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a framework that integrates Large Language Models
  (LLMs) with a scholarly knowledge graph to enhance query processing for academic
  research. The core method involves a Deep Document Model (DDM) for fine-grained
  document representation and a KG-enhanced Query Processing (KGQP) approach that
  leverages KG structure to improve query accuracy and efficiency.
---

# Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph

## Quick Facts
- **arXiv ID**: 2405.15374
- **Source URL**: https://arxiv.org/abs/2405.15374
- **Reference count**: 22
- **Key outcome**: KG-based method outperforms vector-based baseline across relevance, accuracy, completeness, and readability on 10 computer science papers

## Executive Summary
This paper proposes a framework that integrates Large Language Models (LLMs) with a scholarly knowledge graph to enhance query processing for academic research. The core method involves a Deep Document Model (DDM) for fine-grained document representation and a KG-enhanced Query Processing (KGQP) approach that leverages KG structure to improve query accuracy and efficiency. Experiments on a dataset of 10 computer science papers demonstrate that the KG-based method outperforms a vector-based baseline across multiple evaluation dimensions.

## Method Summary
The proposed framework combines a Deep Document Model (DDM) for hierarchical document decomposition with KG-enhanced Query Processing (KGQP) for semantic query handling. DDM parses academic papers into fine-grained structures using an ontology (DOMO), creating RDF triples for KG construction. KGQP transforms user queries into triples, performs SPARQL-based matching against the KG, and uses LLM ranking to select relevant context for answer generation. The system employs automatic LLM-SPARQL fusion to retrieve facts and textual nodes from the Academic Scholarly Knowledge Graph (ASKG).

## Key Results
- KG-based method outperforms vector-based baseline across relevance, accuracy, completeness, and readability metrics
- KGQP demonstrates superior performance in handling complex queries with multiple entities and relationships
- The system shows promise for advancing scholarly knowledge management and discovery in academic research

## Why This Works (Mechanism)

### Mechanism 1
The Deep Document Model (DDM) improves knowledge graph construction by decomposing academic papers into fine-grained hierarchical structures rather than treating documents as monolithic text blobs. By parsing the logical structure of documents and mapping it to an ontology (DOMO), DDM enables the extraction of semantic relationships at multiple granularities, which can then be represented as structured triples in the knowledge graph.

### Mechanism 2
KG-enhanced Query Processing (KGQP) reduces LLM hallucination by grounding responses in knowledge graph facts through SPARQL query matching. KGQP transforms user queries into triples (LOT), performs exact or fuzzy matching against KG triples (CTKG), and uses LLM ranking to select the most relevant context for response generation.

### Mechanism 3
The combination of DDM-structured KGs with LLMs creates a retrieval-augmented generation system that outperforms pure vector-based retrieval in both relevance and completeness. The KG provides structured metadata and entity relationships that guide LLM context selection, while the LLM provides natural language understanding to bridge between user queries and KG structure.

## Foundational Learning

- **Concept**: RDF and SPARQL query language
  - Why needed here: The knowledge graph uses RDF triples, and KGQP relies on SPARQL for querying the graph structure
  - Quick check question: What does a SPARQL query like "SELECT ?s ?p ?o WHERE { ?s ?p ?o }" return?

- **Concept**: Document Object Model (DOM) and ontology design
  - Why needed here: DDM is inspired by DOM concepts and uses an ontology (DOMO) to represent document structure
  - Quick check question: How does DOMO differ from traditional document structure analysis approaches?

- **Concept**: Retrieval-Augmented Generation (RAG) systems
  - Why needed here: The system combines knowledge graph retrieval with LLM generation, following RAG principles
  - Quick check question: What are the key components of a RAG system and how do they interact?

## Architecture Onboarding

- **Component map**: User query -> KGQP -> SPARQL matching -> LLM context -> Answer generation
- **Critical path**: User query → KGQP → SPARQL matching → LLM context → Answer generation
- **Design tradeoffs**:
  - Fine-grained vs. coarse-grained KG structure (more detail vs. query efficiency)
  - Exact vs. fuzzy matching (precision vs. recall)
  - KG size vs. query performance (completeness vs. speed)
  - LLM model choice (capability vs. hallucination risk)
- **Failure signatures**:
  - SPARQL query timeouts indicating KG size issues
  - Low overlap entity ratios suggesting KG coverage gaps
  - High embedding distances showing semantic mismatch between KG and vector-based approaches
  - LLM responses that ignore KG context (hallucination persists)
- **First 3 experiments**:
  1. Test SPARQL query performance on small vs. large KG subsets
  2. Compare exact vs. fuzzy matching accuracy for different query complexity levels
  3. Evaluate the impact of different chunking strategies on KGQP retrieval quality

## Open Questions the Paper Calls Out

### Open Question 1
How can the Deep Document Model (DDM) be extended to effectively handle non-textual elements such as tables, mathematical formulas, and charts in academic papers? The paper mentions that "DDM primarily focuses on textual content" and suggests extending its capabilities to include further content structural decomposition of tables, mathematical formulas, equations, and charts.

### Open Question 2
How can the KG-enhanced Query Processing (KGQP) framework be optimized to handle complex queries involving multiple entities and relationships in the scholarly knowledge graph? The paper discusses the KGQP method and its ability to leverage the KG structure to improve query accuracy and efficiency, but it does not provide specific details on handling complex queries involving multiple entities and relationships.

### Open Question 3
How can the proposed KG-based question answering system be scaled to handle large-scale datasets and real-world academic paper collections? The paper mentions that the current experiments were conducted on a relatively small dataset and discusses the potential of the KG-based approach for larger-scale datasets, but it does not provide specific details on scaling the system.

## Limitations

- Experimental validation based on only 10 computer science papers limits generalizability to other domains
- Limited details on hyperparameter settings and prompt engineering approaches for LLM integration
- Small sample size and limited evaluation questions reduce statistical confidence in performance claims

## Confidence

- **High confidence**: The core architectural concepts (DDM for document decomposition, KGQP for query processing, SPARQL-based retrieval) are well-founded and align with established practices in knowledge graph construction and RAG systems
- **Medium confidence**: The claimed performance improvements over vector-based baselines are supported by internal experiments, but the small sample size reduces statistical confidence
- **Medium confidence**: The mechanism for reducing LLM hallucination through KG grounding is theoretically sound but would require more extensive testing across diverse query types

## Next Checks

1. **Scale validation**: Test the KGQP system on a larger corpus of 50-100 papers across multiple domains to assess scalability and domain transferability
2. **Hallucination measurement**: Design controlled experiments comparing LLM responses with and without KG grounding on complex fact-verification queries to quantify hallucination reduction
3. **Component ablation study**: Systematically evaluate the contribution of each KGQP component (exact vs. fuzzy matching, LLM ranking, entity recognition) to identify the most critical factors for performance improvements