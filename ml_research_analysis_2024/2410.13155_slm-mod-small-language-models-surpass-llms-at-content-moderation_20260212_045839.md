---
ver: rpa2
title: 'SLM-Mod: Small Language Models Surpass LLMs at Content Moderation'
arxiv_id: '2410.13155'
source_url: https://arxiv.org/abs/2410.13155
tags:
- moderation
- content
- slms
- llms
- subreddit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Fine-tuned small language models (SLMs) with fewer than 15B parameters
  outperform larger off-the-shelf LLMs in content moderation tasks. On 150K Reddit
  comments across 15 communities, SLMs achieved 11.5% higher accuracy and 25.7% higher
  recall than zero-shot LLMs, with only slightly lower precision.
---

# SLM-Mod: Small Language Models Surpass LLMs at Content Moderation

## Quick Facts
- **arXiv ID:** 2410.13155
- **Source URL:** https://arxiv.org/abs/2410.13155
- **Reference count:** 40
- **Primary result:** Fine-tuned small language models (SLMs) with fewer than 15B parameters outperform larger off-the-shelf LLMs in content moderation tasks

## Executive Summary
Fine-tuned small language models with fewer than 15B parameters significantly outperform larger off-the-shelf LLMs in content moderation tasks. On a dataset of 150K Reddit comments across 15 communities, SLMs achieved 11.5% higher accuracy and 25.7% higher recall than zero-shot LLMs, with only slightly lower precision. The performance advantage held true even when LLMs were given few-shot in-context learning, and SLMs maintained superior performance on imbalanced datasets with 1-10% moderation rates.

The study demonstrates that SLMs can generalize effectively across different communities, outperforming LLMs by up to 11.6% in cross-domain settings. However, qualitative analysis revealed that SLMs tend to be more aggressive at flagging harmful content, which may lead to over-moderation of short comments. This finding suggests that while SLMs offer superior detection capabilities, careful calibration may be needed to balance moderation effectiveness with user experience.

## Method Summary
The study evaluated 16 LLMs and 14 SLMs on a dataset of 150K Reddit comments from 15 communities, using accuracy, precision, recall, and AUC metrics. Models were tested in zero-shot and few-shot configurations, with performance compared across different dataset imbalance ratios (1-10% moderation rates). Cross-community generalization was assessed by training on one community and testing on others.

## Key Results
- SLMs achieved 11.5% higher accuracy and 25.7% higher recall than zero-shot LLMs on content moderation tasks
- Even with few-shot in-context learning, LLMs still underperformed SLMs by 5-7% in accuracy
- SLMs maintained higher AUC scores on imbalanced datasets (1-10% moderation rate) compared to LLMs

## Why This Works (Mechanism)
SLMs can be fine-tuned on domain-specific data to optimize for content moderation tasks, while large off-the-shelf LLMs lack this specialized training. The targeted adaptation allows SLMs to develop more nuanced understanding of moderation contexts and better balance precision-recall tradeoffs for the specific task.

## Foundational Learning
1. **Content moderation evaluation metrics** (accuracy, precision, recall, AUC) - why needed: to comprehensively assess model performance in balancing false positives and false negatives; quick check: verify metrics are calculated using standard formulas
2. **Zero-shot vs few-shot learning** - why needed: to compare model performance with and without task-specific examples; quick check: confirm number and quality of few-shot examples
3. **Cross-domain generalization** - why needed: to validate model robustness across different communities and contexts; quick check: examine performance variance across communities
4. **Imbalanced dataset handling** - why needed: content moderation datasets typically have low positive class prevalence; quick check: verify appropriate metrics (AUC) are used for imbalanced data

## Architecture Onboarding

**Component Map:** Data Preprocessing -> Model Training -> Evaluation -> Cross-validation -> Generalization Testing

**Critical Path:** Reddit comment dataset → Model fine-tuning → Zero-shot vs few-shot evaluation → Cross-community testing → Performance comparison

**Design Tradeoffs:** SLMs offer better task-specific performance through fine-tuning but require training data and compute resources, while LLMs provide convenience but lack optimization for moderation tasks.

**Failure Signatures:** Over-moderation of short comments, potential overfitting to Reddit-style data, reduced performance on non-Reddit content types.

**First 3 Experiments to Run:**
1. Test SLMs and LLMs on content from different platforms (Twitter, Facebook, forums)
2. Conduct human evaluation to validate automated moderation decisions
3. Evaluate performance on datasets with different imbalance ratios beyond 1-10%

## Open Questions the Paper Calls Out
None

## Limitations
- Study based on single dataset of 150K Reddit comments, limiting generalizability
- 1-3% precision drop in SLMs may lead to over-moderation affecting user experience
- Performance claims may reflect domain-specific optimization rather than universal superiority

## Confidence

| Claim | Confidence |
|-------|------------|
| Fine-tuned SLMs outperform zero-shot LLMs on Reddit moderation data | High |
| SLMs show general superiority in content moderation | Medium |

## Next Checks
1. Test the SLMs and baseline LLMs on content from different platforms (Twitter, Facebook, forum posts) to assess cross-platform generalization
2. Conduct human evaluation studies to determine if the higher recall rates translate to meaningful safety improvements or excessive censorship
3. Evaluate performance on datasets with different imbalance ratios (beyond the 1-10% range tested) to verify robustness claims