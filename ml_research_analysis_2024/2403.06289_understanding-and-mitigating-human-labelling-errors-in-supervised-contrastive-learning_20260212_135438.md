---
ver: rpa2
title: Understanding and Mitigating Human-Labelling Errors in Supervised Contrastive
  Learning
arxiv_id: '2403.06289'
source_url: https://arxiv.org/abs/2403.06289
tags:
- learning
- errors
- human-labelling
- https
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Human-labelling errors, though prevalent in vision datasets, have
  been underexplored in the context of supervised contrastive learning (SCL). This
  paper shows that such errors differ from synthetic noise and uniquely impact SCL,
  especially through false positive samples, which constitute ~99% of problematic
  learning signals.
---

# Understanding and Mitigating Human-Labelling Errors in Supervised Contrastive Learning

## Quick Facts
- arXiv ID: 2403.06289
- Source URL: https://arxiv.org/abs/2403.06289
- Reference count: 40
- Human-labelling errors uniquely impact supervised contrastive learning, with false positives comprising ~99% of problematic learning signals

## Executive Summary
This paper addresses the underexplored problem of human-labelling errors in supervised contrastive learning (SCL). Unlike synthetic noise, human errors create a distinct pattern where false positive samples dominate problematic learning signals. The authors propose SCL-RHE, a novel objective that mitigates these errors by reducing the influence of "easy positives" while emphasizing true positives that are semantically aligned but distant in feature space. The method demonstrates superior performance compared to existing SCL and noise-mitigation approaches across multiple vision benchmarks.

## Method Summary
The authors develop SCL-RHE, a modified supervised contrastive learning objective that specifically addresses human-labelling errors. The method introduces two key modifications: it reduces the weight of "easy positives" (samples that are trivially similar) and emphasizes "true positives" that are semantically similar but farther apart in feature space. This approach is designed to be robust in realistic low-noise scenarios (<5%) where existing methods often overfit. The framework maintains computational efficiency while achieving improved accuracy on standard benchmarks.

## Key Results
- Achieves up to 6.3% higher accuracy than cross-entropy training on CIFAR-10/100 and ImageNet-1K
- Reduces training time by approximately 30% compared to prior methods
- Demonstrates robustness to synthetic noise up to 20% while maintaining strong performance in real-world low-noise scenarios

## Why This Works (Mechanism)
The mechanism behind SCL-RHE's effectiveness lies in its nuanced handling of the contrastive learning space. Human-labelling errors create a disproportionate number of false positive pairs that can corrupt the learning process. By downweighting easy positives (which are often incorrectly labeled as similar) and emphasizing true positives that are semantically aligned but have larger feature distances, the method creates a more robust learning signal. This approach is particularly effective because human errors tend to create false positives rather than false negatives, making the "easy positive" reduction strategy well-suited to the problem.

## Foundational Learning
- Supervised Contrastive Learning (SCL): A framework that learns representations by pulling together samples of the same class and pushing apart samples of different classes. Why needed: Forms the baseline approach that SCL-RHE improves upon.
- Noise in Deep Learning: The presence of incorrect labels in training data that can degrade model performance. Why needed: Understanding how different types of noise affect learning is crucial for developing robust methods.
- False Positive vs False Negative Errors: False positives occur when different classes are incorrectly labeled as the same, while false negatives occur when the same class is labeled as different. Why needed: The paper shows that human errors are predominantly false positives, which shapes the mitigation strategy.

## Architecture Onboarding

Component Map:
Input -> Feature Extractor -> Contrastive Loss (SCL-RHE) -> Model Parameters

Critical Path:
The critical path involves computing the modified contrastive loss that downweights easy positives and emphasizes true positives. This requires efficient computation of pairwise similarities and distance-based weighting.

Design Tradeoffs:
The method trades some complexity in the loss function for improved robustness to labeling errors. The weighting scheme adds computational overhead but enables better performance in low-noise scenarios.

Failure Signatures:
The method may underperform if the assumption about false positive dominance doesn't hold, or if the distance metrics don't accurately capture semantic similarity in the feature space.

First Experiments:
1. Test SCL-RHE on CIFAR-10 with varying levels of synthetic noise to validate robustness claims
2. Compare training time and accuracy against standard SCL and cross-entropy baselines
3. Evaluate transfer learning performance on a downstream task to assess representation quality

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the generalization of their findings to other domains beyond vision, the impact of systematic labeling biases, and the scalability of their approach to larger, more complex datasets.

## Limitations
- Focuses primarily on vision datasets with limited exploration of other domains like NLP or multimodal data
- Assumes human errors are predominantly false positives without fully accounting for potential systematic biases
- Evaluation metrics could be more comprehensive regarding computational resources and scalability

## Confidence

High confidence: Characterization of human-labelling errors as distinct from synthetic noise and their unique impact on SCL learning signals

Medium confidence: Effectiveness of SCL-RHE in improving accuracy on benchmark datasets, as results show consistent but modest improvements

Medium confidence: Computational efficiency claims, as training time comparisons are made against specific baselines without broader benchmarking

## Next Checks

1. Test SCL-RHE's robustness across diverse dataset domains beyond vision, particularly in NLP and multimodal settings where labeling errors may have different characteristics

2. Conduct ablation studies to quantify the individual contributions of the two key components of SCL-RHE (easy positive reduction and true positive emphasis)

3. Evaluate the method's performance with real-world human-labelling errors from production datasets, rather than simulated noise scenarios