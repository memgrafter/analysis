---
ver: rpa2
title: Data augmentation method for modeling health records with applications to clopidogrel
  treatment failure detection
arxiv_id: '2402.18046'
source_url: https://arxiv.org/abs/2402.18046
tags:
- data
- augmentation
- records
- medical
- codes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses data scarcity in applying natural language
  processing (NLP) algorithms to Electronic Health Records (EHR) by proposing a data
  augmentation method that rearranges medical records within visits. The approach
  mitigates ordinal biases and increases training data by permuting records within
  the same medical types (diagnosis, procedures, prescriptions) while preserving inherent
  ordering between types.
---

# Data augmentation method for modeling health records with applications to clopidogrel treatment failure detection

## Quick Facts
- arXiv ID: 2402.18046
- Source URL: https://arxiv.org/abs/2402.18046
- Reference count: 9
- Primary result: 5.3% absolute ROC-AUC improvement (0.908 → 0.961) for clopidogrel treatment failure detection

## Executive Summary
This study addresses data scarcity in applying natural language processing (NLP) algorithms to Electronic Health Records (EHR) by proposing a data augmentation method that rearranges medical records within visits. The approach mitigates ordinal biases and increases training data by permuting records within the same medical types (diagnosis, procedures, prescriptions) while preserving inherent ordering between types. Applied to clopidogrel treatment failure detection using BERT, the method achieved up to 5.3% absolute improvement in ROC-AUC (from 0.908 to 0.961) during pre-training with augmentation factor 8. The augmentation also improved performance during fine-tuning, especially when labeled training data was limited. The approach avoids generating synthetic data, maintaining fidelity to real patient records while enhancing model robustness.

## Method Summary
The method permutes medical codes within the same type (diagnosis, procedure, prescription) while preserving the ordering between types. This mitigates ordinal biases from flattening multi-visit sequences and increases training data without synthetic generation. The augmented data is used for pre-training BERT via masked language modeling, followed by fine-tuning on clopidogrel treatment failure labels. The permutation factor α controls the number of augmented sequences generated per original visit.

## Key Results
- 5.3% absolute ROC-AUC improvement (0.908 → 0.961) during pre-training with augmentation factor 8
- Test-time augmentation showed negligible impact (0.2% change) on ROC-AUC
- Performance improvements during fine-tuning were particularly notable when labeled training data was limited

## Why This Works (Mechanism)

### Mechanism 1
Permuting records within the same medical type mitigates ordinal biases introduced by flattening multi-visit sequences. When records are flattened across visits, an arbitrary visit order is imposed. Permuting within-visit records disrupts this artificial sequence while preserving medically meaningful inter-type order (diagnosis → procedure → prescription), forcing the model to learn type-invariant representations.

### Mechanism 2
Augmentation increases effective training data size, improving BERT's ability to learn robust embeddings. Each patient's visits generate factorial-many sequences; selecting a subset (factor α) multiplies the dataset size without synthetic generation, providing more gradient updates and variance in training examples.

### Mechanism 3
Permutation-based augmentation avoids ethical/legal issues of synthetic EHR generation. By only rearranging real records rather than generating new ones, the augmented data remains faithful to observed patient histories, sidestepping synthetic data controversies in healthcare.

## Foundational Learning

- **BERT pre-training objectives (MLM vs NSP)**: The paper explicitly drops NSP because flattened visit sequences lack natural sentence boundaries; understanding this choice is critical for reproducing the setup.
  - Quick check question: Why does the paper avoid using the next sentence prediction (NSP) objective during pre-training?

- **Permutation combinatorics in EHR visits**: The number of possible permutations is factorial in the number of records per type; understanding this informs computational feasibility decisions.
  - Quick check question: How many unique sequences can be generated from a single visit with 3 diagnoses, 2 procedures, and 1 prescription?

- **AUC and ROC curves for imbalanced medical datasets**: Treatment failure is a binary classification on a relatively small labeled set; understanding AUC interpretation is key for evaluating model performance.
  - Quick check question: What does an AUC improvement from 0.908 to 0.961 represent in absolute terms?

## Architecture Onboarding

- **Component map**: Data loader → Visit flattener → Within-visit permuter → BERT encoder (12-layer Transformer) → MLM head (pre-train) / classification head (fine-tune)
- **Critical path**:
  - For pre-training: Permute → Feed 512 tokens → MLM loss → Update embeddings
  - For fine-tuning: Permute training set → Feed → Classification loss → Update classifier and possibly encoder
- **Design tradeoffs**:
  - Permutation factor α vs. computational cost: higher α gives more data but exponential sequence growth
  - Permutation scope: within-type vs. cross-type affects ordinal bias mitigation vs. signal preservation
  - Pre-training data source: non-clopidogrel patients for general patterns vs. risk of domain shift
- **Failure signatures**:
  - No AUC gain: permutation destroying clinically relevant within-visit order
  - Overfitting on permutations: model memorizing specific sequences instead of learning robust patterns
  - Pre-training collapse: MLM unable to converge without NSP due to lack of sentence structure
- **First 3 experiments**:
  1. Run pre-training with α=1 (no augmentation) vs. α=4 on a small subset; verify AUC improvement in fine-tuning.
  2. Test permutation within vs. across medical types; measure impact on performance and training stability.
  3. Apply test-time augmentation during inference; confirm minimal (≤0.2%) performance change as reported.

## Open Questions the Paper Calls Out

- How does the proposed data augmentation method perform on other EHR-based prediction tasks beyond clopidogrel treatment failure detection?
- What is the optimal augmentation factor (α) for balancing computational cost and performance gains across different EHR datasets and model architectures?
- How does the permutation-based augmentation compare to other data augmentation strategies for EHR data, such as synthetic data generation or contrastive learning approaches?

## Limitations

- The assumption that within-visit order lacks clinical relevance remains unverified and could reduce signal quality if temporal dependencies exist.
- Pre-training on non-clopidogrel patients introduces potential domain shift risks despite providing general EHR pattern learning.
- Results are demonstrated on a single UK Biobank dataset, limiting external validation across different medical conditions or EHR systems.

## Confidence

**High confidence**: The core augmentation mechanism and 5.3% absolute ROC-AUC improvement are clearly specified and verifiable.

**Medium confidence**: The mechanism by which permutation mitigates ordinal biases is well-explained, but empirical validation is limited to presented results.

**Low confidence**: The claim about avoiding synthetic data ethical issues lacks discussion of potential regulatory interpretations of data permutation.

## Next Checks

1. Systematically vary the augmentation factor α from 1 to 16 and measure ROC-AUC changes to verify claimed improvement plateaus appropriately.

2. Design a controlled experiment comparing performance with full within-visit permutation versus preserving natural visit order to test whether ordinal biases are genuinely detrimental versus containing useful signal.

3. Apply the augmentation method to a different binary classification task in the same EHR dataset (e.g., diabetes treatment response) and measure whether similar performance improvements occur to test broader applicability.