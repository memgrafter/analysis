---
ver: rpa2
title: 'SymBa: Symbolic Backward Chaining for Structured Natural Language Reasoning'
arxiv_id: '2402.12806'
source_url: https://arxiv.org/abs/2402.12806
tags:
- reasoning
- symba
- young
- proof
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper identifies that existing LLM-based backward chaining\
  \ systems (Least-to-most prompting and LAMBADA) are incomplete, lacking crucial\
  \ algorithmic components like backtracking and binding propagation found in classic\
  \ SLD Resolution. To address this, the authors propose SymBa (Symbolic Backward\
  \ Chaining), which integrates a symbolic solver and an LLM\u2014where the solver\
  \ controls the proof process and the LLM is only called when new information is\
  \ needed."
---

# SymBa: Symbolic Backward Chaining for Structured Natural Language Reasoning

## Quick Facts
- arXiv ID: 2402.12806
- Source URL: https://arxiv.org/abs/2402.12806
- Authors: Jinu Lee; Wonseok Hwang
- Reference count: 39
- Primary result: SymBa achieves 79.8-96.3% answer accuracy and significant efficiency gains (9× fewer tokens, 22× faster) across seven reasoning benchmarks

## Executive Summary
This paper identifies critical incompleteness in existing LLM-based backward chaining systems like Least-to-most prompting and LAMBADA, which lack essential algorithmic components such as backtracking and binding propagation found in classic SLD Resolution. To address this gap, the authors propose SymBa (Symbolic Backward Chaining), a novel system that integrates a symbolic solver with an LLM where the solver controls the proof process and the LLM is only called when new information is needed. SymBa demonstrates significant improvements in both accuracy (79.8-96.3% answer accuracy) and efficiency (9× fewer tokens, 22× faster) across seven benchmarks covering deductive, relational, and arithmetic reasoning tasks, outperforming existing baselines.

## Method Summary
SymBa implements a symbolic backward chaining system based on SLD Resolution that integrates a symbolic solver with an LLM. The symbolic solver performs depth-first search with backtracking, exploring multiple rule applications and bindings until a valid proof is found. The LLM is only invoked when the solver cannot prove a goal using its current database, generating single-step statements that are validated and added to the database. This architecture ensures completeness by systematically exploring all reasoning paths while maintaining efficiency by minimizing LLM calls.

## Key Results
- Answer accuracy: 79.8-96.3% across seven benchmarks, significantly outperforming LAMBADA (42.7-85.3%) and Least-to-most (34.5-82.3%)
- Proof accuracy: Consistently higher than baselines, with improvements ranging from 7.5 to 43.6 percentage points
- Efficiency gains: 9× reduction in tokens and 22× speedup compared to LAMBADA, with total API costs of $6.89-$16.03 across all benchmarks
- Reasoning types: Superior performance across deductive, relational, and arithmetic reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The symbolic solver ensures completeness by systematically exploring all possible reasoning paths through backtracking
- Mechanism: The solver performs depth-first search with backtracking, exploring multiple rule applications and bindings until a valid proof is found or all paths are exhausted
- Core assumption: The symbolic solver's completeness guarantees that if a valid proof exists, it will be found
- Evidence anchors:
  - [abstract] "SLD Resolution algorithm recursively searches the valid proof for the goal term using given rules"
  - [section 2.2] "SLD Resolution algorithm recursively searches the valid proof for the goal term using given rules. It can be viewed as a depth-first search algorithm with four key steps, Search, Decompose, Binding propagation, and Backtracking"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism

### Mechanism 2
- Claim: The LLM is only called when the solver requires new information, reducing computational overhead
- Mechanism: The solver attempts to prove the goal using its current database, and only invokes the LLM when no applicable rules or facts are found
- Core assumption: The symbolic solver can handle most proof steps without LLM intervention
- Evidence anchors:
  - [abstract] "the solver controls the proof process, and the LLM is only called when the solver requires new information to complete the proof"
  - [section 3.2.1] "When a goal is not provable by the solver alone, an LLM is instructed to generate a single reasoning step which is then added to the symbolic solver's database"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism

### Mechanism 3
- Claim: Binding propagation ensures coreferential constraints are maintained throughout the proof tree
- Mechanism: When a variable binding is determined, it is propagated to all instances of that variable in the proof tree
- Core assumption: Proper binding propagation is essential for maintaining logical consistency in multi-step proofs
- Evidence anchors:
  - [section 2.2] "Binding propagation happens in three directions, from goal to subgoal, between subgoals, or subgoal to goal"
  - [section 3.1.2] "LAMBADA fails to address binding propagation properly as it only implements the binding propagation from goal to subgoals"
  - [corpus] Weak - no direct corpus evidence for this specific mechanism

## Foundational Learning

- Concept: SLD Resolution algorithm
  - Why needed here: Understanding the theoretical foundation of SymBa's solver component
  - Quick check question: What are the four key steps of SLD Resolution and how do they relate to SymBa's operation?

- Concept: Logic programming and predicate logic
  - Why needed here: SymBa operates on logic program representations of natural language problems
  - Quick check question: How does verb(subject, object) format differ from other common logic programming representations?

- Concept: Binding propagation in logic programming
  - Why needed here: Critical for understanding why SymBa outperforms baselines that lack this feature
  - Quick check question: What are the three directions of binding propagation in SLD Resolution?

## Architecture Onboarding

- Component map: Solver (symbolic reasoning engine) ↔ LLM (natural language reasoning) ↔ Database (working memory)
- Critical path: Goal → Search → Decompose → Binding propagation → Backtracking → (LLM call if needed) → Proof completion
- Design tradeoffs: Completeness vs. efficiency - complete search guarantees correct proofs but may be computationally expensive
- Failure signatures: Search-Hallucination (LLM generates invalid statements), Search-Miss (LLM fails to find relevant rules), Translation (LLM incorrectly translates natural language to symbolic form)
- First 3 experiments:
  1. Test solver's ability to find proofs on simple deductive reasoning tasks without LLM calls
  2. Measure LLM's accuracy in generating single-step statements for various reasoning types
  3. Evaluate the impact of binding propagation by comparing with and without this feature enabled

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SymBa's performance scale with increasingly complex reasoning tasks that require higher-order logic or meta-predicates beyond first-order SLD Resolution?
- Basis in paper: [explicit] The paper mentions that SymBa cannot handle high-order logic problems requiring meta-predicates like call/N in Prolog, which are beyond first-order SLD Resolution
- Why unresolved: The paper explicitly states this limitation but does not explore potential extensions or alternative approaches to handle higher-order logic within the SymBa framework
- What evidence would resolve it: Experiments comparing SymBa's performance on reasoning tasks requiring higher-order logic versus tasks solvable with first-order logic, along with proposed modifications to extend SymBa's capabilities

### Open Question 2
- Question: What is the impact of different logic program representation formats (e.g., verb(subject, object) vs. subject(predicate, object)) on SymBa's performance and proof accuracy across various reasoning tasks?
- Basis in paper: [explicit] The paper uses verb(subject, object) format consistently but mentions that other formats like subject(predicate, object) are also commonly used in related work
- Why unresolved: While the paper applies a specific format, it doesn't investigate whether this choice affects performance or whether alternative formats might be more effective for certain types of reasoning tasks
- What evidence would resolve it: Comparative experiments testing SymBa with different logic program representation formats across the same benchmark tasks, measuring both accuracy and proof accuracy

### Open Question 3
- Question: How does the efficiency of SymBa change when applied to fact-intensive tasks like knowledge base question answering (KBQA) that might require substantial computation?
- Basis in paper: [inferred] The paper notes that naively implemented backward chaining systems might require substantial computation in fact-intensive tasks and mentions that hybrid forward and backward chaining or sophisticated planning algorithms could mitigate this issue
- Why unresolved: The paper identifies this as a limitation but does not empirically test SymBa's performance on KBQA-style tasks or explore the proposed mitigation strategies
- What evidence would resolve it: Benchmarking SymBa on KBQA datasets measuring token usage, API cost, and execution time, along with experiments implementing hybrid approaches or advanced planning algorithms to improve efficiency

## Limitations
- Cannot handle high-order logic problems requiring meta-predicates beyond first-order SLD Resolution
- Performance may degrade on fact-intensive tasks requiring substantial computation in knowledge base question answering
- Limited validation of robustness to adversarial examples designed to trigger search-hallucination, search-miss, and translation failures

## Confidence
- High confidence in the theoretical framework and algorithm design based on well-established SLD Resolution principles
- Medium confidence in the empirical results, as they show significant improvements but may be sensitive to implementation details and benchmark selection
- Low confidence in the generalizability of the results to other reasoning domains or more complex natural language inputs

## Next Checks
1. **Proof Completeness Test**: Systematically test SymBa's ability to find valid proofs on a diverse set of logic program benchmarks, including edge cases with multiple valid proofs, no valid proofs, and proofs requiring backtracking
2. **Efficiency Benchmark**: Compare SymBa's token usage and runtime against LAMBADA on a large set of reasoning tasks, measuring the frequency of LLM calls and the computational overhead of the symbolic solver
3. **Robustness Evaluation**: Evaluate SymBa's performance on adversarial examples designed to trigger search-hallucination, search-miss, and translation failures, and assess the impact of these failures on proof accuracy