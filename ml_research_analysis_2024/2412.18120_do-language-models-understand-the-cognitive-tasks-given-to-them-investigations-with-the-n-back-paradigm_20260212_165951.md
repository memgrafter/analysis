---
ver: rpa2
title: Do Language Models Understand the Cognitive Tasks Given to Them? Investigations
  with the N-Back Paradigm
arxiv_id: '2412.18120'
source_url: https://arxiv.org/abs/2412.18120
tags:
- back
- task
- different
- letter
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether poor performance on n-back cognitive
  tasks by language models reflects genuine working memory limitations or inadequate
  task comprehension. The authors benchmark several models (GPT 3.5 Turbo and open-source
  models) on 1-back, 2-back, and 3-back tasks, identifying three performance tiers.
---

# Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm

## Quick Facts
- arXiv ID: 2412.18120
- Source URL: https://arxiv.org/abs/2412.18120
- Reference count: 10
- Key outcome: Language models' poor n-back performance often reflects task comprehension failure rather than working memory limitations

## Executive Summary
This paper investigates whether poor performance on n-back cognitive tasks by language models reflects genuine working memory limitations or inadequate task comprehension. The authors benchmark several models on 1-back, 2-back, and 3-back tasks, identifying three performance tiers. They find that low-performing models fail to understand the task, consistently executing a different m-back task despite detailed instructions and demonstrations. The study concludes that task comprehension is the primary bottleneck for many models, not working memory capacity.

## Method Summary
The study evaluates language models (GPT 3.5 Turbo and open-source models) on n-back cognitive tasks using recursive prompting with detailed instructions and demonstrations. Each task involves 24-letter sequences where 8 positions match the letter n steps back. Performance is measured through retrieval accuracy and task accuracy, with additional analysis of log probabilities and attention patterns. The authors identify three performance tiers (T3≤20%, T2~50%, T1>80% on 2/3-back tasks) and investigate mechanisms of task comprehension failure through counterfactual retrieval probabilities and error accumulation analysis.

## Key Results
- Low-performing models (Tier 3) systematically execute incorrect m-back tasks despite detailed instructions
- Intermediate models (Tier 2) can infer tasks from demonstrations but drift toward simpler tasks as errors accumulate
- High-performing models (Tier 1) consistently execute correct tasks and achieve 90.08% accuracy on 8-back/9-back and 84.75% on 10-back with curriculum learning
- Higher retrieval attention to the correct source token predicts better task performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Poor n-back performance in language models often reflects task comprehension failure rather than working memory limitations.
- **Mechanism:** Models may execute an incorrect m-back task (m≠n) despite detailed instructions and demonstrations. This systematic deviation from the target task produces low accuracy scores that mimic memory capacity constraints.
- **Core assumption:** Task comprehension can be reliably measured through counterfactual retrieval probabilities - comparing log probabilities of letters consistent with different m-back tasks under the same instructions.
- **Evidence anchors:**
  - [abstract] "low-performing models (Tier 3) fail to understand the task, consistently executing a different m-back task (m≠n) despite detailed instructions and demonstrations"
  - [section 4.2] "Under 2-back instructions, including with demonstrations, 1-back continuations are assigned to be the most plausible, with both P2,1 > P2,2 > P2,3"
  - [corpus] Weak evidence - no directly comparable corpus papers identified
- **Break condition:** If models can demonstrate task comprehension through consistent execution of the correct task across trials, this mechanism no longer explains performance gaps.

### Mechanism 2
- **Claim:** Task set maintenance degrades over time as errors accumulate, causing models to drift toward simpler task interpretations.
- **Mechanism:** Each incorrect response creates a local error that biases subsequent predictions toward an easier task interpretation (e.g., 1-back instead of 2-back). This creates a compounding effect where error accumulation progressively shifts the model's task set.
- **Core assumption:** The probability distribution over possible tasks is updated incrementally based on recent prediction history, with simpler tasks having higher prior probability.
- **Evidence anchors:**
  - [section 4.3] "A2,·(2, i) crosses below A2,·(1, i) halfway through the task, suggesting a gradual shift from 2-back to 1-back behavior"
  - [section 4.3] "As 1-back errors accumulate, 1-back responses are increasingly favored by the T2 model for subsequent steps, despite 2- or 3-back instructions and demonstrations"
  - [corpus] Weak evidence - no directly comparable corpus papers identified
- **Break condition:** If models can maintain consistent task set execution regardless of error accumulation, this drift mechanism is not the primary factor.

### Mechanism 3
- **Claim:** Higher retrieval attention to the correct source token predicts better task performance.
- **Mechanism:** Models that allocate greater attention weight to the letter appearing n steps back when performing n-back retrieval demonstrate better understanding and execution of the task. This attention pattern reflects the model's ability to maintain and access the relevant memory content.
- **Core assumption:** Attention weights directly reflect the model's retrieval strategy and correlate with task comprehension quality.
- **Evidence anchors:**
  - [section 4.7] "For each retrieval, a more performant model should attend more to the source token from n steps back"
  - [section 4.7] "Compared to the 14B model, QWEN 2 72 B INSTRUCT (T1) contains a much larger proportion of high-MRAT attentions (Figure 11), with its highest scoring attention (71.98%) closely matching our hypothesized pattern"
  - [corpus] Weak evidence - no directly comparable corpus papers identified
- **Break condition:** If attention patterns do not consistently correlate with task performance across different model architectures, this mechanism is not universally applicable.

## Foundational Learning

- **Concept:** Task comprehension measurement through counterfactual evaluation
  - Why needed here: To distinguish between genuine memory limitations and failure to understand task requirements, we need methods to assess whether models correctly infer the intended task from instructions
  - Quick check question: How can you determine if a model is executing the wrong task (m-back instead of n-back) given only the model's outputs?

- **Concept:** Error accumulation and task drift analysis
  - Why needed here: Understanding how errors propagate through sequential tasks helps identify whether performance degradation stems from memory limitations or systematic misinterpretation
  - Quick check question: What evidence would indicate that a model is drifting from an n-back task toward an m-back task as it processes a sequence?

- **Concept:** Curriculum learning principles for in-context task adaptation
  - Why needed here: Progressive exposure to increasing task difficulty can help models establish the correct task set before being challenged with more complex instances
  - Quick check question: How does presenting examples from simpler tasks (1-back, 2-back) before more complex ones (3-back, 4-back) potentially improve performance?

## Architecture Onboarding

- **Component map:** Language models (GPT 3.5 Turbo, QWEN, LLAMA, GEMMA families) -> Recursive prompting framework -> N-back task processing -> Evaluation metrics (retrieval accuracy, log probabilities, attention patterns)
- **Critical path:** Instruction → Demonstration → Sequential letter presentation → Model response → Evaluation of retrieval accuracy and task comprehension
- **Design tradeoffs:** Detailed instructions and demonstrations increase task comprehension but add context length overhead; simpler prompts reduce overhead but may compromise understanding; attention analysis provides insight but requires model access to internal states.
- **Failure signatures:** Consistent execution of m-back instead of n-back tasks, progressive drift toward simpler task interpretations, low retrieval attention to the correct source token, inability to maintain task set across trials.
- **First 3 experiments:**
  1. Measure counterfactual retrieval log probabilities for different m-back tasks under n-back instructions to assess task comprehension
  2. Analyze error accumulation patterns by computing accuracy at each time step versus overall accuracy to detect task drift
  3. Compare attention weight distributions between high-performing and low-performing models to identify retrieval strategy differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific neural circuit mechanisms in language models that enable or hinder task comprehension for n-back tasks?
- Basis in paper: Explicit - The paper acknowledges limitations in understanding the internal mechanisms responsible for inferring and maintaining task sets, suggesting causal interventions on smaller models could yield insights.
- Why unresolved: The study focused on behavioral outputs and attention patterns but did not conduct mechanistic analysis of the internal circuits that process task instructions and maintain task sets during execution.
- What evidence would resolve it: Detailed circuit analysis showing how different model components process task instructions, maintain working memory representations, and update task sets during execution, potentially through ablation studies or activation analysis.

### Open Question 2
- Question: How do different transformer architectures (beyond attention patterns) influence n-back task performance and what architectural modifications could improve task comprehension?
- Basis in paper: Explicit - The paper notes puzzling differences in attention patterns between QWEN and LLAMA models despite both using grouped query attention, calling for closer examination of architectural differences.
- Why unresolved: While attention analysis revealed some patterns, the study did not comprehensively investigate how architectural choices like layer design, feed-forward networks, or positional encoding affect task comprehension.
- What evidence would resolve it: Systematic comparison of different transformer architectures on n-back tasks, including controlled experiments varying architectural components while measuring task comprehension and working memory performance.

### Open Question 3
- Question: What is the relationship between model scale, task comprehension capabilities, and working memory capacity in n-back tasks?
- Basis in paper: Explicit - The study identifies three performance tiers across different model sizes but does not fully explore how scale relates to the distinct capabilities of task comprehension versus working memory capacity.
- Why unresolved: The paper demonstrates that poor performance often stems from task comprehension issues rather than memory limitations, but doesn't systematically investigate how this relationship varies across different model scales.
- What evidence would resolve it: Comprehensive scaling studies examining task comprehension and working memory performance across multiple orders of magnitude in model size, potentially revealing breakpoints or phase transitions in cognitive capabilities.

## Limitations

- Limited model coverage focusing on specific model families without testing broader range of architectures
- Task comprehension assessment method assumes most probable m-back continuation directly reflects understanding
- Context window effects not systematically investigated across different sequence lengths

## Confidence

**High confidence:**
- Tier-based performance classification is robust and reproducible
- Task comprehension failure manifests as systematic execution of m-back instead of n-back tasks
- Attention patterns correlate with task performance across tested models

**Medium confidence:**
- Error accumulation leads to task drift toward simpler interpretations
- Curriculum learning provides modest performance improvements
- N-back tasks can effectively distinguish between working memory and comprehension limitations

**Low confidence:**
- Exact mechanisms by which detailed instructions improve task comprehension
- Generalization of findings to longer sequences or more complex cognitive tasks
- Optimal prompt engineering strategies for task comprehension

## Next Checks

1. **Cross-architecture validation:** Test the tier classification and task comprehension assessment methods on a broader range of models including Claude, PaLM, and other transformer architectures to verify the generalizability of the findings.

2. **Ablation study on instruction format:** Systematically vary the level of detail in instructions and demonstrations (from minimal to maximal) while measuring task comprehension through counterfactual probabilities to identify the critical features that enable understanding.

3. **Attention intervention experiment:** Develop methods to artificially modify attention patterns (e.g., through attention head replacement or fine-tuning) and measure whether improving MRAT patterns directly causes performance improvements on n-back tasks.