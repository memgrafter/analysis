---
ver: rpa2
title: Pseudo-labelling meets Label Smoothing for Noisy Partial Label Learning
arxiv_id: '2402.04835'
source_url: https://arxiv.org/abs/2402.04835
tags:
- label
- learning
- partial
- pals
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the problem of Noisy Partial Label Learning
  (NPLL), where each training example has a set of candidate labels containing the
  true label plus some noise, which is especially challenging in fine-grained classification
  where labels are ambiguous. The proposed method, PALS, uses a two-stage iterative
  approach: first, it assigns pseudo-labels to images using a weighted K-nearest neighbors
  (KNN) algorithm that leverages the noisy partial labels; second, it trains a deep
  neural network classifier using these pseudo-labels with label smoothing to handle
  potential noise.'
---

# Pseudo-labelling meets Label Smoothing for Noisy Partial Label Learning

## Quick Facts
- arXiv ID: 2402.04835
- Source URL: https://arxiv.org/abs/2402.04835
- Reference count: 37
- This paper proposes PALS, a method that outperforms nine state-of-the-art PLL and NPLL methods on seven datasets, achieving over 5-16 percentage points improvement on CUB-200.

## Executive Summary
This paper addresses Noisy Partial Label Learning (NPLL), where training examples have candidate labels containing both the true label and noise, particularly challenging in fine-grained classification. The proposed PALS method uses a two-stage iterative approach: first applying weighted K-nearest neighbors (KNN) pseudo-labelling to assign reliable labels, then training a deep neural network with label smoothing to handle potential noise. The framework iteratively refines both pseudo-labels and classifier features, creating a positive feedback loop. Extensive experiments show PALS outperforms existing methods, especially in high-noise and fine-grained settings.

## Method Summary
PALS tackles NPLL through an iterative two-stage process. First, it generates pseudo-labels using weighted KNN that considers cosine similarity between feature representations, selecting reliable samples per class. Second, it trains a deep neural network classifier using these pseudo-labels with label smoothing (fixed rate r=0.5) to prevent overfitting to noisy pseudo-labels. The method also includes partial label augmentation that progressively de-noises labels by incorporating confident model predictions with a decaying threshold. This creates a feedback loop where improved features lead to better pseudo-labels, which in turn train better classifiers.

## Key Results
- PALS achieves over 5-16 percentage points improvement on CUB-200 compared to state-of-the-art methods
- Outperforms nine baseline methods across seven datasets including CIFAR-10, CIFAR-100, CUB-200, Treeversity#6, Benthic, and Plankton
- Demonstrates strong generalization on real-world crowd-sourced fine-grained datasets
- Maintains robust performance even as noise levels increase

## Why This Works (Mechanism)

### Mechanism 1
Weighted KNN pseudo-labelling iteratively improves both label accuracy and feature representation quality, creating a positive feedback loop. The algorithm uses cosine similarity to weight nearest neighbors, computes posterior probabilities, and selects the most reliable samples per class. As training progresses, the classifier's feature space becomes more discriminative, leading to better neighbor selection and higher agreement within classes.

### Mechanism 2
Label smoothing with fixed high smoothing rate (r=0.5) provides noise-robustness during pseudo-label training by preventing overconfidence on potentially incorrect pseudo-labels. Instead of using hard one-hot pseudo-labels, the method creates smoothed labels that are a weighted average of the pseudo-label and uniform distribution, preventing the model from becoming too confident in noisy pseudo-labels while still providing useful gradient signals.

### Mechanism 3
Partial label augmentation with decaying threshold allows the method to progressively de-noise partial labels by incorporating confident model predictions into the candidate sets. The algorithm adds the model's highest probability class to the partial label set if its confidence exceeds a threshold λt that decays over training, balancing precision (high threshold early) and recall (low threshold later).

## Foundational Learning

- Concept: Cosine similarity and nearest neighbor search in feature space
  - Why needed here: The weighted KNN algorithm relies on measuring similarity between feature representations to determine pseudo-labels
  - Quick check question: Given two feature vectors with cosine similarity of 0.8 and 0.3 to a query point, which neighbor contributes more weight to the pseudo-label calculation?

- Concept: Label smoothing and its effect on gradient updates
  - Why needed here: The method uses label smoothing to handle noise in pseudo-labels, requiring understanding how smoothed labels affect the cross-entropy loss
  - Quick check question: How does a label smoothing rate of 0.5 modify the target distribution compared to a one-hot label?

- Concept: Iterative refinement and feedback loops in training
  - Why needed here: The method alternates between pseudo-labelling and classifier training, requiring understanding how each step affects the other
  - Quick check question: In what way does improving feature representations affect the quality of pseudo-labels in subsequent iterations?

## Architecture Onboarding

- Component map: Encoder (ResNet-18/50) → Feature extraction → Weighted KNN → Pseudo-label assignment → Label smoothing → Classifier training → Feature update → Partial label augmentation → Next iteration
- Critical path: Pseudo-labelling → Reliable pair selection → Classifier training → Partial label augmentation
- Design tradeoffs: Single trainable component vs. multi-branch networks (simpler, faster training vs. potentially more expressive); fixed label smoothing rate vs. adaptive (simpler hyperparameter tuning vs. potentially suboptimal smoothing)
- Failure signatures: Poor initial pseudo-labels leading to error propagation; threshold parameters too conservative preventing de-noising; insufficient iterations preventing feedback loop formation
- First 3 experiments:
  1. Verify KNN pseudo-labelling on clean data with known labels to confirm the method can recover correct labels from similar samples
  2. Test label smoothing with synthetic noisy labels to confirm it improves robustness compared to hard labels
  3. Run a single iteration of the full pipeline to verify all components integrate correctly and pseudo-labels improve from iteration 0 to iteration 1

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of PALS scale when applied to datasets with significantly more classes than CIFAR-100 (e.g., ImageNet-scale datasets)? The authors note that "Performance improvements, compared to other methods, become more pronounced with increasing numbers of classes," but they do not test beyond CIFAR-100 and CUB-200.

### Open Question 2
What is the theoretical justification for the specific choice of weighted KNN for pseudo-labeling, and could other similarity metrics or neighborhood selection strategies yield better performance? The authors cite prior work [8] for using KNN in PLL but do not provide a rigorous theoretical analysis of why this approach is optimal for NPLL.

### Open Question 3
How sensitive is PALS to the choice of the reliability threshold λt in partial label augmentation, and what strategies could be used to adaptively tune it during training? The authors mention that λt is a decaying threshold but only experiment with a linear decay schedule.

## Limitations
- Limited ablation studies to isolate the contribution of individual components (KNN pseudo-labelling, label smoothing, partial label augmentation)
- Fixed hyperparameter choices (r=0.5 for label smoothing) without theoretical justification or sensitivity analysis
- Does not explore alternative similarity metrics or neighborhood selection strategies beyond weighted KNN

## Confidence

- Weighted KNN pseudo-labelling effectiveness: Medium - Strong empirical results but limited ablation analysis
- Label smoothing noise robustness: Medium - Clear performance gains but fixed hyperparameter choice lacks justification
- Partial label augmentation mechanism: Medium - Described clearly but minimal analysis of threshold decay impact

## Next Checks

1. Run ablation studies removing either the KNN pseudo-labelling or label smoothing to quantify their individual contributions to overall performance gains
2. Test the method's robustness to the fixed label smoothing rate by varying r across different noise levels to identify optimal smoothing schedules
3. Evaluate feature space quality using t-SNE or UMAP visualizations to confirm that KNN pseudo-labelling genuinely captures semantic similarity rather than low-level correlations