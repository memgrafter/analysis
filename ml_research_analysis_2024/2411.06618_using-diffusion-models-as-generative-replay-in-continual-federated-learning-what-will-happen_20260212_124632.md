---
ver: rpa2
title: Using Diffusion Models as Generative Replay in Continual Federated Learning
  -- What will Happen?
arxiv_id: '2411.06618'
source_url: https://arxiv.org/abs/2411.06618
tags:
- data
- learning
- diffusion
- clients
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DCFL, a novel continual federated learning
  framework that integrates diffusion models for synthetic historical data generation.
  The method addresses catastrophic forgetting in dynamic distributed learning by
  using conditional diffusion models at each client device to generate synthetic historical
  data during communication rounds, while keeping the diffusion models local for privacy.
---

# Using Diffusion Models as Generative Replay in Continual Federated Learning -- What will Happen?

## Quick Facts
- arXiv ID: 2411.06618
- Source URL: https://arxiv.org/abs/2411.06618
- Authors: Yongsheng Mei; Liangqi Yuan; Dong-Jun Han; Kevin S. Chan; Christopher G. Brinton; Tian Lan
- Reference count: 40
- Primary result: DCFL achieves 32.61% improvement in Class Incremental IID, 15.16% in Class Incremental Non-IID, and 7.45% in Domain Incremental scenarios compared to best baselines

## Executive Summary
This paper introduces DCFL, a novel continual federated learning framework that integrates diffusion models for synthetic historical data generation. The method addresses catastrophic forgetting in dynamic distributed learning by using conditional diffusion models at each client device to generate synthetic historical data during communication rounds, while keeping the diffusion models local for privacy. Theoretical analysis provides convergence bounds that show the system's performance depends on the diffusion model's bounded characteristics. Experiments across three CFL scenarios (Class Incremental IID/Non-IID, Domain Incremental) on MNIST, Fashion-MNIST, CIFAR-10, and PACS datasets demonstrate significant improvements over baselines.

## Method Summary
DCFL is a continual federated learning framework that combines standard federated averaging with conditional diffusion models at each client device. During each communication round, clients train both their target model (for the FL task) and a local diffusion model on mixed real and synthetic data. The diffusion model generates synthetic historical data representing previously seen data distributions, which is then used alongside current real data to train the target model. This approach prevents catastrophic forgetting without storing actual historical data, maintaining privacy by keeping diffusion models local. The framework uses a CNN architecture for the target model and a conditional UNet architecture for the diffusion model, with theoretical convergence bounds that incorporate both FL model convergence and diffusion model performance.

## Key Results
- DCFL achieves 32.61% improvement over best baseline in Class Incremental IID scenario
- DCFL achieves 15.16% improvement over best baseline in Class Incremental Non-IID scenario  
- DCFL achieves 7.45% improvement over best baseline in Domain Incremental scenario
- The framework successfully transforms non-IID problems into IID-like scenarios through synthetic data generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion models generate high-quality synthetic historical data that prevents catastrophic forgetting in continual federated learning.
- Mechanism: The conditional diffusion model learns the data distribution at each client device and generates synthetic data that approximates previously seen data distributions. This synthetic data is mixed with current real data during local training, allowing the model to retain knowledge of past tasks without storing actual historical data.
- Core assumption: The diffusion model can accurately reconstruct the data distribution from previous time steps, and the generated synthetic data is sufficiently similar to real historical data to prevent forgetting.
- Evidence anchors:
  - [abstract] "Our approach harnesses the power of the conditional diffusion model to generate synthetic historical data at each local device during communication, effectively mitigating latent shifts in dynamic data distribution inputs."
  - [section 3.1] "In the DCFL framework, each client possesses a target model θ (for various FL tasks) and a diffusion model ω for replaying data distributions from previous time periods."
  - [corpus] Weak evidence - no direct citations found in corpus for diffusion models in continual federated learning.

### Mechanism 2
- Claim: The convergence of the entire CFL system depends on the performance of the diffusion model.
- Mechanism: Theoretical analysis shows that the overall convergence bound comprises three components: FL model convergence, diffusion model performance, and data distribution shift. As communication rounds approach infinity, only the diffusion model term remains relevant.
- Core assumption: The diffusion model's convergence is bounded and its performance determines the system's ultimate convergence.
- Evidence anchors:
  - [section 3.2] "Therefore, by integrating Lemma 1, 2 and Theorem 1, our CFL framework with the diffusion model DCFL can be proven bounded during the learning."
  - [section 3.2] "The convergence bound, as outlined in Theorem 2, comprises three components: the convergence bound of the federated learning model, the bound of the diffusion model, and the divergence of the data distribution."
  - [corpus] Weak evidence - no direct citations found in corpus for convergence analysis of diffusion models in CFL.

### Mechanism 3
- Claim: Local training with synthetic data allows each client to learn multiple classes simultaneously, transforming non-IID problems into IID-like problems.
- Mechanism: Each client trains its target model on both current real data and synthetic historical data generated by its local diffusion model. Over communication rounds, clients gradually acquire information about global classes through synthetic datasets, effectively converting the non-IID setting into an IID-like scenario.
- Core assumption: Synthetic data generated by the diffusion model accurately represents the class distributions from other clients.
- Evidence anchors:
  - [section 4.2] "Benefiting from the diffusion model, clients can learn features of multiple classes simultaneously, transforming the Non-IID problem into an IID problem: as clients iterate through communication rounds, they gradually acquire information about global classes through synthetic datasets."
  - [section 4.3] "Class Incremental Non-IID is the simplest (i.e., the least affected by catastrophic forgetting) CFL scenario because the server can aggregate a generalized global model based on the clients with diverse class distributions."
  - [corpus] Weak evidence - no direct citations found in corpus for this specific mechanism of transforming non-IID to IID.

## Foundational Learning

- Concept: Federated Averaging (FedAvg)
  - Why needed here: DCFL uses FedAvg as its backbone algorithm for aggregating local model updates from clients.
  - Quick check question: What is the update rule for the global model in FedAvg, and how are client contributions weighted?

- Concept: Continual Learning (CL) and Catastrophic Forgetting
  - Why needed here: DCFL specifically addresses catastrophic forgetting in the context of federated learning where data distributions change over time.
  - Quick check question: What is catastrophic forgetting, and why is it particularly problematic in continual federated learning scenarios?

- Concept: Diffusion Models and Denoising Processes
  - Why needed here: The core innovation of DCFL relies on using conditional diffusion models to generate synthetic historical data.
  - Quick check question: How does the forward diffusion process work in denoising diffusion probabilistic models, and what is the role of the reverse process?

## Architecture Onboarding

- Component map:
  Server -> Aggregates target model updates from clients
  Client devices -> Each contains target model (for FL tasks) and local diffusion model (for data replay)
  Diffusion model -> Conditional UNet architecture for generating synthetic data
  Target model -> CNN architecture (two convolutional layers, two fully connected layers)

- Critical path:
  1. Client trains diffusion model on mixed real and synthetic data
  2. Client generates synthetic historical data using trained diffusion model
  3. Client trains target model on combined real current data + synthetic historical data
  4. Client sends target model parameters to server
  5. Server aggregates target models using weighted averaging

- Design tradeoffs:
  - Keeping diffusion models local preserves privacy but requires each client to train their own model
  - Using synthetic data instead of replay buffers saves storage but depends on diffusion model quality
  - Conditional diffusion allows class/domain conditioning but increases model complexity

- Failure signatures:
  - Poor synthetic data quality (blurry, incorrect class distributions) indicates diffusion model training issues
  - Accuracy drops on previously seen classes indicate catastrophic forgetting
  - Slow convergence suggests insufficient synthetic data or poor model architecture

- First 3 experiments:
  1. Test DCFL on Class Incremental IID with MNIST to verify basic functionality and compare against FedAvg baseline
  2. Evaluate synthetic data quality by visually inspecting generated samples and checking class distribution alignment
  3. Test DCFL on Class Incremental Non-IID with Fashion-MNIST to verify transformation of non-IID to IID-like behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between synthetic and real data during training to maximize model performance while minimizing computational overhead?
- Basis in paper: [explicit] The paper discusses sensitivity studies on the number of synthetic samples (δ factor) and mentions the need to balance synthetic data generation with computational efficiency.
- Why unresolved: The paper only tests δ = 1 and doesn't explore the full trade-off space between performance gains and computational costs.
- What evidence would resolve it: Systematic experiments varying the ratio of synthetic to real data across different datasets and CFL scenarios, measuring both accuracy and computational costs.

### Open Question 2
- Question: How does the performance of DCFL scale with the number of clients and communication rounds in large-scale deployments?
- Basis in paper: [inferred] The paper shows sensitivity to client number (Figure 6) but only tests up to 50 clients and doesn't analyze scaling behavior or communication efficiency.
- Why unresolved: The experiments focus on small-scale scenarios (20-50 clients) and don't examine how the framework performs as the system scales to hundreds or thousands of clients.
- What evidence would resolve it: Large-scale experiments with varying client counts and communication round budgets, measuring convergence speed, accuracy, and communication costs.

### Open Question 3
- Question: Can the diffusion model in DCFL be effectively protected against privacy attacks that extract sensitive information from synthetic data?
- Basis in paper: [explicit] The broader impacts section mentions privacy risks where attackers could potentially replay all historical data if they gain access to the diffusion model.
- Why unresolved: The paper acknowledges this risk but doesn't propose or test any privacy-preserving techniques for the generative model component.
- What evidence would resolve it: Implementation and evaluation of privacy protection mechanisms (e.g., differential privacy, secure aggregation) specifically designed for conditional diffusion models in federated settings.

## Limitations
- The theoretical convergence analysis relies on assumptions about bounded diffusion model errors that lack empirical validation
- Claims about transforming non-IID problems to IID-like scenarios require more rigorous testing across diverse data distributions
- The framework's scalability and performance in large-scale deployments with hundreds or thousands of clients remains untested

## Confidence
- **High Confidence**: The basic DCFL framework architecture and experimental setup are clearly specified, allowing for reproducible implementation.
- **Medium Confidence**: The convergence bounds are theoretically sound but lack empirical validation of the assumptions about diffusion model boundedness.
- **Low Confidence**: Claims about the diffusion model's ability to prevent catastrophic forgetting and transform non-IID problems require more direct evidence through ablation studies.

## Next Checks
1. Conduct ablation studies to quantify the impact of diffusion model quality on catastrophic forgetting - train DCFL with varying quality synthetic data and measure forgetting on previous tasks.
2. Validate the convergence bounds empirically by measuring the diffusion model error term (ϵscore) across training and comparing against the theoretical bounds.
3. Test DCFL's performance on additional non-IID scenarios beyond the three specified to verify the robustness of the non-IID to IID transformation mechanism.