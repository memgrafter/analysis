---
ver: rpa2
title: 'How to Understand Named Entities: Using Common Sense for News Captioning'
arxiv_id: '2403.06520'
source_url: https://arxiv.org/abs/2403.06520
tags:
- named
- entities
- news
- commonsense
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of named entity understanding
  in news captioning, where semantically similar named entities (e.g., "Mr. Gates"
  vs.
---

# How to Understand Named Entities: Using Common Sense for News Captioning

## Quick Facts
- arXiv ID: 2403.06520
- Source URL: https://arxiv.org/abs/2403.06520
- Authors: Ning Xu; Yanhui Wang; Tingting Zhang; Hongshuo Tian; Mohan Kankanhalli; An-An Liu
- Reference count: 40
- This paper proposes a three-module approach using commonsense knowledge to improve named entity understanding in news captioning, achieving significant improvements in rare proper noun F1 scores and overall captioning quality.

## Executive Summary
This paper addresses the challenge of named entity understanding in news captioning, where semantically similar entities (e.g., "Mr. Gates" vs. "Mr. Sarkozy") require more than just article context for accurate description. The authors propose three communicative modules that exploit commonsense knowledge from ConceptNet: Filter, Distinguish, and Enrich. The Filter Module retrieves and divides commonsense into explanatory and relevant knowledge; the Distinguish Module uses explanatory knowledge to disambiguate similar entities; the Enrich Module leverages relevant knowledge to generate more descriptive captions. Experiments on GoodNews and NYTimes datasets show that their method outperforms state-of-the-art models, achieving up to 4.16% absolute gain in rare proper noun F1 scores.

## Method Summary
The method employs a three-module architecture to integrate commonsense knowledge into news captioning. First, the Filter Module retrieves one-hop ConceptNet sub-graphs for each named entity and divides them into explanatory (e.g., "IsA", "Synonym") and relevant (e.g., "RelatedTo", "CreatedBy") knowledge. The Distinguish Module then uses explanatory knowledge to disambiguate semantically similar entities through multi-aspect aggregation (node-degree, dependency, distinguish) and multi-head attention. Finally, the Enrich Module leverages relevant commonsense to provide more descriptive captions by modeling commonsense-entity interaction. The system is trained end-to-end with Adam optimizer (learning rate 1e-4 with warmup), L2 regularization (1e-5), and batch size 16, using pretrained ResNet-152 for image features, RoBERTa for article features, and transformer-based encoders.

## Key Results
- Achieved up to 4.16% absolute gain in rare proper noun F1 scores compared to state-of-the-art models
- Improved overall captioning quality across multiple metrics (BLEU-1, BLEU-4, METEOR, ROUGE-L, CIDEr-D) on GoodNews and NYTimes datasets
- Demonstrated effectiveness of commonsense knowledge in disambiguating semantically similar named entities and enriching their descriptions beyond article context

## Why This Works (Mechanism)

### Mechanism 1
The Filter Module effectively retrieves and divides commonsense knowledge into explanatory and relevant sub-graphs by querying ConceptNet for one-hop related concepts and categorizing relations based on their information type. This targeted division enables subsequent modules to use the appropriate knowledge type for their specific tasks.

### Mechanism 2
The Distinguish Module uses explanatory commonsense to accurately differentiate semantically similar named entities by aggregating knowledge from node-degree (importance weighting), dependency (semantic ordering), and distinguish (irrelevant concept scaling) aspects through multi-head attention, creating discriminative representations.

### Mechanism 3
The Enrich Module uses relevant commonsense to provide more descriptive captions by modeling commonsense-entity interaction through concept-entity pairing and multi-head attention, allowing the decoder to copy relevant concepts that enrich the entity description beyond article content.

## Foundational Learning

- **Concept**: Named Entity Recognition (NER)
  - Why needed here: The method requires accurate identification of named entities (people, organizations, places) in news articles to query ConceptNet and apply commonsense knowledge
  - Quick check question: How does SpaCy's NER system identify and classify named entities in text, and what are its limitations for news domain entities?

- **Concept**: Graph Neural Networks (GNNs) and attention mechanisms
  - Why needed here: The Filter Module processes ConceptNet sub-graphs, while the Distinguish and Enrich Modules use multi-head attention to aggregate and weight information from these graphs
  - Quick check question: How do multi-head attention mechanisms aggregate information from graph-structured data, and what role does the node-degree and dependency information play?

- **Concept**: Commonsense knowledge bases and relation types
  - Why needed here: The method relies on ConceptNet's structured knowledge with specific relation types to retrieve and categorize information for entity understanding
  - Quick check question: What are the different relation types in ConceptNet, and how do "explanatory" relations (e.g., IsA) differ from "relevant" relations (e.g., CreatedBy) in terms of the information they provide?

## Architecture Onboarding

- **Component map**: Image features (ResNet patches, face features, object features) + Article features (RoBERTa embeddings) → Filter Module → Distinguish Module → Entity probability distribution → Enrich Module → Commonsense probability distribution → Integration Layer → Generated caption

- **Critical path**: Image + Article features → Filter Module → Distinguish Module → Entity probability distribution → Enrich Module → Commonsense probability distribution → Integration → Caption

- **Design tradeoffs**:
  - One-hop vs multi-hop ConceptNet retrieval: One-hop reduces noise and computation but may miss deeper connections; multi-hop captures richer relationships but increases noise and complexity
  - Number of named entities queried: More entities provide richer commonsense but increase computational cost and potential noise
  - Sub-graph size: Larger sub-graphs capture more information but increase computational burden and noise; smaller sub-graphs are efficient but may miss important concepts

- **Failure signatures**:
  - Poor named entity recognition → Incorrect or missing commonsense queries → Downstream modules receive wrong input
  - Insufficient discriminative concepts in explanatory sub-graph → Distinguish Module cannot separate similar entities
  - Generic or irrelevant concepts in relevant sub-graph → Enrich Module adds noise rather than value
  - Over-reliance on commonsense → Generated captions contain information not supported by image/article context

- **First 3 experiments**:
  1. Validate Filter Module: Compare entity disambiguation performance with and without the Filter Module's sub-graph division on a controlled dataset with semantically similar entities
  2. Test Distinguish Module: Measure the impact of each aggregation aspect (node-degree, dependency, distinguish) individually by ablating them and observing changes in entity separation accuracy
  3. Evaluate Enrich Module: Compare caption informativeness and named entity description completeness with and without the Enrich Module on a test set with entities requiring external knowledge for full description

## Open Questions the Paper Calls Out

- **Open Question 1**: How can commonsense knowledge be effectively integrated across multiple domains to improve named entity understanding in news captioning?
  - Basis in paper: The paper mentions that integrating multi-source knowledge like news, wikis, and web text could enrich the commonsense corpus, but it also notes this is a challenging problem for future work.
  - Why unresolved: The paper demonstrates the effectiveness of using ConceptNet for commonsense knowledge, but acknowledges that a single knowledge source may have limitations, particularly for less famous named entities.
  - What evidence would resolve it: Experiments comparing models using single vs. multiple commonsense knowledge sources, measuring performance on diverse named entity types and domains.

- **Open Question 2**: What is the optimal balance between distinguishing semantically similar named entities and enriching their descriptions in news captioning?
  - Basis in paper: The paper presents two parallel modules (Distinguish and Enrich) with learned parameters (β, x, y) to balance their contributions, but acknowledges that the abilities to distinguish and describe named entities are "compatible and mutually reinforcing" without specifying the optimal balance.
  - Why unresolved: While the paper demonstrates that both modules contribute to improved performance, it doesn't explore the optimal weighting between them or how this balance might vary depending on the specific news image and article content.
  - What evidence would resolve it: Systematic ablation studies varying the balance parameters across different types of news images and articles to determine optimal configurations.

- **Open Question 3**: How can commonsense knowledge retrieval be improved for less famous named entities that may not have sufficient information in existing knowledge bases?
  - Basis in paper: The paper identifies a failure case where the model couldn't generate detailed information about "Elena" because she wasn't famous enough to have sufficient commonsense knowledge in ConceptNet.
  - Why unresolved: The paper demonstrates the effectiveness of commonsense knowledge for well-known entities but highlights a clear limitation for less prominent named entities, suggesting the need for alternative or expanded knowledge sources.
  - What evidence would resolve it: Experiments comparing performance on datasets with varying proportions of famous vs. non-famous named entities, and testing alternative knowledge retrieval strategies (e.g., web search, entity linking) for less common entities.

## Limitations

- The method relies heavily on ConceptNet's coverage, which may be insufficient for rare or domain-specific named entities common in news articles
- The one-hop retrieval strategy may miss critical distinguishing features for entities with complex relationships
- The effectiveness of the explanatory vs relevant knowledge division depends on the chosen relation types, which may not optimally capture all entity characteristics

## Confidence

- **High confidence**: The overall three-module architecture design and the basic premise that commonsense knowledge can improve named entity understanding in news captioning
- **Medium confidence**: The specific mechanisms for dividing commonsense knowledge (explanatory vs relevant) and the effectiveness of the multi-aspect aggregation approach
- **Low confidence**: The scalability and generalization of the approach to domains beyond news captioning, and the method's robustness when ConceptNet coverage is sparse

## Next Checks

1. **Ablation study on commonsense division strategy**: Test alternative methods for categorizing ConceptNet relations beyond the current explanatory/relevant split to determine if the current division strategy is optimal for named entity disambiguation.

2. **Multi-hop retrieval impact analysis**: Systematically compare one-hop vs multi-hop ConceptNet retrieval on a subset of entities known to require deeper knowledge connections, measuring the trade-off between improved disambiguation accuracy and increased noise or computational cost.

3. **Cross-domain generalization test**: Evaluate the method on a different captioning domain (e.g., social media posts with entities) to assess whether the commonsense-based approach generalizes beyond the news domain where it was developed and tested.