---
ver: rpa2
title: 'TSCMamba: Mamba Meets Multi-View Learning for Time Series Classification'
arxiv_id: '2406.04419'
source_url: https://arxiv.org/abs/2406.04419
tags:
- time
- features
- mamba
- scanning
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TSCMamba, a novel time series classification
  method that addresses limitations in existing approaches by leveraging multi-view
  learning and a state-space model. The key innovation is the integration of spectral,
  temporal, local, and global features, captured through continuous wavelet transform
  and random convolutional kernels.
---

# TSCMamba: Mamba Meets Multi-View Learning for Time Series Classification

## Quick Facts
- arXiv ID: 2406.04419
- Source URL: https://arxiv.org/abs/2406.04419
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on 30 benchmark datasets with 4.01-6.45% and 7.93% average accuracy improvements

## Executive Summary
This paper introduces TSCMamba, a novel time series classification method that addresses limitations in existing approaches by leveraging multi-view learning and a state-space model. The key innovation is the integration of spectral, temporal, local, and global features, captured through continuous wavelet transform and random convolutional kernels. TSCMamba employs a Mamba state-space model for efficient sequence modeling and introduces a new scanning scheme called "tango scanning" to model sequence relationships and leverage inversion invariance. The method achieves state-of-the-art performance on two sets of benchmark datasets (10+20 datasets), with average accuracy improvements of 4.01-6.45% and 7.93% respectively, over leading TSC models.

## Method Summary
TSCMamba is a multi-view learning framework for multivariate time series classification that combines spectral features from continuous wavelet transform with temporal features extracted via ROCKET or MLP, fused adaptively using a switch gate mechanism. The fused features are processed through tango scanning modules (time-wise and channel-wise) using a shared Mamba state-space model to capture bidirectional dependencies efficiently. The output undergoes depth-wise pooling followed by MLP classification, trained with cross-entropy loss using ADAM optimizer and cosine-annealing learning rate scheduling.

## Key Results
- Achieves state-of-the-art accuracy on 30 benchmark datasets with average improvements of 4.01-6.45% and 7.93%
- Tango scanning demonstrates higher accuracy than vanilla Mamba scanning while maintaining similar memory footprint
- Multi-view fusion with adaptive switch gate outperforms single-view approaches across diverse datasets
- Method generalizes well across datasets with varying dimensions, sequence lengths, and class counts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-view learning with spectral, temporal, local, and global features improves discriminative power
- Mechanism: By combining CWT-derived time-frequency features (shift-equivariant) with ROCKET-derived local temporal features and MLP-derived global features, the model captures complementary information across domains. The switch gate dynamically selects the most discriminative temporal features (local vs global) for fusion with spectral features, providing enriched context for classification.
- Core assumption: Different time series datasets have varying dominant feature types (local vs global patterns) that can be adaptively selected during training
- Evidence anchors:
  - [abstract]: "Our method integrates diverse features, including spectral, temporal, local, and global features, to obtain rich, complementary contexts for TSC"
  - [section 3.3]: "Through our empirical study, we observe that for many MTS data, either local features or global features in the temporal domain play a dominant role in discriminating between classes for TSC"
  - [corpus]: Weak evidence - the corpus neighbors focus on alternative approaches but don't directly validate the multi-view fusion mechanism
- Break condition: If the switch gate consistently selects only one type of temporal feature across all datasets, suggesting the adaptive selection is not learning meaningful differences

### Mechanism 2
- Claim: Tango scanning effectively models inter-token relationships while maintaining computational efficiency
- Mechanism: Tango scanning processes both forward and reverse sequences through a single Mamba block with element-wise addition, achieving full pairwise attention coverage without the computational overhead of separate bidirectional blocks. This creates inversion-invariant features useful when temporal direction is ambiguous.
- Core assumption: Sharing one Mamba block for both forward and reverse sequences provides sufficient parameter efficiency while capturing bidirectional dependencies
- Evidence anchors:
  - [abstract]: "We introduce a new scanning scheme for Mamba, called tango scanning, to effectively model sequence relationships and leverage inversion invariance"
  - [section 3.4]: "Unlike the bi-directional Mamba block in [26, 27] that uses two separate SSMs with one for forward direction and the other for backward direction, our tango scanning block uses only a single Mamba block"
  - [corpus]: Weak evidence - the corpus neighbors don't discuss scanning mechanisms or inversion invariance
- Break condition: If tango scanning shows no improvement over standard forward scanning on datasets where temporal direction is meaningful

### Mechanism 3
- Claim: Mamba's selective state-space mechanism efficiently captures long-range dependencies in time series
- Mechanism: Mamba dynamically parameterizes state transitions based on input content, filtering irrelevant information and selectively propagating key features. This allows linear complexity sequence modeling compared to quadratic complexity in transformers, making it suitable for long time series.
- Core assumption: The selectivity property of Mamba (gate gk controlling convex combination of current input and previous state) effectively captures relevant information in time series classification
- Evidence anchors:
  - [abstract]: "We utilize the Mamba state space model for efficient and scalable sequence modeling and capturing long-range dependencies in time series"
  - [section 3.4]: "Mamba introduces selective state spaces, a mechanism that updates only a subset of state dimensions based on each input"
  - [corpus]: Moderate evidence - related papers mention frequency-aware Mamba variants, suggesting the base Mamba approach is recognized for TSC
- Break condition: If performance degrades significantly when using longer sequences where long-range dependencies should matter most

## Foundational Learning

- Concept: Shift equivariance in time series
  - Why needed here: The paper explicitly states that shift equivariance is an important property that existing TSC methods underexplored, and CWT is chosen specifically because it provides shift-equivariant features
  - Quick check question: If a time series pattern occurs at different temporal positions in two samples, what property should a good TSC model exhibit to recognize them as the same class?

- Concept: State-space models and their selectivity property
  - Why needed here: Mamba is the core sequence modeling component, and understanding how its selectivity property (gate-controlled state updates) differs from standard RNNs is crucial for grasping why it's effective for TSC
  - Quick check question: How does Mamba's gate-controlled state update differ from a standard RNN's update rule, and what advantage does this provide for sequence modeling?

- Concept: Multi-view learning and feature fusion strategies
  - Why needed here: The paper's main innovation involves combining multiple feature types (spectral, local temporal, global temporal) and fusing them adaptively, which requires understanding how multi-view approaches can improve classification
  - Quick check question: What are the potential benefits and challenges of combining features from different domains (time vs frequency) in a classification task?

## Architecture Onboarding

- Component map: Input → CWT + ROCKET/MLP → Switch-fused features → Tango scanning → Pooling → MLP → Output
- Critical path: Input → CWT + ROCKET/MLP → Switch-fused features → Tango scanning → Pooling → MLP → Output
- Design tradeoffs: Single Mamba block for tango scanning vs separate blocks (memory vs performance), CWT vs DFT/DWT (shift-equivariance vs computational cost), switch gate vs fixed fusion ratio (adaptivity vs simplicity)
- Failure signatures:
  - If tango scanning shows no improvement over forward scanning → issue with bidirectional dependency modeling
  - If switch gate consistently selects only one temporal feature type → adaptive selection not learning meaningful differences
  - If performance degrades with longer sequences → Mamba's long-range dependency capture insufficient
- First 3 experiments:
  1. Compare vanilla Mamba (forward scanning only) vs TSCMamba on a small dataset to validate tango scanning benefit
  2. Test with fixed fusion ratio (no switch gate) vs adaptive fusion to validate switch mechanism
  3. Replace CWT with DFT to test if shift-equivariance property is actually important for the datasets used

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would different wavelet functions (e.g., Morlet vs. other complex-valued wavelets) affect classification accuracy and computational efficiency in TSCMamba?
- Basis in paper: [explicit] The paper mentions using the Morlet wavelet with specific parameters (σ² = 1, f = 5/(2π)) but notes that "keeping these parameters learnable may potentially benefit the classification accuracy."
- Why unresolved: The authors chose Morlet with fixed parameters but did not explore alternatives or learnable parameters, leaving uncertainty about optimal wavelet selection for different time series datasets.
- What evidence would resolve it: Comparative experiments testing multiple wavelet functions (Morlet, Mexican Hat, Complex Gaussian, etc.) with both fixed and learnable parameters across diverse benchmark datasets, measuring accuracy and computational cost.

### Open Question 2
- Question: How does the tango scanning mechanism scale with extremely long sequences (e.g., >10,000 time points) compared to standard bidirectional processing in terms of both accuracy and memory usage?
- Basis in paper: [explicit] The paper introduces tango scanning as a novel approach that "uses essentially the same memory footprint but demonstrates higher accuracy than vanilla Mamba scanning" and compares it favorably to BiMamba, but does not test extreme sequence lengths.
- Why unresolved: While tango scanning shows benefits over vanilla Mamba and BiMamba, the paper does not evaluate its performance at the upper limits of sequence length where memory and computational constraints become critical.
- What evidence would resolve it: Systematic scaling experiments testing tango scanning on progressively longer sequences (1K, 2K, 5K, 10K+ time points) while measuring accuracy retention, memory consumption, and processing time compared to alternative bidirectional approaches.

### Open Question 3
- Question: Would a dynamic, data-driven switching mechanism between local (ROCKET) and global (MLP) temporal features outperform the current learnable binary mask approach?
- Basis in paper: [inferred] The paper mentions using "a switch mechanism that selects between CNN-based (primarily local) features and MLP-based global patterns" implemented as "a learnable binary mask," but does not explore more sophisticated selection strategies.
- Why unresolved: The authors employ a simple binary mask for feature selection, but more advanced methods (e.g., attention-based weighting, mixture-of-experts) could potentially yield better performance by more nuanced feature integration.
- What evidence would resolve it: Comparative experiments testing alternative switching mechanisms (attention-based soft selection, learned gating functions, mixture-of-experts architectures) against the current binary mask approach across multiple datasets, measuring classification accuracy and feature utilization patterns.

## Limitations

- Limited ablation studies prevent clear attribution of performance gains to specific components (tango scanning vs multi-view fusion vs Mamba architecture)
- No statistical significance testing reported for performance differences across datasets
- Hyperparameter tuning appears dataset-specific but lacks systematic comparison

## Confidence

- **High confidence**: Mamba's effectiveness as a state-space model for sequence modeling (well-established in literature)
- **Medium confidence**: Multi-view learning framework improves performance (supported by results but lacks ablation clarity)
- **Low confidence**: Shift-equivariance via CWT is a key differentiator (claim not rigorously validated against alternatives)

## Next Checks

1. Conduct systematic ablation studies isolating tango scanning, multi-view fusion, and Mamba components to quantify individual contributions
2. Perform statistical significance testing (paired t-tests) across all dataset comparisons to verify claimed improvements are not due to chance
3. Test performance with alternative spectral feature extraction methods (DFT, DWT) to validate the specific importance of CWT's shift-equivariance property