---
ver: rpa2
title: 'BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?'
arxiv_id: '2411.12235'
source_url: https://arxiv.org/abs/2411.12235
tags:
- questions
- retrieval
- question
- boolean
- dense
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether dense retrieval systems understand
  Boolean logic in natural language queries. The authors formulate the Boolean Dense
  Retrieval (BDR) task and create BOOL QUESTIONS , a benchmark dataset containing
  complex queries with AND, OR, and NOT operators, along with corresponding annotated
  passages.
---

# BoolQuestions: Does Dense Retrieval Understand Boolean Logic in Language?

## Quick Facts
- arXiv ID: 2411.12235
- Source URL: https://arxiv.org/abs/2411.12235
- Reference count: 22
- State-of-the-art dense retrievers show significant performance drops on NOT questions, indicating limited understanding of Boolean logic in natural language.

## Executive Summary
This paper investigates whether dense retrieval systems can understand Boolean logic operations (AND, OR, NOT) when expressed in natural language queries. The authors introduce BOOL QUESTIONS, a benchmark dataset containing complex queries with Boolean operators, and evaluate state-of-the-art dense retrievers on this dataset. Results show that while retrievers perform well on AND and OR queries, they struggle significantly with NOT queries, often returning documents that should be excluded by negation logic. To address this limitation, the authors propose two baseline methods: Boolean operation on decomposed queries and contrastive continual training on NOT queries. Experiments demonstrate that both methods can reduce false positives in NOT queries but at the cost of some overall retrieval accuracy.

## Method Summary
The authors formulate the Boolean Dense Retrieval (BDR) task and create the BOOL QUESTIONS benchmark dataset. The dataset is constructed through a multi-step process: hierarchical passage clustering using BERT-style encoders, question generation using GPT-4 for different Boolean operations, and cyclic consistency filtering for quality control. Two baseline methods are proposed to improve Boolean logic understanding: (1) Boolean operation on decomposed query, which decomposes complex queries into simpler ones and performs set operations on retrieval results, and (2) contrastive continual training, which fine-tunes dense retrievers on additional NOT query training data. The methods are evaluated using MRR@10 for overall performance and NegRecall@10 specifically for NOT query handling.

## Key Results
- Dense retrievers show MRR@10 scores of 0.0091 on NOT queries in BOOL QUESTIONS, compared to much higher scores on AND/OR queries
- Boolean operation on decomposed queries reduces NegRecall@10 from 19.50% to 15.54% but also reduces MRR@10
- Contrastive continual training on NOT questions reduces NegRecall@10 from 19.50% to 13.72% while maintaining better MRR@10 performance

## Why This Works (Mechanism)

### Mechanism 1
Dense retrievers fail on NOT queries because their training objectives only optimize for relevance matching, not for understanding logical negation. The models learn to produce high scores for relevant documents but have no explicit signal to suppress scores for documents that should be excluded by NOT logic. Current dense retrieval training frameworks (contrastive learning) only model positive relevance signals, leaving negative logic patterns unlearned.

### Mechanism 2
Boolean operation on decomposed queries fails because the decomposition process introduces semantic drift that breaks the original query's logical meaning. Large language models may not preserve exact logical equivalence when paraphrasing complex Boolean expressions into simpler components, leading to mismatched candidate lists. The decomposed queries, while individually valid, don't maintain the same semantic boundaries as the original complex query.

### Mechanism 3
Contrastive continual training on NOT queries improves understanding of negation because it provides explicit negative examples that the model can learn to distinguish. By fine-tuning with additional NOT query training data, the model learns to assign lower scores to documents that match the negated portion of the query. Additional training data with explicit NOT logic examples provides sufficient signal for the model to learn negation patterns.

## Foundational Learning

- **Concept**: Boolean logic operations (AND, OR, NOT) and their set-theoretic interpretations
  - Why needed here: The paper's core contribution is testing whether dense retrievers understand these operations in natural language queries
  - Quick check question: If you have sets A={1,2,3} and B={3,4,5}, what are A AND B, A OR B, and A NOT B?

- **Concept**: Dense retrieval architecture and contrastive learning objectives
  - Why needed here: Understanding how current dense retrievers are trained helps explain why they fail on Boolean logic
  - Quick check question: In contrastive learning for dense retrieval, what are the "positive" and "negative" pairs used for training?

- **Concept**: Set operations on ranked lists (intersection, union, difference)
  - Why needed here: The "Boolean operation on decomposed query" baseline uses these operations to combine retrieval results
  - Quick check question: If you have two ranked lists of documents, how would you compute their intersection while preserving ranking scores?

## Architecture Onboarding

- **Component map**: Query encoder -> Document encoder -> Similarity function -> Index structure -> Training pipeline
- **Critical path**: Encode query → dense vector → search index for nearest neighbors → ranked document list → return top-k documents. The critical issue is step 2 fails for NOT queries because similarity search doesn't understand negation.
- **Design tradeoffs**: Dense vs sparse representations (dense captures semantics but loses explicit Boolean logic), pre-training vs fine-tuning (pre-trained models work well on relevance but not on logical operations), model size vs speed (larger models may capture more nuance but are slower for real-time retrieval)
- **Failure signatures**: High NegRecall@k indicates the model returns documents that should be excluded by NOT logic, low MRR@k on AND/OR subsets suggests decomposition or combination strategies are flawed, inconsistent performance across different dense retriever architectures indicates the problem is fundamental to the approach
- **First 3 experiments**: 1) Run baseline dense retriever on BOOL QUESTIONS and measure MRR@k and NegRecall@k for each query type, 2) Implement Boolean operation on decomposed query and compare performance degradation on AND/OR subsets, 3) Train contrastive model on additional NOT queries and measure improvement in NegRecall@k while monitoring MRR@k degradation

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed contrastive continual training method effectively generalize to handle other types of Boolean logic beyond AND, OR, and NOT operations? The paper only evaluates the proposed method on AND, OR, and NOT questions, leaving the generalization to other types of Boolean logic unexplored.

### Open Question 2
How does the proposed Boolean operation on decomposed query method perform compared to traditional sparse retrieval methods in terms of handling Boolean logic in natural language queries? The paper focuses on dense retrieval methods and does not provide a direct comparison between the proposed method and traditional sparse retrieval methods.

### Open Question 3
Can the proposed cyclic consistency filtering strategy be further improved to reduce the number of false negatives in the generated dataset? The paper mentions that the cyclic consistency filtering strategy effectively eliminates most false positives but discards false negatives, which may compromise the quality of the filtered data.

## Limitations

- BOOL QUESTIONS dataset relies heavily on GPT-4 for question generation, potentially introducing biases in natural language formulations
- Both proposed baseline methods show improvements in negation handling but at the cost of overall retrieval accuracy
- The paper does not fully explore whether limitations stem from fundamental architectural constraints or could be addressed through alternative training approaches

## Confidence

- **High Confidence**: Claims about dense retrievers' poor performance on NOT queries (MRR@10 drops are consistently observed across multiple models)
- **Medium Confidence**: The effectiveness of the two proposed baseline methods (results show promise but also reveal significant trade-offs)
- **Medium Confidence**: The dataset construction methodology (systematic but dependent on LLM generation quality)

## Next Checks

1. **Dataset Validation**: Test whether the BOOL QUESTIONS dataset reveals similar performance gaps when used with other information retrieval tasks (e.g., question answering, fact verification) to confirm the findings aren't specific to the dense retrieval setting.

2. **Alternative Decomposition Methods**: Implement and evaluate alternative question decomposition strategies (e.g., using different LLMs or rule-based approaches) to determine whether the performance degradation is inherent to decomposition or specific to the proposed method.

3. **Extended Training Analysis**: Conduct ablation studies on the contrastive continual training method to identify the minimum amount of NOT query training data needed for improvement and whether this data can be synthetically generated rather than requiring human annotation.