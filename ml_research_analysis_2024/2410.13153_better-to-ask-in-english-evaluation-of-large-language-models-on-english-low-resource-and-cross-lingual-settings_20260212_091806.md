---
ver: rpa2
title: 'Better to Ask in English: Evaluation of Large Language Models on English,
  Low-resource and Cross-Lingual Settings'
arxiv_id: '2410.13153'
source_url: https://arxiv.org/abs/2410.13153
tags:
- languages
- llms
- arxiv
- english
- settings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates three large language models (GPT-4, Llama
  2, and Gemini) on English versus low-resource South Asian languages (Bangla, Hindi,
  and Urdu) using zero-shot prompting across five prompt settings. The primary finding
  is that GPT-4 consistently outperforms Llama 2 and Gemini across all languages and
  settings, with English prompts yielding better results than low-resource language
  prompts.
---

# Better to Ask in English: Evaluation of Large Language Models on English, Low-resource and Cross-Lingual Settings

## Quick Facts
- arXiv ID: 2410.13153
- Source URL: https://arxiv.org/abs/2410.13153
- Authors: Krishno Dey; Prerona Tarannum; Md. Arid Hasan; Imran Razzak; Usman Naseem
- Reference count: 20
- Primary result: GPT-4 outperforms Llama 2 and Gemini on English and low-resource South Asian languages using zero-shot prompting

## Executive Summary
This study evaluates three large language models (GPT-4, Llama 2, and Gemini) on English versus low-resource South Asian languages (Bangla, Hindi, and Urdu) using zero-shot prompting across five prompt settings. The primary finding is that GPT-4 consistently outperforms Llama 2 and Gemini across all languages and settings, with English prompts yielding better results than low-resource language prompts. Notably, cross-lingual translation of prompts did not significantly impact performance, suggesting translation quality is not a primary factor in LLM effectiveness for these languages. Llama 2 particularly struggled with low-resource languages, while Gemini showed moderate performance but had limitations with Urdu and harmful content. The results highlight the need for improved multilingual capabilities and better language-specific resources for low-resource languages in LLM development.

## Method Summary
The study evaluates three LLMs (GPT-4, Llama 2, and Gemini) on Natural Language Inference (NLI) tasks using the XNLI dataset and classification tasks using the SIB-200 dataset. Five zero-shot prompt settings are tested: original language-specific prompts (P1) and translated prompts from English to target languages (P2-P5). Models are evaluated across English, Hindi, Urdu, and Bangla using accuracy and F1 scores (weighted and macro). Post-processing handles invalid labels, and safety settings are adjusted for Gemini when needed.

## Key Results
- GPT-4 consistently outperforms Llama 2 and Gemini across all languages and settings
- English prompts yield better results than low-resource language prompts for all three models
- Cross-lingual translation of prompts did not significantly impact performance, suggesting translation quality is not a primary factor
- Llama 2 particularly struggled with low-resource languages, while Gemini showed moderate performance with limitations for Urdu and harmful content

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Translation quality does not significantly impact LLM performance on low-resource languages.
- Mechanism: Even when prompts are translated from English to low-resource languages (e.g., Bangla, Hindi, Urdu), the LLM's ability to generate correct labels remains largely unchanged, suggesting the model's underlying language understanding capability is not dependent on translation accuracy.
- Core assumption: LLMs have robust internal representations that allow them to interpret prompts in multiple languages without relying on perfect translation fidelity.
- Evidence anchors:
  - [abstract] "cross-lingual translation of prompts did not significantly impact performance, suggesting translation quality is not a primary factor in LLM effectiveness for these languages."
  - [section] "Our results suggest that the translation of a specific language does not significantly affect the prediction capabilities of LLMs."
- Break condition: If translation errors introduce ambiguity or incorrect terminology that fundamentally changes the task meaning, performance may degrade.

### Mechanism 2
- Claim: English prompts consistently yield better LLM performance than low-resource language prompts.
- Mechanism: LLMs are predominantly trained on English data (e.g., Llama 2 uses ~90% English data), so their language models and contextual understanding are better optimized for English, leading to superior performance even when prompts are otherwise equivalent.
- Core assumption: The underlying distribution of training data heavily influences model performance across languages.
- Evidence anchors:
  - [abstract] "all three LLMs performed better for English language prompts than other low-resource language prompts."
  - [section] "One significant reason is the disproportionate training distribution, with most LLMs predominantly trained on extensive English corpora."
- Break condition: If training data distribution is balanced across languages, the performance gap may narrow or disappear.

### Mechanism 3
- Claim: GPT-4's superior multilingual capabilities and prompt understanding lead to better performance across all languages and settings.
- Mechanism: GPT-4's architecture and training process enable it to better understand prompts and generate appropriate responses, with minimal extraneous output, across both high-resource and low-resource languages.
- Core assumption: GPT-4's training includes more diverse multilingual data and better instruction tuning than other models.
- Evidence anchors:
  - [abstract] "GPT-4 consistently outperforms Llama 2 and Gemini across all languages and settings."
  - [section] "GPT-4 demonstrated superior performance to Llama 2 and Gemini Pro across all settings and languages, showcasing its accuracy in understanding prompts and providing appropriate responses."
- Break condition: If GPT-4's training data or instruction tuning is compromised or if prompts are designed in a way that specifically exploits weaknesses in GPT-4.

## Foundational Learning

- Concept: Zero-shot prompting
  - Why needed here: The study relies on providing task instructions without examples, testing the model's ability to generalize from instructions alone.
  - Quick check question: What distinguishes zero-shot prompting from few-shot prompting in terms of task instruction delivery?

- Concept: Cross-lingual evaluation
  - Why needed here: The study compares model performance across English and low-resource languages to identify performance gaps and biases.
  - Quick check question: How does cross-lingual evaluation differ from monolingual evaluation in terms of dataset requirements and metric interpretation?

- Concept: NLI (Natural Language Inference) task
  - Why needed here: The study uses XNLI dataset, which is based on NLI, requiring models to determine entailment, contradiction, or neutrality between premise and hypothesis.
  - Quick check question: What are the three possible labels in an NLI task and what does each represent?

## Architecture Onboarding

- Component map: LLM evaluation pipeline → Data preparation (XNLI/SIB-200) → Prompt generation (5 settings) → Model inference (GPT-4, Llama 2, Gemini) → Post-processing (label extraction) → Evaluation (accuracy, F1 scores)
- Critical path: Data preparation → Prompt generation → Model inference → Evaluation
- Design tradeoffs: Using zero-shot prompting avoids need for task-specific fine-tuning but may limit performance compared to few-shot approaches; focusing on NLI task provides consistency but may not generalize to all NLP tasks.
- Failure signatures: Invalid labels returned by models, safety filters blocking predictions, class imbalance in results, performance degradation with translated prompts
- First 3 experiments:
  1. Test each model on English prompts with original XNLI data to establish baseline performance
  2. Test each model on translated prompts (P2-P5 settings) to assess impact of translation on performance
  3. Compare class-wise precision and recall across languages to identify specific performance bottlenecks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs perform on other low-resource languages not included in this study (e.g., African languages, indigenous languages)?
- Basis in paper: [explicit] The authors state "Despite their widespread use, these languages are considered low-resource in NLP" and discuss the need for "developing resources for South Asian languages to improve LLM generalization," suggesting the broader question of low-resource language performance.
- Why unresolved: The study only examined three specific South Asian languages (Bangla, Hindi, Urdu), limiting generalizability to other low-resource language contexts.
- What evidence would resolve it: Comparative evaluation of the same three LLMs across a diverse set of low-resource languages from different language families and geographic regions using similar experimental methodology.

### Open Question 2
- Question: What specific aspects of translation quality (e.g., word order, lexical choice, grammatical structure) most significantly impact LLM performance in cross-lingual settings?
- Basis in paper: [inferred] The authors found "translation quality of prompts has minimal impact on LLM performance" but did not investigate which specific translation aspects might matter, suggesting deeper analysis could reveal nuanced effects.
- Why unresolved: The study used Google Translate without analyzing specific translation errors or comparing different translation approaches, leaving the relationship between translation quality and performance unclear.
- What evidence would resolve it: Systematic analysis comparing LLM performance across manually translated prompts with varying quality levels, focusing on specific translation features like syntactic preservation, semantic equivalence, and cultural adaptation.

### Open Question 3
- Question: How would few-shot prompting techniques affect LLM performance on low-resource languages compared to zero-shot methods used in this study?
- Basis in paper: [explicit] The authors acknowledge "we only utilized zero-shot prompting techniques and did not explore explicit prompting techniques (e.g., few-shot prompting)" and note resource limitations prevented broader experimentation.
- Why unresolved: Resource constraints limited the study to zero-shot prompting only, preventing comparison with more sample-efficient prompting strategies that might improve low-resource language performance.
- What evidence would resolve it: Direct comparison of zero-shot versus few-shot prompting across the same tasks and languages, measuring performance gains and analyzing how few examples in target languages affect model behavior.

## Limitations
- Study focuses on three South Asian languages from the Indo-Aryan family, limiting generalizability to other language families
- Evaluation relies on zero-shot prompting without exploring few-shot examples that might improve performance
- Does not investigate whether fine-tuning on low-resource language data could bridge performance gaps

## Confidence

**High Confidence:** The finding that GPT-4 consistently outperforms Llama 2 and Gemini across all languages and settings is well-supported by the experimental results.

**Medium Confidence:** The conclusion that translation quality does not significantly impact LLM performance requires careful interpretation and may be due to models' robustness to translation noise rather than translation quality being irrelevant.

**Low Confidence:** The claim that Llama 2 "particularly struggled" with low-resource languages doesn't explore whether this is due to training data imbalance, architectural limitations, or evaluation methodology.

## Next Checks

1. **Cross-linguistic validation**: Repeat the experiment with low-resource languages from different language families (e.g., African languages, Southeast Asian languages) to determine whether the English performance advantage is consistent across language families or specific to Indo-Aryan languages.

2. **Prompt engineering exploration**: Test alternative prompt engineering strategies for low-resource languages, including few-shot examples, chain-of-thought prompting, and culturally contextualized prompts, to determine whether the performance gap can be reduced through better prompting rather than model changes.

3. **Fine-tuning impact assessment**: Fine-tune Llama 2 and Gemini on additional low-resource language data and re-evaluate performance to determine whether the observed gaps are primarily due to training data limitations or fundamental architectural differences between the models.