---
ver: rpa2
title: Transformers with Sparse Attention for Granger Causality
arxiv_id: '2411.13264'
source_url: https://arxiv.org/abs/2411.13264
tags:
- time
- attention
- causality
- causal
- granger
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Sparse Attention Transformer (SAT) to identify
  Granger causal relationships in multivariate time-series data with random delays.
  Unlike traditional methods requiring fixed lag, SAT learns to select the most significant
  past time instances for predictions using a novel sparse attention mechanism.
---

# Transformers with Sparse Attention for Granger Causality

## Quick Facts
- arXiv ID: 2411.13264
- Source URL: https://arxiv.org/abs/2411.13264
- Authors: Riya Mahesh; Rahul Vashisht; Chandrashekar Lakshminarayanan
- Reference count: 24
- The paper introduces Sparse Attention Transformer (SAT) to identify Granger causal relationships in multivariate time-series data with random delays, achieving AUC-ROC scores of 0.70-0.78 and F1 scores of 0.63-0.72.

## Executive Summary
This paper presents the Sparse Attention Transformer (SAT), a novel approach for identifying Granger causal relationships in multivariate time-series data with random delays. Unlike traditional methods that require fixed lag specifications, SAT learns to select the most significant past time instances through a two-step attention mechanism: first performing temporal attention to identify important time steps, then computing inter-variable attention to establish causal links. The method demonstrates superior performance compared to VAR-based Granger Causality baselines, achieving AUC-ROC scores between 0.70-0.78 and F1 scores between 0.63-0.72 across synthetic datasets with 4-10 variables.

## Method Summary
The SAT model uses a novel sparse attention mechanism that first performs temporal attention to select the top-k important past time instances within a given window, then computes self-attention between variables to capture causal relationships. The model employs a two-layer transformer architecture with positional embeddings, where the first layer performs temporal attention selection and the second layer computes variable relationships. During inference, individual variables are masked to compute Granger causality indices based on prediction error variances. The method is evaluated on synthetic multivariate time-series datasets generated using the Causality 4 Climate (C4C) framework, comparing performance against VAR-based Granger Causality baselines using AUC-ROC and F1 metrics.

## Key Results
- SAT achieves AUC-ROC scores of 0.70-0.78 across synthetic datasets with 4-10 variables, outperforming VAR baseline scores of 0.47-0.67
- F1 scores for SAT range from 0.63-0.72, compared to baseline scores of 0.51-0.66
- The method effectively handles varying lag dependencies and random delays in stationary data
- Performance advantage is particularly notable for datasets with complex lag structures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The sparse attention mechanism learns to select the most significant past time instances for prediction by analyzing column sums of the temporal attention matrix.
- Mechanism: The model computes temporal attention weights across all past time steps within a 2k window. It then uses column sums of this attention matrix to identify the k most influential time instances, effectively learning the optimal lag structure without manual specification.
- Core assumption: Column sums of the attention matrix serve as a valid proxy for temporal importance in predicting the current time step.
- Evidence anchors:
  - [abstract]: "Our Sparse Attention Transformer (SAT) uses a novel sparse attention mechanism which at time ð‘¡ selects the top 'ð‘˜' important past time instance within a given window."
  - [section]: "We now analyze the physical significance of the column sums of this matrix. The mean of a column ð‘— indicates the average influence that time-instance ð‘— has on all other time-instances."
  - [corpus]: Weak evidence. No corpus papers directly validate column sum selection for temporal importance, though related work exists on attention-based temporal modeling.
- Break condition: If the temporal dependencies are non-linear or if important time steps have similar influence patterns, column sum selection may fail to identify the true causal lags.

### Mechanism 2
- Claim: Inter-variable attention identifies causal relationships by computing self-attention between variables using the selected k time instances.
- Mechanism: After temporal attention selects the k most important time steps, the model transposes this data and computes self-attention between variables. This attention matrix directly represents causal strength between variable pairs.
- Core assumption: Self-attention weights between variables, when computed on optimally selected time steps, reflect true causal relationships rather than mere correlations.
- Evidence anchors:
  - [abstract]: "Our Sparse Attention Transformer captures causal relationships using a two-fold approach - performing temporal attention first followed by attention between the variables across the time steps masking them individually to compute Granger Causality indices."
  - [section]: "On performing self-attention between queries and keys of this input in a similar way, we obtain the attention matrix ð´ð‘‘ âˆˆ ð‘…ð· Ã—ð· capturing the dependencies of the D variables over each other as: ð´ð‘‘ = ð‘ ð‘œ ð‘“ ð‘¡ð‘šð‘Žð‘¥ ( ð‘„2ð¾ð‘‡ 2âˆšï¸ð‘‘ð‘˜2 )"
  - [corpus]: Weak evidence. While attention weights are suggested as causal indicators in related work, the specific two-step temporal-then-variable approach lacks direct corpus validation.
- Break condition: If variables have strong indirect relationships through other variables, or if the temporal selection is suboptimal, the inter-variable attention may capture spurious correlations rather than true causal links.

### Mechanism 3
- Claim: Masking individual variables during inference provides Granger causality indices by comparing prediction error variances.
- Mechanism: After training, the model is evaluated by masking each variable individually and computing prediction errors. The variance ratio between unrestricted and restricted models yields Granger causality indices.
- Core assumption: The difference in prediction accuracy when masking a variable reflects its true causal influence on other variables in the system.
- Evidence anchors:
  - [abstract]: "We apply a ð· Ã— ð· mask with entries of the ð‘–ð‘¡â„Ž column as âˆ’âˆž and others as 0 to mask the effect of the ð‘–ð‘¡â„Ž variable. Hence, new predictions for ð‘‹ð‘¡ are obtained with each column being masked individually."
  - [section]: "We now compute the standard deviation of errors for the unrestricted model (predictions obtained during the training phase) and restricted model (predictions obtained during the inference stage by masking variables one by one) and calculate the Granger Causality Index of every variable."
  - [corpus]: Moderate evidence. This follows the standard Granger causality framework of comparing restricted vs unrestricted models, though applied in the transformer context.
- Break condition: If the model overfits to the training data, masking effects may be underestimated. Additionally, if variables have compensating effects, masking one may not significantly impact prediction accuracy.

## Foundational Learning

- Concept: Vector Autoregression (VAR) models and traditional Granger causality
  - Why needed here: The paper explicitly compares against VAR-based Granger causality as a baseline, and the final causality indices are computed using the same variance ratio approach.
  - Quick check question: How does the traditional Granger causality test determine if variable X causes variable Y?

- Concept: Transformer self-attention mechanism
  - Why needed here: The entire method builds upon transformer self-attention, using it both for temporal selection and inter-variable relationship identification.
  - Quick check question: What is the mathematical form of scaled dot-product attention in transformers?

- Concept: Time series stationarity and lag dependencies
  - Why needed here: The method assumes stationary data with variable lag dependencies, and the temporal attention specifically addresses the challenge of random delays in lag structure.
  - Quick check question: Why is stationarity an important assumption for Granger causality analysis?

## Architecture Onboarding

- Component map: Input -> Positional embedding -> Temporal attention (selects k time steps) -> Variable attention (computes causal matrix) -> Output. During inference: Output -> Masked evaluation (computes causality indices).
- Critical path: Temporal attention selection -> Variable attention computation -> Causality index calculation. Each stage must succeed for the final output to be meaningful.
- Design tradeoffs: Fixed window size (2k) vs adaptive windowing; single-head vs multi-head attention; computational efficiency of sparse selection vs potential information loss.
- Failure signatures: Low AUC-ROC scores despite high training accuracy (overfitting); inconsistent causality matrices across different random seeds; poor performance on datasets with known causal structure.
- First 3 experiments:
  1. Verify temporal attention correctly identifies known important time steps in synthetic data with clear lag structure.
  2. Test variable attention on data with known variable relationships to confirm it captures these links.
  3. Compare against VAR baseline on datasets with varying levels of noise and different lag structures.

## Open Questions the Paper Calls Out
None

## Limitations
- The method relies on the column sum heuristic for temporal attention selection, which may not hold for complex non-linear relationships or when multiple time steps have similar influence patterns.
- The approach requires stationarity assumptions that may not hold in real-world datasets.
- The fixed 2k window size may miss important dependencies beyond this range, and sparse selection could discard relevant information when causal relationships involve multiple interacting time steps.

## Confidence

- **High Confidence**: The temporal attention mechanism's ability to select relevant time steps within the specified window is well-supported by experimental results showing consistent AUC-ROC scores of 0.70-0.78 across datasets.
- **Medium Confidence**: The inter-variable attention's ability to identify true causal relationships is moderately supported, though the evidence from corpus papers is weak and the method may capture spurious correlations in cases of indirect relationships.
- **Low Confidence**: The column sum heuristic for temporal importance selection lacks direct validation in the corpus and may fail in scenarios with complex lag structures or non-linear dependencies.

## Next Checks

1. Test SAT on synthetic datasets with known non-linear lag dependencies to verify if the column sum selection correctly identifies important time steps beyond linear relationships.
2. Evaluate the method's performance on datasets where variables have strong indirect relationships through intermediary variables to assess whether it captures true causal links or spurious correlations.
3. Systematically vary the window size parameter and analyze how it affects causal discovery performance, particularly for datasets with known dependencies extending beyond the 2k window.