---
ver: rpa2
title: 'InteraRec: Screenshot Based Recommendations Using Multimodal Large Language
  Models'
arxiv_id: '2403.00822'
source_url: https://arxiv.org/abs/2403.00822
tags:
- user
- interarec
- screenshots
- framework
- recommendations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces InteraRec, a novel recommendation framework
  that captures user browsing screenshots and leverages multimodal large language
  models to extract user preferences. InteraRec generates personalized recommendations
  by converting these insights into optimization problems.
---

# InteraRec: Screenshot Based Recommendations Using Multimodal Large Language Models

## Quick Facts
- arXiv ID: 2403.00822
- Source URL: https://arxiv.org/abs/2403.00822
- Reference count: 8
- Key outcome: InteraRec improves MRR@50 and Recall@50 for session-based recommendations by processing screenshots with MLLMs and re-ranking predictions

## Executive Summary
This paper introduces InteraRec, a novel recommendation framework that leverages screenshots of user browsing sessions to extract preferences using multimodal large language models. The system generates personalized recommendations by converting these insights into optimization problems or using them to re-rank session-based model predictions. Experiments on a curated Amazon dataset demonstrate improved ranking performance across multiple baselines, though effectiveness diminishes with larger training data.

## Method Summary
InteraRec captures screenshots of user browsing sessions at regular intervals and processes them using multimodal large language models (MLLMs) like GPT-4V to extract keyword summaries representing user preferences. These summaries are then embedded using sentence transformers and used to re-rank top-k predictions from session-based recommendation models via cosine similarity. The framework can also integrate with optimization tools to convert extracted constraints (price range, color preferences) into actionable recommendations. The method was evaluated on a dataset of 1,500 Amazon sessions with various session-based recommendation baselines.

## Key Results
- InteraRec improves MRR@50 and Recall@50 across multiple session-based recommendation baselines
- Performance gains diminish as training data size increases, suggesting models implicitly capture summary information
- Using only product images instead of full web pages leads to decreased performance due to limited context
- Framework demonstrates effectiveness in both re-ranking and constraint-based optimization scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using MLLM to process screenshots captures user preferences more interpretably than raw weblogs
- Mechanism: Screenshots provide visual context that can be directly processed by multimodal models to extract user intent through structured keyword summaries, bypassing complex feature engineering from log data
- Core assumption: Visual browsing patterns are sufficiently informative and MLLMs can reliably translate them into structured textual summaries
- Evidence anchors: [abstract] "By opting for screenshots instead of relying on weblogs, the system can benefit from heightened interpretability... the visual nature of screenshots offer a lucid and transparent representation of user actions"; [section 4.1.4] "Our approach focuses on extracting constraints like the color and price range of products"
- Break condition: If MLLMs fail to produce consistent, accurate keyword summaries or if screenshots lack sufficient visual information to infer user intent

### Mechanism 2
- Claim: Re-ranking session-based recommendations with keyword summaries improves personalization
- Mechanism: Keyword summaries derived from screenshots are embedded and used to compute similarity scores against top-k ranked items, enabling dynamic re-ordering based on user-specific browsing context
- Core assumption: Embedding similarity between user interest keywords and item attributes correlates with relevance for the user
- Evidence anchors: [section 3.4] "We leverage a sentence embedding model to obtain vector representations... By computing the cosine similarity between the summary embeddings and the attribute embeddings of each top-ranked item, we re-rank the initial predictions"; [section 4.2.5] "We observe performance gains across all baselines using the InteraRec framework, as indicated by the evaluation metrics MRR@50 and Recall@50"
- Break condition: If keyword summaries become too generic or if the embedding space fails to capture nuanced user preferences

### Mechanism 3
- Claim: Integration with optimization tools converts keyword summaries into actionable recommendations
- Mechanism: Extracted constraints (price range, color, etc.) are passed to an optimization solver that maximizes expected revenue under user preference constraints, producing a personalized item set
- Core assumption: User preference constraints derived from keyword summaries can be mapped to optimization problem parameters without significant information loss
- Evidence anchors: [section 3.3] "InteraRec harnesses the InteraSSort framework... to deconstruct the user behavior summary into relevant constraints and uses them to solve an assortment optimization problem"; [section 4.1.2] "Under this model, the probability that a user chooses item k from an assortment S is given by P(k|S) = vl/(v0 + P k′∈S vk′)"
- Break condition: If the optimization problem becomes infeasible due to overly restrictive or conflicting constraints from the summaries

## Foundational Learning

- Concept: Multimodal Large Language Models (MLLMs)
  - Why needed here: To bridge visual browsing data (screenshots) with textual preference summaries that can be used in downstream tasks
  - Quick check question: What is the difference between an MLLM and a traditional LLM, and why is it critical for processing screenshots?

- Concept: Session-based Recommendation Systems
  - Why needed here: The baseline models predict next-item interactions based on chronological sequences, which InteraRec enhances via re-ranking
  - Quick check question: How does a session-based recommendation model differ from a traditional collaborative filtering model in terms of input and prediction?

- Concept: Optimization under Discrete Choice Models (e.g., MNL)
  - Why needed here: To translate user preference constraints into a solvable assortment optimization problem that maximizes expected revenue
  - Quick check question: In an MNL model, how is the probability of choosing an item from an assortment calculated, and what role do item utilities play?

## Architecture Onboarding

- Component map: Screenshot Capture Layer → MLLM Summarization → Embedding/Constraint Extraction → Session-based Recommender → Re-ranking / Optimization → Final Recommendations
- Critical path:
  1. Real-time screenshot capture during user session
  2. Batch processing via MLLM to extract keyword summary
  3. Embedding summary and re-ranking top-k items (session-based setup)
  4. (Optional) Constraint extraction and optimization (assortment setup)
  5. Output final ranked recommendations
- Design tradeoffs:
  - Screenshot frequency vs. system overhead: Higher frequency yields more context but increases latency and storage
  - MLLM model size vs. response quality: Larger models may improve accuracy but increase cost and delay
  - Embedding granularity vs. computational cost: Finer-grained embeddings may improve re-ranking but require more processing
- Failure signatures:
  - MLLM returns incomplete or irrelevant keyword summaries → Check prompt quality and model input constraints
  - Re-ranking yields minimal performance gains → Investigate embedding quality and similarity threshold
  - Optimization fails to produce feasible assortments → Review constraint parsing and feasibility checks
- First 3 experiments:
  1. Run a single session with baseline recommender only, measure Recall@50 and MRR@50
  2. Run the same session with InteraRec re-ranking enabled, measure improvement
  3. Vary screenshot capture frequency (e.g., 2s, 4s, 6s) and observe impact on re-ranking performance

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability concerns for real-world production environments with computational overhead of frequent screenshot processing and MLLM API usage
- Diminishing performance gains with larger training datasets suggest potential brittleness when deployed at scale
- Curated Amazon dataset may not generalize to diverse e-commerce platforms with different visual layouts and user interaction patterns

## Confidence

**High**: The mechanism of using MLLMs to process screenshots for interpretable user preference extraction
**Medium**: The effectiveness of re-ranking session-based recommendations with keyword summaries
**Medium**: The integration with optimization tools for constraint-based recommendations

## Next Checks

1. **Scalability Test**: Evaluate InteraRec's performance and computational overhead on datasets with 10x-100x more sessions to verify if diminishing returns persist with larger training data.

2. **Generalization Test**: Apply InteraRec to screenshots from multiple e-commerce platforms (e.g., eBay, Walmart, Target) to assess robustness across different website designs and product categories.

3. **Cost-Benefit Analysis**: Measure the trade-off between recommendation quality improvements and the computational/cost overhead of frequent screenshot capture and MLLM processing to determine practical deployment viability.