---
ver: rpa2
title: 'SpeechTaxi: On Multilingual Semantic Speech Classification'
arxiv_id: '2409.06372'
source_url: https://arxiv.org/abs/2409.06372
tags:
- languages
- speech
- multilingual
- language
- speechtaxi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces SpeechTaxi, an 80-hour multilingual dataset
  for semantic speech classification covering 28 diverse languages, derived from Bible
  audiobooks. The dataset enables a systematic comparison of two dominant approaches
  for semantic speech classification: end-to-end (E2E) models fine-tuned on multilingual
  speech encoders versus cascade approaches (CA) combining speech transcription with
  text-based classifiers.'
---

# SpeechTaxi: On Multilingual Semantic Speech Classification

## Quick Facts
- **arXiv ID**: 2409.06372
- **Source URL**: https://arxiv.org/abs/2409.06372
- **Reference count**: 38
- **Primary result**: Cascade approaches with Romanized transcription (MMS-ZS + LLM2Vec) outperform end-to-end models in multilingual training and cross-lingual transfer for semantic speech classification

## Executive Summary
This paper introduces SpeechTaxi, an 80-hour multilingual dataset for semantic speech classification covering 28 diverse languages derived from Bible audiobooks. The authors systematically compare two dominant approaches: end-to-end (E2E) models fine-tuned on multilingual speech encoders versus cascade approaches (CA) combining speech transcription with text-based classifiers. Through experiments across monolingual, multilingual, and zero-shot cross-lingual transfer scenarios, the study reveals that while E2E models excel in monolingual settings for low-resource languages, cascade approaches with Romanized transcription achieve superior performance in multilingual and cross-lingual settings, offering a more versatile solution for diverse linguistic contexts.

## Method Summary
The study evaluates semantic speech classification using SpeechTaxi dataset (80 hours, 28 languages, 6 topical labels) across three training scenarios: In-Language (monolingual), All-Languages (multilingual), and Zero-Shot Cross-Lingual Transfer (ZS-XLT). Two E2E models are fine-tuned: MMS-1b with learning rate 3×10⁻⁵ and XEUS with learning rate 2×10⁻⁴, both using AdamW optimizer, sequence mean-pooling, and softmax classifiers. Two cascade approaches are implemented: (1) Whisper transcription to native script followed by Furina or LLM2Vec classification, and (2) MMS-ZS Romanized transcription followed by Furina or LLM2Vec classification. All models are trained with cross-entropy loss, mixed precision, batch size 16, warmup schedules, and linear decay.

## Key Results
- E2E models (MMS-1b, XEUS) achieve highest performance in monolingual settings, particularly for low-resource languages without ASR support
- Cascade approaches with Romanized transcription (MMS-ZS + LLM2Vec) outperform all other configurations in multilingual training and zero-shot cross-lingual transfer
- The combination of MMS-ZS for Romanized transcription and LLM2Vec for text classification provides the most versatile solution across diverse linguistic contexts

## Why This Works (Mechanism)
The success of cascade approaches with Romanized transcription stems from the improved cross-lingual generalization enabled by shared Latin script representation. While native script transcription preserves linguistic nuances, it creates barriers for cross-lingual transfer between languages with different writing systems. Romanization normalizes these differences, allowing the text classifier to leverage shared linguistic patterns across languages. E2E models, while powerful for monolingual tasks, struggle to capture cross-lingual semantic relationships as effectively due to their reliance on language-specific acoustic patterns.

## Foundational Learning
- **Multilingual speech classification**: Classification of spoken content across multiple languages; needed to evaluate model performance in diverse linguistic contexts; quick check: verify models handle all 28 languages in SpeechTaxi
- **Zero-shot cross-lingual transfer**: Training on source languages and testing on unseen target languages; needed to assess model generalization beyond training data; quick check: ensure ZS-XLT setup excludes target language from training
- **Romanized transcription**: Converting non-Latin scripts to Latin alphabet; needed to enable cross-lingual transfer through shared script representation; quick check: validate Romanization quality for all 28 languages
- **Cascade vs end-to-end approaches**: Cascade uses separate transcription and classification modules, while end-to-end processes speech directly; needed to compare architectural trade-offs; quick check: confirm both approaches use identical text classifiers for fair comparison
- **Macro-F1 metric**: Unweighted average of per-class F1 scores; needed to evaluate performance across all languages and classes fairly; quick check: verify macro averaging across all 28 languages and 6 classes
- **Speech encoders**: Wav2Vec2-based models (MMS-1b, XEUS) for acoustic feature extraction; needed to process speech input for both E2E and transcription-based approaches; quick check: confirm encoder outputs match expected dimensionality

## Architecture Onboarding

**Component Map**: Audio -> (E2E: Speech Encoder -> Classifier) OR (CA: Speech Encoder -> Transcription -> Text Encoder -> Classifier)

**Critical Path**: For E2E: Speech encoding → Mean pooling → Classification; For CA: Speech encoding → Transcription → Text encoding → Classification

**Design Tradeoffs**: E2E models offer end-to-end optimization but struggle with cross-lingual transfer; CA approaches provide modularity and better cross-lingual generalization but introduce transcription errors as bottlenecks

**Failure Signatures**: Poor performance on low-resource languages indicates Romanization issues or inadequate cross-lingual transfer setup; suboptimal multilingual results suggest batch composition or learning rate schedule problems

**First Experiments**: 1) Train MMS-1b on single low-resource language to verify monolingual performance; 2) Implement Whisper + LLM2Vec cascade for multilingual training; 3) Test MMS-ZS + LLM2Vec with Romanized transcription for ZS-XLT

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Bible-derived dataset with fixed topical categories may not represent diverse real-world speech domains
- Evaluation focuses exclusively on macro-F1 performance without examining computational efficiency or other metrics
- Results depend on specific pretrained models (MMS-1b, XEUS, Whisper, MMS-ZS, Furina, LLM2Vec) that may evolve over time

## Confidence
- **High confidence**: E2E superiority in monolingual settings for low-resource languages; cascade advantage in multilingual training and cross-lingual transfer; Romanized transcription's contribution to cross-lingual generalization
- **Medium confidence**: Quantitative performance differences between specific model variants; exact ranking across all 28 languages
- **Low confidence**: Extrapolation to non-religious speech domains; performance predictions for languages beyond the 28 evaluated

## Next Checks
1. Test model generalization on a non-religious speech dataset with different semantic categories to assess domain transfer limitations
2. Conduct ablation studies removing the Romanization step to quantify its specific contribution to cross-lingual performance gains
3. Evaluate computational resource requirements and inference latency for both E2E and cascade approaches across different hardware configurations