---
ver: rpa2
title: 'Compressed Chain of Thought: Efficient Reasoning Through Dense Representations'
arxiv_id: '2412.13171'
source_url: https://arxiv.org/abs/2412.13171
tags:
- tokens
- contemplation
- reasoning
- hidden
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Compressed Chain-of-Thought (CCoT), a method
  that generates contentful, continuous contemplation tokens as compressed representations
  of reasoning chains, achieving improved reasoning accuracy with reduced generation
  latency compared to standard Chain-of-Thought. The approach finetunes decoder-only
  language models to generate a variable number of autoregressive contemplation tokens,
  which are then used to condition the answer generation.
---

# Compressed Chain of Thought: Efficient Reasoning Through Dense Representations

## Quick Facts
- arXiv ID: 2412.13171
- Source URL: https://arxiv.org/abs/2412.13171
- Authors: Jeffrey Cheng; Benjamin Van Durme
- Reference count: 11
- Key outcome: CCoT achieves 15.1% accuracy on GSM8K with r=0.1 (vs. 8.9% baseline) while only increasing decode time from 0.33s to 0.49s

## Executive Summary
This paper introduces Compressed Chain-of-Thought (CCoT), a method that generates contentful, continuous contemplation tokens as compressed representations of reasoning chains, achieving improved reasoning accuracy with reduced generation latency compared to standard Chain-of-Thought. The approach finetunes decoder-only language models to generate a variable number of autoregressive contemplation tokens, which are then used to condition the answer generation. Experiments on GSM8K show that CCoT with a compression ratio of 0.1 achieves 15.1% accuracy while only increasing decode time from 0.33s to 0.49s, outperforming discrete filler token methods.

## Method Summary
CCoT finetunes decoder-only language models to generate autoregressive contemplation tokens that compress reasoning chains into dense representations. The method uses intermediate hidden layer representations (l ≈ L/2) as inputs for generating these tokens, then trains a decoder to produce answers conditioned on the contemplation tokens. During inference, the model generates contemplation tokens and uses them to decode the final answer, with the compression ratio r controlling the trade-off between performance and efficiency.

## Key Results
- CCoT with compression ratio r=0.1 achieves 15.1% accuracy on GSM8K (vs. 8.9% baseline)
- Decode time increases from 0.33s to 0.49s (35% increase) compared to standard CoT
- Accuracy plateaus around r=0.2, suggesting diminishing returns beyond this point
- Outperforms discrete filler token methods while maintaining lower latency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuous contemplation tokens enable reasoning in dense vector space instead of discrete token space
- Mechanism: CCoT generates contentful continuous embeddings that compress reasoning chains into dense representations, allowing the model to perform additional computation in continuous space rather than being constrained to discrete token sequences
- Core assumption: The continuous representations capture sufficient semantic information to enable reasoning while being more computationally efficient than explicit token sequences
- Evidence anchors:
  - [abstract] "generates contentful and continuous contemplation tokens of variable sequence length" and "compressed representations of explicit reasoning chains"
  - [section 3.3] "we instead propose learning a module to generate the compressed representations z directly"
  - [corpus] No direct evidence - weak correlation

### Mechanism 2
- Claim: Autoregressive generation of contemplation tokens provides additional computational depth beyond parallel token processing
- Mechanism: By using intermediate hidden layer representations (l ≈ L/2) as inputs for autoregressive generation, CCoT creates sequential computational steps that build upon each other, providing depth that parallel processing cannot achieve
- Core assumption: The intermediate layer representations contain appropriate global information for chaining computations while avoiding the locality issues of early/late layers
- Evidence anchors:
  - [section 4.1] "we instead take inspiration from reasoning over continuous space and use the intermediate hidden layers of the previous contemplation token as input to the next token"
  - [section 6.1] "we found that l ≈ L/2 resulted in the best performance; we hypothesize that the hidden states at intermediate layers encode global information"
  - [corpus] No direct evidence - weak correlation

### Mechanism 3
- Claim: Adaptive compression ratio enables performance-efficiency tradeoff control
- Mechanism: The compression ratio r determines how many contemplation tokens are generated relative to the full reasoning chain, allowing users to balance reasoning performance against computational cost
- Core assumption: There exists an optimal compression ratio beyond which additional tokens provide diminishing returns due to noise accumulation
- Evidence anchors:
  - [abstract] "the reasoning improvements can be adaptively modified on demand by controlling the number of contemplation tokens generated"
  - [section 6.1] "we found that accuracy plateaus after a certain threshold, about r = 0.2"
  - [section 4.1] "This compression ratio controls how much the reasoning chains are compressed"

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Understanding how CCoT modifies standard Transformer operations is crucial for implementation and debugging
  - Quick check question: How does using hidden states from layer l as autoregressive inputs differ from standard token generation in Transformers?

- Concept: Knowledge distillation and teacher forcing
  - Why needed here: CCoT uses teacher forcing with gold hidden states during training, which requires understanding these concepts
  - Quick check question: What is the difference between training CCoT with teacher forcing versus standard autoregressive training?

- Concept: Efficient inference techniques (LoRA, KV cache compression)
  - Why needed here: The paper mentions using LoRA for finetuning and efficiency considerations are central to the work
  - Quick check question: How does LoRA finetuning reduce the computational overhead compared to full model finetuning?

## Architecture Onboarding

- Component map:
  Base LLM (LLAMA 2-7B-Chat) -> CCOT module -> DECODE module -> END predictor -> Scorer module

- Critical path:
  1. Embed query and reasoning chain
  2. Compute hidden states and select gold subset
  3. Train CCOT to generate contemplation tokens
  4. Train DECODE to generate answers from tokens
  5. During inference: generate tokens → generate answer

- Design tradeoffs:
  - Compression ratio r vs. accuracy: Higher r improves accuracy but increases latency
  - Autoregressive layer l choice: Balances local vs. global information
  - Continuous vs. discrete tokens: Continuous enables more efficient computation but requires specialized training
  - Variable vs. fixed token length: Variable provides flexibility but complicates optimization

- Failure signatures:
  - Poor reasoning accuracy despite token generation: Likely issues with token representation quality or autoregressive layer choice
  - High latency with minimal accuracy gains: Compression ratio may be too high
  - Training instability: Learning rate or LoRA rank parameters may need adjustment
  - Degraded performance on non-reasoning tasks: Model may overfit to reasoning patterns

- First 3 experiments:
  1. Baseline comparison: Run CCoT with r=0 (no tokens) vs. r=1 (full reasoning chain) to establish performance bounds
  2. Layer sensitivity: Test different autoregressive layer l values (e.g., 3, 15, 31) to find optimal configuration
  3. Compression ratio sweep: Evaluate performance across r values (0.05, 0.1, 0.2) to identify plateau point and optimal tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of compression ratio r affect the trade-off between reasoning accuracy and generation latency in CCoT?
- Basis in paper: [explicit] The paper discusses varying r and its impact on accuracy and decode time.
- Why unresolved: While the paper shows that accuracy plateaus after a certain threshold (around r = 0.2), the exact relationship between r and the performance-efficiency trade-off needs further investigation.
- What evidence would resolve it: Systematic experiments varying r across a wider range of values and tasks, coupled with detailed analysis of the generated contemplation tokens and their impact on reasoning performance.

### Open Question 2
- Question: Can the subset selection module for choosing which hidden states to approximate be learned end-to-end, rather than using a fixed scorer?
- Basis in paper: [explicit] The paper mentions that a learned scorer could potentially identify a better subset of hidden states to emulate.
- Why unresolved: The current approach uses a fixed scorer, but the paper suggests that a learned scorer could improve performance. The feasibility and effectiveness of end-to-end learning of the subset selection module is unclear.
- What evidence would resolve it: Experiments comparing the performance of CCoT with a fixed scorer versus a learned scorer, and analysis of the impact of the learned scorer on the generated contemplation tokens and reasoning accuracy.

### Open Question 3
- Question: How does the choice of the autoregressive layer l affect the quality of the generated contemplation tokens and the reasoning performance?
- Basis in paper: [explicit] The paper discusses the importance of choosing l and shows results for different layer choices.
- Why unresolved: The paper shows that l ≈ L/2 results in the best performance, but the reasons behind this and the impact of different layer choices on the generated tokens and reasoning accuracy are not fully explored.
- What evidence would resolve it: Detailed analysis of the hidden states at different layers, their suitability for autoregressive decoding, and the impact of different layer choices on the generated contemplation tokens and reasoning performance across various tasks.

## Limitations
- Limited evaluation scope: Only tested on GSM8K mathematical reasoning benchmark without testing generalization to other reasoning tasks
- Missing direct evidence: Lacks ablation studies comparing continuous vs. discrete compression approaches to validate the core mechanism claims
- Implementation gaps: Incomplete specification of scorer module implementation and some hyperparameter details

## Confidence
- High Confidence: The experimental results showing CCoT achieves better accuracy than standard CoT with similar or reduced latency (r=0.1 achieving 15.1% vs 8.9% baseline) are well-supported by the GSM8K experiments.
- Medium Confidence: The claim that autoregressive generation of contemplation tokens provides additional computational depth is plausible based on the architecture but lacks direct evidence comparing it to parallel processing alternatives.
- Low Confidence: The core mechanism claim that continuous representations enable fundamentally different reasoning in dense vector space versus discrete tokens is asserted but not empirically validated.

## Next Checks
1. **Ablation on Continuous vs Discrete Compression**: Implement a discrete token version of the compression module (using filler tokens or vocabulary-based compression) and compare its performance to CCoT's continuous approach on the same tasks.

2. **Layer Sensitivity Analysis**: Conduct a more comprehensive evaluation of the autoregressive layer l parameter by testing a wider range of values (not just l=15) and examining the impact on both reasoning performance and computational efficiency.

3. **Cross-Task Generalization Study**: Evaluate CCoT on multiple reasoning benchmarks beyond GSM8K (such as MATH, CommonsenseQA, or MultiArith) to assess whether the performance gains and optimal compression ratios generalize across different types of reasoning tasks.