---
ver: rpa2
title: Why you don't overfit, and don't need Bayes if you only train for one epoch
arxiv_id: '2411.14478'
source_url: https://arxiv.org/abs/2411.14478
tags:
- arxiv
- bayesian
- data
- neural
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses why overfitting is not observed and Bayesian
  methods are not needed in modern large-scale LLM pretraining. The key insight is
  that when training with a single epoch on a data-rich dataset, standard maximum
  likelihood training optimizes the same objective as Bayesian inference - the true
  data generating process (DGP) loss, which is equivalent to the test loss.
---

# Why you don't overfit, and don't need Bayes if you only train for one epoch

## Quick Facts
- arXiv ID: 2411.14478
- Source URL: https://arxiv.org/abs/2411.14478
- Reference count: 4
- One-line primary result: Single-epoch training on large datasets optimizes the true data generating process loss, eliminating the need for Bayesian methods to prevent overfitting

## Executive Summary
This paper argues that modern large-scale language model pretraining doesn't suffer from overfitting and doesn't benefit from Bayesian methods because it typically uses single-epoch training on massive datasets. The key insight is that when training for just one epoch on a data-rich dataset, standard maximum likelihood training optimizes the same objective as Bayesian inference - the true data generating process (DGP) loss, which is equivalent to the test loss. Each data point serves as an unbiased sample from the true DGP, making stochastic gradient descent estimates reliable. The paper concludes that as machine learning moves toward large foundation models trained on enormous datasets, the importance of Bayesian neural networks will diminish, though they remain essential in scientific settings where understanding uncertainty from finite data is the primary goal.

## Method Summary
The paper analyzes the theoretical relationship between single-epoch maximum likelihood training and Bayesian inference in data-rich settings. It examines how stochastic gradient descent on empirical loss provides unbiased estimates of the true DGP loss when each data point is sampled only once from the underlying data distribution. The analysis compares the objectives being optimized by Bayesian inference (expected log-likelihood under the true DGP) versus single-epoch maximum likelihood training (empirical log-likelihood), showing they converge to similar solutions under the stated conditions. The paper also discusses the differences between single-epoch and multi-epoch settings, explaining why overfitting occurs in the latter case.

## Key Results
- Single-epoch training on large datasets provides unbiased estimates of the true data generating process loss
- Maximum likelihood training and Bayesian inference optimize the same objective in the single-epoch setting
- Overfitting is prevented in single-epoch training because the model doesn't see repeated data points
- Bayesian methods offer no advantage in terms of overfitting or calibration in single-epoch pretraining regimes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Single-epoch training provides unbiased estimates of the true DGP loss
- Mechanism: In single-epoch training, each data point is an independent sample from the true data generating process (P(y|x,θ*)P(x)). This means the stochastic gradient descent updates on the empirical loss are unbiased estimates of the true DGP loss, which is equivalent to the test loss.
- Core assumption: The dataset is large enough that each data point is effectively an independent sample from the true DGP
- Evidence anchors:
  - [abstract] "in the data-rich setting where you only train on each datapoint once (or equivalently, you only train for one epoch), standard 'maximum likelihood' training optimizes the true data generating process (DGP) loss, which is equivalent to the test loss"
  - [section] "we can obtain unbiased estimates of the true DGP loss (Eq. 5) stochastic gradient descent, on a maximum likelihood objective, with a minibatch of data of size B"
  - [corpus] Weak evidence - corpus doesn't provide additional mechanisms
- Break condition: Multi-epoch training where data points are repeated and become dependent on the current weights

### Mechanism 2
- Claim: Bayesian inference and maximum likelihood training optimize the same objective in single-epoch setting
- Mechanism: Bayesian inference minimizes the expected log-likelihood under the true DGP, while single-epoch maximum likelihood training directly optimizes an unbiased estimate of this same objective. Therefore, both methods converge to similar solutions.
- Core assumption: The single-epoch setting provides enough independent samples to make the empirical and true DGP losses equivalent
- Evidence anchors:
  - [abstract] "As standard maximum likelihood training in the single-epoch setting optimizes the same objective as Bayesian inference, we argue that we do not expect Bayesian inference to offer any advantages in terms of overfitting or calibration in these settings"
  - [section] "in the single-epoch, data-rich setting, there is no good reason to believe that Bayesian inference will give any improvements over standard maximum-likelihood pretraining in terms of overfitting or calibration"
  - [corpus] Weak evidence - corpus doesn't provide additional mechanisms
- Break condition: When the dataset is small or when training requires multiple epochs

### Mechanism 3
- Claim: Overfitting is mitigated because the model doesn't see repeated data
- Mechanism: In multi-epoch training, repeated exposure to the same data points allows the model to memorize training data rather than learn general patterns. Single-epoch training prevents this by only seeing each data point once, maintaining the unbiased sampling from the true DGP.
- Core assumption: Repeated exposure to data points in multi-epoch training leads to overfitting
- Evidence anchors:
  - [section] "in the multi-epoch setting, the data we are actually training on are not sampled from P(y|xi,θ*)P(xi). Instead they are sampled from the empirical data distribution, Pempirical(x,y). These are different distributions"
  - [section] "we do not have this in the multi-epoch setting, where we may have trained on the current datapoint previously, and thus there may be dependencies between (xt,yt) and wt"
  - [corpus] Weak evidence - corpus doesn't provide additional mechanisms
- Break condition: When the dataset is small enough that each data point doesn't provide a good sample of the true DGP

## Foundational Learning

- Concept: Bayesian decision theory
  - Why needed here: The paper uses Bayesian decision theory to show that the Bayesian model average optimizes the expected test loss, which is equivalent to the true DGP loss
  - Quick check question: What is the key principle of Bayesian decision theory that connects it to the true DGP loss?

- Concept: Maximum likelihood estimation
  - Why needed here: The paper compares maximum likelihood training to Bayesian inference and shows they optimize the same objective in the single-epoch setting
  - Quick check question: How does maximum likelihood estimation differ from Bayesian inference in terms of the loss function being optimized?

- Concept: Stochastic gradient descent and unbiased estimation
  - Why needed here: The paper argues that SGD on single-epoch data provides unbiased estimates of the true DGP loss, which is crucial for the main claim
  - Quick check question: What conditions must be met for SGD to provide unbiased estimates of a loss function?

## Architecture Onboarding

- Component map: Neural network model Qw(y|x) -> Data distribution P(x) -> True DGP P(y|x,θ*) -> Empirical loss computation -> SGD weight updates
- Critical path: Data generation → Single epoch training with SGD → Weight updates → Convergence to true DGP optimum
- Design tradeoffs: Single-epoch training trades off the potential for better generalization through multiple passes over data against the benefit of unbiased estimation of the true DGP loss
- Failure signatures: If the dataset is too small, single-epoch training may not provide good samples of the true DGP, leading to poor generalization. If the model is too complex relative to the data, it may still overfit despite single-epoch training.
- First 3 experiments:
  1. Compare single-epoch vs multi-epoch training on a large dataset with known DGP to verify that single-epoch achieves better calibration
  2. Test the effect of dataset size on the equivalence between single-epoch ML and Bayesian inference
  3. Measure the impact of model complexity on overfitting in single-epoch training

## Open Questions the Paper Calls Out
- Question: Does the one-epoch optimization framework apply to all types of foundation models (e.g., image, audio, multimodal) or is it specific to LLMs?
  - Basis in paper: [inferred] The paper focuses primarily on LLMs but suggests the principle may extend to "foundation models" generally
  - Why unresolved: The paper only provides empirical evidence from LLM pretraining and doesn't test whether the same principles hold for other modalities
  - What evidence would resolve it: Systematic experiments comparing single-epoch training outcomes across different model types and modalities

- Question: What happens to the single-epoch optimization advantage when training data is not i.i.d. or contains significant domain shift?
  - Basis in paper: [inferred] The paper assumes data is sampled from the true DGP, but real-world datasets often have distribution shifts and temporal dependencies
  - Why unresolved: The theoretical framework relies on unbiased sampling from the true DGP, which may not hold in practice
  - What evidence would resolve it: Empirical studies of single-epoch training performance under various data distribution conditions and domain shifts

- Question: How does the single-epoch optimization framework interact with curriculum learning or data ordering strategies?
  - Basis in paper: [inferred] The paper assumes random sampling from the DGP, but many training pipelines use specific data ordering
  - Why unresolved: The theoretical guarantees depend on data being independent samples, which may be violated by curriculum learning
  - What evidence would resolve it: Controlled experiments comparing random vs. ordered data presentation in single-epoch training regimes

## Limitations
- The paper's claims rely heavily on the assumption that single-epoch training on massive datasets provides truly unbiased samples from the true data generating process
- The assertion that Bayesian methods offer no advantage in single-epoch settings may be premature, as certain Bayesian techniques could still provide value for uncertainty quantification
- The paper doesn't provide empirical validation of calibration claims across diverse model architectures or domains

## Confidence
- High confidence: The theoretical equivalence between single-epoch maximum likelihood training and Bayesian inference objectives
- Medium confidence: The claim that single-epoch training prevents overfitting in practice
- Medium confidence: The broader conclusion that Bayesian methods will diminish in importance for large-scale pretraining

## Next Checks
1. Empirically test calibration metrics (Expected Calibration Error, Negative Log Likelihood) across different model sizes and architectures when trained for one epoch vs multiple epochs on identical datasets
2. Evaluate whether the theoretical equivalence between single-epoch ML and Bayesian objectives holds when datasets contain temporal dependencies or selection biases
3. Investigate whether specific Bayesian techniques (like uncertainty quantification for OOD detection) still provide value in single-epoch training scenarios, even when standard overfitting concerns are mitigated