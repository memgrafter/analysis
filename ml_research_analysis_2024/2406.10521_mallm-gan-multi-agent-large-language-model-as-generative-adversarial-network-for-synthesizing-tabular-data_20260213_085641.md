---
ver: rpa2
title: 'MALLM-GAN: Multi-Agent Large Language Model as Generative Adversarial Network
  for Synthesizing Tabular Data'
arxiv_id: '2406.10521'
source_url: https://arxiv.org/abs/2406.10521
tags:
- data
- synthetic
- causal
- generation
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MALLM-GAN, a multi-agent LLM framework that
  generates high-quality synthetic tabular data by optimizing the data generation
  process using adversarial training. The approach uses one LLM as a generator to
  produce synthetic data based on a natural language data generation process, another
  LLM as an optimizer to refine this process, and a discriminator (trained logistic
  regression) to evaluate synthetic vs real data.
---

# MALLM-GAN: Multi-Agent Large Language Model as Generative Adversarial Network for Synthesizing Tabular Data

## Quick Facts
- arXiv ID: 2406.10521
- Source URL: https://arxiv.org/abs/2406.10521
- Reference count: 40
- Key outcome: MALLM-GAN achieves 0.82 F1 vs 0.72 CTGAN on Adult dataset with N=25 samples while maintaining privacy

## Executive Summary
This paper introduces MALLM-GAN, a multi-agent LLM framework that generates high-quality synthetic tabular data through adversarial optimization. The system uses one LLM as a generator to produce synthetic data based on natural language prompts, another LLM as an optimizer to refine the generation process, and a logistic regression discriminator to evaluate realism. Experiments on healthcare and public datasets show MALLM-GAN outperforms state-of-the-art models in both utility (downstream task performance) and privacy preservation while providing explainable data generation through natural language prompts.

## Method Summary
MALLM-GAN implements a multi-agent adversarial training framework where a generator LLM creates synthetic data based on prompts containing context, schema, causal structure, and task instructions. The synthetic data is evaluated by a logistic regression discriminator that distinguishes it from real data. An optimizer LLM then refines the generation prompt to minimize the discriminator's accuracy, creating an iterative optimization loop. The approach uses in-context few-shot learning with serialized JSON tabular data and incorporates causal structure to guide realistic data generation, supporting conditional sampling while maintaining privacy through distance metrics.

## Key Results
- Achieves 0.82 F1 vs 0.72 CTGAN on Adult dataset with N=25 samples
- Maintains privacy with similar or higher DCR compared to baselines
- Outperforms state-of-the-art models across multiple datasets including Medical Insurance, Asia, ATACH2, and ERICH

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial optimization using discriminator score as loss drives data generation toward realism without gradients
- Mechanism: Generator LLM produces synthetic data, discriminator evaluates distinguishability, optimizer updates prompts to minimize discriminator accuracy
- Core assumption: Discriminator accuracy serves as reliable proxy for data realism optimizable through prompt engineering
- Evidence anchors: [abstract] "incorporating data generation process as contextual information and utilizing LLM as the optimizer", [section 3.2.2] "evaluate the accuracy of the discriminator with Dtest and pass a pair of (θi, L(fi)) to the optimizer"
- Break condition: If discriminator becomes too strong too quickly, it may not provide useful gradients for prompt refinement

### Mechanism 2
- Claim: Few-shot in-context learning with serialized tabular data enables realistic generation without fine-tuning
- Mechanism: Structured data serialized into JSON format included as examples in prompt for LLM to learn patterns
- Core assumption: LLM's pre-trained knowledge combined with in-context examples sufficient to generate realistic tabular data
- Evidence anchors: [section 3.2.1] "Structured data (x, y) is serialized into JSON format...The number n of examples is crucial", [section 5.2] "implemented a 'batches in a batch' method"
- Break condition: If context window exceeded or examples too few, LLM may not learn sufficient patterns

### Mechanism 3
- Claim: Causal structure embedded in generation prompt guides LLM to produce data respecting variable relationships
- Mechanism: Causal graph converted to text format included in prompt, providing LLM with explicit variable dependency knowledge
- Core assumption: LLM can effectively incorporate causal knowledge from prompt to generate data respecting specified relationships
- Evidence anchors: [section 3.2.1] "causal structure, represented as a DAG and converted into text format...The causal structure is heuristically determined", [section 5.3] "causal structure evolves to the ground truth...thanks to the knowledge obtained from the pre-trained LLM"
- Break condition: If initial causal structure significantly wrong or LLM cannot properly interpret causal information, generated data may violate important relationships

## Foundational Learning

- Concept: Adversarial training framework
  - Why needed here: Provides principled way to iteratively improve synthetic data quality without requiring differentiable parameters
  - Quick check question: How does using discriminator's accuracy as loss function differ from traditional GAN gradient-based optimization?

- Concept: In-context few-shot learning
  - Why needed here: Enables LLM to generate realistic data without expensive fine-tuning, critical for data-scarce scenarios
  - Quick check question: What trade-off exists between number of examples provided and context window limitations?

- Concept: Causal inference and graph representation
  - Why needed here: Ensures generated data respects known variable relationships, improving realism and downstream utility
  - Quick check question: How might incorrect causal assumptions propagate through generation process?

## Architecture Onboarding

- Component map: Generator LLM → Discriminator (logistic regression) → Optimizer LLM → Updated Generator prompt (iterative loop)
- Critical path: Generator creates synthetic data → Discriminator evaluates realism → Optimizer refines prompts → Generator produces improved data
- Design tradeoffs:
  - Context window vs number of examples: More examples improve learning but may exceed context limits
  - Discriminator complexity vs computational cost: Simpler discriminators update faster but may be less discriminative
  - Causal structure accuracy vs generation quality: Better causal knowledge improves realism but requires accurate prior knowledge
- Failure signatures:
  - Discriminator accuracy plateaus at high levels: Indicates generator cannot fool discriminator, may need prompt refinement or different discriminator
  - Generated data contains obvious errors or duplicates: Suggests insufficient examples or poor prompt construction
  - Causal relationships violated in output: Indicates causal structure not properly interpreted or incorporated
- First 3 experiments:
  1. Test basic generation: Run generator with fixed prompt on small dataset, evaluate realism qualitatively
  2. Test discriminator feedback: Generate data, evaluate with discriminator, observe accuracy changes
  3. Test optimizer refinement: Run full loop for 2-3 iterations, compare initial vs final discriminator accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MALLM-GAN performance scale with dataset size beyond evaluated ranges, and what are theoretical limitations of this scaling?
- Basis in paper: [inferred] Paper notes "while our model performs well with small sample sizes, showing better results than other baselines, the improvement diminishes with larger datasets" but lacks systematic evaluation beyond N=800 or theoretical analysis
- Why unresolved: Only benchmarks up to N=800 without theoretical analysis of how performance would degrade with larger datasets or fundamental scaling limitations
- What evidence would resolve it: Systematic experiments with larger datasets (N > 1000) comparing MALLM-GAN against baselines, combined with theoretical analysis of context window limitations and adversarial optimization dynamics

### Open Question 2
- Question: What is optimal strategy for initializing causal structure in data generation process, and how does different initialization affect convergence speed and final quality?
- Basis in paper: [explicit] Paper states "The initial causal structure is heuristically determined (e.g., Hill climbing)" and shows "Different convergence patterns were observed with different initialization strategies" but lacks systematic comparison
- Why unresolved: While demonstrating different initialization strategies lead to different convergence patterns, paper does not systematically evaluate which initialization methods are most effective or provide guidelines
- What evidence would resolve it: Controlled experiments comparing multiple causal structure initialization methods with quantitative metrics on convergence speed, final MLE, and DCR across multiple datasets

### Open Question 3
- Question: How does "batches in a batch" method for handling context window limitations compare to alternative approaches like prompt compression or hierarchical generation strategies?
- Basis in paper: [explicit] Paper describes "batches in a batch" method as solution to context length limitations and states "Various natural language serializations were tested but had minimal impact on performance" but does not compare to other potential solutions
- Why unresolved: Presents one solution to context window problem but does not evaluate whether alternative approaches might be more effective or efficient
- What evidence would resolve it: Comparative experiments testing "batches in a batch" against alternative approaches like prompt compression techniques, hierarchical generation, or fine-tuning strategies with metrics on MLE, DCR, and computational efficiency

## Limitations
- Performance claims lack ablation studies to isolate contributions of multi-agent framework versus traditional approaches
- Reliance on heuristic causal structure discovery without systematic evaluation of initialization methods
- Limited evaluation of prompt quality and sensitivity to prompt engineering variations

## Confidence

**High Confidence:**
- Overall multi-agent architecture and iterative adversarial training framework is sound and technically feasible
- Using discriminator accuracy as proxy loss for prompt optimization is valid conceptual approach
- Serialization of tabular data into JSON format for in-context learning is implementable

**Medium Confidence:**
- Specific prompt engineering techniques and meta-prompt formats will work as described across different domains
- Causal structure incorporation meaningfully improves synthetic data quality versus simpler approaches
- Reported performance improvements over state-of-the-art models are primarily due to multi-agent framework

**Low Confidence:**
- Exact causal structure discovery method produces accurate initial structures for all datasets
- Optimizer LLM can reliably refine prompts to achieve meaningful improvements in synthetic data quality
- Privacy preservation claims (DCR values) adequately address all potential privacy risks

## Next Checks

1. **Ablation study on causal structure**: Generate synthetic data with and without causal structure in prompts, comparing downstream task performance to isolate contribution of causal knowledge.

2. **Discriminator accuracy trajectory analysis**: Track discriminator accuracy across training iterations for multiple datasets to verify expected decreasing trend and identify potential stalling points.

3. **Prompt quality sensitivity analysis**: Systematically vary number and quality of examples in generator prompt to quantify trade-off between context window usage and synthetic data quality.