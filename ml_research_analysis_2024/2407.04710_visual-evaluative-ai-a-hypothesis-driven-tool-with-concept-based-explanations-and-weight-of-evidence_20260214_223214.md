---
ver: rpa2
title: 'Visual Evaluative AI: A Hypothesis-Driven Tool with Concept-Based Explanations
  and Weight of Evidence'
arxiv_id: '2407.04710'
source_url: https://arxiv.org/abs/2407.04710
tags:
- evidence
- concept
- concepts
- pcbm
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Visual Evaluative AI, a hypothesis-driven decision
  support tool that provides positive and negative evidence from image data for a
  given hypothesis by identifying high-level human concepts and calculating their
  Weight of Evidence. The authors apply this tool to skin cancer diagnosis using a
  web-based application (EvaSkan) where users can upload dermatoscopic images, select
  hypotheses, and view evidence for/against each diagnosis.
---

# Visual Evaluative AI: A Hypothesis-Driven Tool with Concept-Based Explanations and Weight of Evidence

## Quick Facts
- arXiv ID: 2407.04710
- Source URL: https://arxiv.org/abs/2407.04710
- Authors: Thao Le; Tim Miller; Ruihan Zhang; Liz Sonenberg; Ronal Singh
- Reference count: 19
- Primary result: Concept-based explanation model combining ICE and PCBM with WoE achieves 80.29% F1-score on HAM10000 dataset

## Executive Summary
This paper presents Visual Evaluative AI, a hypothesis-driven decision support tool that provides positive and negative evidence from image data for a given hypothesis by identifying high-level human concepts and calculating their Weight of Evidence. The authors apply this tool to skin cancer diagnosis using a web-based application (EvaSkan) where users can upload dermatoscopic images, select hypotheses, and view evidence for/against each diagnosis. The approach combines concept-based explanation models (ICE and PCBM) with Weight of Evidence calculations to achieve comparable performance to original CNN models while using fewer features. The tool is publicly available as a Python package.

## Method Summary
The method involves a two-stage process: first, extracting human-understandable concepts from dermatoscopic images using concept-based explanation models (ICE and PCBM); second, calculating the Weight of Evidence for each hypothesis based on these concepts. The system uses a CNN backbone (ResneXt50) to generate feature embeddings, which are then processed to identify relevant concepts. The WoE calculation aggregates evidence across concepts to support or refute specific hypotheses. The web-based interface allows users to upload images, select hypotheses, and view visual explanations of the evidence supporting or contradicting each diagnosis.

## Key Results
- EvaSkan achieves 80.29% F1-score on HAM10000 dataset using WoE-based approach
- Performance comparable to original CNN models while using fewer features
- Web-based tool successfully demonstrates hypothesis-driven visual explanation for skin cancer diagnosis

## Why This Works (Mechanism)
The approach works by bridging the gap between black-box CNN predictions and human-understandable explanations through concept-based evidence. By identifying high-level concepts (like color patterns, texture features, and structural elements) that humans use in medical diagnosis, the system can provide transparent reasoning for its predictions. The Weight of Evidence calculation aggregates both positive and negative evidence for each hypothesis, allowing users to understand not just what the system predicts, but why it reaches that conclusion and what evidence contradicts it.

## Foundational Learning

1. **Concept-based explanation models (ICE and PCBM)**
   - Why needed: Traditional CNN explanations are often opaque and difficult for domain experts to interpret
   - Quick check: Verify that extracted concepts align with dermatological knowledge and clinical decision-making

2. **Weight of Evidence (WoE) calculation**
   - Why needed: Single prediction scores don't convey the strength of evidence supporting or contradicting hypotheses
   - Quick check: Ensure WoE values correlate with clinical confidence levels and diagnostic certainty

3. **Hypothesis-driven analysis framework**
   - Why needed: Medical diagnosis requires considering multiple competing hypotheses simultaneously
   - Quick check: Validate that the system can effectively compare evidence across different diagnostic possibilities

## Architecture Onboarding

Component map: CNN backbone -> Concept extraction (ICE/PCBM) -> WoE calculation -> Hypothesis ranking -> Visual explanation

Critical path: Image upload -> Feature extraction -> Concept identification -> Evidence aggregation -> Result visualization

Design tradeoffs: The system prioritizes interpretability over maximum predictive accuracy, accepting slightly lower F1-scores in exchange for transparent explanations. This tradeoff is appropriate for medical applications where understanding the reasoning is as important as the prediction itself.

Failure signatures: 
- Over-reliance on non-diagnostic features (image artifacts, lighting conditions)
- Concept extraction failure leading to insufficient evidence
- WoE calculation dominated by spurious correlations

First experiments:
1. Test concept extraction on known diagnostic patterns to verify medical relevance
2. Compare WoE-based predictions against ground truth diagnoses
3. Evaluate user comprehension of explanations through expert feedback

## Open Questions the Paper Calls Out
The authors acknowledge the limitation of using predefined concepts and hyperparameters, but the impact of these choices on explanation quality and decision-making accuracy is not fully explored. The paper also lacks discussion of potential biases in the concept extraction process and how they might affect diagnostic outcomes.

## Limitations
- Evaluation limited to single dataset (HAM10000) and specific skin cancer diagnoses
- No statistical significance testing provided for performance comparisons
- Practical utility remains unproven pending expert validation studies

## Confidence

High confidence in the technical implementation and methodology
Medium confidence in the performance claims due to lack of statistical significance testing
Low confidence in the practical utility claims pending expert validation studies

## Next Checks

1. Conduct statistical significance testing between CNN baseline and WoE-based approaches across multiple runs
2. Perform comprehensive user studies with dermatologists to evaluate diagnostic accuracy and user experience
3. Test the tool's performance on additional medical imaging datasets beyond skin cancer diagnosis to assess generalizability