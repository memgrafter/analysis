---
ver: rpa2
title: Vector Quantization Prompting for Continual Learning
arxiv_id: '2410.20444'
source_url: https://arxiv.org/abs/2410.20444
tags:
- learning
- prompt
- task
- continual
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in class-incremental
  learning by introducing VQ-Prompt, a method that incorporates vector quantization
  into prompt-based learning. The core idea is to generate discrete prompts from a
  continuous version using nearest-neighbor lookup in a prompt pool, enabling end-to-end
  training with task loss.
---

# Vector Quantization Prompting for Continual Learning

## Quick Facts
- arXiv ID: 2410.20444
- Source URL: https://arxiv.org/abs/2410.20444
- Reference count: 40
- Primary result: VQ-Prompt achieves FAA scores of 79.23 (ImageNet-R), 88.73 (Split CIFAR-100), and 86.72 (Split CUB-200) in class-incremental learning

## Executive Summary
This paper introduces VQ-Prompt, a method that addresses catastrophic forgetting in class-incremental learning by integrating vector quantization with prompt-based learning. The approach generates discrete prompts from continuous versions using nearest-neighbor lookup in a prompt pool, enabling end-to-end training with task loss through gradient estimation and vector quantization regularization. VQ-Prompt demonstrates state-of-the-art performance across multiple benchmark datasets while showing robustness to different pre-training regimes.

## Method Summary
VQ-Prompt tackles catastrophic forgetting by generating discrete prompts from continuous prompt embeddings through vector quantization. The method maintains a prompt pool and uses nearest-neighbor lookup to select discrete prompts during training. Gradient estimation techniques enable end-to-end training with task loss, while vector quantization regularization helps preserve learned knowledge. The approach is designed to work with pre-trained vision transformers and can be applied to various class-incremental learning scenarios without requiring task-specific architectural modifications.

## Key Results
- Achieves FAA score of 79.23 on ImageNet-R benchmark
- Achieves FAA score of 88.73 on Split CIFAR-100 benchmark
- Achieves FAA score of 86.72 on Split CUB-200 benchmark
- Demonstrates robustness across different pre-training regimes

## Why This Works (Mechanism)
VQ-Prompt addresses catastrophic forgetting by maintaining discrete prompt representations that can be efficiently updated and retrieved during continual learning. The vector quantization process creates a compressed representation of task-specific knowledge that can be preserved while learning new tasks. By using gradient estimation techniques, the method enables end-to-end training while maintaining the discrete nature of the prompts, which helps prevent interference between tasks and preserves previously learned knowledge.

## Foundational Learning
- Catastrophic forgetting: The tendency of neural networks to forget previously learned tasks when trained on new ones. Needed to understand the problem being solved. Quick check: Can the model maintain performance on earlier tasks while learning new ones.
- Vector quantization: The process of mapping continuous vectors to discrete representations. Needed for efficient prompt storage and retrieval. Quick check: Are the quantized prompts sufficiently representative of the original continuous embeddings.
- Gradient estimation: Techniques for approximating gradients through discrete operations. Needed to enable end-to-end training with discrete prompts. Quick check: Do the estimated gradients lead to stable and effective learning.
- Class-incremental learning: The scenario where classes are introduced sequentially and the model must learn to recognize all classes seen so far. Needed to frame the evaluation context. Quick check: Can the model correctly classify both old and new classes after training on new tasks.

## Architecture Onboarding
- Component map: Pre-trained ViT -> Prompt generator -> Vector quantization -> Prompt pool -> Nearest-neighbor lookup -> Task-specific head
- Critical path: Input image → Pre-trained backbone → Prompt generation → Vector quantization → Prompt selection → Classification head → Output
- Design tradeoffs: Discrete prompts vs. continuous prompts (memory efficiency vs. flexibility), end-to-end training vs. separate optimization phases
- Failure signatures: Performance degradation on previous tasks indicates catastrophic forgetting, high quantization error suggests poor prompt representation
- First experiments: 1) Evaluate performance on single-task learning to establish baseline, 2) Test on two-task sequence to verify basic continual learning capability, 3) Scale to full benchmark to assess scalability

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability to larger-scale datasets beyond evaluated benchmarks remains uncertain
- Memory efficiency concerns as the number of tasks increases due to prompt pool requirements
- Computational overhead from gradient estimation and vector quantization regularization not thoroughly characterized

## Confidence
- High confidence in core methodology and benchmark performance claims
- Medium confidence in scalability and practical deployment implications
- Medium confidence in robustness across pre-training regimes

## Next Checks
1. Evaluate VQ-Prompt on larger-scale datasets (e.g., ImageNet-1K) and under long task sequences to assess scalability and performance stability
2. Conduct ablation studies to quantify the impact of prompt initialization strategies and the size of the prompt pool on final performance
3. Measure and report the computational overhead introduced by VQ-Prompt during training and inference, comparing it to baseline methods