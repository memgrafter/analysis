---
ver: rpa2
title: Reasoning about unpredicted change and explicit time
arxiv_id: '2407.06622'
source_url: https://arxiv.org/abs/2407.06622
tags:
- change
- time
- minimal
- explanation
- uents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a framework for detecting and explaining unpredicted
  changes in time-stamped observations using "surprises" (changes in fluent truth
  values). The approach provides minimal sets of surprises with time intervals, characterized
  through model-based diagnosis.
---

# Reasoning about unpredicted change and explicit time

## Quick Facts
- arXiv ID: 2407.06622
- Source URL: https://arxiv.org/abs/2407.06622
- Authors: Florence Dupin de Saint-Cyr; Jérôme Lang
- Reference count: 16
- Primary result: A framework for detecting and explaining unpredicted changes using "surprises" with time intervals, providing minimal explanations characterized through model-based diagnosis and ranked probabilistically based on persistence tendencies.

## Executive Summary
This paper introduces a temporal reasoning framework that detects and explains unpredicted changes in time-stamped observations by representing them as "surprises" - changes in fluent truth values with associated time intervals. The approach computes minimal sets of surprises that explain observations by finding maximal consistent subsets of persistence assumptions, leveraging model-based diagnosis techniques. A probabilistic method ranks these explanations based on fluent persistence tendencies and time intervals, with the key insight that when change probabilities are small, only minimal explanations have significant probability, making the representation concise and efficient.

## Method Summary
The framework operates by first identifying relevant variables and time points from observations, then generating persistence axioms between consecutive observations for each variable. Minimal explanations are computed by finding maximal subsets of persistence axioms consistent with observations, using model-based diagnosis techniques that treat unexpected changes as "faults." The probabilistic ranking calculates posterior probabilities of explanations based on fluent persistence tendencies and time intervals, assuming Markovian fluents where independence simplifies computation. The method handles pure prediction and postdiction cases without requiring prior probabilities for observed fluents.

## Key Results
- Minimal explanations for unpredicted changes are computed by finding maximal consistent subsets of persistence axioms
- Probabilistic ranking accounts for both fluent persistence tendencies and time intervals between observations
- When change probabilities are small, only minimal explanations have significant probability, making representation concise
- The framework extends previous approaches by incorporating explicit temporal intervals and connects to model-based diagnosis and belief update frameworks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework detects unpredicted changes by representing them as "surprises" (fluent truth value changes) with associated time intervals, which enables concise representation of minimal explanations.
- Mechanism: Each unpredicted change is modeled as a surprise event ⟨f, t, t'⟩ where f is the fluent, t is the earliest possible time, and t' is the latest possible time. The framework computes minimal sets of such surprises that explain observations by finding maximal consistent subsets of persistence assumptions.
- Core assumption: All observations are correct (K in Sandewall's taxonomy) and fluents generally persist over time (inertia assumption).
- Evidence anchors:
  - [abstract]: "This paper proposes a framework for detecting and explaining unpredicted changes in time-stamped observations using 'surprises' (changes in fluent truth values)."
  - [section 2.2]: "A framework for dealing with surprises is defined. Minimal sets of surprises are provided together with time intervals where each surprise has occurred, and they are characterized from a model-based diagnosis point of view."
- Break condition: If observations are incorrect or if fluents change frequently (violating inertia), the surprise representation becomes less meaningful and the minimal explanations may not be accurate.

### Mechanism 2
- Claim: The probabilistic ranking of explanations accounts for both fluent persistence tendencies and time intervals, making longer intervals between observations increase the likelihood of change.
- Mechanism: For highly persistent fluents, the probability of a surprise is approximated as P(⟨f, t, t'⟩) ≈ (t' - t)εf·pf where εf is the change probability and pf is the prior probability. This creates a natural weighting where longer intervals increase change likelihood.
- Core assumption: Probabilities of change are small within the considered time period ((t - t')εf ≪ 1), making non-minimal explanations negligible.
- Evidence anchors:
  - [abstract]: "The probabilistic method ranks explanations based on fluent persistence tendencies and time intervals."
  - [section 3.2]: "Proposition 9. Assume that all fluents are highly persistent w.r.t. [0, tmax], then: 1. P(⟨f, t, t'⟩) ≈ P([t]f ∧ [t']¬f) = (t' - t)εf·pf + o(εf)."
- Break condition: If change probabilities are not small or if fluents are not highly persistent, the approximation breaks down and non-minimal explanations may have significant probability.

### Mechanism 3
- Claim: The framework connects to model-based diagnosis by translating K-IS problems into system diagnosis problems where minimal explanations correspond to minimal fault configurations.
- Mechanism: The computation of minimal explanations is reduced to finding minimal sets of faulty components by identifying relevant time points for each variable and computing maximal consistent subsets of persistence axioms.
- Core assumption: The problem class K-IS (no actions, only observations and inertia) can be directly mapped to a diagnosis problem where "faults" are unexpected fluent changes.
- Evidence anchors:
  - [section 2.3]: "The method consists in completing the set of observations Σ by a set of persistence assumptions... Hence, the computation of minimal explanation can be done by well-known algorithms from these fields."
  - [section 2.3]: "This principle of finding minimal explanations corresponds exactly to finding minimal sets of faulty components in model-based diagnosis."
- Break condition: If the problem involves actions with complex effects or dependencies between fluents, the direct mapping to diagnosis problems breaks down.

## Foundational Learning

- Concept: Temporal reasoning with explicit time intervals
  - Why needed here: The framework requires precise handling of when changes could have occurred, not just that they did occur. Time intervals provide the granularity needed for both detection and probabilistic ranking.
  - Quick check question: Given observations at t=0 and t=10, what time interval should be considered for a surprise if a fluent changes?

- Concept: Model-based diagnosis principles
  - Why needed here: The minimal explanation computation directly leverages diagnosis algorithms, treating unexpected fluent changes as "faults" in a temporal system.
  - Quick check question: How does the persistence axiom approach relate to the "normal behavior" assumptions in traditional model-based diagnosis?

- Concept: Probabilistic reasoning with Markovian assumptions
  - Why needed here: The ranking mechanism requires computing probabilities of explanations based on change tendencies and time intervals, which relies on Markovian independence assumptions.
  - Quick check question: Why does the independence assumption between fluents simplify the probability computation of explanations?

## Architecture Onboarding

- Component map:
  Observation parser -> Relevant time point identifier -> Persistence axiom generator -> Consistency checker -> Minimal explanation finder -> Probability calculator -> Interval compressor

- Critical path:
  Observation → Relevant time points → Persistence axioms → Consistency check → Minimal explanations → Probability ranking → Final output

- Design tradeoffs:
  - Time precision vs. computational complexity: Finer time granularity increases accuracy but computational cost
  - Markovian assumption vs. real-world dependencies: Simplifies probability computation but may miss important dependencies
  - Interval representation vs. point representation: Intervals are more compact but require interval-specific reasoning

- Failure signatures:
  - Inconsistent observations with persistence assumptions indicate missing surprises
  - Multiple minimal explanations with similar probabilities suggest ambiguous situations
  - High probability of non-minimal explanations indicates violation of small change probability assumption

- First 3 experiments:
  1. Implement the basic framework with simple two-fluent examples to verify surprise detection and minimal explanation computation
  2. Add probability ranking with mock persistence data to test the ranking mechanism
  3. Test the interval handling by creating scenarios where the exact change time is ambiguous

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the framework handle cases where probabilities of change are not small across the considered interval?
- Basis in paper: [explicit] The paper states "Computing probabilities of change over an interval... requires computing the probability that an odd number of pointwise surprises occurred between t and t′" and notes this is left outside the scope when probabilities are not small
- Why unresolved: The paper focuses on "highly persistent" fluents where change probabilities are very small, making non-minimal explanations negligible. The general case with larger change probabilities remains computationally challenging.
- What evidence would resolve it: A computational method that efficiently calculates explanation probabilities when change probabilities are not small, demonstrating whether minimal explanations still dominate or if multiple explanations become relevant.

### Open Question 2
- Question: How can the framework be extended to handle dependent fluents (speciality D in Sandewall's ontology)?
- Basis in paper: [explicit] The authors state "Further work will include the handling of dependent fluents... in the probabilistic case they may for instance be structured in a Bayesian network"
- Why unresolved: The current framework assumes fluents are mutually independent, which is a significant limitation for real-world applications where fluents often have dependencies.
- What evidence would resolve it: An extension of the framework that incorporates fluents with dependencies, showing how the minimal explanation computation and probability calculations would work with dependent variables structured in a Bayesian network.

### Open Question 3
- Question: How can the surprise minimization approach be integrated with action handling (speciality A in Sandewall's ontology)?
- Basis in paper: [explicit] The authors mention "the integration of surprise minimisation together with a handling of actions with alternative effects" as future work
- Why unresolved: The current framework treats the agent as passive and does not consider actions with deterministic or probabilistic effects, limiting its applicability to interactive scenarios.
- What evidence would resolve it: A unified framework that combines surprise minimization with action effects, demonstrating how the system would distinguish between changes caused by actions versus unpredicted changes.

## Limitations

- The framework heavily relies on fluents being highly persistent and change probabilities being small, which may not hold in domains with frequent state changes
- Computational complexity can grow exponentially with the number of fluents and observations, though no complexity analysis is provided
- The current framework assumes fluents are mutually independent, limiting applicability to real-world scenarios where fluents often have dependencies

## Confidence

- **High Confidence**: The basic mechanism for detecting surprises and computing minimal explanations through model-based diagnosis principles (Mechanism 1 and 3). These are well-grounded in established temporal reasoning and diagnosis literature.
- **Medium Confidence**: The probabilistic ranking approach (Mechanism 2) works well under stated assumptions about small change probabilities and high persistence, but the confidence decreases when these assumptions are only partially met.
- **Medium Confidence**: The connection to belief update frameworks is conceptually sound but would require additional validation to confirm practical equivalence in all cases.

## Next Checks

1. Test the framework with synthetic data where change probabilities are deliberately set to violate the small-change assumption to quantify how badly the approximation breaks down.
2. Implement a complexity benchmark comparing the minimal explanation computation time against different model-based diagnosis algorithms to identify scalability limits.
3. Validate the probabilistic ranking on real-world temporal data with known change patterns to assess whether the Markovian assumption provides sufficient accuracy or if dependency modeling is necessary.