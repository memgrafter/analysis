---
ver: rpa2
title: 'ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio'
arxiv_id: '2408.00674'
source_url: https://arxiv.org/abs/2408.00674
tags:
- chord
- audio
- alignment
- music
- annotations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ChordSync is a conformer-based model that aligns chord annotations
  to audio without requiring preliminary weak alignment. It uses an acoustic model
  to estimate frame-wise chord probabilities, followed by a CTC forced-alignment decoder
  to align chords to the audio.
---

# ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio

## Quick Facts
- arXiv ID: 2408.00674
- Source URL: https://arxiv.org/abs/2408.00674
- Reference count: 0
- Primary result: Conformer-based model achieving F1 scores of 0.86 for chord boundary detection in pop/rock, significantly outperforming HCDF methods

## Executive Summary
ChordSync introduces a conformer-based model for aligning chord annotations to music audio without requiring weak alignment data. The model first estimates frame-wise chord probabilities using a conformer acoustic model, then applies CTC forced-alignment to synchronize chord labels with the audio. This approach eliminates the need for pre-aligned training data while achieving state-of-the-art performance on chord boundary detection tasks. The system is publicly available with pre-trained weights and a user-friendly library.

## Method Summary
ChordSync employs a two-stage approach: first, a conformer encoder processes audio CQT features to produce frame-level chord probabilities; second, a CTC decoder performs forced alignment between these probabilities and the provided chord annotation sequence. The conformer architecture combines self-attention and convolution to capture both local spectral patterns and global harmonic context. Training uses cross-entropy loss with AdamW optimizer and cosine annealed warm restart scheduling, while SpecAugment is applied for data augmentation.

## Key Results
- Achieves F1 score of 0.86 for chord boundary detection in pop/rock music
- Outperforms Harmonic Change Detection methods (F1 0.86 vs 0.53)
- Performs comparably to DTW-based alignment on Schubert Winterreise dataset (0.82 vs 0.86 correct alignments)
- Works without requiring weak alignment data during training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChordSync can align chord annotations to audio without requiring weak alignment data by using a conformer-based acoustic model to estimate frame-wise chord probabilities.
- Mechanism: The model first processes the audio signal to produce frame-level chord probabilities using a conformer architecture, then uses a CTC forced-alignment decoder to align these probabilities to the provided list of chord labels, bypassing the need for pre-aligned data.
- Core assumption: The conformer architecture can effectively learn to map audio features to chord labels directly, without needing temporal alignment in the training data.
- Evidence anchors:
  - [abstract] states that ChordSync "align chord annotations with audio without requiring any preliminary weak alignment"
  - [section 3.1] describes the problem setup and training approach: "we train an acoustic model to optimise the following equation: Z* = argmax p(Z|X)"
  - [corpus] shows related work on conformer-based models for music tasks, indicating this architecture is viable for audio-to-symbolic alignment

### Mechanism 2
- Claim: The forced-alignment decoder using CTC can handle temporal misalignment between predicted frame-wise probabilities and target chord sequences.
- Mechanism: The CTC decoder computes the probability of all possible alignments that produce the target chord sequence given the input features, allowing it to find the optimal alignment path even when the acoustic model's predictions are not perfectly temporally aligned.
- Core assumption: CTC's ability to handle temporal misalignment between predictions and targets generalizes to the chord alignment task.
- Evidence anchors:
  - [section 3.4] describes the CTC objective function used for alignment: "We utilise the Connectionist Temporal Classification (CTC) objective function [28], which computes the probability of a given alignment between the input features and output labels"
  - [section 3.1] explains the alignment process: "the decoder generates the aligned chord labels with respect to the audio signal"
  - [corpus] shows CTC is used in similar alignment tasks like lyrics-to-audio alignment

### Mechanism 3
- Claim: Using a conformer architecture with convolution-augmented transformers effectively models both local and global audio dependencies needed for chord recognition and alignment.
- Mechanism: The conformer combines self-attention for global context with convolution for local feature extraction, enabling it to capture both the temporal structure of chords and their harmonic relationships within the audio signal.
- Core assumption: The conformer's hybrid architecture is well-suited to the chord recognition task's requirements for modeling both local spectral patterns and global harmonic context.
- Evidence anchors:
  - [section 3.3] describes the conformer architecture used: "The conformer architecture [11] has recently emerged in ASR as a novel architecture to effectively model global and local audio dependencies"
  - [section 3.3] notes the choice of medium conformer size: "we opt for the M architecture, which comprises a 16 encoder layer with a dimension of 256"
  - [corpus] shows conformer-based approaches have succeeded in other music tasks like melodic transcription and representation learning

## Foundational Learning

- Concept: Audio feature extraction and representation (CQT, chroma features)
  - Why needed here: The model relies on CQT features as input to the conformer encoder, and understanding these representations is crucial for preprocessing and feature engineering.
  - Quick check question: What is the frequency resolution of the CQT used in ChordSync, and how does it affect chord recognition performance?

- Concept: Sequence-to-sequence modeling with attention mechanisms
  - Why needed here: The conformer architecture and CTC alignment both rely on attention mechanisms to model relationships between audio frames and chord labels.
  - Quick check question: How does the multi-head self-attention in the conformer help capture chord transitions and harmonic relationships?

- Concept: Connectionist Temporal Classification (CTC) loss and alignment
  - Why needed here: The forced-alignment decoder uses CTC to compute alignment probabilities without requiring pre-aligned training data.
  - Quick check question: How does CTC handle the temporal misalignment between predicted frame probabilities and target chord sequences during alignment?

## Architecture Onboarding

- Component map: Audio → CQT preprocessing → Conformer encoding → Frame-wise chord probabilities → CTC alignment → Aligned chord labels
- Critical path: Audio → CQT preprocessing → Conformer encoding → Frame-wise chord probabilities → CTC alignment → Aligned chord labels
- Design tradeoffs:
  - CQT vs other audio features: CQT chosen for its logarithmic frequency scale matching musical pitch perception
  - Conformer size: Medium (M) architecture chosen for balance of performance and computational efficiency
  - Vocabulary size: Simplified chord vocabulary used to manage model complexity, at cost of some expressiveness
- Failure signatures:
  - Poor chord boundary detection: Likely issues with conformer training or CTC alignment parameters
  - Inaccurate chord labels: May indicate problems with vocabulary design or model architecture
  - Slow inference: Could be due to inefficient conformer implementation or excessive CTC computation
- First 3 experiments:
  1. Train the conformer model on a small subset of data with a simplified chord vocabulary, evaluate frame-wise chord recognition accuracy
  2. Implement CTC alignment on predicted frame probabilities, evaluate alignment accuracy on a small test set
  3. Test the full pipeline on a few tracks with known chord annotations, compare predicted alignments to ground truth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ChordSync perform when aligning chord annotations to music from genres not well-represented in the training data (e.g., electronic, metal, hip hop, reggae)?
- Basis in paper: [explicit] The paper states that performance decreases in less represented genres like jazz and classical, and notes that the proposed model achieves results without relying on weak-aligned data, which is a requirement for DTW-based approaches.
- Why unresolved: The paper only provides performance metrics for pop/rock, classical, and jazz genres. It does not provide specific performance metrics for genres like electronic, metal, hip hop, and reggae, which are mentioned as being present in crowd-sourced chord annotation repositories.
- What evidence would resolve it: Experimental results showing ChordSync's performance on audio tracks from these underrepresented genres, with metrics such as precision, recall, and F1 score for chord boundary detection and alignment accuracy.

### Open Question 2
- Question: Can ChordSync be adapted to handle key differences between the chord labels and the audio signal?
- Basis in paper: [inferred] The paper mentions that the primary limitation of the proposed approach stems from its reliance on an acoustic model trained using a simplified vocabulary of chord labels. It also suggests that investigating alternative chord encoding could make the model key-agnostic.
- Why unresolved: The current model is not specifically designed to handle discrepancies in key between the chord labels and the audio signal. The paper only suggests that alternative chord encoding might yield better performance and make the model key-agnostic, but does not provide any experimental results or implementation details.
- What evidence would resolve it: Experimental results comparing ChordSync's performance with and without key-agnostic adaptations, using audio tracks with varying keys and corresponding chord annotations.

### Open Question 3
- Question: How does ChordSync's performance compare to other state-of-the-art audio-to-score alignment methods, such as those based on differentiable DTW or neural network architectures?
- Basis in paper: [explicit] The paper mentions that a differentiable variant of DTW, SoftDTW, has been used as the loss function within neural network architectures, mainly for multi-pitch estimation tasks. It also mentions that other deep-learning methods have been investigated for audio-to-score alignment, including leveraging automatic transcription techniques and training audio features tailored explicitly for alignment tasks.
- Why unresolved: The paper only compares ChordSync to Harmonic Change Detection (HCDF) methods and a traditional DTW-based approach. It does not provide any comparison to other state-of-the-art audio-to-score alignment methods, such as those based on differentiable DTW or neural network architectures.
- What evidence would resolve it: Experimental results comparing ChordSync's performance to other state-of-the-art audio-to-score alignment methods, using the same evaluation metrics and datasets.

## Limitations
- Performance decreases for genres not well-represented in training data (jazz, classical)
- Simplified chord vocabulary may limit expressiveness for complex harmonies
- No analysis of computational efficiency or real-time performance constraints

## Confidence
- Medium: Claims about conformer architecture effectively modeling audio-to-chord relationships
- Medium: Claims about CTC alignment handling temporal misalignment
- High: Claims about improved boundary detection compared to HCDF methods
- Medium: Claims about comparable performance to DTW without requiring pre-aligned data

## Next Checks
1. Conduct ablation study comparing conformer vs. traditional CNN architectures for the acoustic model component
2. Test performance on non-Western music genres with different harmonic structures
3. Measure inference time and memory usage to assess practical deployment constraints