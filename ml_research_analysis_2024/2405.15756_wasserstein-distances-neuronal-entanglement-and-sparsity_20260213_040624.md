---
ver: rpa2
title: Wasserstein Distances, Neuronal Entanglement, and Sparsity
arxiv_id: '2405.15756'
source_url: https://arxiv.org/abs/2405.15756
tags:
- neurons
- sparse
- neuron
- expansion
- wasserstein
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work identifies a new class of highly entangled "Wasserstein
  neurons" in LLMs characterized by highly non-Gaussian output distributions. The
  authors introduce the Wasserstein distance to a Gaussian as a novel metric for quantifying
  neuronal entanglement and show that these neurons are critical for model performance
  under sparsity.
---

# Wasserstein Distances, Neuronal Entanglement, and Sparsity

## Quick Facts
- arXiv ID: 2405.15756
- Source URL: https://arxiv.org/abs/2405.15756
- Reference count: 40
- New metric for quantifying neuronal entanglement via Wasserstein distance to Gaussian

## Executive Summary
This paper introduces a novel approach to understanding and addressing neuronal entanglement in large language models through the lens of Wasserstein distance. The authors identify a class of "Wasserstein neurons" characterized by highly non-Gaussian output distributions that are critical for model performance under sparsity. They develop Sparse Expansion, an input-aware pruning framework that disentangles these entangled neurons by creating specialized experts for different input clusters. Empirical results demonstrate that Sparse Expansion outperforms state-of-the-art one-shot pruning methods, particularly for entangled neurons that are most sensitive to compression.

## Method Summary
The authors analyze neuron output distributions in pre-trained LLMs to identify entangled neurons using Wasserstein distance to Gaussian distributions. They develop Sparse Expansion, which clusters inputs layer-wise and creates sparse experts using SparseGPT for each cluster. During inference, inputs are routed to appropriate experts based on PCA-reduced representations and K-means clustering. The method aims to preserve the complex output distributions of entangled neurons while enabling extreme sparsity through input-specific specialization.

## Key Results
- Wasserstein distance effectively identifies entangled neurons that are more sensitive to pruning
- Sparse Expansion recovers performance lost when compressing entangled neurons
- Entangled neurons are crucial for reasoning and mathematical tasks
- Performance degrades significantly when entangled neurons are pruned

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Wasserstein distance from a Gaussian is a strong metric for quantifying neuronal entanglement.
- **Mechanism:** Neurons with highly non-Gaussian output distributions are "Wasserstein neurons" that are crucial for model performance under sparsity. The Wasserstein distance captures how different a neuron's output distribution is from Gaussian, with higher distances indicating greater entanglement.
- **Core assumption:** Non-Gaussian output distributions correlate with the neuron's ability to map similar inputs to dissimilar outputs (mapping difficulty).
- **Evidence anchors:**
  - [abstract] "We suggest a novel measure for estimating neuronal entanglement: the Wasserstein distance of a neuron's output distribution to a Gaussian."
  - [section 2.2] "We introduce the metric 'mapping difficulty' (MD)... A greater MD means that a neuron generally increases the separation of similar inputs into more dissimilar outputs."
  - [corpus] Weak - corpus neighbors focus on polysemanticity and Wasserstein distances in general, but not specifically on neuronal output distributions.
- **Break condition:** If mapping difficulty and Wasserstein distance are not correlated, the metric would lose its validity as an entanglement measure.

### Mechanism 2
- **Claim:** Sparse Expansion disentangles polysemantic neurons by creating input-specific experts.
- **Mechanism:** Sparse Expansion clusters inputs layer-wise and creates sparse experts for each cluster. Each expert specializes to a subset of inputs, effectively disentangling the input-output relationship of individual neurons, particularly the difficult Wasserstein neurons.
- **Core assumption:** Input-aware sparsity can improve performance by allocating different sparse experts to different input distributions.
- **Evidence anchors:**
  - [abstract] "Our framework separates each layer's inputs to create a mixture of experts where each neuron's output is computed by a mixture of neurons of lower Wasserstein distance, each better at maintaining accuracy when sparsified without retraining."
  - [section 3.2] "Through Sparse Expansion, the original output distribution can be better preserved under sparse computation... Sparse Expansion is able to recover significant performance following Wasserstein neuron sparsification."
  - [corpus] Weak - corpus neighbors don't discuss input-aware sparsity or mixture-of-experts approaches.
- **Break condition:** If the routing overhead exceeds the performance gains, or if input clustering fails to capture the relevant input distributions.

### Mechanism 3
- **Claim:** Entangled neurons are more sensitive to pruning because their complex output distributions are harder to model with fewer weights.
- **Mechanism:** As neurons lose edges through pruning, their output distributions tend toward Gaussian. Entangled neurons with irregular shapes are more challenging to model with fewer weights than Gaussian-like distributions, making them more sensitive to pruning.
- **Core assumption:** The complexity of a neuron's output distribution correlates with its sensitivity to weight pruning.
- **Evidence anchors:**
  - [section 2.3] "Wasserstein neurons are crucial for maintaining accuracy and are severely limited in their ability to be compressed."
  - [section 3.2] "As a neuron lose edges, its output distribution tends to shift toward a Gaussian distribution... This in turn places even more stress upon the neuron."
  - [corpus] Weak - corpus neighbors don't discuss the relationship between output distribution complexity and pruning sensitivity.
- **Break condition:** If pruning other neurons (e.g., those with high weight magnitude) causes more performance degradation than pruning entangled neurons.

## Foundational Learning

- **Concept:** Wasserstein distance (optimal transport)
  - Why needed here: It's the core metric for quantifying how different a neuron's output distribution is from Gaussian, which measures entanglement.
  - Quick check question: How does Wasserstein distance differ from other distribution similarity metrics like KL divergence?

- **Concept:** Polysemanticity in neural networks
  - Why needed here: The paper's main focus is on neurons that respond to multiple unrelated features, and how this affects sparsity.
  - Quick check question: What makes a neuron polysemantic versus monosemantic?

- **Concept:** SparseGPT and input-aware pruning
  - Why needed here: Sparse Expansion builds upon SparseGPT's input-aware pruning approach to create specialized experts.
  - Quick check question: How does SparseGPT use the Hessian matrix to determine which weights to prune?

## Architecture Onboarding

- **Component map:**
  PCA -> K-means clustering -> SparseGPT experts -> Input routing -> Sparse matrix multiplication

- **Critical path:**
  1. Run PCA on calibration inputs to reduce dimensionality
  2. Apply K-means clustering to group inputs
  3. For each cluster, run SparseGPT to create a sparse expert
  4. During inference, apply PCA and K-means to route each input to its expert
  5. Perform sparse matrix multiplication with the appropriate expert

- **Design tradeoffs:**
  - More clusters → better specialization but higher memory and routing overhead
  - Clustering granularity → too coarse loses benefits, too fine increases complexity
  - Starting from dense vs. MoE model → allows studying individual neuron behavior

- **Failure signatures:**
  - Performance plateaus despite increasing clusters → indicates routing or clustering issues
  - Certain neurons consistently have high weighted WD after expansion → clustering not effective for those inputs
  - Routing overhead exceeds computational savings → needs optimization

- **First 3 experiments:**
  1. Apply Sparse Expansion with 2 clusters to a single FFN layer and measure output distribution WD before/after
  2. Compare performance of Sparse Expansion vs. SparseGPT on a small dataset with 4 clusters
  3. Vary the number of PCA components and observe impact on clustering quality and performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do Wasserstein neurons form during training, and what specific mechanisms in the learning dynamics lead to their emergence?
- Basis in paper: [explicit] The paper notes that Wasserstein neurons arise within 10-20 billion tokens of training but observes that they do not receive more weight updates than other neurons, leaving the formation mechanism unclear.
- Why unresolved: The paper identifies the timing of emergence but does not explain the underlying training dynamics or feature interactions that create these neurons.
- What evidence would resolve it: Detailed analysis of gradient patterns, feature orthogonality changes, and neuron activation statistics during the critical early training period when Wasserstein neurons form.

### Open Question 2
- Question: What circuit-level functions do Wasserstein neurons implement, and how do they contribute to specific model capabilities beyond general reasoning and mathematical tasks?
- Basis in paper: [explicit] The paper demonstrates that sparsifying Wasserstein neurons degrades performance on complex reasoning tasks but does not investigate their mechanistic role in specific computational circuits.
- Why unresolved: While the paper shows these neurons are important, it does not trace their connections or determine what specific computational roles they play in the network's architecture.
- What evidence would resolve it: Mechanistic interpretability studies tracing the activation patterns, downstream effects, and circuit contributions of Wasserstein neurons across different tasks and layers.

### Open Question 3
- Question: Can we develop a pruning algorithm that explicitly accounts for neuronal entanglement measured by Wasserstein distance to improve sparsity beyond current methods?
- Basis in paper: [inferred] The paper shows that current sparsification methods like SparseGPT slightly over-prune Wasserstein neurons despite their importance, and suggests future algorithms should consider entanglement.
- Why unresolved: While the paper identifies the problem of entanglement-sensitivity in pruning, it does not propose or test a specific algorithm that incorporates Wasserstein distance into the pruning objective.
- What evidence would resolve it: Comparative evaluation of pruning algorithms that weight neurons by their Wasserstein distance against standard methods across multiple sparsity levels and model architectures.

## Limitations

- The paper's theoretical framework connecting Wasserstein distance to "mapping difficulty" lacks direct empirical validation
- Sparse Expansion's routing overhead and scalability to trillion-parameter models remain unproven
- The relationship between output distribution complexity and pruning sensitivity, while theoretically sound, needs more empirical testing

## Confidence

**High Confidence:** The empirical demonstration that entangled neurons (high Wasserstein distance) are more sensitive to pruning than other neurons. The paper clearly shows this through systematic ablation studies across multiple model sizes and sparsity levels.

**Medium Confidence:** The claim that Sparse Expansion outperforms existing one-shot pruning methods. While results are promising, the comparison is limited to a specific set of baselines and datasets. The routing overhead and practical deployment considerations are not fully explored.

**Low Confidence:** The theoretical framework connecting Wasserstein distance to "mapping difficulty" and the claim that this metric is superior to other measures of neuronal entanglement. The paper provides limited empirical validation of this specific theoretical claim.

## Next Checks

1. **Direct validation of mapping difficulty:** Design an experiment that explicitly measures how well neurons with high Wasserstein distance perform at separating similar inputs compared to neurons with low Wasserstein distance. This could involve creating controlled input pairs with known similarities and measuring output separation.

2. **Routing overhead analysis:** Implement a detailed analysis of the computational overhead introduced by Sparse Expansion's routing mechanism. Measure the break-even point where the benefits of input-specific experts are offset by routing costs, and identify conditions under which this approach remains beneficial.

3. **Alternative non-Gaussianity metrics:** Replace Wasserstein distance with other measures of non-Gaussianity (e.g., kurtosis, entropy) in the Sparse Expansion framework and compare performance. This would validate whether Wasserstein distance provides unique benefits or if simpler metrics could achieve similar results.