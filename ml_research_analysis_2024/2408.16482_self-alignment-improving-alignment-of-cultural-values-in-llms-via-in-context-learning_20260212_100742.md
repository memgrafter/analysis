---
ver: rpa2
title: 'Self-Alignment: Improving Alignment of Cultural Values in LLMs via In-Context
  Learning'
arxiv_id: '2408.16482'
source_url: https://arxiv.org/abs/2408.16482
tags:
- examples
- values
- alignment
- cultural
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to improve cultural value alignment
  in large language models (LLMs) using in-context learning (ICL) at inference time.
  The approach leverages demonstration examples based on the World Values Survey (WVS)
  to prompt LLMs toward culturally appropriate responses.
---

# Self-Alignment: Improving Alignment of Cultural Values in LLMs via In-Context Learning
## Quick Facts
- arXiv ID: 2408.16482
- Source URL: https://arxiv.org/abs/2408.16482
- Reference count: 24
- Method achieves 73% improvement in cultural value alignment for Llama3-8B on US-aligned English prompts

## Executive Summary
This paper introduces a method to improve cultural value alignment in large language models (LLMs) using in-context learning (ICL) at inference time. The approach leverages demonstration examples based on the World Values Survey (WVS) to prompt LLMs toward culturally appropriate responses. Four demonstration selection strategies were evaluated: fully random, random within category, and two using chrF++ similarity scores—within and across categories. Results show that chrF++ across categories most effectively improves alignment, achieving a 73% increase for Llama3-8B on English prompts aligned to US values. The method generalized across five models (Llama3-8B, Mistral, Gemini, CommandR, BLOOMz), with performance highest for Mistral. When tested in 12 multilingual settings, self-alignment consistently improved alignment across languages, with effectiveness varying by language and model. Qualitative analysis revealed that models often adjusted responses based on meaningful patterns in demonstrations, though some relied on spurious correlations.

## Method Summary
The proposed self-alignment method uses in-context learning at inference time to align LLM responses with target cultural values. The approach uses the World Values Survey (WVS) framework to define cultural value categories and employs four demonstration selection strategies: fully random selection, random within category, chrF++ similarity within categories, and chrF++ similarity across categories. At inference, prompts are paired with selected demonstration examples to guide the model toward culturally appropriate responses. The method was tested across five different LLM architectures (Llama3-8B, Mistral, Gemini, CommandR, BLOOMz) and evaluated in both English and multilingual settings.

## Key Results
- chrF++ across categories strategy achieved 73% improvement in alignment for Llama3-8B on US-aligned English prompts
- Method generalized across five models, with Mistral showing the highest effectiveness
- Self-alignment consistently improved alignment across 12 multilingual settings, though effectiveness varied by language and model
- Qualitative analysis showed models adjusted responses based on demonstration patterns, but some relied on spurious correlations

## Why This Works (Mechanism)
The method works by providing LLMs with culturally relevant demonstration examples at inference time, allowing them to learn appropriate response patterns through in-context learning. The chrF++ similarity metric helps select demonstrations that are semantically similar to the target response, making the alignment more effective than random selection.

## Foundational Learning
- **World Values Survey (WVS)**: Framework for categorizing cultural values - needed to define alignment targets; quick check: verify WVS categories match cultural dimensions of interest
- **In-Context Learning (ICL)**: Technique for adapting model behavior at inference time - needed to avoid retraining; quick check: test with varying numbers of demonstration examples
- **chrF++ similarity metric**: String matching metric for selecting relevant demonstrations - needed to improve demonstration quality; quick check: compare against other similarity metrics like BLEU or BERTScore

## Architecture Onboarding
**Component Map**: Prompt -> Demonstration Selection -> In-Context Learning -> Aligned Response
**Critical Path**: Prompt → Demonstration Selection (chrF++) → ICL with demonstrations → Output response
**Design Tradeoffs**: chrF++ across categories vs within categories - across categories showed better alignment but may be more computationally expensive
**Failure Signatures**: Models relying on spurious correlations in demonstrations rather than meaningful patterns; variable effectiveness across languages and models
**First Experiments**: 1) Test demonstration selection with different similarity thresholds, 2) Evaluate impact of demonstration quantity on alignment quality, 3) Compare chrF++ with alternative similarity metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on WVS framework may not capture full complexity of cultural values
- chrF++ similarity metric may not fully represent cultural nuance or context
- In-context learning introduces inference-time latency and computational overhead
- Effectiveness varies significantly across languages and models, suggesting limited universal applicability

## Confidence
- High confidence in chrF++ across categories effectiveness for English prompts with Llama3-8B
- Medium confidence in generalizability across five tested models
- Medium confidence in multilingual results due to considerable variation
- Low confidence in robustness to cultural nuances beyond WVS framework

## Next Checks
1. Test method on additional cultural frameworks beyond WVS to assess robustness to different value systems
2. Evaluate approach on larger language models (70B+ parameters) to determine if effectiveness scales with model size
3. Conduct user study with native speakers from target cultures to validate whether aligned responses genuinely reflect cultural values beyond chrF++ metric