---
ver: rpa2
title: Hierarchical Object-Oriented POMDP Planning for Object Rearrangement
arxiv_id: '2412.01348'
source_url: https://arxiv.org/abs/2412.01348
tags:
- object
- objects
- state
- rearrangement
- location
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a hierarchical planning framework, HOO-POMDP,
  for multi-object rearrangement in partially observable, multi-room environments.
  The approach combines a high-level POMDP planner with low-level policies to handle
  both exploration and manipulation under uncertainty.
---

# Hierarchical Object-Oriented POMDP Planning for Object Rearrangement

## Quick Facts
- arXiv ID: 2412.01348
- Source URL: https://arxiv.org/abs/2412.01348
- Authors: Rajesh Mangannavar; Alan Fern; Prasad Tadepalli
- Reference count: 40
- One-line primary result: HOO-POMDP framework outperforms baselines in multi-object rearrangement under partial observability

## Executive Summary
This paper introduces a hierarchical planning framework, HOO-POMDP, for multi-object rearrangement in partially observable, multi-room environments. The approach combines a high-level POMDP planner with low-level policies to handle both exploration and manipulation under uncertainty. A new benchmark, MultiRoomR, featuring complex rearrangement challenges, is introduced to evaluate the system. Experimental results demonstrate that the proposed method outperforms existing baselines in terms of success rate and task completion efficiency, even in the presence of imperfect perception and partial observability. The framework effectively handles blocked paths and other challenging scenarios, showcasing its robustness and adaptability.

## Method Summary
The HOO-POMDP framework employs a hierarchical planning approach that separates high-level strategic decision-making from low-level execution details. It uses an object-oriented POMDP planner to generate sub-goals in an abstract state space, which are then executed by specialized low-level policies (Move, Rotate, PickPlace). The system maintains belief distributions over object locations using an observation model that accounts for detection failures and false positives. A belief update system converts continuous world states into discrete abstract representations suitable for efficient POMDP planning. The framework is evaluated on the MultiRoomR benchmark, which includes 400 room configurations with varying degrees of partial observability, blocked paths, and object counts.

## Key Results
- HOO-POMDP achieves higher success scores than baselines (FHC, VRR, MSS) on MultiRoomR benchmark
- The framework maintains robust performance with imperfect perception (60% detection TP rate)
- HOO-POMDP effectively handles blocked paths and obstructed goal scenarios
- Hierarchical abstraction improves scalability compared to flat POMDP approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hierarchical abstraction reduces the effective planning space and improves scalability.
- Mechanism: The high-level planner operates on discrete abstract states and outputs sub-goals that map to specialized low-level policies, avoiding reasoning over continuous action spaces.
- Core assumption: The object independence assumption holds—object states and observations can be factored without considering inter-object interactions.
- Evidence anchors: [abstract] "This approach comprises of (a) an object-oriented POMDP planner generating sub-goals, (b) a set of low-level policies for sub-goal achievement, and (c) an abstraction system converting the continuous low-level world into a representation suitable for abstract planning."

### Mechanism 2
- Claim: The belief update system enables robust handling of perception uncertainty.
- Mechanism: After each action, the system updates belief probabilities over object locations using observation models that account for true/false positives and distance-based detection reliability.
- Core assumption: Detection performance statistics are stable across environments.
- Evidence anchors: [abstract] "maintaining robust performance even with imperfect perception"

### Mechanism 3
- Claim: The POUCT planner with action abstraction enables efficient exploration-exploitation trade-off under partial observability.
- Mechanism: POUCT builds a search tree over histories (action-observation sequences) rather than states, allowing it to handle uncertainty about object locations.
- Core assumption: The abstract action space is rich enough to represent all necessary sub-goals for task completion.
- Evidence anchors: [abstract] "object-oriented POMDP planner generating sub-goals"

## Foundational Learning

- Concept: Partially Observable Markov Decision Process (POMDP)
  - Why needed here: The rearrangement task involves hidden object locations and noisy perception, requiring reasoning over belief states rather than single states.
  - Quick check question: What is the belief update equation for a POMDP after taking action a and receiving observation z?

- Concept: Object-Oriented Belief Factorization
  - Why needed here: Allows independent belief updates for each object, reducing computational complexity from exponential to linear in the number of objects.
  - Quick check question: How does the observation model factor when assuming conditional independence of object observations?

- Concept: Hierarchical Planning with Action Abstraction
  - Why needed here: Separates strategic decision-making (when/where to search/rearrange) from execution details (navigation, grasping), enabling scalability to larger environments.
  - Quick check question: What are the three types of abstract actions defined in the HOO-POMDP, and what low-level policies do they trigger?

## Architecture Onboarding

- Component map: Perception System → Observation z → Belief Update → Abstract State → Abstract Planner → Sub-goal → Low-level Policy Executor → Environment
- Critical path: 1. Initialize belief and map from walkthrough 2. Execute low-level action → get RGB/depth → run detector 3. Update belief with observation model 4. Generate abstract state from belief 5. Run POUCT to select sub-goal 6. Execute corresponding low-level policy 7. Repeat until task complete
- Design tradeoffs:
  - Independence assumption vs. handling object interactions (simplifies belief update but fails in clutter)
  - Fixed TP/FP detection parameters vs. adaptive models (easier to implement but less robust to domain shift)
  - Discrete abstraction vs. continuous planning (scales better but may miss fine-grained solutions)
- Failure signatures:
  - Low scene success but decent object success → low-level policy failures (pick/place) or detector false positives
  - High action count with moderate success → inefficient exploration due to belief uncertainty
  - Complete failure on blocked path scenes → abstraction not generating necessary intermediate sub-goals
- First 3 experiments:
  1. Run ablation comparing HOOP vs HOOP-HP (no hierarchical abstraction) on MultiRoomR with 10 objects, 2 rooms, 0 blocked paths.
  2. Test belief update robustness by artificially reducing detector TP rate from 60% to 30% and measuring success drop.
  3. Evaluate POUCT search depth sensitivity by running with depths 1, 6, 12 on RoomR dataset and measuring success and action counts.

## Open Questions the Paper Calls Out
- How would the system perform in real-world scenarios with dynamic changes in the environment, such as objects being moved by external agents?
- Can the system be extended to handle objects with different physical properties, such as fragile or heavy objects, which may require different manipulation strategies?
- How does the system's performance scale with an increasing number of objects and rooms, and what are the computational limitations?

## Limitations
- The object independence assumption likely breaks in highly cluttered scenes where object positions are interdependent.
- Fixed detection model parameters (60% TP, 10% FP, distance decay) may not generalize across different environments or object categories.
- The action abstraction space could miss necessary intermediate steps in complex rearrangement scenarios.

## Confidence

- **High confidence**: The hierarchical architecture with separated high-level planning and low-level execution is sound and well-supported by the described mechanisms and experimental results.
- **Medium confidence**: The belief update system's effectiveness with imperfect perception is demonstrated but depends heavily on stable detector performance; performance may degrade significantly in different domains.
- **Low confidence**: The object independence assumption's robustness in extremely cluttered or tightly packed environments hasn't been thoroughly tested, and this could be a critical failure mode.

## Next Checks

1. Run HOO-POMDP on MultiRoomR scenes with 20 objects in 4 rooms (maximum complexity) to stress-test the object independence assumption and identify when it breaks.
2. Conduct domain adaptation experiments by training the detection model on one subset of object classes and evaluating on unseen classes to measure sensitivity to detector performance changes.
3. Perform ablation studies removing the hierarchical abstraction (using flat POMDP planning instead) on blocked path scenarios to quantify the value of the hierarchical approach in handling complex constraints.