---
ver: rpa2
title: 'OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and Omission
  Translation Errors Detection'
arxiv_id: '2406.01919'
source_url: https://arxiv.org/abs/2406.01919
tags:
- word
- alignment
- hallucination
- omission
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OTTAWA, an Optimal Transport-based word aligner
  designed to detect hallucination and omission errors in machine translation. The
  method explicitly models missing alignments by introducing a "null" vector, which
  is adaptively aligned using a novel one-side constrained optimal transport setting.
---

# OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and Omission Translation Errors Detection

## Quick Facts
- arXiv ID: 2406.01919
- Source URL: https://arxiv.org/abs/2406.01919
- Reference count: 27
- Key outcome: OTTAWA achieves competitive performance on HalOmi benchmark across 18 language pairs, outperforming existing methods in omission detection while maintaining balanced performance for both hallucination and omission errors

## Executive Summary
This paper introduces OTTAWA, an Optimal Transport-based word aligner designed to detect hallucination and omission errors in machine translation. The method explicitly models missing alignments by introducing a "null" vector, which is adaptively aligned using a novel one-side constrained optimal transport setting. Experiments on the HalOmi benchmark across 18 language pairs show that OTTAWA performs on par with state-of-the-art methods, achieving competitive results while also being able to distinguish between hallucination and omission errors at the word level.

## Method Summary
OTTAWA employs a novel optimal transport framework that introduces a "null" vector to explicitly model missing alignments between source and target sentences. The method uses a one-side constrained transport formulation where the null vector is adaptively aligned to detect both hallucination and omission errors. The approach leverages Wasserstein distance to measure the discrepancy between aligned words and the null vector, allowing for effective detection of translation errors at the word level.

## Key Results
- OTTAWA achieves competitive performance on the HalOmi benchmark across 18 language pairs
- The method outperforms existing approaches specifically in detecting omission errors
- OTTAWA successfully distinguishes between hallucination and omission errors at the word level

## Why This Works (Mechanism)
The method works by introducing a "null" vector that explicitly represents missing alignments in the optimal transport framework. This allows the model to detect both hallucination errors (where target words don't have source correspondences) and omission errors (where source words lack target correspondences). The one-side constrained transport setting enables adaptive alignment of the null vector, making the detection more robust to different types of translation errors.

## Foundational Learning
- Optimal Transport: Mathematical framework for measuring distances between probability distributions
  - Why needed: Provides a principled way to align words between source and target sentences
  - Quick check: Verify that transport cost matrix captures semantic similarity

- Wasserstein Distance: Metric for comparing probability distributions
  - Why needed: Measures the discrepancy between aligned words and null vector
  - Quick check: Confirm that distance calculation properly handles null vector alignments

- Null Vector Concept: Representation of missing alignments
  - Why needed: Explicitly models cases where words are hallucinated or omitted
  - Quick check: Ensure null vector properly captures unmatched words

## Architecture Onboarding

Component Map: Source Sentences -> Word Embeddings -> OTTAWA (Null Vector + Transport) -> Error Detection

Critical Path: Word embedding generation → Null vector integration → Optimal transport computation → Error classification

Design Tradeoffs: The introduction of null vector increases model expressiveness but adds computational overhead. The one-side constraint simplifies the optimization but may miss some complex alignment patterns.

Failure Signatures: Poor performance on highly idiomatic expressions, failure to detect subtle semantic shifts, computational bottlenecks with long sequences.

First 3 Experiments:
1. Baseline comparison without null vector on HalOmi benchmark
2. Ablation study removing one-side constraint
3. Performance evaluation across different sequence lengths

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity and scalability not thoroughly analyzed
- Ablation studies could be more comprehensive
- Evaluation framework's sensitivity to different translation quality levels not explored

## Confidence

High confidence in:
- Technical novelty of optimal transport formulation and null vector approach

Medium confidence in:
- Empirical performance claims due to limited computational complexity analysis
- Error type distinction capability based on available experimental evidence

## Next Checks

1. Conduct detailed runtime complexity analysis and scalability testing across different sequence lengths
2. Perform extensive ablation studies isolating contributions of null vector and one-side constraint components
3. Evaluate performance across diverse translation quality levels and domain-specific datasets to assess robustness