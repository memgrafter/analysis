---
ver: rpa2
title: 'II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual
  Question Answering'
arxiv_id: '2402.11058'
source_url: https://arxiv.org/abs/2402.11058
tags:
- reasoning
- ii-mmr
- answer
- question
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes II-MMR, a method to identify and improve multi-modal
  multi-hop reasoning in Visual Question Answering (VQA). The authors observe that
  conventional Chain-of-Thought (CoT) prompting fails to generate effective reasoning
  for VQA, especially for complex scenarios requiring multi-hop reasoning.
---

# II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering

## Quick Facts
- arXiv ID: 2402.11058
- Source URL: https://arxiv.org/abs/2402.11058
- Reference count: 15
- Primary result: II-MMR improves accuracy on A-OKVQA from 36.06% to 49.31% in zero-shot setting

## Executive Summary
II-MMR addresses the challenge of multi-modal multi-hop reasoning in Visual Question Answering by proposing two novel language prompting strategies: answer prediction-guided CoT and knowledge triplet-guided prompt. The method identifies that current VQA benchmarks predominantly feature single-hop reasoning questions, with only a few requiring multi-hop reasoning. II-MMR demonstrates effectiveness across all reasoning cases, particularly improving performance on complex multi-hop questions where traditional Chain-of-Thought prompting fails.

## Method Summary
The method employs two prompting strategies: (1) Answer Prediction-Guided CoT (APCoT) which uses predicted answers to guide the reasoning process, and (2) Knowledge Triplet-Guided Prompt (KTPrompt) which extracts and utilizes knowledge triplets to construct reasoning paths. The approach analyzes generated reasoning paths to categorize questions by hop count and reasoning type (visual vs. beyond-visual). This analysis reveals that most VQA questions require simple single-hop reasoning, while II-MMR specifically targets and improves performance on the more challenging multi-hop reasoning cases.

## Key Results
- Improves A-OKVQA accuracy from 36.06% to 49.31% in zero-shot setting
- Identifies that most VQA questions in current benchmarks require only single-hop reasoning
- Demonstrates effectiveness across all reasoning cases in both zero-shot and fine-tuning settings
- Shows traditional CoT prompting struggles with complex multi-hop reasoning questions

## Why This Works (Mechanism)
The method works by providing more structured and guided reasoning paths compared to traditional CoT prompting. By leveraging answer predictions and knowledge triplets, II-MMR creates more coherent and contextually relevant reasoning chains that better navigate the multi-modal nature of VQA tasks. The analysis of reasoning paths allows for targeted improvements based on the specific requirements of different question types.

## Foundational Learning
1. **Multi-modal reasoning** - Why needed: VQA requires combining visual and textual information; quick check: can the model effectively integrate both modalities
2. **Chain-of-Thought prompting** - Why needed: Provides step-by-step reasoning for complex tasks; quick check: does the reasoning path make logical sense
3. **Knowledge extraction** - Why needed: External knowledge is crucial for many VQA questions; quick check: are extracted triplets relevant and accurate
4. **Prompt engineering** - Why needed: Careful prompt design is essential for guiding LLM reasoning; quick check: do prompts consistently produce desired output format
5. **Reasoning path analysis** - Why needed: Understanding reasoning complexity helps improve model performance; quick check: can reasoning hops be accurately counted and categorized

## Architecture Onboarding

**Component Map**: Visual Input -> V&L Model (BLIP-2/LLaVA-1.5) -> LLM (Llama-2-70b) -> Prompt Generator -> Reasoning Path -> Answer Prediction

**Critical Path**: The critical path involves the interaction between the V&L model's visual understanding and the LLM's reasoning capabilities, mediated by the carefully designed prompts that guide the reasoning process.

**Design Tradeoffs**: The method trades computational complexity for improved reasoning accuracy, requiring multiple model inferences (V&L model, LLM for prompt generation, LLM for reasoning). The choice between APCoT and KTPrompt involves a tradeoff between using predicted answers versus extracted knowledge triplets.

**Failure Signatures**: The method may fail when: (1) the V&L model fails to extract relevant visual features, (2) the LLM cannot generate coherent reasoning paths even with guided prompts, or (3) the analysis of reasoning paths incorrectly categorizes question complexity.

**3 First Experiments**:
1. Test basic VQA question answering with each prompting strategy individually
2. Analyze reasoning paths for a sample of questions to verify hop counting and type categorization
3. Compare performance on single-hop vs multi-hop questions to validate targeted improvements

## Open Questions the Paper Calls Out
1. How does the quality of II-MMR's generated rationales compare to human-generated explanations in terms of correctness and reasoning steps?
2. What is the impact of using different V&L models (e.g., BLIP-2 vs. LLaVA-1.5) on the performance of II-MMR across various reasoning cases?
3. How does the performance of II-MMR vary when applied to VQA benchmarks with different characteristics?
4. What is the optimal strategy for augmenting questions with more reasoning steps to create a more challenging VQA benchmark?

## Limitations
- Dependence on quality of generated reasoning paths, which is constrained by underlying model capabilities
- Limited analysis based on only two benchmarks (GQA and A-OKVQA) may not represent full diversity of VQA tasks
- Lack of detailed implementation specifics for prompting strategies and analysis criteria
- Uncertainty about generalizability to other VQA datasets with different reasoning patterns

## Confidence
- Medium Confidence: The accuracy improvement claim on A-OKVQA is supported by results but implementation details are incomplete
- Medium Confidence: Observation about predominance of single-hop reasoning is plausible but may not generalize
- Low Confidence: Effectiveness across all reasoning cases claimed but not fully validated with comprehensive comparisons

## Next Checks
1. Implement and validate the two prompting strategies on a diverse set of VQA benchmarks
2. Conduct thorough analysis of generated reasoning paths against ground truth when available
3. Evaluate performance on complex multi-hop reasoning tasks with baseline comparisons