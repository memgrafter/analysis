---
ver: rpa2
title: 'TASAR: Transfer-based Attack on Skeletal Action Recognition'
arxiv_id: '2409.02483'
source_url: https://arxiv.org/abs/2409.02483
tags:
- attack
- bayesian
- adversarial
- attacks
- s-har
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TASAR introduces the first transfer-based attack on skeleton-based
  action recognition (S-HAR) by addressing low adversarial transferability. The key
  insight is that poor transferability stems from the non-smooth loss landscape of
  S-HAR models.
---

# TASAR: Transfer-based Attack on Skeletal Action Recognition

## Quick Facts
- **arXiv ID**: 2409.02483
- **Source URL**: https://arxiv.org/abs/2409.02483
- **Reference count**: 40
- **Primary result**: TASAR achieves 35.5% average transfer success rate, outperforming S-HAR attacks by 23.4% and transfer-based attacks by 8.1%

## Executive Summary
TASAR introduces the first transfer-based attack on skeleton-based action recognition (S-HAR) that addresses the fundamental challenge of low adversarial transferability in skeletal data. The key insight is that poor transferability stems from the non-smooth loss landscape of S-HAR models. TASAR introduces a post-train Dual Bayesian optimization strategy that appends lightweight Bayesian components to pre-trained surrogates without retraining, smoothing the loss surface and enabling efficient sampling from the model posterior. Unlike existing transfer-based attacks that ignore temporal coherence, TASAR integrates motion dynamics through temporal gradient modeling to disrupt spatial-temporal features in S-HAR models. The evaluation uses a newly constructed RobustBenchHAR benchmark comprising 7 S-HAR models, 10 attack methods, 3 datasets, and 2 defense models.

## Method Summary
TASAR operates by first appending lightweight Bayesian components (two-layer MLPs) to pre-trained surrogate models without retraining. The core innovation is the Dual Bayesian optimization strategy, which uses dual MCMC sampling to explore a smoothed posterior distribution of the surrogate models. The attack then incorporates temporal motion gradients by computing first-order (velocity) and second-order (acceleration) dynamics, disrupting the spatial-temporal coherence that S-HAR models rely on. The adversarial examples are generated through iterative gradient attacks with perturbation budgets of 0.01 over 200 iterations, using K=3 appended models and M=20 sampling iterations.

## Key Results
- TASAR achieves 35.5% average transfer success rate across 7 S-HAR models
- Outperforms state-of-the-art S-HAR attacks by 23.4% and transfer-based attacks by 8.1%
- Maintains comparable white-box attack performance while showing superior results against defense models
- Demonstrates effectiveness across 3 different skeletal action recognition datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Poor transferability in S-HAR stems from low smoothness in the loss landscape of skeletal models
- Mechanism: Smoother loss surfaces allow adversarial examples to transfer more reliably across different models by avoiding sharp local minima that are model-specific
- Core assumption: Loss landscape smoothness correlates directly with adversarial transferability
- Evidence anchors:
  - [abstract]: "one prominent indicator of poor transferability is the low smoothness of the loss function"
  - [section]: "The loss surface of models trained on skeletal data is much sharper than those trained on image data"
  - [corpus]: No direct corpus evidence found; this appears to be a novel insight specific to the paper
- Break condition: If the correlation between loss smoothness and transferability doesn't hold for certain S-HAR architectures

### Mechanism 2
- Claim: Post-train Dual Bayesian optimization creates a smoothed posterior distribution for better adversarial sampling
- Mechanism: By appending lightweight Bayesian components to pre-trained surrogates and using dual MCMC sampling, TASAR generates adversarial examples from a smoother posterior distribution
- Core assumption: Models sampled from a smooth posterior will have better adversarial transferability
- Evidence anchors:
  - [abstract]: "TASAR explores the smoothened model posterior of pre-trained surrogates, which is achieved by a new post-train Dual Bayesian optimization strategy"
  - [section]: "we aim for proposing a smooth posterior for learning post-train BNNs, hence possibly possessing higher adversarial transferability"
  - [corpus]: Weak corpus evidence; while Bayesian methods are known to smooth loss landscapes, the specific "post-train dual" approach appears novel
- Break condition: If the computational cost of dual sampling outweighs the transferability gains

### Mechanism 3
- Claim: Temporal motion gradient integration disrupts spatial-temporal coherence to improve transferability
- Mechanism: TASAR incorporates first-order and second-order motion dynamics (velocity and acceleration) into the adversarial gradient computation, rather than treating each frame independently
- Core assumption: S-HAR models learn spatial-temporal features, so disrupting temporal coherence improves transferability
- Evidence anchors:
  - [abstract]: "TASAR incorporates motion dynamics into the Bayesian attack, effectively disrupting the spatial-temporal coherence of S-HARs"
  - [section]: "most S-HAR models learn the spatial-temporal features because skeletal data contains rich motion dynamics"
  - [corpus]: No corpus evidence found; this temporal gradient approach appears to be a novel contribution
- Break condition: If temporal coherence disruption makes adversarial examples too easily detectable

## Foundational Learning

- Concept: Bayesian Neural Networks and posterior sampling
  - Why needed here: TASAR relies on sampling from model posteriors to create smoother loss landscapes
  - Quick check question: How does Bayesian inference differ from standard neural network training in terms of parameter uncertainty?

- Concept: Loss landscape visualization and smoothness metrics
  - Why needed here: Understanding loss landscape smoothness is critical to TASAR's core insight about transferability
  - Quick check question: What visualization techniques can be used to compare loss landscape smoothness between different models?

- Concept: Temporal dynamics modeling in skeletal sequences
  - Why needed here: TASAR's temporal gradient modeling requires understanding motion dynamics in skeletal data
  - Quick check question: What are the differences between position, velocity, and acceleration gradients in temporal sequences?

## Architecture Onboarding

- Component map: Pre-trained surrogate model (frozen) -> Lightweight Bayesian component (trainable MLP layer) -> Dual Bayesian optimization module -> Temporal motion gradient computation -> Adversarial example generation module

- Critical path: Pre-trained surrogate → Bayesian component training → Dual sampling → Temporal gradient computation → Adversarial example generation

- Design tradeoffs:
  - Computational cost vs. transferability gain (dual sampling is expensive)
  - Temporal coherence disruption vs. example detectability
  - Model size (appended components) vs. performance

- Failure signatures:
  - Low transferability despite smooth loss landscape (temporal component may be missing)
  - High computational cost with minimal gain (dual sampling parameters need tuning)
  - Adversarial examples too easily detected (temporal gradient weights may be too aggressive)

- First 3 experiments:
  1. Compare loss landscape smoothness between normally trained and TASAR-optimized models using the same surrogate
  2. Test transferability with and without temporal motion gradients on a simple surrogate-target pair
  3. Measure the impact of dual sampling iterations (M parameter) on both performance and computation time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the smoothness of the loss landscape quantitatively correlate with adversarial transferability across different S-HAR architectures?
- Basis in paper: [explicit] The paper demonstrates a clear correlation between loss landscape smoothness and transferability in Figure 2, noting that CTR-GCN's flatter landscape results in higher transferability than ST-GCN.
- Why unresolved: While the correlation is visually apparent, the paper doesn't provide quantitative metrics (e.g., curvature measures, Hessian eigenvalues) that could be used to predict transferability performance across architectures.
- What evidence would resolve it: A systematic study measuring loss landscape smoothness metrics (like sharpness, local curvature, or spectral norms of Hessian) for each S-HAR model and correlating these with their average transferability rates would establish quantitative relationships.

### Open Question 2
- Question: What is the theoretical limit of transferability for S-HAR models, and can it be approached with current attack methodologies?
- Basis in paper: [inferred] The paper shows TASAR achieves 35.5% average transfer success rate, outperforming baselines by significant margins, but this still leaves the majority of attacks unsuccessful, suggesting fundamental limitations.
- Why unresolved: The paper doesn't explore whether there's an inherent ceiling for transferability in S-HAR due to architectural differences, or whether current methods are approaching theoretical limits.
- What evidence would resolve it: Empirical studies testing transferability against an exhaustive set of S-HAR architectures, combined with theoretical analysis of decision boundary similarity measures, would help determine if current methods are approaching theoretical limits.

### Open Question 3
- Question: How does the dual Bayesian optimization strategy compare to other posterior sampling methods (e.g., Stein Variational Gradient Descent, Laplace approximation) in terms of both transferability and computational efficiency?
- Basis in paper: [explicit] The paper proposes post-train Dual Bayesian optimization as a novel approach and shows it improves upon vanilla post-train Bayesian in Figure 2, but doesn't compare against alternative Bayesian sampling methods.
- Why unresolved: The paper focuses on comparing against non-Bayesian methods and the vanilla Bayesian approach, but doesn't benchmark against other sophisticated Bayesian posterior approximation techniques.
- What evidence would resolve it: Direct experimental comparison of TASAR's dual Bayesian optimization against alternative Bayesian sampling methods on the same benchmark, measuring both transferability rates and computational costs, would establish relative effectiveness.

### Open Question 4
- Question: How do temporal motion gradients specifically affect the transferability of attacks on skeleton sequences compared to spatial-only perturbations?
- Basis in paper: [explicit] The paper introduces temporal motion gradient modeling (Equations 11-14) and shows through ablation studies that it improves transferability compared to position-only gradients.
- Why unresolved: While the paper demonstrates improvement, it doesn't provide detailed analysis of which motion dynamics (velocity vs. acceleration) contribute most to transferability, or how temporal modeling affects perturbation detectability.
- What evidence would resolve it: Controlled experiments isolating velocity and acceleration components, measuring their individual contributions to transferability and comparing perturbation detectability, would clarify the specific benefits of temporal modeling.

## Limitations

- The Dual Bayesian optimization strategy introduces significant computational overhead compared to standard transfer-based attacks
- The attack requires appending Bayesian components to pre-trained surrogates, increasing model complexity
- Limited evaluation against certified defense mechanisms that could potentially mitigate the attack

## Confidence

**High Confidence**: The experimental results showing TASAR's 35.5% average transfer success rate and 23.4% improvement over state-of-the-art S-HAR attacks are well-documented with specific datasets and metrics. The comparison against 10 different attack methods across 7 target models provides robust empirical evidence.

**Medium Confidence**: The theoretical framework linking loss landscape smoothness to transferability, while compelling, relies on assumptions about the S-HAR domain that haven't been extensively validated in the broader adversarial machine learning literature. The post-train Dual Bayesian optimization strategy appears novel but lacks comparative analysis against alternative smoothing techniques.

**Low Confidence**: The specific implementation details of the temporal gradient modeling and the exact configuration of the TV-AR models for motion dynamics are not fully specified, making independent verification challenging.

## Next Checks

1. **Loss Landscape Validation**: Replicate the loss landscape smoothness analysis by comparing TASAR-optimized surrogates against normally trained models using the same architectures. Visualize and quantify the smoothness differences using established metrics like gradient cosine similarity and eigenvalue spectra.

2. **Component Ablation Study**: Isolate the contributions of the three main TASAR components (Bayesian smoothing, dual sampling, temporal gradients) through systematic ablation experiments. Measure how each component individually affects transfer success rates and computational costs.

3. **Defense Robustness Testing**: Evaluate TASAR's performance against a broader range of defense mechanisms beyond the two mentioned (BEAT and TRADES), including adversarial training and certified defenses. Assess whether the attack maintains effectiveness when facing multiple defense strategies simultaneously.