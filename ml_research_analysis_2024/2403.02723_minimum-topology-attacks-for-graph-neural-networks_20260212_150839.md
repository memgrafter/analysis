---
ver: rpa2
title: Minimum Topology Attacks for Graph Neural Networks
arxiv_id: '2403.02723'
source_url: https://arxiv.org/abs/2403.02723
tags:
- attacks
- attack
- budget
- node
- topology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MiBTack, the first minimum-budget topology
  attack on graph neural networks (GNNs). Instead of fixing the attack budget, MiBTack
  adaptively finds the minimum perturbation edges sufficient to misclassify each target
  node.
---

# Minimum Topology Attacks for Graph Neural Networks

## Quick Facts
- arXiv ID: 2403.02723
- Source URL: https://arxiv.org/abs/2403.02723
- Authors: Mengmei Zhang; Xiao Wang; Chuan Shi; Lingjuan Lyu; Tianchi Yang; Junping Du
- Reference count: 40
- Primary result: Introduces MiBTack, the first minimum-budget topology attack on GNNs that adaptively finds the minimum perturbation edges needed to misclassify each target node

## Executive Summary
This paper introduces MiBTack, the first minimum-budget topology attack on graph neural networks that dynamically finds the smallest perturbation edges needed to misclassify each target node. Instead of fixing the attack budget, MiBTack uses a dynamic projected gradient descent algorithm that iteratively updates perturbations and budget until the decision boundary is crossed. The method achieves 100% attack success rate while using significantly fewer perturbation edges than fixed-budget attacks. Extensive experiments on four real-world datasets and three GNNs demonstrate MiBTack's effectiveness, and the obtained minimum budgets are used to quantify node robustness and analyze its relationships with node degree and uncertainty.

## Method Summary
MiBTack addresses the minimum-budget topology attack problem by decoupling budget and perturbation optimization into alternating convex problems. The algorithm uses projected gradient descent (PGD) to optimize perturbations under fixed budget constraints, while dynamically adjusting the budget based on attack success. It starts with one-step attacks toward each class to identify the closest decision boundary, then iteratively updates perturbations and budget until convergence. The method includes a patience parameter to prevent endless optimization and uses projection operators to ensure perturbations remain within valid ranges.

## Key Results
- MiBTack achieves 100% attack success rate on all tested datasets and GNN architectures
- The method uses significantly fewer perturbation edges than fixed-budget attacks (minimum total budget reduction)
- MiBTack outperforms all baseline methods in most scenarios, yielding minimum attacks with guaranteed misclassification
- Analysis reveals positive correlation between node degree and robustness, but many high-degree nodes remain vulnerable

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic budget adjustment allows finding the minimal perturbation needed to cross the decision boundary exactly
- Mechanism: The algorithm starts with a small budget and increases it incrementally when attacks fail, or decreases it when attacks succeed, converging to the minimum sufficient budget
- Core assumption: The decision boundary is relatively smooth and can be approached through iterative gradient-based perturbations
- Evidence anchors:
  - [abstract] "MiBTack adaptively finds the minimum perturbation edges sufficient to misclassify each target node"
  - [section] "we propose an attack model, named MiBTack, based on a dynamic projected gradient descent algorithm, which can effectively solve the involving non-convex constraint optimization on discrete topology"
- Break condition: If the decision boundary is too jagged or discontinuous, the iterative approach may overshoot or oscillate around the minimum

### Mechanism 2
- Claim: Decoupling budget and perturbation optimization transforms a non-convex problem into alternating convex problems
- Mechanism: The algorithm alternates between (1) fixing the budget and optimizing perturbations with PGD, and (2) updating the budget based on attack success
- Core assumption: The perturbation optimization under fixed budget is convex and solvable by PGD
- Evidence anchors:
  - [section] "we decouple the budget and perturbation, turning the non-convex constrained optimization to alternatively solve the easier convex constrained optimization"
  - [abstract] "which can effectively solve the involving non-convex constraint optimization on discrete topology"
- Break condition: If the perturbation optimization under fixed budget becomes non-convex due to the discrete nature of graph topology

### Mechanism 3
- Claim: Initialization with one-step attacks toward each class identifies the closest decision boundary
- Mechanism: Instead of random initialization, the algorithm performs one perturbation toward each possible class and selects the class that causes the largest loss reduction as the target
- Core assumption: The closest decision boundary is likely the one that can be reached with minimal perturbation from the current position
- Evidence anchors:
  - [section] "Here we solve this problem by performing topology attacks with one-step towards each wrong class, and choose the class with the largest descent of L"
  - [abstract] "Our MiBTack can outperform all baselines in most scenarios, yielding minimum attacks with the guarantee of misclassification of all nodes"
- Break condition: If the closest decision boundary is not aligned with the largest loss reduction direction, the initialization may lead to suboptimal attacks

## Foundational Learning

- Concept: Projected Gradient Descent (PGD)
  - Why needed here: PGD is used to optimize perturbations under budget constraints
  - Quick check question: What is the key difference between standard gradient descent and projected gradient descent?

- Concept: Non-convex optimization
  - Why needed here: The attack problem involves minimizing a non-convex loss function with discrete constraints
  - Quick check question: Why is non-convex optimization generally harder than convex optimization?

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: The attack targets GNNs specifically, exploiting their vulnerability to topology perturbations
  - Quick check question: How do GNNs aggregate information from neighboring nodes during message passing?

## Architecture Onboarding

- Component map: Initialization -> Perturbation Optimizer (PGD-based) -> Decision Boundary Tester -> Budget Updater -> Convergence Checker
- Critical path: Initialize → Optimize perturbations → Test success → Update budget → Repeat until convergence
- Design tradeoffs:
  - Budget step size vs. convergence speed: Larger steps may converge faster but risk overshooting
  - Patience parameter vs. resource usage: Higher patience allows better solutions but increases computation
  - Initialization strategy vs. attack effectiveness: Better initialization reduces search space but adds computation
- Failure signatures:
  - No convergence: Budget oscillates without settling on minimum
  - Suboptimal solutions: Final budget much larger than necessary
  - Computational inefficiency: Too many iterations required for convergence
- First 3 experiments:
  1. Run MiBTack on a single node with known decision boundary to verify convergence
  2. Compare fixed-budget vs. dynamic-budget approaches on a small graph
  3. Test initialization strategies (random vs. one-step) on attack effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can MiBTack be effectively extended to black-box GNN settings where gradients are unavailable?
- Basis in paper: [explicit] The paper mentions that MiBTack variants like MiBTack-J and MiBTack-R can handle defended GNNs by modifying the search space or replacing the target GNN, but notes that extending to complex or black-box defended GNNs remains challenging.
- Why unresolved: Black-box settings prevent gradient computation, which is central to MiBTack's optimization process.
- What evidence would resolve it: Development and empirical validation of gradient-free or query-based optimization methods that achieve comparable performance to MiBTack in black-box settings.

### Open Question 2
- Question: What is the relationship between node degree and robustness under different attack budgets?
- Basis in paper: [explicit] The paper observes a positive correlation between node degree and robustness but notes that many high-degree nodes are surprisingly vulnerable.
- Why unresolved: The analysis is limited to fixed attack budgets; varying budgets may reveal different robustness patterns.
- What evidence would resolve it: Systematic experiments varying attack budgets to analyze how degree-robustness relationships change.

### Open Question 3
- Question: How does the initialization strategy affect MiBTack's performance on graphs with different structural properties?
- Basis in paper: [explicit] The paper proposes a one-step attack initialization to estimate the closest decision boundary, noting its importance for performance.
- Why unresolved: The effectiveness of this initialization across diverse graph structures (e.g., sparse vs. dense, community-structured vs. random) is not explored.
- What evidence would resolve it: Comparative experiments testing MiBTack with and without initialization across graphs with varying structural properties.

## Limitations

- The dynamic budget adjustment may get stuck in local minima rather than finding the global minimum, especially given the non-convex nature of the optimization problem
- The evaluation scope is limited to four datasets and three GNN architectures, potentially limiting generalizability to other graph types
- The computational complexity of the iterative approach is not adequately addressed compared to fixed-budget methods
- The robustness analysis may conflate attack difficulty with inherent node properties

## Confidence

- High confidence: The basic framework of dynamic budget adjustment and the claim that MiBTack achieves 100% attack success rate
- Medium confidence: The claim that MiBTack uses significantly fewer perturbation edges than fixed-budget attacks, and the robustness quantification methodology
- Low confidence: The assertion that the optimization problem becomes "easier" after decoupling, and the generalizability of results to other graph types

## Next Checks

1. Test MiBTack on additional graph datasets with different characteristics (e.g., different sparsity levels, community structures) to verify generalizability

2. Compare convergence behavior on graphs with smooth vs. jagged decision boundaries to validate the core assumption about iterative approach effectiveness

3. Implement a baseline that performs exhaustive search for small graphs to verify whether MiBTack truly finds the minimum budget or gets trapped in local optima