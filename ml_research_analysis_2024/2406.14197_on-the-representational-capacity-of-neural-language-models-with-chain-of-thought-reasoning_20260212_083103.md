---
ver: rpa2
title: On the Representational Capacity of Neural Language Models with Chain-of-Thought
  Reasoning
arxiv_id: '2406.14197'
source_url: https://arxiv.org/abs/2406.14197
tags:
- transformer
- output
- function
- symbol
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Chain-of-thought reasoning in language models improves performance
  on reasoning tasks by allowing the model to store and utilize intermediate results
  during computation. This work formalizes chain-of-thought reasoning in a probabilistic
  setting and analyzes its impact on the representational capacity of recurrent and
  transformer language models.
---

# On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning

## Quick Facts
- arXiv ID: 2406.14197
- Source URL: https://arxiv.org/abs/2406.14197
- Authors: Franz Nowak; Anej Svete; Alexandra Butoi; Ryan Cotterell
- Reference count: 40
- Primary result: Chain-of-thought reasoning enables neural language models to simulate non-deterministic probabilistic Turing machines

## Executive Summary
This work formalizes chain-of-thought (CoT) reasoning in a probabilistic setting to analyze its impact on the representational capacity of recurrent and transformer language models. The key insight is that CoT enables these models to simulate non-deterministic probabilistic Turing machines by augmenting their output alphabet to include intermediate computational states. The authors prove that constant-precision recurrent neural networks with CoT are equivalent to probabilistic finite-state automata, while logarithmically bounded precision recurrent networks and decoder-only transformers with CoT can simulate any probabilistic Turing machine.

## Method Summary
The paper presents a theoretical analysis of chain-of-thought reasoning's impact on neural language models' computational power. The method involves augmenting language model output alphabets to include intermediate state information, then using regular functions to remove these intermediate states while preserving the final string distribution. The authors prove equivalence theorems showing that CoT-augmented models can simulate various probabilistic models of computation, from finite-state automata to Turing machines, depending on precision constraints.

## Key Results
- CoT reasoning enables neural language models to simulate non-deterministic probabilistic Turing machines
- Constant-precision RNNs with CoT are equivalent to probabilistic finite-state automata
- Logarithmically bounded precision transformers with CoT can simulate any probabilistic Turing machine
- The required precision for transformer simulations grows logarithmically with computational steps

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain-of-thought reasoning allows neural language models to simulate non-deterministic probabilistic Turing machines.
- Mechanism: By augmenting the output alphabet to include intermediate computational states, the model can keep track of multiple possible execution paths, enabling non-deterministic behavior.
- Core assumption: The additional state information in the output can be removed via a regular function without affecting the final string distribution.
- Evidence anchors:
  - [abstract] "Chain-of-thought reasoning enables these models to simulate non-deterministic probabilistic Turing machines, significantly expanding their computational power."
  - [section] "Thm. 3.1 captures a crucial property of regular reducibility: It allows us to simulate non-determinism with a deterministic device."
  - [corpus] Weak: No direct mention of non-determinism in corpus neighbors.
- Break condition: If the regular function cannot remove intermediate states without altering the final output distribution, the simulation fails.

### Mechanism 2
- Claim: Constant-precision recurrent neural networks with chain-of-thought reasoning are equivalent to probabilistic finite-state automata.
- Mechanism: The RNN stores current automaton states in its output, allowing it to handle non-deterministic transitions that fixed-precision RNNs without CoT cannot.
- Core assumption: The RNN can accurately encode and decode state information within its output symbols.
- Evidence anchors:
  - [abstract] "constant-precision recurrent neural networks with chain-of-thought reasoning are equivalent to probabilistic finite-state automata"
  - [section] "Thms. 4.1 and 4.2 establish the equivalence between CoT-augmented constant-precision Elman RNN LMs and general regular LMs."
  - [corpus] Weak: No direct mention of PFSA equivalence in corpus neighbors.
- Break condition: If the state encoding exceeds the fixed precision, the equivalence breaks down.

### Mechanism 3
- Claim: Log-precision decoder-only transformers with chain-of-thought reasoning can simulate any probabilistic Turing machine.
- Mechanism: The transformer encodes the current configuration of the Turing machine in its output, allowing it to simulate the probabilistic transition function.
- Core assumption: The precision of the transformer scales logarithmically with the number of computational steps.
- Evidence anchors:
  - [abstract] "logarithmically bounded precision decoder-only transformers with chain-of-thought reasoning can simulate any probabilistic Turing machine."
  - [section] "The precision required for the representation of these values grows logarithmically with the number of computational steps."
  - [corpus] Weak: No direct mention of log-precision or PTM simulation in corpus neighbors.
- Break condition: If the precision grows faster than logarithmically, the simulation becomes infeasible.

## Foundational Learning

- Concept: Probabilistic Turing Machines
  - Why needed here: The paper formalizes chain-of-thought reasoning in terms of probabilistic Turing machines, so understanding their definition and behavior is crucial.
  - Quick check question: How does a probabilistic Turing machine differ from a deterministic one in terms of transition functions?

- Concept: Regular Functions and Reducibility
  - Why needed here: The paper uses regular reducibility to formalize chain-of-thought reasoning, so understanding how regular functions can transform strings is essential.
  - Quick check question: Can you provide an example of a regular function that removes intermediate computation steps from a string?

- Concept: Weighted Finite-State Automata
  - Why needed here: The paper establishes connections between chain-of-thought-augmented models and probabilistic finite-state automata, so understanding their structure and behavior is important.
  - Quick check question: How do probabilistic finite-state automata differ from deterministic ones in terms of language recognition?

## Architecture Onboarding

- Component map: RNN/Transformer -> Output Layer (augmented) -> Regular Function -> Sampling Mechanism
- Critical path: 1. Initialize model with augmented output alphabet 2. Generate output string, including intermediate states 3. Apply regular function to remove intermediate states 4. Compute final string distribution
- Design tradeoffs: Precision vs. Computational Power: Higher precision allows simulation of more complex models but increases computational cost. State Encoding: The choice of how to encode state information affects both model performance and ease of post-processing.
- Failure signatures: Inconsistent string distributions after applying regular function, inability to simulate non-deterministic behavior, precision overflow when encoding state information
- First 3 experiments: 1. Implement a simple RNN with augmented output alphabet and test its ability to simulate a non-deterministic finite automaton. 2. Add a regular function to remove intermediate states and verify that the final string distribution matches the original automaton. 3. Gradually increase the complexity of the automaton and measure the precision requirements of the RNN.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the computational complexity of CoT-augmented models scale with the length of intermediate reasoning steps?
- Basis in paper: [explicit] The paper mentions that CoT reasoning allows models to store and utilize intermediate results, but does not provide a detailed complexity analysis.
- Why unresolved: The paper focuses on representational capacity rather than computational efficiency, leaving open questions about the practical scalability of CoT approaches.
- What evidence would resolve it: Empirical studies comparing the computational cost of CoT-augmented models versus standard models across varying reasoning depths and task complexities.

### Open Question 2
- Question: What is the minimum precision required for transformer models to achieve Turing completeness with CoT reasoning in practice?
- Basis in paper: [explicit] The paper shows that logarithmically bounded precision is sufficient for theoretical Turing completeness, but notes this is unrealistic in practice.
- Why unresolved: The gap between theoretical requirements (logarithmic precision) and practical implementations (fixed precision floating point) remains unaddressed.
- What evidence would resolve it: Experimental demonstrations of CoT transformers operating near Turing-complete tasks with realistic precision constraints.

### Open Question 3
- Question: How does the choice of normalization function (sparsemax vs softmax) affect the representational capacity of CoT-augmented models?
- Basis in paper: [explicit] The paper explicitly chooses sparsemax to avoid the full support limitation of softmax, but does not explore the broader implications of this choice.
- Why unresolved: The paper does not investigate whether other normalization functions could provide similar or better representational capabilities.
- What evidence would resolve it: Comparative analysis of CoT-augmented models using different normalization functions across various computational tasks.

## Limitations
- Analysis remains purely theoretical without empirical validation on real-world tasks
- Assumes rational arithmetic throughout, but real systems use finite-precision arithmetic
- Does not provide concrete implementations of regular functions for removing intermediate states

## Confidence
- High confidence (8/10): Equivalence between constant-precision RNNs with CoT and probabilistic finite-state automata is well-supported by rigorous mathematical proofs
- Medium confidence (6/10): Logarithmic precision scaling requirement for transformer simulations is theoretically sound but may face practical limitations
- Low confidence (4/10): Claim that CoT universally improves representational capacity lacks empirical evidence

## Next Checks
1. **Empirical verification**: Implement a simple CoT-augmented RNN and test its ability to simulate non-deterministic finite automata on concrete examples. Compare performance with standard RNNs on tasks requiring non-deterministic behavior.
2. **Precision scaling experiment**: Systematically vary the precision of CoT-augmented transformer models and measure their ability to simulate increasingly complex probabilistic Turing machines. Verify whether precision scales logarithmically as claimed.
3. **Regular function implementation**: Construct and test concrete implementations of regular functions for removing intermediate states from CoT-generated strings. Evaluate the computational complexity and impact on final output distributions.