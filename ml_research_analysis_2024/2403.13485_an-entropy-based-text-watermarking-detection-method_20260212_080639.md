---
ver: rpa2
title: An Entropy-based Text Watermarking Detection Method
arxiv_id: '2403.13485'
source_url: https://arxiv.org/abs/2403.13485
tags:
- detection
- text
- entropy
- token
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an entropy-based text watermarking detection
  method called EWD, which addresses the challenge of detecting watermarked texts
  with low entropy. The core idea is to assign higher influence weights to higher-entropy
  tokens during the detection process, thereby improving the detection performance
  for low-entropy scenarios.
---

# An Entropy-based Text Watermarking Detection Method

## Quick Facts
- arXiv ID: 2403.13485
- Source URL: https://arxiv.org/abs/2403.13485
- Reference count: 16
- Primary result: EWD method improves detection accuracy in low-entropy scenarios by 2.5% and 9.4% TPR for HumanEval and MBPP datasets respectively

## Executive Summary
This paper addresses the challenge of detecting watermarked text in low-entropy scenarios where existing methods struggle. The authors propose an entropy-based text watermarking detection (EWD) method that assigns higher influence weights to higher-entropy tokens during detection. By using a monotonically-increasing function to generate influence weights from token entropy, EWD achieves superior detection performance in low-entropy scenarios while maintaining comparable performance in high-entropy scenarios. The method is training-free and fully automated, demonstrating robustness against back-translation attacks.

## Method Summary
The EWD method calculates token entropy using spike entropy, then applies a monotonically-increasing function to generate influence weights for each token. During detection, the method sums the weighted green tokens, calculates a z-score with weighted variance, and compares it to a threshold for final detection. The core innovation is recognizing that higher-entropy tokens contribute more to watermark detectability under the same watermark strength, making differential weighting by entropy an effective detection strategy.

## Key Results
- 2.5% and 9.4% improvement in TPR for HumanEval and MBPP datasets in low-entropy scenarios
- Similar detection performance to baselines in high-entropy scenarios using Rotowire and C4 datasets
- Efficient detection speed and robustness against back-translation attacks
- Training-free and fully automated detection process

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Higher-entropy tokens contribute more to watermark detectability than lower-entropy tokens under the same watermark strength.
- Mechanism: The watermark generation process adds a fixed bias (δ) to green token logits. When logits are spread (high entropy), this bias meaningfully shifts the sampling distribution toward green tokens. When logits are concentrated (low entropy), the bias has little effect.
- Core assumption: The token sampling distribution is approximately uniform when entropy is high and peaked when entropy is low.
- Evidence anchors:
  - [abstract] "The probability of sampling a token from the green list is proportional to its entropy"
  - [section 3.3] "When the logits resembles a uniform distribution, this logits modification would very likely produce a green-list token. However, when the logits concentrates on one single token, this watermark embedding process would hardly affect the token sampling"
- Break condition: If the token distribution becomes bimodal or the watermark strength δ becomes too large, the entropy-sampling relationship may no longer hold.

### Mechanism 2
- Claim: Weighting detection scores by token entropy improves detection accuracy in low-entropy scenarios.
- Mechanism: By assigning higher detection weights to high-entropy tokens, the method amplifies the signal from tokens most likely to be affected by watermarking, while minimizing noise from low-entropy tokens that are unlikely to change.
- Core assumption: Detection performance can be improved by differentially weighting tokens rather than treating them equally.
- Evidence anchors:
  - [abstract] "we utilize a monotonically-increasing and continuous function to generate influence weights from token entropy"
  - [section 4.2] "the weight of each token during watermark detection should be customized according to its entropy, rather than setting the weights of all tokens to the same value"
- Break condition: If the entropy-weighting function is poorly calibrated or if token entropy and watermark susceptibility become uncorrelated.

### Mechanism 3
- Claim: The EWD method maintains detection performance in high-entropy scenarios while improving it in low-entropy ones.
- Mechanism: The entropy-based weighting function is monotonic and continuous, preserving the relative contributions of tokens in high-entropy regimes while adjusting their influence in low-entropy regimes.
- Core assumption: The monotonic weight function does not distort the detection signal in high-entropy scenarios where all tokens are already well-differentiated.
- Evidence anchors:
  - [abstract] "our method is also general and can be applied to texts with different entropy distributions"
  - [section 6.2] "For the high-entropy scenarios using the Rotowire and C4 datasets, the detection performance of our method is overall very similar to other baselines"
- Break condition: If the monotonic function introduces non-linear distortions or if high-entropy scenarios have different underlying statistics.

## Foundational Learning

- Concept: Token entropy as measured by spike entropy formula
  - Why needed here: Understanding how token entropy is calculated is crucial for implementing the weighting function and interpreting results
  - Quick check question: What is the minimum and maximum value of spike entropy, and what do they represent in terms of token predictability?

- Concept: Watermarking via logit modification
  - Why needed here: The entire detection mechanism depends on understanding how watermarks are embedded through logit modification
  - Quick check question: How does adding a constant δ to green token logits affect the sampling probability, and why is this effect entropy-dependent?

- Concept: Binomial distribution approximation for detection statistics
  - Why needed here: The theoretical analysis relies on modeling the number of green tokens as a binomial distribution
  - Quick check question: Under what conditions is the binomial distribution a good approximation for the number of green tokens in watermarked text?

## Architecture Onboarding

- Component map:
  Token entropy calculator (spike entropy) -> Weight function generator (monotonic increasing) -> Green list detector (using detection key and context) -> Z-score calculator (weighted sum and normalization) -> Threshold comparator (final detection decision)

- Critical path:
  1. Calculate token entropies from model logits
  2. Apply monotonic function to generate weights
  3. For each token position, determine if it's in green list
  4. Sum weighted green tokens
  5. Calculate z-score with weighted variance
  6. Compare to threshold and output detection result

- Design tradeoffs:
  - Weight function choice: Linear vs sigmoid vs exponential - affects sensitivity to entropy variations
  - Detection window size: Larger windows provide more context but may introduce dependencies
  - Threshold setting: Balancing false positives and false negatives

- Failure signatures:
  - Poor detection in low-entropy scenarios: Likely weight function not sensitive enough to entropy differences
  - Degraded performance in high-entropy scenarios: Weight function may be introducing non-linear distortions
  - High false positive rate: Threshold may be too low or weight function may be over-emphasizing certain entropy ranges

- First 3 experiments:
  1. Compare detection performance using linear vs sigmoid vs exponential weight functions on HumanEval dataset
  2. Measure detection accuracy with and without original prompts to understand prompt dependency
  3. Test robustness against back-translation attacks on C4 dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed EWD method perform on different types of watermarking methods, such as token sampling-based methods?
- Basis in paper: [inferred] The paper mentions that the method should be theoretically effective for various types of watermark methods, but it does not provide empirical evidence or detailed analysis of its performance on different types of watermarking methods.
- Why unresolved: The paper only provides experimental results on a specific type of watermarking method (KGW) and does not explore the method's performance on other types of watermarking methods.
- What evidence would resolve it: Conducting experiments on different types of watermarking methods, such as token sampling-based methods, and comparing the performance of EWD with other baselines would provide insights into the method's generalizability and effectiveness across different watermarking scenarios.

### Open Question 2
- Question: How does the choice of the monotonically-increasing function (e.g., Sigmoid, Exponential) affect the detection performance of EWD?
- Basis in paper: [explicit] The paper explores different monotonically-increasing functions (Sigmoid, Exponential) and their strengths, but it does not provide a comprehensive analysis of how the choice of function affects the detection performance.
- Why unresolved: The paper only provides results for a few specific functions and their strengths, without a thorough investigation of the impact of different functions on the detection performance.
- What evidence would resolve it: Conducting experiments with a wider range of monotonically-increasing functions and their strengths, and analyzing the impact of each function on the detection performance, would provide insights into the optimal choice of function for different scenarios.

### Open Question 3
- Question: How does the proposed EWD method perform on low-entropy datasets other than code generation tasks?
- Basis in paper: [inferred] The paper mentions that the low-entropy datasets tested are limited to code generation tasks, and it aims to include more low-entropy tasks and datasets in the future.
- Why unresolved: The paper only provides experimental results on code generation datasets and does not explore the method's performance on other low-entropy tasks, such as news report generation or data-to-text generation.
- What evidence would resolve it: Conducting experiments on a variety of low-entropy tasks and datasets, such as news report generation or data-to-text generation, and comparing the performance of EWD with other baselines would provide insights into the method's generalizability and effectiveness across different low-entropy scenarios.

## Limitations

- The exact form and parameters of the monotonic weight function are not specified, making reproducibility challenging
- The method's effectiveness depends on the assumption that token entropy correlates strongly with watermark susceptibility
- Evaluation focuses primarily on synthetic benchmarks and may not generalize to real-world scenarios

## Confidence

**High Confidence**: The theoretical framework connecting token entropy to watermark detectability is sound and well-explained. The empirical results showing improved TPR in low-entropy scenarios compared to baselines are specific and reproducible.

**Medium Confidence**: The generalizability of EWD across different text types and entropy distributions is supported by results on multiple datasets but requires further validation on more diverse real-world text. The claim of similar performance to baselines in high-entropy scenarios is based on limited datasets.

**Low Confidence**: The assertion that EWD is "fully automated" and requires no training is questionable given the need for parameter tuning. The robustness against back-translation attacks is demonstrated but not extensively tested against other attack vectors.

## Next Checks

1. **Weight Function Sensitivity Analysis**: Systematically test the detection performance using different monotonic functions (linear, sigmoid, exponential) with varying parameters on the HumanEval dataset to determine how sensitive the method is to this choice.

2. **Cross-Dataset Generalization**: Evaluate EWD on additional real-world datasets beyond the synthetic benchmarks, including longer-form text generation tasks and different domains, to assess generalizability claims.

3. **Comprehensive Attack Testing**: Conduct extensive robustness testing against a wider range of watermark detection evasion techniques beyond back-translation, including synonym replacement, grammatical error injection, and prompt injection attacks.