---
ver: rpa2
title: Compositional learning of functions in humans and machines
arxiv_id: '2403.12201'
source_url: https://arxiv.org/abs/2403.12201
tags:
- function
- functions
- each
- participants
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates human and machine ability to learn and
  compose visual functions, focusing on context-sensitive function interactions. Participants
  learned individual visual functions and were tested on composing pairs of functions
  under four interaction conditions (feeding, counter-feeding, bleeding, counter-bleeding).
---

# Compositional learning of functions in humans and machines

## Quick Facts
- arXiv ID: 2403.12201
- Source URL: https://arxiv.org/abs/2403.12201
- Reference count: 4
- Key outcome: Humans achieve 86.8% accuracy on zero-shot visual function composition across four interaction types, with a Transformer model matching performance through meta-learning and behavioral fine-tuning

## Executive Summary
This study investigates human and machine ability to learn and compose visual functions, focusing on context-sensitive function interactions. Participants learned individual visual functions and were tested on composing pairs of functions under four interaction conditions (feeding, counter-feeding, bleeding, counter-bleeding). Humans achieved high accuracy (86.8% overall) across all interaction types without showing biases observed in linguistic studies. Error analysis revealed structural mistakes such as partial function application or reversed order. A Transformer model trained via meta-learning for compositionality (MLC) achieved near-human accuracy (97.9% on validation) and captured human-like error patterns when fine-tuned on behaviorally-guided data. Results show that standard neural networks can mimic human compositional generalization through meta-learning and behavioral fine-tuning.

## Method Summary
The study tested human participants (117 adults) on learning visual functions that edit cartoon car objects, then composing pairs of functions across four interaction types. Each participant learned three individual functions through nine training examples each, then completed composition tests with eight trials per interaction type. A 2-layer Transformer encoder-decoder model was trained using meta-learning for compositionality, learning to generate outputs for novel function compositions based on support examples. The model was subsequently fine-tuned on synthetic data distributions designed to capture human error patterns and on actual human-generated responses.

## Key Results
- Humans achieved 86.8% accuracy on zero-shot function composition across all four interaction types
- No significant accuracy differences across feeding, counter-feeding, bleeding, and counter-bleeding conditions
- Transformer model achieved 97.9% validation accuracy and captured human-like error patterns through behavioral fine-tuning
- Error analysis revealed systematic structural mistakes: partial function application, function mismatch, and reversed order

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Humans can generalize to novel visual function compositions without explicit training on interaction types.
- Mechanism: Participants learned individual functions through few-shot exposure, then applied meta-learning-like generalization to compose functions in zero-shot trials across all four interaction conditions.
- Core assumption: Visual function learning transfers composition skills learned from single functions to novel pairs.
- Evidence anchors:
  - [abstract] "humans can make zero-shot generalizations on novel visual function compositions across interaction conditions"
  - [section] "high accuracy on all three groups suggests sufficient learning of the single functions"
- Break condition: If participants fail to maintain accuracy across interaction types, or if error patterns differ fundamentally from predictions.

### Mechanism 2
- Claim: Meta-learning for compositionality (MLC) enables standard Transformers to mimic human compositional generalization.
- Mechanism: Training via meta-learning episodes forces the model to learn representations of single functions and their composition rules without explicit compositional supervision.
- Core assumption: Function composition is learnable as a meta-task where models infer composability from support examples.
- Evidence anchors:
  - [abstract] "through the meta-learning for compositionality (MLC) approach, a standard sequence-to-sequence Transformer can mimic human generalization patterns"
  - [section] "The MLC model uses a standard sequence-to-sequence Transformer optimized to generate the correct output in response to a novel query based a set of support examples"
- Break condition: If model fails to achieve comparable accuracy or error patterns diverge significantly from human data.

### Mechanism 3
- Claim: Fine-tuning on behaviorally-guided data distributions captures nuanced human error patterns in function composition.
- Mechanism: Injecting noise into function order during training (synthetic data) or using actual human responses (raw data) adjusts model outputs to reflect human-like mistakes.
- Core assumption: Human errors are systematic and can be modeled by perturbing ground truth outputs in training data.
- Evidence anchors:
  - [abstract] "model generations further captured nuanced error patterns observed in human-generated function outputs"
  - [section] "we created a synthetic data distribution S containing 2,000 episodes that is human behaviorally-guided"
- Break condition: If fine-tuning does not improve log-likelihood on held-out human data or error patterns remain unrepresentative.

## Foundational Learning

- Concept: Tree-based representation of visual objects
  - Why needed here: Functions are defined as edits to car objects represented as trees; understanding tree operations is essential for defining and applying functions.
  - Quick check question: How would you represent adding a window to a car as a tree edit operation?

- Concept: Function interaction types (feeding, counter-feeding, bleeding, counter-bleeding)
  - Why needed here: The study systematically tests all four interaction types to evaluate composition sensitivity; understanding these distinctions is crucial for interpreting results.
  - Quick check question: In bleeding, why does the first function remove the context for the second function to apply?

- Concept: Meta-learning and few-shot generalization
  - Why needed here: Both humans and models are evaluated on zero-shot composition after limited exposure; understanding meta-learning principles explains the experimental design and results.
  - Quick check question: What distinguishes meta-learning from standard supervised learning in the context of function composition?

## Architecture Onboarding

- Component map: Flattened car string -> Encoder (2-layer Transformer with 8 heads) -> Support examples -> Decoder (2-layer Transformer with 8 heads) -> Output car string
- Critical path: Input car → flatten to string → concatenate with function handles → encode with support examples → decode to output car
- Design tradeoffs: Using standard Transformers without explicit symbolic reasoning capabilities versus specialized architectures for function composition; meta-learning requires extensive episode generation versus direct training
- Failure signatures: Model accuracy drops below human levels; error patterns don't match human structural mistakes; training fails to converge on function composition tasks
- First 3 experiments:
  1. Test base MLC model accuracy on held-out function triplets without fine-tuning
  2. Evaluate model error patterns against human error types (function mismatch, input copying, feature mismatch)
  3. Compare log-likelihood of human-generated data under base versus fine-tuned models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do different age groups show varying performance across the four function interaction types, with some interactions being mastered earlier than others?
- Basis in paper: [explicit] The paper mentions that extending the study to evaluate populations at various developmental stages might help elucidate if certain function interaction types are indeed harder to grasp, noting that counter-feeding is demonstrated to be an infant behavior before the onset of function composition skills.
- Why unresolved: The current study only examined adult participants, so developmental trajectories across interaction types remain unknown.
- What evidence would resolve it: Longitudinal studies testing children at different ages on the same function composition tasks, comparing performance patterns across feeding, counter-feeding, bleeding, and counter-bleeding conditions.

### Open Question 2
- Question: How would alternative input representations (e.g., raw images or tree structures) affect model performance and human-model behavioral alignment?
- Basis in paper: [explicit] The paper suggests that extending the current study to evaluate populations at various developmental stages might help elucidate if certain function interaction types are indeed harder to grasp, and notes that sequences used by the model can be translated into other representational formats such as raw images or tree structures.
- Why unresolved: The study used string representations for both humans and models, but the authors acknowledge that raw images (what human participants actually observed) or tree structures (without arbitrary ordering) might yield different results.
- What evidence would resolve it: Training the MLC model on raw image inputs or tree-structured representations, then comparing both performance and error patterns to human data on the same tasks.

### Open Question 3
- Question: What is the relationship between the meta-learning approach and Bayesian priors in capturing human compositional generalization?
- Basis in paper: [explicit] The paper mentions that instead of modeling the learning process, the goal is to model human inductive biases by forming a generative process over systems of functions (equivalent to a Bayesian prior) and using samples from this process as meta-learning episodes.
- Why unresolved: While the paper draws an explicit connection between the meta-learning approach and Bayesian priors, it doesn't explore whether this relationship could be made more explicit or whether alternative Bayesian approaches might yield similar or better results.
- What evidence would resolve it: Direct comparison of the MLC model's performance with a Bayesian model that explicitly represents and updates priors over function compositions, examining whether the Bayesian approach captures human-like error patterns as effectively.

## Limitations
- The experimental design lacks direct control conditions testing whether explicit training on interaction types would improve performance
- The Transformer model achieves near-human accuracy despite using only a 2-layer architecture, raising questions about genuine compositional understanding
- Claims about meta-learning enabling genuine compositional generalization lack comparison with alternative approaches like Bayesian models

## Confidence

- **High confidence**: Human accuracy results (86.8% overall) and error pattern analysis showing systematic structural mistakes
- **Medium confidence**: Model accuracy (97.9%) and its ability to capture human-like error patterns through fine-tuning
- **Low confidence**: Claims about meta-learning enabling genuine compositional generalization without explicit symbolic reasoning

## Next Checks
1. Test model performance on out-of-distribution car object variations to assess whether compositional generalization extends beyond the training domain
2. Implement ablation studies comparing MLC with standard supervised learning to isolate the contribution of meta-learning to compositional success
3. Conduct human replication studies with varying levels of function complexity and interaction diversity to test the robustness of the zero-shot composition finding