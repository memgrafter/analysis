---
ver: rpa2
title: Multimodal Fusion Strategies for Mapping Biophysical Landscape Features
arxiv_id: '2410.04833'
source_url: https://arxiv.org/abs/2410.04833
tags:
- fusion
- features
- three
- class
- imagery
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies three strategies for fusing thermal, RGB, and
  LiDAR data in deep learning models for ecological landscape feature mapping. The
  methods compared are Early fusion (concatenating multimodal inputs), Late fusion
  (separately processing modalities then combining), and Mixture of Experts (using
  a gating network to adaptively weight modality-specific predictions).
---

# Multimodal Fusion Strategies for Mapping Biophysical Landscape Features

## Quick Facts
- **arXiv ID**: 2410.04833
- **Source URL**: https://arxiv.org/abs/2410.04833
- **Reference count**: 13
- **One-line primary result**: Three fusion strategies (Early, Late, Mixture of Experts) achieved similar overall performance for ecological landscape feature mapping, with Late fusion achieving highest AUC of 0.698

## Executive Summary
This paper investigates three strategies for fusing thermal, RGB, and LiDAR data in deep learning models for ecological landscape feature mapping. The methods compared are Early fusion (concatenating multimodal inputs), Late fusion (separately processing modalities then combining), and Mixture of Experts (using a gating network to adaptively weight modality-specific predictions). All three methods achieved similar overall performance with Late fusion obtaining the highest AUC of 0.698. However, their per-class performance varied significantly, with Early fusion achieving the best recall for rhino middens and water features, while Mixture of Experts performed best for termite mounds.

## Method Summary
The study compares three fusion strategies using ResNet-50 as the base architecture for mapping three biophysical landscape features (rhino middens, termite mounds, water) from multimodal aerial imagery. Early fusion concatenates all modalities into a 5-channel input processed by a modified ResNet-50. Late fusion uses separate ResNet-50s for each modality with concatenation at the feature level. Mixture of Experts employs separate ResNet-50s with a gating network to weight modality-specific predictions. Models were trained on a proprietary dataset from Kruger National Park with spatial train-validation-test splits, using Adam optimizer and macro-averaged precision, recall, F1-score, and AUC as evaluation metrics.

## Key Results
- Late fusion achieved the highest overall AUC of 0.698, though all three methods performed similarly
- Early fusion achieved the best recall for rhino middens (0.747) and water features (0.720)
- Mixture of Experts performed best for termite mounds (0.669 recall)
- The Mixture of Experts method provided interpretability through its modality weighting, showing LiDAR was most important for termite mounds while thermal was most important for water features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Early fusion works well for certain classes (middens, water) because the simple concatenation preserves direct modality relationships that Late fusion's separate processing might obscure.
- Mechanism: By combining all modalities at the input level before feature extraction, the model can learn joint representations that capture the intrinsic correlations between thermal, RGB, and LiDAR signals for those classes.
- Core assumption: The classes that benefit most from Early fusion have features that are directly correlated across modalities and can be effectively learned from the concatenated raw input.
- Evidence anchors:
  - [abstract] "Early fusion achieved the best recall for middens and water"
  - [section] "we concatenate these three tiles to form a (5,400,400) array for each grid cell"
- Break condition: If the direct correlations between modalities for these classes are weak or if the input-level fusion creates noise that overwhelms the useful signal.

### Mechanism 2
- Claim: Mixture of Experts provides class-specific modality weighting that adapts to input characteristics, making it particularly effective for heterogeneous classes like termite mounds.
- Mechanism: The gating network learns to assign different weights to each modality based on the input features, allowing the model to emphasize LiDAR for tall mounds while de-emphasizing it for shorter ones.
- Core assumption: Termite mounds exhibit significant intra-class variation in their appearance across modalities, requiring adaptive weighting rather than fixed modality importance.
- Evidence anchors:
  - [abstract] "Mixture of Experts performed best for termite mounds"
  - [section] "the gating network makes it possible to weight the modalities differently for different inputs"
- Break condition: If the gating network overfits to training data or if the class characteristics are more uniform than assumed.

### Mechanism 3
- Claim: Late fusion achieves the best overall AUC by balancing the strengths of separate modality processing with appropriate fusion at the feature level.
- Mechanism: Separate ResNet-50 feature extractors for each modality learn modality-specific representations that are then combined, allowing each modality to be processed optimally before integration.
- Core assumption: The modalities contain complementary information that is best extracted through specialized processing before being combined.
- Evidence anchors:
  - [abstract] "Late fusion obtaining the highest AUC of 0.698"
  - [section] "The three sets of 256 features output by the three feature extractors are then concatenated"
- Break condition: If the separate processing creates modality-specific biases or if the concatenation at the feature level loses important cross-modal relationships.

## Foundational Learning

- Concept: Multimodal data fusion strategies (early, late, and mixture of experts)
  - Why needed here: The paper directly compares these three strategies to determine which is most effective for ecological landscape feature mapping
  - Quick check question: What is the key difference between early fusion and late fusion in terms of when modalities are combined?

- Concept: Transfer learning with ResNet-50
  - Why needed here: The authors use a pre-trained ResNet-50 as the base architecture for all three fusion methods to address limited training data
  - Quick check question: How did the authors modify the ResNet-50 architecture to handle the different input modalities?

- Concept: Class imbalance handling techniques
  - Why needed here: The dataset has severe class imbalance, with most cells being empty, requiring undersampling and oversampling strategies
  - Quick check question: What specific balancing strategy did the authors use for the training set?

## Architecture Onboarding

- Component map:
  - Early fusion: 5-channel input → modified ResNet-50 → class predictions
  - Late fusion: 3 separate ResNet-50s (1-channel, 3-channel, 1-channel) → concatenation → fully connected → class predictions
  - Mixture of Experts: 3 separate ResNet-50s → 3 separate classifiers → gating network → weighted sum → class predictions

- Critical path: For all methods, the critical path is the feature extraction and classification pipeline, with the main variation being when and how modalities are fused

- Design tradeoffs:
  - Early fusion: Simpler architecture but may lose modality-specific feature extraction
  - Late fusion: More parameters but allows specialized processing per modality
  - Mixture of Experts: Most complex but provides interpretability and adaptive weighting

- Failure signatures:
  - Early fusion: Poor performance on classes requiring specialized modality processing
  - Late fusion: May not capture direct modality correlations
  - Mixture of Experts: Overfitting due to additional parameters, or poor modality weighting

- First 3 experiments:
  1. Verify the modified ResNet-50 architectures handle the correct input dimensions for each fusion method
  2. Test the class balancing strategy on a small subset to ensure it creates the desired class distribution
  3. Validate the spatial train-validation-test split maintains geographic independence between sets

## Open Questions the Paper Calls Out
None

## Limitations
- The study evaluated performance on only one 284-hectare site in Kruger National Park, raising questions about generalizability to other ecosystems
- Severe class imbalance (only 0.3% of cells contained landscape features) required aggressive undersampling and oversampling
- Thermal and LiDAR data were upsampled to match RGB resolution, potentially introducing interpolation artifacts

## Confidence
- **High Confidence**: The experimental methodology (three fusion strategies, ResNet-50 architecture, evaluation metrics) is clearly specified and reproducible
- **Medium Confidence**: The interpretability claims for Mixture of Experts (LiDAR importance for termite mounds, thermal importance for water) are based on weight analysis but could be affected by model initialization
- **Low Confidence**: Generalization of performance metrics and modality importance to other ecological contexts or sites is not established due to single-site evaluation

## Next Checks
1. **Spatial Independence Validation**: Verify that the spatial train-validation-test split maintains true geographic independence by checking for spatial autocorrelation in prediction errors across the three sets
2. **Upsampling Artifact Analysis**: Compare model performance using different interpolation methods for thermal and LiDAR upsampling to ensure the observed results aren't artifacts of the upsampling procedure
3. **Cross-Site Transferability**: Test whether the trained models maintain performance when applied to landscape feature data from a different geographic region or ecosystem type, particularly for the Mixture of Experts method where modality importance may vary