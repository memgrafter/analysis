---
ver: rpa2
title: 'CODA: A COst-efficient Test-time Domain Adaptation Mechanism for HAR'
arxiv_id: '2403.14922'
source_url: https://arxiv.org/abs/2403.14922
tags:
- adaptation
- coda
- learning
- data
- feedback
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CODA addresses performance degradation in mobile HAR systems due
  to dynamic usage conditions and sensor variability. It introduces a cost-efficient,
  test-time domain adaptation mechanism based on nearest-neighbor models and active
  learning, enabling real-time adaptation directly on devices.
---

# CODA: A COst-efficient Test-time Domain Adaptation Mechanism for HAR

## Quick Facts
- arXiv ID: 2403.14922
- Source URL: https://arxiv.org/abs/2403.14922
- Reference count: 37
- Primary result: CODA achieves superior F1-scores across varying feedback ratios in HAR tasks with minimal computational overhead

## Executive Summary
CODA addresses performance degradation in mobile HAR systems due to dynamic usage conditions and sensor variability. It introduces a cost-efficient, test-time domain adaptation mechanism based on nearest-neighbor models and active learning, enabling real-time adaptation directly on devices. The method employs a clustering loss function and importance-weighted active learning to maintain data distribution structure while updating models incrementally. Evaluated on four datasets (phone, watch, and integrated sensors), CODA consistently outperforms baselines like random replacement and time-heuristic strategies, even without learnable parameters. For example, in PAMAP2, HHAR, WHAR, and TAPRINT datasets, CODA achieves superior F1-scores across varying feedback ratios, with minimal computational overhead (median latency increase of 7ms on LG, 2ms on HW, and 1ms decrease on TW smartwatches). These results demonstrate CODA's robustness, adaptability, and potential for unobtrusive, real-world HAR deployment.

## Method Summary
CODA is a test-time domain adaptation mechanism for HAR that operates as a nearest-neighbor cache with instance-based learning. The system maintains a fixed-size cache per class and updates it using importance-weighted active learning with a clustering loss function. When feedback is received, instances are inserted into the cache based on their importance probability, which is calculated from disagreement among pruned hypotheses. The clustering loss preserves intra-class similarity by maximizing the minimum distance between instances within each class. A retentive reweighting strategy with exponential temporal decay ensures recent instances have higher influence while allowing adaptation to drift. The method functions without learnable parameters, making it computationally efficient for mobile deployment.

## Key Results
- CODA achieves superior F1-scores across varying feedback ratios in PAMAP2, HHAR, WHAR, and TAPRINT datasets
- Computational overhead remains minimal (median latency increase of 7ms on LG, 2ms on HW, and 1ms decrease on TW smartwatches)
- CODA outperforms baselines including random replacement, time heuristics, and MetaSense across all tested scenarios
- The method maintains performance even with sparse feedback (down to 10% feedback ratio)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Nearest-neighbor cache adaptation with clustering loss preserves intra-class similarity while adapting to distribution drift.
- Mechanism: Maintains a fixed-size cache per class. When a new instance arrives with feedback, it is inserted into the cache using importance-weighted active learning. The clustering loss ensures that instances within a class form compact clusters by maximizing the minimum distance between the instance and its class members.
- Core assumption: Class-conditional clusters exist in the feature space and can be preserved via distance-based losses.
- Evidence anchors:
  - [abstract]: "By incorporating a clustering loss and importance-weighted active learning algorithm, CODA retains the relationship between different clusters during cost-effective instance-level updates, preserving meaningful structure within the data distribution."
  - [section]: "We operate under the assumption that instances with a shared label (e.g., walking) should exhibit greater similarity to each other and therefore should form a cluster."
  - [corpus]: Weak anchor. No directly comparable mechanism in corpus; closest is maxVSTAR, which uses edge adaptation but not nearest-neighbor with clustering loss.
- Break condition: If the feature space does not support clear cluster formation, the clustering loss becomes ineffective.

### Mechanism 2
- Claim: Importance-weighted active learning with rejection threshold ensures efficient cache updates under limited feedback.
- Mechanism: At each timestep, the system calculates an importance probability based on disagreement among pruned hypotheses. Instances with high importance are added to the cache with weight 1/p. This corrects for selection bias and allows adaptation even when feedback is sparse.
- Core assumption: The disagreement among hypotheses is a good proxy for instance importance under distribution shift.
- Evidence anchors:
  - [abstract]: "CODA functions as a 'cache' for human activity recognition using an instance-based model as the predictor."
  - [section]: "In response to this limitation, we propose a revised IWAL algorithm that incorporates feedback in a passive manner. Specifically, we tailor IWAL for an instance-based model, utilizing a distance-based loss function constrained by a flexible kernel."
  - [corpus]: Weak anchor. The corpus contains unsupervised domain adaptation approaches (e.g., M3BAT) but not active learning-based nearest-neighbor cache adaptation.
- Break condition: If feedback becomes extremely sparse (e.g., <1%), the importance estimation may become unreliable.

### Mechanism 3
- Claim: Retentive reweighting with monotonically decreasing temporal function preserves recent knowledge while adapting to drift.
- Mechanism: Each cached instance is assigned a temporal weight E(t) = exp(-Δt), where Δt is timesteps since arrival. This ensures that older instances decay in influence, allowing the model to adapt to new conditions without forgetting recent trends.
- Core assumption: Recent instances are more representative of the current data distribution under drift.
- Evidence anchors:
  - [abstract]: "By incorporating a clustering loss and importance-weighted active learning algorithm, CODA retains the relationship between different clusters during cost-effective instance-level updates."
  - [section]: "We also try to enhance the temporal sensitivity and propose to control the adaptation with reweighting function as follows... a monotonically decreasing function is empirically adopted in CODA."
  - [corpus]: Weak anchor. No corpus papers explicitly use temporal decay in instance-based adaptation.
- Break condition: If drift is cyclical, exponential decay may prematurely discard relevant older patterns.

## Foundational Learning

- Concept: Instance-based learning and nearest-neighbor classification
  - Why needed here: CODA's core predictor is a K-nearest-neighbor model operating on a dynamic cache. Understanding how distance metrics and voting schemes work is essential to reason about clustering loss and hypothesis pruning.
  - Quick check question: What happens to the nearest-neighbor decision boundary when the cache contains both old and new instances with conflicting labels?

- Concept: Active learning theory and importance weighting
  - Why needed here: The rejection-threshold subroutine in CODA is derived from importance-weighted active learning. Engineers must understand how disagreement in hypothesis space translates to instance importance.
  - Quick check question: Why does CODA use 1/p as the weight instead of p?

- Concept: Domain adaptation and concept drift
  - Why needed here: CODA addresses test-time domain adaptation where the data distribution changes after deployment. Understanding drift types (e.g., covariate shift vs. concept drift) helps diagnose failure modes.
  - Quick check question: How does CODA differ from traditional domain adaptation that requires labeled source and target domains?

## Architecture Onboarding

- Component map: Signal detection & preprocessing -> Feature extraction -> Distance-based classification -> Feedback trigger -> Importance evaluation (Rejection-Threshold) -> Cache update (Weighted ERM) -> Hypothesis generation
- Critical path: New instance arrives -> Compute distances to cache -> Predict label -> Receive feedback -> Evaluate importance -> Update cache with weighted insertion -> Retrain hypothesis space
- Design tradeoffs:
  - Fixed cache size vs. memory growth: Limits memory but may lose useful old instances.
  - Temporal decay vs. stability: Allows adaptation but may discard long-term patterns.
  - Distance kernel choice vs. adaptability: Linear kernel is lightweight; GAK preserves temporal alignment but is heavier.
- Failure signatures:
  - Sudden drop in F1-score: Cache may be corrupted or feedback rate too low.
  - High latency spikes: Kernel computation overhead or cache size mismanagement.
  - Model stagnation: Importance probability collapsing to near-zero; feedback loop broken.
- First 3 experiments:
  1. Simulate single-class drift: Feed a stream where one activity gradually shifts in feature space; measure F1 over time with/without CODA.
  2. Feedback sparsity sweep: Vary feedback ratio from 0.1 to 1.0; plot adaptation speed and final performance.
  3. Cache size sensitivity: Run same drift with cache sizes 10, 50, 100 per class; observe trade-off between adaptability and memory.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The clustering loss function's effectiveness under severe distribution shift with overlapping features remains uncertain
- Importance-weighted active learning assumes hypothesis disagreement is a reliable importance proxy, which may not hold in all drift scenarios
- Retentive reweighting with exponential decay could prematurely discard useful older instances in cyclical drift patterns

## Confidence

- **High Confidence**: Computational efficiency claims (7ms latency increase on LG smartwatch) and general framework of nearest-neighbor cache with importance-weighted updates are well-supported across four datasets
- **Medium Confidence**: Superiority over baselines is demonstrated, but ablation studies could be more thorough in isolating component contributions
- **Low Confidence**: Claim of working "without learnable parameters" needs scrutiny as importance-weighted updates involve evolving parameter-like structures

## Next Checks

1. **Feedback Sensitivity Analysis**: Conduct experiments varying feedback ratios from 0.1% to 1% to determine minimum feedback rate required for effective adaptation, particularly for challenging drift scenarios

2. **Temporal Pattern Robustness**: Test CODA on cyclical drift patterns where exponential decay might discard useful historical information, comparing against alternative decay functions like cosine annealing

3. **Cross-Dataset Generalization**: Evaluate CODA when trained on one dataset and adapted to a completely different dataset, measuring domain gap reduction and adaptation speed compared to traditional unsupervised domain adaptation methods