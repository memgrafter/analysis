---
ver: rpa2
title: LLM-Assisted Rule Based Machine Translation for Low/No-Resource Languages
arxiv_id: '2405.08997'
source_url: https://arxiv.org/abs/2405.08997
tags:
- sentence
- sentences
- translation
- english
- simple
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LLM-RBMT (LLM-Assisted Rule-Based Machine
  Translation), a new approach for translating no-resource languages using large language
  models (LLMs) to assist handcrafted rule-based translators. The authors apply this
  paradigm to create the first machine translator for Owens Valley Paiute (OVP), a
  critically endangered Indigenous American language.
---

# LLM-Assisted Rule Based Machine Translation for Low/No-Resource Languages

## Quick Facts
- arXiv ID: 2405.08997
- Source URL: https://arxiv.org/abs/2405.08997
- Reference count: 15
- This paper introduces LLM-RBMT, the first machine translator for Owens Valley Paiute using LLM-assisted rule-based translation.

## Executive Summary
This paper presents LLM-RBMT (LLM-Assisted Rule-Based Machine Translation), a novel approach for translating no-resource languages by using large language models to assist handcrafted rule-based translators. The authors apply this paradigm to create the first machine translator for Owens Valley Paiute (OVP), a critically endangered Indigenous American language. Their system includes an OVP sentence builder, an OVP-to-English translator, and an English-to-OVP translator, achieving 98% accuracy on randomly generated sentences.

## Method Summary
The LLM-RBMT approach uses large language models to bridge the gap between rule-based translation systems and natural language output without requiring the LLM to have direct knowledge of the target language. For OVP-to-English translation, the system encodes structured sentence information into English-only representations and uses few-shot prompting to transform this structured data into natural language. For English-to-OVP translation, complex sentences are decomposed into simple subject-verb and subject-verb-object structures, then translated using the available vocabulary. Semantic similarity via sentence embeddings is used to evaluate translation quality in the absence of parallel corpora.

## Key Results
- OVP-to-English translator achieved 98% accuracy on randomly generated sentences
- System successfully handles complex English sentences by breaking them into simpler components
- Translations often preserve semantic meaning even when vocabulary limitations prevent complete translation
- Semantic similarity scores provide meaningful evaluation signals for translation quality assessment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can effectively translate structured sentence information into natural language without direct knowledge of the target language.
- Mechanism: By providing the LLM with structured English representations of sentences (including subject, verb, tense, and proximity information), the model generates accurate translations using only its general language capabilities.
- Core assumption: The LLM has sufficient general language understanding to map structured representations to natural language without needing to "know" the target language.
- Evidence anchors:
  - [abstract] "Using this approach, the LLM never interacts directly with the target language. Rather, we rely on the LLM to tell us how to use the simple, rule-based translators to provide a translation as close as possible to the user's original input."
  - [section 3] "After the user creates a valid OVP sentence, we translate it by first encoding the following sentence information into an English-only (using vocabulary definitions) structured simple sentence... Then, we use few-shot prompting to encourage an LLM to transform the structured English data into a natural language sentence."
- Break condition: If the LLM cannot generalize from structured representations to natural language, or if the structured representation loses critical semantic information.

### Mechanism 2
- Claim: Semantic similarity via embeddings can effectively evaluate translation quality when parallel corpora are unavailable.
- Mechanism: The system computes semantic similarity between input sentences and various translation outputs (simple, comparator, backwards) using sentence embeddings, allowing quality assessment without ground truth translations.
- Core assumption: Semantic embeddings capture meaning sufficiently well to distinguish good translations from poor ones, even without reference translations.
- Evidence anchors:
  - [section 4] "To measure the quality of each translation, we compute the semantic similarity between the input sentence and: the set of simple sentences generated by the LLM-powered segmenter... the set of simple sentences with unknown vocabulary removed... the 'round-trip' English translation."
  - [section 4] "We computed the semantic similarity between all pairs of sentences in the dataset to establish a baseline for comparison. The mean semantic similarity between a pair of unrelated sentences was μ ≈ 0.574 with a standard deviation of σ ≈ 0.061."
- Break condition: If semantic embeddings fail to capture meaning differences, or if the baseline similarity makes it impossible to distinguish good translations.

### Mechanism 3
- Claim: Breaking complex sentences into simple structures enables translation of otherwise untranslatable inputs.
- Mechanism: The system uses LLMs to decompose complex English sentences into sets of simple subject-verb and subject-verb-object sentences that can be translated using the available vocabulary, then reconstructs meaning from these components.
- Core assumption: Meaning can be preserved through decomposition and reconstruction, even when the target language lacks vocabulary for all original concepts.
- Evidence anchors:
  - [section 4] "The translator works by first using an LLM to break the input sentence into a set of simple structured subject-verb and subject-verb-object sentences, discarding any adjectives, adverbs, prepositions, objects (except for direct objects), etc."
  - [section 4] "We encourage (through few-shot prompt engineering) the LLM to preserve as much semantic meaning as possible between the original sentence and the set of simple sentences."
- Break condition: If decomposition loses critical semantic information that cannot be recovered, or if the LLM fails to preserve meaning during segmentation.

## Foundational Learning

- Concept: Rule-based translation systems and their limitations
  - Why needed here: Understanding how handcrafted rules can translate simple sentences with limited vocabulary is essential for grasping the LLM-RBMT paradigm
  - Quick check question: What are the key advantages and disadvantages of rule-based translation compared to neural machine translation?

- Concept: Semantic similarity and embedding models
  - Why needed here: The evaluation methodology relies on computing semantic similarity between sentences using embedding models, which requires understanding how these models work
  - Quick check question: How do sentence embedding models like MiniLM differ from traditional word embeddings in capturing semantic relationships?

- Concept: Large language model prompting and few-shot learning
  - Why needed here: The system heavily relies on carefully crafted prompts and few-shot examples to guide LLM behavior for both translation and sentence segmentation
  - Quick check question: What are the key principles for designing effective few-shot prompts that achieve consistent results across different input types?

## Architecture Onboarding

- Component map: English sentence → LLM segmentation → Sentence builder (with available vocabulary) → OVP sentence → OVP-to-English translation → English output
- Critical path: English sentence → LLM segmentation → Sentence builder (with available vocabulary) → OVP sentence → OVP-to-English translation → English output
- Design tradeoffs:
  - Vocabulary limitation vs. translation accuracy: Expanding vocabulary improves translation quality but increases system complexity
  - Simple vs. complex sentence handling: Simple structures are reliably translatable, but complex sentences require lossy decomposition
  - Embedding model choice: Different models have varying effectiveness at capturing semantic similarity for evaluation
- Failure signatures:
  - Low comparator scores with high simple/backwards scores: Vocabulary limitations preventing full translation
  - Low simple scores: LLM failing to preserve meaning during sentence segmentation
  - Low backwards scores with high simple scores: OVP-to-English translation inaccuracies
- First 3 experiments:
  1. Test the OVP-to-English translator with 100 randomly generated sentences and measure accuracy to verify the core translation mechanism
  2. Evaluate semantic similarity scores between unrelated sentence pairs to establish baseline similarity distribution
  3. Translate a set of complex English sentences and analyze where meaning loss occurs in the pipeline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we quantify the "usefulness" of a partial translation when the vocabulary is incomplete?
- Basis in paper: [explicit] The paper discusses cases where simple and backwards scores are high but comparator scores are low, representing partial translations that preserve meaning despite missing vocabulary.
- Why unresolved: The paper doesn't provide a quantitative framework for measuring when a partial translation is "good enough" for language learning purposes versus when it's too incomplete to be useful.
- What evidence would resolve it: User studies with language learners evaluating different partial translation scenarios, coupled with a metric that balances semantic preservation against vocabulary coverage.

### Open Question 2
- Question: What is the optimal vocabulary size threshold for the OVP sentence builder to achieve a target translation quality?
- Basis in paper: [inferred] The paper shows that semantic similarity scores improve as more vocabulary is added, but doesn't determine when adding more words yields diminishing returns.
- Why unresolved: The paper demonstrates that vocabulary expansion improves translation quality but doesn't establish a stopping point or identify which types of words (verbs vs nouns vs modifiers) provide the most value.
- What evidence would resolve it: A systematic study varying vocabulary size and composition while measuring translation quality across different sentence types, identifying the point of diminishing returns.

### Open Question 3
- Question: How does the performance of LLM-RBMT compare to zero-shot or few-shot translation approaches for no-resource languages?
- Basis in paper: [explicit] The paper mentions that other approaches like RAG-based translation should be explored and that this is the first work on no-resource language translation.
- Why unresolved: The paper doesn't benchmark LLM-RBMT against alternative no-resource translation methods, making it difficult to assess whether the rule-based approach is optimal.
- What evidence would resolve it: Direct comparisons between LLM-RBMT and other no-resource approaches (zero-shot, few-shot, RAG-based) on the same OVP dataset using identical evaluation metrics.

## Limitations

- The system relies on a very small vocabulary of only 20 words, severely limiting real-world applicability
- Semantic similarity evaluation depends on embedding models that may not perfectly capture meaning for low-resource languages with unique linguistic features
- The 98% accuracy on generated sentences may not generalize to naturally occurring text with diverse vocabulary

## Confidence

*High Confidence:* The core mechanism of using LLMs to assist rule-based translation is well-demonstrated through the successful creation of the first OVP translator and the high accuracy on generated sentences.

*Medium Confidence:* The system's ability to handle real-world translation tasks beyond the limited vocabulary is less certain. The semantic similarity metric provides useful signals but may not perfectly distinguish between good and poor translations in all cases.

*Low Confidence:* The long-term effectiveness of this approach for actual language revitalization efforts, including community adoption and usability for language learners, remains to be seen.

## Next Checks

1. Test the complete translation pipeline on a corpus of naturally occurring OVP sentences (if available) or on other low-resource languages with larger vocabularies to assess real-world performance.

2. Conduct human evaluation studies comparing LLM-RBMT translations with those from human translators or other machine translation approaches for low-resource languages to validate the semantic similarity metric.

3. Perform ablation studies removing the LLM assistance to quantify the exact contribution of the LLM component versus the rule-based system alone.