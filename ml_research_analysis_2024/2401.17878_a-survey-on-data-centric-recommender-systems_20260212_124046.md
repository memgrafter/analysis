---
ver: rpa2
title: A Survey on Data-Centric Recommender Systems
arxiv_id: '2401.17878'
source_url: https://arxiv.org/abs/2401.17878
tags:
- data
- user
- recommendation
- data-centric
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey systematically reviews Data-Centric Recommender Systems
  (Data-Centric RSs), which shift focus from model-centric innovations to enhancing
  recommendation data quality and quantity. The paper identifies three key data issues:
  incompleteness, noise, and bias, and categorizes existing research addressing these
  problems.'
---

# A Survey on Data-Centric Recommender Systems

## Quick Facts
- arXiv ID: 2401.17878
- Source URL: https://arxiv.org/abs/2401.17878
- Reference count: 7
- Primary result: Systematic review of data-centric recommender systems focusing on improving data quality and quantity rather than model innovations

## Executive Summary
This survey provides a comprehensive overview of Data-Centric Recommender Systems (Data-Centric RSs), which shift focus from model-centric innovations to enhancing recommendation data quality and quantity. The paper identifies three key data issues—incompleteness, noise, and bias—and categorizes existing research addressing these problems. It explores methods for attribute completion using graph neural networks, interaction augmentation through negative sampling or generative models, denoising techniques including reweighting and dataset distillation, and debiasing approaches using causal methods and inverse propensity scoring. The survey also highlights future directions such as leveraging multimodal data, large language models, automated methods, and transparent Data-Centric RSs.

## Method Summary
The survey systematically categorizes research on Data-Centric Recommender Systems by the type of data issue they address. For incomplete data, methods include attribute completion using graph neural networks that leverage topological structures in user-item graphs and knowledge graphs, as well as interaction augmentation through negative sampling or generative models. To handle noisy data, techniques involve reweighting, selection-based denoising, and dataset distillation. For biased data, approaches include user preference alignment via causal methods and item popularity alignment using inverse propensity scoring or counterfactual reasoning. The paper reviews existing literature without providing original experimental results.

## Key Results
- Data-centric approaches can outperform model-centric ones when data quality is the limiting factor by enhancing data through completion, augmentation, denoising, and debiasing
- Multimodal data integration can significantly improve recommendation relevance by incorporating heterogeneous data sources
- Large Language Models can serve dual roles as recommendation models and data processors for completing missing attributes and augmenting data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data-centric methods can outperform model-centric ones when data quality is the limiting factor
- Mechanism: Enhancing the data (completing missing attributes, augmenting interactions, denoising, debiasing) shifts the upper bound of model performance, allowing simpler models to reach higher accuracy
- Core assumption: The data bottleneck is more severe than the model bottleneck in modern recommender systems
- Evidence anchors: Abstract mentions moving spotlight from model-centric to data-centric efforts; section states data dictates upper limits of model capabilities
- Break Condition: If model capacity is already saturated or data quality improvements are negligible, further data-centric efforts yield diminishing returns

### Mechanism 2
- Claim: Multimodal data integration can significantly improve recommendation relevance
- Mechanism: By incorporating heterogeneous data sources (text, images, audio), the system can capture richer user preferences and item characteristics, overcoming limitations of interaction-only data
- Core assumption: Additional modalities are informative and not redundant with existing data
- Evidence anchors: Section defines multimodal data as consisting of multiple modalities or types of information
- Break Condition: If modality integration introduces significant noise or computational overhead without corresponding performance gains, the approach may be counterproductive

### Mechanism 3
- Claim: Large Language Models can serve dual roles as recommendation models and data processors
- Mechanism: LLMs can generate personalized recommendations and augment/reprocess existing data to address incompleteness, noise, and bias
- Core assumption: LLMs have sufficient domain knowledge and reasoning capability to be effective in these roles
- Evidence anchors: Section mentions leveraging LLMs to complete missing attributes given their extensive knowledge base and reasoning capabilities
- Break Condition: If LLM usage is constrained by token limits, latency, or introduces privacy risks, their effectiveness may be limited

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GNNs are used for attribute completion by leveraging topological structures in user-item graphs and knowledge graphs
  - Quick check question: How do GNNs aggregate information from neighboring nodes to complete missing attributes?

- Concept: Negative Sampling in Collaborative Filtering
  - Why needed here: Negative sampling is a key technique for interaction augmentation, helping to characterize user preferences by identifying uninteracted items as dislikes
  - Quick check question: What are the differences between random, popularity-based, and hard negative sampling strategies?

- Concept: Causal Inference for Debiasing
  - Why needed here: Causal methods are used to align biased training distributions with unbiased test distributions by identifying and mitigating effects of popularity bias
  - Quick check question: How can causal graphs help in understanding and addressing shifts in user preferences or item popularity?

## Architecture Onboarding

- Component map: Data Enhancement Layer → Recommendation Model Layer → Evaluation Layer
- Critical path: Data → Enhancement → Model Training → Evaluation
- Design tradeoffs:
  - Complexity vs. Performance: More sophisticated data enhancement may improve results but increase computational cost
  - Privacy vs. Completeness: Augmenting user profiles or interactions may improve recommendations but raise privacy concerns
  - Transparency vs. Black-box: Complex data enhancement methods may be less interpretable
- Failure signatures:
  - Data augmentation leads to overfitting on synthetic data
  - Denoising removes too much signal, harming model performance
  - Debiasing methods introduce new biases or information leakage
- First 3 experiments:
  1. Implement attribute completion using GNNs on a user-item bipartite graph and evaluate completion accuracy
  2. Compare different negative sampling strategies (random, popularity-based, hard) on a collaborative filtering task
  3. Apply causal debiasing methods to a biased dataset and evaluate performance on temporal and popularity split test sets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop more effective methods to handle the heterogeneity and imbalance challenges in multimodal data for recommender systems?
- Basis in paper: [explicit] The paper identifies heterogeneity and imbalance as key challenges in multimodal data for recommender systems
- Why unresolved: While the paper acknowledges these challenges, it does not provide concrete solutions or methods to address them
- What evidence would resolve it: Empirical studies demonstrating improved performance on multimodal recommendation tasks using novel methods that effectively handle heterogeneity and imbalance

### Open Question 2
- Question: What are the optimal strategies for combining data-centric and model-centric approaches to achieve the best performance in recommender systems?
- Basis in paper: [explicit] The paper discusses the complementary nature of data-centric and model-centric approaches but does not provide concrete guidelines for their optimal combination
- Why unresolved: The paper highlights the potential benefits of combining both approaches but lacks specific strategies or empirical evidence to support the optimal integration
- What evidence would resolve it: Empirical studies comparing different combinations of data-centric and model-centric approaches and identifying the most effective strategies for various recommendation scenarios

### Open Question 3
- Question: How can we develop transparent data-centric recommender systems that provide insights into the enhancement process while maintaining model complexity and user privacy?
- Basis in paper: [explicit] The paper discusses the importance of transparency in data-centric recommender systems but does not provide concrete methods for achieving it
- Why unresolved: The paper identifies the need for transparency but lacks specific techniques or guidelines for developing transparent data-centric recommender systems
- What evidence would resolve it: Empirical studies demonstrating the effectiveness of transparent data-centric recommender systems in providing insights while maintaining model complexity and user privacy

## Limitations
- Limited quantitative performance comparisons between data-centric and model-centric approaches
- Lack of detailed implementation details or code for discussed methods
- Limited discussion of computational overhead and scalability concerns for data-centric approaches

## Confidence
- High: Data quality issues (incompleteness, noise, bias) are real problems in recommender systems
- Medium: Data-centric methods can address these issues and potentially improve recommendation performance
- Low: Specific effectiveness claims about multimodal data, LLMs, and automated methods require further empirical validation

## Next Checks
1. Implement a controlled experiment comparing model-centric vs. data-centric approaches on the same recommendation task to quantify performance differences
2. Conduct ablation studies on attribute completion methods to measure the marginal value of graph neural networks versus simpler imputation techniques
3. Evaluate the trade-offs between data augmentation benefits and computational costs across different dataset sizes and recommendation domains