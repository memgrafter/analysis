---
ver: rpa2
title: Which PPML Would a User Choose? A Structured Decision Support Framework for
  Developers to Rank PPML Techniques Based on User Acceptance Criteria
arxiv_id: '2411.06995'
source_url: https://arxiv.org/abs/2411.06995
tags:
- ppml
- data
- user
- privacy
- techniques
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a structured decision support framework to help
  developers select Privacy Preserving Machine Learning (PPML) techniques based on
  user acceptance criteria. The framework translates user preferences (e.g., ease
  of use, performance, privacy concerns) into measurable criteria for evaluating PPML
  methods like Federated Learning (FL), Local Differential Privacy (LDP), Metric Differential
  Privacy (MDP), Secure Multiparty Computation (SMPC), Homomorphic Encryption (HE),
  and Trusted Execution Environments (TEE).
---

# Which PPML Would a User Choose? A Structured Decision Support Framework for Developers to Rank PPML Techniques Based on User Acceptance Criteria

## Quick Facts
- arXiv ID: 2411.06995
- Source URL: https://arxiv.org/abs/2411.06995
- Reference count: 40
- The framework translates user acceptance criteria into measurable PPML characteristics, enabling developers to rank PPML techniques without requiring users to understand technical details

## Executive Summary
This paper presents a structured decision support framework that helps developers select Privacy Preserving Machine Learning (PPML) techniques based on user acceptance criteria. The framework addresses the challenge that users typically lack technical understanding of PPML methods while their acceptance is crucial for successful implementation. By translating user preferences (such as ease of use, performance, and privacy concerns) into measurable evaluation criteria, the framework enables systematic comparison of techniques like Federated Learning, Local Differential Privacy, Metric Differential Privacy, Secure Multiparty Computation, Homomorphic Encryption, and Trusted Execution Environments. Applied to a privacy-sensitive information detection use case, the framework demonstrated that FL+LDP achieved the highest user acceptance score of 0.523 compared to 0.485 for FL alone.

## Method Summary
The framework operates through a three-stage process: First, user acceptance criteria are collected through surveys (typically using AHP methodology) and translated into PPML characteristics via a binary mask matrix that maps 15 user criteria to 14 PPML characteristics. Second, developers define evaluation categories for each PPML characteristic and assign weights based on their relative importance for the specific use case. Third, PPML techniques are evaluated against these categories using binary or weighted scoring, and final technique scores are calculated by combining normalized user preference scores with technical evaluations through matrix operations. The approach enables systematic comparison while avoiding the need to survey users about technical PPML details directly.

## Key Results
- FL+LDP achieved the highest user acceptance score (0.523) when evaluated against user preferences in the privacy-sensitive information detection use case
- The framework successfully translated user acceptance criteria into technical PPML characteristics without requiring users to understand PPML details
- User-centered evaluation showed significant variation in technique rankings based on different preference weightings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework translates user acceptance criteria (UAC) into measurable PPML characteristics, enabling developers to make privacy decisions without requiring users to understand technical PPML details.
- Mechanism: A binary mask matrix Fij maps 15 UAC to 14 PPML characteristics, converting user preference scores into characteristic scores ci via dot product and normalization.
- Core assumption: The mapping between UAC and PPML characteristics is valid and comprehensive enough to capture user preferences for privacy decisions.
- Evidence anchors:
  - [abstract]: "we translate these criteria into differentiating characteristics for various PPML techniques"
  - [section 4.1]: "We build on the entities that were already introduced by Löbner et al. [45]. Therefore, we only provide a brief summary of our definitions."
- Break condition: If the mapping matrix Fij doesn't capture important user concerns or introduces significant bias in translation.

### Mechanism 2
- Claim: Weighted categories for PPML characteristics allow fine-grained evaluation that distinguishes between different PPML techniques based on specific use case requirements.
- Mechanism: Each PPML characteristic is divided into categories k with associated weights yi,k, and techniques are evaluated against these categories using binary or weighted scoring.
- Core assumption: Categories can be defined for each PPML characteristic that meaningfully differentiate between techniques for the specific use case.
- Evidence anchors:
  - [section 4.3.2]: "A crucial step is defining categories, denoted as k, for each PPML Characteristic"
  - [section 6.3.2]: "Next, we explain how we set up the categorical scales for the different PPML Characteristics"
- Break condition: If categories are too broad to distinguish techniques or too narrow to be practically applicable.

### Mechanism 3
- Claim: The final PPML technology score combines user preference weights with technical evaluation to rank techniques according to user acceptance criteria.
- Mechanism: The score et for each technique is calculated as the sum over all characteristics of the product of normalized user preference scores and the dot product of category evaluations and weights.
- Core assumption: The weighted combination of user preferences and technical characteristics produces a meaningful ranking that reflects user acceptance.
- Evidence anchors:
  - [section 4.5]: "We calculate the evaluation vectore so that ∀t : et := Σ˜ci · (XTi · yi)"
  - [section 6.5]: "The final scores ofe are shown in table 9"
- Break condition: If the weighting scheme over- or under-emphasizes certain characteristics relative to user priorities.

## Foundational Learning

- Concept: Matrix operations for mapping and scoring
  - Why needed here: The framework relies on matrix multiplication and vector operations to translate user preferences into PPML scores
  - Quick check question: Can you explain how the dot product of Fij and uj produces the PPML characteristic scores ci?

- Concept: Analytic Hierarchy Process (AHP) for preference elicitation
  - Why needed here: User preferences are collected through AHP surveys, which the framework then translates into PPML scores
  - Quick check question: What is the purpose of normalizing consistency ratios in AHP surveys?

- Concept: Privacy-preserving machine learning techniques
  - Why needed here: The framework evaluates six specific PPML techniques (FL, FL+LDP, MDP, SMPC, HE, TEE) and their trade-offs
  - Quick check question: What is the key difference between Local Differential Privacy and Metric Differential Privacy in the context of text data?

## Architecture Onboarding

- Component map: User input collection -> UAC to PPML characteristic translation -> Developer evaluation of PPML techniques -> Final score calculation -> Technology ranking
- Critical path: User input collection → UAC to PPML characteristic translation → Developer evaluation of PPML techniques → Final score calculation → Technology ranking
- Design tradeoffs: The framework trades technical precision for user accessibility by avoiding direct PPML questions to users, but this introduces complexity in mapping and requires expert validation of the translation process.
- Failure signatures: Poor mapping between UAC and PPML characteristics, incomplete category definitions for PPML techniques, or inappropriate weighting of categories can all lead to misleading rankings.
- First 3 experiments:
  1. Implement the framework with a simple use case (e.g., binary classification) and verify that changing user preferences produces different rankings
  2. Test the framework with known PPML technique strengths and weaknesses to validate the scoring logic
  3. Conduct sensitivity analysis by varying category weights to understand their impact on final rankings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the trade-off between accuracy and privacy be quantified in a standardized way across different PPML techniques?
- Basis in paper: [explicit] The paper discusses trade-offs between accuracy and privacy in techniques like FL+LDP and MDP, but notes the need for a standardized quantification method.
- Why unresolved: The paper highlights the existence of trade-offs but does not provide a method to quantify them consistently across techniques.
- What evidence would resolve it: Development of a universal metric or framework that allows direct comparison of privacy-accuracy trade-offs across all PPML techniques.

### Open Question 2
- Question: How can the framework be extended to incorporate B2B use cases and organizational user preferences?
- Basis in paper: [explicit] The authors mention this as future work, noting that their current framework focuses on B2C scenarios.
- Why unresolved: The framework's current design and evaluation criteria are tailored to individual users, requiring significant adaptation for organizational contexts.
- What evidence would resolve it: Case studies demonstrating successful application of the framework to B2B scenarios with appropriate modifications to evaluation criteria.

### Open Question 3
- Question: What is the optimal method for collecting user input that balances comprehensiveness with practical survey length?
- Basis in paper: [explicit] The authors note the challenge of surveying users about technical PPML characteristics while acknowledging they lack deep technical understanding.
- Why unresolved: The paper uses AHP with 55 participants but acknowledges this may not be optimal and doesn't provide guidance on balancing detail versus survey burden.
- What evidence would resolve it: Comparative studies of different survey methodologies showing optimal trade-offs between information richness and participant burden.

## Limitations
- The binary mask approach for mapping user criteria to technical characteristics may oversimplify complex relationships between user preferences and PPML capabilities
- The framework's effectiveness depends heavily on accurate category definitions and weight assignments, which may vary significantly across different application domains
- The study focuses on a single use case (privacy-sensitive information detection), limiting external validity of the findings

## Confidence
- Medium confidence in core claims due to dependence on accurate mapping and weight assignment, limited generalizability from single use case study

## Next Checks
1. Conduct expert validation study to assess accuracy of UAC-to-characteristic mapping and identify potential gaps or biases in the translation process
2. Apply the framework to at least two additional application domains (e.g., healthcare data sharing and financial fraud detection) to evaluate robustness across different privacy requirements
3. Perform systematic sensitivity analysis on category weights and user preference parameters to quantify their impact on final PPML technique rankings