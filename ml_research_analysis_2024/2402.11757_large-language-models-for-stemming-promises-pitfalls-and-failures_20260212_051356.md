---
ver: rpa2
title: 'Large Language Models for Stemming: Promises, Pitfalls and Failures'
arxiv_id: '2402.11757'
source_url: https://arxiv.org/abs/2402.11757
tags:
- stemming
- arxiv
- language
- stemmed
- contextual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explored the use of large language models (LLMs) for
  stemming words to their base forms within an information retrieval pipeline. Three
  approaches were devised: vocabulary stemming (stemming each unique word), contextual
  stemming (stemming words in context), and entity-based contextual stemming (identifying
  entities to avoid stemming them).'
---

# Large Language Models for Stemming: Promises, Pitfalls and Failures

## Quick Facts
- **arXiv ID:** 2402.11757
- **Source URL:** https://arxiv.org/abs/2402.11757
- **Reference count:** 39
- **Primary result:** Vocabulary and contextual LLM stemming degrade retrieval performance compared to traditional stemmers

## Executive Summary
This paper investigates whether large language models (LLMs) can effectively perform stemming - reducing words to their base forms - as part of an information retrieval pipeline. Three distinct approaches were developed: vocabulary stemming (stemming each unique word), contextual stemming (stemming words within their document context), and entity-based contextual stemming (identifying entities to avoid stemming them while stemming other words). The study systematically evaluates these methods against traditional stemmers like Porter and Krovetz across two standard IR datasets.

The experimental results reveal a nuanced picture. While direct vocabulary and contextual LLM stemming approaches consistently underperform traditional methods, the entity-based contextual approach shows promise. By combining LLM-based entity extraction with traditional stemming for non-entity words, this hybrid method achieves statistically significant improvements over Porter stemmer alone in certain cases, suggesting that LLMs may add value when their strengths in entity recognition are leveraged rather than attempting to replace traditional stemming entirely.

## Method Summary
The researchers developed three distinct LLM-based stemming approaches and evaluated them against traditional stemmers. The vocabulary stemming approach processed each unique word independently through the LLM to obtain its base form. The contextual stemming approach provided the LLM with the full document context when stemming each word, allowing for context-aware decisions. The entity-based contextual stemming approach first identified entities using the LLM, then applied traditional stemming to non-entity words while preserving entity forms.

These methods were tested using three different LLMs (ChatGPT, LlaMa-2, and SOLAR) on two standard IR datasets: Trec-Covid and Trec-Robust04-LAT. Performance was measured using standard IR effectiveness metrics including NDCG, MAP, and MRR, with comparisons made against established traditional stemmers like Porter and Krovetz.

## Key Results
- Vocabulary stemming and contextual stemming approaches consistently performed worse than traditional stemmers across all tested datasets
- Entity-based contextual stemming achieved statistically significant improvements over Porter stemmer alone in some cases
- The performance gap between LLM-based and traditional stemming methods was substantial, with traditional methods maintaining superiority in most scenarios
- No single LLM consistently outperformed the others across all approaches and datasets

## Why This Works (Mechanism)
The entity-based contextual approach succeeds because it leverages LLMs' strengths in semantic understanding and entity recognition while avoiding their weaknesses in morphological analysis. Traditional stemmers excel at systematic morphological reduction but cannot recognize named entities or domain-specific terms that should remain intact. By using LLMs to identify entities that should not be stemmed, then applying traditional stemmers to the remaining words, the hybrid approach combines the best capabilities of both methods.

The failure of direct vocabulary and contextual stemming stems from LLMs' tendency to over-generalize or produce inconsistent base forms. Unlike rule-based stemmers that apply systematic transformations, LLMs may interpret words semantically rather than morphologically, leading to base forms that don't match the query terms effectively. This semantic drift reduces the match between queries and documents, degrading retrieval effectiveness.

## Foundational Learning
- **Information Retrieval Pipeline**: The sequence of steps from query to ranked results; understanding this is crucial because stemming occurs early in the pipeline and affects all downstream processing
- **Stemming vs Lemmatization**: Stemming crudely chops word endings while lemmatization uses vocabulary and morphological analysis; this distinction matters because the paper evaluates against both approaches
- **Entity Recognition in IR**: Identifying named entities that should be preserved; critical because the successful approach depends on correctly identifying which words to protect from stemming
- **Evaluation Metrics (NDCG, MAP, MRR)**: Standard measures of retrieval effectiveness; necessary for understanding how performance is quantified and compared
- **Traditional Stemmers (Porter, Krovetz)**: Rule-based algorithms for reducing words to base forms; important as the baseline against which LLM methods are compared

Quick checks: Verify understanding of how stemming affects query-document matching, review the differences between stemming algorithms, and confirm familiarity with the standard IR evaluation metrics used.

## Architecture Onboarding
**Component Map:** Query -> Stemming Module -> Inverted Index -> Retrieval Engine -> Ranked Results

**Critical Path:** Document text → LLM entity recognition → Entity list → Traditional stemmer → Stemmed document → Indexing

**Design Tradeoffs:** 
- Accuracy vs. computational cost: LLM-based approaches require significantly more processing than traditional stemmers
- Context sensitivity vs. consistency: Contextual approaches may produce better individual decisions but less consistent overall stemming
- Entity preservation vs. matching breadth: Protecting entities improves precision but may reduce recall for related terms

**Failure Signatures:** 
- Reduced retrieval effectiveness when LLM produces inconsistent base forms
- Performance degradation when entity recognition fails or over-generates false positives
- Increased computational latency and resource consumption

**First Experiments:**
1. Test entity-based stemming on a small subset of documents to validate entity recognition quality
2. Compare stemmed output consistency between LLM and traditional approaches on identical vocabulary
3. Measure retrieval effectiveness impact of varying the entity recognition confidence threshold

## Open Questions the Paper Calls Out
The paper acknowledges several open questions regarding the generalizability of their findings. The experiments were limited to English datasets, leaving unknown how these approaches would perform on morphologically rich languages or domain-specific vocabularies. The computational overhead of LLM-based stemming was not quantified, making practical deployment assessment difficult. Additionally, the evaluation focused on retrieval effectiveness metrics without examining precision-recall trade-offs or term-level matching behavior, leaving questions about the mechanisms behind any observed improvements.

## Limitations
- Experiments were limited to English datasets, so performance on other languages remains unknown
- Computational overhead and resource requirements of LLM-based stemming were not measured
- Evaluation focused on retrieval effectiveness metrics without examining precision-recall trade-offs or term-level matching behavior
- The quality of entity extraction was not independently validated or analyzed for its impact on overall performance

## Confidence
- **High confidence**: The finding that vocabulary and contextual LLM stemming degrade retrieval performance compared to traditional stemmers, based on multiple dataset evaluations
- **Medium confidence**: The conclusion that entity-based contextual stemming can improve over Porter stemmer alone, as this was only statistically significant in some cases and depends heavily on entity extraction quality
- **Low confidence**: Claims about the general superiority of hybrid approaches across all retrieval scenarios, given the limited scope of testing

## Next Checks
1. Test entity-based contextual stemming on morphologically complex languages (e.g., Arabic, Finnish) to assess cross-linguistic validity
2. Measure and compare computational latency and resource consumption between LLM-based and traditional stemming approaches at scale
3. Conduct ablation studies isolating the impact of entity recognition quality versus stemming decisions on retrieval effectiveness