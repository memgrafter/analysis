---
ver: rpa2
title: 'BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated
  Learning'
arxiv_id: '2410.03281'
source_url: https://arxiv.org/abs/2410.03281
tags:
- learning
- local
- statistics
- global
- scaffold
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the performance degradation of Batch Normalization
  (BN) in Federated Learning (FL) when dealing with heterogeneous data across clients.
  The authors propose BN-SCAFFOLD, an extension of the SCAFFOLD algorithm that corrects
  client drift not only for model gradients but also for BN statistics using control
  variates.
---

# BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning

## Quick Facts
- arXiv ID: 2410.03281
- Source URL: https://arxiv.org/abs/2410.03281
- Reference count: 40
- Addresses BN statistics drift in FL with heterogeneous data across clients

## Executive Summary
This paper introduces BN-SCAFFOLD, a method that extends the SCAFFOLD algorithm to correct drift in Batch Normalization statistics during Federated Learning. The approach uses control variates to align client and server BN statistics, addressing the performance degradation that occurs when clients have heterogeneous data distributions. The authors provide a unified theoretical framework for analyzing convergence of variance reduction algorithms in BN-equipped deep neural networks and prove that BN-SCAFFOLD removes the bias introduced by BN statistics drift. Experiments demonstrate that BN-SCAFFOLD matches centralized training performance and outperforms existing FL methods including FedAvg, SCAFFOLD, FedBN, and FedTAN on multiple datasets while maintaining communication efficiency.

## Method Summary
BN-SCAFFOLD extends the SCAFFOLD algorithm by introducing control variates that correct both gradient and BN statistics drift. The method maintains local estimates of BN statistics at each client and server, updating them using a correction term based on the difference between client and server statistics. This correction is applied during local training and when sending updates to the server. The algorithm operates in a cross-silo FL setting where all clients participate in each global round. The theoretical analysis provides convergence guarantees for the method under non-IID data distributions, showing that the variance reduction technique removes the bias introduced by BN statistics drift. The implementation uses Nvidia Flare framework with ResNet-18 and DenseNet-121 architectures, trained with SGD optimizer on heterogeneous datasets.

## Key Results
- BN-SCAFFOLD matches centralized training performance on MNIST, CIFAR-10, and clinical mammography datasets
- Outperforms FedAvg, SCAFFOLD, FedBN, and FedTAN across all three datasets with 95% CI statistical significance
- Achieves state-of-the-art accuracy without the high communication cost of FedTAN
- Demonstrates effectiveness on clinical mammography data with 2-5 clients in cross-silo setting

## Why This Works (Mechanism)
BN-SCAFFOLD addresses the fundamental problem that Batch Normalization statistics drift between clients and server when data distributions are heterogeneous. During local training, each client computes BN statistics on its local data, which differ from the server's global statistics. When clients send gradients to the server, these gradients are computed using local BN statistics that don't match the server's, introducing bias. BN-SCAFFOLD uses control variates to estimate and correct this drift, aligning client and server statistics. The method introduces a unified theoretical framework that analyzes how variance reduction techniques can remove the bias introduced by BN statistics drift, proving that the correction term effectively eliminates this source of error and enables convergence to the optimal solution.

## Foundational Learning
- **Batch Normalization statistics drift**: Why needed - BN statistics computed on local data differ from global statistics when data is heterogeneous. Quick check - compare running mean/variance across clients vs server.
- **Control variates in variance reduction**: Why needed - corrects bias in stochastic gradients by reducing variance through auxiliary variables. Quick check - verify control variate variance reduction factor.
- **Cross-silo vs cross-device FL**: Why needed - determines client participation model and algorithm applicability. Quick check - confirm all clients participate in each round.
- **Non-IID data distributions**: Why needed - heterogeneity causes BN statistics drift and affects convergence. Quick check - measure label distribution skew across clients.
- **Lipschitz continuity**: Why needed - theoretical convergence analysis requires bounded gradient changes. Quick check - verify gradient norm bounds during training.

## Architecture Onboarding

**Component Map**: Client local training -> BN statistics computation -> Control variate correction -> Gradient update -> Server aggregation

**Critical Path**: Local client training with BN statistics computation → Control variate drift correction → Gradient computation → Server aggregation → Global model update

**Design Tradeoffs**: 
- All clients participate vs. partial participation (communication efficiency vs. control variate lag)
- Option I (server updates) vs. Option II (client updates) control variates (communication cost vs. computation)
- Local E steps vs. global R rounds (convergence speed vs. communication overhead)

**Failure Signatures**:
- Performance drops when E=1 local steps (check convergence rate term σ²₀/E)
- High variance in results with heterogeneous client data (verify bootstrapping for CI)
- Inconsistent performance across architectures (check BN implementation consistency)

**3 First Experiments**:
1. Compare BN-SCAFFOLD vs FedAvg on MNIST with 2 clients and strong non-IID distribution
2. Test BN-SCAFFOLD with different σ²_th thresholds on CIFAR-10 to find optimal correction sensitivity
3. Evaluate convergence speed with varying E local steps to validate theoretical bounds

## Open Questions the Paper Calls Out

**Open Question 1**: What is the theoretical upper bound on the Lipschitz constant J for BN statistics to ensure BN-SCAFFOLD's convergence when using option II? The paper provides the inequality M²J² < L²/3 but does not calculate specific values of J in practice.

**Open Question 2**: How does BN-SCAFFOLD perform when only a fraction of clients participate in each global round rather than all clients? The paper acknowledges this limitation, noting that partial participation adds lag in control variates that should translate into additional source of variability.

**Open Question 3**: Can the principle of BN statistics drift control be extended to stateless algorithms like MIME for cross-device federated learning? The authors argue this possibility but have not developed or tested such an extension.

**Open Question 4**: How does BN-SCAFFOLD compare to other normalization techniques (like Group Normalization) across different batch sizes and heterogeneity levels? The paper focuses on BN-based methods but does not directly compare different normalization strategies.

## Limitations
- Focuses on cross-silo settings with few clients rather than large-scale cross-device FL
- Assumes all clients participate in all global rounds, which adds lag in control variates
- Does not explore the impact of different local step counts (E) on convergence beyond theoretical analysis
- Specific experimental details like variance threshold values and heterogeneity quantification are underspecified

## Confidence

**High**: Theoretical convergence analysis framework; BN-SCAFFOLD outperforms FedAvg/SCAFFOLD on CIFAR-10 and MNIST; communication efficiency claims vs FedTAN

**Medium**: Claims of matching centralized performance; state-of-the-art results on clinical mammography; effectiveness across ResNet and DenseNet architectures

**Low**: Generalization to large-scale cross-device FL; exact impact of σ²_th choice on clinical results; performance with E=1 local steps

## Next Checks
1. Test BN-SCAFFOLD with varying σ²_th thresholds on clinical mammography to quantify sensitivity
2. Evaluate performance when E=1 local steps to validate theoretical convergence rate claims
3. Scale experiments to 50-100 clients to assess cross-device FL applicability