---
ver: rpa2
title: Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits
arxiv_id: '2403.03281'
source_url: https://arxiv.org/abs/2403.03281
tags:
- fusion
- credibility
- modality
- each
- predictive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multimodal fusion in discriminative
  learning, specifically focusing on understanding the reliability of each data source
  in noisy, multi-source domains. The authors propose a novel approach using probabilistic
  circuits (PCs) to combine predictive distributions over individual modalities while
  also defining a probabilistic measure to evaluate the credibility of each modality.
---

# Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits

## Quick Facts
- arXiv ID: 2403.03281
- Source URL: https://arxiv.org/abs/2403.03281
- Authors: Sahil Sidheekh; Pranuthi Tenali; Saurabh Mathur; Erik Blasch; Kristian Kersting; Sriraam Natarajan
- Reference count: 22
- Key outcome: Novel approach using probabilistic circuits to combine predictive distributions while evaluating modality credibility, demonstrating robust performance across multimodal datasets.

## Executive Summary
This paper addresses the challenge of multimodal fusion in discriminative learning by proposing a credibility-aware approach using probabilistic circuits (PCs). The method combines predictive distributions from individual modalities while defining a probabilistic measure to evaluate each modality's credibility. The approach leverages the tractable inference capabilities of PCs to model complex interactions between modalities and provide faithful credibility estimates. Experimental results demonstrate that this fusion method reliably infers credibility while maintaining competitive performance with state-of-the-art methods across various multimodal datasets.

## Method Summary
The proposed method uses probabilistic circuits as combination functions to fuse multimodal predictions while estimating modality credibility. The approach involves training separate unimodal predictors for each data source, then using PCs to model the joint distribution over unimodal predictions and target classes. Credibility is computed as the KL-divergence between conditional distributions, and two fusion strategies are proposed: Direct-PC (conditional inference) and Credibility-Weighted Mean (weighted combination). The complete model is trained end-to-end using cross-entropy loss.

## Key Results
- The proposed fusion method achieves competitive performance with state-of-the-art approaches across four multimodal datasets (CUB, NYUD, SUNRGBD, A V-MNIST)
- Credibility-aware fusion demonstrates robustness to noise, with the lowest performance decline when modalities are corrupted
- The method provides faithful credibility estimates that decrease for noisy modalities and increase for reliable ones
- Theoretical analysis establishes a lower bound between credibility and conditional entropy under marginal dominance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Probabilistic Circuits enable tractable credibility estimation by modeling the joint distribution over unimodal predictions and target class.
- Mechanism: PCs support exact inference of conditional and marginal probabilities, allowing computation of credibility as a divergence between conditional distributions.
- Core assumption: The PC structure is smooth, decomposable, and has leaf distributions with unimodal densities upper-bounded by unity.
- Evidence anchors:
  - [abstract]: "PCs are a class of generative models that are expressive enough to model complex distributions while tractable for exact inference."
  - [section 3.1]: "Probabilistic Circuits (PCs) are one such class of generative models that can model complex distributions while supporting tractable and linear time inference of conditional and marginal distributions."
  - [corpus]: Weak - corpus neighbors discuss credibility in LLMs but don't address the PC-based approach directly.
- Break condition: If PC structure loses smoothness or decomposability, tractability of credibility inference is lost.

### Mechanism 2
- Claim: Credibility is theoretically grounded in information theory through conditional entropy.
- Mechanism: Credibility is defined as the KL-divergence between conditional distributions over the target given all unimodal predictions versus all but one. This divergence is bounded below by negative conditional entropy.
- Core assumption: The model is Marginal Dominant, meaning marginals are lower bounded by the joint distribution.
- Evidence anchors:
  - [section 3]: "Theorem 3.1... The expected credibility Cj of a modality j in predicting the target Y, under a Marginal Dominant distribution is lower bounded by the negative of the conditional entropy..."
  - [appendix A]: Formal proof showing how marginal dominance leads to this bound.
  - [corpus]: Weak - corpus focuses on credibility in language models, not information-theoretic definitions.
- Break condition: If the model is not Marginal Dominant, the theoretical bound between credibility and conditional entropy breaks.

### Mechanism 3
- Claim: Credibility-aware fusion is robust to noise because it weights modalities based on their information contribution.
- Mechanism: The Credibility-Weighted Mean (CWM) combination function uses credibility scores to weight unimodal predictions, giving more weight to modalities with higher credibility (less noise).
- Core assumption: Credibility scores accurately reflect the information content and reliability of each modality.
- Evidence anchors:
  - [section 4.3]: "Figure 4 depicts the decline in test performance for the different fusion methods... our approach suffers the lowest decline in terms of both F1 score and AUROC, validating the robustness of our approach."
  - [section 4.2]: Experimental validation showing credibility scores decrease for noisy modalities.
  - [corpus]: Weak - corpus discusses credibility in LLMs but not specifically in the context of multimodal fusion robustness.
- Break condition: If credibility scores are inaccurate or fail to capture modality reliability, the robustness advantage is lost.

## Foundational Learning

- Concept: Probabilistic Circuits (PCs)
  - Why needed here: PCs provide tractable inference for joint and conditional distributions, enabling exact credibility computation.
  - Quick check question: What are the two key structural properties of PCs that enable tractable inference?

- Concept: Information Theory (Entropy and KL-Divergence)
  - Why needed here: Credibility is defined and bounded using information-theoretic measures (conditional entropy and KL-divergence).
  - Quick check question: How does the conditional entropy of a modality's prediction relate to its credibility?

- Concept: Marginal Dominance
  - Why needed here: This property ensures the theoretical bound between credibility and conditional entropy holds.
  - Quick check question: What does it mean for a probability distribution to be Marginal Dominant?

## Architecture Onboarding

- Component map: Multiple modalities -> Unimodal Predictors -> Probabilistic Circuit -> Fusion Functions -> Final multimodal prediction with credibility scores

- Critical path:
  1. Extract unimodal predictions using individual predictors
  2. Feed predictions into the PC
  3. Perform inference (conditional or weighted combination)
  4. Output final prediction and credibility scores

- Design tradeoffs:
  - PCs vs. Neural Networks: PCs offer tractable inference but may be less expressive than deep networks
  - Direct-PC vs. CWM: Direct-PC models complex dependencies but is more complex; CWM is simpler but assumes linear combination
  - Training complexity: Joint training of unimodal predictors and PC vs. separate training

- Failure signatures:
  - Poor performance: Could indicate issues with PC structure, unimodal predictors, or training process
  - Inaccurate credibility scores: May suggest violations of marginal dominance or issues with PC inference
  - Sensitivity to noise: Could indicate problems with credibility estimation or weighting scheme

- First 3 experiments:
  1. Implement unimodal predictors and verify they produce valid probability distributions
  2. Train a basic PC on synthetic data to ensure tractability of inference
  3. Test credibility computation on a simple two-modality dataset with controlled noise levels

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the proposed credibility measure behave under different divergence measures beyond KL-divergence?
  - Basis in paper: [explicit] The paper defines credibility using KL-divergence and mentions it can be unbounded, leading to normalization for comparison.
  - Why unresolved: The paper only uses KL-divergence for defining and evaluating credibility, without exploring alternative divergence measures like Jensen-Shannon or Hellinger distance.
  - What evidence would resolve it: Empirical comparison of credibility scores and fusion performance using different divergence measures on the same datasets.

- **Open Question 2**: What is the impact of the structural properties (smoothness, decomposability) of probabilistic circuits on credibility-aware fusion performance?
  - Basis in paper: [explicit] The paper states that PCs need to be smooth, decomposable, and have leaf distributions with unimodal densities upper-bounded by unity to be Marginal Dominant, which is required for the theoretical grounding of credibility.
  - Why unresolved: The paper does not provide experimental evidence showing how relaxing or enforcing these structural properties affects credibility estimation and fusion performance.
  - What evidence would resolve it: Controlled experiments comparing fusion performance with PCs having varying degrees of smoothness and decomposability.

- **Open Question 3**: How does the credibility-aware fusion method scale to domains with more than two modalities?
  - Basis in paper: [inferred] The paper focuses on multi-modal datasets with two modalities (e.g., image+text, RGB+Depth) but does not explore scenarios with three or more modalities.
  - Why unresolved: The theoretical framework and experimental evaluation are limited to bimodal fusion, leaving questions about scalability and performance in high-dimensional multi-modal settings.
  - What evidence would resolve it: Experiments on datasets with three or more modalities (e.g., video+audio+text) comparing credibility-aware fusion with other methods.

## Limitations
- The method's effectiveness relies heavily on maintaining specific PC structural properties (smoothness, decomposability) which may not hold across all datasets
- Scalability to many-modality scenarios (10+ data sources) remains unverified, with computational complexity growing with the number of modalities
- The Marginal Dominance property required for theoretical credibility bounds is assumed rather than empirically verified

## Confidence
- **High Confidence**: The core mechanism of using PCs for tractable credibility-aware fusion is well-established in the literature, and experimental results show consistent performance gains across multiple datasets
- **Medium Confidence**: The theoretical connection between credibility and conditional entropy under Marginal Dominance is mathematically sound, but practical implications of violating this assumption are not thoroughly explored
- **Medium Confidence**: Noise robustness claims are supported by synthetic noise injection experiments, but real-world noise patterns may be more complex than tested scenarios

## Next Checks
1. **Structure Sensitivity Analysis**: Systematically vary PC structural properties (smoothness, decomposability, leaf distribution bounds) and measure the impact on credibility estimation accuracy and fusion performance.

2. **Scalability Benchmark**: Test the method on synthetic datasets with increasing numbers of modalities (5, 10, 20) to identify performance degradation points and computational bottlenecks.

3. **Real-world Noise Testing**: Apply the method to multimodal datasets with naturally occurring noise (e.g., corrupted sensor data, varying audio quality) rather than synthetic noise injection to validate robustness claims in practical scenarios.