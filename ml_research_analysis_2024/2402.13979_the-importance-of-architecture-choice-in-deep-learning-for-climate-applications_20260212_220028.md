---
ver: rpa2
title: The Importance of Architecture Choice in Deep Learning for Climate Applications
arxiv_id: '2402.13979'
source_url: https://arxiv.org/abs/2402.13979
tags:
- climate
- shap
- amoc
- deeplift
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how well different neural network architectures
  can model the Atlantic Meridional Overturning Circulation (AMOC) under various climate
  scenarios. The authors use a physical box model to generate synthetic AMOC data
  under six different forcing setups, including linear and sinusoidal freshwater and
  temperature forcings, both stationary and nonstationary.
---

# The Importance of Architecture Choice in Deep Learning for Climate Applications

## Quick Facts
- arXiv ID: 2402.13979
- Source URL: https://arxiv.org/abs/2402.13979
- Authors: Simon Dräger; Maike Sonnewald
- Reference count: 40
- Primary result: Architecture choice critically affects reliability in nonstationary climate modeling, with dense architectures (MLP, Deep Ensemble) outperforming Bayesian Neural Networks for AMOC prediction.

## Executive Summary
This paper investigates how different neural network architectures model the Atlantic Meridional Overturning Circulation (AMOC) under various climate scenarios. Using a physical box model to generate synthetic AMOC data, the authors compare three architectures—MLP, Deep Ensemble, and Bayesian Neural Network—across six forcing setups. Results show that Bayesian Neural Networks consistently underperform, producing uncertain and biased predictions, while MLPs and Deep Ensembles generalize better and exhibit attribution patterns consistent with AMOC physics. The study reveals that dense architectures are more suitable than BNNs for capturing AMOC dynamics in nonstationary climate modeling.

## Method Summary
The study uses a Stommel box model to generate synthetic AMOC data under six forcing scenarios (F1-F6) with combinations of linear/sinusoidal and stationary/nonstationary freshwater and temperature forcings. Three neural network architectures (MLP, Deep Ensemble, Bayesian Neural Network) are trained on both physics-informed features (salinity, temperature differences) and autoregressive inputs. Models are trained for 120 epochs using the Adam optimizer. Performance is evaluated through prediction accuracy and feature attribution maps using DeepLIFT and SHAP to determine whether models learn underlying physics or merely imitate time-series patterns.

## Key Results
- Bayesian Neural Networks underperform compared to dense architectures, producing uncertain and biased predictions in nonstationary scenarios
- Deep Ensembles and MLPs show better generalization and attribution patterns consistent with AMOC physics
- "Spiking" prediction patterns near tipping points in autoregressive settings question recent claims of imminent AMOC collapse
- Physics-informed features lead to better AMOC predictions than autoregressive inputs by capturing causal structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BNNs fail in nonstationary climate scenarios because their latent space regularization prevents accurate modeling of abrupt state transitions like AMOC tipping points
- Mechanism: The Bayesian framework imposes a prior over network weights that acts as a regularizer, discouraging sharp, discontinuous predictions needed to capture tipping behavior
- Core assumption: The BNN's prior distribution and Monte Carlo sampling cannot adequately represent the attractor basin structure of the AMOC system
- Evidence anchors: "Our results show that Bayesian Neural Networks perform poorly compared to more dense architectures and care should be taken when applying neural networks to nonstationary scenarios such as climate projections."

### Mechanism 2
- Claim: Deep Ensembles outperform MLPs in AMOC prediction because they better capture the attractor basin structure through diverse model sampling
- Mechanism: By training multiple independent networks and averaging their predictions, Deep Ensembles effectively explore different regions of the weight space, representing different pathways through the AMOC's attractor basin
- Core assumption: The AMOC system has multiple stable states that need to be represented simultaneously for accurate prediction
- Evidence anchors: "Deep Ensembles consist of training multiple independent deep neural networks whose predictions are averaged during inference."

### Mechanism 3
- Claim: Physics-informed features lead to better AMOC predictions than autoregressive inputs because they capture the underlying causal structure rather than just temporal correlations
- Mechanism: Physics-informed features (salinity, temperature differences) directly represent the variables that drive AMOC dynamics through density differences
- Core assumption: The AMOC dynamics are fundamentally driven by density differences that can be captured through salinity and temperature measurements
- Evidence anchors: "The density ρi in each box of the Stommel model depends on Ti and Si and fundamentally affects q via the difference in ρi between both boxes."

## Foundational Learning

- Concept: Tipping point dynamics in nonlinear systems
  - Why needed here: Understanding AMOC tipping points is crucial for interpreting model predictions and identifying failure modes in nonstationary scenarios
  - Quick check question: What distinguishes a tipping point from a gradual transition in a dynamical system?

- Concept: Explainable AI (XAI) techniques for neural networks
  - Why needed here: Attribution methods (DeepLIFT, SHAP) are used to determine whether models learn physical understanding or merely imitate time series patterns
  - Quick check question: How do DeepLIFT and SHAP differ in their approach to feature attribution?

- Concept: Ensemble methods in machine learning
  - Why needed here: Deep Ensembles are shown to outperform single models, and understanding their mechanics is crucial for replication
  - Quick check question: What is the primary advantage of using multiple models versus a single model in ensemble methods?

## Architecture Onboarding

- Component map: Stommel box model → Feature extraction (physics-informed vs autoregressive) → Neural network (MLP, Deep Ensemble, BNN) → Prediction (q) → Attribution analysis (DeepLIFT, SHAP)
- Critical path: Generate synthetic AMOC data → Preprocess features → Train multiple architectures → Evaluate predictions → Analyze attributions
- Design tradeoffs: Physics-informed features capture causality but may miss temporal dependencies; autoregressive features capture temporal patterns but may include spurious correlations
- Failure signatures: BNN producing smooth, shifted predictions; high uncertainty bands during tipping points; attribution maps showing uniform feature importance
- First 3 experiments:
  1. Replicate F1 results with MLP using physics-informed features to establish baseline performance
  2. Compare MLP with Deep Ensemble on F2 to observe ensemble benefits
  3. Test BNN with different prior standard deviations on F1 to understand hyperparameter sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does varying the prior standard deviation in Bayesian Neural Networks affect their ability to learn the AMOC's physics versus merely imitating its time-series behavior?
- Basis in paper: Explicit - The paper conducts experiments varying the prior standard deviation (σ) of the BNN across six forcing scenarios and includes detailed results showing different outcomes for predictive performance and explainability
- Why unresolved: While the paper demonstrates that BNNs are sensitive to prior standard deviation, it does not establish a clear relationship between σ values and the network's ability to learn physics versus imitate patterns
- What evidence would resolve it: Systematic experiments mapping specific σ ranges to successful physics learning versus imitation behavior, along with corresponding attribution pattern analysis

### Open Question 2
- Question: Can more complex neural network architectures like Fourier Neural Operators or Graph Neural Networks successfully model AMOC dynamics in nonstationary climate scenarios while maintaining interpretability?
- Basis in paper: Explicit - The paper mentions FNOs and GNNs as potential alternatives but states they lack the ability to apply XAI methods like DeepLIFT and SHAP
- Why unresolved: The paper only tests MLP, Deep Ensemble, and BNN architectures, leaving the question of whether more complex architectures could perform better while still providing interpretable results unanswered
- What evidence would resolve it: Direct comparison studies using FNOs and GNNs on the same AMOC modeling tasks, evaluating both predictive performance and the development of new interpretability methods

### Open Question 3
- Question: What is the fundamental reason for the "spiking" prediction patterns near critical collapse points in autoregressive settings, and how can this phenomenon be addressed?
- Basis in paper: Explicit - The paper observes "spiking" behavior in autoregressive predictions near tipping points and raises concern about previous AMOC collapse predictions
- Why unresolved: While the paper identifies the spiking behavior and questions its implications, it does not determine whether this is due to model architecture limitations, the nature of autoregressive prediction, or genuine system dynamics near tipping points
- What evidence would resolve it: Detailed analysis of the spiking patterns across different forcing scenarios and architectures, combined with theoretical investigation of how autoregressive models handle critical transitions

## Limitations

- The study uses synthetic data from a simplified Stommel box model rather than observational AMOC data, which may not capture full system complexity
- BNN performance findings may be specific to hyperparameter choices rather than fundamental architectural limitations
- Attribution analysis using DeepLIFT and SHAP may not definitively prove that models have learned physical understanding versus statistical patterns

## Confidence

- **High confidence**: MLP and Deep Ensemble architectures can successfully model AMOC dynamics under various forcing scenarios when trained on physics-informed features
- **Medium confidence**: BNN architectures underperform due to regularization preventing capture of abrupt transitions in nonstationary regimes
- **Medium confidence**: Attribution patterns differ meaningfully between physics-informed and autoregressive approaches, suggesting distinct learning mechanisms
- **Low confidence**: The "spiking" prediction patterns near tipping points definitively indicate against imminent AMOC collapse

## Next Checks

1. **Hyperparameter Sensitivity Analysis for BNNs**: Systematically vary the prior standard deviation and Monte Carlo sampling parameters in BNN architectures to determine if performance can be improved

2. **Real Data Validation**: Apply the best-performing architectures (MLP and Deep Ensemble) to observational AMOC proxy data from the RAPID array or other sources to verify that synthetic data findings translate to real-world conditions

3. **Alternative Attribution Methods**: Implement additional XAI techniques such as Integrated Gradients or Layer-wise Relevance Propagation to cross-validate attribution findings and strengthen confidence in conclusions about physical understanding versus statistical learning