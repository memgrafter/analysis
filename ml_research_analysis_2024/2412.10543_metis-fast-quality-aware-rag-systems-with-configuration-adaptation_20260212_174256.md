---
ver: rpa2
title: 'METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation'
arxiv_id: '2412.10543'
source_url: https://arxiv.org/abs/2412.10543
tags:
- metis
- query
- configuration
- delay
- chunks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces METIS, the first system to optimize both
  quality and delay in RAG by jointly scheduling queries and adapting configurations
  on a per-query basis. The approach uses an LLM to estimate query profiles, then
  prunes the configuration space and jointly selects configurations and scheduling
  decisions based on available GPU resources.
---

# METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation

## Quick Facts
- arXiv ID: 2412.10543
- Source URL: https://arxiv.org/abs/2412.10543
- Reference count: 40
- Primary result: 1.64-2.54x lower response delay with maintained/improved quality

## Executive Summary
METIS is the first system to jointly optimize both quality and delay in Retrieval-Augmented Generation (RAG) systems through per-query configuration adaptation and intelligent scheduling. The system uses an LLM to estimate query profiles, then prunes the configuration space and jointly selects configurations and scheduling decisions based on available GPU resources. Across four RAG QA datasets, METIS achieves 1.64-2.54x lower response delay compared to state-of-the-art baselines while maintaining or improving generation quality, and provides 1.8-4.5x higher throughput.

## Method Summary
METIS optimizes RAG quality-delay tradeoffs by profiling each query to estimate complexity, joint reasoning needs, information requirements, and summarization length. This profile is mapped to ranges of three key RAG configurations (number of chunks, synthesis method, intermediate length), which are then jointly scheduled based on GPU memory availability. The system employs a two-level design: first pruning the massive configuration space to high-quality options, then selecting the best configuration that fits available GPU memory. The profiling overhead is minimal, adding at most 1/10th of total response delay.

## Key Results
- 1.64-2.54x lower response delay compared to state-of-the-art baselines
- 12-15% higher quality scores than static configuration approaches
- 1.8-4.5x higher throughput under Poisson query arrivals
- Profiling overhead adds at most 1/10th of total response delay

## Why This Works (Mechanism)

### Mechanism 1
METIS achieves significant delay reduction by jointly scheduling queries and adapting RAG configurations per-query. The LLM profiler estimates four high-level dimensions (complexity, joint reasoning needs, information pieces, summarization length) to narrow the configuration space from exponential to manageable. Within this pruned space, configurations and scheduling decisions are jointly optimized based on GPU memory availability.

Core assumption: Query profiles can be accurately estimated using metadata and the query itself, without requiring full context access.

### Mechanism 2
Per-query configuration adaptation provides substantial quality improvements by matching query complexity with appropriate RAG parameters. Different queries require different levels of inter-chunk reasoning and context chunks - simple queries can use lightweight synthesis methods while complex queries need more sophisticated approaches with additional context.

Core assumption: RAG queries naturally vary in complexity and require different levels of inter-chunk reasoning and context chunks.

### Mechanism 3
The two-level design (configuration pruning + joint scheduling) achieves loose coupling that enables efficient resource utilization. After initial pruning, quality configurations and scheduling decisions can be optimized separately, allowing METIS to adapt to varying GPU memory constraints without sacrificing quality.

Core assumption: Quality configurations and scheduling decisions can be optimized separately after initial pruning.

## Foundational Learning

- Concept: RAG system architecture (retrieval + synthesis phases)
  - Why needed here: Understanding how RAG systems work is fundamental to grasping why configuration tuning affects both quality and delay
  - Quick check question: What are the two main phases of a RAG system and how does each contribute to overall response delay?

- Concept: Query profiling and complexity estimation
  - Why needed here: METIS relies on accurately estimating query profiles to make configuration decisions
  - Quick check question: What four dimensions does METIS's LLM profiler estimate for each query?

- Concept: GPU memory management and batching in LLM serving
  - Why needed here: The joint scheduling optimization depends on understanding how different configurations consume GPU memory
  - Quick check question: How does the size of the input context affect GPU memory requirements for LLM inference?

## Architecture Onboarding

- Component map: LLM Profiler → Configuration Mapper → Joint Scheduler → RAG Executor → Feedback Loop
- Critical path: Query → Profiler → Configuration Mapper → Joint Scheduler → RAG Executor → Response
- Design tradeoffs:
  - Larger profiler LLM provides more accurate estimates but increases profiling overhead
  - More aggressive configuration pruning reduces search space but risks missing optimal configurations
  - Tighter GPU memory utilization improves resource efficiency but increases risk of queuing delays
- Failure signatures:
  - Consistently low profiler confidence scores (>90% threshold)
  - High GPU memory fragmentation preventing configuration fitting
  - Profiling overhead becoming significant fraction of total delay (>10%)
- First 3 experiments:
  1. Benchmark METIS with a single fixed configuration (num_chunks=5, synthesis_method=stuff) to establish baseline quality and delay
  2. Implement and test the LLM profiler with a small subset of queries to validate profile accuracy
  3. Measure GPU memory requirements for different configuration combinations to validate the best-fit algorithm

## Open Questions the Paper Calls Out

### Open Question 1
How would METIS perform when extended to multi-modal RAG systems that incorporate both text and image data? The paper theoretically discusses this extension suggesting METIS could profile queries asking for facts and supporting images, but lacks empirical evaluation on multi-modal datasets.

### Open Question 2
What is the optimal frequency for generating feedback prompts to improve the profiler's accuracy over time? The paper mentions generating feedback prompts "once every 30 queries" but acknowledges this as an area for future work without sensitivity analysis.

### Open Question 3
How would METIS perform with alternative embedding algorithms like all-Mpnet-base-v2 or text-embedding-3-large-256? The paper mentions testing alternatives in Appendix A.2 and found minimal impact on F1-score, but lacks detailed analysis of trade-offs.

### Open Question 4
What is the optimal confidence score threshold for determining when to trust the profiler's output? The paper uses a 90% threshold but states "This can be tuned for better performance" as future work without exploring how different thresholds affect overall system performance.

## Limitations
- Performance gains may not generalize to all serving frameworks and hardware configurations
- Assumes Poisson arrival patterns with specific rates, real-world patterns may be bursty
- Heavy GPU memory constraints can force fallback to fixed configurations, losing quality benefits

## Confidence

**High Confidence**: Per-query configuration adaptation mechanism is well-grounded and 12-15% quality improvement is supported by systematic evaluation across four datasets. Profiling overhead claim (<10% of total delay) is verifiable.

**Medium Confidence**: 1.64-2.54x lower response delay depends on specific baselines and hardware, and may vary significantly with different serving systems or GPU types. Joint scheduling effectiveness under heavy load requires further validation.

**Low Confidence**: 1.8-4.5x higher throughput assumes specific Poisson arrival patterns. Real-world bursty patterns may affect throughput benefits. Fallback mechanism effectiveness when profiler confidence <90% is not thoroughly validated.

## Next Checks

1. **Profiler Accuracy Validation**: Implement the LLM profiler with multiple prompt variations and metadata formats to empirically determine sensitivity of profile accuracy to prompt engineering choices. Measure confidence score distributions across diverse query types.

2. **Cross-Platform Benchmarking**: Reproduce METIS performance on different serving frameworks (TGI, SGLang) and GPU configurations (A100, H100) to validate whether the 1.64-2.54x delay improvement generalizes beyond vLLM baseline.

3. **Stress Testing Under Burst Traffic**: Evaluate METIS under bursty query arrivals (rather than Poisson distribution) with varying arrival rates to assess how well joint scheduling optimization maintains quality-delay tradeoffs when GPU memory becomes heavily contended.