---
ver: rpa2
title: 'How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study
  of ChatGPT, AI Models and Human Perception'
arxiv_id: '2411.09266'
source_url: https://arxiv.org/abs/2411.09266
tags:
- video
- detection
- chatgpt
- audio
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the capability of OpenAI's ChatGPT to detect
  audiovisual deepfakes and compares its performance with humans and state-of-the-art
  AI models. The research explores how different prompt designs affect ChatGPT's detection
  accuracy and interpretability.
---

# How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study of ChatGPT, AI Models and Human Perception

## Quick Facts
- arXiv ID: 2411.09266
- Source URL: https://arxiv.org/abs/2411.09266
- Reference count: 40
- ChatGPT achieves 65% accuracy on deepfake detection, comparable to humans but lower than specialized AI models (87.5%-97.5%)

## Executive Summary
This study investigates OpenAI's ChatGPT for audiovisual deepfake detection, comparing its performance against humans and state-of-the-art AI models. Using 40 videos from the FakeAVCeleb dataset with balanced gender representation, researchers tested ChatGPT-4 with various prompt designs. Results show that simple binary prompts yield poor performance, while context-rich prompts focused on specific artifacts and manipulations achieve higher accuracy. ChatGPT's accuracy of 65% matches human performance but falls significantly below specialized deepfake detection models. The study highlights the importance of prompt engineering and domain knowledge for effective LLM use in multimedia forensic tasks, while revealing limitations of traditional analysis techniques compared to deep learning approaches.

## Method Summary
The study used 40 videos (20 real, 20 fake) from the FakeAVCeleb dataset, with ChatGPT-4 processing each video using seven different prompt designs ranging from simple binary questions to detailed artifact-focused queries. Researchers extracted audio and video streams, performed traditional analysis using OpenCV and librosa libraries, and evaluated ChatGPT's predictions across multiple metrics including precision, recall, F1-score, accuracy, and rejection rate. Results were compared against human performance data and state-of-the-art AI model benchmarks from the literature.

## Key Results
- ChatGPT achieves 65% accuracy on deepfake detection, matching human performance (65.64%) but significantly lower than specialized models (87.5%-97.5%)
- Context-rich prompts focused on specific artifacts and manipulations outperform simple binary prompts
- ChatGPT relies on traditional analysis techniques rather than deep learning-based feature extraction, limiting comprehensive audiovisual analysis

## Why This Works (Mechanism)

### Mechanism 1
ChatGPT's performance improves significantly when prompts contain domain-specific artifact descriptions and require detailed output. The model leverages its multimodal training to analyze both visual and audio streams, but requires explicit guidance to focus on forensic artifacts rather than general content. Core assumption: ChatGPT has sufficient implicit knowledge about deepfake artifacts embedded in its training data to perform forensic analysis when properly prompted.

### Mechanism 2
ChatGPT achieves comparable accuracy to humans but lags behind specialized deep learning models because it relies on traditional analysis techniques rather than deep learning-based feature extraction. The model uses traditional computer vision and speech processing libraries for analysis, limiting its ability to extract sophisticated deep features that specialized models can learn. Core assumption: Traditional analysis techniques are insufficient for comprehensive deepfake detection compared to deep learning-based approaches.

### Mechanism 3
Multimodal input processing allows ChatGPT to detect inconsistencies across modalities that unimodal detectors miss, but this advantage is limited by the model's analysis methodology. The model performs joint analysis of audio and video to identify synchronization issues and cross-modal inconsistencies, but relies on traditional correlation features rather than learned multimodal representations. Core assumption: Cross-modal inconsistency detection is valuable for deepfake detection but requires sophisticated feature extraction.

## Foundational Learning

- **Prompt engineering for multimodal forensic analysis**: Why needed here - Simple prompts fail to leverage ChatGPT's capabilities, while context-rich prompts significantly improve performance. Quick check question: What specific elements should be included in prompts to maximize ChatGPT's deepfake detection accuracy?

- **Traditional vs deep learning-based feature extraction for multimedia forensics**: Why needed here - Understanding why ChatGPT underperforms specialized models requires knowledge of the fundamental differences in analysis approaches. Quick check question: How do traditional computer vision techniques compare to deep learning feature extraction for detecting subtle deepfake artifacts?

- **Cross-modal inconsistency detection in multimedia analysis**: Why needed here - The paper emphasizes ChatGPT's ability to analyze both modalities, but this advantage depends on effective cross-modal feature correlation. Quick check question: What types of audiovisual inconsistencies are most indicative of deepfake content?

## Architecture Onboarding

- **Component map**: Input video → Audio extraction → Visual frame extraction → Traditional analysis (OpenCV, librosa) → Multimodal consistency checking → Prompt-guided reasoning → Final prediction
- **Critical path**: Prompt design → Multimodal input processing → Traditional feature extraction → Cross-modal consistency analysis → Decision generation
- **Design tradeoffs**: Flexibility and interpretability of LLM approach vs. accuracy and sophistication of specialized deep learning models
- **Failure signatures**: High rejection rates indicate ineffective prompts; systematic bias toward one modality suggests correlation feature extraction issues
- **First 3 experiments**:
  1. Test prompt variations systematically to identify optimal prompt structure for different types of deepfake artifacts
  2. Compare ChatGPT's traditional analysis features against deep learning feature extraction on the same dataset
  3. Evaluate cross-modal inconsistency detection by creating controlled audiovisual mismatches and measuring detection accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How does ChatGPT's performance compare to state-of-the-art multimodal deepfake detection models when provided with prompts specifically engineered for audiovisual artifact detection? The paper shows ChatGPT achieves 65% accuracy with optimal prompts, while specialized models reach 87.5%-97.5% accuracy, but doesn't explore whether further prompt optimization could narrow this gap.

### Open Question 2
What specific types of audiovisual artifacts and manipulations are most challenging for ChatGPT to detect compared to specialized deepfake detection models? While the paper identifies general limitations of ChatGPT's approach, it doesn't systematically analyze which specific artifact types pose the greatest challenges.

### Open Question 3
How does the rejection rate of ChatGPT vary with different prompt designs, and what prompt characteristics minimize rejection while maximizing detection accuracy? The paper shows rejection rates range from 0% to 7.5% depending on prompt design, but doesn't explore the full parameter space of prompt characteristics.

## Limitations

- Small dataset size (40 videos) limits statistical power and generalizability across different deepfake techniques
- Reliance on a single benchmark dataset (FakeAVCeleb) may not capture full diversity of manipulation types
- Comparison assumes identical detection tasks but may not account for operational context differences

## Confidence

- **High confidence**: ChatGPT's performance is comparable to human accuracy but lower than specialized deep learning models
- **Medium confidence**: Context-rich prompts significantly outperform simple binary prompts for deepfake detection
- **Low confidence**: The specific mechanisms by which ChatGPT's traditional analysis techniques limit performance

## Next Checks

1. **Dataset Generalization Test**: Evaluate ChatGPT's performance on multiple deepfake detection benchmarks (e.g., DFDC, Celeb-DF) to assess robustness across different manipulation techniques and video qualities.

2. **Prompt Optimization Study**: Systematically explore the prompt engineering space using techniques like chain-of-thought prompting, few-shot examples, or adaptive prompting strategies to determine if higher accuracy is achievable.

3. **Cross-modal Analysis Validation**: Conduct controlled experiments creating specific audiovisual inconsistencies (e.g., lip-sync errors, audio-visual delays) to measure ChatGPT's sensitivity to cross-modal artifacts and compare against unimodal detection methods.