---
ver: rpa2
title: 'Llamipa: An Incremental Discourse Parser'
arxiv_id: '2406.18256'
source_url: https://arxiv.org/abs/2406.18256
tags:
- discourse
- llamipa
- relation
- structure
- link
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Llamipa, the first incremental discourse parser
  built by finetuning a large language model (LLM) on corpora annotated in the style
  of SDRT. The key innovation is using an incremental parsing strategy that leverages
  discourse context to predict both links and relation types between discourse units
  simultaneously, rather than using separate pipeline stages.
---

# Llamipa: An Incremental Discourse Parser

## Quick Facts
- arXiv ID: 2406.18256
- Source URL: https://arxiv.org/abs/2406.18256
- Reference count: 15
- Key outcome: Llamapa3 achieves up to 90% F1 for link prediction and 81% F1 for link+relation prediction on MSDC test data

## Executive Summary
This paper presents Llamapa, the first incremental discourse parser built by finetuning a large language model (LLM) on corpora annotated in the style of SDRT. The key innovation is using an incremental parsing strategy that leverages discourse context to predict both links and relation types between discourse units simultaneously, rather than using separate pipeline stages. The authors finetune Llama2 and Llama3 to produce Llamapa2 and Llamapa3 models that significantly outperform previous state-of-the-art parsers on both the link and link+relation tasks across multiple corpora including MSDC, STAC, and Molweni.

## Method Summary
Llamapa finetunes Llama2 and Llama3 models using QLoRA with specific hyperparameters (3 epochs, batch size 4, learning rate 2e-4) on discourse-annotated corpora. The incremental parsing strategy predicts links and relations simultaneously while maintaining a context window of 15 EDUs. The model processes discourse units one at a time, using the previously inferred discourse structure as input for new predictions. Training uses supervised finetuning on formatted data representing discourse structures, with evaluation on link prediction and link+relation prediction tasks using micro-averaged and weighted F1 scores respectively.

## Key Results
- Llamapa3 achieves 90% F1 for link prediction on MSDC test data
- Llamapa3 achieves 81% F1 for link+relation prediction on MSDC test data
- Llamapa shows substantial improvements over BERTLine baselines, particularly for long-distance relations like Narration and Correction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Llamapa's superior performance comes from its ability to process richer contextual information compared to local models.
- Mechanism: The incremental parsing strategy leverages discourse context to predict both links and relation types simultaneously, allowing the model to use the previously inferred discourse structure as input for new predictions.
- Core assumption: Discourse relations are context-dependent and require information beyond local EDU pairs to be accurately predicted.
- Evidence anchors:
  - [abstract] "Llamapa leverages discourse context, leading to substantial performance gains over approaches that use encoder-only models to provide local, context-sensitive representations of discourse units."
  - [section 6] "Llamapa shows impressive gains for predictions of certain relation types... the largest relative increase comes from improved predictions for Narration and Correction, which Thompson et al. (2024) cite as the most difficult to predict given that they are heavily context dependent."

### Mechanism 2
- Claim: Llamapa's ability to handle multiple parents for discourse units gives it an advantage over previous parsers.
- Mechanism: The model can identify cases where a single EDU has two parent EDUs, which arises naturally in multiparty and situated dialogue where a speaker can respond to multiple channels simultaneously.
- Core assumption: The data contains discourse units with multiple parents that are semantically meaningful and should be captured by the parser.
- Evidence anchors:
  - [abstract] "The model also handles complex structural features like multiple parents for discourse units that arise naturally in multiparty and situated dialogue."
  - [section 1] "Most current SDRT based parsers cannot handle such structures (Shi and Huang, 2019; Liu and Chen, 2021; Wang et al., 2021; Chi and Rudnicky, 2022)."

### Mechanism 3
- Claim: Llamapa's simultaneous prediction of links and relation types is more effective than pipeline approaches.
- Mechanism: By predicting both the attachment structure and relation labels at the same time, the model can capture informational dependencies between these decisions, leading to better overall performance.
- Core assumption: The decisions about where to attach a discourse unit and what relation type to use are interdependent and benefit from joint prediction.
- Evidence anchors:
  - [section 3] "BERTLine uses BERT embeddings for EDUs and EEUs, along with a linear layer for features like speaker change and distance information, to build a local model and predicts link and link+relation in pipeline fashion. However the relation labeling uses a multitask architecture to capture informational dependencies between link and relation labeling decisions."
  - [section 6] "Llamapa offers improvements over BERTLine for many other relation types which are typically not considered long distance."

## Foundational Learning

- Concept: Discourse parsing and SDRT
  - Why needed here: The paper builds on SDRT theory and requires understanding of discourse structure, elementary discourse units, and semantic relations.
  - Quick check question: What are the three main tasks in discourse parsing, and how does SDRT differ from RST?

- Concept: Incremental processing and context windows
  - Why needed here: Llamapa uses an incremental approach that processes discourse units one at a time while maintaining context, which is key to its performance.
  - Quick check question: How does an incremental parser differ from a pipeline parser, and why is a larger context window beneficial?

- Concept: LLM finetuning and prompt engineering
  - Why needed here: The paper finetunes Llama2 and Llama3 models, requiring understanding of how to adapt pre-trained LLMs for specific tasks.
  - Quick check question: What are the key considerations when finetuning an LLM for a structured prediction task like discourse parsing?

## Architecture Onboarding

- Component map:
  - Input sequence of EDUs/EEUs + gold/predicted discourse structure -> LLM backbone (Llama2/Llama3) -> Predicted links and relation types

- Critical path:
  1. Load and preprocess corpus data
  2. Format input samples with context and target relations
  3. Finetune LLM on the formatted data
  4. Evaluate on test set using gold/predicted structure

- Design tradeoffs:
  - Context window size vs. computational cost
  - Simultaneous vs. pipeline prediction of links and relations
  - Handling of multiple parents vs. simpler graph structures

- Failure signatures:
  - Poor performance on long-distance relations
  - Inability to predict multiple parents
  - Inconsistent link and relation predictions

- First 3 experiments:
  1. Reproduce baseline results using BERTLine on MSDC corpus
  2. Finetune Llama3 on MSDC and evaluate link+relation performance
  3. Test Llamapa's ability to predict multiple parents on multiparty data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Llamapa's performance scale with different sizes of the context window beyond the tested window size of 15?
- Basis in paper: [explicit] The authors mention using a window size k = 15 but do not explore larger window sizes.
- Why unresolved: The paper only tests Llamapa with a window size of 15, so the impact of larger context windows on performance is unknown.
- What evidence would resolve it: Experiments testing Llamapa with various context window sizes (e.g., 20, 25, 30) to determine if performance improves or plateaus.

### Open Question 2
- Question: What is the impact of automatically segmenting EDUs on Llamapa's performance, given that the current model assumes gold discourse unit segmentation?
- Basis in paper: [inferred] The paper mentions that existing work suggests automatic segmentation is relatively tractable but does not evaluate Llamapa with automatically segmented data.
- Why unresolved: The paper evaluates Llamapa with gold-standard segmentation, so the effect of segmentation errors on performance is not quantified.
- What evidence would resolve it: Experiments running Llamapa on automatically segmented data to measure the degradation in performance due to segmentation errors.

### Open Question 3
- Question: How does Llamapa handle long-distance discourse relations beyond distance 15, and what is the upper limit of relation distances it can effectively process?
- Basis in paper: [explicit] The paper mentions that Llamapa can handle relations up to distance 15 but does not test beyond this limit.
- Why unresolved: The paper only reports performance up to distance 15, so the model's effectiveness on even longer-distance relations is unknown.
- What evidence would resolve it: Experiments testing Llamapa on data with longer-distance relations (e.g., distances 16-25) to determine if performance degrades significantly or if the model can still capture these relations effectively.

## Limitations

- Restricted context window size (15 EDUs) may not capture all relevant discourse dependencies for very long dialogues
- Reliance on annotated corpora limits generalizability to domains without discourse annotations
- Paper doesn't adequately address potential biases introduced by training data or limitations in handling unrepresented discourse phenomena

## Confidence

**High Confidence**: The core claims about Llamapa3's superior performance on MSDC (90% F1 for links, 81% F1 for link+relation) are well-supported by the presented results and comparisons with BERTLine baselines.

**Medium Confidence**: Claims about Llamapa's ability to handle multiple parents and its advantages over pipeline approaches are supported by qualitative observations and some quantitative results.

**Low Confidence**: The paper doesn't adequately address potential biases introduced by the training data or limitations in handling discourse phenomena not present in the annotated corpora.

## Next Checks

1. **Context Window Sensitivity Analysis**: Systematically evaluate Llamapa's performance as context window size varies (e.g., 10, 15, 20 EDUs) to determine the optimal window size and identify at what point performance plateaus or degrades.

2. **Cross-Domain Transfer Evaluation**: Test Llamapa's performance on a truly out-of-domain corpus (e.g., news articles or scientific papers) to assess its generalizability beyond dialogue data and identify domain-specific limitations.

3. **Multiple Parents Frequency Analysis**: Quantify the actual frequency of multiple parent structures in each corpus and measure how often Llamapa successfully predicts these cases compared to baselines, providing concrete evidence for this claimed advantage.