---
ver: rpa2
title: Selected Languages are All You Need for Cross-lingual Truthfulness Transfer
arxiv_id: '2406.14434'
source_url: https://arxiv.org/abs/2406.14434
tags:
- language
- languages
- arxiv
- multilingual
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enhancing the truthfulness
  of large language models (LLMs) in multilingual settings. The authors propose a
  novel method called Fact-aware Multilingual Selective Synergy (FaMSS) to improve
  cross-lingual truthfulness transfer.
---

# Selected Languages are All You Need for Cross-lingual Truthfulness Transfer

## Quick Facts
- arXiv ID: 2406.14434
- Source URL: https://arxiv.org/abs/2406.14434
- Reference count: 34
- Addresses cross-lingual truthfulness transfer in LLMs through selective language synergy

## Executive Summary
This paper tackles the challenge of improving large language models' (LLMs) truthfulness across multiple languages by introducing the Fact-aware Multilingual Selective Synergy (FaMSS) method. The core insight is that not all languages contribute equally to cross-lingual truthfulness transfer, and selecting the optimal subset of languages can significantly enhance performance. FaMSS operates by first identifying the most beneficial languages based on language bias and transfer contributions, then employing translation instruction tuning using fact-aware multilingual data. This approach reduces multilingual representation disparity and boosts cross-lingual truthfulness transfer capabilities of LLMs.

## Method Summary
FaMSS introduces a two-step approach to cross-lingual truthfulness transfer. First, it employs a language selection mechanism that identifies an optimal subset of languages based on language bias metrics and transfer contribution scores. This selection process aims to minimize multilingual representation disparity while maximizing the potential for knowledge transfer across languages. Second, the method utilizes translation instruction tuning with fact-aware multilingual data, where the selected languages serve as pivots for transferring truthful knowledge to other target languages. The approach is designed to work effectively in both open-ended generation and multi-choice question-answering settings, providing a versatile framework for enhancing LLM truthfulness across linguistic boundaries.

## Key Results
- FaMSS achieves 2.5% to 9.7% improvement in True*Info scores on MTruthfulQA benchmark compared to baseline models
- The method demonstrates effectiveness across multiple languages including English, Chinese, French, German, Hindi, Italian, Japanese, Korean, Portuguese, Russian, Spanish, and Thai
- Robust performance observed in both open-ended generation and multi-choice question-answering settings

## Why This Works (Mechanism)
FaMSS works by strategically selecting languages that minimize representation disparity and maximize transfer potential. The language selection process identifies languages that serve as effective bridges for transferring truthful knowledge across linguistic boundaries. By focusing on these optimal languages and using them as pivots in translation instruction tuning, the method creates a more efficient pathway for cross-lingual knowledge transfer. This approach addresses the fundamental challenge that direct cross-lingual transfer between all language pairs is inefficient and can lead to knowledge dilution.

## Foundational Learning

Language Bias and Transfer Contribution: These metrics are essential for quantifying how well a language can serve as a source for transferring knowledge to other languages. Quick check: Calculate bias scores by comparing language-specific model performance to multilingual performance.

Multilingual Representation Disparity: This concept refers to the differences in how well various languages are represented in the model's internal representations. Quick check: Measure disparity using KL divergence between language-specific and multilingual model outputs.

Translation Instruction Tuning: A technique that fine-tunes models using translation tasks to improve cross-lingual capabilities. Quick check: Evaluate tuning effectiveness by measuring translation quality and downstream task performance.

Fact-aware Data: Multilingual datasets that are curated to contain factual information and minimize hallucinations. Quick check: Verify factuality using automated fact-checking tools and human evaluation.

Cross-lingual Transfer Learning: The process of applying knowledge learned in one language to improve performance in another language. Quick check: Measure transfer success through zero-shot or few-shot learning performance across languages.

## Architecture Onboarding

Component Map: Data Collection -> Language Selection (Bias & Transfer Contribution Analysis) -> Translation Instruction Tuning -> Cross-lingual Truthfulness Evaluation

Critical Path: The most crucial steps are the language selection process and the translation instruction tuning phase. These determine which languages are chosen as transfer sources and how effectively the truthful knowledge is transferred to target languages.

Design Tradeoffs: The method trades computational efficiency for improved cross-lingual performance by limiting the number of languages used in the transfer process. This selective approach reduces the complexity of the transfer task but may miss some language-specific nuances.

Failure Signatures: Potential failures include poor language selection leading to ineffective transfer, inadequate fact-aware data causing the model to learn false information, or overfitting to the selected languages during instruction tuning.

First Experiments:
1. Conduct language bias analysis across all available languages to identify potential candidates for selection
2. Perform ablation studies removing individual languages from the selected set to validate their contribution
3. Test translation instruction tuning effectiveness on a small subset of languages before scaling to the full set

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, focusing instead on presenting its solution and results. However, implicit questions remain regarding the generalizability of the approach to other truthfulness tasks and the long-term effectiveness of the language selection methodology as language dynamics evolve.

## Limitations
- Reliance on True*Info scores as the sole metric for evaluating truthfulness may not capture the full complexity of factual accuracy in multilingual contexts
- Potential biases introduced by fact-aware multilingual data used for translation instruction tuning
- Limited validation on a single benchmark (MTruthfulQA) raises questions about generalizability to other truthfulness tasks

## Confidence

High confidence in the methodological approach and implementation of FaMSS
Medium confidence in the cross-lingual transfer improvements due to limited evaluation on a single benchmark
Medium confidence in the language selection methodology, pending further validation on diverse language sets
Low confidence in long-term robustness across evolving linguistic landscapes

## Next Checks

1. Evaluate FaMSS on additional multilingual truthfulness benchmarks beyond MTruthfulQA to assess generalizability across different domains and knowledge types
2. Conduct ablation studies removing specific language subsets to verify the claimed importance of selected languages in the transfer process
3. Test the method's performance on low-resource languages not included in the original language selection to determine its effectiveness for truly underrepresented linguistic communities