---
ver: rpa2
title: Open Generative Large Language Models for Galician
arxiv_id: '2406.13893'
source_url: https://arxiv.org/abs/2406.13893
tags:
- language
- galician
- languages
- were
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first two open-source generative language
  models for Galician, addressing the lack of resources for this under-represented
  language. The models, Carballo-bloom-1.3B and Carballo-cerebras-1.3B, are built
  using continual pretraining from multilingual and monolingual base models, respectively.
---

# Open Generative Large Language Models for Galician

## Quick Facts
- **arXiv ID:** 2406.13893
- **Source URL:** https://arxiv.org/abs/2406.13893
- **Reference count:** 11
- **Primary result:** Introduces first open-source generative models for Galician, showing strong performance in human evaluations and task benchmarks

## Executive Summary
This paper presents the first open-source generative language models for Galician, addressing the significant gap in resources for this under-represented language. The authors developed two models, Carballo-bloom-1.3B and Carballo-cerebras-1.3B, through continual pretraining of multilingual and monolingual base models respectively. Trained on a 2.1 billion-word corpus, these models demonstrate promising capabilities in human evaluations and task-specific benchmarks, outperforming existing multilingual models in certain cases. The work highlights the effectiveness of continual pretraining for low-resource languages and emphasizes the importance of linguistic diversity in AI development.

## Method Summary
The authors developed two generative language models for Galician through continual pretraining. Carballo-bloom-1.3B was created by further training a multilingual base model, while Carballo-cerebras-1.3B was developed from a monolingual base model. Both models underwent training on a corpus of 2.1 billion words in Galician. The continual pretraining approach allowed the models to leverage existing multilingual knowledge while specializing in Galician language patterns. Human evaluations and task-based benchmarks were used to assess model performance, comparing results against existing multilingual models.

## Key Results
- First open-source generative models developed specifically for Galician language
- Models demonstrate strong performance in human evaluations and task-based benchmarks
- Outperformed existing multilingual models in certain evaluation scenarios

## Why This Works (Mechanism)
The success of these models stems from the continual pretraining approach, which allows models to build upon existing multilingual knowledge while specializing in Galician linguistic patterns. By training on a substantial corpus of 2.1 billion words, the models develop a robust understanding of Galician language structure, idioms, and usage patterns. The use of both multilingual and monolingual base models provides complementary strengths, with the multilingual approach offering broader linguistic context and the monolingual approach providing deeper specialization in Galician.

## Foundational Learning
- **Continual Pretraining**: Why needed - allows models to build on existing knowledge while specializing in target language; Quick check - compare performance gains against starting from scratch
- **Low-resource Language Modeling**: Why needed - addresses the lack of AI resources for under-represented languages; Quick check - evaluate model performance on diverse Galician text types
- **Human Evaluation Methods**: Why needed - essential for assessing language model quality in subjective tasks; Quick check - cross-validate human judgments across multiple evaluators
- **Task-specific Benchmarking**: Why needed - measures model performance on practical applications; Quick check - test on diverse Galician language tasks
- **Linguistic Diversity in AI**: Why needed - ensures fair representation of different languages in technology; Quick check - compare model performance across language families
- **Multilingual vs Monolingual Base Models**: Why needed - different approaches offer complementary strengths; Quick check - analyze performance differences between base model types

## Architecture Onboarding

**Component Map:** Base Model Selection -> Corpus Preparation -> Continual Pretraining -> Evaluation

**Critical Path:** The critical path involves selecting appropriate base models, preparing a high-quality Galician corpus, executing the continual pretraining process, and conducting comprehensive evaluations to validate model performance.

**Design Tradeoffs:** The authors balanced between using multilingual base models (offering broader linguistic context) and monolingual base models (providing deeper Galician specialization). They also had to consider the trade-off between model size and training efficiency, ultimately choosing 1.3B parameters as a practical compromise.

**Failure Signatures:** Potential failure modes include poor generalization to out-of-distribution text, inability to handle evolving language use, and saturation effects from the relatively modest corpus size. The models may also struggle with tasks requiring deep cultural or contextual understanding specific to Galician-speaking communities.

**First 3 Experiments:**
1. Evaluate model performance on a diverse set of Galician language tasks, including colloquial and emerging language use
2. Conduct cross-lingual transfer experiments to assess support for related Iberian languages
3. Investigate the impact of scaling up the pretraining corpus size on downstream task performance

## Open Questions the Paper Calls Out
Major uncertainties remain around the long-term robustness of these models, particularly their performance on out-of-distribution text and their ability to handle evolving language use in Galician. The evaluation relied heavily on human judgment and a limited set of task-specific benchmarks, which may not fully capture the models' capabilities or failure modes. Additionally, the models were trained on a relatively modest corpus of 2.1 billion words, raising questions about potential saturation effects or whether further pretraining could yield additional gains. The comparison with existing multilingual models, while promising, was not exhaustive and may not account for all relevant baselines.

## Limitations
- Reliance on human judgment and limited task-specific benchmarks may not fully capture model capabilities
- Training on a relatively modest corpus raises questions about potential saturation effects
- Comparison with existing multilingual models was not exhaustive and may miss relevant baselines

## Confidence
- **Novelty and significance of the first open-source Galician generative models**: High
- **Effectiveness of continual pretraining for low-resource languages**: Medium
- **Superior performance over existing multilingual models**: Medium

## Next Checks
1. Conduct systematic evaluation on a broader range of Galician language tasks, including those involving colloquial and emerging language use, to assess generalization.
2. Perform cross-lingual transfer experiments to determine whether these models can effectively support related Iberian languages or benefit from joint training.
3. Investigate the impact of scaling up the pretraining corpus size and diversity on downstream task performance and linguistic coverage.