---
ver: rpa2
title: 'Simplifying Translations for Children: Iterative Simplification Considering
  Age of Acquisition with LLMs'
arxiv_id: '2408.04217'
source_url: https://arxiv.org/abs/2408.04217
tags:
- words
- translation
- sentence
- translations
- sentences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of simplifying translations for
  children by controlling the Age of Acquisition (AoA) of words used. The proposed
  method iteratively replaces high-AoA words in translations with simpler alternatives
  using large language models (LLMs).
---

# Simplifying Translations for Children: Iterative Simplification Considering Age of Acquisition with LLMs

## Quick Facts
- arXiv ID: 2408.04217
- Source URL: https://arxiv.org/abs/2408.04217
- Authors: Masashi Oshika; Makoto Morishita; Tsutomu Hirao; Ryohei Sasano; Koichi Takeda
- Reference count: 12
- Key outcome: Proposed method effectively replaces high-AoA words with lower-AoA ones while maintaining high BLEU and COMET scores, successfully simplifying 97% of complex translations after five iterations

## Executive Summary
This paper addresses the challenge of simplifying translations for children by controlling the Age of Acquisition (AoA) of words used. The proposed method iteratively replaces high-AoA words in translations with simpler alternatives using large language models (LLMs). By providing a triple of the source sentence, the translation, and the target word to be replaced, the LLM can generate simplified sentences that maintain meaning while reducing complexity. Experimental results show that the method outperforms baseline approaches and achieves high success rates in simplification tasks.

## Method Summary
The method uses back-translation to create a benchmark dataset from Simple English Wikipedia, introducing controlled complexity by translating to Japanese and back to English. The core approach iteratively fine-tunes an LLM using LoRA adapters on a bilingual GPT-NeoX model. At each iteration, the LLM receives the source sentence, current translation, and a high-AoA target word, then generates a simplified version. The process repeats until the highest AoA in the sentence falls below the target threshold or no further simplification is possible.

## Key Results
- The method successfully replaced high-AoA words with lower-AoA alternatives while maintaining high BLEU and COMET scores
- After five iterations, the method simplified 97% of complex translations to meet the target AoA threshold
- Outperformed baseline methods including MUSS, Constraint Generation, Automatic Post-Editing, and Direct Translation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative word replacement guided by AoA and LLM reasoning preserves meaning while simplifying vocabulary
- Mechanism: The LLM receives a triple (source sentence, initial translation, target word) and is prompted to simplify the translation by replacing the target word. This process is repeated iteratively until the highest AoA in the sentence falls below the target threshold.
- Core assumption: LLMs can accurately identify and replace complex words while preserving the original meaning when provided with the source sentence and context.
- Evidence anchors:
  - [abstract] "Our method effectively replaces high-AoA words with lower-AoA words and, moreover, can iteratively replace most of the high-AoA words while still maintaining high BLEU and COMET scores."
  - [section] "LLMs are advanced language models that can reconstruct phrases containing high-AoA words, meaning they can significantly alter translations without changing their meanings."
- Break condition: The iterative process stops when the highest AoA in the sentence falls below the target threshold, or when no further simplification is possible without losing meaning.

### Mechanism 2
- Claim: Back-translation creates a suitable benchmark dataset by introducing controlled complexity
- Mechanism: Simple English Wikipedia articles are translated to an intermediate language (Japanese) and back to English, creating translations with higher AoA words than the original. These are paired with the original simple sentences as references.
- Core assumption: Back-translation introduces complexity bias that makes the translated sentences harder than the originals, creating suitable test cases for simplification.
- Evidence anchors:
  - [section] "Current machine translation systems often produce translations with high-AoA words due to biases in a training parallel corpora, even when the original sentences are intended for beginners."
  - [section] "We found that the highest AoA of the words in the back-translation is sometimes greater than those in the original reference sentences."
- Break condition: The process breaks when the AoA difference between source and target falls below the threshold (0.5 in experiments), or when sufficient data is collected.

### Mechanism 3
- Claim: Providing both source sentence and target word to LLM enables context-aware simplification
- Mechanism: The LLM is fine-tuned with prompts containing the source sentence, the current translation, and the target word to be replaced, allowing it to generate simplified sentences that maintain meaning while reducing complexity.
- Core assumption: LLMs can leverage source context to make more accurate word replacements than word-level substitution alone.
- Evidence anchors:
  - [section] "We fine-tuned an LLM to generate a simplified sentence from a given initial translation, the source sentence, and a word whose AoA is greater than the specific value in the translation."
  - [section] "This technique allows us to replace not only the target word but also the surrounding words within the context of the sentence, which helps to simplify the overall sentence while preserving its original meaning."
- Break condition: The process breaks when the LLM fails to generate valid output, or when the desired AoA threshold is met.

## Foundational Learning

- Concept: Age of Acquisition (AoA) as a measure of word complexity
  - Why needed here: AoA provides an objective metric to determine which words are too complex for the target age group, enabling systematic simplification
  - Quick check question: If a word has an AoA of 8, what age group is it most appropriate for?

- Concept: Back-translation and its bias effects
  - Why needed here: Understanding how back-translation introduces complexity bias is crucial for creating the benchmark dataset and interpreting results
  - Quick check question: Why would a back-translation of simple English likely contain more complex words than the original?

- Concept: Iterative refinement with LLMs
  - Why needed here: The iterative approach allows for progressive simplification of all complex words in a sentence, not just one
  - Quick check question: What happens if an LLM iteration doesn't reduce the highest AoA in the sentence?

## Architecture Onboarding

- Component map:
  Dataset creation pipeline: Simple English Wikipedia → MT to Japanese → MT back to English → AoA filtering → train/dev/test split
  LLM fine-tuning module: LoRA adapters on bilingual GPT-NeoX with custom prompts
  Simplification engine: Iterative loop that checks AoA and generates new simplified sentences
  Evaluation module: BLEU, COMET, SARI, FKGL, Dale-Chall, and custom AoA metrics

- Critical path:
  1. Load initial translation and source sentence
  2. Identify highest AoA word above threshold
  3. Generate simplified sentence via LLM with prompt
  4. Evaluate highest AoA in output
  5. If above threshold, repeat from step 2
  6. If below threshold or no change, return result

- Design tradeoffs:
  - Single-word vs multi-word replacement per iteration (single-word achieves better success rate)
  - Iterative vs one-shot simplification (iterative achieves better AoA reduction)
  - Source sentence inclusion (essential for meaning preservation)
  - Computational cost vs simplification quality (iterative approach is slower but more effective)

- Failure signatures:
  - Stuck in loop replacing same high-AoA words
  - BLEU/COMET scores drop significantly indicating meaning loss
  - LLM fails to generate output for certain sentences
  - Success rate plateaus below target threshold

- First 3 experiments:
  1. Test iterative simplification on a small sample with known AoA values to verify the process works end-to-end
  2. Compare single-word vs multi-word replacement strategies on a held-out validation set
  3. Evaluate the impact of including vs excluding the source sentence in LLM prompts on BLEU scores

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed iterative simplification method perform when the target age varies, and what are the optimal number of iterations for different age groups?
- Basis in paper: [explicit] The paper mentions that the target age was set to 10 years old but suggests it would be interesting to see the effect of varying the target age.
- Why unresolved: The paper only tested the method with a target age of 10 years old, and the impact of different target ages on the method's performance is not explored.
- What evidence would resolve it: Conducting experiments with different target ages (e.g., 5, 15, 20 years old) and analyzing the performance metrics (BLEU, COMET, Success Rate) for each age group would provide insights into the method's effectiveness across various age ranges.

### Open Question 2
- Question: Can the proposed method be effectively extended to languages other than English, such as Spanish, and how would the absence of an AoA list for certain languages affect the method's performance?
- Basis in paper: [explicit] The paper suggests extending the method to other languages like Spanish, which already has an AoA estimation, and mentions the possibility of using unigram probability in the corpus for languages without an AoA list.
- Why unresolved: The paper only focuses on simplifying English translations and does not provide experimental results or analysis for other languages.
- What evidence would resolve it: Implementing the method for languages like Spanish and comparing its performance with English, as well as testing the method on languages without an AoA list using unigram probability, would demonstrate its generalizability and effectiveness across different languages.

### Open Question 3
- Question: What are the computational cost implications of the proposed iterative simplification method, and how can it be optimized for faster processing without compromising performance?
- Basis in paper: [explicit] The paper mentions that the method requires an average of 0.5 seconds per iteration and suggests that the computation could be faster by distilling the LLMs or utilizing smaller LLMs.
- Why unresolved: The paper does not provide detailed analysis or experiments on optimizing the computational cost of the method.
- What evidence would resolve it: Conducting experiments to compare the processing time and performance of the method using different LLM sizes, distillation techniques, and optimization strategies would provide insights into how to balance computational efficiency and simplification quality.

## Limitations
- The back-translation approach for creating benchmark data may introduce artifacts that don't generalize to real-world translation scenarios
- The method's success heavily depends on the quality and coverage of the AoA word list, which is not fully specified
- The iterative process may get stuck in local optima where high-AoA words cannot be replaced without losing meaning

## Confidence

**High Confidence**: The core iterative mechanism of using LLMs for word replacement guided by AoA is well-established and the experimental methodology is sound. The reported success rates (97% after 5 iterations) and maintained translation quality metrics (BLEU, COMET) are convincing.

**Medium Confidence**: The back-translation benchmark creation method is reasonable but may introduce artifacts that inflate performance. The paper shows back-translations have higher AoA than originals, but doesn't fully characterize the nature of introduced complexity.

**Low Confidence**: The exact implementation details are sparse - the AoA word list source is unclear, training prompts are not provided, and the selection criteria for target words during iteration could affect results significantly.

## Next Checks
1. Test the iterative simplification method on human-generated translations with known complexity levels to verify performance outside the back-translation benchmark domain
2. Conduct ablation studies removing the source sentence from LLM prompts to quantify its contribution to meaning preservation versus computational overhead
3. Evaluate the method's performance on domain-specific content (technical documents, literature, etc.) to assess generalizability beyond Wikipedia-style text