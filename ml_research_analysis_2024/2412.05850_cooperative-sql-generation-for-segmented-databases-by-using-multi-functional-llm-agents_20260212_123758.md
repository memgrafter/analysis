---
ver: rpa2
title: Cooperative SQL Generation for Segmented Databases By Using Multi-functional
  LLM Agents
arxiv_id: '2412.05850'
source_url: https://arxiv.org/abs/2412.05850
tags:
- schema
- agents
- which
- agent
- database
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a cooperative SQL generation framework based
  on multi-functional agents for segmented databases. The method uses LLM-based agents
  that each hold a portion of the database schema, collaborating through information
  interaction to generate SQL queries for user questions.
---

# Cooperative SQL Generation for Segmented Databases By Using Multi-functional LLM Agents

## Quick Facts
- arXiv ID: 2412.05850
- Source URL: https://arxiv.org/abs/2412.05850
- Authors: Zhiguang Wu; Fengbin Zhu; Xuequn Shang; Yupei Zhang; Pan Zhou
- Reference count: 7
- Key outcome: Presents a cooperative SQL generation framework using multi-functional LLM agents for segmented databases, achieving high performance comparable to state-of-the-art approaches while maintaining data privacy.

## Executive Summary
This paper introduces a cooperative SQL generation framework (CSMA) that uses multiple LLM-based agents, each holding a portion of the database schema, to collaboratively generate SQL queries from natural language questions. The framework addresses data privacy concerns by keeping schema segments distributed while enabling agents to communicate relevant schema information for SQL generation. Through a three-stage process of schema collection, iterative SQL generation, and correctness checking, CSMA achieves competitive performance on benchmarks while maintaining data segmentation.

## Method Summary
The CSMA framework divides the database schema among multiple LLM agents, each responsible for a subset of the schema. When processing a user question, agents communicate to exchange schema elements relevant to the question, iteratively enriching their known schema. Each agent takes turns as the working agent, generating SQL based on its current schema knowledge, while subsequent agents check the correctness of the generated SQL. The process continues until the SQL passes correctness checking or a termination condition is met. The framework uses a retention mechanism with threshold δ to determine which schema elements to keep during the exchange process.

## Key Results
- Achieves high performance on Spider and Bird benchmarks, comparable to state-of-the-art approaches
- Maintains data privacy by keeping schema segments distributed among agents
- Demonstrates effectiveness of multi-agent collaboration for SQL generation in segmented databases
- Shows that performance generally declines with more agents, but fluctuates based on difficulty level

## Why This Works (Mechanism)

### Mechanism 1
Schema decomposition and agent specialization enable focused reasoning on relevant portions of the database. The database schema is divided among agents, each holding a subset. Agents communicate to exchange only the schema elements relevant to the user's question, expanding their "known schema" iteratively without needing the full schema. Core assumption: Relevant schema elements can be identified and exchanged efficiently without full schema visibility. Evidence anchors: [abstract] "LLM-based agents that each hold a portion of the database schema, collaborating through information interaction to generate SQL queries for user questions." [section] "In the first stage, agents analyze their respective schema and communicate with each other to collect the schema information relevant to the question."

### Mechanism 2
Iterative schema enrichment and SQL generation lead to progressive refinement of the query. Each agent takes turns as the "working agent," generating SQL based on its current known schema (private + global). The global schema is updated in each round, allowing agents to progressively discover missing schema elements and refine their SQL generation. Core assumption: SQL generation quality improves with more complete schema knowledge, and agents can iteratively converge on the correct query. Evidence anchors: [abstract] "agents try to generate the corresponding SQL query for the question using the collected information." [section] "due to the incompleteness and alteration of the schema knowledge of agents, the task for them is trying to generate SQL for the question from their own perspective iteratively."

### Mechanism 3
Agent-based SQL correctness checking enables decentralized validation without centralized schema access. After each SQL generation, the next agent checks the correctness of the generated SQL against its known schema. This distributed checking allows the system to determine when to terminate without requiring any agent to have the complete schema. Core assumption: Agents can accurately validate SQL syntax and semantics against their partial schema knowledge. Evidence anchors: [abstract] "agents check if the SQL query is created correctly according to their known information." [section] "To judge the correctness of generated SQL queries, they are fed to and checked carefully by agents according to agents' known schema at that moment."

## Foundational Learning

- Concept: Dec-POMDP (Decentralized Partially Observable Markov Decision Process)
  - Why needed here: The framework models the multi-agent SQL generation task as a decentralized decision process where agents have partial observability of the global state (schema) and must coordinate through communication.
  - Quick check question: How does Dec-POMDP differ from standard POMDP in modeling multi-agent coordination?

- Concept: Schema partitioning and information exchange protocols
  - Why needed here: Agents must efficiently partition the schema and communicate only relevant schema elements without exposing private data, requiring careful protocol design.
  - Quick check question: What criteria determine which schema elements are "relevant" to a given question?

- Concept: Iterative refinement and convergence in distributed systems
  - Why needed here: The framework relies on agents iteratively refining their SQL generation through schema enrichment, requiring understanding of convergence conditions in distributed systems.
  - Quick check question: What conditions guarantee that the iterative SQL generation process will converge to the correct answer?

## Architecture Onboarding

- Component map: Schema partitioning module -> Global schema manager -> Agent interface -> Communication layer -> Control loop
- Critical path: 1. Initialize global schema as empty 2. Agent 1 updates global schema with relevant elements from private schema 3. Agent 1 generates SQL using enriched known schema 4. Agent 2 checks SQL correctness against its known schema 5. If incorrect, repeat from step 2 with next agent 6. Terminate when SQL passes correctness check
- Design tradeoffs: Schema partitioning granularity vs. communication overhead; Number of agents vs. convergence speed and accuracy; Schema retention threshold (δ) vs. completeness vs. noise; Prompt strategy complexity vs. LLM capability requirements
- Failure signatures: High iteration counts without convergence; Inconsistent SQL checking results between agents; Schema communication failures or deadlocks; Performance degradation with increased agent count
- First 3 experiments: 1. Baseline comparison: Single agent with full schema vs. single agent with partial schema 2. Communication efficiency: Measure schema exchange volume vs. accuracy improvement 3. Agent count sensitivity: Test performance with 2, 3, and 4 agents on same task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CSMA scale with the number of agents, and is there an optimal number of agents for different task complexities?
- Basis in paper: [inferred] The paper mentions experiments with 2, 3, and 4 agents showing performance generally declined with more agents, but fluctuates based on difficulty level.
- Why unresolved: The paper only tested up to 4 agents and did not explore the full range of possible agent numbers or provide theoretical analysis of the scaling behavior.
- What evidence would resolve it: Systematic experiments testing CSMA with varying numbers of agents (e.g., 2-10) across tasks of different complexities, along with analysis of computational efficiency and communication overhead.

### Open Question 2
- Question: How does the retention mechanism threshold (δ) affect the performance and efficiency of CSMA, and what is the optimal value for different types of databases?
- Basis in paper: [explicit] The paper mentions a retention mechanism with threshold δ but does not provide detailed analysis of its impact or optimal values.
- Why unresolved: The paper only mentions the mechanism exists but doesn't explore its sensitivity to different threshold values or provide guidelines for setting it.
- What evidence would resolve it: Comprehensive experiments varying the δ parameter across different database sizes and complexities, along with analysis of trade-offs between schema completeness and computational efficiency.

### Open Question 3
- Question: How does CSMA's performance compare to centralized approaches when dealing with databases that have varying degrees of schema overlap between agents?
- Basis in paper: [inferred] The paper mentions agents may have overlapping schema but doesn't systematically study how different overlap levels affect performance.
- Why unresolved: The paper doesn't explore scenarios with different degrees of schema overlap or compare performance against centralized approaches under these conditions.
- What evidence would resolve it: Controlled experiments comparing CSMA's performance against centralized approaches across databases with systematically varied schema overlap ratios.

### Open Question 4
- Question: What are the failure modes of CSMA when agents have conflicting schema interpretations or when schema evolution occurs during the interaction process?
- Basis in paper: [inferred] The paper describes the interaction process but doesn't address potential conflicts or schema evolution issues.
- Why unresolved: The paper doesn't discuss how the system handles disagreements between agents or changes in schema during the interaction process.
- What evidence would resolve it: Experiments introducing controlled schema conflicts and evolution scenarios, along with analysis of how CSMA handles these situations and potential modifications to improve robustness.

## Limitations

- The framework's performance depends heavily on the quality of schema partitioning, which is not specified in the paper
- The iterative refinement process lacks theoretical guarantees of convergence and may require many iterations
- The correctness checking mechanism could introduce inconsistencies if agents have conflicting schema interpretations

## Confidence

**High Confidence**: The core concept of using multi-agent collaboration for SQL generation is well-founded and supported by the paper's experimental results. The framework's three-stage process (schema collection, SQL generation, and correctness check) is clearly articulated and demonstrates measurable improvements over baseline approaches.

**Medium Confidence**: The paper's claims about maintaining data privacy through schema segmentation are plausible but not rigorously proven. While agents only share schema elements relevant to specific questions, the framework still requires careful implementation to prevent information leakage through schema analysis patterns or SQL query structures.

**Low Confidence**: The efficiency claims regarding communication overhead and iteration counts are not sufficiently validated. The paper does not provide detailed analysis of how schema partitioning granularity affects communication volume or how the number of agents impacts convergence speed and accuracy.

## Next Checks

1. **Convergence Analysis**: Conduct experiments to measure iteration counts required for convergence across different database complexities and agent configurations. Establish whether the iterative process reliably converges within practical iteration limits.

2. **Schema Partitioning Impact**: Systematically vary schema partitioning strategies (random, balanced, domain-based) and measure their effects on SQL generation accuracy and communication efficiency. Determine optimal partitioning approaches for different database structures.

3. **Privacy Leakage Assessment**: Design experiments to test whether schema segmentation and selective information exchange effectively prevent information leakage. Attempt to reconstruct private schema elements from communication patterns and generated SQL queries.