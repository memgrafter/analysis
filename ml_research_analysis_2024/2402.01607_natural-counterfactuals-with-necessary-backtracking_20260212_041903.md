---
ver: rpa2
title: Natural Counterfactuals With Necessary Backtracking
arxiv_id: '2402.01607'
source_url: https://arxiv.org/abs/2402.01607
tags:
- counterfactuals
- counterfactual
- natural
- variables
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes "natural counterfactuals," a framework to generate
  counterfactuals that are more realistic with respect to actual data distributions.
  Unlike traditional non-backtracking counterfactuals, which can be too removed from
  realistic scenarios, natural counterfactuals allow for necessary backtracking to
  minimize deviations from realistic scenarios while satisfying a "naturalness" criterion.
---

# Natural Counterfactuals With Necessary Backtracking

## Quick Facts
- arXiv ID: 2402.01607
- Source URL: https://arxiv.org/abs/2402.01607
- Reference count: 40
- The paper proposes "natural counterfactuals," a framework to generate counterfactuals that are more realistic with respect to actual data distributions.

## Executive Summary
This paper introduces "natural counterfactuals," a novel framework for generating counterfactual explanations that remain within realistic data distributions while satisfying causal interventions. Unlike traditional non-backtracking counterfactuals that can produce out-of-distribution values, natural counterfactuals allow for necessary backtracking to ancestor variables when direct interventions would lead to unrealistic scenarios. The method formulates an optimization problem that balances the extent of backtracking with a "naturalness" criterion based on local mechanism distributions. Experiments demonstrate significant improvements in prediction reliability compared to non-backtracking approaches, particularly in cases where standard methods produce unrealistic counterfactuals.

## Method Summary
The method learns a generative model from data and formulates counterfactual generation as a Feasible Intervention Optimization (FIO) problem. When a direct intervention violates the naturalness criterion (i.e., produces out-of-distribution values), the framework backtracks to minimally modify ancestor variables while maintaining the naturalness constraint. The optimization uses an L1 norm distance metric to encourage sparse changes and ensures generated counterfactuals remain within the original data distribution. The approach is implemented through Lagrangian optimization and validated on both synthetic and real datasets.

## Key Results
- Natural counterfactuals significantly reduce mean absolute error (MAE) in predicting counterfactual outcomes compared to non-backtracking methods
- The approach successfully handles cases where non-backtracking counterfactuals produce out-of-distribution values
- Experimental validation shows consistent performance improvements across synthetic and real datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Natural counterfactuals improve prediction reliability by ensuring generated counterfactuals remain within the data distribution.
- Mechanism: The optimization framework (FIO) balances backtracking extent with naturalness constraints. When direct intervention (do(A=a*)) would place the counterfactual outside the data support, the method backtracks to modify ancestor variables minimally, ensuring the resulting counterfactual stays within realistic scenarios.
- Core assumption: The learned generative model can accurately represent the joint distribution of observed variables within their support.
- Evidence anchors:
  - [abstract]: "natural counterfactuals allow for necessary backtracking to minimize deviations from realistic scenarios while satisfying a 'naturalness' criterion"
  - [section]: "our approach amounts to searching for feasible changes that keep generated counterfactuals within its original distribution"
  - [corpus]: Weak corpus coverage - only 1 of 8 related papers directly addresses backtracking counterfactuals, suggesting this mechanism is relatively novel
- Break condition: If the generative model fails to generalize within the support (e.g., due to limited data or model capacity), the naturalness constraint may not effectively constrain counterfactuals to realistic regions.

### Mechanism 2
- Claim: Minimal backtracking is achieved through an L1 norm distance measure that encourages sparse changes in ancestor variables.
- Mechanism: The distance metric D(an(A), an(A)*) = ||an(A)* - an(A)||₁ penalizes changes in ancestor variables, favoring modifications to variables closest to the target variable A. This creates a bias toward minimal intervention extent.
- Core assumption: Changes propagate through the causal graph such that modifying closer ancestors requires fewer downstream changes.
- Evidence anchors:
  - [section]: "For our purpose, the L1 norm is a good choice, as it encourage sparse changes and thus sparse backtracking"
  - [section]: "Implicitly, this distance metric favors changes in variables that are proximal to A"
  - [corpus]: Limited direct evidence - the mechanism relies on standard optimization principles rather than novel theoretical contributions
- Break condition: In causal graphs with long chains or complex dependencies, minimal backtracking may still require substantial changes in upstream variables.

### Mechanism 3
- Claim: The naturalness criterion uses local mechanism distributions to assess whether counterfactual values are realistic.
- Mechanism: Naturalness is evaluated through measures like entropy-normalized density, exogenous CDF, or conditional CDF. These assess whether each variable's value is a natural outcome of its local mechanism given parent values.
- Core assumption: The local mechanism distributions can be accurately estimated from data and provide meaningful naturalness assessments.
- Evidence anchors:
  - [section]: "we propose to assess naturalness by examining the distribution characteristics, such as density, of each variable's value"
  - [section]: "A value setting AN(A) = an(A)* satisfies ϵ-natural generation, if and only if, gn(an(A)*) > ϵ"
  - [corpus]: Weak corpus evidence - most related work focuses on feasibility rather than naturalness criteria based on local mechanisms
- Break condition: If the local mechanisms are misspecified or the data is insufficient to characterize them accurately, the naturalness assessment may fail to identify unrealistic counterfactuals.

## Foundational Learning

- Concept: Structural Causal Models (SCM)
  - Why needed here: The entire framework relies on understanding causal relationships and interventions within an SCM framework
  - Quick check question: What is the difference between a do-operator and a change-operator in counterfactual reasoning?

- Concept: Counterfactual reasoning and interventions
  - Why needed here: Natural counterfactuals build on standard counterfactual reasoning but modify the intervention mechanism to include backtracking
  - Quick check question: Why might non-backtracking counterfactuals lead to out-of-distribution predictions?

- Concept: Optimization with constraints
  - Why needed here: The Feasible Intervention Optimization (FIO) framework formulates counterfactual generation as a constrained optimization problem
  - Quick check question: How does the L1 norm in the distance measure encourage sparse backtracking?

## Architecture Onboarding

- Component map:
  - Causal graph (input) -> Data samples from joint distribution (input) -> Generative model (learned from data) -> Feasible Intervention Optimization (FIO) module -> Distance metric (L1 norm) -> Naturalness criterion (local mechanism assessment) -> Counterfactual generator (output)

- Critical path:
  1. Learn generative model from data
  2. Receive counterfactual query (change(A=a*))
  3. Evaluate if do(A=a*) satisfies naturalness constraint
  4. If not, solve FIO optimization to find minimal backtracking
  5. Generate counterfactual using identified intervention

- Design tradeoffs:
  - Strictness of naturalness threshold (ϵ) vs. feasibility of interventions
  - Computational cost of optimization vs. accuracy of counterfactuals
  - Complexity of distance metric vs. interpretability of backtracking decisions

- Failure signatures:
  - No feasible intervention found (optimization fails)
  - Counterfactuals still fall outside data support despite backtracking
  - Excessive backtracking required for seemingly simple changes
  - Generative model fails to generalize within data support

- First 3 experiments:
  1. Generate counterfactuals for simple causal graph (e.g., Toy 1) with known ground truth to verify basic functionality
  2. Test sensitivity to naturalness threshold (ϵ) by varying its value and measuring intervention feasibility
  3. Compare prediction errors between natural and non-backtracking counterfactuals on real dataset (e.g., MorphoMNIST)

## Open Questions the Paper Calls Out

- The paper acknowledges that its approach assumes a known causal graph and could be extended to handle causal discovery scenarios
- The authors note that evaluating the practical utility of natural counterfactuals beyond prediction accuracy remains an open direction
- The framework's scalability to high-dimensional settings and complex causal structures is identified as an area for future work

## Limitations
- The naturalness criterion relies heavily on accurate estimation of local mechanism distributions, which may be challenging with limited data or complex causal relationships
- The method assumes a known causal graph, which may not be available in many real-world applications
- Evaluation focuses primarily on prediction accuracy rather than the interpretability or practical utility of the generated counterfactuals

## Confidence

- **High confidence**: The core optimization framework (FIO) and its formulation as a constrained optimization problem is mathematically sound and well-established
- **Medium confidence**: The claim that L1 distance encourages sparse backtracking is supported by standard optimization principles, though the practical impact may vary depending on causal graph structure
- **Medium confidence**: The experimental results showing reduced MAE for natural counterfactuals are promising, but the evaluation could be more comprehensive with additional real-world scenarios

## Next Checks
1. Test robustness to causal graph misspecification by systematically perturbing edge directions and measuring impact on counterfactual quality
2. Evaluate performance on high-dimensional datasets with complex dependencies to assess scalability beyond synthetic examples
3. Compare interpretability scores of natural vs. non-backtracking counterfactuals using human evaluation studies to complement the quantitative MAE metrics