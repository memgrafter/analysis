---
ver: rpa2
title: 'Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages'
arxiv_id: '2403.06354'
source_url: https://arxiv.org/abs/2403.06354
tags:
- amharic
- data
- text
- language
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents Amharic LLaMA and Amharic LLaVA, open-source
  multimodal large language models designed for low-resource languages. The approach
  involves extending the LLaMA-2 tokenizer with SentencePiece to improve Amharic tokenization,
  generating synthetic training data by translating English text from the RedPajama
  dataset, and fine-tuning on translated multimodal instruction datasets.
---

# Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages

## Quick Facts
- arXiv ID: 2403.06354
- Source URL: https://arxiv.org/abs/2403.06354
- Reference count: 32
- Presents open-source Amharic multimodal LLMs with improved tokenization and synthetic training data

## Executive Summary
This work introduces Amharic LLaMA and Amharic LLaVA, the first open-source multimodal large language models designed specifically for the low-resource Amharic language. The approach extends LLaMA-2's tokenizer with SentencePiece for better Amharic tokenization and generates synthetic training data by translating English text from the RedPajama dataset. The models are fine-tuned on translated multimodal instruction datasets and evaluated on a newly created Amharic version of the MMLU benchmark, demonstrating improved performance over smaller datasets while highlighting the potential and limitations of synthetic data approaches for low-resource languages.

## Method Summary
The methodology involves extending the LLaMA-2 tokenizer with SentencePiece to improve Amharic language tokenization, generating synthetic training data through translation of English text from the RedPajama dataset, and fine-tuning the models on translated multimodal instruction datasets. The approach leverages existing large language models and adapts them to the Amharic language context through careful data preparation and model adaptation techniques.

## Key Results
- Evaluation scores of 0.29 on full text topics and 0.37 on non-STEM topics using the newly created Amharic MMLU benchmark
- Improved performance compared to smaller datasets when using the extended tokenizer approach
- Demonstrated proficiency in text generation, summarization, and multimodal understanding tasks
- Models show limitations including brittleness and reliance on synthetic training data

## Why This Works (Mechanism)
The success of this approach stems from addressing the fundamental challenge of tokenization for morphologically rich languages like Amharic. By extending LLaMA-2's tokenizer with SentencePiece, the models can better handle the complex character combinations and word formations inherent in Amharic. The synthetic data generation through translation provides a scalable way to create training data for low-resource languages, though it introduces quality limitations that affect final model performance.

## Foundational Learning
- Tokenization for morphologically rich languages: Essential for proper text representation in languages with complex word formation patterns; quick check: verify token coverage across diverse Amharic text samples
- Synthetic data generation through translation: Provides scalable training data for low-resource languages; quick check: compare synthetic data quality metrics against human-annotated benchmarks
- Multimodal instruction tuning: Enables models to handle both text and image inputs effectively; quick check: validate multimodal task performance across different input types

## Architecture Onboarding

Component Map:
Tokenizer (LLaMA-2 + SentencePiece) -> Synthetic Data Generator -> Multimodal Fine-tuning Pipeline -> Evaluation Framework

Critical Path:
The critical path flows from tokenizer extension through synthetic data generation to fine-tuning and evaluation. Each stage must maintain data quality to ensure final model performance, with the tokenizer extension being particularly crucial for proper Amharic text representation.

Design Tradeoffs:
The approach trades data quality for quantity by relying on synthetic translation-based data generation. While this enables scalable training for low-resource languages, it introduces potential biases and limitations compared to human-annotated data. The tokenizer extension provides better language coverage but increases model complexity.

Failure Signatures:
- Poor tokenization leading to fragmented word representations
- Synthetic data artifacts manifesting as unnatural language patterns
- Brittleness in handling out-of-distribution inputs
- Reduced performance on complex reasoning tasks

First Experiments:
1. Test tokenizer coverage on diverse Amharic text samples
2. Evaluate synthetic data quality through human assessment
3. Validate basic text generation capabilities before full fine-tuning

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy dependence on synthetic training data through translation, which may not fully represent natural language patterns
- Reported performance metrics suggest significant limitations in reasoning and knowledge retention
- Brittleness implies poor generalization to novel or out-of-distribution inputs

## Confidence
- High confidence in tokenizer extension methodology and technical implementation details
- Medium confidence in training approach using synthetic data, given the inherent limitations of translation-based generation
- Low confidence in reported evaluation results due to the novelty of the Amharic MMLU benchmark and the relatively low performance scores

## Next Checks
1. Conduct human evaluation studies on model outputs for key tasks (text generation, summarization, multimodal understanding) to validate the synthetic evaluation metrics
2. Test model performance on established Amharic language benchmarks beyond the newly created MMLU variant to establish broader competency
3. Perform ablation studies to quantify the impact of synthetic data quality versus quantity on final model performance