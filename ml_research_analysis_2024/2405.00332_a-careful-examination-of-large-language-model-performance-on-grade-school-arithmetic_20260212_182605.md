---
ver: rpa2
title: A Careful Examination of Large Language Model Performance on Grade School Arithmetic
arxiv_id: '2405.00332'
source_url: https://arxiv.org/abs/2405.00332
tags:
- gsm8k
- gsm1k
- each
- many
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors commissioned GSM1k, a new grade school math benchmark
  to rigorously measure overfitting in large language models (LLMs) on GSM8k. GSM1k
  is designed to be comparable to GSM8k in difficulty, number of steps, and answer
  magnitude.
---

# A Careful Examination of Large Language Model Performance on Grade School Arithmetic

## Quick Facts
- arXiv ID: 2405.00332
- Source URL: https://arxiv.org/abs/2405.00332
- Reference count: 40
- Key outcome: GSM1k benchmark reveals up to 8% accuracy drops in LLMs on GSM8k, indicating partial overfitting through memorization of training data

## Executive Summary
This paper presents GSM1k, a new grade school math benchmark designed to detect overfitting in large language models on GSM8k. The authors benchmark 50+ open- and closed-source LLMs and find systematic accuracy drops of up to 8% on GSM1k compared to GSM8k. Analysis reveals a positive relationship between a model's probability of generating GSM8k examples and its performance gap, suggesting partial memorization of GSM8k. Frontier models show minimal signs of overfitting, indicating they have developed reasoning capabilities that generalize beyond memorized patterns. The GSM1k dataset will be released when certain conditions are met to prevent future data contamination.

## Method Summary
The authors commissioned GSM1k, a benchmark of 1205 grade school math problems comparable to GSM8k in difficulty, steps, and answer magnitude. They evaluated 50+ LLMs using LM Evaluation Harness with standardized prompts containing 5 random GSM8k train examples as few-shot demonstrations. Automatic answer extraction was used to identify the last numeric answer in model outputs. The analysis compared accuracy across GSM8k and GSM1k, computed performance gaps, and examined the relationship between GSM8k generation probability and overfitting severity.

## Key Results
- Accuracy drops of up to 8% on GSM1k compared to GSM8k across multiple model families
- Positive relationship (Spearman's r² = 0.36) between GSM8k generation probability and performance gap
- Frontier models show minimal overfitting, suggesting genuine reasoning capabilities
- Several model families show systematic overfitting across all model sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Models overfit on GSM8k through partial memorization of training data, leading to inflated performance on the original benchmark but lower performance on GSM1k.
- Mechanism: Training data contains GSM8k examples, causing models to learn specific problem-solution mappings rather than general reasoning. Performance drops on GSM1k because memorized solutions don't directly apply to new problems.
- Core assumption: GSM8k test set examples have leaked into training data of some models.
- Evidence: Positive relationship between GSM8k generation probability and performance gap (Spearman's r² = 0.36).

### Mechanism 2
- Claim: Model builders inadvertently create training data resembling benchmarks, leading to overfitting even without direct contamination.
- Mechanism: Data collection processes select examples similar in style and difficulty to GSM8k, causing models to learn specific patterns rather than general reasoning.
- Core assumption: Data selection processes can introduce bias toward benchmark-like examples.
- Evidence: Several outliers with high overfitting but low per-character log-likelihood suggest indirect contamination through reward modeling.

### Mechanism 3
- Claim: Frontier models show minimal overfitting because they develop genuine reasoning capabilities that generalize beyond memorized patterns.
- Mechanism: Advanced models learn underlying mathematical reasoning principles rather than memorizing specific problem-solution mappings, allowing them to apply reasoning to novel problems.
- Core assumption: Frontier models have developed reasoning capabilities beyond pattern matching.
- Evidence: All frontier models show minimal signs of overfitting despite potentially seeing GSM8k in training data.

## Foundational Learning

- Concept: Benchmark contamination and its impact on model evaluation
  - Why needed here: Understanding how data leakage affects performance measurements is crucial for interpreting results and designing proper evaluation methods.
  - Quick check: What is the difference between a model's performance on GSM8k versus GSM1k meant to measure?

- Concept: Correlation vs. causation in data analysis
  - Why needed here: The paper identifies a positive relationship between GSM8k generation probability and performance gap, but establishing causation requires careful consideration.
  - Quick check: Does finding a correlation between GSM8k generation probability and performance gap prove that memorization caused the overfitting?

- Concept: Statistical significance testing
  - Why needed here: The paper uses p-values to determine whether performance differences are statistically significant.
  - Quick check: What does a p-value of 0.03 mean in the context of testing whether there's a relationship between GSM8k generation probability and performance gap?

## Architecture Onboarding

- Component map: GSM1k generation -> Model inference pipeline -> Statistical analysis
- Critical path: Obtain GSM1k access -> Set up evaluation environment -> Configure prompts -> Run inference -> Analyze results
- Design tradeoffs: Private GSM1k prevents contamination but limits reproducibility; automatic answer extraction is efficient but may misclassify formatted answers
- Failure signatures: Performance gaps not correlating with generation probabilities; frontier models showing significant overfitting; inconsistent results across prompt formats
- First 3 experiments:
  1. Replicate main analysis with Mistral-7B, Phi-2, Claude-3-Haiku on both benchmarks
  2. Test impact of prompt format using standard vs. alternative prompts
  3. Analyze generation probabilities by computing log-likelihood of GSM8k examples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms in the reward modeling process might have caused Math-Shepherd-Mistral-7B-RL to leak information about GSM8k reasoning chains without direct data contamination?
- Basis: Paper notes this model is an outlier with high overfitting but low per-character log-likelihood, suggesting indirect contamination through reward modeling
- Why unresolved: Only hypothesizes about mechanism without concrete evidence or analysis of how the reward model might have encoded GSM8k reasoning patterns
- What evidence would resolve it: Detailed analysis of reward model's training data, architecture, and scoring of GSM8k-style solutions

### Open Question 2
- Question: At what precise reasoning capability threshold do frontier models become immune to GSM8k data contamination?
- Basis: Paper suggests sufficiently strong models may learn elementary reasoning capabilities that allow generalization beyond memorized patterns
- Why unresolved: Does not define specific capability metrics or conduct controlled experiments to identify when models transition from susceptible to immune
- What evidence would resolve it: Systematic testing of models with varying reasoning capabilities on increasingly contaminated datasets

### Open Question 3
- Question: How does the number of GSM8k examples in pretraining data correlate with the degree of overfitting across different model architectures?
- Basis: Paper finds positive relationship between model's likelihood of generating GSM8k examples and performance gap
- Why unresolved: Establishes correlation but does not quantify relationship between contamination level and overfitting severity across model families
- What evidence would resolve it: Controlled experiments varying number of GSM8k examples in pretraining data for identical model architectures

## Limitations
- Moderate correlation (r² = 0.36) between generation probability and performance gap suggests other mechanisms beyond data contamination
- Private GSM1k dataset prevents independent verification and limits reproducibility
- Automatic answer extraction may misclassify correct answers with different formatting

## Confidence
- High confidence: Systematic overfitting across multiple model families is well-established through direct measurements
- Medium confidence: Attribution of overfitting primarily to data contamination is partially supported but not definitively proven
- Medium confidence: Claim that frontier models show minimal overfitting due to genuine reasoning capabilities is supported but alternative explanations cannot be ruled out

## Next Checks
1. Test additional models with varying training data characteristics to better understand how training data composition relates to overfitting patterns
2. Conduct ablation studies on prompt formats to determine sensitivity of overfitting detection to evaluation methodology
3. Analyze model-internal representations using activation analysis or probing classifiers to examine whether overfit models rely on different internal mechanisms than those that generalize