---
ver: rpa2
title: Using GPT-4 to guide causal machine learning
arxiv_id: '2407.18607'
source_url: https://arxiv.org/abs/2407.18607
tags:
- causal
- case
- graphs
- graph
- constraints
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the ability of Large Language Models (LLMs)
  to identify causal relationships by focusing on GPT-4 (Turbo) under restrictive
  conditions, using only variable labels without additional human context. A questionnaire
  was conducted with human participants to evaluate the accuracy of causal graphs
  produced by GPT-4, causal machine learning (ML) algorithms, and domain experts across
  five case studies.
---

# Using GPT-4 to guide causal machine learning

## Quick Facts
- arXiv ID: 2407.18607
- Source URL: https://arxiv.org/abs/2407.18607
- Authors: Anthony C. Constantinou; Neville K. Kitson; Alessio Zanga
- Reference count: 6
- Primary result: GPT-4 generates more accurate causal graphs than causal ML algorithms when using only variable labels, and GPT-4 outputs improve causal ML performance when used as constraints

## Executive Summary
This study investigates the ability of GPT-4 (Turbo) to identify causal relationships using only variable labels without additional human context. Through a human questionnaire evaluating causal graphs from GPT-4, domain experts, and causal machine learning algorithms across five case studies, GPT-4 graphs were judged most accurate, closely followed by expert knowledge graphs, with causal ML significantly behind due to counterintuitive edge orientations. The study further demonstrates that using GPT-4 outputs as constraints in causal ML algorithms improves alignment with expert-generated graphs, particularly when applied as required edge constraints. These findings suggest GPT-4 can enhance causal discovery processes despite not being explicitly designed for causal reasoning.

## Method Summary
The study used five real-world datasets from diverse domains (Sports, COVID-19, Property, Diarrhoea, ForMed) with variable labels but no additional context. For each case study, 10 different prompts were used to query GPT-4 for causal relationships, which were then averaged using a 2/3rds rule to create representative LLM graphs. Human participants evaluated three graph types (knowledge graphs from experts, causal ML graphs learned from data, and LLM graphs) through questionnaires, rating accuracy and identifying graph sources. Additionally, GPT-4 constraints were extracted at 33%, 50%, and 67% confidence thresholds and applied to causal ML algorithms as required edges, initial graphs, and temporal constraints, with learned structures compared to expert graphs using F1, BSF, SHD, and BIC metrics.

## Key Results
- GPT-4 generated graphs were judged most accurate by human participants, followed closely by expert knowledge graphs, with causal ML graphs rated significantly lower
- Causal ML algorithms produced counterintuitive or incorrect edge orientations, leading to poor performance in human evaluations
- Applying GPT-4 outputs as required edge constraints in causal ML algorithms improved structural alignment with expert graphs, particularly at 50% and 67% confidence thresholds
- GPT-4 constraint application as initial graphs or temporal constraints showed minimal improvement over baseline causal ML performance

## Why This Works (Mechanism)
Assumption: GPT-4's strong performance stems from its ability to leverage world knowledge embedded in its training data, allowing it to infer plausible causal relationships even from limited variable labels. The mechanism likely involves pattern recognition from similar variable names encountered during training, combined with implicit understanding of common causal structures in real-world systems. This contrasts with causal ML algorithms that rely solely on statistical dependencies in the data, which can produce counterintuitive results when those dependencies don't reflect true causal relationships.

## Foundational Learning
- **Causal discovery from observational data**: Understanding how to infer causal relationships from statistical dependencies without controlled experiments; needed because the study compares automated causal learning approaches; quick check: verify the dataset contains sufficient variables to support causal inference
- **Variable label-based reasoning**: Ability to infer causal relationships from only variable names without additional context; needed because GPT-4 operates under restrictive conditions; quick check: test GPT-4 with variable labels from a new domain to assess generalizability
- **Constraint-based causal structure learning**: Methods that incorporate prior knowledge as constraints in learning causal graphs; needed because GPT-4 outputs are used as constraints; quick check: implement a simple constraint-based algorithm and verify it respects given edge requirements
- **Human evaluation of causal graphs**: Methods for assessing the quality of causal relationships through expert judgment; needed because human questionnaires form the primary evaluation metric; quick check: have multiple experts rate the same graph and measure inter-rater reliability
- **LLM prompt engineering for causal reasoning**: Designing prompts that effectively elicit causal relationship identification from language models; needed because performance depends on prompt design; quick check: test multiple prompt variations with the same input data and compare consistency
- **DAG structure comparison metrics**: F1 score, BSF, SHD, and BIC for evaluating structural similarity between causal graphs; needed for quantitative comparison of learned structures to ground truth; quick check: calculate all four metrics between two simple DAGs and verify they capture different aspects of similarity

## Architecture Onboarding
- **Component map**: Human participants <- Questionnaire <- Graph evaluation (Knowledge, ML, LLM) <- GPT-4 queries <- Variable labels <- Case study datasets
- **Critical path**: Variable labels → GPT-4 queries (10 prompts) → Constraint extraction → Causal ML algorithms (with constraints) → Structure comparison to expert graphs
- **Design tradeoffs**: Using only variable labels limits GPT-4's context but demonstrates its ability to reason causally without domain expertise; this makes the approach generalizable but potentially less accurate than with full context
- **Failure signatures**: Inconsistent GPT-4 outputs across prompts, human participants unable to complete questionnaires, causal ML algorithms producing cyclic graphs when constraints are applied, or constraint application causing algorithms to fail to converge
- **First experiments**: 1) Run a single case study through GPT-4 with all 10 prompts and verify constraint extraction produces reasonable edge sets; 2) Apply GPT-4 constraints at different confidence thresholds to a simple causal ML algorithm and check for structural improvements; 3) Conduct a pilot questionnaire with 5 participants on a single graph type to validate the evaluation methodology

## Open Questions the Paper Calls Out
None

## Limitations
- The study relies heavily on human judgment through questionnaires, introducing potential subjectivity and expertise variability that was not fully characterized
- Performance improvements from using GPT-4 constraints appear modest in some cases, suggesting benefits may be context-dependent rather than universally applicable
- Exact prompt templates beyond the generic description were not provided, making exact reproduction difficult

## Confidence
- GPT-4 produces more accurate causal graphs than causal ML algorithms: Medium
- Using GPT-4 outputs as constraints improves causal ML performance: Medium
- GPT-4 enhances causal discovery processes overall: Low to Medium

## Next Checks
1. Reproduce the GPT-4 constraint generation using the exact prompt templates and compare the consistency of outputs across multiple runs with the same input data
2. Conduct a blinded expert review comparing GPT-4-generated graphs to domain expert knowledge graphs without the intermediate human questionnaire step
3. Test the constraint application methodology on additional case studies from different domains to assess generalizability and identify conditions under which GPT-4 constraints provide the most benefit