---
ver: rpa2
title: 'ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic Executors
  in Large Language Models'
arxiv_id: '2404.15515'
source_url: https://arxiv.org/abs/2404.15515
tags:
- symbolic
- reasoning
- formulation
- llms
- tom-lm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of improving Theory of Mind (ToM)
  reasoning in Large Language Models (LLMs), which struggle with complex ToM tasks.
  The core method, ToM-LM, delegates the reasoning process to an external symbolic
  executor, specifically the SMCDEL model checker, to perform transparent and verifiable
  ToM reasoning.
---

# ToM-LM: Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models

## Quick Facts
- arXiv ID: 2404.15515
- Source URL: https://arxiv.org/abs/2404.15515
- Authors: Weizhi Tang; Vaishak Belle
- Reference count: 31
- Primary result: ToM-LM achieves 91% accuracy on Theory of Mind reasoning tasks by delegating to external symbolic executors

## Executive Summary
This paper addresses the challenge of Theory of Mind (ToM) reasoning in Large Language Models (LLMs), which often struggle with complex social reasoning tasks. The proposed ToM-LM framework delegates ToM reasoning to an external symbolic executor, specifically the SMCDEL model checker, rather than relying solely on LLM reasoning capabilities. By fine-tuning an LLM to generate symbolic formulations from natural language ToM problems, which are then executed by the SMCDEL model checker, the approach achieves significant performance improvements over direct LLM prompting methods.

## Method Summary
The ToM-LM framework operates through a two-stage process. First, a fine-tuned LLM generates symbolic representations from natural language ToM problems. Second, these symbolic formulations are executed by the SMCDEL model checker, which performs the actual reasoning to produce answers. This delegation approach leverages the precision and transparency of formal symbolic reasoning while maintaining the flexibility of LLMs in natural language understanding. The method was evaluated against baseline approaches including direct LLM prompting and symbolic formulation generation prompting.

## Key Results
- ToM-LM achieves 91% accuracy compared to 58% for direct prompting baseline
- ToM-LM achieves 0.94 AUC compared to 0.58 AUC for direct prompting baseline
- ToM-LM achieves 91% accuracy compared to 49% accuracy for symbolic formulation generation prompting baseline

## Why This Works (Mechanism)
The approach works by combining the natural language understanding strengths of LLMs with the rigorous logical reasoning capabilities of symbolic executors. LLMs are fine-tuned to translate natural language ToM problems into precise symbolic representations that capture the complex belief structures and mental states involved. The SMCDEL model checker then performs formal reasoning on these representations, avoiding the probabilistic reasoning errors and hallucinations that LLMs often exhibit when handling complex logical structures. This division of labor allows each system to operate in its optimal domain.

## Foundational Learning
- Theory of Mind reasoning: Understanding that others have beliefs, desires, and intentions different from one's own. Needed for modeling social intelligence and interpersonal understanding. Quick check: Can the system reason about false beliefs and knowledge attribution?
- Symbolic model checking: Formal verification method for checking logical properties against finite state models. Needed for precise, verifiable reasoning about belief states. Quick check: Can the executor correctly evaluate complex belief formulas?
- Fine-tuning strategies for LLMs: Techniques for adapting pre-trained models to specific tasks through additional training. Needed for generating accurate symbolic formulations. Quick check: Does fine-tuning improve symbolic formulation accuracy?

## Architecture Onboarding
Component map: Natural Language Problem -> Fine-tuned LLM -> Symbolic Formulation -> SMCDEL Executor -> Answer

Critical path: The end-to-end pipeline from problem input through LLM translation to symbolic execution is critical. Any failure in symbolic formulation generation directly impacts downstream reasoning accuracy.

Design tradeoffs: The approach trades computational overhead and system complexity for improved reasoning accuracy and transparency. While requiring an external executor adds latency, it provides verifiable reasoning traces and avoids LLM hallucinations.

Failure signatures: Common failure modes include incorrect symbolic formulation generation by the LLM, leading to reasoning errors in the SMCDEL executor, and inability to handle problems requiring temporal reasoning beyond the symbolic representation capabilities.

First experiments: (1) Test symbolic formulation generation accuracy across diverse ToM scenarios, (2) Validate SMCDEL reasoning correctness on generated symbolic problems, (3) Measure end-to-end performance degradation when varying LLM fine-tuning quality.

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Limited generalizability to novel problem types beyond tested ToM scenarios
- Computational overhead from external symbolic executor may impact practical deployment
- Evaluation focuses on accuracy metrics without thorough analysis of reasoning transparency or failure cases

## Confidence
High: ToM-LM significantly improves accuracy over baselines
Medium: Claims about transparency and verifiability need more thorough validation
Low: Generalizability to broader reasoning domains not established

## Next Checks
(1) Test ToM-LM on broader range of ToM scenarios including complex belief structures and temporal dynamics
(2) Conduct ablation studies to isolate contributions of fine-tuning versus symbolic execution components
(3) Perform computational efficiency analysis to quantify overhead and assess practical deployment feasibility