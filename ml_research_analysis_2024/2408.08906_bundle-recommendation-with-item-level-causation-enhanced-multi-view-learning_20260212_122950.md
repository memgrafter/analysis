---
ver: rpa2
title: Bundle Recommendation with Item-level Causation-enhanced Multi-view Learning
arxiv_id: '2408.08906'
source_url: https://arxiv.org/abs/2408.08906
tags:
- bundle
- learning
- items
- user
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes BunCa, a novel bundle recommendation approach
  that leverages asymmetric item relationships through item-level causation-enhanced
  multi-view learning. BunCa models user preferences and bundle construction using
  two views: the Coherent View (using Multi-Prospect Causation Network to capture
  causation-sensitive item relations) and the Cohesive View (using LightGCN for user-bundle
  interactions).'
---

# Bundle Recommendation with Item-level Causation-enhanced Multi-view Learning

## Quick Facts
- arXiv ID: 2408.08906
- Source URL: https://arxiv.org/abs/2408.08906
- Reference count: 24
- BunCa outperforms state-of-the-art methods by 8.77-9.57% on iFashion dataset in R@20 and N@20 metrics

## Executive Summary
This paper introduces BunCa, a novel bundle recommendation approach that leverages asymmetric item relationships through item-level causation-enhanced multi-view learning. The method models user preferences and bundle construction using two complementary views: the Coherent View (capturing causation-sensitive item relations via Multi-Prospect Causation Network) and the Cohesive View (using LightGCN for user-bundle interactions). The approach also incorporates both concrete and discrete contrastive learning to optimize representation consistency and discrimination. Experiments on three benchmark datasets show BunCa achieves significant improvements over state-of-the-art methods, particularly on iFashion where it outperforms the second-best model by 8.77-9.57% in R@20 and N@20 metrics.

## Method Summary
BunCa implements a two-view learning framework for bundle recommendation. The Cohesive View uses LightGCN to encode high-order collaborative signals from user-bundle interactions through user co-occurrence and bundle co-occurrence graphs. The Coherent View employs a Multi-Prospect Causation Network (MPCNet) to model asymmetric item relationships, where influence flows from anchor items to complementary items based on user preferences. Both views are enhanced with contrastive learning - discrete contrastive learning aligns representations between views while concrete contrastive learning enhances self-discrimination of augmented representations. The model is trained using Bayesian Personalized Ranking loss with L2 regularization.

## Key Results
- BunCa achieves 8.77-9.57% improvement over second-best model on iFashion dataset (R@20 and N@20 metrics)
- Consistent performance gains across all three benchmark datasets (Youshu, NetEase, iFashion)
- Ablation studies confirm the necessity of both views and contrastive learning components
- Asymmetric causation modeling shows superior performance compared to symmetric alternatives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Asymmetric item relationships improve bundle recommendation accuracy by capturing real-world influence dynamics.
- Mechanism: Multi-Prospect Causation Network (MPCNet) models asymmetric causation weights between items, where influence flows from anchor items to complementary items based on user preferences and bundling strategies.
- Core assumption: Real-world item relationships within bundles are asymmetric rather than symmetric, with certain items acting as anchors that drive purchases of complementary items.
- Evidence anchors:
  - [abstract] "understanding these dynamics requires examining item-item relations across diverse user preferences"
  - [section 3.3] "MPCNet is constructed with L prospects, each represented by a learnable prospect vector pl ∈ Rd"
  - [corpus] Weak corpus support - no direct neighbor papers discuss asymmetric item causation in bundles
- Break condition: If causation weights converge to symmetric values or if performance degrades when using asymmetric vs symmetric matrices

### Mechanism 2
- Claim: Multi-view learning captures both direct user-bundle interactions and explicit user intent through separate but complementary representations.
- Mechanism: Coherent View (via MPCNet for causation-sensitive item relations) + Cohesive View (via LightGCN for user-bundle interactions) provide dual perspectives on bundle recommendation.
- Core assumption: User preferences and bundle construction can be effectively modeled through separate but complementary views that capture different aspects of the recommendation problem.
- Evidence anchors:
  - [abstract] "modeling user preferences and bundle construction combined from both views ensures rigorous cohesion in direct user-bundle interactions"
  - [section 3.2-3.3] "The Cohesive View learning aims to encode rigorously high-order collaborative signals in user-bundle interactions"
  - [section 4.3] Ablation study shows performance drops when either view is removed
- Break condition: If one view consistently underperforms or if combining views provides no benefit over single-view approaches

### Mechanism 3
- Claim: Contrastive learning enhances representation quality by enforcing consistency across views and discrimination within each view.
- Mechanism: Discrete contrastive learning aligns representations between views while concrete contrastive learning enhances self-discrimination of augmented representations.
- Core assumption: Representations from different views should be consistent while maintaining discriminative power for individual users/bundles.
- Evidence anchors:
  - [abstract] "simultaneously, the integration of concrete and discrete contrastive learning optimizes the consistency and self-discrimination of multi-view representations"
  - [section 3.4] "The discrete contrastive learning is directed at minimizing the inconsistency between two different views"
  - [section 4.3] Ablation study shows performance degradation when contrastive learning is removed
- Break condition: If contrastive loss components don't improve validation performance or if they cause overfitting

## Foundational Learning

- Graph Neural Networks
  - Why needed here: LightGCN is used for both user-bundle interactions and item-level representations in different views
  - Quick check question: What distinguishes LightGCN from standard GCN in terms of operations and complexity?

- Multi-View Learning
  - Why needed here: The approach explicitly separates bundle recommendation into Cohesive and Coherent views with different objectives
  - Quick check question: How do you ensure information consistency between different views while maintaining their distinct characteristics?

- Contrastive Learning
  - Why needed here: Both discrete (between views) and concrete (within views) contrastive learning modules are integrated to optimize representations
  - Quick check question: What is the difference between discrete and concrete contrastive learning in this context?

## Architecture Onboarding

- Component map: User-bundle interactions (X) -> LightGCN -> Cohesive View; User-item interactions (Y) + Bundle-item affiliations (Z) -> MPCNet -> LightGCN -> Coherent View; Contrastive learning -> Final prediction
- Critical path: MPCNet → Enhanced item representations → View-specific LightGCN → Contrastive learning → Final prediction
- Design tradeoffs: Symmetric vs asymmetric item relationships (simplicity vs accuracy), number of prospects in MPCNet (representation quality vs computational cost)
- Failure signatures:
  - Symmetric matrix performs as well as asymmetric - indicates real-world relationships may not be asymmetric
  - Removing contrastive learning has minimal impact - suggests views may not need alignment
  - Ablation of either view causes significant degradation - confirms multi-view approach is necessary
- First 3 experiments:
  1. Replace MPCNet with symmetric co-occurrence matrix and compare performance
  2. Remove discrete contrastive learning and observe impact on cross-view consistency
  3. Test different numbers of prospects (L) in MPCNet to find optimal trade-off between performance and efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does BunCa perform on datasets with larger bundles where items are less coherent and more diverse?
- Basis in paper: [explicit] The paper notes that BunCa's performance is "negatively affected due to noisy connections" on large-sized bundle datasets like NetEase and Youshu where "many items within the same bundle demonstrate high-level influence."
- Why unresolved: The paper only evaluates on three datasets with varying bundle sizes but does not systematically test BunCa's performance across a spectrum of bundle sizes or datasets with specifically large, diverse bundles.
- What evidence would resolve it: Testing BunCa on datasets with progressively larger bundles and measuring performance degradation as bundle size increases, or creating synthetic datasets with controlled bundle diversity.

### Open Question 2
- Question: Can the asymmetric causation relationships identified by MPCNet be explained or interpreted in terms of product attributes or user behavior patterns?
- Basis in paper: [explicit] The paper demonstrates that "within each bundle, certain anchor items can be identified" through asymmetric weights and shows qualitative examples, but does not provide analysis of what these relationships mean in terms of product attributes or user psychology.
- Why unresolved: While the paper shows that asymmetric relationships exist and improve performance, it does not investigate the semantic meaning or interpretability of these relationships.
- What evidence would resolve it: Analyzing the item features of anchor items versus complementary items, or conducting user studies to understand why certain items are perceived as more influential in bundle decisions.

### Open Question 3
- Question: How does BunCa's performance compare to traditional multi-view learning approaches when the bundle-item bipartite graph is removed from the graph construction?
- Basis in paper: [inferred] The paper's Cohesive View relies on user-bundle interactions and homogeneous correlations, while the Coherent View relies on bundle-item bipartite graph. The paper does not test performance when the bundle-item graph is removed.
- Why unresolved: The paper establishes that both views are important but does not isolate the contribution of the bundle-item bipartite graph specifically.
- What evidence would resolve it: Running experiments where BunCa is modified to exclude the bundle-item bipartite graph and comparing performance to standard multi-view approaches that don't use this graph structure.

## Limitations

- Low confidence in the claimed superiority of asymmetric causation modeling due to limited ablation studies and minimal related work validation
- Medium confidence in multi-view architecture benefits, with uncertainty about whether the specific view decomposition is optimal
- Medium confidence in contrastive learning contributions, with limited analysis of discrete vs concrete component effects

## Confidence

- Asymmetric causation modeling: Low confidence - limited ablation studies and minimal corpus support for this approach
- Multi-view architecture: Medium confidence - ablation studies show benefits but optimal decomposition is unproven
- Contrastive learning: Medium confidence - performance degradation when removed, but hyperparameter sensitivity not explored

## Next Checks

1. **Ablation study**: Systematically compare BunCa with symmetric causation matrices vs asymmetric MPCNet to quantify the actual contribution of asymmetric modeling and validate the core assumption about real-world bundling dynamics.

2. **Hyperparameter sensitivity analysis**: Conduct extensive experiments varying the number of prospects (L) in MPCNet, temperature τ, regularization weights λ1/λ2, and balance parameters α/β/γ/µ to understand their impact on performance and identify optimal configurations.

3. **Cross-dataset generalization**: Evaluate BunCa's performance across different bundle types (books, songs, outfits) with varying bundle sizes and item relationships to assess whether the asymmetric causation approach generalizes beyond the specific characteristics of each dataset.