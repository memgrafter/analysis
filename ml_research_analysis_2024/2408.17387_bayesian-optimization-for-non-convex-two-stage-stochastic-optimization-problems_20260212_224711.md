---
ver: rpa2
title: Bayesian Optimization for Non-Convex Two-Stage Stochastic Optimization Problems
arxiv_id: '2408.17387'
source_url: https://arxiv.org/abs/2408.17387
tags:
- optimization
- design
- knowledge
- gradient
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles non-convex two-stage stochastic optimization
  problems where expensive black-box evaluations are needed for both here-and-now
  and wait-and-see decisions under uncertainty. The authors propose using Bayesian
  optimization with a knowledge gradient acquisition function to jointly optimize
  the fixed design and adjustable control policy.
---

# Bayesian Optimization for Non-Convex Two-Stage Stochastic Optimization Problems

## Quick Facts
- arXiv ID: 2408.17387
- Source URL: https://arxiv.org/abs/2408.17387
- Reference count: 40
- This paper tackles non-convex two-stage stochastic optimization problems where expensive black-box evaluations are needed for both here-and-now and wait-and-see decisions under uncertainty.

## Executive Summary
This paper addresses the challenge of optimizing expensive black-box functions in two-stage stochastic optimization problems, where decisions must be made both before and after uncertainty is revealed. The authors propose a Bayesian optimization framework using knowledge gradient acquisition functions that can jointly optimize both the fixed design (here-and-now decisions) and the adjustable control policy (wait-and-see decisions). The method provides asymptotic consistency guarantees and demonstrates superior performance compared to existing approaches on both synthetic and real-world problems, including optical table design and supply chain optimization.

## Method Summary
The method employs Gaussian Process (GP) surrogate modeling with knowledge gradient (KG) acquisition functions to handle expensive black-box evaluations in two-stage stochastic optimization. The core innovation is the joint knowledge gradient (jKG) algorithm that simultaneously optimizes both the here-and-now decisions and the wait-and-see control policy through a quasi-Monte Carlo approximation. An alternative alternating knowledge gradient (aKG) variant achieves similar performance with fewer computational approximations by alternating between optimizing each variable type separately. The approach provides asymptotic consistency guarantees and naturally handles observation noise.

## Key Results
- jKG significantly outperforms both naïve two-step approaches and the state-of-the-art algorithm from Xie et al. (2021), particularly in high-dimensional and noisy settings
- jKG and aKG achieve comparable empirical performance, with aKG offering computational advantages through reduced approximation requirements
- The method naturally provides optimal control policies, not just fixed designs, and demonstrates robustness to observation noise

## Why This Works (Mechanism)

### Mechanism 1
Joint knowledge gradient (jKG) outperforms two-step approaches because it optimizes fixed design and control policy simultaneously, avoiding wasteful re-initialization. The joint acquisition function evaluates the expected change in the posterior mean maximum after a new observation, accounting for the coupling between here-and-now and wait-and-see decisions. This allows it to focus exploration on regions that improve both variables together. Core assumption: The posterior mean and covariance of the expected objective converge uniformly to continuous limits as more data is collected. Evidence anchors: Theorem 3.2 proves almost sure and mean convergence of recommendations. Break condition: If the coupling between fixed design and control policy is weak or the problem becomes separable, the advantage of joint optimization diminishes.

### Mechanism 2
The alternating knowledge gradient (aKG) achieves similar performance to jKG with fewer computational approximations. By alternating between acquisition functions that improve either the fixed design or adjustable variables separately, aKG avoids the quasi-Monte Carlo approximation over the next observation required in jKG. Each step reduces uncertainty in one variable type while holding the other fixed. Core assumption: The problem structure allows effective decomposition into two alternating subproblems without losing global optimality. Evidence anchors: "demonstrate empirically that both of these perform similarly" and "computationally efficient approximation". Break condition: If the alternating steps create significant model drift or if the subproblems are highly coupled, performance may degrade.

### Mechanism 3
Knowledge gradient naturally handles observation noise and partial information, unlike expected improvement. KG measures the expected change in the maximum of the posterior mean after a noisy observation, making it robust to uncertainty in the observations themselves. This is crucial when each evaluation is expensive and noisy. Core assumption: The observation noise follows a known distribution (typically Gaussian) and the GP surrogate can model this noise. Evidence anchors: "knowledge-gradient-based acquisition function" and "expensive black-box evaluations". Break condition: If observation noise is extremely high relative to signal or if noise distribution is misspecified, KG performance may suffer.

## Foundational Learning

- Concept: Gaussian Process (GP) surrogate modeling
  - Why needed here: GPs provide a probabilistic model of the expensive black-box objective, enabling uncertainty quantification and efficient acquisition function optimization.
  - Quick check question: What kernel would you choose for a function with multiple length scales in different dimensions?

- Concept: Knowledge Gradient acquisition function
  - Why needed here: KG measures the expected improvement in the optimal solution after a new observation, making it suitable for problems where we care about the final recommendation, not just immediate improvement.
  - Quick check question: How does knowledge gradient differ from expected improvement in handling noisy observations?

- Concept: Two-stage stochastic optimization structure
  - Why needed here: Understanding the separation between here-and-now decisions (fixed design) and wait-and-see decisions (adjustable variables) is crucial for formulating the problem correctly.
  - Quick check question: In the supply chain example, which decisions must be made before uncertainty is resolved?

## Architecture Onboarding

- Component map: GP surrogate model (constant mean, Matérn-5/2 kernel with ARD) -> Acquisition function optimizer (multi-start L-BFGS-B with Boltzmann sampling) -> Quasi-Monte Carlo approximation (scrambled Sobol' sequences) -> Recommendation generator (one-shot optimization of fixed design, single-start for control policy) -> Caching layer (cross-covariances between training data and discretization)

- Critical path: Initialize with space-filling design -> Fit GP hyperparameters (MAP estimation) -> Optimize acquisition function to select next evaluation point -> Evaluate expensive objective -> Update GP and repeat until budget exhausted -> Generate final recommendation

- Design tradeoffs: Joint vs. alternating: Joint requires MC approximation over next observation but optimizes both variables together; alternating avoids this but may create model drift. Discretization size: Larger discretizations improve acquisition function accuracy but increase computational cost. Raw samples in acquisition optimization: More raw samples improve exploration but increase initialization time.

- Failure signatures: Poor convergence: Check if acquisition function optimization is stuck in local optima (increase raw samples or restarts). High regret: Verify GP hyperparameters are being updated correctly and that discretization is adequate. Memory issues: Monitor cross-covariance matrix sizes, especially for high-dimensional problems.

- First 3 experiments: Run jKG on a simple 2D synthetic problem (dx=dy=du=1) to verify basic functionality and compare with random sampling. Test aKG vs jKG on a problem with different length scales to observe the effect of alternating vs joint optimization. Validate noise handling by running with known observation noise and comparing to noiseless case.

## Open Questions the Paper Calls Out

### Open Question 1
How would the joint knowledge gradient algorithm perform on higher-dimensional two-stage stochastic optimization problems, such as wind farm layout design with hundreds of parameters? The authors mention this as a limitation in the discussion section, noting that their current implementation may not scale well to problems with hundreds of parameters like wind farm layout. Extending to higher dimensions would require incorporating recent ideas from high-dimensional Bayesian optimization research. Empirical results showing the algorithm's performance on synthetic or real-world problems with hundreds of dimensions, compared to other methods, would resolve this question.

### Open Question 2
Can the joint knowledge gradient algorithm be extended to handle black-box constraints in addition to the existing box constraints on the variable spaces? The authors mention this as a potential future research direction, stating that while the algorithm can support optimizing over constrained spaces X and Y, it would be interesting to extend it to handle black-box constraints as in (Ungredda & Branke, 2024). The current implementation only supports optimizing over constrained spaces X and Y, but does not handle black-box constraints where the feasibility of a solution cannot be determined without expensive function evaluations. A modified version of the algorithm that incorporates black-box constraint handling, along with empirical results showing its performance on constrained problems, would resolve this question.

### Open Question 3
How would the joint knowledge gradient algorithm perform when using alternative acquisition functions, such as expected improvement or entropy-based methods, instead of knowledge gradient? The authors choose knowledge gradient because it naturally handles partial information and observation noise, and has been successfully used in related problems. However, they do not explore alternative acquisition functions. Empirical results comparing the joint knowledge gradient algorithm to versions using alternative acquisition functions on the same set of problems would resolve this question.

## Limitations
- Computational complexity scales with discretization size, becoming prohibitive for high-dimensional wait-and-see decisions
- Asymptotic consistency guarantees rely on uniform convergence assumptions that may not hold for highly non-smooth or discontinuous objectives
- The method assumes known observation noise distributions, which may not hold in practice

## Confidence

Confidence in the joint knowledge gradient method's superiority (High): The theoretical foundation is solid with proven asymptotic consistency, and empirical results consistently show improvement over baselines across multiple problem types and dimensions.

Confidence in the alternating knowledge gradient approximation (Medium): While empirical results show comparable performance, the theoretical justification is weaker, and the method's effectiveness may degrade for problems with strong coupling between here-and-now and wait-and-see decisions.

Confidence in the computational efficiency claims (Medium): The paper demonstrates significant speedups on tested problems, but scaling behavior for very high-dimensional problems remains unexplored.

## Next Checks

1. **Scaling Analysis**: Test the method on problems with d=10 or higher wait-and-see dimensions to identify the practical limits of the quasi-Monte Carlo approximation and evaluate whether alternative approximation strategies (e.g., sparse grids) could extend the method's applicability.

2. **Noise Sensitivity**: Systematically vary the observation noise level across several orders of magnitude to quantify the method's robustness to noise misspecification and identify thresholds where performance degrades significantly.

3. **Non-Stationary Problems**: Evaluate the method on problems where the optimal control policy exhibits sharp discontinuities or non-convexities in the wait-and-see decision space to test the robustness of the GP surrogate and acquisition function optimization.