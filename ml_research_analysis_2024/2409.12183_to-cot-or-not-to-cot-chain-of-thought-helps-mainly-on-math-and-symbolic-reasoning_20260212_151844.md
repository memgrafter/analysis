---
ver: rpa2
title: To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning
arxiv_id: '2409.12183'
source_url: https://arxiv.org/abs/2409.12183
tags:
- reasoning
- symbolic
- soft
- llama
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Chain-of-thought prompting is most beneficial for tasks requiring
  symbolic reasoning such as math and formal logic, with minimal gains on commonsense
  or knowledge-based tasks. The authors found that CoT primarily aids the execution
  step of symbolic problems, but underperforms compared to tool-augmented approaches
  using external solvers.
---

# To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning
## Quick Facts
- arXiv ID: 2409.12183
- Source URL: https://arxiv.org/abs/2409.12183
- Reference count: 40
- Primary result: CoT benefits symbolic reasoning but not commonsense tasks; tool-augmentation outperforms CoT for math

## Executive Summary
This study systematically evaluates when Chain-of-Thought (CoT) prompting helps large language models (LLMs). The authors find that CoT is most effective for symbolic reasoning tasks like math and formal logic, where it aids the execution step of problem-solving. However, CoT shows minimal gains on commonsense reasoning or knowledge-based tasks. The study also demonstrates that tool-augmented approaches using external solvers outperform CoT for symbolic problems, suggesting that CoT should be applied selectively to save inference costs.

## Method Summary
The authors conducted extensive evaluations across multiple reasoning task categories using various LLMs. They compared CoT prompting against standard prompting and tool-augmented approaches. The evaluation framework included symbolic reasoning tasks (math, logic), commonsense reasoning tasks, and knowledge-based tasks. They analyzed performance patterns to identify when CoT provides benefits and when it falls short, particularly comparing against external solver approaches for math problems.

## Key Results
- CoT significantly improves performance on math and formal logic tasks
- Minimal performance gains observed for commonsense reasoning tasks
- Tool-augmented approaches outperform CoT for symbolic reasoning problems

## Why This Works (Mechanism)
Chain-of-thought prompting works by encouraging step-by-step reasoning, which is particularly beneficial for tasks requiring structured problem decomposition. For symbolic reasoning, this allows LLMs to break down complex mathematical operations or logical deductions into manageable steps. The execution phase of symbolic problems benefits most from this structured approach. However, for commonsense reasoning, which often relies on implicit knowledge and pattern recognition rather than explicit step-by-step logic, CoT provides limited additional value.

## Foundational Learning
- **Symbolic reasoning**: Formal logic and mathematical problem-solving requiring explicit step-by-step procedures. Needed because it represents the domain where CoT shows maximum benefit.
- **Commonsense reasoning**: Everyday knowledge and inference about the physical and social world. Needed to understand the contrast with symbolic reasoning where CoT underperforms.
- **Tool augmentation**: Using external solvers or computational tools alongside LLMs. Needed to evaluate CoT against more advanced approaches for symbolic tasks.
- **Prompt engineering**: Techniques for improving LLM outputs through specific prompting strategies. Needed as the foundation for understanding CoT's implementation.
- **Task decomposition**: Breaking complex problems into smaller, manageable steps. Needed to understand why CoT helps with symbolic reasoning.
- **Inference cost**: Computational resources required for LLM reasoning. Needed to contextualize the recommendation for selective CoT application.

## Architecture Onboarding
**Component Map**: User Query -> Prompt Generator -> LLM -> Output Parser -> Performance Evaluator
**Critical Path**: Prompt generation and model inference are the most resource-intensive components, particularly when CoT is applied to tasks where it provides minimal benefit.
**Design Tradeoffs**: CoT increases inference costs and latency but may improve accuracy for specific task types. The tradeoff between cost and accuracy varies significantly by task category.
**Failure Signatures**: CoT fails when tasks don't benefit from step-by-step reasoning, leading to increased computation without accuracy gains. Particularly evident in commonsense reasoning tasks.
**3 First Experiments**:
1. Test CoT on a variety of math problems of increasing complexity to verify the execution-step benefit
2. Compare CoT performance against direct computation for symbolic tasks using the same LLM
3. Evaluate CoT on multiple commonsense reasoning datasets to confirm limited benefits

## Open Questions the Paper Calls Out
The paper highlights several open questions, including the generalizability of findings across different model sizes and architectures, as the study focused on specific LLMs without exploring how results might vary with other models. The evaluation of commonsense reasoning tasks may have been limited by the specific datasets chosen, potentially missing nuances in how CoT affects different types of common-sense reasoning. Additionally, the study did not extensively explore hybrid approaches that might combine CoT with tool-augmentation strategies, leaving open questions about potential synergies between these methods.

## Limitations
- Study focused on specific LLMs, limiting generalizability across model families and sizes
- Evaluation scope may not capture the full spectrum of commonsense reasoning challenges
- Did not explore hybrid approaches combining CoT with tool augmentation

## Confidence
- High confidence: CoT significantly benefits symbolic reasoning tasks (math, formal logic)
- Medium confidence: CoT underperforms tool-augmented approaches for symbolic tasks
- Low confidence: Generalization of CoT's limited benefits to all commonsense reasoning tasks

## Next Checks
1. Conduct experiments across multiple model families (including smaller and larger models) to verify if the symbolic reasoning advantage of CoT is consistent across different LLM architectures and scales.

2. Expand commonsense reasoning evaluation to include a broader range of datasets covering social reasoning, physical reasoning, and temporal reasoning to better characterize CoT's limitations in this domain.

3. Test hybrid approaches that combine CoT with selective tool augmentation, particularly for symbolic tasks, to determine if such combinations can outperform either method alone and identify optimal integration strategies.