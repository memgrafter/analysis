---
ver: rpa2
title: 'MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors'
arxiv_id: '2409.14019'
source_url: https://arxiv.org/abs/2409.14019
tags:
- semantic
- semantics
- reconstruction
- geometry
- priors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces MOSE, a monocular semantic reconstruction
  system that leverages NeRF-based neural implicit representation to reconstruct 3D
  scenes with accurate geometry and fine-grained semantic labels from RGB images and
  noisy 2D priors. The key innovation lies in addressing inconsistent 2D semantic
  predictions and geometric degradation in texture-less regions through two proposed
  components: a locally-consistent fusion strategy (LCF) that uses class-agnostic
  segment masks to enforce semantic coherence, and a semantically-weighted geometric
  regularization (SGR) that adaptively smooths SDF fields based on learned semantic
  classes.'
---

# MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors

## Quick Facts
- arXiv ID: 2409.14019
- Source URL: https://arxiv.org/abs/2409.14019
- Reference count: 29
- Key outcome: MOSE achieves state-of-the-art 3D semantic reconstruction (56.2% mIoU) and surface reconstruction (0.776 F-score) on ScanNet by leveraging NeRF with noisy priors and proposed LCF and SGR components.

## Executive Summary
MOSE addresses the challenge of monocular 3D semantic reconstruction from RGB images with noisy 2D priors. The method introduces two key innovations: a Locally-Consistent Fusion Strategy (LCF) that uses class-agnostic segment masks to enforce semantic coherence, and a Semantically-Weighted Geometric Regularization (SGR) that adaptively smooths geometry in texture-less regions based on learned semantic classes. These components work together to overcome the limitations of existing methods that suffer from inconsistent semantic predictions and geometric degradation. Experimental results on ScanNet demonstrate significant improvements across all metrics compared to state-of-the-art baselines.

## Method Summary
MOSE extends NeRF-based neural implicit representation to jointly reconstruct geometry and semantics from monocular RGB images with noisy 2D priors. The method uses three separate MLPs for color, SDF, and semantic predictions, with LCF enforcing local semantic consistency through segment-based voting and SGR applying adaptive geometric regularization based on semantic classes. By preventing semantic gradients from flowing to the SDF MLP, the approach maintains geometric fidelity while achieving fine-grained semantic understanding. The framework operates in a joint optimization setting where appearance, geometry, and semantics are learned simultaneously but with carefully designed constraints to prevent interference between modalities.

## Key Results
- Achieves 56.2% mIoU for 3D semantic segmentation on ScanNet, outperforming state-of-the-art baselines
- Attains 61.9% mIoU for 2D semantic segmentation, demonstrating effective lifting of 2D priors to 3D
- Reconstructs accurate 3D surfaces with 0.776 F-score, significantly improving geometry quality in texture-less regions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Locally-Consistent Fusion Strategy (LCF) improves semantic coherence by enforcing class consistency within segment masks.
- Mechanism: By clustering rays within the same segment mask and voting for the most probable class, the method enforces semantic consistency at a local level, reducing the noise from inconsistent 2D predictions.
- Core assumption: Segment masks provide reliable boundaries for semantic regions, and voting within these regions produces more consistent semantic labels than pixel-wise fusion.
- Evidence anchors:
  - [abstract]: "The key motivation for our method is to leverage generic class-agnostic segment masks as guidance to promote local consistency of rendered semantics during training."
  - [section]: "We introduce a locally-consistent fusion strategy (LCF), leveraging on 2D segmentation techniques... to perceive neighboring pixels and output locally consistent semantics."
  - [corpus]: Weak evidence - corpus lacks direct comparisons of LCF vs. baseline semantic fusion methods.
- Break condition: If segment masks are inaccurate or fail to align with semantic boundaries, the voting mechanism could enforce incorrect consistency.

### Mechanism 2
- Claim: The Semantically-Weighted Geometric Regularization (SGR) improves geometry quality in texture-less regions by adaptively smoothing SDF based on semantic class.
- Mechanism: SGR increases the weight of Eikonal loss for dominant planar structures (walls, floors, ceilings) while preserving object details in other classes, leading to smoother geometry in texture-less areas without over-smoothing objects.
- Core assumption: Semantic classes can reliably indicate which regions should be smoothed (planar) versus preserved (objects), and the weighting function appropriately balances these needs.
- Evidence anchors:
  - [abstract]: "we further apply a smoothness regularization to texture-less regions for better geometric quality, thus achieving mutual benefits of geometry and semantics."
  - [section]: "we could adaptively adjust the strength of Eikonal loss based on learned semantic classes, and propose a semantically-weighted geometric regularization (SGR)"
  - [corpus]: Weak evidence - corpus lacks direct comparisons of SGR vs. standard Eikonal loss on texture-less regions.
- Break condition: If semantic classification is inaccurate in texture-less regions, SGR could either over-smooth objects or fail to smooth planar regions adequately.

### Mechanism 3
- Claim: Stopping semantic gradients from flowing to the SDF MLP prevents geometric degradation caused by noisy semantic supervision.
- Mechanism: By preventing the SDF MLP from being influenced by semantic loss, the geometry remains faithful to the input normal priors rather than distorting to accommodate noisy semantic labels.
- Core assumption: Geometry and semantics can be learned independently without mutual interference, and geometry quality is more sensitive to semantic noise than semantic quality is to geometric noise.
- Evidence anchors:
  - [section]: "It is worth to note that we prevent gradients from semantics... to SDF MLP. We empirically observe that the volume density (i.e., SDF value) often distorts to accommodate input noisy labels, leading to significant geometric degradation."
  - [section]: "Comparing Model-A with Model-B, we observe that preventing semantic gradients to other branches leads to improvements in both geometry and semantics evaluation."
  - [corpus]: Weak evidence - corpus lacks ablation studies comparing with/without gradient stopping in similar frameworks.
- Break condition: If semantic and geometric information are inherently coupled, stopping gradients could prevent beneficial interactions between modalities.

## Foundational Learning

- Concept: Neural Radiance Fields (NeRF) and implicit scene representation
  - Why needed here: MOSE builds on NeRF to represent scene appearance, geometry, and semantics in a compact neural field, which is fundamental to understanding how the method lifts 2D priors to 3D.
  - Quick check question: How does NeRF represent a 3D scene using a neural network, and what are the key components of this representation?

- Concept: Signed Distance Functions (SDF) and surface reconstruction
  - Why needed here: MOSE uses SDF fields to represent geometry, and understanding SDF is crucial for grasping how the method achieves accurate surface reconstruction from implicit representations.
  - Quick check question: What is the relationship between SDF values and surface geometry, and how does this enable accurate surface extraction?

- Concept: Semantic segmentation and multi-class classification
  - Why needed here: The method incorporates semantic labels and performs multi-class classification to achieve fine-grained semantic understanding, which is essential for the LCF and SGR components.
  - Quick check question: How does multi-class semantic segmentation work, and what challenges arise when lifting 2D semantic predictions to 3D?

## Architecture Onboarding

- Component map:
  Input: RGB images, normal priors, semantic labels, segment masks
  Color MLP -> SDF MLP -> Semantic MLP
  Losses: Photometric loss, normal loss, semantic loss, LCF loss, SGR loss
  Output: 3D semantic mesh with geometry and semantics

- Critical path:
  1. Sample rays and 3D points
  2. Render color, normal, and semantic predictions
  3. Compute losses (including LCF and SGR)
  4. Update MLPs via backpropagation
  5. Extract 3D mesh using Marching Cubes

- Design tradeoffs:
  - Joint optimization vs. independent learning: MOSE learns geometry and semantics jointly but prevents gradient flow between certain components to avoid interference.
  - Segment-based vs. pixel-based fusion: LCF uses segments for consistency but requires accurate segment masks as input.
  - Adaptive vs. uniform regularization: SGR adapts regularization strength based on semantics but requires reliable semantic classification.

- Failure signatures:
  - Inconsistent semantic patches: Indicates LCF not working properly or segment masks misaligned with semantic boundaries
  - Fragmented surfaces in texture-less regions: Suggests SGR not effectively smoothing planar areas or semantic classification failing in these regions
  - Geometric distortion to fit semantics: Indicates gradient stopping not properly implemented or semantic noise too severe

- First 3 experiments:
  1. Implement basic NeRF with geometry and appearance only, verify surface reconstruction quality
  2. Add semantic MLP and semantic loss, verify semantic predictions while keeping geometry fixed
  3. Implement LCF module, verify improvement in semantic consistency using segment masks

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends heavily on quality of input segment masks, which may not generalize to complex scenes
- Effectiveness of SGR relies on semantic classes reliably indicating geometric smoothness requirements, which may fail in mixed regions
- Gradient stopping mechanism may prevent beneficial information flow between geometry and semantics in cases where they are naturally correlated

## Confidence
- Performance claims (56.2% mIoU, 61.9% mIoU, 0.776 F-score): **High** - Results are quantitatively reported with clear baselines
- LCF effectiveness: **Medium** - Mechanism is well-explained but lacks ablation studies on segment mask quality
- SGR effectiveness: **Medium** - Adaptive regularization is conceptually sound but evidence for texture-less region improvements is indirect
- Gradient stopping benefits: **Medium** - Empirical observation is reported but theoretical justification is limited

## Next Checks
1. Test MOSE on datasets with varying noise levels in semantic priors to quantify robustness to input quality
2. Conduct ablation studies comparing LCF performance with different segment mask qualities and alternative fusion strategies
3. Evaluate SGR on scenes with mixed geometric properties (planar and non-planar) to verify adaptive regularization works across diverse scenarios