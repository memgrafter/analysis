---
ver: rpa2
title: 'PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies'
arxiv_id: '2401.09489'
source_url: https://arxiv.org/abs/2401.09489
tags:
- anomaly
- data
- time
- anomalies
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PUPAE, a domain-agnostic method for explaining
  time series anomalies using counterfactual explanations. The core idea is to identify
  the minimal transformation needed to make an anomaly resemble normal data, following
  the format "Would be like A, except for corruption B." The method tests various
  operators including uniform scaling, occlusion, warping, smoothing, reversal, linear
  trend adjustment, and piecewise normalization.
---

# PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies

## Quick Facts
- arXiv ID: 2401.09489
- Source URL: https://arxiv.org/abs/2401.09489
- Reference count: 40
- Primary result: Achieves 84.41% accuracy on synthetic benchmark with 9,600 time series for identifying inserted anomaly types

## Executive Summary
PUPAE introduces a novel approach for explaining time series anomalies using counterfactual transformations. The method identifies the minimal transformation needed to make an anomaly resemble normal data, following the format "Would be like A, except for corruption B." PUPAE tests various operators including uniform scaling, occlusion, warping, smoothing, reversal, linear trend adjustment, and piecewise normalization. A key innovation is making these diverse operators commensurate by measuring their improvement in reducing distance to normal data. Experiments show PUPAE achieves high accuracy in identifying anomaly types and provides both visual and natural language explanations that are objectively correct and actionable for domain experts.

## Method Summary
PUPAE works by taking an identified anomaly and finding the minimal transformation that makes it resemble normal data. The method uses a set of operators (scaling, occlusion, warping, smoothing, reversal, linear trend, piecewise normalization) that are applied to the anomaly. For each operator, PUPAE computes an Improvement score (I) which is the ratio of post-operator distance to normal data over original distance. The operator with the minimum I score is selected as the explanation. The approach is completely independent of the anomaly detection algorithm used, requiring only that the anomaly be identified and its nearest neighbor in normal data be found.

## Key Results
- Achieves 84.25% mean per-dataset accuracy and 84.41% general accuracy on a synthetic benchmark with 9,600 time series
- Correctly identifies anomaly types in 84.41% of cases when tested on Amazon's synthetic anomaly generator
- Successfully explains anomalies across diverse domains including particle accelerators and industrial conveyor belt systems
- Provides natural language explanations in the format "Would be like A, except for corruption B" that domain experts find intuitive

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method produces explanations that are both objectively correct and actionable for domain experts.
- Mechanism: By finding the minimal transformation that makes an anomaly resemble normal data, PUPAE provides a counterfactual explanation that directly answers "what would need to change to make this normal?" This format aligns with how domain experts naturally communicate about anomalies.
- Core assumption: Domain experts consistently describe anomalies using the format "Would be like A, except for corruption B."
- Evidence anchors:
  - [abstract] "Our review of the literature/checklists/user-manuals used by frontline practitioners in various domains reveals an interesting near-universal commonality. Most practitioners discuss, explain and report anomalies in the following format: The anomaly would be like normal data A, if not for the corruption B."
  - [section 2] "Returning to our original question, what format should an anomaly explanation take? Rather than impose our preferred method on the users of anomaly detection systems, it makes sense to understand how domain experts normally talk, reason and communicate about anomalies."
  - [corpus] Weak - only 5 related papers found, none directly addressing the natural language counterfactual explanation format.
- Break condition: If domain experts do not actually use this format consistently, or if the minimal transformation does not correspond to meaningful explanations in practice.

### Mechanism 2
- Claim: The set of operators is expressive enough to explain most real-world anomalies.
- Mechanism: The paper tests various operators including uniform scaling, occlusion, warping, smoothing, reversal, linear trend adjustment, and piecewise normalization. These operators are designed to capture the most common types of anomalies found in time series data.
- Core assumption: The operators cover the majority of anomaly types that appear in real-world time series data.
- Evidence anchors:
  - [section 4] "We are now able to explain our proposed operators. These operators are based on our inspection of all publicly available TSAD benchmarks [17][24][44][45], reviewing the literature [2][12][22][25][36], and interviews with several domain experts in cardiology..."
  - [section 6.3] "A recently published paper by a research group in Amazon [17] includes a sophisticated tool for generating plausible synthetic anomalies. In Figure 14 we show their plot introducing this tool."
  - [corpus] Weak - the related papers focus on different explanation methods but do not validate the operator coverage.
- Break condition: If real-world anomalies exist that cannot be explained by any of the operators, or if the operators miss common anomaly types.

### Mechanism 3
- Claim: Making operators commensurate through Improvement scores allows fair comparison and selection of the best explanation.
- Mechanism: All operators return distances that are either ED or based on ED. The Improvement score (ratio of post-operator distance to original distance) provides a common metric for comparison across different operators with different units.
- Core assumption: A lower Improvement score indicates a more plausible explanation, regardless of which operator produced it.
- Evidence anchors:
  - [section 5] "All our proposed operators return distances that are either ED or based on ED... For all operators we define a scalar I (Improvement), which is simply the ratio of the new, post-operator distance divided by the original distance."
  - [section 5.1] "Equation 1: Anomaly Explanations provided by PUPAE... f* = argmin fi,θ∈F (min θ ED(Â, TN)/ED(A, TN)), Â = fθ(A)"
  - [corpus] Weak - no direct evidence about the effectiveness of this commensuration approach.
- Break condition: If the Improvement score does not reliably indicate which explanation is most plausible, or if some operators consistently produce misleadingly good scores.

## Foundational Learning

- Concept: Counterfactual explanations
  - Why needed here: The entire approach is built on providing counterfactual explanations in the format "Would be like A, except for corruption B"
  - Quick check question: Can you explain what a counterfactual explanation is and give an example of how it differs from other types of explanations?

- Concept: Time series distance measures (Euclidean, DTW)
  - Why needed here: The operators use various distance measures to quantify similarity between time series, and DTW is specifically mentioned as important for handling warping anomalies
  - Quick check question: What is the difference between Euclidean distance and Dynamic Time Warping for time series, and when would you use each?

- Concept: Time series preprocessing and transformation
  - Why needed here: The operators perform various transformations (scaling, smoothing, flipping, etc.) on time series data to explain anomalies
  - Quick check question: What are some common preprocessing techniques for time series data, and how might they affect anomaly detection?

## Architecture Onboarding

- Component map: Input anomaly -> Nearest neighbor search -> Operator application -> Distance calculation -> I score computation -> Best explanation selection

- Critical path: Anomaly detection → Nearest neighbor search → Operator application → Distance calculation → I score computation → Best explanation selection

- Design tradeoffs:
  - Operator expressiveness vs. computational complexity: More operators provide better coverage but increase computation time
  - Granularity of operator parameters: Fine-grained parameters may capture nuances but increase search space
  - Independence from TSAD algorithm: Provides flexibility but may miss algorithm-specific insights

- Failure signatures:
  - All operators produce high I scores: The anomaly may be too complex for single-operator explanation
  - Multiple operators produce similar I scores: The anomaly may have multiple contributing factors
  - Explanation does not match domain expert intuition: The operator set may be missing domain-specific transformations

- First 3 experiments:
  1. Run PUPAE on a simple synthetic dataset with known anomalies to verify basic functionality
  2. Apply PUPAE to a real-world dataset with domain expert validation of explanations
  3. Benchmark PUPAE against alternative explanation methods on the Amazon synthetic anomaly dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the set of operators in PUPAE cover all anomaly types found in real-world datasets, or are there important anomaly types that require additional operators?
- Basis in paper: Explicit - The authors acknowledge "we do not claim that they are a complete set" and suggest practitioners can add custom operators.
- Why unresolved: The authors tested their operators on Amazon's synthetic anomaly generator but this may not capture all real-world anomaly types. The benchmark used is synthetic, not real-world data.
- What evidence would resolve it: Testing PUPAE on a large collection of real-world anomaly detection datasets across diverse domains to identify any anomaly types that cannot be adequately explained by the current operator set.

### Open Question 2
- Question: How does PUPAE's performance change when using anomaly detection algorithms other than DAMP or Matrix Profile?
- Basis in paper: Explicit - The authors state "PUPAE is completely independent of the algorithm used to do the actual TSAD" and "we remind the reader that PUPAE is completely independent of the algorithm used."
- Why unresolved: All experiments in the paper use DAMP or Matrix Profile for anomaly detection. The authors claim independence but don't demonstrate it with other algorithms.
- What evidence would resolve it: Applying PUPAE to anomalies detected by various state-of-the-art TSAD algorithms (e.g., isolation forests, autoencoder-based methods, deep learning approaches) and comparing explanation quality and accuracy.

### Open Question 3
- Question: How sensitive is PUPAE's explanation quality to the choice of anomaly threshold in the detection phase?
- Basis in paper: Inferred - The authors use a threshold of μ + 3σ for defining anomalies and show results on a synthetic benchmark, but don't explore threshold sensitivity.
- Why unresolved: The paper doesn't investigate how different threshold choices affect the subsequent explanations, even though threshold selection is a critical parameter in TSAD.
- What evidence would resolve it: Systematically varying the anomaly threshold and measuring how it affects PUPAE's explanation accuracy and plausibility across multiple datasets.

## Limitations
- Operator coverage may be incomplete for all real-world anomaly types despite benchmark testing
- Single-operator limitation prevents explaining multi-causal anomalies that require combined transformations
- Synthetic benchmark validation may not fully represent the complexity of real-world time series data

## Confidence
- Mechanism 1 (natural language format): Medium - well-reasoned but based on limited corpus evidence
- Mechanism 2 (operator expressiveness): Medium - supported by benchmark review but not exhaustively validated
- Mechanism 3 (commensuration through I scores): Low - innovative approach but lacks independent validation

## Next Checks
1. Apply PUPAE to a real-world domain (e.g., cardiology) with domain expert evaluation of whether explanations match their mental models
2. Systematically test PUPAE on anomalies that combine multiple corruption types to assess operator coverage gaps
3. Compare PUPAE's Improvement score selection against alternative ranking methods (e.g., weighted combination of operator-specific metrics)