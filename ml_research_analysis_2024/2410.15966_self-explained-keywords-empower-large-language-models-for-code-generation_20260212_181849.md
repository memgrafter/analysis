---
ver: rpa2
title: Self-Explained Keywords Empower Large Language Models for Code Generation
arxiv_id: '2410.15966'
source_url: https://arxiv.org/abs/2410.15966
tags:
- problem
- number
- first
- llms
- keywords
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of low-frequency terms in code
  generation by large language models (LLMs), which often leads to misunderstanding
  or overlooking of problem-specific keywords. To tackle this, the authors propose
  a novel technique called Self-Explained Keywords (SEK).
---

# Self-Explained Keywords Empower Large Language Models for Code Generation

## Quick Facts
- arXiv ID: 2410.15966
- Source URL: https://arxiv.org/abs/2410.15966
- Reference count: 40
- Key outcome: SEK improves DeepSeek-Coder-V2-Instruct Pass@1 from 85.4% to 93.3% on HumanEval

## Executive Summary
This paper addresses the challenge of low-frequency terms in code generation by large language models (LLMs), which often leads to misunderstanding or overlooking of problem-specific keywords. To tackle this, the authors propose a novel technique called Self-Explained Keywords (SEK). SEK automatically identifies and explains low-frequency, problem-specific terms using the LLM itself and ranks them based on frequency. The method involves three main steps: extracting and explaining keywords, ranking them by importance, and enriching the problem description with the ranked keywords and their explanations. Experimental results across three benchmarks (HumanEval(+), MBPP(+), and APPS) with five representative LLMs demonstrate that SEK significantly improves code generation performance, yielding substantial and consistent gains.

## Method Summary
SEK works by first extracting low-frequency, problem-specific keywords from problem descriptions and using the LLM to generate explanations for these terms. The keywords are then ranked by frequency using TF-IDF scoring, with lower-frequency terms receiving higher priority. Finally, the problem description is enriched by appending the ranked keywords and their explanations. This process leverages the LLM's pre-trained semantic understanding capabilities while exploiting position bias to ensure important concepts receive focused attention. The approach trades computational overhead (two LLM calls per problem) for improved code generation accuracy.

## Key Results
- SEK improves Pass@1 score from 85.4% to 93.3% on HumanEval with DeepSeek-Coder-V2-Instruct
- SEK achieves substantial and consistent gains across three benchmarks (HumanEval+, MBPP+, APPS)
- SEK helps LLMs shift attention from low-frequency keywords to their corresponding high-frequency counterparts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs possess inherent semantic understanding capabilities for low-frequency terms after pre-training on large-scale general corpora.
- Mechanism: The LLM can interpret and explain low-frequency problem-specific keywords using its existing knowledge from pre-training, even when these terms have insufficient direct code examples in training data.
- Core assumption: LLMs have been exposed to enough general language context during pre-training to understand the semantic meaning of low-frequency terms, even if they haven't seen many code examples using them.
- Evidence anchors:
  - [abstract] "Although the direct mapping from low-frequency terms to code is rare in code corpora, the semantics of these terms are typically understandable by LLMs after pre-training on large-scale general corpora."
  - [section] "Our key insight is that LLMs inherently possess strong understanding and reasoning abilities after training on large-scale general corpora, enabling them to explain crucial concepts within a problem description."
- Break condition: If the LLM lacks sufficient general knowledge about the specific low-frequency terms, or if the terms are too domain-specific and were not covered in pre-training.

### Mechanism 2
- Claim: Positioning explanations at the end of the prompt leverages position bias to increase attention on key concepts.
- Mechanism: By appending ranked keywords and their explanations to the end of the problem description, SEK exploits the LLM's tendency to pay more attention to tokens appearing later in the prompt, ensuring critical concepts receive focused attention.
- Core assumption: LLMs have position bias where tokens at the end of prompts receive more attention, as observed in previous research on LLM behavior.
- Evidence anchors:
  - [section] "Previous research has demonstrated that LLMs are sensitive to the order of tokens in the prompt, known as position bias (Li et al., 2024b; Yu et al., 2024)."
  - [section] "pragmatic human developers tend to place more important keywords at the beginning in practice (Hunt & Thomas., 2000). This preference may be reflected in the training dataset, leading LLMs to also focus more on the keywords written at the front."
- Break condition: If the LLM's position bias is weak or if the problem description is already too long, causing the appended explanations to be truncated or ignored.

### Mechanism 3
- Claim: Frequency-based ranking prioritizes the most challenging low-frequency terms for LLM comprehension.
- Mechanism: SEK uses TF-IDF scoring to rank general keywords by importance, where lower document frequency indicates more challenging code conversion and higher importance for explanation.
- Core assumption: Lower document frequency in the training corpus correlates with LLM difficulty in mapping terms to code implementations, making these terms more critical to explain.
- Evidence anchors:
  - [section] "since keywords with lower frequency are more likely to be misunderstood or overlooked by LLMs, we use a frequency-based ranking algorithm to sort these keywords"
  - [section] "if a keyword appears less frequently in a corpus (i.e., lower document frequency), the corresponding code conversion could be more challenging as we stated in the Introduction section, and thus its explanation is more significant"
- Break condition: If the frequency ranking does not accurately reflect the actual difficulty of understanding terms for the specific LLM, or if the corpus used for frequency calculation is not representative.

## Foundational Learning

- Concept: Long-tail distribution in LLM training data
  - Why needed here: Understanding why low-frequency terms are problematic for LLMs is fundamental to grasping SEK's purpose
  - Quick check question: Why do LLMs struggle with low-frequency terms in code generation tasks?

- Concept: Chain of Thought (CoT) prompting
  - Why needed here: SEK is compared against CoT, so understanding how CoT works helps differentiate the mechanisms
  - Quick check question: How does Chain of Thought prompting differ from SEK's approach to enhancing LLM comprehension?

- Concept: Prompt engineering and in-context learning
  - Why needed here: SEK relies on carefully designed prompts with demonstrations to guide LLM behavior
  - Quick check question: What role do demonstrations play in SEK's KeyExtract & Explain step?

## Architecture Onboarding

- Component map: KeyExtract & Explain -> KeyRank -> PromptEnrich -> LLM code generation
- Critical path: The critical execution path is: problem description → KeyExtract & Explain → KeyRank → PromptEnrich → LLM code generation. This requires two LLM invocations per problem.
- Design tradeoffs: SEK trades computational overhead (two LLM calls) for improved code generation accuracy. Alternative designs could compress to one call but might lose effectiveness.
- Failure signatures: If SEK underperforms, check: (1) whether keywords are being extracted correctly, (2) if ranking is prioritizing the right terms, (3) if explanations are accurate and helpful, (4) whether position bias is being effectively leveraged.
- First 3 experiments:
  1. Run Default baseline vs SEK on HumanEval to establish baseline improvement
  2. Test with different corpora for TF-IDF scoring to verify robustness
  3. Compare with Beam Search (same number of LLM calls) to isolate SEK's unique contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SEK's performance scale with increasingly long problem descriptions?
- Basis in paper: [inferred] The paper mentions APPS problems have average 257.3 tokens, but does not test scaling effects on longer problems
- Why unresolved: The paper only tests on problems up to APPS length and doesn't systematically vary problem length
- What evidence would resolve it: Experiments showing performance degradation/improvement curves as problem description length increases

### Open Question 2
- Question: Can SEK be adapted for other programming languages beyond Python?
- Basis in paper: [inferred] The paper uses Python subsets of code corpora but doesn't test SEK on other languages
- Why unresolved: All experiments use Python benchmarks and Python-specific corpora for IDF calculation
- What evidence would resolve it: Performance comparisons of SEK on code generation tasks in languages like Java, C++, or JavaScript

### Open Question 3
- Question: What is the optimal number of demonstrations for different problem complexities?
- Basis in paper: [explicit] "Following previous work... we adopt a differentiated strategy that varies based on benchmark complexity"
- Why unresolved: The paper uses fixed demonstration numbers (2 for HumanEval, 1 for MBPP, 2 for APPS) without exploring alternatives
- What evidence would resolve it: Systematic ablation studies varying demonstration count per benchmark to find optimal values

## Limitations

- SEK's effectiveness depends on LLMs having sufficient pre-training exposure to low-frequency terms, which may not hold for highly specialized domain-specific terminology
- The method requires two LLM invocations per problem, introducing computational overhead compared to simpler prompting techniques
- The generalizability of SEK beyond programming tasks to other domains with different semantic structures remains untested

## Confidence

High confidence: The experimental results demonstrating SEK's improvement across multiple benchmarks and LLMs are well-documented and show consistent gains. The mechanism of leveraging position bias and frequency-based ranking is theoretically sound and supported by the experimental outcomes.

Medium confidence: The claim that SEK shifts LLM attention from low-frequency to high-frequency keywords is supported by attention analysis, but the causal relationship between this attention shift and improved code generation accuracy could benefit from more direct evidence linking the two phenomena.

Low confidence: The generalizability of SEK across different types of low-frequency terms and problem domains is not fully established. The paper focuses on programming tasks, and it's unclear whether the approach would work equally well for other domains with different semantic structures.

## Next Checks

1. **Ablation Study on Position Bias**: Conduct experiments varying the position of keyword explanations within the prompt (beginning, middle, end) to quantify the exact contribution of position bias to SEK's effectiveness and determine if the observed improvements are primarily due to this mechanism.

2. **Cross-Domain Transfer**: Apply SEK to non-programming tasks (e.g., mathematical reasoning, general knowledge question answering) to test whether the approach generalizes beyond code generation and identify any domain-specific limitations.

3. **Complexity Analysis of Keyword Types**: Systematically categorize the low-frequency terms that benefit most from SEK (e.g., technical jargon vs. common words in unusual contexts) to better understand which types of semantic misunderstandings SEK can address and which remain problematic.