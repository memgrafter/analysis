---
ver: rpa2
title: Rediscovering the Latent Dimensions of Personality with Large Language Models
  as Trait Descriptors
arxiv_id: '2409.09905'
source_url: https://arxiv.org/abs/2409.09905
tags:
- personality
- trait
- five
- adjectives
- principal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) implicitly
  encode personality traits in their latent spaces. The authors hypothesize that when
  LLMs generate text, they encode personality dimensions similar to the Big Five model
  without explicit questionnaires.
---

# Rediscovering the Latent Dimensions of Personality with Large Language Models as Trait Descriptors

## Quick Facts
- arXiv ID: 2409.09905
- Source URL: https://arxiv.org/abs/2409.09905
- Reference count: 40
- Primary result: LLMs can rediscover Big Five personality traits from text without explicit questionnaires

## Executive Summary
This paper investigates whether large language models implicitly encode personality traits in their latent spaces when modeling next-token responses. The authors develop a method that measures the likelihood of 100 trait-descriptive adjectives describing authors of personal stories, constructs an observation matrix of these log-probabilities, and applies singular value decomposition (SVD) to uncover latent personality dimensions. The results show that the top-5 principal components correspond to the Big Five traits, explaining 74.3% of the total variance, and that this approach achieves improved accuracy in predicting personality trait polarities compared to existing methods.

## Method Summary
The method involves computing log-probabilities for 100 trait-descriptive adjectives across a dataset of personal stories using LLMs, constructing an observation matrix from these probabilities, and applying SVD to identify latent personality dimensions. The approach uses Llama-3.1-70B, Llama-3-70B, or Mixtral-8x22B to measure how likely each adjective is to describe a story's author. The top-5 principal components from SVD are then analyzed for correspondence with Big Five traits, and the signs of elements in the factor matrix are used to predict binary personality trait polarities with Lasso regression as an optional enhancement.

## Key Results
- Top-5 principal components from SVD correspond to Big Five traits (extraversion, openness, agreeableness, neuroticism, conscientiousness)
- These components explain 74.3% of the total variance in the observation matrix
- The approach achieves up to 5% better accuracy than fine-tuned models and up to 21% better than direct LLM-based scoring for personality prediction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs implicitly encode personality trait information in their latent spaces when modeling next-token responses
- Mechanism: The LLM's token prediction probabilities capture the likelihood of personality trait descriptive adjectives being appropriate descriptors for a given text, reflecting the text's personality dimensions without explicit questionnaire inputs
- Core assumption: The lexical hypothesis holds - that personality characteristics are encoded in natural language usage patterns
- Evidence anchors:
  - [abstract] "we hypothesize that LLMs implicitly encode notions of personality when modeling next-token responses"
  - [section] "We argue that we can analyze and extract personality traits present in personal stories by carefully querying the LLM and analyzing the log-probabilities of trait-descriptive adjectives"
  - [corpus] Weak evidence - corpus shows related work on personality control and measurement in LLMs, but lacks direct evidence for this specific latent encoding mechanism
- Break condition: If the lexical hypothesis does not hold, or if LLMs do not learn personality-related linguistic patterns from their training data, this mechanism would fail

### Mechanism 2
- Claim: SVD applied to the log-probability matrix reveals latent personality dimensions that align with the Big Five model
- Mechanism: The singular value decomposition decomposes the observation matrix into factor and loading matrices, where the principal components in the loading matrix correspond to the Big Five personality dimensions based on their relationship to trait adjectives
- Core assumption: The latent personality structure in LLM token probabilities is similar to the structure discovered through human psycholexical analyses
- Evidence anchors:
  - [abstract] "Our experiments show that LLMs 'rediscover' core personality traits such as extraversion, agreeableness, conscientiousness, neuroticism, and openness"
  - [section] "We perform singular value decomposition (SVD) on the matrix to identify the top-5 factors... The sum of the top-5 squared singular values from SVD accounts for 74.3% of the total variance"
  - [corpus] Moderate evidence - corpus shows related work on Big Five traits in LLMs but doesn't directly validate the SVD alignment mechanism
- Break condition: If the latent personality structure in LLM token probabilities does not align with human personality structures, or if SVD fails to capture the relevant variance, this mechanism would break

### Mechanism 3
- Claim: The signs of elements in the factor matrix can predict binary personality trait polarities with high accuracy
- Mechanism: Each element of the factor matrix represents the association strength between a story and a latent personality factor; the sign of this element predicts whether the author exhibits the corresponding personality trait
- Core assumption: The factor matrix elements have meaningful sign-based interpretations that correlate with actual personality trait labels
- Evidence anchors:
  - [abstract] "we can use the derived principal components to assess personality along the Big Five dimensions, and achieve improvements in average personality prediction accuracy"
  - [section] "The element of U, Uij, represents the scale of the j-th Big Five trait of the i-th user. By taking the signs of the predicted scales and comparing them with binary personality labels, we measure the accuracy of personality assessment."
  - [corpus] Weak evidence - corpus lacks specific evidence about sign-based prediction accuracy for personality traits
- Break condition: If the factor matrix elements do not have consistent sign-based interpretations, or if they do not correlate with actual personality labels, this mechanism would fail

## Foundational Learning

- Concept: Singular Value Decomposition (SVD)
  - Why needed here: SVD is used to decompose the observation matrix of log-probabilities to uncover the latent personality dimensions
  - Quick check question: What do the U, Σ, and V matrices represent in SVD decomposition, and how do they relate to personality trait analysis?

- Concept: Lexical Hypothesis
  - Why needed here: This hypothesis underpins the assumption that personality traits are encoded in natural language, justifying the use of trait-descriptive adjectives
  - Quick check question: How does the lexical hypothesis explain the relationship between language use and personality trait expression?

- Concept: Big Five Personality Model
  - Why needed here: The method aims to rediscover these five dimensions (extraversion, openness, agreeableness, conscientiousness, neuroticism) through LLM analysis
  - Quick check question: What are the five dimensions of the Big Five personality model, and how were they originally derived from language analysis?

## Architecture Onboarding

- Component map: LLM prompt → log-probability measurement → observation matrix construction → SVD analysis → principal component extraction → personality prediction
- Critical path: prompt LLM → measure log-probabilities → build observation matrix → apply SVD → analyze principal components → predict personality traits
- Design tradeoffs: Using log-probabilities captures usage frequency differences but introduces potential bias; SVD provides dimensionality reduction but may lose some information; the unsupervised approach avoids label dependency but may have alignment issues with human personality models
- Failure signatures: Low explained variance (below ~70%) indicates poor latent structure capture; inconsistent correspondence between principal components and Big Five traits suggests model misalignment; low prediction accuracy (below ~70%) indicates poor personality assessment capability
- First 3 experiments:
  1. Measure log-probabilities for the 100 TDAs across the PersonaLLM dataset stories using a pretrained LLM, then verify the variance explained by top-5 components is above 70%
  2. Analyze the loading matrix to check if the top-5 principal components show clear alignment with Big Five traits by examining which adjectives have extreme loadings
  3. Compare prediction accuracy of binary personality traits using factor matrix signs against the actual labels, ensuring accuracy exceeds 70% for most traits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the discovered latent dimensions in LLMs compare to those found in human personality assessments across different languages and cultures?
- Basis in paper: [inferred] The paper demonstrates that LLMs can rediscover the Big Five personality dimensions from English text, but doesn't explore cross-linguistic or cross-cultural validity
- Why unresolved: The study only used English text data and focused on the Big Five model which was developed primarily using English-language data. Cultural differences in personality expression and linguistic diversity could affect the latent dimensions discovered by LLMs
- What evidence would resolve it: Testing the same methodology across multiple languages and cultures, comparing the resulting latent dimensions, and examining whether the Big Five structure remains consistent or if culture-specific personality dimensions emerge

### Open Question 2
- Question: What is the temporal stability of personality assessments derived from LLMs, and how do they compare to traditional test-retest reliability measures?
- Basis in paper: [explicit] The paper mentions test-retest reliability as a direction for future work, noting that "test-retest reliability evaluates the consistency of test results by administering the same test to the same group at different points in time"
- Why unresolved: The paper acknowledges this as an open direction but doesn't provide any empirical data on the stability of LLM-based personality assessments over time or under varying conditions
- What evidence would resolve it: Longitudinal studies comparing LLM-based personality assessments at multiple time points, examining how personality trait predictions change with evolving text data from the same individuals, and comparing stability to traditional personality assessments

### Open Question 3
- Question: How does the level of acquaintance or relationship between text authors and LLM assessors affect personality assessment accuracy?
- Basis in paper: [explicit] The paper mentions acquaintance as a future direction, stating that "studies indicate that acquaintance between a person and a perceiver generally enhances the assessment accuracy" and suggests simulating acquaintance with persona steering methods
- Why unresolved: While the paper identifies this as an important factor in human personality assessment, it doesn't explore whether similar effects exist in LLM-based assessments or how acquaintance might be simulated in this context
- What evidence would resolve it: Experiments varying the amount of contextual information provided to LLMs (e.g., brief bios, conversation history), measuring how personality assessment accuracy changes with different levels of acquaintance, and comparing these effects to human assessment patterns

## Limitations
- The synthetic nature of the PersonaLLM dataset (208 stories from GPT-4-0613) raises concerns about generalizability to real human-authored text
- The method assumes linear separability of personality traits through SVD, which may oversimplify complex personality structures
- Inconsistent specification of the temperature parameter (T=1) for log-probability computation affects reproducibility

## Confidence
**High Confidence:** The mathematical framework (SVD decomposition of log-probability matrices) is sound and well-established. The hypothesis that LLMs encode linguistic patterns related to personality traits is supported by the lexical hypothesis and prior work on personality in language.

**Medium Confidence:** The claim that top-5 principal components correspond to Big Five traits (explaining 74.3% variance) is supported by results but lacks external validation on real-world data. The improvement claims over fine-tuned models (5%) and direct scoring (21%) are based on comparisons within the synthetic dataset.

**Low Confidence:** The generalizability of findings to diverse real-world text sources and different LLM architectures remains unproven. The sign-based prediction mechanism for binary traits lacks thorough validation beyond the PersonaLLM dataset.

## Next Checks
1. Apply the method to a large corpus of human-authored personal stories (e.g., blog posts, social media content) and verify that the top-5 principal components still align with Big Five traits and maintain high explained variance
2. Test the approach across multiple LLM architectures (transformer variants, different pretraining objectives) to determine if the latent personality structure is architecture-dependent or universal
3. Evaluate whether the latent personality dimensions remain stable across different temperature settings and generation strategies, or if they are artifacts of specific decoding parameters