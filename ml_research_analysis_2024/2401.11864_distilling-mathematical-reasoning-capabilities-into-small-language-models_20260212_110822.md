---
ver: rpa2
title: Distilling Mathematical Reasoning Capabilities into Small Language Models
arxiv_id: '2401.11864'
source_url: https://arxiv.org/abs/2401.11864
tags:
- reasoning
- slms
- dataset
- eotd
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method to compress advanced mathematical
  reasoning capabilities of large language models (LLMs) into smaller models with
  under one billion parameters, without sacrificing performance. The approach introduces
  Equation-of-Thought Distillation (EoTD), which encapsulates reasoning into equation-based
  representations, and Ensemble Thoughts Distillation (ETD), which combines Chain-of-Thought,
  Program-of-Thought, and Equation-of-Thought reasoning paths.
---

# Distilling Mathematical Reasoning Capabilities into Small Language Models

## Quick Facts
- **arXiv ID**: 2401.11864
- **Source URL**: https://arxiv.org/abs/2401.11864
- **Reference count**: 40
- **Primary result**: Compresses advanced mathematical reasoning capabilities of large language models into small models under one billion parameters while achieving state-of-the-art performance

## Executive Summary
This paper presents a method to compress advanced mathematical reasoning capabilities from large language models (LLMs) into smaller language models (SLMs) with under one billion parameters. The approach introduces Equation-of-Thought Distillation (EoTD), which encapsulates reasoning into equation-based representations, and Ensemble Thoughts Distillation (ETD), which combines Chain-of-Thought, Program-of-Thought, and Equation-of-Thought reasoning paths. Experimental results show that EoTD significantly boosts the reasoning abilities of small models, while ETD enables them to achieve state-of-the-art performance. For example, EoTD improved CodeT5-Small's accuracy on GSM8K from 1.1% to 18.87%, and ETD raised CodeT5-Large's accuracy on GSM8K to 42.45%.

## Method Summary
The approach involves generating equation-based reasoning data from LLMs using ChatGPT, filtering this data through external solvers (equation solver for EoTD, Python interpreter for PoTD), and fine-tuning CodeT5 models on individual and combined datasets. EoTD represents reasoning as symbolic equations rather than executable code or textual steps, while ETD combines CoTD, PoTD, and EoTD datasets with respective prompts. The models are fine-tuned using the Huggingface library on NVIDIA 3090 GPU with 24GB RAM, using a learning rate of 5e-4 for 10 epochs. Evaluation is performed on GSM8K, ASDiv, SVAMP, and MultiArith test sets, comparing performance against baselines including proprietary LLMs, open-source LLMs, and previous fine-tuned SLMs.

## Key Results
- EoTD improved CodeT5-Small's accuracy on GSM8K from 1.1% to 18.87%
- ETD raised CodeT5-Large's accuracy on GSM8K to 42.45%
- CodeT5-Small attained 33.58% accuracy, CodeT5-Base reached 40.63%, and CodeT5-Large achieved 42.45% accuracy on GSM8K

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Equation-of-Thought Distillation (EoTD) reduces cognitive load on SLMs by offloading computation to an external Equation Solver.
- Mechanism: EoTD represents reasoning as symbolic equations rather than executable code or textual steps, allowing the model to focus on logical relationships instead of arithmetic execution.
- Core assumption: SLMs can accurately map problem semantics to symbolic equations without performing arithmetic internally.
- Evidence anchors:
  - [abstract] "Equation-of-Thought Distillation (EoTD), a novel technique that encapsulates the reasoning process into equation-based representations"
  - [section] "EoTD delegates the computational tasks to an Equation Solver, allowing the model to focus solely on generating reasoning steps."
  - [corpus] Weak evidence; no direct citations about equation-based offloading in distillation literature.
- Break condition: If the Equation Solver fails to parse or solve generated equations, or if the model cannot properly identify variables and their relationships.

### Mechanism 2
- Claim: Ensemble Thoughts Distillation (ETD) improves performance by combining complementary reasoning representations that focus on different aspects of problem-solving.
- Mechanism: Each reasoning path (CoT, PoT, EoT) captures distinct problem-solving strategies; combining them allows SLMs to learn from multiple perspectives and fallback options.
- Core assumption: Different reasoning forms provide complementary rather than redundant knowledge.
- Evidence anchors:
  - [abstract] "ETD enables these models to achieve state-of-the-art reasoning performance" through combining "Chain-of-Thought (CoT), Program-of-Thought (PoT), and Equation-of-Thought (EoT)"
  - [section] "Different reasoning forms have distinct focal points: CoT offers clear intermediate steps... EoT, based on mathematical principles and formulas, ensures high rigor and accuracy. PoT allows for reasoning automation via programming..."
  - [corpus] Moderate evidence; related work on multi-path distillation exists but not specifically with this triad.
- Break condition: If one reasoning form dominates or if the ensemble creates conflicting training signals.

### Mechanism 3
- Claim: Larger SLMs benefit more from distillation because they have greater capacity to absorb reasoning knowledge across multiple paths.
- Mechanism: Model parameter count scales the ability to represent complex reasoning patterns learned from the ensemble dataset.
- Core assumption: Parameter scaling in SLMs correlates with reasoning capability after distillation.
- Evidence anchors:
  - [abstract] "Model size is crucial for reasoning distillation efficacy in SLMs; larger models assimilate more reasoning knowledge"
  - [section] "CodeT5-Small attains 33.58% accuracy... CodeT5-Base reaches 40.63%, and CodeT5-Large achieves 42.45%"
  - [corpus] Weak evidence; scaling laws for distilled reasoning not well-established in literature.
- Break condition: If diminishing returns occur where additional parameters don't translate to reasoning improvements.

## Foundational Learning

- **Concept**: Knowledge Distillation
  - Why needed here: The entire approach relies on transferring reasoning capabilities from LLMs to SLMs
  - Quick check question: What is the difference between response-based and rationale-based distillation?

- **Concept**: Chain-of-Thought Reasoning
  - Why needed here: CoT forms one component of the ensemble and understanding its limitations is crucial
  - Quick check question: What are the main failure modes of CoT reasoning in mathematical problems?

- **Concept**: Symbolic Equation Representation
  - Why needed here: EoT requires understanding how to represent problems as systems of equations
  - Quick check question: How would you represent "John has 3 times as many apples as Mary who has 5" as an equation?

## Architecture Onboarding

- **Component map**: Teacher LLM (ChatGPT/gpt-3.5-turbo) → Dataset Generator → Dataset filtering → SLM fine-tuning → Answer extraction → Evaluation
- **Critical path**: Teacher LLM generation → Dataset filtering → SLM fine-tuning → Answer extraction → Evaluation
- **Design tradeoffs**:
  - EoT vs PoT: Equation generation requires less computation but depends on solver reliability
  - Dataset size vs quality: Larger datasets improve performance but increase filtering overhead
  - Model size vs efficiency: Larger SLMs perform better but reduce deployment benefits
- **Failure signatures**:
  - High dataset drop rates indicate generation quality issues
  - Performance gaps between reasoning paths suggest imbalanced training
  - Solver failures during evaluation indicate model output issues
- **First 3 experiments**:
  1. Generate and validate a small EoT dataset (100 samples) to verify solver integration
  2. Fine-tune CodeT5-Small on CoTD alone to establish baseline performance
  3. Compare single-path vs ensemble fine-tuning on a small validation set to measure synergy effects

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the reasoning ability of SLMs improve over time when continuously trained with new EoTD and ETD datasets?
  - Basis in paper: [inferred] The paper mentions the use of datasets for fine-tuning but does not discuss the long-term effects of continuous training on reasoning performance.
  - Why unresolved: The paper does not provide information on the sustainability or improvement of reasoning abilities over extended periods or with ongoing training.
  - What evidence would resolve it: Longitudinal studies tracking the performance of SLMs over time with continuous updates to the EoTD and ETD datasets would provide insights into the long-term effectiveness of the proposed methods.

- **Open Question 2**: What are the specific limitations of EoTD and ETD when applied to non-mathematical reasoning tasks?
  - Basis in paper: [inferred] The paper focuses on mathematical reasoning and mentions future work exploring applications beyond mathematics, but does not provide details on limitations in other domains.
  - Why unresolved: The paper does not address how the methods perform in reasoning tasks outside of mathematics, leaving uncertainty about their versatility.
  - What evidence would resolve it: Experiments applying EoTD and ETD to various non-mathematical reasoning tasks, such as logical reasoning or natural language inference, would reveal the methods' limitations and potential areas for improvement.

- **Open Question 3**: How does the quality of the initial LLM-generated datasets impact the final performance of SLMs after distillation?
  - Basis in paper: [explicit] The paper discusses the importance of data filtering and quality control but does not explore how initial dataset quality affects SLM performance.
  - Why unresolved: The paper does not provide a detailed analysis of the relationship between initial dataset quality and the effectiveness of the distillation process.
  - What evidence would resolve it: Comparative studies examining the performance of SLMs trained on datasets of varying initial quality would highlight the impact of dataset quality on the distillation outcome.

## Limitations

- The paper lacks ablation studies examining which components of the ensemble are most critical for performance gains
- Reliance on external solvers for dataset filtering introduces potential brittleness if solver accuracy drops
- The approach's effectiveness for non-mathematical reasoning tasks remains unexplored

## Confidence

- **High Confidence**: Technical implementation details of dataset generation and fine-tuning procedures are clearly specified and reproducible
- **Medium Confidence**: The claim that EoTD reduces cognitive load through equation-based offloading is plausible but not directly validated through controlled experiments
- **Medium Confidence**: Performance improvements over baseline SLMs are demonstrated, though the exact contribution of each ensemble component remains unclear
- **Low Confidence**: The assertion that larger SLMs inherently assimilate more reasoning knowledge lacks direct evidence beyond correlation in the reported results

## Next Checks

1. Conduct ablation studies to isolate the contribution of each reasoning path (CoT, PoT, EoT) and determine whether ensemble benefits come from complementary knowledge or increased dataset size
2. Test solver failure tolerance by intentionally degrading solver accuracy and measuring downstream performance impact on SLM reasoning capabilities
3. Evaluate the approach on mathematical problems requiring contextual reasoning beyond straightforward equation formulation to assess generalization limits