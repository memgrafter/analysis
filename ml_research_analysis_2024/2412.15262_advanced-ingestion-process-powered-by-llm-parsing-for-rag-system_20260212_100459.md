---
ver: rpa2
title: Advanced ingestion process powered by LLM parsing for RAG system
arxiv_id: '2412.15262'
source_url: https://arxiv.org/abs/2412.15262
tags:
- system
- page
- text
- perez
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an advanced document ingestion process for
  Retrieval-Augmented Generation (RAG) systems that addresses challenges in processing
  multimodal documents with varying structural complexity. The core methodology employs
  a multi-strategy parsing approach using LLM-powered OCR, combining FAST, LLM, and
  OCR techniques to extract content from diverse document types including presentations
  and high-text-density files.
---

# Advanced ingestion process powered by LLM parsing for RAG system

## Quick Facts
- arXiv ID: 2412.15262
- Source URL: https://arxiv.org/abs/2412.15262
- Authors: Arnau Perez; Xavier Vizcaino
- Reference count: 0
- Primary result: Improves answer relevancy and faithfulness in RAG systems through multimodal document parsing with LLM-powered OCR

## Executive Summary
This paper presents an advanced document ingestion process for Retrieval-Augmented Generation (RAG) systems that addresses challenges in processing multimodal documents with varying structural complexity. The core methodology employs a multi-strategy parsing approach using LLM-powered OCR, combining FAST, LLM, and OCR techniques to extract content from diverse document types including presentations and high-text-density files. A node-based extraction technique creates relationships between different information types while generating context-aware metadata. The system implements a Multimodal Assembler Agent and flexible embedding strategy to enhance document comprehension and retrieval capabilities.

## Method Summary
The methodology employs a multi-strategy parsing approach using FAST, LLM, and OCR techniques to extract content from diverse document types. The system creates a node-based extraction technique with hierarchical relationships between Header, Text, Table, Image, Page, and Document nodes. A Multimodal Assembler Agent synthesizes content from different parsing strategies, while Metadata Extractor, Question Generator, and Summary Generator agents create context-aware metadata. The flexible embedding strategy uses different models for text and images, with document splitting optimized for node size. The processed documents are stored in vector databases for enhanced retrieval capabilities.

## Key Results
- Experimental evaluations across multiple knowledge bases demonstrated improvements in answer relevancy and information faithfulness
- The system effectively handles diverse document structures while maintaining semantic relationships between content elements
- Contextual precision varied across document types, with some documents showing higher precision than others

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-strategy parsing approach effectively handles diverse document structures by combining FAST, OCR, and LLM techniques
- Mechanism: Each parsing strategy compensates for the limitations of others - FAST excels at extracting text and images from standard documents, OCR handles scanned documents and precise text extraction from images, while LLM provides contextual understanding and relationship mapping between content elements
- Core assumption: Different document types have unique parsing challenges that require specialized approaches, and combining these approaches creates complementary strengths
- Evidence anchors:
  - [abstract]: "The core methodology employs a multi-strategy parsing approach using LLM-powered OCR, combining FAST, LLM, and OCR techniques to extract content from diverse document types"
  - [section]: "During the preprocessing phase, we observed the remarkable capacity of the three strategies to work together in extracting content from files, with each strategy taking on more responsibility depending on the file type"
  - [corpus]: Weak evidence - corpus neighbors focus on RAG systems but don't specifically address multi-strategy parsing approaches
- Break condition: If the cost of running multiple parsing strategies exceeds the benefit of improved extraction quality, or if the strategies produce conflicting outputs that cannot be resolved through the assembling agent

### Mechanism 2
- Claim: The node-based extraction technique creates meaningful hierarchical relationships that improve retrieval relevance
- Mechanism: By creating distinct node types (Header, Text, Table, Image, Page, Document) with parent-child relationships, the system preserves document structure and enables context-aware embedding based on node hierarchy
- Core assumption: Document structure contains semantic information that can be captured through hierarchical node relationships, and this structure improves retrieval accuracy
- Evidence anchors:
  - [abstract]: "The methodology employs a node-based extraction technique that creates relationships between different information types and generates context-aware metadata"
  - [section]: "Four relationship types are established between nodes: next, previous, parent and child. Only Header nodes can possess child nodes, facilitating context window tracking and hierarchical structuring"
  - [corpus]: Moderate evidence - several related papers discuss document structure but not specifically node-based hierarchical approaches
- Break condition: If the overhead of maintaining complex node relationships outweighs retrieval improvements, or if the hierarchical structure doesn't translate to better semantic embeddings

### Mechanism 3
- Claim: Context-aware metadata generation through specialized agents improves answer relevancy and faithfulness
- Mechanism: Dedicated agents (Metadata Extractor, Question Generator, Summary Generator) create structured metadata that captures document semantics beyond raw text extraction, enabling more targeted retrieval
- Core assumption: Metadata that captures semantic relationships and context provides more effective retrieval signals than raw text alone
- Evidence anchors:
  - [abstract]: "By implementing a Multimodal Assembler Agent and a flexible embedding strategy, the system enhances document comprehension and retrieval capabilities"
  - [section]: "The metadata extraction phase employs a Metadata Extractor Agent to analyze the consolidated markdown, extracting fields such as topic, keywords and summary"
  - [corpus]: Weak evidence - corpus neighbors don't specifically address metadata generation through specialized agents
- Break condition: If the metadata generation agents produce noisy or irrelevant metadata that degrades rather than improves retrieval quality

## Foundational Learning

- Concept: Document structure analysis and parsing strategies
  - Why needed here: Understanding how different document types (PDFs, presentations, scanned documents) require different parsing approaches is fundamental to implementing the multi-strategy approach
  - Quick check question: What are the key differences between parsing standard PDFs versus scanned documents, and why do they require different strategies?

- Concept: Hierarchical information representation and node relationships
  - Why needed here: The node-based approach relies on understanding how to represent documents as hierarchical structures with meaningful relationships between different content types
  - Quick check question: How do parent-child relationships between nodes help preserve document context during retrieval?

- Concept: Vector embedding and semantic similarity
  - Why needed here: The system uses embeddings for retrieval, so understanding how different embedding strategies affect semantic matching is crucial
  - Quick check question: Why would embedding a table's description be more effective than embedding the raw table content for retrieval purposes?

## Architecture Onboarding

- Component map: Document → Parsing strategies → Assembly → Node extraction → Metadata generation → Embedding → Vector database → Retrieval → Answer generation
- Critical path: The system processes documents through three parsing strategies, assembles content using the Multimodal Assembler Agent, extracts hierarchical nodes, generates metadata through specialized agents, creates embeddings, stores in vector database, and enables retrieval
- Design tradeoffs: The multi-strategy approach increases processing time but improves extraction quality; the node-based hierarchy adds complexity but preserves document context; specialized agents add overhead but generate better metadata
- Failure signatures: Poor retrieval quality may indicate parsing strategy failures, node relationship errors, or embedding problems; low answer relevancy suggests metadata generation issues; high context precision with low recall indicates potential ranking problems
- First 3 experiments:
  1. Test parsing strategies independently on different document types to verify their individual capabilities
  2. Validate node relationships by reconstructing document structure from extracted nodes
  3. Compare retrieval quality using different embedding strategies for the same content

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the system's performance vary when processing documents with mixed content types (text, tables, images) compared to homogeneous documents?
- Basis in paper: [explicit] The paper mentions that the system was evaluated using three knowledge bases with different content types: academic articles (high text density), corporate slides (high image density), and a mixture of both.
- Why unresolved: While the paper presents overall performance metrics, it does not provide a detailed comparative analysis of how the system handles different content mixtures within a single document.
- What evidence would resolve it: A study comparing system performance on documents with varying ratios of text, tables, and images, measuring metrics like answer relevancy, faithfulness, and contextual precision for each mixture.

### Open Question 2
- Question: What is the optimal threshold for chunking large Text nodes using Recursive Splitter or Semantic Splitter?
- Basis in paper: [inferred] The paper mentions that Text nodes exceeding a size threshold are chunked using these splitters, but does not specify what this threshold is or how it was determined.
- Why unresolved: The choice of chunking threshold can significantly impact retrieval quality and computational efficiency, but the paper does not provide guidance on this parameter.
- What evidence would resolve it: Experiments testing different threshold values and their impact on system performance metrics across various document types and sizes.

### Open Question 3
- Question: How does the use of different embedding models for images (multimodal vs. text embedding) affect retrieval accuracy and system performance?
- Basis in paper: [explicit] The paper discusses that images can be embedded using either multimodal or text embedding models, but does not provide experimental results comparing these approaches.
- Why unresolved: The choice between multimodal and text embeddings for images could have significant implications for retrieval quality, but the paper does not explore this decision space.
- What evidence would resolve it: Comparative studies using both embedding approaches on the same document sets, measuring retrieval accuracy and other relevant performance metrics.

## Limitations
- The multi-strategy parsing approach introduces significant computational overhead that may not scale efficiently for large document corpora
- The node-based hierarchical structure assumes consistent document formatting that may not hold across all real-world documents
- The specialized agent-based metadata generation relies heavily on LLM performance, which can be inconsistent and may produce hallucinated or irrelevant metadata

## Confidence
- High confidence: The multi-strategy parsing approach effectively handles diverse document types through complementary techniques (supported by experimental results showing improved answer relevancy)
- Medium confidence: The node-based hierarchical structure improves retrieval quality by preserving document context (supported by improved contextual precision metrics, but limited by lack of comparative analysis against non-hierarchical approaches)
- Low confidence: The specialized agent-based metadata generation consistently improves retrieval quality across all document types (limited experimental evidence and no analysis of metadata quality consistency)

## Next Checks
1. Conduct scalability testing with large document corpora to measure computational overhead and processing time of the multi-strategy approach compared to single-strategy alternatives
2. Perform comparative analysis between node-based and flat document representation approaches across diverse document types to quantify the retrieval quality improvement from hierarchical structuring
3. Implement a quality control mechanism for metadata generation agents to measure and improve consistency, including hallucination detection and relevance scoring for generated metadata fields