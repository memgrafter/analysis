---
ver: rpa2
title: Towards a Knowledge Graph for Models and Algorithms in Applied Mathematics
arxiv_id: '2408.10003'
source_url: https://arxiv.org/abs/2408.10003
tags:
- mathematical
- data
- research
- algorithms
- http
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of FAIR (Findable, Accessible,\
  \ Interoperable, Reusable) representation of mathematical models and algorithms\
  \ in applied mathematics by developing a joint ontology and knowledge graph. The\
  \ authors merged two previously separate ontologies\u2014MathModDB for mathematical\
  \ models and MathAlgoDB for algorithms\u2014and extended them by introducing computational\
  \ tasks as the connecting element between models and algorithms."
---

# Towards a Knowledge Graph for Models and Algorithms in Applied Mathematics

## Quick Facts
- arXiv ID: 2408.10003
- Source URL: https://arxiv.org/abs/2408.10003
- Reference count: 40
- Authors merged two ontologies for mathematical models and algorithms, creating a joint system with over 250 research assets connected through computational tasks

## Executive Summary
This paper addresses the challenge of FAIR representation of mathematical models and algorithms in applied mathematics by developing a unified ontology and knowledge graph. The authors merged MathModDB (for models) and MathAlgoDB (for algorithms) ontologies, introducing computational tasks as the connecting element between them. The system enables semantic representation of mathematical research data and supports automated algorithm selection based on model properties, with two illustrative use cases demonstrating functionality across gravitational modeling and epidemiological applications.

## Method Summary
The method involves merging two previously separate ontologies into a unified system by introducing computational tasks as semantic bridges between mathematical models and algorithms. The authors extended the ontologies by distinguishing base quantities from specific use-case quantities, incorporating controlled vocabularies like QUDT for standardized metadata, and enabling metadata enrichment for both models and algorithms. The resulting knowledge graph currently contains over 250 research assets from applied mathematics across more than twenty research fields, with SPARQL queries enabling algorithm selection and a web interface for data access.

## Key Results
- Successfully merged MathModDB and MathAlgoDB ontologies into a unified system with computational tasks as linking elements
- Introduced Quantity Kind class to distinguish base quantities from specific use-case quantities, enabling standardized metadata
- Created knowledge graph with over 250 research assets from applied mathematics across 20+ research fields
- Demonstrated functionality through two use cases: gravitational effects modeling and Romanization spreading in Northern Tunisia

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Introducing a dedicated `Computational Task` class bridges the semantic gap between mathematical models and algorithms by representing the intermediate step of solving model equations.
- Mechanism: Computational tasks act as semantic connectors that link a mathematical formulation (from a model) to an algorithmic problem (in the algorithm ontology), enabling automated algorithm selection based on model properties.
- Core assumption: The relationship between a model's mathematical formulation and the computational task it requires is well-defined and can be formally represented.
- Evidence anchors:
  - [abstract] "The link between the two ontologies is established by introducing computational tasks, as they occur in modeling, corresponding to algorithmic tasks."
  - [section 3.2] "In the preliminary work, MathModDB as the ontology for mathematical models and MathAlgoDB as the ontology for algorithms were rather separate developments. However, since they represent two sides of the same epistemic coin, they have been unified in this approach."
  - [corpus] Weak evidence - no direct references to computational tasks as linking mechanisms found in neighboring papers.
- Break condition: If the computational task abstraction becomes too generic or fails to capture domain-specific nuances, the semantic bridge may not enable meaningful algorithm selection.

### Mechanism 2
- Claim: Distinguishing `Quantity` from `Quantity Kind` classes improves semantic precision by separating base quantities from specific use-case quantities.
- Mechanism: The Quantity Kind class provides controlled vocabulary links (e.g., to QUDT) for base quantities, while specific quantities in use cases can inherit these standardized definitions, reducing ambiguity and ensuring consistent interpretation across domains.
- Core assumption: Mathematical expressions in different domains share common base quantities that can be standardized, while domain-specific instances require separate representation.
- Evidence anchors:
  - [section 3.3] "The rationale behind this distinction is to enhance clarity and precision in our semantic representations by categorically separating basic quantities from the specific quantities that occur in the use cases."
  - [section 3.4] "The information was added either as data properties or annotation properties - depending on whether the information can be used to make new findings in reasoning or it should only be available to users."
  - [corpus] Weak evidence - no direct references to quantity-kind distinctions in neighboring papers.
- Break condition: If domain experts disagree on what constitutes a "base quantity" versus a "specific use-case quantity," the distinction may create more confusion than clarity.

### Mechanism 3
- Claim: Metadata enrichment through controlled vocabularies (QUDT, MSC, PhySH) enables unambiguous semantic representation and improves interoperability with external knowledge systems.
- Mechanism: By assigning standardized identifiers to quantities, research fields, and other ontology elements, the knowledge graph can connect with external databases (Wikidata, ORKG) and enable cross-domain reasoning and discovery.
- Core assumption: External controlled vocabularies are comprehensive enough to cover the mathematical models and algorithms being represented, and the mapping between ontology elements and vocabulary terms is accurate.
- Evidence anchors:
  - [section 3.4] "Individuals from the Quantity class can now be equipped with IDs from QUDT. Only if quantities are clearly presented, potential risks of incorrect units or misinterpretation... can be avoided."
  - [section 3.4] "In addition, individuals in the Research Field class can now be assigned identifiers from the German Research Foundation (DFG), Mathematics Subject Classification (MSC) and Physics Subject Headings (PhySH) classification systems."
  - [corpus] Weak evidence - no direct references to controlled vocabulary integration in neighboring papers.
- Break condition: If the controlled vocabularies are incomplete or mappings are incorrect, the metadata enrichment could introduce errors or limit the system's ability to represent novel concepts.

## Foundational Learning

- Concept: Semantic Web technologies (RDF, OWL, SPARQL)
  - Why needed here: The knowledge graph is built using semantic web standards to enable machine-readable representation, reasoning, and querying of mathematical models and algorithms.
  - Quick check question: How would you represent the relationship "Mathematical Model contains Mathematical Formulation" using RDF triples?

- Concept: Ontology design patterns
  - Why needed here: The paper extends existing ontologies by introducing new classes (Computational Task, Quantity Kind) and relationships, requiring understanding of how to structure knowledge for both human and machine consumption.
  - Quick check question: What design pattern would you use to represent the "requires" and "recommends" relationships between algorithms and model properties?

- Concept: Knowledge graph population and maintenance
  - Why needed here: The system currently relies on manual curation but plans to automate data ingestion, requiring understanding of data quality assurance and knowledge graph lifecycle management.
  - Quick check question: What challenges might arise when automatically extracting mathematical model information from research papers?

## Architecture Onboarding

- Component map:
  - MathModDB ontology: Classes for mathematical models, formulations, quantities, research fields
  - MathAlgoDB ontology: Classes for algorithms, software, benchmarks, algorithmic tasks
  - Computational Task class: Bridges models and algorithms
  - Quantity Kind class: Provides controlled vocabulary for base quantities
  - Metadata enrichment layer: Integrates external vocabularies (QUDT, MSC, PhySH)
  - SPARQL endpoint: Enables querying and algorithm selection
  - Web interface: Allows browsing and data contribution

- Critical path: Mathematical model → Computational task → Algorithm selection → Implementation
- Design tradeoffs:
  - Manual vs. automated data ingestion: Manual ensures quality but is slow; automated would scale but risks errors
  - Granularity of ontology: More detailed classes enable precise reasoning but increase complexity
  - Integration with external vocabularies: Improves interoperability but requires maintenance of mappings

- Failure signatures:
  - SPARQL queries return no results: Likely issue with ontology mappings or property specifications
  - Algorithm recommendations are incorrect: Problems with computational task definitions or property relationships
  - Knowledge graph loading slowly: Possible issues with ontology size or query optimization

- First 3 experiments:
  1. Test SPARQL query from section 4.1 to verify basic functionality
  2. Add a simple mathematical model (like the free fall example) and verify it appears in the knowledge graph
  3. Modify a model's properties and verify algorithm recommendations update accordingly

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ontology be adapted to handle discretization more explicitly and consistently across different mathematical domains?
- Basis in paper: [explicit] The authors acknowledge that "discretization" is an essential part of modeling and simulation but is only implicitly represented in their current approach, either on the model side or algorithm side depending on the use case.
- Why unresolved: The paper identifies this as a limitation but does not propose a solution or framework for explicitly representing discretization within the ontology.
- What evidence would resolve it: A proposed extension to the ontology that explicitly captures discretization methods, their properties, and relationships to models and algorithms, along with examples demonstrating its application across multiple domains.

### Open Question 2
- Question: What strategies can be developed to partially automate the data ingestion process while maintaining high data quality?
- Basis in paper: [explicit] The authors state that "manual data ingestion" is a limitation, noting that while it guarantees high data quality, it is "tedious and time-consuming," and strategies need to be developed to partially automate this process.
- Why unresolved: The paper identifies the need for automation but does not propose specific strategies or evaluate potential trade-offs between automation and data quality.
- What evidence would resolve it: Implementation and evaluation of automated data ingestion methods (e.g., natural language processing, template-based extraction) with metrics showing acceptable data quality and efficiency improvements.

### Open Question 3
- Question: Can the joint ontology effectively handle more complex algebraic models and models from other mathematical domains beyond applied and numerical mathematics?
- Basis in paper: [explicit] The authors note that "further investigations are necessary to conclude whether or not MathModDB is able to handle more complex algebraic models and models from other domains."
- Why unresolved: The current implementation primarily contains research assets from applied and numerical mathematics, and the authors have not yet tested the ontology's scalability to other mathematical areas.
- What evidence would resolve it: Successful integration of models from diverse mathematical domains (e.g., abstract algebra, topology, pure mathematics) with appropriate metadata and semantic relationships maintained in the knowledge graph.

## Limitations

- Manual data ingestion approach limits scalability and requires significant time investment for knowledge graph population
- Discretization and numerical implementation details are only implicitly represented rather than explicitly captured in the ontology
- Current implementation primarily covers applied and numerical mathematics, with uncertain effectiveness for more complex algebraic models or other mathematical domains

## Confidence

- **Medium**: The effectiveness of computational tasks as semantic bridges between models and algorithms remains partially validated, as the paper provides only two use cases. While the theoretical framework is sound, real-world scalability across diverse mathematical domains is uncertain.
- **Low**: The manual curation approach limits the knowledge graph's comprehensiveness and raises questions about reproducibility. With over 250 assets integrated manually, the approach may not scale efficiently to larger mathematical knowledge bases.
- **Medium**: The handling of discretization and numerical implementation details is implicit rather than explicit in the ontology. This could limit the system's ability to capture important algorithmic considerations that affect model selection and implementation.

## Next Checks

1. **Automated Data Ingestion Validation**: Implement and test automated extraction of mathematical models from research papers to assess accuracy and identify error patterns in the knowledge graph population process.

2. **Algorithm Selection Performance**: Conduct systematic evaluation of algorithm recommendations across diverse mathematical problem domains to verify the computational task mechanism works consistently beyond the two presented use cases.

3. **Ontology Coverage Assessment**: Map the current ontology structure against a comprehensive corpus of applied mathematics literature to identify gaps in quantity kinds, computational tasks, and algorithmic relationships that need explicit representation.