---
ver: rpa2
title: 'IITR-CIOL@NLU of Devanagari Script Languages 2025: Multilingual Hate Speech
  Detection and Target Identification in Devanagari-Scripted Languages'
arxiv_id: '2412.17947'
source_url: https://arxiv.org/abs/2412.17947
tags:
- hate
- speech
- subtask
- languages
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses hate speech detection and target identification
  in Devanagari-scripted languages including Hindi, Marathi, Nepali, Bhojpuri, and
  Sanskrit. The proposed MultilingualRobertaClass model uses a transformer architecture
  with contextualized embeddings for multilingual and transliterated contexts.
---

# IITR-CIOL@NLU of Devanagari Script Languages 2025: Multilingual Hate Speech Detection and Target Identification in Devanagari-Scripted Languages

## Quick Facts
- arXiv ID: 2412.17947
- Source URL: https://arxiv.org/abs/2412.17947
- Reference count: 5
- Primary result: Achieved 88.40% accuracy for hate speech detection and 66.11% accuracy for target identification

## Executive Summary
This paper presents a multilingual transformer-based approach for detecting hate speech and identifying its targets in Devanagari-scripted languages (Hindi, Marathi, Nepali, Bhojpuri, and Sanskrit). The authors propose the MultilingualRobertaClass model built on ia-multilingual-transliterated-roberta, which leverages contextualized embeddings to handle linguistic diversity across these languages. The model includes a classifier head with dropout for binary classification tasks. Results show strong performance on hate speech detection (88.40% accuracy) but more modest results on target identification (66.11% accuracy).

## Method Summary
The study employs a transformer architecture fine-tuned for multilingual hate speech detection and target identification. The model uses ia-multilingual-transliterated-roberta as its base, processes input text with a maximum sequence length of 256 tokens, and includes a classifier head with 0.3 dropout rate. Training uses AdamW optimizer with learning rate 2e-5, batch size 16 for training and 64 for evaluation, with 2-5 epochs of training. The approach handles both original and transliterated text across five Devanagari-scripted languages, addressing the challenge of multilingual hate speech detection in low-resource language settings.

## Key Results
- Achieved 88.40% accuracy on hate speech detection (Subtask B) test set
- Achieved 66.11% accuracy on target identification (Subtask C) test set
- Ablation study shows performance degradation from 0.8221 to 0.8050 accuracy when reducing sequence length from 256 to 128 tokens

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model achieves high hate speech detection accuracy due to leveraging multilingual contextualized embeddings that capture shared syntactic and semantic structures across Devanagari-scripted languages.
- Mechanism: The ia-multilingual-transliterated-roberta model is pretrained on multilingual data, allowing it to recognize patterns common across Hindi, Marathi, Nepali, Bhojpuri, and Sanskrit, which share linguistic roots and often appear in transliterated forms.
- Core assumption: Shared linguistic features and transliterated scripts enable effective cross-language generalization without requiring language-specific training data.
- Evidence anchors:
  - [abstract]: "The model leverages contextualized embeddings to handle linguistic diversity, with a classifier head for binary classification."
  - [section]: "By leveraging a transformer model pretrained on multilingual data, the architecture is especially adept at handling languages with similar linguistic roots or transliterated forms, which are common in South Asian languages."
  - [corpus]: Weak - corpus shows related work on Devanagari script and multilingual models but no direct evidence of shared structure effectiveness.
- Break condition: If linguistic features are too dissimilar or transliteration patterns are inconsistent across languages, the model's cross-language generalization fails.

### Mechanism 2
- Claim: The binary classification head with dropout regularization prevents overfitting while maintaining high detection accuracy.
- Mechanism: The classifier head applies a fully connected layer, ReLU activation, and 0.3 dropout rate to the transformer's CLS token output, creating a robust binary classification decision boundary.
- Core assumption: The 768-dimensional transformer output contains sufficient semantic information for binary classification, and dropout at 0.3 rate optimally balances regularization and information retention.
- Evidence anchors:
  - [abstract]: "The model includes a classifier head with dropout for binary classification."
  - [section]: "To reduce overfitting, a dropout layer with a 0.3 rate is included, which stochastically zeroes out 30% of the neurons during training."
  - [corpus]: Weak - corpus mentions transformer-based models but lacks specific evidence about dropout effectiveness in this multilingual context.
- Break condition: If the classification task becomes more complex (multi-class) or the dataset size decreases significantly, the current dropout rate may be insufficient.

### Mechanism 3
- Claim: The sequence length of 256 tokens provides optimal context for hate speech detection in social media text.
- Mechanism: Longer sequences capture more conversational context and linguistic patterns that indicate hate speech, while the transformer architecture can process this length efficiently.
- Core assumption: Hate speech typically requires understanding context beyond individual sentences, and 256 tokens encompass most relevant contextual information in social media posts.
- Evidence anchors:
  - [section]: "tokenizing input text with a transformer-compatible tokenizer from the transformers library, setting the maximum sequence length to 256 tokens."
  - [section]: Ablation study shows reducing sequence length to 128 tokens causes accuracy drop from 0.8221 to 0.8050 for Subtask B.
  - [corpus]: Weak - corpus shows related work on Devanagari text processing but no direct evidence about optimal sequence length for hate speech detection.
- Break condition: If social media platforms adopt longer post formats or if hate speech often spans multiple posts, 256 tokens may become insufficient.

## Foundational Learning

- Concept: Multilingual transformer architectures and contextualized embeddings
  - Why needed here: The model must handle five different languages with shared scripts and linguistic features, requiring understanding of cross-language patterns
  - Quick check question: How does a multilingual transformer differ from training separate models for each language?

- Concept: Binary classification with sigmoid activation and dropout regularization
  - Why needed here: The hate speech detection task requires binary output (hate speech present/absent) with regularization to prevent overfitting on social media data
  - Quick check question: Why use sigmoid activation instead of softmax for this binary classification task?

- Concept: Ablation study methodology and hyperparameter tuning
  - Why needed here: Understanding which components (sequence length, learning rate, batch size) most affect model performance is crucial for optimization
  - Quick check question: What does an ablation study reveal that simple model evaluation cannot?

## Architecture Onboarding

- Component map: Tokenizer → ia-multilingual-transliterated-roberta → Pre-classifier (Linear + ReLU) → Dropout (0.3) → Classifier (Linear + Sigmoid) → Binary Output
- Critical path: Input text → Tokenization → Multilingual embedding extraction → CLS token processing → Classification head → Probability output
- Design tradeoffs: Longer sequence length improves context understanding but increases computational cost; higher dropout prevents overfitting but may reduce model capacity
- Failure signatures: Poor performance on transliterated text suggests tokenizer issues; inconsistent results across languages indicate multilingual model limitations; high false positives/negatives suggest classifier head problems
- First 3 experiments:
  1. Test model performance with sequence length reduced to 128 tokens to validate ablation study findings
  2. Experiment with different dropout rates (0.2, 0.4) to find optimal regularization balance
  3. Evaluate model on a held-out validation set with balanced class distribution to check for bias

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the model's performance change if we incorporated more specialized layers or attention mechanisms to better handle the complex linguistic structures in Devanagari-scripted languages?
- Basis in paper: [inferred] The paper mentions that the model's architecture could benefit from further optimization to enhance its ability to handle complex linguistic structures, especially for Task C (Target Identification).
- Why unresolved: The paper does not explore the impact of adding specialized layers or attention mechanisms, and their potential benefits remain untested.
- What evidence would resolve it: Conducting experiments with modified architectures that include specialized layers or attention mechanisms and comparing their performance to the current model would provide evidence.

### Open Question 2
- Question: Would increasing the dataset size for Subtask C (Target Identification) lead to significant improvements in performance?
- Basis in paper: [inferred] The paper notes that Subtask C has lower performance compared to Subtask B, suggesting that the task may require more data to improve results.
- Why unresolved: The paper does not investigate the impact of dataset size on model performance, leaving the relationship between data quantity and accuracy unexplored.
- What evidence would resolve it: Experimenting with larger datasets for Subtask C and evaluating the resulting performance changes would clarify the impact of data size.

### Open Question 3
- Question: How does the performance of the model vary across different Devanagari-scripted languages, such as Hindi, Marathi, Nepali, Bhojpuri, and Sanskrit?
- Basis in paper: [explicit] The paper discusses the challenges of processing multiple Devanagari-scripted languages and mentions the model's ability to handle linguistic diversity, but does not provide detailed performance metrics for each language.
- Why unresolved: The paper does not present separate performance evaluations for each language, making it unclear how well the model handles the nuances of each.
- What evidence would resolve it: Analyzing and reporting the model's performance metrics separately for each language would provide insights into its effectiveness across different linguistic contexts.

## Limitations

- Limited dataset size for target identification task (only 2,214 training samples) may lead to overfitting and insufficient representation
- Evaluation focuses on accuracy metrics without reporting class balance or confusion matrices, making it difficult to assess performance across different hate speech types
- Lack of comparison with alternative multilingual architectures prevents understanding whether the chosen model is optimal for this task

## Confidence

**High Confidence:** The claim that the model achieves 88.40% accuracy for hate speech detection and 66.11% accuracy for target identification is well-supported by the reported test results.

**Medium Confidence:** The claim that shared linguistic features across Devanagari-scripted languages enable effective cross-language generalization is plausible but not directly validated.

**Low Confidence:** The claim that the 0.3 dropout rate optimally balances regularization and information retention lacks empirical support.

## Next Checks

1. **Class Distribution and Bias Analysis:** Analyze the class distribution in the test set and compute precision, recall, and F1 scores for each class (hate vs. non-hate, and different target categories).

2. **Cross-Domain Generalization Test:** Evaluate the trained model on an external hate speech dataset from a different platform (e.g., Facebook posts or news comments) to assess whether the model generalizes beyond the NLU 2025 dataset.

3. **Ablation Study Extension:** Conduct an expanded ablation study testing different dropout rates (0.2, 0.3, 0.4) and sequence lengths (128, 256, 512 tokens) while monitoring both accuracy and training stability.