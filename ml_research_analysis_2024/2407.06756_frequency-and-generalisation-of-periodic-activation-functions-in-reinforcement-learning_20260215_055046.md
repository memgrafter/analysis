---
ver: rpa2
title: Frequency and Generalisation of Periodic Activation Functions in Reinforcement
  Learning
arxiv_id: '2407.06756'
source_url: https://arxiv.org/abs/2407.06756
tags:
- fourier
- features
- learned
- representations
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Periodic activation functions improve sample efficiency in deep
  RL but learn high-frequency representations that overfit to bootstrapped targets,
  performing worse than ReLU networks under observation noise. While initialization
  scale has minimal effect on final frequency, weight decay regularization can partially
  offset overfitting, balancing fast learning with better generalization.
---

# Frequency and Generalisation of Periodic Activation Functions in Reinforcement Learning

## Quick Facts
- **arXiv ID**: 2407.06756
- **Source URL**: https://arxiv.org/abs/2407.06756
- **Reference count**: 24
- **Primary result**: Periodic activation functions improve sample efficiency but overfit to bootstrapped targets, performing worse under observation noise.

## Executive Summary
This paper investigates the use of periodic activation functions (learned Fourier features) in reinforcement learning value function approximation. The study finds that while these activations provide better sample efficiency during training, they tend to learn high-frequency representations that overfit to noisy bootstrapped targets. This results in worse generalization performance when test states contain observation noise compared to standard ReLU networks. Weight decay regularization can partially offset this overfitting by stabilizing feature geometry, balancing the fast learning benefits with improved robustness.

## Method Summary
The authors implement Soft Actor-Critic (SAC) with learned Fourier features in the critic network, using sinusoidal activations in the first layer followed by standard ReLU layers. They train agents on 8 DeepMind Control Suite environments using proprioceptive observations, comparing learned Fourier features against ReLU baselines. The experiments include training with different weight initialization scales (β), adding Gaussian observation noise at test time to evaluate generalization, and applying weight decay regularization to periodic activations. Key metrics tracked include sample efficiency, feature frequency (measured via weight scales and neuron cycles), effective rank, and sensitivity to input perturbations.

## Key Results
- Periodic activations achieve superior sample efficiency during training compared to ReLU networks
- Learned Fourier features converge to high frequencies regardless of initialization, leading to overfitting on bootstrapped targets
- Under observation noise, periodic activations show worse generalization than ReLU networks
- Weight decay regularization (0.1) partially mitigates overfitting while maintaining fast learning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Periodic activations learn high-frequency representations regardless of initialization frequency.
- **Mechanism**: Weight growth during training causes oscillation frequencies to increase, converging to similar high-frequency values.
- **Core assumption**: Weight distributions in deep RL tend to grow in norm over training.
- **Evidence anchors**:
  - [abstract]: "periodic representations consistently converge to high frequencies regardless of their initialisation frequency."
  - [section 4.1.1]: "Weight distributions generally rise to similar scales after training regardless of their initialisaion."
  - [corpus]: Weak corpus evidence; no direct neighbor paper discussing RL weight growth dynamics.
- **Break condition**: If weight norms remain bounded or decay, learned frequencies would not converge to high values.

### Mechanism 2
- **Claim**: High-frequency representations overfit to bootstrapped targets, hurting generalization under noise.
- **Mechanism**: Sinusoidal activations become brittle: small input perturbations cause large changes in post-activation representations, reducing cosine similarity and increasing Euclidean distances.
- **Core assumption**: Bootstrapped targets in RL are noisy, and generalization requires stable feature geometry.
- **Evidence anchors**:
  - [abstract]: "periodic activation functions improve sample efficiency... but exhibit worse generalization on states with added observation noise."
  - [section 4.3]: "periodic activations are more brittle... small changes in input observations will cause larger changes in the post-activation representations than ReLU activations."
  - [corpus]: Weak; no neighbor directly measures feature brittleness under noise in RL.
- **Break condition**: If noise levels are very low or representations are regularized to low frequencies, overfitting gap narrows.

### Mechanism 3
- **Claim**: Weight decay regularization counteracts frequency growth, improving both sample efficiency and robustness.
- **Mechanism**: Penalizing large weights discourages high-frequency oscillations, stabilizing feature geometry and improving generalization.
- **Core assumption**: Regularization strength can be tuned to balance expressivity and robustness.
- **Evidence anchors**:
  - [abstract]: "weight decay regularization is able to partially offset the overfitting of periodic activation functions."
  - [section 4.4]: "we introduce a weight decay term... allowing for use to learn Fourier features which train quickly but also more robust to perturbations."
  - [corpus]: No direct neighbor evidence; weight decay effects on periodic activations are understudied in RL.
- **Break condition**: If weight decay is too strong, expressivity drops and sample efficiency suffers.

## Foundational Learning

- **Concept**: Markov decision processes (MDPs) and the structure of value functions.
  - **Why needed here**: The paper studies value function approximation with periodic activations; understanding MDPs is essential to interpret results.
  - **Quick check question**: In an MDP, what does Q(s,a) represent, and how is it related to the return G?

- **Concept**: Fourier analysis and frequency representation of functions.
  - **Why needed here**: The paper's core claim revolves around learned Fourier features and their frequency properties; basic Fourier concepts are necessary to understand "frequency" as used here.
  - **Quick check question**: In the context of periodic activations, how does the weight norm relate to the frequency of the output oscillation?

- **Concept**: Generalization and robustness in deep RL.
  - **Why needed here**: The paper contrasts sample efficiency (in-distribution) with generalization (out-of-distribution under noise); distinguishing these is key to interpreting the experimental results.
  - **Quick check question**: Why might a representation that is highly expressive (high frequency) be less robust to observation noise?

## Architecture Onboarding

- **Component map**: Input (state+action) -> Periodic layer (sinusoid/cosine) -> ReLU layers (1024 units) -> Output (value estimate)
- **Critical path**: 1) Forward pass through periodic layer → ReLU stack → output 2) Loss computed from TD error 3) Backward pass with gradients flowing through periodic activations
- **Design tradeoffs**: High initial weight scale → fast convergence but risk of high-frequency overfitting; Low initial weight scale → slower convergence but more robust final representations; Weight decay → balances speed and robustness but may hurt expressivity if too strong
- **Failure signatures**: Performance collapses at high β initializations; Generalization degrades sharply under observation noise; Feature representations become extremely sensitive to small input changes (high Euclidean distance)
- **First 3 experiments**: 1) Train periodic vs ReLU critic on walker-run, measure final weight scales and in-distribution return 2) Add observation noise at test time, compare generalization gap between periodic and ReLU 3) Apply weight decay to periodic activations, re-run noise generalization test to see if robustness improves

## Open Questions the Paper Calls Out

- **Open Question 1**: How do different weight initialization strategies affect the final frequency convergence of periodic activation functions in RL?
  - **Basis in paper**: [explicit] The paper measures weight scales assuming a diagonal Gaussian distribution and finds that despite differing initializations, weights generally converge to similar scales.
  - **Why unresolved**: The analysis only considers a specific initialization scheme and a single distributional assumption for weights.
  - **What evidence would resolve it**: Systematic experiments varying initialization methods (e.g., orthogonal, Xavier, He initialization) and comparing final frequency distributions across these schemes would clarify if the convergence to high frequencies is robust to initialization choice.

- **Open Question 2**: What is the precise relationship between the effective rank of learned Fourier features and their generalization performance under observation noise?
  - **Basis in paper**: [inferred] The paper reports that learned Fourier features have higher effective rank than ReLU features and perform worse under noise, but doesn't establish a direct causal link.
  - **Why unresolved**: While both phenomena are observed, correlation doesn't imply causation, and other factors (e.g., frequency, sensitivity to perturbations) could contribute to the generalization gap.
  - **What evidence would resolve it**: Controlled experiments that explicitly vary the effective rank (e.g., through low-rank approximations or regularization) while keeping other properties constant would determine if effective rank is a primary driver of generalization performance.

- **Open Question 3**: How does the frequency of periodic activation functions influence the stability and convergence of off-policy RL algorithms like SAC, beyond their impact on generalization?
  - **Basis in paper**: [inferred] The paper focuses on generalization and sample efficiency, but doesn't deeply analyze how frequency affects the stability of the learning process itself.
  - **Why unresolved**: While high frequency representations are shown to be brittle under noise, their effect on the convergence dynamics and stability of the underlying RL algorithm (e.g., overestimation bias, gradient variance) remains unexplored.
  - **What evidence would resolve it**: Empirical studies tracking learning curves, policy entropy, and Q-value estimates across different frequency regimes during training would reveal how frequency impacts algorithmic stability and convergence speed.

## Limitations
- The causal mechanism linking initialization scale to final frequency is not fully characterized
- Only a single weight decay strength (0.1) was tested, leaving optimal regularization uncertain
- The study focuses on proprioceptive observations without exploring vision-based inputs
- No analysis of how frequency affects algorithmic stability beyond generalization

## Confidence

- **High confidence**: Sample efficiency advantage of periodic activations in clean settings; weight growth during training leading to high-frequency convergence
- **Medium confidence**: Generalization degradation under observation noise; effectiveness of weight decay in partially offsetting overfitting
- **Low confidence**: Causal mechanism linking initialization scale to final frequency; optimal regularization strength for robustness

## Next Checks
1. **Dynamic frequency tracking**: Log neuron oscillation cycles and weight norms throughout training for multiple β initializations to clarify convergence dynamics
2. **Regularization sweep**: Test a range of weight decay strengths (e.g., 0.01, 0.1, 1.0) to map the tradeoff between expressivity and robustness
3. **Noise robustness ablation**: Isolate the effect of noise type (Gaussian vs. structured) and level on periodic vs. ReLU generalization to test brittleness claims more broadly