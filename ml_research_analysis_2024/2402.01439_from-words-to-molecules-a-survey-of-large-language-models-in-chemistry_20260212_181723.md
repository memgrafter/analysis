---
ver: rpa2
title: 'From Words to Molecules: A Survey of Large Language Models in Chemistry'
arxiv_id: '2402.01439'
source_url: https://arxiv.org/abs/2402.01439
tags:
- chemical
- molecule
- llms
- molecular
- smiles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews the integration of Large Language
  Models (LLMs) into chemistry, addressing the challenge of applying LLMs to a domain
  with specialized knowledge and distinct semantic structures. The paper categorizes
  molecular tokenization methods (character-level, atom-level, motif-level) and presents
  a taxonomy of chemical LLMs based on their pretraining data (single-domain, multi-domain,
  multi-modal).
---

# From Words to Molecules: A Survey of Large Language Models in Chemistry

## Quick Facts
- arXiv ID: 2402.01439
- Source URL: https://arxiv.org/abs/2402.01439
- Reference count: 10
- Key outcome: Comprehensive review of LLM applications in chemistry, categorizing tokenization methods and chemical LLM taxonomy

## Executive Summary
This survey systematically reviews the integration of Large Language Models into chemistry, addressing the unique challenges of applying LLMs to a domain with specialized knowledge and distinct semantic structures. The paper presents a comprehensive taxonomy of chemical LLMs based on their pretraining data (single-domain, multi-domain, multi-modal) and pretraining objectives (MLM, MPP, ATG, XMC). It identifies novel applications of LLMs in chemistry such as molecule completion, representation translation, and in-context learning for chemical tasks. The work highlights critical research directions including deeper integration with chemical knowledge (particularly quantum chemistry), continual learning for evolving chemical data, and improving model interpretability through methods like Chain-of-Thought prompting.

## Method Summary
The survey conducts a comprehensive literature review covering tokenization methods for molecular sequences, pretraining objectives for chemical LLMs, and their applications in chemistry. It categorizes existing approaches based on pretraining data types and objectives, analyzes tokenization strategies at different granularities, and identifies emerging applications and future research directions. The method involves systematic collection and categorization of relevant papers, comparative analysis of different approaches, and synthesis of findings into a structured taxonomy.

## Key Results
- Categorizes molecular tokenization methods into character-level, atom-level, and motif-level approaches
- Presents taxonomy of chemical LLMs based on pretraining data: single-domain, multi-domain, and multi-modal
- Reviews four main pretraining objectives: Masked Language Modeling, Molecular Property Prediction, Autoregressive Token Generation, and Cross-modal Contrastive learning
- Identifies unique LLM applications in chemistry including molecule completion, representation translation, and in-context learning
- Highlights future research directions: quantum chemistry integration, continual learning, and improved interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tokenization granularity directly affects LLM performance in chemistry tasks.
- Mechanism: Different tokenization approaches encode chemical information at varying levels of abstraction. Character-level tokenization treats each character as a token, which can lead to incorrect splits of multi-character entities like 'Br', but surprisingly shows effectiveness. Atom-level tokenization segments sequences into atoms, providing a more chemically meaningful representation. Motif-level tokenization breaks molecules into chemically meaningful substructures, either through chemistry-driven approaches using expert knowledge or data-driven approaches inspired by subword-level tokenization in NLP.
- Core assumption: The level of granularity in tokenization preserves or loses critical chemical information that affects model learning.
- Evidence anchors:
  - The survey explicitly categorizes tokenization methods and provides examples showing how each approach handles the same molecular sequence differently.
  - The corpus includes multiple papers demonstrating effectiveness of character-level approaches despite theoretical implausibility.
- Break condition: If the chemical task requires understanding of specific substructures or functional groups, overly granular tokenization (character-level) may lose this information, while overly coarse tokenization (atom-level) may miss important chemical patterns.

### Mechanism 2
- Claim: Cross-modal contrastive learning aligns representations from different modalities (text, graphs, images) for molecular data.
- Mechanism: Info-NCE loss and other contrastive objectives maximize similarity between representations of the same molecule across different modalities while emphasizing distinction between different molecules. This alignment allows LLMs to leverage complementary information from multiple data types.
- Core assumption: Representations from different modalities contain overlapping but complementary information about molecular structure and properties.
- Evidence anchors:
  - The survey provides the formal definition of Info-NCE loss and describes how various models deploy this objective.
  - The abstract mentions "cross-modal contrastive learning" as a key pretraining objective.
- Break condition: If the modalities contain conflicting or redundant information, or if the alignment process is poorly implemented, the contrastive learning may fail to produce meaningful representations.

### Mechanism 3
- Claim: In-context learning enables LLMs to perform chemistry tasks without model fine-tuning.
- Mechanism: LLMs can learn directly from conversation-based interactions (in-context learning), requiring no alterations to their model weights. This allows them to adapt to new tasks by providing examples in the prompt.
- Core assumption: LLMs have sufficient capacity to learn from limited examples provided in the prompt without forgetting previously learned knowledge.
- Evidence anchors:
  - The survey describes Guo et al.'s comprehensive assessment showing in-context learned generalist LLMs performing on par with chemistry-pretrained models.
  - The abstract mentions "in-context learning for chemical tasks" as a unique application.
- Break condition: If the prompt design is poor (simple prompts lead to diminished performance as shown by Castro Nascimento and Pimentel 2023), or if the task requires extensive domain-specific knowledge not present in the LLM's pretraining data.

## Foundational Learning

- Concept: Tokenization methods for molecular sequences
  - Why needed here: Understanding how molecules are converted into tokens that LLMs can process is fundamental to applying LLMs to chemistry
  - Quick check question: What are the three main categories of tokenization methods for molecules described in the survey?

- Concept: Cross-modal representation learning
  - Why needed here: Many chemistry tasks benefit from combining information from molecular sequences, graphs, and text descriptions
  - Quick check question: What loss function is commonly used for cross-modal contrastive learning in chemical LLMs?

- Concept: In-context learning capabilities of LLMs
  - Why needed here: This allows LLMs to perform chemistry tasks without expensive fine-tuning
  - Quick check question: According to the survey, what is a critical factor affecting the effectiveness of in-context learning?

## Architecture Onboarding

- Component map: Tokenization layer (converting molecules to tokens) → Pretraining framework (applying objectives like MLM, MPP, ATG, or XMC) → Application layer (chatbot, in-context learning, or representation learning). For multi-modal approaches, additional encoders process graphs, fingerprints, and images before alignment with the LLM.
- Critical path: Tokenization → Pretraining (with domain-specific objectives) → Application (task-specific modules or in-context learning)
- Design tradeoffs: Character-level tokenization is simple but may lose chemical meaning; atom-level is more meaningful but may miss patterns; motif-level captures patterns but requires more complex processing. Single-domain approaches are simpler but less versatile than multi-domain or multi-modal approaches.
- Failure signatures: Poor tokenization leading to chemically invalid representations; misaligned cross-modal representations; in-context learning failing due to poor prompt design; models unable to generalize beyond pretraining data.
- First 3 experiments:
  1. Implement character-level, atom-level, and motif-level tokenization on a small set of molecules and compare the token sequences to verify they capture appropriate chemical information.
  2. Train a simple LLM on molecular SMILES using Masked Language Modeling and evaluate its ability to predict masked tokens and generate valid molecules.
  3. Implement a basic in-context learning setup where the LLM is given examples of reaction prediction in the prompt and tested on its ability to predict products for new reactions without fine-tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal tokenization granularity for molecular representations in LLMs?
- Basis in paper: The paper categorizes tokenization methods into character-level, atom-level, and motif-level, but does not definitively determine which is optimal for different chemical tasks
- Why unresolved: Different studies show varying performance across tokenization levels depending on the task, dataset size, and molecular complexity
- What evidence would resolve it: Systematic benchmarking across diverse chemical tasks comparing all three tokenization levels with consistent model architectures and datasets

### Open Question 2
- Question: How can chemical LLMs effectively integrate quantum chemistry knowledge?
- Basis in paper: The paper identifies "further integration with chemical knowledge, particularly quantum chemistry" as a future research direction
- Why unresolved: Current chemical LLMs are "rooted in conventional theories" while chemistry evolves with quantum mechanics, creating a knowledge gap
- What evidence would resolve it: Successful implementation of quantum chemistry principles in LLMs that demonstrably improves prediction accuracy for quantum-level molecular properties

### Open Question 3
- Question: What are the best practices for continual learning in chemical LLMs?
- Basis in paper: The paper identifies "advancements in continual learning" as a future research direction due to LLMs encountering new knowledge incrementally
- Why unresolved: Chemical LLMs deployed in applications like reaction prediction face variable synthesis routes and uncertain reaction conditions requiring ongoing adaptation
- What evidence would resolve it: Proven continual learning frameworks for chemical LLMs that maintain performance on previous tasks while adapting to new chemical data without catastrophic forgetting

## Limitations

- Performance of chemical LLMs remains heavily dependent on tokenization strategies, yet the optimal granularity for different chemical tasks remains unclear
- The field faces challenges with limited domain-specific pretraining data, particularly for specialized areas like quantum chemistry
- Model interpretability remains poor - while techniques like Chain-of-Thought prompting show promise, the reasoning processes of LLMs for chemical predictions are largely opaque

## Confidence

- **High confidence**: The categorization of tokenization methods (character-level, atom-level, motif-level) and pretraining objectives (MLM, MPP, ATG, XMC) - these represent well-established NLP concepts applied to chemistry with clear theoretical foundations
- **Medium confidence**: The taxonomy of chemical LLMs by pretraining data type (single-domain, multi-domain, multi-modal) - while logically sound, the boundaries between categories can be blurry in practice
- **Low confidence**: Predictions about future research directions and the long-term impact of current approaches - the field is evolving too rapidly for definitive projections

## Next Checks

1. **Tokenization granularity validation**: Systematically compare character-level, atom-level, and motif-level tokenization on benchmark chemistry tasks (reaction prediction, property prediction) to quantify performance differences and identify optimal granularity for different task types
2. **Cross-modal alignment quality assessment**: Implement and evaluate cross-modal contrastive learning on a diverse set of molecular representations (SMILES, graphs, images) to measure how well aligned representations improve downstream task performance compared to single-modal approaches
3. **In-context learning robustness test**: Conduct controlled experiments varying prompt quality, example quantity, and task complexity to establish the boundaries of effective in-context learning for chemical reasoning tasks and identify failure modes