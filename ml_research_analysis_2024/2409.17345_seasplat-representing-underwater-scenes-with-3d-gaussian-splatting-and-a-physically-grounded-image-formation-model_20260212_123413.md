---
ver: rpa2
title: 'SeaSplat: Representing Underwater Scenes with 3D Gaussian Splatting and a
  Physically Grounded Image Formation Model'
arxiv_id: '2409.17345'
source_url: https://arxiv.org/abs/2409.17345
tags:
- underwater
- image
- color
- gaussian
- scene
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SeaSplat addresses the challenge of rendering underwater scenes
  by integrating a physically grounded underwater image formation model with 3D Gaussian
  Splatting. The method learns both the true color of the scene and the parameters
  governing underwater light attenuation and backscatter, enabling real-time novel
  view synthesis while restoring the scene's underlying appearance as if no water
  were present.
---

# SeaSplat: Representing Underwater Scenes with 3D Gaussian Splatting and a Physically Grounded Image Formation Model

## Quick Facts
- arXiv ID: 2409.17345
- Source URL: https://arxiv.org/abs/2409.17345
- Authors: Daniel Yang; John J. Leonard; Yogesh Girdhar
- Reference count: 40
- Key outcome: SeaSplat outperforms prior radiance field methods in both quantitative metrics (PSNR, SSIM, LPIPS) and qualitative depth and color restoration while maintaining computational efficiency.

## Executive Summary
SeaSplat addresses the challenge of rendering underwater scenes by integrating a physically grounded underwater image formation model with 3D Gaussian Splatting. The method learns both the true color of the scene and the parameters governing underwater light attenuation and backscatter, enabling real-time novel view synthesis while restoring the scene's underlying appearance as if no water were present. Experiments on real-world and simulated underwater datasets show SeaSplat outperforms prior radiance field methods in both quantitative metrics (PSNR, SSIM, LPIPS) and qualitative depth and color restoration. Notably, SeaSplat maintains the computational efficiency of 3D Gaussian Splatting, requiring only modest additional memory and training time.

## Method Summary
SeaSplat integrates underwater image formation physics into the 3D Gaussian Splatting framework to enable real-time rendering of underwater scenes with color restoration. The method learns both the true scene color and medium parameters (attenuation coefficients βD, backscatter coefficients βB, backscatter color B∞) simultaneously. During training, it renders color and depth images from 3D Gaussians, applies the underwater image formation model to simulate degraded underwater appearance, and optimizes using a combination of reconstruction loss, backscatter loss (using dark channel prior), gray-world loss, saturation loss, background loss, smooth depth loss, and depth-weighted reconstruction loss. The optimization interleaves updates to the 3D Gaussian representation and the medium parameters.

## Key Results
- SeaSplat achieves higher PSNR, SSIM, and lower LPIPS than vanilla 3D Gaussian Splatting and SeaThru-NeRF on underwater datasets
- The method successfully restores color and depth information in underwater scenes, removing the effects of attenuation and backscatter
- SeaSplat maintains the computational efficiency of 3D Gaussian Splatting with only modest additional memory and training time requirements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The physically grounded underwater image formation model improves 3D Gaussian Splatting depth estimation by constraining the scene representation to account for wavelength-dependent attenuation and backscatter.
- Mechanism: SeaSplat integrates the underwater image formation model into the 3D Gaussian Splatting framework, learning both the true scene color and medium parameters simultaneously. This forces the 3D Gaussians to represent the scene as it would appear without water, while the model computes attenuation and backscatter effects based on depth and wavelength to generate the degraded underwater appearance.
- Core assumption: The underwater image formation model accurately captures the physics of light propagation through water, and the depth estimates from 3D Gaussian Splatting are sufficiently accurate to parameterize the model.
- Evidence anchors:
  - [abstract]: "constrain 3D Gaussian Splatting (3DGS)...with a physically grounded underwater image formation model"
  - [section]: "By modelling the color-corrected scene, we can estimate the depth and wavelength dependent effects with the depth from our 3D Gaussian representation and the physical model described in Eq. (3)."
  - [corpus]: Weak evidence. The corpus contains related works like "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting" but no direct validation of this specific mechanism.
- Break condition: If the underwater image formation model parameters are incorrectly estimated or if the depth from 3D Gaussian Splatting is too noisy, the constraints could degrade rather than improve the representation.

### Mechanism 2
- Claim: The additional loss functions (backscatter loss, gray world hypothesis loss, saturation loss, background loss) guide the optimization to produce physically plausible underwater reconstructions.
- Mechanism: These loss functions prevent trivial solutions and encourage the 3D Gaussian representation to learn meaningful scene structure. The backscatter loss uses a dark channel prior variant to estimate backscatter parameters, the gray world loss ensures color balance, the saturation loss prevents oversaturation, and the background loss pushes low-opacity Gaussians in water-like regions.
- Core assumption: The loss functions are well-calibrated to the underwater imaging problem and do not conflict with each other or with the primary reconstruction objective.
- Evidence anchors:
  - [section]: "we introduce additional loss constraints while also interleaving optimization of the medium parameters with optimization of the underlying 3D Gaussian representation"
  - [section]: "Lbs = ∑(i, j) ∑c ||max{ ˆDc(i, j),0} + k min{ ˆDc(i, j),0}||, with hyperparameter k > 1"
  - [corpus]: Weak evidence. No direct mention of these specific loss functions in related works, though "TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian" suggests similar physics-based approaches.
- Break condition: If the hyperparameters for these loss functions are poorly chosen, they could dominate the optimization and prevent convergence to a good solution.

### Mechanism 3
- Claim: SeaSplat maintains the computational efficiency of 3D Gaussian Splatting while adding underwater restoration capabilities.
- Mechanism: By using global medium parameters instead of per-pixel sampling and leveraging the efficient rasterization of 3D Gaussians, SeaSplat adds minimal computational overhead. The additional depth rendering pass and convolution operations for medium parameters are computationally cheap compared to the core 3D Gaussian rendering.
- Core assumption: The computational cost of the additional operations (depth rendering, convolution for medium parameters) is negligible compared to the 3D Gaussian rendering pipeline.
- Evidence anchors:
  - [abstract]: "SeaSplat maintains the computational efficiency of 3D Gaussian Splatting, requiring only modest additional memory and training time"
  - [section]: "This preserves and reinforces the significant paradigm improvements from NeRFs to 3D Gaussians as seen in the high computational requirements for Sea-Thru NeRF"
  - [section]: "Inference Time: Ours 1 h 25 m 0.012 s 4.0GB"
- Break condition: If the scene complexity increases significantly or if the depth rendering becomes a bottleneck, the efficiency advantage could diminish.

## Foundational Learning

- Concept: Underwater image formation physics (attenuation and backscatter)
  - Why needed here: Understanding how light interacts with water is fundamental to constraining the 3D Gaussian representation appropriately
  - Quick check question: What are the two main physical processes that affect underwater image formation, and how do they differ in their wavelength dependence?

- Concept: 3D Gaussian Splatting rendering pipeline
  - Why needed here: The method builds upon 3D Gaussian Splatting, so understanding how it renders scenes efficiently is crucial
  - Quick check question: How does 3D Gaussian Splatting differ from NeRF in terms of scene representation and rendering efficiency?

- Concept: Physically-based rendering constraints
  - Why needed here: SeaSplat uses additional loss functions based on physical priors to guide the optimization
  - Quick check question: What is the purpose of the gray world hypothesis loss in underwater image restoration?

## Architecture Onboarding

- Component map:
  - 3D Gaussian representation (means, covariances, opacities, colors) -> Underwater image formation model (attenuation and backscatter parameters) -> Rendering pipeline (two-pass: color and depth) -> Loss functions (reconstruction, backscatter, color, saturation, background, depth smoothness) -> Optimization procedure (interleaved optimization of medium parameters and 3D Gaussian representation)

- Critical path:
  1. Initialize 3D Gaussian representation from input images
  2. For each training iteration:
     - Render color and depth images
     - Compute underwater image formation effects
     - Calculate loss components
     - Update 3D Gaussian parameters and medium parameters
  3. For inference: Render color and depth, apply image formation model

- Design tradeoffs:
  - Using global medium parameters vs. per-pixel sampling (efficiency vs. accuracy)
  - Adding physical constraints vs. maintaining flexibility in representation
  - Two-pass rendering (depth + color) vs. single-pass efficiency

- Failure signatures:
  - Floater artifacts in depth maps (indicates insufficient constraints on 3D Gaussian placement)
  - Color bleeding or unrealistic color restoration (indicates medium parameter estimation issues)
  - Slow convergence or poor reconstruction quality (indicates loss function imbalance)

- First 3 experiments:
  1. Train SeaSplat on a simple synthetic underwater scene with known ground truth to verify the medium parameter estimation and color restoration capabilities
  2. Compare depth map quality between SeaSplat and vanilla 3D Gaussian Splatting on a real underwater dataset to validate the depth improvement mechanism
  3. Perform an ablation study removing individual loss components to understand their relative importance in the optimization process

## Open Questions the Paper Calls Out
- Question: How can the method be extended to handle dynamic underwater scenes with moving objects like swaying coral?
- Basis in paper: [explicit] The authors state "the underwater world is filled with dynamic, moving objects (e.g. fan coral that sway with the currents) and our work focuses on static, underwater environments."
- Why unresolved: The current approach assumes static scenes and would not capture temporal variations in object positions or appearance.
- What evidence would resolve it: Testing the method on sequences with known moving objects and evaluating tracking accuracy and rendering quality over time.

## Limitations
- The global medium parameter assumption may struggle with scenes containing multiple water types or significant turbidity variations.
- The method's performance on highly turbid water or scenes with strong scattering effects remains untested.
- The reliance on accurate depth estimation from 3D Gaussian Splatting means that severe occlusions or reflective surfaces in underwater environments could degrade performance.

## Confidence
- **High Confidence**: The computational efficiency claims are well-supported by timing results and memory usage comparisons. The quantitative improvements over baseline methods (PSNR, SSIM, LPIPS) are robust across multiple datasets.
- **Medium Confidence**: The qualitative color restoration results appear convincing but depend heavily on the accuracy of the underwater image formation model parameters. The gray-world hypothesis may not hold in all underwater scenarios.
- **Low Confidence**: The method's generalizability to extreme underwater conditions (very turbid water, strong scattering) and its robustness to varying water types are not thoroughly evaluated.

## Next Checks
1. **Ablation study on medium parameters**: Train SeaSplat with fixed vs. learned attenuation and backscatter coefficients on the same dataset to quantify the contribution of parameter learning to final quality.
2. **Cross-water-type generalization**: Test SeaSplat trained on one water type (e.g., clear tropical water) on scenes with significantly different water properties (e.g., murky harbor water) to assess robustness.
3. **Failure case analysis**: Systematically evaluate SeaSplat on scenes with challenging underwater conditions (strong backscatter, highly reflective surfaces, extreme depth ranges) to identify specific failure modes and their severity.