---
ver: rpa2
title: Bridging the Data Provenance Gap Across Text, Speech and Video
arxiv_id: '2412.17847'
source_url: https://arxiv.org/abs/2412.17847
tags:
- arxiv
- online
- available
- visited
- http
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents the largest multimodal audit of public datasets
  used for AI training, spanning nearly 4000 datasets across text, speech, and video
  from 1990-2024. The audit traces dataset provenance including licensing, sourcing,
  and representation across 608 languages, 798 sources, and 67 countries.
---

# Bridging the Data Provenance Gap Across Text, Speech and Video

## Quick Facts
- arXiv ID: 2412.17847
- Source URL: https://arxiv.org/abs/2412.17847
- Reference count: 40
- Largest multimodal audit of public datasets used for AI training across text, speech, and video modalities

## Executive Summary
This work presents the first large-scale longitudinal audit of public datasets used for AI training across text, speech, and video modalities. Spanning nearly 4000 datasets from 1990-2024, the audit traces dataset provenance including licensing, sourcing, and representation across 608 languages, 798 sources, and 67 countries. The study reveals overwhelming reliance on web-crawled and social media sources like YouTube for training data, significant licensing inconsistencies between datasets and sources, and persistent geographical and linguistic representation inequalities despite increases in absolute numbers. The authors release their complete audit to enable better transparency and responsible AI development.

## Method Summary
The audit collected 3916 public datasets across three modalities from various repositories, with text datasets from HuggingFace and individual papers, speech datasets from OpenSLR and LRE/LRE challenges, and video datasets from the CV4Audio workshop. Each dataset was manually annotated for licenses, terms of use, sources, and representation features including languages, geographical distribution, and content types. The analysis traced dataset derivations to identify licensing inconsistencies and measured representation using Gini coefficients to quantify concentration across languages and geographies.

## Key Results
- Web-crawled, synthetic, and social media sources like YouTube dominate AI training data, especially since 2019
- While <33% of datasets are restrictively licensed, over 80% of source content carries non-commercial restrictions
- Over 55% of content shows inconsistent licensing between datasets and sources
- Despite absolute increases in languages and geographies represented, relative representation has not improved since 2013, with Gini coefficients remaining consistently high (>0.7)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The paper's findings are more robust than prior work due to multimodal scope and scale.
- Mechanism: Prior audits focused on text-only datasets or single features. This work expands coverage to 3916 datasets across text, speech, and video, spanning 608 languages, 798 sources, and 67 countries from 1990-2024. The breadth and longitudinal design capture ecosystem-level trends in data sourcing, licensing, and representation.
- Core assumption: Ecosystem-level patterns are more stable than single-dataset features.
- Evidence anchors:
  - [abstract]: "largest and first-of-its-kind longitudinal audit across modalities"
  - [section]: "nearly 4000 public datasets between 1990-2024, covering 443 unique tasks, 608 languages, derived from 798 original sources"
  - [corpus]: Corpus neighbors include papers with "Bridging" in title and "modality gap" focus; average FMR score 0.515 suggests related but not directly overlapping work.
- Break condition: If the multimodal integration is superficial or if most datasets are low-quality, the scale advantage collapses.

### Mechanism 2
- Claim: Dataset provenance complexity is driven by iterative re-packaging and missing metadata.
- Mechanism: Developers frequently repackage datasets without carrying forward licensing or sourcing information. This leads to inconsistent terms between datasets and their sources, making compliance verification difficult.
- Core assumption: Dataset re-packaging is common and metadata loss is systematic.
- Evidence anchors:
  - [abstract]: "tracing the chain of dataset derivations"
  - [section]: "tracing the lineage and distribution of licenses and terms for a given modality"
  - [corpus]: No direct corpus anchor, but corpus average FMR 0.515 suggests a specialized provenance angle.
- Break condition: If metadata tracking improves dramatically or packaging chains become transparent, the complexity drops.

### Mechanism 3
- Claim: Web and social media dominance in AI training data reflects scale and freshness needs, not quality optimization.
- Mechanism: Developers require massive, fresh, and heterogeneous data to train general-purpose models. Web crawling and social media platforms provide these properties at scale, despite higher privacy, copyright, and bias risks compared to curated sources.
- Core assumption: Scale and freshness outweigh quality in foundation model training.
- Evidence anchors:
  - [abstract]: "multimodal machine learning applications have overwhelmingly turned to web-crawled, synthetic, and social media platforms"
  - [section]: "These sources comprise the vast majority of text tokens, as well as speech and video hours in public data"
  - [corpus]: Weak evidence; corpus focuses on modality bridging, not data sourcing drivers.
- Break condition: If model architectures shift to prioritize data quality over scale, or if curated data sources scale up, this dynamic reverses.

## Foundational Learning

- Concept: License vs Terms of Service distinction
  - Why needed here: The paper distinguishes between dataset licenses (legal permissions granted) and source terms (platform rules governing content use). This distinction is critical for compliance analysis.
  - Quick check question: If a dataset is CC BY 4.0 but derived from YouTube, which restriction governs use?

- Concept: Gini coefficient as inequality measure
  - Why needed here: The paper uses Gini coefficients to quantify concentration in language and geographical representation. This allows tracking whether diversity efforts are effective.
  - Quick check question: A Gini of 0.92 for text creators means what about distribution concentration?

- Concept: Modality-specific dataset collection
  - Why needed here: Different modalities have different ecosystems (text on HuggingFace, speech on OpenSLR, video via workshops). Understanding this is key to replicating the audit.
  - Quick check question: Why does the text audit include both collections and individual datasets while speech and video do not?

## Architecture Onboarding

- Component map: Data collection -> Manual annotation -> Statistical analysis -> Visualization -> Release
- Critical path: Dataset selection -> Source tracing -> License/terms annotation -> Representation measurement
- Design tradeoffs: Breadth vs depth (auditing 4000 datasets vs detailed per-dataset analysis); Modality uniformity vs specificity (different collection processes per modality)
- Failure signatures: Incomplete source tracing -> licensing inconsistencies; Language code mapping errors -> representation misreporting; Missing dataset versions -> size measurement errors
- First 3 experiments:
  1. Replicate the annotation taxonomy on a small sample of 10 datasets from each modality
  2. Compare manual vs automated license detection accuracy
  3. Validate Gini coefficient calculations against known distributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can dataset licensing restrictions be harmonized across the AI ecosystem to enable responsible data reuse?
- Basis in paper: [explicit] The paper finds significant inconsistencies between dataset licenses and source restrictions, with over 80% of source content carrying non-commercial restrictions despite fewer than 33% of datasets having such licenses.
- Why unresolved: The paper highlights this as a challenge but does not propose solutions for harmonizing conflicting licensing terms across the complex chain of dataset derivations.
- What evidence would resolve it: Development and adoption of standardized licensing frameworks that trace and reconcile permissions across dataset derivations, along with empirical studies showing improved compliance rates.

### Open Question 2
- Question: What mechanisms can ensure fair geographical and linguistic representation in AI training data as dataset scale increases?
- Basis in paper: [explicit] Despite absolute increases in languages and countries represented, relative representation has not improved since 2013, with Gini coefficients remaining high (>0.7) and Western-centric concentration persisting.
- Why unresolved: The paper documents the persistent inequality but does not explore structural changes needed to improve representation or evaluate potential interventions.
- What evidence would resolve it: Comparative studies of representation metrics across different funding models, incentive structures, and community-driven data collection initiatives.

### Open Question 3
- Question: How can privacy, copyright, and bias risks be mitigated when using web-crawled and social media data for AI training?
- Basis in paper: [explicit] The paper finds rising use of web-crawled, synthetic, and social media sources (especially YouTube) while noting these sources are particularly prone to privacy, copyright, and factuality concerns.
- Why unresolved: While identifying the trend, the paper does not evaluate the effectiveness of different risk mitigation strategies for these data sources.
- What evidence would resolve it: Empirical comparisons of model performance and safety metrics when trained on different combinations of curated versus web-sourced data, along with validation of privacy-preserving techniques.

## Limitations

- Audit findings depend heavily on completeness of dataset metadata and accuracy of manual annotations
- Gaps in source documentation, inconsistent naming conventions, and potential exclusion of proprietary datasets introduce uncertainty
- Longitudinal analysis may be affected by changes in data collection practices over time, making it difficult to distinguish between actual trends and artifacts of evolving documentation standards

## Confidence

- High confidence: Overall patterns of web/social media dominance in training data, scale of licensing inconsistencies, persistence of representation concentration over time
- Medium confidence: Specific numerical estimates (e.g., exact percentages of restrictively licensed content) and relative ranking of sources across modalities
- Low confidence: Attribution of trends to specific causal mechanisms, particularly relationship between data sourcing practices and model performance

## Next Checks

1. Replicate the audit methodology on a smaller, controlled sample of datasets with known provenance to measure annotation accuracy and consistency
2. Conduct sensitivity analysis on the representation metrics by varying language mapping approaches and country attribution rules
3. Compare audit findings against developer surveys and platform data to validate reported trends in data sourcing and licensing practices