---
ver: rpa2
title: Retrieval Augmented Time Series Forecasting
arxiv_id: '2411.08249'
source_url: https://arxiv.org/abs/2411.08249
tags:
- mase
- time
- series
- chronos
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Retrieval Augmented Forecasting (RAF), a
  principled framework for enhancing time-series foundation models (TSFMs) through
  retrieval-augmented generation (RAG). The method retrieves relevant time-series
  patterns from external databases and incorporates them into forecasts to improve
  accuracy, especially in out-of-domain scenarios.
---

# Retrieval Augmented Time Series Forecasting

## Quick Facts
- arXiv ID: 2411.08249
- Source URL: https://arxiv.org/abs/2411.08249
- Authors: Kutay Tire; Ege Onur Taga; Muhammed Emrullah Ildiz; Samet Oymak
- Reference count: 40
- Primary result: RAF improves time-series forecasting accuracy through retrieval-augmented generation, with larger models benefiting more significantly

## Executive Summary
This paper introduces Retrieval Augmented Forecasting (RAF), a principled framework for enhancing time-series foundation models (TSFMs) through retrieval-augmented generation (RAG). The method retrieves relevant time-series patterns from external databases and incorporates them into forecasts to improve accuracy, especially in out-of-domain scenarios. RAF operates in two variants: Naive RAF (black-box use of TSFMs) and Advanced RAF (fine-tuning for better retrieval integration). Experiments with Chronos Mini and Base on 11 diverse datasets across two benchmarks show that RAF consistently outperforms baseline approaches, with larger models benefiting more significantly. For example, RAF achieves relative WQL improvements of 0.887 (Mini) and 0.733 (Base) on Benchmark I, and 0.950 (Mini) and 0.880 (Base) on Benchmark II. Fine-tuned Advanced RAF further boosts performance, demonstrating RAF's effectiveness as a resource-efficient alternative to full model retraining.

## Method Summary
RAF retrieves relevant time-series patterns from an external database and augments the input to TSFMs before forecasting. The framework consists of two variants: Naive RAF uses TSFMs as black boxes, while Advanced RAF fine-tunes models for better retrieval integration. The method involves database formation (80% of each dataset), similarity metric calculation using ℓ2 norm between embeddings, instance normalization applied separately to original and retrieved time series, and retrieval query formation by concatenating retrieved context and future with original context. The approach is evaluated on Chronos Mini and Base models across 11 diverse datasets with Weighted Quantile Loss (WQL) and Mean Absolute Scaled Error (MASE) as primary metrics.

## Key Results
- RAF achieves relative WQL improvements of 0.887 (Mini) and 0.733 (Base) on Benchmark I
- RAF achieves relative WQL improvements of 0.950 (Mini) and 0.880 (Base) on Benchmark II
- Larger models (Base) benefit more significantly from retrieval augmentation than smaller models (Mini)
- Advanced RAF (fine-tuned) further improves performance over Naive RAF

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retrieval-augmented forecasting improves accuracy in out-of-domain time series datasets by incorporating relevant external patterns.
- Mechanism: RAF retrieves time series patterns that match the query's context and augments the input with these retrieved segments before forecasting. This allows the model to leverage in-context learning capabilities by providing additional relevant historical patterns that may not be present in the original data.
- Core assumption: The model can effectively incorporate retrieved patterns into its forecasting process, and the retrieved patterns are sufficiently similar to the query to provide useful information.
- Evidence anchors:
  - [abstract] "RAF operates in two variants: Naive RAF (black-box use of TSFMs) and Advanced RAF (fine-tuning for better retrieval integration). Experiments with Chronos Mini and Base on 11 diverse datasets across two benchmarks show that RAF consistently outperforms baseline approaches"
  - [section] "RAF facilitates the model to capture these properties by augmenting the query with top matching patterns and harnessing the in-context learning capability of the TSFM"
  - [corpus] Weak evidence - no direct comparison of retrieval-augmented vs non-augmented forecasting in the corpus
- Break condition: If the retrieved patterns are not sufficiently similar to the query or if the model cannot effectively incorporate the retrieved information into its forecasting process.

### Mechanism 2
- Claim: Larger time series foundation models benefit more from retrieval augmentation than smaller models.
- Mechanism: As model size increases, the model's capacity to process and integrate more complex retrieved patterns improves, leading to greater performance gains from retrieval augmentation.
- Core assumption: The model's ability to process and utilize retrieved information scales with model size.
- Evidence anchors:
  - [abstract] "the improvement is more significant for larger TSFM sizes"
  - [section] "the relative improvement of RAF increases as the model size grows, in line with the empirical findings of RAG in large language models"
  - [section] "the Chronos Mini completely fails; that is, even without noise, it is unable to perform retrieval, indicating a failure in the basic TS-R task"
- Break condition: If the model's architecture doesn't scale its retrieval integration capabilities proportionally with size, or if other factors limit the benefit of retrieval augmentation.

### Mechanism 3
- Claim: Instance normalization applied separately to original and retrieved time series mitigates distribution shift effects.
- Mechanism: By normalizing each time series instance with zero mean and unit standard deviation before input, RAF reduces the impact of different scales and distributions between the original data and retrieved patterns.
- Core assumption: Distribution shift between original and retrieved time series is a significant factor affecting forecasting performance.
- Evidence anchors:
  - [section] "To mitigate the distribution shift effects between training and testing data, we apply instance normalization [50, 19]. We normalize each time series instance x(i) with zero mean and unit standard deviation"
  - [section] "original time series x(i) and the retrieved time series x'(i) are normalized separately before being input into the model"
  - [corpus] Weak evidence - no direct mention of instance normalization in the corpus
- Break condition: If distribution shift is not a significant factor in the forecasting task, or if the normalization process removes important information from the time series.

## Foundational Learning

- Concept: Time series motif discovery and matching
  - Why needed here: RAF fundamentally relies on identifying and matching similar patterns (motifs) in time series data to retrieve relevant historical examples.
  - Quick check question: Can you explain how the ℓ2 norm is used to find the top-n best matches between time series embeddings?

- Concept: In-context learning in transformer models
  - Why needed here: RAF leverages the in-context learning capability of TSFMs by augmenting the input with retrieved patterns, allowing the model to learn from these examples during inference.
  - Quick check question: How does in-context learning differ from fine-tuning, and why is it particularly useful for retrieval-augmented forecasting?

- Concept: Distribution shift and normalization techniques
  - Why needed here: RAF applies instance normalization to mitigate distribution shift between original and retrieved time series, which is crucial for effective pattern matching and forecasting.
  - Quick check question: What are the potential drawbacks of applying instance normalization to time series data before forecasting?

## Architecture Onboarding

- Component map:
  - Database formation (20% test split, 80% database) -> Similarity metric calculation (ℓ2 norm between embeddings) -> Instance normalization (separate for original and retrieved series) -> Retrieval query formation (concatenation of retrieved context and future with original context) -> Forecasting model (Chronos Mini or Base)

- Critical path:
  1. Index and normalize database time series
  2. Compute embeddings for query time series
  3. Calculate similarity scores with database
  4. Retrieve top-1 matching time series
  5. Form retrieval query by concatenating retrieved context, future, and original context
  6. Apply instance normalization
  7. Generate forecast using TSFM

- Design tradeoffs:
  - Larger context lengths improve pattern matching but increase computational cost
  - More sophisticated similarity metrics may improve retrieval quality but require additional computation
  - Fine-tuning for Advanced RAF improves performance but requires additional resources

- Failure signatures:
  - Poor retrieval quality (retrieved patterns not similar to query)
  - Distribution shift not adequately handled by normalization
  - Model unable to effectively incorporate retrieved information
  - Computational overhead outweighs performance benefits

- First 3 experiments:
  1. Compare RAF performance with and without instance normalization on a small dataset
  2. Test RAF with different context lengths to find optimal balance between retrieval quality and computational cost
  3. Evaluate RAF performance on a dataset where retrieval should be particularly beneficial (e.g., with known repeating patterns)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does RAF's performance scale with model size beyond Chronos Base, particularly for extremely large TSFMs?
- Basis in paper: [explicit] "Our study has also revealed that model size matters: Chronos Mini fails to solve simple synthetic retrieval tasks and larger models benefit more from retrieval-augmented forecasting both in synthetic and real experiments."
- Why unresolved: The paper only tests RAF with Chronos Mini and Base models, leaving open whether even larger models would show further performance gains or exhibit different scaling behaviors.
- What evidence would resolve it: Empirical results showing RAF performance across a broader range of model sizes (e.g., Chronos Small, Chronos Large) would clarify scaling trends and potential saturation points.

### Open Question 2
- Question: What is the optimal strategy for retrieving multiple time series samples rather than just the top-1 match, and how should they be combined?
- Basis in paper: [inferred] "As a future perspective, we propose expanding the RAF framework to handle multi-channel predictions and retrieve multiple samples from external sources."
- Why unresolved: The current RAF implementation uses only the single best-matching time series, but the paper suggests potential benefits from retrieving multiple samples without specifying how to combine them effectively.
- What evidence would resolve it: Experiments comparing different multi-sample retrieval strategies (e.g., ensemble averaging, weighted combinations, attention mechanisms) would identify optimal approaches.

### Open Question 3
- Question: How does RAF's effectiveness vary across different types of time series motifs (e.g., periodic vs. non-periodic, short-term vs. long-term patterns)?
- Basis in paper: [inferred] The synthetic retrieval experiment uses sinusoidal signals with different frequencies, suggesting interest in motif-based retrieval, but real-world motif diversity is not explicitly analyzed.
- Why unresolved: The paper demonstrates RAF works on diverse datasets but doesn't characterize which motif types benefit most from retrieval augmentation.
- What evidence would resolve it: Systematic analysis categorizing time series by motif characteristics and measuring RAF performance per category would reveal motif-specific effectiveness patterns.

## Limitations

- Evaluation constrained by specific Chronos models and 11 datasets, limiting generalizability to other TSFM architectures
- No analysis of computational overhead introduced by retrieval augmentation or scalability with larger databases
- Performance gains for smaller models (Mini) are less consistent, suggesting limitations in retrieval integration for compact architectures

## Confidence

- **High confidence**: RAF improves forecasting accuracy in out-of-domain scenarios, supported by consistent relative WQL improvements across both benchmarks and both model sizes
- **Medium confidence**: Larger models benefit more from retrieval augmentation, as the trend is observed but not extensively validated across a wider range of model scales or datasets
- **Low confidence**: Effectiveness of instance normalization as a mitigation strategy for distribution shift, due to lack of ablation studies or alternative normalization methods for comparison

## Next Checks

1. Conduct ablation studies to isolate the contribution of instance normalization versus retrieval augmentation on forecasting accuracy
2. Test RAF with alternative similarity metrics (e.g., cosine similarity) to assess robustness of retrieval quality to embedding distance measures
3. Evaluate RAF on datasets with known periodic patterns to quantify the benefit of retrieval in structured versus unstructured time series