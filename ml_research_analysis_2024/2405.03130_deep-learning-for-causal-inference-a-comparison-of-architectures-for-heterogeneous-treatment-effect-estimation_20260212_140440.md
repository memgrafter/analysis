---
ver: rpa2
title: 'Deep Learning for Causal Inference: A Comparison of Architectures for Heterogeneous
  Treatment Effect Estimation'
arxiv_id: '2405.03130'
source_url: https://arxiv.org/abs/2405.03130
tags:
- treatment
- network
- causal
- effect
- nnet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a deep learning method for estimating heterogeneous
  treatment effects, building on Bayesian Causal Forests (BCF) by implementing it
  with neural networks. The proposed BCF-nnet method separates the networks for the
  prognostic and treatment effect functions, contrasting with existing shared-weight
  approaches like Farrell et al.
---

# Deep Learning for Causal Inference: A Comparison of Architectures for Heterogeneous Treatment Effect Estimation

## Quick Facts
- arXiv ID: 2405.03130
- Source URL: https://arxiv.org/abs/2405.03130
- Authors: Demetrios Papakostas; Andrew Herren; P. Richard Hahn; Francisco Castillo
- Reference count: 3
- Primary result: BCF-nnet separates prognostic and treatment effect networks, showing lower bias and RMSE than shared architectures when treatment effects are small relative to prognostic effects, particularly under targeted selection

## Executive Summary
This paper introduces BCF-nnet, a deep learning method for estimating heterogeneous treatment effects that separates prognostic and treatment effect networks, contrasting with shared-weight approaches like Farrell et al. (2020). Through simulation studies and a real sleep dataset application, BCF-nnet demonstrates advantages in bias and RMSE when treatment effects are small relative to prognostic effects, especially under targeted selection. The method provides flexibility in regularization and feature selection while maintaining scalability through PyTorch implementation.

## Method Summary
BCF-nnet implements Bayesian Causal Forest using separate neural networks for the prognostic function α(X) and treatment effect function β(X), contrasting with shared-weight architectures. The method estimates propensity scores π(X) and incorporates them as features in the prognostic network, following Hahn et al. [2020]. The architecture uses two completely separate networks trained independently, allowing different regularization strategies and feature sets for each component. The approach is compared against Farrell's shared architecture, a naive partition-based method, and linear models across simulation studies with varying sample sizes and a real sleep study dataset.

## Key Results
- BCF-nnet shows lower bias and RMSE than shared architectures when treatment effects are small relative to prognostic effects
- Under targeted selection, incorporating estimated propensity scores as features in the prognostic network improves performance
- For large treatment effects, shared architectures perform better initially but converge with BCF-nnet as sample size grows
- Applied to sleep study examining stress effects, BCF-nnet yields interpretable causal estimates

## Why This Works (Mechanism)

### Mechanism 1
The BCF-nnet architecture separates prognostic and treatment effect networks, avoiding shared-weight bias when treatment effects are small relative to prognostic effects. By training separate neural networks for α(X) (prognostic) and β(X) (treatment effect), BCF-nnet prevents the dominant prognostic signal from overwhelming the learning of heterogeneous treatment effects, which can occur when using shared hidden layers as in Farrell et al. This works when prognostic and treatment effect functions have different underlying structures and regularization needs.

### Mechanism 2
Incorporating estimated propensity scores as features in the prognostic network improves performance under targeted selection. When π(X) is a function of α(X) (targeted selection), explicitly including the propensity estimate as an input to the prognostic network helps the model learn the correlation between treatment assignment and prognostic outcomes. This requires that targeted selection exists in the data generating process, creating a functional relationship between propensity and prognostic functions.

### Mechanism 3
Separate networks allow different regularization strategies for prognostic and treatment effect functions. By decoupling the networks, BCF-nnet enables independent regularization (dropout rates, weight decay, etc.) for α(X) and β(X), allowing more aggressive regularization on the treatment effect network which typically has less signal. This assumes that the treatment effect function β(X) requires different regularization than the prognostic function α(X) due to different signal-to-noise ratios.

## Foundational Learning

- Concept: Potential outcomes framework
  - Why needed here: The paper's notation and estimators are built on potential outcomes (Y¹, Y⁰), requiring understanding of counterfactual reasoning and assumptions like SUTVA and exchangeability.
  - Quick check question: What is the fundamental limitation of using observational data to estimate treatment effects under the potential outcomes framework?

- Concept: Conditional Average Treatment Effect (CATE)
  - Why needed here: The paper focuses on estimating heterogeneous treatment effects as a function β(X), distinguishing it from average treatment effect estimation and requiring understanding of conditioning on covariates.
  - Quick check question: How does CATE estimation differ from ATE estimation when X is continuous and high-dimensional?

- Concept: Neural network architecture design tradeoffs
  - Why needed here: Understanding why separate vs. shared architectures perform differently requires knowledge of how information flows through neural networks and how shared weights can bias learning.
  - Quick check question: What is the primary advantage of shared weights in neural networks, and why might this advantage be detrimental for causal effect estimation?

## Architecture Onboarding

- Component map: X → π-estimator → α-network (with π as feature) → β-network → Output
- Critical path: X → π-estimator → α-network (with π as feature) → β-network → Output
  The propensity score flows into the α-network, which together with the β-network produces the final prediction
- Design tradeoffs:
  - Separate networks increase parameter count but allow independent regularization and feature selection
  - Adding propensity as feature in α-network helps under targeted selection but adds complexity
  - Flexibility to use different architectures for each network vs. unified training procedure
- Failure signatures:
  - Poor calibration when propensity is poorly estimated
  - Overfitting in β-network when treatment effects are small relative to noise
  - Convergence issues when networks have incompatible learning rates
- First 3 experiments:
  1. Compare BCF-nnet vs. shared architecture on synthetic data with known targeted selection to verify propensity feature benefit
  2. Test different regularization strategies on β-network to find optimal balance between bias and variance
  3. Evaluate performance across different treatment-to-prognostic effect ratios to characterize when separation is most beneficial

## Open Questions the Paper Calls Out

### Open Question 1
How do BCF-nnet's performance characteristics change with varying levels of regularization on the β network compared to shared architectures? The paper mentions this flexibility exists but doesn't empirically explore how different regularization approaches affect performance across different data generating processes.

### Open Question 2
Under what conditions do confidence intervals derived from influence functions become reliable for BCF-nnet, and how can they be improved for small sample sizes? The paper states that influence function-based confidence intervals were "far too tight and exhibited poor coverage in the low n settings" but doesn't explore why or propose alternatives.

### Open Question 3
How does BCF-nnet perform when treatment assignment is determined by a complex non-linear function of the prognostic effect (targeted selection) versus simpler confounding mechanisms? While the paper demonstrates BCF-nnet's advantage under strong targeted selection, it doesn't characterize its performance across the full range of confounding mechanisms or determine the threshold where shared architectures become competitive.

## Limitations
- Simulation studies focus on specific data generating process with targeted selection, limiting generalizability
- Comparison with Farrell et al. is limited to a single shared architecture variant without exploring full design space
- Real-world sleep study has only 253 observations, which may not fully capture scalability advantages

## Confidence

- **High confidence**: Separate-network architecture provides clear benefits when treatment effects are small relative to prognostic effects and under targeted selection
- **Medium confidence**: Advantages of independent regularization and flexibility in feature selection are theoretically sound but not empirically validated
- **Medium confidence**: Runtime advantages for large-scale applications are plausible but not empirically demonstrated

## Next Checks

1. Test BCF-nnet performance under alternative treatment assignment mechanisms (e.g., purely random assignment, overlap selection) to establish boundary conditions for the propensity score feature benefit.

2. Conduct an ablation study systematically varying the degree of network separation (e.g., partially shared layers) to quantify the marginal benefit of complete separation versus other architectural choices.

3. Scale the evaluation to larger datasets (10,000+ observations) with varying dimensionality to empirically validate the claimed computational advantages and assess performance degradation patterns.