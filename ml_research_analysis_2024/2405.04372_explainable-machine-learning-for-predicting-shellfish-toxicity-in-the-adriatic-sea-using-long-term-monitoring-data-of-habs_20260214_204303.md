---
ver: rpa2
title: Explainable machine learning for predicting shellfish toxicity in the Adriatic
  Sea using long-term monitoring data of HABs
arxiv_id: '2405.04372'
source_url: https://arxiv.org/abs/2405.04372
tags:
- data
- were
- toxicity
- positive
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study applies explainable machine learning techniques to predict
  diarrhetic shellfish poisoning (DSP) toxicity in mussels from the Gulf of Trieste
  using a 28-year dataset of toxic phytoplankton and environmental variables. Random
  forest models achieved the highest performance with F1 score of 0.65, recall of
  0.59, and precision of 0.74.
---

# Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs

## Quick Facts
- arXiv ID: 2405.04372
- Source URL: https://arxiv.org/abs/2405.04372
- Reference count: 0
- Random forest models achieved F1 score of 0.65 for predicting DSP toxicity in mussels

## Executive Summary
This study applies explainable machine learning techniques to predict diarrhetic shellfish poisoning (DSP) toxicity in mussels from the Gulf of Trieste using a 28-year dataset of toxic phytoplankton and environmental variables. The research demonstrates how interpretable ML models combined with explainability methods can improve trust in predictive models for early warning systems supporting sustainable aquaculture. Random forest models achieved the highest performance with F1 score of 0.65, recall of 0.59, and precision of 0.74. Decision tree models provided interpretable decision rules showing that D. fortii abundances above 30 cells l-1 strongly indicate positive toxicity.

## Method Summary
The study utilized a 28-year dataset of shellfish toxicity monitoring data from the Gulf of Trieste, incorporating toxic phytoplankton species abundances and environmental variables including salinity, river discharge, and precipitation. Multiple machine learning algorithms were evaluated including random forest, decision trees, and logistic regression. Explainable AI techniques such as feature importance analysis and partial dependence plots were applied to identify key predictors and interpret model decisions. The models were trained to classify shellfish toxicity status as positive or negative based on the input variables.

## Key Results
- Random forest models achieved highest performance with F1 score of 0.65, recall of 0.59, and precision of 0.74
- Dinophysis fortii and D. caudata identified as most important phytoplankton species for predicting DSP toxicity
- Environmental variables including salinity, river discharge, and precipitation emerged as key predictors alongside phytoplankton species
- Decision tree models revealed interpretable decision rules showing D. fortii abundances above 30 cells l-1 strongly indicate positive toxicity

## Why This Works (Mechanism)
The approach works by leveraging the long-term monitoring data to capture the complex relationships between environmental conditions, phytoplankton dynamics, and shellfish toxicity. Random forest models excel at handling non-linear relationships and interactions between multiple variables, while decision trees provide interpretable decision rules that can be easily understood by stakeholders. The explainability methods reveal which factors most strongly influence predictions, building trust in the models and enabling targeted monitoring and management strategies.

## Foundational Learning
- Random forest ensemble learning: Why needed - handles complex non-linear relationships; Quick check - verify proper hyperparameter tuning
- Feature importance analysis: Why needed - identifies key predictors driving model decisions; Quick check - compare importance rankings across multiple models
- Partial dependence plots: Why needed - visualizes relationship between predictors and model predictions; Quick check - validate trends against domain knowledge
- Decision tree interpretability: Why needed - provides transparent decision rules for stakeholders; Quick check - test if rules align with established monitoring thresholds
- Time-series cross-validation: Why needed - prevents data leakage in temporally correlated monitoring data; Quick check - compare performance across different temporal splits

## Architecture Onboarding
Component map: Environmental data -> Preprocessing -> ML models (RF, DT, LR) -> Explainability methods -> Predictions
Critical path: Raw monitoring data → Feature engineering → Model training → Explainability analysis → Decision support
Design tradeoffs: Binary vs. multi-class classification; local vs. global interpretability; model complexity vs. stakeholder understanding
Failure signatures: Overfitting to specific years; poor generalization to new locations; misalignment with expert knowledge
First experiments: 1) Test feature importance stability across different random seeds, 2) Compare partial dependence plots for top predictors, 3) Validate decision rules against historical monitoring decisions

## Open Questions the Paper Calls Out
None

## Limitations
- Model performance (F1 score of 0.65) indicates substantial room for improvement in predicting shellfish toxicity events
- Dataset covers only one specific location (Gulf of Trieste), limiting generalizability to other Adriatic regions
- Binary classification approach may oversimplify the complex nature of toxicity dynamics and miss important gradations in risk levels

## Confidence
- High confidence in identified key predictors (Dinophysis species, salinity, river discharge, precipitation) based on established literature
- Medium confidence in predictive performance metrics due to modest F1 score and binary classification nature
- Medium confidence in generalizability beyond Gulf of Trieste region

## Next Checks
1. Test model performance on independent datasets from different Adriatic regions to assess geographical generalizability
2. Implement time-series cross-validation to evaluate model stability and prevent temporal data leakage
3. Conduct sensitivity analysis to quantify impact of individual environmental variables on predictions and identify early warning thresholds