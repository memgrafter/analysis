---
ver: rpa2
title: 'Collective Counterfactual Explanations: Balancing Individual Goals and Collective
  Dynamics'
arxiv_id: '2402.04579'
source_url: https://arxiv.org/abs/2402.04579
tags:
- optimal
- cost
- probability
- function
- transport
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Collective Counterfactual Explanations (CCE)
  to address limitations of individual-centric counterfactual explanations in scenarios
  where many individuals seek similar state modifications. The core idea leverages
  optimal transport theory to formulate counterfactual recommendations as a collective
  optimization problem that considers underlying data distributions and minimizes
  externalities caused by correlated changes across the population.
---

# Collective Counterfactual Explanations: Balancing Individual Goals and Collective Dynamics

## Quick Facts
- arXiv ID: 2402.04579
- Source URL: https://arxiv.org/abs/2402.04579
- Authors: Ahmad-Reza Ehyaei; Ali Shirali; Samira Samadi
- Reference count: 30
- One-line primary result: Introduces Collective Counterfactual Explanations (CCE) using optimal transport theory to improve upon standard counterfactual explanations across multiple desiderata including actionability, security/privacy, and robustness.

## Executive Summary
This paper introduces Collective Counterfactual Explanations (CCE) to address limitations of individual-centric counterfactual explanations in scenarios where many individuals seek similar state modifications. The core idea leverages optimal transport theory to formulate counterfactual recommendations as a collective optimization problem that considers underlying data distributions and minimizes externalities caused by correlated changes across the population. The method introduces a δ-confidence region concept to target recommendations toward denser areas of the feature space, reducing competition and outlier recommendations.

The framework is shown to improve upon standard counterfactual explanations across multiple desiderata including actionability, data manifold closeness, security/privacy, and robustness. The authors develop scalable algorithms including Sinkhorn and back-and-forth methods for computing collective counterfactuals. Empirical results on synthetic Gaussian mixture data demonstrate that CCE effectively balances individual modification costs with their impact on others, achieving more equitable and efficient outcomes compared to existing recourse methods.

## Method Summary
The paper formulates counterfactual explanations as an optimal transport problem, mapping individuals from the negative classification region to a δ-confidence region with higher probability density. The approach uses Sinkhorn algorithm and unbalanced optimal transport to solve the collective optimization problem. The method introduces a δ parameter to control the density of the target region, balancing between reducing competition (higher δ) and keeping modification costs reasonable (lower δ). The framework naturally extends to path-guided counterfactuals and ordered classifiers while improving security by making decision boundary manipulation more difficult.

## Key Results
- CCE reduces competition and outlier recommendations by targeting denser areas of feature space through δ-confidence regions
- The approach improves security/privacy by spreading recommendations across the δ-confidence region, making decision boundary inference harder
- CCE provides more equitable outcomes by balancing individual modification costs with their collective impact through optimal transport formulation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Collective Counterfactual Explanations (CCE) reduce competition and outlier recommendations by incorporating population density into the optimization.
- Mechanism: CCE formulates the counterfactual problem as an optimal transport problem, mapping individuals from the negative region to a δ-confidence region that has higher probability density. This prevents individuals from being recommended to low-density areas near the decision boundary where competition would be high.
- Core assumption: The underlying population probability measure P is known or can be empirically estimated.
- Evidence anchors:
  - [abstract] "The method introduces a δ-confidence region concept to target recommendations toward denser areas of the feature space, reducing competition and outlier recommendations."
  - [section] "To preventCE from concentrating in a specific area during optimization, we add a constraint to spread CE across the target region."
- Break condition: If the probability measure P is incorrectly estimated or if the classifier's decision boundary changes rapidly, the δ-confidence region may not accurately represent where individuals should be recommended.

### Mechanism 2
- Claim: CCE improves security/privacy by making decision boundary manipulation more difficult compared to individual counterfactual explanations.
- Mechanism: By spreading recommendations across the δ-confidence region rather than concentrating them near the decision boundary, CCE makes it harder for an adversary to infer the decision boundary through low-budget queries. The collective optimization considers multiple factors including the distribution and cost function.
- Core assumption: The decision boundary is not explicitly known to potential adversaries.
- Evidence anchors:
  - [abstract] "The approach also naturally extends to path-guided counterfactuals and ordered classifiers."
  - [section] "Combining these diverse elements in the search for CCE complicates the boundary manipulation, as shown in Fig. 3(b)."
- Break condition: If the adversary has access to the underlying population distribution P or can observe the δ-confidence region selection, they may still be able to infer the decision boundary.

### Mechanism 3
- Claim: CCE provides more equitable outcomes by balancing individual modification costs with their impact on others.
- Mechanism: The optimal transport formulation naturally distributes recommendations in a way that minimizes total transportation cost while respecting the population distribution. This creates a market equilibrium where individuals pay prices for state changes that reflect both their individual costs and the collective impact.
- Core assumption: Individuals' utility functions can be approximated by the transportation cost and the market equilibrium prices.
- Evidence anchors:
  - [abstract] "By balancing individual modification costs with their impact on others, our method ensures more equitable and efficient outcomes."
  - [section] "According to Thm. 1, this equilibrium reflects the collective efficient effort required for state modification."
- Break condition: If the cost function c(x, x') is not accurately known or if there are significant externalities not captured by the transportation model, the equilibrium may not represent true social welfare.

## Foundational Learning

- Concept: Optimal Transport Theory
  - Why needed here: CCE is formulated as an optimal transport problem, requiring understanding of Monge and Kantorovich formulations, dual problems, and computational methods like Sinkhorn algorithm.
  - Quick check question: What is the difference between Monge and Kantorovich formulations of optimal transport?

- Concept: Probability Measures and Distributions
  - Why needed here: The framework relies on understanding probability measures P, truncated measures, and how to estimate population distributions from data.
  - Quick check question: How do you compute a truncated probability measure PA for a set A with P(A) > 0?

- Concept: Counterfactual Explanations
  - Why needed here: Understanding the standard counterfactual explanation framework (finding minimal cost modifications to change classification) is essential to grasp how CCE extends this approach.
  - Quick check question: In the standard counterfactual explanation framework, what is the mathematical formulation for finding the counterfactual recommendation?

## Architecture Onboarding

- Component map:
  - Data preprocessing: Feature space X, classifier h, probability measure P estimation
  - CCE core: Optimal transport solver (Sinkhorn/Unbalanced Sinkhorn), δ-confidence region computation
  - Output generation: Sampling from transport plan, path interpolation for path-guided explanations
  - Evaluation: Cost comparison with baseline, density distribution analysis

- Critical path:
  1. Estimate population probability measure P from data
  2. Define classifier h and identify negative region X-
  3. Compute δ-confidence region L+δ
  4. Set up optimal transport problem between P- and Pδ
  5. Solve using Sinkhorn or unbalanced Sinkhorn algorithm
  6. Generate counterfactual recommendations by sampling from transport plan

- Design tradeoffs:
  - δ parameter selection: Higher δ provides more dense recommendations but may increase cost; lower δ reduces cost but may increase competition
  - Balanced vs unbalanced transport: Unbalanced allows for mass creation/annihilation but adds complexity
  - Computational efficiency vs accuracy: Sinkhorn is fast but approximate; back-and-forth is more accurate but slower

- Failure signatures:
  - High variance in recommendations across similar individuals (indicates poor probability estimation)
  - Recommendations concentrated in small regions (δ too low or transport solver issues)
  - Extremely high costs compared to baseline (δ too high or incorrect cost function)

- First 3 experiments:
  1. Implement Sinkhorn algorithm on synthetic Gaussian mixture data with known distribution to verify correctness
  2. Compare CCE recommendations with baseline counterfactual explanations on a simple 2D dataset
  3. Test sensitivity of recommendations to δ parameter selection on a real-world dataset with estimated probability distribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of δ in the δ-confidence region affect the balance between collective optimization and individual modification costs in practice?
- Basis in paper: [explicit] The paper discusses the δ-confidence region as a key component of CCE but does not provide a principled framework for selecting δ values.
- Why unresolved: The paper mentions that δ should be chosen based on intuitions like moving away from low-density areas and ensuring societal stability, but it doesn't offer a concrete mathematical framework or empirical methodology for determining the optimal δ value in different scenarios.
- What evidence would resolve it: A study that empirically tests CCE with different δ values on real-world datasets, showing how varying δ affects the trade-off between collective optimization and individual costs, and providing guidelines for selecting δ based on specific problem characteristics.

### Open Question 2
- Question: How can CCE be effectively implemented with real-world datasets where the underlying population probability distribution P is unknown?
- Basis in paper: [explicit] The paper states "In empirical settings, the algorithm deals with discrete distributions often derived from data samples" and mentions using sample distributions with Sinkhorn methods, but doesn't provide a comprehensive solution for real-world implementation.
- Why unresolved: The paper acknowledges the challenge of working with empirical distributions but doesn't provide a complete methodology for estimating P from real-world data, handling sampling bias, or dealing with high-dimensional feature spaces.
- What evidence would resolve it: A detailed implementation framework that shows how to estimate P from real-world data, validates the approach using multiple real datasets with different characteristics, and compares the performance of CCE with classical CE on these datasets.

### Open Question 3
- Question: How does CCE perform when individuals have heterogeneous preferences or utility functions that differ from the standard cost-based approach?
- Basis in paper: [explicit] The paper mentions utility-based counterfactual explanations in Section 4.3 but focuses primarily on cost minimization. It doesn't explore scenarios where individuals have different utility functions.
- Why unresolved: The paper assumes a uniform cost function for all individuals and doesn't explore how CCE would perform when individuals have different preferences or when the utility function varies across the population.
- What evidence would resolve it: An extension of CCE that incorporates heterogeneous utility functions, tested on datasets where different individuals have varying preferences, showing how CCE adapts to these differences and whether it still achieves better collective outcomes compared to classical CE.

## Limitations
- Empirical validation relies entirely on synthetic data with known distributions, limiting real-world applicability
- The approach assumes accurate estimation of population probability measure P, which is challenging in practice
- Security/privacy claims lack empirical validation against concrete adversarial attacks

## Confidence

- **High confidence**: The theoretical framework connecting collective counterfactual explanations to optimal transport theory is mathematically sound. The core optimization formulations and their relationship to market equilibrium principles are well-established.
- **Medium confidence**: The algorithmic implementations (Sinkhorn, unbalanced Sinkhorn) and their application to the counterfactual problem are correct, but the empirical results are limited to synthetic scenarios.
- **Low confidence**: The real-world applicability of the approach, including the quality of probability measure estimation, the relevance of synthetic benchmarks, and the practical security benefits, requires further validation.

## Next Checks

1. **Real-world dataset validation**: Apply CCE to a real-world dataset with an estimated population distribution and compare outcomes against individual counterfactual explanations across multiple metrics including actual classification success rates, not just theoretical cost measures.

2. **Sensitivity analysis**: Systematically vary the δ parameter and cost function parameters to understand their impact on recommendation quality and identify regimes where collective approaches provide clear advantages over individual methods.

3. **Adversarial robustness testing**: Design and implement concrete attacks to test whether the collective approach genuinely provides improved security/privacy compared to individual counterfactual explanations under realistic threat models with budget constraints.