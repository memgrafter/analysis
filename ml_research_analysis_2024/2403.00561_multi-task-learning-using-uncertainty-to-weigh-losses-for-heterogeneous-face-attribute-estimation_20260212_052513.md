---
ver: rpa2
title: Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face
  Attribute Estimation
arxiv_id: '2403.00561'
source_url: https://arxiv.org/abs/2403.00561
tags:
- estimation
- attribute
- face
- task
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multi-task learning framework for estimating
  heterogeneous face attributes using deep convolutional neural networks with hard
  parameter sharing. The approach addresses ordinal and nominal attributes by converting
  ordinal regression into a series of binary classification subproblems and weighting
  task losses based on homoscedastic uncertainty.
---

# Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face Attribute Estimation

## Quick Facts
- arXiv ID: 2403.00561
- Source URL: https://arxiv.org/abs/2403.00561
- Authors: Huaqing Yuan; Yi He; Peng Du; Lu Song
- Reference count: 34
- Primary result: Proposed uncertainty-weighted multi-task framework achieves 86.59% gender accuracy on Adience (vs 80.40% SOTA) and 64.74% age accuracy on UTKFace (vs 61.34% SOTA)

## Executive Summary
This paper proposes a multi-task learning framework for heterogeneous face attribute estimation that addresses both ordinal (age) and nominal (gender, race) attributes using deep convolutional neural networks with hard parameter sharing. The key innovation is converting ordinal regression into binary classification subproblems and using homoscedastic uncertainty to automatically weight task losses during training. The approach demonstrates significant improvements over state-of-the-art methods on both Adience and UTKFace benchmarks while reducing estimation error for ordinal attributes.

## Method Summary
The framework employs hard parameter sharing of shallow convolutional layers across all tasks, followed by task-specific branches for nominal and ordinal attribute estimation. Ordinal regression is transformed into K-1 binary classification subproblems, where each binary classifier determines if the attribute value exceeds a specific threshold. Homoscedastic uncertainty is used as task-dependent weights to automatically balance the heterogeneous losses during training. The model is trained using a joint loss function that incorporates uncertainty-weighted cross-entropy for nominal tasks and uncertainty-weighted binary cross-entropy for ordinal tasks.

## Key Results
- Gender accuracy: 86.59% on Adience (vs 80.40% previous SOTA)
- Age accuracy: 64.74% on UTKFace (vs 61.34% previous SOTA)
- Ordinal attribute estimation: Lower MSE and MAE values compared to baseline methods
- Real-time feasibility: Validated on edge systems for practical deployment

## Why This Works (Mechanism)

### Mechanism 1
Hard parameter sharing of shallow features enables information sharing across heterogeneous tasks while reducing overfitting risk. The network shares low-level convolutional layers across all tasks, learning common features like edges and textures, then branches into task-specific layers for nominal and ordinal attribute estimation. This assumes lower layers capture universal visual features applicable to all face attributes, while higher layers need task-specific processing.

### Mechanism 2
Ordinal regression is transformed into binary classification subproblems to simplify the learning task and reduce estimation bias. For each ordinal attribute (like age), the problem is decomposed into K-1 binary classifiers where each classifier determines if the attribute value exceeds a specific threshold. This assumes binary classification is easier to learn than direct ordinal regression, and the linear combination of binary outputs reconstructs the ordinal value accurately.

### Mechanism 3
Homoscedastic uncertainty is used as task-dependent weights to automatically balance losses from heterogeneous tasks. Each task has an associated uncertainty parameter σ that scales its loss contribution. Tasks with higher uncertainty (potentially noisier or harder) get lower weights in the joint loss function. This assumes different face attribute estimation tasks have different inherent uncertainties due to data quality, annotation difficulty, or task complexity.

## Foundational Learning

- **Concept: Multi-task learning with hard parameter sharing**
  - Why needed here: Face attributes are correlated but heterogeneous, requiring shared low-level feature extraction while maintaining task-specific processing
  - Quick check question: What are the advantages of hard parameter sharing versus soft parameter sharing for face attribute estimation?

- **Concept: Ordinal regression vs classification**
  - Why needed here: Age and other ordinal attributes have inherent order that standard classification doesn't capture, but direct regression is challenging
  - Quick check question: How does decomposing ordinal regression into binary classification subproblems preserve the ordinal relationship?

- **Concept: Bayesian uncertainty modeling**
  - Why needed here: Different face attribute tasks have varying difficulty and noise levels that need to be accounted for in loss weighting
  - Quick check question: What is the difference between aleatoric and homoscedastic uncertainty in the context of multi-task learning?

## Architecture Onboarding

- **Component map**: Input → Shared shallow CNN layers (MBConv blocks) → Task-specific branches → Nominal task: FC layer → Ordinal task: K-1 binary classifiers → Loss computation with uncertainty weighting
- **Critical path**: Image preprocessing → Feature extraction → Attribute-specific processing → Loss computation → Backpropagation with uncertainty-weighted gradients
- **Design tradeoffs**: Shared layers reduce parameters but may limit task-specific optimization; ordinal decomposition simplifies learning but increases output complexity; uncertainty weighting automates loss balancing but adds parameters
- **Failure signatures**: Poor performance on one task may indicate insufficient task-specific capacity; high uncertainty weights suggest data quality issues; ordinal estimation errors may indicate decomposition problems
- **First 3 experiments**:
  1. Train with only shared layers and single task to verify basic feature extraction works
  2. Add task-specific branches without uncertainty weighting to test architecture design
  3. Implement uncertainty weighting with fixed weights to validate the multi-task learning framework before full optimization

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness of hard parameter sharing for heterogeneous face attributes lacks direct empirical validation
- Ordinal regression decomposition is not validated against alternative approaches (direct ordinal regression, ordinal classification)
- Homoscedastic uncertainty weighting assumes constant task uncertainty across all inputs, which may not hold for varying conditions

## Confidence

- **High confidence**: The overall framework design and its ability to handle both nominal and ordinal face attributes simultaneously
- **Medium confidence**: The specific implementation details and hyperparameter choices, which are not fully specified in the paper
- **Low confidence**: The superiority of the uncertainty-based weighting approach compared to alternative loss balancing strategies

## Next Checks

1. Compare the hard parameter sharing approach against soft parameter sharing (task-specific low-level layers) to quantify the information sharing benefit
2. Validate the ordinal regression decomposition by testing direct ordinal regression approaches on the same datasets and attribute types
3. Test the sensitivity of the uncertainty weighting scheme by varying the number of tasks and their relative difficulty levels to ensure robust performance across different task combinations