---
ver: rpa2
title: 'Creative Agents: Simulating the Systems Model of Creativity with Generative
  Agents'
arxiv_id: '2411.17065'
source_url: https://arxiv.org/abs/2411.17065
tags:
- artist
- text
- were
- generated
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates creativity in AI systems through simulations\
  \ of Csikszentmihalyi\u2019s systems model of creativity, using virtual agents powered\
  \ by large language models (LLMs) and text-to-image models. The study compares isolated\
  \ agents to those operating within a multi-agent system to assess the emergence\
  \ of creativity in generated artifacts."
---

# Creative Agents: Simulating the Systems Model of Creativity with Generative Agents

## Quick Facts
- arXiv ID: 2411.17065
- Source URL: https://arxiv.org/abs/2411.17065
- Authors: Naomi Imasato; Kazuki Miyazawa; Takayuki Nagai; Takato Horii
- Reference count: 6
- Primary result: Virtual agents using LLMs and text-to-image models produce more varied creative outputs when operating in multi-agent systems compared to isolation.

## Executive Summary
This paper investigates creativity in AI systems through simulations of Csikszentmihalyi's systems model of creativity, using virtual agents powered by large language models (LLMs) and text-to-image models. The study compares isolated agents to those operating within a multi-agent system to assess the emergence of creativity in generated artifacts. Artists, critics, and a domain context interact iteratively, with agents receiving and reflecting on feedback to evolve their outputs. Results show that agents in the system setting produced more varied and creative artifacts, as measured by user studies and LLM-based evaluations, compared to isolated agents.

## Method Summary
The study simulates Csikszentmihalyi's systems model of creativity using virtual agents: artist agents generate art prompts and images, field agents (critics) provide feedback, and a domain context maintains ranking of significant artworks. The system uses Gemini Pro 1.5 for text generation and Stable Diffusion v1.5 for image generation. Artists create artwork, critics evaluate and rank the pieces, the domain ranking updates based on feedback, and artists reflect on this feedback to modify their next creations. This process iterates 15 times, comparing results between isolated artists and those in the multi-agent system.

## Key Results
- Agents in system settings produced more varied and creative artifacts than isolated agents
- The feedback loop between artists, critics, and domain context enabled creative evolution over iterations
- LLM-based evaluations and user studies confirmed higher creativity scores for system-based agents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Agents in a system setting outperform isolated agents in creative output variation.
- Mechanism: Interaction between artist agents, field agents (critics), and domain context creates a feedback loop that shapes creative evolution.
- Core assumption: The domain and critic feedback provide contextual novelty that isolated agents lack.
- Evidence anchors:
  - [abstract]: "Results show that agents in the system setting produced more varied and creative artifacts, as measured by user studies and LLM-based evaluations, compared to isolated agents."
  - [section]: "The critiques were also returned to the artists, where each agent underwent a process of 'self-reflection', which occurred via another text generation that was prompted with the following: [domain descrip.] + 'The art student made a piece of art that was described as:' + [art prompt] + 'The art teacher made the following comment about this artwork:' + [critique] + [artist descrip.] + 'How do you react to this feedback? Briefly describe what actions you will take next.'"
  - [corpus]: "Found 25 related papers (using 8). Average neighbor FMR=0.478, average citations=0.0." (Weak corpus support; no direct citations to this specific systems model creativity simulation.)
- Break condition: If the critic feedback is too vague or the domain context is too static, the feedback loop fails to generate meaningful novelty.

### Mechanism 2
- Claim: Artist agents evolve creatively over time within the system.
- Mechanism: Self-reflection step allows agents to incorporate critic feedback into future art prompts, leading to gradual creative change.
- Core assumption: Agents are designed to be receptive to feedback and modify their artistic approach accordingly.
- Evidence anchors:
  - [abstract]: "agents receiving and reflecting on feedback to evolve their outputs."
  - [section]: "The output from this 'reflection' goes into the Artist's additional text. We run these steps iteratively, where the text defining the Artist and the ranking in the Domain change at each step."
  - [corpus]: No direct evidence; the corpus shows related work on generative agents but not specifically on iterative creative evolution.
- Break condition: If agents are not receptive to feedback (e.g., defined as highly confident artists), the self-reflection step becomes ineffective.

### Mechanism 3
- Claim: The domain ranking system influences creative direction.
- Mechanism: Critic feedback updates the domain's artwork ranking, which in turn shapes the keywords and context available to artists.
- Core assumption: Artists are influenced by the current trends and significant works in the domain.
- Evidence anchors:
  - [section]: "The paintings in the list were ranked according to the impressions obtained from the field agent(s)... The ranking mechanics are detailed in the next section."
  - [section]: "The decay was enforced thus the considerations made at the earlier time-steps were not as valuable as those more recent."
  - [corpus]: No direct evidence; the corpus does not mention domain ranking mechanics in creative systems.
- Break condition: If the ranking system is too slow to update or the decay rate is too aggressive, artists may not perceive current trends accurately.

## Foundational Learning

- Concept: Systems Model of Creativity (Csikszentmihalyi)
  - Why needed here: The entire simulation is based on this model, which defines creativity as a product of interactions between individuals, field, and domain.
  - Quick check question: What are the three subsystems in Csikszentmihalyi's systems model of creativity?
- Concept: Large Language Models (LLMs) for text generation
  - Why needed here: LLMs are used to generate artist descriptions, critic feedback, and self-reflection text.
  - Quick check question: What LLM was used for text generation in this study?
- Concept: Text-to-Image Models
  - Why needed here: Stable Diffusion is used to generate visual artifacts from the art prompts created by the LLM.
  - Quick check question: Which text-to-image model was used to generate the visual artifacts?

## Architecture Onboarding

- Component map: Artist Agents -> Field Agents (Critics) -> Domain Context -> Artist Agents (feedback loop)
- Critical path:
  1. Initialize domain, artist agents, and field agents.
  2. Artist agents generate art prompts and images.
  3. Field agents provide feedback on each artwork.
  4. Domain ranking is updated based on critic feedback.
  5. Artist agents reflect on feedback and update their descriptions.
  6. Repeat steps 2-5 for a set number of iterations.
- Design tradeoffs:
  - Using separate models for text and image generation simplifies implementation but may lead to mismatches between art prompts and generated images.
  - Defining artist agents as novice students makes them more receptive to feedback but may limit the range of creative outputs.
  - Simplifying the domain and field agents reduces complexity but may not fully capture the nuances of real-world creative systems.
- Failure signatures:
  - Artist agents generate repetitive or nonsensical art prompts.
  - Critic feedback is too vague or too harsh, leading to artist demotivation.
  - Domain ranking becomes static, failing to reflect current trends.
  - Text-to-image model fails to generate images that match the art prompts.
- First 3 experiments:
  1. Run a single simulation with one artist agent, one critic, and a simple domain to verify basic functionality.
  2. Increase the number of artist agents and critics to test scalability and interaction effects.
  3. Modify the domain context (e.g., time period, cultural setting) to observe its impact on creative outputs.

## Open Questions the Paper Calls Out

- How does the presence of multiple artists in a system setting versus isolated affect the diversity and novelty of generated artifacts?
- How do different definitions of creativity, such as Boden's and Csikszentmihalyi's, impact the assessment of AI-generated artifacts?
- What is the impact of integrating human participants into the proposed system framework on the co-creation process?

## Limitations
- Evaluation relies heavily on subjective assessments and LLM-based grading, which may not capture full complexity of human creativity
- Simplified agent descriptions and interactions may limit richness of emergent creative behaviors
- Focus on specific art domain and time period may not generalize to other creative domains

## Confidence

- **High confidence**: Agents in system settings produce more varied outputs than isolated agents
- **Medium confidence**: The systems model framework meaningfully enhances creativity
- **Low confidence**: Long-term creative evolution is sustainable

## Next Checks
1. Conduct a follow-up study with human experts in art criticism to validate LLM-based creativity assessments and identify potential blind spots in automated evaluation
2. Implement a control condition where isolated agents receive periodic external feedback to isolate the effect of continuous system interaction
3. Test the system with different domain contexts and cultural settings to evaluate generalizability beyond the specific art domain used in current study