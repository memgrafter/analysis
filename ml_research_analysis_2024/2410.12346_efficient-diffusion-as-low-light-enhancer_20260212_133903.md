---
ver: rpa2
title: Efficient Diffusion as Low Light Enhancer
arxiv_id: '2410.12346'
source_url: https://arxiv.org/abs/2410.12346
tags:
- image
- diffusion
- trajectory
- low-light
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ReDDiT, a distillation framework for efficient
  low-light image enhancement using diffusion models. The key innovation is a Reflectance-Aware
  Trajectory Refinement (RATR) module that refines the teacher trajectory using reflectance
  components to reduce fitting errors and inference gaps.
---

# Efficient Diffusion as Low Light Enhancer

## Quick Facts
- arXiv ID: 2410.12346
- Source URL: https://arxiv.org/abs/2410.12346
- Authors: Guanzhou Lan; Qianli Ma; Yuqi Yang; Zhigang Wang; Dong Wang; Xuelong Li; Bin Zhao
- Reference count: 40
- Primary result: ReDDiT achieves state-of-the-art PSNR of 28.09dB on LOLv1, 30.92dB on LOLv2-real, and 25.32dB on SID with only 2 sampling steps

## Executive Summary
This paper introduces ReDDiT, a distillation framework that significantly improves the efficiency of diffusion models for low-light image enhancement. The key innovation is the Reflectance-Aware Trajectory Refinement (RATR) module, which refines teacher trajectories using reflectance components to reduce fitting errors and inference gaps. By operating with just 2 sampling steps while maintaining competitive performance, ReDDiT addresses the computational bottleneck that has limited diffusion models' practical deployment in real-world low-light enhancement applications.

## Method Summary
ReDDiT employs knowledge distillation to train a compact student diffusion model from a pre-trained teacher model. The framework uses an iterative sampling scheme where the student progressively generates intermediate results through denoising steps. The core innovation is the Reflectance-Aware Trajectory Refinement (RATR) module, which analyzes the teacher's trajectory and extracts reflectance components to guide trajectory refinement. This module reduces the gap between teacher and student distributions by providing more accurate target distributions for the student model during training. The distillation process involves forward trajectory generation from the teacher, refinement through RATR, and backward supervision where the student learns to mimic the refined trajectory. This approach enables the student to achieve comparable performance to the teacher with significantly fewer sampling steps.

## Key Results
- Achieves new SOTA PSNR of 28.09dB on LOLv1, 30.92dB on LOLv2-real, and 25.32dB on SID datasets
- Maintains competitive performance with only 2 sampling steps compared to previous diffusion methods requiring 8-16 steps
- Demonstrates superior visual quality with enhanced visibility, color preservation, noise reduction, and detail retention in low-light images
- Outperforms existing methods on multiple benchmark datasets while significantly reducing computational complexity

## Why This Works (Mechanism)
The RATR module effectively bridges the gap between teacher and student distributions by incorporating reflectance information into trajectory refinement. By analyzing the teacher's denoising trajectory and extracting reflectance components, the framework provides more precise target distributions for the student during training. This refined supervision enables the student to learn more effectively with fewer sampling steps, as the reflectance-aware refinement compensates for the reduced inference depth by providing better gradient signals during training.

## Foundational Learning

**Diffusion Models**: Generative models that progressively denoise random noise into structured outputs through iterative sampling. Needed to understand the baseline approach for low-light enhancement; quick check: verify understanding of forward noising and reverse denoising processes.

**Knowledge Distillation**: Training a compact student model to mimic a larger teacher model's behavior. Essential for reducing computational complexity; quick check: confirm understanding of how soft targets from teacher guide student learning.

**Reflectance Components**: Intrinsic image properties representing surface reflectance independent of illumination. Critical for separating lighting effects from content; quick check: validate understanding of how reflectance differs from shading in image formation.

**Trajectory Refinement**: Process of improving intermediate sampling steps during diffusion. Key to reducing inference gaps; quick check: ensure comprehension of how trajectory quality affects final output fidelity.

**Low-Light Image Enhancement**: Task of improving visibility in under-exposed images while preserving natural appearance. Core application domain; quick check: verify understanding of common challenges like noise amplification and color distortion.

## Architecture Onboarding

**Component Map**: Input Image -> Teacher Model -> RATR Module -> Refined Trajectory -> Student Model -> Enhanced Output

**Critical Path**: The distillation training loop forms the critical path: Teacher forward pass → RATR refinement → Student training with refined targets → Evaluation with reduced sampling steps

**Design Tradeoffs**: The framework trades off some model capacity for dramatic sampling efficiency gains. While the student model may have slightly lower representational power than the teacher, the RATR-guided training compensates by providing superior supervision signals, enabling comparable performance with 4-8x fewer inference steps.

**Failure Signatures**: Potential failure modes include over-smoothing when reflectance extraction fails, color shifts if the RATR module misestimates illumination components, and residual noise in extremely dark regions where the teacher model's guidance becomes unreliable.

**Three First Experiments**:
1. Train student model without RATR module to quantify its contribution to performance gains
2. Vary sampling steps (2, 4, 8) to analyze the tradeoff between efficiency and quality
3. Test on extreme low-light conditions beyond training distribution to evaluate robustness

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

- Limited ablation studies to validate individual component contributions, particularly the effectiveness of the RATR module
- Potential lack of comparison with the most recent diffusion-based methods that may have emerged after initial experiments
- No comprehensive analysis of robustness under varying noise conditions or on additional low-light datasets beyond the main benchmarks

## Confidence

**High confidence**: The basic framework of using diffusion models for low-light enhancement and the general approach of knowledge distillation
**Medium confidence**: The specific implementation details and the effectiveness of the RATR module
**Low confidence**: The claim of achieving state-of-the-art performance, as the comparison set may not be comprehensive

## Next Checks

1. Conduct ablation studies to isolate the contribution of the RATR module versus other components of the framework
2. Compare performance against the most recent diffusion-based low-light enhancement methods to verify current SOTA status
3. Test the method on additional low-light datasets and under different noise conditions to evaluate robustness and generalization