---
ver: rpa2
title: 'DeFine: Decision-Making with Analogical Reasoning over Factor Profiles'
arxiv_id: '2410.01772'
source_url: https://arxiv.org/abs/2410.01772
tags:
- factor
- earnings
- reasoning
- https
- analogical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DEFINE, a framework for improving LLM decision-making
  using analogical reasoning with probabilistic factor profiles. The framework addresses
  challenges in processing complex earnings call transcripts, which often contain
  verbosity, hedging, and vagueness.
---

# DeFine: Decision-Making with Analogical Reasoning over Factor Profiles

## Quick Facts
- arXiv ID: 2410.01772
- Source URL: https://arxiv.org/abs/2410.01772
- Authors: Yebowen Hu; Xiaoyang Wang; Wenlin Yao; Yiming Lu; Daoan Zhang; Hassan Foroosh; Dong Yu; Fei Liu
- Reference count: 29
- One-line primary result: Achieves 29.64% accuracy in predicting stock movements from earnings call transcripts

## Executive Summary
This paper introduces DEFINE, a framework for improving LLM decision-making using analogical reasoning with probabilistic factor profiles. The framework addresses challenges in processing complex earnings call transcripts, which often contain verbosity, hedging, and vagueness. DEFINE constructs factor profiles from transcripts, capturing key factors and their outcome probabilities. It then employs analogical reasoning to leverage insights from similar past experiences. The framework separates uncertainty quantification from decision-making, making it particularly useful in fields like finance, consulting, and medical consultations. DEFINE uses a Bradley-Terry model to identify influential factors and achieves superior performance compared to baseline methods.

## Method Summary
DEFINE is a framework that enhances LLM decision-making by constructing probabilistic factor profiles from complex transcripts and applying analogical reasoning. The method extracts key factors and their potential outcome probabilities from earnings call transcripts, then uses a Bradley-Terry model to identify influential factors through pairwise comparisons. For decision-making, it calculates KL divergence between the current factor profile and historical examples to find similar cases, leveraging their outcomes to guide recommendations. The framework was evaluated on an earnings call dataset with 11,950 transcripts from S&P 500/NASDAQ 500 companies (2017-2024), predicting investment decisions with 29.64% accuracy and a macro-averaged F1-score of 0.2783.

## Key Results
- 29.64% accuracy in predicting stock movements from earnings call transcripts
- Macro-averaged F1-score of 0.2783 for investment decision classification
- Outperforms baseline methods in decision-making accuracy
- Successfully integrates probabilistic factor profiles with analogical reasoning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework constructs probabilistic factor profiles to quantify uncertainty in complex scenarios.
- Mechanism: By extracting key factors from transcripts and estimating the probabilities of their potential outcomes, the framework creates a structured representation of uncertainty that can be systematically analyzed.
- Core assumption: The LLM can accurately identify relevant factors and their likelihood of outcomes from complex transcripts.
- Evidence anchors:
  - [abstract] "Our framework separates the tasks of quantifying uncertainty in complex scenarios and incorporating it into LLM decision-making."
  - [section 2.1] "These probabilities are inferred using a methodology that optimally integrates textual reasoning with quantitative analysis."
  - [corpus] Weak evidence - corpus neighbors do not directly support this mechanism.
- Break condition: If the LLM cannot accurately extract relevant factors or their likelihood from transcripts, the factor profile becomes unreliable and cannot properly quantify uncertainty.

### Mechanism 2
- Claim: Analogical reasoning with factor profiles identifies similar past experiences to guide decision-making.
- Mechanism: By comparing the current factor profile to historical examples using KL divergence, the framework finds analogous cases and leverages their outcomes to inform current decisions.
- Core assumption: Similar factor profiles indicate similar decision outcomes, and the historical examples are representative of the decision space.
- Evidence anchors:
  - [abstract] "Our research integrates probabilistic factor profiles with analogical reasoning, leveraging insights from similar past experiences to guide LLMs in making critical decisions in novel situations."
  - [section 4] "Transcripts with lower KL divergence values are considered more analogous, and therefore more likely to influence investor decisions similarly."
  - [corpus] Moderate evidence - corpus includes papers on analogical reasoning and LLMs, supporting the general concept.
- Break condition: If historical examples are not representative of current scenarios or if the similarity metric fails to capture meaningful relationships, analogical reasoning will provide poor guidance.

### Mechanism 3
- Claim: The Bradley-Terry model identifies influential factors by comparing pairwise outcomes across similar transcripts.
- Mechanism: By analyzing how factors from different transcripts compare when one leads to better outcomes than another, the model estimates the relative importance of each factor.
- Core assumption: The pairwise comparisons between transcripts are meaningful and that factor importance is consistent across different scenarios.
- Evidence anchors:
  - [abstract] "Moreover, we employ the Bradley-Terry model to identify dominant factors and evaluate how these factors collectively impact decision-making."
  - [section 2.2] "In this model, we estimate parameters that represent the strength of each factor."
  - [corpus] Weak evidence - corpus neighbors do not directly support this specific mechanism.
- Break condition: If the pairwise comparison methodology is flawed or if factor importance varies significantly across different contexts, the Bradley-Terry model will produce inaccurate rankings.

## Foundational Learning

- Concept: Probability theory and Bayesian inference
  - Why needed here: The framework relies on estimating probabilities of outcomes and combining them to make decisions under uncertainty.
  - Quick check question: How would you calculate the expected utility of an action given probabilities of different outcomes and their utilities?

- Concept: Information theory and KL divergence
  - Why needed here: The framework uses KL divergence to measure similarity between factor profiles for analogical reasoning.
  - Quick check question: What does a KL divergence of zero between two probability distributions indicate?

- Concept: Ranking algorithms and pairwise comparison models
  - Why needed here: The Bradley-Terry model is used to identify influential factors through pairwise comparisons.
  - Quick check question: How does the Bradley-Terry model estimate the relative strength of items based on pairwise comparison data?

## Architecture Onboarding

- Component map:
  Factor profile construction -> Bradley-Terry analysis -> Analogical reasoning engine -> Decision integration

- Critical path:
  1. Construct factor profile from transcript
  2. Calculate pairwise comparisons and Bradley-Terry scores
  3. Find analogous examples using KL divergence
  4. Integrate analogical insights with factor profile analysis
  5. Generate final decision recommendation

- Design tradeoffs:
  - Token efficiency vs. completeness: Using factor profiles instead of full transcripts saves tokens but may lose context
  - Historical representativeness vs. specificity: More examples improve reliability but may include less relevant cases
  - Model complexity vs. interpretability: Bradley-Terry adds complexity but provides clear factor importance rankings

- Failure signatures:
  - Poor factor profile construction: Low quality or missing key factors in profiles
  - Weak analogical matches: High KL divergence values between test cases and examples
  - Inconsistent Bradley-Terry scores: Factor importance rankings that change dramatically across different comparison sets

- First 3 experiments:
  1. Test factor profile construction accuracy by comparing LLM-extracted factors against human-labeled ground truth
  2. Validate analogical reasoning by measuring correlation between KL divergence and actual outcome similarity
  3. Evaluate Bradley-Terry model performance by comparing predicted influential factors against known market drivers in controlled scenarios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the DEFINE framework perform when applied to decision-making in domains beyond finance, such as medical consultations or political debates?
- Basis in paper: [explicit] The paper mentions potential applications in medical consultations and political debates but does not provide experimental results.
- Why unresolved: The current evaluation is limited to financial decision-making using earnings call transcripts.
- What evidence would resolve it: Empirical studies applying DEFINE to decision-making tasks in medical or political domains, demonstrating its effectiveness and adaptability.

### Open Question 2
- Question: What is the impact of varying the number of factors (beyond the 15 used in this study) on the performance of the DEFINE framework?
- Basis in paper: [inferred] The paper discusses the selection of 15 factors but does not explore the effect of using a different number of factors.
- Why unresolved: The optimal number of factors for balancing complexity and performance is not determined.
- What evidence would resolve it: Experiments testing the performance of DEFINE with different numbers of factors, identifying the optimal set for various decision-making scenarios.

### Open Question 3
- Question: How does the DEFINE framework handle real-time decision-making, given the computational costs associated with constructing factor profiles and performing analogical reasoning?
- Basis in paper: [inferred] The paper does not address the real-time applicability of the framework or its computational efficiency.
- Why unresolved: The latency issues associated with Bayesian inference are mentioned, but the overall computational efficiency of DEFINE is not evaluated.
- What evidence would resolve it: Benchmarking the runtime performance of DEFINE in real-time decision-making scenarios, comparing it to existing methods.

## Limitations
- Potential overfitting to earnings call transcripts and financial decision-making context
- Assumption that past analogical examples remain relevant in changing market conditions
- Computational overhead of pairwise comparisons across large historical datasets
- 29.64% accuracy indicates significant room for improvement in real-world deployment

## Confidence
- Factor profile construction: High confidence in the core mechanism of extracting key factors and probabilities
- Analogical reasoning: Medium confidence due to sensitivity to K value and KL divergence thresholds
- Bradley-Terry model: Low confidence in identifying truly influential factors across different contexts

## Next Checks
1. Conduct ablation studies varying K values in analogical reasoning to quantify sensitivity to the number of similar examples used
2. Test the framework on out-of-distribution scenarios (different industries, market conditions) to evaluate generalizability
3. Implement human evaluation of factor profiles to assess whether LLM-extracted factors align with expert-identified key drivers in earnings calls