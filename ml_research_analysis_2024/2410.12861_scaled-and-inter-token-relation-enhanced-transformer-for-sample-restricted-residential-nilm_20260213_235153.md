---
ver: rpa2
title: Scaled and Inter-token Relation Enhanced Transformer for Sample-restricted
  Residential NILM
arxiv_id: '2410.12861'
source_url: https://arxiv.org/abs/2410.12861
tags:
- attention
- inter-token
- transformer
- temperature
- softmax
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of training transformer models
  on small datasets for Non-Intrusive Load Monitoring (NILM). The authors propose
  two key innovations: an inter-token relation enhancement mechanism that removes
  diagonal entries from the similarity matrix to improve focus on inter-token relationships,
  and a dynamic temperature tuning mechanism with a learnable parameter that adapts
  attention sharpness during training.'
---

# Scaled and Inter-token Relation Enhanced Transformer for Sample-restricted Residential NILM

## Quick Facts
- arXiv ID: 2410.12861
- Source URL: https://arxiv.org/abs/2410.12861
- Authors: Minhajur Rahman; Yasir Arafat
- Reference count: 17
- Primary result: 10-15% higher F1 scores across multiple appliance types compared to original transformer and state-of-the-art models

## Executive Summary
This paper addresses the challenge of training transformer models on small datasets for Non-Intrusive Load Monitoring (NILM). The authors propose two key innovations: an inter-token relation enhancement mechanism that removes diagonal entries from the similarity matrix to improve focus on inter-token relationships, and a dynamic temperature tuning mechanism with a learnable parameter that adapts attention sharpness during training. The method was validated on the REDD dataset and demonstrated improved performance, establishing its effectiveness for small-scale NILM datasets.

## Method Summary
The proposed method enhances standard transformer architecture with two mechanisms for small dataset scenarios. First, an inter-token relation enhancement removes diagonal entries from the attention similarity matrix by setting them to negative infinity, forcing the model to focus on relationships between different tokens rather than self-similarity. Second, a dynamic temperature tuning mechanism uses a meta-network to learn a temperature parameter τ that scales the similarity matrix before softmax, preventing over-smoothing and enhancing sensitivity to token relationships. The model was tested on the REDD dataset with houses 2-6 for training and house 1 for testing, evaluating performance on refrigerator, washer, microwave, and dishwasher appliances.

## Key Results
- Achieved 10-15% higher F1 scores across multiple appliance types compared to original transformer and state-of-the-art models
- Demonstrated effectiveness specifically for small-scale NILM datasets (REDD dataset)
- Showed improved accuracy, F1 score, Mean Relative Error (MRE), and Mean Absolute Error (MAE) metrics

## Why This Works (Mechanism)

### Mechanism 1: Inter-token Relation Enhancement
The diagonal entries in attention similarity matrices represent self-similarity and are set to negative infinity, causing softmax to assign near-zero attention to these entries. This redistributes attention across other tokens, improving focus on inter-token relationships. The core assumption is that self-attention scores on diagonal entries are artificially inflated due to shared linear projections, and removing them improves inter-token focus without losing representational power.

### Mechanism 2: Dynamic Temperature Tuning
A learnable temperature parameter τ is dynamically adjusted during training through a meta-network that outputs values bounded in [√dk/8, 8√dk]. This τ scales the similarity matrix before softmax, controlling attention distribution sharpness. The core assumption is that optimal temperature varies across datasets, appliance types, and training phases, and can be learned rather than fixed.

### Mechanism 3: Meta-network Architecture
The meta-network takes average-pooled token embeddings and passes them through fully connected layers with ReLU activations to output τ, which is then scaled to the desired range using a sigmoid-like function. The core assumption is that pooled features from token embeddings contain sufficient information for the meta-network to predict appropriate temperature values for the current training context.

## Foundational Learning

- **Attention mechanism in transformers**: Understanding how self-attention works is crucial for grasping why removing diagonal entries and adding learnable temperature improves performance. *Quick check*: What happens to attention distribution when you set diagonal entries to negative infinity in the similarity matrix?

- **Temperature scaling in softmax functions**: The dynamic temperature tuning mechanism relies on understanding how temperature affects softmax output distribution. *Quick check*: How does increasing temperature affect the sharpness of a softmax distribution?

- **Meta-learning and learnable parameters**: The dynamic temperature tuning uses a meta-network to learn temperature values, requiring understanding of meta-learning concepts. *Quick check*: What is the difference between a learnable parameter and a fixed hyperparameter in neural network training?

## Architecture Onboarding

- **Component map**: Input sequence → Embedding block (1D conv) → Transformer blocks (with inter-token enhancement + dynamic temperature) → Reconstruction block (1D deconv) → Output appliance signals

- **Critical path**: Input sequence flows through embedding, transformer layers with enhanced attention mechanisms, and reconstruction to produce appliance-specific outputs

- **Design tradeoffs**: Inter-token enhancement vs. standard self-attention removes potential useful self-information but improves inter-token focus; learnable temperature vs. fixed scaling adds complexity but adapts to data characteristics; meta-network overhead vs. performance gain provides small computational cost for significant performance improvement

- **Failure signatures**: Poor performance with learnable temperature but good with fixed temperature indicates meta-network not learning appropriate values; degradation when removing diagonal entries suggests task relies heavily on self-information; training instability may indicate temperature bounds too restrictive or meta-network architecture insufficient

- **First 3 experiments**: 1) Compare performance with and without diagonal entry removal while keeping fixed temperature; 2) Compare performance with fixed temperature (multiple values) vs. learnable temperature with fixed diagonal entries; 3) Test different temperature bounds [√dk/8, 8√dk] to find optimal range for the meta-network

## Open Questions the Paper Calls Out

### Open Question 1
How does the inter-token relation enhancement mechanism perform on larger datasets beyond REDD, and does its advantage scale with dataset size? The paper focuses solely on small-scale datasets (REDD) and does not provide evidence of scalability or performance on larger datasets. Testing on larger, more diverse NILM datasets would provide insights into scalability.

### Open Question 2
What is the optimal range for the learnable temperature parameter τ, and how does it vary across different appliance types and datasets? The paper uses an empirical range for τ without exploring how this range might vary depending on appliance types or dataset characteristics. Experiments with different ranges across multiple appliance types and datasets would clarify optimal range and variability.

### Open Question 3
How does the computational overhead of the proposed method compare to other advanced transformer-based methods for NILM, and can it be optimized further? The paper only provides a comparison with standard attention mechanism and does not benchmark against other advanced methods or discuss potential optimizations. Benchmarking against other advanced transformer-based methods and exploring optimization techniques would provide a clearer picture of computational efficiency.

## Limitations

- Performance gains validated only on single dataset (REDD) with 4 appliance types, limiting generalizability
- Transformer architecture used is relatively simple (2 layers, 2 heads, hidden dimension=16) compared to standard transformers
- Lacks comprehensive ablation studies showing individual contribution of each mechanism
- Meta-network complexity adds overhead without clear analysis of whether it's learning meaningful temperature patterns

## Confidence

- **Performance Improvement Claims**: Medium - Well-supported by experimental results on REDD but limited dataset scope reduces generalizability confidence
- **Mechanism Effectiveness Claims**: Low-Medium - Theoretical justification is sound but lacks direct empirical evidence of individual contributions
- **Small Dataset Applicability**: High - Method's effectiveness on small datasets is well-demonstrated as designed for sample-restricted scenarios

## Next Checks

1. **Ablation Study on Individual Mechanisms**: Conduct experiments isolating the inter-token relation enhancement and dynamic temperature tuning to quantify their individual contributions by comparing performance across different combinations.

2. **Cross-Dataset Validation**: Test the method on additional NILM datasets beyond REDD (such as UK-DALE or PLAID) with different appliance types and data characteristics to verify generalizability of performance improvement claims.

3. **Temperature Value Analysis**: During training, log and analyze learned temperature values from the meta-network to verify they are adapting meaningfully rather than converging to fixed values, examining patterns across different appliances and training epochs.