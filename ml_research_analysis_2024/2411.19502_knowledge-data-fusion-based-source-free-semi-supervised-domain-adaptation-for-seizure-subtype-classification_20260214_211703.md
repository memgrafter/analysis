---
ver: rpa2
title: Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for
  Seizure Subtype Classification
arxiv_id: '2411.19502'
source_url: https://arxiv.org/abs/2411.19502
tags:
- seizure
- domain
- classi
- learning
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses seizure subtype classification using EEG signals
  under source-free semi-supervised domain adaptation (SF-SSDA), where only limited
  labeled target data are available without access to source data. The proposed KDF-MutualSHOT
  method fuses expert knowledge and raw EEG data by training a Soft Decision Tree
  (SDT) with handcrafted features and a Vision Transformer (ViT) with raw EEG signals,
  using Jensen-Shannon Divergence to encourage mutual learning between them.
---

# Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification

## Quick Facts
- arXiv ID: 2411.19502
- Source URL: https://arxiv.org/abs/2411.19502
- Authors: Ruimin Peng; Jiayu An; Dongrui Wu
- Reference count: 32
- Primary result: 0.662 balanced accuracy and 0.669 F1 score on TUSZ→CHSZ cross-dataset adaptation

## Executive Summary
This paper addresses seizure subtype classification using EEG signals under source-free semi-supervised domain adaptation (SF-SSDA), where only limited labeled target data are available without access to source data. The proposed KDF-MutualSHOT method fuses expert knowledge and raw EEG data by training a Soft Decision Tree (SDT) with handcrafted features and a Vision Transformer (ViT) with raw EEG signals, using Jensen-Shannon Divergence to encourage mutual learning between them. For domain adaptation, MutualSHOT improves SHOT with a consistency-based pseudo-label selection strategy that selects only samples with consistent predictions from both models. Experiments on TUSZ and CHSZ datasets show KDF-MutualSHOT achieved 0.662 balanced accuracy and 0.669 F1 score on TUSZ→CHSZ, and 0.701 balanced accuracy and 0.702 F1 score on CHSZ→TUSZ, outperforming other SF-SSDA approaches.

## Method Summary
The KDF-MutualSHOT approach consists of two stages: (1) KDF model pre-training using Jensen-Shannon Divergence for mutual learning between SDT and ViT on source data, and (2) MutualSHOT fine-tuning with consistency-based pseudo-label selection on target data. The method fuses expert knowledge through handcrafted features with data-driven learning from raw EEG signals, using a Soft Decision Tree for feature-driven learning and a Vision Transformer for data-driven learning. During adaptation, a consistency-based pseudo-label selection strategy improves SHOT by only using samples where both models agree on the pseudo-label, reducing the impact of incorrect pseudo-labels.

## Key Results
- Achieved 0.662 balanced accuracy and 0.669 F1 score on TUSZ→CHSZ cross-dataset adaptation
- Achieved 0.701 balanced accuracy and 0.702 F1 score on CHSZ→TUSZ cross-dataset adaptation
- Outperformed other SF-SSDA approaches in both cross-dataset adaptation scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Jensen-Shannon Divergence (JSD) enforces mutual learning between SDT and ViT, improving their collaboration.
- Mechanism: JSD measures the similarity between the probability distributions of SDT and ViT predictions. By minimizing JSD, the two models are encouraged to align their predictions, leading to better information exchange and improved overall performance.
- Core assumption: The predictions of SDT and ViT are complementary and can benefit from mutual learning.
- Evidence anchors:
  - [abstract]: "In source model training, KDF uses Jensen–Shannon Divergence to facilitate mutual learning between a feature-driven Decision Tree-based model and a data-driven Transformer-based model."
  - [section]: "To further enhance the learning efficiency, we additionally incorporate a mutual distillation mechanism to utilize complementary information from knowledge and data. As LKL is asymmetric, we adopt the JSD loss LJSD as the consistency constraint for mutual learning."
- Break condition: If the predictions of SDT and ViT are not complementary or if one model consistently outperforms the other, mutual learning may not provide significant benefits.

### Mechanism 2
- Claim: Consistency-based pseudo-label selection improves the quality of pseudo-labels in SF-SSDA.
- Mechanism: The consistency-based pseudo-label selection strategy only selects samples that have consistent pseudo-labels generated by both SDT and ViT. This ensures that only high-confidence samples are used for training, reducing the impact of incorrect pseudo-labels.
- Core assumption: Samples with consistent pseudo-labels from both models are more likely to be correctly classified.
- Evidence anchors:
  - [abstract]: "To adapt KDF to a new target dataset, an SF-SSDA algorithm, MutualSHOT, is developed, which features a consistency-based pseudo-label selection strategy."
  - [section]: "Since wrong pseudo-labels are harmful for domain adaptation, we propose a consistency-based pseudo-label selection strategy. Rather than taking all target domain pseudo-labels, we only select samples that have consistent pseudo-labels generated by manual features and raw data to form the confident sample set S+: S+ = {(s, f, y)|ySDT(s) == yViT(f)}."
- Break condition: If the predictions of SDT and ViT are highly correlated or if one model consistently makes incorrect predictions, the consistency-based selection may not effectively filter out incorrect pseudo-labels.

### Mechanism 3
- Claim: Combining expert knowledge and raw EEG data improves seizure subtype classification performance.
- Mechanism: The KDF approach combines handcrafted features based on expert knowledge with raw EEG data processed by a Vision Transformer. This fusion of knowledge and data allows the model to leverage both the interpretability of handcrafted features and the representational power of deep learning.
- Core assumption: Expert knowledge and raw data provide complementary information for seizure subtype classification.
- Evidence anchors:
  - [abstract]: "In source model training, KDF uses Jensen–Shannon Divergence to facilitate mutual learning between a feature-driven Decision Tree-based model and a data-driven Transformer-based model."
  - [section]: "Inspired by deep mutual learning [16] for image classification, which introduces a mutual distillation mechanism with the Kullback-Leibler divergence loss LKL to encourage two networks with different parameters to learn from each other, we propose KDF to enhance the collaboration between a knowledge-driven SDT and a data-driven ViT."
- Break condition: If the handcrafted features are not relevant to seizure subtype classification or if the raw EEG data does not contain useful information, the fusion of knowledge and data may not improve performance.

## Foundational Learning

- Concept: Jensen-Shannon Divergence (JSD)
  - Why needed here: JSD is used as a consistency constraint to encourage mutual learning between SDT and ViT.
  - Quick check question: What is the difference between JSD and Kullback-Leibler (KL) divergence, and why is JSD preferred in this context?

- Concept: Soft Decision Tree (SDT)
  - Why needed here: SDT is used to learn from handcrafted features based on expert knowledge.
  - Quick check question: How does SDT differ from a traditional decision tree, and what are the advantages of using SDT in this context?

- Concept: Vision Transformer (ViT)
  - Why needed here: ViT is used to learn from raw EEG data.
  - Quick check question: How does ViT process raw EEG data, and what are the key components of the ViT architecture used in this paper?

## Architecture Onboarding

- Component map: SDT -> ViT -> JSD loss -> MutualSHOT adaptation
- Critical path: 1. Pre-train KDF model using SDT, ViT, and JSD loss on source data 2. Initialize target model with pre-trained KDF 3. Fine-tune target model using MutualSHOT on target data
- Design tradeoffs: Using both SDT and ViT increases model complexity but allows for the fusion of expert knowledge and raw data; Consistency-based pseudo-label selection may reduce the number of training samples but improves the quality of pseudo-labels
- Failure signatures: Poor performance on either SDT or ViT may indicate issues with the corresponding input data or model architecture; Inconsistent pseudo-labels across SDT and ViT may indicate domain shift or insufficient model capacity
- First 3 experiments: 1. Evaluate the performance of SDT and ViT separately on the source data to ensure they are learning meaningful representations 2. Assess the impact of JSD loss on the mutual learning between SDT and ViT by comparing performance with and without JSD loss 3. Test the effectiveness of the consistency-based pseudo-label selection strategy by comparing performance with and without the selection strategy on the target data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of KDF-MutualSHOT vary when using different handcrafted feature sets beyond the 41 features described in the paper?
- Basis in paper: [explicit] The paper states that the authors extracted 41 handcrafted features per EEG channel but does not explore alternative feature sets or compare different feature extraction approaches.
- Why unresolved: The paper only reports results using one specific handcrafted feature set, leaving uncertainty about whether this is optimal or if other feature combinations could yield better performance.
- What evidence would resolve it: Comparative experiments testing KDF-MutualSHOT with various handcrafted feature sets, including different temporal, spectral, time-frequency, and nonlinear features, to identify the most effective combination.

### Open Question 2
- Question: What is the impact of increasing the number of labeled target samples beyond 5-shot on the performance gap between MutualSHOT and fully supervised learning?
- Basis in paper: [explicit] The paper investigates 1-, 3-, and 5-shot settings but notes that MutualSHOT enabled performance "comparably with a supervised learning model" without quantifying the exact performance gap across more labeled samples.
- Why unresolved: The paper does not explore scenarios with more than 5 labeled samples per class, which would reveal whether MutualSHOT maintains its advantage as labeled data availability increases.
- What evidence would resolve it: Systematic experiments varying the number of labeled target samples from 5 up to near-supervised levels, measuring performance metrics and convergence behavior.

### Open Question 3
- Question: How does KDF-MutualSHOT perform when applied to seizure classification across different EEG acquisition systems with varying channel configurations?
- Basis in paper: [explicit] The paper evaluates KDF-MutualSHOT on TUSZ and CHSZ datasets but does not address cross-dataset scenarios where EEG acquisition parameters differ significantly.
- Why unresolved: The experiments focus on cross-subject adaptation within similar datasets, but real-world clinical applications often involve transitioning between different recording systems with different channel counts and placements.
- What evidence would resolve it: Experiments testing KDF-MutualSHOT on multiple datasets with varying channel configurations, electrode montages, and recording parameters to assess robustness across different EEG acquisition systems.

## Limitations
- The approach requires access to both handcrafted features and raw EEG data, which may not be feasible in all clinical settings where feature engineering expertise is limited
- The consistency-based pseudo-label selection strategy, while effective, reduces the number of available training samples, potentially limiting performance on very small target datasets
- The method's generalizability to other medical imaging tasks beyond EEG-based seizure classification remains unverified

## Confidence
- **High Confidence**: The core mechanism of Jensen-Shannon Divergence for mutual learning between SDT and ViT is well-established in the literature and directly supported by experimental results showing consistent performance improvements
- **Medium Confidence**: The effectiveness of the consistency-based pseudo-label selection strategy is supported by results, but the paper lacks ablation studies showing the individual contribution of each component to the overall performance
- **Medium Confidence**: While the balanced accuracy and F1 scores show improvements over baselines, the absolute performance levels (0.662-0.702) indicate that the problem remains challenging and the method is not yet achieving clinical-grade reliability

## Next Checks
1. Conduct ablation studies to isolate the individual contributions of the Jensen-Shannon Divergence loss and the consistency-based pseudo-label selection to the overall performance improvement
2. Test the method on additional domain adaptation scenarios beyond TUSZ→CHSZ and CHSZ→TUSZ to assess generalizability to different EEG datasets and seizure types
3. Evaluate model calibration and uncertainty estimates, particularly for pseudo-labels, to better understand the reliability of predictions in clinical settings where false positives/negatives have serious consequences