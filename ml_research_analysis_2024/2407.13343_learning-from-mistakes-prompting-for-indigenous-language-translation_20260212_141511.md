---
ver: rpa2
title: Learning-From-Mistakes Prompting for Indigenous Language Translation
arxiv_id: '2407.13343'
source_url: https://arxiv.org/abs/2407.13343
tags:
- language
- translation
- prompting
- amis
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a methodology to improve translation of low-resource
  indigenous languages using large language models (LLMs) like GPT-3.5. The approach
  uses three techniques: KNN-Prompting with Retrieved Prompting Context (RPC), Chain-of-Thought
  (CoT) Prompting, and Learning-from-Mistakes (LFM) Prompting.'
---

# Learning-From-Mistakes Prompting for Indigenous Language Translation

## Quick Facts
- arXiv ID: 2407.13343
- Source URL: https://arxiv.org/abs/2407.13343
- Reference count: 6
- One-line primary result: KNN-Prompting with RPC, CoT Prompting, and LFM Prompting significantly improve indigenous language translation, increasing BLEU scores from near zero to 44.4-50.0.

## Executive Summary
This paper introduces a novel approach to improve translation of low-resource indigenous languages using large language models (LLMs) like GPT-3.5. The methodology combines three prompting techniques: KNN-Prompting with Retrieved Prompting Context (RPC), Chain-of-Thought (CoT) Prompting, and Learning-from-Mistakes (LFM) Prompting. These methods work together to provide context, guide the LLM's reasoning, and incorporate feedback from translation errors to produce more accurate and culturally appropriate translations. Experiments on six indigenous languages demonstrate significant improvements in translation quality compared to zero-shot translation baselines.

## Method Summary
The methodology leverages LLMs as language compilers to translate Chinese sentences into Taiwanese indigenous languages. It first retrieves k nearest neighbor sentences and word-level translations to create a Retrieved Prompting Context (RPC). Chain-of-Thought Prompting then guides the LLM on how to use this context for translation. Finally, Learning-from-Mistakes Prompting introduces a feedback mechanism where the LLM learns from its previous translation errors to refine subsequent translations. This approach is particularly effective for low-resource languages with limited parallel corpora.

## Key Results
- BLEU scores increased from near zero for zero-shot translation to 44.4-50.0 with the full methodology
- LFM Prompting demonstrated the ability to improve translation quality through iterative refinement
- Expert review confirmed that LFM Prompting produces more accurate and culturally appropriate translations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KNN-Prompting with RPC improves translation by providing LLMs with relevant examples and word-level translations.
- Mechanism: The approach retrieves contextually similar sentences and individual word translations from a datastore and dictionary, creating a Retrieved Prompting Context (RPC) that helps the LLM understand grammar and context.
- Core assumption: LLMs can learn syntactic structures and improve translation accuracy when given relevant examples and word-level translations.
- Evidence anchors:
  - [abstract]: "Our methodology hinges on utilizing LLMs as language compilers for selected language pairs, hypothesizing that they could internalize syntactic structures to facilitate accurate translation."
  - [section]: "The core principle of our method is to enable the LLM to assimilate the grammatical norms and sentence constructs of the target language. It achieves this through the analysis of the k examples, thereby learning to organize the individually translated words into coherent and grammatically consistent sentences."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.
- Break condition: If the datastore lacks relevant examples or the dictionary is incomplete, the RPC may not provide sufficient context for accurate translation.

### Mechanism 2
- Claim: Chain-of-Thought (CoT) Prompting guides LLMs to effectively use RPC for translation.
- Mechanism: CoT demonstrations show how to integrate RPC (k examples and word translations) to formulate the final translated sentences, enhancing the LLM's understanding of grammatical rules.
- Core assumption: LLMs can follow step-by-step reasoning when demonstrated how to use contextual information for translation.
- Evidence anchors:
  - [abstract]: "We introduce three techniques: KNN-Prompting with Retrieved Prompting Context, Chain-of-Thought Prompting and Learning-from-Mistakes Prompting..."
  - [section]: "The overarching aim of this methodology is to empower the LLM with an understanding of the grammatical rules and the proficiency to fully leverage the RPC..."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.
- Break condition: If CoT demonstrations are not clear or relevant, the LLM may not effectively utilize the RPC for translation.

### Mechanism 3
- Claim: Learning-from-Mistakes (LFM) Prompting introduces a feedback mechanism for continuous improvement.
- Mechanism: LFM uses trial translations from CoT Prompting, treats errors as learning examples, and refines subsequent translations based on past mistakes.
- Core assumption: LLMs can improve translation quality when provided with examples of their previous errors and guidance on how to correct them.
- Evidence anchors:
  - [abstract]: "...culminating in the Learning-from-Mistakes (LFM) Prompting technique that incorporates feedback mechanisms for continuous improvement."
  - [section]: "The second phase of LFM Prompting introduces a crucial element: the incorporation of past translation errors... The language model is tasked with refining Ë†t by considering the error examples in translation."
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism.
- Break condition: If the LLM cannot recognize or learn from its mistakes, the LFM approach may not lead to improved translations.

## Foundational Learning

- Concept: In-context learning
  - Why needed here: LLMs like GPT-3.5 rely on in-context learning to perform tasks without fine-tuning, crucial for low-resource language translation.
  - Quick check question: How does providing examples within the prompt help the LLM learn to translate a new language?

- Concept: Few-shot learning
  - Why needed here: With limited parallel corpora, few-shot learning techniques are essential to teach the LLM translation patterns.
  - Quick check question: What is the difference between zero-shot and few-shot learning in the context of LLM translation?

- Concept: Feedback mechanisms in machine learning
  - Why needed here: Incorporating feedback from previous errors allows the LLM to refine its translations over time.
  - Quick check question: How can a feedback loop improve the performance of an LLM in translating low-resource languages?

## Architecture Onboarding

- Component map:
  Datastore -> Dictionary -> LLM (e.g., GPT-3.5) -> KNN-Prompting with RPC -> CoT Prompting -> LFM Prompting

- Critical path:
  1. Retrieve k nearest neighbor sentences and word translations to form RPC
  2. Apply CoT Prompting to guide LLM in using RPC
  3. Generate trial translations
  4. Use LFM Prompting to learn from errors and refine translations

- Design tradeoffs:
  - More examples in RPC may improve context but increase prompt size
  - CoT demonstrations must be carefully crafted to effectively guide the LLM
  - LFM requires storing and analyzing previous translations, adding complexity

- Failure signatures:
  - BLEU scores remain low despite using all prompting techniques
  - Translations are grammatically incorrect or lack coherence
  - LLM fails to improve after multiple LFM iterations

- First 3 experiments:
  1. Test KNN-Prompting with RPC alone to establish baseline improvement
  2. Add CoT Prompting to see if it further enhances translation quality
  3. Implement LFM Prompting to measure the impact of the feedback mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the LFM prompting method perform when scaling to larger datasets with more diverse translation examples?
- Basis in paper: [inferred] The paper mentions LFM prompting uses past translation errors for refinement, but does not explore performance at scale
- Why unresolved: The paper only tests on a limited dataset of 350 reference sentences per language
- What evidence would resolve it: Experiments showing LFM prompting performance with varying dataset sizes and example diversity

### Open Question 2
- Question: What is the impact of dictionary quality and coverage on translation accuracy for extremely low-resource languages?
- Basis in paper: [explicit] "We introduce another assumption: the existence of a dictionary that spans word-level translations" and mentions "dictionary absences are addressed by seeking synonyms"
- Why unresolved: The paper acknowledges dictionary limitations but doesn't quantify their impact on translation quality
- What evidence would resolve it: Systematic evaluation of translation quality with dictionaries of varying quality and coverage

### Open Question 3
- Question: How does the proposed methodology generalize to language pairs beyond Chinese to Taiwanese indigenous languages?
- Basis in paper: [inferred] The methodology is presented as general but only tested on Chinese to indigenous language pairs
- Why unresolved: All experiments focus specifically on Chinese to indigenous language translation
- What evidence would resolve it: Testing the methodology on different language pairs and comparing performance across them

## Limitations

- Reliance on Chinese as the source language constrains generalizability to other source languages
- Evaluation depends heavily on automatic metrics without comprehensive human evaluation across all languages
- Assumes sufficient parallel examples exist in the datastore to enable effective KNN retrieval

## Confidence

- Translation quality improvements: High confidence (supported by significant BLEU score increases and expert validation)
- LFM prompting effectiveness: Medium confidence (strong qualitative evidence but limited quantitative validation)
- Generalization to other language pairs: Low confidence (results specific to Chinese-indigenous language pairs)

## Next Checks

1. **Cross-language validation**: Test the complete methodology pipeline on indigenous language pairs that don't involve Chinese as the source language to assess generalizability.

2. **Human evaluation expansion**: Conduct comprehensive human evaluation across all six languages using native speakers to validate the automatic metric results and assess cultural appropriateness.

3. **Resource scaling analysis**: Systematically vary the size of the parallel corpus and dictionary to determine the minimum viable dataset size required for effective translation, identifying the method's breaking points.