---
ver: rpa2
title: Multi-granular Adversarial Attacks against Black-box Neural Ranking Models
arxiv_id: '2404.01574'
source_url: https://arxiv.org/abs/2404.01574
tags:
- attack
- ranking
- document
- adversarial
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces RL-MARA, a novel method for multi-granular
  adversarial attacks against black-box neural ranking models. Unlike existing single-granular
  attacks, RL-MARA incorporates word-level, phrase-level, and sentence-level perturbations
  to generate more effective and imperceptible adversarial examples.
---

# Multi-granular Adversarial Attacks against Black-box Neural Ranking Models

## Quick Facts
- arXiv ID: 2404.01574
- Source URL: https://arxiv.org/abs/2404.01574
- Reference count: 40
- Authors: Yu-An Liu; Ruqing Zhang; Jiafeng Guo; Maarten de Rijke; Yixing Fan; Xueqi Cheng
- Key outcome: RL-MARA significantly outperforms existing baselines in both attack effectiveness (42.2% average boosted ranks vs 39.6% for best baseline on MS MARCO) and imperceptibility while maintaining semantic consistency

## Executive Summary
This paper introduces RL-MARA, a novel method for multi-granular adversarial attacks against black-box neural ranking models. Unlike existing single-granular attacks, RL-MARA incorporates word-level, phrase-level, and sentence-level perturbations to generate more effective and imperceptible adversarial examples. The method formulates the attack as a sequential decision-making process, using reinforcement learning with two cooperative agents to identify vulnerabilities and organize perturbations optimally. Experiments on MS MARCO and ClueWeb09 datasets demonstrate that RL-MARA significantly outperforms existing baselines in attack effectiveness while maintaining naturalness of perturbed documents.

## Method Summary
RL-MARA treats adversarial ranking attacks as a sequential decision-making process where perturbations build upon previously perturbed documents. The framework employs two cooperative agents: a sub-agent that identifies vulnerable positions across word, phrase, and sentence levels, and a meta-agent that organizes perturbation candidates into an optimal sequence. The method uses a surrogate ranking model (BERT-base) trained with pseudo relevance feedback to guide attacks against black-box targets, with rewards balancing attack effectiveness and naturalness. Training follows the REINFORCE policy gradient algorithm with a term manipulation budget of ε=25.

## Key Results
- RL-MARA achieves 42.2% average boosted ranks on MS MARCO compared to 39.6% for the best baseline
- Significant improvements in naturalness metrics including grammar checking, spamicity detection, and perplexity scores
- Ablation studies confirm the importance of both multi-granularity and sequential perturbation organization
- Robust performance across both MS MARCO and ClueWeb09 datasets against various target models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequential perturbation aggregation improves attack effectiveness by building upon previously successful perturbations
- Mechanism: The method treats adversarial ranking attack as a sequential decision-making process where each perturbation step builds on the current perturbed document state, allowing the attack to adapt based on intermediate results
- Core assumption: Each perturbation step provides useful feedback that can guide the selection of subsequent perturbations
- Evidence anchors:
  - [abstract] "transform the multi-granular adversarial attack into a sequential decision-making process, where perturbations in the next attack step build on the perturbed document in the current attack step"
  - [section] "The global objective is to optimize the final ranking improvement of the target document with indiscernible perturbations"

### Mechanism 2
- Claim: Multi-granular perturbations provide richer vulnerability coverage than single-granularity approaches
- Mechanism: By incorporating word-level, phrase-level, and sentence-level perturbations simultaneously, the attack can exploit vulnerabilities at different granularities within the same document-query pair
- Core assumption: Different query-document pairs exhibit vulnerabilities at different granularity levels, and a single granularity cannot capture all vulnerability patterns
- Evidence anchors:
  - [abstract] "incorporates word-level, phrase-level, and sentence-level perturbations to generate more effective and imperceptible adversarial examples"
  - [section] "limiting perturbations to a single granularity may fail to adequately capture the nuanced and diverse vulnerability features"

### Mechanism 3
- Claim: Cooperative dual-agent architecture enables flexible organization of perturbations
- Mechanism: The vulnerability indicator identifies important positions at each granularity level, while the perturbation aggregator generates and organizes perturbations into an optimal sequence, allowing for flexible selection rather than rigid application
- Core assumption: A single agent cannot effectively both identify vulnerabilities across multiple granularities and organize perturbations optimally
- Evidence anchors:
  - [abstract] "two agents work cooperatively to identify multi-granular vulnerabilities as attack targets and organize perturbation candidates into a final perturbation sequence"
  - [section] "The objective of the multi-granular attacker is to identify possible attack positions at all granularities and organize them into a final perturbation sequence"

## Foundational Learning

- Concept: Reinforcement Learning for sequential decision making
  - Why needed here: The attack process requires making a series of decisions (which perturbation to apply next) based on the current state without direct intermediate supervision
  - Quick check question: Why can't we use supervised learning to train the attack agent directly?

- Concept: Black-box adversarial attack methodology
  - Why needed here: The target NRM is inaccessible, requiring the use of a surrogate model to guide the attack while maintaining transferability
  - Quick check question: What is the key difference between white-box and black-box adversarial attacks in terms of information available?

- Concept: Text perturbation at multiple granularity levels
  - Why needed here: Different types of textual modifications (word, phrase, sentence) can affect the ranking model differently and have varying impacts on naturalness
  - Quick check question: How does the number of manipulated terms typically differ between word-level and sentence-level perturbations?

## Architecture Onboarding

- Component map: Environment (surrogate model + LLM) → RL-MARA framework → Vulnerability indicator sub-agent → Perturbation aggregator meta-agent → Document perturbation sequence
- Critical path: Identify vulnerable positions → Generate specific perturbations → Organize into sequence → Apply until budget exhausted
- Design tradeoffs: Multi-granular flexibility vs computational complexity; naturalness constraints vs attack effectiveness; surrogate model fidelity vs transferability
- Failure signatures: Poor surrogate model performance leading to ineffective attacks; imbalance between agents causing suboptimal sequences; insufficient budget for meaningful attacks
- First 3 experiments:
  1. Implement single-granular version of RL-MARA to establish baseline performance
  2. Add vulnerability indicator to identify positions across all granularities without aggregation
  3. Integrate perturbation aggregator with fixed ordering to test sequential decision making impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we efficiently optimize the combinatorial explosion problem in multi-granular adversarial attacks from a theoretical perspective?
- Basis in paper: [inferred] The paper mentions that "Achieving this objective involves tackling a combinatorial explosion problem" and discusses the computational challenges of identifying optimal combinations of perturbations across all possible levels of granularity, positions, and textual pieces.
- Why unresolved: While the paper proposes RL-MARA as a practical solution, it acknowledges the theoretical complexity of the combinatorial problem and suggests this as a direction for future work.
- What evidence would resolve it: A formal mathematical framework that characterizes the computational complexity of multi-granular attacks and provides provable bounds on the number of perturbations needed to achieve a certain attack success rate.

### Open Question 2
- Question: How can we make the single-granular attack methods learnable and dynamically update them within the entire RL-MARA framework?
- Basis in paper: [explicit] The paper states "In the future, we plan to consider more granularity and add more attack methods at the same granularity to make the perturbation even more diverse. Besides, the above three single-granular attacks remain constant in our current multi-granular attack method. In the future, we aim to make these attack methods learnable and dynamically update them within the entire framework to achieve enhanced interoperability."
- Why unresolved: The current implementation uses static single-granular attack methods (PRADA, PLAT, PAT) without any learning capability. The paper explicitly identifies this as a limitation and future research direction.
- What evidence would resolve it: An experimental comparison showing improved attack performance when single-granular methods are dynamically updated during training versus the static approach used in the current RL-MARA framework.

### Open Question 3
- Question: How effective are multi-granular adversarial attacks against LLMs directly used as rankers compared to NRMs distilled from LLMs?
- Basis in paper: [inferred] The paper mentions "Our method proves effective against NRMs distilled from LLMs, as exemplified by RankLLM" and notes this as a promising future research avenue.
- Why unresolved: The current evaluation focuses on NRMs and their distilled versions, but does not directly attack LLMs acting as rankers. The paper explicitly identifies this gap.
- What evidence would resolve it: Empirical results comparing the success rates and imperceptibility of multi-granular attacks against both LLMs used directly as rankers versus NRMs distilled from LLMs under identical conditions.

## Limitations

- Limited surrogate model fidelity - The paper relies on a surrogate ranking model (BERT-base) to guide attacks against black-box targets, but the fidelity of this approximation is not thoroughly validated
- Reward function complexity - The dual-objective reward function balancing attack effectiveness and naturalness introduces tuning challenges with a single β parameter used without sensitivity analysis
- Generalizability concerns - Experiments focus on specific datasets (MS MARCO, ClueWeb09) and ranking models (BERT-base, uniCOIL), requiring further validation across different domains and architectures

## Confidence

**High confidence**: The core mechanism of sequential multi-granular perturbations building upon previous states is well-supported by experimental results showing consistent improvements over baselines across multiple metrics and datasets.

**Medium confidence**: The claim that cooperative dual-agent architecture outperforms single-agent alternatives is supported by ablation studies, but the specific contribution of each agent component could benefit from more granular analysis.

**Medium confidence**: The naturalness preservation claims are supported by automated metrics and human evaluation, but the absolute naturalness levels and their impact on downstream tasks remain unclear.

## Next Checks

1. **Transferability validation**: Conduct controlled experiments comparing attack effectiveness when using the surrogate model versus direct black-box queries, measuring the performance gap to quantify surrogate fidelity.

2. **Hyperparameter sensitivity analysis**: Systematically vary the β parameter controlling the effectiveness-naturalness trade-off and the perturbation budget ε to map the performance landscape and identify optimal operating points.

3. **Cross-domain generalization**: Test RL-MARA on ranking tasks outside the MS MARCO/ClueWeb09 domain (e.g., academic search, e-commerce) and against different ranking architectures (e.g., T5-based, Cross-Encoder models) to assess robustness across diverse scenarios.