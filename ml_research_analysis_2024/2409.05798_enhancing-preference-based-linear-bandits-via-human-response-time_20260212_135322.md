---
ver: rpa2
title: Enhancing Preference-based Linear Bandits via Human Response Time
arxiv_id: '2409.05798'
source_url: https://arxiv.org/abs/2409.05798
tags:
- each
- times
- choices
- response
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work is the first to leverage human response times to improve
  fixed-budget best-arm identification in preference-based linear bandits. We proposed
  a utility estimator that combines choices and response times.
---

# Enhancing Preference-based Linear Bandits via Human Response Time

## Quick Facts
- arXiv ID: 2409.05798
- Source URL: https://arxiv.org/abs/2409.05798
- Reference count: 40
- Key outcome: This work is the first to leverage human response times to improve fixed-budget best-arm identification in preference-based linear bandits. We proposed a utility estimator that combines choices and response times. Both theoretical and empirical analyses show that response times provide complementary information about preference strength, particularly for queries with strong preferences, enhancing estimation performance. When integrated into a bandit algorithm, incorporating response times consistently improved results across three real-world datasets.

## Executive Summary
This paper introduces a novel approach to preference-based linear bandits that leverages human response times alongside binary choices to improve best-arm identification. The authors propose a choice-decision-time estimator that combines both signals using the difference-based EZ-diffusion model (dEZDM) framework. The key insight is that response times provide complementary information about preference strength, especially for queries with strong preferences where choices become less informative. The proposed method is theoretically grounded with concentration bounds and empirically validated across three real-world datasets.

## Method Summary
The method combines human choices and response times in a preference-based linear bandit framework using the difference-based EZ-diffusion model (dEZDM). The choice-decision-time estimator computes θ* by combining choices and response times via a linear relationship, while the choice-only estimator uses logistic regression on choices alone. These estimators are integrated into a Generalized Successive Elimination (GSE) algorithm with two experimental designs: transductive (equal weighting) and weak-preference (prioritizing weak preferences). The algorithm operates under a fixed budget, eliminating suboptimal arms iteratively until the best arm is identified.

## Key Results
- Response times provide complementary information about preference strength, particularly for queries with strong preferences
- The choice-decision-time estimator outperforms the choice-only estimator, especially for strong preferences
- When integrated into GSE, incorporating response times consistently improved best-arm identification performance across three real-world datasets
- The transductive design performs comparably to the weak-preference design while being more practical

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Response times provide complementary information about preference strength, especially for queries with strong preferences.
- **Mechanism:** The choice-decision-time estimator combines choices and response times using the relationship `x⊤θ*/a = E[cx]/E[tx]`. This transforms binary choices into richer continuous signals by weighting queries based on their expected decision time rather than choice variance alone.
- **Core assumption:** The relationship between expected choice and expected decision time is linear in the utility difference divided by barrier parameter `a`.
- **Evidence anchors:**
  - [abstract] "response times complement choices by providing extra information about preference strength, particularly for queries with strong preferences"
  - [section 3.2] "decision times complement choices by capturing preference strength, leading to improved estimation"
  - [corpus] Weak - related papers mention "preference strength learning" but don't explicitly validate the specific mechanism of using `E[cx]/E[tx]` ratio.
- **Break condition:** If the linearity assumption breaks down (e.g., non-decision times vary systematically across queries, or the relationship becomes non-linear for certain preference strengths).

### Mechanism 2
- **Claim:** For strong preferences, choices become less informative because humans consistently select the same option regardless of whether preference is moderate or very strong.
- **Mechanism:** When preferences are strong, the choice variance `a²V[cx]` quickly decays to zero, making it difficult to distinguish between moderate and very strong preferences. Response times remain informative because they capture the actual speed of decision-making.
- **Core assumption:** Choice consistency increases monotonically with preference strength in the dEZDM framework.
- **Evidence anchors:**
  - [section 3.2] "choices from queries with strong preferences provide little information" and "choices from such queries contribute minimally to utility estimation"
  - [section 5.1] Empirical results showing choice-only estimator performance degrades as preferences become stronger
  - [corpus] Weak - related papers discuss preference strength but don't validate the specific claim about choice variance decay.
- **Break condition:** If the relationship between preference strength and choice consistency is non-monotonic or if response times become similarly uninformative for very strong preferences.

### Mechanism 3
- **Claim:** The choice-decision-time estimator provides better asymptotic and non-asymptotic concentration bounds than the choice-only estimator.
- **Mechanism:** The asymptotic variance for the choice-decision-time estimator is weighted by `minx'∈Xsample E[tx']`, which remains relatively large even for strong preferences, while the choice-only estimator is weighted by `a²V[cx]` which decays to zero for strong preferences.
- **Core assumption:** The minimum expected decision time across sampled queries is a reasonable upper bound on the asymptotic variance.
- **Evidence anchors:**
  - [section 3.2] Comparison of asymptotic variances showing different weighting schemes
  - [section 3.3] Non-asymptotic concentration bounds comparing `mnon-asym_CH,DT` and `mnon-asym_CH`
  - [corpus] Weak - related papers don't provide concentration bound comparisons for this specific estimator.
- **Break condition:** If the minimum expected decision time is dominated by a few queries with artificially long decision times, or if the relationship between expected choice and expected decision time breaks down.

## Foundational Learning

- **Concept:** Drift-Diffusion Models (DDM) and EZ-Diffusion Model (EZDM)
  - **Why needed here:** The dEZDM provides the theoretical foundation for modeling choices and response times as functions of utility differences
  - **Quick check question:** In the dEZDM, what is the relationship between expected choice `E[cx]` and expected decision time `E[tx]` for a query with utility difference `ux` and barrier `a`?

- **Concept:** Linear utility functions in bandit settings
  - **Why needed here:** The linear utility assumption `uz = z⊤θ*` enables efficient estimation across many arms and queries
  - **Quick check question:** Why is estimating `θ*/a` sufficient for best-arm identification, even though we don't know the barrier parameter `a`?

- **Concept:** Generalized Successive Elimination (GSE) algorithm
  - **Why needed here:** GSE provides the framework for integrating the choice-decision-time estimator into a complete bandit learning algorithm
  - **Quick check question:** In GSE, what is the purpose of the buffer size `Bbuff` and how does it relate to the random resource consumption of queries?

## Architecture Onboarding

- **Component map:**
  - Data Collection: Query selection, response time measurement, choice recording
  - Estimation Engine: Choice-decision-time estimator (`bθCH,DT`) and choice-only estimator (`bθCH`)
  - Algorithm Core: GSE with two experimental designs (transductive and weak-preference)
  - Evaluation: Best-arm identification error probability, budget tracking

- **Critical path:**
  1. Select query using experimental design
  2. Present query to human, collect choice and response time
  3. Update estimates using choice-decision-time estimator
  4. Eliminate low-utility arms based on estimates
  5. Repeat until budget exhausted or single arm remains
  6. Output recommended arm

- **Design tradeoffs:**
  - Known vs. unknown non-decision time: Using response times directly vs. decision times affects estimator performance slightly but adds complexity
  - Transductive vs. weak-preference design: Transductive design weights all queries equally; weak-preference design prioritizes weak preferences but requires knowledge of θ*
  - Choice-decision-time vs. choice-only estimator: Choice-decision-time provides better performance but requires both signals; choice-only is simpler but less informative

- **Failure signatures:**
  - Estimator variance remains high despite sufficient budget: May indicate non-stationary preferences or violation of dEZDM assumptions
  - Performance degrades with higher barriers: Could indicate systematic bias in response time measurements or choice consistency assumptions
  - Buffer size too small/large: Budget overrun or inefficient resource utilization

- **First 3 experiments:**
  1. Implement the choice-decision-time estimator on synthetic data with known θ* and varying preference strengths; verify that it outperforms choice-only estimator for strong preferences
  2. Integrate both estimators into GSE with transductive design; compare performance on simple synthetic bandit problems with 5-10 arms
  3. Test the unknown non-decision time variant (`bθCH,RT`) on the same problems to quantify performance degradation compared to known non-decision time case

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice-decision-time estimator perform when the non-decision time (tnondec) is unknown and must be estimated from data?
- Basis in paper: [explicit] The paper discusses a variation of the estimator (bθCH,RT) that uses response times directly instead of decision times when tnondec is unknown, and notes that empirical results show minimal performance degradation.
- Why unresolved: The paper only empirically evaluates this scenario and does not provide theoretical analysis of how estimation uncertainty in tnondec affects the estimator's performance.
- What evidence would resolve it: Theoretical analysis showing the impact of tnondec estimation error on the estimator's asymptotic variance or concentration bounds, or empirical comparison with ground-truth tnondec values.

### Open Question 2
- Question: Can the insights about response times complementing choices for strong preferences be generalized to other bounded accumulation models beyond the EZ-diffusion model?
- Basis in paper: [inferred] The paper suggests in Appendix B.3 that the key insight might extend to other models, noting that many psychological models produce "S"-shaped psychometric functions that flatten for strong preferences.
- Why unresolved: The paper only empirically validates this insight for the EZ-diffusion model and does not test it with other bounded accumulation models.
- What evidence would resolve it: Empirical comparison of the choice-decision-time estimator's performance using other bounded accumulation models (e.g., race models, attentional-DDM) on the same datasets.

### Open Question 3
- Question: How should the elimination parameter (η) and buffer size (Bbuff) be optimally tuned for different datasets and budget constraints in the GSE algorithm?
- Basis in paper: [explicit] The paper mentions that both parameters require manual tuning and suggests that further theoretical analysis is needed to better understand and optimize them.
- Why unresolved: The paper only provides empirical tuning results for specific datasets and does not offer a general method for parameter selection.
- What evidence would resolve it: Theoretical analysis providing guidelines for setting η and Bbuff based on problem characteristics (e.g., number of arms, expected response times, budget size), or an adaptive method that tunes these parameters during algorithm execution.

## Limitations
- Theoretical guarantees rely heavily on dEZDM assumptions holding exactly in practice
- Empirical validation limited to three real-world datasets from potentially narrow domains
- Weak-preference experimental design requires knowledge of the optimal arm, limiting practical applicability
- Performance depends on quality of response time measurements, which can be affected by technical factors

## Confidence

- **High Confidence**: The core theoretical framework (dEZDM, estimator definitions, concentration bounds) is mathematically sound and well-established.
- **Medium Confidence**: The empirical improvements over choice-only methods are demonstrated but require more diverse datasets for robust validation.
- **Low Confidence**: The weak-preference experimental design's practical applicability given its requirement for knowing θ*.

## Next Checks

1. **Cross-dataset validation**: Test the algorithm on at least 5 additional preference-based datasets from different domains to assess generalizability.
2. **Response time quality analysis**: Conduct controlled experiments varying response time measurement conditions to quantify sensitivity to measurement quality.
3. **Non-stationary preference testing**: Evaluate algorithm performance when human preferences evolve over time to assess robustness to assumption violations.