---
ver: rpa2
title: 'Forecasting with Deep Learning: Beyond Average of Average of Average Performance'
arxiv_id: '2406.16590'
source_url: https://arxiv.org/abs/2406.16590
tags:
- forecasting
- time
- series
- performance
- nhits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a comprehensive evaluation framework for comparing
  univariate time series forecasting methods across multiple dimensions. The framework
  moves beyond traditional single-metric comparisons by examining model performance
  across different forecasting horizons, sampling frequencies, and specific scenarios
  like anomalies.
---

# Forecasting with Deep Learning: Beyond Average of Average of Average Performance

## Quick Facts
- arXiv ID: 2406.16590
- Source URL: https://arxiv.org/abs/2406.16590
- Authors: Vitor Cerqueira; Luis Roque; Carlos Soares
- Reference count: 30
- Primary result: NHITS deep learning model shows superior multi-step forecasting performance but struggles with anomalies compared to classical methods

## Executive Summary
This study presents a comprehensive evaluation framework for comparing univariate time series forecasting methods across multiple dimensions. The framework moves beyond traditional single-metric comparisons by examining model performance across different forecasting horizons, sampling frequencies, and specific scenarios like anomalies. The authors compare a state-of-the-art deep learning approach (NHITS) with classical forecasting methods (ARIMA, ETS, Theta, etc.) using three benchmark datasets containing 99,140 time series. While NHITS shows the best overall performance according to SMAPE, the analysis reveals nuanced insights about its relative performance across different forecasting conditions.

## Method Summary
The study employs a multi-faceted evaluation framework that assesses forecasting methods across three benchmark datasets containing 99,140 time series. The comparison includes both classical methods (ARIMA, ETS, Theta) and a state-of-the-art deep learning approach (NHITS). Performance is evaluated across multiple dimensions including forecasting horizons (one-step vs multi-step), sampling frequencies, and specific scenarios such as anomalies. The primary metric used is SMAPE, though the framework considers various evaluation perspectives. The analysis goes beyond simple average performance to examine how methods perform under different conditions and in worst-case scenarios.

## Key Results
- NHITS demonstrates superior performance in multi-step forecasting scenarios across benchmark datasets
- Classical methods maintain competitive performance in one-step forecasting, outperforming NHITS in some cases
- Deep learning approaches show particular strength in worst-case scenarios but struggle with anomaly handling compared to classical methods

## Why This Works (Mechanism)
The deep learning approach (NHITS) works effectively for multi-step forecasting due to its ability to capture complex temporal dependencies and nonlinear patterns across extended forecasting horizons. The architecture leverages attention mechanisms and transformer-like structures that can learn long-range dependencies in time series data. For one-step forecasting, classical methods like ARIMA and ETS remain competitive because they can efficiently model simpler patterns and are less prone to overfitting on single-step predictions. The superior worst-case performance of deep learning models likely stems from their capacity to adapt to various time series patterns and maintain performance across diverse scenarios, though this comes at the cost of reduced robustness to anomalies.

## Foundational Learning

1. **Time Series Decomposition** - Why needed: Understanding how time series can be broken into trend, seasonal, and residual components is crucial for selecting appropriate forecasting methods. Quick check: Can you decompose a sample time series into its components?

2. **Stationarity Testing** - Why needed: Many classical forecasting methods assume stationarity, making it essential to test and potentially transform non-stationary series. Quick check: Can you identify and transform non-stationary time series?

3. **Model Selection Criteria** - Why needed: Understanding AIC, BIC, and cross-validation helps in selecting appropriate models for different time series characteristics. Quick check: Can you choose between competing models using appropriate criteria?

## Architecture Onboarding

Component Map: Data Preprocessing -> Feature Engineering -> Model Training -> Multi-step Forecasting -> Performance Evaluation

Critical Path: The evaluation framework establishes a systematic pipeline from raw time series through preprocessing, model application, and multi-dimensional performance assessment across different forecasting scenarios.

Design Tradeoffs: The study trades computational complexity for comprehensive evaluation, running multiple models across extensive datasets to capture nuanced performance differences. This approach provides deeper insights but requires significant computational resources.

Failure Signatures: Deep learning models show degraded performance with anomalies and may overfit on simpler patterns, while classical methods may struggle with complex nonlinear relationships and multi-step forecasting.

First Experiments:
1. Compare NHITS and classical methods on a small synthetic dataset with known patterns
2. Test one-step vs multi-step forecasting performance on a simple dataset
3. Evaluate model performance on data with injected anomalies

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Focus on univariate forecasting limits generalizability to multivariate scenarios common in real-world applications
- Reliance on SMAPE as primary metric, which can be problematic for series containing zero values
- Limited comparison to a single deep learning approach (NHITS) may not capture variations across different architectures
- Datasets, while extensive, may not fully represent all possible time series characteristics encountered in practice

## Confidence

High Confidence Claims:
- NHITS demonstrates superior performance in multi-step forecasting scenarios
- Classical methods maintain competitive performance in one-step forecasting
- Deep learning approaches show particular strength in worst-case scenarios

Medium Confidence Claims:
- NHITS performance degrades when handling anomalies
- The superiority of NHITS varies significantly across different forecasting conditions

Low Confidence Claims:
- Generalization of findings to multivariate forecasting scenarios

## Next Checks

1. Validate findings across additional deep learning architectures (e.g., N-BEATS, DeepAR) to assess if results are specific to NHITS
2. Test performance on multivariate time series datasets to evaluate generalizability beyond univariate scenarios
3. Conduct ablation studies to isolate the impact of specific deep learning components on anomaly handling performance