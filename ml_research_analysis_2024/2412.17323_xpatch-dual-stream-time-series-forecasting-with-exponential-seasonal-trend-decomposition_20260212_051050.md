---
ver: rpa2
title: 'xPatch: Dual-Stream Time Series Forecasting with Exponential Seasonal-Trend
  Decomposition'
arxiv_id: '2412.17323'
source_url: https://arxiv.org/abs/2412.17323
tags:
- prediction
- xpatch
- series
- trend
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces xPatch, a dual-stream neural architecture
  for long-term time series forecasting that outperforms transformer-based models.
  The core innovation is a seasonal-trend decomposition using exponential moving average
  (EMA), which separates input series into trend and seasonal components.
---

# xPatch: Dual-Stream Time Series Forecasting with Exponential Seasonal-Trend Decomposition

## Quick Facts
- arXiv ID: 2412.17323
- Source URL: https://arxiv.org/abs/2412.17323
- Authors: Artyom Stitsyuk; Jaesik Choi
- Reference count: 40
- xPatch outperforms transformer-based models like CARD and PatchTST by 3-9% in MSE and MAE metrics

## Executive Summary
xPatch introduces a dual-stream neural architecture for long-term time series forecasting that achieves state-of-the-art performance without using transformers. The core innovation is an exponential moving average-based seasonal-trend decomposition that separates input series into trend and seasonal components. These components are processed through specialized streams: an MLP-based linear stream for trend features and a CNN-based non-linear stream with patching and depthwise separable convolutions for seasonal patterns. The method employs a novel arctangent loss function and sigmoid learning rate adjustment scheme. Experiments on nine real-world datasets demonstrate superior performance compared to transformer-based approaches while maintaining computational efficiency.

## Method Summary
The xPatch architecture combines exponential moving average-based seasonal-trend decomposition with a dual-stream processing approach. The decomposition separates time series into trend and seasonal components using a weighted average that emphasizes recent observations. The trend component is processed through a linear stream using MLP blocks with GELU activation and layer normalization, while the seasonal component flows through a non-linear stream employing patching mechanisms and depthwise separable convolutions. A novel arctangent loss function addresses outlier sensitivity, and a sigmoid-based learning rate adjustment scheme improves training stability. The architecture processes both streams independently before combining their outputs for final forecasting.

## Key Results
- xPatch achieves 3-9% better MSE and MAE performance compared to transformer-based models CARD and PatchTST
- The model demonstrates superior performance on nine real-world univariate time series datasets
- Computational efficiency is maintained compared to transformer architectures while achieving better forecasting accuracy

## Why This Works (Mechanism)
xPatch succeeds by leveraging the inherent structure of time series data through targeted decomposition and specialized processing streams. The exponential moving average decomposition effectively separates temporal patterns that require different processing approaches - linear trends benefit from MLP-based processing while non-linear seasonal patterns are better captured by CNN architectures with patching. The dual-stream design allows each component to be processed optimally rather than forcing a single architecture to handle both patterns simultaneously. The arctangent loss function provides robustness to outliers, which are common in real-world time series, while the sigmoid learning rate adjustment enables smoother convergence during training.

## Foundational Learning
- **Seasonal-Trend Decomposition**: Separating time series into trend and seasonal components to process each pattern type optimally. Why needed: Different temporal patterns require different modeling approaches. Quick check: Verify decomposition quality by examining separated components visually.
- **Exponential Moving Average**: Weighted averaging technique that gives more importance to recent observations. Why needed: Provides adaptive smoothing for trend extraction. Quick check: Test sensitivity to EMA parameter values on sample data.
- **Patching Mechanism**: Dividing input sequences into patches for local feature extraction. Why needed: Enables efficient processing of long sequences by focusing on local patterns. Quick check: Compare performance with different patch sizes.
- **Depthwise Separable Convolutions**: Convolutional layers that separate spatial and channel-wise operations. Why needed: Reduces computational complexity while maintaining representational power. Quick check: Measure parameter count and FLOPs compared to standard convolutions.
- **Arctangent Loss Function**: Non-linear loss function based on arctangent transformation. Why needed: Provides robustness to outliers in time series data. Quick check: Test loss behavior on data with varying outlier magnitudes.
- **Sigmoid Learning Rate Adjustment**: Dynamic learning rate scheduling using sigmoid function. Why needed: Enables smooth convergence and training stability. Quick check: Compare training curves with and without sigmoid adjustment.

## Architecture Onboarding

**Component Map**: Time Series -> EMA Decomposition -> Trend Stream (MLP) + Seasonal Stream (CNN with Patching) -> Concatenation -> Forecasting Output

**Critical Path**: Input series → EMA decomposition → dual-stream processing → feature fusion → output layer

**Design Tradeoffs**: The dual-stream approach trades architectural complexity for specialized processing, avoiding the computational overhead of transformers while achieving superior performance through targeted decomposition and stream-specific architectures.

**Failure Signatures**: Poor decomposition quality when seasonal periods are misestimated, degradation in performance on non-seasonal time series, sensitivity to patching parameters for irregular seasonal patterns.

**First Experiments**:
1. Test decomposition quality on synthetic series with known seasonal periods
2. Compare dual-stream performance against single-stream baseline on simple periodic data
3. Evaluate sensitivity to patching parameters (patch size, overlap) on controlled datasets

## Open Questions the Paper Calls Out
None

## Limitations
- Fixed seasonal periods derived from periodograms may not adapt well to non-stationary time series
- Limited ablation studies make it difficult to isolate contributions of individual components
- Performance on short time series and multivariate forecasting remains unexplored
- Patching mechanism performance across different time series granularities is not explicitly evaluated

## Confidence
- **High Confidence**: Superior performance compared to transformer-based models on tested univariate datasets
- **Medium Confidence**: Computational efficiency claims relative to transformers
- **Medium Confidence**: Arctangent loss function's contribution to training stability
- **Low Confidence**: Generalizability to multivariate time series and irregular patterns

## Next Checks
1. Conduct systematic ablation studies removing arctangent loss and sigmoid learning rate adjustment
2. Evaluate xPatch's performance on multivariate time series datasets
3. Test model robustness on time series with non-stationary seasonality and varying seasonal periods