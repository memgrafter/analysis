---
ver: rpa2
title: Minority-Focused Text-to-Image Generation via Prompt Optimization
arxiv_id: '2410.07838'
source_url: https://arxiv.org/abs/2410.07838
tags:
- arxiv
- prompt
- diffusion
- generation
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the problem of generating minority samples\
  \ in text-to-image generation\u2014instances that are rare or live in low-density\
  \ regions of the learned conditional data distribution. Existing diffusion-based\
  \ T2I models are inherently biased toward high-density regions due to guidance techniques,\
  \ making minority generation difficult."
---

# Minority-Focused Text-to-Image Generation via Prompt Optimization

## Quick Facts
- arXiv ID: 2410.07838
- Source URL: https://arxiv.org/abs/2410.07838
- Authors: Soobin Um; Jong Chul Ye
- Reference count: 40
- Primary result: Introduces MinorityPrompt, a prompt optimization framework that significantly improves minority sample generation in text-to-image diffusion models while maintaining text-image alignment

## Executive Summary
This paper addresses the challenge of generating minority samples in text-to-image generation, where instances are rare or reside in low-density regions of the learned conditional data distribution. Existing diffusion-based T2I models are inherently biased toward high-density regions due to guidance techniques, making minority generation difficult. The authors propose MinorityPrompt, an inference-time prompt optimization framework that iteratively refines learnable token embeddings while preserving the original prompt's semantics. The approach is theoretically connected to conditional log-likelihood and demonstrates significant improvements across multiple Stable Diffusion variants.

## Method Summary
The method introduces an online prompt optimization framework that selectively updates learnable token embeddings during inference. The framework augments the original prompt with a placeholder string marking the position for a learnable token, which is then optimized using a carefully designed objective function. This objective encourages low-likelihood features and is theoretically connected to the conditional log-likelihood through the negative ELBO. The optimization is performed iteratively during sampling timesteps using standard ODE/SDE solvers, allowing the framework to generate minority samples while maintaining semantic alignment with the original prompt.

## Key Results
- Outperforms existing samplers (DDIM, Null-prompted DDIM, CADS, SGMS) in generating high-quality minority samples
- Maintains strong text-image alignment across multiple Stable Diffusion versions (v1.5, v2.0, SDXL-Lightning)
- Compatible with distilled variants and adaptable to diversity enhancement tasks
- Shows significant improvements in CLIPScore, PickScore, and ImageReward metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Updating only learnable token embeddings preserves prompt semantics better than full-text embedding updates
- Mechanism: By attaching a dedicated placeholder token and optimizing its embedding during inference, the framework avoids altering the original prompt's word embeddings, thereby maintaining semantic integrity
- Core assumption: Semantic content is encoded primarily in the original prompt tokens, and modifying only the learnable token does not significantly distort this content
- Evidence anchors: [abstract] states the approach "updates the prompts in a selective fashion to preserve the intended semantics while encouraging generations of unique low-density features." [section 3.2] explains that "our optimization does not affect the embeddings of the tokens w.r.t. the original prompt" and is "inherently more advantageous for preserving semantics compared to existing methods."
- Break condition: If the original prompt embeddings are interdependent such that modifying one token (even a learnable one) indirectly alters the semantic representation of the entire prompt

### Mechanism 2
- Claim: The proposed objective function approximates the conditional log-likelihood, encouraging generation of minority features
- Mechanism: The objective function is designed to minimize the reconstruction loss between a clean estimate of the noisy latent and a noised version conditioned on the original prompt, theoretically aligning with the negative ELBO of the conditional log-likelihood
- Core assumption: Minimizing reconstruction error under the proposed objective correlates with maximizing the likelihood of minority samples
- Evidence anchors: [section 3.3] provides Proposition 1, showing the objective is equivalent (up to a constant) to the negative ELBO with respect to the target log-likelihood. [abstract] mentions the objective is "carefully designed to encourage low-likelihood (i.e., minority) features and is theoretically connected to the conditional log-likelihood."
- Break condition: If the reconstruction loss does not accurately reflect the likelihood in the latent space, or if the noise schedule or other sampling parameters disrupt the theoretical connection

### Mechanism 3
- Claim: The framework is versatile and can be adapted to other tasks beyond minority generation by changing the optimization objective
- Mechanism: The generic prompt optimization framework accepts any arbitrary objective function, allowing it to be tailored for different goals such as diversity enhancement by incorporating a repulsion-based loss
- Core assumption: The prompt optimization framework is modular and the objective function can be swapped without affecting the core mechanism of learnable token updates
- Evidence anchors: [section 3.2] states the framework "is versatile, i.e., it can be applied to various tasks with distinct optimization objectives beyond minority generation." [section 4.2] explores an application to diversity enhancement, demonstrating the framework's adaptability
- Break condition: If the framework's architecture is too tightly coupled to the minority generation objective, making it difficult to adapt to other tasks without significant redesign

## Foundational Learning

- Concept: Text-to-Image (T2I) Diffusion Models
  - Why needed here: Understanding how T2I models generate images from text prompts is fundamental to grasping the problem of minority sample generation and the proposed solution
  - Quick check question: How does the classifier-free guidance (CFG) technique in T2I models influence the generation of high-density versus low-density regions of the data distribution?

- Concept: Prompt Optimization
  - Why needed here: The core of the proposed method involves optimizing prompt embeddings during inference, so understanding prompt optimization techniques is crucial
  - Quick check question: What is the difference between online prompt optimization (updating embeddings during inference) and offline prompt tuning (updating embeddings during training)?

- Concept: Log-Likelihood and ELBO in Diffusion Models
  - Why needed here: The theoretical justification for the proposed objective function relies on its connection to the conditional log-likelihood and the Evidence Lower Bound (ELBO)
  - Quick check question: How does the ELBO relate to the log-likelihood in the context of variational inference and diffusion models?

## Architecture Onboarding

- Component map: Text Encoder (T) -> Learnable Token Embedding (v) -> Diffusion Model (ϵθ) -> Optimization Objective (JC) -> ODE/SDE Solver

- Critical path:
  1. Augment the user prompt with a placeholder string
  2. Initialize the learnable token embedding
  3. For each sampling timestep:
     a. If it's an optimization step, update the learnable token embedding using the objective function
     b. Compute the text embedding using the updated token
     c. Use the text embedding to guide the denoising process
  4. Decode the final latent representation into an image

- Design tradeoffs:
  - Computational cost vs. semantic preservation: Optimizing only a learnable token reduces computational cost compared to full-text optimization but may limit the extent of control over the generation process
  - Theoretical connection vs. empirical performance: The proposed objective function has a strong theoretical justification but may require careful tuning of hyperparameters for optimal performance

- Failure signatures:
  - Loss of semantic alignment: If the optimized token embedding significantly alters the meaning of the original prompt
  - Degradation in sample quality: If the objective function encourages generation of unrealistic or low-quality images
  - Computational inefficiency: If the optimization process is too slow or resource-intensive for practical use

- First 3 experiments:
  1. Implement the basic framework with a simple objective function (e.g., reconstruction loss) and test it on a small dataset to verify that it can generate images and that the learnable token embedding is being updated
  2. Compare the performance of the framework with different optimization objectives (e.g., the proposed JC vs. a naive extension) to validate the theoretical justification
  3. Test the framework's compatibility with different ODE/SDE solvers and T2I model architectures to ensure its robustness and adaptability

## Open Questions the Paper Calls Out

### Open Question 1  
- Question: How does the performance of MinorityPrompt change when using different initial word embeddings for the learnable token? 
- Basis in paper: [explicit] The paper explores the impact of different initial words on performance in Tab. 4c and Tab. 6a.  
- Why unresolved: While the paper shows that using a specific word like "cool" works well, it doesn't systematically compare a wide range of initial words or determine optimal strategies for selecting them.  
- What evidence would resolve it: A comprehensive study comparing MinorityPrompt performance across a diverse set of initial word embeddings, identifying which types of words yield the best minority generation results.

### Open Question 2  
- Question: Can the prompt optimization framework be extended to other generative models beyond text-to-image diffusion models?  
- Basis in paper: [inferred] The paper mentions that the framework is versatile and can be applied to various tasks with distinct optimization objectives (Sec. 3.2), but only demonstrates it for T2I generation and diversity enhancement.  
- Why unresolved: The paper focuses exclusively on T2I models and doesn't explore whether the approach generalizes to other domains like text generation, audio synthesis, or 3D generation.  
- What evidence would resolve it: Empirical validation of the prompt optimization framework applied to other generative model architectures and tasks, demonstrating improved minority generation or other targeted objectives.

### Open Question 3  
- Question: What is the theoretical relationship between the likelihood objective and actual minority sample quality?  
- Basis in paper: [explicit] The paper theoretically connects the objective to conditional log-likelihood (Proposition 1) but acknowledges that this is an approximation.  
- Why unresolved: While the framework is designed to maximize likelihood, there's no rigorous proof that higher likelihood under this objective directly translates to better minority samples in terms of human perception or downstream task performance.  
- What evidence would resolve it: A formal analysis establishing the correlation (or lack thereof) between the objective's likelihood maximization and actual minority sample quality metrics, potentially identifying scenarios where the approximation breaks down.

## Limitations

- The framework's ability to discover truly novel minority samples beyond the training distribution is speculative and not rigorously validated
- Performance depends heavily on hyperparameter tuning, particularly the learning rate and optimization frequency
- The theoretical connection between the objective function and conditional log-likelihood may not hold in practice for all noise schedules and sampling parameters

## Confidence

- High Confidence: The framework's basic architecture and compatibility with existing ODE/SDE solvers is well-established
- Medium Confidence: The claim that the objective function approximates conditional log-likelihood is theoretically sound but practically dependent on implementation details and hyperparameters
- Low Confidence: The assertion that the framework can discover truly novel minority samples beyond the training distribution is the most speculative claim

## Next Checks

**Check 1: Semantic Drift Quantification**
Implement a systematic evaluation measuring semantic drift by computing embedding distances between original and optimized prompts using multiple text encoders (CLIP, T5, BERT). Track how semantic alignment metrics (CLIPScore, text-image similarity) change across optimization iterations to establish quantitative bounds on semantic preservation.

**Check 2: Cross-Distribution Generalization**
Test the framework on minority types from completely different domains than the training data (e.g., generating rare medical conditions from a general-purpose T2I model trained on LAION). Measure whether the framework can discover novel minority instances or merely remixes known training examples.

**Check 3: Objective Function Ablation**
Compare the proposed objective JC against simpler alternatives (reconstruction loss only, likelihood maximization) while controlling for optimization frequency and learning rate. Use likelihood estimation (bits-per-dimension) to verify whether the theoretical connection to conditional log-likelihood translates to actual likelihood reduction in practice.