---
ver: rpa2
title: 'Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges'
arxiv_id: '2410.03458'
source_url: https://arxiv.org/abs/2410.03458
tags:
- speech
- dataset
- dialect
- dialects
- central
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ViMD, the first Vietnamese speech dataset
  containing 102.56 hours of audio across 63 provincial dialects. Each dialect corresponds
  to a specific Vietnamese province, providing fine-grained dialect classification.
---

# Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges

## Quick Facts
- arXiv ID: 2410.03458
- Source URL: https://arxiv.org/abs/2410.03458
- Reference count: 40
- Primary result: ViMD dataset introduced with 102.56 hours of audio across 63 Vietnamese provincial dialects

## Executive Summary
This paper introduces ViMD, the first Vietnamese speech dataset containing 102.56 hours of audio across 63 provincial dialects. Each dialect corresponds to a specific Vietnamese province, providing fine-grained dialect classification. The dataset includes 18,949 utterances and over 1.2 million words, with additional speaker attributes like gender and identification codes. To benchmark the dataset, the authors fine-tune state-of-the-art models on two tasks: dialect identification and speech recognition. Results show high accuracy in broad dialect classification (91.47% F1-macro for 3-region classification) but significant challenges in fine-grained provincial classification (35.22% F1-macro for 63 dialects).

## Method Summary
The study involves collecting and preprocessing a multi-dialect Vietnamese speech dataset (ViMD), then fine-tuning pre-trained models for dialect identification and speech recognition tasks. For dialect identification, models are trained to classify audio into 3 regional dialects or 63 provincial dialects using F1-macro as the evaluation metric. For speech recognition, models transcribe audio to text across dialect regions, evaluated using Word Error Rate (WER). The dataset contains 102.56 hours of audio from 63 Vietnamese provinces, with 18,949 utterances and over 1.2 million words. Models are fine-tuned using standard procedures with AdamW optimizer, learning rate of 1e-4, and specific batch sizes for each task.

## Key Results
- Regional dialect classification achieves 91.47% F1-macro accuracy while provincial classification drops to 35.22% F1-macro
- Central region shows highest dialect identification accuracy (62.31% F1-macro) but worst speech recognition performance (17.15% WER)
- Coastal provinces demonstrate better classification performance than inland provinces
- Combined training provides only marginal improvement (1.86-3.07% WER reduction) over regional fine-tuning despite 2-3x more data

## Why This Works (Mechanism)

### Mechanism 1
Fine-grained provincial dialect classification is more difficult than broad regional classification because provincial dialects exhibit smaller, more subtle pronunciation differences. When dialects are grouped into broader regions, the model can leverage larger, more distinct pronunciation patterns to classify speech. At the provincial level, the pronunciation differences between neighboring provinces are minimal, requiring finer distinctions.

### Mechanism 2
Coastal provinces show more distinct dialect features than inland provinces, potentially due to historical maritime trade and cultural exchange. Geographic isolation and historical factors create unique pronunciation patterns in coastal areas that differ more from neighboring provinces than inland provinces differ from each other.

### Mechanism 3
Training on combined dialect data doesn't necessarily improve performance because the model struggles to learn cross-dialect mappings effectively. When trained on a mixture of dialects, the model may not develop the ability to generalize pronunciation variations across dialects, instead treating each dialect as a separate category to be learned independently.

## Foundational Learning

- Concept: Tonal languages and pitch contours
  - Why needed here: Vietnamese is a tonal language with six distinct tones, and understanding how tones vary across dialects is crucial for speech recognition.
  - Quick check question: How many tones does Vietnamese have, and how do they affect word meaning?

- Concept: Dialect vs. accent
  - Why needed here: The paper uses "dialect" to refer to both regional and provincial variations, which can be confusing since in other contexts these might be distinguished.
  - Quick check question: What's the difference between a regional dialect and a provincial dialect in the context of Vietnamese?

- Concept: Speech recognition evaluation metrics (WER, F1-macro)
  - Why needed here: Understanding how to evaluate speech recognition and dialect identification models is crucial for interpreting the results.
  - Quick check question: What's the difference between WER and F1-macro, and when would you use each?

## Architecture Onboarding

- Component map: Data collection pipeline (video extraction → audio segmentation → transcription → quality control) → Pre-trained models (wav2vec2.0, XLSR, Whisper variants) → Fine-tuning process for both DI and SR tasks → Evaluation metrics (F1-macro for DI, WER for SR)

- Critical path: 1. Data collection and preprocessing 2. Model selection and loading 3. Fine-tuning for specific task (DI or SR) 4. Evaluation and analysis

- Design tradeoffs: Base vs. large model versions (Base models are faster to train but may have lower performance); Fine-tuning vs. direct inference (Fine-tuning improves performance but requires additional training time); Regional vs. provincial classification (Regional is easier but less granular)

- Failure signatures: High WER in specific regions (e.g., Central region in SR task) indicates dialect-specific challenges; Confusion between neighboring provinces in DI task suggests need for more granular features; Poor performance on combined dataset vs. separate datasets suggests issues with cross-dialect generalization

- First 3 experiments: 1. Fine-tune wav2vec2-base-vietnamese on [SR_North] and evaluate WER 2. Fine-tune PhoWhisperbase on [DI_VN_63] and evaluate F1-macro 3. Compare performance of XLSR vs. wav2vec2.0 on [DI_Central]

## Open Questions the Paper Calls Out

### Open Question 1
What specific geographical factors (e.g., proximity to coast, latitude, topography) most strongly influence the distinctiveness of provincial dialects in Vietnam? The paper notes that 10 out of 12 most distinctive provinces in the [DI_VN_63] experiment are coastal regions, and discusses how Central Vietnam's narrow, elongated shape may affect dialectal variation. This remains unresolved due to lack of rigorous statistical analysis isolating specific geographical variables.

### Open Question 2
Why does the Central region show the highest dialect identification accuracy ([DI_Central] at 62.31% F1-macro) but the worst speech recognition performance ([SR_Central] at 17.15% WER)? This counterintuitive pattern where Central provinces are most distinctive for dialect ID but worst for speech recognition lacks a mechanistic explanation in the paper.

### Open Question 3
Why does training on the entire ViMD dataset provide only marginal improvement (1.86-3.07% WER reduction) over training on regional subsets, despite having 2-3 times more data? The paper doesn't investigate whether this limited improvement is due to data quality issues, model architecture limitations, or fundamental challenges in transferring knowledge across dialects.

## Limitations
- Dataset construction relies on administrative provincial divisions rather than verified linguistic boundaries
- Significant performance gap between regional and provincial classification suggests data imbalance issues
- Analysis focuses primarily on pronunciation-based classification without examining vocabulary or grammar differences

## Confidence
- High Confidence: Regional dialect classification is significantly easier than provincial classification (91.47% vs 35.22% F1-macro)
- Medium Confidence: Coastal provinces show better classification performance, but requires validation of causal factors
- Low Confidence: Combined training doesn't substantially improve performance across dialects based on limited metrics

## Next Checks
1. Conduct detailed analysis of speaker and sample distribution across provinces to verify data imbalance claims
2. Design experiment testing cross-dialect generalization by evaluating models trained on individual dialects on unseen dialects
3. Supplement pronunciation-based analysis with linguistic expert validation of actual dialect boundaries and feature differences