---
ver: rpa2
title: Nearest Neighbor Normalization Improves Multimodal Retrieval
arxiv_id: '2410.24114'
source_url: https://arxiv.org/abs/2410.24114
tags:
- retrieval
- coco
- beit-3
- flickr
- clip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NNN improves cross-modal retrieval accuracy across multiple models
  (CLIP, BLIP, ALBEF, SigLIP, BEiT) and datasets (Flickr30k, COCO) by 1.2-7.4% R@1
  using a training-free, sublinear-time bias correction approach that addresses the
  hubness problem in contrastive embeddings.
---

# Nearest Neighbor Normalization Improves Multimodal Retrieval

## Quick Facts
- arXiv ID: 2410.24114
- Source URL: https://arxiv.org/abs/2410.24114
- Authors: Neil Chowdhury; Franklin Wang; Sumedh Shenoy; Douwe Kiela; Sarah Schwettmann; Tristan Thrush
- Reference count: 2
- Key outcome: NNN improves cross-modal retrieval accuracy across multiple models (CLIP, BLIP, ALBEF, SigLIP, BEiT) and datasets (Flickr30k, COCO) by 1.2-7.4% R@1 using a training-free, sublinear-time bias correction approach that addresses the hubness problem in contrastive embeddings.

## Executive Summary
Nearest Neighbor Normalization (NNN) is a training-free method that improves cross-modal retrieval accuracy by correcting for hubness in contrastive embeddings. The approach normalizes retrieval scores using only the k-nearest query embeddings, preventing high-similarity outliers from dominating the retrieval space. NNN achieves sublinear runtime complexity through efficient vector retrieval indices and can reduce gender bias in image retrieval without requiring task-specific training data.

## Method Summary
NNN applies an additive correction to match scores using bias scores estimated from the k closest query embeddings from a reference dataset. The method computes a bias score for each retrieval candidate as a constant multiple of the mean similarity with its k-nearest queries, then subtracts this bias from the original similarity score. This can be efficiently implemented by precomputing bias scores using vector retrieval indices like FAISS, storing them, and applying them during retrieval by modifying query and retrieval embeddings.

## Key Results
- NNN improves cross-modal retrieval accuracy by 1.2-7.4% R@1 across multiple models and datasets
- The method achieves sublinear runtime complexity through efficient vector retrieval indices
- NNN can reduce gender bias in image retrieval while improving retrieval accuracy

## Why This Works (Mechanism)

### Mechanism 1
NNN corrects hubness by normalizing retrieval scores using only the k-nearest query embeddings, preventing high-similarity outliers from dominating the retrieval space. The method computes a bias score for each retrieval candidate as a constant multiple of the mean similarity with its k-nearest queries, then subtracts this bias from the original similarity score, effectively reducing the influence of "hubs" that would otherwise be retrieved too frequently.

### Mechanism 2
NNN achieves sublinear runtime complexity by leveraging vector retrieval indices to compute bias scores efficiently, avoiding the need to calculate similarities with all reference queries. The method uses an inverted file index (like Faiss) to efficiently find the k-nearest query embeddings for each retrieval candidate, with these precomputed bias scores cached and applied during retrieval by modifying the query and retrieval embeddings.

### Mechanism 3
NNN can reduce gender bias in image retrieval by adjusting similarity scores based on the reference query distribution, without requiring task-specific training data. The method applies the same bias correction to all retrieval candidates, but because the reference query distribution may contain fewer gender-biased queries for certain candidates, the adjusted scores can reduce unwanted correlations between gender attributes and retrieval outcomes.

## Foundational Learning

- Concept: Cosine similarity and its role in contrastive learning
  - Why needed here: NNN operates on the cosine similarity scores between embeddings, so understanding how these scores are computed and what they represent is crucial for implementing and debugging the method.
  - Quick check question: If two embeddings have a cosine similarity of 1.0, what does this tell you about their relationship in the embedding space?

- Concept: Hubness in high-dimensional spaces
  - Why needed here: NNN specifically addresses the hubness problem where certain points (hubs) appear as nearest neighbors for many other points, leading to retrieval errors. Understanding this phenomenon is key to grasping why NNN is necessary.
  - Quick check question: Why does hubness become more problematic as the dimensionality of the embedding space increases?

- Concept: Vector retrieval indices (e.g., FAISS)
  - Why needed here: NNN relies on efficient vector retrieval to find the k-nearest queries for bias computation. Understanding how these indices work is essential for implementing the method efficiently.
  - Quick check question: What is the primary advantage of using an inverted file index like FAISS over exhaustive search for finding nearest neighbors in high-dimensional spaces?

## Architecture Onboarding

- Component map: Embedding model (CLIP, BLIP, etc.) -> Reference query database -> FAISS index for k-nearest neighbor search -> Bias computation module -> Modified retrieval pipeline with bias adjustment

- Critical path:
  1. Load and index reference queries in FAISS
  2. For each retrieval candidate, find k-nearest queries using FAISS
  3. Compute bias score as mean similarity with k-nearest queries
  4. Cache bias scores for all candidates
  5. During retrieval, adjust similarity scores by subtracting bias

- Design tradeoffs:
  - Choice of k: Larger k provides more robust bias estimates but increases computation time
  - Choice of α: Controls the strength of bias correction; too high can over-correct and hurt accuracy
  - Reference database size: Larger databases provide better bias estimates but increase memory usage

- Failure signatures:
  - Accuracy degradation when k is too small (bias estimates become noisy)
  - No improvement or accuracy loss when α is too large (over-correction)
  - Slow inference when FAISS index is not properly optimized

- First 3 experiments:
  1. Verify k-nearest neighbor search with FAISS on a small dataset and visualize the neighbors
  2. Implement bias computation for a single retrieval candidate and validate against manual calculation
  3. Apply NNN to a small retrieval task and compare results with and without bias correction

## Open Questions the Paper Calls Out

### Open Question 1
How does NNN's performance vary with the choice of k and α parameters across different retrieval tasks and model architectures? The paper mentions hyperparameter sweeps but only reports optimal values without analyzing trends or sensitivity.

### Open Question 2
Can NNN be effectively extended to models with cross-attention mechanisms beyond contrastive embeddings? The paper mentions that NNN does not significantly improve cross-attention models like BLIP's image-text matching, suggesting potential limitations.

### Open Question 3
How does the size of the reference database affect NNN's performance and efficiency trade-offs? The paper mentions ablation studies on reference database size but doesn't provide detailed analysis of the relationship between database size and performance.

## Limitations
- NNN's performance relies heavily on the quality and size of the reference query database, which is not extensively explored
- The choice of hyperparameters (α and k) significantly impacts results, but the paper does not provide systematic guidance for optimal selection across different domains
- Gender bias reduction experiments are promising but limited to a single dataset and specific bias metric

## Confidence

- High Confidence: The core claim that NNN improves cross-modal retrieval accuracy by 1.2-7.4% R@1 is well-supported by extensive experiments across multiple models and datasets
- Medium Confidence: The claim that NNN addresses the hubness problem is theoretically sound but relies on empirical validation that could benefit from more detailed analysis
- Low Confidence: The claim about NNN's effectiveness in reducing gender bias is based on limited experiments and requires further validation across diverse datasets and bias metrics

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically evaluate how different values of α and k affect retrieval accuracy across diverse datasets to identify optimal settings and understand the trade-offs between bias correction strength and performance

2. **Reference Database Quality Study**: Investigate how the size, diversity, and quality of the reference query database impact NNN's effectiveness, including experiments with varying database sizes and compositions

3. **Generalization to Other Bias Types**: Extend the gender bias experiments to test NNN's effectiveness in reducing other types of biases (e.g., racial, age-related) across multiple datasets and bias metrics