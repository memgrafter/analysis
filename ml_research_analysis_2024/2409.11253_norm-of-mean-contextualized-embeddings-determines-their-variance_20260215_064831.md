---
ver: rpa2
title: Norm of Mean Contextualized Embeddings Determines their Variance
arxiv_id: '2409.11253'
source_url: https://arxiv.org/abs/2409.11253
tags:
- embeddings
- layer
- layers
- embedding
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study analyzes the distribution of contextualized embeddings
  using statistical measures. The researchers focus on three values for each token''s
  embedding set: the mean squared norm Q(Xt), the squared norm of the mean embedding
  M(Xt), and the sum of variances V(Xt).'
---

# Norm of Mean Contextualized Embeddings Determines their Variance

## Quick Facts
- arXiv ID: 2409.11253
- Source URL: https://arxiv.org/abs/2409.11253
- Reference count: 40
- Primary result: Norm of mean contextualized embeddings determines their variance, with a strong inverse trade-off between mean norm and variance in intermediate layers due to layer normalization

## Executive Summary
This study analyzes the distribution of contextualized embeddings using statistical measures Q(Xt), M(Xt), and V(Xt) for token-wise embedding sets. The researchers prove that these values satisfy the identity Q(Xt) = M(Xt) + V(Xt) and provide an efficient sequential computation method. Experiments with BERT, RoBERTa, and GPT-2 models show that Q(Xt) has small variation in intermediate layers, creating a strong trade-off between M(Xt) and V(Xt): when a token's meaning is weaker (smaller M(Xt)), its embedding variance is larger, and vice versa. For the entire embedding set X, the study shows that total variance can be decomposed into within-cluster variance (VW(X)) and between-cluster variance (VB(X)), with anisotropy increasing as layers deepen.

## Method Summary
The researchers compute token embeddings from BERT, RoBERTa, and GPT-2 models using the BookCorpus dataset. They calculate statistical measures Q(Xt), M(Xt), and V(Xt) using an efficient sequential algorithm that updates running statistics as embeddings are processed. The analysis examines layer-wise variations and trade-offs between mean norm and variance, then extends to corpus-level variance decomposition into within-cluster and between-cluster components. The study validates the Q = M + V identity, demonstrates the trade-off relationship, and analyzes anisotropy trends across layers.

## Key Results
- Q(Xt) = M(Xt) + V(Xt) identity holds for token embedding sets
- Q(Xt) exhibits small variation in intermediate layers for BERT/RoBERTa
- Strong inverse trade-off between M(Xt) and V(Xt) due to layer normalization
- As layers deepen, embeddings move farther from origin with increasing M(X) and decreasing VB(X)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layer normalization constrains squared norm variation across tokens
- Mechanism: LN normalizes embeddings so squared norms cluster tightly around constant value, forcing M(Xt) and V(Xt) to trade off inversely
- Core assumption: LN parameters γ and β are fixed and don't vary significantly
- Evidence anchors: Layer normalization controls squared norm with small variation; trade-off likely influenced by LN

### Mechanism 2
- Claim: Q(Xt) = M(Xt) + V(Xt) enforces trade-off mathematically
- Mechanism: Q(Xt) near-constancy due to LN means any M(Xt) increase must be compensated by V(Xt) decrease
- Core assumption: Q(Xt) near-constancy holds across intermediate layers
- Evidence anchors: Sum of M(Xt) and V(Xt) exhibits small variation; coefficient of variation reaches minimum in intermediate layers

### Mechanism 3
- Claim: Deepening layers increase anisotropy through embedding drift
- Mechanism: As layers deepen, mean embedding μ(X) drifts from origin, VW(X) increases, VB(X) decreases
- Core assumption: Layer-wise transformation consistently shifts embeddings outward
- Evidence anchors: Embeddings move farther from origin as layers deepen; ratios of M(X), VW(X), VB(X) show anisotropy increase

## Foundational Learning

- Concept: Variance decomposition V(X) = VW(X) + VB(X)
  - Why needed here: Explains how total variance splits into within- and between-cluster parts for anisotropy analysis
  - Quick check question: If all embeddings cluster tightly around their own μ(Xt) but μ(Xt) are far apart, which variance component dominates?

- Concept: Sequential computation of statistics
  - Why needed here: Enables efficient online update of Q(Xt), M(Xt), V(Xt) without storing all embeddings
  - Quick check question: What update formula is used for running mean when new embedding arrives?

- Concept: Layer normalization effect on embedding norms
  - Why needed here: LN's role in constraining Q(Xt) variation is central to observed trade-off mechanism
  - Quick check question: How does LN transform an embedding before output?

## Architecture Onboarding

- Component map: Token embedding sets Xt → mean μ(Xt), squared norm Q(Xt), variance V(Xt); Entire set X → global μ(X), Q(X), V(X), VW(X), VB(X); LN → norm constraint
- Critical path: Compute Xt statistics → observe Q constancy → deduce M-V trade-off → extend to X decomposition → analyze layer-wise anisotropy
- Design tradeoffs: Token embeddings avoid subword averaging artifacts; norm focus simplifies analysis but may miss directional structure
- Failure signatures: Large Q(Xt) variation → weak M-V trade-off; increasing VB(X) with depth → anisotropy not increasing; GPT-2 vs BERT/RoBERTa differences → LN placement matters
- First 3 experiments:
  1. Compute Q(Xt), M(Xt), V(Xt) for sample tokens across layers and verify Q constancy in BERT/RoBERTa vs GPT-2
  2. Plot M(X) and V(X)/Q(X) across layers to confirm anisotropy trend
  3. Vary LN parameters in toy model to observe effects on Q(Xt) variation and M-V trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed trade-off between mean norm (M(Xt)) and variance (V(Xt)) hold consistently across different languages and multilingual models?
- Basis in paper: [inferred] Paper only analyzed English models and acknowledged this limitation
- Why unresolved: Experiments conducted exclusively on English models using BookCorpus dataset
- What evidence would resolve it: Running same analysis on multilingual models (mBERT, XLM-R) with multilingual datasets

### Open Question 2
- Question: How does relationship between token frequency and statistical measures change with different tokenization strategies?
- Basis in paper: [inferred] Paper notes artifacts from word embeddings represented by mean of token embeddings
- Why unresolved: Paper switched to token embeddings to avoid artifacts but didn't systematically explore tokenization effects
- What evidence would resolve it: Experiments with different tokenization approaches (character-level, subword-level, word-level)

### Open Question 3
- Question: What is precise mechanism by which layer normalization causes small Q(Xt) variation?
- Basis in paper: [explicit] Paper discusses LN's role and provides theoretical conditions
- Why unresolved: Theoretical framework provided but probability distribution settings don't reflect reality
- What evidence would resolve it: Detailed analysis of LN parameters across models and layers combined with empirical Q(Xt) measurements

### Open Question 4
- Question: How do layer-wise anisotropy metric changes compare when using different anisotropy measures like cosine similarity?
- Basis in paper: [explicit] Paper acknowledges previous studies used cosine similarity for anisotropy
- Why unresolved: Paper uses norm-based metrics but doesn't directly compare with cosine similarity-based measures
- What evidence would resolve it: Computing both norm-based and cosine similarity-based metrics across same models and layers

## Limitations
- Analysis depends critically on layer normalization producing tightly clustered squared norm distribution
- Study focuses on BERT and RoBERTa, may not represent full diversity of modern transformer architectures
- Corpus-level variance decomposition assumes meaningful cluster assignments not validated for semantic coherence

## Confidence

**High Confidence**: Mathematical identity Q(Xt) = M(Xt) + V(Xt) and sequential computation method are theoretically sound and correctly implemented. Empirical observation of Q(Xt) small variation in intermediate layers for BERT/RoBERTa is well-supported.

**Medium Confidence**: Mechanism by which layer normalization constrains Q(Xt) variation and forces M-V trade-off is plausible but not rigorously proven. Corpus-level variance decomposition and anisotropy trends are supported but not explored across different datasets or clustering methods.

## Next Checks

1. **Layer Normalization Ablation**: Modify BERT model to remove or alter layer normalization, then recompute Q(Xt), M(Xt), and V(Xt) across layers to directly test whether LN is necessary for observed Q constancy and M-V trade-off.

2. **Cross-Architecture Generalization**: Apply same analysis to models with different normalization schemes (Pre-LN, RMSNorm, no normalization) and datasets with different characteristics (formal vs informal text, multiple languages) to test universality of Q constancy and M-V trade-off mechanisms.

3. **Cluster Validation and Alternative Clustering**: Validate whether clusters used for variance decomposition correspond to semantically meaningful groups using intrinsic metrics or downstream tasks. Test whether anisotropy trends persist with different clustering algorithms or cluster numbers.