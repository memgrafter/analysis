---
ver: rpa2
title: Enabling Time-series Foundation Model for Building Energy Forecasting via Contrastive
  Curriculum Learning
arxiv_id: '2412.17285'
source_url: https://arxiv.org/abs/2412.17285
tags:
- tsfm
- energy
- data
- forecasting
- building
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of adapting existing time-series
  foundation models (TSFMs) to building energy forecasting (BEF) tasks, where direct
  fine-tuning shows limited improvement. The authors propose a contrastive curriculum
  learning (CCL) method that organizes training data by difficulty using a contrastive
  representation-based measurer, enabling better adaptation of TSFMs to building energy
  data.
---

# Enabling Time-series Foundation Model for Building Energy Forecasting via Contrastive Curriculum Learning

## Quick Facts
- **arXiv ID**: 2412.17285
- **Source URL**: https://arxiv.org/abs/2412.17285
- **Reference count**: 17
- **Key outcome**: Contrastive curriculum learning improves TSFM adaptation to building energy forecasting by 9.9-18.3% (zero-shot) and 11.9-14.9% (few-shot) in CV-RMSE

## Executive Summary
This paper addresses the challenge of adapting existing time-series foundation models (TSFMs) to building energy forecasting (BEF) tasks, where direct fine-tuning shows limited improvement. The authors propose a contrastive curriculum learning (CCL) method that organizes training data by difficulty using a contrastive representation-based measurer, enabling better adaptation of TSFMs to building energy data. Experiments on three public datasets with two product-level TSFMs (IBM TTM-5M and Amazon Chronos-710M) demonstrate significant improvements over direct fine-tuning and state-of-the-art forecasting models.

## Method Summary
The method combines curriculum learning with contrastive representation learning to adapt TSFMs to building energy forecasting. It first measures difficulty using TSFM forecasting errors on real data, then uses contrastive learning to transfer this difficulty measurement to simulated data by finding the most similar real sample representation. Training samples are then presented in increasing order of difficulty using a linear continuous scheduler. The approach leverages both real and simulated data, with simulated data providing diversity while contrastive learning transfers the difficulty ranking from real data.

## Key Results
- Zero-shot performance improves by 9.9-18.3% in CV-RMSE compared to direct fine-tuning
- Few-shot performance improves by 11.9-14.9% in CV-RMSE compared to direct fine-tuning
- CCL outperforms three state-of-the-art forecasting models (LSTM, Autoformer, TFT) in most cases
- The method effectively harnesses generalized knowledge from pre-trained models for specific domain applications

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Curriculum learning based on contrastive representation effectively orders training data by difficulty for TSFM adaptation
- **Mechanism**: The method first measures difficulty using TSFM forecasting errors on real data, then uses contrastive learning to transfer this difficulty measurement to simulated data by finding the most similar real sample representation. Training samples are then presented in increasing order of difficulty
- **Core assumption**: TSFM comprehension (ability to forecast accurately) can serve as a reliable proxy for sample difficulty, and contrastive representation similarity can effectively transfer difficulty measurement from real to simulated data
- **Evidence anchors**: [abstract] "Experiments show that our method can improve the zero/few-shot performance by 14.6% compared to the existing FMs" [section] "We leverage contrastive learning to predict the TSFM comprehension on the representation of ùë¢‚Ä≤ and hence to determine the difficulty"
- **Break condition**: If the TSFM cannot provide meaningful difficulty scores for real data samples, or if contrastive representations fail to capture similarity in difficulty between real and simulated samples

### Mechanism 2
- **Claim**: Using simulated data alongside real data improves TSFM adaptation through curriculum learning
- **Mechanism**: Simulated data provides a larger and more diverse training set, but cannot be directly ranked by difficulty. The contrastive difficulty measurer transfers difficulty ranking from real data to simulated data, allowing curriculum learning to effectively utilize both data sources
- **Core assumption**: Simulated building energy data captures sufficient variability to be useful for training, and the difficulty patterns transfer between real and simulated domains
- **Evidence anchors**: [section] "considering that the curriculum is for adapting an existing TSFM M, which has been pre-trained with various knowledge and patterns, we can directly make inference with the TSFM and use the performance as the difficulty score of samples in the real-world dataset"
- **Break condition**: If simulated data does not adequately represent the complexity of real building energy patterns, or if the difficulty transfer introduces systematic bias

### Mechanism 3
- **Claim**: Contrastive learning with memory bank and TCN encoder effectively captures temporal patterns relevant to building energy forecasting
- **Mechanism**: The TCN encoder captures daily and weekly seasonality patterns in building energy time series, while the memory bank structure handles the large number of negative pairs efficiently. The contrastive loss weighted by TSFM comprehension differences ensures similar samples have similar difficulty levels
- **Core assumption**: Temporal patterns captured by TCN are relevant to the difficulty of forecasting tasks, and the InfoNCE loss with weighted negative pairs effectively learns useful representations
- **Evidence anchors**: [section] "Considering the huge amount of negative pairs, we leverage the classical memory bank structure and adopt temporal convolutional network (TCN) as the encoder since it can be trained efficiently and shows superior performance in capturing daily and weekly seasonality"
- **Break condition**: If TCN fails to capture the relevant temporal patterns, or if the contrastive representation does not align with forecasting difficulty

## Foundational Learning

- **Concept**: Curriculum Learning
  - **Why needed here**: Building energy forecasting involves data with varying complexity patterns that can overwhelm a pre-trained model if presented randomly. Curriculum learning gradually introduces complexity, allowing the TSFM to adapt more effectively
  - **Quick check question**: Why might presenting the most difficult building energy patterns first lead to poor adaptation of a pre-trained TSFM?

- **Concept**: Contrastive Learning
  - **Why needed here**: Simulated data lacks ground truth difficulty labels, making it impossible to rank directly. Contrastive learning transfers difficulty information from real data to simulated data through representation similarity
  - **Quick check question**: How does the InfoNCE loss help the model learn representations where samples with similar TSFM comprehension are closer together?

- **Concept**: Time Series Foundation Models
  - **Why needed here**: TSFMs provide generalized knowledge from diverse pre-training data, but struggle with domain-specific patterns in building energy. Understanding their limitations is crucial for effective adaptation
  - **Quick check question**: What makes building energy time series particularly challenging for foundation models trained on diverse datasets?

## Architecture Onboarding

- **Component map**: Data Pipeline (Real/Simulated) -> Difficulty Measurer -> Curriculum Scheduler -> Contrastive Model (TCN+MLP+Memory Bank) -> TSFM Adapter
- **Critical path**: Data ‚Üí Difficulty Measurement ‚Üí Curriculum Scheduling ‚Üí Contrastive Training ‚Üí TSFM Fine-tuning
- **Design tradeoffs**:
  - TCN vs Transformer for encoder: TCN chosen for efficiency and seasonal pattern capture, but may miss long-range dependencies
  - Memory bank size: Larger banks provide better negative sampling but increase memory usage
  - Growth rate of curriculum: Faster growth may speed training but risk overwhelming the model; slower growth is safer but slower
  - Number of contrastive pairs: More pairs improve representation quality but increase training time
- **Failure signatures**:
  - Curriculum has no effect: Check if difficulty measurer produces meaningful variance in scores
  - Performance degrades with curriculum: Verify that easy samples are actually easier for the TSFM
  - Contrastive training fails to converge: Check memory bank implementation and temperature parameter œÑ
  - Simulated data hurts performance: Verify that difficulty transfer is working correctly
- **First 3 experiments**:
  1. Verify difficulty measurer: Run TSFM on real data and plot error distribution to ensure meaningful difficulty scores exist
  2. Test contrastive transfer: For a subset of simulated samples, find nearest real samples by contrastive representation and verify their difficulty scores are similar
  3. Validate curriculum effectiveness: Compare TSFM fine-tuning with and without curriculum on a small dataset, measuring both training stability and final performance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the performance of CCL-based TSFM adaptation vary across different building types and climate conditions?
- **Basis in paper**: [explicit] The paper evaluates performance across five datasets from BDG and UCI, but doesn't provide detailed analysis of how building type or climate affects CCL effectiveness
- **Why unresolved**: The current evaluation shows overall performance improvements but doesn't stratify results by building characteristics or geographic location
- **What evidence would resolve it**: Detailed performance breakdown by building type (residential, commercial, industrial) and climate zone would reveal whether CCL is equally effective across all scenarios

### Open Question 2
- **Question**: What is the optimal scheduling strategy for the curriculum learning process beyond the linear continuous scheduler used in this work?
- **Basis in paper**: [inferred] The paper uses a linear continuous scheduler but acknowledges this is just one approach to the training scheduler subtask of curriculum learning
- **Why unresolved**: The paper demonstrates effectiveness of CCL but doesn't explore alternative scheduling strategies or optimize the scheduler parameters beyond basic settings
- **What evidence would resolve it**: Comparative experiments testing different scheduler types (exponential, step-based, adaptive) and parameter optimization would identify the most effective scheduling approach

### Open Question 3
- **Question**: How does the CCL method scale to other time-series domains beyond building energy forecasting?
- **Basis in paper**: [explicit] The paper states "This work highlights the potential of curriculum learning to harness the generalized knowledge of FM tailored specifically for a specific domain" but doesn't test transferability
- **Why unresolved**: The method is only validated on building energy data, leaving uncertainty about its applicability to other domains with similar data challenges
- **What evidence would resolve it**: Testing CCL adaptation on other time-series domains (healthcare, finance, weather) with limited real data and abundant simulated data would demonstrate generalizability

## Limitations

- The study relies heavily on the assumption that TSFM performance on real data can serve as a reliable proxy for sample difficulty, which may not hold for all TSFM architectures
- The contrastive transfer mechanism's sensitivity to hyperparameter choices (ùõø, ùúè, ùúÜ0, ùëágrow) remains underexplored, potentially limiting reproducibility
- The TCN encoder's ability to capture all relevant temporal patterns for building energy forecasting is assumed rather than empirically validated through ablation studies

## Confidence

- **High Confidence**: The core methodology of using curriculum learning with difficulty-based ordering is well-established and the mathematical framework is sound
- **Medium Confidence**: The specific application to building energy forecasting with contrastive transfer from simulated to real data, while promising, requires more extensive validation across diverse building types and climate conditions
- **Medium Confidence**: The claimed improvements over state-of-the-art models, though statistically significant in the reported experiments, may not generalize to all building energy forecasting scenarios

## Next Checks

1. **Difficulty Transfer Validation**: For a stratified sample of simulated data, manually verify that contrastive representations correctly identify the most similar real samples and that their difficulty scores align within a 15% tolerance

2. **Hyperparameter Sensitivity Analysis**: Systematically vary ùõø (0.1-0.5), ùúè (0.07-0.2), ùúÜ0 (0.1-0.3), and ùëágrow (50-200 epochs) to identify the robustness range of CCL performance improvements

3. **Cross-Domain Generalization**: Test the CCL-adapted TSFM on a geographically distinct building dataset not used in training to assess whether curriculum learning prevents overfitting to the specific training domain's complexity patterns