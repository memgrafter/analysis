---
ver: rpa2
title: 'MetaOpenFOAM: an LLM-based multi-agent framework for CFD'
arxiv_id: '2407.21320'
source_url: https://arxiv.org/abs/2407.21320
tags:
- metaopenfoam
- input
- file
- simulation
- pass
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MetaOpenFOAM is a novel multi-agent framework that uses large language
  models to automate computational fluid dynamics simulations with only natural language
  input. It employs MetaGPT's assembly line paradigm to assign specialized roles to
  agents, breaking down complex CFD tasks into manageable subtasks, while Langchain's
  RAG technology enhances the framework with a searchable database of OpenFOAM tutorials.
---

# MetaOpenFOAM: an LLM-based multi-agent framework for CFD

## Quick Facts
- arXiv ID: 2407.21320
- Source URL: https://arxiv.org/abs/2407.21320
- Reference count: 20
- Framework achieves 85% pass rate for CFD simulations using only natural language input

## Executive Summary
MetaOpenFOAM is a novel multi-agent framework that leverages large language models to automate computational fluid dynamics simulations through natural language input. The framework employs MetaGPT's assembly line paradigm to assign specialized roles to agents, breaking down complex CFD tasks into manageable subtasks. By integrating Langchain's RAG technology with a searchable database of OpenFOAM tutorials, the system can handle diverse CFD scenarios with minimal user intervention while demonstrating generalization capabilities through parameter modification and error correction.

## Method Summary
The framework implements a four-agent system (Architect, InputWriter, Runner, Reviewer) using the MetaGPT assembly line paradigm to decompose CFD simulations into specialized tasks. It integrates Langchain's RAG technology with an OpenFOAM tutorials database for contextual guidance. The system processes natural language requirements through iterative refinement, with the Reviewer agent providing error feedback until successful execution or maximum iterations are reached. The implementation requires OpenFOAM 10, MetaGPT v0.8.0, LangChain v0.1.19, and FAISS vector store, with testing conducted on eight benchmark CFD cases covering various flow types.

## Key Results
- Achieved 85% pass rate across eight benchmark CFD simulation tasks
- Average cost of $0.22 per simulation case with 5.5 iterations and 5772 tokens
- Ablation study confirmed necessity of each component, particularly reviewer role and RAG technology
- Sensitivity analysis showed lower LLM temperature settings (0.01) yield more stable results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MetaOpenFOAM achieves high automation by decomposing complex CFD tasks into manageable subtasks using the MetaGPT assembly line paradigm.
- Mechanism: The framework assigns specialized roles (Architect, InputWriter, Runner, Reviewer) to different agents, each responsible for specific stages of the CFD simulation pipeline. This division of labor allows the system to handle intricate tasks like mesh pre-processing, simulation execution, and error correction in a structured manner.
- Core assumption: Specialized agents can collaborate effectively without human intervention to complete the entire CFD workflow.
- Evidence anchors:
  - [abstract] "MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks."
  - [section 2.1] "The framework is divided into four primary roles, each with specific responsibilities and actions..."
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.415, average citations=0.0. Top related titles: OptMetaOpenFOAM: Large Language Model Driven Chain of Thought for Sensitivity Analysis and Parameter Optimization based on CFD.

### Mechanism 2
- Claim: The integration of Retrieval-Augmented Generation (RAG) technology enhances the framework's ability to handle diverse CFD scenarios by providing relevant information and contextual guidance.
- Mechanism: Langchain's RAG technology integrates a searchable database of OpenFOAM tutorials and documents, allowing agents to retrieve and utilize relevant information during task execution. This ensures that the framework can adapt to various CFD scenarios with minimal user intervention.
- Core assumption: The database contains sufficient and relevant information to guide the agents in most CFD scenarios.
- Evidence anchors:
  - [abstract] "Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs."
  - [section 2.2] "Langchain's RAG technology is a critical component that supports MetaOpenFOAM by integrating a searchable database of OpenFOAM official documents and tutorials."
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.415, average citations=0.0. Top related titles: OptMetaOpenFOAM: Large Language Model Driven Chain of Thought for Sensitivity Analysis and Parameter Optimization based on CFD.

### Mechanism 3
- Claim: MetaOpenFOAM demonstrates generalization ability through parameter modification and error correction capabilities, allowing it to adapt to different user requirements and simulation scenarios.
- Mechanism: The framework can identify and modify key parameters in user requirements and correct errors when failures occur, with or without human participation. This adaptability ensures that the framework can handle a wide range of CFD simulation tasks and user inputs.
- Core assumption: The agents can accurately identify and modify key parameters based on user requirements and correct errors effectively.
- Evidence anchors:
  - [abstract] "MetaOpenFOAM own the ability to identify and modify key parameters in user requirements and excels in correcting bugs when failures occur, with or without human participation, which demonstrates the generalization of MetaOpenFOAM."
  - [section 4.3] "MetaOpenFOAM can identify and modify the corresponding parameters in the input for key data that can be directly corrected..."
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.415, average citations=0.0. Top related titles: OptMetaOpenFOAM: Large Language Model Driven Chain of Thought for Sensitivity Analysis and Parameter Optimization based on CFD.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their capabilities in natural language processing and generation.
  - Why needed here: LLMs form the core of MetaOpenFOAM, enabling it to understand and generate natural language inputs for CFD simulations.
  - Quick check question: Can LLMs handle complex tasks that require extensive text generation and domain-specific knowledge?

- Concept: Multi-Agent Systems (MAS) and their role in collaborative problem-solving.
  - Why needed here: MAS allows MetaOpenFOAM to decompose complex CFD tasks into manageable subtasks, with each agent specializing in different aspects of the simulation pipeline.
  - Quick check question: How do MAS improve the efficiency and accuracy of complex problem-solving compared to single-agent systems?

- Concept: Retrieval-Augmented Generation (RAG) and its application in enhancing LLM performance.
  - Why needed here: RAG provides MetaOpenFOAM with access to relevant information and contextual guidance, enabling it to handle diverse CFD scenarios effectively.
  - Quick check question: How does RAG improve the ability of LLMs to answer queries and generate accurate responses in specialized domains?

## Architecture Onboarding

- Component map: Architect -> InputWriter -> Runner -> Reviewer (loop until no errors or max iterations)
- Critical path: Architect interprets requirements → InputWriter generates input files → Runner executes simulations → Reviewer analyzes errors → loop back if needed
- Design tradeoffs:
  - Specialization vs. Generalization: Specialized agents may perform tasks more accurately but may struggle with tasks outside their domain
  - Automation vs. Human Intervention: Higher automation reduces the need for human expertise but may lead to errors in complex scenarios
  - Database Size vs. Retrieval Speed: A larger database provides more information but may slow down the retrieval process
- Failure signatures:
  - High iteration counts: Indicates difficulty in resolving errors or finding relevant information
  - Low executability scores: Suggests issues with input file generation or simulation execution
  - High token usage: May indicate inefficient task decomposition or communication between agents
- First 3 experiments:
  1. Run a simple 2D incompressible flow simulation (e.g., Cavity case) to test basic functionality
  2. Introduce a parameter modification (e.g., change grid size) to test generalization capabilities
  3. Simulate a more complex scenario (e.g., BuoyantCavity) to evaluate error handling and correction mechanisms

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MetaOpenFOAM scale with increasing problem complexity and larger mesh sizes?
- Basis in paper: [inferred] The paper demonstrates performance on 8 benchmark cases but does not explore scalability to more complex geometries or larger problems.
- Why unresolved: The study focuses on moderate-sized test cases and does not systematically investigate how performance metrics (pass rate, iterations, tokens) change with problem complexity or mesh size.
- What evidence would resolve it: Systematic testing of MetaOpenFOAM on progressively more complex CFD problems with varying mesh sizes, documenting how execution time, iteration count, and success rate scale.

### Open Question 2
- Question: What is the impact of using different LLMs (e.g., GPT-4, Llama 2, ChatGLM) on MetaOpenFOAM's performance?
- Basis in paper: [explicit] The paper uses GPT-4o as the representative LLM but acknowledges that different LLMs exist.
- Why unresolved: The study only tests with one LLM model, leaving open questions about how other models might perform in terms of accuracy, cost, and iteration efficiency.
- What evidence would resolve it: Comparative testing of MetaOpenFOAM using multiple LLM models on the same benchmark suite, measuring pass rates, token usage, and execution time for each.

### Open Question 3
- Question: How can MetaOpenFOAM be extended to handle cases requiring secondary calculations (e.g., Reynolds number conversion to input parameters)?
- Basis in paper: [explicit] The paper notes that MetaOpenFOAM cannot directly handle parameters like Reynolds number that require secondary calculations.
- Why unresolved: The current framework identifies this limitation but does not propose or test solutions for incorporating calculation capabilities.
- What evidence would resolve it: Implementation and testing of an extended version of MetaOpenFOAM with additional agents or function libraries capable of performing necessary secondary calculations, demonstrating successful handling of such cases.

## Limitations
- Single LLM dependency creates potential bottleneck and limits adaptability to different model strengths
- Database coverage and retrieval accuracy not quantitatively evaluated for edge cases
- Cannot handle secondary calculations like Reynolds number conversions requiring intermediate computation

## Confidence
- High confidence: Task decomposition through specialized agents is well-supported by 85% pass rate and ablation study
- Medium confidence: RAG technology effectiveness in diverse scenarios supported by mechanism but lacks quantitative retrieval accuracy data
- Medium confidence: Generalization claims through parameter modification demonstrated with examples but needs broader testing

## Next Checks
1. **Error propagation analysis**: Track how errors propagate through the agent pipeline by instrumenting each agent's outputs and measuring the correlation between early-stage errors and final simulation failures.

2. **RAG coverage evaluation**: Systematically measure the retrieval accuracy and coverage of the OpenFOAM database by creating test queries that probe edge cases and measuring whether relevant information is retrieved.

3. **Cross-domain generalization test**: Apply MetaOpenFOAM to CFD scenarios outside the 8 benchmark cases (e.g., multiphase flows or transient simulations) to validate the claimed generalization capabilities with parameter modification and error correction.