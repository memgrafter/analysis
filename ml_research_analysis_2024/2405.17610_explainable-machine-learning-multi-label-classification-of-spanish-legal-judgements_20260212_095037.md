---
ver: rpa2
title: Explainable machine learning multi-label classification of Spanish legal judgements
arxiv_id: '2405.17610'
source_url: https://arxiv.org/abs/2405.17610
tags:
- legal
- classification
- multi-label
- data
- decision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an explainable machine learning system for
  multi-label classification of Spanish legal judgements. The system combines text
  processing, legal entity detection, anonymization, feature engineering, and machine
  learning classification with visual and natural language explanations.
---

# Explainable machine learning multi-label classification of Spanish legal judgements

## Quick Facts
- arXiv ID: 2405.17610
- Source URL: https://arxiv.org/abs/2405.17610
- Authors: Francisco de Arriba-Pérez; Silvia García-Méndez; Francisco J. González-Castaño; Jaime González-González
- Reference count: 8
- Primary result: Over 85% micro precision in multi-label classification of Spanish legal judgments with automatic explanations

## Executive Summary
This paper presents an explainable machine learning system for multi-label classification of Spanish legal judgments. The system combines text processing, legal entity detection, anonymization, feature engineering, and machine learning classification with visual and natural language explanations. Using a dataset of 106,806 annotated judgments, the system achieves over 85% micro precision in predicting up to three law categories per judgment. The approach uses Random Forest with multi-class transformation strategy and provides interpretable decision trees with explanations at feature level. This is the first work to provide automatic explanations for legal judgment classification, addressing the challenge of opaque AI decisions in the legal domain.

## Method Summary
The system employs a multi-stage pipeline for classifying Spanish Supreme Court judgments into legal categories. Text preprocessing includes stop-word removal, lemmatization, and tokenization. Legal entities are detected and anonymized to protect privacy while preserving discriminative features. Feature engineering extracts domain-specific metadata including case type, court, and jurisdiction. Classification uses Random Forest with multi-class transformation strategy, outperforming binary transformation approaches. Explanations are generated through decision tree visualization and natural language templates, providing interpretable reasoning for each classification outcome.

## Key Results
- Multi-class transformation strategy (MTS) outperforms binary transformation (BTS) by up to 10% in exact match and precision
- Legal entity detection and anonymization improve classification accuracy by focusing on legally relevant patterns
- Decision tree-based explanations provide interpretable reasoning at feature level, unique in legal classification literature
- System achieves over 85% micro precision across the dataset of 106,806 Spanish Supreme Court judgments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-label classification with transformation strategy (MTS) outperforms binary transformation (BTS) for Spanish legal judgments.
- Mechanism: By treating the problem as a single multi-class classification with combined label classes, the system avoids the redundancy and noise of training many binary classifiers, and better captures inter-label dependencies.
- Core assumption: Label dependencies and combinations are informative and the training data is sufficient to learn them.
- Evidence anchors:
  - [abstract] states "multi-label classification with transformation strategy and provides interpretable decision trees..."
  - [section] shows "The mts strategy achieved notable improvements, of up to 10 % in exact match and precision."
  - [corpus] weak; no neighbor papers report comparable MTS vs BTS results.
- Break condition: If label dependencies are weak or training data per label combination is sparse, performance could degrade.

### Mechanism 2
- Claim: Feature engineering with legal entity detection and anonymization boosts classification accuracy.
- Mechanism: By extracting domain-specific features (case type, court, jurisdiction, etc.) and removing sensitive names, the model focuses on legally relevant patterns and avoids bias from personal names.
- Core assumption: Legal entities are strong discriminative signals for the classification task.
- Evidence anchors:
  - [abstract] mentions "deep legal reasoning to identify the entities, such as the parties, involved."
  - [section] states "We include in-depth entity detection to extract relevant judicial entities such as case type, court and jurisdiction among others."
  - [corpus] weak; no neighbor papers explicitly link entity detection to improved accuracy.
- Break condition: If legal entities are not predictive or if anonymization removes important context, the benefits could be lost.

### Mechanism 3
- Claim: Visual and natural language explanations increase user trust and model transparency.
- Mechanism: Decision tree paths are rendered visually and mapped to templates, giving users interpretable reasoning for each classification outcome.
- Core assumption: Decision trees are sufficiently interpretable and the explanation templates are meaningful to legal experts.
- Evidence anchors:
  - [abstract] highlights "the first work to provide automatic explanations for legal judgement classification."
  - [section] details "The focus of this work is the explainable classification of legal judgements... our work contributes to the state of the art in legal judgement classification with a hybrid system that combines ml for prediction and visual and natural language representation down to feature level for explanations."
  - [corpus] weak; neighbor papers do not address explainability in legal classification.
- Break condition: If decision trees become too deep or the domain is too complex for templates to be meaningful, explanations may lose value.

## Foundational Learning

- Concept: Multi-label classification vs multi-class classification
  - Why needed here: The system must assign up to three legal categories per judgment, requiring multi-label handling.
  - Quick check question: What is the key difference between a multi-label and multi-class problem?

- Concept: Feature engineering and selection
  - Why needed here: Legal judgments contain rich unstructured text and domain metadata; extracting relevant features is critical for model performance.
  - Quick check question: Why is it important to remove stop-words and perform lemmatization before feature extraction?

- Concept: Explainable AI and interpretable models
  - Why needed here: Legal domain demands transparency; opaque models are unacceptable to practitioners.
  - Quick check question: What is the difference between a transparent model and an opaque model?

## Architecture Onboarding

- Component map: Text Processing -> Legal Entity Detection -> Anonymization -> Feature Engineering -> ML Classification -> Evaluation -> Explainability

- Critical path:
  - Anonymization must happen before feature engineering to prevent bias.
  - Legal entity detection and anonymization are parallel preprocessing steps feeding into feature engineering.
  - Classification (MTS) is the bottleneck; explanation generation follows.

- Design tradeoffs:
  - Use of Random Forest (RF) for explainability vs. higher accuracy but opaque deep models.
  - Feature selection based on Spearman correlation vs. more complex selection methods.
  - Real-time anonymization vs. batch preprocessing.

- Failure signatures:
  - Low micro-precision: likely feature engineering or class imbalance issues.
  - Long training times: model complexity or feature dimensionality too high.
  - Poor explanations: decision tree depth too shallow or templates not aligned with model outputs.

- First 3 experiments:
  1. Train MTS vs BTS with identical preprocessing; measure exact match and training time.
  2. Compare feature sets with and without legal entity features; measure precision and recall.
  3. Generate explanations for a small test set; validate templates against a legal expert.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation conducted on single proprietary dataset of Spanish Supreme Court judgments, limiting generalizability to other legal systems or languages
- Detailed per-label performance metrics not provided, making it difficult to assess systematic misclassifications for certain law categories
- Legal entity detection and anonymization steps described but not empirically validated for their impact on classification accuracy
- Comparison between MTS and BTS only evaluated on one dataset and with one model type (Random Forest)

## Confidence

- Multi-label classification performance claims: Medium
- Explainability and explanation quality: Low
- Legal entity detection and anonymization benefits: Low
- MTS vs BTS comparison results: Medium

## Next Checks
1. Conduct ablation studies to quantify the exact contribution of legal entity features and anonymization to classification performance.
2. Validate explanation templates with legal domain experts to assess their accuracy, clarity, and practical utility.
3. Test the system on legal judgments from different jurisdictions or languages to evaluate generalizability.