---
ver: rpa2
title: 'MultiTASC++: A Continuously Adaptive Scheduler for Edge-Based Multi-Device
  Cascade Inference'
arxiv_id: '2412.04147'
source_url: https://arxiv.org/abs/2412.04147
tags:
- devices
- accuracy
- multitasc
- number
- server
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces MultiTASC++, a multi-tenancy-aware scheduler
  for edge-based multi-device cascade inference. It addresses the problem of efficiently
  sharing a single server-side model across multiple heterogeneous IoT devices in
  AI-driven environments.
---

# MultiTASC++: A Continuously Adaptive Scheduler for Edge-Based Multi-Device Cascade Inference

## Quick Facts
- arXiv ID: 2412.04147
- Source URL: https://arxiv.org/abs/2412.04147
- Reference count: 36
- Multi-device cascade inference scheduler achieving 95% SLO satisfaction across up to 100 devices

## Executive Summary
MultiTASC++ introduces a multi-tenancy-aware scheduler for edge-based multi-device cascade inference that dynamically adjusts forwarding decision thresholds at runtime to optimize throughput, latency, and accuracy. The system continuously monitors Service-Level Objective (SLO) satisfaction rates and fine-tunes per-device thresholds to maintain target performance while scaling to large device populations. Through extensive experimentation with heterogeneous IoT devices, MultiTASC++ demonstrates superior accuracy, better scalability, and reduced performance variance compared to static and discrete-step baselines.

## Method Summary
MultiTASC++ implements continuous threshold reconfiguration for cascade inference systems, where each IoT device runs a lightweight local model and can forward samples to a shared server model for refinement. The scheduler receives real-time SLO satisfaction rate updates from devices and adjusts forwarding thresholds using a continuous update rule: Δthresh = -a · (SRtarget - SRupdate), where a = 0.005 and SRtarget = 95%. The system also supports server model switching between high-accuracy/low-throughput and low-accuracy/high-throughput models based on device threshold patterns, enabling dynamic accuracy-latency trade-offs under varying load conditions.

## Key Results
- Maintains 95% SLO satisfaction rate across up to 100 heterogeneous devices
- Achieves higher accuracy than static threshold baselines while meeting satisfaction targets
- Reduces performance variance compared to MultiTASC and static approaches

## Why This Works (Mechanism)

### Mechanism 1
MultiTASC++ maintains high SLO satisfaction rates (95%) across up to 100 devices by dynamically adjusting forwarding decision thresholds based on real-time satisfaction updates. Each device continuously reports its current SLO satisfaction rate to the scheduler, which uses these updates to fine-tune per-device forwarding thresholds. The scheduler increases thresholds when satisfaction is above target (allowing more samples to skip the server) and decreases them when below target (ensuring more samples are forwarded for refinement).

### Mechanism 2
Continuous threshold reconfiguration via fine-grained adjustments allows MultiTASC++ to adapt faster and more precisely than discrete-step methods. Instead of stepping thresholds by fixed amounts, the scheduler computes threshold changes as a continuous function of the gap between current and target satisfaction rates, scaled by a device-specific factor. This enables rapid convergence to optimal thresholds and smooth adaptation to changing conditions.

### Mechanism 3
Server model switching between high-accuracy/low-throughput and low-accuracy/high-throughput models enables MultiTASC++ to dynamically balance accuracy and responsiveness under varying load. The scheduler monitors device thresholds and switches the server model when all devices are consistently above or below predefined threshold bounds. This switches the system between prioritizing accuracy (heavy model) and responsiveness (light model).

## Foundational Learning

- Concept: Cascade inference architecture (lightweight on-device model + heavy server model)
  - Why needed here: MultiTASC++ is built to manage multi-device cascades, so understanding how cascades balance local processing with server refinement is essential.
  - Quick check question: In a cascade system, what determines whether a sample is forwarded to the server or kept on-device?

- Concept: Service-Level Objective (SLO) and satisfaction rate
  - Why needed here: The scheduler's goal is to maintain a target SLO satisfaction rate (e.g., 95%), so engineers must understand how SLOs are defined and measured in this context.
  - Quick check question: How is the SLO satisfaction rate calculated in a multi-device cascade system?

- Concept: Dynamic batching for throughput optimization
  - Why needed here: MultiTASC++ uses dynamic batching to maximize server throughput without introducing excessive latency, so engineers must grasp how batch sizes are adapted to queue length.
  - Quick check question: What is the benefit of dynamic batching compared to fixed batch sizes in a server request queue?

## Architecture Onboarding

- Component map: IoT devices -> Forwarding decision functions -> Request queue -> Server model -> MultiTASC++ scheduler -> Communication channel

- Critical path:
  1. Device runs local inference and computes BvSB confidence.
  2. Forwarding decision function compares BvSB to per-device threshold.
  3. If forwarded, sample enters server request queue.
  4. Server processes queued samples in dynamic batches.
  5. Results are returned to originating device.
  6. Device reports SLO satisfaction rate to scheduler.

- Design tradeoffs:
  - Accuracy vs. latency: Higher thresholds → more local-only processing → faster but less accurate; lower thresholds → more server refinement → slower but more accurate.
  - Model switching overhead: Switching server models can improve long-term balance but may introduce short-term latency spikes.
  - Threshold update frequency: More frequent updates enable faster adaptation but increase communication overhead.

- Failure signatures:
  - SLO satisfaction rate consistently below target: Indicates thresholds are too low or server model too slow.
  - High variance in device satisfaction rates: May indicate imbalanced thresholds or uneven device capabilities.
  - Sudden drop in system throughput: Could indicate queue buildup or inefficient batching.

- First 3 experiments:
  1. Deploy MultiTASC++ with 5 low-tier devices and a static server model; verify SLO satisfaction rate converges to target.
  2. Increase device count to 50; observe threshold adjustments and measure accuracy vs. satisfaction rate trade-off.
  3. Enable server model switching; run with mixed load to confirm scheduler switches models appropriately.

## Open Questions the Paper Calls Out

- **Question**: How does MultiTASC++ perform with generative inference tasks like image and text generation in multi-device cascade setups?
  - Basis in paper: The conclusion section mentions extending the system to investigate generative inference tasks.
  - Why unresolved: The paper focuses on image classification and does not evaluate generative tasks.
  - What evidence would resolve it: Experiments comparing MultiTASC++ with generative models like GANs or transformers for text generation in multi-device cascades.

- **Question**: What is the impact of varying server-side model switching thresholds (clower and c upper) on system performance and accuracy?
  - Basis in paper: The paper mentions that upper and lower limits are set after thorough examination but does not detail the impact of varying these thresholds.
  - Why unresolved: The paper does not provide sensitivity analysis for these thresholds.
  - What evidence would resolve it: Experiments showing system performance and accuracy across a range of threshold values for server model switching.

- **Question**: How does MultiTASC++ scale with non-uniform device participation rates, where some devices have significantly higher or lower probabilities of being offline?
  - Basis in paper: The paper evaluates intermittent device participation with a uniform 50% probability but does not explore non-uniform participation.
  - Why unresolved: The evaluation focuses on uniform device participation rates.
  - What evidence would resolve it: Experiments with devices having varying probabilities of being offline, showing how MultiTASC++ adapts to these differences.

## Limitations

- Limited evaluation under realistic network conditions including packet loss, variable latency, and device failures
- Effectiveness of server model switching depends on availability of appropriate model pool with sufficient latency-accuracy trade-offs
- Continuous threshold adjustment mechanism may be vulnerable to oscillation or instability if scaling factor is not properly tuned

## Confidence

**High confidence** in the core mechanism of continuous threshold reconfiguration and its ability to adapt to changing device loads, supported by detailed mathematical formulation and experimental validation across multiple device tiers.

**Medium confidence** in the server model switching capability, as the paper provides clear logic for when switching occurs but limited evaluation of the actual impact on system performance.

**Medium confidence** in the scalability claims to 100 devices, as the paper demonstrates this capability but the experiments may not capture all real-world edge deployment challenges.

## Next Checks

1. Evaluate MultiTASC++ performance under realistic network conditions including 5-20% packet loss, variable latency (50-500ms), and periodic device communication failures to verify SLO satisfaction rate maintenance.

2. Test the scheduler with different server model configurations (e.g., only 2 models instead of 3, or models with overlapping latency-accuracy characteristics) to assess how critical the model switching capability is to overall performance.

3. Run extended experiments (30+ minutes) with gradually increasing device counts to identify potential oscillation or instability in the continuous threshold adjustment mechanism under sustained load.