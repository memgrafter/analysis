---
ver: rpa2
title: 'TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document'
arxiv_id: '2403.04473'
source_url: https://arxiv.org/abs/2403.04473
tags:
- text
- tokens
- document
- image
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TextMonkey, a large multimodal model designed
  for text-centric tasks. It addresses challenges in text-heavy tasks like document
  question answering and fine-grained text analysis by adopting Shifted Window Attention
  with zero initialization to establish relationships while increasing input resolutions
  using a sliding window.
---

# TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document

## Quick Facts
- arXiv ID: 2403.04473
- Source URL: https://arxiv.org/abs/2403.04473
- Authors: Yuliang Liu; Biao Yang; Qiang Liu; Zhang Li; Zhiyin Ma; Shuo Zhang; Xiang Bai
- Reference count: 40
- Primary result: Achieves 561 on OCRBench, outperforming previous open-sourced large multimodal models for document understanding

## Executive Summary
TextMonkey is a large multimodal model designed to excel at text-centric tasks in documents and scenes. It addresses challenges in text-heavy tasks like document question answering and fine-grained text analysis by adopting Shifted Window Attention with zero initialization to establish relationships while increasing input resolutions using a sliding window. The model also employs a Token Resampler to reduce the number of tokens. TextMonkey engages in multiple text-oriented tasks simultaneously, enhancing its perception and understanding of spatial relationships, leading to improved interpretability and support for clicking screenshots.

## Method Summary
TextMonkey uses a combination of techniques to handle high-resolution images and text-centric tasks. It employs Shifted Window Attention with zero initialization to establish cross-window connectivity while stabilizing early training. A Token Resampler is used to reduce redundant tokens through similarity-based filtering. The model incorporates positional information into responses to enhance interpretability and reduce hallucination. It is trained on a combination of open-source datasets with task-specific augmentations.

## Key Results
- Achieves excellent results on multiple benchmarks, outperforming previous open-sourced large multimodal models for document understanding with a score of 561 on OCRBench
- Shows significant improvements in scene text-centric tasks (5.2%), document-oriented tasks (6.9%), and key information extraction tasks (2.8%)
- Demonstrates strong performance in scene text spotting tasks with a 10.9% increase

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Shifted Window Attention with zero initialization enables cross-window connectivity while stabilizing early training in high-resolution document images.
- **Mechanism:** The model slices high-resolution images into non-overlapping windows of 448x448 pixels, applies Transformer blocks within each window, and then uses Shifted Window Attention (SWA) with cyclic-shifting to introduce interactions between windows. Zero initialization in the MLP layers (weight B set to zero) prevents drastic modifications to early training features.
- **Core assumption:** Maintaining stable early feature representations is crucial for effective training when introducing cross-window relationships.
- **Evidence anchors:**
  - [abstract] "By adopting Shifted Window Attention with zero-initialization, we achieve cross-window connectivity at higher input resolutions and stabilize early training"
  - [section] "To achieve smoother training initialization, we have made modifications to the shifted window attention by allowing them to start learning from zero initialization, avoiding excessive transformation of early features during the initial stages"
  - [corpus] No direct corpus evidence available for this specific mechanism
- **Break condition:** If zero initialization fails to prevent excessive feature transformation, training instability could occur, particularly when dealing with high-resolution inputs that require complex cross-window relationships.

### Mechanism 2
- **Claim:** Token Resampler effectively reduces redundant tokens while preserving important information in high-resolution document images.
- **Mechanism:** The Token Resampler uses similarity-based filtering to identify important tokens that lack closely similar counterparts. These significant tokens serve as queries in a cross-attention mechanism to re-aggregate features from all original tokens, compressing the token sequence while maintaining crucial information.
- **Core assumption:** High-resolution images contain redundant tokens that can be identified through similarity metrics and safely compressed without losing essential information.
- **Evidence anchors:**
  - [abstract] "We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance"
  - [section] "We have observed that there are numerous repetitive image features that align with the language space... we utilize similarity as a metric to identify significant tokens"
  - [corpus] No direct corpus evidence available for this specific mechanism
- **Break condition:** If the similarity threshold is set too high or too low, the model might either retain too many redundant tokens or lose important information, negatively impacting performance.

### Mechanism 3
- **Claim:** Incorporating positional information into responses enhances interpretability and reduces hallucination in text-centric tasks.
- **Mechanism:** The model grounds answers to specific visual evidence by including positional coordinates in responses. It processes text spotting and grounding tasks, standardizing positional information across different image ratios using a (0, 1000) scale, and integrates these cues into the final answers.
- **Core assumption:** Humans can typically locate answers within images themselves, and providing positional context helps anchor the model's responses to actual visual evidence.
- **Evidence anchors:**
  - [abstract] "by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability"
  - [section] "To alleviate the issue of hallucinations in Large Language Models (LLMs), where they can produce incorrect responses not related to the provided image, we aim to enhance their capability to analyze and incorporate visual information into their replies"
  - [corpus] No direct corpus evidence available for this specific mechanism
- **Break condition:** If the model fails to accurately ground answers or if positional information becomes too complex to interpret, the intended interpretability benefits may not materialize.

## Foundational Learning

- **Concept:** Cross-attention mechanisms in multimodal models
  - Why needed here: The model uses cross-attention in both the Image Resampler and Token Resampler to map visual features to the language domain and compress token sequences
  - Quick check question: How does cross-attention differ from self-attention in processing visual and language modalities?

- **Concept:** Zero initialization in neural network layers
  - Why needed here: Zero initialization in the MLP layers of Shifted Window Attention prevents drastic changes to early training features, stabilizing the learning process
  - Quick check question: What are the advantages and disadvantages of zero initialization compared to standard initialization methods?

- **Concept:** Cosine similarity for token redundancy detection
  - Why needed here: Cosine similarity measures the similarity between image tokens already mapped to the language space, helping identify redundant tokens that can be compressed
  - Quick check question: How does cosine similarity work as a metric for comparing high-dimensional embeddings in token space?

## Architecture Onboarding

- **Component map:** Input module -> Window splitting -> CLIP encoding -> Shifted Window Attention -> Image Resampler -> Token Resampler -> LLM -> Output with grounding

- **Critical path:** Image → Window splitting → CLIP encoding → Shifted Window Attention → Image Resampler → Token Resampler → LLM → Output with grounding

- **Design tradeoffs:**
  - Resolution vs. computational cost: Higher resolution improves text recognition but increases token count and computational requirements
  - Token compression vs. information retention: Aggressive compression reduces computational load but risks losing important features
  - Positional grounding vs. reasoning flexibility: Including positional information enhances interpretability but may constrain the model's reasoning capabilities in certain tasks

- **Failure signatures:**
  - Training instability or slow convergence indicating issues with Shifted Window Attention initialization
  - Performance degradation on text-heavy tasks suggesting insufficient token compression or poor cross-window connectivity
  - Hallucination in responses indicating failure in positional grounding or insufficient visual-text alignment

- **First 3 experiments:**
  1. Test Shifted Window Attention with and without zero initialization on a small document dataset to measure training stability and performance impact
  2. Evaluate Token Resampler effectiveness by comparing similarity-based compression against random token selection on high-resolution images
  3. Measure the impact of positional information inclusion on interpretability metrics across different document types (forms, tables, charts)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TextMonkey compare to other models when handling documents with very small text?
- Basis in paper: [explicit] The paper mentions that previous models struggle with small text in images, and TextMonkey aims to address this issue.
- Why unresolved: The paper does not provide specific quantitative comparisons of TextMonkey's performance on documents with very small text versus other models.
- What evidence would resolve it: Direct comparison of TextMonkey's performance on datasets with very small text against other models, using metrics like accuracy or F1 score.

### Open Question 2
- Question: What is the impact of the token resampler on the overall performance of TextMonkey, and how does it compare to other methods of reducing token length?
- Basis in paper: [explicit] The paper introduces a token resampler to reduce redundant tokens, claiming it improves performance compared to random queries.
- Why unresolved: The paper does not provide a detailed ablation study comparing the token resampler to other methods of reducing token length, such as pruning or quantization.
- What evidence would resolve it: A comprehensive ablation study comparing the token resampler to other token reduction methods on various benchmarks.

### Open Question 3
- Question: How does the zero initialization in Shifted Window Attention affect the training stability and final performance of TextMonkey?
- Basis in paper: [explicit] The paper mentions that zero initialization is used to achieve smoother training initialization in Shifted Window Attention.
- Why unresolved: The paper does not provide a detailed analysis of how zero initialization affects training stability and final performance compared to other initialization methods.
- What evidence would resolve it: A controlled experiment comparing the training stability and final performance of TextMonkey with and without zero initialization in Shifted Window Attention.

## Limitations
- Lack of direct experimental validation for the core mechanisms, particularly zero initialization and Token Resampler effectiveness
- No detailed ablation studies showing how much each mechanism contributes to the claimed performance improvements
- Absence of quantitative evaluation demonstrating that positional grounding actually reduces hallucination compared to models without positional outputs

## Confidence
**High Confidence**: The architectural components (CLIP-based visual encoder, LLM integration, window-based processing) are well-established in the literature and have been validated in previous works. The claim that TextMonkey achieves state-of-the-art performance on OCRBench with a score of 561 is supported by published benchmark results.

**Medium Confidence**: The claimed performance improvements (5.2% on scene text tasks, 6.9% on document tasks, 2.8% on key information extraction) are reported, but the paper does not provide detailed ablation studies showing how much each mechanism contributes to these gains. The effectiveness of the Token Resampler and Shifted Window Attention mechanisms could vary significantly depending on the specific document types and text densities encountered in real-world applications.

**Low Confidence**: The claims about interpretability enhancement through positional grounding lack rigorous evaluation. While the paper mentions this feature, there are no user studies or quantitative metrics demonstrating that the positional information actually helps users understand or trust the model's responses better than traditional approaches.

## Next Checks
1. **Ablation Study on Shifted Window Attention Initialization**: Train TextMonkey with three different initialization strategies (zero initialization, standard initialization, and Xavier initialization) on a controlled document dataset, measuring both training stability metrics (loss convergence speed) and final performance on document QA tasks.

2. **Token Resampler Sensitivity Analysis**: Systematically vary the similarity threshold used in the Token Resampler from 0.5 to 0.95 in increments of 0.1, evaluating the trade-off between token compression ratio and downstream task performance on high-resolution document images with varying text densities.

3. **Positional Grounding Effectiveness Evaluation**: Conduct a user study where participants are asked to verify model responses with and without positional information, measuring response verification accuracy and time. Additionally, implement an automated hallucination detection metric that compares positional-anchored responses against traditional responses on datasets known for hallucinatory outputs.