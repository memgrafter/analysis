---
ver: rpa2
title: 'OneProt: Towards Multi-Modal Protein Foundation Models'
arxiv_id: '2411.04863'
source_url: https://arxiv.org/abs/2411.04863
tags:
- pocket
- protein
- text
- oneprot-4
- oneprot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces OneProt, a multi-modal protein foundation
  model that integrates structural, sequence, text, and binding site data using the
  ImageBind framework. The model aligns protein modality encoders through pairwise
  contrastive learning with sequence data, enabling emergent alignment across modalities
  without requiring full matches.
---

# OneProt: Towards Multi-Modal Protein Foundation Models

## Quick Facts
- **arXiv ID**: 2411.04863
- **Source URL**: https://arxiv.org/abs/2411.04863
- **Reference count**: 40
- **Primary result**: OneProt achieves strong multi-modal protein representation learning, outperforming baselines on enzyme function prediction, binding site analysis, and evolutionary sequence classification through emergent alignment of structure, sequence, text, and pocket data.

## Executive Summary
This work introduces OneProt, a multi-modal protein foundation model that integrates structural, sequence, text, and binding site data using the ImageBind framework. The model aligns protein modality encoders through pairwise contrastive learning with sequence data, enabling emergent alignment across modalities without requiring full matches. OneProt demonstrates strong performance in retrieval tasks and outperforms existing models on downstream benchmarks including enzyme function prediction, binding site analysis, and evolutionary sequence classification. Ablation studies highlight the critical contribution of the binding site encoder, which is not present in similar models. The approach offers a flexible, lightweight framework for protein representation learning with applications in drug discovery and protein engineering.

## Method Summary
OneProt employs a multi-modal architecture based on the ImageBind framework, using pairwise contrastive learning to align embeddings from different protein data modalities. The model uses ESM2 as a frozen sequence encoder, with separate encoders for structure (both token-based and GNN-based), text (BiomedBERT with LoRA), and binding sites (GNN). Training pairs each modality with sequence using InfoNCE loss, allowing emergent alignment between modalities not directly paired. The approach is lightweight, training on only 1M data points compared to 40M for similar models, and generates embeddings that can be used with simple MLPs for downstream tasks.

## Key Results
- OneProt achieves R@1 of 0.83, R@10 of 0.95, and R@100 of 0.99 for structure-sequence retrieval, outperforming baselines
- On enzyme function prediction, OneProt achieves Spearman correlation of 0.75 compared to 0.64 for the best baseline
- For protein-ligand binding site prediction, OneProt achieves Fmax of 0.82 versus 0.76 for ProSPECCTs
- Ablation studies show the binding site encoder contributes 15-20% improvement across binding-related tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: OneProt's emergent alignment across modalities not explicitly paired during training arises because sequence is consistently present as an anchor and each modality is paired with it, creating a shared latent space where all modalities indirectly align.
- Mechanism: By pairing each modality (structure, text, pocket) only with sequence during training, and using InfoNCE loss, the model learns to align all modalities to the sequence embedding space. Since all embeddings are mapped into the same shared latent space via projection heads, modalities not directly paired still align due to transitive relationships through sequence.
- Core assumption: The sequence modality is a sufficiently rich and stable anchor that captures common semantic features across protein representations, enabling emergent alignment without requiring full pairwise training.
- Evidence anchors:
  - [abstract]: "align the latent spaces of protein modality encoders in a lightweight fine-tuning scheme that focuses on pairwise alignment with sequence data rather than requiring full matches"
  - [section]: "Because all modalities are mapped into the same shared latent space via F, modalities, which were not directly paired together during training, still align with each other - this is also known as emergent alignment"
  - [corpus]: Weak or missing - no corpus papers directly test emergent alignment in protein models.
- Break condition: If sequence fails to capture sufficient semantic overlap with other modalities (e.g., if structure or pocket features are too localized or domain-specific), emergent alignment will degrade, as observed in weaker median ranks for untrained pairs.

### Mechanism 2
- Claim: The inclusion of graph neural network (GNN) encoders for structure and pocket data significantly improves downstream task performance by capturing local spatial relationships and chemical environments that sequence-only models miss.
- Mechanism: GNN encoders process protein structures as hierarchical 3D graphs, preserving local chemical environments (atom positions, torsion angles) and geometric relationships. This complements sequence encoders by encoding structural and pocket-level features crucial for tasks like binding site prediction, enzyme function, and protein-protein interactions.
- Core assumption: Local geometric and chemical details are critical for accurate prediction of functional properties, and these details are not fully captured by sequence-based or token-based structure encoders alone.
- Evidence anchors:
  - [section]: "We observe that combining the structure graph and pocket encoders significantly improves performance on the HumanPPI and Metal Ion Binding tasks"
  - [section]: "The superiority of the discussed models is further evident... where the GNN structure and pocket encoders of OneProt contribute to the results"
  - [corpus]: Weak or missing - no corpus papers directly compare GNN vs token-based encoders for protein binding tasks.
- Break condition: If downstream tasks rely primarily on global structural similarity or sequence motifs rather than local chemical environments, GNN encoders may add complexity without performance gain.

### Mechanism 3
- Claim: Multi-modal training enables transfer of representational information from specialized encoders to the sequence encoder, enhancing its ability to distinguish evolutionarily related and unrelated proteins.
- Mechanism: During contrastive learning, the sequence encoder receives gradients not only from sequence data but also indirectly from the specialized encoders (structure, pocket, text). This cross-modal gradient flow enriches the sequence embeddings with structural and functional information, improving their ability to capture evolutionary relationships.
- Core assumption: Information encoded by specialized modalities (e.g., structural conservation, binding site similarity) correlates with evolutionary relatedness and can be effectively transferred to sequence representations through joint training.
- Evidence anchors:
  - [abstract]: "enables the transfer of representational information from specialized encoders to the sequence encoder, enhancing capabilities for distinguishing evolutionarily related and unrelated sequences"
  - [section]: "OneProt's superior capacity to distinguish homologous from non-homologous sequences is likely due to OneProt's multi-modal training with the InfoNCE loss... facilitates the exchange of representational information between encoders"
  - [corpus]: Weak or missing - no corpus papers explicitly measure representational transfer in protein models.
- Break condition: If evolutionary relationships are primarily sequence-driven and structural/pocket features do not correlate strongly with phylogeny, the transfer benefit will be minimal or absent.

## Foundational Learning

- Concept: Contrastive learning with InfoNCE loss
  - Why needed here: Enables alignment of embeddings from different modalities by pushing similar pairs together and dissimilar pairs apart, forming the core training objective for OneProt.
  - Quick check question: In InfoNCE loss, what role does the temperature parameter τ play in controlling the sharpness of the similarity distribution?

- Concept: Graph Neural Networks (GNNs) for structural data
  - Why needed here: GNNs capture local chemical environments and geometric relationships in protein structures and pockets, providing features that complement sequence-based representations.
  - Quick check question: How does a GNN's hierarchical message passing differ from standard convolutional operations when processing protein structures?

- Concept: Emergent alignment in multi-modal learning
  - Why needed here: Explains how OneProt achieves alignment between modalities not directly paired during training, a key advantage over traditional pairwise training schemes.
  - Quick check question: What condition must hold for emergent alignment to occur when training only on sequence-paired modality pairs?

## Architecture Onboarding

- Component map:
  Sequence encoder (ESM2) -> Structure token encoder (SaProt) -> Structure graph encoder (ProNet) -> Pocket encoder (ProNet) -> Text encoder (BiomedBERT+LoRA) -> Projection heads -> Shared latent space -> Contrastive loss

- Critical path: Training pipeline → Embedding generation → Downstream MLP training
  - Pre-training: Pair each modality with sequence, apply InfoNCE loss, update only modality-specific encoders and projection heads
  - Inference: Generate embeddings using frozen OneProt model, train simple MLP on downstream task

- Design tradeoffs:
  - Small training dataset (1M datapoints) vs. large baseline models (40M datapoints) → favors lightweight, modular design
  - Pairwise vs. full multi-modal training → reduces computational cost but may limit emergent alignment quality
  - Frozen sequence encoder vs. fine-tuning → faster adaptation but less task-specific optimization

- Failure signatures:
  - Poor retrieval performance (high median rank) → modality encoders not well-aligned
  - Degraded downstream accuracy → insufficient representational transfer or modality-specific information loss
  - Memory errors during training → modality encoder size or batch size too large for hardware

- First 3 experiments:
  1. Verify emergent alignment: Compute retrieval metrics for untrained modality pairs (e.g., structure-text) and compare to random baseline
  2. Ablation test: Train OneProt-4 (without structure token encoder) and compare downstream performance to OneProt-5
  3. Modality contribution: Train ablations with only one additional modality (e.g., only text or only pocket) and measure impact on evolutionary sequence classification task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the emergent alignment quality scale with increasing numbers of modalities in OneProt, and what is the optimal number of modalities for maximizing both alignment and downstream performance?
- Basis in paper: [explicit] The paper discusses emergent alignment across modalities not directly trained together and notes that OneProt-4 sometimes outperforms OneProt-5 on certain tasks, suggesting a trade-off between modality number and performance.
- Why unresolved: While the paper provides retrieval metrics for different modality combinations, it does not systematically explore how alignment quality changes as modalities are incrementally added or removed, nor does it determine the optimal modality configuration for different task types.
- What evidence would resolve it: Systematic ablation studies varying the number of modalities (e.g., 2, 3, 4, 5) with detailed alignment metrics (R@1, R@10, R@100, median rank) and downstream task performance comparisons would clarify the relationship between modality number and model effectiveness.

### Open Question 2
- Question: What is the precise mechanism by which the binding site encoder improves performance on protein-ligand interaction tasks, and can this be further enhanced through architectural modifications?
- Basis in paper: [explicit] The paper highlights the critical role of the binding site encoder in ProSPECCTs benchmarks and notes that it consistently contributes to performance improvements, particularly for datasets involving protein-ligand interactions.
- Why unresolved: The paper does not provide a detailed analysis of how the binding site encoder's features specifically contribute to improved predictions or whether architectural changes (e.g., attention mechanisms, hierarchical representations) could further enhance its effectiveness.
- What evidence would resolve it: Detailed feature importance analysis (e.g., attention weight visualization, gradient-based attribution) and controlled experiments testing architectural variations of the binding site encoder would elucidate its contribution mechanisms and potential for enhancement.

### Open Question 3
- Question: How does OneProt's performance on evolutionary sequence classification tasks compare to specialized models trained specifically on multiple sequence alignments (MSAs), and what are the key factors driving this difference?
- Basis in paper: [explicit] The paper demonstrates that OneProt captures evolutionary relationships through zero-shot learning without direct MSA training, outperforming ESM-2 and ProTrek models, but does not compare against MSA-specific models.
- Why unresolved: The paper does not benchmark OneProt against models explicitly designed for MSA analysis (e.g., MSA Transformer, ESM-1b variants), leaving open the question of whether the multi-modal approach or the MSA-specific features are more important for evolutionary classification.
- What evidence would resolve it: Direct comparison of OneProt against state-of-the-art MSA-specific models on standardized evolutionary classification benchmarks (e.g., protein family classification, phylogenetic tree reconstruction) would reveal the relative strengths of multi-modal versus MSA-focused approaches.

## Limitations

- Weak experimental validation of emergent alignment as a core mechanism, with no ablation studies testing whether this alignment would emerge without the sequence anchor
- Downstream tasks use simple MLP classifiers on pre-computed embeddings rather than end-to-end fine-tuning, potentially underrepresenting the model's true capabilities
- Limited comparison to specialized MSA-based models for evolutionary sequence classification tasks

## Confidence

- **High Confidence**: The architectural implementation and training methodology (ImageBind framework with pairwise contrastive learning) are clearly described and technically sound. The retrieval performance metrics are directly measured and reported.
- **Medium Confidence**: The claim that GNN encoders improve performance by capturing local structural features is supported by comparative results but lacks ablation studies that would definitively prove this mechanism over alternative explanations like increased model capacity.
- **Low Confidence**: The strongest claims about representational transfer from specialized encoders to the sequence encoder are based on indirect evidence (downstream performance improvements) rather than direct measurement of representational similarity or ablation studies isolating this specific effect.

## Next Checks

1. **Emergent Alignment Validation**: Design an experiment where you train ablations with only direct modality pairs (e.g., structure-text without sequence) and compare their cross-modal retrieval performance to OneProt. This would directly test whether the sequence anchor is necessary for emergent alignment.

2. **Representational Transfer Measurement**: Use centered kernel alignment (CKA) or similar metrics to directly measure representational similarity between the sequence encoder embeddings before and after multi-modal training. Compare these to baseline sequence-only models to quantify the transfer effect.

3. **GNN Contribution Isolation**: Create an ablation that replaces the GNN structure encoder with a token-based encoder (similar to SaProt) while keeping all other components identical. This would isolate whether the GNN architecture itself provides benefits beyond simply having two different structure representations.