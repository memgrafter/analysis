---
ver: rpa2
title: Learned denoising with simulated and experimental low-dose CT data
arxiv_id: '2408.08115'
source_url: https://arxiv.org/abs/2408.08115
tags:
- data
- noise
- noisy
- experimental
- simulated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the effectiveness of machine learning-based
  denoising algorithms trained on simulated noisy data versus experimental noisy data
  for low-dose CT imaging. Using the 2DeteCT dataset, two CNN architectures (U-Net
  and MSD-Net) were trained on both simulated and experimental noisy sinograms and
  evaluated in both sinogram and reconstruction domains.
---

# Learned denoising with simulated and experimental low-dose CT data

## Quick Facts
- arXiv ID: 2408.08115
- Source URL: https://arxiv.org/abs/2408.08115
- Reference count: 40
- Primary result: Training on experimental noisy data yields better results when applying algorithms to real-world experimental data

## Executive Summary
This study investigates the effectiveness of machine learning-based denoising algorithms for low-dose CT imaging, specifically comparing models trained on simulated noisy data versus experimental noisy data. Using the 2DeteCT dataset, two CNN architectures (U-Net and MSD-Net) were trained on both data types and evaluated in both sinogram and reconstruction domains. The research reveals that while sinogram denoising performs better with simulated noisy data in the sinogram domain, this advantage does not carry over to the reconstruction domain where experimental data training shows superior performance.

The study demonstrates that end-to-end training from sinogram to reconstruction significantly improves model performance for both architectures. Importantly, the results highlight that training on experimental noisy data yields better results when applying algorithms to real-world experimental data, emphasizing the importance of using realistic noise simulations or actual experimental data for training CT denoising algorithms. This finding has significant implications for the development of practical CT denoising systems.

## Method Summary
The study utilizes the 2DeteCT dataset containing 5,000 distinct image slices acquired in three modes: clean, noisy, and artifact-inflicted. Pre-processed beam intensity loss images (ILI) are derived from raw sinograms using dark-field and flat-field corrections. Simulated noisy data is generated from clean data using Poisson noise with parameter I0=200. The data is split into training (~80%), validation (~10%), and testing (~10%) sets.

Two CNN architectures, U-Net and MSD-Net, are trained on both simulated and experimental noisy data for 100 epochs using Adam optimization. Performance is evaluated using structural similarity (SSIM) and peak signal-to-noise ratio (PSNR) metrics in both sinogram and reconstruction domains. The study compares training in the sinogram domain versus end-to-end training from sinogram to reconstruction, with qualitative visual inspection of reconstructed images to assess denoising quality and artifact presence.

## Key Results
- Sinogram denoising performed better with simulated noisy data in the sinogram domain
- Performance advantage of simulated data did not carry over to reconstruction domain where experimental noisy data training showed higher performance
- End-to-end training from sinogram to reconstruction significantly improved model performance for both architectures
- Training on experimental noisy data yields better results when applying algorithms to real-world experimental data

## Why This Works (Mechanism)
The study demonstrates that machine learning models for CT denoising are highly sensitive to the characteristics of their training data. When models are trained on simulated noisy data, they learn to denoise based on the statistical properties of the noise model used in simulation. However, real experimental data contains additional complexities such as beam hardening, photon starvation artifacts, and other non-linear effects that are not captured by simple Poisson noise models. This mismatch between training and test conditions leads to suboptimal performance when models trained on simulated data are applied to experimental data.

The end-to-end training approach works effectively because it allows the model to learn an optimal mapping from noisy sinograms directly to clean reconstructions, rather than learning intermediate representations that may not be optimal for the final reconstruction task. This holistic approach enables the model to implicitly account for the non-linearities in the reconstruction process, leading to improved performance compared to separate sinogram denoising followed by reconstruction.

## Foundational Learning
1. **Sinogram representation in CT**: Sinograms are the raw projection data collected during CT scanning, representing the line integrals of X-ray attenuation through the object at various angles. Understanding sinogram structure is essential for CT denoising as it provides the direct input to reconstruction algorithms.

2. **Poisson noise in photon-limited imaging**: CT imaging with low-dose protocols suffers from photon starvation, leading to Poisson-distributed noise in the measured sinograms. This noise model is fundamental to understanding why low-dose CT requires denoising.

3. **CT reconstruction principles**: The process of converting sinogram data into cross-sectional images through algorithms like filtered back-projection or iterative reconstruction. This non-linear transformation is crucial for understanding why denoising performance can differ between sinogram and reconstruction domains.

4. **CNN architectures for image restoration**: U-Net and MSD-Net are specifically designed for image-to-image tasks with skip connections that preserve spatial information. These architectures are particularly suited for CT denoising due to their ability to capture both local and global image features.

5. **Domain adaptation challenges**: The performance gap between models trained on simulated versus experimental data illustrates fundamental challenges in domain adaptation, where the statistical properties of training and test data differ.

## Architecture Onboarding

**Component Map**: Raw sinograms -> Preprocessing (dark-field/flat-field correction) -> Beam Intensity Loss Images (ILI) -> Simulated/Experimental noisy data -> CNN model (U-Net/MSD-Net) -> Denoised sinograms/reconstructions

**Critical Path**: Noisy sinogram input → CNN processing → Denoised output (sinogram or reconstruction)

**Design Tradeoffs**: Training on simulated data offers better control and larger training sets but suffers from domain mismatch; training on experimental data provides realistic noise characteristics but may have limited data availability and introduces acquisition artifacts.

**Failure Signatures**: Poor generalization when training and test data distributions differ significantly; end-to-end training failure manifests as poor intermediate outputs before reconstruction.

**First Experiments**:
1. Train a simple U-Net on simulated noisy data and evaluate performance on both simulated and experimental test sets to establish baseline domain gap
2. Implement end-to-end training from sinogram to reconstruction and compare with separate denoising + reconstruction pipeline
3. Analyze the statistical differences between simulated and experimental noisy data distributions to quantify domain mismatch

## Open Questions the Paper Calls Out

**Open Question 1**: What specific beam hardening or photon starvation artifacts in experimental noisy data cannot be captured by the current noise simulation approach?
The paper explicitly states that the noise model assumes monochromatic sources and cannot simulate highly non-linear effects such as beam hardening or photon starvation artifacts. While the study identifies this limitation, it does not provide detailed characterization of which specific artifacts are missed or how significant their impact is on model performance. Systematic comparison of experimental noisy data containing known beam hardening/photon starvation artifacts with simulated data showing quantitative metrics of the differences and visual examples of the specific artifacts present would resolve this question.

**Open Question 2**: How would more sophisticated noise simulation approaches, such as generative models or simplified Monte Carlo particle simulations, affect the performance gap between models trained on simulated versus experimental noisy data?
The paper suggests that future work should investigate computationally efficient ways of including effects such as beam hardening or photon starvation, mentioning generative models or simplified Monte Carlo simulations as possibilities. However, the study only uses a simplified noise model and does not explore these alternative approaches, leaving the question of whether more sophisticated simulations could bridge the performance gap unanswered. Implementation and comparison of models trained on data generated using generative models or Monte Carlo simulations against models trained on experimental data, with performance metrics showing whether the gap has been reduced, would resolve this question.

**Open Question 3**: How does the performance of learned denoising algorithms vary across different types of image content (e.g., objects with varying attenuation levels, complex versus simple structures)?
While the paper mentions that there is a strong influence of the attenuation of objects on the similarity between reconstructions based on simulated and experimental data, and that qualitative analysis shows varying performance across different slices, it does not conduct a systematic analysis of how different image content types affect algorithm performance. Detailed analysis categorizing test images by object complexity and attenuation levels, with performance metrics showing how these factors correlate with denoising effectiveness across different model architectures and training data types, would resolve this question.

## Limitations
- The noise simulation model assumes monochromatic sources and cannot capture highly non-linear effects such as beam hardening or photon starvation artifacts
- The study does not explore more sophisticated noise simulation approaches that might bridge the performance gap between simulated and experimental data training
- Limited analysis of how algorithm performance varies across different types of image content and object characteristics

## Confidence

| Claim | Confidence |
|-------|------------|
| Training on experimental noisy data yields better results when applying algorithms to real-world experimental data | High |
| End-to-end training from sinogram to reconstruction significantly improves model performance | Medium |
| Specific performance metrics and quantitative comparisons | Medium |

## Next Checks

1. Replicate the study using the same 2DeteCT dataset with detailed architectural specifications for U-Net and MSD-Net to verify the quantitative performance differences between simulated and experimental data training approaches.

2. Conduct ablation studies to isolate the effects of end-to-end training versus separate sinogram denoising and reconstruction steps, using identical model architectures and training procedures.

3. Compare the noise distributions and feature statistics between simulated and experimental noisy data to quantify the degree of mismatch and correlate this with performance differences observed in the study.