---
ver: rpa2
title: 'VideoDPO: Omni-Preference Alignment for Video Diffusion Generation'
arxiv_id: '2412.14167'
source_url: https://arxiv.org/abs/2412.14167
tags:
- video
- quality
- alignment
- arxiv
- preference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VideoDPO, the first adaptation of Direct
  Preference Optimization (DPO) for video diffusion models. It addresses the problem
  of generating videos that align with user preferences by considering both visual
  quality and semantic alignment.
---

# VideoDPO: Omni-Preference Alignment for Video Diffusion Generation

## Quick Facts
- arXiv ID: 2412.14167
- Source URL: https://arxiv.org/abs/2412.14167
- Reference count: 40
- This paper introduces VideoDPO, the first adaptation of Direct Preference Optimization (DPO) for video diffusion models, showing substantial improvements in visual quality and semantic alignment.

## Executive Summary
This paper introduces VideoDPO, the first adaptation of Direct Preference Optimization (DPO) for video diffusion models. It addresses the problem of generating videos that align with user preferences by considering both visual quality and semantic alignment. The key innovation is the OmniScore, a comprehensive scoring system that evaluates videos across multiple dimensions. VideoDPO uses an automated pipeline to generate preference pair data and introduces a novel data reweighting strategy based on OmniScore. Experiments on three state-of-the-art text-to-video models show substantial improvements in both visual quality and semantic alignment, as measured by VBench, HPS (V), and PickScore.

## Method Summary
VideoDPO adapts the DPO framework to video diffusion models by introducing an automated pipeline for generating preference pair data. The method generates N=4 videos per prompt, evaluates them using OmniScore (a comprehensive scoring system combining multiple dimensions of video quality), selects the best-vs-worst pair for training, and applies OmniScore-based reweighting during DPO training. The approach is trained for 3000 steps with AdamW optimizer (lr=6e-6) on three base models: VideoCrafter2, T2V-Turbo, and CogVideo.

## Key Results
- Substantial improvements in VBench scores across all three base models (VideoCrafter2, T2V-Turbo, CogVideo)
- Significant gains in HPS (V) and PickScore metrics demonstrating better alignment with human preferences
- The OmniScore-based reweighting strategy (α=0.72, β=1) showed optimal performance compared to other configurations
- Best-vs-worst preference pair selection strategy outperformed other selection methods

## Why This Works (Mechanism)

### Mechanism 1
VideoDPO improves alignment by using OmniScore to evaluate both visual quality and semantic alignment simultaneously. OmniScore combines multiple sub-scores (aesthetic quality, subject consistency, motion smoothness, dynamic degree, overall consistency, and text-video semantic alignment) into a comprehensive preference score. This allows the model to learn from preference pairs that are distinctly better across multiple dimensions rather than optimizing for a single metric.

### Mechanism 2
The best-vs-worst preference pair selection strategy is more effective than other strategies for alignment learning. By selecting only the highest-scoring video as the positive sample and the lowest-scoring video as the negative sample, the model receives clear, high-contrast learning signals that are easier to optimize against than pairs with smaller quality differences.

### Mechanism 3
OmniScore-based reweighting improves learning efficiency by focusing training on the most informative preference pairs. Preference pairs with larger score differences (more distinctive pairs) are assigned higher weights during training, allowing the model to learn more effectively from these pairs rather than treating all pairs equally.

## Foundational Learning

- **Diffusion models and the denoising process**
  - Why needed here: VideoDPO operates on pre-trained video diffusion models, so understanding how they work is essential for implementing the alignment procedure
  - Quick check question: What is the purpose of the noise prediction model ϵθ in diffusion models?

- **Direct Preference Optimization (DPO) framework**
  - Why needed here: VideoDPO adapts the DPO framework specifically for video generation, so understanding the core DPO mechanism is crucial
  - Quick check question: How does DPO differ from traditional reinforcement learning approaches in terms of training stability?

- **Multi-dimensional evaluation metrics for video quality**
  - Why needed here: OmniScore relies on multiple evaluation dimensions, so understanding what each metric measures and how they interact is important for implementation
  - Quick check question: Why might subject consistency and aesthetic quality be only moderately correlated in video evaluation?

## Architecture Onboarding

- **Component map**: Pre-trained video diffusion model -> OmniScore evaluation pipeline -> Preference pair generation system -> Data reweighting module -> DPO training loop

- **Critical path**: Prompt → N video generation → OmniScore evaluation → Preference pair selection → Reweighting → DPO training update

- **Design tradeoffs**:
  - N vs. quality: Higher N generates more distinctive pairs but increases computational cost
  - α parameter: Higher α focuses more on distinctive pairs but may overfit to extreme examples
  - Score aggregation: Combining multiple dimensions improves robustness but adds complexity

- **Failure signatures**:
  - Low VBench scores despite training: Could indicate poor preference pair quality or inappropriate reweighting
  - Mode collapse: Could indicate over-reliance on reweighting or insufficient diversity in preference pairs
  - Slow convergence: Could indicate α is too low or N is too small

- **First 3 experiments**:
  1. Baseline alignment without reweighting (α=0) to establish baseline performance
  2. Sensitivity analysis of α parameter to find optimal reweighting strength
  3. Ablation study comparing best-vs-worst strategy against other pair selection methods

## Open Questions the Paper Calls Out

### Open Question 1
How does the OmniScore performance scale with increasing model complexity (e.g., larger ViT backbones, more dimensions)?
The paper uses existing models for different OmniScore dimensions but doesn't explore scaling them up or adding more dimensions. The authors used existing models as-is without exploring potential improvements from larger/more complex models.

### Open Question 2
What is the optimal balance between preference pair distinctiveness and dataset diversity for alignment performance?
The authors note that removing less-distinct pairs reduced performance, suggesting diversity is important, but don't determine the optimal balance. The paper shows removing pairs hurts performance but doesn't explore the tradeoff between distinctiveness and diversity systematically.

### Open Question 3
How does VideoDPO's alignment generalize to prompts outside the VidProm dataset distribution?
The authors use VidProm for training but don't test on out-of-distribution prompts. All experiments use prompts from VidProm, leaving open whether the alignment transfers to real-world, unseen prompts.

## Limitations
- Evaluation relies on automated metrics (VBench, HPS, PickScore) that may not fully capture human preferences for video quality
- The computational cost of generating N=4 videos per prompt and evaluating them with multiple sub-models is substantial
- Exact implementation details of the OmniScore components are not fully specified in the paper

## Confidence
- **High confidence**: The general framework of adapting DPO to video diffusion models is well-established and the experimental improvements over baselines are significant across multiple models and metrics
- **Medium confidence**: The OmniScore aggregation method and its specific weightings are reasonable but not extensively validated
- **Low confidence**: The exact implementation details of the OmniScore components are not fully specified in the paper

## Next Checks
1. Conduct an ablation analysis of individual OmniScore components to determine which dimensions contribute most to the observed improvements
2. Test VideoDPO on additional video diffusion models beyond the three used in the paper to verify that the improvements generalize across different architectures
3. Conduct a human evaluation study comparing the top-ranked videos from VideoDPO against baseline models to validate that the automated metrics align with human preferences