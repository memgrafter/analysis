---
ver: rpa2
title: Enhancing the Stability of LLM-based Speech Generation Systems through Self-Supervised
  Representations
arxiv_id: '2402.03407'
source_url: https://arxiv.org/abs/2402.03407
tags:
- speaker
- speech
- self-supervised
- codes
- reference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new approach to improve the stability of
  LLM-based speech generation systems. The key idea is to use self-supervised voice
  conversion (SSVC) to learn speaker-disentangled representations, separating transitory
  features like content from stationary ones like speaker ID.
---

# Enhancing the Stability of LLM-based Speech Generation Systems through Self-Supervised Representations

## Quick Facts
- arXiv ID: 2402.03407
- Source URL: https://arxiv.org/abs/2402.03407
- Reference count: 14
- Primary result: 4.7pp improvement in speaker similarity and 5.4pp lower WER using speaker-disentangled representations

## Executive Summary
This paper addresses the stability challenges in LLM-based speech generation systems by introducing a novel approach using self-supervised speaker-disentangled representations. The key innovation involves using WavLM hidden states split into speaker and non-speaker features, with the non-speaker features quantized and fed to an LLM for text-to-speech generation. This architecture allows the LLM to focus on generating content and style from text alone, while the decoder provides speaker identity, resulting in more stable and natural speech synthesis compared to entangled representations.

## Method Summary
The approach trains a Self-Supervised Voice Conversion (SSVC) model using WavLM hidden states, contrastive learning for speaker embeddings, and Residual Vector Quantization (RVQ) for quantizing non-speaker features. Two LLM variants are trained: one without reference embeddings (LSSL-NR) and one with reference encoder (LSSL-R). The system generates speech using a BigVGAN decoder conditioned on speaker embeddings and LLM-generated tokens. Training uses 44k hours of speech data with evaluations on LibriTTS test-other and test-clean datasets, measuring WER for intelligibility, speaker embedding cosine similarity (SECS) for speaker similarity, and MUSHRA tests for naturalness.

## Key Results
- 4.7pp improvement in speaker similarity over state-of-the-art entangled representations
- 5.4pp lower word error rate (WER) with speaker-disentangled representations
- 14pp increase in WER when using explicit reference embeddings compared to text-only prompting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-supervised speaker disentanglement reduces content hallucination and repetition.
- Mechanism: WavLM hidden states are split into speaker and non-speaker features via learnable weights; non-speaker features are quantized and fed to LLM, so LLM only predicts content and style, not speaker identity.
- Core assumption: Speaker identity can be fully captured in a separate embedding without losing naturalness.
- Evidence anchors:
  - [abstract] "allows the LLM to generate the content and the style of the speech only from the text, similarly to humans, while the speaker identity is provided by the decoder of the VC model"
  - [section] "Using speaker-disentangled codes to train LLMs for text-to-speech (TTS) allows the LLM to generate the content and the style of the speech only from the text, similarly to humans, while the speaker identity is provided by the decoder of the VC model"
- Break condition: If the speaker embedding cannot fully represent the source speaker, the decoder will produce inconsistent identity, causing speaker similarity to drop.

### Mechanism 2
- Claim: Masked language modeling on self-supervised tokens is easier than on raw audio codes.
- Mechanism: SSVC quantizes WavLM features that are already highly correlated, so LLM autoregressive prediction is more stable than predicting EnCodec entangled codes.
- Core assumption: Correlation among quantized tokens reduces prediction uncertainty for the LLM.
- Evidence anchors:
  - [section] "the causal language modeling task performed in LLMs is expected to be simpler when predicting these tokens than when predicting tokens with no enforced correlation, such as the ones coming from audio codecs like EnCodec or HiFi-Codec"
  - [section] "Results show that LLMs trained over speaker-disentangled self-supervised representations provide an improvement of 4.7pp in speaker similarity over SOTA entangled representations, and a word error rate (WER) 5.4pp lower"
- Break condition: If quantization destroys too much prosody information, WER will increase despite reduced entanglement.

### Mechanism 3
- Claim: Text-only prompting yields higher content stability than speech-prompting.
- Mechanism: Conditioning LLM solely on text removes variability introduced by reference embeddings, which can misrepresent speaker/style when out-of-distribution.
- Core assumption: Reference embeddings add noise to LLM generation more than they help stabilize speaker identity.
- Evidence anchors:
  - [abstract] "using explicit reference embedding negatively impacts intelligibility (stability), with WER increasing by 14pp compared to the model that only uses text to infer the style"
  - [section] "Text-prompting shows a significantly higher content stability than speech-prompting, as the WER is lower in all models, independently of the codes used or the presence of a reference embedding"
- Break condition: If the reference embedding is high quality and in-distribution, the WER penalty may shrink or vanish.

## Foundational Learning

- Concept: Self-supervised speech representation learning
  - Why needed here: Provides disentangled speaker vs. content features without labeled data.
  - Quick check question: Can WavLM features be split into speaker and non-speaker components via learnable linear regressors?

- Concept: Vector quantization for discrete audio tokens
  - Why needed here: Enables LLM to predict quantized codes instead of continuous spectrograms.
  - Quick check question: Does RVQ preserve enough prosodic detail after quantization?

- Concept: Contrastive learning for speaker embedding
  - Why needed here: Learns speaker identity embeddings without requiring speaker labels.
  - Quick check question: Does cosine similarity on contrastive embeddings correlate with human-perceived speaker similarity?

## Architecture Onboarding

- Component map: WavLM encoder (frozen) → speaker extractor + non-speaker extractor → contrastive loss + gradient reversal → RVQ → LLM decoder → BigVGAN decoder
- Critical path: WavLM hidden states → speaker embedding + quantized non-speaker tokens → LLM prediction → RVQ decode → BigVGAN reconstruction
- Design tradeoffs:
  - Speaker disentanglement reduces LLM burden but relies on decoder to faithfully reconstruct identity.
  - Text-only prompting improves stability but sacrifices explicit prosody control.
  - Higher RVQ codebook count improves reconstruction quality but increases compute.
- Failure signatures:
  - WER spikes when reference embedding is used.
  - Speaker similarity drops if contrastive loss underfits speaker separation.
  - Output speech quality degrades if RVQ quantization collapses prosody.
- First 3 experiments:
  1. Compare WER with and without reference embedding on held-out speakers.
  2. Vary RVQ codebook size and measure trade-off between quality and compute.
  3. Ablate contrastive loss weight to find optimal speaker vs. content disentanglement balance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal configuration for the self-supervised voice conversion (SSVC) model to achieve the best balance between speaker disentanglement, speech quality, and computational efficiency?
- Basis in paper: [explicit] The paper discusses the architecture of SSVC and its performance compared to the baseline FreeVC, but does not explore the optimal configuration for different aspects such as speaker disentanglement, speech quality, and computational efficiency.
- Why unresolved: The paper focuses on demonstrating the effectiveness of SSVC compared to the baseline, but does not delve into the optimal configuration for different aspects. This leaves room for further exploration and experimentation.
- What evidence would resolve it: Systematic experiments varying the configuration of SSVC, such as the number of codebooks, the size of the hidden states, and the trade-off between different losses, would provide insights into the optimal configuration for different aspects.

### Open Question 2
- Question: How does the performance of LLM-based TTS systems trained on speaker-disentangled representations compare to those trained on entangled representations in terms of stability, naturalness, and speaker similarity across different languages and datasets?
- Basis in paper: [explicit] The paper compares the performance of LLM-based TTS systems trained on speaker-disentangled representations with those trained on entangled representations, but the comparison is limited to a specific language (English) and dataset (LibriTTS).
- Why unresolved: The performance of TTS systems can vary across different languages and datasets due to differences in linguistic features, speaker characteristics, and recording conditions. Therefore, the generalizability of the findings needs to be investigated.
- What evidence would resolve it: Experiments comparing the performance of LLM-based TTS systems trained on speaker-disentangled representations with those trained on entangled representations across different languages and datasets would provide insights into the generalizability of the findings.

### Open Question 3
- Question: What are the potential applications and limitations of using speaker-disentangled representations in speech generation systems beyond TTS and voice conversion, such as in speech enhancement, emotion recognition, and speaker diarization?
- Basis in paper: [explicit] The paper discusses the potential applications of speaker-disentangled representations in TTS and voice conversion, but does not explore their potential applications in other speech-related tasks.
- Why unresolved: Speaker-disentangled representations have the potential to improve the performance of various speech-related tasks by providing a more robust and generalizable representation of speech. However, their effectiveness in these tasks needs to be investigated.
- What evidence would resolve it: Experiments applying speaker-disentangled representations to different speech-related tasks, such as speech enhancement, emotion recognition, and speaker diarization, would provide insights into their potential applications and limitations.

## Limitations

- The effectiveness of WavLM hidden states for disentanglement is assumed rather than empirically validated against alternative representations.
- The dramatic 14pp WER penalty from reference embeddings is presented without exploring whether this is due to embedding quality, distributional mismatch, or architectural issues.
- The evaluation datasets (LibriTTS test-other and test-clean) may not fully capture real-world variability in speaker characteristics and acoustic conditions.

## Confidence

- **High Confidence**: The core quantitative findings (WER improvements with disentangled representations, WER degradation with reference embeddings) are well-supported by experimental results.
- **Medium Confidence**: The proposed mechanism of reducing LLM burden through speaker disentanglement is plausible given the results, but alternative explanations (e.g., quantization effects, architectural differences) are not ruled out.
- **Low Confidence**: The claim that text-only prompting yields more stable content than speech-prompting is demonstrated through WER differences but lacks analysis of why reference embeddings specifically cause degradation.

## Next Checks

1. **Cross-dataset generalization test**: Evaluate the models on non-LibriTTS datasets (e.g., VCTK, Common Voice) to verify that the stability improvements generalize beyond the training domain.

2. **Ablation of quantization effects**: Compare performance using different quantization strategies (e.g., VQ-VAE, Gumbel-softmax) while keeping the disentanglement architecture fixed to isolate whether quantization or disentanglement drives improvements.

3. **Reference embedding quality analysis**: Systematically vary the quality and similarity of reference embeddings (using same-speaker vs. different-speaker references, high-quality vs. low-quality recordings) to determine whether the WER penalty stems from distributional mismatch or fundamental architectural limitations.