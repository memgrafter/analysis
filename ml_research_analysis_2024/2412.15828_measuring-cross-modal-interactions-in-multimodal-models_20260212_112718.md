---
ver: rpa2
title: Measuring Cross-Modal Interactions in Multimodal Models
arxiv_id: '2412.15828'
source_url: https://arxiv.org/abs/2412.15828
tags:
- modalities
- intershap
- dataset
- interactions
- cross-modal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces InterSHAP, a novel cross-modal interaction
  score that quantifies the contributions of individual modalities and their interactions
  in multimodal models. Unlike existing methods limited to two modalities or reliant
  on labeled data and model performance, InterSHAP uses the Shapley interaction index
  to precisely separate modality contributions from cross-modal interactions.
---

# Measuring Cross-Modal Interactions in Multimodal Models

## Quick Facts
- arXiv ID: 2412.15828
- Source URL: https://arxiv.org/abs/2412.15828
- Reference count: 40
- Key outcome: Introduces InterSHAP, a novel cross-modal interaction score using Shapley interaction index to quantify modality contributions and interactions without approximations or performance dependency

## Executive Summary
This paper presents InterSHAP, a novel method for quantifying cross-modal interactions in multimodal models using the Shapley Interaction Index (SII). Unlike existing approaches limited to two modalities or dependent on labeled data and model performance, InterSHAP provides a performance-agnostic framework that works with any number of modalities and unlabelled data. The method separates individual modality contributions from cross-modal interactions through exact Shapley value computation, providing both global and local explanations. Experimental validation on synthetic datasets demonstrates accurate measurement of cross-modal interactions, detecting 0% on datasets with no synergy and 99.7% on datasets with exclusive synergy.

## Method Summary
InterSHAP leverages the Shapley interaction index to quantify cross-modal interactions by computing marginal contributions across all possible modality coalitions. The method generates perturbed inputs through modality masking, computes model outputs for each coalition, and calculates Shapley interaction indices to separate individual modality contributions from interactions. It provides global explanations through aggregation across datasets and local explanations at individual sample level. The approach is performance-agnostic, working without labeled data by focusing on model behavior through input perturbations. InterSHAP integrates with the SHAP package for visualization and has computational complexity O(NM) where N is the number of samples and M is the number of modalities.

## Key Results
- InterSHAP accurately measures cross-modal interactions, achieving 0% interaction scores on datasets with no synergy and 99.7% on datasets with exclusive synergy
- Minimal cross-modal interactions detected (0.9%) in multimodal single-cell dataset for cell type classification
- Task-dependent interactions found in MIMIC-III dataset for mortality prediction, with interactions increasing as prediction horizon extends from 24 to 48 hours
- Successfully extends beyond XOR baseline to HD-XOR with early fusion achieving 0.74 F1 score

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: InterSHAP uses the Shapley Interaction Index (SII) to separate modality contributions from cross-modal interactions without approximations.
- **Mechanism**: The SII decomposes model behavior into individual modality contributions and pairwise interactions by measuring marginal contributions across all possible coalitions of modalities. This separation allows precise quantification of interactions independent of model performance.
- **Core assumption**: The Shapley interaction index can be directly adapted to measure cross-modal interactions without requiring approximations that would compromise accuracy.
- **Evidence anchors**:
  - [abstract]: "InterSHAP uses the Shapley interaction index to precisely separate and quantify the contributions of the individual modalities and their interactions without approximations."
  - [section 3.2]: "To isolate interactions from the model behaviour, we apply the SII."
  - [corpus]: Weak evidence - no direct citations to Shapley interaction index applications in multimodal contexts found.
- **Break condition**: If the Shapley interaction index cannot be computed exactly for more than two modalities due to computational complexity, approximations would be required, potentially compromising the separation of interactions from individual contributions.

### Mechanism 2
- **Claim**: InterSHAP provides both global (dataset-level) and local (sample-level) explanations by aggregating Shapley values appropriately.
- **Mechanism**: For global explanations, InterSHAP averages absolute Shapley interaction values across all samples to capture overall interaction strength. For local explanations, it computes interactions per sample and aggregates to maintain individual-level interpretability.
- **Core assumption**: Aggregating Shapley values across samples preserves meaningful interaction information while maintaining interpretability at different levels.
- **Evidence anchors**:
  - [abstract]: "can handle multiple modalities, and provides detailed explanations at a local level for individual samples."
  - [section 3.4]: "To determine if InterSHAP is effective at the level of all individual data points, we aggregate Ia across the entire dataset to obtain the local interaction score for the dataset as a whole."
  - [corpus]: Weak evidence - limited corpus support for local Shapley value aggregation in multimodal settings.
- **Break condition**: If individual sample interactions vary wildly due to masking errors, local aggregation may produce misleading results that don't reflect true interaction patterns.

### Mechanism 3
- **Claim**: InterSHAP is performance-agnostic and works with unlabelled data by focusing on model behavior rather than prediction accuracy.
- **Mechanism**: Instead of measuring interaction effects through performance changes, InterSHAP directly measures how much of the model's output changes can be attributed to cross-modal interactions by examining perturbations in input modalities.
- **Core assumption**: Cross-modal interactions can be meaningfully quantified without reference to ground truth labels or model performance metrics.
- **Evidence anchors**:
  - [abstract]: "is agnostic to model performance, and works with unlabelled data."
  - [section 1]: "certain methods assess interactions solely based on performance gain, rendering them highly performance-dependent."
  - [section 4.2]: "InterSHAP operates performance-agnostic, as only random performance could be achieved on this dataset."
  - [corpus]: No direct evidence found in corpus for performance-agnostic interaction measurement approaches.
- **Break condition**: If model behavior is dominated by random noise rather than meaningful interactions, performance-agnostic measurement may still capture spurious interactions that aren't interpretable.

## Foundational Learning

- **Shapley value theory**
  - Why needed here: Understanding how Shapley values decompose contributions in cooperative game theory is essential for grasping how InterSHAP measures modality contributions.
  - Quick check question: Can you explain why the Shapley value formula includes the factorial terms and how they weight marginal contributions?

- **Cross-modal interaction concepts**
  - Why needed here: Distinguishing between additive modality contributions and non-additive interactions is fundamental to understanding what InterSHAP measures.
  - Quick check question: What's the difference between a dataset with synergy versus one with redundancy, and how would InterSHAP scores differ?

- **Masking strategies in XAI**
  - Why needed here: InterSHAP uses input perturbations/masking to measure marginal contributions, so understanding different masking approaches is crucial.
  - Quick check question: What are the tradeoffs between replacing modalities with random noise versus using data from other samples for masking?

## Architecture Onboarding

- **Component map**: Input layer -> Masking module -> Model evaluation -> Shapley computation -> Aggregation layer -> SHAP integration
- **Critical path**:
  1. Load model and input data
  2. Generate all modality coalitions through masking
  3. Compute model outputs for each coalition
  4. Calculate Shapley interaction indices
  5. Aggregate to obtain InterSHAP scores
  6. Visualize using SHAP package
- **Design tradeoffs**:
  - Computational complexity vs. exact measurement: Exact Shapley values require exponential computation but provide precise separation of interactions
  - Performance agnosticism vs. practical utility: Measuring all interactions regardless of performance may capture noise but provides complete understanding
  - Global vs. local explanations: Global scores provide dataset-level insights while local scores enable individual sample explanations
- **Failure signatures**:
  - Extremely low or high scores across all samples may indicate masking issues or dataset problems
  - Inconsistent local scores with stable global scores suggest high variance in individual interactions
  - Zero interactions in synergy datasets indicate implementation errors or masking problems
- **First 3 experiments**:
  1. Run InterSHAP on XOR function with two modalities (uniqueness vs synergy) to verify expected 0% vs 100% interaction scores
  2. Apply InterSHAP to FCNN on HD-XOR dataset with early fusion to test scalability beyond the XOR baseline
  3. Compute both global and local InterSHAP scores on synthetic dataset to validate aggregation approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can InterSHAP be effectively extended to quantify interactions in datasets with more than two modalities, particularly in synergy settings where information is distributed across multiple modalities?
- Basis in paper: [inferred] The paper notes that for synergy datasets with more than two modalities, the HD-XOR datasets no longer contain maximum synergy due to the XOR function's definition, and F1 scores decrease as the number of modalities increases, suggesting the synergy present is not fully learned.
- Why unresolved: The paper could not clearly demonstrate that InterSHAP functions as intended for synergy datasets with more than two modalities, leaving uncertainty about its effectiveness in such scenarios.
- What evidence would resolve it: Empirical results showing InterSHAP values for synergy datasets with three or more modalities that accurately reflect the expected synergy, along with consistent F1 scores across different numbers of modalities.

### Open Question 2
- Question: How does the computational complexity of InterSHAP scale with the number of modalities, and are there approximation methods that could mitigate the exponential growth in runtime?
- Basis in paper: [explicit] The paper states that InterSHAP has a computational complexity of O(NM), where N is the number of samples and M is the number of modalities, and notes that this leads to exponential growth with increasing modalities.
- Why unresolved: While the paper mentions the computational challenge, it does not explore approximation methods or their potential impact on the accuracy of InterSHAP.
- What evidence would resolve it: Experimental results comparing InterSHAP's accuracy and runtime with and without approximation methods, demonstrating whether approximations can maintain accuracy while reducing computational cost.

### Open Question 3
- Question: What alternative interaction measures, beyond the Shapley Interaction Index, could be applied to quantify cross-modal interactions in datasets with more than two modalities?
- Basis in paper: [explicit] The paper suggests that future research could explore alternative interaction measures, such as Faith-SHAP or the Shapley-Taylor Interaction Index, to overcome limitations of the SII.
- Why unresolved: The paper does not provide empirical comparisons of these alternative measures with InterSHAP, leaving their effectiveness untested.
- What evidence would resolve it: Comparative studies evaluating the performance of InterSHAP against alternative interaction measures like Faith-SHAP and Shapley-Taylor Interaction Index on synthetic and real-world datasets with multiple modalities.

## Limitations
- Computational complexity grows exponentially with number of modalities, limiting practical applications to small modality sets
- Masking strategy for local explanations is not thoroughly validated and may produce misleading results if individual sample interactions vary dramatically
- Performance-agnostic approach may capture spurious interactions from random noise rather than meaningful cross-modal synergies

## Confidence

**High confidence**: The core mechanism of using Shapley interaction indices to separate modality contributions from interactions is theoretically sound and well-established in cooperative game theory. The distinction between global and local explanations follows standard XAI practices.

**Medium confidence**: The performance-agnostic approach is conceptually valid, but the paper doesn't adequately address potential false positives from noise or random interactions. The comparison with existing methods (PID, EMAP, SHAPE) shows superiority on synthetic data but lacks comprehensive validation on real-world datasets.

**Low confidence**: The assumption that aggregation of local Shapley values preserves meaningful interaction information is not empirically validated. The paper doesn't explore edge cases where individual sample interactions might vary dramatically, potentially leading to misleading global scores.

## Next Checks

1. **Scalability test**: Apply InterSHAP to a dataset with 5+ modalities to measure actual runtime and memory requirements, comparing against the theoretical exponential complexity.

2. **Masking sensitivity analysis**: Run InterSHAP with different masking strategies (random noise, sample replacement, zero masking) on the same dataset and measure variance in interaction scores to assess robustness.

3. **Noise floor characterization**: Generate synthetic datasets with varying levels of random noise and measure how InterSHAP scores change to establish baselines for distinguishing meaningful interactions from spurious correlations.