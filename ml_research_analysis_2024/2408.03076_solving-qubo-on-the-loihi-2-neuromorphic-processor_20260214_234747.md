---
ver: rpa2
title: Solving QUBO on the Loihi 2 Neuromorphic Processor
arxiv_id: '2408.03076'
source_url: https://arxiv.org/abs/2408.03076
tags:
- loihi
- qubo
- problems
- neuromorphic
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a neuromorphic algorithm for solving quadratic
  unconstrained binary optimization (QUBO) problems on Intel's Loihi 2 chip. The method
  is based on a hardware-aware parallel simulated annealing approach that leverages
  Loihi 2's integrated memory-compute architecture and massive parallelism to efficiently
  explore solution spaces.
---

# Solving QUBO on the Loihi 2 Neuromorphic Processor

## Quick Facts
- arXiv ID: 2408.03076
- Source URL: https://arxiv.org/abs/2408.03076
- Authors: Alessandro Pierro; Philipp Stratmann; Gabriel Andres Fonseca Guerra; Sumedh Risbud; Timothy Shea; Ashish Rao Mangalore; Andreas Wild
- Reference count: 40
- One-line primary result: Neuromorphic QUBO solver on Loihi 2 achieves 37x power reduction and 1ms solutions for 1000-variable problems

## Executive Summary
This paper introduces a neuromorphic algorithm for solving quadratic unconstrained binary optimization (QUBO) problems on Intel's Loihi 2 chip. The method is based on a hardware-aware parallel simulated annealing approach that leverages Loihi 2's integrated memory-compute architecture and massive parallelism to efficiently explore solution spaces. For maximum independent set problems up to 1000 variables, the approach achieves solutions within 1 ms and consumes 37x less power than state-of-the-art CPU solvers.

## Method Summary
The algorithm implements a hardware-aware parallel simulated annealing approach using spiking neural networks on Loihi 2. The QUBO problem is encoded in a SNN architecture where variable neurons maintain candidate solutions, connected through a synaptic layer that encodes off-diagonal elements of the Q matrix. A cost integrator sums local contributions to obtain the total QUBO cost. The algorithm uses integer approximations of the Metropolis criterion to enable efficient evaluation on Loihi 2 neuro-cores, along with stochastic refractory periods to control parallelization while mitigating solution degradation from simultaneous updates.

## Key Results
- Achieves solutions within 1 ms for MIS problems up to 1000 variables
- Consumes 37x less power than state-of-the-art CPU solvers
- Maintains solution quality through stochastic refractory periods while enabling parallelization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Loihi 2's integrated memory-compute architecture enables fine-grained parallel updates without the memory bandwidth bottlenecks seen in CPU/GPU solvers.
- Mechanism: Each Loihi 2 neurocore has its own local memory, allowing neurons to access and update their states locally without expensive global memory transfers. This reduces the time and energy cost of data movement during iterative updates.
- Core assumption: The QUBO problem structure allows for efficient local computation and sparse communication between neurons.
- Evidence anchors:
  - [abstract]: "leverages Loihi 2's integrated memory-compute architecture and massive parallelism"
  - [section]: "Each neurocore is equipped with its own integrated memory, so that each neuron is equipped with its own local memory that allows quick and efficient iterative updates of neuronal states."
- Break condition: If the QUBO problem becomes too dense or the communication patterns become too complex, the local memory advantage may be lost.

### Mechanism 2
- Claim: The stochastic refractory period introduces controlled non-equilibrium dynamics that accelerate convergence while mitigating the parallelization-induced solution degradation.
- Mechanism: After a neuron flips its state, it enters a random refractory period during which it cannot flip again. This reduces the number of simultaneous updates per step, addressing the issue where parallel updates can worsen the solution due to interaction terms Qij.
- Core assumption: The distribution of refractory periods can be tuned to balance parallelization speed-up against solution quality.
- Evidence anchors:
  - [section]: "we introduce a stochastic refractory period, preventing neurons from repeatedly flipping variables in successive steps."
  - [section]: "The distribution of duration of the refractory period can be tuned to explicitly control the level of parallelization"
- Break condition: If the refractory periods are too long, the parallelization benefit is lost and the algorithm becomes effectively sequential.

### Mechanism 3
- Claim: The integer approximation of the Metropolis criterion enables efficient evaluation on Loihi 2 neuro-cores without requiring unsupported operations like exponentiation and division.
- Mechanism: The switching condition is transformed using base-2 logarithm and the count-leading-zeros (clz) function, which are supported on Loihi 2. This allows the Metropolis criterion to be evaluated using only integer operations.
- Core assumption: The integer approximation of the logarithm and the switching condition is sufficiently accurate for the SA algorithm to function properly.
- Evidence anchors:
  - [section]: "we introduce an integer approximation to evaluate the stochastic switching condition."
  - [section]: "The condition can be further simplified using the count leading zero(clz) function. This operation, which is supported by Loihi 2, counts the number of left-most zeros in the binary representation of a number, which approximates the logarithm in base 2."
- Break condition: If the integer approximation introduces too much error, the SA algorithm may fail to converge to good solutions.

## Foundational Learning

- Concept: Quadratic Unconstrained Binary Optimization (QUBO)
  - Why needed here: The entire paper is about solving QUBO problems on neuromorphic hardware.
  - Quick check question: What is the mathematical form of a QUBO problem, and what are some real-world applications?

- Concept: Simulated Annealing (SA)
  - Why needed here: The proposed algorithm is a hardware-aware parallel simulated annealing approach.
  - Quick check question: How does the Metropolis criterion work in SA, and what is the role of the temperature parameter?

- Concept: Spiking Neural Networks (SNNs)
  - Why needed here: The algorithm is implemented as an SNN on the Loihi 2 neuromorphic processor.
  - Quick check question: How do spiking neurons differ from traditional artificial neurons, and what are the advantages of SNNs for certain computational tasks?

## Architecture Onboarding

- Component map: Variable neurons -> Synaptic layer -> Cost integrator -> Variable neuron updates
- Critical path: Variable neurons → Synaptic layer → Cost integrator → Variable neuron updates
- Design tradeoffs:
  - Precision vs. efficiency: Using 8-bit integer coefficients vs. higher precision
  - Parallelism vs. accuracy: Stochastic refractory periods control the level of parallelization
  - Algorithmic simplicity vs. hardware optimization: Integer approximation of Metropolis criterion
- Failure signatures:
  - Poor solution quality: May indicate issues with the SA algorithm implementation or hardware limitations
  - High energy consumption: May indicate inefficient use of Loihi 2's integrated memory-compute architecture
  - Slow convergence: May indicate issues with the annealing schedule or the stochastic refractory period
- First 3 experiments:
  1. Implement a basic SA algorithm on Loihi 2 for small QUBO problems without parallelization.
  2. Add parallelization with stochastic refractory periods and evaluate the tradeoff between speed and solution quality.
  3. Implement the integer approximation of the Metropolis criterion and compare its performance to a floating-point implementation on CPU.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the maximum problem size that can be solved on a single Loihi 2 chip with the current implementation, and what are the key bottlenecks preventing scaling to larger problems (e.g., 1 million variables)?
- Basis in paper: [explicit] "But in its current implementation, the solver is not capable of scaling up to very large-scale problems (e.g. up to 1M variables) due to limitations in the synaptic encoding and transmission of messages in multi-chip networks on Loihi 2."
- Why unresolved: The paper mentions limitations but does not provide specific numbers or detailed analysis of the bottlenecks.
- What evidence would resolve it: Experimental results showing performance scaling with problem size, analysis of memory and communication constraints on Loihi 2, and proposed solutions for overcoming these limitations.

### Open Question 2
- Question: How does the performance of the neuromorphic QUBO solver compare to quantum annealers like D-Wave's system for problems where both can be applied?
- Basis in paper: [explicit] "Finally, future work should evaluate the performance of our algorithm against QUBO-specific accelerators, such as those based on FPGAs [13, 15, 16, 17, 18], application-specific CMOS [19, 20], analogue hardware [21, 22], and D-Wave’s Quantum Annealer [23, 24]."
- Why unresolved: The paper only mentions this as future work without providing any comparative results.
- What evidence would resolve it: Direct benchmarking results comparing the Loihi 2 solver against D-Wave quantum annealer on identical QUBO problem sets, including metrics for solution quality, time-to-solution, and energy consumption.

### Open Question 3
- Question: How does the algorithm's performance vary across different types of QUBO problems beyond maximum independent set problems, and what characteristics of QUBO problems (e.g., landscape roughness, number of near-optimal solutions) most strongly influence performance?
- Basis in paper: [explicit] "In additional testing, we observe that many other QUBO problems possess significantly greater complexity than MIS, as expressed in the roughness of the QUBO cost landscape and in the number of acceptably near-optimal solutions in the search space. Additional research should extend these initial benchmarks to a broader representation of real-world applications to properly understand the performance benefits of our approach."
- Why unresolved: The paper only tests on MIS problems and mentions this as a limitation without providing systematic analysis of other QUBO problem types.
- What evidence would resolve it: Comprehensive benchmarking results across diverse QUBO problem families (e.g., TSP, portfolio optimization, graph partitioning) with analysis of correlations between problem characteristics and solver performance.

## Limitations
- Current implementation cannot scale to very large-scale problems (e.g., 1M variables) due to synaptic encoding and multi-chip communication limitations
- Only tested on maximum independent set problems, not other QUBO problem types
- Performance compared only against CPU solvers, not quantum annealers or FPGA-based accelerators

## Confidence
- Loihi 2 architectural advantages: **High** - Well-documented in Intel's technical literature
- Energy efficiency gains vs CPU: **Medium** - Performance data provided but limited comparison scope
- Solution quality preservation under parallelization: **Medium** - Demonstrated for tested problem sizes but scalability unknown

## Next Checks
1. **Accuracy benchmarking**: Systematically evaluate solution quality degradation as refractory period length increases to quantify the parallelization accuracy trade-off.

2. **Density scaling study**: Test the algorithm on QUBO problems with edge densities >30% to identify communication/compute bottlenecks that may eliminate Loihi 2's local memory advantages.

3. **Integer approximation validation**: Compare the integer-based Metropolis criterion against floating-point implementations across a range of temperature values to establish error bounds and identify failure conditions.