---
ver: rpa2
title: Can LLMs Generate Visualizations with Dataless Prompts?
arxiv_id: '2406.17805'
source_url: https://arxiv.org/abs/2406.17805
tags:
- data
- visualization
- queries
- chart
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether large language models (LLMs) can
  generate accurate visualizations from dataless prompts, where users provide queries
  without accompanying data. The study compares GPT-3.5, GPT-4, and DALL-E using prompts
  for public data visualizations.
---

# Can LLMs Generate Visualizations with Dataless Prompts?

## Quick Facts
- arXiv ID: 2406.17805
- Source URL: https://arxiv.org/abs/2406.17805
- Reference count: 16
- GPT-4 can generate appropriate visualizations from dataless prompts, matching expert guidelines for chart selection

## Executive Summary
This paper investigates whether large language models can generate accurate visualizations from dataless prompts, where users provide queries without accompanying data. The study compares GPT-3.5, GPT-4, and DALL-E using prompts for public data visualizations. GPT-4 demonstrated the ability to generate appropriate visualizations and correctly match chart types to data scenarios according to visualization expert guidelines, achieving perfect alignment with a standard visualization cheat sheet. However, while GPT-4 accurately represented data trends, it often provided inconsistent numerical values compared to ground truth data from Google Images.

## Method Summary
The study used 15 prompts based on popular data visualizations from Google Images, including 7 prompts from chart types found on Google Images and 8 crowd-sourced prompts from graduate students. GPT-4 was used to generate visualizations for each prompt, which were then evaluated by comparing them to visualization cheat sheets created by experts and human-generated charts from Google Images. The evaluation focused on chart type appropriateness and data trend accuracy.

## Key Results
- GPT-4 correctly matched chart types to data scenarios according to visualization expert guidelines
- GPT-4 achieved perfect alignment with a standard visualization cheat sheet
- While GPT-4 accurately represented data trends, it often provided inconsistent numerical values compared to ground truth data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can generate appropriate visualizations from dataless prompts by leveraging its pre-training on web-scale data that includes both public datasets and visualization examples.
- Mechanism: The model maps natural language queries to both the relevant data patterns and the correct visualization type based on learned correlations between query topics and chart formats.
- Core assumption: GPT-4's training corpus included sufficient examples of public data queries paired with their corresponding visualizations.
- Evidence anchors:
  - [abstract] states GPT-4 "demonstrated the ability to generate appropriate visualizations and correctly match chart types to data scenarios according to visualization expert guidelines"
  - [section 3.3.2] confirms "every chart generated was appropriate" when compared to the visualization cheat sheet
  - [corpus] shows related work on LLM-based visualization generation, supporting the feasibility of this approach
- Break condition: If the query domain is too specialized or the relevant data patterns weren't well-represented in the training corpus, GPT-4 would fail to generate appropriate visualizations.

### Mechanism 2
- Claim: GPT-4 learned visualization design rules from its training data, allowing it to follow expert guidelines for chart selection.
- Mechanism: The model internalized visualization conventions through exposure to numerous professionally-designed charts during training, enabling it to apply these rules to new queries.
- Core assumption: The training data included enough high-quality, expert-created visualizations that GPT-4 could extract and generalize the underlying design principles.
- Evidence anchors:
  - [abstract] notes GPT-4 "correctly match chart types to data scenarios according to visualization expert guidelines"
  - [section 4] states GPT-4 "has been an excellent 'student' of the art and science of data visualization, having learned an impressive amount of visualization knowledge from its 'teachers'"
  - [corpus] references visualization cheat sheets and expert guidelines used for evaluation
- Break condition: If the training data contained predominantly poor or inconsistent visualization examples, GPT-4 might internalize incorrect design principles.

### Mechanism 3
- Claim: GPT-4 can approximate data trends even without access to exact datasets, by generating plausible values that follow the general pattern of the underlying data.
- Mechanism: The model uses its understanding of typical data distributions and relationships to create synthetic data that matches the expected shape and trend of real data for the given query.
- Core assumption: GPT-4's training included enough examples of similar data patterns that it can generate reasonable approximations for new queries.
- Evidence anchors:
  - [section 3.3.2] notes "While GPT-4 accurately represented data trends, it often provided inconsistent numerical values compared to ground truth data"
  - [section 4] acknowledges "While the visualizations so produced are not perfect in every detail, they nevertheless indicate that GPT-4 has obtained a sufficient amount of data knowledge"
  - [corpus] shows related work on text-to-visualization, suggesting this approximation approach is viable
- Break condition: If the query requires precise numerical values or the data pattern is too unusual or specialized, GPT-4's approximations would be inadequate.

## Foundational Learning

- Concept: Data visualization principles and chart selection guidelines
  - Why needed here: Understanding why certain chart types are appropriate for specific data scenarios is crucial for evaluating GPT-4's visualization outputs
  - Quick check question: What chart type would you use to show the relationship between two continuous variables, and why?

- Concept: Natural language processing and query understanding
  - Why needed here: GPT-4 must correctly interpret the intent behind dataless prompts to generate appropriate visualizations
  - Quick check question: How would you distinguish between a query asking for "trends over time" versus "comparisons between categories" in terms of appropriate chart selection?

- Concept: Visualization evaluation and comparison methodologies
  - Why needed here: The paper uses expert guidelines (visualization cheat sheets) to evaluate the quality of generated charts
  - Quick check question: What criteria would you use to determine if a bar chart is the appropriate visualization for a given dataset and query?

## Architecture Onboarding

- Component map: User query -> Prompt engineering -> GPT-4 generation -> Output evaluation -> Result delivery
- Critical path: User query → Prompt engineering → GPT-4 generation → Output evaluation → Result delivery
- Design tradeoffs: Using dataless prompts sacrifices precision (exact numerical values) for accessibility (no need to find datasets first), while relying on GPT-4's approximations introduces potential inaccuracies but enables rapid visualization generation.
- Failure signatures: Incorrect chart type selection, implausible data values, missing data elements, or failure to generate any visualization output.
- First 3 experiments:
  1. Test GPT-4 with simple, well-defined prompts from the cheat sheet categories to verify basic functionality
  2. Compare GPT-4's chart type selection against the cheat sheet for a variety of data scenarios
  3. Evaluate the accuracy of generated data values by comparing trends against known datasets for the same queries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs reliably generate accurate numerical data values from dataless prompts across different domains and query types?
- Basis in paper: [explicit] The paper notes that while GPT-4 accurately represents data trends, it often provides inconsistent numerical values compared to ground truth data, particularly in line charts where values were not identical and trends were only correct at a larger scale.
- Why unresolved: The study only tested 15 prompts across a limited set of visualization types (line charts, bar charts). The inconsistency in numerical values suggests this may be a systematic limitation rather than an isolated issue, but the scope was too narrow to determine if this is domain-specific or a general limitation.
- What evidence would resolve it: A comprehensive study testing dataless prompts across diverse domains (economics, health, sports, etc.) with various chart types and larger sample sizes, comparing generated values against multiple ground truth datasets to determine consistency patterns.

### Open Question 2
- Question: What is the source of the data that LLMs use when generating visualizations from dataless prompts, and how current is this data?
- Basis in paper: [explicit] The paper observes that GPT-4 "appeared to retrieve data from a different year" when generating visualizations, and that models "provided mock data values or pointers to publicly available data," but doesn't investigate where exactly the data comes from.
- Why unresolved: The paper doesn't trace the origin of the data used by LLMs. It's unclear whether the models are accessing real-time data sources, cached data from their training corpus, or generating plausible but fabricated values.
- What evidence would resolve it: Analysis of the temporal patterns in generated data values across prompts about time-series data, comparison with known data sources and their update frequencies, and investigation into whether models can be prompted to specify data sources and timeframes.

### Open Question 3
- Question: Can LLMs be effectively combined with data retrieval mechanisms to produce accurate visualizations from dataless prompts?
- Basis in paper: [explicit] The paper mentions this as a current line of work: "identifying effective mechanisms for LLMs to pull CSV files on its own from the respective online repositories, followed by running the code that generates the appropriate visualizations."
- Why unresolved: The paper only hints at this possibility but doesn't explore it experimentally. The current limitation of inaccurate numerical values suggests that pure LLM generation may be insufficient.
- What evidence would resolve it: Experimental comparison of visualizations generated purely by LLMs versus those produced when LLMs are augmented with automated data retrieval and validation systems, measuring accuracy improvements and any trade-offs in response time or user experience.

### Open Question 4
- Question: How generalizable is GPT-4's demonstrated visualization knowledge to other LLM architectures and to models beyond the GPT family?
- Basis in paper: [explicit] The paper compares GPT-4 favorably to GPT-3.5 and DALL-E, finding that "GPT-4 was the only model that could respond with an appropriate image or chart," but doesn't test whether this capability extends to other LLMs.
- Why unresolved: The study is limited to three specific models. While GPT-4 showed strong performance, it's unclear whether this reflects the state of the art for LLMs in general or specific characteristics of the GPT architecture.
- What evidence would resolve it: Systematic testing of multiple LLM architectures (Claude, Gemini, LLaMA, etc.) with identical prompt sets, evaluating their ability to generate appropriate visualizations and match expert guidelines, to determine if visualization knowledge is architecture-dependent or a broader LLM capability.

## Limitations
- The study's findings are based on a relatively small sample of 15 prompts, which may not represent the full range of visualization needs users might have.
- While GPT-4 showed strong performance in chart type selection, the generated numerical values often deviated from ground truth data, raising questions about reliability for precise analytical tasks.
- The study did not evaluate the usability of generated visualizations from an end-user perspective, focusing instead on technical accuracy against expert guidelines.

## Confidence
- **High confidence**: GPT-4 can correctly match chart types to data scenarios according to visualization expert guidelines
- **Medium confidence**: GPT-4 can generate visualizations from dataless prompts that approximate data trends, despite numerical inconsistencies
- **Low confidence**: The generated visualizations are suitable for precise analytical tasks requiring exact numerical values

## Next Checks
1. Scale up prompt diversity: Test GPT-4 with a larger and more diverse set of 50+ prompts spanning various domains and complexity levels to assess the generalizability of the findings beyond the initial 15 prompts.

2. Quantitative accuracy assessment: Develop a rigorous methodology to quantify the numerical accuracy of generated visualizations by comparing them against multiple ground truth datasets, measuring both trend accuracy and value precision using statistical metrics.

3. User-centered evaluation: Conduct a user study with visualization practitioners to evaluate the usability, interpretability, and practical utility of the generated visualizations, including task completion rates and user satisfaction scores.