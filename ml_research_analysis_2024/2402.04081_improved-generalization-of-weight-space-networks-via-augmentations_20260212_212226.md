---
ver: rpa2
title: Improved Generalization of Weight Space Networks via Augmentations
arxiv_id: '2402.04081'
source_url: https://arxiv.org/abs/2402.04081
tags:
- weight
- space
- mixup
- neural
- augmentations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses overfitting in deep weight space models, where
  neural networks process the weights of other networks. The authors find that a key
  issue is the lack of diversity in datasets, as each object can be represented by
  many different weight configurations (neural views) but datasets typically use only
  a single view per object.
---

# Improved Generalization of Weight Space Networks via Augmentations

## Quick Facts
- **arXiv ID**: 2402.04081
- **Source URL**: https://arxiv.org/abs/2402.04081
- **Reference count**: 24
- **Primary result**: Weight space-specific data augmentations improve generalization by up to 18%, equivalent to using 10 times more training data

## Executive Summary
This paper addresses overfitting in deep weight space models, where neural networks process the weights of other networks. The authors identify that a key issue is the lack of diversity in datasets, as each object can be represented by many different weight configurations (neural views) but datasets typically use only a single view per object. To improve generalization, they propose weight space-specific data augmentation techniques, including a MixUp method adapted for weight spaces that handles permutation symmetries. They conduct experiments on implicit neural representation (INR) classification tasks using grayscale images (FMNIST), color images (CIFAR10), and 3D shapes (ModelNet40), demonstrating significant accuracy improvements with their augmentation methods.

## Method Summary
The authors propose weight space-specific data augmentation techniques to improve generalization in deep weight space models. They introduce several augmentation methods including input space transforms (translation, rotation, scaling), data-agnostic augmentations (masking, Gaussian noise), neural network-specific augmentations exploiting activation function symmetries, and MixUp variants adapted for weight spaces. The key innovation is an alignment-based MixUp that addresses permutation symmetries by optimally aligning weight vectors before interpolation. They evaluate these methods on INR classification tasks using DWS and GNN architectures, comparing performance with and without augmentations across multiple datasets and training scenarios.

## Key Results
- Weight space models trained on 10 views per object achieve better generalization than those trained on single views
- Alignment-based MixUp consistently outperforms other augmentation methods, improving accuracy by up to 18%
- In self-supervised contrastive learning, augmentations yield 5-10% gains in downstream classification accuracy
- The proposed augmentations improve performance similarly to having up to 10 times more training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multiple neural views per object improve generalization by exposing the model to diverse weight configurations representing the same underlying object.
- Mechanism: Weight space models trained on multiple views learn to map varied neural representations to the same semantic class, effectively increasing training data diversity without increasing unique objects.
- Core assumption: Different weight configurations (neural views) represent the same object but have distinct statistical properties that benefit the model's learning process.
- Evidence anchors:
  - [abstract]: "While a given object can be represented by many different weight configurations, typical INR training sets fail to capture variability across INRs that represent the same object."
  - [section 3]: "models trained on a single view...start substantially overfitting after only 5 − 10% of training iterations. In contrast, models trained on 10 views per object...suffer from less overfitting and generalize better."
  - [corpus]: No direct corpus evidence found.

### Mechanism 2
- Claim: Weight space MixUp with alignment mitigates overfitting by creating convex combinations of weight vectors that preserve low-loss intermediate states.
- Mechanism: By aligning weight vectors before interpolation (solving permutation symmetry problem), the MixUp produces new weight configurations that maintain functional similarity to originals, thus enriching training distribution.
- Core assumption: Aligned weight vectors have low linear mode connectivity, meaning their interpolations remain in low-loss regions of loss landscape.
- Evidence anchors:
  - [abstract]: "they propose a MixUp method adapted for weight spaces...improve performance similarly to having up to 10 times more data."
  - [section 4.2]: "interpolating between a weight vector v1 and an optimally permuted version of another weight vector p · v2 results in intermediate weight vectors that maintain low loss values."
  - [corpus]: No direct corpus evidence found.

### Mechanism 3
- Claim: Neural network-specific augmentations exploit activation function symmetries to generate new weight views without retraining.
- Mechanism: By applying transformations based on activation symmetries (e.g., sin(x) = −sin(−x) for SIREN, or ReLU scaling), the model receives additional weight configurations representing the same function, increasing effective dataset size.
- Core assumption: The weight space model can learn from these symmetry-induced variations without explicit retraining of underlying INR.
- Evidence anchors:
  - [section 4.1]: "These symmetries are much more difficult to incorporate directly into the weight space architectures...We propose two augmentations that exploit this symmetry."
  - [corpus]: No direct corpus evidence found.

## Foundational Learning

- Concept: Implicit Neural Representations (INRs)
  - Why needed here: The paper's augmentation strategies are specifically designed for weight spaces derived from INRs, so understanding how INRs encode objects as neural networks is essential.
  - Quick check question: What does an INR output when queried at coordinate (x, y) for a 2D image representation?

- Concept: Permutation symmetries in weight spaces
  - Why needed here: The alignment problem in MixUp arises from these symmetries, so understanding how permutations of weights/biases yield equivalent functions is critical.
  - Quick check question: Why does permuting rows of a weight matrix and corresponding columns of the next layer preserve the function represented by the network?

- Concept: Linear mode connectivity
  - Why needed here: The motivation for alignment-based MixUp relies on the idea that aligned weight vectors have low-loss paths between them.
  - Quick check question: What property of two weight vectors indicates that their linear interpolation maintains low loss values?

## Architecture Onboarding

- Component map: Input (Weight space vectors) -> Core model (DWS/GNN) -> Augmentation layer -> Output (Classification logits/Contrastive embeddings)
- Critical path:
  1. Generate or load INR weights for each object
  2. Apply data augmentation (e.g., MixUp + alignment)
  3. Forward pass through weight space model
  4. Compute loss (classification or contrastive)
  5. Backpropagate and update model weights
- Design tradeoffs:
  - More views per object improve generalization but increase training time
  - Alignment-based MixUp is more effective but computationally expensive vs. randomized MixUp
  - Using equivariant architectures respects symmetries but may limit architectural flexibility
- Failure signatures:
  - Overfitting despite augmentations → insufficient view diversity or model capacity too high
  - Poor MixUp performance → alignment algorithm failing or interpolations breaking functional properties
  - Low accuracy on internal vs. external test sets → model memorizing views rather than learning object semantics
- First 3 experiments:
  1. Train DWS with 1 view per object vs. 10 views per object on FMNIST-INR; compare test accuracy and overfitting curves
  2. Apply alignment-based MixUp vs. no augmentation on ModelNet40-INR; measure accuracy gain and training stability
  3. Pre-train weight space model with contrastive learning using augmentations, then fine-tune on 5% labeled data; compare to fine-tuning only baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal alignment method for weight space MixUp that respects both permutation symmetries and activation symmetries?
- Basis in paper: [explicit] The paper notes that their alignment-based MixUp approach produces somewhat underwhelming results compared to direct MixUp, suggesting the alignment algorithm might produce suboptimal alignments. They specifically mention that the current method "only considers permutation symmetries and overlooks the additional symmetries such as activation symmetries."
- Why unresolved: The paper acknowledges that finding an optimal alignment method is crucial but doesn't provide one that fully accounts for all symmetries in the weight space.
- What evidence would resolve it: Developing and testing a weight alignment algorithm that incorporates both permutation and activation symmetries, then comparing its performance against the current alignment-based MixUp.

### Open Question 2
- Question: How do weight space augmentations perform on other neural network architectures beyond INRs?
- Basis in paper: [explicit] The paper states "The evaluation of data augmentation schemes in this paper centers on INRs" and notes that "The use of weight space augmentations may be extended to other scenarios, including generalization prediction and learning to optimize."
- Why unresolved: The paper focuses exclusively on INRs and doesn't explore how these augmentations would work with other types of neural networks or weight space applications.
- What evidence would resolve it: Conducting experiments applying the weight space augmentations to different types of neural networks (e.g., CNNs, transformers) and other weight space tasks (e.g., model ranking, learning to optimize).

### Open Question 3
- Question: What is the theoretical explanation for why multiple neural views improve generalization in weight space learning?
- Basis in paper: [explicit] The paper finds that "training with multiple neural views improves generalization to unseen objects" but doesn't provide a theoretical framework explaining this phenomenon. They note that "a given object can be represented by many different weight configurations (neural views) but datasets typically use only a single view per object."
- Why unresolved: While the empirical results show improvement, the paper doesn't explain the underlying mechanism of why exposing the model to multiple views helps it generalize better to new objects.
- What evidence would resolve it: Developing a theoretical framework that explains how exposure to multiple views of the same object helps the model learn more robust representations and better distinguish between objects.

## Limitations
- The alignment-based MixUp algorithm is computationally expensive and produces somewhat underwhelming results compared to direct MixUp
- The paper focuses exclusively on INR datasets, limiting generalizability to other weight space learning tasks
- Implementation details for the alignment algorithm and hyperparameter settings are not fully specified

## Confidence

- **High**: The empirical results showing accuracy improvements with augmentations (up to 18%) and the comparison between single-view and multi-view training
- **Medium**: The theoretical motivation for why weight space MixUp with alignment works, particularly the claim about low-loss interpolation paths
- **Low**: The generalization of results beyond INR datasets to other weight space learning tasks

## Next Checks
1. Test the robustness of MixUp gains to the number of views per object (e.g., 2 vs 10 views) to confirm diminishing returns
2. Apply the augmentation methods to a non-INR weight space task (e.g., model weights for tabular data) to assess broader applicability
3. Perform ablation studies on each augmentation type (input space, data-agnostic, symmetry-based) to quantify individual contributions