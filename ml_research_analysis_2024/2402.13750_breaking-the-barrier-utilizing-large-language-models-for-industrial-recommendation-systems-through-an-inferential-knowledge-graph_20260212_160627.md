---
ver: rpa2
title: 'Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation
  Systems through an Inferential Knowledge Graph'
arxiv_id: '2402.13750'
source_url: https://arxiv.org/abs/2402.13750
tags:
- entity
- complementary
- latexit
- items
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses limitations in industrial recommendation systems
  that rely on historical data and struggle to recommend complementary items or adapt
  to new items. It proposes LLM-KERec, a novel system that uses large language models
  to construct a complementary knowledge graph linking entities extracted from user
  bills and item information.
---

# Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph

## Quick Facts
- arXiv ID: 2402.13750
- Source URL: https://arxiv.org/abs/2402.13750
- Authors: Qian Zhao; Hao Qian; Ziqi Liu; Gong-Duo Zhang; Lihong Gu
- Reference count: 27
- One-line primary result: LLM-KERec improves click-through and conversion rates by 0.4-2.0% compared to state-of-the-art baselines

## Executive Summary
This paper addresses the limitations of traditional industrial recommendation systems that rely solely on historical user-item interactions and struggle to recommend complementary items or adapt to new items. The proposed LLM-KERec system leverages large language models to construct a complementary knowledge graph that captures semantic relationships between entities extracted from user bills and item information. Through a two-stage knowledge enhancement procedure combining LLM-based inference with real exposure-click feedback, the system significantly improves recommendation performance for complementary items in e-commerce scenarios.

## Method Summary
LLM-KERec introduces a novel approach to industrial recommendation systems by integrating large language models into the knowledge graph construction process. The system extracts entities from user bills and item information using an entity extractor, then employs an LLM to determine complementary relationships between entity pairs, constructing a complementary knowledge graph. An Entity-Entity-Item (E-E-I) weight decision model is trained using real complementary exposure-click samples to refine the scoring of the ranking model. The two-stage knowledge enhancement procedure consists of a ranking stage that uses graph neural networks and contrastive learning to learn entity representations from substitutable and complementary views, followed by an integration stage that adds a complementary recall route and incorporates E-E-I model scores into the fine-ranking model.

## Key Results
- Online A/B tests show 0.4-2.0% improvements in click-through rate (CTR) and conversion rate (CVR) compared to state-of-the-art baselines
- Significant performance gains demonstrated across three Alipay datasets (Super 567, Consumer Channel, Payment Result Page)
- Enhanced user engagement and consumption through personalized complementary item recommendations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-KERec uses LLMs to construct a complementary knowledge graph that captures user intent transitions beyond historical clicks.
- Mechanism: The system extracts entities from user bills and item info, then uses an LLM (e.g., Claude) to reason about complementary relationships between entity pairs. These relationships form edges in a complementary graph, enabling recommendations based on conceptual complementarity rather than just click history.
- Core assumption: The LLM can accurately infer complementary relationships between entities based on world knowledge and commonsense reasoning.
- Evidence anchors:
  - [abstract] "The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph."
  - [section 3.2.2] "We also leverage the capabilities of large language models to determine the existence of a complementary relationship in an entity pair."
- Break condition: LLM reasoning produces incorrect or irrelevant complementary relationships, leading to poor recommendation quality.

### Mechanism 2
- Claim: The E-E-I weight decision model refines complementary item scoring using real exposure-click samples.
- Mechanism: After constructing the complementary graph, an E-E-I (entity1-entity2-item) weight decision model is trained using real complementary exposure-click samples. This model adjusts the graph edge weights based on actual user feedback, correcting for the LLM's weakness in assessing user preference strength.
- Core assumption: Real user feedback data can effectively calibrate the LLM's inferred complementary relationships.
- Evidence anchors:
  - [abstract] "Furthermore, a new complementary recall module and an Entity-Entity-Item (E-E-I) weight decision model refine the scoring of the ranking model using real complementary exposure-click samples."
  - [section 3.3.1] "However, due to the limited ability of LLM to accurately assess user preferences, we require an E-E-I (entity1-entity2-item) weight decision model to effectively accomplish this task."
- Break condition: Insufficient real exposure-click samples for training, leading to poor calibration.

### Mechanism 3
- Claim: The two-stage knowledge enhancement procedure improves both recall and ranking of complementary items.
- Mechanism: The system employs a two-stage approach. First, the ranking stage uses a dual-tower architecture with graph neural networks and contrastive learning to represent entities from both substitutable and complementary views. Second, the integration stage adds a complementary recall route and incorporates E-E-I model scores into the fine-ranking model.
- Core assumption: The two-stage approach can effectively combine graph-based entity representations with real feedback to improve complementary item recommendations.
- Evidence anchors:
  - [section 3.3.1] "we propose a Two-stage Complementary Knowledge Enhancement Procedure, which consists of the Ranking Stage and the Integration Stage"
  - [section 3.3.2] "we employ Graph Neural Network and Contrastive Learning to representative entity from two distinct perspectives: the first-order substitutable view and the second-order complementary view."
- Break condition: The two-stage approach introduces excessive complexity or latency, making it impractical for real-time recommendations.

## Foundational Learning

- Concept: Entity extraction and recognition
  - Why needed here: The system needs to extract unified concept terms (entities) from user bills and item information to create a common representation for reasoning about complementary relationships.
  - Quick check question: What NLP technique is used to extract entities from user bills and item information?

- Concept: Graph neural networks
  - Why needed here: GNNs are used to learn entity representations from both substitutable and complementary perspectives, which are crucial for the ranking stage of the two-stage knowledge enhancement procedure.
  - Quick check question: How do graph neural networks help in learning entity representations for the recommendation system?

- Concept: Contrastive learning
  - Why needed here: Contrastive learning is used in the ranking stage to maximize the agreement between representations learned from substitutable and complementary views, improving the quality of entity embeddings.
  - Quick check question: What is the role of contrastive learning in the ranking stage of LLM-KERec?

## Architecture Onboarding

- Component map: Entity Extractor → Complementary Graph Construction (LLM) → E-E-I Weight Decision Model → Traditional Recommendation Module (Recall, Coarse-Ranking, Fine-Ranking, Re-Ranking)
- Critical path: User request → Entity extraction → Complementary graph lookup → E-E-I scoring → Fine-ranking → Display
- Design tradeoffs: Using LLMs for knowledge graph construction provides flexibility but introduces latency; the two-stage approach improves quality but increases complexity.
- Failure signatures: Poor entity extraction leads to incomplete graph; LLM produces irrelevant complementary relationships; insufficient real feedback data for E-E-I model training.
- First 3 experiments:
  1. Test entity extraction accuracy on a sample of user bills and items.
  2. Evaluate LLM-generated complementary relationships on a manually annotated dataset.
  3. Measure the impact of E-E-I model on complementary item recall and ranking performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLM-KERec compare when using different large language models (e.g., ChatGPT, ChatGLM, Claude) for complementary graph construction?
- Basis in paper: [explicit] The paper compares the performance of different LLMs (ChatGPT, ChatGLM, and Claude) using manual annotation scores.
- Why unresolved: While the paper provides a comparison using manual annotation scores, it does not provide a comprehensive evaluation of how the choice of LLM affects the overall performance of LLM-KERec in real-world scenarios.
- What evidence would resolve it: Conducting extensive experiments using different LLMs in various real-world recommendation scenarios and comparing the performance metrics (e.g., click-through rate, conversion rate) would provide a clear answer.

### Open Question 2
- Question: What is the impact of entity popularity and long-tail distribution on the effectiveness of the complementary graph construction?
- Basis in paper: [inferred] The paper mentions the long-tail distribution of entity popularity and the use of a segmented combination strategy to address this issue.
- Why unresolved: The paper does not provide a detailed analysis of how the long-tail distribution affects the quality of the complementary graph and the overall performance of LLM-KERec.
- What evidence would resolve it: Analyzing the performance of LLM-KERec with different strategies for handling entity popularity and long-tail distribution, and comparing the results with the current approach, would provide insights into the impact of this factor.

### Open Question 3
- Question: How does the E-E-I weight decision model handle the trade-off between personalization and diversity in recommendations?
- Basis in paper: [explicit] The paper mentions that the E-E-I weight decision model is trained using real exposure-click samples to refine the scoring of the ranking model.
- Why unresolved: The paper does not discuss how the model balances personalization (recommending items based on user preferences) and diversity (recommending a variety of items).
- What evidence would resolve it: Evaluating the performance of LLM-KERec in terms of both personalization (e.g., click-through rate) and diversity (e.g., number of unique items recommended) would provide insights into how the E-E-I weight decision model handles this trade-off.

## Limitations
- Entity dictionary used for the entity extractor is not provided, making exact reproduction difficult
- Prompt engineering details for the large language model are not disclosed, which could significantly impact the quality of complementary relationship inference
- Evaluation is primarily conducted on Alipay-specific datasets, raising questions about generalizability to other domains

## Confidence
- **High confidence**: The core concept of using LLMs to construct complementary knowledge graphs and the two-stage knowledge enhancement procedure are well-supported by the experimental results.
- **Medium confidence**: The effectiveness of the E-E-I weight decision model relies on the availability of sufficient real exposure-click samples, which may vary across different recommendation scenarios.
- **Low confidence**: The generalization of the approach to domains beyond e-commerce and the practical deployment considerations (latency, scalability) are not thoroughly addressed.

## Next Checks
1. **Entity extraction validation**: Test the entity extraction module on a diverse set of user bills and items to assess its accuracy and robustness across different data formats and domains.
2. **LLM reasoning evaluation**: Conduct a manual evaluation of the LLM-generated complementary relationships on a held-out dataset to measure the precision and relevance of the inferred connections.
3. **E-E-I model calibration**: Analyze the impact of varying amounts of real exposure-click samples on the performance of the E-E-I weight decision model to determine the minimum required data for effective calibration.