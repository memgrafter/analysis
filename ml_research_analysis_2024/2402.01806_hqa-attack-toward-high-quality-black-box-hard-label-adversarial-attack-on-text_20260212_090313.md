---
ver: rpa2
title: 'HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on
  Text'
arxiv_id: '2402.01806'
source_url: https://arxiv.org/abs/2402.01806
tags:
- adversarial
- example
- hqa-attack
- similarity
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles black-box hard-label adversarial attack on text,
  where only the predicted label is accessible. The proposed HQA-Attack method first
  generates an adversarial example via random initialization, then substitutes original
  words back to reduce perturbation, and finally optimizes the example using a synonym
  set to improve semantic similarity while maintaining adversarial condition.
---

# HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack on Text

## Quick Facts
- arXiv ID: 2402.01806
- Source URL: https://arxiv.org/abs/2402.01806
- Reference count: 40
- Key outcome: Proposes HQA-Attack method that generates high-quality adversarial examples with improved semantic similarity and reduced perturbation rate under black-box hard-label settings.

## Executive Summary
This paper addresses the challenge of black-box hard-label adversarial attacks on text, where only the predicted label is accessible. The proposed HQA-Attack method innovatively combines random initialization, word substitution back steps, and synonym-based optimization to generate adversarial examples that maintain high semantic similarity while achieving attack success. By introducing a transition synonym search mechanism, the method significantly reduces query numbers compared to exhaustive synonym set traversal. Extensive experiments across five text classification datasets, three natural language inference datasets, and two real-world APIs demonstrate that HQA-Attack outperforms strong baselines in both semantic similarity and perturbation rate under the same query budget.

## Method Summary
HQA-Attack operates in three main stages: first, it generates an initial adversarial example through random word substitution; second, it iteratively substitutes original words back to improve semantic similarity while maintaining the adversarial condition; and third, it optimizes the example using a synonym set to further enhance semantic similarity. The method employs a transition synonym search strategy that samples a small subset of synonyms rather than traversing the entire set, significantly reducing query numbers. Semantic similarity is calculated using the Universal Sentence Encoder, and the method aims to maximize this similarity while ensuring the adversarial condition (misclassification) is preserved throughout the optimization process.

## Key Results
- HQA-Attack achieves significantly higher semantic similarity compared to baseline methods under the same query budget
- The method reduces perturbation rate by effectively substituting original words back while maintaining adversarial conditions
- Query efficiency is improved through transition synonym search, avoiding exhaustive traversal of synonym sets
- Strong performance demonstrated across five text classification datasets, three NLI datasets, and two real-world APIs

## Why This Works (Mechanism)

### Mechanism 1
Substituting original words back reduces perturbation rate while preserving adversarial condition. The method iteratively replaces altered words with their original counterparts, checking if the adversarial condition still holds. By prioritizing replacements that maximize semantic similarity and maintain misclassification, it minimizes unnecessary changes. Core assumption: The victim model's decision boundary is locally stable under small, semantically similar perturbations.

### Mechanism 2
Transition synonym search reduces query count by avoiding exhaustive synonym set traversal. Instead of testing all synonyms, the method samples a small set of candidates, selects the best transition word that maintains adversariality and improves similarity, then optimizes from there. Core assumption: A good transition synonym exists within a small random subset and can guide further optimization effectively.

### Mechanism 3
Weighted averaging of semantic improvement directions guides effective synonym selection. For each changed word, the method computes semantic similarity gains for candidate synonyms, weights directions by improvement magnitude, and selects the word maximizing cosine similarity along the averaged direction. Core assumption: Semantic similarity changes are approximately linear in the embedding space, so weighted averaging provides a meaningful update direction.

## Foundational Learning

- **Concept**: Black-box hard-label adversarial attack
  - **Why needed here**: The attack must work without access to model internals or confidence scores, only labels.
  - **Quick check question**: Can this method work if the model returns softmax probabilities instead of hard labels?

- **Concept**: Discrete, non-differentiable text space
  - **Why needed here**: Text modifications must preserve grammaticality and semantics while being discrete token swaps.
  - **Quick check question**: Why can't we directly apply gradient-based continuous optimization to text?

- **Concept**: Synonym set utilization for semantic preservation
  - **Why needed here**: Replacing words with synonyms maintains meaning while altering input to fool the model.
  - **Quick check question**: What happens if a word has no synonyms in the chosen thesaurus?

## Architecture Onboarding

- **Component map**: Random initialization → Word back-substitution → Synonym-based optimization → Query budget manager → Similarity calculator → Victim model interface
- **Critical path**: Initialization → Back-substitution loop → Sequential optimization → Adversarial example
- **Design tradeoffs**:
  - Query efficiency vs. semantic similarity: Sampling reduces queries but may miss optimal synonyms
  - Perturbation rate vs. attack success: More aggressive substitutions may succeed but reduce quality
  - Synonym set size vs. computation: Larger sets improve quality but increase query cost
- **Failure signatures**:
  - High query count without success: Likely poor initialization or difficult decision boundary
  - Low semantic similarity: Insufficient back-substitution or poor synonym selection
  - Failed attacks: Model too robust or synonym set inadequate
- **First 3 experiments**:
  1. Run on MR dataset with WordCNN victim; measure semantic similarity and perturbation rate
  2. Vary r (synonym sample size) from 3 to 9; observe query efficiency and quality trade-offs
  3. Test on a real API (Google Cloud); verify practical constraints and robustness

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the proposed HQA-Attack method compare to existing black-box hard-label adversarial attack methods in terms of semantic similarity and perturbation rate?
- **Basis in paper**: The paper states that HQA-Attack outperforms other strong baselines significantly in semantic similarity and perturbation rate under the same query budget.
- **Why unresolved**: The paper does not provide a detailed comparison of HQA-Attack with other methods on specific datasets or models.
- **What evidence would resolve it**: Experimental results comparing HQA-Attack with other methods on various datasets and models would provide evidence to resolve this question.

### Open Question 2
- **Question**: How does the proposed HQA-Attack method handle the trade-off between semantic similarity and perturbation rate?
- **Basis in paper**: The paper mentions that HQA-Attack first substitutes original words back to reduce perturbation, and then optimizes the example using a synonym set to improve semantic similarity while maintaining adversarial condition. However, it does not provide a detailed analysis of how the method balances these two aspects.
- **Why unresolved**: The paper does not provide a quantitative analysis of the trade-off between semantic similarity and perturbation rate in HQA-Attack.
- **What evidence would resolve it**: A detailed analysis of the trade-off between semantic similarity and perturbation rate in HQA-Attack, including quantitative results, would provide evidence to resolve this question.

### Open Question 3
- **Question**: How does the proposed HQA-Attack method perform on different types of text data, such as long documents or short sentences?
- **Basis in paper**: The paper mentions that HQA-Attack is tested on five text classification datasets, three natural language inference datasets, and two real-world APIs. However, it does not provide a detailed analysis of the method's performance on different types of text data.
- **Why unresolved**: The paper does not provide a detailed analysis of HQA-Attack's performance on different types of text data, such as long documents or short sentences.
- **What evidence would resolve it**: Experimental results comparing HQA-Attack's performance on different types of text data, such as long documents or short sentences, would provide evidence to resolve this question.

## Limitations

- Sampling parameters r and k lack detailed sensitivity analysis across different datasets and models
- Method's effectiveness depends on comprehensive synonym coverage, with no analysis of failure cases where appropriate synonyms don't exist
- Reliance on Universal Sentence Encoder without addressing potential biases or comparing alternative semantic similarity metrics
- No ablation studies to validate the contribution of individual components or alternative optimization strategies

## Confidence

**High Confidence**: The core mechanism of substituting original words back to reduce perturbation rate is well-supported by the abstract and methodology section.

**Medium Confidence**: The transition synonym search method shows promise but lacks detailed validation of sampling parameters across different scenarios.

**Low Confidence**: The weighted averaging of semantic improvement directions relies on assumptions about linearity in embedding space that aren't empirically validated.

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically vary the sampling parameters r (from 3 to 9 as suggested) and k across all datasets to determine their impact on query efficiency, semantic similarity, and attack success rate.

2. **Synonym Coverage Evaluation**: Analyze cases where adversarial attacks fail due to insufficient synonym availability by creating a dataset of words that lack appropriate synonyms in the chosen thesaurus and measuring how this limitation affects overall attack success rates.

3. **Alternative Similarity Metrics Comparison**: Replace the Universal Sentence Encoder with alternative semantic similarity measures (e.g., BERTScore, BLEU, or human evaluation) to assess whether the current metric choice significantly impacts the quality of generated adversarial examples.