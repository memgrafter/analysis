---
ver: rpa2
title: Adaptive Self-training Framework for Fine-grained Scene Graph Generation
arxiv_id: '2401.09786'
source_url: https://arxiv.org/abs/2401.09786
tags:
- predicate
- classes
- predicates
- class
- triplets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ST-SGG, a self-training framework for scene
  graph generation that leverages unannotated triplets to alleviate the long-tailed
  predicate distribution problem. The core challenge is designing effective pseudo-labeling
  in SGG due to semantic ambiguity and the long-tailed distribution of predicate classes.
---

# Adaptive Self-training Framework for Fine-grained Scene Graph Generation

## Quick Facts
- arXiv ID: 2401.09786
- Source URL: https://arxiv.org/abs/2401.09786
- Reference count: 40
- Key outcome: Introduces ST-SGG framework that significantly improves performance on fine-grained predicate classes while maintaining general predicate performance

## Executive Summary
This paper presents ST-SGG, a self-training framework designed to address the long-tailed predicate distribution problem in scene graph generation. The framework leverages unannotated triplets through a novel pseudo-labeling approach called Class-specific Adaptive Thresholding with Momentum (CATM), which dynamically adjusts thresholds for each predicate class based on the model's learning state. Additionally, a Graph Structure Learner (GSL) is introduced to enrich scene graph structures, particularly benefiting message-passing neural network-based models. The framework demonstrates significant improvements on both Visual Genome and Open Images V6 datasets, outperforming existing debiasing methods while maintaining performance on general predicates.

## Method Summary
ST-SGG operates through a self-training paradigm where a teacher model generates pseudo-labels on unannotated data, which are then used to train a student model. The core innovation lies in CATM, which addresses semantic ambiguity and long-tailed distribution by implementing adaptive, class-specific thresholding mechanisms that adjust based on momentum tracking of each predicate class's learning progress. The GSL component enhances the graph structure by learning richer representations, particularly beneficial for MPNN-based architectures. The framework is designed to be model-agnostic, allowing integration with various scene graph generation models while maintaining computational efficiency through its adaptive thresholding approach.

## Key Results
- Achieves significant performance improvements on fine-grained predicate classes while maintaining general predicate performance
- Outperforms state-of-the-art debiasing methods on both Visual Genome and Open Images V6 datasets
- Demonstrates effectiveness of adaptive thresholding in addressing semantic ambiguity in pseudo-label generation

## Why This Works (Mechanism)
The framework addresses the fundamental challenge of semantic ambiguity in scene graph generation, where predicates can have nuanced meanings that are difficult to distinguish. By implementing adaptive thresholding that responds to each class's learning state, the model can better handle the long-tailed distribution where rare predicates are underrepresented. The momentum-based adjustment ensures stable learning progression, preventing catastrophic forgetting of less frequent classes while improving overall predicate classification accuracy.

## Foundational Learning

**Scene Graph Generation (SGG)**: The task of detecting objects and their relationships in images, represented as subject-predicate-object triplets. Essential for understanding complex visual scenes and downstream tasks like image retrieval and visual question answering.

**Message-Passing Neural Networks (MPNNs)**: Graph neural networks that aggregate information from neighboring nodes through iterative message passing. Critical for SGG as they enable contextual reasoning about object relationships.

**Long-tailed Distribution**: The phenomenon where a few predicate classes have abundant training examples while most have very few. Requires specialized techniques to prevent model bias toward frequent classes.

**Pseudo-labeling**: The process of using a model's predictions as training labels for unlabeled data. Effective for semi-supervised learning but requires careful threshold management to ensure label quality.

**Class-specific Adaptive Thresholding**: A technique that maintains separate decision thresholds for each class based on their individual characteristics. Necessary for handling the diverse difficulty levels across different predicate types.

**Graph Structure Enrichment**: The process of enhancing graph representations with additional structural information. Improves the model's ability to capture complex relationship patterns in scene graphs.

## Architecture Onboarding

Component Map: Input Images -> Object Detection -> Predicate Classification -> Scene Graph Generation -> GSL Enhancement -> Output

Critical Path: The most critical components are the predicate classification module and the CATM mechanism, as they directly address the long-tailed distribution problem. The GSL component provides additional performance gains but is secondary to the core thresholding innovation.

Design Tradeoffs: The framework balances between exploration (generating pseudo-labels) and exploitation (using high-confidence labels), with the adaptive thresholding providing a dynamic equilibrium. The model-agnostic design trades some potential performance gains from architecture-specific optimizations for broader applicability.

Failure Signatures: Potential failure modes include threshold oscillations during training, over-reliance on pseudo-labels leading to error propagation, and insufficient adaptation for extremely rare predicate classes. The momentum mechanism helps mitigate some of these risks but requires careful hyperparameter tuning.

First Experiments:
1. Test basic pseudo-label generation with fixed thresholds on a small subset of Visual Genome to establish baseline performance
2. Implement CATM with simplified momentum tracking to evaluate threshold adaptation effectiveness
3. Compare GSL-enhanced versus baseline MPNN performance on predicate classification accuracy

## Open Questions the Paper Calls Out

The paper acknowledges that the effectiveness of the framework on downstream tasks that utilize scene graphs (such as image retrieval and visual question answering) requires further investigation. Additionally, the impact of different momentum parameters and threshold update frequencies on various predicate distributions could be more thoroughly explored.

## Limitations

- Limited analysis of how predicate classification improvements translate to downstream task performance
- Insufficient exploration of threshold dynamics and momentum parameter sensitivity
- Ablation studies could be more comprehensive in isolating GSL versus CATM contributions

## Confidence

- High confidence: The framework's general design and implementation details are clearly presented and reproducible
- Medium confidence: The quantitative improvements on benchmark datasets are demonstrated, but the significance of these gains relative to computational overhead is unclear
- Medium confidence: The model-agnostic nature is claimed but only validated on a limited set of SGG models

## Next Checks

1. Evaluate the framework's performance on downstream tasks (e.g., image retrieval, VQA) that use scene graphs as input to verify practical utility beyond predicate classification accuracy
2. Conduct comprehensive ablation studies varying the momentum parameters and threshold update frequencies to understand their impact on different predicate distributions
3. Test the framework with additional SGG model architectures beyond MPNNs to validate the claimed model-agnostic properties and identify any architectural dependencies