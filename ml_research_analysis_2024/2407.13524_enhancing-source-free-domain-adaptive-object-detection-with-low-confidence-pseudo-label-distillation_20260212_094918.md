---
ver: rpa2
title: Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence
  Pseudo Label Distillation
arxiv_id: '2407.13524'
source_url: https://arxiv.org/abs/2407.13524
tags:
- domain
- pseudo
- source
- object
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of source-free domain adaptive
  object detection, where a detector trained on a source domain must be adapted to
  an unlabeled target domain without access to source data. The authors identify that
  existing Mean-Teacher based SFOD methods rely heavily on high-confidence pseudo
  labels, which overlook small instances and objects from minor classes that undergo
  significant appearance changes across domains.
---

# Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence Pseudo Label Distillation

## Quick Facts
- arXiv ID: 2407.13524
- Source URL: https://arxiv.org/abs/2407.13524
- Reference count: 40
- Primary result: LPLD loss outperforms previous SFOD methods, reducing false negatives and improving detection accuracy for small objects and minor classes

## Executive Summary
This paper addresses source-free domain adaptive object detection (SFOD), where a detector trained on a source domain must be adapted to an unlabeled target domain without access to source data. The authors identify that existing Mean-Teacher based SFOD methods rely heavily on high-confidence pseudo labels, which overlook small instances and objects from minor classes that undergo significant appearance changes across domains. To address this, they propose a Low-confidence Pseudo Label Distillation (LPLD) loss that leverages low-confidence proposals from the Region Proposal Network to capture hard-to-detect objects. The method refines these proposals by amplifying foreground signals and applies KL divergence loss between teacher and student predictions, with adaptive weights based on feature distances. Experiments on four cross-domain object detection benchmarks show that the proposed LPLD loss outperforms previous SFOD methods, reducing false negatives and improving overall detection accuracy, particularly for small objects and minor classes.

## Method Summary
The paper proposes a Low-confidence Pseudo Label Distillation (LPLD) loss for source-free domain adaptive object detection. The method builds upon the Mean-Teacher framework and leverages low-confidence proposals from the Region Proposal Network to capture hard-to-detect objects that are missed by high-confidence pseudo-labeling. These low-confidence proposals are refined by removing background scores and amplifying foreground signals, then used to compute KL divergence loss between teacher and student predictions. Adaptive weights based on feature distances between teacher and student predictions are applied to focus optimization on more informative proposals. The total loss combines Mean-Teacher loss on high-confidence pseudo labels with LPLD loss on low-confidence proposals, providing complementary supervision that reduces false negatives and improves detection of small objects and minor classes.

## Key Results
- LPLD loss outperforms previous SFOD methods on four cross-domain object detection benchmarks
- The method consistently reduces false negative rates compared to Mean-Teacher baseline, especially for hard-positive objects like minor classes and small objects
- Combining HPL and LPL supervision provides more comprehensive coverage than either alone, preventing bias toward easy-positive objects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low-confidence proposals often contain hard-to-detect objects (small instances, minor classes) that are missed by high-confidence pseudo-labeling.
- Mechanism: The model captures proposals that don't overlap much with HPL (IoU < δ_IoU), refines them by removing background scores and amplifying foreground signals, then applies KL divergence loss to enforce consistency between teacher and student predictions on these LPL regions.
- Core assumption: Low-confidence proposals still contain meaningful object signal, and distilling teacher-student consistency on these regions improves detection of previously overlooked objects.
- Evidence anchors:
  - [abstract] "These LPL are further refined by leveraging class-relation information and reducing the effect of inherent noise for the LPLD loss calculation."
  - [section] "To address this problem, we employ the KL divergence loss between the student categorical prediction c^s_i,j and amplified class distribution e_c_i,j ∈ e_Y_i in the same region of LPL."
- Break condition: If background removal and foreground amplification fail to isolate actual objects, LPL distillation may introduce noise rather than useful supervision.

### Mechanism 2
- Claim: Adaptive weighting based on teacher-student feature distance prioritizes LPL that are more likely to contain objects and improves consistency.
- Mechanism: For each LPL, compute cosine distance between teacher and student features (d_cos(f^s_i,j, f^t_i,j)). Use this as weight α_j in the KL divergence loss, so regions with larger feature distances (likely more object-dominated) get higher weight.
- Core assumption: Feature distance between teacher and student predictions correlates with the foreground area in the LPL proposal, and weighting by this distance focuses optimization on more informative LPL.
- Evidence anchors:
  - [section] "We observe a positive correlation between the feature distance of the student and the teacher in the same region and the IoU with the ground-truth."
  - [section] "Utilizing adaptive weights on the LPL along with HPL showed the best performance (+15.2 mAP)."
- Break condition: If feature distance doesn't correlate with objectness, weighting could mislead optimization toward irrelevant proposals.

### Mechanism 3
- Claim: Combining HPL and LPL supervision reduces false negatives and prevents bias toward easy-positive objects.
- Mechanism: HPL provides reliable supervision for confident detections, while LPL provides complementary supervision for hard positives. The total loss is L_total = L_MT + L_LPLD, where L_MT uses HPL and L_LPLD uses LPL.
- Core assumption: HPL and LPL capture different types of objects (easy vs. hard positives), and their combination provides more comprehensive supervision than either alone.
- Evidence anchors:
  - [abstract] "Our method outperforms previous SFOD methods on four cross-domain object detection benchmarks."
  - [section] "Our method shows a consistently lower FNR than the MT baseline on hard-positive objects (e.g., Minor classes, Small objects)."
- Break condition: If LPL contains too much noise, combining with HPL could degrade overall performance.

## Foundational Learning

- Concept: Pseudo-labeling in semi-supervised learning
  - Why needed here: The method relies on generating pseudo labels from teacher predictions to supervise the student model.
  - Quick check question: What is the difference between hard pseudo labels and soft pseudo labels in semi-supervised learning?

- Concept: Knowledge distillation
  - Why needed here: The LPLD loss uses KL divergence between teacher and student predictions, which is a form of knowledge distillation.
  - Quick check question: How does KL divergence differ from cross-entropy in knowledge distillation?

- Concept: Feature alignment and distance metrics
  - Why needed here: The adaptive weighting mechanism uses cosine distance between teacher and student features.
  - Quick check question: Why might cosine distance be preferred over L2 distance for comparing feature vectors in this context?

## Architecture Onboarding

- Component map:
  - Teacher model -> Generates proposals, computes HPL and LPL, provides teacher features for adaptive weighting
  - Student model -> Receives supervision from both HPL (via MT loss) and LPL (via LPLD loss)
  - RPN -> Generates initial proposals for both teacher and student
  - Pseudo-label mining -> Extracts HPL and LPL with specific thresholding rules
  - Adaptive weighting -> Computes feature distances and applies weights to LPLD loss

- Critical path:
  1. Teacher generates proposals from weakly augmented image
  2. HPL and LPL are mined from teacher proposals
  3. Student processes strongly augmented image
  4. MT loss computed using HPL
  5. Feature distances computed between teacher and student on LPL regions
  6. LPLD loss computed using LPL and adaptive weights
  7. Student parameters updated using combined loss
  8. Teacher parameters updated via EMA

- Design tradeoffs:
  - Using only HPL vs. combining HPL and LPL: Combining provides better coverage but risks more noise
  - Fixed vs. adaptive weights: Adaptive weights focus on more informative LPL but add computational overhead
  - Confidence thresholds for HPL vs. LPL: HPL uses high threshold (0.7) for reliability, LPL uses lower threshold (0.9 for foreground) to capture hard positives

- Failure signatures:
  - Performance degradation on minor classes: May indicate LPL mining isn't capturing these objects
  - High false negative rate persists: May indicate HPL is still dominating supervision
  - Training instability: May indicate LPL contains too much noise

- First 3 experiments:
  1. Ablation: Run with only HPL supervision (L_total = L_MT) vs. only LPL supervision (L_total = L_LPLD) to verify complementary benefits
  2. Hyperparameter sensitivity: Vary δ_IoU, δ_bg, δ_lc thresholds to find optimal LPL mining settings
  3. Weighting analysis: Compare adaptive weighting vs. fixed weights on LPLD loss to verify effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise threshold value for the adaptive weights that optimizes the performance of the Low-confidence Pseudo Label Distillation (LPLD) loss?
- Basis in paper: [inferred] The paper mentions using feature distance to adaptively weight the LPLD loss, but does not provide a specific threshold value for this weighting.
- Why unresolved: The authors mention that they use feature distance to adaptively weight the LPLD loss, but they do not provide a specific threshold value for this weighting. This leaves room for further exploration and optimization of the adaptive weights.
- What evidence would resolve it: Conducting experiments with different threshold values for the adaptive weights and comparing the performance of the model could provide evidence to determine the optimal threshold value.

### Open Question 2
- Question: How does the performance of the LPLD loss vary with different domain shifts and dataset combinations?
- Basis in paper: [explicit] The paper evaluates the LPLD loss on four cross-domain object detection benchmarks, but does not explore all possible domain shifts and dataset combinations.
- Why unresolved: While the paper demonstrates the effectiveness of the LPLD loss on specific domain shifts and dataset combinations, it does not explore all possible combinations. This leaves room for further investigation into the generalizability of the LPLD loss.
- What evidence would resolve it: Conducting experiments with different domain shifts and dataset combinations and comparing the performance of the model could provide evidence to determine the generalizability of the LPLD loss.

### Open Question 3
- Question: What is the impact of the LPLD loss on the model's performance for objects with varying scales and classes?
- Basis in paper: [inferred] The paper mentions that the LPLD loss helps reduce false negatives, particularly for small objects and minor classes, but does not provide a detailed analysis of the impact on objects with varying scales and classes.
- Why unresolved: While the paper mentions that the LPLD loss helps reduce false negatives for small objects and minor classes, it does not provide a detailed analysis of the impact on objects with varying scales and classes. This leaves room for further investigation into the effectiveness of the LPLD loss for different types of objects.
- What evidence would resolve it: Conducting experiments with objects of varying scales and classes and comparing the performance of the model with and without the LPLD loss could provide evidence to determine the impact of the LPLD loss on different types of objects.

## Limitations
- The effectiveness of LPL distillation heavily depends on the quality of low-confidence proposals, which may contain significant noise that could degrade performance in more challenging domain shifts.
- The adaptive weighting mechanism assumes a positive correlation between feature distance and objectness, but this relationship may not hold consistently across all object categories and domain pairs.
- The method requires careful hyperparameter tuning for thresholds (δ_IoU, δ_bg, δ_lc) that may not generalize well across different datasets.

## Confidence

- **High confidence**: The mechanism of using low-confidence proposals to capture hard-to-detect objects is well-supported by experimental results showing consistent improvement over baseline MT methods across four benchmarks.
- **Medium confidence**: The adaptive weighting based on feature distance effectively prioritizes informative LPL regions, though the underlying assumption about correlation with objectness requires further validation.
- **Medium confidence**: The combination of HPL and LPL supervision reduces false negatives compared to using HPL alone, though the optimal balance between these supervision signals may vary by domain.

## Next Checks

1. **Ablation study on noise tolerance**: Evaluate LPLD performance with varying levels of proposal noise by artificially degrading the quality of low-confidence proposals to determine the method's robustness to noisy supervision.

2. **Cross-domain threshold analysis**: Systematically test the sensitivity of LPLD performance to different threshold combinations (δ_IoU, δ_bg, δ_lc) across multiple domain pairs to identify more generalizable hyperparameter settings.

3. **Real-time feasibility assessment**: Measure the computational overhead introduced by LPLD processing and evaluate whether the method can be optimized for practical deployment scenarios with strict latency requirements.