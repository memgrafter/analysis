---
ver: rpa2
title: 'The Pitfalls of Memorization: When Memorization Hurts Generalization'
arxiv_id: '2412.07684'
source_url: https://arxiv.org/abs/2412.07684
tags:
- memorization
- training
- spurious
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how memorization in neural networks can exacerbate
  reliance on spurious correlations, leading to poor generalization under distribution
  shifts. It formalizes the problem using an interpretable binary classification setup
  where spurious features are easier to learn than core features.
---

# The Pitfalls of Memorization: When Memorization Hurts Generalization

## Quick Facts
- **arXiv ID:** 2412.07684
- **Source URL:** https://arxiv.org/abs/2412.07684
- **Reference count:** 40
- **Key outcome:** Memorization combined with spurious correlations causes models to fail on minority examples by achieving zero training loss without learning generalizable patterns.

## Executive Summary
This paper investigates how memorization in neural networks can exacerbate reliance on spurious correlations, leading to poor generalization under distribution shifts. The authors formalize this problem using an interpretable binary classification setup where spurious features are easier to learn than core features. They demonstrate that when combined with memorization, spurious correlations cause models to fail on minority examples, achieving zero training loss but poor generalization. To address this, they propose memorization-aware training (MAT), which uses held-out predictions to shift model logits during training, encouraging learning of invariant patterns. MAT improves generalization under subpopulation shifts as demonstrated on image and text datasets.

## Method Summary
The paper studies memorization-spurious correlation interaction in neural networks and proposes MAT to mitigate the problem. MAT uses an auxiliary model trained on disjoint data to compute held-out predictions, which are then used to shift logits during training. This modification encourages the model to learn patterns that generalize across distributions rather than relying on spurious correlations. The method operates without requiring group annotations, making it more flexible than existing approaches.

## Key Results
- MAT improves worst-group accuracy on Waterbirds, CelebA, MultiNLI, and CivilComments datasets compared to ERM baseline
- The paper categorizes memorization into "good" (benign overfitting), "bad" (malign overfitting), and "ugly" (catastrophic overfitting) types based on the strength of example-specific features
- Self-influence score analysis shows MAT reduces memorization compared to ERM while maintaining similar average accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Memorization combined with spurious correlations reduces training loss to zero but prevents learning of generalizable patterns.
- **Mechanism:** When a model learns spurious features that correlate with labels during training, it can use example-specific features to memorize minority examples. This achieves zero training loss without needing to learn core features, resulting in reliance on spurious features at test time.
- **Core assumption:** The spurious feature is easier to learn than the core feature due to larger norm or other learning dynamics.
- **Evidence anchors:**
  - [abstract] "This behavior leads to poor generalization when the learned explanations rely on spurious correlations."
  - [section 2.1] "Memorization can reduce training loss to zero, leaving no incentive to learn robust, generalizable patterns."
  - [corpus] Weak evidence for this specific mechanism; most corpus papers discuss mitigation methods rather than the underlying memorization-spurious correlation interaction.
- **Break condition:** If spurious features are not easier to learn than core features, or if there are no example-specific features available for memorization.

### Mechanism 2
- **Claim:** MAT uses held-out predictions to shift logits during training, encouraging learning of invariant patterns.
- **Mechanism:** MAT computes calibrated held-out probabilities from an auxiliary model, then uses these probabilities to adjust the loss function. This shifts the optimization landscape to prioritize examples with poor generalization performance.
- **Core assumption:** Held-out predictions from a model trained on disjoint data can serve as a proxy for memorization behavior.
- **Evidence anchors:**
  - [abstract] "MAT encourages learning robust patterns invariant across distributions, improving generalization under distribution shifts."
  - [section 3] "MAT modifies the empirical risk minimization (ERM) objective by introducing a per-example logit shift based on calibrated probabilities."
  - [corpus] No direct corpus evidence for this specific mechanism; most related work focuses on environment discovery rather than logit shifting.
- **Break condition:** If the auxiliary model's held-out predictions do not correlate with memorization behavior, or if the temperature parameter τ is poorly tuned.

### Mechanism 3
- **Claim:** Memorization can be "good" (benign overfitting) or "bad" (malign overfitting) depending on the nature of the data.
- **Mechanism:** When example-specific features are present but weak (σϵ = 10^-4), the model can memorize residual noise while still learning the true function, achieving good generalization. When example-specific features are strong (σϵ = 10^-3), the model relies on them instead of learning the true function, resulting in poor generalization.
- **Core assumption:** The level of example-specific features determines whether memorization is beneficial or harmful.
- **Evidence anchors:**
  - [section 5] "Good memorization (Left, σϵ = 10−4): Model learns the true function f(xy) well but slightly memorizes residual noise in the training data using the input example-specific features ϵ."
  - [section 5] "Bad memorization (Middle, σϵ = 10−3): The model relies more on example-specific features than learning the true function f(xy)."
  - [corpus] Weak evidence; most corpus papers discuss memorization in general terms rather than distinguishing between good and bad types.
- **Break condition:** If the relationship between example-specific feature strength and generalization is not monotonic, or if other factors dominate the generalization behavior.

## Foundational Learning

- **Concept:** Empirical Risk Minimization (ERM)
  - **Why needed here:** ERM is the baseline training method that MAT modifies. Understanding ERM's limitations with spurious correlations is crucial for appreciating MAT's contributions.
  - **Quick check question:** Why does ERM tend to learn spurious features before core features in the setup described in section 2.1?

- **Concept:** Distribution shift and subpopulation shift
  - **Why needed here:** The paper focuses on improving generalization under subpopulation shift, where spurious correlations differ between training and test distributions.
  - **Quick check question:** What is the difference between subpopulation shift and domain shift in the context of this paper?

- **Concept:** Influence functions and memorization scores
  - **Why needed here:** The paper uses influence scores to analyze memorization behavior in different training methods. Understanding how these scores are computed and interpreted is important for evaluating the experimental results.
  - **Quick check question:** How does a high self-influence score indicate memorization in the context of the Waterbirds dataset experiments?

## Architecture Onboarding

- **Component map:**
  - Data preprocessing -> Base model (ResNet-50/BERT) -> Auxiliary XRM model -> MAT training loop -> Evaluation

- **Critical path:**
  1. Train XRM auxiliary model on random halves of training data
  2. Compute held-out predictions p(yho | xi) for each training example
  3. Calculate calibration matrix p(y | yho) from training data
  4. Compute calibrated held-out probabilities pho(y | xi)
  5. Modify loss function with logit shifts: l(softmax(f(xi) + logpho(. | xi)), yi)
  6. Train main model with modified loss
  7. Evaluate on test set with ground-truth group annotations

- **Design tradeoffs:**
  - MAT introduces one hyperparameter τ for temperature control, while methods like GroupDRO require group annotations
  - MAT operates without explicit group information during training, making it more flexible but requiring careful validation setup
  - The auxiliary XRM model adds computational overhead but enables group-agnostic training

- **Failure signatures:**
  - If τ is too high, the logit shifts become too weak to affect learning
  - If τ is too low, the shifts become too strong and may destabilize training
  - Poor auxiliary model quality leads to inaccurate held-out predictions and ineffective shifts
  - If spurious correlations are weak or absent, MAT may not provide significant benefits over ERM

- **First 3 experiments:**
  1. Run ERM baseline on Waterbirds dataset with different random seeds to establish baseline performance
  2. Implement MAT training loop and compare average and worst-group accuracy against ERM baseline
  3. Analyze self-influence score distributions for ERM vs MAT models to quantify memorization differences

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Under what precise conditions does memorization shift from "good" (benign overfitting) to "bad" (malign overfitting) in neural networks trained on real-world data?
- **Basis in paper:** Explicit discussion in Section 5 and Figure 3, which categorizes memorization into "good," "bad," and "ugly" types based on the level of example-specific features (σϵ).
- **Why unresolved:** The paper provides a theoretical framework for a simplified regression setup but does not extend this analysis to the complex, high-dimensional data and architectures used in practice.
- **What evidence would resolve it:** Empirical studies on real-world datasets comparing the generalization performance of models with varying degrees of memorization, particularly in the presence of spurious correlations and label noise.

### Open Question 2
- **Question:** Can MAT be extended to handle more complex forms of spurious correlations, such as those involving multiple attributes or continuous variables?
- **Basis in paper:** Explicit discussion in Section E, which shows that MAT can handle multiple spurious features in a simplified setup but does not explore more complex scenarios.
- **Why unresolved:** The paper focuses on binary classification with discrete spurious attributes and does not address the challenges of continuous or high-dimensional spurious features.
- **What evidence would resolve it:** Experiments on datasets with multiple or continuous spurious attributes, demonstrating MAT's effectiveness in these settings.

### Open Question 3
- **Question:** How does the performance of MAT compare to other methods for mitigating spurious correlations when group annotations are unavailable for both training and validation?
- **Basis in paper:** Explicit discussion in Section C, which highlights MAT's robustness in scenarios where group annotations are unavailable, but does not provide direct comparisons with other methods in this setting.
- **Why unresolved:** The paper compares MAT to other methods under various annotation availability scenarios but does not specifically focus on the most restrictive case where no annotations are available.
- **What evidence would resolve it:** A comprehensive comparison of MAT with other methods (e.g., GroupDRO, LfF, JTT) in settings where no group annotations are provided, using metrics such as worst-group accuracy and average accuracy.

## Limitations

- The paper's claims about memorization exacerbating spurious correlations are well-supported by synthetic data experiments, but real-world dataset results are less conclusive
- MAT's effectiveness depends heavily on the quality of held-out predictions, which may vary across datasets and tasks
- The distinction between "good" and "bad" memorization is somewhat arbitrary and may not capture the full spectrum of memorization behaviors

## Confidence

- **High:** The synthetic data experiments demonstrating the memorization-spurious correlation interaction are reproducible and well-controlled
- **Medium:** The MAT algorithm's effectiveness on real-world datasets, as the results show improvement but with less dramatic margins than synthetic experiments
- **Medium:** The categorization of memorization types, as the boundary between "good" and "bad" memorization is not clearly defined

## Next Checks

1. **Ablation study on auxiliary model quality:** Systematically vary the quality of held-out predictions by training auxiliary models with different architectures and data subsets to determine the minimum required quality for MAT to be effective

2. **Analysis of temperature parameter sensitivity:** Conduct a grid search over temperature τ values for each dataset to identify optimal ranges and assess the algorithm's robustness to hyperparameter choice

3. **Comparison with alternative spurious correlation mitigation methods:** Implement and compare MAT against established methods like GroupDRO, JTT, and EIIL on the same datasets to quantify relative performance gains and identify complementary strengths