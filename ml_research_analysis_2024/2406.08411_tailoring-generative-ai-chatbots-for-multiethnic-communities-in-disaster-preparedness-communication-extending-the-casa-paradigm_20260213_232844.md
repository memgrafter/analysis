---
ver: rpa2
title: 'Tailoring Generative AI Chatbots for Multiethnic Communities in Disaster Preparedness
  Communication: Extending the CASA Paradigm'
arxiv_id: '2406.08411'
source_url: https://arxiv.org/abs/2406.08411
tags:
- disaster
- communication
- chatbot
- cultural
- chatbots
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed and tested GPT-4 chatbots for hurricane preparedness
  communication with Black, Hispanic, and Caucasian Florida residents. The chatbots
  varied in tone formality (formal vs.
---

# Tailoring Generative AI Chatbots for Multiethnic Communities in Disaster Preparedness Communication: Extending the CASA Paradigm

## Quick Facts
- arXiv ID: 2406.08411
- Source URL: https://arxiv.org/abs/2406.08411
- Reference count: 18
- Primary result: Formal tone increases chatbot credibility but decreases friendliness; cultural tailoring improves credibility among Hispanic and Black participants

## Executive Summary
This study developed and tested GPT-4 chatbots for hurricane preparedness communication with Black, Hispanic, and Caucasian Florida residents. The chatbots varied in tone formality (formal vs. informal) and cultural tailoring (tailored vs. generic). Results showed that formal tone increased perceived credibility but decreased friendliness, while cultural tailoring improved credibility perceptions among Hispanic and Black participants. Perceived credibility positively influenced information-seeking intention, sharing intention, and disaster preparedness. The study highlights the potential of GenAI chatbots for culturally tailored disaster communication, suggesting that a formal tone combined with cultural tailoring can enhance credibility and improve disaster preparedness outcomes.

## Method Summary
The study employed a between-subjects experiment with 441 Black, Hispanic, and Caucasian Florida residents recruited through Prolific. Participants were randomly assigned to interact with one of four chatbot conditions varying in tone formality (formal vs. informal) and cultural tailoring (tailored vs. generic). Chatbots were developed using OpenAI's GPT-4 API with specific prompt templates for each condition. The experiment used Qualtrics for survey administration with custom URL generation for random assignment. Data collection included chat histories and participant responses measuring perceived chatbot friendliness and credibility as mediators, with hurricane preparedness outcomes as dependent variables. Structural equation modeling was used to test the hypothesized relationships.

## Key Results
- Formal tone increased perceived credibility but decreased friendliness compared to informal tone
- Cultural tailoring improved credibility perceptions among Hispanic and Black participants but not Caucasian participants
- Perceived credibility positively influenced information-seeking intention, information-sharing intention, and disaster preparedness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Formal tone increases chatbot credibility.
- Mechanism: Formal tone signals authority and trustworthiness, aligning with disaster communication norms where official, authoritative language is expected.
- Core assumption: Users associate formal tone with official government agencies and thus trust the information more.
- Evidence anchors:
  - [abstract] "Results showed that formal tone increased perceived credibility but decreased friendliness"
  - [section 1.3] "a chatbot's formal tone directly enhanced perceived source credibility, likely increasing information trustworthiness"
- Break condition: If users perceive formal tone as impersonal or robotic, it may reduce perceived humanness and engagement.

### Mechanism 2
- Claim: Cultural tailoring improves credibility perceptions among Hispanic and Black participants.
- Mechanism: Culturally tailored chatbots signal in-group membership, triggering social identity processes that enhance trust and credibility.
- Core assumption: Users respond to chatbots as social actors and treat culturally aligned communication as more trustworthy.
- Evidence anchors:
  - [abstract] "cultural tailoring improved credibility perceptions among Hispanic and Black participants"
  - [section 1.4] "deep-level tailoring engages with a community's social, historical, and psychological characteristics... considered as the culture's deep structure"
  - [corpus] "Multi-Label Classification Framework for Hurricane Damage Assessment" - weak correlation, no direct cultural tailoring evidence
- Break condition: If cultural tailoring is perceived as stereotypical or superficial, it may backfire and reduce credibility.

### Mechanism 3
- Claim: Perceived friendliness increases information sharing intention through enhanced social presence.
- Mechanism: Friendliness cues trigger social presence, making users feel they are interacting with a real person, which increases willingness to share information.
- Core assumption: Users respond to chatbot friendliness as they would to human friendliness in social interactions.
- Evidence anchors:
  - [abstract] "Perceived credibility positively influenced information-seeking intention, sharing intention, and disaster preparedness"
  - [section 1.3] "perceived friendliness positively affects users' evaluation of chatbots"
  - [section 2.6] "Bot Friendliness... measured through five items from Koh and Sundar (2010)"
- Break condition: If friendliness is perceived as insincere or inappropriate for the disaster context, it may reduce rather than increase sharing intention.

## Foundational Learning

- Concept: CASA (Computers Are Social Actors) paradigm
  - Why needed here: Provides theoretical foundation for understanding how users interact with chatbots as social entities
  - Quick check question: How does the CASA paradigm explain user responses to chatbot tone and cultural cues?

- Concept: Cultural tailoring (surface vs. deep level)
  - Why needed here: Explains how chatbots can be adapted to different cultural groups and why this matters for engagement
  - Quick check question: What are the differences between surface-level and deep-level cultural tailoring in chatbot communication?

- Concept: Anthropomorphism in human-computer interaction
  - Why needed here: Explains how human-like qualities in chatbots (including tone and cultural adaptation) affect user perceptions and behaviors
  - Quick check question: How does anthropomorphism influence user trust and engagement with chatbots?

## Architecture Onboarding

- Component map: GPT-4 API backend → Prompt engineering layer (tone and cultural tailoring variations) → Web server interface → User interaction frontend → Data logging system → Analysis pipeline
- Critical path: User interaction → Prompt generation → GPT-4 response → Data logging → Analysis
- Design tradeoffs: Formal tone vs. friendliness, cultural specificity vs. generalization, complexity of prompts vs. response reliability
- Failure signatures: Low engagement rates, negative sentiment in user feedback, inconsistent cultural tailoring effectiveness across groups
- First 3 experiments:
  1. A/B test comparing formal vs. informal tone effectiveness on credibility perception
  2. Cultural tailoring effectiveness test across different racial/ethnic groups
  3. Combined effect test of tone formality and cultural tailoring on disaster preparedness outcomes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different levels of disaster experience among participants influence their perceptions of chatbot credibility and friendliness?
- Basis in paper: [explicit] The study controlled for disaster experience as a covariate but did not analyze its moderating effects on the relationships between chatbot tone/cultural tailoring and perceptions/outcomes.
- Why unresolved: The paper only mentioned controlling for disaster experience without exploring whether it interacts with the chatbot manipulations.
- What evidence would resolve it: Analyzing interaction effects between disaster experience and chatbot conditions on perceptions and preparedness outcomes would clarify this relationship.

### Open Question 2
- Question: What is the optimal balance between formal and informal tone that maximizes both credibility and friendliness perceptions in disaster communication chatbots?
- Basis in paper: [inferred] The study found that formal tone increased credibility but decreased friendliness, while informal tone had the opposite effect, suggesting a potential trade-off.
- Why unresolved: The study only tested extreme ends of the tone continuum without examining intermediate levels or optimal combinations.
- What evidence would resolve it: Testing multiple levels of tone formality and analyzing the resulting perceptions and outcomes would identify the optimal balance.

### Open Question 3
- Question: How do deep-level cultural tailoring elements (values, beliefs, historical context) compare to surface-level elements (language, names) in their effectiveness for disaster communication chatbots?
- Basis in paper: [explicit] The study acknowledged that it focused more on surface-level cultural tailoring and suggested that deep-level tailoring might be more effective based on prior literature.
- Why unresolved: The study did not systematically compare the effectiveness of deep versus surface cultural tailoring elements.
- What evidence would resolve it: Conducting experiments that manipulate deep-level versus surface-level cultural tailoring elements separately would allow for direct comparison of their effectiveness.

## Limitations
- The study's findings are based on a single experimental session with hypothetical hurricane scenarios, which may not translate to actual disaster behavior.
- The sample, while demographically diverse, was recruited online through Prolific and may not fully represent vulnerable populations most at risk during disasters.
- The cultural tailoring approach, though grounded in established frameworks, relies on researcher interpretation of cultural characteristics that may not capture the full complexity of cultural identity.
- The study only tested two levels of tone formality and two levels of cultural tailoring, leaving uncertainty about optimal configurations for different contexts and user groups.

## Confidence

**High confidence**: The finding that formal tone increases perceived credibility is supported by consistent results across multiple analyses and aligns with established disaster communication norms. The positive relationship between perceived credibility and disaster preparedness outcomes also shows strong statistical support.

**Medium confidence**: The effectiveness of cultural tailoring for Hispanic and Black participants is supported but shows more variability. The mechanism by which cultural alignment improves credibility is theoretically sound but may be influenced by individual differences in cultural identification and context.

**Low confidence**: The negative effect of formal tone on perceived friendliness is statistically significant but may be context-dependent. In disaster scenarios where trust and authority are paramount, the trade-off between credibility and friendliness might be acceptable or even desirable.

## Next Checks

1. **Field validation**: Conduct a longitudinal study tracking actual hurricane preparedness behaviors following chatbot interactions, comparing engagement rates and preparedness outcomes across different tone and cultural tailoring configurations.

2. **Cultural nuance testing**: Implement a more granular cultural tailoring approach with multiple cultural reference points for each group, then test which specific cultural elements most strongly influence credibility and engagement across different subgroups.

3. **Context sensitivity validation**: Test the chatbot across different disaster types (hurricane vs. flood vs. wildfire) and urgency levels to determine whether the formal tone and cultural tailoring effects remain consistent or require adaptation for different emergency contexts.