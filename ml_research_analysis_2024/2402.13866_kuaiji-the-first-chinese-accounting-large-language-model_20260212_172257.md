---
ver: rpa2
title: 'Kuaiji: the First Chinese Accounting Large Language Model'
arxiv_id: '2402.13866'
source_url: https://arxiv.org/abs/2402.13866
tags:
- accounting
- kuaiji
- financial
- language
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Kuaiji is the first Chinese accounting-focused large language model,
  created to address the lack of specialized, open-source models for accounting applications.
  It uses Baichuan as a base, followed by continuous pre-training on a curated dataset
  of textbooks, academic papers, and real-world financial data (828MB total).
---

# Kuaiji: the First Chinese Accounting Large Language Model

## Quick Facts
- arXiv ID: 2402.13866
- Source URL: https://arxiv.org/abs/2402.13866
- Reference count: 7
- Kuaiji is the first Chinese accounting-focused large language model, created to address the lack of specialized, open-source models for accounting applications.

## Executive Summary
Kuaiji is the first Chinese accounting-focused large language model, created to address the lack of specialized, open-source models for accounting applications. It uses Baichuan as a base, followed by continuous pre-training on a curated dataset of textbooks, academic papers, and real-world financial data (828MB total). The model is then fine-tuned with 35,784 question-answer pairs from professional CPA exam materials and real accountant-client dialogues (CAtAcctQA), augmented with data generated by stronger LLMs. Training employs QLoRA for efficient parameter adaptation and includes supervised fine-tuning with expert validation. Kuaiji is evaluated against baselines like ChatGPT and Baichuan2-13B, showing superior accuracy and faster response in accounting tasks. The model is publicly accessible via API and supports multi-turn dialogue, serving as a domain-specific knowledge base and inference tool for accounting, tax, auditing, and financial analysis.

## Method Summary
Kuaiji leverages Baichuan2-13B as its base model, followed by continuous pre-training on an 828MB curated dataset of accounting textbooks, academic papers, and real-world financial data. The model is then fine-tuned using 35,784 question-answer pairs from CPA exam materials and real accountant-client dialogues (CAtAcctQA), augmented with data generated by stronger LLMs. QLoRA with 8-bit quantization and LoRA adapters is employed for efficient parameter adaptation. The training process includes supervised fine-tuning with expert validation, using a mix of domain-specific and general instructions (80:20 ratio) to avoid capability collapse.

## Key Results
- Kuaiji achieves superior accuracy and faster response times compared to baselines like ChatGPT and Baichuan2-13B in accounting tasks.
- The model is publicly accessible via API and supports multi-turn dialogue, serving as a domain-specific knowledge base for accounting, tax, auditing, and financial analysis.
- Evaluation shows Kuaiji outperforms baselines on CPA exam questions and real-world accountant-client dialogue scenarios.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific fine-tuning of a pre-trained LLM improves performance on specialized tasks like accounting.
- Mechanism: The model leverages existing general language understanding from Baichuan2-13B and refines it with accounting-specific knowledge through continuous pre-training and supervised fine-tuning.
- Core assumption: Pre-trained LLMs contain transferable language representations that can be adapted to new domains with targeted data.
- Evidence anchors:
  - [abstract] states the model is "meticulously fine-tuned using the Baichuan framework, which encompasses continuous pre-training and supervised fine-tuning processes."
  - [section] 4.1 and 4.2 describe the two-stage training process, with continuous pre-training on accounting textbooks and papers, followed by supervised fine-tuning on CPA exam questions and accountant-client dialogues.
  - [corpus] shows related work on domain-specific LLM fine-tuning, supporting the general approach.
- Break condition: If the pre-training data lacks sufficient domain coverage or the fine-tuning data is not representative of the target tasks, the model may fail to generalize.

### Mechanism 2
- Claim: Incorporating real-world data from accountant-client dialogues enhances the model's practical utility.
- Mechanism: The CAtAcctQA dataset contains 70,000 QA pairs from genuine accountant-client dialogues, exposing the model to the language and scenarios encountered in actual accounting practice.
- Core assumption: Real-world data captures the nuances and complexities of a domain better than synthetic or curated datasets alone.
- Evidence anchors:
  - [abstract] mentions the dataset "containing 15,677 genuine accountant-client dialogues" (note: abstract says 15,677, paper text says 70,000; likely a typo in the abstract).
  - [section] 3.2 describes constructing the SFT dataset from real accountant-client dialogues across 14 accounting departments.
  - [corpus] evidence is weak here, as the related papers focus on other domains and don't directly address the use of real-world dialogue data.
- Break condition: If the dialogue data is not diverse enough or contains biases, the model may not perform well on unseen scenarios.

### Mechanism 3
- Claim: Efficient parameter adaptation through QLoRA enables training on limited computational resources.
- Mechanism: QLoRA uses low-rank adaptation and 8-bit quantization to reduce memory usage while preserving model accuracy during fine-tuning.
- Core assumption: The low-rank structure of the adapter weights captures the essential domain-specific information needed for adaptation.
- Evidence anchors:
  - [section] 4.3 describes adopting QLoRA due to its ability to mitigate memory limitations and performance degradation during CPT and SFT phases.
  - [section] provides the mathematical formulation of QLoRA with 8-bit quantization for a single linear layer.
  - [corpus] shows related work on efficient fine-tuning methods, supporting the general approach.
- Break condition: If the low-rank assumption is violated or the quantization introduces significant errors, the model's performance may degrade.

## Foundational Learning

- Concept: Transfer learning in LLMs
  - Why needed here: Kuaiji leverages the language understanding from Baichuan2-13B and adapts it to the accounting domain.
  - Quick check question: What are the key differences between pre-training, fine-tuning, and adaptation in the context of LLMs?

- Concept: Domain-specific data curation
  - Why needed here: The quality and relevance of the accounting data used for continuous pre-training and supervised fine-tuning directly impact the model's performance.
  - Quick check question: How does the diversity and coverage of the training data affect the model's ability to generalize to new accounting tasks?

- Concept: Efficient fine-tuning methods
  - Why needed here: QLoRA enables training on limited computational resources, making it feasible to develop domain-specific models without requiring massive compute infrastructure.
  - Quick check question: What are the trade-offs between model performance and computational efficiency when using parameter-efficient fine-tuning methods like QLoRA?

## Architecture Onboarding

- Component map:
  - Pre-trained LLM (Baichuan2-13B) -> Continuous pre-training pipeline (accounting textbooks, papers, financial data) -> Supervised fine-tuning pipeline (CPA exam questions, accountant-client dialogues) -> QLoRA adapter for efficient parameter adaptation -> Evaluation framework (comparisons with ChatGPT, Baichuan2-13B, human experts)

- Critical path:
  1. Prepare domain-specific datasets (continuous pre-training and supervised fine-tuning)
  2. Initialize model with pre-trained weights
  3. Perform continuous pre-training on accounting data
  4. Apply QLoRA adapter
  5. Conduct supervised fine-tuning on accounting tasks
  6. Evaluate model performance and iterate as needed

- Design tradeoffs:
  - Balancing dataset size and quality vs. computational resources
  - Choosing between general pre-trained models vs. domain-specific pre-training
  - Trade-off between model accuracy and inference speed

- Failure signatures:
  - Model fails to capture domain-specific terminology or concepts
  - Performance degradation on out-of-distribution accounting tasks
  - Overfitting to the fine-tuning data, leading to poor generalization

- First 3 experiments:
  1. Evaluate the model's performance on a held-out set of CPA exam questions to assess its domain-specific knowledge.
  2. Compare the model's responses to those of human accounting experts on a set of realistic client queries to gauge practical utility.
  3. Analyze the model's sensitivity to different proportions of continuous pre-training vs. supervised fine-tuning data to optimize the training process.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Kuaiji's performance on real-world accounting tasks compare to human experts, and in what specific areas does it outperform or underperform them?
- Basis in paper: [explicit] The paper mentions that Kuaiji was evaluated against GPT-4 and human experts, showing superior accuracy and response speed. However, the paper doesn't provide detailed comparisons of Kuaiji's performance against human experts in specific accounting tasks.
- Why unresolved: The paper provides a general statement about Kuaiji's performance but lacks detailed analysis of its strengths and weaknesses compared to human experts in specific accounting domains.
- What evidence would resolve it: A comprehensive study comparing Kuaiji's performance with human experts on a wide range of accounting tasks, including financial analysis, tax consultancy, risk management, and audit, would provide the necessary evidence.

### Open Question 2
- Question: How does the performance of Kuaiji change over time as it is exposed to more real-world data and feedback from accounting professionals?
- Basis in paper: [inferred] The paper mentions that Kuaiji is a continuously evolving model, but it doesn't provide information on how its performance changes over time with exposure to more data and feedback.
- Why unresolved: The paper doesn't discuss the long-term performance of Kuaiji or how it adapts to new accounting regulations, practices, and challenges.
- What evidence would resolve it: A longitudinal study tracking Kuaiji's performance over time, including its ability to handle new accounting scenarios, adapt to changing regulations, and incorporate feedback from professionals, would provide the necessary evidence.

### Open Question 3
- Question: How does Kuaiji's performance on accounting tasks in Chinese compare to its performance on similar tasks in other languages?
- Basis in paper: [explicit] The paper focuses on Kuaiji as a Chinese accounting large language model, but it doesn't provide a comparison of its performance on Chinese accounting tasks versus tasks in other languages.
- Why unresolved: The paper doesn't discuss Kuaiji's cross-linguistic capabilities or how its performance might vary across different languages and accounting systems.
- What evidence would resolve it: A comparative study evaluating Kuaiji's performance on accounting tasks in Chinese versus other languages, such as English or Japanese, would provide the necessary evidence.

## Limitations

- The model's performance claims are based on comparisons with ChatGPT and Baichuan2-13B, but lacks direct comparisons with other domain-specific LLMs or human experts across diverse accounting tasks.
- The evaluation methodology does not specify statistical significance testing or confidence intervals for performance differences.
- While the model shows promise in Chinese accounting contexts, its generalization to international accounting standards and multilingual scenarios remains untested.

## Confidence

- **High Confidence**: The fundamental approach of domain-specific fine-tuning for specialized LLMs is well-established and theoretically sound. The use of QLoRA for efficient adaptation is a proven technique.
- **Medium Confidence**: The model's performance improvements over baselines are reported but lack detailed statistical validation. The real-world utility claims based on accountant-client dialogues are promising but not independently verified.
- **Low Confidence**: Long-term maintenance and update strategies for the model are not addressed, raising questions about its sustainability as accounting standards evolve.

## Next Checks

1. Conduct a blinded evaluation comparing Kuaiji's responses to those of certified public accountants on a standardized set of real-world accounting scenarios, measuring both accuracy and response time.
2. Test the model's performance on accounting tasks from different jurisdictions and regulatory frameworks to assess cross-domain generalization capabilities.
3. Perform an ablation study varying the proportions of continuous pre-training data versus supervised fine-tuning data to optimize the training pipeline and identify potential overfitting points.