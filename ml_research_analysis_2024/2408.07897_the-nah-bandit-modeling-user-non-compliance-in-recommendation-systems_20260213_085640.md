---
ver: rpa2
title: 'The Nah Bandit: Modeling User Non-compliance in Recommendation Systems'
arxiv_id: '2408.07897'
source_url: https://arxiv.org/abs/2408.07897
tags:
- user
- learning
- recommendation
- bandit
- non-compliance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Nah Bandit framework, which addresses
  online preference learning in cyber-physical recommendation systems where users
  can easily opt out of recommendations and revert to their baseline behavior. The
  authors propose a user non-compliance model that parameterizes the anchoring effect,
  capturing how recommendations influence user choices, and combine it with a hierarchical
  clustering approach called Expert with Clustering (EWC).
---

# The Nah Bandit: Modeling User Non-compliance in Recommendation Systems

## Quick Facts
- **arXiv ID**: 2408.07897
- **Source URL**: https://arxiv.org/abs/2408.07897
- **Reference count**: 40
- **Primary result**: EWC achieves regret bound O(N√T log K + NT) and outperforms LinUCB in short-term online preference learning

## Executive Summary
This paper addresses the "Nah Bandit" problem in cyber-physical recommendation systems where users can easily opt out of recommendations and revert to baseline behavior. The authors propose the Expert with Clustering (EWC) framework that combines a user non-compliance model with hierarchical clustering to accelerate preference learning. EWC learns user preferences from both compliance and non-compliance feedback by parameterizing the anchoring effect of recommendations, then uses clustering to group similar users and expert advice to reduce regret. Theoretical analysis shows EWC achieves superior short-term performance compared to LinUCB, with experimental results on travel and restaurant datasets confirming lower regret than traditional contextual bandit methods.

## Method Summary
EWC consists of two phases: offline training and online learning. During offline training, the user non-compliance model learns individual user preference parameters by parameterizing the anchoring effect of recommendations using a softmax probability framework. These parameters are then clustered using K-Means with loss-guided distance to create expert centroids. In online learning, EWC uses the Hedge algorithm to select the best expert for each new user based on context prediction, updating expert weights based on observed choices. The approach transforms the recommendation problem into a prediction with expert advice problem, leveraging shared information across similar users to accelerate learning while accounting for non-compliance behavior.

## Key Results
- EWC achieves theoretical regret bound O(N√T log K + NT), outperforming LinUCB in short-term scenarios
- Experimental results on travel route and restaurant recommendation datasets show consistently lower regret than LinUCB, DYNUCB, and XGBoost
- Ablation study confirms both the user non-compliance model and clustering components are essential for EWC's superior performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: EWC uses clustering to identify user groups with similar preferences, enabling rapid preference learning by leveraging shared information across users.
- **Mechanism**: EWC first clusters users based on learned preference parameters, then treats each cluster centroid as an expert. For each new user, it uses the Hedge algorithm to select the expert whose centroid best predicts the user's choices, thereby accelerating learning by exploiting group similarity.
- **Core assumption**: Users' preference parameters exhibit a hierarchical structure, such that users with similar contexts share similar preferences, and cluster centroids can approximate individual preferences well enough to reduce regret in the short term.
- **Evidence anchors**:
  - [abstract]: "EWC leverages the user non-compliance model and clustering to group users into K clusters based on preference similarity."
  - [section]: "EWC consists of both an offline training phase and an online learning phase... It transforms the recommendation problem into a prediction with expert advice problem, using clustering to get experts during the offline training phase and employing the Hedge algorithm to select the most effective expert during the online learning phase."
  - [corpus]: Weak corpus evidence. Closest neighbor "CoCoB: Adaptive Collaborative Combinatorial Bandits for Online Recommendation" mentions clustering bandits and collaborative information, but does not directly support the specific hierarchical expert-clustering mechanism of EWC.
- **Break condition**: If the hierarchical structure assumption fails (i.e., users with similar contexts do not share similar preferences), clustering will not effectively reduce regret. Also, if the number of clusters K is too small, the model may oversimplify user diversity; if too large, it may overfit and slow learning.

### Mechanism 2
- **Claim**: The user non-compliance model parameterizes the anchoring effect, reducing bias when learning user preferences from both compliance and non-compliance feedback.
- **Mechanism**: The model introduces a context variable representing how much an option is recommended (xrec), then learns a preference parameter θi,rec that quantifies the additional preference toward recommended options. This allows the model to predict user choices accounting for the anchoring effect, using both recommended and non-recommended feedback.
- **Core assumption**: The anchoring effect is linear and proportional to the size of the recommendation perturbation, and can be captured by a simple linear parameterization in the utility function.
- **Evidence anchors**:
  - [abstract]: "We model the user non-compliance by parameterizing an anchoring effect of recommendations on users."
  - [section]: "We propose a user non-compliance model to discern this additional preference and thereby address the anchoring effect... The probability of selecting each option is predicted as pi,t = σ(Ui,t), where σ(·) denotes the softmax function."
  - [corpus]: Weak corpus evidence. While "Security Implications of User Non-compliance Behavior to Software Updates" mentions non-compliance, it does not discuss modeling the anchoring effect in recommendation systems.
- **Break condition**: If the anchoring effect is not linear or cannot be captured by the proposed parameterization, the model will fail to reduce bias. Also, if users do not exhibit consistent dependence on recommendations (θi,rec = 0 for many users), the model adds unnecessary complexity without benefit.

### Mechanism 3
- **Claim**: EWC's regret bound improves as user compliance rates increase, due to a reduction in the Lipschitz constant L.
- **Mechanism**: Higher compliance rates mean users are more likely to choose the recommended option regardless of other parameter values, leading to smaller differences in user behavior. This reduces the Lipschitz constant L, which characterizes how sensitively user choices change with variations in preference parameters, thereby decreasing the upper bound on regret.
- **Core assumption**: User compliance rates directly influence the Lipschitz constant L in the regret bound, and this relationship is monotonic.
- **Evidence anchors**:
  - [abstract]: "We show that this bound decreases further as the user compliance rate increases."
  - [section]: "The users' compliance rates θi,rec further influence the regret by affecting the Lipschitz constant L... When θi,rec is large, the recommended option tends to dominate the user's decision, making them more likely to choose it regardless of other parameter values. This leads to smaller differences in user behavior and, consequently, a smaller Lipschitz constant L which significantly reduces the upper bound on regret."
  - [corpus]: No direct corpus evidence supporting this specific mechanism. The paper's own analysis is the primary source.
- **Break condition**: If the relationship between compliance rates and the Lipschitz constant is not as assumed (e.g., non-monotonic or threshold effects), the theoretical advantage may not materialize. Also, if compliance rates are uniformly low, the benefit disappears.

## Foundational Learning

- **Concept**: Contextual bandits and the exploration-exploitation tradeoff
  - Why needed here: EWC is built on the contextual bandit framework, where the system must balance recommending known good options (exploitation) with trying new options to learn user preferences (exploration). Understanding this tradeoff is essential to grasp how EWC differs from pure supervised learning.
  - Quick check question: What is the main challenge that contextual bandits address compared to traditional multi-armed bandits?

- **Concept**: Clustering algorithms and their use in collaborative filtering
  - Why needed here: EWC uses K-Means clustering to group users by preference similarity, then uses cluster centroids as experts. Knowledge of how clustering works, its limitations (e.g., sensitivity to initialization, choice of K), and its role in collaborative filtering is crucial to understand EWC's approach.
  - Quick check question: How does K-Means clustering determine which cluster a data point belongs to?

- **Concept**: Logistic regression and its sample complexity
  - Why needed here: The user non-compliance model reduces to logistic regression when using two-option updates, and the paper analyzes its sample complexity to show how fast user preference parameters can be learned. Understanding logistic regression, its assumptions (e.g., linear decision boundary, independence of observations), and sample complexity bounds is necessary to follow this analysis.
  - Quick check question: What is the key assumption about the relationship between input features and log-odds in logistic regression?

## Architecture Onboarding

- **Component map**: User Non-compliance Model -> Clustering Module -> Expert Framework -> User Context Integration -> Recommendation Engine
- **Critical path**: Offline Training → Clustering → Online Learning → Regret Minimization
  1. Offline Training: Use user non-compliance model on historical data to learn θi for all users.
  2. Clustering: Apply K-Means with loss-guided distance to cluster users by θi, creating experts (centroids).
  3. Context Prediction: Train logistic regression to map user contexts to cluster probabilities.
  4. Online Learning: For each new user, initialize expert weights using context prediction, then use Hedge to select experts and update based on observed choices.
- **Design tradeoffs**:
  - Clustering granularity (K): Small K may oversimplify user diversity, large K may overfit and slow learning.
  - Offline vs. Online learning: Offline learning of θi provides accuracy but may not adapt to evolving preferences; online learning adapts but may be less accurate initially.
  - Linear vs. Non-linear models: The user non-compliance model assumes linearity for simplicity, but may miss complex preference patterns.
- **Failure signatures**:
  - High regret in early rounds: Indicates poor initialization of expert weights or ineffective clustering.
  - Regret plateaus without decreasing: Suggests the model has converged to a suboptimal solution, possibly due to incorrect clustering or insufficient exploration.
  - Large variance in regret across runs: Indicates sensitivity to initialization or data noise.
- **First 3 experiments**:
  1. **Ablation study baseline**: Run EWC without the user non-compliance model (use a simple linear model instead) to quantify the benefit of accounting for the anchoring effect.
  2. **Clustering sensitivity**: Vary the number of clusters K and measure regret to find the optimal granularity for the given dataset.
  3. **Context utility**: Run EWC without using user context to predict initial expert weights (initialize uniformly) to measure the acceleration benefit of context integration.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the regret bound of EWC compare to LinUCB in the long-term regime when the number of users N is small but the number of rounds per user T is very large?
- **Basis in paper**: [explicit] The paper states that EWC does not achieve sublinear regret in the long term because it uses the cluster centroid as an estimate of user-specific preferences each time, but provides a comparison showing EWC has superior theoretical performance in the short term compared to LinUCB.
- **Why unresolved**: The paper only provides a theoretical comparison showing EWC's advantage in the short term. It does not analyze or provide empirical evidence for the long-term regime when T is very large.
- **What evidence would resolve it**: A theoretical analysis or extensive empirical evaluation comparing EWC and LinUCB's regret bounds in scenarios with varying T and N values, particularly focusing on the long-term regime with small N and large T.

### Open Question 2
- **Question**: How does the performance of EWC scale with the number of clusters K, and is there an optimal number of clusters that minimizes regret?
- **Basis in paper**: [inferred] The paper mentions that K is a hyperparameter and evaluates different values on the offline training set to choose the one that yields the minimum regret, but does not provide a detailed analysis of how EWC's performance scales with K or identify an optimal K.
- **Why unresolved**: The paper does not provide a systematic analysis of the relationship between the number of clusters K and EWC's regret, nor does it identify an optimal K value.
- **What evidence would resolve it**: A detailed analysis or empirical evaluation of EWC's performance across a range of K values, identifying the optimal K that minimizes regret for different problem settings and data distributions.

### Open Question 3
- **Question**: How does the user non-compliance model's assumption of a linear relationship between option context and user preferences affect its performance in scenarios with complex, non-linear preference structures?
- **Basis in paper**: [explicit] The paper mentions that the current user non-compliance model assumes a linear relationship between option context and user preferences, and suggests extending this component with kernel methods or nonlinear models to better handle nonlinear relationships as a direction for future work.
- **Why unresolved**: The paper does not provide empirical evidence or theoretical analysis of the user non-compliance model's performance in scenarios with non-linear preference structures, nor does it compare it to potential nonlinear extensions.
- **What evidence would resolve it**: An empirical evaluation comparing the performance of the linear user non-compliance model to nonlinear extensions (e.g., kernel methods, neural networks) in scenarios with known non-linear preference structures, and a theoretical analysis of the impact of the linearity assumption on the model's sample complexity and regret bounds.

## Limitations
- Theoretical regret bound depends heavily on the Lipschitz constant L, which is influenced by user compliance rates - this relationship is assumed but not empirically validated across diverse user populations
- Clustering approach assumes user preferences exhibit a stable hierarchical structure that can be captured by K-Means, but real-world preference drift or context-dependent clustering could violate this assumption
- Model's performance may degrade in scenarios with very low compliance rates or when user preferences are highly individualistic (K approaches N)

## Confidence
- **High confidence**: The core mechanism of using clustering to accelerate preference learning by sharing information across similar users is well-supported by the theoretical analysis and experimental results
- **Medium confidence**: The parameterization of the anchoring effect and its integration into the user non-compliance model is theoretically sound, but its effectiveness may vary depending on the specific nature of user non-compliance in different domains
- **Medium confidence**: The regret bound improvement with increased compliance rates is derived analytically but requires more empirical validation across different compliance distributions

## Next Checks
1. **Compliance rate sensitivity**: Systematically vary user compliance rates in simulation to empirically verify the relationship between compliance, Lipschitz constant, and regret bound, testing both monotonic and threshold effects
2. **Preference drift robustness**: Evaluate EWC's performance when user preferences evolve over time by introducing synthetic drift patterns and measuring clustering stability and regret accumulation
3. **Alternative clustering validation**: Replace K-Means with alternative clustering methods (e.g., hierarchical clustering, DBSCAN) to test whether the specific choice of clustering algorithm affects EWC's performance or if the approach is more generally applicable