---
ver: rpa2
title: 'Large Language Model based Multi-Agents: A Survey of Progress and Challenges'
arxiv_id: '2402.01680'
source_url: https://arxiv.org/abs/2402.01680
tags:
- agents
- arxiv
- systems
- agent
- llm-ma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper surveys LLM-based multi-agent systems, covering their
  applications in problem-solving and world simulation across domains like software
  development, embodied AI, gaming, and societal modeling. It categorizes agent-environment
  interfaces, profiling methods, communication structures, and capability acquisition
  strategies.
---

# Large Language Model based Multi-Agents: A Survey of Progress and Challenges

## Quick Facts
- arXiv ID: 2402.01680
- Source URL: https://arxiv.org/abs/2402.01680
- Reference count: 15
- Primary result: Comprehensive survey of LLM-based multi-agent systems covering applications, architectures, and challenges

## Executive Summary
This survey provides a systematic overview of Large Language Model (LLM) based multi-agent systems, analyzing their architecture, applications, and challenges. The paper categorizes these systems based on their agents-environment interfaces (Sandbox, Physical, None), agent profiling methods (Pre-defined, Model-Generated, Data-Derived), communication structures (Layered, Decentralized, Centralized, Shared Message Pool), and capability acquisition approaches (Memory, Self-Evolution, Dynamic Generation). The survey identifies significant progress in complex problem-solving and world simulation across domains like software development, embodied AI, gaming, and societal modeling, while highlighting critical challenges including hallucination, scalability, and the acquisition of collective intelligence.

## Method Summary
The survey methodology involves a comprehensive literature review of existing LLM-based multi-agent systems, categorizing them according to their architectural components and application domains. The authors systematically analyzed papers to identify common patterns in how these systems are designed and deployed, organizing their findings into a framework that covers agent-environment interfaces, profiling methods, communication structures, and capability acquisition strategies. The survey also identifies open challenges and opportunities for future research in this rapidly evolving field.

## Key Results
- LLM-based multi-agent systems achieve superior problem-solving by combining specialized agent profiles with collaborative communication structures
- Three distinct agents-environment interfaces (Sandbox, Physical, None) determine the types of tasks agents can perform and how they receive feedback
- Capability acquisition through memory, self-evolution, and dynamic generation enables agents to adapt and improve over time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based multi-agent systems achieve superior problem-solving and world simulation by combining specialized agent profiles with collaborative communication structures.
- Mechanism: The survey shows that distinct agent profiles (like product manager, programmer, robot specialists) combined with communication paradigms (cooperative, debate, competitive) enable division of labor and emergent collective intelligence that single-agent systems cannot replicate.
- Core assumption: Agents can be effectively profiled to match specific roles and that communication structures can be designed to facilitate meaningful collaboration toward shared goals.
- Evidence anchors:
  - [abstract] "LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation"
  - [section] "Compared to systems using a single LLM-powered agent, multi-agent systems offer advanced capabilities by 1) specializing LLMs into various distinct agents, each with different capabilities, and 2) enabling interactions among these diverse agents"
  - [corpus] Weak - only survey papers in related works, no experimental validation cited
- Break condition: When agent profiling becomes too generic or communication structures become too complex to manage effectively, leading to coordination overhead that outweighs benefits.

### Mechanism 2
- Claim: The agents-environment interface determines how effectively multi-agent systems can operate in different domains.
- Mechanism: The survey categorizes interfaces into Sandbox (simulated environments), Physical (real-world), and None (no external environment), showing that the choice of interface directly impacts the types of tasks agents can perform and how they receive feedback.
- Core assumption: The environment provides meaningful feedback that agents can use to improve their performance over time.
- Evidence anchors:
  - [section] "The operational environments defines the specific contexts or settings in which the LLM-MA systems are deployed and interact"
  - [section] "We categorize the current interfaces in LLM-MA systems into three types, Sandbox, Physical, and None"
  - [corpus] Missing - no empirical data on interface effectiveness across domains
- Break condition: When the environment feedback is insufficient, delayed, or too noisy for agents to learn meaningful patterns.

### Mechanism 3
- Claim: Capability acquisition through memory, self-evolution, and dynamic generation enables agents to adapt and improve over time.
- Mechanism: The survey describes three main approaches for agents to adjust their capabilities: storing successful actions in memory, dynamically modifying goals and strategies through self-evolution, and generating new agents on-the-fly to meet emerging needs.
- Core assumption: Agents can learn from feedback (environmental, agent interactions, or human) and apply this learning to improve future performance.
- Evidence anchors:
  - [section] "Agents Capabilities Acquisition is a crucial process in LLM-MA, enabling agents to learn and evolve dynamically"
  - [section] "To enhance their capabilities, agents in LLM-MA systems can adapt through three main solutions: Memory, Self-Evolution, and Dynamic Generation"
  - [corpus] Missing - no quantitative comparison of different capability acquisition methods
- Break condition: When feedback loops are broken or when the cost of adaptation exceeds the performance gains.

## Foundational Learning

- Concept: Multi-agent system architecture
  - Why needed here: Understanding how multiple autonomous agents coordinate and communicate is fundamental to designing effective LLM-based multi-agent systems
  - Quick check question: What are the three main communication paradigms identified in the survey, and how do they differ in their approach to agent interaction?

- Concept: Agent profiling and specialization
  - Why needed here: Creating distinct agent profiles with specialized capabilities is essential for achieving the division of labor that makes multi-agent systems effective
  - Quick check question: How does the survey categorize agent profiling methods, and what are the key differences between pre-defined, model-generated, and data-derived approaches?

- Concept: Feedback mechanisms in learning systems
  - Why needed here: Understanding how agents receive and process feedback is crucial for designing systems that can adapt and improve over time
  - Quick check question: What are the four types of feedback sources mentioned in the survey, and how do they impact agent capability acquisition?

## Architecture Onboarding

- Component map: Agents (profiles, capabilities, communication modules) → Environment interface (Sandbox/Physical/None) → Communication infrastructure (Layered/Decentralized/Centralized/Shared Message Pool) → Capability acquisition (Memory/Self-Evolution/Dynamic Generation)
- Critical path: Agent profiling → Environment interface setup → Communication structure configuration → Capability acquisition mechanism implementation → Evaluation and iteration
- Design tradeoffs: Specialized agents vs. generalization (more specialized agents require more complex coordination), centralized vs. decentralized communication (centralized is easier to manage but creates bottlenecks), memory-based vs. self-evolution learning (memory is simpler but self-evolution enables more adaptive behavior)
- Failure signatures: Agents failing to coordinate effectively, communication overhead overwhelming system performance, agents not adapting to feedback, system scaling issues with increasing agent count
- First 3 experiments:
  1. Implement a simple two-agent cooperative system for a basic software development task (e.g., code review and testing) to validate communication and coordination mechanisms
  2. Test different agent profiling methods (pre-defined vs. model-generated) on a simple debate task to compare effectiveness
  3. Implement a small-scale world simulation with 5-10 agents to test environment interface and feedback mechanisms in a controlled setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the scaling laws governing the behavior and efficiency of LLM-based multi-agent systems as the number of agents increases?
- Basis in paper: [explicit] The paper discusses the challenge of scaling up LLM-based multi-agent systems and mentions the need to explore and define the scaling laws that govern the behavior and efficiency of these systems as they grow larger.
- Why unresolved: While the paper highlights the importance of understanding scaling laws, it does not provide any specific insights or research findings on this topic. The complex interactions and emergent behaviors in larger systems make it difficult to predict how the system's performance will change with increasing agent numbers.
- What evidence would resolve it: Empirical studies that systematically vary the number of agents in LLM-based multi-agent systems and measure their performance on various tasks. These studies should analyze the relationships between agent count, task completion time, resource utilization, and overall system effectiveness to identify potential scaling laws.

### Open Question 2
- Question: How can hallucination in LLM-based multi-agent systems be effectively detected and mitigated, considering the potential cascading effects of misinformation?
- Basis in paper: [explicit] The paper explicitly identifies hallucination as a significant challenge in LLM-based multi-agent systems, noting that one agent's hallucination can have a cascading effect due to the interconnected nature of these systems.
- Why unresolved: While the paper acknowledges the problem, it does not propose any specific solutions or methodologies for detecting and mitigating hallucinations in multi-agent settings. The complex communication patterns and potential for misinformation spread make this a challenging problem to address.
- What evidence would resolve it: Development and evaluation of novel techniques for detecting and correcting hallucinations in LLM-based multi-agent systems. These techniques should be able to identify the source of misinformation, prevent its spread to other agents, and maintain the overall integrity of the system's outputs.

### Open Question 3
- Question: How can collective intelligence be effectively acquired and leveraged in LLM-based multi-agent systems, beyond the current approaches of memory and self-evolution?
- Basis in paper: [explicit] The paper discusses the challenge of acquiring collective intelligence in LLM-based multi-agent systems, noting that current approaches like memory and self-evolution adjust agents in isolation and do not fully capitalize on the potential synergistic effects of coordinated multi-agent interactions.
- Why unresolved: The paper highlights the limitations of existing approaches but does not provide concrete solutions for achieving optimal collective intelligence in these systems. The complex dynamics of multi-agent interactions and the need for coordinated learning make this a challenging problem to solve.
- What evidence would resolve it: Development and evaluation of novel techniques that enable coordinated learning and knowledge sharing among agents in LLM-based multi-agent systems. These techniques should facilitate the emergence of collective intelligence by allowing agents to learn from each other's experiences and adapt their behaviors in a synergistic manner.

## Limitations
- The survey relies entirely on existing literature without presenting original experimental validation, creating uncertainty about the practical effectiveness of the categorized approaches
- The mechanisms described are theoretical constructs derived from survey analysis rather than empirically tested systems
- The rapid evolution of LLM technology means some survey findings may become outdated quickly

## Confidence
- **High Confidence:** The categorization framework for agents-environment interfaces, agent profiling methods, and communication structures is well-supported by the literature and provides a useful organizing principle for understanding LLM-based multi-agent systems
- **Medium Confidence:** The identified challenges (hallucination, scalability, collective intelligence) are well-documented in the literature, but their relative importance and severity across different application domains remains unclear without empirical data
- **Low Confidence:** The effectiveness of different capability acquisition methods (memory, self-evolution, dynamic generation) cannot be confidently assessed without comparative experimental studies across multiple domains and task types

## Next Checks
1. Conduct a controlled experiment comparing centralized versus decentralized communication structures in a software development task, measuring coordination efficiency and final output quality across teams of varying sizes
2. Implement and test the three different agent profiling methods (pre-defined, model-generated, data-derived) on a standardized debate task to empirically compare their effectiveness in producing specialized, competent agents
3. Design a benchmark evaluation framework for LLM-based multi-agent systems that includes metrics for coordination overhead, collective intelligence emergence, and adaptation speed across different environmental interfaces