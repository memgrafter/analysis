---
ver: rpa2
title: Open-Set Domain Adaptation for Semantic Segmentation
arxiv_id: '2405.19899'
source_url: https://arxiv.org/abs/2405.19899
tags:
- classes
- domain
- unknown
- target
- private
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the novel task of Open-Set Domain Adaptation
  for Semantic Segmentation (OSDA-SS), where the target domain contains unknown classes
  not present in the source domain. The authors identify two key challenges: difficulty
  in accurately predicting boundaries between known and unknown classes, and challenges
  in correctly identifying the shape of unknown objects.'
---

# Open-Set Domain Adaptation for Semantic Segmentation

## Quick Facts
- arXiv ID: 2405.19899
- Source URL: https://arxiv.org/abs/2405.19899
- Authors: Seun-An Choe; Ah-Hyung Shin; Keon-Hee Park; Jinwoo Choi; Gyeong-Moon Park
- Reference count: 40
- Primary result: Proposes BUS method with DECON loss and OpenReMix, achieving state-of-the-art H-Score on GTA5→Cityscapes and SYNTHIA→Cityscapes benchmarks

## Executive Summary
This paper introduces BUS (Boundary-aware Unknown-aware Segmentation), a novel approach for Open-Set Domain Adaptation in Semantic Segmentation (OSDA-SS). The method addresses the challenge of segmenting target images containing unknown classes not present in the source domain. BUS combines head expansion with two key innovations: DECON loss for boundary discrimination using morphological operations, and OpenReMix for size-invariant learning through domain mixing augmentation. The approach significantly improves the harmonic mean (H-Score) of known and unknown class performance compared to previous methods.

## Method Summary
BUS extends standard UDA for semantic segmentation by expanding the classification head from C to (C+1) dimensions, where the additional head represents unknown classes. The method introduces DECON loss, which applies dilation and erosion operations to pseudo-labels to create boundary masks for contrastive learning between known and unknown regions. OpenReMix augments training by mixing resized source objects into target images and pasting target unknown regions into source images, enabling the model to learn size-invariant features and better recognize unknown class shapes. The approach is built on the DAFormer architecture with MiT-B5 encoder and trained with AdamW optimizer using confidence-based pseudo-label thresholding.

## Key Results
- BUS achieves state-of-the-art H-Score on GTA5→Cityscapes and SYNTHIA→Cityscapes benchmarks
- Significant improvements in H-Score (harmonic mean of known and unknown class performance) compared to previous methods
- DECON loss effectively improves boundary prediction between known and unknown classes
- OpenReMix enhances shape detection of unknown classes through size-invariant feature learning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** DECON loss improves boundary discrimination between known and unknown classes by using morphological operations to create explicit positive/negative samples for contrastive learning.
- **Mechanism:** The method applies dilation and erosion to the target private mask to create boundary masks (MN) and erosion masks (MP). These masks are used to generate anchor, positive, and negative samples for contrastive learning. The contrastive loss pulls features of confident private class regions (positive) away from boundary regions (negative), sharpening the distinction.
- **Core assumption:** Morphological operations like dilation and erosion can reliably extract boundary and confident regions that reflect the true structure of unknown classes.
- **Evidence anchors:**
  - [abstract] "Our BUS can accurately discern the boundaries between known and unknown classes in a contrastive manner using a novel dilation-erosion-based contrastive loss."
  - [section 3.3] "To discern the boundaries effectively, we leverage two morphological operations, which are dilation and erosion."
  - [corpus] No direct evidence found; this appears to be novel to the paper.
- **Break condition:** If morphological operations fail to align with semantic boundaries (e.g., due to noise, texture, or complex object shapes), the contrastive signal becomes misleading.

### Mechanism 2
- **Claim:** OpenReMix enables shape-invariant learning by mixing resized source objects into target images and pasting target unknown regions into source images.
- **Mechanism:** The method resizes a random "thing" class from the source and mixes it into the target, training the model to recognize objects regardless of size. It also copies target unknown regions and pastes them into source images, allowing the expanded head to learn to reject unknown classes even when no ground truth is available.
- **Core assumption:** The model can learn shape-invariant features if it sees the same object at different scales during training.
- **Evidence anchors:**
  - [abstract] "we propose OpenReMix, a new domain mixing augmentation method that guides our model to effectively learn domain and size-invariant features for improving the shape detection of the known and unknown classes."
  - [section 3.4] "We hypothesize that if a model consistently predicts the same object regardless of size variations, the model can accurately predict the shape of the object as well."
  - [corpus] No direct evidence found; appears to be novel.
- **Break condition:** If the resized objects or pasted regions are too small/large or contextually implausible, the model may learn spurious correlations instead of true shape invariance.

### Mechanism 3
- **Claim:** Head expansion with confidence-based thresholding allows the model to explicitly learn an "unknown" class without corrupting known class predictions.
- **Mechanism:** The classification head is expanded from C to (C+1) dimensions, where the (C+1)-th head represents unknown classes. Pseudo-labels are generated with a threshold; low-confidence pixels are assigned to the unknown head, enabling supervised learning on unknown regions via OpenReMix and DECON loss.
- **Core assumption:** The model's softmax outputs are reasonably calibrated so that thresholding can reliably separate known from unknown.
- **Evidence anchors:**
  - [abstract] "Another baseline could be a head-expansion baseline...we expand the classification head from C to (C + 1) dimensions..."
  - [section 3.2] "We build a OSDA-SS baseline by extending the number of classifier heads from C to (C + 1), where the (C + 1)-th head corresponds to unknown classes."
  - [corpus] Weak evidence; thresholding strategies are common but this specific head expansion is novel.
- **Break condition:** If the model is poorly calibrated or the domain gap is too large, thresholding may mislabel known as unknown or vice versa, corrupting both heads.

## Foundational Learning

- **Concept:** Unsupervised Domain Adaptation (UDA) for semantic segmentation
  - **Why needed here:** The paper builds on UDA as a foundation, extending it to open-set scenarios where target classes are not seen during training.
  - **Quick check question:** In standard UDA for semantic segmentation, what assumption about label spaces is typically made, and why is it problematic in real-world deployment?

- **Concept:** Contrastive learning with positive/negative sample pairs
  - **Why needed here:** DECON loss relies on contrastive objectives to sharpen boundaries; understanding how contrastive loss pulls positives together and pushes negatives apart is key.
  - **Quick check question:** In a contrastive setup, what roles do the anchor, positive, and negative samples play, and how does temperature scaling affect the loss?

- **Concept:** Domain mixing augmentation (e.g., ClassMix)
  - **Why needed here:** OpenReMix is an extension of domain mixing techniques; knowing how mixing encourages domain invariance helps understand the size-invariance motivation.
  - **Quick check question:** How does mixing source and target patches encourage the model to learn domain-invariant features, and what might happen if the mix is too aggressive?

## Architecture Onboarding

- **Component map:**
  - Encoder: MiT-B5 (pre-trained on ImageNet-1K)
  - Decoder: Standard segmentation head with C+1 output channels
  - Teacher network: EMA-updated copy for pseudo-label generation
  - DECON module: Applies morphological ops and contrastive loss
  - OpenReMix augmentation: Mixes resized objects and pastes unknown regions
  - Refinement: MobileSAM-based refinement applied every 10k iterations

- **Critical path:**
  1. Forward pass through encoder/decoder to get predictions
  2. Generate pseudo-labels using teacher and threshold
  3. Apply OpenReMix to create mixed source/target images
  4. Compute supervised loss on source and adaptation loss on target
  5. Apply DECON loss using morphological masks from pseudo-labels
  6. Update model and EMA teacher

- **Design tradeoffs:**
  - Head expansion vs. confidence thresholding: Head expansion enables explicit learning of unknown but increases parameter count; thresholding is lighter but may be less robust.
  - DECON vs. standard contrastive: DECON uses morphological cues for boundaries, which may be more reliable than random sampling but depends on mask quality.
  - OpenReMix complexity: Adds augmentation logic and memory overhead but improves shape invariance.

- **Failure signatures:**
  - Degraded performance on known classes: Likely from over-aggressive thresholding or DECON loss pulling known features toward unknown.
  - Poor unknown detection: Could indicate low-quality pseudo-labels or ineffective OpenReMix.
  - Slow convergence: May suggest high variance in OpenReMix or instability in DECON loss.

- **First 3 experiments:**
  1. **Baseline sanity check:** Run the head-expansion baseline on GTA5→Cityscapes to confirm it outperforms confidence-thresholding.
  2. **DECON ablation:** Remove DECON loss and compare H-Score; verify improvement comes from boundary discrimination.
  3. **OpenReMix ablation:** Disable OpenReMix and compare shape detection on unknown classes; confirm size-invariance benefit.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed BUS method perform when applied to real-world scenarios where unknown classes may emerge dynamically during operation?
- Basis in paper: [inferred] The paper demonstrates effectiveness on synthetic-to-real benchmarks (GTA5 → Cityscapes, SYNTHIA → Cityscapes) but does not evaluate dynamic emergence of unknown classes.
- Why unresolved: The current evaluation assumes a fixed set of unknown classes defined during training, while real-world applications may encounter novel classes not present in the training data.
- What evidence would resolve it: Experiments on datasets with dynamically introduced unknown classes during inference, or on real-world autonomous driving datasets where new object categories emerge.

### Open Question 2
- Question: What is the computational overhead introduced by the DECON loss and OpenReMix augmentation compared to standard UDA methods?
- Basis in paper: [explicit] The paper mentions that OpenReMix involves additional processing steps like resizing and mixing operations, and DECON loss requires morphological operations and contrastive learning.
- Why unresolved: While the paper demonstrates performance improvements, it does not quantify the computational cost or memory requirements of these additional components.
- What evidence would resolve it: Detailed runtime analysis comparing BUS with baseline methods, including training time, inference latency, and memory consumption.

### Open Question 3
- Question: How sensitive is the BUS method to the choice of pseudo-label generation threshold (τp) and refinement network quality?
- Basis in paper: [explicit] The paper shows sensitivity to τp in Table 5 and uses MobileSAM for refinement, but does not extensively analyze how refinement quality affects overall performance.
- Why unresolved: The effectiveness of both DECON loss and OpenReMix depends on the quality of pseudo-labels, which are threshold-dependent and refined using MobileSAM.
- What evidence would resolve it: Ablation studies varying refinement network quality, and analysis of performance degradation with different pseudo-label quality levels.

## Limitations
- Effectiveness of DECON loss depends on morphological operations reliably identifying true boundary regions, which may fail with complex textures or noisy masks
- OpenReMix assumes resizing objects preserves shape semantics, but extreme scale changes could break this assumption
- Method assumes unknown classes in target are semantically distinct from source classes, which may not hold in all real-world scenarios

## Confidence

- DECON loss boundary discrimination: Medium (relies on unproven assumption about morphological reliability)
- OpenReMix shape invariance: Medium (lacks ablation showing scale sensitivity)
- Head expansion baseline: Low (novel formulation without extensive comparative analysis)

## Next Checks
1. Perform scale sensitivity analysis for OpenReMix by varying resize ratios and measuring impact on unknown class IoU
2. Evaluate DECON loss robustness by adding synthetic noise to pseudo-labels and measuring boundary accuracy degradation
3. Conduct calibration analysis of softmax outputs to verify threshold-based pseudo-label quality across domain gaps