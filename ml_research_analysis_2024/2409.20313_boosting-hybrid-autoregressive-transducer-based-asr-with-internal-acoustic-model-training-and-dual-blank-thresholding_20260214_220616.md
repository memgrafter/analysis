---
ver: rpa2
title: Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic
  Model Training and Dual Blank Thresholding
arxiv_id: '2409.20313'
source_url: https://arxiv.org/abs/2409.20313
tags: []
core_contribution: The paper addresses slow decoding in HAT-based ASR due to per-frame
  softmax over large vocabularies. It proposes joint training of HAT with internal
  acoustic model (IAM), where IAM shares encoder and joint networks with HAT, enabling
  synchronous blank emissions and faster CTC-blank thresholding.
---

# Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding

## Quick Facts
- arXiv ID: 2409.20313
- Source URL: https://arxiv.org/abs/2409.20313
- Reference count: 0
- Primary result: HAT with IAM and dual blank thresholding achieves 42-75% decoding speed-up with no significant WER degradation on TLv2 and LibriSpeech datasets.

## Executive Summary
This paper tackles the slow decoding problem in Hybrid Autoregressive Transducer (HAT)-based ASR systems caused by per-frame softmax operations over large vocabularies. The authors propose joint training of HAT with an Internal Acoustic Model (IAM), where IAM shares encoder and joint networks with HAT, enabling synchronous blank emissions and faster CTC-blank thresholding. They introduce dual blank thresholding, combining IAM- and HAT-blank thresholding with a compatible decoding algorithm to skip non-blank computations. Experiments demonstrate significant decoding speed-ups (42-75%) across Chinese and English datasets with minimal WER impact.

## Method Summary
The approach introduces an Internal Acoustic Model (IAM) that shares the encoder and joint networks with the HAT model. IAM is trained to predict blank tokens using CTC loss, while HAT performs standard autoregressive decoding. The dual blank thresholding mechanism uses both IAM-blank and HAT-blank predictions to skip unnecessary non-blank computations during decoding. A compatible decoding algorithm synchronizes the blank emission patterns between IAM and HAT, enabling faster threshold-based decoding without sacrificing accuracy.

## Key Results
- 42-75% decoding speed-up achieved on TLv2 and LibriSpeech datasets
- RTF improves from 0.344 to 0.098 on TLv2
- RTF improves from 0.448 to 0.246 on LibriSpeech
- No significant WER degradation observed

## Why This Works (Mechanism)
The method works by exploiting the shared architecture between IAM and HAT. Since both models use the same encoder and joint networks, they naturally learn similar blank emission patterns. IAM-blank thresholding provides faster, CTC-style blank detection, while HAT-blank thresholding maintains autoregressive consistency. The dual approach allows skipping expensive non-blank softmax computations when either model predicts a blank, dramatically reducing computational overhead per frame.

## Foundational Learning
- **Hybrid Autoregressive Transducer (HAT)**: Combines CTC and attention-based decoding in a single framework. Needed for understanding the baseline architecture being optimized. Quick check: Verify HAT uses both blank prediction and attention-based token generation.
- **Internal Acoustic Model (IAM)**: A CTC-style model that shares weights with HAT. Provides fast blank detection capability. Quick check: Confirm IAM uses CTC loss and shares encoder/joint networks with HAT.
- **Dual Blank Thresholding**: Uses both IAM-blank and HAT-blank predictions for efficient decoding. Enables skipping non-blank computations. Quick check: Verify both models can independently predict blanks and their predictions are compatible.
- **Synchronous Blank Emission**: Blank predictions from IAM and HAT occur at the same frames due to shared architecture. Critical for dual thresholding to work. Quick check: Confirm blank emission patterns align between IAM and HAT during inference.

## Architecture Onboarding
**Component Map**: Encoder -> Joint Network -> [IAM Head (CTC) + HAT Head (AR)]
**Critical Path**: Input frames → Encoder → Joint Network → Blank decision (IAM/HAT) → Skip/Proceed → Output token
**Design Tradeoffs**: IAM provides speed but may lack context sensitivity; HAT provides accuracy but is slower. Dual thresholding balances both.
**Failure Signatures**: Misaligned blank predictions between IAM and HAT; degradation in WER despite speed gains; compatibility issues with decoding algorithm.
**First Experiments**: 1) Test blank prediction accuracy separately for IAM and HAT. 2) Measure speedup from single vs dual blank thresholding. 3) Validate WER stability across different vocabulary sizes.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to Chinese (TLv2) and English (LibriSpeech) datasets, limiting cross-linguistic generalizability
- Assumes synchronous blank emission patterns may not hold for morphologically complex languages
- Streaming ASR compatibility and real-time latency constraints not explicitly validated

## Confidence
- **High confidence**: Experimental methodology and baseline comparisons are sound with clear RTF improvements
- **Medium confidence**: Scalability claims to larger vocabularies are supported but need validation in open-vocabulary settings
- **Medium confidence**: IAM-HAT architecture benefits are well-demonstrated, though long-term training stability needs more investigation

## Next Checks
1. Evaluate dual blank thresholding on morphologically rich languages (Finnish, Turkish) to assess cross-linguistic robustness
2. Test streaming compatibility under strict real-time constraints (200ms end-to-end delay) on same datasets
3. Benchmark against hybrid CTC/attention models with similar vocabulary sizes to establish relative efficiency gains