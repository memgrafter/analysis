---
ver: rpa2
title: A Strategy to Combine 1stGen Transformers and Open LLMs for Automatic Text
  Classification
arxiv_id: '2408.09629'
source_url: https://arxiv.org/abs/2408.09629
tags:
- llms
- few-shot
- sttrs
- cost
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether open large language models (LLMs)
  can outperform first-generation transformer models (1stTRs) for sentiment analysis.
  We compare three 1stTRs (BERT, RoBERTa, BART) with two open LLMs (Llama 2, Bloom)
  across 11 datasets.
---

# A Strategy to Combine 1stGen Transformers and Open LLMs for Automatic Text Classification

## Quick Facts
- arXiv ID: 2408.09629
- Source URL: https://arxiv.org/abs/2408.09629
- Reference count: 24
- Open LLMs moderately outperform or match 1st-generation transformers for sentiment analysis when fine-tuned

## Executive Summary
This study investigates whether open large language models (LLMs) can outperform first-generation transformer models (1stTRs) for sentiment analysis. The researchers compare three 1stTRs (BERT, RoBERTa, BART) with two open LLMs (Llama 2, Bloom) across 11 datasets. Results show that open LLMs moderately outperform or match 1stTRs in 8 out of 11 datasets, but only when fine-tuned. Given the high computational costs of fine-tuning LLMs for modest gains, the team proposes a confidence-based strategy called "Call My Big Sibling" (CMBS) that combines 1stTRs and LLMs.

## Method Summary
The researchers evaluate three 1st-generation transformers (BERT, RoBERTa, BART) against two open LLMs (Llama 2, Bloom) on 11 sentiment analysis datasets. They compare zero-shot, few-shot, and fine-tuned configurations across all models. The CMBS strategy routes high-confidence documents to cost-effective 1stTRs while sending uncertain cases to LLMs in zero-shot or few-shot modes. The confidence thresholds for routing are determined through validation sets, and computational costs are measured across different hardware configurations.

## Key Results
- Open LLMs moderately outperform or match 1stTRs in 8 out of 11 datasets when fine-tuned
- CMBS strategy achieves comparable results to fine-tuned LLMs at 1/13th the computational cost on average
- High-confidence documents can be reliably classified by 1stTRs, enabling cost-effective routing

## Why This Works (Mechanism)
The strategy leverages the complementary strengths of 1stTRs and LLMs. First-generation transformers provide fast, cost-effective classification for clear-cut cases with high confidence scores. Open LLMs, despite their computational overhead, excel at handling ambiguous or complex cases where 1stTRs show uncertainty. By routing documents based on confidence scores, the system achieves better overall performance while minimizing expensive LLM computations.

## Foundational Learning
- **Sentiment analysis fundamentals**: Understanding how models detect polarity in text is crucial for evaluating performance on these datasets
  - Why needed: Provides context for why 1stTRs and LLMs might differ in their capabilities
  - Quick check: Review the 11 datasets to understand their characteristics and domains

- **Fine-tuning vs. zero-shot learning**: Different training paradigms affect model performance and computational requirements
  - Why needed: Explains the performance differences observed between training approaches
  - Quick check: Compare accuracy metrics across fine-tuned, few-shot, and zero-shot configurations

- **Confidence scoring in classification**: How models quantify uncertainty in their predictions
  - Why needed: Central to the CMBS routing strategy's effectiveness
  - Quick check: Analyze the distribution of confidence scores from 1stTRs on validation sets

## Architecture Onboarding

Component map: Input text -> 1stTR confidence scoring -> Confidence threshold check -> Route to 1stTR or LLM -> Output classification

Critical path: The routing decision based on confidence thresholds determines whether computation uses fast 1stTRs or expensive LLMs. This threshold must balance cost savings against accuracy requirements.

Design tradeoffs: The system trades computational efficiency against potential accuracy loss on borderline cases. Lower confidence thresholds reduce LLM calls but may miss complex cases that require LLM reasoning.

Failure signatures: Over-aggressive routing to 1stTRs may miss nuanced sentiment cases. Under-aggressive routing wastes LLM resources on clear-cut cases. Threshold miscalibration can lead to either failure mode.

First experiments:
1. Run 1stTRs on a validation set and analyze confidence score distributions to establish baseline thresholds
2. Test CMBS routing on a small subset of data with varying thresholds to find the optimal balance
3. Compare computational costs between full fine-tuning, pure 1stTR classification, and CMBS across different dataset sizes

## Open Questions the Paper Calls Out
The study focuses exclusively on sentiment analysis, raising questions about whether the CMBS strategy generalizes to other classification tasks like topic classification or intent detection. The computational cost analysis assumes specific hardware configurations, which may vary significantly across different setups. The confidence-based routing strategy requires establishing appropriate thresholds, which were determined through validation sets but may need adjustment for different domains or dataset characteristics.

## Limitations
- Results may not generalize beyond sentiment analysis to other classification tasks
- Only tested with relatively small open LLMs (7B and 13B parameters) against 1st-generation transformers
- Computational cost analysis depends on specific hardware configurations that may not reflect all deployment scenarios

## Confidence

**Major claim clusters and confidence:**

- **Open LLMs moderately outperform 1stTRs for sentiment analysis when fine-tuned (High confidence)**: Strong experimental evidence across 11 datasets
- **CMBS strategy achieves comparable results to fine-tuned LLMs at significantly lower cost (Medium confidence)**: Compelling cost reduction but depends on implementation choices
- **High-confidence documents can be reliably classified by 1stTRs (Medium confidence)**: Validated through experiments but may not hold universally

## Next Checks

1. Test the CMBS strategy on non-sentiment classification tasks (e.g., topic classification, intent detection) to assess generalizability beyond the current domain.

2. Evaluate the strategy with larger open LLMs (30B+ parameters) and compare against more recent transformer architectures to understand scalability limits.

3. Conduct ablation studies on the confidence threshold selection process to determine optimal parameters across different dataset sizes and domain complexities.