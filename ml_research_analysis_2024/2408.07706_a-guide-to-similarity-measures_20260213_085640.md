---
ver: rpa2
title: A Guide to Similarity Measures
arxiv_id: '2408.07706'
source_url: https://arxiv.org/abs/2408.07706
tags:
- distance
- similarity
- measures
- example
- measure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a comprehensive guide to similarity measures
  used in data science applications, serving both non-experts and professionals. It
  categorizes and describes over 50 similarity/distance measures grouped by families:
  inner product-based, Minkowski, intersection, entropy, chi-squared, fidelity, and
  string-based measures.'
---

# A Guide to Similarity Measures

## Quick Facts
- arXiv ID: 2408.07706
- Source URL: https://arxiv.org/abs/2408.07706
- Reference count: 40
- This paper provides a comprehensive guide to similarity measures used in data science applications, serving both non-experts and professionals

## Executive Summary
This paper provides a comprehensive guide to similarity measures used in data science applications, serving both non-experts and professionals. It categorizes and describes over 50 similarity/distance measures grouped by families: inner product-based, Minkowski, intersection, entropy, chi-squared, fidelity, and string-based measures. Each measure is presented with its formula, purpose, and examples. The guide aims to help researchers choose appropriate measures for their specific tasks and domains by presenting principles of similarity measure design and a wide variety of options beyond their typical knowledge scope.

## Method Summary
The guide presents a comprehensive taxonomy of over 50 similarity and distance measures organized by mathematical families. Each measure includes its formula, purpose, and practical examples. The authors conducted an extensive literature review, scanning approximately 80 papers and several survey books to compile the measures. The approach emphasizes breadth across data types (numerical, categorical, strings, probability distributions) rather than depth in any single domain, enabling cross-domain application of similarity measures.

## Key Results
- Categorization of over 50 similarity/distance measures into seven mathematical families
- Unified presentation of measures applicable to both numerical and categorical data types
- Detailed examples and formulas for each measure to enable practical application
- Cross-domain connections showing how similar measures apply across different data science contexts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The guide's value stems from providing a unified taxonomy that spans both numerical and categorical data types, enabling cross-domain application of similarity measures.
- Mechanism: By categorizing over 50 similarity/distance measures into families (inner product, Minkowski, intersection, entropy, chi-squared, fidelity, and string-based), the guide allows users to identify structurally similar measures across domains. For example, the Jaccard index is presented both for binary vectors and for probability density functions, highlighting its versatility.
- Core assumption: Researchers benefit from seeing measures outside their typical domain knowledge scope, leading to better-informed choices.
- Evidence anchors:
  - [abstract]: "Our description is meant to guide both non-experts and professionals...we considered several surveys and books...as well as scanned overall about 80 papers presenting the relevant measures."
  - [section]: "Unlike the above mentioned surveys and books, our purpose in the presentation of the measures was different...We did not narrow our focus to measures designed for a specific data type in order to enable a potential reader to broaden the view on the subject."
  - [corpus]: Weak or missing—no direct evidence in the corpus about cross-domain benefit, but the comprehensive approach is consistent with the guide's stated goals.
- Break condition: If a user only needs a measure for a specific, narrow task, the breadth of the guide may be overwhelming rather than helpful.

### Mechanism 2
- Claim: Providing both formulas and design motivation helps users understand when and why to apply each measure, not just how to compute it.
- Mechanism: Each measure includes its formula, purpose, and examples. For instance, the Mahalanobis distance is presented with its formula, an explanation of its use for multivariate anomaly detection on imbalanced data, and a worked example with a sample dataset and covariance matrix.
- Core assumption: Users make better choices when they understand the mathematical and practical rationale behind each measure.
- Evidence anchors:
  - [abstract]: "Non-experts that wish to understand the motivation for the measure as well as how to use it may find a friendly and detailed exposition of the formulas of the measures."
  - [section]: "Each measure is presented with its formula, purpose, and examples...The choice of a similarity or distance measure adequate for a specific task within an application domain is of great importance."
  - [corpus]: Weak or missing—no direct evidence in the corpus about the effectiveness of combined formula and motivation explanations.
- Break condition: If a user is already an expert and only needs a quick reference, the detailed exposition may be more than necessary.

### Mechanism 3
- Claim: Including both similarity and distance measures, along with explicit relationships (e.g., d = 1 - s), enables flexible adaptation to different problem formulations.
- Mechanism: The guide presents each similarity measure alongside its corresponding distance measure (e.g., cosine similarity and cosine distance), and explains how to convert between them. For example, the Jaccard distance is defined as d = 1 - s, and the Jaccard similarity is given both as a normalized inner product and as the complement of the distance.
- Core assumption: Users can more easily map measures to their specific needs when both formulations are available.
- Evidence anchors:
  - [abstract]: "Similarity and distance measures are closely related...Most similarity measures pertinent to the intersection can be transformed into distance measures using the formula dx(P,Q) = 1 - sx(P,Q)."
  - [section]: "Most similarity measures pertinent to the intersection can be transformed into distance measures using the formula dx(P,Q) = 1 - sx(P,Q)."
  - [corpus]: Weak or missing—no direct evidence in the corpus about the value of dual presentation.
- Break condition: If a user is only interested in one formulation (similarity or distance), the dual presentation may be redundant.

## Foundational Learning

- Concept: Probability density functions (PDFs) and histograms
  - Why needed here: Many similarity measures (intersection, entropy, chi-squared, fidelity families) are defined on PDFs or normalized histograms, so users must understand these concepts to apply the measures correctly.
  - Quick check question: Given a histogram with counts [10, 20, 30], what is the corresponding PDF?

- Concept: Vector spaces and inner products
  - Why needed here: The inner product-based measures (cosine, Jaccard, Dice) rely on vector space concepts, so users must understand inner products, norms, and the properties of vector spaces.
  - Quick check question: For vectors P = (1, 2) and Q = (3, 4), compute the inner product and the norm of P.

- Concept: Set theory and set operations
  - Why needed here: Intersection-based and string-based measures (Jaccard, Sørensen, Hamming, edit distance) rely on set operations (union, intersection, difference), so users must understand these concepts to interpret and apply the measures.
  - Quick check question: For sets A = {1, 2, 3} and B = {2, 3, 4}, what are A ∩ B, A ∪ B, and A - B?

## Architecture Onboarding

- Component map: The guide is organized into families of measures (inner product, Minkowski, intersection, entropy, chi-squared, fidelity, string-based). Each family contains multiple specific measures, each with a formula, purpose, and example. The guide also includes a table mapping all measures to their families.
- Critical path: To choose a measure for a specific task, a user should: 1) Identify the data type (numerical, categorical, strings, PDFs); 2) Determine the relevant family(ies); 3) Review the measures in that family, considering their formulas, purposes, and examples; 4) Select the measure that best fits the task and domain.
- Design tradeoffs: The guide prioritizes breadth (over 50 measures) over depth (no single measure is covered exhaustively). This enables cross-domain learning but may require users to consult additional sources for implementation details.
- Failure signatures: If a user applies a measure outside its intended domain (e.g., using Euclidean distance for categorical data), the results may be misleading or invalid. The guide mitigates this by explaining each measure's purpose and domain of applicability.
- First 3 experiments:
  1. For two binary vectors P = (1, 0, 1) and Q = (0, 1, 1), compute and compare Jaccard similarity, Dice coefficient, and cosine similarity.
  2. For two probability distributions P = (0.2, 0.3, 0.5) and Q = (0.1, 0.4, 0.5), compute and compare Kullback-Leibler divergence, Jensen-Shannon divergence, and Hellinger distance.
  3. For two strings P = "kitten" and Q = "sitting", compute and compare Hamming distance, edit distance, and Jaro similarity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can similarity measures be systematically designed to optimize performance across different data science application domains, considering the trade-offs between computational efficiency and discriminative power?
- Basis in paper: [explicit] The paper mentions "principles of designing similarity measures" and discusses various measures but doesn't provide a systematic framework for optimal design across domains.
- Why unresolved: The paper provides a comprehensive survey of existing measures but doesn't establish design principles or optimization criteria that would guide the creation of new measures tailored to specific application needs.
- What evidence would resolve it: A framework that demonstrates how to select or design similarity measures based on application-specific requirements (e.g., data type, computational constraints, desired discriminative properties) with empirical validation across multiple domains.

### Open Question 2
- Question: What are the theoretical limitations of commonly used similarity measures (like Euclidean distance) in specific data science applications, and how can these limitations be quantified and addressed?
- Basis in paper: [explicit] The paper states that "compressed image retrieval uses similarity and distance measures for evaluations, where some commonly used distance measures, as the Euclidean distance, do not give good retrieval performance."
- Why unresolved: While the paper identifies performance issues with certain measures in specific contexts, it doesn't provide a systematic analysis of theoretical limitations or methods to quantify these limitations across different application domains.
- What evidence would resolve it: A theoretical framework that characterizes the conditions under which specific similarity measures fail to capture meaningful relationships in data, accompanied by empirical studies demonstrating the impact of these limitations.

### Open Question 3
- Question: How can string similarity measures be extended to handle more complex data structures beyond traditional string representations, such as time series, graphs, or multi-dimensional arrays?
- Basis in paper: [inferred] The paper focuses heavily on string-based measures but acknowledges the need for similarity measures across various data types, suggesting a gap in addressing more complex structures.
- Why unresolved: The paper provides an extensive treatment of string similarity measures but doesn't explore how these approaches could be generalized or adapted for non-sequential data structures that are increasingly common in modern data science.
- What evidence would resolve it: Novel similarity measures that successfully extend string-based concepts (like edit distance or N-grams) to other data structures, with demonstrated improvements in tasks involving complex data types.

## Limitations

- The guide lacks empirical validation of the claimed benefits of cross-domain measure selection and the effectiveness of combined formula-motivation explanations
- The confidence in the guide's utility is Medium, as the approach is well-founded but not directly tested
- Major uncertainties include the practical value of the breadth-first organization for users with specific, narrow needs and the potential for overwhelming users with the volume of measures presented

## Confidence

- Cross-domain benefit: Medium - Comprehensive approach is consistent with stated goals but lacks direct evidence
- Combined formula-motivation effectiveness: Medium - Guide claims this helps users but provides no empirical support
- Breadth vs. depth tradeoff: Medium - Enables cross-domain learning but may overwhelm users with specific needs

## Next Checks

1. User testing to assess whether the guide helps non-experts select appropriate measures for specific tasks
2. Implementation verification by applying a subset of measures to real-world datasets and comparing results to established benchmarks
3. Expert review to confirm the accuracy and completeness of the measure descriptions and examples