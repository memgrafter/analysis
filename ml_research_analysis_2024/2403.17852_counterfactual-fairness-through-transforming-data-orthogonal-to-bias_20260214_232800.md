---
ver: rpa2
title: Counterfactual Fairness through Transforming Data Orthogonal to Bias
arxiv_id: '2403.17852'
source_url: https://arxiv.org/abs/2403.17852
tags:
- data
- fairness
- sensitive
- variables
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Orthogonal to Bias (OB), a model-agnostic data
  pre-processing algorithm that decorrelates data from sensitive variables to achieve
  counterfactual fairness. The method is based on transforming the non-sensitive variables
  to be orthogonal to sensitive variables under the assumption of a jointly normal
  distribution within a structural causal model.
---

# Counterfactual Fairness through Transforming Data Orthogonal to Bias

## Quick Facts
- arXiv ID: 2403.17852
- Source URL: https://arxiv.org/abs/2403.17852
- Authors: Shuyi Chen; Shixiang Zhu
- Reference count: 40
- Primary result: Achieves counterfactual fairness by decorrelating non-sensitive data from sensitive variables under joint normality assumption

## Executive Summary
This paper introduces Orthogonal to Bias (OB), a model-agnostic data pre-processing algorithm that achieves counterfactual fairness by transforming non-sensitive variables to be orthogonal to sensitive variables. The method operates under the assumption of jointly normal distributions within a structural causal model framework. A sparse variant (SOB) with ℓ1-regularization improves numerical stability. Empirical evaluation demonstrates that OB achieves lower counterfactual fairness metrics and improved observational fairness with comparable or better accuracy than state-of-the-art fair learning methods.

## Method Summary
The method transforms non-sensitive variables A to be orthogonal to sensitive variables B under the assumption of joint normality. OB uses rank-k approximation with singular value decomposition and least squares projection to minimize Frobenius norm changes while ensuring orthogonality. SOB adds ℓ1-norm penalty to encourage sparsity and improve numerical stability. The approach is model-agnostic and works by preprocessing data before training any machine learning model.

## Key Results
- OB achieves lower counterfactual fairness metrics (CF-metric, KL-divergence) compared to baseline methods
- Improved observational fairness (EO, AA) with comparable or better accuracy across multiple datasets
- Effective balance between fairness and accuracy with minimal data modification
- SOB variant provides numerical stability benefits in high-dimensional scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual fairness is achieved by ensuring non-sensitive variables are uncorrelated with sensitive variables under jointly normal distribution
- Mechanism: Decorrelates non-sensitive variables from sensitive ones by transforming data to be orthogonal to sensitive variables while minimizing changes
- Core assumption: Sensitive and non-sensitive variables follow jointly normal distribution in structural causal model
- Evidence anchors: [abstract], [section], [corpus] Weak
- Break condition: If joint normality assumption doesn't hold or orthogonality fails after transformation

### Mechanism 2
- Claim: OB minimizes data changes while achieving counterfactual fairness
- Mechanism: Uses rank-k approximation of non-sensitive data matrix, ensuring orthogonality to sensitive data matrix via constrained optimization with minimal Frobenius norm change
- Core assumption: Optimization problem solvable in closed form using SVD and least squares projection
- Evidence anchors: [section], [section], [corpus] Weak
- Break condition: If closed-form solution doesn't converge or rank-k approximation insufficient

### Mechanism 3
- Claim: SOB improves numerical stability and handles high-dimensional data
- Mechanism: Adds ℓ1-norm penalty to OB algorithm, encouraging sparsity in transformation matrix and improving numerical stability
- Core assumption: ℓ1-norm penalty doesn't significantly compromise counterfactual fairness
- Evidence anchors: [section], [section], [corpus] Weak
- Break condition: If ℓ1-norm penalty too strong, causing excessive sparsity and information loss

## Foundational Learning

- Concept: Structural Causal Model (SCM)
  - Why needed here: Framework to define and achieve counterfactual fairness
  - Quick check question: What are key components of SCM and how do they relate to variables in this paper?

- Concept: Counterfactual Fairness
  - Why needed here: Goal is ensuring predictions remain consistent across counterfactual variations of sensitive attributes
  - Quick check question: How is counterfactual fairness formally defined in this paper and what assumptions achieve it?

- Concept: Joint Normality Assumption
  - Why needed here: Assumes sensitive and non-sensitive variables follow jointly normal distribution to connect counterfactual fairness with data uncorrelation
  - Quick check question: Why is joint normality assumption important for achieving counterfactual fairness and what are its limitations?

## Architecture Onboarding

- Component map: Data Preprocessing (OB/SOB) -> Model Training (Logistic regression, ML models) -> Evaluation (Metrics)

- Critical path:
  1. Standardize non-sensitive and sensitive data
  2. Apply OB or SOB algorithm to decorrelate non-sensitive data from sensitive data
  3. Train machine learning model on transformed data
  4. Evaluate model performance and fairness metrics

- Design tradeoffs:
  - Accuracy vs. Fairness: Potential tradeoff between the two objectives
  - Computational Complexity: Matrix operations may be expensive for large datasets
  - Model Agnosticism: Algorithms designed to work with any ML model, but choice affects overall performance

- Failure signatures:
  - Low accuracy or AUC: Transformation may have removed too much information
  - High CF-metrics or EO/AA Fairness: Algorithm may not have successfully decorrelated data
  - Numerical instability: SOB may not have converged or produced unstable results

- First 3 experiments:
  1. Apply OB/SOB to synthetic dataset with known sensitive/non-sensitive variables, evaluate correlation between transformed non-sensitive data and sensitive data
  2. Train logistic regression model on transformed data, compare performance to model trained on original data
  3. Evaluate counterfactual fairness using CF-metrics, EO Fairness, and AA Fairness on real-world dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does OB perform when applied to datasets with complex, non-linear relationships between sensitive and non-sensitive variables beyond assumed jointly normal distribution?
- Basis in paper: [inferred] Methodology based on joint normality assumption but experiments show promising results even when assumption not met
- Why unresolved: Paper doesn't explicitly test or discuss performance on datasets with non-linear relationships
- What evidence would resolve it: Empirical results demonstrating performance on datasets with known non-linear relationships

### Open Question 2
- Question: What are potential impacts of using OB on datasets with highly correlated non-sensitive variables and how does it affect fairness/accuracy tradeoff?
- Basis in paper: [inferred] Discusses performance on various datasets but doesn't specifically address highly correlated non-sensitive variables
- Why unresolved: Interaction between OB and highly correlated non-sensitive variables could significantly impact outcomes, not explored
- What evidence would resolve it: Analysis of performance on datasets with varying correlation degrees among non-sensitive variables

### Open Question 3
- Question: How does SOB perform in extremely high-dimensional data scenarios and what are limitations in feature selection and computational efficiency?
- Basis in paper: [explicit] Introduces SOB to improve numerical stability in high-dimensional data scenarios
- Why unresolved: Mentions SOB introduction but doesn't provide detailed insights into performance in extremely high-dimensional scenarios or discuss limitations
- What evidence would resolve it: Comparative studies of SOB's performance and computational efficiency in extremely high-dimensional datasets

## Limitations
- Joint normality assumption critical limitation as real-world data often deviates from this assumption
- Reliance on linear relationship between sensitive and non-sensitive variables may not capture complex, non-linear biases
- ℓ1-regularization in SOB may lead to excessive sparsity, potentially removing information crucial for accurate predictions

## Confidence

- **High Confidence**: Core mechanism of achieving counterfactual fairness through orthogonalization of non-sensitive variables from sensitive variables, supported by Theorem 3.3 and empirical results
- **Medium Confidence**: Effectiveness of ℓ1-regularization in SOB for improving numerical stability, as impact on counterfactual fairness not fully explored
- **Low Confidence**: Generalizability to non-linear relationships and non-normal distributions, given strong assumptions underlying method

## Next Checks
1. Test OB and SOB algorithms on datasets with known non-linear relationships between sensitive and non-sensitive variables to assess performance outside joint normality assumption
2. Conduct sensitivity analysis on rank-k approximation parameter and ℓ1-regularization strength to determine impact on fairness/accuracy trade-offs
3. Evaluate algorithms on high-dimensional datasets (p > n) to identify potential numerical stability issues and assess SOB variant effectiveness in such scenarios