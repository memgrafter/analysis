---
ver: rpa2
title: 'The Landscape of Data Reuse in Interactive Information Retrieval: Motivations,
  Sources, and Evaluation of Reusability'
arxiv_id: '2411.15430'
source_url: https://arxiv.org/abs/2411.15430
tags:
- data
- reuse
- research
- information
- researchers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated data reuse practices among Interactive
  Information Retrieval (IIR) researchers through 21 semi-structured interviews. Findings
  revealed that while system-oriented researchers frequently reuse external data for
  validation and generalizability, user-oriented researchers primarily reuse data
  within their own labs for exploration.
---

# The Landscape of Data Reuse in Interactive Information Retrieval: Motivations, Sources, and Evaluation of Reusability

## Quick Facts
- arXiv ID: 2411.15430
- Source URL: https://arxiv.org/abs/2411.15430
- Reference count: 0
- Primary result: Interviews with 21 IIR researchers revealed distinct data reuse patterns between system-oriented and user-oriented researchers, with trust and contextual information being critical factors.

## Executive Summary
This study investigated data reuse practices among Interactive Information Retrieval (IIR) researchers through 21 semi-structured interviews. The research found that system-oriented researchers frequently reuse external data for validation and generalizability, while user-oriented researchers primarily reuse data within their own labs for exploration. Key motivations included saving time, accessing unavailable data, and increasing reliability. Researchers primarily discover data through academic literature and personal connections, with trust and understandability being critical assessment factors. Major concerns include missing contextual information, usefulness alignment, and community acceptance. The study highlights unique challenges in IIR data reuse due to methodological diversity and rapid technological changes, suggesting the need for standardized documentation frameworks and community-level familiarity approaches.

## Method Summary
The study employed qualitative research methods, conducting 21 semi-structured interviews with IIR researchers from varying backgrounds, institutions, and career stages. Interviews were recorded and transcribed with participant permission. Qualitative analysis was performed using MAXQDA 2022 with two rounds of coding, developing a codebook based on research questions. Inter-coder reliability was assessed using Cohen's kappa to ensure consistency in theme identification.

## Key Results
- System-oriented researchers frequently reuse external data for validation and generalizability, while user-oriented researchers primarily reuse data within their own labs for exploration
- Trust and understandability are critical assessment factors, with researchers relying heavily on personal connections and institutional reputation
- Major concerns include missing contextual information, usefulness alignment with research questions, and community acceptance of reused data
- The field's methodological diversity and rapid technological changes create unique challenges for data reuse compared to other disciplines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data reuse in IIR is driven by time/resource constraints and need for generalizability.
- Mechanism: Researchers reuse data when their own data collection is too costly or impossible, and when they need to validate findings across different contexts.
- Core assumption: The field's rapid technological changes and methodological diversity make collecting fresh data less feasible than reusing existing data.
- Evidence anchors:
  - [abstract] "Building a sustainable data reuse process and culture relies on frameworks that encompass policies, standards, roles, and responsibilities..."
  - [section] "All the system-oriented participants reported frequent data reuse practices in their studies, typically using data created by individuals or institutions with whom they had no direct connection."
- Break condition: If the cost of data collection drops significantly or if the field stabilizes methodologically, the incentive to reuse data decreases.

### Mechanism 2
- Claim: Trust in data reusability is built through personal connections and institutional reputation.
- Mechanism: Researchers prefer reusing data from known colleagues or reputable institutions to reduce risk of misinterpretation and ensure data quality.
- Core assumption: Data embedded in local context are hard to interpret without direct communication with the original collector.
- Evidence anchors:
  - [abstract] "trust and understandability being critical assessment factors"
  - [section] "Trustworthiness depends on the reliability and validity of the dataset. Participants assessed these factors by examining how data were produced and used previously."
- Break condition: If standardized documentation frameworks become widely adopted, reliance on personal connections may decrease.

### Mechanism 3
- Claim: Data reuse in IIR is limited by methodological diversity and rapid change in user behavior.
- Mechanism: The variety of research methods and fast-evolving user interactions make it hard to find reusable data that fits specific research needs.
- Core assumption: User-oriented research designs are tightly coupled with specific research questions, making data repurposing difficult.
- Evidence anchors:
  - [abstract] "IIR research exhibits a large variety of research designs and methods... making it an ideal example to observe data reuse practices and challenges in a cross-disciplinary environment."
  - [section] "Usefulness concern was especially common among user-oriented IIR participants... The design and methods of data collection were closely tied to specific research questions, making it challenging for researchers with different questions to re-purpose the data."
- Break condition: If the field converges on common data collection standards, cross-study reuse becomes more feasible.

## Foundational Learning

- Concept: Data reuse definition and scope
  - Why needed here: To distinguish reuse from replication or secondary analysis
  - Quick check question: What qualifies as data reuse in IIR versus just continuing an existing study?

- Concept: FAIR principles (Findable, Accessible, Interoperable, Reusable)
  - Why needed here: The paper discusses challenges in finding and assessing reusable data
  - Quick check question: How do FAIR principles apply differently to system-oriented vs user-oriented IIR research?

- Concept: Contextual information loss
  - Why needed here: Understanding why data reusability is hard in IIR
  - Quick check question: What types of contextual information are most critical for reusing IIR data?

## Architecture Onboarding

- Component map: Data discovery → Trust assessment → Contextual understanding → Reuse validation
- Critical path: Researcher identifies potential data → Verifies trustworthiness through reputation/personal connection → Assesses contextual fit → Documents reuse rationale
- Design tradeoffs: Personal connections provide trust but limit scale; repositories provide scale but require trust mechanisms
- Failure signatures: Low reuse rates, high perceived risk, data silos within research groups
- First 3 experiments:
  1. Survey of IIR researchers on data discovery preferences
  2. Pilot documentation framework for user experiment data
  3. Controlled study comparing reuse success rates with/without personal connection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do IIR researchers assess the validity of data collection methods when critical contextual information is missing?
- Basis in paper: [explicit] The paper highlights that user-oriented researchers struggle with assessing validity due to missing details like participant selection criteria and experimental environment.
- Why unresolved: The paper describes the challenge but doesn't provide specific strategies or frameworks researchers use to evaluate validity in these situations.
- What evidence would resolve it: Empirical data showing how researchers handle missing contextual information when assessing data validity, including specific techniques or criteria they apply.

### Open Question 2
- Question: What are the long-term impacts of data reuse on research innovation in the IIR field?
- Basis in paper: [inferred] The paper discusses concerns about data reuse potentially reducing innovation, particularly among user-oriented researchers who worry about limited opportunities for new research designs.
- Why unresolved: The paper identifies this as a concern but doesn't examine whether data reuse actually leads to decreased innovation over time or how researchers balance reuse with novel research approaches.
- What evidence would resolve it: Longitudinal studies tracking research outputs and innovation levels in studies that reuse data versus those that collect new data.

### Open Question 3
- Question: How effective are community-level familiarity approaches compared to individual-level approaches in promoting data reuse across different IIR subfields?
- Basis in paper: [explicit] The paper contrasts individual-level approaches (personal connections, academic literature) with potential community-level approaches (standardized documentation, accepted frameworks) but doesn't evaluate their relative effectiveness.
- Why unresolved: The paper identifies these approaches but doesn't provide comparative data on which method better facilitates data reuse across the diverse IIR community.
- What evidence would resolve it: Comparative studies measuring data reuse rates and success across subfields using different familiarity approaches, with control for other variables.

## Limitations
- The findings are based on a relatively small sample (n=21) from a single field, limiting generalizability to other research domains
- Interview data may be subject to self-reporting bias, with researchers potentially overstating or understating their data reuse practices
- The study focused on IIR researchers' perspectives without examining actual data reuse patterns in published literature

## Confidence
- **High confidence**: System-oriented researchers reuse data more frequently than user-oriented researchers for validation purposes
- **Medium confidence**: Trust and understandability are critical factors in data reuse assessment across all IIR research types
- **Low confidence**: The specific mechanisms of how personal connections influence data discovery and reuse practices

## Next Checks
1. **Survey validation**: Conduct a larger-scale survey of IIR researchers to quantify data reuse patterns and verify interview findings
2. **Literature analysis**: Examine published IIR papers to identify actual data reuse instances and compare with reported practices
3. **Cross-domain comparison**: Apply the same interview protocol to researchers in related fields (e.g., human-computer interaction, machine learning) to assess generalizability of findings