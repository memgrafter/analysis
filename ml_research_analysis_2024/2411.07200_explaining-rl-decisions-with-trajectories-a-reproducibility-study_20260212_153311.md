---
ver: rpa2
title: '''Explaining RL Decisions with Trajectories'': A Reproducibility Study'
arxiv_id: '2411.07200'
source_url: https://arxiv.org/abs/2411.07200
tags:
- trajectories
- authors
- cluster
- learning
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines the reproducibility of "Explaining RL decisions
  with trajectories" by Deshmukh et al. (2023), which proposes attributing RL agent
  decisions to specific training trajectories.
---

# 'Explaining RL Decisions with Trajectories': A Reproducibility Study

## Quick Facts
- **arXiv ID:** 2411.07200
- **Source URL:** https://arxiv.org/abs/2411.07200
- **Reference count:** 40
- **Primary result:** Partial confirmation of claims about trajectory attribution in RL across multiple environments

## Executive Summary
This reproducibility study examines "Explaining RL Decisions with Trajectories" by Deshmukh et al. (2023), which proposes attributing RL agent decisions to specific training trajectories. We implemented missing code for Seaquest, HalfCheetah, Breakout, and Q*Bert environments and conducted experiments to verify four main claims: (i) removing trajectories reduces initial state value, (ii) clusters represent high-level behaviors, (iii) distant trajectories influence decisions, and (iv) humans can identify attributed trajectories. Our results show partial confirmation of claims (i), (ii), and (iii) across environments, with quantitative metrics supporting claim (iii) beyond the original qualitative analysis. Claim (iv) could not be fully supported due to limited original experiments.

## Method Summary
We implemented a 5-step methodology to reproduce the original paper's approach: (1) trajectory encoding using LSTM Seq2Seq for Grid-World and pre-trained GPT models for other environments, (2) XMeans clustering of trajectory embeddings, (3) creation of cluster embeddings, (4) complementary dataset creation by removing specific clusters, and (5) decision attribution through training explanation policies using SAC and DiscreteSAC algorithms. We used trajectory datasets from d4rl-Atari, Expert-offline RL Repository, and d4rl Repository, and evaluated results using five metrics including Initial State Value (ISV), Local Mean Absolute Action-Value Difference, Action Contrast Measure, Wasserstein distance, and Cluster attribution frequency.

## Key Results
- Partial confirmation of claims (i), (ii), and (iii) across multiple environments
- Quantitative metrics support claim (iii) beyond original qualitative analysis
- Differences in clustering outcomes and ISV results compared to original paper due to computational constraints
- Alternative clustering algorithms (DBSCAN) yielded comparable results to original method

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Removing trajectories induces a lower initial state value (ISV)
- **Mechanism:** Training on complete trajectory datasets allows RL agents to learn comprehensive policies. When specific trajectories are removed, the agent's policy becomes less complete, leading to lower ISV estimates. The ISV measures expected long-term returns, so reduction indicates degraded performance due to missing critical trajectories.
- **Core assumption:** Trajectories contain unique and valuable information that contributes to the agent's ability to achieve high returns.
- **Evidence anchors:**
  - [abstract]: "removing trajectories reduces initial state value"
  - [section]: "Removing Trajectories induces a lower Initial State Value: Including all relevant trajectories in the training data will result in higher or equal initial state value estimates compared to training sets where key trajectories are omitted."
- **Break condition:** If removed trajectories are redundant and don't contribute unique information, their removal wouldn't significantly impact ISV.

### Mechanism 2
- **Claim:** Clusters represent high-level behaviors
- **Mechanism:** Trajectory embeddings are clustered using algorithms like XMeans or DBSCAN. Trajectories within the same cluster share similar high-level behavioral patterns defined as sequences of actions and states leading to the same outcome that repeat across multiple trajectories.
- **Core assumption:** Trajectory embeddings capture meaningful information about agent behavior, and clustering algorithms can effectively group similar trajectories.
- **Evidence anchors:**
  - [abstract]: "clusters represent high-level behaviors"
  - [section]: "Cluster High-Level Behaviours: High-level behaviours are defined as patterns within a trajectory which lead to the same result and repeat over multiple trajectories."
- **Break condition:** If clustering fails to group similar trajectories or embeddings don't capture meaningful behavioral information, clusters won't represent high-level behaviors.

### Mechanism 3
- **Claim:** Distant trajectories influence decisions of the agents
- **Mechanism:** Agent decision-making is influenced by past experiences encoded in trajectory data. Even distant trajectories contain valuable information that shapes the agent's policy. By attributing decisions to specific trajectory clusters, researchers can identify which past experiences are most influential in current decision-making.
- **Core assumption:** The agent's policy is a function of both current state and historical trajectory data.
- **Evidence anchors:**
  - [abstract]: "distant trajectories influence decisions"
  - [section]: "Distant Trajectories influence Decisions of the Agents: Decisions performed by RL agents can be influenced by trajectories distant from the state under consideration."
- **Break condition:** If the agent's policy is solely based on current state without considering historical data, distant trajectories won't influence decisions.

## Foundational Learning

- **Concept:** Reinforcement Learning (RL)
  - Why needed here: The paper focuses on explaining RL agent decisions using trajectory attribution. Understanding RL fundamentals is crucial for grasping methodology and claims.
  - Quick check question: What is the goal of an RL agent, and how does it learn to achieve that goal?

- **Concept:** Trajectory Embeddings
  - Why needed here: Trajectory embeddings represent the agent's past experiences in compressed form, then clustered to identify high-level behaviors and attribute decisions.
  - Quick check question: How are trajectory embeddings typically generated, and what information do they capture?

- **Concept:** Clustering Algorithms (XMeans, DBSCAN)
  - Why needed here: Clustering algorithms group similar trajectory embeddings together to identify high-level behaviors and attribute decisions to specific clusters.
  - Quick check question: What are the key differences between XMeans and DBSCAN, and when would you choose one over the other?

## Architecture Onboarding

- **Component map:** Environments -> Trajectory Generation -> Trajectory Encoding -> Clustering -> Complementary Datasets -> Policy Training -> Evaluation
- **Critical path:** The critical path involves generating trajectories, encoding them into embeddings, clustering the embeddings, creating complementary datasets, training new policies, and evaluating policies using various metrics.
- **Design tradeoffs:**
  - Choice of clustering algorithm: XMeans vs. DBSCAN
  - Choice of trajectory encoder: LSTM-based Seq2Seq vs. Trajectory Transformer vs. BERT
  - Number of trajectories: More trajectories provide more data but increase computational cost
- **Failure signatures:**
  - Low ISV values across all policies indicate trajectory attribution method is not effective in improving agent performance
  - Inconsistent clustering results suggest trajectory embeddings don't capture meaningful behavioral information
  - High action contrast measure values indicate attributed trajectories significantly influence agent's decisions
- **First 3 experiments:**
  1. Reproduce Grid-World experiments to verify claim that removing trajectories induces lower ISV
  2. Implement Seaquest environment and compare clustering results with original paper
  3. Experiment with different clustering algorithms (XMeans vs. DBSCAN) to assess impact on attribution process

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do different clustering algorithms (beyond XMeans and DBSCAN) affect identification of high-level behavioral patterns in trajectory attribution?
- **Basis in paper:** [inferred] The paper tested XMeans and DBSCAN clustering algorithms, finding comparable results, but did not explore other clustering methods.
- **Why unresolved:** Authors only tested two clustering algorithms, leaving open whether other algorithms might yield better or different insights.
- **What evidence would resolve it:** Systematic comparison of trajectory clustering and behavioral pattern identification across multiple clustering algorithms (e.g., hierarchical clustering, spectral clustering) with quantitative metrics for cluster interpretability.

### Open Question 2
- **Question:** Does allowing multiple clusters per attribution (rather than one) improve comprehensiveness and accuracy of decision explanations?
- **Basis in paper:** [explicit] Authors note in Discussion that "allowing only one cluster per attribution" is a key limitation and suggest this could lead to "more comprehensive analysis."
- **Why unresolved:** Methodology was constrained to single-cluster attributions, preventing exploration of how multi-cluster attributions might capture more complex decision-making influences.
- **What evidence would resolve it:** Implementation of multi-cluster attribution framework and comparison of explanation quality metrics (e.g., attribution accuracy, human interpretability) against single-cluster baseline.

### Open Question 3
- **Question:** How do trajectory importance weights vary across different state-action pairs and environmental contexts?
- **Basis in paper:** [inferred] Paper found some clusters have larger influence on initial state value than others, suggesting varying importance, but did not systematically analyze this variation.
- **Why unresolved:** Analysis focused on cluster-level importance but did not explore how individual trajectory importance might vary based on state, action, or environmental conditions.
- **What evidence would resolve it:** Development of trajectory importance scoring mechanism and analysis of importance distributions across states, actions, and environments, potentially revealing contextual factors affecting attribution significance.

## Limitations

- Significant computational constraints limit ability to reproduce exact training durations and saturation criteria used in original study
- Package compatibility issues arise from outdated libraries and OS differences between our setup and original authors' environment
- Lack of implementation details for human study component prevents full validation of claim (iv)

## Confidence

- **Claim (i) - ISV reduction from trajectory removal:** Medium confidence - Partially confirmed across environments but with numerical discrepancies
- **Claim (ii) - Cluster behavior representation:** Medium confidence - Qualitative patterns observed but clustering outcomes differ from original paper
- **Claim (iii) - Distant trajectory influence:** High confidence - Quantitative metrics support this claim beyond original qualitative analysis
- **Claim (iv) - Human identification of attributed trajectories:** Low confidence - Cannot fully validate due to missing implementation details

## Next Checks

1. Implement systematic hyperparameter sweeps for each environment to identify optimal settings that balance computational constraints with claim verification requirements
2. Conduct multiple runs with different random seeds to assess stability of clustering outcomes and ISV values across varied initializations
3. Develop a simplified human study protocol with a small, controlled participant group to provide partial validation of claim (iv) while documenting methodological limitations