---
ver: rpa2
title: Leveraging MLLM Embeddings and Attribute Smoothing for Compositional Zero-Shot
  Learning
arxiv_id: '2411.12584'
source_url: https://arxiv.org/abs/2411.12584
tags:
- attributes
- features
- visual
- attribute
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses limitations in compositional zero-shot learning
  (CZSL), where models struggle with disentangling attributes and objects due to background
  interference, limited semantic representation from word embeddings, and overconfidence
  in seen compositions. To overcome these issues, the authors propose TRIDENT, a framework
  that leverages multimodal large language model (MLLM) embeddings and attribute smoothing
  for guided disentanglement.
---

# Leveraging MLLM Embeddings and Attribute Smoothing for Compositional Zero-Shot Learning

## Quick Facts
- arXiv ID: 2411.12584
- Source URL: https://arxiv.org/abs/2411.12584
- Reference count: 35
- Key outcome: TRIDENT achieves state-of-the-art performance on MIT-States, C-GQA, and V AW-CZSL by leveraging MLLM embeddings and attribute smoothing to address disentanglement and overconfidence challenges in compositional zero-shot learning

## Executive Summary
This paper addresses fundamental challenges in compositional zero-shot learning (CZSL), where models struggle to disentangle attributes and objects due to background interference, limited semantic representation from word embeddings, and overconfidence in seen compositions. The authors propose TRIDENT, a framework that uses multimodal large language model (MLLM) embeddings and attribute smoothing for guided disentanglement. By incorporating feature adaptive aggregation modules to reduce background noise, learnable condition masks to capture multi-granularity features, and the last hidden states of MLLMs as word embeddings, TRIDENT significantly improves both seen and unseen composition recognition. Experiments on three challenging datasets demonstrate state-of-the-art performance.

## Method Summary
TRIDENT tackles CZSL by combining three key innovations: feature adaptive aggregation (FAA) modules that reduce background interference through patch-level weighting, learnable condition masks that create multi-granularity global representations by conditioning on the [CLS] token, and attribute smoothing with LLM-generated auxiliary attributes to address overconfidence in seen compositions. The framework uses frozen LLaVA-v1.5 as a visual backbone and incorporates a disentanglement module that extracts shared and exclusive features between image pairs. Feature alignment with MLLM embeddings is achieved through cross-entropy loss, while orthogonal regularization and multi-task optimization ensure robust learning. The method is evaluated on MIT-States, C-GQA, and V AW-CZSL datasets.

## Key Results
- Achieves state-of-the-art performance on MIT-States, C-GQA, and V AW-CZSL datasets
- Significantly improves both seen and unseen composition recognition accuracy
- Demonstrates the effectiveness of attribute smoothing in addressing overconfidence in seen compositions
- Shows that MLLM embeddings provide better multimodal semantic representation than traditional word embeddings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feature Adaptive Aggregation (FAA) modules reduce background noise and improve disentanglement by filtering patch tokens based on learned attention weights.
- Mechanism: FAA computes a weight vector `agg` from patch features via a 1x1 convolution and ReLU, then performs a weighted sum over patch tokens to produce a local feature vector. This selectively aggregates patches that are relevant to the attribute or object, suppressing background regions.
- Core assumption: The background is spatially separable from the attribute/object in the patch token space, so that weighted averaging can isolate foreground content.
- Evidence anchors: [abstract] "we leverage feature adaptive aggregation modules to mitigate the impact of background" and [section] "To filter out background noise and focus on related regions, we deploy p feature adaptive aggregation (FAA) modules"
- Break condition: If the attribute/object overlaps significantly with background texture or is not localized in patch space, the weighting cannot isolate it cleanly.

### Mechanism 2
- Claim: Learnable condition masks create multi-granularity global representations by splitting the [CLS] token into multiple feature slices.
- Mechanism: A learnable vector `c` is element-wise multiplied with the [CLS] feature to produce a conditioned global representation. Multiple such masks yield multiple global feature vectors that capture different semantic aspects of the image.
- Core assumption: Different dimensions of the [CLS] feature encode different semantic aspects, so conditioning can disentangle them.
- Evidence anchors: [abstract] "utilize learnable condition masks to capture multi-granularity features for disentanglement" and [section] "to disperse multi-granularity global information into different representations at the dimensional level"
- Break condition: If the [CLS] token is not sufficiently rich or dimensions are highly correlated, masks may not produce diverse enough representations.

### Mechanism 3
- Claim: Attribute smoothing with auxiliary attributes generated by LLM reduces overconfidence in seen compositions, improving generalization to unseen ones.
- Mechanism: GPT-3.5 generates `t` adjectives for each composition. During training, the ground-truth attribute label is smoothed with uniform mass on auxiliary attributes (`α/t`). This reduces the penalty on related attributes and encourages the model to learn broader attribute concepts.
- Core assumption: Objects have multiple valid attributes, and the model benefits from recognizing related attributes instead of only the ground-truth one.
- Evidence anchors: [abstract] "propose attribute smoothing with auxiliary attributes generated by the large language model (LLM) for seen compositions to address the overconfidence challenge" and [section] "to tackle the problem that the overconfidence of the models regarding the ground-truth attribute hinders it from generalizing to unseen compositions"
- Break condition: If auxiliary attributes are noisy or irrelevant, smoothing may degrade performance by encouraging incorrect attribute predictions.

## Foundational Learning

- Concept: Cosine similarity for multimodal alignment
  - Why needed here: To compare visual feature vectors with MLLM word embeddings in a shared embedding space, capturing semantic similarity across modalities.
  - Quick check question: If two vectors have cosine similarity 0.9, what does that imply about their angular difference?

- Concept: Label smoothing in classification
  - Why needed here: To prevent the model from becoming overconfident on seen compositions by redistributing target probability mass to plausible alternative labels.
  - Quick check question: In label smoothing, if the smoothing factor α=0.1 and there are 3 auxiliary attributes, what is the target probability assigned to each auxiliary attribute?

- Concept: Disentanglement via shared/exclusive feature extraction
  - Why needed here: To separate attribute and object features from a composite image by comparing two images that share either attribute or object, isolating what is common vs. unique.
  - Quick check question: In a triplet of images (main, same-attr, same-obj), which pair would you use to extract exclusive object features for the main image?

## Architecture Onboarding

- Component map: Visual Backbone (LLaVA-v1.5 ViT-Large-Patch14-336px) -> FAA modules -> Condition Masks -> Image Embedder -> Disentanglement Module -> Feature Alignment -> Losses
- Critical path:
  1. Extract visual features (ViT + CMC)
  2. Generate local and global features (FAA + masks)
  3. Disentangle attributes/objects from image pairs
  4. Align with MLLM embeddings via cross-entropy
  5. Optimize with multi-task loss
- Design tradeoffs:
  - Using frozen LLaVA vs. fine-tuning: saves compute but limits adaptation to CZSL domain
  - Auxiliary attributes vs. no smoothing: smoother improves unseen accuracy but may hurt seen accuracy slightly
  - Multi-granularity features vs. single global: richer representations but higher complexity
- Failure signatures:
  - If disentangled attributes are too object-like or vice versa: FAA or masks not isolating features correctly
  - If unseen accuracy drops: label smoothing too aggressive or auxiliary attributes irrelevant
  - If training diverges: loss weights unbalanced, especially orthogonal regularization too high
- First 3 experiments:
  1. Run with only ViT [CLS] token (no FAA, no masks) to benchmark baseline disentanglement
  2. Add FAA modules but no condition masks to test local feature impact
  3. Enable condition masks but no label smoothing to isolate MLLM embedding contribution

## Open Questions the Paper Calls Out
None explicitly identified in the paper.

## Limitations
- Scalability concerns with attribute smoothing mechanism for domains requiring more diverse auxiliary attributes
- Reliance on frozen MLLM embeddings limits domain-specific adaptation
- Computational overhead of generating auxiliary attributes for every composition

## Confidence
- High Confidence: The effectiveness of MLLM embeddings for multimodal semantic representation
- Medium Confidence: The attribute smoothing mechanism's contribution to unseen composition accuracy
- Medium Confidence: The FAA and condition mask design for disentanglement

## Next Checks
1. Ablation of auxiliary attribute quality: Systematically vary the number and relevance of GPT-3.5-generated auxiliary attributes to quantify the trade-off between smoothing benefits and noise introduction.
2. Cross-dataset generalization: Evaluate TRIDENT on datasets from different domains (e.g., action-object compositions) to test whether the attribute smoothing and MLLM embedding approach transfers beyond attribute-object recognition.
3. Fine-tuning vs. frozen MLLM: Compare frozen LLaVA embeddings against fine-tuned versions to measure the performance gap and determine if domain adaptation is necessary for optimal results.