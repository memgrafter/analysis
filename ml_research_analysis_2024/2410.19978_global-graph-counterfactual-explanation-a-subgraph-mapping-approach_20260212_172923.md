---
ver: rpa2
title: 'Global Graph Counterfactual Explanation: A Subgraph Mapping Approach'
arxiv_id: '2410.19978'
source_url: https://arxiv.org/abs/2410.19978
tags:
- graph
- counterfactual
- subgraph
- graphs
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GlobalGCE, a novel method for generating global-level
  counterfactual explanations for Graph Neural Networks (GNNs). The key idea is to
  identify a collection of subgraph mapping rules as explanations, where substituting
  significant subgraphs with their counterfactuals changes GNN predictions for most
  graphs.
---

# Global Graph Counterfactual Answer: A Subgraph Mapping Approach

## Quick Facts
- **arXiv ID:** 2410.19978
- **Source URL:** https://arxiv.org/abs/2410.19978
- **Reference count:** 13
- **Key outcome:** GlobalGCE achieves 93.34% coverage on AIDS dataset and 98.80% on ENZYMES dataset, outperforming state-of-the-art baselines in coverage, proximity, and comprehensibility metrics.

## Executive Summary
This paper proposes GlobalGCE, a novel method for generating global-level counterfactual explanations for Graph Neural Networks (GNNs) through subgraph mapping rules. The key innovation is identifying collections of significant subgraphs and their counterfactuals that, when substituted, change GNN predictions for most graphs in the dataset. GlobalGCE consists of a significant subgraph generator using frequent subgraph mining, a counterfactual subgraph autoencoder for generating valid counterfactuals, and a greedy algorithm for selecting the most effective subgraph mapping rules. Experiments on five real-world datasets demonstrate superior performance compared to existing methods in terms of coverage (proportion of graphs affected), proximity (similarity between original and counterfactual), and comprehensibility (compactness of graph edits).

## Method Summary
GlobalGCE generates global counterfactual explanations by identifying subgraph mapping rules that maximize coverage across an input graph dataset. The method first uses gSpan algorithm to find frequent subgraphs, then selects diverse and influential significant subgraphs based on appearance rate and diversity metrics. For each significant subgraph, a counterfactual subgraph autoencoder generates valid counterfactuals that change GNN predictions while maintaining structural similarity. Finally, a greedy algorithm selects the top-k subgraph mapping rules based on their coverage of the dataset. The framework is evaluated on five real-world graph datasets using coverage, proximity, and comprehensibility metrics, with comparisons against five state-of-the-art baseline methods.

## Key Results
- GlobalGCE achieves 93.34% coverage on AIDS dataset and 98.80% on ENZYMES dataset
- Outperforms baselines (GNNExplainer, CF-GNNExplainer, CLEAR, RegExplainer, GCFExplainer) on all three evaluation metrics
- The proposed comprehensibility metric effectively measures how easily humans can understand the counterfactual generation process
- Greedy algorithm achieves (1-1/e) performance lower bound due to monotonic submodularity of coverage function

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GlobalGCE identifies subgraph mapping rules that maximize coverage across the input graph dataset
- Mechanism: Uses greedy algorithm to select most frequent and diverse significant subgraphs, then generates counterfactual subgraphs for each significant subgraph, finally selecting top k rules covering largest proportion of graphs
- Core assumption: Coverage function is monotonic submodular, allowing greedy approximation to achieve (1-1/e) performance bound
- Evidence anchors:
  - [abstract]: "GlobalGCE aims to identify a collection of subgraph mapping rules as counterfactual explanations for the target GNN. According to these rules, substituting certain significant subgraphs with their counterfactual subgraphs will change the GNN prediction to the desired class for most graphs (i.e., maximum coverage)."
  - [section 2.1]: "We can observe that this problem is NP-hard (see proof in Appendix A). However, it is straightforward to see that the coverage function coverage(C) is monotonic submodular (proof omitted for brevity), we can optimize coverage greedily while maintaining a (1-1/e) performance lower bound (Nemhauser et al., 1978)."
- Break condition: If coverage function is not monotonic submodular, greedy approximation may not provide theoretical performance guarantee

### Mechanism 2
- Claim: Counterfactual subgraph autoencoder generates valid counterfactual subgraphs that change GNN predictions
- Mechanism: Autoencoder maps significant subgraphs to latent space, samples from this space, and decodes to generate counterfactual subgraphs using loss function with structural similarity and prediction loss
- Core assumption: VAE can learn meaningful latent representation allowing generation of counterfactuals with desired properties
- Evidence anchors:
  - [section 3.2]: "Our CSA is a lightweight framework allowing all forms of graph edits. We optimize gcf by maximizing the log-likelihood that the application of the CSM {g→gcf} successfully generates the counterfactuals of the input graphs containing g."
  - [section 3.2]: "We estimate Equ. 4 utilizing the Monte Carlo approximation... However, lnP (Gcf|y∗,g,G ) is intractable... Therefore, we utilize a viable substitute optimization target, which is a lower bound of Equ. 4 based on the Evidence Lower Bound (ELBO)."
- Break condition: If autoencoder fails to learn meaningful latent representations or optimization target does not effectively guide counterfactual generation

### Mechanism 3
- Claim: Comprehensibility metric effectively measures how easily humans can understand the counterfactual generation process
- Mechanism: Calculates average number of connected components in symmetric difference graphs between original and counterfactuals, with higher values indicating more scattered edits and lower comprehensibility
- Core assumption: Concentrated graph edits are more easily packaged into unified, human-comprehensible rules than scattered edits
- Evidence anchors:
  - [section 2.3]: "This metric aims to measure the compactness of the graph edits during the GCE process. In fact, with a certain amount of graph edits (node/edge addition/deletion feature changes) allowed, one intuitively expects to achieve a valid counterfactual with those edits being as compact (i.e., graph edits being near-in-distance) as possible, because concentrated edits can be more easily packaged into a unified, human-comprehensible GCE rule."
  - [section 2.3]: "Fig. 3 shows that original input graph. (b) and (c) are two of its valid counterfactuals, they have the same proximity of 0.25, but different comprehensibility 1 and 5 respectively. (b) is apparently more human-comprehensive, which we can interpret as 'removing house motif may alter the GNN prediction label for a graph.'"
- Break condition: If humans find scattered edits equally comprehensible as concentrated edits, or if metric does not correlate with actual human understanding

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GlobalGCE is designed to explain GNN predictions through counterfactual explanations
  - Quick check question: What are the key components of a GNN architecture and how do they process graph-structured data?

- Concept: Subgraph mining and frequent subgraph discovery
  - Why needed here: GlobalGCE relies on identifying significant subgraphs that are frequent and diverse across the input graph dataset
  - Quick check question: How does the gSpan algorithm work for frequent subgraph mining, and what are its computational complexities?

- Concept: Variational Autoencoders (VAEs) and graph representation learning
  - Why needed here: The counterfactual subgraph autoencoder uses a VAE-like architecture to generate counterfactual subgraphs in a latent space
  - Quick check question: How do VAEs differ from standard autoencoders, and what challenges arise when extending them to graph-structured data?

## Architecture Onboarding

- Component map: Frequent Subgraph Mining -> Significant Subgraph Selection -> Counterfactual Subgraph Autoencoder -> Greedy Rule Selection
- Critical path:
  1. Generate frequent subgraphs from input dataset using gSpan
  2. Select significant subgraphs based on appearance rate and diversity
  3. Train counterfactual subgraph autoencoder for each significant subgraph
  4. Generate candidate subgraph mapping rules (significant subgraph → counterfactual subgraph)
  5. Greedily select top k rules based on coverage
  6. Evaluate and output selected rules
- Design tradeoffs:
  - Using frequent subgraph mining vs. random subgraph sampling: Mining ensures coverage but is computationally expensive
  - Allowing all graph edits vs. restricting to specific edit types: More flexible but harder to learn
  - Greedy selection vs. exact optimization: Faster but may miss optimal solutions
- Failure signatures:
  - Low coverage: Significant subgraphs not representative of dataset, or counterfactuals not effective
  - Poor comprehensibility: Counterfactuals too scattered, indicating autoencoder not learning meaningful patterns
  - Long training times: Frequent subgraph mining or autoencoder training bottlenecks
- First 3 experiments:
  1. Run on small synthetic dataset with known ground-truth rules to verify correct rule recovery
  2. Compare coverage and comprehensibility on a real dataset against baseline methods
  3. Perform ablation study removing autoencoder to test its impact on performance

## Open Questions the Paper Calls Out

- Question: How does GlobalGCE scale to extremely large graph datasets?
  - Basis in paper: [inferred] The paper mentions computational complexity increases with graph size and number of input graphs
  - Why unresolved: The authors note this limitation but do not provide empirical data on performance with very large datasets or propose specific solutions for scaling
  - What evidence would resolve it: Experimental results showing GlobalGCE's performance on datasets with millions of graphs, or analysis of computational complexity as a function of dataset size

- Question: Can GlobalGCE be effectively extended to multi-class classification or regression tasks?
  - Basis in paper: [explicit] The authors state "The effectiveness of our approach relies on the quality of the identified significant subgraphs, which may not always align perfectly with the most influential substructures for the GNN's predictions."
  - Why unresolved: While the authors acknowledge this limitation, they do not explore how the current framework might be adapted or what challenges would arise in extending to these tasks
  - What evidence would resolve it: Experiments applying GlobalGCE to multi-class classification tasks or regression problems, along with analysis of performance and potential modifications needed

- Question: How sensitive is GlobalGCE's performance to the choice of hyperparameters, particularly the minimum appearance rate for frequent subgraph generation?
  - Basis in paper: [explicit] The authors mention that the minimum appearance rate is determined by trials to ensure the generated number of frequent subgraphs can achieve the predefined budget
  - Why unresolved: The paper does not provide a sensitivity analysis showing how performance varies with different minimum appearance rate values or other key hyperparameters
  - What evidence would resolve it: A systematic study varying the minimum appearance rate and other critical hyperparameters, showing their impact on coverage, proximity, and comprehensibility metrics

## Limitations
- Comprehensibility metric relies on structural compactness rather than actual human understanding
- Computational cost of frequent subgraph mining may limit scalability to large graphs
- No ablation study on the importance of individual components
- Results depend on the quality of the pre-trained GNN models

## Confidence
- Coverage results: **High** (supported by extensive experimental comparisons)
- Comprehensibility claims: **Medium** (based on proposed metric which requires further human studies)
- Theoretical guarantees: **High** (well-established in submodular optimization literature)

## Next Checks
1. Conduct human evaluation studies to validate the proposed comprehensibility metric against actual user understanding
2. Perform ablation studies to quantify the contribution of the autoencoder versus simpler baseline methods
3. Test scalability on larger graph datasets and analyze the computational bottleneck between subgraph mining and autoencoder training