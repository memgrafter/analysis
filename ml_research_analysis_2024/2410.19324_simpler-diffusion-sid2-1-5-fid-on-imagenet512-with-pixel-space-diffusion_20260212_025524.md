---
ver: rpa2
title: 'Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion'
arxiv_id: '2410.19324'
source_url: https://arxiv.org/abs/2410.19324
tags:
- diffusion
- sigmoid
- loss
- training
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Simpler Diffusion (SiD2) shows that end-to-end pixel-space diffusion
  models can match or exceed latent diffusion models in both image quality and efficiency.
  By using sigmoid loss-weighting, a simplified memory-efficient architecture, and
  flop-heavy scaling, SiD2 achieves state-of-the-art FID scores of 1.5 on ImageNet512
  and new records on ImageNet128, ImageNet256, and Kinetics600.
---

# Simpler Diffusion (SiD2): 1.5 FID on ImageNet512 with pixel-space diffusion

## Quick Facts
- arXiv ID: 2410.19324
- Source URL: https://arxiv.org/abs/2410.19324
- Reference count: 40
- Key outcome: Achieves 1.5 FID on ImageNet512, surpassing latent diffusion models in quality and efficiency.

## Executive Summary
Simpler Diffusion (SiD2) demonstrates that end-to-end pixel-space diffusion models can achieve state-of-the-art image generation quality and efficiency, matching or exceeding latent diffusion models. By employing sigmoid loss-weighting, simplified memory-efficient architecture, and intensive computational scaling, SiD2 attains leading FID scores on ImageNet benchmarks and Kinetics600. The approach removes block skip-connections in favor of levelwise ones and incorporates guidance intervals for enhanced sampling. SiD2 narrows the performance gap with latent diffusion models, showing pixel-space models can be competitive without requiring a separate autoencoder.

## Method Summary
SiD2 is an end-to-end pixel-space diffusion model that improves upon prior approaches by removing block skip-connections in favor of levelwise skip-connections, employing sigmoid loss-weighting for noise schedules, and introducing guidance intervals to enhance sampling. The architecture is designed for memory efficiency and supports heavy computational scaling to maximize image quality. These modifications collectively yield improved training and sampling efficiency while achieving superior FID scores on standard image benchmarks.

## Key Results
- Achieves 1.5 FID on ImageNet512, surpassing previous state-of-the-art results for pixel-space diffusion models.
- Sets new records on ImageNet128, ImageNet256, and Kinetics600, demonstrating broad applicability.
- Demonstrates improved training and sampling efficiency compared to prior pixel-space diffusion models.

## Why This Works (Mechanism)
SiD2's improvements stem from architectural and training innovations. Sigmoid loss-weighting stabilizes training by dynamically adjusting noise schedule weights, allowing more effective learning at different scales. Levelwise skip-connections simplify the architecture and improve gradient flow, boosting efficiency. Guidance intervals provide more stable and higher-quality sampling by leveraging model predictions across different noise levels. Heavy computational scaling further enhances quality, making pixel-space models competitive with latent diffusion approaches.

## Foundational Learning
- **Sigmoid loss-weighting**: Adjusts noise schedule weights dynamically during training to improve stability and convergence. *Why needed*: Helps the model learn effectively across different noise levels. *Quick check*: Verify the loss curve is smooth and stable during training.
- **Levelwise skip-connections**: Replaces block skip-connections with levelwise ones to simplify architecture and improve gradient flow. *Why needed*: Reduces memory overhead and enhances training efficiency. *Quick check*: Monitor training speed and memory usage.
- **Guidance intervals**: Uses model predictions at multiple noise levels to improve sampling quality. *Why needed*: Provides more stable and higher-quality samples during inference. *Quick check*: Compare sample quality with and without guidance intervals.
- **Memory-efficient architecture**: Designed to reduce GPU memory requirements while maintaining performance. *Why needed*: Enables scaling to higher resolutions and batch sizes. *Quick check*: Confirm memory usage is within expected limits during training.
- **Computational scaling**: Employs intensive computational resources to maximize image quality. *Why needed*: Allows pixel-space models to match or exceed latent diffusion quality. *Quick check*: Measure FLOPs and compare against baseline models.
- **End-to-end training**: Trains the model directly in pixel space, avoiding the need for a separate autoencoder. *Why needed*: Simplifies the pipeline and reduces preprocessing overhead. *Quick check*: Ensure no preprocessing artifacts affect final image quality.

## Architecture Onboarding
- **Component map**: Input image -> SiD2 UNet (with levelwise skip-connections) -> Output image
- **Critical path**: Forward diffusion steps with sigmoid loss-weighting and guidance intervals applied during sampling
- **Design tradeoffs**: Simplified architecture improves efficiency but may reduce flexibility compared to complex skip-connection patterns
- **Failure signatures**: Unstable training if sigmoid weighting parameters are poorly tuned; degraded quality if guidance intervals are not well-calibrated
- **First experiments**: 1) Train a small SiD2 model on CIFAR-10 to verify basic functionality. 2) Compare training curves with and without sigmoid loss-weighting. 3) Evaluate sampling quality with and without guidance intervals.

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Performance claims are primarily validated on a narrow set of datasets (ImageNet variants and Kinetics-600), raising questions about robustness to other domains.
- Heavy reliance on computational scaling may limit practical applicability in resource-constrained settings.
- Lack of ablation studies makes it unclear which architectural modifications are essential for the reported gains.

## Confidence
- **High** for the core finding that end-to-end pixel-space diffusion can match latent diffusion in quality on ImageNet512.
- **Medium** for claims about training efficiency and architectural simplicity due to lack of detailed ablation and reproducibility details.
- **Low** for claims about broad applicability and superiority over latent diffusion at other resolutions or in other modalities, as evidence is limited to the tested datasets.

## Next Checks
1. Replicate the training setup and results on at least two additional image datasets (e.g., CIFAR-10 and COCO) to assess generalizability.
2. Perform an ablation study to quantify the impact of sigmoid loss-weighting, levelwise skip-connections, and guidance intervals on FID and efficiency.
3. Compare SiD2's memory and compute efficiency against the best latent diffusion models on a held-out high-resolution dataset (e.g., 1024x1024) under identical hardware constraints.