---
ver: rpa2
title: 'RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized
  Quantization'
arxiv_id: '2402.06606'
source_url: https://arxiv.org/abs/2402.06606
tags:
- privacy
- quantization
- learning
- rqp-sgd
- projection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training machine learning
  models with quantized weights while preserving privacy, specifically for resource-constrained
  edge IoT devices. The authors propose RQP-SGD, a novel approach that combines differentially
  private stochastic gradient descent (DP-SGD) with randomized quantization projection.
---

# RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization

## Quick Facts
- arXiv ID: 2402.06606
- Source URL: https://arxiv.org/abs/2402.06606
- Authors: Ce Feng; Parv Venkitasubramaniam
- Reference count: 40
- Primary result: RQP-SGD achieves up to 35% higher accuracy than deterministic quantization while maintaining the same privacy budget

## Executive Summary
This paper introduces RQP-SGD, a novel approach that combines differentially private stochastic gradient descent (DP-SGD) with randomized quantization projection. The key innovation is integrating controlled randomness into the quantization projection step, which enhances privacy protection and reduces the required noise level compared to deterministic quantization. RQP-SGD achieves (ε,0)-differential privacy while addressing the challenge of training machine learning models with quantized weights for resource-constrained edge IoT devices. Experiments on MNIST and Breast Cancer Wisconsin datasets demonstrate significant accuracy improvements over deterministic quantization methods.

## Method Summary
RQP-SGD extends standard DP-SGD by incorporating a randomized projection mechanism during the quantization step. The algorithm uses a projection randomness coefficient q to control the probability of selecting either the nearest quantized value or a random alternative. This stochastic element contributes to the differential privacy guarantee, allowing for reduced Gaussian noise addition while maintaining the same privacy budget. The method operates by computing stochastic gradients on mini-batches, adding calibrated Gaussian noise, and then projecting the parameters onto a discrete quantization set using the randomized projection mechanism.

## Key Results
- RQP-SGD achieves up to 35% higher accuracy than deterministic quantization on MNIST and Breast Cancer Wisconsin datasets while maintaining the same privacy budget
- The projection randomness coefficient q significantly impacts the privacy-utility tradeoff, with optimal values depending on the dataset and privacy requirements
- Theoretical analysis shows that RQP-SGD satisfies (ε,0)-differential privacy through Rényi Differential Privacy composition
- Quantization bit granularity affects both accuracy and the required noise scale, with diminishing returns beyond 4-6 bits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding controlled randomness during quantization projection reduces the required noise level in DP-SGD while maintaining privacy
- Mechanism: The randomized projection step introduces uncertainty about the exact quantized value, which amplifies privacy protection and allows using less Gaussian noise for the same privacy budget
- Core assumption: The randomized projection contributes meaningfully to the differential privacy guarantee, allowing for noise reduction
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If q is too high (close to 1), the projection becomes nearly deterministic, losing the privacy benefit

### Mechanism 2
- Claim: Quantization-induced randomness can substitute for some differential privacy noise, improving model utility
- Mechanism: By making the projection stochastic rather than deterministic, RQP-SGD exploits quantization discretization as a privacy mechanism, reducing the need for external Gaussian noise
- Core assumption: Quantization randomness can be treated as a privacy mechanism that contributes to the overall DP guarantee
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If quantization step size is too large relative to noise scale, quantization error dominates

### Mechanism 3
- Claim: The privacy-utility tradeoff can be optimized by tuning the quantization randomness coefficient q
- Mechanism: The coefficient q controls the probability of selecting the nearest quantized value versus a random alternative. Lower q increases randomness (better privacy, less noise needed) but also increases quantization error
- Core assumption: There exists an optimal q that balances quantization error and noise error for a given privacy budget
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If q is set too low, excessive quantization randomness degrades model performance despite noise reduction

## Foundational Learning

- Concept: Differential Privacy (DP) and Rényi Differential Privacy (RDP)
  - Why needed here: RQP-SGD relies on DP theory to formally guarantee privacy. The analysis uses RDP composition to bound privacy loss across iterations
  - Quick check question: What is the relationship between the privacy budget (ε, δ) and the noise scale σ in Gaussian mechanism-based DP?

- Concept: Stochastic Gradient Descent (SGD) and Projected SGD
  - Why needed here: RQP-SGD is a variant of SGD that includes projection onto a discrete quantization set. Understanding convergence properties of SGD with projections is essential
  - Quick check question: How does the projection error affect the convergence rate of SGD when optimizing over a non-convex set?

- Concept: Quantization and Information Loss
  - Why needed here: RQP-SGD quantizes model weights to reduce memory and computation costs. The tradeoff between quantization granularity and information loss is central to the method
  - Quick check question: How does the number of quantization bits b affect the quantization error and the randomness coefficient q required for the same privacy level?

## Architecture Onboarding

- Component map: Input dataset -> RQP-SGD loop (gradient computation, noise addition, randomized projection) -> Trained quantized model with (ε,0)-DP guarantee

- Critical path:
  1. Initialize model parameters within bounded convex set W
  2. For each iteration: sample mini-batch Bt, compute stochastic gradient, add Gaussian noise, project onto quantization set using randomized projection with coefficient q
  3. Return final parameters after T iterations

- Design tradeoffs:
  - Privacy vs. Utility: Higher q improves privacy (less noise needed) but increases quantization error
  - Quantization Granularity vs. Efficiency: More bits b reduce quantization error but increase memory and computation
  - Noise Scale vs. Convergence: Larger σ provides stronger privacy but slows convergence and degrades utility

- Failure signatures:
  - Accuracy plateaus or degrades significantly: Excessive quantization randomness (q too low) or insufficient noise calibration
  - Privacy budget exceeded: Noise scale σ too small relative to sensitivity or q not properly tuned
  - Training instability: Step size η too large or batch size m too small

- First 3 experiments:
  1. Implement RQP-SGD on logistic regression with Breast Cancer Wisconsin dataset, b=4, q=0.9, compare to deterministic quantization under same privacy budget
  2. Sweep q from 0.3 to 0.95 and plot accuracy vs. q to identify optimal randomness coefficient
  3. Vary quantization bits b from 2 to 8 and measure impact on accuracy and memory usage for IoT deployment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the projection randomness coefficient (q) affect the convergence rate and final accuracy of RQP-SGD compared to deterministic quantization under varying privacy budgets?
- Basis in paper: [explicit] The paper discusses the trade-off between utility and privacy but does not provide detailed analysis of how q affects convergence rate and final accuracy across different privacy budgets
- Why unresolved: The paper mentions the trade-off but lacks comprehensive study of q's impact on convergence rate and final accuracy under different privacy budgets
- What evidence would resolve it: Empirical results showing convergence rate and final accuracy of RQP-SGD with varying q values under different privacy budgets, compared to deterministic quantization

### Open Question 2
- Question: Can RQP-SGD be effectively applied to non-convex optimization problems, such as training deep neural networks, while maintaining the privacy-utility trade-off?
- Basis in paper: [inferred] The paper mentions scopes for further research including exploring application to non-convex optimization problems and training neural networks
- Why unresolved: The paper focuses on convex objectives and does not explore effectiveness on non-convex optimization problems or deep neural networks
- What evidence would resolve it: Experimental results demonstrating effectiveness of RQP-SGD on non-convex optimization problems while maintaining privacy-utility trade-off

### Open Question 3
- Question: What is the impact of quantization bit granularity on the privacy-utility tradeoff in RQP-SGD, and how does it compare to other quantization-aware training methods?
- Basis in paper: [explicit] The paper mentions that test accuracy does not increase as quantization bits increase, attributing this to reduced randomness with higher quantization bits
- Why unresolved: The paper provides initial observations but lacks comprehensive comparison with other quantization-aware training methods
- What evidence would resolve it: Detailed study comparing privacy-utility tradeoff of RQP-SGD with varying quantization bit granularity to other quantization-aware training methods

## Limitations
- Limited empirical validation on diverse datasets and model architectures beyond MNIST and Breast Cancer Wisconsin
- Theoretical privacy guarantees may be conservative in practice due to approximation errors in RDP composition
- Claims about IoT deployment suitability lack empirical measurements of memory usage, computation time, or energy consumption on actual edge hardware

## Confidence
- Privacy Guarantee Cluster: High confidence - RDP composition analysis and noise scale derivation appear mathematically rigorous
- Accuracy Improvement Cluster: Medium confidence - 35% improvement demonstrated on specific datasets but generalizability requires more extensive testing
- IoT Suitability Cluster: Low confidence - Resource efficiency claims not substantiated with empirical measurements on actual IoT hardware

## Next Checks
1. Cross-Dataset Validation: Implement RQP-SGD on CIFAR-10, IMDB, and additional tabular datasets to assess generalizability and identify optimal q values across domains

2. Hardware Deployment Analysis: Deploy RQP-SGD on Raspberry Pi and Jetson Nano to measure memory footprint, inference latency, and energy consumption for validating IoT suitability claims

3. Sensitivity to Hyperparameters: Conduct systematic grid search over q ∈ [0.3, 0.95], b ∈ [2, 8], σ ∈ calibrated range on representative dataset to quantify robustness and identify failure modes