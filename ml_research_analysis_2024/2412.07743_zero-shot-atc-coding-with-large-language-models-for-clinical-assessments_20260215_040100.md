---
ver: rpa2
title: Zero-Shot ATC Coding with Large Language Models for Clinical Assessments
arxiv_id: '2412.07743'
source_url: https://arxiv.org/abs/2412.07743
tags:
- level
- coding
- health
- drug
- names
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of automating Anatomical Therapeutic
  Chemical (ATC) code assignment for prescription records, a time-consuming manual
  process at Ontario Health and InterRAI Canada. The authors develop a privacy-preserving
  approach using locally deployable large language models (LLMs) to perform hierarchical
  information extraction, guiding models through the ATC ontology level by level.
---

# Zero-Shot ATC Coding with Large Language Models for Clinical Assessments

## Quick Facts
- arXiv ID: 2412.07743
- Source URL: https://arxiv.org/abs/2412.07743
- Authors: Zijian Chen; John-Michael Gamble; Micaela Jantzi; John P. Hirdes; Jimmy Lin
- Reference count: 5
- Key outcome: Automated ATC coding achieves 78% exact match accuracy with GPT-4o and 60% with Llama 3.1 70B on clinical notes

## Executive Summary
This paper addresses the challenge of automating Anatomical Therapeutic Chemical (ATC) code assignment for prescription records at Ontario Health and InterRAI Canada. The authors develop a privacy-preserving approach using locally deployable large language models (LLMs) to perform hierarchical information extraction, guiding models through the ATC ontology level by level. Their method achieves strong performance across multiple datasets while enabling deployment in privacy-sensitive healthcare environments where sending data to external APIs is prohibited.

## Method Summary
The authors frame ATC coding as a hierarchical information extraction task, prompting LLMs to select from valid options at each level of the ATC hierarchy rather than generating codes directly. They implement three knowledge grounding strategies: Code Only, With Name (generic name), and With UMLS (UMLS definitions). The approach is evaluated using zero-shot prompting with Llama 3.1 70B and GPT-4o, and also fine-tuned Llama 3.1 8B models. Experiments are conducted across three datasets: Health Canada drug product data, RABBITS benchmark, and real clinical notes from Ontario Health.

## Key Results
- Zero-shot ATC coding achieves 78% exact match accuracy with GPT-4o and 60% with Llama 3.1 70B on clinical notes
- Fine-tuned Llama 3.1 8B matches zero-shot Llama 3.1 70B accuracy, suggesting smaller models can be effective when fine-tuned
- Knowledge grounding with UMLS definitions provides modest improvements over generic name grounding, particularly at level 5
- Performance on brand names is significantly lower than on generic names, indicating string similarity is a key factor

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Level-by-level prompting prevents code fabrication by constraining the LLM to select from valid options
- Mechanism: By presenting only valid options at each hierarchical level, the model cannot generate non-existent codes and must choose from the provided set
- Core assumption: LLMs have sufficient knowledge to recognize the correct code from a constrained set, even if they cannot generate it accurately
- Evidence anchors:
  - [abstract] "Our method frames ATC coding as a hierarchical information extraction task, guiding LLMs through the ATC ontology level by level"
  - [section] "This level-by-level information extraction approach offers two key advantages: it prevents code fabrication by constraining the LLM to select from valid options"
  - [corpus] Weak evidence - no direct citations found for this specific mechanism in related papers

### Mechanism 2
- Claim: Hierarchical decomposition reduces the label space complexity from thousands to an average of 5 options per decision
- Mechanism: The ATC hierarchy naturally partitions the 6,807 codes into manageable subsets at each level, making the classification task more tractable
- Core assumption: The hierarchical structure of ATC codes meaningfully reduces the search space for each decision point
- Evidence anchors:
  - [section] "it reduces the size of the large label space when making decisions by leveraging the ATC hierarchy; at each level, the LLM chooses from an average of just 5 options, with a maximum of 37 options for any given parent code"
  - [abstract] "our method frames ATC coding as a hierarchical information extraction task, guiding LLMs through the ATC ontology level by level"
  - [corpus] Weak evidence - no direct citations found for this specific mechanism in related papers

### Mechanism 3
- Claim: Knowledge grounding with UMLS definitions provides contextual information that enables finer-grained decisions at deeper levels
- Mechanism: UMLS definitions provide semantic context about therapeutic categories and drug substances that helps the LLM distinguish between similar codes at levels 4-5
- Core assumption: LLMs have sufficient pre-trained medical knowledge to benefit from explicit semantic context when making fine-grained distinctions
- Evidence anchors:
  - [section] "When presenting code options to the LLM, we augment each option with its corresponding UMLS definition, providing rich context about the therapeutic category or drug substance"
  - [section] "UMLS definition grounding provides modest improvements over generic name grounding, particularly at level 5, suggesting that the additional contextual information enable the LLM to make finer decisions deeper in the ATC hierarchy"
  - [corpus] Weak evidence - no direct citations found for this specific mechanism in related papers

## Foundational Learning

- Concept: Hierarchical classification systems
  - Why needed here: Understanding how the ATC hierarchy works is essential to grasp why level-by-level prompting is effective
  - Quick check question: How many levels are there in the ATC classification system and what does each level represent?

- Concept: Zero-shot learning with LLMs
  - Why needed here: The paper relies on models making predictions without task-specific training, which requires understanding LLM capabilities and limitations
  - Quick check question: What is the key difference between zero-shot and few-shot prompting in LLMs?

- Concept: Knowledge grounding techniques
  - Why needed here: The paper experiments with augmenting code options with UMLS definitions, requiring understanding of how additional context affects model performance
  - Quick check question: What is the difference between knowledge grounding and fine-tuning in the context of LLM applications?

## Architecture Onboarding

- Component map: Drug mention → Hierarchical classifier (5 levels) → ATC code prediction
- Critical path: Drug mention → Hierarchical classifier (5 levels) → ATC code prediction
- Design tradeoffs:
  - Privacy vs accuracy: Using open-source models vs proprietary ones
  - Speed vs thoroughness: Level-by-level approach adds latency but improves accuracy
  - Context vs simplicity: Knowledge grounding improves accuracy but adds complexity
- Failure signatures:
  - Low accuracy on brand names vs generic names indicates string similarity dependency
  - Performance degradation at level 5 suggests insufficient medical knowledge for fine distinctions
  - Inconsistent results across datasets indicate sensitivity to input format
- First 3 experiments:
  1. Compare level-by-level prompting vs direct code generation on a small validation set
  2. Test different temperature settings to find optimal balance between exploration and consistency
  3. Evaluate the impact of different prompt formats (with/without drug definitions) on accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ATC coding systems vary when using different LLM architectures (e.g., encoder-only vs decoder-only models) and what architectural features are most critical for hierarchical medical coding tasks?
- Basis in paper: [explicit] The paper compares GPT-4o (decoder-only) and Llama 3.1 70B (decoder-only) but does not explore other architectural approaches or compare with encoder-only models like BERT.
- Why unresolved: The paper only tests decoder-only models and does not systematically compare different architectural approaches to ATC coding.
- What evidence would resolve it: Direct comparison of multiple LLM architectures (encoder-only, decoder-only, and encoder-decoder) on the same ATC coding tasks with identical evaluation protocols.

### Open Question 2
- Question: What is the optimal balance between model size and task-specific fine-tuning data quantity for achieving high ATC coding accuracy while maintaining computational efficiency?
- Basis in paper: [explicit] The paper shows that fine-tuned Llama 3.1 8B matches zero-shot Llama 3.1 70B accuracy, but does not systematically explore the trade-offs across different model sizes and training dataset sizes.
- Why unresolved: The paper only tests one small model (Llama 3.1 8B) and does not explore the relationship between model size, fine-tuning data quantity, and accuracy across a range of configurations.
- What evidence would resolve it: Comprehensive experiments varying both model sizes and fine-tuning dataset sizes to identify the point of diminishing returns for accuracy gains versus computational costs.

### Open Question 3
- Question: How do different knowledge grounding strategies (beyond UMLS definitions) affect ATC coding accuracy, and what is the optimal way to present contextual information to LLMs for hierarchical classification tasks?
- Basis in paper: [explicit] The paper tests only UMLS definitions as grounding strategy and finds modest improvements, but does not explore alternative grounding approaches or compare different presentation formats.
- Why unresolved: The paper only tests one specific grounding approach (UMLS definitions) and does not explore other potential grounding strategies or compare different ways of presenting contextual information.
- What evidence would resolve it: Systematic comparison of multiple grounding strategies (e.g., drug mechanism explanations, therapeutic uses, side effects) and different presentation formats (embedded in options vs separate context window) on the same ATC coding tasks.

## Limitations

- Performance on real clinical notes (60% accuracy) is significantly lower than on structured datasets, suggesting limited generalizability to noisy clinical text
- The approach is only validated on ATC codes and has not been tested on other medical coding systems or broader clinical assessment tasks
- No formal safety analysis or error impact assessment is provided, leaving concerns about potential treatment errors unaddressed

## Confidence

**High Confidence** (★★★☆☆)
- Level-by-level prompting prevents code fabrication - The hierarchical approach consistently constrains model outputs to valid ATC codes across all experiments and datasets
- Smaller fine-tuned models can match larger zero-shot models - Llama 3.1 8B fine-tuned on the task achieves equivalent accuracy to Llama 3.1 70B in zero-shot mode
- String similarity drives performance - The correlation between name similarity and coding accuracy is observed consistently across all datasets

**Medium Confidence** (★★☆☆☆)
- Knowledge grounding provides modest improvements - While statistically measurable, the absolute gains are small and may not justify the added complexity
- Fine-tuned models show lower variance - The claim about reduced variance in fine-tuned models is based on limited statistical analysis
- Clinical note performance is adequate - The 60% accuracy on real clinical notes is promising but may not be sufficient for production deployment

**Low Confidence** (★☆☆☆☆)
- Privacy preservation claims - The paper asserts privacy benefits but does not provide empirical validation of these claims
- Scalability to other coding systems - The approach is only validated on ATC codes, with no evidence it would work for other hierarchical coding systems
- Safety for clinical deployment - No formal safety analysis or error impact assessment is provided

## Next Checks

1. **Clinical Safety Validation**: Conduct a formal safety analysis by having clinicians review ATC code predictions to assess whether incorrect predictions could lead to harmful treatment decisions, particularly focusing on the 40% error rate in clinical notes

2. **Cross-System Generalization**: Test the hierarchical prompting approach on other medical coding systems (e.g., ICD-11, SNOMED CT) to validate whether the mechanism generalizes beyond ATC codes

3. **Real-World Performance Study**: Deploy the system in a controlled clinical environment to measure performance on actual prescription records over time, including evaluation of how model errors propagate through clinical workflows and impact patient care