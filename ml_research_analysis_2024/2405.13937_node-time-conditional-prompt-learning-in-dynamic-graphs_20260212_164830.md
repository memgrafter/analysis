---
ver: rpa2
title: Node-Time Conditional Prompt Learning In Dynamic Graphs
arxiv_id: '2405.13937'
source_url: https://arxiv.org/abs/2405.13937
tags:
- node
- time
- prompt
- graph
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "DYGPROMPT addresses the challenge of bridging pre-training and\
  \ downstream task gaps in dynamic graph modeling by introducing dual prompts\u2014\
  node and time prompts\u2014that reconcile divergent task objectives and temporal\
  \ variations. It further employs dual condition-nets to generate time-conditioned\
  \ node prompts and node-conditioned time prompts, capturing the evolving, mutual\
  \ interplay between node and time patterns in a parameter-efficient manner."
---

# Node-Time Conditional Prompt Learning In Dynamic Graphs

## Quick Facts
- arXiv ID: 2405.13937
- Source URL: https://arxiv.org/abs/2405.13937
- Authors: Xingtong Yu; Zhenghao Liu; Xinming Zhang; Yuan Fang
- Reference count: 40
- Key outcome: DYGPROMPT consistently outperforms state-of-the-art baselines on both temporal node classification and link prediction tasks, achieving significant improvements in AUC-ROC scores across diverse dynamic graph scenarios.

## Executive Summary
DYGPROMPT addresses the challenge of bridging pre-training and downstream task gaps in dynamic graph modeling by introducing dual prompts—node and time prompts—that reconcile divergent task objectives and temporal variations. It further employs dual condition-nets to generate time-conditioned node prompts and node-conditioned time prompts, capturing the evolving, mutual interplay between node and time patterns in a parameter-efficient manner. Evaluated on four benchmark datasets, DYGPROMPT consistently outperforms state-of-the-art baselines on both temporal node classification and link prediction tasks, achieving significant improvements in AUC-ROC scores across diverse dynamic graph scenarios.

## Method Summary
DYGPROMPT is a prompt-based learning framework for dynamic graphs that addresses the pre-training and downstream task gap through dual prompts (node and time) and dual condition-nets. The method pre-trains a DGNN backbone (TGAT/TGN) on temporal link prediction, then tunes only the prompt parameters and condition-net weights on limited downstream data (1% of events). Node prompts modify node features via element-wise multiplication to align with downstream tasks, while time prompts adjust time features to capture temporal evolution. Dual condition-nets generate context-aware prompts conditioned on input features, modeling the evolving node-time patterns. The framework is evaluated on four benchmark datasets (Wikipedia, Reddit, MOOC, Genre) for temporal node classification and link prediction tasks.

## Key Results
- DYGPROMPT consistently outperforms state-of-the-art baselines on both temporal node classification and link prediction tasks
- Achieves significant improvements in AUC-ROC scores across diverse dynamic graph scenarios
- Effective in data-scarce scenarios with only 1% downstream training data
- Validated on four benchmark datasets (Wikipedia, Reddit, MOOC, Genre)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Node prompts bridge the task gap by modifying node features to align downstream tasks with pre-training objectives.
- Mechanism: Element-wise multiplication of a learnable vector `pnode` with node features, adjusting feature importance.
- Core assumption: The pre-trained model can still process modified features effectively if the modification preserves essential semantic structure.
- Evidence anchors:
  - [abstract] "a node prompt alters the node features to reformulate task input and bridge the task gap"
  - [section] "we define a learnable vector pnode as the node prompt to modify the node features... via element-wise multiplication"
  - [corpus] Weak evidence: no direct citation, but the general concept aligns with graph prompt learning literature.
- Break condition: If feature modification destroys essential structural information needed for downstream task, the pre-trained model cannot generalize.

### Mechanism 2
- Claim: Time prompts bridge the temporal gap by adjusting time features to match downstream temporal patterns.
- Mechanism: Element-wise multiplication of a learnable vector `ptime` with time-encoded features, capturing temporal evolution.
- Core assumption: The time encoder was trained on different temporal spans than downstream tasks, requiring adjustment.
- Evidence anchors:
  - [abstract] "at a time prompt adjusts the time features, capturing the temporal evolution of the dynamic graph"
  - [section] "we propose a time prompt to adjust time features... the time feature at t, denoted by ft, is reformulated as follows: ftime_t = ptime ⊙ ft"
  - [corpus] Weak evidence: no direct citation, but the concept of temporal misalignment is standard in dynamic graph learning.
- Break condition: If temporal patterns in downstream tasks are too different from pre-training data, time prompts cannot adequately compensate.

### Mechanism 3
- Claim: Dual condition-nets capture evolving node-time patterns by generating context-aware prompts conditioned on input features.
- Mechanism: Lightweight MLPs generate time-conditioned node prompts and node-conditioned time prompts based on current features.
- Core assumption: Node and time patterns mutually characterize each other, and this relationship varies across different nodes and time points.
- Evidence anchors:
  - [abstract] "we propose dual condition-nets to model the evolving node-time patterns in downstream tasks"
  - [section] "a time condition-net generates a sequence of time-conditioned node prompts for each node... a node condition-net generates a sequence of node-conditioned time prompts at each timestamp"
  - [corpus] Moderate evidence: the concept of conditional prompting is supported by recent graph prompt learning literature.
- Break condition: If the condition-nets are too simple to capture complex node-time interactions, or if the mutual characterization assumption is invalid.

## Foundational Learning

- Concept: Dynamic Graph Neural Networks (DGNNs) and their message-passing mechanism over time.
  - Why needed here: DYGPROMPT builds upon pre-trained DGNNs, so understanding their architecture and temporal message passing is essential.
  - Quick check question: How does a DGNN update node embeddings differently from a static GNN, and why is this important for temporal patterns?
- Concept: Prompt learning in NLP and its adaptation to graph structures.
  - Why needed here: DYGPROMPT uses prompts to bridge pre-training and downstream gaps, so understanding how prompts work in language models and how they're adapted to graphs is crucial.
  - Quick check question: What is the core idea behind prompt learning in NLP, and how does it translate to graph neural networks?
- Concept: Temporal point processes and time encoding in dynamic graphs.
  - Why needed here: Time encoding is a core component of DGNNs used in DYGPROMPT, so understanding how time is represented and processed is important.
  - Quick check question: How do common time encoding methods (like sinusoidal encoding) represent time in continuous dynamic graphs, and what are their limitations?

## Architecture Onboarding

- Component map:
  - Pre-trained DGNN backbone (TGAT/TGN) -> Node prompt (`pnode`) -> Time prompt (`ptime`) -> Dual condition-nets (TCN, NCN) -> Downstream loss function
- Critical path:
  1. Input features → Node prompt modification → Time prompt modification
  2. Modified features → Condition-nets → Conditional prompt generation
  3. Conditional prompts → Further feature modification
  4. Final features → Pre-trained DGNN → Embeddings
  5. Embeddings → Similarity calculation → Downstream loss
- Design tradeoffs:
  - Parameter efficiency vs. expressiveness: Condition-nets use fewer parameters than per-node/per-time prompts but may be less expressive
  - Static vs. dynamic prompts: Fixed prompts are simpler but cannot capture evolving patterns
  - Backbone choice: TGAT vs. TGN affects temporal modeling capability and compatibility with prompts
- Failure signatures:
  - Poor performance despite correct implementation: Could indicate insufficient capacity of condition-nets or misalignment between pre-training and downstream tasks
  - Instability during training: May suggest learning rate issues or overfitting to small downstream datasets
  - Degradation on certain datasets: Might indicate that temporal patterns in those datasets are too different from pre-training data
- First 3 experiments:
  1. Implement DYGPROMPT with only node prompts (no time prompts or condition-nets) on a small dataset to verify basic prompt learning works
  2. Add time prompts to the previous setup to test temporal gap bridging
  3. Implement full DYGPROMPT with condition-nets on the same dataset to validate the mutual characterization mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DYGPROMPT scale with the size of the downstream training dataset, particularly in scenarios with extremely limited labeled data?
- Basis in paper: [inferred] The paper mentions DYGPROMPT is designed for data-scarce scenarios and evaluates it with limited training data (1% of events), but does not systematically study how performance varies with training set size.
- Why unresolved: The experiments use a fixed small training set size, and the paper does not report performance curves as a function of training data quantity.
- What evidence would resolve it: Experiments showing AUC-ROC scores across multiple training set sizes (e.g., 0.1%, 0.5%, 1%, 5%, 10%) for each dataset would clarify the method's effectiveness in truly low-resource settings.

### Open Question 2
- Question: What is the impact of different time encoder architectures on DYGPROMPT's performance, and could alternative time encoding methods improve results?
- Basis in paper: [explicit] The paper uses a standard sinusoidal time encoder and mentions it is optimized based on pre-training data, but does not explore alternative time encoding strategies.
- Why unresolved: The choice of time encoder is not ablated, and the paper does not discuss whether the temporal patterns in pre-training and downstream tasks are sufficiently similar for the same encoder to be optimal.
- What evidence would resolve it: Experiments comparing DYGPROMPT with different time encoders (e.g., positional encoding, timestamp embedding) on the same datasets would reveal whether the time encoder choice significantly impacts performance.

## Limitations

- The effectiveness of DYGPROMPT depends heavily on the pre-training phase, but the paper provides limited details about the pre-training procedure and its impact on downstream performance.
- The assumption that node and time patterns mutually characterize each other is plausible but not rigorously validated through ablation studies that isolate the contribution of each condition-net.
- The experimental setup (1% training data) is highly constrained and may not generalize to scenarios with more abundant downstream data, making it unclear how the method scales with larger datasets.

## Confidence

- **High Confidence:** The core mechanism of using learnable prompts (node and time) to bridge pre-training and downstream task gaps is well-established in the prompt learning literature and has been demonstrated to work in various contexts.
- **Medium Confidence:** The specific design choices for dual condition-nets and their ability to capture evolving node-time patterns are reasonable but not extensively validated. The mutual characterization assumption needs more empirical support.
- **Low Confidence:** The paper claims significant improvements over state-of-the-art baselines, but the experimental setup (1% training data) is highly constrained and may not generalize to scenarios with more abundant downstream data.

## Next Checks

1. **Ablation Study:** Conduct a comprehensive ablation study to isolate the contribution of each component (node prompts, time prompts, condition-nets) and validate the mutual characterization assumption. Specifically, test whether node-conditioned time prompts and time-conditioned node prompts individually improve performance, and whether their combination provides additional benefits.

2. **Pre-training Sensitivity Analysis:** Investigate how different pre-training strategies (e.g., varying the amount of pre-training data, using different DGNN backbones) affect the downstream performance of DYGPROMPT. This will help understand the importance of the pre-training phase and identify potential failure modes.

3. **Generalization to Larger Datasets:** Evaluate DYGPROMPT on a larger-scale dynamic graph dataset with more abundant downstream training data (e.g., 10% or 20% instead of 1%). This will test whether the approach's advantages persist in less constrained settings and provide insights into its scalability.