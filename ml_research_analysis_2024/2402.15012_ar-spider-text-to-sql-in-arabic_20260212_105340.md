---
ver: rpa2
title: 'Ar-Spider: Text-to-SQL in Arabic'
arxiv_id: '2402.15012'
source_url: https://arxiv.org/abs/2402.15012
tags:
- arabic
- dataset
- lgesql
- language
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Ar-Spider, the first Arabic cross-domain
  text-to-SQL dataset, created by translating the English Spider dataset. The authors
  address the challenges of schema linguistic and SQL structural differences between
  Arabic and English by using cross-lingual pre-trained models and introducing a Context
  Similarity Relationship (CSR) approach that maps Arabic question tokens to English
  schema items based on cosine similarity.
---

# Ar-Spider: Text-to-SQL in Arabic

## Quick Facts
- arXiv ID: 2402.15012
- Source URL: https://arxiv.org/abs/2402.15012
- Reference count: 30
- Key outcome: Introduces Ar-Spider dataset and achieves 66.63% accuracy with LGESQL+XLM-R+CSR, only 7.73% below English baseline

## Executive Summary
This paper addresses the challenge of Arabic text-to-SQL by creating Ar-Spider, the first Arabic cross-domain dataset translated from English Spider. The authors develop a Context Similarity Relationship (CSR) approach that maps Arabic question tokens to English schema items using cosine similarity of LASER embeddings, overcoming character-level mismatches between languages. Two baseline models (LGESQL and S2SQL) are evaluated with mBERT and XLM-R encoders, demonstrating that CSR improves performance by 1.52-2.33% across all configurations.

## Method Summary
The method involves translating the English Spider dataset to Arabic to create Ar-Spider, then adapting two state-of-the-art text-to-SQL models (LGESQL and S2SQL) with cross-lingual pre-trained encoders (mBERT and XLM-R). The CSR approach injects new edges into the question-schema graph encoder by computing cosine similarity between Arabic question tokens and English schema items using LASER embeddings, with a 78% similarity threshold. Models are trained on the Ar-Spider dataset and evaluated using exact match accuracy against gold SQL queries.

## Key Results
- Ar-Spider dataset created with 9,691 Arabic questions over 166 databases
- LGESQL+XLM-R+CSR achieves 66.63% accuracy, 7.73% below English baseline
- CSR improves performance by 1.52-2.33% across all model-encoder combinations
- Models perform worse on harder question types, mirroring English Spider patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CSR improves text-to-SQL performance by enabling Arabic tokens to match English schema items through semantic embedding similarity.
- Mechanism: CSR computes cosine similarity between LASER embeddings of Arabic question tokens and English schema items, creating cross-lingual edges when similarity exceeds 78%. This bypasses character-level mismatches between Arabic and English.
- Core assumption: LASER embeddings map semantically equivalent sentences in different languages to nearby points in embedding space.
- Evidence anchors:
  - [abstract] "CSR approach to mitigate the effect of the schema linguistic problem by injecting new relationship into the question-schema graph encoder"
  - [section 5] "LASER maps a sentence in any language to a point in a high-dimensional embedding space in such a way that the same statement in any language will end up in the same neighborhood"
  - [corpus] Weak: No corpus evidence directly supports CSR mechanism performance.
- Break condition: If LASER embeddings do not preserve semantic similarity across Arabic and English for domain-specific terms, CSR edges will be noisy and harm performance.

### Mechanism 2
- Claim: Cross-lingual pre-training models (mBERT, XLM-R) mitigate schema linguistic challenges by providing multilingual token representations.
- Mechanism: These models are pre-trained on Arabic and English text, so Arabic tokens and English schema items obtain contextualized representations in shared embedding space, enabling partial matching.
- Core assumption: Pre-training on multilingual corpora creates shared semantic spaces where cross-lingual tokens are meaningfully aligned.
- Evidence anchors:
  - [abstract] "tested with two cross-lingual models to alleviate the effects of schema linguistic and SQL structure linking challenges"
  - [section 4.1] "both evaluated with two pre-training cross-lingual language models: mBERT [8] and XLM-R [6]"
  - [corpus] Weak: No corpus evidence directly validates this mechanism.
- Break condition: If cross-lingual alignment is insufficient for technical vocabulary (e.g., SQL keywords), performance will plateau.

### Mechanism 3
- Claim: Combining LGESQL and S2SQL architectures with graph-based relation encoding captures complex SQL semantics better than sequence models.
- Mechanism: These models encode questions and schemas as nodes in a graph with edges representing exact/partial matches and syntactic dependencies, then use relational graph attention to aggregate information across the graph structure.
- Core assumption: Graph-structured representations better capture the compositional structure of SQL queries compared to flat sequences.
- Evidence anchors:
  - [abstract] "adopt two baseline models LGESQL [4] and S2SQL [12]"
  - [section 4] "both LGESQL and S2SQL models have a similar encoder-decoder architecture, which consists of three parts"
  - [corpus] Weak: No corpus evidence directly supports graph architecture advantage.
- Break condition: If the graph edges are too sparse or noisy, attention aggregation will fail to improve over sequence models.

## Foundational Learning

- Concept: Cross-lingual embeddings and semantic similarity
  - Why needed here: The Arabic-to-English schema mapping requires semantic understanding beyond character matching, so understanding how cross-lingual embeddings work is essential.
  - Quick check question: How does LASER ensure that "SELECT" in English and "SELECT" in Arabic (if transliterated) get similar embeddings?
- Concept: Graph neural networks and relational attention
  - Why needed here: Both LGESQL and S2SQL use graph-based encoding; understanding relational attention and graph message passing is critical for debugging model behavior.
  - Quick check question: In a relational graph attention network, how is information aggregated from neighboring nodes?
- Concept: Text-to-SQL semantic parsing evaluation
  - Why needed here: Exact match accuracy is the primary metric; understanding what constitutes a correct SQL query prediction is key for interpreting results.
  - Quick check question: What makes two SQL queries equivalent for exact match evaluation?

## Architecture Onboarding

- Component map: Question tokens → Cross-lingual encoder (mBERT/XLM-R) → Graph node embeddings → Relational graph attention → Decoder (grammar-based AST generation) → SQL output. CSR adds LASER-based cosine similarity edges to the initial graph.
- Critical path: Input graph construction (CSR edges) → Hidden line graph (relational attention) → Output graph (grammar-based decoding) → Exact match accuracy.
- Design tradeoffs: CSR adds preprocessing overhead and complexity but enables matching; cross-lingual encoders trade vocabulary richness for language coverage.
- Failure signatures: Low exact match accuracy with high variance across difficulty levels suggests CSR edges are noisy; poor performance with XLM-R but better with mBERT suggests insufficient cross-lingual alignment in the larger model.
- First 3 experiments:
  1. Train baseline LGESQL + XLM-R on Ar-Spider without CSR to establish performance ceiling.
  2. Add CSR with varying similarity thresholds (70%, 75%, 80%) to find optimal threshold.
  3. Compare CSR performance with and without cross-lingual encoders to isolate CSR impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective would fine-tuning pre-trained cross-lingual models specifically for the Arabic-English schema linking task be compared to using general-purpose models like mBERT and XLM-R with CSR?
- Basis in paper: [inferred] The paper mentions this as future work: "it would be useful to develop better methods for linking Arabic questions to English schema items, such as utilizing large language models or by fine-tuning pre-trained models specifically for the arabic-english schema linking task."
- Why unresolved: The authors only experimented with off-the-shelf cross-lingual models and did not explore task-specific fine-tuning approaches for schema linking.
- What evidence would resolve it: Comparative experiments showing exact match accuracy of fine-tuned cross-lingual models versus mBERT/XLM-R with CSR on the Ar-Spider dataset.

### Open Question 2
- Question: Would combining Arabic with similar morphologically rich languages (like Persian or Urdu) during training improve performance compared to training with English and Arabic separately?
- Basis in paper: [explicit] The authors note: "Thus, combining Arabic with similar languages such as Persian or Urdu may enhance the performance" after finding that combining English and Arabic datasets didn't improve results.
- Why unresolved: The authors only experimented with combining English and Arabic datasets, not with morphologically similar languages.
- What evidence would resolve it: Experimental results comparing model performance when trained on Arabic-only, Arabic+English, and Arabic+similar-languages datasets.

### Open Question 3
- Question: What is the optimal similarity threshold for the CSR approach, and how does performance vary across different threshold values?
- Basis in paper: [inferred] The authors state they used a 78% threshold for cosine similarity in CSR but don't explore other threshold values or analyze sensitivity to this parameter.
- Why unresolved: The paper only reports results using a fixed 78% threshold without exploring how different thresholds affect performance.
- What evidence would resolve it: A sensitivity analysis showing exact match accuracy across different cosine similarity thresholds (e.g., 70%, 75%, 80%, 85%) for the CSR approach.

### Open Question 4
- Question: How would the CSR approach perform if implemented using different cross-lingual embedding models like mBERT or XLM instead of LASER?
- Basis in paper: [explicit] The authors conducted an ablation study comparing LASER with mBERT, XLM, and SBERT, but only reported that LASER performed best. They didn't actually implement CSR with these other models.
- Why unresolved: The authors only implemented CSR with LASER and didn't test the approach with other embedding models that showed lower cosine similarity scores in their analysis.
- What evidence would resolve it: Experimental results showing exact match accuracy when CSR is implemented with different cross-lingual embedding models (mBERT, XLM, SBERT) compared to LASER-based CSR.

## Limitations

- Evaluation framework relies entirely on dataset translation without native speaker validation, introducing potential semantic drift between Arabic questions and their English sources.
- CSR approach depends critically on LASER's cross-lingual alignment quality, but no ablation study removes CSR to isolate its contribution.
- The 78% similarity threshold appears arbitrary without sensitivity analysis.
- Cross-lingual pre-training models may fail on Arabic-specific SQL terminology not well-represented in training corpora.

## Confidence

- **High Confidence**: Ar-Spider dataset creation and basic translation methodology; baseline model implementations using standard architectures; CSR approach description and implementation details.
- **Medium Confidence**: Claims about CSR improving performance by 1.52-2.33%; claims about cross-lingual models mitigating schema linguistic challenges; claims about graph architectures capturing SQL semantics better than sequence models.
- **Low Confidence**: Claims about Arabic-English semantic equivalence preservation through translation; claims about LASER's ability to handle technical vocabulary across languages; claims about the 78% threshold being optimal without sensitivity analysis.

## Next Checks

1. **Ablation Study on CSR**: Train and evaluate all four model configurations (LGESQL and S2SQL with mBERT and XLM-R) on Ar-Spider with and without CSR, measuring exact match accuracy differences to quantify CSR's contribution beyond cross-lingual pre-training.

2. **Threshold Sensitivity Analysis**: Systematically vary the CSR cosine similarity threshold (70%, 75%, 80%, 85%) and measure performance impact, identifying whether 78% is optimal or if different thresholds work better for different model-encoder combinations.

3. **Semantic Drift Analysis**: Sample 50 Arabic questions and their English sources, have native Arabic speakers evaluate semantic equivalence, and correlate accuracy drops with semantic drift severity to understand translation quality impact on model performance.