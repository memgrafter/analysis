---
ver: rpa2
title: Neurosymbolic Conformal Classification
arxiv_id: '2409.13585'
source_url: https://arxiv.org/abs/2409.13585
tags:
- conformal
- classi
- cation
- learning
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of providing trustworthy predictions
  in multi-label classification by integrating neurosymbolic AI with conformal prediction.
  The authors propose methods to transform a classifier into a conformal predictor
  that outputs confidence sets guaranteed to include the true label with a specified
  probability, while incorporating prior knowledge expressed as propositional formulas.
---

# Neurosymbolic Conformal Classification

## Quick Facts
- arXiv ID: 2409.13585
- Source URL: https://arxiv.org/abs/2409.13585
- Authors: Arthur Ledaguenel; Céline Hudelot; Mostepha Khouadjia
- Reference count: 18
- Primary result: Introduces semantic filtering and conditioning techniques to integrate prior knowledge into conformal classification for trustworthy multi-label predictions

## Executive Summary
This paper addresses the challenge of providing trustworthy predictions in multi-label classification by integrating neurosymbolic AI with conformal prediction. The authors propose methods to transform a classifier into a conformal predictor that outputs confidence sets guaranteed to include the true label with a specified probability, while incorporating prior knowledge expressed as propositional formulas. The key contribution is the introduction of semantic filtering and semantic conditioning techniques to integrate prior knowledge into conformal classification. Semantic filtering simply removes states that do not satisfy the prior knowledge from the confidence set, while semantic conditioning incorporates the prior knowledge directly into the non-conformity measure.

## Method Summary
The paper presents a framework that combines neural networks with symbolic knowledge representation for multi-label classification using conformal prediction. The approach uses a probability-based non-conformity measure that transforms confidence set computation into state enumeration with probability thresholds. Two methods are introduced for incorporating prior knowledge: semantic filtering, which removes invalid states from confidence sets, and semantic conditioning, which integrates prior knowledge directly into the non-conformity measure. The methods can be computed efficiently when prior knowledge is compiled into tractable dDNNF circuits, enabling polynomial-time operations relative to the number of variables and states.

## Key Results
- Semantic filtering preserves conformal prediction guarantees while reducing confidence set size by removing states that violate prior knowledge
- Semantic conditioning integrates prior knowledge into the non-conformity measure itself, improving alignment with the model's training objective
- The proposed non-conformity measure enables efficient computation of confidence sets in multi-label classification through state enumeration with probability thresholds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The semantic filtering approach preserves conformal prediction guarantees while reducing confidence set size.
- Mechanism: By filtering out states that violate prior knowledge κ after computing the confidence set, the method maintains the statistical guarantee while only including semantically valid predictions.
- Core assumption: The test set follows the consistency hypothesis where all labels satisfy the prior knowledge κ.
- Evidence anchors:
  - [abstract] "The key contribution is the introduction of semantic filtering and semantic conditioning techniques to integrate prior knowledge into conformal classification."
  - [section] "Since satisfaction of a propositional formula can be done in a time linear in the size of the formula, this approach represents a minor overhead to the un-informed inductive conformal classification method in terms of computational complexity."
- Break condition: If the consistency hypothesis is violated (test labels violate κ), the statistical guarantee no longer holds.

### Mechanism 2
- Claim: Semantic conditioning integrates prior knowledge into the non-conformity measure itself, improving alignment with the model's training objective.
- Mechanism: By conditioning the probability distribution on prior knowledge κ within the non-conformity measure (sκ θ px, yq " 1 ´ Ppy|Mθpxq, κq), the method optimizes parameters to minimize the conditioned negative likelihood rather than the standard negative likelihood.
- Core assumption: The model can be trained effectively using semantic conditioning and the dDNNF compilation of κ is tractable.
- Evidence anchors:
  - [abstract] "The key contribution is the introduction of semantic filtering and semantic conditioning techniques to integrate prior knowledge into conformal classification."
  - [section] "Therefore, prior knowledge can be integrated in the non-conformity measure itself (by conditioning the probability distribution on the prior knowledge) to restore the alignment, i.e.,: sκ θ px, yq " 1 ´ Ppy|Mθpxq, κq"
- Break condition: If κ cannot be compiled into dDNNF of reasonable size, the computation becomes intractable.

### Mechanism 3
- Claim: Using sθpx, yq " 1 ´ Ppy|Mθpxqq as the non-conformity measure enables efficient computation of confidence sets in multi-label classification.
- Mechanism: This non-conformity measure transforms confidence set computation into state enumeration with probability thresholds, which can be done efficiently in polynomial time relative to the number of variables and states.
- Core assumption: The underlying model's probability distribution can be efficiently evaluated and the quantile threshold is not too small.
- Evidence anchors:
  - [section] "Computing the confidence set Cαpxq :“ t y P Y|sθpx, yq ă qαu is equivalent to enumerating all states with a probability superior to a threshold tα “ 1 ´ qα. This can be done efficiently in time polynomial in the number of variables and in the number of states."
- Break condition: If the quantile threshold is very small, the number of states to check becomes prohibitively large, making the method intractable.

## Foundational Learning

- Concept: Conformal prediction framework
  - Why needed here: This work builds on conformal prediction to provide statistical guarantees for multi-label classification
  - Quick check question: What is the key property that makes conformal prediction useful for trustworthy AI systems?

- Concept: Propositional logic and satisfiability
  - Why needed here: Prior knowledge is represented as propositional formulas κ that constrain valid output states
  - Quick check question: How do you determine if a state y satisfies a formula κ in propositional logic?

- Concept: Probabilistic reasoning with logical constraints
  - Why needed here: The paper uses probabilistic reasoning to integrate logical knowledge with neural predictions through PQE, MPE, and thresholding problems
  - Quick check question: What is the difference between Probabilistic Query Estimation (PQE) and Most Probable Explanation (MPE)?

## Architecture Onboarding

- Component map:
  Base classifier Mθ (neural network) -> Non-conformity measure sθ (probability-based) -> Calibration mechanism (quantile computation) -> Prior knowledge representation κ (propositional formula) -> dDNNF compiler (for tractable reasoning when available) -> Confidence set generator (filtering or conditioning)

- Critical path:
  1. Train base classifier Mθ on training data
  2. Compute non-conformity scores on calibration set
  3. Determine quantile threshold qα for miscoverage rate α
  4. For each test instance, enumerate/identify high-probability states
  5. Apply semantic filtering or conditioning based on prior knowledge κ
  6. Output confidence set with statistical guarantee

- Design tradeoffs:
  - Semantic filtering vs. semantic conditioning: filtering is simpler and preserves guarantees but may produce larger sets; conditioning can produce tighter sets but requires tractable dDNNF compilation
  - Computational efficiency vs. precision: more precise probability evaluation enables tighter confidence sets but increases computational cost
  - dDNNF compilation overhead vs. runtime efficiency: pre-compiling κ to dDNNF speeds up reasoning but requires compilation time and memory

- Failure signatures:
  - Confidence sets consistently include invalid states: semantic filtering not applied correctly or consistency hypothesis violated
  - Confidence sets too large to enumerate: quantile threshold too small, probability distribution too diffuse
  - Computation becomes intractable: κ cannot be compiled to tractable dDNNF, or number of high-probability states exceeds practical limits
  - Statistical guarantees fail: test data violates prior knowledge constraints

- First 3 experiments:
  1. Implement the basic non-informed conformal classifier using sθpx, yq " 1 ´ Ppy|Mθpxqq and verify confidence set enumeration works correctly on a small synthetic dataset
  2. Add semantic filtering with a simple propositional formula κ and validate that invalid states are excluded while maintaining statistical guarantees
  3. Implement semantic conditioning with a dDNNF-compiled κ and compare confidence set sizes against filtering approach on a benchmark multi-label dataset

## Open Questions the Paper Calls Out

- Open Question 1: How does the performance of semantic conditioning compare to semantic filtering when prior knowledge is highly restrictive?
  - Basis in paper: [inferred] The paper introduces both semantic filtering and semantic conditioning methods for integrating prior knowledge into conformal classification, but does not provide empirical comparisons of their performance under different conditions.
  - Why unresolved: The paper focuses on theoretical analysis and computational complexity rather than empirical evaluation of the two methods under varying levels of prior knowledge restrictiveness.
  - What evidence would resolve it: Empirical studies comparing the effectiveness of semantic filtering and semantic conditioning methods on datasets with varying degrees of prior knowledge restrictiveness, measuring metrics such as confidence set size and prediction accuracy.

- Open Question 2: What is the impact of prior knowledge compilation quality on the tractability of semantic conditioning?
  - Basis in paper: [explicit] The paper states that semantic conditioning can be computed tractably when prior knowledge can be compiled into dDNNF circuits of reasonable size, but does not explore how compilation quality affects this tractability.
  - Why unresolved: The relationship between the quality of prior knowledge compilation and the computational efficiency of semantic conditioning is not investigated in the paper.
  - What evidence would resolve it: Studies analyzing the correlation between the size and structure of compiled dDNNF circuits and the computational time required for semantic conditioning, under various compilation methods and prior knowledge formulations.

- Open Question 3: How does the choice of non-conformity measure affect the performance of conformal classification in the presence of prior knowledge?
  - Basis in paper: [explicit] The paper introduces different non-conformity measures for uninformed and informed conformal classification, but does not compare their performance.
  - Why unresolved: The paper does not provide empirical results comparing the effectiveness of different non-conformity measures, particularly in the context of integrating prior knowledge.
  - What evidence would resolve it: Experimental results comparing the performance of various non-conformity measures (e.g., those based on probability distributions vs. distance metrics) in terms of confidence set size, prediction accuracy, and computational efficiency, both with and without prior knowledge integration.

## Limitations
- Computational tractability of semantic conditioning heavily depends on the ability to compile prior knowledge κ into dDNNF circuits
- The paper assumes the consistency hypothesis (all test labels satisfy κ) without discussing what happens when this is violated
- The exponential growth of the output space in multi-label classification poses inherent scalability challenges

## Confidence
- **High**: The core mechanism of using probability-based non-conformity measures for multi-label conformal classification is well-established and the computational complexity analysis is sound.
- **Medium**: The statistical guarantees preservation under semantic filtering is theoretically valid but depends on the consistency hypothesis being satisfied in practice.
- **Medium**: The benefits of semantic conditioning in terms of tighter confidence sets are demonstrated but the practical impact depends on the tractability of dDNNF compilation.

## Next Checks
1. Test the consistency hypothesis by evaluating how often test instances violate the prior knowledge κ and measure the resulting impact on statistical guarantees.
2. Benchmark the actual computation time for semantic conditioning with various formula complexities to determine practical dDNNF size limits.
3. Compare the trade-off between semantic filtering and conditioning approaches across multiple real-world multi-label datasets with varying levels of prior knowledge expressiveness.