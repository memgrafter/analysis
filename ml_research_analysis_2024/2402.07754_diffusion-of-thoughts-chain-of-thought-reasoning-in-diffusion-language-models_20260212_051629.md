---
ver: rpa2
title: 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models'
arxiv_id: '2402.07754'
source_url: https://arxiv.org/abs/2402.07754
tags:
- diffusion
- reasoning
- language
- training
- plaid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Diffusion-of-Thought (DoT), a novel approach
  that integrates diffusion models with Chain-of-Thought reasoning to enhance the
  reasoning abilities of diffusion language models. DoT allows reasoning steps to
  diffuse over time through a diffusion model, offering greater flexibility in trading
  off computation for reasoning performance compared to autoregressive models.
---

# Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models

## Quick Facts
- **arXiv ID:** 2402.07754
- **Source URL:** https://arxiv.org/abs/2402.07754
- **Reference count:** 40
- **Primary result:** DoT achieves up to 27× speedup over autoregressive models while maintaining accuracy on reasoning tasks

## Executive Summary
This paper introduces Diffusion-of-Thought (DoT), a novel approach that integrates diffusion models with Chain-of-Thought reasoning to enhance the reasoning abilities of diffusion language models. DoT allows reasoning steps to diffuse over time through a diffusion language model, offering greater flexibility in trading off computation for reasoning performance compared to autoregressive models. Experiments on multi-digit multiplication, boolean logic, and grade school math problems show that DoT outperforms larger autoregressive models in both efficiency and accuracy, with a small diffusion model achieving up to 27× speed-up without performance loss. DoT also demonstrates promising self-correction abilities and benefits from techniques like self-consistency decoding.

## Method Summary
DoT fine-tunes pre-trained diffusion language models (Plaid 1.3B, SEDD-small/medium) on reasoning tasks by integrating Chain-of-Thought rationales into the denoising process. The approach uses scheduled sampling to improve self-correction during training, where model-generated predictions replace oracle demonstrations at random. For inference, DoT employs a conditional ODE solver for accelerated sampling and self-consistency decoding with 20 samples to select final answers. The method can generate multiple reasoning steps in parallel (single-pass) or sequentially (multi-pass DoTMP) with causal bias, allowing later steps to condition on prior correct thoughts.

## Key Results
- DoT achieves 100% accuracy on 4×4 and 5×5 digit multiplication with up to 27× speed-up compared to GPT-2
- On GSM8K, DoT with self-consistency decoding matches or exceeds larger autoregressive models' performance
- Scheduled sampling during training improves DoT's self-correction ability on complex reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DoT's parallel diffusion of reasoning steps enables greater computational efficiency compared to autoregressive CoT.
- Mechanism: By allowing multiple reasoning steps to be generated simultaneously across diffusion timesteps rather than sequentially, DoT can leverage the parallel processing capabilities of diffusion models. This reduces the number of sequential operations required to generate complex reasoning chains.
- Core assumption: The diffusion model can effectively denoise and generate coherent reasoning steps when multiple steps are diffused in parallel rather than in a strict left-to-right order.
- Evidence anchors:
  - [abstract]: "In contrast to autoregressive language models that make decisions in a left-to-right, token-by-token manner, DoT allows reasoning steps to diffuse over time through a diffusion language model and offers greater flexibility in trading-off computation for reasoning performance."
  - [section 4.2]: "Interestingly, DoT can attain 100% accuracy for these tasks while maintaining significant throughput with diffusion sampling steps set at 1 for multiplication datasets and 2 for the boolean logical dataset, achieving maximum 27× speed-up compared to GPT-2."
  - [corpus]: Weak evidence - no direct comparison of parallel vs sequential processing in diffusion literature.

### Mechanism 2
- Claim: Scheduled sampling during training improves DoT's self-correction ability by exposing the model to noisy intermediate thoughts.
- Mechanism: By randomly replacing oracle demonstrations with model-generated predictions during training, the model learns to recover from errors introduced by previous timesteps rather than relying solely on ground truth. This mimics the inference-time denoising process.
- Core assumption: The model can effectively learn to correct errors when exposed to its own noisy predictions during training, rather than only seeing clean oracle data.
- Evidence anchors:
  - [section 3.3]: "To further improve their self-correcting ability, we design a scheduled sampling [3] mechanism tailored for diffusion models such that self-generated error thoughts in previous timesteps are exposed and corrected during the training stage."
  - [section 4.6]: "In the second case where the problem is slightly harder, the model cannot give concrete thoughts in the first step but can still produce the correct answer through the later 'slow' thinking process."
  - [corpus]: Moderate evidence - scheduled sampling is well-established in autoregressive models, but its application to diffusion models for reasoning is novel.

### Mechanism 3
- Claim: Multi-pass DoT (DoTMP) with causal bias improves performance by allowing later reasoning steps to condition on prior correct thoughts.
- Mechanism: By generating reasoning steps sequentially in multiple passes rather than all at once, each subsequent thought can be conditioned on the previously generated correct thoughts, introducing a causal structure that guides the reasoning process.
- Core assumption: The sequential conditioning in DoTMP provides stronger guidance than parallel generation, particularly for complex problems requiring multi-step reasoning.
- Evidence anchors:
  - [section 3.2]: "This method disentangles the generation of multiple rationales and introduces casual inductive bias such that later rationale can be guided by stronger condition signals of prior rationales during the generation."
  - [section 4.3]: "Additionally, multi-pass DoT, with casual bias, performs slightly better than single-pass one on Plaid, while the latter is more efficient."
  - [corpus]: Weak evidence - the causal bias concept is borrowed from autoregressive models but its effectiveness in diffusion models is not extensively validated in existing literature.

## Foundational Learning

- Concept: Diffusion models and denoising processes
  - Why needed here: Understanding how diffusion models gradually transform noisy data back to clean data is fundamental to grasping how DoT generates reasoning steps through denoising latent representations.
  - Quick check question: How does the forward noising process in diffusion models differ from the reverse denoising process, and why is this distinction important for DoT?

- Concept: Chain-of-Thought (CoT) reasoning in language models
  - Why needed here: DoT is explicitly designed to integrate CoT reasoning with diffusion models, so understanding the traditional CoT approach and its limitations is crucial for appreciating DoT's innovations.
  - Quick check question: What are the main limitations of autoregressive CoT that DoT aims to address, particularly regarding efficiency and self-correction?

- Concept: Scheduled sampling and exposure bias
  - Why needed here: The scheduled sampling mechanism is a key training technique used in DoT to improve self-correction, so understanding how it works and why it addresses exposure bias is important.
  - Quick check question: How does scheduled sampling during training help mitigate exposure bias, and why is this particularly important for diffusion models used in reasoning tasks?

## Architecture Onboarding

- Component map: Input problem statement -> Partial noising of rationale portion -> Diffusion timesteps -> Denoising process -> Generated reasoning steps -> Final answer (via majority vote in self-consistency)

- Critical path: Input problem statement → Partial noising of rationale portion → Diffusion timesteps → Denoising process → Generated reasoning steps → Final answer (via majority vote in self-consistency)

- Design tradeoffs:
  - Parallel vs sequential reasoning: DoT favors parallel generation for efficiency, while DoTMP uses sequential generation for better guidance at the cost of speed
  - Sampling timesteps: More timesteps improve accuracy but reduce throughput; ODE solver helps balance this tradeoff
  - Scheduled sampling probability: Higher probability improves self-correction but may slow convergence

- Failure signatures:
  - Poor reasoning quality despite high throughput: Indicates the diffusion model cannot maintain coherence when generating multiple steps in parallel
  - Degraded performance with scheduled sampling: Suggests the model cannot effectively recover from its own errors
  - Inconsistent answers across different runs: May indicate insufficient diversity in the diffusion sampling process

- First 3 experiments:
  1. Compare DoT with standard autoregressive CoT on 4×4 multiplication to validate the 27× speedup claim while maintaining accuracy
  2. Test scheduled sampling ablation by training DoT with and without this mechanism on GSM8K to measure impact on self-correction
  3. Evaluate DoTMP vs DoT on complex GSM8K problems to quantify the benefit of causal bias in multi-step reasoning tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the reasoning capability of DoT scale with increasing model size compared to autoregressive models?
- Basis in paper: [explicit] The paper states that "Although it is challenging for current pre-trained diffusion language models to directly compete with LLMs that are hundreds of times larger in parameter size, our study emphasizes the possibility of their complex reasoning abilities."
- Why unresolved: The paper uses relatively small diffusion models (1.3B parameters) and notes the gap with larger autoregressive models, but does not explore scaling effects.
- What evidence would resolve it: Experiments comparing DoT performance across a range of model sizes, from small to large-scale diffusion models, against similarly sized autoregressive models.

### Open Question 2
- Question: Can DoT be effectively extended to multimodal reasoning tasks beyond text-based problems?
- Basis in paper: [inferred] The paper discusses text-based mathematical and logical reasoning tasks, but does not explore other modalities like visual or auditory reasoning.
- Why unresolved: The paper focuses on text generation and reasoning, leaving multimodal applications unexplored.
- What evidence would resolve it: Experiments applying DoT to multimodal datasets, such as visual question answering or audio-based reasoning tasks, and comparing performance to autoregressive models.

### Open Question 3
- Question: How does DoT perform on real-world, open-ended reasoning tasks compared to structured benchmark datasets?
- Basis in paper: [explicit] The paper evaluates DoT on structured tasks like digit multiplication, boolean logic, and grade school math, but does not test on open-ended, real-world reasoning problems.
- Why unresolved: The paper's focus on controlled datasets limits insights into DoT's applicability to unstructured, real-world scenarios.
- What evidence would resolve it: Testing DoT on real-world datasets or open-ended reasoning tasks, such as common sense reasoning or scientific problem-solving, and comparing results to autoregressive models.

## Limitations

- The efficiency gains are primarily demonstrated on simple tasks; more complex reasoning shows more modest improvements
- The model architecture details and specific hyperparameters are not fully specified, limiting reproducibility
- The approach requires significant engineering effort to adapt pre-trained diffusion models for reasoning tasks

## Confidence

- **High confidence**: DoT can achieve competitive accuracy on simple reasoning tasks with reduced inference time compared to autoregressive baselines
- **Medium confidence**: Scheduled sampling improves self-correction in diffusion models for reasoning tasks, though the magnitude of improvement varies by task complexity
- **Medium confidence**: DoTMP's causal bias provides marginal accuracy benefits for complex reasoning, with unclear efficiency implications
- **Low confidence**: Claims of superior efficiency scaling for very complex reasoning tasks are not fully substantiated in the current results

## Next Checks

1. **Architecture sensitivity analysis**: Test DoT performance across multiple diffusion model sizes (small to large) on GSM8K to determine if efficiency gains scale proportionally or if there's a crossover point where autoregressive models become more efficient for complex reasoning

2. **Scheduled sampling ablation study**: Systematically vary the scheduled sampling probability (0.0 to 1.0) on GSM8K and measure both self-correction ability (error recovery rate) and overall accuracy to identify the optimal tradeoff point

3. **Error propagation analysis**: Track error rates at each diffusion timestep across different reasoning task complexities to quantify how errors accumulate and whether the self-correction mechanism effectively mitigates this issue, particularly for DoTMP where causal bias may amplify early errors