---
ver: rpa2
title: Similarity-based Neighbor Selection for Graph LLMs
arxiv_id: '2402.03720'
source_url: https://arxiv.org/abs/2402.03720
tags:
- neighbor
- graph
- llms
- selection
- neighbors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses node classification on text-attributed graphs
  (TAGs), where nodes have textual attributes and graph structure. Current methods
  integrating LLMs with graph data underperform traditional GNNs due to over-squashing,
  heterophily, and ineffective neighbor selection.
---

# Similarity-based Neighbor Selection for Graph LLMs

## Quick Facts
- arXiv ID: 2402.03720
- Source URL: https://arxiv.org/abs/2402.03720
- Authors: Rui Li; Jiwei Li; Jiawei Han; Guoyin Wang
- Reference count: 32
- Primary result: SNS outperforms traditional GNNs and LLM-based methods on PubMed and Ogbn-arxiv datasets

## Executive Summary
This paper addresses node classification on text-attributed graphs (TAGs) where nodes have textual attributes and graph structure. Current methods integrating LLMs with graph data underperform traditional GNNs due to over-squashing, heterophily, and ineffective neighbor selection. The proposed Similarity-based Neighbor Selection (SNS) uses recursive neighbor selection to progressively find labeled neighbors and ranks them using SimCSE similarity to mitigate these issues. SNS achieves state-of-the-art results on PubMed and demonstrates superior generalization and scalability compared to both traditional GNN methods and existing LLM-based approaches.

## Method Summary
SNS is a zero-shot solution for node classification on text-attributed graphs that integrates LLMs with graph structure through similarity-based neighbor selection. The method recursively finds labeled neighbors for each node, then uses SimCSE to measure and rank similarity between text attributes of nodes and their neighbors. Only the top-ranking neighbors are selected and integrated into LLM prompts for inference. This selective approach addresses over-squashing by preventing information compression from excessive neighbors, handles heterophily by excluding dissimilar nodes, and leverages LLMs' pre-trained commonsense knowledge without requiring additional training.

## Key Results
- SNS achieves state-of-the-art accuracy on PubMed and Ogbn-arxiv datasets
- Outperforms traditional GNNs and existing LLM-based graph methods
- Demonstrates better scalability and generalization compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SNS outperforms traditional GNN methods by leveraging LLM's commonsense knowledge and reasoning capabilities through carefully crafted prompts that integrate graph structure information.
- Mechanism: SNS uses recursive neighbor selection to progressively find labeled neighbors and ranks them using SimCSE similarity to mitigate over-squashing and heterophily issues. This approach allows LLMs to leverage their extensive pre-trained knowledge base without requiring additional training.
- Core assumption: LLMs possess sufficient commonsense knowledge and reasoning capabilities to effectively utilize graph structure information when properly integrated through prompts.
- Evidence anchors:
  - [abstract] "their extensive commonsense knowledge and robust reasoning capabilities offer great promise for node classification in TAGs"
  - [section 1.2] "LLMs' potential in tackling reasoning-intensive tasks in a wide range of fields including language understanding, multi-hop reasoning, vision, and robotics"
  - [corpus] Weak evidence - the corpus papers focus on related graph-LLM integration but don't directly support the specific commonsense knowledge claim
- Break condition: If the LLM lacks sufficient domain-specific knowledge or the graph structure is too complex for the LLM to effectively reason about through prompts alone.

### Mechanism 2
- Claim: SNS addresses the over-squashing problem by selectively integrating only the most relevant neighbors based on similarity ranking, rather than including all available neighbors.
- Mechanism: SNS employs SimCSE to measure and rank the similarity between text attributes of nodes and their neighbors, then selects only the top-ranking neighbors for prompt integration. This selective approach prevents information compression that leads to over-squashing.
- Core assumption: Similarity-based ranking effectively identifies the most relevant neighbors for accurate node classification.
- Evidence anchors:
  - [section 2.2] "Over-squashing (Topping et al., 2021; Deac et al., 2022; Alon & Yahav, 2020) denotes the situation where the model fails to leverage all available information when excessive neighbor information is supplied"
  - [section 2.3.2] "We adopt SimCSE (Gao et al., 2021) as our similarity metric, calculating the cosine similarity between the text attribute of each node and that of its neighbors"
  - [corpus] Moderate evidence - the corpus contains papers on link prediction and knowledge distillation that support selective neighbor approaches
- Break condition: If the similarity metric fails to capture true relevance or if the LLM cannot effectively process the reduced set of neighbors.

### Mechanism 3
- Claim: SNS effectively handles heterophilous graphs by using similarity-based neighbor selection rather than random neighbor selection, which often includes dissimilar nodes.
- Mechanism: SNS uses SimCSE similarity scores to rank neighbors and exclude dissimilar nodes, addressing the challenge that attention mechanisms fundamentally rely on similarity (Vaswani et al., 2017).
- Core assumption: Heterophilous graphs contain enough similar nodes to enable accurate classification when properly selected.
- Evidence anchors:
  - [section 2.2] "Struggles with heterophilous graphs: Heterophily describes a situation where connected nodes in a graph are more likely to differ than resemble, a scenario contrasting with homophily"
  - [section 2.3.2] "it skillfully addresses heterophily by excluding dissimilar neighbors, as the similarity metric inherently selects nodes with analogous characteristics"
  - [corpus] Weak evidence - the corpus doesn't directly address heterophily challenges in graph-LLM integration
- Break condition: If the graph is predominantly heterophilous with insufficient similar nodes for accurate classification.

## Foundational Learning

- Concept: Text-attributed graphs (TAGs) - graphs where nodes have associated textual attributes
  - Why needed here: Understanding TAGs is fundamental to grasping the problem space SNS addresses
  - Quick check question: What distinguishes text-attributed graphs from standard graphs?

- Concept: Graph neural networks (GNNs) - neural networks designed to process graph-structured data
  - Why needed here: SNS is compared against traditional GNN methods, requiring understanding of GNN limitations
  - Quick check question: What are the main limitations of traditional GNNs that SNS aims to address?

- Concept: Zero-shot learning - model performance without task-specific training
  - Why needed here: SNS is described as a zero-shot solution, distinguishing it from traditional supervised methods
  - Quick check question: How does zero-shot learning differ from few-shot or supervised learning approaches?

## Architecture Onboarding

- Component map: Recursive neighbor selection -> SimCSE similarity ranking -> Prompt construction -> LLM inference
- Critical path: Recursive neighbor selection → Similarity ranking → Prompt integration → LLM inference
- Design tradeoffs: Selective neighbor integration improves quality but may miss some relevant information; zero-shot approach eliminates training but relies heavily on LLM capabilities
- Failure signatures: Poor performance on heterophilous graphs, failure to find sufficient labeled neighbors, LLM context limitations preventing neighbor inclusion
- First 3 experiments:
  1. Test SNS performance on a simple homophilous dataset to establish baseline effectiveness
  2. Compare SNS with random neighbor selection on a dataset with known heterophily to demonstrate superiority
  3. Evaluate SNS with different similarity metrics to optimize neighbor selection quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SNS performance scale with increasing graph size and node degree?
- Basis in paper: [inferred] The paper mentions SNS has better scalability than GNNs but doesn't provide detailed scaling analysis. The Ogbn-products dataset (25M nodes) was used with k=100 neighbors.
- Why unresolved: The paper only tests on five datasets and doesn't systematically explore performance across varying graph sizes or node degrees. The scalability claims need empirical validation across a broader range of graph sizes.
- What evidence would resolve it: Systematic experiments varying graph size from small (Cora-scale) to large (Ogbn-products-scale), measuring accuracy, inference time, and memory usage across different node degrees and graph densities.

### Open Question 2
- Question: How does SNS handle nodes with no labeled neighbors within the search radius?
- Basis in paper: [explicit] The paper mentions a failure rate in Cora (4.9% for SNS) when no labeled neighbors are found, but doesn't explore fallback strategies or performance degradation.
- Why unresolved: The paper reports failure rates but doesn't investigate how SNS performs on these nodes or what strategies could be employed when labeled neighbors are unavailable.
- What evidence would resolve it: Experiments isolating nodes with no labeled neighbors within γ hops, testing alternative strategies (e.g., using unlabeled neighbors, expanding search radius, or using zero-shot predictions), and measuring performance impact.

### Open Question 3
- Question: What is the impact of different similarity metrics beyond SimCSE for neighbor ranking?
- Basis in paper: [explicit] The paper states "We adopt SimCSE (Gao et al., 2021) as our similarity metric" but doesn't compare with alternatives or explore the sensitivity to similarity metric choice.
- Why unresolved: The paper commits to one similarity metric without ablation studies or comparison to alternatives like sentence transformers, SBERT, or domain-specific embeddings.
- What evidence would resolve it: Comparative experiments using different similarity metrics (sentence transformers, SBERT, custom embeddings), measuring top-k accuracy and final classification performance across datasets to determine if SimCSE is optimal.

## Limitations

- The core claim about leveraging LLM commonsense knowledge lacks systematic empirical validation beyond performance comparisons
- The method's effectiveness may be limited by LLM context windows, preventing inclusion of sufficient neighbors for some nodes
- SNS performance on nodes with no labeled neighbors within search radius is not well-characterized, with some nodes potentially failing classification

## Confidence

- **High confidence**: SNS demonstrates superior performance over traditional GNNs and existing LLM-based methods on benchmark datasets (PubMed, Ogbn-arxiv)
- **Medium confidence**: The mechanisms of over-squashing mitigation and heterophily handling through similarity-based neighbor selection are theoretically sound but lack ablation studies isolating each component's contribution
- **Low confidence**: The claim that SNS effectively leverages LLM commonsense knowledge and reasoning capabilities is largely assumed rather than empirically validated through systematic analysis

## Next Checks

1. **Ablation study on neighbor selection**: Compare SNS performance with random neighbor selection versus similarity-based selection on datasets with varying degrees of heterophily to isolate the contribution of the similarity ranking mechanism.

2. **LLM capability analysis**: Test SNS with smaller, less capable LLMs to determine the minimum model size required for effective performance, helping quantify the reliance on LLM commonsense knowledge.

3. **Cross-domain generalization**: Evaluate SNS on datasets from different domains (e.g., biomedical vs. academic citations) to assess whether performance depends on the LLM's pre-existing knowledge of the specific domain.