---
ver: rpa2
title: 'GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake News
  Detection'
arxiv_id: '2412.12164'
source_url: https://arxiv.org/abs/2412.12164
tags:
- news
- fake
- detection
- gamed
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GAMED, a novel approach for multimodal fake
  news detection that addresses the limitations of existing methods by focusing on
  modal decoupling and cross-modal synergies. GAMED employs a Mixture of Experts (MMoE-Pro)
  network with token attention and relaxed softmax constraints to refine features
  from text and images, followed by adaptive feature distribution adjustment using
  AdaIN.
---

# GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake News Detection

## Quick Facts
- arXiv ID: 2412.12164
- Source URL: https://arxiv.org/abs/2412.12164
- Reference count: 40
- Key outcome: GAMED achieves 93.93% accuracy on Fakeddit and 98.46% on Yang datasets, outperforming state-of-the-art baselines by up to 2.65%

## Executive Summary
GAMED addresses the limitations of existing multimodal fake news detection methods by introducing a novel approach that combines modal decoupling with cross-modal synergies. The framework employs a Mixture of Experts (MMoE-Pro) network with token attention and relaxed softmax constraints to refine text and image features separately. It then integrates semantic knowledge from pre-trained language models like ERNIE2.0 to enhance fact and relationship understanding. A novel veto voting mechanism dynamically manages contributions from different modalities, improving both transparency and explainability. Experimental results demonstrate that GAMED significantly outperforms state-of-the-art models on two major datasets, with accuracy gains of up to 2.65%.

## Method Summary
The GAMED framework introduces a three-stage approach to multimodal fake news detection. First, it employs an enhanced MMoE-Pro network that uses token attention mechanisms and relaxed softmax constraints to refine features from both text and images independently. Second, the model applies adaptive feature distribution adjustment using AdaIN to better align cross-modal representations. Third, it integrates semantic knowledge from pre-trained language models like ERNIE2.0 to improve understanding of facts and relationships within the content. The framework concludes with a veto voting mechanism that dynamically manages contributions from different modalities, allowing the model to make more informed decisions while maintaining interpretability.

## Key Results
- GAMED achieves 93.93% accuracy on the Fakeddit dataset, surpassing state-of-the-art baselines
- The model reaches 98.46% accuracy on the Yang dataset, demonstrating strong performance across different data sources
- Ablation studies confirm the effectiveness of each component, with semantic knowledge integration showing particularly significant impact

## Why This Works (Mechanism)
GAMED's effectiveness stems from its ability to decouple modal features while maintaining cross-modal synergies. The token attention mechanism in the MMoE-Pro network allows for more precise feature refinement by focusing on relevant tokens rather than treating all tokens equally. The relaxed softmax constraints enable more flexible decision boundaries, reducing the risk of overfitting to specific patterns. AdaIN-based adaptive feature distribution adjustment helps align representations from different modalities in a more meaningful way, addressing the challenge of heterogeneous feature spaces. The integration of semantic knowledge provides contextual understanding that goes beyond surface-level feature matching. Finally, the veto voting mechanism introduces a form of dynamic ensemble learning that can adapt to the strengths and weaknesses of different modalities in real-time.

## Foundational Learning
- **Mixture of Experts (MoE)**: Why needed - Enables specialized processing for different aspects of multimodal data; Quick check - Verify that expert networks learn distinct feature representations
- **Token Attention Mechanisms**: Why needed - Allows selective focus on relevant content tokens rather than treating all tokens equally; Quick check - Ensure attention weights correlate with content importance
- **Adaptive Instance Normalization (AdaIN)**: Why needed - Aligns feature distributions across modalities with different statistical properties; Quick check - Confirm feature distributions become more similar post-AdaIN
- **Veto Voting Mechanisms**: Why needed - Provides interpretability and handles conflicting modality signals; Quick check - Verify veto decisions align with human judgment of modality reliability
- **Cross-modal Feature Fusion**: Why needed - Combines complementary information from different modalities for better decision-making; Quick check - Measure information gain from fusion compared to individual modalities

## Architecture Onboarding

Component Map: Text/Image Input -> MMoE-Pro Network -> AdaIN Adjustment -> Semantic Knowledge Integration -> Veto Voting -> Classification Output

Critical Path: The most critical processing path involves the MMoE-Pro network's token attention mechanism, which directly influences the quality of features passed through the entire pipeline. This is followed by AdaIN adjustment and semantic knowledge integration, as these components significantly impact the final decision quality.

Design Tradeoffs: The framework trades computational complexity for improved accuracy and interpretability. The extensive use of pre-trained models and multiple attention mechanisms increases model size and inference time but provides better feature extraction and decision-making capabilities. The veto voting mechanism adds complexity but significantly improves explainability.

Failure Signatures: The model may struggle with cross-lingual content due to its reliance on English-specific pre-trained language models. It might also face challenges with multimodal content where one modality is significantly degraded or missing. The veto mechanism could potentially lead to overly conservative decisions in cases where both modalities provide weak but consistent signals.

First Experiments:
1. Test individual modality performance to establish baseline contributions
2. Evaluate MMoE-Pro network performance with and without token attention
3. Measure impact of semantic knowledge integration by comparing with and without ERNIE2.0 features

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided content.

## Limitations
- Reliance on pre-trained English language models may limit generalizability to other languages or domains
- Computational overhead from multiple attention mechanisms and pre-trained models may hinder real-time deployment
- Veto voting mechanism complexity may not generalize well to datasets with different fake news generation patterns

## Confidence
High confidence in accuracy improvements and the effectiveness of MMoE-Pro network and AdaIN refinement. Medium confidence in the veto voting mechanism's contribution to explainability, as interpretability results are primarily qualitative. Low confidence regarding cross-dataset generalization and performance on non-English content due to limited testing scope.

## Next Checks
1. Test GAMED on multilingual fake news datasets to assess language generalization capabilities
2. Conduct ablation studies on veto voting mechanism with varying threshold parameters to quantify performance and interpretability impacts
3. Evaluate computational efficiency and inference time compared to baseline models for practical deployment assessment