---
ver: rpa2
title: 'Friends Across Time: Multi-Scale Action Segmentation Transformer for Surgical
  Phase Recognition'
arxiv_id: '2401.11644'
source_url: https://arxiv.org/abs/2401.11644
tags:
- surgical
- recognition
- phase
- temporal
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses automatic surgical phase recognition, which
  is critical for both online surgical video assessment in operating rooms and offline
  surgical video analysis for training and standardization. The authors propose a
  Multi-Scale Action Segmentation Transformer (MS-AST) for offline surgical phase
  recognition and a Multi-Scale Action Segmentation Causal Transformer (MS-ASCT) for
  online recognition.
---

# Friends Across Time: Multi-Scale Action Segmentation Transformer for Surgical Phase Recognition

## Quick Facts
- arXiv ID: 2401.11644
- Source URL: https://arxiv.org/abs/2401.11644
- Reference count: 34
- Primary result: Proposes MS-AST and MS-ASCT for surgical phase recognition, achieving 96.15% offline and 95.26% online accuracy on Cholec80

## Executive Summary
This paper addresses the challenge of automatic surgical phase recognition, proposing a Multi-Scale Action Segmentation Transformer (MS-AST) for offline and a Multi-Scale Action Segmentation Causal Transformer (MS-ASCT) for online surgical video analysis. The authors introduce a novel architecture that uses multi-scale temporal self-attention and cross-attention layers with different kernel sizes to capture both fast and slow actions in surgical videos. The methods achieve state-of-the-art performance on the Cholec80 dataset, with 96.15% accuracy for offline recognition and 95.26% for online recognition, while also demonstrating superior performance on non-medical action segmentation datasets.

## Method Summary
The method employs a two-stage approach: first extracting spatial features using ResNet50 or EfficientNetV2-M, then processing these features through a transformer-based architecture with multi-scale temporal self-attention and cross-attention layers. The MS-AST uses three different kernel sizes (3, 5, 17) in dilated convolutions to capture temporal relationships at multiple scales simultaneously. For online recognition, MS-ASCT modifies MS-AST by incorporating causality through causal dilated convolutions, removing layer normalization to prevent future information leaks, and implementing causal sliding window attention that only uses past information.

## Key Results
- MS-AST achieves 96.15% accuracy on Cholec80 for offline surgical phase recognition
- MS-ASCT achieves 95.26% accuracy on Cholec80 for online surgical phase recognition
- MS-AST outperforms existing methods on non-medical datasets (50Salads and GTEA)
- The multi-scale attention design effectively handles both short surgical phases (P3, P7) and longer phases

## Why This Works (Mechanism)

### Mechanism 1
Multi-scale temporal self-attention and cross-attention layers capture both fast and slow actions using different temporal kernel sizes (3, 5, 17). The design allows the model to attend to temporal relationships at multiple scales simultaneously, addressing the challenge that different surgical phases have inherently different temporal scales.

### Mechanism 2
The causal variant MS-ASCT enables online surgical phase recognition by preventing information leakage from future frames. It modifies MS-AST by using causal dilated convolutions, removing layer normalization, and implementing causal sliding window attention that only uses past information.

### Mechanism 3
Multi-scale attention weights (w1,i, w2,i, w3,i) are learned parameters that optimize the contribution of each temporal scale to the final feature representation. These weights determine how much each temporal scale contributes to the final output for each encoder or decoder block, allowing the model to adapt to specific surgical phase contexts.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: The entire MS-AST and MS-ASCT models are built upon transformer blocks with modified attention layers
  - Quick check question: What is the difference between self-attention and cross-attention in transformer architectures?

- Concept: Temporal modeling in video analysis
  - Why needed here: The paper focuses on capturing temporal relationships at different scales in surgical videos
  - Quick check question: How does dilated convolution help in expanding the receptive field without increasing computational cost?

- Concept: Causal vs non-causal processing
  - Why needed here: The distinction between online (causal) and offline (non-causal) surgical phase recognition is central to the paper's contribution
  - Quick check question: What are the key architectural changes required to convert a non-causal transformer to a causal one?

## Architecture Onboarding

- Component map:
  - Feature extraction backbone (ResNet50 or EfficientNetV2-M) → Frame-level spatial features
  - Multi-scale temporal self-attention layers (encoder) → Frame-level temporal relationships
  - Multi-scale temporal cross-attention layers (decoder) → Segment-level temporal relationships
  - Causal modifications (MS-ASCT only) → Online processing capability

- Critical path: Feature extraction → Multi-scale temporal modeling → Surgical phase classification

- Design tradeoffs:
  - Memory vs accuracy: Using multi-scale attention increases memory usage but improves accuracy
  - Online vs offline: Causal modifications enable online use but may slightly reduce accuracy compared to offline versions
  - Model complexity vs generalization: More complex multi-scale designs may overfit to specific datasets

- Failure signatures:
  - Over-segmentation errors indicate the model is too sensitive to temporal changes
  - Confusion between similar surgical phases suggests insufficient feature discrimination
  - Poor online performance compared to offline indicates causality constraints are too limiting

- First 3 experiments:
  1. Implement single-scale baseline (kernel size 3 only) and compare with multi-scale version to validate the multi-scale benefit
  2. Test causal vs non-causal versions on the same dataset to quantify the online/offline accuracy tradeoff
  3. Vary the number of temporal scales (2 vs 3 vs 4) to find the optimal configuration for the Cholec80 dataset

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas remain unexplored based on the limitations section.

## Limitations

- Limited ablation studies on temporal scales prevent understanding the marginal benefit of each scale
- Computational latency implications of causal attention for real-time OR deployment are not discussed
- Limited performance evaluation on non-medical datasets reduces confidence in broader applicability

## Confidence

- Multi-scale attention mechanism: Medium - Strong empirical results but lacks ablation studies isolating each scale's contribution
- Online recognition capability: Medium - Achieves good accuracy but doesn't discuss computational latency requirements
- Broader applicability claim: Low - Limited detailed performance metrics on non-medical datasets

## Next Checks

1. Implement and compare single-scale, two-scale, and three-scale versions of MS-AST on Cholec80 to quantify the marginal benefit of each additional scale.

2. Measure inference time and latency for MS-ASCT in an online setting to verify it meets practical OR requirements (typically sub-second response times).

3. Apply the pre-trained MS-AST model to a different surgical procedure dataset (e.g., M2CAI) without fine-tuning to assess true domain generalization capabilities.