---
ver: rpa2
title: A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic
  Data only
arxiv_id: '2402.05593'
source_url: https://arxiv.org/abs/2402.05593
tags:
- statues
- data
- reconstruction
- only
- sketch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for reconstructing 3D models of destroyed
  stucco statues from historic sketches (sinopia) using synthetic data only. The approach
  involves training an encoder-decoder network on synthetic renderings of 3D statue
  models to predict color images, depth maps, surface normals, and object masks from
  input sketches.
---

# A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only

## Quick Facts
- arXiv ID: 2402.05593
- Source URL: https://arxiv.org/abs/2402.05593
- Reference count: 8
- Primary result: 3D models of destroyed stucco statues can be reconstructed from historic sketches using synthetic training data only

## Executive Summary
This paper proposes a method for reconstructing 3D models of destroyed stucco statues from historic sketches (sinopia) using synthetic data only. The approach involves training an encoder-decoder network on synthetic renderings of 3D statue models to predict color images, depth maps, surface normals, and object masks from input sketches. The network is trained to generalize to unseen statue shapes using a combination of reconstruction losses and a gradient reversal layer to discourage memorization of specific training examples. Preliminary results demonstrate the feasibility of the approach, with the network successfully reconstructing plausible geometry and appearance from restored sinopia sketches of historical statues.

## Method Summary
The method trains an encoder-decoder network on synthetic 3D statue renderings to predict RGB, depth, normals, and masks from sketch inputs. The network uses a gradient reversal layer to encourage generalization across different statue shapes. Image-to-image translation techniques are applied to convert real sinopia sketches into a domain more similar to the synthetic training data. The trained network then generates plausible 3D reconstructions including color, geometry, and surface properties from the translated sketches.

## Key Results
- Successfully reconstructs plausible geometry and appearance from restored sinopia sketches
- Demonstrates the feasibility of using synthetic data only for training statue reconstruction networks
- Shows the approach can generate useful starting points for manual statue reconstruction by experts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Encoder-decoder architecture with gradient reversal layer enables synthetic-to-real sketch translation by learning domain-invariant features.
- Mechanism: The network is trained to map synthetic statue renderings to line drawings, then reverse the mapping for real sketches. The gradient reversal layer during training discourages the encoder from memorizing specific statue identities, forcing it to learn generalizable features that work across domains.
- Core assumption: The synthetic and real sketches share sufficient geometric structure that domain-invariant features can be learned.
- Evidence anchors:
  - [abstract] "Our proposed solution allows real-time reconstruction on-site, for instance, within an exhibition, or to generate a useful starting point for an expert, trying to manually reconstruct the statue, all while using only synthetic data for training."
  - [section] "We choose to build an encoder-decoder architecture, but add an adversarial component via an additional classification output in the decoder, together with a gradient reversal layer. This technique, as shown in [GL15] [ZKI19], discourages the encoder to distinguish between different inputs (e.g. different statues), regularizing the weights and increasing generalization between different figurines."
- Break condition: If the geometric structure of synthetic and real sketches diverges significantly, the learned features may not generalize, causing poor reconstruction quality.

### Mechanism 2
- Claim: Multi-task learning (RGB, depth, normals, mask prediction) stabilizes training and provides complementary geometric information.
- Mechanism: By predicting multiple output modalities simultaneously, the network receives diverse supervision signals that constrain the latent space representation and improve geometric understanding.
- Core assumption: The multiple output tasks are sufficiently correlated that learning them jointly improves performance compared to learning each task separately.
- Evidence anchors:
  - [abstract] "introducing multiple criterions stabilizes training, while also introducing additional queues to the network without requiring additional inputs at inference time"
  - [section] "We extend the capabilities of our network by, additionally to a one-hot image mask separating the figurine from the background, and a depth map, predicting surface normals, as well as an RGB reconstruction"
- Break condition: If the tasks conflict or the network cannot effectively share representations across them, performance may degrade compared to single-task training.

### Mechanism 3
- Claim: Image-to-image translation using learned style transfer bridges the domain gap between synthetic renderings and historic sketches.
- Mechanism: Instead of fixed edge detection filters, a learned non-linear function transforms synthetic renderings into line drawings that more closely resemble the target domain of historic sketches.
- Core assumption: The learned style transfer can effectively map the geometric structure of synthetic renderings to the appearance of historic sketches without losing essential shape information.
- Evidence anchors:
  - [section] "Using a learned non-linear function greatly increases the expressiveness of our intermediary sketch domain, while preventing a linear 1-to-1 mapping given the right loss function. We rely on the very recent [CDI22] for our sketch generation, which explicitly tackles the encoding of 3d shape via a geometric loss function."
- Break condition: If the style transfer fails to preserve geometric structure or introduces artifacts that confuse the subsequent reconstruction network, the overall pipeline will fail.

## Foundational Learning

- Concept: Domain adaptation and transfer learning
  - Why needed here: The method trains on synthetic data but must work on real historic sketches with different appearance characteristics.
  - Quick check question: What is the key difference between domain adaptation and standard supervised learning?

- Concept: Encoder-decoder architectures and latent space representations
  - Why needed here: The network must compress complex 3D statue information into a compact representation that can be decoded into multiple output modalities.
  - Quick check question: How does the dimensionality of the latent space affect the network's ability to reconstruct detailed geometry?

- Concept: Multi-task learning and shared representations
  - Why needed here: The network simultaneously predicts RGB, depth, normals, and masks, requiring it to learn a unified geometric understanding.
  - Quick check question: What are the benefits and potential drawbacks of sharing early network layers across multiple prediction tasks?

## Architecture Onboarding

- Component map: Sketch -> Image-to-image translation (style transfer) -> Encoder (residual CNN) -> Latent space (2050 dimensions) -> Decoder heads (RGB, depth, normals, mask, classifier) -> Outputs
- Critical path: Sketch -> Style transfer -> Encoder -> Decoder heads -> Output predictions
- Design tradeoffs: Using synthetic data avoids the need for real training examples but requires effective domain adaptation; multi-task learning provides complementary supervision but may introduce task interference.
- Failure signatures: Poor reconstruction quality on real sketches (domain gap too large), mode collapse in style transfer, decoder heads producing inconsistent outputs.
- First 3 experiments:
  1. Train encoder-decoder on synthetic data only (no style transfer) and evaluate reconstruction quality on synthetic test set to establish baseline performance.
  2. Add image-to-image translation step and evaluate whether it improves reconstruction on real sketches while maintaining performance on synthetic data.
  3. Test different combinations of output modalities (e.g., depth+normals only vs. all four outputs) to determine which tasks are most critical for successful reconstruction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well does the approach generalize to statues from different time periods or cultures beyond ancient Greece, Rome, and the Middle Ages?
- Basis in paper: [explicit] The authors mention that their approach could be applied to "other historic drawings, found at other locations" but note that focusing on statues with similar appearance to the target domain may improve results.
- Why unresolved: The current study only tests on statues from a limited set of time periods and cultures. It's unclear how well the approach would work on statues from vastly different artistic traditions or eras.
- What evidence would resolve it: Testing the approach on a diverse dataset of statues from various time periods and cultures, and evaluating the quality of the reconstructions.

### Open Question 2
- Question: What is the optimal architecture and training strategy for the encoder-decoder network to achieve the best balance between reconstruction quality and generalization to unseen statues?
- Basis in paper: [explicit] The authors discuss their choice of an encoder-decoder architecture with a gradient reversal layer and dropout, but note that they experimented with different loss terms and scaling. They also mention that the network tends to transfer details from the training set to unseen samples.
- Why unresolved: The current study presents a preliminary architecture and training strategy, but does not exhaustively explore different design choices or optimize the network's performance.
- What evidence would resolve it: A comprehensive ablation study comparing different architectures, loss functions, and training strategies, and identifying the combination that yields the best results on a diverse test set.

### Open Question 3
- Question: How can the approach be extended to handle more complex sketches with greater detail, such as those found in clothing or intricate patterns?
- Basis in paper: [explicit] The authors note that their preliminary results on real sinopia sketches show "a lack of detail such as found in the clothing."
- Why unresolved: The current approach seems to struggle with reconstructing fine details from the sketches, which may limit its applicability to more complex or detailed artwork.
- What evidence would resolve it: Developing and testing techniques to enhance the network's ability to capture and reconstruct fine details from the input sketches, such as using multi-scale feature extraction or incorporating additional prior knowledge about common patterns in historic artwork.

## Limitations
- The effectiveness of the style transfer from real sketches to synthetic domain and back is not thoroughly validated
- The network architecture details and training hyperparameters are not fully specified
- The evaluation is limited to qualitative assessment of reconstruction quality rather than quantitative metrics

## Confidence
- **High confidence**: The fundamental approach of using synthetic data for training with domain adaptation techniques is sound and well-established in computer vision literature.
- **Medium confidence**: The multi-task learning framework with gradient reversal layer for regularization should work as described, but optimal implementation details are uncertain.
- **Low confidence**: The effectiveness of the style transfer from real sketches to synthetic domain and back is not thoroughly validated, representing a critical weak point.

## Next Checks
1. Implement the full pipeline on a small-scale dataset (e.g., 10-20 statues) and quantitatively measure reconstruction quality on held-out synthetic test data to establish baseline performance before testing on real sketches.
2. Systematically evaluate the impact of different loss function weightings and latent space dimensions on reconstruction quality through ablation studies.
3. Conduct a user study with art historians to assess whether the reconstructed models capture historically plausible details and stylistic features of the original statues, beyond mere geometric accuracy.