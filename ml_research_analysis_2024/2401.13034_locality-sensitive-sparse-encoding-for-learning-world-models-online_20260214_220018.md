---
ver: rpa2
title: Locality Sensitive Sparse Encoding for Learning World Models Online
arxiv_id: '2401.13034'
source_url: https://arxiv.org/abs/2401.13034
tags:
- learning
- online
- indices
- world
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of learning accurate world models
  online for model-based reinforcement learning, particularly under data nonstationarity
  which causes catastrophic forgetting in neural networks. The authors propose a locality
  sensitive sparse encoding (Losse) that enables efficient Follow-The-Leader (FTL)
  updates with linear regression on sparse random features.
---

# Locality Sensitive Sparse Encoding for Learning World Models Online

## Quick Facts
- arXiv ID: 2401.13034
- Source URL: https://arxiv.org/abs/2401.13034
- Authors: Zichen Liu; Chao Du; Wee Sun Lee; Min Lin
- Reference count: 40
- Primary result: Losse achieves FTL updates without catastrophic forgetting by using sparse random features with soft binning

## Executive Summary
This paper addresses the challenge of learning accurate world models online for model-based reinforcement learning under data nonstationarity. The authors propose a locality sensitive sparse encoding (Losse) that enables efficient Follow-The-Leader (FTL) updates using linear regression on sparse random features. By combining random projections with soft binning, Losse creates high-dimensional sparse features that allow closed-form incremental updates without retraining on all past data. Experimental results demonstrate that their approach outperforms neural network baselines in both supervised learning with covariate shift and model-based RL, showing strong resistance to forgetting while maintaining competitive performance.

## Method Summary
The method uses locality sensitive sparse encoding to create high-dimensional sparse features from input data through random projections and soft binning. These features are then used with linear regression models that support incremental closed-form updates via Sherman-Morrison formula. The approach maintains two memory matrices (At and Bt) that are updated incrementally at each time step using the sparse feature representation. This enables Follow-The-Leader updates without catastrophic forgetting while requiring only a single pass through trajectory data. The soft binning operation preserves discriminative information better than hard binning while maintaining sparsity guarantees.

## Key Results
- Losse-based world models outperform neural network baselines in both supervised learning with covariate shift and model-based RL environments
- The method achieves competitive or superior performance while requiring only a single pass through trajectory data
- Strong resistance to catastrophic forgetting compared to neural networks, particularly in environments with dramatic policy-induced state visitation changes
- Efficient incremental updates with computational cost proportional to feature sparsity rather than full feature dimension

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Locality sensitive sparse encoding enables efficient online FTL updates without catastrophic forgetting
- Mechanism: The sparse encoding creates high-dimensional features where only a small subset of weights need updating per sample, allowing closed-form incremental updates using Sherman-Morrison formula
- Core assumption: The sparsity of Losse features guarantees computational efficiency proportional to the number of non-zero entries rather than the full feature dimension
- Evidence anchors:
  - [abstract]: "We introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features"
  - [section]: "The incremental updates ϕ(xt)ϕ(xt)⊤ and ϕ(xt)y⊤t are highly sparse by Losse, so that we can efficiently update a small subset of weights"
  - [corpus]: Weak evidence - corpus mentions locality but not the specific sparse encoding mechanism
- Break condition: When feature sparsity drops below the threshold needed to maintain constant-time updates per sample

### Mechanism 2
- Claim: Linear models on random features achieve FTL without retraining on all past data
- Mechanism: The quadratic loss function of linear models on random features allows closed-form solutions that can be updated incrementally using accumulated memory matrices At and Bt
- Core assumption: The hypothesis class H of linear models on random features is rich enough to approximate complex dynamics while maintaining computational tractability
- Evidence anchors:
  - [abstract]: "our world model is a linear regression model supported by nonlinear random features"
  - [section]: "The loss function of such models is quadratic with respect to the parameters, satisfying the online learning requirement"
  - [corpus]: Weak evidence - corpus doesn't directly support this specific mechanism
- Break condition: When the random features become insufficient to represent the underlying dynamics, requiring more complex models

### Mechanism 3
- Claim: Soft binning in Losse provides better generalization than hard binning while maintaining sparsity
- Mechanism: Soft binning computes distances to neighboring bin edges as real-valued weights rather than binary indicators, preserving more information about feature values
- Core assumption: The soft binning operation b : Rd → RD preserves enough discriminative information while maintaining the sparsity guarantee
- Evidence anchors:
  - [section]: "Compared to naive binning which produces binary one-hot vectors and loses precision, ours has greater discriminative power by generating multi-hot real-valued representations"
  - [abstract]: "Our encoder generates high-dimensional sparse features with random projection and soft binning"
  - [corpus]: Weak evidence - corpus doesn't discuss soft binning specifically
- Break condition: When the number of bins becomes too small to provide meaningful soft assignments

## Foundational Learning

- Concept: Follow-The-Leader (FTL) online learning
  - Why needed here: FTL provides the theoretical foundation for incremental model updates without catastrophic forgetting
  - Quick check question: What is the regret bound for FTL in online linear regression with quadratic loss?

- Concept: Johnson-Lindenstrauss lemma and random projections
  - Why needed here: Random projections allow dimensionality reduction while approximately preserving distances in the original space
  - Quick check question: How does the Johnson-Lindenstrauss lemma guarantee that random projections approximately preserve distances?

- Concept: Sherman-Morrison formula for incremental matrix inversion
  - Why needed here: This formula enables efficient updates of the inverse matrix without full recomputation
  - Quick check question: What is the computational complexity of updating a matrix inverse using Sherman-Morrison compared to full recomputation?

## Architecture Onboarding

- Component map: Input -> Random projection (σ) -> Soft binning (b) -> Sparse feature vector (ϕ) -> Linear regression weights (W) -> Output prediction
- Critical path: Feature extraction (σ+b) -> Memory matrix updates (At, Bt) -> Weight updates (W) -> Prediction
- Design tradeoffs: Higher dimensionality vs. sparsity level vs. representational capacity vs. computational efficiency
- Failure signatures: Increasing prediction error over time indicates feature sparsity is insufficient; stable but high error indicates insufficient representational capacity
- First 3 experiments:
  1. Implement Losse encoder with fixed parameters and verify sparsity guarantee on synthetic data
  2. Test incremental weight updates on a simple linear regression problem and compare to full recomputation
  3. Evaluate representation power by comparing Losse to other random feature encodings on a simple denoising task

## Open Questions the Paper Calls Out
None

## Limitations
- Dependence on maintaining feature sparsity for computational efficiency
- Potential sensitivity to hyperparameter choices (number of features, bins, bin dimension)
- Assumption that linear models on random features are sufficiently expressive for complex dynamics

## Confidence
- Sparse encoding enabling efficient incremental updates: High confidence
- Achieving FTL without catastrophic forgetting: Medium confidence
- Soft binning advantage over hard binning: Low confidence

## Next Checks
1. **Sparsity Guarantee Verification**: Implement the Losse encoder and systematically measure the actual sparsity of generated features across different input distributions and parameter settings to confirm the claimed computational efficiency.

2. **Robustness to Hyperparameters**: Conduct a sensitivity analysis varying the number of random features, bin counts, and bin dimensions to identify regimes where performance degrades or sparsity guarantees fail.

3. **Catastrophic Forgetting Benchmark**: Design a controlled experiment with clear nonstationary data shifts (e.g., sudden concept drift) to quantitatively compare forgetting rates between Losse-based models and neural network baselines under identical conditions.