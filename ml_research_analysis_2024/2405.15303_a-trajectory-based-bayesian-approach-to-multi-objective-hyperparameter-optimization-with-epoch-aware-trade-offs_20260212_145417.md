---
ver: rpa2
title: A Trajectory-Based Bayesian Approach to Multi-Objective Hyperparameter Optimization
  with Epoch-Aware Trade-Offs
arxiv_id: '2405.15303'
source_url: https://arxiv.org/abs/2405.15303
tags:
- training
- tmobo
- hyperparameter
- optimization
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a trajectory-based multi-objective Bayesian
  optimization (TMOBO) method for hyperparameter optimization (HPO) that treats training
  epochs as a decision variable. The key innovation is capturing trade-offs across
  the entire training trajectory, not just at full convergence, by incorporating epoch-wise
  model performance into a novel trajectory-based acquisition function (TEHVI) and
  an early stopping mechanism.
---

# A Trajectory-Based Bayesian Approach to Multi-Objective Hyperparameter Optimization with Epoch-Aware Trade-Offs

## Quick Facts
- arXiv ID: 2405.15303
- Source URL: https://arxiv.org/abs/2405.15303
- Reference count: 40
- This paper introduces TMOBO, a trajectory-based multi-objective Bayesian optimization method that treats training epochs as a decision variable, achieving better Pareto-optimal trade-offs with lower computational cost than state-of-the-art methods.

## Executive Summary
This paper introduces TMOBO, a trajectory-based multi-objective Bayesian optimization method for hyperparameter optimization that treats training epochs as a decision variable. The key innovation is capturing trade-offs across the entire training trajectory, not just at full convergence, by incorporating epoch-wise model performance into a novel trajectory-based acquisition function (TEHVI) and an early stopping mechanism. Experiments on synthetic benchmarks and real-world HPO tasks demonstrate that TMOBO consistently identifies better Pareto-optimal trade-offs with lower hypervolume differences than state-of-the-art multi-objective BO methods, while reducing computational cost through efficient early stopping.

## Method Summary
TMOBO extends standard multi-objective Bayesian optimization by treating the number of training epochs as a decision variable alongside hyperparameters. The method uses Gaussian Process surrogate models to predict training trajectories and employs a trajectory-based acquisition function (TEHVI) that evaluates entire training trajectories rather than just final converged values. An epoch-wise early stopping mechanism uses GP-based trajectory predictions to terminate training when future model performances are unlikely to improve the current Pareto front. The approach is implemented using BoTorch and GPyTorch, with synthetic benchmarks (ZDT/DTLZ variants with epoch-dependent objectives) and real-world HPO tasks from LCBench (MLP models on tabular datasets) and a CNN task (MobileNetV2 on CIFAR-10).

## Key Results
- TMOBO consistently identifies better Pareto-optimal trade-offs with lower hypervolume differences than state-of-the-art multi-objective BO methods
- The method reduces computational cost through efficient early stopping while maintaining or improving Pareto front quality
- TMOBO is particularly effective in avoiding overfitting and optimizing for scenarios requiring rapid model retraining
- Performance validated across synthetic benchmarks and real-world HPO tasks including MLP and CNN models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TMOBO improves Pareto-optimal trade-off discovery by incorporating epoch-wise trajectory information, not just final converged values.
- Mechanism: The trajectory-based acquisition function (TEHVI) evaluates entire training trajectories of hyperparameter settings, treating the number of epochs as a decision variable, thereby identifying trade-offs that emerge during training (e.g., due to overfitting).
- Core assumption: Training trajectories contain meaningful trade-off information that is missed when only considering fully trained model performance.
- Evidence anchors:
  - [abstract]: "This paper introduces a trajectory-based multi-objective Bayesian optimization (TMOBO) method for hyperparameter optimization (HPO) that treats training epochs as a decision variable. The key innovation is capturing trade-offs across the entire training trajectory, not just at full convergence."
  - [section]: "We propose an enhanced multi-objective hyperparameter optimization problem that treats the number of training epochs as a decision variable, rather than merely an auxiliary parameter, to account for trade-offs at an earlier training stage."
- Break condition: If training trajectories are smooth and monotonic, the benefit of trajectory-based evaluation diminishes.

### Mechanism 2
- Claim: TMOBO reduces computational cost through epoch-efficient early stopping while maintaining or improving Pareto front quality.
- Mechanism: The multi-objective early stopping mechanism uses GP-based trajectory predictions to conservatively terminate training when future model performances are unlikely to improve the current Pareto front.
- Core assumption: Predictive uncertainty from GP models can reliably estimate when a trajectory segment will not contribute to the Pareto front.
- Evidence anchors:
  - [abstract]: "Experiments on synthetic benchmarks and real-world HPO tasks demonstrate that TMOBO consistently identifies better Pareto-optimal trade-offs with lower hypervolume (HV) differences than state-of-the-art multi-objective BO methods, while reducing computational cost through efficient early stopping."
  - [section]: "The proposed early stopping mechanism additionally ensures that the iterative learning continues until sufficient trade-offs along the trajectory have been collected."
- Break condition: If GP predictions are unreliable due to high noise or insufficient data, early stopping may terminate training prematurely.

### Mechanism 3
- Claim: Treating training epochs as a decision variable in EMOHPO expands the search space beyond what multi-fidelity methods can explore.
- Mechanism: By optimizing over (x, t) pairs where t ∈ T (not just t = tmax), TMOBO captures Pareto-optimal trade-offs that may occur at intermediate epochs, such as avoiding overfitting.
- Core assumption: Trade-offs between objectives can emerge at epochs earlier than the maximum allowed training time.
- Evidence anchors:
  - [section]: "EMOHPO broadens the search domain from X × {tmax} in multi-fidelity MOHPO to X × T and thus accounts for all observations on the trajectories."
  - [section]: "This broader perspective enables more efficient decision-making in hyperparameter tuning, particularly for scenarios requiring model retraining."
- Break condition: If the optimal model performance always occurs at the maximum number of epochs, the benefit of treating epochs as a decision variable is minimal.

## Foundational Learning

- Concept: Gaussian Process (GP) regression and acquisition functions
  - Why needed here: GPs model the relationship between hyperparameter settings, epochs, and model performance, providing uncertainty estimates used in the TEHVI acquisition function and early stopping criterion.
  - Quick check question: How does a GP model the predictive mean and uncertainty for a new (hyperparameter, epoch) pair based on observed data?

- Concept: Pareto optimality and hypervolume (HV) metrics
  - Why needed here: These concepts define what constitutes a good Pareto front and provide the objective metric (HV difference) for comparing TMOBO against other methods.
  - Quick check question: What is the difference between a Pareto-optimal solution and a non-dominated solution in the context of multi-objective optimization?

- Concept: Bayesian Optimization (BO) framework
  - Why needed here: TMOBO extends the BO framework by modifying the acquisition function to consider trajectories rather than single points, and by incorporating early stopping.
  - Quick check question: How does the standard Expected Improvement (EI) acquisition function differ from the trajectory-based TEHVI in TMOBO?

## Architecture Onboarding

- Component map:
  - GP surrogate models (one per objective) -> Trajectory-based acquisition function (TEHVI) -> Multi-objective early stopping mechanism -> Data augmentation strategy for GP training -> Candidate search strategy for hyperparameter sampling

- Critical path:
  1. Initialize GP models with Sobol sequence samples
  2. Fit GP models to observed data
  3. Generate candidates using trajectory-based acquisition
  4. Select best candidate and begin training
  5. Epoch-wise update GP predictions and check early stopping
  6. Augment data and repeat

- Design tradeoffs:
  - Trade-off between exploration and exploitation controlled by candidate search radius
  - Computational cost of TEHVI approximation vs. accuracy of trajectory evaluation
  - Data augmentation size vs. GP model training efficiency
  - Early stopping confidence parameter (β) vs. premature termination risk

- Failure signatures:
  - Poor convergence: GP predictions are inaccurate, leading to suboptimal candidate selection
  - High computational cost: Early stopping parameter too conservative, causing unnecessary training
  - Degraded Pareto front: Candidate search radius too small, limiting exploration of hyperparameter space

- First 3 experiments:
  1. Verify GP trajectory prediction accuracy on a synthetic problem with known learning curves
  2. Test TEHVI acquisition function against standard EHVI on a simple benchmark
  3. Validate early stopping mechanism by comparing training epochs with and without early stopping on a real HPO task

## Open Questions the Paper Calls Out
The paper mentions limitations including: (1) only testing up to 3 objectives, (2) not addressing categorical hyperparameters, and (3) lacking formal convergence guarantees for the full TMOBO algorithm.

## Limitations
- TMOBO's effectiveness depends on the assumption that meaningful trade-offs exist at intermediate epochs, which may not hold for all learning problems
- The early stopping mechanism could terminate training prematurely if GP predictions are inaccurate, particularly in high-noise scenarios
- The specific implementation details of TEHVI approximation and candidate search strategy are not fully specified, affecting reproducibility

## Confidence
- High confidence: The general framework of treating epochs as decision variables and using trajectory-based BO is well-founded
- Medium confidence: The specific TEHVI approximation method and its computational efficiency claims
- Medium confidence: The early stopping mechanism's reliability across different problem domains

## Next Checks
1. Implement a simplified version of TEHVI with grid-based candidate search to verify the core trajectory-based optimization concept
2. Test TMOBO on problems with known epoch-dependent trade-offs to validate the early stopping mechanism
3. Compare GP prediction accuracy on learning trajectories with varying noise levels to assess robustness