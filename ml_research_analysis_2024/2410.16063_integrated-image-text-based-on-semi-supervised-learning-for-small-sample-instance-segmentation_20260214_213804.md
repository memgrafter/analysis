---
ver: rpa2
title: Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance
  Segmentation
arxiv_id: '2410.16063'
source_url: https://arxiv.org/abs/2410.16063
tags:
- training
- data
- segmentation
- instance
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses small sample instance segmentation by proposing
  a method that integrates image and text features for classification and uses semi-supervised
  learning with pseudo labels to improve mask accuracy. The method consists of two
  modules: a semantic branch that combines visual and semantic information to enhance
  classification, and a two-stage training strategy that utilizes unlabeled data through
  pseudo labeling.'
---

# Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation

## Quick Facts
- arXiv ID: 2410.16063
- Source URL: https://arxiv.org/abs/2410.16063
- Authors: Ruting Chi; Zhiyi Huang; Yuexing Han
- Reference count: 40
- Key outcome: A two-module method (Semantic Branch + Two-stage Training) that integrates image-text features and pseudo-labels to improve small sample instance segmentation performance across three datasets

## Executive Summary
This paper addresses the challenge of instance segmentation when only limited labeled data is available. The authors propose SemInst, a method that combines image and text features for improved classification and employs semi-supervised learning with pseudo labels to enhance mask accuracy. The approach consists of a semantic branch that integrates visual and semantic information, and a two-stage training strategy that leverages unlabeled data through pseudo labeling. Experiments on three diverse datasets demonstrate competitive performance compared to existing models, with notable improvements in both AP and AP50 metrics.

## Method Summary
The proposed SemInst method tackles small sample instance segmentation through two complementary modules. First, the Semantic Branch integrates text and image features by extracting word embeddings of categories using SciBert, projecting them to match image feature dimensions, and fusing them to enhance classification confidence. Second, the Two-stage Training strategy employs supervised learning on limited labeled data followed by semi-supervised learning where a teacher model generates pseudo labels for unlabeled data, which a student model then learns from. The method uses AdamW optimizer with learning rates of 0.01 (Mask R-CNN) and 0.0001 (FastInst), batch size of 4, 200 epochs for supervised training, and 10 epochs for semi-supervised training.

## Key Results
- Semantic branch improves classification by filtering incorrect predictions through text-image feature integration
- Two-stage training refines masks and discovers undetected instances using pseudo labels from unlabeled data
- Competitive performance on three datasets: TrashCan (22 classes), COCO2017 (80 classes), and 2205DSS (microscopic images)

## Why This Works (Mechanism)
The method leverages both visual and semantic information to address the small sample problem. By integrating text features from category embeddings, the model gains additional context that helps correct classification confidence, especially when visual features alone are ambiguous due to limited training examples. The two-stage training approach first establishes a baseline model on labeled data, then progressively improves it by incorporating pseudo-labeled instances from unlabeled data, effectively expanding the training set without additional annotation cost.

## Foundational Learning
- Instance Segmentation Fundamentals: Understanding how segmentation masks are generated and evaluated (why needed: to grasp the core task being addressed)
  - Quick check: Verify understanding of AP, AP50, and AP75 metrics
- Semi-supervised Learning: Knowledge of how pseudo-labeling works in training pipelines (why needed: the two-stage training strategy is central to the approach)
  - Quick check: Understand teacher-student model relationship in semi-supervised learning
- Text-Image Feature Integration: Concepts of feature projection and fusion across modalities (why needed: the semantic branch relies on combining text and image representations)
  - Quick check: Confirm understanding of how word embeddings are processed and integrated with visual features

## Architecture Onboarding

Component Map: Image Features -> Semantic Branch (Text Features + MLP) -> Fused Features -> Classification -> Segmentation Masks
                    ↓
            Two-stage Training (Supervised → Semi-supervised)

Critical Path: Image features extracted from backbone → fused with text embeddings in semantic branch → classification → mask prediction → refinement through semi-supervised pseudo-labeling

Design Tradeoffs: The semantic branch adds computational overhead but provides better classification confidence, while two-stage training increases training time but leverages unlabeled data effectively. The choice of weak vs. strong augmentations affects pseudo-label quality.

Failure Signatures: Poor performance on datasets with many classes (like COCO2017) suggests difficulty learning from few examples per class. Overfitting to limited labeled data indicates need for stronger regularization or augmentation.

First Experiments:
1. Baseline implementation using only image features without text integration to quantify semantic branch contribution
2. Test multiple pseudo-label filtering thresholds to evaluate their impact on performance stability
3. Compare against standard semi-supervised baselines (e.g., FixMatch, UDA) using the same labeled data ratios

## Open Questions the Paper Calls Out
- How does text-image feature integration specifically improve classification accuracy compared to image features alone? The paper lacks a direct comparison showing the semantic branch's contribution to classification metrics.
- What is the optimal threshold for filtering pseudo labels across different datasets? The paper mentions using a threshold but doesn't explore how different values affect performance.
- How does the two-stage training strategy compare to other semi-supervised methods in computational efficiency and final performance? The paper doesn't benchmark against alternative semi-supervised approaches.

## Limitations
- Implementation details for semantic branch fusion are underspecified, making exact reproduction challenging
- Specific weak and strong augmentation techniques used in two-stage training are not detailed
- Limited discussion of hyperparameter sensitivity and ablation studies to validate design choices

## Confidence
- Semantic Branch Implementation: Medium - Architecture described but fusion details unclear
- Two-stage Training Procedure: Medium - General approach clear but augmentation specifics missing
- Performance Claims: Medium - Results presented but reproducibility limited by implementation gaps

## Next Checks
1. Implement baseline version using only image features without text integration to quantify semantic branch's contribution
2. Test multiple pseudo-label filtering thresholds to evaluate their impact on performance stability
3. Compare against standard semi-supervised baselines (e.g., FixMatch, UDA) using the same labeled data ratios