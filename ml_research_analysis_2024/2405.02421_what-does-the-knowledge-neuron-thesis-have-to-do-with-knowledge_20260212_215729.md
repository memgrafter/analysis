---
ver: rpa2
title: What does the Knowledge Neuron Thesis Have to do with Knowledge?
arxiv_id: '2405.02421'
source_url: https://arxiv.org/abs/2405.02421
tags:
- agreement
- language
- these
- noun
- neuron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper critically reassesses the Knowledge Neuron (KN) Thesis,
  which proposes that facts are stored in transformer models' MLP weights and can
  be manipulated to control factual recall. The authors evaluate this thesis by applying
  KN-inspired editing methods to both factual associations and syntactic phenomena.
---

# What does the Knowledge Neuron Thesis Have to do with Knowledge?

## Quick Facts
- arXiv ID: 2405.02421
- Source URL: https://arxiv.org/abs/2405.02421
- Authors: Jingcheng Niu; Andrew Liu; Zining Zhu; Gerald Penn
- Reference count: 40
- This paper critically reassesses the Knowledge Neuron Thesis, showing that MLP weights store "token expression patterns" rather than knowledge

## Executive Summary
This paper critically evaluates the Knowledge Neuron (KN) Thesis, which proposes that transformer models store facts in MLP weights and can be edited to control factual recall. The authors apply KN-inspired editing methods to both factual associations and syntactic phenomena, finding that while information can be localized to specific neurons, the resulting edits are weak, unreliable, and often rely on superficial word co-occurrence patterns. They demonstrate that KN editing fails to generalize under symmetry and synonymy criteria, and that ROME only achieves brittle token-level changes. The authors conclude that MLP weights store "token expression patterns" rather than knowledge, and argue for a more comprehensive investigation of transformer architecture beyond MLP modules.

## Method Summary
The authors evaluate the Knowledge Neuron Thesis by applying KN-inspired editing methods to both factual associations and syntactic phenomena. They use integral of gradients to identify knowledge neurons, suppress these neurons to test effects, and employ causal mediation analysis for ROME method evaluation. The study uses the BLiMP corpus for syntactic phenomena and PARA REL corpus for factual relations, testing reliability, generality, locality, bijective symmetry, and synonymous invariance metrics. They compare localization patterns across BERT, GPT-2, and LLaMA-2 models, and conduct ablation studies to understand the role of MLP versus attention mechanisms.

## Key Results
- MLP weights store "token expression patterns" rather than knowledge, as evidenced by weak and unreliable editing outcomes
- KN editing fails to generalize under symmetry and synonymy criteria, only affecting exact token associations
- Information processing in transformers involves distributed representations across layers and attention mechanisms, not just isolated MLP neurons

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MLP weights in transformers store token expression patterns rather than knowledge
- Mechanism: When specific MLP neurons are activated by input patterns, they alter output token probabilities based on superficial co-occurrence statistics rather than deep semantic understanding
- Core assumption: The patterns identified in MLP neurons reflect statistical associations rather than knowledge representations
- Evidence anchors:
  - [abstract] "While it is possible to argue that the MLP weights store complex patterns that are interpretable both syntactically and semantically, these patterns do not constitute 'knowledge.'"
  - [section 3.2] "This frequency effect is not limited to scattered. Other words such as any, all, unified, and the three adjectives unique, single and sole exhibit a similar bias."
- Break condition: If editing MLP neurons could reliably change both a fact and all its related expressions, or if neurons showed consistent semantic relationships independent of co-occurrence patterns

### Mechanism 2
- Claim: Knowledge localization to specific neurons is an oversimplification of transformer information processing
- Mechanism: Information processing in transformers involves distributed representations across layers and attention mechanisms, not just isolated MLP neurons
- Core assumption: The KN thesis incorrectly reduces complex information processing to localized neuron patterns
- Evidence anchors:
  - [abstract] "The authors demonstrate that KN editing fails to generalize under symmetry and synonymy criteria"
  - [section 2.1] "Our evaluation shows that existing model-editing methods are even less robust under these two new criteria"
- Break condition: If model editing methods could achieve reliable symmetry and synonymy generalization

### Mechanism 3
- Claim: Causal tracing reveals distributed processing across MLP and attention modules
- Mechanism: Information processing involves multiple phases with different modules handling different aspects, contradicting the KN thesis's simplified model
- Core assumption: The original KN thesis oversimplified the division of labor between MLP and attention mechanisms
- Evidence anchors:
  - [section 4] "The distinction between the early and late site is no longer discernible... Many factual causal traces also do not show this distinction"
  - [section 2.3] "We explore here the possibility that no dividing line exists at all between the mechanisms through which a language model processes information"
- Break condition: If clear phase-based division of labor between MLP and attention could be consistently demonstrated

## Foundational Learning

- Concept: Causal mediation analysis
  - Why needed here: Understanding how changes in intermediate representations affect final outputs is crucial for evaluating knowledge editing methods
  - Quick check question: What does it mean when causal mediation analysis shows that restoring hidden states can fix corrupted outputs?

- Concept: Minimal pair paradigm
  - Why needed here: This methodology allows rigorous testing of syntactic phenomena localization by comparing grammatical and ungrammatical sentence pairs
  - Quick check question: How does using minimal pairs help distinguish between syntax and semantics in language model analysis?

- Concept: Bijective relationships and symmetry
  - Why needed here: These concepts provide rigorous evaluation criteria for knowledge editing methods by testing whether edits generalize to related facts
  - Quick check question: Why is testing for symmetry important when evaluating knowledge editing methods?

## Architecture Onboarding

- Component map: Transformer layers -> MLP modules (feed-forward networks) -> Attention mechanisms -> Output layer
- Critical path: Input -> Token embedding -> Layer processing (MLP + Attention) -> Output prediction
- Design tradeoffs: MLP modules offer interpretable patterns but limited generalization vs. attention mechanisms providing context but less interpretability
- Failure signatures: Low reliability scores, failure to generalize across synonyms/symmetry, reliance on superficial co-occurrence patterns
- First 3 experiments:
  1. Reproduce determiner-noun agreement localization using integral of gradients to identify KNs
  2. Test symmetry generalization by editing one direction of a bijective relationship and checking the reverse
  3. Compare causal mediation effects across MLP and attention modules for the same task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms in transformer architecture beyond MLP modules contribute to knowledge representation?
- Basis in paper: [explicit] Authors conclude that "to gain a more comprehensive understanding of the knowledge representation process, we must look beyond the MLP weights and explore recent models' complex layer structures and attention mechanisms"
- Why unresolved: The paper demonstrates MLP modules store "token expression patterns" rather than knowledge, but doesn't specify what alternative architectural components might actually store knowledge
- What evidence would resolve it: Empirical studies isolating the contributions of attention heads, layer normalization, and residual connections to knowledge representation tasks

### Open Question 2
- Question: How do superficial word co-occurrence patterns differ from true knowledge in language models?
- Basis in paper: [explicit] Authors note that "patterns identified for these neurons can only be completely accounted for by appealing to superficial cues such as word co-occurrence frequency"
- Why unresolved: The paper identifies that MLP neurons respond to frequency-based patterns but doesn't establish clear criteria for distinguishing these from genuine semantic knowledge
- What evidence would resolve it: Systematic experiments comparing model performance on tasks requiring deep semantic understanding versus pattern matching, particularly under distribution shifts

### Open Question 3
- Question: What explains the discrepancy between high localization of information to neurons and weak model editing outcomes?
- Basis in paper: [explicit] Authors find that while neurons show "high level of localization in the underlying probability drift," the effect of editing "is not enough to overturn the categorical predictions"
- Why unresolved: The paper identifies this phenomenon but doesn't explain why localized information fails to produce strong editing effects
- What evidence would resolve it: Investigation of information flow through the transformer, measuring how localized neuron activations propagate through subsequent layers and affect final predictions

## Limitations

- Scope of syntactic evaluation is limited to English grammar patterns, raising questions about generalizability to other languages
- Study focuses primarily on BERT, GPT-2, and LLaMA-2 models, potentially limiting conclusions about other transformer architectures
- Paper acknowledges training data influence on MLP patterns but doesn't systematically analyze how different corpora affect localization results

## Confidence

**High Confidence (8-10/10)**: The finding that KN editing methods show low reliability scores (1.66%-47.86%) and fail symmetry/synonymy criteria. The experimental methodology using minimal pairs and causal mediation analysis is rigorous and reproducible.

**Medium Confidence (5-7/10)**: The claim that MLP weights store "token expression patterns" rather than knowledge. While the evidence is compelling, alternative interpretations are not fully ruled out.

**Low Confidence (2-4/10)**: The broader implications for transformer architecture understanding. The paper challenges the KN thesis but doesn't provide a complete alternative model of how transformers process and store information.

## Next Checks