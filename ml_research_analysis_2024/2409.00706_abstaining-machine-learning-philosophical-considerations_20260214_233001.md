---
ver: rpa2
title: Abstaining Machine Learning -- Philosophical Considerations
arxiv_id: '2409.00706'
source_url: https://arxiv.org/abs/2409.00706
tags:
- abstention
- data
- systems
- training
- abstaining
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines abstaining machine learning (AML) systems
  from a philosophical perspective, connecting them to the epistemological concept
  of suspended judgment. It categorizes AML systems along two dimensions: reasons
  for abstention (ambiguity vs.'
---

# Abstaining Machine Learning -- Philosophical Considerations

## Quick Facts
- arXiv ID: 2409.00706
- Source URL: https://arxiv.org/abs/2409.00706
- Reference count: 19
- One-line primary result: Merged AML systems, particularly those using unlabeled abstention, better align with philosophical criteria for suspended judgment than attached systems, offering greater autonomy and explainability.

## Executive Summary
This paper examines abstaining machine learning (AML) systems through a philosophical lens, connecting them to the epistemological concept of suspended judgment. The author categorizes AML systems along two dimensions: reasons for abstention (ambiguity vs. outlier) and implementation methods (attached vs. merged). Through this framework, the paper argues that merged AML systems, particularly those using unlabeled abstention, demonstrate stronger alignment with philosophical criteria for suspended judgment. The analysis reveals that merged systems offer greater autonomy in abstention decisions and provide more informative explanations for abstaining outputs compared to attached systems.

## Method Summary
The paper employs a philosophical analysis framework to examine AML systems, establishing a structured comparison between different implementation approaches. It uses a breast cancer detection example with two features (smallest nucleus perimeter and proportion of concave points) to illustrate the concepts. The methodology distinguishes between attached systems (where abstention is a post-algorithmic decision based on certainty thresholds) and merged systems (where abstention is integrated as a learned output class through modified loss functions). The analysis focuses on two key dimensions: the reasons for abstention (ambiguity abstention for uncertainty vs. outlier abstention for data points far from training distribution) and the implementation approach (attached vs. merged).

## Key Results
- Merged AML systems align more closely with philosophical criteria for suspended judgment than attached systems
- Merged systems demonstrate greater autonomy in establishing connections between input characteristics and abstention decisions
- Merged systems provide better explainability of abstaining outputs by allowing feature attributions for abstention decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The paper establishes a meaningful analogy between AML abstention and philosophical suspension of judgment.
- Mechanism: By categorizing AML systems along two dimensions (reason for abstention: ambiguity vs outlier; implementation: attached vs merged), the paper aligns these categories with philosophical distinctions in suspension (privative vs positive justification, epistemic vs indeterminacy suspension). This creates a structured framework for comparing ML behavior to philosophical doxastic stances.
- Core assumption: The behaviors of abstaining ML systems can be meaningfully mapped to philosophical concepts of suspension.
- Evidence anchors:
  - [abstract] The paper investigates abstaining machine learning systems from a philosophical perspective, connecting them to the epistemological concept of suspended judgment.
  - [section] The distinction between ambiguity abstention (privatively justified) and outlier abstention (positively justified) maps to philosophical norms for suspension.
- Break condition: If AML systems do not actually exhibit the epistemic properties required for philosophical suspension (e.g., genuine indecision or neutrality), the analogy fails.

### Mechanism 2
- Claim: Merged AML systems are philosophically preferable to attached systems for modeling suspension.
- Mechanism: Merged systems treat abstention as a genuine output class integrated into the decision process, aligning with philosophical suspension as a doxastic stance toward the question under discussion. Attached systems treat abstention as a post-hoc decision about certainty, which doesn't address the original question.
- Core assumption: Philosophical suspension requires addressing the question under discussion directly, not merely the certainty of an answer.
- Evidence anchors:
  - [abstract] The paper argues that merged systems align more closely with philosophical criteria for suspended judgment.
  - [section] Merged systems allow the system to autonomously establish connections between input characteristics and abstention, while attached systems use hard-coded thresholds.
- Break condition: If attached systems can be modified to integrate abstention more naturally into the decision process, the distinction may weaken.

### Mechanism 3
- Claim: Merged AML systems offer better explainability for abstention decisions than attached systems.
- Mechanism: In merged systems, abstention is learned as a class, allowing explanations to reference input features that led to abstention. In attached systems, abstention is determined by certainty thresholds applied to regular predictions, making explanations indirect and less informative.
- Core assumption: Explainability requires the system to have learned a direct relationship between input features and the abstention decision.
- Evidence anchors:
  - [abstract] Merged systems offer better explainability of abstaining outputs compared to attached systems.
  - [section] Merged systems can point to particular features of the input sample as reasons for abstention, while attached systems can only say "certainty below threshold."
- Break condition: If new methods emerge for explaining threshold-based decisions in attached systems, the advantage of merged systems may diminish.

## Foundational Learning

- Concept: Supervised machine learning and classification
  - Why needed here: The paper assumes familiarity with basic ML concepts like training data, decision boundaries, and classification tasks.
  - Quick check question: Can you explain how a classifier learns to separate different classes in the training data?

- Concept: Doxastic attitudes (belief, disbelief, suspension)
  - Why needed here: The philosophical analysis relies on understanding these three doxastic stances and how suspension differs from belief and disbelief.
  - Quick check question: What distinguishes suspension of judgment from belief and disbelief in philosophical terms?

- Concept: Explainable AI principles
  - Why needed here: The paper discusses explainability of abstention outputs, referencing the Explanation Principle from Phillips et al. (2020).
  - Quick check question: What does the Explanation Principle require for AI system outputs?

## Architecture Onboarding

- Component map:
  Input → Feature extraction → Core predictor → Abstention module → Output

- Critical path:
  For attached systems: Input → Predictor → Certainty calculation → Threshold comparison → Output
  For merged systems: Input → Abstention predictor → Output (class OR abstention)

- Design tradeoffs:
  - Attached systems: Simpler to implement, can reuse existing classifiers, but offer less philosophical alignment and explainability
  - Merged systems: Better philosophical alignment and explainability, but require modifying training process and loss functions

- Failure signatures:
  - High abstention rates in attached systems may indicate poorly tuned thresholds rather than genuine uncertainty
  - Low abstention rates in merged systems may indicate α parameter set too high in loss function
  - Mismatch between expected and actual abstention behavior suggests incorrect categorization of outlier vs ambiguity cases

- First 3 experiments:
  1. Compare abstention rates and accuracy between attached (threshold-based) and merged (unlabeled) systems on a binary classification task
  2. Evaluate explainability by attempting to generate feature attributions for abstention decisions in both system types
  3. Test philosophical alignment by analyzing whether abstention decisions correspond to genuine epistemic uncertainty (e.g., ambiguous inputs) rather than just outlier detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do AML systems perform in real-world high-stakes scenarios compared to traditional ML systems?
- Basis in paper: [explicit] The paper mentions that AML systems are preferable in high-stakes scenarios like medical decision-making but does not provide empirical evidence comparing their performance to traditional ML systems.
- Why unresolved: The paper focuses on philosophical analysis rather than empirical performance evaluation. Real-world implementation and testing of AML systems in various domains remain largely unexplored.
- What evidence would resolve it: Comparative studies and empirical data showing the performance of AML systems versus traditional ML systems in high-stakes scenarios across different domains.

### Open Question 2
- Question: Can AML systems be effectively integrated into existing ML frameworks without significant computational overhead?
- Basis in paper: [inferred] The paper discusses different implementations of AML systems (attached vs. merged) but does not address the practical challenges of integrating these systems into existing ML frameworks.
- Why unresolved: The philosophical analysis does not delve into the technical and computational aspects of implementing AML systems in real-world applications.
- What evidence would resolve it: Case studies and technical reports demonstrating the integration of AML systems into existing ML frameworks, highlighting computational efficiency and any challenges faced.

### Open Question 3
- Question: How do users perceive and trust AML systems compared to traditional ML systems in decision-making processes?
- Basis in paper: [explicit] The paper mentions that AML systems can enhance trust by communicating uncertainties but does not explore user perceptions and trust in these systems.
- Why unresolved: The philosophical analysis focuses on the theoretical aspects of AML systems and does not include user studies or surveys to gauge perceptions and trust.
- What evidence would resolve it: Surveys and studies involving users interacting with both AML and traditional ML systems to assess their trust, understanding, and comfort with the decision-making processes.

## Limitations

- The paper's central claim about philosophical alignment rests on a potentially debatable mapping between machine learning behaviors and philosophical concepts of suspended judgment.
- The explainability claims are supported by conceptual arguments but lack empirical validation with concrete examples or metrics.
- The distinction between feature-based explanations in merged systems versus threshold-based explanations in attached systems remains somewhat abstract without implementation details.

## Confidence

- **High Confidence**: The categorization framework itself (ambiguity vs outlier reasons, attached vs merged implementations) is well-defined and internally consistent.
- **Medium Confidence**: The argument that merged systems better align with philosophical criteria for suspended judgment is plausible but depends on accepting the initial analogy.
- **Low-Medium Confidence**: The claims about superior explainability of merged systems are theoretically reasonable but lack empirical substantiation in the paper.

## Next Checks

1. **Empirical Explainability Comparison**: Implement both attached and merged abstention systems on a standard dataset and conduct a user study or automated evaluation comparing the quality and informativeness of explanations for abstention decisions in each approach.

2. **Philosophical Alignment Validation**: Design experiments to test whether abstention decisions in merged systems actually correspond to genuine epistemic uncertainty (ambiguous inputs) versus other factors like outlier detection, by systematically varying input characteristics and measuring abstention patterns.

3. **Threshold Sensitivity Analysis**: For attached systems, conduct systematic experiments varying certainty thresholds to determine how robust abstention decisions are to parameter changes, and whether this undermines claims about their philosophical inadequacy compared to merged approaches.