---
ver: rpa2
title: 'Multimodal Fact-Checking with Vision Language Models: A Probing Classifier
  based Solution with Embedding Strategies'
arxiv_id: '2412.05155'
source_url: https://arxiv.org/abs/2412.05155
tags:
- text
- image
- claim
- evidence
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the effectiveness of Vision Language Models
  (VLMs) in fact-checking tasks by proposing a probing classifier approach that extracts
  embeddings from VLMs' last hidden layers. The research addresses whether incorporating
  multimodal content improves fact-checking performance compared to text-only models
  and how effectively VLMs utilize text and image information.
---

# Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies

## Quick Facts
- **arXiv ID**: 2412.05155
- **Source URL**: https://arxiv.org/abs/2412.05155
- **Reference count**: 19
- **Key outcome**: Proposed neural probing classifier with VLM embeddings achieved F1-macro scores up to 0.670 on Factify2 dataset

## Executive Summary
This study investigates whether Vision Language Models (VLMs) can enhance fact-checking performance by leveraging both text and image information. The researchers propose a probing classifier approach that extracts embeddings from VLMs' last hidden layers and processes them through a neural network for veracity prediction. Through experiments on Mocheg and Factify2 datasets, the study demonstrates that while multimodal content can improve fact-checking, fusing separate text and image embeddings yields better results than using VLM embeddings. The neural probing classifier significantly outperformed traditional baselines like KNN and SVM.

## Method Summary
The method involves extracting embeddings from the last hidden layer of pre-trained VLMs (Qwen-VL, Idefics2-8b, PaliGemma-3b) using text and image inputs, then feeding these representations into a feed-forward neural probing classifier. The approach compares two fusion strategies: intrinsic fusion using VLM embeddings that inherently combine text and image information, and extrinsic fusion where separate text and image embeddings are extracted and combined externally. The classifier is trained with weighted cross-entropy loss and evaluated using F1-macro scores across three classes: supported, refuted, and not enough info.

## Key Results
- The neural probing classifier achieved F1-macro scores up to 0.670 on Factify2 dataset, significantly outperforming KNN and SVM baselines
- Extrinsic fusion of separate text and image embeddings consistently outperformed intrinsic VLM fusion across both datasets
- PaliGemma-3b showed poor performance due to injected safety policies returning generic responses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VLMs can improve fact-checking by leveraging both text and image information through multimodal embeddings.
- Mechanism: VLMs fuse text and image information using cross-attention mechanisms, creating representations that capture multimodal context. These embeddings are then processed by a neural probing classifier to predict veracity classes.
- Core assumption: The fused multimodal embeddings from VLMs contain sufficient discriminative information for fact-checking tasks.
- Evidence anchors:
  - [abstract] "we demonstrate that while multimodality can enhance performance, fusing separate embeddings from text and image encoders yielded superior results compared to using VLM embeddings."
  - [section 4.2] "we examined whether inherently multimodal models effectively utilize both text and image information. First, we extracted embeddings from selected VLMs and fed these vector representations into a feed-forward multi-class classifier."
  - [corpus] Weak evidence - the corpus contains related papers but no direct experimental validation of this specific VLM probing classifier mechanism.
- Break condition: If the probing classifier fails to outperform text-only models or separate text/image embeddings, indicating that VLM fusion doesn't provide additional discriminative power.

### Mechanism 2
- Claim: A probing classifier using VLM embeddings can effectively learn fact-checking patterns without requiring full model fine-tuning.
- Mechanism: The probing classifier extracts embeddings from the last hidden layer of pre-trained VLMs and uses these as input features for a shallow neural network, avoiding the computational cost of full fine-tuning.
- Core assumption: The last hidden layer representations of VLMs contain task-relevant features that can be linearly separable for fact-checking.
- Evidence anchors:
  - [abstract] "The proposed neural classifier significantly outperformed KNN and SVM baselines in leveraging extracted embeddings, highlighting its effectiveness for multimodal fact-checking."
  - [section 3.1] "A key advantage of probing classifiers is their ability to assess how well the pre-trained model has captured linguistic properties."
  - [corpus] Weak evidence - related work exists on probing classifiers but not specifically for VLMs in fact-checking.
- Break condition: If the probing classifier performance degrades significantly when using embeddings from earlier layers or when the VLM wasn't pre-trained on relevant multimodal data.

### Mechanism 3
- Claim: Extrinsic fusion of separate text and image embeddings outperforms intrinsic VLM fusion for fact-checking.
- Mechanism: By extracting embeddings separately from text-only and image-only encoders and fusing them externally in the classifier, the model can learn optimal feature combinations for fact-checking rather than relying on pre-fused VLM representations.
- Core assumption: Separate text and image encoders capture complementary information that can be better combined by the classifier than the VLM's internal fusion mechanism.
- Evidence anchors:
  - [abstract] "fusing separate embeddings from text and image encoders yielded superior results compared to using VLM embeddings."
  - [section 4.3] "Separate embeddings were extracted for text and image information from the vision encoders and language models, respectively. Afterward, we performed mean pooling to obtain one-dimensional vector representations for each instance."
  - [corpus] Weak evidence - the corpus mentions related embedding approaches but lacks direct comparison studies.
- Break condition: If the extrinsic fusion approach fails to improve performance or becomes computationally prohibitive compared to intrinsic fusion.

## Foundational Learning

- Concept: Multimodal representation learning
  - Why needed here: The system relies on VLMs that fuse text and image information through cross-attention mechanisms to create meaningful representations for fact-checking.
  - Quick check question: How do cross-attention mechanisms in VLMs combine text and image information compared to simple concatenation?

- Concept: Probing classifier methodology
  - Why needed here: The approach uses probing classifiers to evaluate how well pre-trained models capture task-relevant information without full fine-tuning.
  - Quick check question: What is the difference between probing classifiers and fine-tuning in terms of computational efficiency and evaluation purpose?

- Concept: Zero-shot inference with VLMs
  - Why needed here: The experiments include zero-shot evaluation of VLMs on fact-checking tasks to establish baseline performance before proposing the probing classifier approach.
  - Quick check question: How does zero-shot inference differ from few-shot or fine-tuned approaches in terms of required prompt engineering?

## Architecture Onboarding

- Component map: VLM → Embedding Extractor → Probing Classifier → Veracity Prediction. The VLM provides multimodal representations, the extractor obtains embeddings from the last hidden layer, and the classifier processes these embeddings for classification.
- Critical path: Embedding extraction from VLM → Probing classifier training → Veracity prediction. The bottleneck is the VLM inference time for embedding extraction.
- Design tradeoffs: Using VLMs avoids fine-tuning costs but requires expensive inference for embedding extraction. Separate text/image encoders are more efficient but may lose cross-modal interactions captured by VLMs.
- Failure signatures: Poor performance on "not enough info" class suggests the model struggles with uncertainty detection. If text-only models outperform multimodal approaches, it indicates images don't add value for this task.
- First 3 experiments:
  1. Compare zero-shot performance of text-only vs multimodal VLMs on fact-checking datasets.
  2. Evaluate intrinsic fusion (VLM embeddings) vs extrinsic fusion (separate text and image embeddings) in the probing classifier.
  3. Compare the proposed neural probing classifier against KNN and SVM baselines using the same embeddings.

## Open Questions the Paper Calls Out
- The paper identifies limitations including the focus on English datasets, lack of multilingual capabilities assessment, and the shallow architecture of the probing classifier. The authors note that PaliGemma-3b's poor performance may be due to injected safety policies, and that evidence cropping due to GPU memory constraints significantly impacted results on the Mocheg dataset.

## Limitations
- The study was limited to English datasets, not assessing multilingual capabilities of the VLMs
- Evidence text exceeding sequence length limits was cropped rather than processed through more sophisticated methods
- PaliGemma-3b showed poor performance due to injected safety policies returning generic responses

## Confidence
- **High confidence**: The neural probing classifier outperforming KNN and SVM baselines is well-supported by experimental results across both datasets.
- **Medium confidence**: The claim that extrinsic fusion (separate text/image embeddings) outperforms intrinsic VLM fusion is supported but may depend on specific VLM architectures and task characteristics.
- **Medium confidence**: The observation that VLMs can improve fact-checking through multimodal embeddings is supported, though the extent of improvement varies by model and dataset.

## Next Checks
1. Test the probing classifier with embeddings from intermediate VLM layers to determine if the last hidden layer is optimal for capturing fact-checking relevant features, and compare performance degradation when using earlier layers.
2. Implement and evaluate alternative fusion strategies such as attention-based fusion or learnable weighted combinations of text and image embeddings to see if they outperform the simple mean pooling approach used in the study.
3. Conduct ablation studies removing either text or image inputs to quantify the marginal contribution of each modality across different claim types and assess whether the computational cost of multimodal processing is justified.