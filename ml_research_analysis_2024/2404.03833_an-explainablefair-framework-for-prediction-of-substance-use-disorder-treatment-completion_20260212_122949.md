---
ver: rpa2
title: An ExplainableFair Framework for Prediction of Substance Use Disorder Treatment
  Completion
arxiv_id: '2404.03833'
source_url: https://arxiv.org/abs/2404.03833
tags:
- fairness
- treatment
- importance
- features
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a novel framework, ExplainableFair, that sequentially
  develops a fair predictive model and provides explanations for fairness enhancements.
  The framework first trains a logistic regression model optimized for performance,
  then applies in-processing bias mitigation using Equalized Odds disparity regularization.
---

# An ExplainableFair Framework for Prediction of Substance Use Disorder Treatment Completion

## Quick Facts
- arXiv ID: 2404.03833
- Source URL: https://arxiv.org/abs/2404.03833
- Reference count: 40
- Primary result: Novel framework achieving high predictive performance (AUROC 85.85-85.76%) while improving fairness in SUD treatment completion prediction

## Executive Summary
This paper presents ExplainableFair, a sequential framework that develops fair predictive models for substance use disorder treatment completion while providing interpretable explanations for fairness enhancements. The framework first trains a logistic regression model optimized for performance, then applies in-processing bias mitigation using Equalized Odds disparity regularization, and finally employs SHAP feature importance analysis to interpret changes in feature importance during the fairness optimization process. Applied to a dataset of 10,673 encounters from the Hazelden Betty Ford Foundation, the framework successfully reduces Equalized Odds disparity from 0.0725 to 0.0298 for race and from 0.0603 to 0.0282 for sex while maintaining high predictive performance (AUROC 85.85-85.76%). The framework reveals that while key predictors like motivation and 12-step participation remain important, treatment goals decrease in importance while living conditions increase after fairness optimization.

## Method Summary
The ExplainableFair framework follows a three-stage approach: First, a logistic regression model is trained using standard optimization techniques to maximize predictive performance. Second, in-processing fairness optimization is applied by introducing Equalized Odds disparity regularization during a fine-tuning phase, which balances True Positive and False Positive Rates across demographic groups. Third, SHAP feature importance analysis is used to compare feature rankings between the original and fairness-optimized models, revealing which features become more or less influential after fairness enhancement. The framework was evaluated on a dataset of substance use disorder treatment encounters, with race (Caucasian vs. Not Caucasian) and sex (Male vs. Female) as sensitive attributes, using Equalized Odds disparity as the primary fairness metric.

## Key Results
- Achieved AUROC of 85.85-85.76% while reducing Equalized Odds disparity for race from 0.0725 to 0.0298 and for sex from 0.0603 to 0.0282
- Maintained high predictive performance (AUROC, sensitivity, specificity) while improving fairness metrics through in-processing regularization
- Revealed clinically meaningful changes in feature importance: motivation, readiness for change, and 12-step participation remained important predictors, while treatment goals decreased in importance and living conditions increased after fairness optimization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework maintains high predictive performance while reducing fairness disparity by decoupling the training and fairness optimization stages.
- Mechanism: The framework first trains a logistic regression model optimized for predictive performance, then applies in-processing bias mitigation by introducing Equalized Odds disparity regularization during a fine-tuning phase. This two-stage approach preserves the predictive accuracy of the initial model while addressing fairness concerns through targeted regularization.
- Core assumption: Fairness optimization via in-processing regularization does not significantly degrade predictive performance when applied as a post-hoc refinement to an already well-performing model.
- Evidence anchors:
  - [abstract] "The framework first trains a logistic regression model optimized for performance, then applies in-processing bias mitigation using Equalized Odds disparity regularization."
  - [section] "We select the logistic regression model as our classifier due to its robustness and interpretability. Given a patient x ∈ Rm with the target variable y, where m is the number of features, the learning process of the logistic regression model is to find the coefficient value ω ∈ Rm that reduces the difference between actual value y and the predicted value fω(x) = ˆy."
  - [corpus] Weak evidence; related work on gradient reconciliation approaches suggests performance-fairness trade-offs exist but are not directly compared.
- Break condition: If the regularization strength is too high or the initial model is poorly calibrated, the fairness optimization may degrade performance beyond acceptable thresholds.

### Mechanism 2
- Claim: Feature importance changes provide interpretable explanations for how fairness optimization alters the model's decision-making process.
- Mechanism: By applying SHAP (SHapley Additive exPlanations) to both the original performance-optimized model and the fairness-enhanced model, the framework quantifies changes in feature importance. Comparing these rankings reveals which features become more or less influential after fairness optimization, offering insights into the model's altered decision boundaries.
- Core assumption: Changes in feature importance rankings directly correspond to meaningful changes in the model's fairness properties and can be interpreted in a clinically relevant manner.
- Evidence anchors:
  - [abstract] "Finally, it employs SHAP feature importance analysis to interpret and explain changes in feature importance during the fairness optimization process."
  - [section] "We utilize a local feature attribution method, SHAP, which distributes the prediction score of a fitted model for a patient x ∈ X to its base features Rm. The score of a base feature can be interpreted as the importance of the feature to the patient."
  - [corpus] Weak evidence; the corpus contains related work on fairness explanation but lacks direct empirical validation of SHAP-based explanations for fairness changes.
- Break condition: If SHAP explanations are unstable across different model runs or the feature importance changes are too subtle to interpret clinically, the explanatory value diminishes.

### Mechanism 3
- Claim: Optimizing for group-based fairness measures like Equalized Odds reduces disparate treatment across sensitive demographic groups while maintaining overall model utility.
- Mechanism: The framework explicitly minimizes the difference in True Positive Rate (TPR) and False Positive Rate (FPR) between privileged and unprivileged groups by incorporating Equalized Odds disparity (EOD) into the loss function. This ensures that the model's predictive accuracy is balanced across demographic groups.
- Core assumption: Equalized Odds disparity is an appropriate and effective fairness metric for the healthcare domain, particularly for substance use disorder treatment prediction.
- Evidence anchors:
  - [abstract] "the framework achieves high predictive performance (AUROC 85.85-85.76%) while improving fairness by reducing Equalized Odds disparity from 0.0725 to 0.0298 for race and from 0.0603 to 0.0282 for sex."
  - [section] "EO mandates that both the True Positive Rate (TPR) and False Positive Rate (FPR) exhibit minimal disparity across different demographic groups. Based on this concept, the proposed loss function incorporates the Equalized Odds Disparity (EOD)."
  - [corpus] Moderate evidence; related work on fairness in healthcare AI supports the use of equalized odds but also highlights the complexity of defining appropriate fairness metrics.
- Break condition: If Equalized Odds is not the most relevant fairness criterion for the specific clinical context or if the demographic groups are not well-defined, the fairness optimization may not achieve the desired outcomes.

## Foundational Learning

- Concept: Logistic Regression and its optimization
  - Why needed here: The framework uses logistic regression as the base model due to its interpretability and robustness, making it crucial to understand how it learns coefficients and makes predictions.
  - Quick check question: What is the mathematical form of the logistic regression loss function, and how does it differ from linear regression?

- Concept: Fairness metrics (Equalized Odds, Disparate Impact)
  - Why needed here: The framework explicitly optimizes for Equalized Odds disparity, requiring a clear understanding of what this metric measures and how it relates to other fairness definitions.
  - Quick check question: How does Equalized Odds differ from Demographic Parity, and in what scenarios might one be preferred over the other?

- Concept: SHAP (SHapley Additive exPlanations)
  - Why needed here: SHAP is used to interpret changes in feature importance, so understanding how it calculates feature contributions and handles model dependence is essential.
  - Quick check question: What is the theoretical basis of SHAP values, and why are they considered a unified approach to interpreting model predictions?

## Architecture Onboarding

- Component map: Data Preprocessing -> Model Training -> Fairness Optimization -> Explanation Generation -> Evaluation
- Critical path:
  1. Prepare and split the data into training and test sets.
  2. Train the initial logistic regression model on the training set.
  3. Apply fairness optimization to the trained model using Equalized Odds disparity regularization.
  4. Calculate SHAP values for both the original and fairness-optimized models on the test set.
  5. Analyze and interpret the changes in feature importance rankings.
  6. Evaluate and report model performance and fairness metrics.

- Design tradeoffs:
  - Performance vs. Fairness: The framework aims to balance predictive accuracy with fairness, but there may be a trade-off depending on the regularization strength.
  - Interpretability vs. Complexity: Logistic regression is chosen for its interpretability, but more complex models might achieve better performance or fairness.
  - Group-based vs. Individual Fairness: The framework focuses on group-based fairness metrics, which may not address individual fairness concerns.

- Failure signatures:
  - High EOD values after fairness optimization indicate that the bias mitigation was insufficient.
  - Significant drops in AUROC, sensitivity, or specificity suggest that the fairness optimization degraded predictive performance.
  - Unstable or inconsistent SHAP explanations across different runs may indicate issues with the explanation method.

- First 3 experiments:
  1. Train the initial logistic regression model and evaluate its performance and fairness metrics (AUROC, EOD) to establish a baseline.
  2. Apply the fairness optimization with different regularization strengths and observe the impact on performance and fairness metrics.
  3. Generate and compare SHAP explanations for the original and fairness-optimized models to identify changes in feature importance and interpret their clinical implications.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the ExplainableFair framework's fairness enhancement process differ when applied to different sensitive attributes (e.g., race vs. sex) in substance use disorder treatment prediction?
- Basis in paper: [explicit] The paper applies the framework to race and sex as sensitive attributes, showing different feature importance changes and EOD improvements for each.
- Why unresolved: The paper presents results for race and sex separately but doesn't compare the mechanisms or explain why the feature changes differ between these attributes.
- What evidence would resolve it: Comparative analysis of the feature importance change patterns and fairness improvement mechanisms between race and sex fairness optimization.

### Open Question 2
- Question: How generalizable is the ExplainableFair framework to other healthcare domains beyond substance use disorder treatment?
- Basis in paper: [inferred] The framework is developed and tested specifically on SUD treatment completion prediction, with no mention of application to other medical conditions.
- Why unresolved: The paper doesn't explore the framework's applicability to different healthcare prediction tasks or discuss its limitations in other contexts.
- What evidence would resolve it: Application of the framework to at least 2-3 other healthcare prediction tasks with documented performance and fairness outcomes.

### Open Question 3
- Question: What is the long-term impact of using fairness-optimized models on patient outcomes in substance use disorder treatment?
- Basis in paper: [explicit] The paper discusses clinical implications of feature changes but doesn't examine actual treatment outcomes after implementing the fairness-optimized model.
- Why unresolved: The study focuses on model development and explanation but lacks longitudinal data on patient outcomes following model implementation.
- What evidence would resolve it: Multi-year follow-up study comparing treatment outcomes between populations treated using the fairness-optimized model versus traditional approaches.

## Limitations

- The framework relies on Equalized Odds as the primary fairness metric, which may not be the most appropriate fairness criterion for all clinical contexts or sensitive attributes.
- The two-stage approach of decoupling performance optimization from fairness enhancement may limit the framework's ability to find global optima where both objectives are simultaneously maximized.
- The clinical significance and practical utility of the SHAP-based explanations for fairness changes require additional validation in real-world substance use disorder treatment settings.

## Confidence

- **High Confidence**: The framework's basic architecture and methodology are sound, with clear implementation steps and well-defined fairness metrics.
- **Medium Confidence**: The predictive performance and fairness improvements are demonstrated, but the clinical interpretation of feature importance changes requires additional validation.
- **Low Confidence**: The generalizability of the framework to other healthcare domains and the long-term stability of the fairness enhancements need further investigation.

## Next Checks

1. Conduct a sensitivity analysis of the Equalized Odds disparity regularization strength to identify the optimal balance between performance and fairness across different healthcare domains.
2. Perform a comprehensive clinical validation study to assess the practical utility and interpretability of the SHAP-based explanations for fairness changes in real-world substance use disorder treatment settings.
3. Extend the framework to incorporate additional fairness metrics (e.g., Demographic Parity, Equal Opportunity) and compare their effectiveness in addressing bias across different sensitive attributes and healthcare applications.