---
ver: rpa2
title: Vision-Language Models are Strong Noisy Label Detectors
arxiv_id: '2409.19696'
source_url: https://arxiv.org/abs/2409.19696
tags:
- noisy
- deft
- label
- noise
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DEFT, a denoising fine-tuning framework for
  adapting vision-language models to noisy datasets. DEFT uses dual textual prompts
  to identify noisy labels and employs parameter-efficient fine-tuning for robust
  adaptation.
---

# Vision-Language Models are Strong Noisy Label Detectors

## Quick Facts
- arXiv ID: 2409.19696
- Source URL: https://arxiv.org/abs/2409.19696
- Reference count: 40
- Pre-trained vision-language models (like CLIP) excel at detecting noisy labels in image datasets

## Executive Summary
This paper introduces DEFT, a denoising fine-tuning framework that leverages pre-trained vision-language models to detect and filter noisy labels in image datasets. The method uses dual textual prompts (positive and negative) to identify clean samples through similarity scoring, followed by parameter-efficient fine-tuning for robust adaptation. DEFT outperforms existing methods on both noisy label detection and image classification tasks, achieving up to 4.58% higher precision and 14.42% higher recall in label detection, with classification accuracy improvements of up to 4.34% on fine-grained datasets.

## Method Summary
DEFT operates in two phases: Phase 1 uses dual textual prompts (positive and negative) with parameter-efficient fine-tuning (PEFT) to detect clean samples by comparing image-text similarity scores, while Phase 2 performs full fine-tuning on the curated clean subset. The dual prompt mechanism learns class-specific features and establishes a learnable threshold for separating clean from noisy samples, leveraging the strong multi-modal alignment of pre-trained vision-language models like CLIP. This approach preserves pre-trained representations while effectively handling noisy labels.

## Key Results
- DEFT achieves up to 4.58% higher precision and 14.42% higher recall in noisy label detection compared to existing methods
- Classification accuracy improves by up to 4.34% on fine-grained datasets (Stanford Cars, CUB-200-2011) when using DEFT
- DEFT outperforms all baseline methods across seven datasets including CIFAR-100N, Clothing1M, and WebVision

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual textual prompts (positive and negative) act as a learnable threshold to separate clean from noisy labels by comparing similarity scores between image embeddings and prompts.
- Mechanism: The positive prompt is trained to align with clean image features from its class, while the negative prompt defines a similarity threshold. Samples with higher similarity to the positive prompt than the negative are classified as clean.
- Core assumption: Pre-trained vision-language models have robust multi-modal alignment that remains effective even with noisy labels, allowing prompt-based thresholding to work.
- Evidence anchors:
  - [abstract] "The positive prompt seeks to reveal distinctive features of the class, while the negative prompt serves as a learnable threshold for separating clean and noisy samples."
  - [section 4.1] "We design a class-specific pair of positive and negative prompts... The positive prompt aims to uncover distinguishable features by maximizing the similarity between the image features and their corresponding text features, while the negative prompt serves as a learnable sample-dependent similarity threshold to select clean data."
- Break condition: If the multi-modal alignment degrades significantly under noise, the prompt-based thresholding will fail to reliably distinguish clean from noisy samples.

### Mechanism 2
- Claim: Parameter-efficient fine-tuning (PEFT) preserves pre-trained feature representations better than full fine-tuning (FFT) when adapting to noisy datasets, making it more effective for noisy label detection.
- Mechanism: PEFT adds only a small number of learnable parameters while keeping pre-trained parameters frozen, reducing the risk of overfitting to noisy labels and preserving generalization from pre-training.
- Core assumption: FFT introduces too many trainable parameters, which can lead to feature distortion when noisy labels are present, whereas PEFT's constrained parameter space provides implicit regularization.
- Evidence anchors:
  - [section 3.2] "VPT benefits representation learning in the presence of massive noisy labels... While FFT yields significant performance on curated datasets, recent work [1] empirically finds that FFT can result in feature distortion in the presence of massive noisy labels."
  - [section 3.2] "In contrast, VPT benefits representation learning when adapting CLIP on noisy data, particularly under high levels of noise."
- Break condition: If the noise level is very low or the dataset is clean, the regularization benefit of PEFT may be outweighed by FFT's ability to adapt more completely to the target domain.

### Mechanism 3
- Claim: The two-phase approach (noisy label detection followed by model adaptation on clean samples) enables both accurate label filtering and task-specific fine-tuning without catastrophic forgetting.
- Mechanism: Phase 1 uses dual prompts and PEFT to identify clean samples and improve image-text alignment. Phase 2 uses FFT on the curated clean subset to adapt the model for the specific downstream task while benefiting from noise-free supervision.
- Core assumption: The clean subset identified in Phase 1 is sufficiently large and representative to enable effective adaptation in Phase 2, and FFT on clean data provides better task-specific performance than PEFT.
- Evidence anchors:
  - [section 4.3] "In the second phase, we can adapt the pre-trained model after acquiring carefully selected clean samples... we learn a linear classifier and fully fine-tune the visual encoders using only selected clean samples."
  - [section 5.4] "Figure 3 demonstrates the test accuracy of DEFT without the model adaptation phase (w/o adap.), adaptation utilizing PEFT and FFT. Results show that fully fine-tuning the model on selected clean samples yields the best classification performance."
- Break condition: If Phase 1 fails to identify a sufficient proportion of clean samples (low recall), Phase 2 will lack enough data for effective adaptation.

## Foundational Learning

- Concept: Multi-modal representation learning (vision-language alignment)
  - Why needed here: DEFT relies on strong alignment between visual and textual features in pre-trained models to implement prompt-based noisy label detection.
  - Quick check question: What property of CLIP enables it to classify images using textual prompts without additional training?

- Concept: Parameter-efficient fine-tuning techniques (VPT, LoRA, etc.)
  - Why needed here: PEFT is used in Phase 1 to adapt the visual encoder while preserving pre-trained representations and avoiding overfitting to noisy labels.
  - Quick check question: How does PEFT differ from FFT in terms of parameter updates and what advantage does this provide for noisy label scenarios?

- Concept: Noisy label learning paradigms (sample selection vs. robust loss functions)
  - Why needed here: Understanding these paradigms helps explain why DEFT uses sample selection (via prompts) rather than robust loss functions.
  - Quick check question: What are the two main categories of approaches for handling noisy labels in deep learning?

## Architecture Onboarding

- Component map: Pre-trained CLIP model (ViT-B/16 + Transformer text encoder) -> PEFT modules (VPT) -> Dual textual prompts (positive/negative per class) -> Noisy label detector (similarity-based classifier) -> Linear classifier -> Training pipeline with two phases

- Critical path: Pre-trained model → PEFT adaptation + dual prompt learning → clean sample selection → FFT on clean samples → final classifier

- Design tradeoffs:
  - Using PEFT vs. FFT: PEFT preserves pre-trained features better under noise but may underfit; FFT adapts more completely but risks overfitting to noise
  - Dual prompts vs. single prompt: Dual prompts enable learnable thresholding but increase complexity; single prompts are simpler but require manual threshold setting
  - Two-phase vs. single-phase: Two-phase enables cleaner adaptation but adds computational overhead; single-phase is simpler but may not handle noise as effectively

- Failure signatures:
  - Low precision in Phase 1: Too many noisy samples classified as clean, leading to poor Phase 2 performance
  - Low recall in Phase 1: Too few clean samples identified, leading to insufficient data for Phase 2
  - Degraded performance on clean datasets: Indicates Phase 1 is over-aggressive in filtering or Phase 2 is not adapting well

- First 3 experiments:
  1. Implement Phase 1 only on a synthetic noisy dataset and measure precision/recall of clean sample selection
  2. Compare PEFT vs. FFT adaptation in Phase 1 on noisy data to verify feature preservation claims
  3. Run full two-phase pipeline on a clean dataset to confirm that Phase 1 doesn't degrade performance when labels are actually clean

## Open Questions the Paper Calls Out
None

## Limitations

- The framework's effectiveness depends heavily on the quality of multi-modal alignment in pre-trained vision-language models, which may degrade under extreme noise levels
- Generalization to vision-language models beyond CLIP remains unverified, limiting claims about broader applicability
- The two-phase approach adds computational overhead compared to single-phase methods, potentially limiting scalability

## Confidence

- **High confidence**: The superiority of DEFT over existing methods in both noisy label detection and image classification tasks is well-supported by experimental results across multiple datasets and noise types.
- **Medium confidence**: The claim that PEFT preserves pre-trained features better than FFT in noisy scenarios is supported by empirical comparisons but lacks theoretical justification for why this occurs.
- **Low confidence**: The assertion that DEFT generalizes to other pre-trained vision-language models is currently speculative, as only CLIP-based experiments are reported.

## Next Checks

1. Test DEFT's performance on vision-language models beyond CLIP (e.g., BLIP, ALBEF) to verify generalizability claims.
2. Conduct ablation studies to determine the maximum noise level at which DEFT remains effective, identifying potential failure points.
3. Compare DEFT against robust loss function approaches on the same datasets to better understand the relative merits of sample selection versus loss correction strategies.