---
ver: rpa2
title: 'Large Language Models for Scientific Information Extraction: An Empirical
  Study for Virology'
arxiv_id: '2401.10040'
source_url: https://arxiv.org/abs/2401.10040
tags:
- question
- values
- disease
- instruction
- covid-19
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a novel automated approach for complex scientific
  information extraction in the domain of Virology, specifically for extracting structured
  summaries of research contributions on the basic reproduction number (R0) estimate
  for infectious diseases. The method involves instruction-based finetuning of the
  FLAN-T5 Large language model with 780M parameters using a corpus of 1,500 annotated
  scholarly article abstracts.
---

# Large Language Models for Scientific Information Extraction: An Empirical Study for Virology

## Quick Facts
- arXiv ID: 2401.10040
- Source URL: https://arxiv.org/abs/2401.10040
- Authors: Mahsa Shamsabadi; Jennifer D'Souza; SÃ¶ren Auer
- Reference count: 21
- Primary result: ORKG-FLAN-T5R0 (780M parameters) achieved 55.89% F1 score, outperforming GPT3.5-davinci (175B parameters) for R0 extraction from virology abstracts

## Executive Summary
This work presents a novel automated approach for complex scientific information extraction in virology, specifically for extracting structured summaries of research contributions on R0 estimates from scholarly article abstracts. The method involves instruction-based finetuning of the FLAN-T5 Large language model (780M parameters) using a corpus of 1,500 annotated scholarly article abstracts. The finetuned model, ORKG-FLAN-T5R0, generates structured summaries in both text and JSON formats containing property-value pairs for disease name, location, date, R0 value, confidence interval values, and method. The approach demonstrates that a moderately-sized instruction-tuned LLM can effectively perform complex information extraction tasks in scientific domains.

## Method Summary
The study uses single-task instruction-based finetuning of FLAN-T5 Large (780M parameters) with 18 instructions from the FLAN 2022 Collection (SQuAD_v2 and DROP datasets). The corpus consists of 1,500 annotated scholarly article abstracts from the CORD-19 dataset, filtered to include articles on R0 estimates. The model is fine-tuned to extract structured information following the ORKG-R0 schema with six properties: disease name, location, date, R0 value, %CI values, and method. The approach uses a single-instruction tuning strategy where the model is fine-tuned with each instruction separately, then the best-performing instructions are combined for final evaluation.

## Key Results
- ORKG-FLAN-T5R0 achieved an overall F1 score of 55.89% for text answers and 55.28% for JSON answers on the held-out test set
- The model outperformed GPT3.5-davinci (175B parameters) despite having 1000x fewer parameters
- Performance varied significantly across properties: disease name (78.11% F1) and location (68.52% F1) performed well, while date (33.78% F1) and method (18.74% F1) showed lower performance
- For answerable questions, ORKG-FLAN-T5R0 correctly answered 95.6% of questions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Single-task instruction finetuning of an instruction-tuned LLM improves domain-specific performance
- Mechanism: Fine-tuning FLAN-T5 with task-specific instructions and domain-relevant data adapts the model to the R0 extraction task
- Core assumption: The model can learn to map abstract task instructions to domain-specific structured outputs
- Evidence anchors:
  - [abstract]: "Our results show that finetuned FLAN-T5 with 1000x fewer parameters than the state-of-the-art GPT-davinci is competitive for the task."
  - [section 4]: "Our approach differs from finetuning a pretrained LM as we instead finetune an instruction-tuned LM, enabling the model to effectively follow instructions it has been trained on and adapt to a new domain and complex IE task, without the need to handle variability in learning new instruction formats."

### Mechanism 2
- Claim: Using a moderately-sized LLM (780M parameters) is sufficient for the complex IE task
- Mechanism: The FLAN-T5-Large model (780M parameters) is chosen as a balance between model capacity and practicality for deployment
- Core assumption: A moderately-sized model can handle the complexity of the R0 extraction task without requiring excessive computational resources
- Evidence anchors:
  - [section 4.1]: "We choose the Large model as a middle ground between the Small and XXL models, providing enough parameters for our complex IE task and practicality for deployment."
  - [abstract]: "Our results show that finetuned FLAN-T5 with 1000x fewer parameters than the state-of-the-art GPT-davinci is competitive for the task."

### Mechanism 3
- Claim: The structured property-value format (ORKG -R0) effectively captures the essential aspects of R0 estimates
- Mechanism: The R0 extraction task is defined using six properties: disease name, location, date, R0 value, %CI values, and method, which are modeled to be generic enough to structure most related research on the R0 estimate and specialized enough to reflect the vital details of the R0 contribution
- Core assumption: The chosen properties adequately represent the key information needed to understand and compare R0 estimates across different studies
- Evidence anchors:
  - [section 3]: "The R0 estimate pertains to an infectious disease (disease name), for a specific population demographic (location), with validity for a specific time period (date). It reports a specific value (R0 value), along with a confidence interval for the statistical value (%CI values), and is computed by a statistical method (method)."
  - [abstract]: "Our novel automated approach leverages the robust text generation capabilities of LLMs to produce structured scholarly contribution summaries, offering both a practical solution and insights into LLMs' emergent abilities."

## Foundational Learning

- Concept: Information Extraction (IE)
  - Why needed here: The core task involves extracting structured information from unstructured text, which is a fundamental IE problem
  - Quick check question: What are the key differences between traditional IE methods and the LLM-based approach used in this work?

- Concept: Instruction Tuning
  - Why needed here: The approach relies on fine-tuning an instruction-tuned LLM, which requires understanding how instruction tuning works and its benefits
  - Quick check question: How does instruction tuning differ from traditional fine-tuning, and what are its advantages for this task?

- Concept: Knowledge Graphs (KGs)
  - Why needed here: The structured summaries are stored in a knowledge graph format (ORKG), which requires familiarity with KGs and their applications in scholarly communication
  - Quick check question: What are the benefits of using a knowledge graph for representing and querying scholarly contributions compared to traditional text-based methods?

## Architecture Onboarding

- Component map: Corpus (1,500 annotated abstracts) -> FLAN-T5-Large (780M) -> Fine-tuning with SQuAD_v2/DROP instructions -> ORKG-R0 structured output (text/JSON)

- Critical path:
  1. Prepare the corpus and annotations
  2. Select and instantiate task-specific instructions
  3. Fine-tune the FLAN-T5 model
  4. Evaluate the model's performance on the test set
  5. Analyze errors and iterate on the approach

- Design tradeoffs:
  - Model size vs. performance: Choosing a moderately-sized model (780M) balances performance and practicality
  - Instruction selection: Using a subset of the FLAN collection instructions vs. all instructions
  - Output format: Text-based vs. JSON-based structured summaries

- Failure signatures:
  - Low F1 scores on individual properties (e.g., date, method) indicate issues with extracting specific information
  - High error rates for unanswerable questions suggest the model struggles to distinguish between answerable and unanswerable contexts
  - Typographical errors in the extracted values indicate the need for normalization and standardization

- First 3 experiments:
  1. Fine-tune the FLAN-T5 model with a single instruction and evaluate its performance on the test set
  2. Fine-tune the model with all instructions and compare its performance to the single-instruction model
  3. Fine-tune the model with the best instructions (based on single-instruction results) and evaluate its performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ORKG-FLAN-T5R0 scale with increasing model size?
- Basis in paper: [inferred] The paper mentions that larger models like GPT3.5-davinci (175B parameters) were outperformed by ORKG-FLAN-T5R0 (780M parameters), but does not explore scaling ORKG-FLAN-T5R0 itself to larger sizes
- Why unresolved: The paper focuses on demonstrating the effectiveness of instruction-tuned models for single-task finetuning, rather than exploring model scaling. It also mentions that scaling up the model size was not the direction chosen for this work
- What evidence would resolve it: Conducting experiments with larger versions of ORKG-FLAN-T5R0 (e.g., XL 3B, XXL 11B) and comparing their performance to the 780M model on the ORKG-R0 complex IE task

### Open Question 2
- Question: How does ORKG-FLAN-T5R0 perform on other scientific information extraction tasks beyond the R0 estimate research problem?
- Basis in paper: [inferred] The paper introduces ORKG-FLAN-T5R0 for the specific task of extracting structured summaries of R0 estimate research contributions, but does not evaluate its performance on other scientific IE tasks
- Why unresolved: The paper focuses on a single use case in virology and does not explore the generalizability of ORKG-FLAN-T5R0 to other scientific domains or IE tasks
- What evidence would resolve it: Evaluating ORKG-FLAN-T5R0 on a diverse set of scientific IE tasks, such as extracting information about clinical trial results, gene-disease associations, or chemical compound properties, and comparing its performance to other models

### Open Question 3
- Question: How does the performance of ORKG-FLAN-T5R0 compare to other instruction-tuned models for the ORKG-R0 task?
- Basis in paper: [inferred] The paper compares ORKG-FLAN-T5R0 to T5, FLAN-T5, and GPT3.5-davinci, but does not evaluate its performance against other instruction-tuned models that could be applicable to the ORKG-R0 task
- Why unresolved: The paper focuses on demonstrating the effectiveness of instruction-tuning within the T5 model family and does not explore other instruction-tuned models that could be suitable for the task
- What evidence would resolve it: Evaluating ORKG-FLAN-T5R0 against other instruction-tuned models, such as PaLM, Chinchilla, or ChatGPT, on the ORKG-R0 complex IE task and comparing their performance in terms of accuracy, efficiency, and other relevant metrics

## Limitations

- The moderate F1 scores (55.89% text, 55.28% JSON) indicate substantial room for improvement, particularly in extracting confidence intervals and methods
- The 1,500-abstract corpus may not capture the full diversity of R0 estimation contexts across all infectious diseases
- The evaluation relies on a single knowledge graph schema (ORKG-R0), limiting assessment of the approach's flexibility for other scientific domains

## Confidence

High confidence: The core finding that FLAN-T5 (780M) outperforms GPT3.5-davinci (175B) for this specific task is well-supported by the experimental results and represents a meaningful contribution demonstrating that instruction-tuned models can be effective for single-task fine-tuning in scientific IE.

Medium confidence: The assertion that single-task instruction fine-tuning is superior to other approaches for this domain requires more extensive ablation studies. While the results are promising, comparison with alternative fine-tuning strategies (multi-task, parameter-efficient methods) and other model architectures would strengthen this claim.

Low confidence: The generalizability of the instruction collection (SQuAD_v2 and DROP) for scientific IE tasks beyond R0 extraction is questionable. The specific instructions that worked well for this task may not transfer to other scientific domains or information extraction objectives without substantial modification.

## Next Checks

1. **Ablation study on instruction selection**: Systematically test the contribution of each instruction from the FLAN collection by fine-tuning separate models with individual instructions and combinations. This would identify which specific instructions drive performance gains and whether the full instruction set is necessary.

2. **Cross-domain transferability evaluation**: Apply the best-performing model to a different scientific domain (e.g., climate science or materials science) with a similar structured extraction task to assess whether the instruction-tuning approach generalizes beyond virology.

3. **Error analysis with human evaluation**: Conduct a detailed qualitative analysis of the model's errors, particularly focusing on the 45% of predictions that don't match the gold standard. This should include human assessment of whether certain errors represent reasonable alternative interpretations versus fundamental failures in understanding.