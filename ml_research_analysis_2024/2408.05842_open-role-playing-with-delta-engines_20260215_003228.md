---
ver: rpa2
title: Open Role-Playing with Delta-Engines
arxiv_id: '2408.05842'
source_url: https://arxiv.org/abs/2408.05842
tags:
- power
- effect
- type
- accuracy
- self
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes open role-playing games (ORPGs), a new style
  of game-play that bridges self-expression and role-playing by allowing players to
  craft and embody unique characters in the game world. The core method is a delta-engine,
  which consists of a base engine that programs the prototype of the character and
  foundational game settings, and a neural proxy that realizes character growth by
  generating new code snippets on the base engine incrementally based on observations.
---

# Open Role-Playing with Delta-Engines

## Quick Facts
- arXiv ID: 2408.05842
- Source URL: https://arxiv.org/abs/2408.05842
- Reference count: 25
- Primary result: Delta-engine achieves 100% execution rate and 86% accuracy on Pokemon-based game after full training

## Executive Summary
This paper introduces delta-engines for open role-playing games, a novel approach that enables characters to evolve through incremental code generation. The system combines a base engine defining game mechanics with a neural proxy that generates new code snippets based on observations, allowing for continuous character growth. A human-AI collaborative design process leverages prototypes and tags of interest to produce novel and interesting game content efficiently. The approach is evaluated on a Pokemon-based game, demonstrating strong performance in both execution and functional correctness.

## Method Summary
The delta-engine consists of a base engine implementing core game mechanics and a neural proxy (LLM) that generates incremental code changes based on observations. The method uses engine-oriented fine-tuning where the base engine is converted into instruction-tuning data to align the LLM with the game's codebase. A human-AI collaborative design process employs explicit prototypes and tags of interest to guide the generation of novel role scripts, which are then converted to code and evaluated for interestingness before being integrated into the engine.

## Key Results
- Delta-engine achieves nearly 100% execution rate on easy test data
- Model achieves 86% accuracy on hard test data after full training exposure
- Human-AI collaborative design produces novel and interesting game content efficiently

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Delta-engine enables continuous character growth by incrementally generating code snippets based on observations.
- Mechanism: The neural proxy LLM generates new code that builds upon the base engine state, allowing characters to evolve with new abilities and properties over time.
- Core assumption: The LLM can effectively generate syntactically correct and semantically meaningful code that integrates with the existing base engine.
- Evidence anchors:
  - [abstract] "The neural proxy is an LLM, which realizes the character growth by generating new code snippets on the base engine incrementally based on observations."
  - [section] "Incremental Prediction Given an observation, a delta-engine seeks to predict the incremental value (e.g. inheritance, overloading, adding) based on the current engine state."
  - [corpus] Weak - corpus neighbors do not directly discuss incremental code generation.
- Break condition: If the LLM generates code that fails to compile or introduces errors that break existing functionality.

### Mechanism 2
- Claim: Engine-oriented fine-tuning aligns the LLM with the base engine, enabling it to generate contextually appropriate code.
- Mechanism: The base engine is converted into an instruction-tuning dataset, where each sample corresponds to a method and its enhancement instructions. The LLM is then fine-tuned on these engine-correlated instructions.
- Core assumption: The LLM can learn the alignment between natural language descriptions and code implementations of the base engine methods.
- Evidence anchors:
  - [section] "We evaluate FE by further fine-tuning the model. Specifically, we convert the base engine into an instruction-tuning dataset... The LLM proxy is then fine-tuned on these engine-correlated instructions to learn the alignment between the base engine's implementation and natural language, integrating the entire E into the model."
  - [abstract] "We an engine-oriented fine-tuning method that embeds the base engine into the proxy."
  - [corpus] Weak - corpus neighbors do not discuss engine-oriented fine-tuning.
- Break condition: If the fine-tuning process does not effectively capture the semantics and syntax of the base engine code.

### Mechanism 3
- Claim: The human-AI collaborative design process produces novel and interesting data by leveraging prototypes and tags of interest.
- Mechanism: Human designers provide prototypes (real-world or fictional entities) that inspire the LLM to generate novel role scripts. The generated scripts are then converted to code and evaluated using tags of interest, which quantify interestingness based on potential factors.
- Core assumption: LLMs can generate creative and diverse content when provided with explicit prototypes, and the tags of interest effectively capture the interestingness of the generated roles.
- Evidence anchors:
  - [section] "We conjecture that LLMs lack or even do not have imagination; their creative outputs are still guided by the prompts they receive... We propose to leverage an explicit prototype, a specific entity described in a paragraph, as the imaginative foundation."
  - [abstract] "We then discuss a human-AI collaborative design process to produce novel and interesting data efficiently."
  - [corpus] Weak - corpus neighbors do not discuss human-AI collaborative design for game role generation.
- Break condition: If the prototypes do not effectively inspire the LLM, or if the tags of interest fail to capture the interestingness of the generated roles.

## Foundational Learning

- Concept: Incremental code generation
  - Why needed here: The delta-engine relies on the LLM's ability to generate new code snippets that build upon the existing base engine state, enabling continuous character growth.
  - Quick check question: What is the purpose of the incremental prediction process in the delta-engine?

- Concept: Engine-oriented fine-tuning
  - Why needed here: The base engine can be too large for the LLM to handle directly. Engine-oriented fine-tuning aligns the LLM with the base engine, allowing it to generate contextually appropriate code.
  - Quick check question: How does engine-oriented fine-tuning help the LLM generate code that integrates with the base engine?

- Concept: Human-AI collaborative design
  - Why needed here: LLMs struggle to generate novel and interesting content on their own. The human-AI collaborative design process leverages human creativity and explicit prototypes to inspire the LLM and produce high-quality data.
  - Quick check question: What is the role of prototypes in the human-AI collaborative design process?

## Architecture Onboarding

- Component map: Base Engine -> Neural Proxy (LLM) -> Human-AI Collaborative Design -> Engine-oriented Fine-tuning
- Critical path: Human provides prototype → LLM generates role script → Script converted to code → Code evaluated using tags of interest → Code added to base engine
- Design tradeoffs:
  - Reusing existing LLMs vs. training a custom model from scratch (tradeoff between development time and model performance)
  - Using natural language instructions vs. structured scripts for LLM inputs (tradeoff between flexibility and control)
  - Human involvement in data generation vs. fully automated synthetic data (tradeoff between creativity and scalability)
- Failure signatures:
  - LLM generates code that fails to compile or introduces errors
  - Generated roles lack novelty or interestingness
  - Engine-oriented fine-tuning does not effectively align the LLM with the base engine
- First 3 experiments:
  1. Test the LLM's ability to generate syntactically correct code snippets that extend the base engine with simple new methods
  2. Evaluate the effectiveness of engine-oriented fine-tuning by comparing the LLM's code generation before and after fine-tuning on the base engine dataset
  3. Assess the quality of the human-AI collaborative design process by measuring the novelty and interestingness of the generated roles compared to a baseline without prototypes or tags of interest

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental limits of LLM-based delta-engines in handling complex state transitions and maintaining coherence over long sequences of incremental updates?
- Basis in paper: [inferred] The paper discusses incremental prediction and the scalability concerns of LLM proxies, but does not rigorously test the limits of the model's ability to maintain coherence over extended sequences of code generation and state updates.
- Why unresolved: The evaluation focuses on correctness and execution rates, but does not explore how well the model maintains consistency and coherence when generating numerous incremental updates over a long period or in complex scenarios.
- What evidence would resolve it: Experiments testing the model's performance on increasingly long sequences of incremental updates, measuring the coherence and consistency of the generated code and the resulting game state.

### Open Question 2
- Question: How does the human-AI collaborative design process scale to larger and more complex virtual worlds with diverse and numerous objects?
- Basis in paper: [explicit] The paper discusses the human-AI co-design process for generating training data, but only demonstrates it on a relatively small-scale Pokemon-based game.
- Why unresolved: The paper does not address how this process would work for a larger, more complex virtual world with a vast number of objects and interactions, and whether the current methods for generating and filtering data would remain effective.
- What evidence would resolve it: Demonstrations of the human-AI co-design process applied to a larger virtual world, with metrics on the efficiency and quality of the generated data compared to the Pokemon-based game.

### Open Question 3
- Question: Can the delta-engine approach be generalized to other types of games or virtual worlds beyond role-playing games, and what are the specific challenges and adaptations required?
- Basis in paper: [inferred] The paper presents delta-engines in the context of an open role-playing game, but does not explore its applicability to other game genres or virtual world applications.
- Why unresolved: The paper does not discuss the potential challenges or necessary adaptations for applying delta-engines to different types of games or virtual worlds, such as strategy games, simulations, or social platforms.
- What evidence would resolve it: Case studies or experiments applying delta-engines to different types of games or virtual worlds, with analysis of the challenges encountered and the modifications required to the delta-engine framework.

## Limitations

- Evaluation limited to a single Pokemon-based game domain, limiting generalizability
- Human-AI collaborative design process relies on assumptions about LLM creativity that aren't fully validated
- Engine-oriented fine-tuning requires substantial base engine code, which may not scale well for larger games

## Confidence

- **High Confidence**: The core mechanism of using a neural proxy to generate incremental code changes based on observations is well-supported by the described architecture and implementation details.
- **Medium Confidence**: The human-AI collaborative design process shows promise but lacks detailed validation of how effectively prototypes inspire novel content generation.
- **Low Confidence**: Claims about the scalability and generalizability of delta-engines to other game genres and more complex scenarios are not sufficiently supported by the current evaluation.

## Next Checks

1. Test the delta-engine on a fundamentally different game genre (e.g., strategy or simulation) to assess generalizability beyond Pokemon-style games.
2. Create scenarios where the LLM must generate code that modifies or extends existing functionality in non-trivial ways to test incremental prediction robustness.
3. Run extended simulations where characters evolve over hundreds or thousands of incremental steps to evaluate long-term sustainability and code quality maintenance.