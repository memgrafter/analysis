---
ver: rpa2
title: Is Complexity an Illusion?
arxiv_id: '2404.07227'
source_url: https://arxiv.org/abs/2404.07227
tags:
- complexity
- which
- then
- abstraction
- sample
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between simplicity and
  generalisation in artificial intelligence, challenging the widely-held belief that
  simpler models are inherently better. The author argues that complexity is an illusion
  created by abstraction layers, and that the correlation between simplicity and generalisation
  is due to confounding factors.
---

# Is Complexity an Illusion?

## Quick Facts
- arXiv ID: 2404.07227
- Source URL: https://arxiv.org/abs/2404.07227
- Authors: Michael Timothy Bennett
- Reference count: 34
- Primary result: Complexity is an illusion created by abstraction layers; simplicity-generalization correlation is due to confounding factors

## Executive Summary
This paper challenges the widely-held belief that simpler models are inherently better by arguing that complexity is an illusion created by abstraction layers. The author presents a formalism for environments and abstraction layers, proving that in the absence of abstraction, all behaviors have equal complexity. The paper demonstrates that when vocabularies are finite (as in real-world systems), policy weakness can confound sample efficiency with policy simplicity, explaining why simpler models often generalize better without implying a causal relationship between simplicity and intelligence.

## Method Summary
The paper develops a mathematical formalism for environments and abstraction layers, defining environments as sets of states and abstraction layers as vocabularies (subsets of declarative programs). The author proves two key propositions: first, that complexity is subjective and can always be minimized without improving sample efficiency when no abstraction exists; second, that policy weakness confounds sample efficiency with simplicity in finite vocabularies. The analysis builds on prior experimental work referenced in [18] and relies on concepts of goal-directed processes and efficiency demands.

## Key Results
- Complexity is an illusion created by abstraction layers rather than an inherent property
- In finite vocabularies, weaker policies take simpler forms due to efficiency demands and need for versatility
- The correlation between simplicity and generalization is due to confounding, not causation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Complexity is an illusion created by abstraction layers, and the correlation between simplicity and generalization is due to confounding factors.
- Mechanism: When there is no abstraction (vocabulary equals all declarative programs), all behaviors have equal complexity regardless of their weakness. However, in finite vocabularies (which represent real-world systems), weaker policies tend to take simpler forms because abstraction layers are goal-directed and efficiency demands versatile behavior.
- Core assumption: Vocabularies are finite in real-world systems, and abstraction layers are goal-directed processes that favor versatility.
- Evidence anchors:
  - [abstract] "The author argues that complexity is an illusion created by abstraction layers, and that the correlation between simplicity and generalization is due to confounding factors."
  - [section] "Proposition 1 (subjectivity). If there is no abstraction, complexity can always be minimized without improving sample efficiency, regardless of the task."
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.479, average citations=0.0. Top related titles: "Comment on Is Complexity an Illusion?" (evidence of community engagement with this topic).
- Break condition: If vocabularies were infinite, or if abstraction layers were not goal-directed, the correlation between simplicity and generalization would not necessarily hold.

### Mechanism 2
- Claim: Sample efficiency and simplicity tend to be correlated because weaker policies take simpler forms in finite vocabularies.
- Mechanism: When vocabularies are finite and tasks are uniformly distributed, weak statements (policies) take simple forms because they need to be versatile and efficient. This creates a confounding relationship where simplicity appears to cause better generalization, but actually weakness is the causal factor.
- Core assumption: Tasks are uniformly distributed and natural selection or other goal-directed processes favor versatile behavior.
- Evidence anchors:
  - [abstract] "The author argues that abstraction layers are goal-directed, and that weaker policies tend to take simpler forms in finite vocabularies due to the need for versatility and efficiency."
  - [section] "Proposition 2 (confounding). If the vocabulary is finite, then policy weakness can confound sample efficiency with policy simplicity."
  - [corpus] "Found 25 related papers" - indicates this is an active area of research with multiple perspectives.
- Break condition: If tasks were not uniformly distributed, or if goal-directed processes did not favor versatility, the correlation between simplicity and generalization would break down.

### Mechanism 3
- Claim: Complexity has no causal influence on generalization, but appears to due to confounding.
- Mechanism: In finite vocabularies, when weaker policies take simpler forms (due to efficiency demands), simplicity becomes correlated with sample efficiency. This creates the illusion that simplicity causes better generalization, when actually weakness is the causal factor that gets confounded with simplicity.
- Core assumption: Efficiency demands that weaker policies take simpler forms in finite vocabularies.
- Evidence anchors:
  - [abstract] "The author argues that abstraction layers are goal-directed, and that weaker policies tend to take simpler forms in finite vocabularies due to the need for versatility and efficiency. This explains why simpler models often generalise better in practice, without implying a causal relationship between simplicity and intelligence."
  - [section] "If function is determined by a goal directed process that favours versatility (e.g. natural selection), then efficiency demands weak constraints take simple forms."
  - [corpus] Corpus signals show moderate relatedness (average FMR=0.479) suggesting this is a nuanced topic with multiple interpretations.
- Break condition: If efficiency did not demand simpler forms for weaker policies, or if vocabularies were not finite, the confounding relationship would not exist.

## Foundational Learning

- Concept: Abstraction layers and vocabularies
  - Why needed here: Understanding that complexity is created by abstraction layers and that finite vocabularies are key to the confounding relationship
  - Quick check question: What happens to the concept of complexity when the vocabulary equals all declarative programs?

- Concept: Weakness vs. simplicity in policies
  - Why needed here: Distinguishing between the actual causal factor (weakness) and the confounded factor (simplicity) that appears to correlate with generalization
  - Quick check question: How does the weakness of a policy relate to its sample efficiency according to the paper?

- Concept: Goal-directed processes and efficiency
  - Why needed here: Understanding why abstraction layers favor versatile behavior and why this leads to weaker policies taking simpler forms
  - Quick check question: Why do abstraction layers tend to minimize vocabulary size while maximizing the weakness of expressible policies?

## Architecture Onboarding

- Component map:
  - Environment (Φ): Set of states
  - Abstraction layer: Vocabulary (v) subset of declarative programs
  - Formal language (Lv): Set of statements (aspects)
  - Tasks (Γv): Pairs of inputs and correct outputs
  - Policies (Πα): Correct policies for each task
  - Proxies (<): Relations measuring weakness and simplicity
  - Learning/inference system: Uses proxies to select policies

- Critical path:
  1. Define environment and abstraction layer
  2. Specify vocabulary and formal language
  3. Create tasks with inputs and outputs
  4. Implement policy selection using proxies
  5. Measure sample efficiency and policy weakness
  6. Analyze correlation between simplicity and generalization

- Design tradeoffs:
  - Vocabulary size vs. expressiveness: Larger vocabularies increase expressiveness but make inference/learning more complex
  - Abstraction level vs. efficiency: Higher abstraction layers can be more efficient but may lose important details
  - Simplicity proxy vs. weakness proxy: Simplicity is easier to measure but weakness is the actual causal factor

- Failure signatures:
  - No correlation between simplicity and generalization when vocabularies are infinite
  - Correlation breaks down when tasks are not uniformly distributed
  - Performance degrades when abstraction layers are not goal-directed

- First 3 experiments:
  1. Compare sample efficiency using weakness proxy vs. simplicity proxy on a finite vocabulary task
  2. Test correlation between simplicity and generalization with varying vocabulary sizes
  3. Analyze policy complexity in the absence of abstraction vs. with different abstraction layers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we empirically test the claim that complexity is an illusion created by abstraction layers, and that all behaviors have equal complexity in the absence of abstraction?
- Basis in paper: [explicit] The paper presents a formalism for environments and abstraction layers, and proves that in the absence of abstraction, all behaviors have equal complexity.
- Why unresolved: While the paper provides a theoretical proof, empirical evidence is needed to validate this claim in real-world systems and across different domains.
- What evidence would resolve it: Conducting experiments across various domains (e.g., physics, biology, artificial intelligence) to measure and compare the complexity of behaviors in systems with and without abstraction layers, and analyzing the results to determine if they support the theoretical claim.

### Open Question 2
- Question: What are the implications of the confounding relationship between policy weakness and policy simplicity for the development of artificial intelligence systems?
- Basis in paper: [explicit] The paper shows that when vocabularies are finite (as they are in real-world systems), policy weakness can confound sample efficiency with policy simplicity.
- Why unresolved: The paper establishes the theoretical relationship between policy weakness and simplicity, but further research is needed to understand how this relationship impacts the design and performance of AI systems in practice.
- What evidence would resolve it: Developing and testing AI systems that explicitly account for the confounding relationship between policy weakness and simplicity, and evaluating their performance compared to systems that do not consider this relationship.

### Open Question 3
- Question: How can we identify and quantify the abstraction layers in complex systems, and how do these layers influence the emergence of goal-directed behavior?
- Basis in paper: [explicit] The paper argues that abstraction layers are goal-directed, and that weaker policies tend to take simpler forms in finite vocabularies due to the need for versatility and efficiency.
- Why unresolved: While the paper provides a theoretical framework for understanding abstraction layers and their role in goal-directed behavior, further research is needed to develop methods for identifying and quantifying these layers in real-world systems.
- What evidence would resolve it: Developing and applying techniques for identifying and quantifying abstraction layers in complex systems (e.g., biological, social, or technological systems), and analyzing how these layers influence the emergence and evolution of goal-directed behavior over time.

## Limitations
- The analysis assumes finite vocabularies and uniformly distributed tasks, which may not hold in all practical scenarios
- The paper's reliance on abstract mathematical formalism may limit accessibility and practical implementation
- The empirical validation is delegated to another paper, making it difficult to assess the complete argument

## Confidence

- **High confidence**: The theoretical framework and mathematical proofs (Propositions 1 and 2) are internally consistent and logically sound within their stated assumptions.
- **Medium confidence**: The claims about complexity being an "illusion" created by abstraction layers are well-supported theoretically but would benefit from more empirical validation across diverse domains.
- **Low confidence**: The paper relies heavily on a separately published paper for practical examples, making it difficult to fully assess the real-world applicability of the claims without access to that work.

## Next Checks

1. Test the correlation between simplicity and generalization across different vocabulary sizes and task distributions to verify the confounding relationship holds empirically
2. Implement the formalism in a concrete AI system to measure how abstraction layers affect perceived complexity
3. Design experiments where vocabulary finiteness is controlled to isolate its effect on the simplicity-generalization relationship