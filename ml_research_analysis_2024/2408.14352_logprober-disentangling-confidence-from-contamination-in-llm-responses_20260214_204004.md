---
ver: rpa2
title: 'LogProber: Disentangling confidence from contamination in LLM responses'
arxiv_id: '2408.14352'
source_url: https://arxiv.org/abs/2408.14352
tags:
- contamination
- training
- question
- logprober
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LogProber, a method to detect contamination
  in large language models (LLMs) by analyzing the cumulative log-probability of question
  tokens in question-answer pairs. The key idea is that contaminated questions will
  show a steeper log-probability curve due to high familiarity, while non-contaminated
  questions will show a more gradual curve.
---

# LogProber: Disentangling confidence from contamination in LLM responses

## Quick Facts
- arXiv ID: 2408.14352
- Source URL: https://arxiv.org/abs/2408.14352
- Reference count: 11
- Primary result: LogProber detects LLM contamination by analyzing cumulative log-probability curves of question tokens

## Executive Summary
This paper introduces LogProber, a method to detect contamination in large language models by analyzing the cumulative log-probability of question tokens in question-answer pairs. The key insight is that contaminated questions will show steeper log-probability curves due to high familiarity, while non-contaminated questions will show more gradual curves. The method fits an exponential function to these curves and uses the parameters as contamination scores, providing a computationally cheap way to detect pretraining contamination.

## Method Summary
LogProber analyzes the cumulative log-probability of question tokens in question-answer pairs to detect contamination. When models are trained on full question-answer pairs, contaminated questions produce steeper log-probability curves compared to non-contaminated ones. The method fits an exponential function to these cumulative log-probability curves and uses the resulting parameters as contamination scores. This approach leverages the observation that familiar questions (due to contamination) lead to higher confidence and faster log-probability accumulation in model responses.

## Key Results
- LogProber effectively distinguishes between models trained on full question-answer pairs versus those trained only on answers
- The method successfully identifies old versus new items when contamination involves complete question-answer training
- High accuracy can be achieved through answer-only training without detectable contamination signatures in log-probability curves

## Why This Works (Mechanism)
LogProber works because contamination creates familiarity with specific question patterns. When models are trained on full question-answer pairs, they develop high confidence in answering those exact questions, which manifests as steeper cumulative log-probability curves. The exponential fitting captures this contamination signature by quantifying how quickly log-probabilities accumulate as the model processes question tokens.

## Foundational Learning
- Cumulative log-probability analysis: Why needed - to quantify model confidence and familiarity with questions; Quick check - compare curves between known contaminated and clean datasets
- Exponential function fitting: Why needed - to parameterize the contamination signature in log-probability curves; Quick check - verify exponential model fits contaminated data better than linear alternatives
- Token-level probability access: Why needed - to compute cumulative log-probabilities for individual question tokens; Quick check - ensure API or model provides token log-probabilities

## Architecture Onboarding
Component map: Question tokens -> Cumulative log-probability calculation -> Exponential function fitting -> Contamination score extraction
Critical path: The method requires access to token log-probabilities, computation of cumulative sums, and exponential curve fitting. Each step depends on the previous one.
Design tradeoffs: The approach trades detection sensitivity for computational efficiency. It can only detect contamination when full question-answer pairs are trained, missing answer-only contamination scenarios.
Failure signatures: The method fails to detect contamination when models are trained only on answer tokens, producing false negatives. It also requires token-level probability access, limiting applicability to certain model deployments.
First experiments:
1. Test on models trained with known contamination (full question-answer pairs) vs clean models
2. Test on models trained with answer-only contamination to establish false negative rates
3. Test across different cognitive benchmarks to assess generalizability

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Cannot detect contamination when models are trained only on answer tokens
- Requires access to token-level log-probabilities, which may not be available for all model deployments
- Assumes a specific contamination signature pattern that may not generalize across all benchmark types
- Validation was limited to cognitive test items, leaving domain generalizability uncertain

## Confidence
- **High confidence**: Successfully distinguishes between models trained on full question-answer pairs versus answer-only training
- **Medium confidence**: Provides computationally efficient contamination detection with notable blind spots
- **Low confidence**: Generalizability to other benchmark types and contamination scenarios beyond cognitive tests

## Next Checks
1. Test LogProber's effectiveness on contamination scenarios where questions are paraphrased or slightly modified during training to assess robustness to question variations
2. Evaluate performance across diverse benchmark domains (scientific reasoning, code generation, creative writing) to establish generalizability limits
3. Compare LogProber scores with alternative contamination detection methods like RADAR and PaCoST on identical contamination scenarios to quantify relative sensitivity and specificity