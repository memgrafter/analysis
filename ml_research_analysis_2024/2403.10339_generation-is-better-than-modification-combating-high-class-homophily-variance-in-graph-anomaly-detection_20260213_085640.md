---
ver: rpa2
title: 'Generation is better than Modification: Combating High Class Homophily Variance
  in Graph Anomaly Detection'
arxiv_id: '2403.10339'
source_url: https://arxiv.org/abs/2403.10339
tags:
- graph
- homophily
- nodes
- datasets
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of high Class Homophily Variance
  (CHV) in graph anomaly detection, where the homophily distribution differences between
  classes are significantly greater than in homophilic or heterophilic graphs. To
  mitigate this issue, the authors propose a novel GNN model called HedGe (Homophily
  Edge Generation Graph Neural Network) that generates new homophilic edges rather
  than modifying existing ones.
---

# Generation is better than Modification: Combating High Class Homophily Variance in Graph Anomaly Detection

## Quick Facts
- arXiv ID: 2403.10339
- Source URL: https://arxiv.org/abs/2403.10339
- Reference count: 40
- The paper proposes HedGe, a GNN model that generates new homophilic edges to combat high Class Homophily Variance in graph anomaly detection.

## Executive Summary
This paper addresses the challenge of high Class Homophily Variance (CHV) in graph anomaly detection, where the homophily distribution differences between classes are significantly greater than in homophilic or heterophilic graphs. The authors propose HedGe (Homophily Edge Generation Graph Neural Network), a novel GNN model that generates new homophilic edges rather than modifying existing ones. HedGe uses a self-attention mechanism to sample homophily adjacency matrices and employs a modified loss function to suppress the generation of unnecessary heterophilic edges. Extensive experiments on multiple benchmark datasets demonstrate that HedGe achieves state-of-the-art performance in anomaly detection and edgeless node classification, while also showing improved robustness under Heterophily Attack.

## Method Summary
HedGe addresses high CHV in graph anomaly detection by generating new homophilic edges rather than modifying existing ones. The model applies position encoding to enhance node representations, then uses a self-attention mechanism to sample homophilic adjacency matrices. A modified loss function with heterophily edge suppression penalizes the generation of unnecessary heterophilic edges. The approach emphasizes generating new relationships with low CHV, using the original relationships as auxiliary information.

## Key Results
- HedGe achieves up to 15% improvement in AUC and 4.5% in AP compared to the best-performing models on benchmark datasets
- Outperforms state-of-the-art baselines in anomaly detection and edgeless node classification tasks
- Shows improved robustness under Heterophily Attack, demonstrating the effectiveness of edge generation strategy

## Why This Works (Mechanism)

### Mechanism 1
Generating homophilic edges from scratch via attention mechanisms reduces CHV more effectively than pruning or modifying existing edges. The self-attention mechanism samples homophilic adjacency matrices, creating new relationships relevant in feature space but not directly connected in the original graph. Core assumption: original graph structure with high CHV impedes GNN performance, and generating new homophilic edges can bypass this limitation.

### Mechanism 2
The modified loss function with heterophily edge suppression penalizes generation of unnecessary heterophilic edges, further reducing CHV. The loss function includes a penalty term calculating squared attention coefficients between nodes with differing labels, suppressing attention values for nodes with different labels and decreasing likelihood of generating heterophilic edges. Core assumption: heterophilic edges contribute to higher CHV and impede anomaly detection performance.

### Mechanism 3
Position encoding enhances node representation by providing additional contextual information for attention mechanism. The model applies degree, Laplacian, and label encoding to each node, enhancing representation ability before attention mechanism. Core assumption: original node features are insufficient for attention mechanism to accurately identify homophilic relationships in high CHV scenarios.

## Foundational Learning

- Concept: Class Homophily Variance (CHV) as a metric for quantifying homophily distribution differences between classes
  - Why needed here: CHV describes unique challenge in graph anomaly detection where homophily distribution differences between different classes are significantly greater than in homophilic or heterophilic graphs
  - Quick check question: What is the primary difference between CHV and traditional homophily metrics, and why is it particularly relevant to graph anomaly detection?

- Concept: Graph Neural Networks (GNNs) and their limitations in handling high CHV scenarios
  - Why needed here: The paper builds on existing GNN architectures but identifies their limitations in graph anomaly detection due to high CHV, motivating development of HedGe model
  - Quick check question: How do traditional GNNs typically handle homophilic and heterophilic graphs, and why do these approaches fail in high CHV scenarios?

- Concept: Attention mechanisms in graph neural networks
  - Why needed here: HedGe uses self-attention mechanism to sample homophily adjacency matrices, which is key component of edge generation strategy
  - Quick check question: How does self-attention mechanism in HedGe differ from traditional attention mechanisms in GNNs, and what advantages does it offer for edge generation?

## Architecture Onboarding

- Component map: Position Encoding (Degree Position Encoding, Laplacian Position Encoding, Label Encoding) -> Attention based Edge Sampler (Attention coefficient calculation, Edge Specific Gumbel Softmax sampling) -> Diverse Relationship Fusion (Aggregation of original, sampled, and attention coefficient features) -> Optimization (Cross-entropy loss with heterophily edge suppression penalty)

- Critical path: Position Encoding → Attention based Edge Sampler → Diverse Relationship Fusion → Optimization

- Design tradeoffs:
  - Edge generation vs. modification: Generating new edges from scratch vs. pruning or connecting existing edges
  - Homophilic focus vs. heterophilic information: Suppressing heterophilic edges vs. potentially useful heterophilic information
  - Complexity vs. performance: Additional components (position encoding, edge generation) vs. improved anomaly detection performance

- Failure signatures:
  - Poor performance on datasets with low CHV (model might be over-engineered for this scenario)
  - High computational cost due to edge generation and attention mechanisms
  - Overfitting to training data if edge generation is not properly regularized

- First 3 experiments:
  1. Compare HedGe performance with and without Edge Specific Gumbel Softmax sampling on a benchmark dataset
  2. Evaluate impact of different position encoding strategies (degree, Laplacian, label) on model's performance
  3. Test model's robustness to varying levels of CHV by applying Heterophily Attack to different datasets and measuring performance degradation

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several remain unaddressed based on the research presented.

## Limitations
- Theoretical justification for why edge generation outperforms modification in high CHV scenarios could be more rigorous
- Computational complexity of generating edges via attention mechanisms may limit scalability to very large graphs
- Position encoding strategy introduces additional hyperparameters requiring careful tuning

## Confidence
- High Confidence: HedGe's overall superior performance across multiple benchmarks (AUC and AP improvements up to 15% and 4.5%)
- Medium Confidence: Mechanism of edge generation reducing CHV more effectively than modification (lacks extensive ablation studies)
- Medium Confidence: Effectiveness of heterophily edge suppression (no sensitivity analysis of penalty strength)

## Next Checks
1. Conduct systematic ablation study to isolate contribution of edge generation versus heterophily edge suppression, comparing against edge modification baselines
2. Evaluate HedGe's performance and computational efficiency on larger graphs (e.g., Twitter or Facebook datasets) to assess real-world applicability
3. Develop formal theoretical framework explaining why edge generation is more effective than modification in high CHV scenarios, potentially through graph signal processing or spectral analysis