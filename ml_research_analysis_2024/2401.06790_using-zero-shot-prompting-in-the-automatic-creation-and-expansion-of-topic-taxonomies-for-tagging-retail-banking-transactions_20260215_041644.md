---
ver: rpa2
title: Using Zero-shot Prompting in the Automatic Creation and Expansion of Topic
  Taxonomies for Tagging Retail Banking Transactions
arxiv_id: '2401.06790'
source_url: https://arxiv.org/abs/2401.06790
tags:
- topic
- taxonomies
- taxonomy
- terms
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an unsupervised method for automatically constructing
  and expanding topic taxonomies using instruction-based fine-tuned large language
  models (LLMs). The approach combines topic modeling and keyword extraction to create
  initial taxonomies, which are then refined and organized into hierarchies using
  ChatGPT.
---

# Using Zero-shot Prompting in the Automatic Creation and Expansion of Topic Taxonomies for Tagging Retail Banking Transactions

## Quick Facts
- arXiv ID: 2401.06790
- Source URL: https://arxiv.org/abs/2401.06790
- Reference count: 4
- One-line primary result: Achieved >90% taxonomy coherence and >80% tag assignment accuracy using zero-shot prompting with LLMs

## Executive Summary
This paper presents an unsupervised method for automatically constructing and expanding topic taxonomies using instruction-based fine-tuned large language models (LLMs). The approach combines topic modeling and keyword extraction to create initial taxonomies, which are then refined and organized into hierarchies using ChatGPT. To expand existing taxonomies, the authors use zero-shot prompting to predict where new nodes should be added. The resulting taxonomies are applied to assign tags to merchants in a retail bank dataset. Evaluation by human volunteers showed high coherence rates exceeding 90% for the generated taxonomies and over 80% for the assigned tags. The taxonomy expansion using LLMs also demonstrated strong performance, with F1 scores above 70% for parent node prediction.

## Method Summary
The method combines YAKE! keyword extraction and LDA topic modeling on merchant descriptions, followed by ChatGPT refinement to organize terms into hierarchies. For taxonomy expansion, zero-shot prompting with ChatGPT predicts parent nodes for new terms. Tag assignment is performed through reverse indexing of taxonomy terms in merchant descriptions. The entire pipeline operates without labeled training data, relying instead on the LLM's pretraining knowledge and statistical extraction methods.

## Key Results
- Taxonomy coherence rates exceeding 90% in human evaluation
- Merchant tagging coherence surpassing 80% accuracy
- Parent node prediction F1 scores above 70% for taxonomy expansion
- Successful application to Food and Shopping categories in retail banking data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot prompting with ChatGPT can effectively predict parent nodes in a taxonomy expansion task.
- Mechanism: The prompt "Who is the father of [new_term]?" leverages ChatGPT's understanding of hierarchical relationships learned during pretraining to infer parent-child links without requiring fine-tuning or labeled data.
- Core assumption: ChatGPT's pretraining corpus contains sufficient examples of taxonomic relationships to generalize to new, unseen terms in retail banking contexts.
- Evidence anchors:
  - [abstract] "To expand an existing taxonomy with new terms, we use zero-shot prompting to find out where to add new nodes"
  - [section] "To verify the parent/root of a new term we used the following prompt: 'Who is the father of '+<new_term>'+'?'"
  - [corpus] Weak evidence - no specific corpus examples of banking taxonomy expansion provided
- Break condition: Performance degrades when new terms are too domain-specific or when the prompt fails to capture the correct hierarchical relationship.

### Mechanism 2
- Claim: Combining keyword extraction (YAKE!) and topic modeling (LDA) with ChatGPT post-processing produces high-quality initial taxonomies.
- Mechanism: YAKE! extracts statistically relevant keywords from merchant descriptions, LDA discovers latent topics, and ChatGPT refines both outputs by removing unrelated terms and organizing them hierarchically.
- Core assumption: The combination of statistical keyword extraction and probabilistic topic modeling captures the semantic structure of merchant descriptions sufficiently for ChatGPT to build coherent taxonomies.
- Evidence anchors:
  - [section] "For post-processing, we use ChatGPT to refine the result of each method, identifying unrelated terms"
  - [section] "To tackle this problem, we use ChatGPT again, this time with a prompt that searches for subcategories within the terms of a topic, to create these hierarchies"
  - [corpus] Weak evidence - no detailed evaluation of individual component contributions
- Break condition: The method fails when merchant descriptions are too sparse or when ChatGPT misinterprets the semantic relationships between terms.

### Mechanism 3
- Claim: Using merchant descriptions with reverse indexing effectively assigns tags to merchants based on the generated taxonomies.
- Mechanism: For each merchant, the system searches their description for terms present in the taxonomy, assigning those terms as tags that characterize the merchant's business type.
- Core assumption: Merchant descriptions contain sufficient textual overlap with taxonomy terms to enable accurate tag assignment through simple string matching.
- Evidence anchors:
  - [section] "To do so, we use the descriptions attached to these establishments, and we see which terms from a taxonomy are mentioned in their descriptions with a reverse index algorithm"
  - [section] "The evaluation revealed a coherence rate exceeding 90% for the chosen taxonomies, while the average coherence for merchant tagging surpassed 80%"
  - [corpus] No corpus-level evidence provided for the reverse indexing effectiveness
- Break condition: Tag assignment accuracy drops when merchant descriptions are ambiguous or when taxonomy terms are too general.

## Foundational Learning

- Concept: Topic modeling (LDA)
  - Why needed here: To discover latent semantic structures in merchant descriptions that can form the basis of topic taxonomies
  - Quick check question: What are the three main parameters of LDA and what does each control?

- Concept: Keyword extraction (YAKE!)
  - Why needed here: To identify statistically significant terms from merchant descriptions that represent business characteristics
  - Quick check question: How does YAKE! differ from traditional TF-IDF keyword extraction methods?

- Concept: Zero-shot prompting
  - Why needed here: To leverage pre-trained LLM knowledge for taxonomy expansion without requiring labeled training data
  - Quick check question: What is the key difference between zero-shot and few-shot prompting in LLM applications?

## Architecture Onboarding

- Component map: Data preprocessing -> Keyword extraction (YAKE!) -> Topic modeling (LDA) -> ChatGPT refinement -> Hierarchy construction -> Tag assignment -> Evaluation
- Critical path: Merchant description -> Taxonomy term extraction -> ChatGPT hierarchy -> Tag assignment -> Human evaluation
- Design tradeoffs: Using ChatGPT for post-processing adds flexibility but introduces dependency on API availability and cost; combining multiple extraction methods improves coverage but increases complexity
- Failure signatures: Low coherence scores indicate poor taxonomy quality; high tag assignment errors suggest inadequate term extraction or poor taxonomy structure
- First 3 experiments:
  1. Test YAKE! keyword extraction on a small sample of merchant descriptions and evaluate the relevance of top 30 keywords
  2. Run LDA on the same sample with varying topic numbers (1-5) and compare topic coherence scores
  3. Use ChatGPT to refine the combined keyword-topic output and verify hierarchical organization with a sample prompt

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed taxonomy construction method compare to other state-of-the-art methods for taxonomy construction?
- Basis in paper: [inferred] The paper mentions that the proposed method achieved high coherence rates exceeding 90% for the generated taxonomies, but it does not provide a direct comparison with other methods.
- Why unresolved: The paper does not provide a direct comparison with other state-of-the-art methods for taxonomy construction, making it difficult to assess the relative performance of the proposed method.
- What evidence would resolve it: A comparative study of the proposed method with other state-of-the-art methods for taxonomy construction, using the same evaluation metrics and datasets.

### Open Question 2
- Question: How does the proposed method handle the challenge of creating taxonomies for languages other than Portuguese?
- Basis in paper: [explicit] The paper mentions that the method was tested on a dataset in Portuguese, but it does not discuss the applicability of the method to other languages.
- Why unresolved: The paper does not provide any insights into the challenges and potential solutions for applying the method to other languages.
- What evidence would resolve it: An analysis of the method's performance on datasets in different languages, along with a discussion of the challenges and potential solutions for handling different languages.

### Open Question 3
- Question: How does the proposed method handle the challenge of creating taxonomies for domains other than retail banking transactions?
- Basis in paper: [explicit] The paper mentions that the method was tested on a dataset of retail banking transactions, but it does not discuss the applicability of the method to other domains.
- Why unresolved: The paper does not provide any insights into the challenges and potential solutions for applying the method to other domains.
- What evidence would resolve it: An analysis of the method's performance on datasets from different domains, along with a discussion of the challenges and potential solutions for handling different domains.

## Limitations
- Evaluation relies on subjective human judgment for taxonomy coherence and tag assignment quality
- Private retail banking dataset cannot be shared or independently verified
- Zero-shot prompting approach performance boundaries not fully explored for edge cases

## Confidence

**High confidence:** The core methodology combining YAKE!, LDA, and ChatGPT refinement is technically sound and well-documented

**Medium confidence:** The reported evaluation metrics are promising but based on subjective human assessment without detailed inter-rater reliability measures

**Medium confidence:** The zero-shot prompting approach demonstrates effectiveness, though limited testing on edge cases and domain-specific terms is acknowledged

## Next Checks
1. Conduct a quantitative evaluation using standardized taxonomy quality metrics (such as path similarity or depth consistency) rather than relying solely on subjective human judgment
2. Test the zero-shot prompting approach on a diverse set of retail banking terms, including edge cases and ambiguous descriptions, to identify performance boundaries and failure modes
3. Compare the proposed method against supervised taxonomy expansion approaches using the same dataset to establish whether the zero-shot approach provides comparable performance with reduced labeling requirements