---
ver: rpa2
title: 'From Intents to Conversations: Generating Intent-Driven Dialogues with Contrastive
  Learning for Multi-Turn Classification'
arxiv_id: '2411.14252'
source_url: https://arxiv.org/abs/2411.14252
tags:
- intent
- multi-turn
- generation
- dialogue
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Chain-of-Intent, a framework that generates
  large-scale, domain-specific, multilingual dialogue datasets by combining Hidden
  Markov Models (HMMs) with Large Language Models (LLMs) to model intent sequences
  and generate context-aware dialogues. The method first extracts domain-specific
  intent transition patterns from real-world e-commerce chat logs, then uses LLMs
  to parameterize HMM emission probabilities, enabling coherent utterance generation
  aligned with predicted intents.
---

# From Intents to Conversations: Generating Intent-Driven Dialogues with Contrastive Learning for Multi-Turn Classification

## Quick Facts
- arXiv ID: 2411.14252
- Source URL: https://arxiv.org/abs/2411.14252
- Reference count: 40
- Key outcome: Chain-of-Intent framework generates high-quality multilingual e-commerce dialogue datasets, improving multi-turn intent classification accuracy while reducing dependence on large-scale annotated data

## Executive Summary
This paper introduces Chain-of-Intent, a novel framework that combines Hidden Markov Models with Large Language Models to generate large-scale, domain-specific, multilingual dialogue datasets for multi-turn intent classification. The method extracts intent transition patterns from real e-commerce chat logs and uses LLMs to parameterize emission probabilities, enabling coherent utterance generation aligned with predicted intents. A multi-task contrastive learning framework (MINT-CL) is also proposed to improve classification performance while reducing annotation costs. The approach is evaluated on MINT-E, a comprehensive multilingual e-commerce dialogue corpus covering 381 intents across eight markets, demonstrating significant improvements in both dialogue generation quality and downstream classification accuracy.

## Method Summary
The Chain-of-Intent framework generates intent-driven dialogues by first extracting domain-specific intent transition patterns from real e-commerce chat logs, then using LLMs to parameterize Hidden Markov Model emission probabilities for context-aware utterance generation. The method samples intent sequences based on extracted turn distributions, initial intent distributions, and transition matrices, then generates coherent dialogues conditioned on both current intent and conversation history. For multi-turn intent classification, the MINT-CL framework combines intent classification with response ranking through contrastive learning, enabling the model to distinguish high-quality from lower-quality responses. The approach is evaluated on MINT-E, a multilingual e-commerce dialogue corpus, showing improvements in both dialogue quality (7.89/10 vs 7.25/10 for baselines) and classification accuracy.

## Key Results
- Chain-of-Intent generates high-quality dialogues with GPT-4 scores of 7.89/10 compared to 7.25/10 for baselines
- MINT-CL improves multi-turn intent classification accuracy across 8 multilingual markets
- Synthetic dataset generation reduces dependence on expensive manual annotation while maintaining quality
- Framework shows particular effectiveness in multilingual settings with 381 intents across different e-commerce domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain-of-Intent combines HMMs with LLMs to generate coherent, intent-driven dialogues by modeling intent transitions and using LLMs to parameterize emission probabilities.
- Mechanism: The HMM models intent sequences from chat logs (initial intent distribution, transition matrix), while LLMs generate context-aware utterances conditioned on both current intent and conversation history.
- Core assumption: Domain-specific intent transitions extracted from real chat logs can guide realistic dialogue generation when combined with LLM capabilities.
- Evidence anchors:
  - [abstract] "Our method first extracts domain-specific intent transition patterns from real-world e-commerce chat logs, which guide the modeling of turn-level dynamics and intent sequences. LLMs are then employed to parameterize the emission probabilities of HMMs"
  - [section] "Using these distributions, we first sample the number of turns T from P(T), then sample the initial intent I1 from Pinit, and subsequent intents It from Ptrans(·|It-1) conditioned on the previous intent"
- Break condition: If extracted intent transitions don't reflect actual user behavior or if LLM fails to generate coherent utterances given the intent context.

### Mechanism 2
- Claim: Multi-task contrastive learning (MINT-CL) improves multi-turn intent classification by distinguishing high-quality from lower-quality responses.
- Mechanism: MINT-CL adds a response ranking task using contrastive loss, where the model learns to assign higher scores to better responses within pairs, alongside the primary intent classification objective.
- Core assumption: Training signals from response quality ranking can improve the model's ability to understand contextual intent patterns.
- Evidence anchors:
  - [abstract] "We also propose MINT-CL, a multi-task contrastive learning framework for multi-turn intent classification, which improves performance while reducing dependence on large-scale annotated datasets"
  - [section] "We employ a contrastive loss similar to [9] to encourage the model to assign higher scores to better responses"
- Break condition: If response quality signals don't correlate with intent classification accuracy or if the contrastive loss overwhelms the primary classification objective.

### Mechanism 3
- Claim: Generating large-scale synthetic dialogue datasets reduces dependence on expensive manual annotation while maintaining quality.
- Mechanism: Chain-of-Intent generates synthetic dialogues by sampling intent sequences and using LLMs to create context-aware utterances, validated through GPT-4 quality assessment.
- Core assumption: Synthetic dialogues generated through this pipeline can match or exceed the quality of manually annotated data.
- Evidence anchors:
  - [abstract] "Empirical results demonstrate that our approach outperforms competitive baselines in dialogue generation quality and classification accuracy, particularly in multilingual settings"
  - [section] "Table 3 shows the quality ratings for the generated dialogues across different markets. Our generated dataset, MINT-E, consistently outperformed the baselines in every market"
- Break condition: If synthetic data fails to capture the complexity of real user interactions or if quality degrades significantly in low-resource languages.

## Foundational Learning

- Concept: Hidden Markov Models (HMMs)
  - Why needed here: HMMs provide a principled way to model sequential intent transitions based on observed patterns in real chat logs
  - Quick check question: What are the three main probability distributions estimated from chat logs in the Chain-of-Intent framework?

- Concept: Contrastive Learning
  - Why needed here: Contrastive learning enables the model to learn better representations by distinguishing between high-quality and lower-quality responses
  - Quick check question: In MINT-CL, what is the purpose of the contrastive loss compared to the standard classification loss?

- Concept: Multi-task Learning
  - Why needed here: Combining intent classification with response ranking tasks provides additional training signals that improve overall model performance
  - Quick check question: How does MINT-CL balance the intent classification loss with the contrastive loss through the λ hyperparameter?

## Architecture Onboarding

- Component map: Data extraction layer -> HMM sampling module -> LLM generation pipeline -> MINT-CL training framework -> Evaluation module
- Critical path:
  1. Extract domain knowledge from chat logs
  2. Sample intent sequences using HMM
  3. Generate context-aware utterances using LLM
  4. Create synthetic dialogue dataset (MINT-E)
  5. Train MTIC model with MINT-CL
  6. Evaluate performance on downstream tasks
- Design tradeoffs:
  - Synthetic vs. real data: Synthetic data is cheaper but may lack some real-world complexity
  - Language model choice: Larger models generate better quality but are more expensive
  - Multi-task weighting: λ balances contrastive learning contribution against primary task
  - Multilingual coverage: Trade-off between model performance and language support
- Failure signatures:
  - Low-quality dialogues: Generated conversations lack coherence or natural flow
  - Poor classification performance: MTIC accuracy doesn't improve despite additional training data
  - Language degradation: Performance drops significantly in low-resource languages
  - Overfitting: Model performs well on synthetic data but poorly on real test sets
- First 3 experiments:
  1. Validate HMM intent transition extraction: Compare extracted transition matrices against random sampling to ensure domain-specific patterns are captured
  2. Test LLM generation quality: Generate dialogues using different LLM sizes/configurations and evaluate quality scores
  3. Assess MINT-CL impact: Train MTIC models with and without MINT-CL to measure performance improvements across different markets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MINT-CL compare to other few-shot learning approaches for multi-turn intent classification?
- Basis in paper: [inferred] The paper mentions that few-shot prompting with ChatGPT does not perform well for intent classification and does not match up to supervised methods. However, it does not compare MINT-CL to other few-shot learning approaches.
- Why unresolved: The paper does not provide a direct comparison between MINT-CL and other few-shot learning approaches for multi-turn intent classification.
- What evidence would resolve it: Conducting experiments comparing MINT-CL to other few-shot learning approaches for multi-turn intent classification on the same datasets.

### Open Question 2
- Question: What is the impact of the number of intents on the performance of the Chain-of-Intent framework?
- Basis in paper: [explicit] The paper mentions that industrial chatbots handle hundreds of intents to meet specific user needs in each market, and that this vast number of intents significantly increases the complexity of both classification tasks and data annotation.
- Why unresolved: The paper does not provide an analysis of how the number of intents affects the performance of the Chain-of-Intent framework.
- What evidence would resolve it: Conducting experiments varying the number of intents in the Chain-of-Intent framework and evaluating its performance on multi-turn intent classification tasks.

### Open Question 3
- Question: How does the performance of MINT-CL vary across different language models?
- Basis in paper: [explicit] The paper mentions that the quality of LLM-generated content may be of lower quality in low-resource languages, and that this affects the performance of the downstream tasks.
- Why unresolved: The paper does not provide a comparison of the performance of MINT-CL across different language models.
- What evidence would resolve it: Conducting experiments comparing the performance of MINT-CL across different language models on the same datasets.

## Limitations
- Heavy reliance on GPT-4 scoring for dialogue quality assessment may introduce subjectivity and miss nuances human evaluators would catch
- Effectiveness in extremely low-resource languages beyond the 8 studied markets remains uncertain due to token fertility and pattern extraction challenges
- Synthetic data generation may not fully capture real-world user interaction complexity and edge cases

## Confidence
- High confidence: The effectiveness of combining HMMs with LLMs for intent-driven dialogue generation (supported by quantitative results showing 7.89/10 vs 7.25/10 baseline quality scores)
- Medium confidence: The MINT-CL framework's contribution to improving multi-turn intent classification (improvements observed but potentially influenced by training data scale)
- Medium confidence: The generalizability of results across the 8 multilingual markets, as language-specific challenges may affect performance differently

## Next Checks
1. Conduct human evaluation studies to validate GPT-4 quality assessments and identify potential blind spots in the automated scoring system, particularly focusing on intent alignment accuracy and conversational naturalness.

2. Test the Chain-of-Intent framework on additional low-resource languages beyond the current 8 markets to assess scalability and identify language-specific limitations in intent transition pattern extraction and LLM performance.

3. Perform ablation studies to isolate the individual contributions of HMM modeling, LLM generation quality, and MINT-CL contrastive learning to overall system performance, determining which components provide the most significant benefits.