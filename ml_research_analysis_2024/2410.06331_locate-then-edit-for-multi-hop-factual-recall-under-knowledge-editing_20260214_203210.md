---
ver: rpa2
title: Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing
arxiv_id: '2410.06331'
source_url: https://arxiv.org/abs/2410.06331
tags:
- knowledge
- multi-hop
- edit
- layers
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates why existing locate-then-edit methods for
  knowledge editing (KE) in LLMs struggle with multi-hop factual recall tasks. Through
  mechanistic interpretability tools, the authors find that in multi-hop queries,
  the model retrieves implicit subject information from deeper MLP layers, whereas
  single-hop tasks rely on shallow layers.
---

# Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing

## Quick Facts
- **arXiv ID**: 2410.06331
- **Source URL**: https://arxiv.org/abs/2410.06.331
- **Reference count**: 40
- **Primary result**: IFMET improves multi-hop accuracy to 23.04% at batch size 1 by editing both shallow and deep MLP layers

## Executive Summary
Existing locate-then-edit knowledge editing methods struggle with multi-hop factual recall tasks because they only modify shallow MLP layers. Through mechanistic interpretability analysis, the authors discover that multi-hop queries retrieve implicit subject information from deeper MLP layers, unlike single-hop tasks that rely on shallow layers. To address this limitation, the paper proposes IFMET, an interpretability-guided method that constructs supplementary editing instances and modifies both shallow and deep layers. Experiments on the MQuAKE dataset demonstrate that IFMET significantly outperforms existing methods, achieving 23.04% accuracy at batch size 1 and maintaining robust performance across different hop counts.

## Method Summary
The paper investigates why traditional locate-then-edit methods fail for multi-hop factual recall by analyzing activation patterns across MLP layers. The authors find that single-hop queries primarily use shallow layers for knowledge retrieval, while multi-hop queries access implicit subject information from deeper layers. Based on this insight, they propose IFMET (Interpretability-guided Furtherance Model Editing), which constructs supplementary editing instances and uses multi-hop editing prompts to locate and modify knowledge in both shallow and deep MLP layers. The method involves generating additional edit instances, applying multi-hop prompts to identify relevant layers, and performing edits across the identified shallow and deep layer sets to ensure comprehensive knowledge modification.

## Key Results
- IFMET achieves 23.04% accuracy at batch size 1 on MQuAKE multi-hop factual recall tasks
- The method demonstrates robust performance across varying numbers of hops and edits
- IFMET significantly outperforms existing locate-then-edit methods that only modify shallow layers

## Why This Works (Mechanism)
Multi-hop factual recall requires accessing implicit subject information that is stored in deeper MLP layers of language models. When editing only shallow layers, the modifications cannot propagate to where multi-hop queries actually retrieve their knowledge. By constructing supplementary editing instances and using multi-hop prompts to identify both shallow and deep layer sets, IFMET ensures that all relevant knowledge locations are modified, enabling successful multi-hop factual recall.

## Foundational Learning

### Mechanistic Interpretability
**Why needed**: To understand how different layers of the model store and retrieve knowledge for single-hop versus multi-hop queries
**Quick check**: Compare activation patterns across MLP layers for single-hop and multi-hop queries to identify differences in knowledge retrieval mechanisms

### Knowledge Editing (KE)
**Why needed**: To modify factual knowledge in pre-trained models without full fine-tuning
**Quick check**: Verify that edits to shallow layers affect single-hop query performance but not multi-hop performance

### Multi-hop Reasoning
**Why needed**: To understand complex query patterns that require chaining multiple pieces of information
**Quick check**: Test query performance degradation as hop count increases to confirm multi-hop nature

## Architecture Onboarding

**Component Map**: Input Query -> MLP Layer Analysis -> Knowledge Location Identification -> Edit Instance Generation -> Multi-hop Prompt Application -> Layer-wise Editing -> Output

**Critical Path**: Multi-hop prompt analysis identifies relevant shallow and deep layers, supplementary instances are generated, edits are applied to both layer sets, enabling successful multi-hop factual recall

**Design Tradeoffs**: Editing both shallow and deep layers increases edit coverage but requires more computational resources and careful instance generation to maintain semantic consistency

**Failure Signatures**: Poor multi-hop performance when only shallow layers are edited, incomplete knowledge modification when supplementary instances are semantically inaccurate

**First Experiments**:
1. Compare activation patterns across MLP layers for single-hop vs multi-hop queries
2. Measure performance degradation when editing only shallow layers on multi-hop tasks
3. Evaluate semantic accuracy of automatically generated supplementary editing instances

## Open Questions the Paper Calls Out

None

## Limitations

- The mechanistic interpretability analysis relies on manual inspection of activation patterns, which may not generalize across different model architectures
- IFMET's effectiveness depends on the quality of automatically generated supplementary editing instances, but validation of their semantic accuracy is limited
- Evaluation focuses primarily on the MQuAKE dataset, which may not represent full diversity of multi-hop factual recall scenarios

## Confidence

- **High**: The observation that single-hop and multi-hop queries show different activation patterns across MLP layers is well-supported by empirical evidence
- **Medium**: The claim that editing only shallow layers is insufficient for multi-hop tasks is demonstrated but needs more systematic ablation studies
- **Medium**: IFMET's effectiveness is shown, but improvements may be partially attributed to increased edit volume rather than interpretability-guided approach

## Next Checks

1. Conduct cross-dataset evaluation to verify IFMET's effectiveness on multi-hop factual recall tasks beyond MQuAKE, including different domain knowledge and query structures
2. Perform systematic ablation studies comparing IFMET's performance when editing only shallow layers, only deep layers, versus both, across multiple model architectures and sizes
3. Evaluate the semantic accuracy and relevance of automatically generated supplementary editing instances through human annotation or automated semantic similarity metrics