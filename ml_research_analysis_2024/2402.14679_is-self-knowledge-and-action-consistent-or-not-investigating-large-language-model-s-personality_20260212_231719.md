---
ver: rpa2
title: 'Is Self-knowledge and Action Consistent or Not: Investigating Large Language
  Model''s Personality'
arxiv_id: '2402.14679'
source_url: https://arxiv.org/abs/2402.14679
tags:
- personality
- llms
- action
- responses
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the consistency between LLMs' self-reported
  personality traits and their behavior in practical scenarios. Using a bilingual
  English-Chinese corpus, researchers compared LLM responses to personality questionnaires
  with their actions in designed situations.
---

# Is Self-knowledge and Action Consistent or Not: Investigating Large Language Model's Personality

## Quick Facts
- arXiv ID: 2402.14679
- Source URL: https://arxiv.org/abs/2402.14679
- Reference count: 35
- Primary result: LLMs demonstrate significantly lower congruence between self-reported personality traits and behavior (cosine similarity 0.24, Spearman correlation 0.22) compared to humans (cosine similarity 0.76, Spearman correlation 0.78)

## Executive Summary
This study investigates the consistency between LLMs' self-reported personality traits and their behavior in practical scenarios. Using a bilingual English-Chinese corpus, researchers compared LLM responses to personality questionnaires with their actions in designed situations. The study found that while human respondents show high consistency between self-knowledge and action, LLMs demonstrate significantly lower congruence, suggesting that LLMs struggle to authentically replicate human personality dynamics. This highlights the need for further research to improve LLMs' ability to perform more genuinely human-like interactions.

## Method Summary
The study constructed a bilingual English-Chinese corpus of 180 personality knowledge statements and corresponding practical scenario cases. Researchers collected responses from 5 selected LLMs (ChatGLM3, GPT-3.5-turbo, GPT-4, Vicuna-13b, Vicuna-33b) using 5 different academic personality questionnaire prompts. They used a 7-point graded forced-choice format for behavior tendency questions and calculated four statistical metrics (cosine similarity, Spearman rank correlation, value mean difference, and proportion of consistent pairs) to compare personality knowledge responses with behavior tendency responses. These results were then compared with human respondents' data.

## Key Results
- LLMs show average cosine similarity of 0.24 and Spearman correlation of 0.22 between self-reported personality and behavior
- Humans show average cosine similarity of 0.76 and Spearman correlation of 0.78 between self-knowledge and action
- The value mean difference for LLMs averages around 1.52, indicating substantial divergence between personality questionnaires and behavior tendency questionnaires

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs struggle to authentically replicate human personality dynamics due to misalignment between self-reported traits and behavior
- Mechanism: The study found that while humans show high consistency between self-knowledge and action (cosine similarity 0.76, Spearman correlation 0.78), LLMs demonstrate significantly lower congruence (cosine similarity 0.24, Spearman correlation 0.22)
- Core assumption: The personality questionnaires used (TDA-100, BFI-44, 16 Personalities) are valid measures of personality traits for both humans and LLMs
- Evidence anchors:
  - [abstract] "This study investigates the consistency between LLMs' self-reported personality traits and their behavior in practical scenarios"
  - [section 3.2] "The average Cosine Similarity and Spearman's Rank Correlation Coefficient for LLMs are substantially below those of human respondents, with a huge difference exceeding 0.42"
- Break condition: If the personality questionnaires are not valid measures for LLMs, the entire comparison becomes meaningless

### Mechanism 2
- Claim: LLMs' responses to personality questionnaires lack logical consistency and split-half reliability
- Mechanism: The study tested seven LLMs and found that only five (ChatGLM3, GPT-3.5-turbo, GPT4, Vicuna13b, and Vicuna33b) produced reliable responses based on logical consistency (Consistency metric) and split-half reliability tests
- Core assumption: Logical consistency and split-half reliability are appropriate measures of questionnaire response quality
- Evidence anchors:
  - [section 3.1] "we employed two distinct methods to examine the reliability of LLMs' responses systematically: Logical Consistency and Split-Half Reliability"
  - [section B] "We assessed the reliability of seven LLMs' responses. The results... indicate that they respond to the personality questionnaires like how humans would"
- Break condition: If LLMs can produce reliable responses under different testing conditions, this mechanism would be invalidated

### Mechanism 3
- Claim: The graded forced-choice format reveals discrepancies between stated personality and behavior better than Likert scales
- Mechanism: The study used a 7-point graded forced-choice format for behavior tendency questions, which showed that LLMs' actions in practical scenarios often contradicted their self-reported personality traits
- Core assumption: The graded forced-choice format is more sensitive to detecting discrepancies between self-knowledge and action than other response formats
- Evidence anchors:
  - [section 3.1] "we apply a 7-point graded forced-choice format... Graded forced-choice scales exhibit comparable validity, superior reliability and model fit"
  - [section 3.2] "The Value Mean Difference for LLMs averages around 1.52, indicating a substantial divergence in self-knowledge between the two types of questionnaires"
- Break condition: If other response formats (like Likert scales) show similar or better detection of discrepancies, this mechanism would be weakened

## Foundational Learning

- Concept: Personality assessment validity
  - Why needed here: The study relies on established personality questionnaires (Big Five, MBTI) being valid measures for both humans and LLMs
  - Quick check question: What are the key psychometric properties (reliability, validity) that make a personality test suitable for this type of research?

- Concept: Response format comparison
  - Why needed here: The study specifically chose graded forced-choice over Likert scales for behavior questions, claiming it's more sensitive
  - Quick check question: What are the key differences between forced-choice and Likert scale formats in terms of measurement properties?

- Concept: Statistical comparison methods
  - Why needed here: The study uses cosine similarity, Spearman correlation, value mean difference, and proportion of consistent pairs to quantify alignment
  - Quick check question: When would you use cosine similarity vs. Spearman correlation to compare two sets of responses?

## Architecture Onboarding

- Component map: Corpus design (personality knowledge questionnaire + behavior tendency questionnaire) -> LLM response generation -> Statistical analysis (4 metrics) -> Comparison with human data
- Critical path: Questionnaire design -> LLM response collection -> Reliability filtering -> Statistical analysis -> Result interpretation
- Design tradeoffs: Bilingual corpus vs. monolingual (broader accessibility but increased complexity), multiple prompts vs. single prompt (reduces prompt-specific bias but increases variability)
- Failure signatures: Low consistency between self-reported traits and behavior, unreliable LLM responses, poor human-LLM comparability
- First 3 experiments:
  1. Test personality questionnaire reliability on a small set of LLMs using logical consistency and split-half reliability metrics
  2. Compare LLM responses to human responses on the same personality questionnaires using the 4 statistical metrics
  3. Test different response formats (forced-choice vs. Likert) to see which better reveals discrepancies between self-knowledge and action

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different prompt formulations affect the consistency between LLM self-reported personality traits and their behavioral responses?
- Basis in paper: [explicit] The paper states "we selected the instructions of five common academic questionnaires with effective analysis of reliability and validity... as the prompt for the LLM of questioning of the personality knowledge questionnaire. We utilize various prompts to prevent any particular prompt from exerting a specific influence on LLM responses"
- Why unresolved: The paper uses multiple prompts to reduce bias but does not analyze how specific prompt formulations impact consistency metrics between self-knowledge and action
- What evidence would resolve it: Systematic comparison of consistency metrics across different prompt formulations, showing whether certain prompts produce more consistent self-knowledge and action responses than others

### Open Question 2
- Question: What specific architectural or training modifications could improve LLM personality-behavior consistency?
- Basis in paper: [inferred] The paper concludes that "there are significant gaps in the coherence between their stated personality and exhibited behaviors" and "our efforts will focus on leveraging the insights gained from this research to improve the performance and reliability of LLMs"
- Why unresolved: The paper identifies the problem but explicitly states it "has yet to identify an effective strategy for enhancing the congruence between LLMs' self-knowledge and action"
- What evidence would resolve it: Comparative experiments testing different architectural modifications (finetuning strategies, additional personality alignment training, etc.) against the baseline models, measuring improvements in consistency metrics

### Open Question 3
- Question: How does LLM personality-behavior consistency vary across different personality dimensions (neuroticism, extraversion, openness, agreeableness, conscientiousness)?
- Basis in paper: [explicit] The paper uses Big Five personality traits (neuroticism, extraversion, openness, agreeableness, conscientiousness) as assessment dimensions and calculates consistency metrics
- Why unresolved: While the paper calculates overall consistency metrics, it does not break down consistency by individual personality dimensions to identify which traits LLMs struggle with most
- What evidence would resolve it: Dimension-specific consistency metrics showing which personality traits have the lowest correlation between self-reported and behavioral responses, potentially guiding targeted improvements

### Open Question 4
- Question: How does the bilingual nature of the corpus (English-Chinese) affect the consistency measurements across different languages?
- Basis in paper: [explicit] The paper states "we ensure that our investigation into the anthropomorphic traits of LLMs is grounded in robust psychological methodology and thereby construct a bilingual English-Chinese Parallel Sentence Pair Self-knowledge-Action Test Set"
- Why unresolved: The paper constructs a bilingual corpus but does not analyze whether consistency metrics differ between English and Chinese responses or whether language choice affects LLM performance
- What evidence would resolve it: Comparative consistency analysis between English and Chinese responses, testing whether LLMs show different levels of personality-behavior alignment across languages

## Limitations
- Language and Cultural Bias: The bilingual English-Chinese corpus may introduce cultural differences in questionnaire interpretation that affect results
- Sample Size and Diversity: Only five LLMs were tested, limiting generalizability to the broader LLM landscape
- Validation of Behavioral Scenarios: The face and construct validity of behavioral scenarios were not explicitly tested
- Statistical Methodology: Specific methodology for significance testing and multiple comparisons handling was not detailed

## Confidence
- High Confidence: LLMs show significantly lower consistency between self-reported personality traits and behavior compared to humans
- Medium Confidence: The graded forced-choice format is more sensitive to detecting discrepancies between self-knowledge and action than Likert scales
- Low Confidence: The study's findings can be generalized to all LLMs and personality assessment contexts

## Next Checks
1. Cross-Cultural Validation: Replicate the study using personality questionnaires and behavioral scenarios in additional languages and cultural contexts
2. Broader LLM Sampling: Test a more diverse set of LLMs, including open-source models of varying sizes and architectures
3. Behavioral Scenario Validation: Conduct a validation study to assess the face and construct validity of the behavioral scenarios used in the study