---
ver: rpa2
title: Learning Multi-Target TDOA Features for Sound Event Localization and Detection
arxiv_id: '2408.17166'
source_url: https://arxiv.org/abs/2408.17166
tags:
- features
- tdoa
- events
- sound
- event
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses sound event localization and detection (SELD)
  using microphone array recordings, focusing on improving localization performance
  by learning better time-difference of arrival (TDOA) features. The proposed method,
  NGCC-PHAT, extends neural generalized cross-correlation with phase-transform (NGCC-PHAT)
  using permutation invariant training to extract TDOA features for multiple overlapping
  sound events.
---

# Learning Multi-Target TDOA Features for Sound Event Localization and Detection

## Quick Facts
- arXiv ID: 2408.17166
- Source URL: https://arxiv.org/abs/2408.17166
- Reference count: 0
- Primary result: Learning-based TDOA features (NGCC-PHAT) outperform traditional methods for SELD on STARSS23 dataset

## Executive Summary
This paper addresses sound event localization and detection (SELD) by proposing a novel approach to extract multi-target time-difference of arrival (TDOA) features using neural generalized cross-correlation with phase-transform (NGCC-PHAT). The method employs permutation invariant training to handle multiple overlapping sound events, enabling the network to predict TDOAs for different events across multiple output tracks. When integrated with a CST-Former SELD network, NGCC-PHAT features demonstrate superior performance compared to standard GCC-PHAT and SALSA-Lite features in terms of location-dependent F-score and direction-of-arrival error metrics.

## Method Summary
The proposed method extends traditional cross-correlation techniques by incorporating neural networks and permutation invariant training to extract TDOA features for multiple simultaneous sound events. The NGCC-PHAT approach processes microphone array recordings to compute generalized cross-correlation features that are then enhanced through neural network learning. This allows the system to better separate spatial cues from overlapping sound events and provide more accurate localization information for downstream SELD tasks.

## Key Results
- NGCC-PHAT features outperform standard GCC-PHAT and SALSA-Lite features on STARSS23 dataset
- Improved location-dependent F-score (FLD) and direction-of-arrival error (DOAE) metrics
- Demonstrated effectiveness for handling overlapping sound events in complex acoustic environments

## Why This Works (Mechanism)
The method leverages neural networks to learn more discriminative TDOA features from microphone array recordings, particularly for scenarios involving multiple overlapping sound events. By using permutation invariant training, the network can effectively separate spatial cues belonging to different sound sources, addressing the challenge of source separation in SELD tasks. The learned features capture more nuanced temporal and spatial patterns than traditional correlation-based methods.

## Foundational Learning
- **Sound Event Localization and Detection (SELD)**: Joint task of detecting sound events and determining their spatial locations; needed because traditional systems treat localization and detection separately, missing potential synergies
- **Time-Difference of Arrival (TDOA)**: Temporal difference in signal arrival between microphones; fundamental for spatial localization using microphone arrays
- **Generalized Cross-Correlation with Phase Transform (GCC-PHAT)**: Signal processing technique for TDOA estimation; provides robust time delay estimates in reverberant environments
- **Permutation Invariant Training**: Training strategy that handles label ambiguity in multi-source scenarios; essential for correctly associating predictions with ground truth when sources overlap
- **Microphone Array Signal Processing**: Techniques for extracting spatial information from multiple microphone signals; basis for acoustic source localization
- **CST-Former Architecture**: Transformer-based model for SELD tasks; provides the framework for integrating learned TDOA features

## Architecture Onboarding

**Component Map:**
Microphone Array -> NGCC-PHAT Network -> CST-Former SELD Network -> Location and Event Predictions

**Critical Path:**
1. Microphone array captures multi-channel audio
2. NGCC-PHAT extracts and enhances TDOA features
3. CST-Former processes enhanced features for SELD
4. Output: Detected events with spatial locations

**Design Tradeoffs:**
- Neural enhancement vs. computational complexity
- Multiple output tracks vs. simpler single-track approaches
- Permutation invariant training vs. traditional source assignment

**Failure Signatures:**
- Degraded performance with increasing number of overlapping events
- Sensitivity to microphone array geometry and spacing
- Potential overfitting to specific acoustic environments

**First Experiments:**
1. Compare NGCC-PHAT vs. GCC-PHAT performance with varying numbers of overlapping events
2. Test method with different microphone array configurations
3. Evaluate sensitivity to reverberation and noise levels

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to STARSS23 dataset with specific 4-microphone tetrahedral configuration
- Scalability to larger microphone arrays and more complex spatial setups remains unproven
- Performance with diverse acoustic environments beyond the evaluated dataset is unknown

## Confidence

**High Confidence:**
- Improvement of NGCC-PHAT features over traditional methods on STARSS23 dataset

**Medium Confidence:**
- Effectiveness of permutation invariant training for multiple overlapping events requires broader validation

**Low Confidence:**
- Scalability to larger arrays and more complex configurations remains unproven

## Next Checks
1. Evaluate performance across multiple datasets with varying microphone array geometries and acoustic conditions
2. Test scalability with increasing numbers of overlapping sound events
3. Conduct ablation studies to quantify contributions of permutation invariant training versus neural network architecture