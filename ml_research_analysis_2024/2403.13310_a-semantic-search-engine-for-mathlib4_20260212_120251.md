---
ver: rpa2
title: A Semantic Search Engine for Mathlib4
arxiv_id: '2403.13310'
source_url: https://arxiv.org/abs/2403.13310
tags:
- query
- theorem
- search
- mathlib4
- formal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a semantic search engine for the Lean 4 mathematical
  library mathlib4 that enables users to search for theorems using informal natural
  language queries. The approach involves converting formal theorem statements into
  informal versions using a large language model with contextual information, storing
  informal-formal theorem pairs in a vector database, and performing semantic search
  with query augmentation.
---

# A Semantic Search Engine for Mathlib4

## Quick Facts
- arXiv ID: 2403.13310
- Source URL: https://arxiv.org/abs/2403.13310
- Reference count: 28
- A semantic search engine for Lean 4's mathlib4 that enables natural language theorem search

## Executive Summary
This paper introduces a semantic search engine for mathlib4 that bridges the gap between formal theorem statements and informal natural language queries. The system converts formal theorems into informal versions using a large language model, stores these as vector embeddings in a database, and performs semantic search with query augmentation. The approach addresses the challenge of searching mathematical libraries where users typically think in terms of concepts and properties rather than formal syntax. The system is evaluated across six mathematical domains using a benchmark of 50 queries.

## Method Summary
The search engine works by first converting formal theorem statements from mathlib4 into informal natural language descriptions using an LLM (specifically gpt-3.5-turbo). These informal-formal theorem pairs are then stored in a vector database (LanceDB) as embeddings generated by the E5mistral-7b model. When users submit natural language queries, the system performs query augmentation by generating multiple alternative phrasings of the query, retrieves relevant theorems from the vector database, and ranks them using BM25 scoring. The system supports multiple mathematical domains including topology, linear algebra, and real analysis, and provides users with both informal descriptions and formal theorem statements.

## Key Results
- E5mistral-7b with augmented queries achieves nDCG@20 of 0.733, P@10 of 0.196, and R@10 of 0.913
- Query augmentation significantly improves retrieval effectiveness by generating diverse query phrasings
- Combining formal and informal theorem representations yields better results than using either representation alone
- The system demonstrates strong performance across topology, linear algebra, and real analysis domains

## Why This Works (Mechanism)
The system works by addressing the fundamental mismatch between how mathematical theorems are formally expressed in Lean and how users naturally think about mathematical concepts. By using an LLM to generate informal versions of formal theorems, the system creates a semantic bridge that captures the underlying mathematical meaning rather than just syntactic structure. The vector database enables efficient semantic similarity search, while query augmentation ensures that the system can handle the natural variability in how users express mathematical queries. This multi-faceted approach allows the system to retrieve relevant theorems even when query terms don't exactly match the formal statement.

## Foundational Learning
1. **Vector Embeddings for Semantic Search** (why needed: enables semantic similarity beyond keyword matching; quick check: verify embeddings capture mathematical concepts, not just words)
2. **Query Augmentation Techniques** (why needed: handles linguistic variability in user queries; quick check: measure diversity of generated query variants)
3. **BM25 Ranking Algorithm** (why needed: combines semantic similarity with term frequency relevance; quick check: validate ranking improves precision)
4. **Formal-Informal Theorem Conversion** (why needed: bridges formal math language and natural language; quick check: assess conversion accuracy with domain experts)
5. **Multi-Domain Mathematical Search** (why needed: supports diverse mathematical fields; quick check: ensure consistent performance across domains)

## Architecture Onboarding

**Component Map:**
LLM Theorem Formalizer -> Vector Database (LanceDB) -> Query Augmentation Engine -> BM25 Ranker -> Search Results

**Critical Path:**
User Query → Query Augmentation → Vector Database Retrieval → BM25 Ranking → Results Display

**Design Tradeoffs:**
The system trades computational overhead for improved retrieval accuracy by using LLM-based theorem formalization and query augmentation. This adds latency but significantly improves semantic understanding compared to keyword-based approaches. The choice of E5mistral-7b for embeddings balances model size with retrieval effectiveness.

**Failure Signatures:**
- Poor retrieval when informal theorem descriptions are inaccurate or incomplete
- Reduced effectiveness for highly specialized or recently added theorems not well-represented in the LLM training data
- Performance degradation when mathematical concepts have ambiguous informal descriptions
- Latency issues during query augmentation phase with complex queries

**First 3 Experiments:**
1. Test retrieval accuracy with formal-only versus informal-only versus combined representations
2. Evaluate different LLM models for theorem formalization quality and consistency
3. Measure performance impact of varying the number of query augmentations per search

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation based on a relatively small set of 50 queries across 6 domains
- Performance metrics sensitive to the curated nature of the evaluation benchmark
- Computational overhead and latency introduced by multi-step query augmentation process
- Potential variability and consistency issues in LLM-based theorem formalization

## Confidence

**High Confidence:**
- The core methodology of using vector databases for semantic search
- General effectiveness of combining formal-informal theorem representations

**Medium Confidence:**
- Specific performance metrics and ranking of embedding models
- Evaluation results sensitivity to benchmark composition

**Low Confidence:**
- Long-term scalability with growing mathlib4 library
- Real-world user query diversity handling

## Next Checks
1. **Scalability Test**: Evaluate performance and response time with a larger, more diverse query set (minimum 200 queries) spanning additional mathematical domains

2. **Cross-Model Consistency**: Test robustness of informal theorem generation by running the same formal statements through multiple LLM instances and measuring consistency

3. **Real-World Deployment**: Conduct user study with mathematicians performing actual theorem searches to assess practical usability and satisfaction