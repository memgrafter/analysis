---
ver: rpa2
title: Causal-aware Graph Neural Architecture Search under Distribution Shifts
arxiv_id: '2405.16489'
source_url: https://arxiv.org/abs/2405.16489
tags:
- graph
- causal
- architecture
- neural
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of graph neural architecture search
  (Graph NAS) under distribution shifts. Existing Graph NAS methods fail to generalize
  under distribution shifts due to spurious correlations between graphs and architectures.
---

# Causal-aware Graph Neural Architecture Search under Distribution Shifts

## Quick Facts
- arXiv ID: 2405.16489
- Source URL: https://arxiv.org/abs/2405.16489
- Authors: Peiwen Li; Xin Wang; Zeyang Zhang; Yijian Qin; Ziwei Zhang; Jialong Wang; Yang Li; Wenwu Zhu
- Reference count: 40
- Primary result: CARNAS achieves 94.41% accuracy on synthetic data and significantly outperforms baselines on molecular property prediction tasks

## Executive Summary
This paper addresses the critical challenge of distribution shifts in graph neural architecture search (Graph NAS), where existing methods fail to generalize due to spurious correlations between graphs and architectures. The authors propose CARNAS, a causal-aware approach that integrates causal inference principles into the Graph NAS process to discover and exploit the true causal relationships between graphs and architectures. By disentangling causal from spurious correlations, CARNAS aims to produce architectures that maintain strong performance under distribution shifts.

The proposed method demonstrates substantial improvements over existing Graph NAS baselines across both synthetic and real-world molecular datasets. Through extensive experiments, CARNAS shows superior out-of-distribution generalization capabilities, achieving state-of-the-art results on challenging molecular property prediction benchmarks while maintaining competitive performance on in-distribution data.

## Method Summary
CARNAS introduces a novel framework that incorporates causal reasoning into the Graph NAS pipeline through three key modules: Disentangled Causal Subgraph Identification, Graph Embedding Intervention, and Invariant Architecture Customization. The method first identifies causal subgraphs within input graphs that are invariant across different data distributions, then intervenes on graph embeddings to remove spurious correlations, and finally customizes architectures based on these causally-relevant features. This approach fundamentally differs from traditional Graph NAS methods by explicitly modeling and accounting for distribution shifts through causal inference principles rather than treating the search space as static.

## Key Results
- On the synthetic Spurious-Motif dataset, CARNAS achieves 94.41% accuracy for b=0.7, outperforming the best baseline (DCGAS) at 87.68%
- On real-world molecular property prediction datasets (OGBG-Mol*), CARNAS consistently outperforms baselines with notable improvements on SIDER (83.36% ROC-AUC vs. 63.46% for DCGAS)
- Ablation studies confirm the effectiveness of each component in the proposed method

## Why This Works (Mechanism)
The effectiveness of CARNAS stems from its ability to identify and leverage invariant causal relationships between graph structures and optimal architectures, rather than learning spurious correlations that may not hold under distribution shifts. By explicitly modeling the causal mechanisms through disentangled causal subgraph identification, the method can distinguish between features that truly drive architectural performance and those that are merely correlated due to data distribution characteristics.

## Foundational Learning
- **Causal inference**: Understanding of causal relationships and confounding variables (why needed: to distinguish causal from spurious correlations; quick check: can identify confounding in simple scenarios)
- **Graph neural networks**: Basic knowledge of GNN architectures and their components (why needed: core technology being optimized; quick check: can explain message passing)
- **Distribution shifts**: Awareness of how data distributions can change and impact model performance (why needed: problem being addressed; quick check: can define covariate and concept shift)
- **Neural architecture search**: Understanding of architecture search spaces and evaluation protocols (why needed: framework for optimizing architectures; quick check: can describe basic search strategies)
- **Intervention in causal models**: Knowledge of how interventions modify causal relationships (why needed: core technique for removing spurious correlations; quick check: can explain do-calculus basics)

## Architecture Onboarding

**Component map**: Data Preprocessing -> Causal Subgraph Identification -> Graph Embedding Intervention -> Architecture Search -> Performance Evaluation

**Critical path**: The most critical path involves the causal subgraph identification and graph embedding intervention modules, as these directly address the core challenge of spurious correlations and distribution shifts.

**Design tradeoffs**: The method trades computational overhead for improved generalization by incorporating causal inference modules, which may increase search time but provides better out-of-distribution performance.

**Failure signatures**: Poor performance on unseen distributions, failure to improve over baselines on in-distribution data, or significant computational overhead without corresponding accuracy gains would indicate implementation or design issues.

**3 first experiments**:
1. Validate causal subgraph identification on synthetic data with known causal structures
2. Test graph embedding intervention module in isolation to verify spurious correlation removal
3. Compare architecture search performance with and without intervention modules on controlled distribution shifts

## Open Questions the Paper Calls Out
None

## Limitations
- The assumption that spurious correlations can be cleanly disentangled from causal relationships may not hold in all graph domains
- Computational overhead introduced by causal inference components is not thoroughly discussed, raising scalability concerns
- Evaluation focuses primarily on classification tasks, leaving unclear whether benefits extend to other graph learning paradigms

## Confidence

**Major Claim Confidence Labels:**
- Outperformance on synthetic datasets (High) - The controlled nature of synthetic data provides strong evidence for the method's effectiveness in ideal conditions
- Outperformance on molecular datasets (Medium) - While results show improvement, molecular datasets have inherent domain-specific properties that may not generalize to other graph types
- Generalizability to other graph domains (Low) - Limited empirical validation beyond synthetic and molecular datasets makes broader claims uncertain

## Next Checks
1. Test CARNAS on non-molecular graph datasets (e.g., social networks, citation networks, or biological interaction graphs) to evaluate cross-domain generalization
2. Conduct ablation studies specifically isolating the computational overhead of each causal module to assess scalability trade-offs
3. Extend experiments to include non-classification tasks such as graph regression or link prediction to verify method versatility beyond the demonstrated use cases