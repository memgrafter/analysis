---
ver: rpa2
title: Combining Knowledge Graphs and Large Language Models
arxiv_id: '2407.06564'
source_url: https://arxiv.org/abs/2407.06564
tags:
- knowledge
- llms
- language
- arxiv
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey paper reviews 28 recent papers on combining knowledge
  graphs (KGs) and large language models (LLMs). The authors systematically analyzed
  methods for KG-powered LLMs, LLM-based KGs, and hybrid approaches.
---

# Combining Knowledge Graphs and Large Language Models

## Quick Facts
- arXiv ID: 2407.06564
- Source URL: https://arxiv.org/abs/2407.06564
- Authors: Amanda Kau; Xuzeng He; Aishwarya Nambissan; Aland Astudillo; Hui Yin; Amir Aryani
- Reference count: 40
- Primary result: Systematic survey of 28 recent papers on KG-LLM integration methods

## Executive Summary
This survey paper systematically analyzes recent approaches to combining knowledge graphs (KGs) and large language models (LLMs). The authors identify three main integration paradigms: KG-powered LLMs, LLM-based KGs, and hybrid approaches that fuse both technologies. Their analysis reveals that combining KGs and LLMs can significantly improve model performance on knowledge-driven tasks while addressing key limitations of both technologies, such as LLM hallucinations and KG construction challenges.

## Method Summary
The paper conducts a systematic literature review by searching arXiv for recent papers combining KGs and LLMs. The authors review 28 papers, classifying them into three main approaches based on how KGs and LLMs are integrated. The analysis synthesizes key trends, techniques, and challenges across the selected papers, providing a comprehensive overview of the current state of KG-LLM integration research.

## Key Results
- KGs can enhance LLMs by providing external facts, improving interpretability, and adding semantic understanding
- LLMs can support KG construction by automating entity extraction, relation identification, and ontology alignment
- Hybrid approaches combining text and KG embeddings show improved performance on knowledge-driven tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KGs provide structured, interpretable knowledge that grounds LLM outputs, reducing hallucinations.
- Mechanism: KG facts are retrieved and injected into LLM prompts, allowing the model to base its responses on verified information rather than pure statistical inference.
- Core assumption: LLMs can effectively incorporate and utilize externally retrieved factual knowledge when it is prepended to their input.
- Evidence anchors:
  - [abstract] "These issues can be effectively mitigated by incorporating knowledge graphs (KGs), which organise information in structured formats that capture relationships between entities in a versatile and interpretable fashion."
  - [section] "A myriad of techniques have been implemented in research and industry to perform knowledge injection using KGs, usually including additional knowledge in LLM prompts as shown in Figure 2."
- Break condition: If the KG facts are not properly retrieved or are irrelevant to the query, the grounding effect fails and the LLM may still hallucinate.

### Mechanism 2
- Claim: LLMs can enhance KG construction by automating entity extraction, relation identification, and ontology alignment.
- Mechanism: LLMs process unstructured text to extract entities and relationships, which are then structured into KG triples. This automation reduces manual labor and speeds up KG creation.
- Core assumption: LLMs trained on large, diverse datasets have implicit knowledge that can be leveraged for accurate KG construction tasks.
- Evidence anchors:
  - [abstract] "Likewise, the construction and validation of KGs present challenges that LLMs can help resolve."
  - [section] "LLMs are trained on large, diverse datasets and store this knowledge implicitly. BertNet [31] sought to harvest KGs of arbitrary relations from LLMs..."
- Break condition: If the LLM's implicit knowledge is inaccurate or outdated, the resulting KG will contain errors, compromising its validity.

### Mechanism 3
- Claim: Hybrid approaches that fuse KG embeddings with LLM embeddings improve performance on knowledge-driven tasks.
- Mechanism: Textual and knowledge embeddings are combined in a unified feature space, allowing the model to leverage both the implicit knowledge of LLMs and the explicit structure of KGs simultaneously.
- Core assumption: The complementary strengths of LLMs (contextual understanding) and KGs (structured facts) can be effectively combined to enhance model performance.
- Evidence anchors:
  - [abstract] "The complementary relationship between LLMs and KGs has led to a trend that combines these technologies to achieve trustworthy results."
  - [section] "ERNIE (Enhanced Language RepresentatioN with Informative Entities) [35], which fuses lexical, syntactic, and knowledge information together by stacking a textual T-Encoder with a knowledge K-Encoder..."
- Break condition: If the fusion mechanism fails to properly align the embeddings, the model may not benefit from either knowledge source effectively.

## Foundational Learning

- Concept: Knowledge Graph Structure
  - Why needed here: Understanding how KGs represent entities and relationships is fundamental to grasping how they can enhance LLMs.
  - Quick check question: What are the basic components of a knowledge graph triple?

- Concept: Transformer Architecture
  - Why needed here: LLMs are based on transformer architecture, so understanding self-attention and token processing is crucial.
  - Quick check question: How does the self-attention mechanism in transformers process input tokens?

- Concept: Knowledge Injection Techniques
  - Why needed here: Various methods exist for incorporating KG knowledge into LLMs, and understanding these is key to implementing KG-LLM systems.
  - Quick check question: What are the differences between prepending KG facts to prompts versus using them for re-ranking?

## Architecture Onboarding

- Component map:
  - Knowledge Graph Store (graph database or triplestore) -> Knowledge Retrieval Module (SPARQL queries, vector search) -> LLM Inference Engine (transformer-based model) -> Fusion Layer (for hybrid approaches) -> Validation Layer (for KG construction with LLMs)

- Critical path:
  1. Query enters system
  2. Relevant KG facts are retrieved
  3. Facts are injected into LLM prompt
  4. LLM generates response grounded in KG knowledge
  5. Response is validated against KG (optional)

- Design tradeoffs:
  - Real-time vs. batch KG retrieval (speed vs. accuracy)
  - Simple prompt injection vs. complex fusion architectures (simplicity vs. performance)
  - Using pre-trained vs. fine-tuned LLMs (cost vs. domain specificity)

- Failure signatures:
  - Hallucinations persist despite KG injection (retrieval or injection mechanism failed)
  - Slow response times (KG retrieval is too slow or model is too large)
  - Incorrect facts in KG (LLM-generated KG construction introduced errors)

- First 3 experiments:
  1. Implement basic KG fact injection: Retrieve facts for a simple query and prepend to LLM prompt
  2. Build a hybrid model: Combine BERT with ERNIE's K-Encoder for entity typing task
  3. Create an LLM-assisted KG: Use an LLM to extract entities and relations from unstructured text to populate a small KG

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the effectiveness of knowledge integration be improved beyond simply increasing the size of the Knowledge Integration corpus?
- Basis in paper: [explicit] The paper states that "according to a study from [42], only a marginal amount of knowledge is successfully integrated into two well-known knowledge-enhanced Language Models (LM), namely ERNIE and K-Adapter, and simply increasing the size of the Knowledge Integration corpus may not lead to better knowledge-enhanced LMs."
- Why unresolved: Current approaches show limited success in effectively integrating knowledge from KGs into LLMs, and simply increasing the corpus size does not yield better results.
- What evidence would resolve it: Research demonstrating novel architectural modifications or fine-tuning strategies that significantly improve the integration of KG knowledge into LLMs, with quantitative comparisons to existing methods.

### Open Question 2
- Question: What are the potential benefits and challenges of combining multimodal KGs with LLMs?
- Basis in paper: [inferred] The paper mentions the recent surge in interest in multimodal LLMs and suggests exploring the potential use of multimodal KGs when combined with LLMs for the recent advances in the research of multimodal models.
- Why unresolved: While multimodal LLMs are gaining traction, the specific benefits and challenges of integrating them with multimodal KGs remain unexplored.
- What evidence would resolve it: Studies presenting concrete examples of multimodal KG-LLM integration, discussing the unique advantages and limitations compared to unimodal approaches, along with empirical results on relevant tasks.

### Open Question 3
- Question: How can we develop smaller integrated KG-LLM models that maintain or improve performance while reducing computational resources?
- Basis in paper: [explicit] The paper highlights that integrating KGs and LLMs can lead to larger parameter sizes and longer running times, and suggests developing smaller integrated models to reduce computational resources.
- Why unresolved: Current integrated models often suffer from increased computational costs, and finding a balance between model size and performance remains a challenge.
- What evidence would resolve it: Research demonstrating the development of smaller KG-LLM models that achieve comparable or superior performance to larger models, with detailed analyses of the architectural choices and training strategies employed.

## Limitations
- Analysis may miss non-English works, preprints, or industry research not publicly available
- Classification of methods into three main approaches may oversimplify nuanced techniques
- Performance improvements are reported without always quantifying the magnitude of gains or providing comparative baselines

## Confidence

**High confidence**: KGs can enhance LLMs by providing external facts, improving interpretability, and adding semantic understanding - supported by multiple papers demonstrating reduced hallucinations and better factuality when KG facts are injected into prompts.

**Medium confidence**: LLMs can support KG construction and temporal forecasting - while papers demonstrate this capability, the quality and accuracy of LLM-generated KGs vary significantly based on model size and domain specificity.

**Medium confidence**: Hybrid approaches combining text and KG embeddings show improved performance on knowledge-driven tasks - though promising, the optimal fusion mechanisms and their effectiveness across different domains require further validation.

## Next Checks

1. **Replicate KG fact injection experiment**: Implement a simple system that retrieves KG facts for a set of questions and measures hallucination reduction compared to baseline LLM responses without KG grounding.

2. **Benchmark hybrid embedding performance**: Compare a standard BERT model against an ERNIE-style hybrid model on a standard entity typing or relation classification dataset to quantify the performance gains from KG integration.

3. **Evaluate LLM-generated KG quality**: Use an LLM to extract entities and relations from unstructured text, then assess the accuracy of the generated triples against a gold standard KG using precision, recall, and F1 metrics.