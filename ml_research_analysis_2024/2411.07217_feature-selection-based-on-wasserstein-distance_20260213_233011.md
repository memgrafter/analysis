---
ver: rpa2
title: Feature Selection Based on Wasserstein Distance
arxiv_id: '2411.07217'
source_url: https://arxiv.org/abs/2411.07217
tags:
- feature
- distance
- data
- selection
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel feature selection method based on
  the Wasserstein distance, addressing limitations of traditional methods that use
  correlation or Kullback-Leibler (KL) divergence. The proposed approach inherently
  captures class relationships and demonstrates robustness to noisy labels without
  requiring specific noise models.
---

# Feature Selection Based on Wasserstein Distance

## Quick Facts
- arXiv ID: 2411.07217
- Source URL: https://arxiv.org/abs/2411.07217
- Authors: Fuwei Li
- Reference count: 39
- Key outcome: Novel feature selection method using Wasserstein distance demonstrates superiority over traditional correlation and KL divergence methods, particularly in noisy label settings

## Executive Summary
This paper introduces a feature selection method based on the Wasserstein distance that addresses limitations of traditional approaches using correlation or KL divergence. The method inherently captures class relationships through a ground metric and demonstrates robustness to noisy labels without requiring specific noise models. A Markov blanket-based algorithm is developed with computational complexity analysis, and theoretical bounds show effectiveness in noisy settings. Experimental results across text, email, and image classification datasets demonstrate consistent superiority over traditional methods.

## Method Summary
The proposed method uses the Wasserstein distance between conditional class distributions to select features. For each feature Xi, it computes δ(Xi) as the expected Wasserstein distance between p(Y|XGi, Xi) and p(Y|XGi), where XGi represents the L most correlated features with Xi. Features with minimum δ values are iteratively removed until K features remain. The approach uses entropy-regularized Wasserstein distance for computational efficiency and incorporates a distance matrix D that captures semantic relationships between classes.

## Key Results
- Wasserstein distance-based feature selection outperforms KL divergence-based methods on three datasets (Enron emails, Yahoo/Flickr 100M, 20 Newsgroups)
- The method shows consistent superiority across different evaluation metrics and dataset types
- Theoretical analysis provides lower bounds on performance in noisy label settings
- Computational complexity is O(M³ + M²N + M²²LNn²c) where M is feature count, N is sample count, L is conditional feature count, n is feature value count, and c is class count

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Wasserstein distance inherently captures inter-class relationships through its ground metric, enabling more discriminative feature selection than KL divergence.
- Mechanism: By incorporating a distance matrix D that quantifies dissimilarity between classes, the Wasserstein distance penalizes misclassifications based on class similarity.
- Core assumption: A meaningful ground metric D can be constructed for the specific classification problem that reflects true semantic or hierarchical relationships between classes.
- Evidence anchors: Abstract states approach "inherently capturing class relationships"; section describes proposed Markov blanket algorithm; corpus contains related work but no direct validation.

### Mechanism 2
- Claim: The Wasserstein distance provides robustness to label noise without requiring specific noise models.
- Mechanism: Since label noise typically occurs between similar classes, the Wasserstein distance's incorporation of class similarity naturally reduces the impact of such noise.
- Core assumption: Label noise follows the pattern of being more likely between similar classes than dissimilar ones.
- Evidence anchors: Abstract mentions effectiveness in reducing impact of noisy labels; section analyzes performance under noisy settings; corpus contains related work but no direct comparison.

### Mechanism 3
- Claim: The Markov Blanket framework with Wasserstein distance enables efficient feature selection by identifying features whose removal minimally affects class conditional distributions.
- Mechanism: By computing δ(Xi) as the expected Wasserstein distance between conditional distributions, the algorithm iteratively removes features that contribute least to class discrimination.
- Core assumption: The Markov Blanket properties hold under the Wasserstein distance measure.
- Evidence anchors: Section explains relationship between δ(Xi) and conditional independence; corpus doesn't address Markov Blanket properties under Wasserstein distance.

## Foundational Learning

- Concept: Earth Mover's Distance / Optimal Transport
  - Why needed here: Understanding the mathematical foundation of Wasserstein distance is crucial for implementing the feature selection algorithm.
  - Quick check question: How does the cost matrix D influence the Wasserstein distance computation between two class conditional distributions?

- Concept: Markov Blanket in Probabilistic Graphical Models
  - Why needed here: The feature selection algorithm relies on identifying and removing features outside the Markov Blanket of the class variable.
  - Quick check question: In a directed graphical model, what nodes constitute the Markov Blanket of a target node?

- Concept: Entropy Regularization for Computational Efficiency
  - Why needed here: The paper uses entropy-regularized Wasserstein distance for computational efficiency, essential for scaling to larger problems.
  - Quick check question: How does adding an entropy regularization term affect the computational complexity and solution properties of the Wasserstein distance?

## Architecture Onboarding

- Component map: Distance matrix construction -> Feature correlation computation -> Conditional distribution estimation -> Wasserstein distance computation -> δ(Xi) calculation -> Feature elimination loop -> Final feature selection output

- Critical path:
  1. Precompute feature correlation matrix
  2. For each feature to be eliminated:
     - Find L most correlated features
     - Estimate conditional distributions
     - Compute Wasserstein distances
     - Calculate δ(Xi)
     - Select and remove feature with minimum δ
  3. Return remaining K features

- Design tradeoffs:
  - L (number of conditional features) vs. computational cost: Larger L provides better Markov Blanket approximation but increases complexity
  - Entropy regularization strength λ vs. accuracy: Higher λ speeds computation but may reduce Wasserstein distance accuracy
  - Discrete vs. continuous feature handling: Current algorithm assumes discrete features; continuous features require discretization or different estimation methods

- Failure signatures:
  - Degenerate distance matrix (all zeros or uniform values) → loss of class relationship information
  - High computational time for large M and L → consider approximation methods or parallel computation
  - Unstable δ(Xi) values across iterations → check conditional distribution estimation quality and correlation matrix

- First 3 experiments:
  1. Implement Wasserstein distance computation with simple synthetic data and verify it captures class relationships better than KL divergence
  2. Test the full feature selection algorithm on a small text classification dataset with known hierarchical label structure
  3. Evaluate noise robustness by introducing controlled label noise and comparing Wasserstein vs KL-based feature selection performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the class distance matrix D be automatically learned or estimated from data without manual specification?
- Basis in paper: The paper acknowledges that "the distance matrix used in the algorithm is hard to define and it varies from datasets to datasets" and suggests this as future work.
- Why unresolved: Current implementation requires manual specification of class distances based on domain knowledge, which limits scalability and general applicability.
- What evidence would resolve it: A method that can automatically learn or estimate the distance matrix from data, demonstrated across multiple datasets with varying label structures.

### Open Question 2
- Question: What is the optimal value of L (number of most relevant features to consider when computing δ(Xi)) for different dataset characteristics?
- Basis in paper: The paper uses L=3 in experiments but states "we find the top-L most relevant features with Xi" without providing guidance on how to choose L.
- Why unresolved: The choice of L affects both computational complexity and selection accuracy, but the paper doesn't analyze how L impacts performance across different datasets.
- What evidence would resolve it: Systematic experiments showing how different L values affect feature selection quality across various dataset types, with recommendations for different scenarios.

### Open Question 3
- Question: How does the Wasserstein distance-based feature selection algorithm perform compared to other advanced feature selection methods (e.g., deep learning-based approaches) on high-dimensional data?
- Basis in paper: The paper compares only to KL-distance-based methods and wrapper/embedded methods are mentioned as having high computational complexity.
- Why unresolved: The experiments focus on moderate-dimensional datasets, and the computational complexity analysis suggests potential challenges with very high-dimensional data where deep learning methods might excel.
- What evidence would resolve it: Comparative experiments on high-dimensional datasets against state-of-the-art deep learning feature selection methods, including scalability analysis.

## Limitations

- The method requires manual specification of a class distance matrix D, which may not be meaningful or available for all classification problems
- Computational complexity of O(M³ + M²N + M²²LNn²c) may be prohibitive for very high-dimensional datasets
- Theoretical analysis provides only a lower bound on performance in noisy settings, leaving the actual effectiveness gap unexplored

## Confidence

- Mechanism 1 (class relationship capture): Medium - theoretically sound but limited empirical validation
- Mechanism 2 (noise robustness): Medium - theoretical promise but requires stronger empirical evidence
- Mechanism 3 (Markov Blanket framework): Low - limited theoretical justification for Wasserstein distance properties in this context

## Next Checks

1. Conduct ablation studies removing the ground metric D to verify its contribution to performance improvements
2. Test on additional datasets with known class hierarchies to strengthen evidence for class relationship capture
3. Implement controlled label noise experiments across multiple noise levels to quantify the robustness advantage