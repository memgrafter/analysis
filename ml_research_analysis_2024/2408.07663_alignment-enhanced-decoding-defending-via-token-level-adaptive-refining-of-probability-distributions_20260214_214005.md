---
ver: rpa2
title: Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of
  Probability Distributions
arxiv_id: '2408.07663'
source_url: https://arxiv.org/abs/2408.07663
tags:
- index
- arxiv
- jailbreak
- competitive
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the vulnerability of large language models
  to jailbreak attacks, which can lead to the generation of harmful content. The proposed
  method, Alignment-Enhanced Decoding (AED), employs adaptive decoding to refine the
  probability distribution of each token, enhancing safety alignment while maintaining
  helpfulness.
---

# Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions

## Quick Facts
- arXiv ID: 2408.07663
- Source URL: https://arxiv.org/abs/2408.07663
- Reference count: 40
- The paper proposes Alignment-Enhanced Decoding (AED) to defend large language models against jailbreak attacks, achieving near-100% rejection rates while maintaining functionality on harmless queries.

## Executive Summary
This paper introduces Alignment-Enhanced Decoding (AED), a novel defense mechanism against jailbreak attacks on large language models. The approach uses a Competitive Index to quantify the risk of alignment failure at each token generation step, then adaptively refines the probability distribution to suppress harmful outputs. Unlike existing defenses, AED leverages the model's own self-evaluation through post-alignment logits, requiring no additional training. Experiments across five models and four common jailbreak attack methods demonstrate that AED effectively counters these attacks while maintaining the model's performance on standard question-answering tasks.

## Method Summary
AED works by computing a Competitive Index (I) that measures the degree of competition between helpful and harmful objectives during token prediction. For each token, AED calculates the original model logits and post-alignment logits (obtained by truncating the model's output and using it as an auxiliary input). These logits are then combined with a tuning coefficient c, which is calculated based on the Competitive Index and a bias term. The tuning coefficient gives more weight to post-alignment logits when the risk of jailbreak is high, effectively suppressing harmful candidate tokens while preserving helpful ones.

## Key Results
- AED achieves near-100% rejection rates against jailbreak attacks across five models and four attack methods
- The method maintains Not Rejection Rates (NRR) above 90% on harmless datasets including MMLU, GMS8K, and Alpaca
- AED introduces minimal computational overhead with an Average Token Generation Time ratio close to 1

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Competitive Index (I) quantifies the degree of competition between helpfulness and harmless objectives during token prediction.
- Mechanism: I is computed as the ratio of the candidate set size S (tokens with probability mass â‰¥ p0) to a model-determined threshold St. When S is large relative to St, more conflicting candidate tokens exist, indicating higher competition and jailbreak risk.
- Core assumption: The size of the candidate set S increases significantly for jailbreak queries compared to harmless ones, and this increase is proportional to the degree of conflicting objectives.
- Evidence anchors:
  - [abstract] "We define the Competitive Index to quantify alignment failures and to represent the risk of the model being jailbroken."
  - [section] "When predicting the next token, AED adaptively refines the original logits based on the Competitive Index and the post-alignment logits."
  - [corpus] "Certain but not Probable? Differentiating Certainty from Probability in LLM Token Outputs for Probabilistic Scenarios" suggests using token logits to quantify uncertainty, supporting the use of candidate set size as a measure of competition.
- Break condition: If the increase in candidate set size is not significantly larger for jailbreak queries, or if St is poorly estimated, the Competitive Index may not accurately reflect the degree of competition.

### Mechanism 2
- Claim: AED adaptively refines the probability distribution of each token to enhance safety alignment while maintaining helpfulness.
- Mechanism: AED computes the post-alignment logits Lpost by truncating the model's output and using it as an auxiliary input. It then combines the original logits Lmodel and post-alignment logits Lpost with a tuning coefficient c to obtain the refined logits LAED. The tuning coefficient c is calculated based on the Competitive Index and a bias term, giving more weight to post-alignment logits when the risk of jailbreak is high.
- Core assumption: The model's self-evaluation through post-alignment logits can effectively identify and suppress harmful candidate tokens, and the tuning coefficient can appropriately balance the influence of original and post-alignment logits.
- Evidence anchors:
  - [abstract] "AED adaptively combines Competitive Index and post-alignment logits with the original logits to obtain harmless and helpful distributions."
  - [section] "We propose the Alignment-Enhanced Decoding (AED), a novel defense method that adaptively refines the distribution of each generation step."
  - [corpus] "Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection" suggests using logits to select appropriate tokens, supporting the use of post-alignment logits in AED.
- Break condition: If the post-alignment logits do not effectively identify harmful candidate tokens, or if the tuning coefficient is not appropriately calculated, AED may not effectively enhance safety alignment.

### Mechanism 3
- Claim: AED achieves high rejection rates against jailbreak attacks while maintaining functionality on harmless queries.
- Mechanism: AED leverages the Competitive Index to identify jailbreak queries and adaptively refines the token distribution to suppress harmful candidate tokens. The method does not require additional training and introduces minimal computational overhead.
- Core assumption: The Competitive Index effectively distinguishes jailbreak queries from harmless ones, and the adaptive refinement of token distribution does not significantly impact the model's performance on harmless queries.
- Evidence anchors:
  - [abstract] "AED effectively counters a range of sophisticated jailbreak attacks... while maintaining the model's functionality in standard question-answering tasks."
  - [section] "We conduct extensive experiments of AED across five models, utilizing four attack methods. Then, we evaluated the performance of AED on three harmless datasets."
  - [corpus] "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding" also aims to enhance model defense without additional training, supporting the feasibility of AED's approach.
- Break condition: If the Competitive Index fails to accurately identify jailbreak queries, or if the adaptive refinement significantly impacts the model's performance on harmless queries, AED may not achieve the desired rejection rates and functionality.

## Foundational Learning

- Concept: Token probability distribution and Top-p sampling
  - Why needed here: AED relies on refining the probability distribution of each token, which is obtained through Top-p sampling. Understanding how Top-p sampling works is crucial for implementing AED.
  - Quick check question: What is the purpose of the threshold p0 in Top-p sampling, and how does it affect the candidate set size S?

- Concept: Logits and softmax function
  - Why needed here: AED manipulates the logits (unnormalized log probabilities) of candidate tokens and uses the softmax function to obtain the final probability distribution. Familiarity with logits and the softmax function is essential for understanding AED's inner workings.
  - Quick check question: How does the softmax function transform logits into probabilities, and what is the role of the temperature parameter in this process?

- Concept: Self-evaluation and post-alignment logits
  - Why needed here: AED utilizes the model's self-evaluation through post-alignment logits, which are obtained by truncating the model's output and using it as an auxiliary input. Understanding how to compute and use post-alignment logits is crucial for implementing AED.
  - Quick check question: How are post-alignment logits different from the original model logits, and why are they used in AED's adaptive refinement process?

## Architecture Onboarding

- Component map: Input processing -> Competitive Index calculation -> Logits computation -> Adaptive refinement -> Output generation
- Critical path:
  1. Compute the Competitive Index based on the candidate set size and model threshold
  2. Calculate the post-alignment logits by truncating the model's output and using it as an auxiliary input
  3. Combine the original and post-alignment logits with the tuning coefficient to obtain the refined logits
  4. Sample the next token from the refined probability distribution
- Design tradeoffs:
  - Computational overhead: AED introduces additional computations for the Competitive Index and post-alignment logits, but aims to minimize the impact on inference time.
  - Safety vs. helpfulness: AED balances the need for safety alignment with maintaining the model's functionality on harmless queries by adaptively refining the token distribution based on the Competitive Index.
- Failure signatures:
  - High rejection rates on harmless queries: Indicates that the Competitive Index may be too sensitive, leading to false positives.
  - Low rejection rates on jailbreak queries: Suggests that the post-alignment logits or tuning coefficient may not effectively suppress harmful candidate tokens.
  - Significant increase in inference time: Implies that the additional computations in AED are not optimized, impacting the overall efficiency.
- First 3 experiments:
  1. Implement AED on a simple language model and test its performance on a set of harmless and jailbreak queries. Measure the rejection rates and compare them to the baseline model without AED.
  2. Vary the bias term Bbias in the tuning coefficient calculation and observe its impact on the rejection rates and functionality on harmless queries.
  3. Experiment with different values of the candidate set size threshold St and assess its effect on the Competitive Index and overall performance of AED.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do variations in model architecture and training data influence the Competitive Index (I) across different LLMs?
- Basis in paper: [inferred] The paper notes variations in the Competitive Index across different models but does not extensively explore why these variations occur.
- Why unresolved: The study acknowledges that differences in model architecture and training data may influence the Competitive Index but does not delve into specific mechanisms or factors that cause these variations.
- What evidence would resolve it: Detailed comparative studies analyzing the relationship between model architectures, training datasets, and the resulting Competitive Index values would help clarify the influence of these factors.

### Open Question 2
- Question: Why do some jailbreak samples result in Competitive Index values that are significantly higher than others, reaching up to 100 times the threshold?
- Basis in paper: [explicit] The paper mentions that some jailbreak samples have Competitive Index values much higher than others but does not investigate why these disparities exist.
- Why unresolved: The paper does not explore the underlying reasons for the wide range of Competitive Index values observed in different jailbreak samples.
- What evidence would resolve it: Further analysis of the characteristics of jailbreak prompts that lead to higher Competitive Index values, possibly through a systematic examination of prompt structures and content, could provide insights into this variation.

### Open Question 3
- Question: How does the inclusion of system prompts affect the Competitive Index, and why does it lead to a decrease in competition?
- Basis in paper: [explicit] The paper observes that incorporating system prompts leads to a noticeable decrease in the Competitive Index, suggesting a reduction in competition, but does not explore the underlying reasons for this effect.
- Why unresolved: While the paper demonstrates that system prompts can reduce the Competitive Index, it does not investigate the mechanisms by which this occurs.
- What evidence would resolve it: Experimental studies examining the impact of different types and phrasings of system prompts on the Competitive Index could elucidate the reasons behind the observed decrease in competition.

## Limitations
- Implementation Specificity: The paper lacks detailed implementation specifications for critical components, particularly the self-evaluation mechanism for computing post-alignment logits (Equation 7) and the exact values for the threshold I_t and bias B_bias parameters.
- Attack Methodology Scope: The paper evaluates against four jailbreak attack methods but doesn't address how AED would perform against zero-shot jailbreak attempts or more sophisticated adversarial techniques.
- Generalization Concerns: The experiments focus primarily on English-language prompts and well-known harmful content categories, with limited exploration of cross-lingual or culturally diverse scenarios.

## Confidence
- High Confidence: The core mathematical framework for the Competitive Index and the adaptive refinement mechanism is clearly specified and internally consistent.
- Medium Confidence: The empirical results demonstrating near-100% rejection rates against jailbreak attacks are compelling but limited in scope, with restricted number of models and attack methods.
- Low Confidence: The claim that AED maintains model functionality on harmless queries while defending against attacks is less substantiated, with limited qualitative analysis of unintended biases or behavioral alterations.

## Next Checks
1. **Parameter Sensitivity Analysis**: Systematically vary the threshold I_t and bias B_bias parameters across multiple orders of magnitude to determine their impact on both rejection rates and harmless query performance.
2. **Cross-Lingual and Cultural Testing**: Evaluate AED on non-English prompts and culturally diverse harmful content scenarios to assess whether the Competitive Index approach generalizes beyond the English-language, Western-centric examples used in the paper.
3. **Transferability Testing**: Apply AED to models that weren't used in training the post-alignment logits (e.g., models from different families or with different architectures) to determine whether the self-evaluation mechanism generalizes across model types or requires model-specific calibration.