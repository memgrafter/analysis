---
ver: rpa2
title: What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Gaussian-Noise-free
  Text-Image Corruption and Evaluation
arxiv_id: '2406.16320'
source_url: https://arxiv.org/abs/2406.16320
tags:
- image
- heads
- patching
- corruption
- blip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NOTICE, a noise-free text-image corruption
  and evaluation pipeline for mechanistic interpretability in Vision-Language Models
  (VLMs). NOTICE uses Semantic Image Pairs (SIP) for image corruption and Symmetric
  Token Replacement (STR) for text, enabling causal mediation analysis across both
  modalities.
---

# What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Gaussian-Noise-free Text-Image Corruption and Evaluation

## Quick Facts
- arXiv ID: 2406.16320
- Source URL: https://arxiv.org/abs/2406.16320
- Reference count: 20
- Introduces noise-free text-image corruption pipeline for VLM mechanistic interpretability

## Executive Summary
This paper presents NOTICE, a novel mechanistic interpretability pipeline designed to understand how Vision-Language Models (VLMs) process and integrate multimodal information. The framework introduces a noise-free corruption approach using Semantic Image Pairs (SIP) and Symmetric Token Replacement (STR) to enable causal mediation analysis across both text and image modalities. The study applies this methodology to BLIP and LLaVA models, revealing distinct functional roles for cross-attention and self-attention mechanisms in multimodal processing.

The research identifies "universal attention heads" that consistently contribute across different tasks and modalities, demonstrating that cross-attention heads in BLIP perform object detection, object suppression, and outlier suppression, while self-attention heads in LLaVA primarily handle outlier suppression. These findings provide crucial insights into the specialized functions of attention mechanisms in VLMs, particularly highlighting the unique role of cross-attention in grounding visual information to textual context.

## Method Summary
NOTICE employs a noise-free corruption strategy using Semantic Image Pairs (SIP) for image corruption and Symmetric Token Replacement (STR) for text corruption, enabling causal mediation analysis across both modalities. The pipeline systematically corrupts specific components of the input while preserving the overall structure, allowing researchers to isolate and measure the contribution of individual attention heads to model performance. By applying this framework to BLIP and LLaVA, the study can attribute specific functional roles to different attention heads based on their impact on task performance when corrupted.

## Key Results
- Cross-attention heads in BLIP perform object detection, object suppression, and outlier suppression
- Self-attention heads in LLaVA primarily handle outlier suppression
- Identification of "universal attention heads" that consistently contribute across tasks and modalities
- Distinct roles of cross-attention and self-attention in multimodal integration, with cross-attention uniquely responsible for image grounding

## Why This Works (Mechanism)
The noise-free corruption approach allows for precise attribution of functional roles to specific attention heads by systematically disabling their contributions while maintaining overall input structure. The Semantic Image Pairs (SIP) and Symmetric Token Replacement (STR) techniques enable controlled perturbations that isolate the effects of individual components. Causal mediation analysis then quantifies how much each attention head contributes to task performance when its functionality is disrupted, revealing their specialized roles in multimodal processing.

## Foundational Learning

1. **Vision-Language Models (VLMs)**
   - Why needed: Understanding the architecture and capabilities of models that process both visual and textual information
   - Quick check: Review the basic architecture of BLIP and LLaVA models

2. **Attention Mechanisms**
   - Why needed: Core component of VLMs that enables information integration across modalities
   - Quick check: Understand the difference between cross-attention and self-attention

3. **Mechanistic Interpretability**
   - Why needed: Framework for understanding how neural networks process information at a component level
   - Quick check: Review causal mediation analysis techniques

4. **Semantic Image Pairs**
   - Why needed: Method for creating noise-free image corruption while preserving semantic structure
   - Quick check: Understand how SIP maintains semantic consistency during corruption

5. **Causal Mediation Analysis**
   - Why needed: Statistical framework for quantifying the contribution of specific model components
   - Quick check: Review how mediation analysis attributes performance changes to corrupted components

## Architecture Onboarding

**Component Map:**
NOTICE Pipeline -> BLIP/LLaVA Model -> Attention Heads -> Task Performance

**Critical Path:**
1. Input processing with SIP and STR corruption
2. Model inference with corrupted inputs
3. Performance measurement and attribution
4. Head role identification through causal mediation

**Design Tradeoffs:**
- Noise-free corruption vs. real-world noise patterns
- Controlled experiments vs. ecological validity
- Attribution precision vs. computational complexity

**Failure Signatures:**
- Over-attribution of head roles due to correlation vs. causation
- Inconsistent results across different corruption intensities
- Limited generalizability to other VLM architectures

**Three First Experiments:**
1. Test head role attributions with varying corruption intensities
2. Apply pipeline to additional VLM architectures for validation
3. Compare noise-free corruption results with traditional noise injection methods

## Open Questions the Paper Calls Out
None

## Limitations
- Noise-free corruption may not capture real-world visual noise patterns
- BLIP and LLaVA model choices may limit generalizability to other architectures
- Statistical significance of "universal attention heads" claims needs further validation

## Confidence
- High confidence in pipeline methodology and noise-free corruption framework
- Medium confidence in cross-attention vs. self-attention role differentiation
- Medium confidence in "universal attention heads" claims
- Medium confidence in specific head role attributions for BLIP and LLaVA

## Next Checks
1. Test the noise-free corruption approach on additional VLM architectures (e.g., CLIP, Flamingo) to verify the generalizability of the "universal attention heads" finding and head role attributions

2. Conduct ablation studies varying corruption intensity and replacement strategies to assess the robustness of causal mediation analysis results

3. Perform qualitative analysis on a broader set of tasks and visual concepts to validate whether the identified head roles (object detection, object suppression, outlier suppression) hold consistently across different visual domains and complexity levels