---
ver: rpa2
title: Evaluating and Mitigating Linguistic Discrimination in Large Language Models
arxiv_id: '2404.18534'
source_url: https://arxiv.org/abs/2404.18534
tags:
- languages
- llms
- language
- safety
- ldfighter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses linguistic discrimination in large language
  models (LLMs), where models perform inconsistently across different languages due
  to uneven training data distribution. The authors systematically analyze this discrimination
  in four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo, and Gemini-pro) using two datasets
  (AdvBench and NQ) across 74 languages.
---

# Evaluating and Mitigating Linguistic Discrimination in Large Language Models

## Quick Facts
- arXiv ID: 2404.18534
- Source URL: https://arxiv.org/abs/2404.18534
- Reference count: 39
- Key outcome: LDFighter reduces jailbreak success rates and improves response quality across multilingual LLMs by translating queries into multiple languages and selecting the most consistent answer

## Executive Summary
This paper addresses linguistic discrimination in large language models (LLMs), where models perform inconsistently across different languages due to uneven training data distribution. The authors systematically analyze this discrimination in four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo, and Gemini-pro) using two datasets (AdvBench and NQ) across 74 languages. They find significant disparities in both safety (jailbreak rates) and quality (F1-scores) between high-resource languages (e.g., English, French, Russian) and low-resource languages (e.g., Bengali, Georgian, Nepali). To mitigate this issue, they propose LDFighter, a lightweight similarity-based voting approach that translates queries into multiple languages, aggregates responses, and selects the most consistent answer. LDFighter significantly reduces jailbreak success rates and improves response quality across all evaluated LLMs, with minimal runtime overhead.

## Method Summary
The authors systematically evaluate four multilingual LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo, and Gemini-pro) for linguistic discrimination using two datasets (AdvBench and NQ) across 74 languages. They measure performance disparities in safety (jailbreak rates) and quality (F1-scores) between high-resource and low-resource languages. To mitigate these disparities, they propose LDFighter, which translates queries into multiple languages, collects responses, translates them back to English, and uses similarity-based voting to select the most consistent response. The approach leverages the observation that harmful queries produce more varied responses across languages than benign queries, allowing similarity voting to reduce jailbreak success rates while improving overall response quality.

## Key Results
- Multilingual LLMs show significant performance disparities, with high-resource languages achieving lower jailbreak rates and higher F1-scores than low-resource languages
- LDFighter reduces jailbreak success rates to 0.0 for GPT-3.5, Gemini-pro, and Llama2-13b when using top-3 languages
- LDFighter improves average F1-scores across all evaluated LLMs compared to original performance
- The approach achieves these improvements with minimal runtime overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LDFighter reduces multilingual jailbreak rates by translating the query into multiple languages and selecting the most consistent response.
- Mechanism: When a harmful query is translated into multiple languages, the model's inconsistent responses to different translations are averaged out by the similarity-based voting, reducing the chance of jailbreak.
- Core assumption: Harmful queries produce more varied responses across languages than benign queries.
- Evidence anchors:
  - [abstract] "LDFighter significantly reduces jailbreak success rates and improves response quality across all evaluated LLMs, with minimal runtime overhead."
  - [section 4.3] "When the value of ùëò is set to be 3 or above, the MJR of each LLM drops significantly compared to the original MJR. Particularly, the MJR of GPT-3.5, Gemini-pro and Llama2-13b falls straight to 0.0 when using the top three languages..."
- Break condition: If harmful queries produce highly consistent responses across languages, similarity-based voting will fail to reduce jailbreak rates.

### Mechanism 2
- Claim: LDFighter improves response quality by selecting the most similar response among multiple language translations.
- Mechanism: Benign queries typically have more consistent correct answers across languages, so similarity-based voting selects the most accurate response.
- Core assumption: Correct answers to benign queries are more similar across languages than incorrect ones.
- Evidence anchors:
  - [abstract] "LDFighter not only significantly reduces the jailbreak success rate but also improve the response quality on average, demonstrating its effectiveness."
  - [section 4.3] "Compared to the original average ùêπ1-score, all LLMs experience an increase in average ùêπ1-score with LDFighter, though the extent varies."
- Break condition: If correct answers vary significantly across languages due to cultural or linguistic differences, similarity-based voting may select suboptimal responses.

### Mechanism 3
- Claim: LDFighter ensures consistency across languages by translating responses to a pivot language and comparing embeddings.
- Mechanism: By translating all responses to English and comparing their embeddings, LDFighter can objectively measure similarity regardless of the original language.
- Core assumption: English serves as a sufficiently neutral pivot language for comparing multilingual responses.
- Evidence anchors:
  - [abstract] "LDFighter translates queries into ùëò selected languages... translates all the responses into a pivot language, i.e., English, and select the final response to the user through similarity-based voting."
  - [section 4.1] "Given a set of responses R in English translated from different languages, each response is first encoded into a vector, resulting in a set of vectors V"
- Break condition: If English translations introduce significant distortion or bias, the similarity measurement becomes unreliable.

## Foundational Learning

- Concept: Multilingual training data distribution
  - Why needed here: Understanding why LLMs perform differently across languages requires knowing how training data is distributed across languages.
  - Quick check question: If English has 100x more training data than Bengali, what would you expect regarding model performance on these languages?

- Concept: Embedding similarity and cosine distance
  - Why needed here: LDFighter relies on comparing response embeddings to select the most consistent answer, requiring understanding of vector similarity metrics.
  - Quick check question: If two response embeddings have cosine similarity of 0.9, how similar are they compared to embeddings with similarity 0.3?

- Concept: Jailbreak attack patterns
  - Why needed here: Evaluating LDFighter's effectiveness requires understanding how jailbreak attacks work and why they might succeed more in certain languages.
  - Quick check question: Why might a model be more susceptible to jailbreak in low-resource languages compared to high-resource languages?

## Architecture Onboarding

- Component map: Original query ‚Üí Translation module ‚Üí LLM interface ‚Üí Response collection ‚Üí Back-translation ‚Üí Embedding engine ‚Üí Voting mechanism ‚Üí Output layer
- Critical path: Query ‚Üí Translation ‚Üí LLM ‚Üí Response collection ‚Üí Back-translation ‚Üí Embedding ‚Üí Voting ‚Üí Output
- Design tradeoffs:
  - More languages (higher k) improves consistency but increases latency and cost
  - Using a single pivot language simplifies implementation but may introduce bias
  - Real-time translation vs. cached translations affects performance
- Failure signatures:
  - Consistently poor performance in specific language pairs suggests translation quality issues
  - No improvement with additional languages indicates similarity voting isn't working
  - High latency suggests translation or embedding bottlenecks
- First 3 experiments:
  1. Test with k=1 (only English) to establish baseline performance
  2. Test with k=3 (top 3 languages by CI score) to find optimal language selection
  3. Test with adversarial prompts to verify jailbreak resistance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the linguistic performance disparities in LLMs evolve as these models continue to scale in size and complexity?
- Basis in paper: [explicit] The paper discusses linguistic discrimination in LLMs but does not explore how model size impacts this discrimination.
- Why unresolved: The study focuses on specific LLMs of fixed sizes and does not address the potential impact of scaling on linguistic discrimination.
- What evidence would resolve it: Comparative analysis of linguistic discrimination across different model sizes and parameter counts, showing trends in performance disparities.

### Open Question 2
- Question: What are the long-term effects of using LDFighter on the overall quality and safety of LLM responses across diverse languages?
- Basis in paper: [explicit] The paper introduces LDFighter as a solution to mitigate linguistic discrimination but does not explore its long-term effects.
- Why unresolved: The study evaluates the immediate effectiveness of LDFighter but lacks a longitudinal analysis of its impact.
- What evidence would resolve it: Longitudinal studies tracking the performance of LLMs with LDFighter over extended periods, measuring changes in safety and quality metrics.

### Open Question 3
- Question: How does the linguistic discrimination in LLMs affect user trust and engagement in non-English speaking regions?
- Basis in paper: [inferred] The paper highlights significant disparities in LLM performance across languages, which could impact user experience.
- Why unresolved: The study does not address the user-centric implications of linguistic discrimination.
- What evidence would resolve it: User studies and surveys in non-English speaking regions, measuring trust and engagement levels before and after implementing solutions like LDFighter.

### Open Question 4
- Question: Can the linguistic discrimination in LLMs be mitigated by incorporating more diverse and representative training data from low-resource languages?
- Basis in paper: [explicit] The paper identifies uneven training data distribution as a cause of linguistic discrimination but does not explore data augmentation strategies.
- Why unresolved: The study focuses on post-training solutions like LDFighter rather than pre-training data improvements.
- What evidence would resolve it: Experimental results comparing LLMs trained on augmented datasets with diverse linguistic representation against those trained on standard datasets.

## Limitations
- Evaluation scope limited to 74 languages and relatively small test sets (30 harmful and 30 benign queries per language)
- Does not address other potential sources of linguistic discrimination beyond uneven training data distribution
- Assumes consistent responses across languages indicate correctness, which may not hold for culturally or linguistically diverse queries

## Confidence
**High Confidence Claims:**
- Multilingual LLMs exhibit significant performance disparities across languages, with high-resource languages consistently outperforming low-resource languages
- LDFighter successfully reduces jailbreak rates across all evaluated models when using 3+ languages
- Response quality (F1-score) improves with LDFighter implementation across all tested LLMs

**Medium Confidence Claims:**
- The relationship between training data distribution and performance gaps is causal rather than correlational
- English serves as an effective pivot language for cross-lingual response comparison
- Three languages provide sufficient coverage for meaningful consistency-based voting

**Low Confidence Claims:**
- LDFighter will generalize to all possible query types and languages beyond the tested 74
- The similarity-based voting mechanism will maintain effectiveness as LLMs continue to evolve
- Runtime overhead remains "minimal" at scale with thousands of concurrent requests

## Next Checks
1. **Cross-Lingual Robustness Test**: Evaluate LDFighter on a larger, more diverse set of queries (minimum 100 harmful and 100 benign per language) across the full 74 languages to verify that performance improvements are consistent and not specific to the initial test set.

2. **Pivot Language Ablation**: Test LDFighter with different pivot languages (e.g., French, Mandarin, Arabic) and directly compare response embeddings across original languages without translation to assess whether English introduces systematic bias in the similarity measurement.

3. **Real-World Deployment Simulation**: Implement LDFighter in a controlled production environment with concurrent requests and measure actual latency, cost, and error rates under realistic load conditions to validate the "minimal runtime overhead" claim beyond laboratory testing.