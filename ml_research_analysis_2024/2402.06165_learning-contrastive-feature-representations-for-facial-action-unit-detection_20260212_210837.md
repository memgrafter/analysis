---
ver: rpa2
title: Learning Contrastive Feature Representations for Facial Action Unit Detection
arxiv_id: '2402.06165'
source_url: https://arxiv.org/abs/2402.06165
tags:
- learning
- detection
- sample
- aunce
- positive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a discriminative contrastive learning framework
  for facial action unit (AU) detection that addresses class imbalance and noisy labels.
  The proposed method, AUNCE, combines self-supervised and supervised signals through
  a positive sample sampling strategy and uses a negative sample re-weighting strategy
  to handle class imbalance.
---

# Learning Contrastive Feature Representations for Facial Action Unit Detection

## Quick Facts
- arXiv ID: 2402.06165
- Source URL: https://arxiv.org/abs/2402.06165
- Authors: Ziqiao Shang; Bin Liu; Fengmao Lv; Fei Teng; Tianrui Li; Lan-Zhe Guo
- Reference count: 40
- Key outcome: AUNCE framework achieves 66.1% F1 on BP4D, 66.4% on DISFA, 62.8% on BP4D+, 63.0% on GFT, 62.2% on Aff-Wild2

## Executive Summary
This paper introduces AUNCE, a discriminative contrastive learning framework for facial action unit (AU) detection that addresses class imbalance and noisy labels through a combination of self-supervised and supervised signals. The method moves beyond traditional pixel-level feature learning by encoding differential information between AUs from sample pairs, using a positive sample sampling strategy and negative sample re-weighting to handle class imbalance. Experimental results on five benchmark datasets demonstrate superior performance compared to state-of-the-art methods, particularly in challenging scenarios involving cross-dataset evaluations and out-of-plane poses.

## Method Summary
AUNCE employs a two-stage discriminative contrastive learning approach that combines weighted cross-entropy loss with a contrastive similarity optimization objective. The framework uses a Swin-transformer backbone with an AU Relationship-aware Node Feature Learning module, implements negative sample re-weighting through importance weights based on sample similarity, and incorporates a positive sample sampling strategy that combines supervised (label-based) and self-supervised (augmentation-based) signals. The method is trained using pre-training with AUNCE loss followed by linear evaluation with weighted cross-entropy loss.

## Key Results
- Achieves average F1-score of 66.1% on BP4D dataset
- Achieves average F1-score of 66.4% on DISFA dataset
- Outperforms state-of-the-art methods across all five benchmark datasets (BP4D, DISFA, BP4D+, GFT, Aff-Wild2)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Encoding differential information between AUs via sample pairs enables the model to learn discriminative cues without overfitting to pixel-level details.
- Mechanism: Contrastive loss optimizes similarity between positive sample pairs (same AU activation pattern) while minimizing similarity with negative pairs (different AU patterns), encouraging focus on subtle feature differences rather than full facial appearance.
- Core assumption: Subtle facial feature differences between AU classes contain sufficient discriminative information for detection.
- Evidence anchors: [abstract], [section 3.2]
- Break condition: If AU activation patterns are too subtle or highly correlated across different AUs.

### Mechanism 2
- Claim: Negative sample re-weighting with importance weights (β) enables effective hard negative mining and mitigates class imbalance.
- Mechanism: Importance weight ωj = sim(f(x), f(x-j))^β amplifies gradients from hard negatives while suppressing easy negatives.
- Core assumption: Similarity distribution between anchor and negative samples follows von Mises-Fisher distribution.
- Evidence anchors: [section 3.3], [abstract]
- Break condition: If similarity distribution doesn't follow assumed pattern or β tuning is not properly calibrated.

### Mechanism 3
- Claim: Positive sample sampling strategy combining supervised and self-supervised signals improves robustness to noisy and false labels.
- Mechanism: Three types of positive samples: highest similarity pairs from labeled data, augmented views of same sample, and mixed feature representations.
- Core assumption: Neural networks learn clean samples before overfitting to noisy ones.
- Evidence anchors: [section 3.4], [abstract]
- Break condition: If label noise is too pervasive or augmentation doesn't preserve AU-relevant features.

## Foundational Learning

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: Understanding how contrastive loss works is essential to grasp why AUNCE is effective for AU detection.
  - Quick check question: What is the key difference between InfoNCE loss and cross-entropy loss in terms of what they optimize during training?

- Concept: Class imbalance and its impact on model training
  - Why needed here: The paper addresses severe class imbalance in AU datasets (many more negative than positive samples per AU).
  - Quick check question: Why does class imbalance in AU detection datasets lead to models that are biased toward predicting negative labels?

- Concept: Self-supervised learning techniques (data augmentation, instance discrimination)
  - Why needed here: The positive sample sampling strategy relies on self-supervised signals through data augmentation.
  - Quick check question: How does using augmented views of the same image as positive pairs help in learning more robust feature representations?

## Architecture Onboarding

- Component map: Anchor sample → Feature encoder → Positive/negative pair construction → AUNCE loss computation → Gradient update
- Critical path: Anchor sample → encoder → positive/negative pair construction → AUNCE loss computation → gradient update
- Design tradeoffs: Using differential AU information rather than full pixel-level features reduces computational complexity but may miss some global contextual cues.
- Failure signatures: Poor performance on highly imbalanced AUs suggests β tuning issues; degraded performance on out-of-plane poses suggests encoder backbone may need adjustment.
- First 3 experiments:
  1. Run baseline with weighted cross-entropy loss (WCE) using the same encoder to establish performance floor
  2. Add only the negative sample re-weighting strategy to the baseline to measure its isolated impact
  3. Add only the positive sample sampling strategy to the baseline to measure its isolated impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the sensitivity of AUNCE's hyperparameters (p1, p2, p3, and β) to dataset characteristics be systematically reduced to improve generalizability?
- Basis in paper: [explicit] The paper identifies hyperparameter tuning as a limitation, noting that optimal settings vary across datasets.
- Why unresolved: While the paper demonstrates improved performance with specific hyperparameter values, it does not provide a principled method for selecting these values across different datasets.
- What evidence would resolve it: Development and validation of an adaptive hyperparameter optimization strategy that consistently achieves strong performance across diverse datasets.

### Open Question 2
- Question: Can the discriminative contrastive learning framework be extended to incorporate temporal information for video-based AU detection?
- Basis in paper: [inferred] The paper focuses exclusively on frame-level AU detection and does not address temporal dynamics in video data.
- Why unresolved: The current framework is designed for static images, and extending it to handle temporal relationships would require significant architectural modifications.
- What evidence would resolve it: A modified version of AUNCE that effectively incorporates temporal information and demonstrates superior performance on video datasets.

### Open Question 3
- Question: How does the performance of AUNCE scale with increasing AU label noise levels, and what is the theoretical limit of its noise tolerance?
- Basis in paper: [explicit] The paper introduces a positive sample sampling strategy specifically designed to handle noisy and false AU labels.
- Why unresolved: While the paper demonstrates improved robustness compared to baseline methods, it does not characterize the relationship between label noise levels and detection accuracy.
- What evidence would resolve it: Empirical studies showing AU detection performance across varying levels of label noise, identifying the threshold beyond which the method's advantages diminish.

## Limitations
- The effectiveness of differential AU encoding relies on the assumption that subtle feature differences between AU classes are sufficiently discriminative.
- The negative sample re-weighting strategy assumes a specific similarity distribution (von Mises-Fisher) that may not generalize across all datasets.
- The positive sample sampling strategy's performance depends critically on hyperparameter tuning (p1, p2, p3) which varies by dataset.

## Confidence

**Major uncertainties:**
The effectiveness of the differential AU encoding mechanism relies heavily on the assumption that subtle feature differences between AU classes are sufficiently discriminative. The negative sample re-weighting strategy assumes a specific similarity distribution (von Mises-Fisher) that may not generalize across all datasets. The positive sample sampling strategy's performance depends critically on hyperparameter tuning (p1, p2, p3) which varies by dataset.

**Confidence assessment:**
- High confidence: The general contrastive learning framework and its application to AU detection is well-established.
- Medium confidence: The specific mechanisms for handling class imbalance and noisy labels are theoretically sound but rely on assumptions about data distributions.
- Low confidence: The optimal hyperparameter configurations for different datasets are not systematically explored.

## Next Checks

1. **Ablation study on hyperparameter sensitivity**: Systematically vary β and p1/p2/p3 across datasets to identify stable operating ranges and assess method robustness.

2. **Cross-dataset AU correlation analysis**: Analyze AU correlation matrices across datasets to determine when differential encoding is most effective and identify failure modes for highly correlated AUs.

3. **Distribution assumption validation**: Verify that the similarity distributions between anchor and negative samples actually follow the assumed von Mises-Fisher distribution in practice, and test alternative re-weighting schemes if violated.