---
ver: rpa2
title: 'ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial Information
  in Medical Images'
arxiv_id: '2410.16947'
source_url: https://arxiv.org/abs/2410.16947
tags:
- images
- isimed
- learning
- medical
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ISImed is a self-supervised learning framework that leverages intrinsic
  spatial information in medical images. The method addresses the challenge of learning
  meaningful representations from medical images without labeled data by exploiting
  the consistent anatomical structures across multiple images.
---

# ISImed: A Framework for Self-Supervised Learning using Intrinsic Spatial Information in Medical Images

## Quick Facts
- arXiv ID: 2410.16947
- Source URL: https://arxiv.org/abs/2410.16947
- Reference count: 24
- ISImed achieves AUC of 0.909 on autoPET and 0.837 on BraTS in downstream classification tasks

## Executive Summary
ISImed is a self-supervised learning framework that leverages intrinsic spatial information in medical images to learn meaningful representations without labeled data. The method exploits the consistent anatomical structures across medical images by sampling image crops and learning a latent representation where the distance between embeddings reflects the true physical distance between the crops. This is achieved through a loss function that minimizes the difference between learned and physical distances. The approach demonstrates superior performance compared to state-of-the-art self-supervised learning methods on two medical imaging datasets: whole-body CT (autoPET) and brain MRI (BraTS).

## Method Summary
ISImed samples 16 patches from each image in a batch and learns embeddings where the L2 distance between patches in the latent space corresponds to their physical distance in the original image. The framework uses DenseNet121 as a backbone to generate 1024-dimensional embeddings, with linear projection layers to 512 and 2048 dimensions for ISImed and BarlowTwins losses respectively. The method can be combined with BarlowTwins regularization to prevent information collapse. The framework is trained for 50 epochs using AdamW optimizer with a learning rate of 0.001 and decay of 0.9. Preprocessing includes ScaleIntensityRangePercentiles (5-95%) and CropForeground transformations.

## Key Results
- ISImed achieves AUC of 0.909 on autoPET whole-body CT dataset
- ISImed achieves AUC of 0.837 on BraTS brain MRI dataset
- Learned representations show strong correlation with anatomical planes (axial, coronal, sagittal)
- Outperforms state-of-the-art self-supervised methods including BarlowTwins, VICReg, and SimCLR

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method works because consistent anatomical structures across medical images allow spatial distance to serve as a reliable self-supervisory signal.
- Mechanism: Medical images share strong anatomical consistency (e.g., organ positions are roughly the same across patients), so the physical distance between patches can be estimated and used as a learning target. The model learns embeddings where the latent distance matches the physical distance.
- Core assumption: Anatomical structures are consistently positioned across different patients' scans in a given modality.
- Evidence anchors:
  - [abstract] "By leveraging this resemblance of human body structures across multiple images, we establish a self-supervised objective that creates a latent representation capable of capturing its location in the physical realm."
  - [section 2.1] "We propose a method for learning medical image representation using physical distance as a learning signal."

### Mechanism 2
- Claim: The L2 distance between learned embeddings correlates strongly with anatomical plane positions.
- Mechanism: The latent representation encodes spatial location information such that principal components align with anatomical directions (axial, coronal, sagittal). This is achieved by minimizing the difference between physical and latent distances across all patch pairs.
- Core assumption: The learned embedding space can be linearly aligned with physical spatial coordinates.
- Evidence anchors:
  - [section 3.1] "The color-coding is set to the axial, coronal and sagittal directions and it can be clearly seen, that all three dimension are captured in this latent representation."
  - [section 3.1] "In Fig. 2b we show the first three Principal Components (PCs) of the latent representations and their correlation with the spatial dimensions."

### Mechanism 3
- Claim: Combining ISImed with BarlowTwins prevents information collapse while preserving spatial information.
- Mechanism: BarlowTwins acts as a regularization by maximizing the similarity between augmented views while minimizing redundancy, preventing the latent representation from collapsing to uninformative dimensions. This regularization is balanced with the ISImed loss using a hyperparameter λ.
- Core assumption: BarlowTwins regularization does not interfere with the spatial learning objective and can coexist without destroying the learned spatial relationships.
- Evidence anchors:
  - [section 2.1] "BarlowTwins can be seen as a information maximization regularization of the latent representation [21]. ISImed however, is inspired by the idea to make the latent representation resemble physical space. This can lead to an information collapse in ISImed... Combining both methods can prevent the information collapse."
  - [section 2.1] "To combine the methods we trained the model as a joint embedding method just as in BarlowTwins."

## Foundational Learning

- Concept: Self-supervised learning in medical imaging
  - Why needed here: Labeled medical data is expensive and scarce, so self-supervised methods can leverage abundant unlabeled data to learn useful representations.
  - Quick check question: What is the main advantage of using self-supervised learning for medical image analysis?

- Concept: Spatial consistency in anatomical structures
  - Why needed here: The method relies on consistent anatomical positioning across patients to use physical distance as a self-supervisory signal.
  - Quick check question: Why is anatomical consistency across patients important for ISImed's approach?

- Concept: Contrastive learning and information maximization
  - Why needed here: The paper compares ISImed with BarlowTwins (information maximization) and simCLR (contrastive learning), so understanding these methods is essential for evaluating ISImed's performance.
  - Quick check question: How do BarlowTwins and simCLR differ in their approach to preventing information collapse?

## Architecture Onboarding

- Component map: Image patches -> DenseNet121 backbone -> 1024-dim embedding -> Linear projection (512-dim) -> ISImed loss; Linear projection (2048-dim) -> BarlowTwins loss
- Critical path: Sampling patches → computing physical distances → generating embeddings → computing latent distances → calculating loss → backpropagating gradients
- Design tradeoffs: Using a joint embedding approach (like BarlowTwins) adds regularization but requires careful balancing with the ISImed loss; random patch sampling is simple but may miss informative pairs
- Failure signatures: Poor downstream classification performance, latent distances not correlating with physical distances, information collapse (most dimensions become uninformative)
- First 3 experiments:
  1. Verify that latent distances correlate with physical distances on a small dataset with known spatial structure.
  2. Compare downstream classification performance with and without BarlowTwins regularization.
  3. Test different λ values to find the optimal balance between ISImed and BarlowTwins losses.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would replacing the L2 distance in ISImed's loss function with other distance-based regression losses (e.g., Huber loss) affect the learned representations and downstream task performance?
- Basis in paper: [explicit] The authors mention that "the L2 distance in (1) could be replaced with any other distance-based regression loss" and that "The implementation of the Huber loss function is a potential optimization strategy for imposing greater penalties on distant patches." However, they state "further optimizations of this objective function will not be expounded upon further."
- Why unresolved: The authors explicitly state that they will not explore other distance-based losses in this paper, leaving their impact on the learned representations and downstream task performance unknown.
- What evidence would resolve it: Conducting experiments using different distance-based regression losses (e.g., Huber loss, smooth L1 loss) and comparing the learned representations and downstream task performance to the current L2 distance implementation.

### Open Question 2
- Question: How does ISImed's performance scale with larger batch sizes and more diverse medical imaging datasets?
- Basis in paper: [inferred] The authors mention that "Contrastive learning methods heavily depend on the sampling strategies for positive and negative pairs" and "very large batch sizes". They also demonstrate ISImed's effectiveness on two specific datasets (autoPET and BraTS) but do not explore its performance on larger or more diverse datasets.
- Why unresolved: The paper does not investigate the impact of batch size on ISImed's performance, nor does it test the method on a wider variety of medical imaging datasets beyond autoPET and BraTS.
- What evidence would resolve it: Conducting experiments with varying batch sizes and testing ISImed on a broader range of medical imaging datasets, including those with different modalities, body parts, and levels of anatomical diversity.

### Open Question 3
- Question: Can ISImed be extended to other medical imaging tasks beyond classification, such as segmentation or anomaly detection?
- Basis in paper: [inferred] The authors mention that "self-supervised learning (SSL) is a rapidly growing area of machine learning that can be used to tackle these issues" in medical imaging and that ISImed can "efficiently learn representations that capture the underlying structure of the data." They also discuss the potential for "content accumulation" through body part regression. However, they only evaluate ISImed on a downstream classification task.
- Why unresolved: The paper focuses solely on the classification performance of ISImed and does not explore its potential for other medical imaging tasks, such as segmentation or anomaly detection.
- What evidence would resolve it: Applying ISImed to downstream tasks like segmentation or anomaly detection and comparing its performance to state-of-the-art methods in those domains. Additionally, investigating whether the learned representations can be directly used for these tasks or if fine-tuning is necessary.

## Limitations

- The method's effectiveness depends heavily on the assumption of anatomical consistency across patients, which may not hold for pathological cases or highly variable anatomical regions
- The paper lacks detailed ablation studies on the impact of λ (the BarlowTwins regularization weight) and the exact patch sampling strategy
- No comparison with other spatial self-supervised methods like VICReg or DINO that also learn spatial representations

## Confidence

- High confidence: The core mechanism of using physical distance as a self-supervisory signal
- Medium confidence: The spatial correlation results showing anatomical planes alignment
- Medium confidence: The effectiveness of combining ISImed with BarlowTwins

## Next Checks

1. Perform ablation studies varying λ to quantify BarlowTwins' contribution and identify optimal regularization strength
2. Test ISImed on pathological cases with significant anatomical deformation to evaluate robustness limits
3. Compare ISImed with other spatial self-supervised methods (VICReg, DINO) on the same datasets to establish relative performance