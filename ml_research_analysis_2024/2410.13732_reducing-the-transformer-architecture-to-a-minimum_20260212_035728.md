---
ver: rpa2
title: Reducing the Transformer Architecture to a Minimum
arxiv_id: '2410.13732'
source_url: https://arxiv.org/abs/2410.13732
tags:
- matrices
- parameters
- attention
- similarity
- matrix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper investigates reducing the parameter count of transformer
  models without significant performance loss. It focuses on three simplifications:
  (a) removing the MLP component, (b) collapsing query/key and value/projection matrices
  into single matrices, and (c) using symmetric similarity measures.'
---

# Reducing the Transformer Architecture to a Minimum

## Quick Facts
- arXiv ID: 2410.13732
- Source URL: https://arxiv.org/abs/2410.13732
- Reference count: 4
- The paper investigates reducing transformer parameters without significant performance loss, achieving up to 90% parameter reduction on MNIST and CIFAR-10

## Executive Summary
This paper investigates three key simplifications to reduce transformer architecture parameter counts: removing the MLP component, collapsing query/key and value/projection matrices into single matrices, and using symmetric similarity measures. Experiments on MNIST and CIFAR-10 demonstrate that simplified transformer variants can achieve similar classification accuracy while using up to 90% fewer parameters compared to standard transformers with MLP. The minimum variant, which omits MLP and collapses all matrices, achieves 95.32% accuracy on MNIST and 39.17% on CIFAR-10 with only about 10% of the original parameter count.

## Method Summary
The paper proposes three parameter reduction strategies for transformer models. First, removing the MLP component from attention modules while maintaining multiple stacked attention layers to preserve nonlinearity through the softmax function. Second, collapsing query/key matrices and value/projection matrices into single matrices when they are square, reducing parameters by 50% in each case. Third, using symmetric similarity measures by setting query and key matrices equal, halving the parameters for these components. Experiments were conducted on MNIST and CIFAR-10 datasets using single-head attention configurations with 6 encoder layers, trained for 500 epochs using Adam optimizer.

## Key Results
- Minimum variant (collapsed matrices, no MLP) achieves 95.32% accuracy on MNIST with ~10% of original parameters
- Same minimum variant achieves 39.17% accuracy on CIFAR-10 with ~10% of original parameters
- Symmetric similarity measures generally outperform asymmetric ones, particularly in generalization
- ImageNet experiments failed to converge, suggesting limitations on more complex tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The attention mechanism alone provides sufficient nonlinearity for many tasks, making the MLP component redundant.
- Mechanism: The attention mechanism uses similarity measures (quadratic functions of inputs) combined with softmax nonlinearity, creating a cubic function of inputs. Stacking multiple attention layers compounds this nonlinearity to polynomial order 3S, where S is the number of transformer layers.
- Core assumption: The nonlinearity provided by attention mechanisms is adequate for modeling the complexity of typical application problems.
- Evidence anchors:
  - [abstract] "However, the attention mechanism itself is nonlinear through its internal use of similarity measures. A possible hypothesis is that this nonlinearity is sufficient for modeling typical application problems."
  - [section 2] "The argument of the Softmax () function is already a quadratic function of input tokens, and the function itself is nonlinear. Even if the Softmax() were linear, the multiplication of input tokens by the weights asi j (which are quadratic in these tokens) would result in a cubic function of input tokens."
- Break condition: Tasks requiring higher-order nonlinearity than what can be captured by the attention mechanism's cubic transformations.

### Mechanism 2
- Claim: Collapsing query/key and value/projection matrices reduces parameters without losing expressive power.
- Mechanism: When matrices are square and model width is constant, the product of query-key matrices WV_sW_O_s can be collapsed into a single matrix WVO_s, and similarly for WQ_sW_KT_s to WQK_s. This eliminates redundant parameters while maintaining the same transformation capability.
- Core assumption: The matrix products can be collapsed without loss of generality when matrices are square.
- Evidence anchors:
  - [section 3] "With square matrices, it is evident that WV_sW_O_s can be collapsed to a single matrix WVO_s, and, analogously, WQ_sW_KT_s to WQK_s. This saves 50 % of the attention module's parameters, from 4SN2 to 2SN2."
  - [section 3] "Concatenating the transformer-encoder layers without MLP leads to the following recursion: ... When stacking the attention modules, the matrices WVO_s concatenate to their product over s = 1, ..., S."
- Break condition: When matrices are not square (as in multi-head configurations with reduced head width), collapsing becomes inefficient.

### Mechanism 3
- Claim: Symmetric similarity measures improve generalization while using fewer parameters.
- Mechanism: By setting WQ_sh = WK_sh, the similarity measure becomes symmetric, reducing parameters by half. This constraint may help the model focus on more meaningful relationships rather than arbitrary asymmetries.
- Core assumption: Symmetric relationships are more appropriate for many tasks, and the reduced parameter space helps generalization.
- Evidence anchors:
  - [section 5] "The symmetry can be guaranteed by simply setting WQ_sh = WK_sh. Then, half of the parameters dedicated to the query and key matrices can be economized."
  - [section 6.1] "The variant with asymmetric similarity without MLP is inferior to the analogical one with symmetric similarity."
  - [section 6.1] "The parameter numbers are substantially different. The symmetric variant without MLP has only about 25 % of the parameter number of the original, full variant with MLP."
- Break condition: Tasks where asymmetric relationships are genuinely important and beneficial.

## Foundational Learning

- Concept: Matrix operations and transformations
  - Why needed here: Understanding how matrix products can be collapsed and how transformations work in attention mechanisms
  - Quick check question: If you have two square matrices A and B, under what condition can you collapse their product AB into a single matrix without changing the transformation?

- Concept: Nonlinearity in neural networks
  - Why needed here: Understanding how nonlinearity arises in attention mechanisms through softmax and quadratic similarity measures
  - Quick check question: What is the mathematical order of the function produced by the attention mechanism when you apply softmax to a quadratic function of inputs?

- Concept: Parameter efficiency and model capacity
  - Why needed here: Understanding the relationship between parameter count, model capacity, and generalization
  - Quick check question: If you reduce the number of parameters in a model by 75%, how might this affect its ability to fit training data versus generalize to validation data?

## Architecture Onboarding

- Component map:
  - Input: Image patches converted to embeddings
  - Embedding layer: Maps image patches to embedding space
  - Transformer stack: Series of attention modules with optional MLP
  - Output: Classification head

- Critical path:
  - Image → Patch embedding → Multi-head attention → (Optional MLP) → Classification head
  - Focus on understanding the attention mechanism and parameter reduction strategies

- Design tradeoffs:
  - MLP vs no MLP: 2x parameter reduction vs potential loss of nonlinearity
  - Symmetric vs asymmetric similarity: 50% parameter reduction vs potential loss of expressiveness
  - Collapsed matrices: 50% parameter reduction vs potential loss of flexibility

- Failure signatures:
  - Poor convergence: May indicate insufficient model capacity
  - Overfitting: May indicate too many parameters relative to data
  - Underfitting: May indicate insufficient model capacity even after reductions

- First 3 experiments:
  1. Compare baseline transformer with MLP vs without MLP on MNIST, measure parameter reduction and performance impact
  2. Test symmetric vs asymmetric similarity measures with collapsed matrices on CIFAR-10
  3. Implement minimum variant (collapsed matrices, no value/projection matrices) and compare to baseline on MNIST

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we optimize second-order optimization methods like the conjugate gradient algorithm for transformer training to prevent early stopping and ensure convergence?
- Basis in paper: [inferred] The authors suggest that second-order optimization methods could be more robust for transformer training, but they face challenges with early stopping in practice.
- Why unresolved: The paper mentions the potential of second-order methods but does not provide experimental evidence or implementation details for their use in transformer architectures.
- What evidence would resolve it: Empirical results comparing convergence rates and final performance of second-order methods (e.g., conjugate gradient) versus first-order methods (e.g., Adam) on transformer models, with detailed analysis of stopping criteria and training stability.

### Open Question 2
- Question: What is the impact of reducing transformer model complexity on downstream NLP tasks when using knowledge distillation from large pre-trained models?
- Basis in paper: [explicit] The authors propose using knowledge distillation as a way to evaluate simplified transformer architectures on NLP tasks, where pre-trained models are typically used.
- Why unresolved: The paper only suggests this approach but does not conduct experiments to validate its effectiveness for reduced transformer models.
- What evidence would resolve it: Comparative studies of simplified transformers trained via knowledge distillation versus their full counterparts on standard NLP benchmarks, measuring both performance and parameter efficiency.

### Open Question 3
- Question: How does the overdetermination ratio (Q) affect the generalization capability of transformers with different architectural simplifications?
- Basis in paper: [explicit] The authors introduce the overdetermination ratio as a metric to assess model complexity relative to training data size and observe its correlation with generalization performance.
- Why unresolved: While the paper presents empirical results showing this relationship, it does not provide a theoretical framework or systematic study of how Q varies with different architectural choices.
- What evidence would resolve it: A comprehensive analysis of how architectural simplifications (e.g., removing MLP, collapsing matrices) affect the overdetermination ratio and its relationship to test performance across multiple datasets and model scales.

## Limitations

- Major limitations include failure to converge on ImageNet experiments, suggesting the simplifications may have fundamental limitations on more complex tasks
- The MNIST and CIFAR-10 experiments use single-head configurations, which may not generalize to multi-head settings where matrix collapsing is less effective
- Claims about symmetric similarity measures improving generalization are based on limited experiments with simplified models on small datasets

## Confidence

- Medium: The matrix collapsing mechanism is mathematically sound for square matrices, but its practical effectiveness across different model architectures remains unproven
- Low: Claims about symmetric similarity measures improving generalization are based on limited experiments with simplified models on small datasets
- Low: The assertion that MLP components are redundant for most tasks is contradicted by the failure to achieve competitive results on ImageNet

## Next Checks

1. Test the simplified variants with multi-head attention configurations to validate if matrix collapsing remains effective when matrices are non-square
2. Conduct ablation studies comparing different combinations of simplifications (symmetric vs asymmetric, with vs without MLP) on larger datasets like ImageNet to identify which reductions are most detrimental
3. Measure the actual learned transformations in simplified models versus baseline to verify they are mathematically equivalent, not just parameter-efficient approximations