---
ver: rpa2
title: Optimizing for ROC Curves on Class-Imbalanced Data by Training over a Family
  of Loss Functions
arxiv_id: '2402.05400'
source_url: https://arxiv.org/abs/2402.05400
tags:
- loss
- training
- class
- values
- imbalance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of training reliable binary classifiers
  under severe class imbalance, where slight changes in hyperparameters of existing
  loss functions can lead to highly variable performance in terms of ROC curves. The
  authors propose training over a family of loss functions using Loss Conditional
  Training (LCT) to reduce sensitivity to hyperparameter choices and improve model
  robustness.
---

# Optimizing for ROC Curves on Class-Imbalanced Data by Training over a Family of Loss Functions

## Quick Facts
- arXiv ID: 2402.05400
- Source URL: https://arxiv.org/abs/2402.05400
- Reference count: 40
- Primary result: LCT improves mean and max ROC curves while reducing variance in imbalanced binary classification

## Executive Summary
This work addresses the challenge of training reliable binary classifiers under severe class imbalance, where slight changes in hyperparameters of existing loss functions can lead to highly variable performance in terms of ROC curves. The authors propose training over a family of loss functions using Loss Conditional Training (LCT) to reduce sensitivity to hyperparameter choices and improve model robustness. Specifically, they adapt LCT to binary classification under imbalance via Vector Scaling (VS) loss, which includes additive and multiplicative factors on logits. Their method consistently improves both the mean and maximum ROC curves while significantly reducing performance variance across various datasets and imbalance ratios, demonstrating that training over a family of loss functions is an effective proxy for optimizing different TPR-FPR tradeoffs on the ROC curve.

## Method Summary
The authors train over a family of loss functions using Loss Conditional Training (LCT) with Vector Scaling (VS) loss. VS loss includes additive (τ) and multiplicative (γ) factors on logits, plus a class weight (Ω). LCT samples λ values (e.g., τ) per batch and uses FiLM layers to condition the model on these values. The model architecture consists of a backbone (ResNet-32 or ResNext50) followed by a FiLM block after the final conv layer and before the linear layer. At inference, the user provides λ with data to obtain the desired TPR-FPR tradeoff. The method is evaluated on CIFAR10 cat vs. dog, CIFAR100 household electronics vs. furniture, Kaggle Dogs vs. Cats, and SIIM-ISIC Melanoma datasets with imbalance ratios up to 1:500.

## Key Results
- LCT consistently improves both mean and maximum ROC curves compared to fixed hyperparameter baselines
- LCT significantly reduces performance variance across different hyperparameter settings, with variance decreasing as imbalance ratio increases
- The best-performing λ value (τ = 3) in LCT achieves comparable or better performance than the best fixed hyperparameter setting while maintaining robustness
- LCT's performance advantage is more pronounced at higher imbalance ratios, where variance in fixed-parameter methods becomes severe

## Why This Works (Mechanism)

### Mechanism 1
Training over a family of loss functions via LCT improves ROC performance by implicitly optimizing across a spectrum of TPR-FPR tradeoffs. LCT samples hyperparameter values per batch, effectively training one model to perform well for many threshold settings. Each λ value corresponds to a different bias in the loss landscape, shifting the set of break-even points. This makes the model robust to threshold choice and reduces sensitivity to fixed hyperparameter selection.

### Mechanism 2
VS loss hyperparameters (τ, γ, Ω) have well-understood effects on the logit space that translate to different TPR/FPR behaviors. τ adds an additive bias to logits, shifting the break-even line z1 = z0 + τ log β. γ scales minority logits, rotating the break-even line. Ω changes the weighting of classes, affecting where the loss curves intersect. By sampling over these, the model learns to handle different decision boundaries.

### Mechanism 3
Variance in model performance under severe class imbalance is largely due to hyperparameter sensitivity, and LCT mitigates this by averaging over many settings. Without LCT, each fixed hyperparameter setting yields a narrow ROC curve with high variance. LCT averages the gradients over a distribution of λ, smoothing the training trajectory and reducing overfitting to a single hyperparameter configuration.

## Foundational Learning

- **ROC curves and AUC as metrics for imbalanced binary classification**: The paper's goal is to optimize classifier performance across all TPR-FPR tradeoffs, not just at a fixed threshold. ROC curves capture this full tradeoff, and AUC summarizes it into a scalar for comparison.
  - Quick check: What does a point on the ROC curve represent in terms of classifier predictions?

- **Hyperparameter sensitivity and its impact on model generalization**: The paper identifies that slight changes in VS loss hyperparameters cause large performance swings under severe imbalance. Understanding this sensitivity is key to appreciating why training over a distribution helps.
  - Quick check: Why does increasing imbalance ratio amplify the effect of hyperparameter changes on model performance?

- **Loss conditional training (LCT) and feature-wise linear modulation (FiLM)**: LCT uses FiLM layers to condition the model on a sampled λ per batch, enabling a single model to adapt to many loss functions. This architectural detail is central to the method.
  - Quick check: How does the FiLM layer use the sampled λ to modulate activations?

## Architecture Onboarding

- **Component map**: Input data → Backbone (ResNet-32/ResNext50) → FiLM block (takes λ) → Linear layer → VS loss (parameterized by λ) → Backpropagation
- **Critical path**: For each batch: sample λ → pass λ and data through backbone → apply FiLM modulation → compute VS loss with λ → backpropagate. At inference: input λ with data → FiLM modulates activations → output logits → softmax → threshold at desired t
- **Design tradeoffs**: Using λ = τ simplifies the conditioning and is empirically strong, but may miss benefits from varying Ω or γ. Sampling from a linear distribution allows flexible λ ranges, but requires choosing bounds a, b and heights hb, ha. Training longer is needed because gradients are averaged over many λ values.
- **Failure signatures**: If variance does not decrease, the λ sampling range may be too narrow or the FiLM layers too weak. If performance is worse than baseline, the λ distribution may be poorly chosen or the model underfit due to increased complexity.
- **First 3 experiments**:
  1. Train baseline VS loss with fixed λ (e.g., Ω=0.5, γ=0, τ=0) and measure ROC variance over 10 random seeds
  2. Train LCT with λ = τ sampled uniformly from [0,3], keep other hyperparameters fixed, compare mean/max ROC and variance
  3. Vary the λ sampling distribution (e.g., triangular vs. linear) and evaluate impact on ROC curves and AUC distribution

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of LCT vary when using λ values other than τ (e.g., λ = (Ω, γ, τ) or λ = γ)?
Basis: The paper compares different λ choices in Section 6.5, finding that λ = τ achieves a good compromise between improving AUC and reducing variance.
Why unresolved: While the paper provides comparisons, it does not extensively explore the performance of LCT with other λ values across diverse datasets and imbalance ratios.
What evidence would resolve it: Systematic experiments evaluating LCT performance with various λ values on a wide range of datasets and imbalance ratios, comparing AUC, variance, and other relevant metrics.

### Open Question 2
Can LCT be effectively adapted for multi-class classification problems under imbalance?
Basis: The paper focuses on binary classification and mentions in the conclusion that adapting LCT for multi-class problems is an area of future work.
Why unresolved: The paper does not provide any experiments or theoretical analysis on applying LCT to multi-class scenarios.
What evidence would resolve it: Experiments demonstrating the effectiveness of LCT in multi-class classification under imbalance, comparing performance metrics like overall accuracy and per-class metrics.

### Open Question 3
How does LCT compare to other advanced methods for handling class imbalance, such as contrastive learning or two-stage learning approaches?
Basis: The related work section discusses various methods for handling class imbalance, including contrastive learning and two-stage learning, but the paper does not compare LCT to these methods.
Why unresolved: The paper focuses on comparing LCT to VS loss without LCT, but does not benchmark against other state-of-the-art methods for handling class imbalance.
What evidence would resolve it: Experiments comparing LCT to other advanced methods for handling class imbalance, using the same datasets and evaluation metrics to assess relative performance.

## Limitations

- The effectiveness of LCT depends on proper implementation of FiLM layers and λ sampling distribution, which have underspecified details
- The method adds computational overhead due to sampling and conditioning, requiring longer training times
- LCT's benefits are demonstrated primarily on CNN architectures and may not generalize to other model types

## Confidence

- Medium: LCT reduces variance in ROC performance under imbalance (supported by experimental results)
- Medium: VS loss hyperparameters have predictable effects on TPR-FPR tradeoffs (theoretically sound but not empirically validated across all settings)
- Low: Training over a family of loss functions is equivalent to optimizing over the ROC curve (mechanism is inferred from observed correlations)

## Next Checks

1. **Direct measurement of ROC coverage**: Train LCT models and explicitly measure the spread of ROC curves obtained by varying threshold t, comparing against the theoretical coverage implied by the λ sampling distribution. This would validate whether the sampling strategy actually spans the intended ROC space.

2. **Ablation on λ sampling strategy**: Systematically vary the λ sampling distribution (uniform, triangular, Gaussian) and measure the impact on both mean/max ROC performance and variance reduction. This would test whether the linear distribution is optimal or merely sufficient.

3. **Transfer to different architectures**: Apply LCT to architectures beyond ResNet-32 and ResNext50 (e.g., transformers or ViT) on imbalanced datasets to test whether variance reduction generalizes beyond the tested CNN models and whether FiLM conditioning remains effective.