---
ver: rpa2
title: 'Source Matters: Source Dataset Impact on Model Robustness in Medical Imaging'
arxiv_id: '2403.04484'
source_url: https://arxiv.org/abs/2403.04484
tags:
- learning
- noise
- medical
- imagenet
- confounders
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how the domain of the source dataset affects
  model generalization in medical imaging tasks. The authors propose a Medical Imaging
  Contextualized Confounder Taxonomy (MICCAT) to categorize confounders and conduct
  experiments using two public chest X-ray and CT datasets.
---

# Source Matters: Source Dataset Impact on Model Robustness in Medical Imaging

## Quick Facts
- arXiv ID: 2403.04484
- Source URL: https://arxiv.org/abs/2403.04484
- Reference count: 30
- Primary result: ImageNet pre-training leads to higher shortcut reliance than RadImageNet pre-training in medical imaging tasks

## Executive Summary
This paper investigates how the domain of the source dataset affects model generalization in medical imaging tasks. The authors propose a Medical Imaging Contextualized Confounder Taxonomy (MICCAT) to categorize confounders and conduct experiments using two public chest X-ray and CT datasets. They show that while ImageNet and RadImageNet achieve comparable classification performance, ImageNet is much more prone to overfitting to confounders. Specifically, ImageNet's out-of-distribution (o.o.d.) performance on X-rays, confounded by tag, denoising, and patient gender, drops more compared to RadImageNet. The authors recommend that researchers using ImageNet-pretrained models reexamine their model robustness by conducting similar experiments.

## Method Summary
The study compares ResNet50 models pre-trained on ImageNet versus RadImageNet for medical imaging tasks. Models are fine-tuned on NIH CXR14 (chest X-ray) and LIDC-IDRI (CT) datasets for binary classification tasks. Synthetic confounders (tag, denoising artifacts, Poisson noise, patient gender) are introduced at varying correlation levels. The models are trained with cross-entropy loss using Adam optimizer (learning rate 1e-5) for up to 200 epochs with early stopping. Performance is evaluated using AUC on both in-distribution and out-of-distribution test sets to assess robustness to confounders.

## Key Results
- ImageNet and RadImageNet pre-trained models achieve comparable i.i.d. classification performance
- ImageNet models show significantly worse o.o.d. performance when confounders are present, indicating higher shortcut reliance
- RadImageNet demonstrates greater robustness to confounders across multiple types (tag, denoising, patient gender)
- Random initialization appears robust to shortcut learning but is attributed to class imbalance rather than genuine feature learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ImageNet pre-training leads to higher shortcut reliance than RadImageNet pre-training in medical imaging tasks.
- Mechanism: ImageNet models overfit to spurious correlations (e.g., tags, denoising artifacts) that are not consistently associated with labels in the medical domain, whereas RadImageNet models are trained on medical images and thus learn representations invariant to such features.
- Core assumption: The source dataset's domain determines the presence of domain-specific confounders in learned representations.
- Evidence anchors:
  - [abstract] "ImageNet is much more prone to overfitting to confounders."
  - [section] "ImageNet's o.o.d. performance on X-rays, confounded by tag, denoising, and patient gender, drops more compared to RadImageNet."
  - [corpus] "Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification" — suggests ongoing investigation of ImageNet vs. domain-specific models.

### Mechanism 2
- Claim: Transfer learning effectiveness depends on the alignment between source and target domain confounders.
- Mechanism: Models pre-trained on datasets with confounders similar to those in the target domain (e.g., RadImageNet for medical imaging) are less likely to overfit to those confounders, leading to better out-of-distribution (o.o.d.) performance.
- Core assumption: The presence and type of confounders in the source dataset influence the robustness of learned representations.
- Evidence anchors:
  - [abstract] "We show that ImageNet and RadImageNet achieve comparable classification performance, yet ImageNet is much more prone to overfitting to confounders."
  - [section] "RadImageNet is more robust in CT scans... suggesting that ImageNet may over-rely on spurious correlations in the target dataset."
  - [corpus] "Current Pathology Foundation Models are unrobust to Medical Center Differences" — highlights the importance of domain alignment.

### Mechanism 3
- Claim: Random initialization can be robust to shortcut learning under certain conditions.
- Mechanism: When the target dataset has an imbalanced class distribution, randomly initialized models may default to predicting the majority class, inadvertently avoiding overfitting to confounders. However, this robustness is task-dependent and may not generalize.
- Core assumption: Class imbalance in the target dataset influences the shortcut learning behavior of randomly initialized models.
- Evidence anchors:
  - [section] "Random initialization appears to be robust to shortcut learning... However, this is mainly due to the unbalanced class distribution in the lung mass prediction task."
  - [abstract] No direct evidence; inferred from experimental results.
  - [corpus] No direct evidence; inferred from experimental results.

## Foundational Learning

- Concept: Transfer learning and domain shift
  - Why needed here: Understanding how pre-trained models adapt to new domains and the challenges posed by domain shifts is crucial for evaluating model robustness in medical imaging.
  - Quick check question: How does the domain shift from natural images (ImageNet) to medical images affect the performance of pre-trained models?

- Concept: Confounders and spurious correlations
  - Why needed here: Identifying and understanding confounders is essential for assessing model robustness and avoiding reliance on spurious features that may not generalize.
  - Quick check question: What are some common confounders in medical imaging, and how can they lead to shortcut learning?

- Concept: Out-of-distribution (o.o.d.) evaluation
  - Why needed here: Evaluating model performance on o.o.d. data helps identify overfitting to confounders and assess the true generalization capability of the model.
  - Quick check question: Why is it important to evaluate model robustness using o.o.d. test sets, and how does this differ from traditional i.i.d. evaluation?

## Architecture Onboarding

- Component map: ResNet50 backbone with average pooling and dropout (0.5 probability) -> Adam optimizer (learning rate 1e-5) -> Cross-entropy loss -> Image augmentations (rotation, shifts, shear, zoom) -> AUC evaluation

- Critical path:
  1. Pre-train models on ImageNet or RadImageNet
  2. Fine-tune models on target datasets (NIH CXR14 and LIDC-IDRI)
  3. Introduce confounders during fine-tuning and evaluate o.o.d. performance
  4. Compare performance between ImageNet and RadImageNet pre-trained models

- Design tradeoffs:
  - Using pre-trained models accelerates training but may introduce shortcut learning if the source dataset's domain differs significantly from the target domain.
  - Fine-tuning on smaller datasets with controlled confounders allows for systematic evaluation of model robustness but may not capture all real-world scenarios.

- Failure signatures:
  - High i.i.d. performance but low o.o.d. performance indicates overfitting to confounders.
  - Significant performance drop when confounders are introduced in the test set suggests reliance on spurious correlations.

- First 3 experiments:
  1. Fine-tune ImageNet and RadImageNet pre-trained models on NIH CXR14 with tag confounders and evaluate o.o.d. performance.
  2. Repeat experiment with denoising confounders.
  3. Repeat experiment with patient gender as a confounder.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do other types of confounders (e.g., age, race, anatomical variations) affect model robustness when using different source datasets?
- Basis in paper: [inferred] The authors introduce MICCAT to categorize confounders and investigate a few examples, but note that expanding the scope to include more confounders would offer a more comprehensive understanding.
- Why unresolved: The study focuses on a limited set of confounders (tag, denoising, Poisson noise, patient gender) due to space constraints. The impact of other confounders on model robustness is not explored.
- What evidence would resolve it: Conducting experiments with a wider range of confounders from each category in MICCAT and comparing the robustness of models pre-trained on different source datasets.

### Open Question 2
- Question: Does the size of the source dataset or its composition have a more significant impact on model robustness in medical imaging tasks?
- Basis in paper: [explicit] The authors mention that recent literature suggests the size of the source dataset may matter more than its domain or composition, but they focus on the impact of the domain.
- Why unresolved: The study compares ImageNet and RadImageNet, which differ in domain but not necessarily in size. The relative importance of dataset size versus domain is not directly addressed.
- What evidence would resolve it: Comparing models pre-trained on datasets of varying sizes within the same domain and across different domains to determine the impact on robustness.

### Open Question 3
- Question: How do the findings generalize to other medical imaging modalities beyond chest X-rays and CT scans?
- Basis in paper: [inferred] The study focuses on chest X-rays and CT scans, but the authors suggest that even transferring from a medical source of a different modality may lead to overfitting on confounders.
- Why unresolved: The experiments are limited to specific modalities, and the generalizability of the findings to other medical imaging tasks is not explored.
- What evidence would resolve it: Conducting similar experiments on other medical imaging modalities (e.g., MRI, ultrasound) to assess the impact of source dataset domain on model robustness across different tasks.

## Limitations

- The study uses synthetic confounders rather than real-world confounders that naturally occur in medical imaging datasets, which may limit generalizability to real clinical scenarios.
- The findings are based on a single backbone architecture (ResNet50), and the generalizability to other architectures like Vision Transformers or EfficientNets remains unexplored.
- The apparent robustness of random initialization appears to be an artifact of class imbalance rather than genuine shortcut avoidance, and this may not hold in balanced datasets.

## Confidence

- **High Confidence**: The core finding that ImageNet pre-trained models show greater vulnerability to synthetic confounders than RadImageNet pre-trained models is well-supported by controlled experiments with clear statistical evidence (AUC comparisons across multiple correlation levels).
- **Medium Confidence**: The generalizability of these findings to real-world medical imaging scenarios and other architectures requires further validation, as the study uses synthetic confounders and a single backbone architecture.
- **Low Confidence**: The claim about random initialization's robustness to shortcut learning is questionable since it appears to be driven by class imbalance rather than genuine feature learning, and this may not generalize to balanced datasets.

## Next Checks

1. **Real Confounder Validation**: Test the robustness findings using real-world confounders (such as patient demographics, scanner types, or imaging protocols) present in actual medical imaging datasets to verify whether synthetic confounders accurately represent real-world scenarios.

2. **Architecture Generalization**: Repeat the experiments with alternative backbone architectures (e.g., Vision Transformers, EfficientNets) to determine whether the observed differences between ImageNet and RadImageNet pre-training are architecture-dependent or generalizable.

3. **Balanced Dataset Evaluation**: Re-run the random initialization experiments on balanced versions of the datasets to determine whether its apparent robustness to shortcut learning persists when class imbalance is eliminated, distinguishing between genuine feature learning and majority-class prediction.