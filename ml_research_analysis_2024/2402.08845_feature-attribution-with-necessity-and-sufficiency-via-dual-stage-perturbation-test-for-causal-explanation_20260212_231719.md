---
ver: rpa2
title: Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation
  Test for Causal Explanation
arxiv_id: '2402.08845'
source_url: https://arxiv.org/abs/2402.08845
tags:
- uni00000013
- uni00000011
- fans
- feature
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FANS addresses the limitation of standard feature attribution methods
  (FAMs) in distinguishing feature importance when their prediction changes are similar
  after perturbation. The core idea is to compute the Probability of Necessity and
  Sufficiency (PNS) as the importance score, which quantifies the joint probability
  of two counterfactual questions about each feature subset.
---

# Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation

## Quick Facts
- arXiv ID: 2402.08845
- Source URL: https://arxiv.org/abs/2402.08845
- Reference count: 30
- FANS significantly outperforms existing FAMs in faithfulness (INF: 47.06%, 29.41%, 26.09% improvement on MNIST, Fashion-MNIST, CIFAR10), sparsity (SPA: 0.65%, 2.61%, 0.32% improvement), and robustness (MS: 13.94%, 6.02% improvement).

## Executive Summary
Standard feature attribution methods (FAMs) struggle to distinguish feature importance when prediction changes are similar after perturbation. FANS addresses this by computing the Probability of Necessity and Sufficiency (PNS) as the importance score, which quantifies the joint probability of two counterfactual questions about each feature subset. The method estimates PNS through a heuristic strategy for determining the neighborhood of the input and a dual-stage perturbation test (factual and interventional) for counterfactual reasoning. Using sampling-importance-resampling to approximate conditional distributions, FANS significantly outperforms existing FAMs on six benchmarks in terms of faithfulness, sparsity, and robustness.

## Method Summary
FANS is a feature attribution method that computes the Probability of Necessity and Sufficiency (PNS) as the importance score for feature subsets. It uses a dual-stage perturbation test involving factual and interventional stages, combined with Sampling-Importance-Resampling (SIR) to approximate conditional distributions. The method determines a neighborhood boundary and prediction change threshold heuristically, then performs counterfactual reasoning to estimate PN and PS, which are combined into PNS. FANS is evaluated against baselines on six benchmarks using faithfulness, sparsity, and robustness metrics.

## Key Results
- FANS achieves 47.06%, 29.41%, and 26.09% improvement in INF faithfulness on MNIST, Fashion-MNIST, and CIFAR10 respectively
- FANS improves SPA sparsity by 0.65%, 2.61%, and 0.32% on the same three datasets
- FANS shows 13.94% and 6.02% improvement in MS robustness metrics

## Why This Works (Mechanism)

### Mechanism 1
Standard feature attribution methods fail to distinguish features when their prediction changes are similar after perturbation. FANS computes PNS by evaluating joint counterfactual probabilities under different perturbation neighborhoods, rather than just raw prediction changes. The core assumption is that prediction changes alone do not fully capture causal importance; the conditions under which those changes occur matter. Break condition: If counterfactual reasoning cannot be reliably estimated due to noise or small sample size, PNS estimates may be unstable.

### Mechanism 2
PNS provides a more discriminative importance score by measuring joint necessity and sufficiency of prediction change. FANS estimates PNS through a dual-stage perturbation test: factual stage generates samples conditioned on prediction change/no change, interventional stage perturbs features differently and measures resulting prediction changes. The core assumption is that the joint probability of necessity and sufficiency captures more complete causal information than marginal probabilities. Break condition: If the neighborhood boundary b or threshold c are poorly estimated, the PNS computation will not reflect true causal relationships.

### Mechanism 3
Sampling-Importance-Resampling (SIR) enables estimation of complex conditional distributions needed for counterfactual reasoning. SIR approximates the required conditional distribution P(˜X|As,b,Bs,c) by resampling observed inputs weighted by their likelihood of satisfying the counterfactual conditions. The core assumption is that the observed sample set is representative enough to approximate the counterfactual conditional distributions. Break condition: If the observed sample set is too small or unrepresentative, SIR approximation error will dominate PNS estimates.

## Foundational Learning

- **Concept**: Structural Causal Model (SCM) for perturbation tests
  - Why needed here: FANS formalizes the perturbation test as a causal model with variables ˜X, S, Y and causal arrows S→˜X, X→˜X, ˜X→Y, S→Y
  - Quick check question: What are the causal relationships between S, ˜X, and Y in the FANS perturbation model?

- **Concept**: Counterfactual reasoning paradigm (Abduction-Action-Prediction)
  - Why needed here: FANS implements PN and PS estimation through factual and interventional stages that follow this paradigm
  - Quick check question: How do the factual and interventional stages of FANS correspond to abduction and action steps in counterfactual reasoning?

- **Concept**: Probability of Necessity and Sufficiency (PNS)
  - Why needed here: PNS is the core importance score that FANS uses instead of raw prediction changes
  - Quick check question: How does PNS combine PN and PS with their respective condition probabilities?

## Architecture Onboarding

- **Component map**: Input → Neighborhood boundary calculation → Dual-stage perturbation test (necessity + sufficiency) → PNS combination → Feature subset optimization
- **Critical path**: Input → Neighborhood boundary calculation → Dual-stage perturbation test (necessity + sufficiency) → PNS combination → Feature subset optimization
- **Design tradeoffs**: 
  - Trade-off between neighborhood size (b) and estimation accuracy
  - Trade-off between perturbation intensity (c) and noise sensitivity
  - Trade-off between sample size for SIR and computational cost
- **Failure signatures**:
  - High MS values indicate sensitivity to input perturbations
  - Low SPA values indicate non-sparse attributions
  - Unstable PNS estimates across runs suggest poor SIR approximation
- **First 3 experiments**:
  1. Validate PNS computation on synthetic data where ground truth causal relationships are known
  2. Test sensitivity to boundary b and threshold c parameter choices
  3. Compare attribution quality on simple image classification tasks against baseline FAMs

## Open Questions the Paper Calls Out

### Open Question 1
How can the boundary b and threshold c in FANS be theoretically justified rather than relying on heuristic strategies? The paper acknowledges the heuristic nature of determining b and c but does not provide a theoretical framework for their identifiability.

### Open Question 2
How does FANS perform on datasets with different data types and model architectures beyond those tested in the paper? The current evaluation is limited to specific datasets and model architectures, which may not generalize to all scenarios.

### Open Question 3
What is the impact of the sample size |E| used in the SIR resampling process on the performance and efficiency of FANS? The paper mentions corroborating convergence analysis but does not provide detailed analysis of the impact of sample size on performance.

## Limitations
- The estimation methods for boundary b and threshold c are heuristic rather than theoretically justified
- Performance evaluation is limited to six specific benchmarks and may not generalize to all data types
- The impact of sample size |E| on performance and efficiency is not comprehensively analyzed

## Confidence
- **High Confidence**: The core mechanism of using PNS instead of raw prediction changes is well-grounded in causal inference theory and logically addresses the stated limitation of standard FAMs
- **Medium Confidence**: The experimental results showing improvements in INF, SPA, and MS metrics appear promising but require independent verification due to limited methodological transparency
- **Low Confidence**: The robustness of FANS across different model architectures and data distributions beyond the six specified benchmarks remains unproven

## Next Checks
1. Conduct ablation studies varying neighborhood boundary b and threshold c to assess sensitivity of PNS estimates and attribution quality
2. Test FANS on additional datasets with different data modalities and model architectures to evaluate generalizability claims
3. Implement and compare alternative counterfactual reasoning approaches to isolate the contribution of the dual-stage test design