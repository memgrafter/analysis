---
ver: rpa2
title: Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints
arxiv_id: '2410.18844'
source_url: https://arxiv.org/abs/2410.18844
tags:
- constraints
- policy
- bound
- optimal
- constraint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses pure exploration in multi-armed bandits under
  unknown linear constraints, a problem relevant to real-world applications like hyperparameter
  tuning and user studies. The key challenge is that both rewards and constraints
  are unknown and must be estimated from sequential feedback, making the optimal feasible
  policy identification difficult.
---

# Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints

## Quick Facts
- arXiv ID: 2410.18844
- Source URL: https://arxiv.org/abs/2410.18844
- Reference count: 40
- Key outcome: Introduces Lagrangian relaxation for pure exploration in multi-armed bandits with unknown linear constraints, achieving asymptotically optimal sample complexity.

## Executive Summary
This paper addresses pure exploration in multi-armed bandits where both rewards and constraints are unknown. The authors propose using Lagrangian relaxation to handle the challenge of identifying an r-optimal and feasible policy. They introduce two algorithms, LATS and LAGEX, which leverage optimistic estimates of the feasible set and adaptive stopping rules. The main results show that LAGEX achieves asymptotically optimal sample complexity, while LATS is optimal up to constraint-dependent constants (shadow price). Experiments demonstrate LAGEX's efficiency compared to competing algorithms across synthetic and real-world datasets.

## Method Summary
The authors develop a Lagrangian relaxation approach for pure exploration in multi-armed bandits with unknown linear constraints. They construct optimistic feasible sets to ensure the true optimal policy is included with high probability, then use Lagrangian multipliers to balance exploration and constraint satisfaction. Two algorithms are proposed: LATS (Lagrangian Track-and-Stop) and LAGEX (Lagrangian Gamified Explorer). Both algorithms use adaptive sampling strategies based on the Lagrangian dual problem and implement constraint-adaptive stopping rules. The methods are validated through synthetic experiments with Gaussian bandits and a real-world movie recommendation dataset.

## Key Results
- LAGEX achieves asymptotically optimal sample complexity for pure exploration under unknown linear constraints
- LATS is optimal up to novel constraint-dependent constants (shadow price)
- Both algorithms outperform existing methods (CTnS, CGE, PTnS, uniform exploration) in terms of sample complexity
- LAGEX effectively tracks changes in problem hardness due to constraints across different problem instances

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Lagrangian relaxation allows the algorithm to handle unknown linear constraints by balancing identifiability of an r-optimal policy and feasibility under estimated constraints.
- **Mechanism:** The Lagrangian multiplier in the relaxation acts as a shadow price that quantifies the trade-off between reward maximization and constraint satisfaction. By solving the dual problem, the algorithm can adaptively adjust its sampling strategy to explore policies that are both informative about rewards and likely to satisfy constraints.
- **Core assumption:** The true constraints have a non-zero slack vector, and the feasible set under estimated constraints is a superset of the true feasible set.
- **Evidence anchors:**
  - [abstract] "The authors propose a Lagrangian relaxation of the sample complexity lower bound, allowing them to balance identifiability of an r-optimal policy and feasibility under estimated constraints."
  - [section 3.2] "The Lagrangian relaxation leads to a natural question: Does the dual of the optimization problem for T^-1_{F,r}(μ) yield the same solution as the primal?"
- **Break condition:** If the constraints are not strictly feasible (i.e., no non-zero slack exists), the Lagrangian relaxation may not provide a valid bound, and the algorithm could recommend infeasible policies.

### Mechanism 2
- **Claim:** Optimistic estimates of the feasible set ensure that the true optimal policy is included in the estimated feasible set with high probability.
- **Mechanism:** The algorithm constructs a confidence ellipsoid around the estimated constraints and uses the minimum constraint value within this ellipsoid to define the optimistic feasible set. This ensures that the true constraints are always satisfied by the estimated feasible set, allowing the algorithm to safely explore without violating constraints.
- **Core assumption:** The estimated constraints converge to the true constraints as the number of samples increases.
- **Evidence anchors:**
  - [section 3.1] "Lemma 1(Optimistic feasible sets). At any time t ∈ N, we construct the optimistic feasible policy set such that with probability 1−δ, F̂_t ⊇ F, where Ã_t ≜ arg min A′∈C_t A′π."
  - [section 3.2] "The inequality holds due to the optimistic choice of the estimated constraint."
- **Break condition:** If the confidence ellipsoid is too small or the convergence rate of the estimated constraints is too slow, the optimistic feasible set may not include the true optimal policy, leading to suboptimal recommendations.

### Mechanism 3
- **Claim:** The Lagrangian relaxation of the lower bound provides a tractable upper bound on the sample complexity, which can be used to design efficient algorithms.
- **Mechanism:** By solving the Lagrangian dual problem, the algorithm can compute a lower bound on the reciprocal of the characteristic time, which is related to the sample complexity. This bound is then used to design sampling strategies that efficiently explore the policy space while satisfying the constraints.
- **Core assumption:** The Lagrangian dual problem has a unique solution, and the lower bound on the characteristic time is tight.
- **Evidence anchors:**
  - [section 3.2] "Theorem 1(Strong Duality and Range of Lagrange Multipliers). The optimisation problem in Equation (6) satisfies ... = sup_{ω∈∆K} min_{l∈L} max_{π∈Πr_F̂} inf_{λ∈Λ_F̂(μ)} ω⊤d(μ,λ)−l⊤Ãω."
  - [section 4] "We propose two algorithms to conduct pure exploration with Lagrangian relaxation of lower bound, and derive upper bounds on their sample complexities."
- **Break condition:** If the Lagrangian dual problem does not have a unique solution or the lower bound is not tight, the sample complexity upper bound may be loose, leading to inefficient algorithms.

## Foundational Learning

- **Concept:** Multi-armed bandits (MAB)
  - Why needed here: The paper studies pure exploration in MABs with unknown linear constraints, so understanding the basic MAB framework is essential.
  - Quick check question: What is the goal of a multi-armed bandit algorithm, and how does it differ from pure exploration?

- **Concept:** Lagrangian relaxation
  - Why needed here: The paper uses Lagrangian relaxation to handle unknown constraints, so understanding this technique is crucial for grasping the algorithm design.
  - Quick check question: How does Lagrangian relaxation transform a constrained optimization problem into an unconstrained one?

- **Concept:** Convex optimization
  - Why needed here: The paper leverages results from convex analysis to prove properties of the Lagrangian relaxation, so familiarity with convex optimization is important.
  - Quick check question: What are the Karush-Kuhn-Tucker (KKT) conditions, and how do they relate to strong duality in convex optimization?

## Architecture Onboarding

- **Component map:** Estimation module -> Lagrangian relaxation module -> Sampling strategy module -> Stopping criterion module -> Recommendation module
- **Critical path:** Estimation → Lagrangian relaxation → Sampling strategy → Stopping criterion → Recommendation
- **Design tradeoffs:**
  - Optimistic vs. pessimistic estimates: Optimistic estimates ensure feasibility but may lead to over-exploration.
  - Lagrangian multiplier tuning: The choice of Lagrangian multipliers affects the balance between exploration and constraint satisfaction.
  - Stopping criterion tightness: A tighter stopping criterion reduces sample complexity but increases computational cost.

- **Failure signatures:**
  - High constraint violation: Indicates that the estimated constraints are not converging fast enough or the Lagrangian relaxation is not effective.
  - Slow convergence to optimal policy: Suggests that the sampling strategy is not efficient or the Lagrangian bound is not tight.
  - Computational inefficiency: May be due to the complexity of solving the Lagrangian dual problem or the stopping criterion.

- **First 3 experiments:**
  1. Test the estimation module on synthetic data with known constraints to verify its accuracy.
  2. Evaluate the Lagrangian relaxation module by comparing its bounds to the true sample complexity.
  3. Implement the sampling strategy and stopping criterion, and test their performance on synthetic environments with varying constraint geometries.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Lagrangian relaxation technique be extended to non-linear constraint settings?
- Basis in paper: [inferred] The authors mention in the Discussion & Future Work section that it would be "intriguing to extend our Lagrangian technique to non-linear constraints."
- Why unresolved: The paper focuses exclusively on linear constraints, and no experiments or theoretical results are provided for non-linear cases.
- What evidence would resolve it: A formal extension of the Lagrangian relaxation framework to non-linear constraints with theoretical guarantees and experimental validation.

### Open Question 2
- Question: What is the optimal way to balance exploration and constraint satisfaction in the unknown constraints setting?
- Basis in paper: [explicit] The authors discuss the trade-off between identifiability of an r-optimal policy and feasibility under estimated constraints, but do not provide a definitive answer on how to optimally balance these objectives.
- Why unresolved: The paper proposes algorithms that attempt to balance these objectives, but does not prove that they are optimal or provide a framework for determining the optimal balance.
- What evidence would resolve it: A theoretical analysis proving the optimality of a particular balance between exploration and constraint satisfaction, or empirical results showing that a specific approach outperforms others across a range of problem instances.

### Open Question 3
- Question: How does the shadow price parameter affect the sample complexity of LATS and LAGEX in practice?
- Basis in paper: [explicit] The authors derive theoretical bounds showing that the shadow price appears in the sample complexity of both algorithms, but do not provide extensive empirical results on its practical impact.
- Why unresolved: The paper only provides theoretical bounds and a limited set of experiments on the shadow price, without a comprehensive analysis of its practical significance.
- What evidence would resolve it: Extensive empirical results across a wide range of problem instances showing the relationship between the shadow price and the actual sample complexity of LATS and LAGEX, as well as any potential strategies for mitigating its impact.

## Limitations

- Theoretical guarantees rely on the assumption of strictly feasible constraints with non-zero slack
- Computational complexity of solving the Lagrangian dual problem and projection lemma may be prohibitive for large-scale problems
- Experimental evaluation limited to synthetic and one real-world dataset, may not capture all practical scenarios

## Confidence

- **High**: Theoretical claims about Lagrangian relaxation framework and strong duality result (Theorem 1)
- **Medium**: Practical performance claims based on experimental evaluation

## Next Checks

1. Test the algorithms on a broader range of real-world datasets with varying constraint geometries and feasibility conditions
2. Analyze the sensitivity of the Lagrangian multipliers and the optimistic estimation parameters to changes in problem parameters
3. Investigate the computational complexity of the Lagrangian dual problem and the projection lemma, and explore potential approximations or relaxations for large-scale problems