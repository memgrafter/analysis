---
ver: rpa2
title: 'SWaT: Statistical Modeling of Video Watch Time through User Behavior Analysis'
arxiv_id: '2408.07759'
source_url: https://arxiv.org/abs/2408.07759
tags:
- video
- time
- watch
- user
- watching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SWaT, a statistical framework for modeling
  video watch time through user behavior analysis. The core idea is to translate user
  behavior assumptions into statistical models using bucketization to handle non-stationary
  watching probabilities.
---

# SWaT: Statistical Modeling of Video Watch Time through User Behavior Analysis

## Quick Facts
- arXiv ID: 2408.07759
- Source URL: https://arxiv.org/abs/2408.07759
- Authors: Shentao Yang; Haichuan Yang; Linna Du; Adithya Ganesh; Bo Peng; Boying Liu; Serena Li; Ji Liu
- Reference count: 40
- Primary result: Introduces SWaT framework modeling video watch time through user behavior analysis, outperforming state-of-the-art methods on public datasets and achieving significant improvements in online A/B testing

## Executive Summary
This paper presents SWaT (Statistical modeling of Watch Time), a statistical framework for predicting video watch time by translating user behavior assumptions into statistical models. The core innovation is using bucketization to handle non-stationary watching probabilities over video horizons, with two distinct behavioral modes: wandering-minded users modeled with binomial distributions and focused users modeled with bucketized geometric distributions. Extensive experiments demonstrate SWaT's effectiveness across public datasets, an industrial dataset, and real-world deployment on a short video platform with hundreds of millions of daily-active users.

## Method Summary
SWaT models video watch time by discretizing the infinite video horizon into finite buckets, learning bucket-specific watching probabilities, and applying appropriate statistical distributions based on behavioral assumptions. The framework implements two models: SWaT-Binom for random pick-and-play behavior using binomial distributions, and SWaT-Geo for sequential watching using bucketized geometric distributions. Both models optimize parameters via maximum likelihood estimation with binary cross-entropy loss. The expected watch time is computed as the sum of bucket-wise expectations using closed-form formulas derived from the statistical distributions.

## Key Results
- On public datasets (CIKM16 Cup and KuaiRec), SWaT-Binom and SWaT-Geo consistently achieve top-2 performance across MAE and XAUC metrics
- On industrial dataset, SWaT models show significant gains over baseline methods
- Online A/B test on a short video platform with hundreds of millions of daily-active users demonstrates SWaT improves accumulated watch time and watch count
- SWaT outperforms state-of-the-art methods including WLR, D2Q, OR, and TPM

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bucketization enables statistical modeling of non-stationary watching probabilities without losing model capacity
- Mechanism: By discretizing the infinite video horizon into finite buckets, the model learns distinct watching probabilities for each bucket, capturing how user interest changes over time
- Core assumption: User's probability of continuing to watch varies across different time segments of the video
- Evidence anchors:
  - [abstract]: "employ bucketization to cope with user's non-stationary watching probability over the video horizon"
  - [section 3.1]: "Considering the users' varying interests/retention intention over the video horizon, we bucketize the infinite video horizon onto smaller buckets"
- Break condition: If user interest is actually stationary across the entire video, bucketization adds unnecessary complexity without improving performance

### Mechanism 2
- Claim: Translating user behavior assumptions into statistical models enables principled watch time estimation
- Mechanism: Different behavioral assumptions (wandering-minded vs focused user) are directly mapped to binomial and geometric distributions, respectively, allowing for closed-form expectation calculations
- Core assumption: User behavior can be categorized into distinct modes that follow known statistical distributions
- Evidence anchors:
  - [abstract]: "directly translates various user behavior assumptions in watching (short) videos into statistical watch time models"
  - [section 3.2]: "the watch time in each bucket can be modeled as a binomial distribution"
- Break condition: If real user behavior doesn't fit these simplified behavioral modes, the statistical models will misrepresent actual watching patterns

### Mechanism 3
- Claim: Bucketization implicitly respects video length constraints and facilitates compatibility with classification-based events
- Mechanism: Short videos naturally concentrate watching probabilities on lower-value buckets, while long videos spread probabilities across higher-value buckets. Additionally, converting regression to classification enables joint training with other classification events
- Core assumption: Video length correlates with where watching probabilities are concentrated in the bucket structure
- Evidence anchors:
  - [abstract]: "bucketization can further implicitly satisfy the constraint of video length"
  - [section 3.1]: "short videos should have watching probabilities concentrated on lower-value buckets and long videos on higher-value buckets"
- Break condition: If video length doesn't correlate with where users stop watching, the implicit length constraint fails to provide meaningful benefits

## Foundational Learning

- Concept: Statistical modeling of user behavior
  - Why needed here: The framework requires translating behavioral assumptions into statistical distributions for principled watch time estimation
  - Quick check question: Can you explain why a wandering-minded user would be modeled with a binomial distribution while a focused user uses a geometric distribution?

- Concept: Bucketization and discretization strategies
  - Why needed here: The framework uses bucketization to handle non-stationary watching probabilities and implicitly manage video length constraints
  - Quick check question: How does bucketization help with both modeling varying user interest and respecting video length constraints simultaneously?

- Concept: Maximum likelihood estimation for parameter fitting
  - Why needed here: The framework fits bucket-specific watching probabilities using MLE based on observed watch times
  - Quick check question: What is the MLE objective for fitting the binomial model's watching probability in a given bucket?

## Architecture Onboarding

- Component map: User features → Bucketization → Bucket-specific probabilities → Statistical model → Expected watch time estimate
- Critical path: User features → Bucketization → Bucket-specific probabilities → Statistical model → Expected watch time estimate
- Design tradeoffs:
  - More buckets increase model capacity but require more training data and computation
  - Fewer buckets simplify the model but may miss important non-stationarities
  - Binomial model handles random pick-and-play behavior but may not capture sequential watching well
  - Geometric model captures sequential watching but assumes more structured behavior
- Failure signatures:
  - Training instability with large or highly varying watch times (especially for geometric model)
  - Poor performance on very short or very long videos (bucketization may not align well)
  - Overfitting to bucket boundaries rather than smooth transitions in user interest
- First 3 experiments:
  1. Vary the number of buckets (10, 50, 100, 200) and measure impact on MAE and XAUC metrics
  2. Compare training stability by monitoring loss curves for binomial vs geometric models
  3. Test different bucket definition strategies (uniform percentiles vs adaptive based on watch time distribution)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the SWaT framework to different user behavior modes not explicitly modeled, such as users who frequently pause and resume videos or those who watch in reverse?
- Basis in paper: [inferred] The paper models two distinct user behavior modes (wandering-minded and focused users) but does not explicitly address other potential behaviors like pausing/resuming or reverse watching
- Why unresolved: The paper does not provide empirical evidence or theoretical analysis on how well the framework generalizes to unmodeled behaviors
- What evidence would resolve it: Experiments comparing SWaT performance on datasets with known pause/resume patterns or reverse watching behavior, or a theoretical extension of the framework to include these behaviors

### Open Question 2
- Question: What is the optimal number of buckets for the bucketization strategy, and how does this choice affect model performance across different video lengths and user behavior patterns?
- Basis in paper: [explicit] The paper mentions using 100 buckets by default and conducts an ablation study showing robustness to bucket numbers, but does not provide a principled method for determining the optimal number
- Why unresolved: The ablation study shows performance is generally robust to bucket numbers, but does not identify an optimal choice or explain how to select bucket numbers for specific scenarios
- What evidence would resolve it: A systematic study varying bucket numbers across multiple datasets with different video length distributions and user behavior patterns, identifying performance trends and optimal choices

### Open Question 3
- Question: How does the SWaT framework perform when applied to live streaming video content, where user behavior and video length characteristics may differ significantly from pre-recorded short videos?
- Basis in paper: [inferred] The paper focuses on short video platforms with pre-recorded content, and while it mentions the possibility of indefinite replays, it does not address live streaming scenarios
- Why unresolved: The paper does not include any experiments or theoretical analysis on live streaming content, which may have different user engagement patterns and technical constraints
- What evidence would resolve it: Experiments applying SWaT to live streaming datasets, or a theoretical extension of the framework to handle the unique characteristics of live content (e.g., no fixed video length, different user interaction patterns)

## Limitations
- Behavioral assumptions may not fully capture complex real user watching patterns, particularly for videos with mixed content or varying quality
- Bucketization introduces hyperparameters (number of buckets, bucket boundaries) that may require dataset-specific tuning
- Models assume watching probabilities are independent across buckets, which may not hold for users with sustained attention patterns

## Confidence
- **High Confidence**: Empirical results showing SWaT models outperforming baselines on multiple datasets and in online A/B testing; mathematical formulation is sound
- **Medium Confidence**: Behavioral assumptions translating to specific statistical distributions; bucketization strategy effectiveness
- **Medium Confidence**: Robustness to bucketization hyperparameters and generalization across different video genres

## Next Checks
1. **Behavioral Assumption Validation**: Conduct user studies or analyze clickstream data to empirically verify whether real user watching patterns align with the binomial (random pick-and-play) and geometric (sequential watching) behavioral modes assumed by the models

2. **Bucket Sensitivity Analysis**: Systematically vary the number of buckets (e.g., 10, 50, 100, 200) and bucket definition strategies (uniform vs. adaptive) across different video categories and measure the impact on both model performance and training stability

3. **Cross-Dataset Generalization**: Test the SWaT models on datasets from different platforms or regions with potentially different user behaviors to assess whether the behavioral assumptions and bucketization approach generalize beyond the tested domains