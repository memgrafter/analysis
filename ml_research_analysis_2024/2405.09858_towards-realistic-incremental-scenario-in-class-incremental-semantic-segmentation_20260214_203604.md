---
ver: rpa2
title: Towards Realistic Incremental Scenario in Class Incremental Semantic Segmentation
arxiv_id: '2405.09858'
source_url: https://arxiv.org/abs/2405.09858
tags:
- task
- classes
- data
- each
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses a critical limitation in the widely used "overlapped"
  scenario for Class Incremental Semantic Segmentation (CISS), where the same image
  can reappear in future tasks with different pixel labels. This unrealistic property
  leads to unintended advantages or disadvantages for commonly used techniques like
  pseudo-labeling and exemplar memory, biasing experimental results.
---

# Towards Realistic Incremental Scenario in Class Incremental Semantic Segmentation

## Quick Facts
- arXiv ID: 2405.09858
- Source URL: https://arxiv.org/abs/2405.09858
- Reference count: 27
- Addresses unrealistic "overlapped" scenario in CISS where same image reappears with different labels

## Executive Summary
This paper addresses a critical limitation in the widely used "overlapped" scenario for Class Incremental Semantic Segmentation (CISS), where the same image can reappear in future tasks with different pixel labels. This unrealistic property leads to unintended advantages or disadvantages for commonly used techniques like pseudo-labeling and exemplar memory, biasing experimental results. To mitigate this, the authors propose a new "partitioned" scenario that divides the dataset into mutually exclusive subsets representing each class, and assigns each subset to its corresponding task. This eliminates overlapping data while still capturing background shifts. The authors also identify and correct an overlooked code implementation issue in exemplar memory retrieval, and introduce a simple yet competitive memory-based baseline, MiB-AugM, that effectively handles background shifts of current task classes in the exemplar memory. MiB-AugM achieves state-of-the-art results across multiple tasks involving learning numerous new classes.

## Method Summary
The authors introduce a "partitioned" scenario for CISS that divides the dataset into mutually exclusive subsets for each class, assigning each subset to its corresponding task to eliminate overlapping data. They also correct an implementation issue in exemplar memory retrieval and propose MiB-AugM, a memory-based baseline that handles background shifts of current task classes in the exemplar memory. MiB-AugM achieves state-of-the-art results across multiple tasks involving learning numerous new classes.

## Key Results
- The "overlapped" scenario in CISS is unrealistic as it allows same images to reappear with different labels
- The proposed "partitioned" scenario eliminates overlapping data while capturing background shifts
- MiB-AugM achieves state-of-the-art results across multiple tasks involving learning numerous new classes

## Why This Works (Mechanism)
The "partitioned" scenario addresses the unrealistic property of the "overlapped" scenario by dividing the dataset into mutually exclusive subsets for each class. This eliminates the issue of same images reappearing with different labels, providing a more realistic evaluation framework for CISS algorithms. The MiB-AugM baseline effectively handles background shifts of current task classes in the exemplar memory, contributing to its state-of-the-art performance.

## Foundational Learning
1. **Class Incremental Semantic Segmentation (CISS)**: A learning paradigm where a model learns to segment new classes incrementally without forgetting previous ones.
   - Why needed: To address the challenge of learning new classes in semantic segmentation without forgetting previously learned classes.
   - Quick check: Understand the concept of incremental learning and its application in semantic segmentation tasks.

2. **Exemplar Memory**: A technique to store a subset of previously seen data to prevent catastrophic forgetting in incremental learning.
   - Why needed: To retain knowledge of previously learned classes while learning new ones.
   - Quick check: Familiarize with the concept of exemplar memory and its role in preventing catastrophic forgetting.

3. **Background Shift**: The phenomenon where the background in images changes over time or across different tasks.
   - Why needed: To understand the challenges posed by background changes in incremental learning scenarios.
   - Quick check: Analyze how background shifts affect the performance of incremental learning models.

## Architecture Onboarding
- **Component Map**: Dataset -> Partitioned Scenario -> CISS Model -> MiB-AugM Baseline
- **Critical Path**: Partitioned Scenario Setup -> Model Training -> Background Shift Handling -> Evaluation
- **Design Tradeoffs**: The partitioned scenario sacrifices the ability to use the same image for multiple tasks in favor of a more realistic evaluation framework.
- **Failure Signatures**: If the partitioned scenario does not adequately capture real-world data distributions, it may lead to biased evaluation results.
- **3 First Experiments**:
  1. Validate the effectiveness of the partitioned scenario on a simple CISS dataset.
  2. Compare the performance of MiB-AugM with existing baselines on a standard CISS benchmark.
  3. Analyze the impact of the corrected exemplar memory retrieval implementation on model performance.

## Open Questions the Paper Calls Out
None

## Limitations
- The "partitioned" scenario may not fully capture the complexity of real-world data distributions and class co-occurrences.
- The assumption that background shift alone captures realistic incremental learning challenges may oversimplify the problem space.
- The correction of exemplar memory retrieval implementation issues may have downstream effects on previously published comparisons.

## Confidence
- High confidence in the identification and critique of the overlapped scenario's unrealistic properties and their impact on evaluation fairness
- Medium confidence in the proposed partitioned scenario as a more realistic alternative, pending broader validation across diverse datasets and use cases
- Medium confidence in MiB-AugM's effectiveness, as the claims of state-of-the-art performance need independent verification

## Next Checks
1. Conduct experiments on additional datasets (e.g., Cityscapes, BDD100K) to verify the partitioned scenario's applicability beyond the current evaluation scope.
2. Perform ablation studies isolating the effects of the exemplar memory retrieval correction to quantify its impact on reported results.
3. Test MiB-AugM in online/streaming settings to evaluate its robustness to temporal variations in class distributions and background shifts.