---
ver: rpa2
title: 'Large Language Models for Classical Chinese Poetry Translation: Benchmarking,
  Evaluating, and Improving'
arxiv_id: '2408.09945'
source_url: https://arxiv.org/abs/2408.09945
tags:
- translation
- chinese
- poetry
- classical
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates large language models (LLMs) for translating
  classical Chinese poetry into English, a task requiring adequacy, fluency, and elegance.
  It introduces PoetMT, a benchmark with curated poetry and translations, and proposes
  a GPT-4-based metric to assess translation quality across these dimensions.
---

# Large Language Models for Classical Chinese Poetry Translation: Benchmarking, Evaluating, and Improving

## Quick Facts
- arXiv ID: 2408.09945
- Source URL: https://arxiv.org/abs/2408.09945
- Reference count: 27
- Primary result: Retrieval-Augmented Translation (RAT) improves classical Chinese poetry translation by integrating knowledge from a curated knowledge base

## Executive Summary
This paper addresses the challenge of translating classical Chinese poetry into English, a task requiring adequacy, fluency, and elegance. The authors introduce PoetMT, a benchmark with curated poetry and translations, and propose a GPT-4-based metric to assess translation quality across these dimensions. They develop RAT (Retrieval-Augmented Translation), which integrates classical poetry knowledge from a curated knowledge base to improve translations. RAT consistently outperforms other methods across multiple evaluation metrics and human evaluation, demonstrating the value of retrieval-augmented knowledge for classical poetry translation.

## Method Summary
The study evaluates large language models for translating classical Chinese poetry into English, focusing on adequacy, fluency, and elegance. The authors introduce the PoetMT benchmark containing 608 classical Chinese poems with human translations. They propose RAT (Retrieval-Augmented Translation), a method that retrieves knowledge from a Classical Chinese Poetry Knowledge Base containing 30,000 entries with historical background, dynasty name, modern Chinese translation, author introduction, modern Chinese analysis, and poetry type. The RAT framework consists of Retriever, Selector, Translator, Voter, and Extractor modules that work together to generate improved translations by integrating knowledge from multiple perspectives.

## Key Results
- RAT method consistently outperforms zero-shot, few-shot, and fine-tuned baselines across BLEU, COMET, BLEURT, and the proposed GPT-4-based metric
- The proposed GPT-4-based metric shows higher correlation with human evaluation compared to traditional metrics
- Modern Chinese translation knowledge proves most helpful for translation quality, followed by author introduction and poetry type knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retrieval-Augmented Translation (RAT) improves classical Chinese poetry translation by integrating context-specific knowledge from a curated knowledge base.
- Mechanism: RAT retrieves multiple types of knowledge (historical background, dynasty name, modern Chinese translation, author introduction, modern Chinese analysis, and poetry type) related to the source poem. This knowledge is then used to generate multiple translation candidates, which are voted on and integrated to produce the final translation.
- Core assumption: Classical Chinese poetry translation benefits from domain-specific knowledge that goes beyond the linguistic capabilities of LLMs.
- Evidence anchors:
  - [abstract]: "we propose a Retrieval-Augmented Machine Translation (RAT) method which incorporates knowledge related to classical poetry for advancing the translation of Chinese Poetry in LLMs."
  - [section 5]: Describes the RAT framework with Retriever, Selector, Translator, Voter, and Extractor modules.
  - [corpus]: Weak evidence - only 8 related papers found, suggesting this approach may be novel.
- Break condition: If the knowledge base contains inaccurate or irrelevant information, the translation quality may degrade.

### Mechanism 2
- Claim: The proposed GPT-4-based metric (LLM-BM, LLM-BF, LLM-BS) better evaluates classical poetry translation quality compared to traditional metrics like BLEU and COMET.
- Mechanism: The LLM-based metric explicitly evaluates translation adequacy, fluency, and elegance from multiple perspectives (Beauty of Meaning, Beauty of Form, and Beauty of Sound) using tailored prompts for GPT-4.
- Core assumption: Traditional translation metrics are insufficient for evaluating the unique requirements of classical poetry translation.
- Evidence anchors:
  - [abstract]: "we propose a new metric based on GPT-4 to evaluate the extent to which current LLMs can meet these demands."
  - [section 4]: Details the evaluation criteria and LLM-based metric design.
  - [section 7.1]: Shows that the LLM-based metric has higher correlation with human evaluation compared to traditional metrics.
- Break condition: If GPT-4's understanding of classical poetry aesthetics is limited, the metric may not accurately reflect translation quality.

### Mechanism 3
- Claim: Different types of classical Chinese poetry (Tang, Song, Yuan) have varying levels of translation difficulty, with Tang poetry being relatively easier due to its stricter structure and brevity.
- Mechanism: The RAT method was evaluated on different poetry types, and the results showed consistent trends across types, with Tang poetry achieving higher scores in certain aspects.
- Core assumption: The structural characteristics of different poetry types influence their translation difficulty.
- Evidence anchors:
  - [section 7.7]: "The results show consistent trends across types. Tang poetry is relatively easier to translate due to its stricter structure and brevity."
  - [section 3.1]: Describes the PoetMT benchmark containing Tang, Song, and Yuan poetry.
  - [corpus]: No direct evidence in corpus, but the claim aligns with general knowledge of classical Chinese poetry forms.
- Break condition: If the structural differences between poetry types are not as significant as assumed, the difficulty ranking may not hold.

## Foundational Learning

- Concept: Classical Chinese poetry structure and aesthetics
  - Why needed here: Understanding the unique requirements of classical Chinese poetry translation, including rhyme, tone, structure, and aesthetic qualities, is crucial for developing effective translation methods and evaluation metrics.
  - Quick check question: What are the key differences between classical Chinese poetry and modern Chinese poetry in terms of structure and aesthetics?

- Concept: Large language model capabilities and limitations
  - Why needed here: Recognizing the strengths and weaknesses of LLMs in translation tasks, particularly their ability to handle cultural context, historical knowledge, and poetic elegance, is essential for evaluating and improving translation performance.
  - Quick check question: How do LLMs typically handle ambiguous words or phrases in translation, and what are the potential pitfalls?

- Concept: Retrieval-augmented generation
  - Why needed here: Understanding the principles and applications of retrieval-augmented generation is crucial for implementing the RAT method and leveraging external knowledge to enhance translation quality.
  - Quick check question: What are the key components of a retrieval-augmented generation system, and how do they interact to produce the final output?

## Architecture Onboarding

- Component map: Knowledge Base -> Retriever -> Selector -> Translator -> Voter -> Extractor -> Final Translation

- Critical path: Knowledge Base → Retriever → Selector → Translator → Voter → Extractor → Final Translation

- Design tradeoffs:
  - Accuracy vs. efficiency: Using a larger knowledge base may improve translation accuracy but increase computational cost.
  - Retrieval relevance vs. diversity: Retrieving more diverse knowledge may lead to more creative translations but could also introduce irrelevant information.
  - Voting mechanism vs. direct integration: Voting on translations may produce more consistent results but could miss opportunities for direct integration of knowledge.

- Failure signatures:
  - Low-quality translations despite high knowledge retrieval scores: Indicates issues with the knowledge base content or the translation process.
  - Inconsistent translations across different runs: Suggests problems with the voter's decision-making process or the knowledge base's reliability.
  - Poor performance on specific poetry types: Highlights limitations in handling the unique characteristics of certain classical Chinese poetry forms.

- First 3 experiments:
  1. Evaluate the impact of different knowledge types on translation quality by ablating each type and comparing the results.
  2. Test the robustness of the RAT method by introducing noise or errors in the knowledge base and observing the translation performance.
  3. Compare the RAT method's performance with other translation approaches (e.g., zero-shot, few-shot, and fine-tuned models) on a held-out test set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different types of retrieval knowledge (historical background, dynasty name, modern Chinese translation, author introduction, modern Chinese analysis, poetry type) contribute to translation quality in the RAT method?
- Basis in paper: [explicit] Section 7.5 discusses the impact of different knowledge types on translation performance
- Why unresolved: While the paper identifies that modern Chinese translation knowledge is most helpful, it doesn't provide detailed analysis of how each knowledge type specifically impacts the three evaluation criteria (adequacy, fluency, elegance)
- What evidence would resolve it: Detailed experimental results showing performance breakdown of RAT using each knowledge type individually on all evaluation metrics

### Open Question 2
- Question: What are the limitations of current LLM-based evaluation metrics for classical poetry translation, and how can they be improved?
- Basis in paper: [explicit] Section 7.1 shows that while GPT-4-based metrics align better with human evaluation than traditional metrics, there is still room for improvement
- Why unresolved: The paper demonstrates the effectiveness of the proposed GPT-4-based metric but doesn't explore potential improvements or alternative evaluation approaches
- What evidence would resolve it: Comparative studies of different LLM-based evaluation approaches and their correlation with human judgment

### Open Question 3
- Question: How does the performance of RAT vary across different types of classical Chinese poetry (Tang, Song, Yuan)?
- Basis in paper: [explicit] Section 7.7 analyzes translation challenges across different poetry types but doesn't provide detailed performance comparisons
- Why unresolved: The paper identifies that Tang poetry is relatively easier to translate but doesn't provide detailed performance metrics for RAT across all poetry types
- What evidence would resolve it: Comprehensive performance analysis of RAT across all three poetry types using all evaluation metrics

### Open Question 4
- Question: What are the specific error patterns in LLM-based translations of classical Chinese poetry, and how can they be systematically addressed?
- Basis in paper: [explicit] Section 8.8 provides a human-centered error analysis of RAT translations, identifying specific error categories
- Why unresolved: While error patterns are identified, the paper doesn't provide systematic approaches to address these errors or measure the effectiveness of error-correction methods
- What evidence would resolve it: Analysis of error-correction methods and their impact on translation quality across different error categories

## Limitations

- The knowledge base coverage may be insufficient for handling diverse classical Chinese poetry content, limiting the method's scalability to broader poetry domains
- The proposed GPT-4-based metric may not generalize well to other languages or cultural contexts, raising questions about its robustness across different translation tasks
- The study focuses exclusively on Chinese classical poetry, limiting the generalizability of findings to other poetic traditions or languages

## Confidence

- Medium: RAT method consistently improves translation quality across multiple metrics and human evaluation
- Medium: GPT-4-based metric correlates better with human evaluation than traditional metrics for classical poetry translation
- Low: Claims about the difficulty ranking of different poetry types (Tang, Song, Yuan) based on structural characteristics

## Next Checks

1. Conduct ablation studies on each type of retrieved knowledge (historical background, dynasty name, modern Chinese translation, author introduction, modern Chinese analysis, and poetry type) to quantify their individual contributions to translation quality improvements.

2. Test the proposed GPT-4-based metric on a diverse set of translation tasks beyond classical Chinese poetry to assess its generalizability and identify potential cultural or linguistic biases.

3. Evaluate the RAT method's performance on a held-out test set of classical Chinese poems not present in the knowledge base to assess the method's ability to handle unseen content and knowledge gaps.