---
ver: rpa2
title: Unsupervised Anomaly Detection Using Diffusion Trend Analysis for Display Inspection
arxiv_id: '2407.09578'
source_url: https://arxiv.org/abs/2407.09578
tags:
- anomaly
- normal
- image
- detection
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of unsupervised anomaly detection
  in display inspection using denoising diffusion models. The core problem tackled
  is the difficulty in setting optimal noise levels for image degradation and the
  tendency of diffusion models to produce false positives in normal regions.
---

# Unsupervised Anomaly Detection Using Diffusion Trend Analysis for Display Inspection

## Quick Facts
- arXiv ID: 2407.09578
- Source URL: https://arxiv.org/abs/2407.09578
- Reference count: 0
- Primary result: mAUROC improved by 8.0% and mAP by 20.3% on public datasets; mAUROC improved by 10.0% and mAP by 9.4% on display inspection datasets

## Executive Summary
This paper addresses the challenge of unsupervised anomaly detection in display inspection using denoising diffusion models. The core innovation is a trend analysis approach that examines reconstruction patterns across multiple noise levels rather than relying on single-level reconstruction errors. The method analyzes both intensity trends and model uncertainty trends, leveraging Fourier coefficient analysis to quantify these patterns. Evaluated on both public industrial datasets (MVTec) and proprietary display inspection data, the approach significantly outperforms existing diffusion-based methods while reducing false positives in normal regions.

## Method Summary
The proposed method trains a denoising diffusion model on normal images only, then applies multiple noise levels to test images and reconstructs them. For each pixel location, it analyzes how reconstruction intensity and model uncertainty change as noise level increases. These trends are quantified using second Fourier coefficient magnitudes, normalized, and combined to produce final anomaly scores. The key insight is that anomaly regions gradually transform toward normal appearance as noise increases, creating directional trends that distinguish them from normal regions which show random fluctuations.

## Key Results
- mAUROC improved by 8.0% and mAP by 20.3% on MVTec Anomaly Detection Dataset compared to existing diffusion-based methods
- mAUROC improved by 10.0% and mAP by 9.4% on proprietary display inspection dataset
- Trend-based analysis effectively reduces false positives in normal regions
- Method shows consistent performance across different defect types including dents, particles, and scratches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Analyzing reconstruction trends across increasing noise levels effectively distinguishes anomalies from normal regions.
- Mechanism: As noise level increases, anomaly regions show a gradual trend toward normal appearance while normal regions show random fluctuations without directional trend.
- Core assumption: The trend patterns in reconstructed images are independent of anomaly morphology (color, size, shape).
- Evidence anchors: Supported by abstract observations and section explanations about noise level effects on reconstruction.

### Mechanism 2
- Claim: Model uncertainty trends provide complementary information to intensity trends for anomaly detection.
- Mechanism: Model uncertainty decreases as reconstructed images approach normal distribution, creating a distinguishable trend for anomalies that can be detected through gradient analysis.
- Core assumption: Diffusion models trained only on normal data will have higher uncertainty when reconstructing anomaly regions.
- Evidence anchors: Abstract mentions uncertainty trend analysis; section explains gradient-based uncertainty calculation.

### Mechanism 3
- Claim: Low-frequency trend analysis using second Fourier coefficient effectively captures the gradual changes of interest.
- Mechanism: Since trends of interest are extremely low-frequency components that change slowly with noise level, using second Fourier coefficient removes high-frequency noise and captures meaningful trends.
- Core assumption: The trend of interest is an extremely low-frequency component that changes slowly with increasing noise levels.
- Evidence anchors: Section explicitly states use of second Fourier coefficient for slow trend quantification.

## Foundational Learning

- Concept: Denoising diffusion models and their reverse process
  - Why needed here: The method relies on diffusion models to reconstruct noisy images back to normal distribution
  - Quick check question: What is the difference between the forward diffusion process and the reverse process in denoising diffusion models?

- Concept: Fourier analysis and frequency components
  - Why needed here: The method uses second Fourier coefficient to capture low-frequency trends in reconstruction patterns
  - Quick check question: Why would using only the second Fourier coefficient be effective for capturing slow trends?

- Concept: Model uncertainty and gradient-based uncertainty estimation
  - Why needed here: The method calculates model uncertainty through gradient analysis to detect unfamiliar data regions
  - Quick check question: How does calculating the gradient of model output with respect to model input help estimate model uncertainty?

## Architecture Onboarding

- Component map: Input image pipeline → Noise addition module → Diffusion model → Multiple reconstruction outputs → Trend analysis module (intensity + uncertainty) → Fourier coefficient extraction → Score normalization → Final anomaly score

- Critical path:
  1. Load input image
  2. Apply multiple noise levels
  3. Generate reconstructions for each noise level
  4. Compute intensity trends and model uncertainty trends
  5. Extract second Fourier coefficients
  6. Normalize and combine trends
  7. Output final anomaly score

- Design tradeoffs:
  - Multiple noise levels vs. single noise level: Multiple levels provide more information but increase computation time
  - Intensity trend vs. uncertainty trend: Intensity trend is computationally cheaper but uncertainty trend provides complementary information
  - Fourier coefficient vs. direct trend measurement: Fourier analysis effectively filters noise but may miss some high-frequency patterns

- Failure signatures:
  - Poor performance on certain defect types: May indicate limitations in trend detection for specific anomaly morphologies
  - High false positive rates: Could suggest normal regions are showing directional trends or uncertainty patterns
  - Computational bottlenecks: May occur during multiple reconstructions or Fourier analysis steps

- First 3 experiments:
  1. Test on a simple dataset (like MVTec) with single noise level to verify basic diffusion reconstruction works
  2. Implement trend analysis with 3-5 noise levels and compare against single-level reconstruction
  3. Add uncertainty trend analysis and evaluate performance improvement on known challenging cases (fine details, high contrast regions)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed trend analysis method perform on extremely rare anomalies that may not exhibit clear trends due to insufficient data points?
- Basis in paper: The paper mentions that AP is sensitive to rare event detection performance and that the method increases sensitivity to small anomalies, but doesn't address performance on extremely rare anomalies.
- Why unresolved: The evaluation used 20 unseen images per defect type, which may be sufficient for most anomalies but may not be representative of extremely rare events.
- What evidence would resolve it: Testing the method on datasets with anomalies occurring at less than 1% frequency and comparing performance metrics against other methods.

### Open Question 2
- Question: What is the computational overhead of trend analysis compared to single-noise-level reconstruction, and how does it scale with image resolution?
- Basis in paper: The method analyzes trends across multiple noise levels and computes model gradients, but the paper doesn't provide detailed computational complexity analysis or scaling behavior.
- Why unresolved: The paper focuses on performance metrics but doesn't discuss computational efficiency or runtime comparisons.
- What evidence would resolve it: Benchmarking runtime performance across different image resolutions and comparing against baseline methods while measuring GPU/CPU utilization.

### Open Question 3
- Question: How sensitive is the method to the choice of Fourier coefficients used for trend quantification, and what is the optimal range for different defect types?
- Basis in paper: The paper states they used "the magnitude of the second Fourier coefficient" but doesn't explore sensitivity to this choice or discuss optimal ranges.
- Why unresolved: The method relies on Fourier analysis for trend quantification, but the paper doesn't investigate whether different frequency components might be more effective for certain defect types.
- What evidence would resolve it: Systematic evaluation using different Fourier coefficient ranges and cross-validation to determine optimal settings for various defect categories.

## Limitations

- Method relies on diffusion models' ability to reconstruct anomalies into normal appearance at high noise levels, which may not hold for all anomaly types
- Assumption that normal regions show non-directional trends while anomaly