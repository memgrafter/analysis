---
ver: rpa2
title: 'Agent-SiMT: Agent-assisted Simultaneous Machine Translation with Large Language
  Models'
arxiv_id: '2406.06910'
source_url: https://arxiv.org/abs/2406.06910
tags:
- translation
- simt
- policy
- source
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Simultaneous Machine Translation
  (SiMT), where the goal is to generate translations while reading the source sentence
  with low latency and high quality. The authors propose Agent-SiMT, a framework that
  combines the strengths of conventional SiMT models and Large Language Models (LLMs)
  through agent collaboration.
---

# Agent-SiMT: Agent-assisted Simultaneous Machine Translation with Large Language Models

## Quick Facts
- arXiv ID: 2406.06910
- Source URL: https://arxiv.org/abs/2406.06910
- Reference count: 40
- Key outcome: Agent-SiMT achieves 33.5 BLEU score on De→En task with 8.4 AL

## Executive Summary
Agent-SiMT addresses the challenge of Simultaneous Machine Translation (SiMT) by combining conventional SiMT models with Large Language Models (LLMs) through agent collaboration. The framework consists of a policy-decision agent (using a conventional SiMT model) and a translation agent (leveraging an LLM) that work together to achieve low latency and high-quality translations. The policy-decision agent determines when to read or generate based on partial source and translation, while the translation agent generates output based on the partial source. Experiments demonstrate state-of-the-art performance, achieving 33.5 BLEU on De→En with 8.4 AL.

## Method Summary
Agent-SiMT introduces a novel framework that combines the strengths of conventional SiMT models and LLMs through agent collaboration. The policy-decision agent, managed by a conventional SiMT model (HMT), determines the translation policy using partial source sentences and translations. The translation agent, leveraging an LLM (Llama2-7B-chat), generates translations based on the partial source sentence. The framework employs Supervised Fine-Tuning (SFT) with LoRA for the LLM using a small amount of full-sentence parallel corpus. A word-level policy is derived from token-level policy with boundary restrictions to address vocabulary mismatch issues. The two agents collaborate to accomplish SiMT, with the policy-decision agent determining when to read or generate, and the translation agent producing the actual translations.

## Key Results
- Achieves 33.5 BLEU score on De→En task with 8.4 Average Lagging (AL)
- Outperforms baseline models (Wait-k, MMA, ITST, HMT) in both quality and latency
- Demonstrates effective collaboration between policy-decision agent and translation agent

## Why This Works (Mechanism)
Agent-SiMT works by leveraging the complementary strengths of conventional SiMT models and LLMs. The policy-decision agent handles the timing and decision-making for reading and generating, which conventional SiMT models excel at, while the translation agent generates high-quality translations using the LLM's capabilities. The word-level policy with boundary restrictions addresses the vocabulary mismatch problem between the conventional SiMT model and the LLM. The fine-tuning of the LLM with a small amount of full-sentence parallel corpus enables it to adapt to the SiMT task while maintaining its translation quality.

## Foundational Learning

**Simultaneous Machine Translation (SiMT)**
- Why needed: Understanding the fundamental problem of generating translations while reading the source sentence
- Quick check: Can you explain the latency-quality tradeoff in SiMT?

**Average Lagging (AL)**
- Why needed: Key metric for measuring latency in SiMT systems
- Quick check: How is AL calculated and what does lower AL mean?

**LoRA Fine-tuning**
- Why needed: Technique used to efficiently fine-tune LLMs for the translation agent
- Quick check: What are the key hyperparameters (r, α) in LoRA and their roles?

## Architecture Onboarding

**Component Map**
HMT (policy-decision agent) <-> LLM (translation agent) <-> Source text

**Critical Path**
1. Policy-decision agent determines read/generate action
2. Translation agent generates output if action is "generate"
3. Process repeats with updated partial source and translation

**Design Tradeoffs**
- Uses conventional SiMT model for policy decisions (proven reliability) vs. pure LLM approach (simplicity)
- Employs word-level policy to bridge vocabulary gap between models
- Fine-tunes LLM with limited data to adapt to SiMT while preserving capabilities

**Failure Signatures**
- High AL: Policy-decision agent not effectively timing read/generate decisions
- Poor BLEU: Translation agent not properly fine-tuned or vocabulary mismatch not handled
- Incoherent translations: Boundary restrictions not properly implemented in word-level policy

**3 First Experiments**
1. Test basic read/generate policy with HMT agent on simple sentences
2. Validate LLM translation quality on full sentences before fine-tuning
3. Check vocabulary alignment between HMT and LLM using word-level policy

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: How does performance vary with different LLMs and what characteristics most influence quality/latency?
- Basis in paper: Experiments used Llama2-7B-chat; tested ParroT and BayLing on Zh→En
- Why unresolved: No detailed analysis of how different LLMs perform or which characteristics matter
- What evidence would resolve it: Systematic comparison of different LLMs with varying sizes/architectures

**Open Question 2**
- Question: What is the impact of different training data quantities and qualities on translation agent performance?
- Basis in paper: Used SFT with 100k samples; mentions impact of data quantity
- Why unresolved: Doesn't explore effects of different data qualities or larger datasets
- What evidence would resolve it: Experiments varying training data amount/quality and measuring BLEU/AL

**Open Question 3**
- Question: How does Agent-SiMT perform in real-world scenarios with varying network conditions and computational resources?
- Basis in paper: Mentions AL-CA metric and practical usability
- Why unresolved: No empirical data on real-world performance under different conditions
- What evidence would resolve it: Deployment in diverse real-world environments measuring performance metrics

## Limitations

- Implementation details of HMT model integration with LLM not fully specified
- Specific prompt template for LLM during SFT and inference not mentioned
- Performance evaluation limited to controlled benchmark datasets

## Confidence

- High confidence in overall concept and potential of Agent-SiMT framework
- Medium confidence in specific implementation details and hyperparameters
- Low confidence in exact prompt template affecting translation quality/latency

## Next Checks

1. Implement and evaluate Agent-SiMT framework with specified HMT model and Llama2-7B-chat LLM, verifying correct integration and policy-decision mechanism

2. Fine-tune Llama2-7B-chat with full-sentence parallel corpus using LoRA (r=8, α=16, lr=0.0001, batch=128) and validate word-level policy effectiveness

3. Compare Agent-SiMT performance with baselines on De→En task using newstest2015, measuring AL and SacreBLEU to verify state-of-the-art results