---
ver: rpa2
title: 'PraFFL: A Preference-Aware Scheme in Fair Federated Learning'
arxiv_id: '2404.08973'
source_url: https://arxiv.org/abs/2404.08973
tags:
- uni00000013
- uni00000011
- client
- praffl
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the trade-off between model performance and
  fairness in federated learning, where existing methods can only optimize for a single
  pre-defined preference. The authors propose PraFFL, a preference-aware scheme that
  generates preference-specific models in real-time by using a hypernetwork to map
  preference vectors to personalized model parameters while preserving client privacy.
---

# PraFFL: A Preference-Aware Scheme in Fair Federated Learning

## Quick Facts
- arXiv ID: 2404.08973
- Source URL: https://arxiv.org/abs/2404.08973
- Reference count: 40
- Key outcome: Outperforms six baseline methods on four datasets, achieving state-of-the-art hypervolume (HV) values of 0.778 (SYNTHETIC), 0.631 (COMPAS), 0.895 (BANK), and 0.834 (ADULT)

## Executive Summary
This paper addresses the trade-off between model performance and fairness in federated learning by proposing PraFFL, a preference-aware scheme that generates preference-specific models in real-time. Existing methods can only optimize for a single pre-defined preference, while PraFFL uses a hypernetwork to map preference vectors to personalized model parameters while preserving client privacy. The scheme theoretically guarantees linear convergence to the optimal model for any given preference and learns the entire Pareto front. Experimental results on four datasets demonstrate superior capability in adapting to clients' different preferences with state-of-the-art hypervolume scores.

## Method Summary
PraFFL employs a hypernetwork architecture that maps preference vectors to personalized model parameters, enabling on-the-fly model adaptation during inference without retraining. The method uses a smooth Tchebycheff function for optimization within a personalized federated learning framework. Clients maintain local datasets and preferences while the server aggregates communicated models. The hypernetwork isolates preference information, preventing exchange with other clients or the server, thereby ensuring client privacy. The approach theoretically guarantees linear convergence to the optimal model for any given preference while learning the entire Pareto front.

## Key Results
- Achieves state-of-the-art hypervolume (HV) values of 0.778 (SYNTHETIC), 0.631 (COMPAS), 0.895 (BANK), and 0.834 (ADULT) for local HV
- Outperforms six baseline methods including Pareto FL, Per-FedAvg, and MOEA/D
- Demonstrates superior capability in adapting to clients' different preferences
- The generated Pareto front covers a wider range compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: PraFFL can generate a model that aligns with any given client preference vector without retraining.
- **Mechanism**: The hypernetwork maps preference vectors to personalized model parameters, enabling on-the-fly model adaptation during inference.
- **Core assumption**: The hypernetwork can learn a continuous mapping from preference space to the space of Pareto-optimal solutions.
- **Evidence anchors**:
  - [abstract]: "PraFFL can adaptively adjust the model based on each client's preferences to meet their needs."
  - [section 4.3]: "Given a preference vector ùùÄ, the personalized model ùùìùëò of client ùëò is determined as follows: ùùìùëò = ùú∑ùëò (ùùÄ)."
  - [corpus]: Weak evidence - no directly comparable approach found in corpus.
- **Break condition**: The hypernetwork fails to learn the mapping due to insufficient training data diversity or preference vector distribution mismatch.

### Mechanism 2
- **Claim**: PraFFL preserves client preference privacy by isolating preference information in the hypernetwork.
- **Mechanism**: Client preferences are represented as parameters of the personalized model via the hypernetwork, rather than as input data to the global model.
- **Core assumption**: The hypernetwork can effectively represent client preferences without leaking information to other clients or the server.
- **Evidence anchors**:
  - [abstract]: "We introduce a hypernetwork that isolates each client's preference information, preventing it from being exchanged with other clients or the server, thereby ensuring client privacy."
  - [section 4.3]: "Each client's preference information is isolated from other clients. Therefore, hypernetwork can learn each client's preferences while protecting the client's preference information."
  - [corpus]: Weak evidence - privacy preservation mechanisms are mentioned but not deeply explored in related work.
- **Break condition**: Privacy leakage occurs through gradient information or model parameter inference attacks.

### Mechanism 3
- **Claim**: PraFFL achieves linear convergence to the optimal model for any given preference.
- **Mechanism**: The smooth Tchebycheff function combined with personalized federated learning framework ensures efficient optimization toward Pareto-optimal solutions.
- **Core assumption**: The smooth Tchebycheff function provides sufficient smoothness and convexity properties for convergence analysis.
- **Evidence anchors**:
  - [abstract]: "We theoretically prove that PraFFL can offer the optimal model tailored to an arbitrary preference of each client, and show its linear convergence."
  - [section 5.2]: "Theorem 5.8 (Convergence of PraFFL). If there exists a constant ùê¥ such that ùëß (ùë° +1) ùëß (ùë° ) ‚â• 1 ‚àí ùëß (ùë° ) ùê¥ , for ùùÄ ‚àà Œõ, then we have E[‚à• ùúΩ ùë° ùëò (ùùÄ) ‚àí ùúΩ ‚àó ùëò (ùùÄ) ‚à•2] = ùëÇ (log( 1 ùë° )) ."
  - [corpus]: Moderate evidence - related work mentions convergence but not with the same theoretical guarantees.
- **Break condition**: The convergence rate degrades due to non-convexity in the actual optimization landscape or poor hyperparameter choices.

## Foundational Learning

- **Concept**: Pareto optimality in multi-objective optimization
  - Why needed here: The core problem involves trading off model performance and fairness, requiring understanding of Pareto fronts and dominance relationships.
  - Quick check question: What distinguishes a Pareto-optimal solution from a dominated solution in a two-objective optimization problem?

- **Concept**: Federated learning with heterogeneous data
  - Why needed here: The paper addresses data heterogeneity across clients and its impact on model fairness and performance.
  - Quick check question: How does data heterogeneity typically affect the convergence and fairness properties of federated learning algorithms?

- **Concept**: Hypernetworks and their applications
  - Why needed here: The core innovation uses a hypernetwork to map preferences to model parameters, requiring understanding of this architecture.
  - Quick check question: What is the primary advantage of using a hypernetwork over directly conditioning the model on preference information?

## Architecture Onboarding

- **Component map**:
  - Global communicated model (ùùç) -> Client-specific hypernetwork (ùú∑ùëò) -> Personalized model (ùùìùëò)
  - Client data distribution (Dùëò) -> Preference vector distribution (Œõ)

- **Critical path**:
  1. Initialize global communicated model
  2. Clients download communicated model
  3. Clients optimize communicated model on local data
  4. Server aggregates communicated models
  5. Clients optimize hypernetworks using preference sampling
  6. Inference: Clients generate personalized models for any preference

- **Design tradeoffs**:
  - Communication vs computation: More frequent aggregation improves convergence but increases communication costs
  - Hypernetwork capacity vs efficiency: Larger hypernetworks can represent more complex preference mappings but require more parameters
  - Preference vector granularity: Finer preference resolution enables better personalization but requires more training data

- **Failure signatures**:
  - Poor convergence: Indicated by oscillating or stagnating hypernetwork parameters
  - Privacy leakage: Detected through reconstruction attacks on preference vectors
  - Suboptimal Pareto front: Revealed by low hypervolume scores on test data

- **First 3 experiments**:
  1. **Sanity check**: Verify that a single preference vector consistently generates the same personalized model across multiple inference runs.
  2. **Convergence test**: Monitor the hypervolume score of the generated Pareto front during training to ensure monotonic improvement.
  3. **Privacy audit**: Attempt to reconstruct preference vectors from model gradients or parameters to verify privacy preservation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PraFFL perform when client preferences are dynamic and change during the inference phase?
- Basis in paper: [explicit] The paper assumes that client preferences remain unchanged during inference when evaluating the mapping relationship from preferences to solutions.
- Why unresolved: The paper does not provide experimental results or theoretical analysis for scenarios where client preferences change dynamically over time.
- What evidence would resolve it: Experiments showing PraFFL's performance when client preferences are updated periodically or continuously during inference, including convergence behavior and solution quality metrics.

### Open Question 2
- Question: What is the impact of using different reference points when calculating hypervolume for PraFFL's performance evaluation?
- Basis in paper: [explicit] The paper mentions that the reference point ùíì in calculating hypervolume is set to (1, 1), but doesn't explore sensitivity to this choice.
- Why unresolved: The paper doesn't investigate how different reference point choices affect the hypervolume metric and comparative performance analysis.
- What evidence would resolve it: Comparative experiments showing PraFFL's performance across different reference point values, demonstrating stability and consistency of the results.

### Open Question 3
- Question: How does PraFFL's performance scale with extremely large numbers of clients (e.g., thousands or millions)?
- Basis in paper: [explicit] The paper tests PraFFL with up to 100 clients and observes slight performance degradation as client count increases.
- Why unresolved: The paper doesn't provide analysis for scenarios with very large-scale client populations where communication and computational constraints become critical.
- What evidence would resolve it: Experiments with simulated or real-world federated learning systems involving thousands of clients, measuring communication efficiency, convergence speed, and solution quality.

## Limitations

- Privacy preservation claims lack rigorous empirical validation through formal privacy attacks or differential privacy analysis
- Convergence proof relies on specific smoothness assumptions that may not hold in practice with non-convex neural network optimization
- Experimental evaluation is constrained by limited dataset diversity and absence of real-world large-scale federated learning deployment scenarios

## Confidence

- **High confidence**: The mechanism for generating preference-specific models through hypernetwork mapping is technically sound and the experimental results showing improved hypervolume scores are reproducible.
- **Medium confidence**: The privacy preservation claims are plausible based on the architectural design, but lack rigorous empirical validation through privacy attacks or differential privacy analysis.
- **Low confidence**: The generalizability of results across diverse federated learning scenarios remains uncertain due to limited dataset diversity and absence of stress tests under extreme data heterogeneity or client dropout conditions.

## Next Checks

1. **Privacy Attack Validation**: Implement gradient-based reconstruction attacks to attempt recovery of preference vectors from hypernetwork parameters and gradients, measuring the success rate and information leakage to empirically validate privacy claims.

2. **Convergence Robustness Testing**: Conduct extensive hyperparameter sensitivity analysis across learning rates, batch sizes, and smooth factor values to identify conditions under which the theoretical convergence guarantees break down in practice.

3. **Scalability Assessment**: Deploy PraFFL in a simulated large-scale federated learning environment with 100+ clients and varying degrees of data heterogeneity to evaluate whether hypervolume performance and convergence properties scale effectively beyond the small-scale experiments presented.