---
ver: rpa2
title: 'FacLens: Transferable Probe for Foreseeing Non-Factuality in Fact-Seeking
  Question Answering of Large Language Models'
arxiv_id: '2406.05328'
source_url: https://arxiv.org/abs/2406.05328
tags:
- faclens
- question
- llms
- hidden
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FacLens, a lightweight model that predicts
  whether a large language model will generate non-factual responses to fact-seeking
  questions before the response is generated. FacLens achieves this by probing hidden
  representations of questions using a lightweight encoder and classifier.
---

# FacLens: Transferable Probe for Foreseeing Non-Factuality in Fact-Seeking Question Answering of Large Language Models

## Quick Facts
- arXiv ID: 2406.05328
- Source URL: https://arxiv.org/abs/2406.05328
- Authors: Yanling Wang; Haoyang Li; Hao Zou; Jing Zhang; Xinlei He; Qi Li; Ke Xu
- Reference count: 40
- Key outcome: Introduces FacLens, a lightweight model that predicts LLM non-factual responses by probing hidden question representations, achieving strong effectiveness and efficiency with cross-LLM transferability through unsupervised domain adaptation.

## Executive Summary
This paper addresses the challenge of non-factuality prediction (NFP) in fact-seeking question answering by introducing FacLens, a lightweight model that probes hidden representations of questions to predict whether an LLM will generate non-factual responses. The key innovation is discovering that hidden question representations from different LLMs exhibit similar NFP patterns, enabling cross-LLM transferability without requiring new labeled data. FacLens uses a lightweight encoder-classifier architecture with MMD loss and question-aligned mini-batches for unsupervised domain adaptation, achieving strong performance across multiple LLMs while being significantly more efficient than baseline methods.

## Method Summary
FacLens is a lightweight model that predicts non-factual responses by probing hidden question representations from LLM middle layers. It consists of a 3-layer MLP encoder that transforms hidden representations into a latent feature space, followed by a linear classifier for binary classification. The model achieves cross-LLM transferability through unsupervised domain adaptation using MMD loss with a novel question-aligned mini-batch strategy, where the same question set is used for both source and target domains in each mini-batch. This approach reduces development costs by enabling the model to work on new LLMs without requiring new labeled data.

## Key Results
- FacLens achieves strong AUC scores (0.85-0.91) on NFP prediction, outperforming baseline methods including PPL, Prompting, Entity-Popularity, SAT Probe, Self-Familiarity, LoRA, and Self-Evaluation.
- The model demonstrates significant efficiency gains with faster training and prediction times compared to baselines, making it practical for real-world deployment.
- FacLens successfully transfers across different LLMs (LLaMA2, LLaMA3, Mistral, Qwen2) without requiring new labeled data, enabled by discovering similar NFP patterns in hidden question representations.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hidden question representations in LLMs contain knowledge-awareness patterns that can predict non-factual responses.
- Mechanism: The model probes hidden states from the LLM's middle layers to extract NFP patterns, then uses a lightweight encoder-classifier to predict factual vs non-factual responses.
- Core assumption: Knowledge awareness about the factual correctness of a question is encoded in the hidden representations during question embedding.
- Evidence anchors: The paper hypothesizes that knowledge awareness has been embedded in hidden representations and validates this through empirical AUC scores on single-LLM training.

### Mechanism 2
- Claim: Similar NFP patterns exist across different LLMs, enabling cross-LLM transferability.
- Mechanism: The model trains on multiple domains (hidden representations from different LLMs) and finds that conditional distributions P(y|X) are similar, allowing domain adaptation without new labels.
- Core assumption: Different LLMs exhibit similar knowledge-awareness patterns when processing the same fact-seeking questions.
- Evidence anchors: Empirical results show FacLens trained on multiple LLMs performs similarly to single-LLM training, suggesting consistent NFP patterns across architectures.

### Mechanism 3
- Claim: Question-aligned mini-batch training improves domain adaptation performance.
- Mechanism: By using the same question set for both source and target domains in each mini-batch, the model reduces sampling variance when estimating distribution distances for MMD loss.
- Core assumption: Sampling variance in mini-batches affects the accuracy of MMD loss estimation when source and target domains use different question sets.
- Evidence anchors: The paper proposes this as a novel contribution to address sampling variance in MMD estimation, though direct ablation studies are not provided.

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD) loss for domain adaptation
  - Why needed here: MMD loss measures the distance between source and target domain distributions in reproducing kernel Hilbert space, enabling the model to find domain-invariant features for cross-LLM transfer
  - Quick check question: How does MMD loss differ from traditional classification loss, and why is it specifically useful for unsupervised domain adaptation?

- Concept: Conditional probability distribution consistency across domains
  - Why needed here: The transferability assumption relies on P(y|X) being similar across different LLMs, even if P(X) differs
  - Quick check question: What would happen to the model's transferability if the conditional distributions P(y|X) were significantly different between LLMs?

- Concept: Hidden state extraction from transformer layers
  - Why needed here: The model relies on extracting meaningful representations from specific transformer layers to probe for knowledge-awareness patterns
  - Quick check question: Why does the paper recommend using middle-layer hidden representations rather than first or last layers?

## Architecture Onboarding

- Component map: Fact-seeking question → LLM hidden states → Encoder (MLP) → Classifier (Linear layer) → Prediction
- Critical path: Question → LLM hidden states → Encoder → Classifier → Prediction
- Design tradeoffs:
  - Using middle layers vs. first/last layers: Middle layers capture more semantic information while avoiding noise from input/output layers
  - Lightweight encoder vs. complex architecture: Trade-off between model capacity and computational efficiency
  - Question-aligned mini-batches: Additional complexity for potentially better domain adaptation performance
- Failure signatures:
  - Poor AUC scores on test sets suggest issues with NFP pattern extraction or domain adaptation
  - High variance in predictions across different LLMs indicates transferability problems
  - Training instability might indicate issues with MMD loss implementation or question alignment strategy
- First 3 experiments:
  1. Verify that hidden question representations contain NFP patterns by training FacLens on a single LLM and measuring AUC
  2. Test cross-LLM transferability by training on one LLM and testing on another without domain adaptation
  3. Validate the question-aligned mini-batch strategy by comparing with random sampling approach using the same MMD loss setup

## Open Questions the Paper Calls Out

- How can FacLens be extended to work effectively with black-box LLMs that do not provide access to hidden representations?
- Can FacLens's transferability across LLMs be improved for models with very different scales or architectures beyond simple linear layer adjustments?
- How does FacLens perform on fact-seeking questions involving periodic or recurring events where LLMs may have limited self-awareness?

## Limitations

- The transferability mechanism relies on consistent knowledge-awareness encoding across LLM architectures, which hasn't been validated across diverse model families beyond similar transformer-based architectures.
- The unsupervised domain adaptation approach assumes target LLM hidden representations are representative, but doesn't address potential distribution shifts from different pretraining data or fine-tuning procedures.
- The question-aligned mini-batch strategy's contribution is not independently validated through ablation studies comparing it against standard MMD loss with random sampling.

## Confidence

- High confidence: The effectiveness of FacLens for single-LLM NFP prediction is well-supported by the AUC scores (0.85-0.91) and efficiency gains compared to baselines.
- Medium confidence: The cross-LLM transferability mechanism shows promise but has limitations, with empirical rather than mechanistic theoretical foundation for why hidden question representations exhibit similar NFP patterns.
- Low confidence: The question-aligned mini-batch strategy's contribution to domain adaptation performance is not independently validated through ablation studies.

## Next Checks

1. **Cross-architecture transferability test**: Evaluate FacLens trained on transformer-based LLMs (LLaMA, Mistral) on non-transformer architectures (e.g., RWKV or Mamba models) to determine if the observed transferability extends beyond similar model families.

2. **Ablation study for domain adaptation components**: Compare FacLens performance using three variants: (a) standard MMD loss with random sampling, (b) MMD loss with question-aligned mini-batches, and (c) no domain adaptation (direct transfer) to quantify the specific contribution of each component.

3. **Distribution analysis of hidden representations**: Conduct t-SNE or UMAP visualization of hidden question representations from different LLMs to empirically verify whether they cluster by factual vs non-factual responses across models, providing visual evidence for the claimed NFP pattern similarity.