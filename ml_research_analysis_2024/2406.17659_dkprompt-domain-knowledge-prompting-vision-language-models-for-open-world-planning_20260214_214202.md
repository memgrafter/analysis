---
ver: rpa2
title: 'DKPROMPT: Domain Knowledge Prompting Vision-Language Models for Open-World
  Planning'
arxiv_id: '2406.17659'
source_url: https://arxiv.org/abs/2406.17659
tags:
- robot
- planning
- action
- object
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DKPROMPT combines classical PDDL planners with vision-language
  models by automatically generating VLM prompts from action preconditions and effects.
  The method uses VLMs to detect action failures and verify affordances during plan
  execution in open-world environments.
---

# DKPROMPT: Domain Knowledge Prompting Vision-Language Models for Open-World Planning

## Quick Facts
- arXiv ID: 2406.17659
- Source URL: https://arxiv.org/abs/2406.17659
- Reference count: 40
- Primary result: 66.5% success rate on five household tasks, outperforming pure VLM planners (2.2%), classical planners (17.1%), and other baselines (35.9%-54.0%)

## Executive Summary
DKPROMPT addresses the challenge of planning in open-world environments by integrating classical PDDL planners with vision-language models (VLMs). The system automatically generates VLM prompts from action preconditions and effects, using VLMs to detect action failures and verify affordances during plan execution. Tested across five household tasks, DKPROMPT demonstrates significantly higher success rates compared to pure VLM planning, pure classical planning, and various hybrid approaches.

## Method Summary
DKPROMPT combines classical PDDL planning with vision-language models by automatically generating prompts from action preconditions and effects. The system uses VLMs to assess whether preconditions are met before executing actions and to detect failures during execution. When failures occur, DKPROMPT re-plans using updated environmental information. The approach leverages the symbolic reasoning capabilities of PDDL planners while using VLMs to handle the uncertainty and variability inherent in open-world environments.

## Key Results
- Achieved 66.5% success rate across five household tasks
- Outperformed pure VLM planners (2.2% success rate)
- Surpassed classical planners (17.1% success rate) and hybrid baselines (35.9%-54.0%)
- Successfully recovered from action failures and re-planned when situations changed

## Why This Works (Mechanism)
The system works by bridging the gap between symbolic planning and perception-based reasoning. Classical PDDL planners provide structured, goal-oriented planning capabilities but struggle with the perceptual uncertainty of open-world environments. VLMs excel at understanding visual scenes but lack systematic planning capabilities. By automatically generating prompts from action preconditions and effects, DKPROMPT enables VLMs to reason about the world state in a planning context, while the PDDL planner provides the logical framework for goal achievement.

## Foundational Learning

**PDDL (Planning Domain Definition Language)**: A standardized language for describing planning problems with objects, predicates, and actions. Why needed: Provides the symbolic framework for representing and solving planning problems. Quick check: Can represent household tasks as structured planning problems with clear goals and action sequences.

**Vision-Language Models (VLMs)**: Neural models that process both visual inputs and natural language. Why needed: Bridge the gap between visual perception and symbolic reasoning. Quick check: Can understand and reason about real-world scenes in natural language terms.

**Affordance Verification**: The process of determining whether an object can support a particular action. Why needed: Essential for validating whether actions can be executed in the current environment. Quick check: Can detect if a cup is graspable or if a drawer can be opened.

## Architecture Onboarding

**Component Map**: Environment Perception -> VLM Prompt Generation -> Action Verification -> PDDL Planning -> Execution -> Feedback Loop

**Critical Path**: The system continuously monitors the environment, generates prompts based on current action preconditions, uses VLMs to verify affordances, executes actions when conditions are met, and re-plans when failures occur.

**Design Tradeoffs**: 
- High accuracy in visual reasoning comes at the cost of increased latency from VLM queries
- Complex precondition and effect specifications improve accuracy but require more sophisticated prompt engineering
- Pure VLM approaches are faster but less reliable; pure classical approaches are more structured but less adaptable

**Failure Signatures**:
- VLM misinterpretation of visual scenes leading to incorrect affordance verification
- PDDL planner generating infeasible plans due to incomplete domain knowledge
- Action execution failures not properly detected by VLM-based monitoring

**Three First Experiments**:
1. Test DKPROMPT on a new household task not included in the original evaluation
2. Systematically vary the specificity of preconditions and effects in the domain model
3. Evaluate performance under simulated VLM failures or degraded visual inputs

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- 66.5% success rate indicates significant room for improvement, particularly for more complex tasks
- Evaluation limited to five specific household tasks in controlled environments
- Performance may degrade in truly open-world scenarios with greater variability
- Reliance on VLMs introduces uncertainty about robustness to model failures or ambiguous inputs

## Confidence

**High**: Comparative performance improvements over baselines are well-documented and statistically significant.

**Medium**: Methodology for prompt generation and VLM integration appears sound, but effectiveness may vary with different VLM architectures.

**Medium**: Claim about importance of combining preconditions and effects is supported by ablation studies but needs broader validation.

## Next Checks

1. Test DKPROMPT on a broader range of household tasks with varying complexity and environmental conditions to assess generalizability

2. Conduct systematic ablation studies varying the types and specificity of preconditions and effects to quantify their individual contributions

3. Evaluate system performance under VLM model failures or degraded visual inputs to assess robustness in less ideal conditions