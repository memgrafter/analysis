---
ver: rpa2
title: 'ConPro: Learning Severity Representation for Medical Images using Contrastive
  Learning and Preference Optimization'
arxiv_id: '2404.18831'
source_url: https://arxiv.org/abs/2404.18831
tags:
- severity
- learning
- contrastive
- preference
- maee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of learning severity representations
  for medical images using a novel framework that combines contrastive learning with
  preference optimization. The method, called ConPrO, incorporates severity information
  into the latent space by first performing binary contrastive learning between normal
  and abnormal classes, followed by preference optimization to rearrange the relative
  distances of severity levels within abnormal classes.
---

# ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization

## Quick Facts
- **arXiv ID**: 2404.18831
- **Source URL**: https://arxiv.org/abs/2404.18831
- **Reference count**: 40
- **Primary result**: ConPrO framework achieves 6% and 20% relative improvement in F1 score compared to supervised and self-supervised baselines on medical imaging datasets

## Executive Summary
This paper introduces ConPrO, a novel framework for learning severity representations in medical images by combining contrastive learning with preference optimization. The method addresses the challenge of severity assessment in medical imaging by first separating normal and abnormal classes through contrastive learning, then refining the representation using preference optimization to capture ordinal severity relationships. Experiments on two medical imaging datasets demonstrate significant performance improvements over existing methods, while also providing interpretable representations that can explain severity predictions.

## Method Summary
ConPrO is a two-phase approach that learns severity representations in medical images. The first phase (Con) uses binary contrastive learning to create separation between normal and abnormal classes in latent space. The second phase (PrO) applies preference optimization using the Bradley-Terry model to rearrange the relative distances of severity levels within abnormal classes, based on their ordinal relationships. The framework uses cosine distance between severity vectors and normality anchors as the reward function for preference optimization. Experiments were conducted on two medical imaging datasets: Papilledema (pediatric fundus images with 5-level severity) and VinDr-Mammogram (mammography examinations with BI-RADS severity assessment).

## Key Results
- ConPrO achieves 6% relative improvement in F1 score compared to supervised baselines on medical imaging datasets
- The framework shows 20% relative improvement over self-supervised baselines in F1 score
- Using multiple normality reference vectors reduces Mean Absolute Exponential Error (MAEE) while slightly improving classification performance

## Why This Works (Mechanism)

### Mechanism 1
The two-stage training approach (binary contrastive learning + preference optimization) creates severity-aware representations by first establishing clear separation between normal and abnormal classes, then refining the ordinal relationships within abnormal classes. The Con step creates a meaningful normality anchor that the PrO step uses to inject severity ordering information through preference comparisons.

### Mechanism 2
The Bradley-Terry model converts pairwise severity comparisons into likelihood probabilities, creating a monotonic relationship between severity and distance from normality. This transforms the ordinal severity prediction problem into a preference ranking problem where higher severity is preferred to be further from normality.

### Mechanism 3
Using multiple normality reference vectors provides a more stable anchor point for preference optimization, reducing the effect of individual vector variations during model updates. This improves the consistency of severity estimation across different training iterations.

## Foundational Learning

- **Concept**: Contrastive learning fundamentals
  - Why needed here: The Con step relies on standard contrastive learning principles to create initial separation between normal and abnormal classes
  - Quick check question: What is the difference between positive and negative pairs in contrastive learning?

- **Concept**: Preference optimization and ranking models
  - Why needed here: The PrO step uses preference optimization (specifically Bradley-Terry model) to rearrange severity levels
  - Quick check question: How does the Bradley-Terry model convert pairwise comparisons into probabilities?

- **Concept**: Cosine distance as reward function
  - Why needed here: The framework uses cosine distance between severity vectors and normality anchor as the reward function for preference optimization
  - Quick check question: Why might cosine distance be preferred over Euclidean distance in high-dimensional latent spaces?

## Architecture Onboarding

- **Component map**: Image → Feature extractor → Projection head g(·) (256-d FC) → Contrastive space; Feature extractor → Projection head h(·) (same dim as normality) → Preference space; Normal cluster vectors → Normality anchor; Pairwise preference data → Bradley-Terry probability calculation

- **Critical path**: Image → Feature extractor → Projection head → Contrastive loss OR Preference loss → Updated parameters. Both Con and PrO steps share the feature extractor and projection heads. The normality anchor is computed once per training iteration.

- **Design tradeoffs**: Single vs. multiple normality references (more references reduce MAEE but may slightly reduce F1); Margin size in contrastive loss (affects separation strength); Preference pair selection (random selection may miss important ordinal relationships)

- **Failure signatures**: High MAEE with decent F1 (model correctly classifies severity but misorders within levels); Low MAEE with poor F1 (model orders correctly but misclassifies overall); Normal and abnormal clusters overlap significantly (Con step not working effectively)

- **First 3 experiments**: 1) Train only Con step and visualize T-SNE to verify normal/abnormal separation; 2) Train only PrO step with fixed normality anchor and compare MAEE to full ConPrO; 3) Vary number of normality reference vectors (1, 10, 20) and measure MAEE/F1 tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
How do different choices of normality anchors (mean, median, or weighted combinations of normal vectors) affect severity representation quality and MAEE performance? The paper only explores mean-based anchors and doesn't compare alternative anchoring strategies or their theoretical implications.

### Open Question 2
What specific visual attributes or features does the latent space learn to distinguish between different severity levels, and how do these align with expert clinical interpretations? The paper focuses on performance metrics but doesn't provide interpretability analysis of what features drive severity discrimination in learned representations.

### Open Question 3
How does the proposed ConPrO framework perform when extended to multi-pathology scenarios where images contain multiple conditions with potentially conflicting severity indicators? The experiments focus on single pathology datasets, and the paper doesn't investigate how the framework handles conflicting severity information from multiple conditions.

## Limitations

- Limited ablation studies make it difficult to isolate the contribution of each component of the framework
- The specific implementation details of preference optimization phase and exact data preprocessing steps are not fully specified
- Choice of cosine distance over other metrics for severity representation lacks thorough justification
- Claim about robustness to architecture choice is based on experiments with only two architectures (ResNet-50 and ViT)

## Confidence

- **High Confidence**: Core claim that ConPrO outperforms supervised and self-supervised baselines on the two medical imaging datasets (F1 improvements of 6% and 20%)
- **Medium Confidence**: Mechanism claims about how binary contrastive learning followed by preference optimization creates severity-aware representations
- **Medium Confidence**: Claim about MAEE improvement with multiple normality reference vectors

## Next Checks

1. Conduct ablation studies varying the number of normality reference vectors beyond what was tested (1, 10, 20) to establish the optimal range and determine if MAEE improvement plateaus
2. Test the framework on a third medical imaging dataset with different characteristics (e.g., different imaging modality or severity scale) to validate generalizability claims
3. Implement and compare alternative distance metrics (Euclidean, Mahalanobis) in the preference optimization phase to quantify the advantage of cosine distance for severity representation