---
ver: rpa2
title: Subspace Optimization for Large Language Models with Convergence Guarantees
arxiv_id: '2410.11289'
source_url: https://arxiv.org/abs/2410.11289
tags:
- galore
- gradient
- subspace
- convergence
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates subspace optimization for large language
  model (LLM) training, focusing on algorithms like GaLore that project gradients
  into low-rank subspaces for memory efficiency. The authors reveal that GaLore lacks
  convergence guarantees under standard assumptions due to its biased SVD-based projection,
  which can capture noise rather than true gradients near local minima.
---

# Subspace Optimization for Large Language Models with Convergence Guarantees

## Quick Facts
- arXiv ID: 2410.11289
- Source URL: https://arxiv.org/abs/2410.11289
- Authors: Yutong He; Pengrui Li; Yipeng Hu; Chuyan Chen; Kun Yuan
- Reference count: 40
- Key outcome: Reveals GaLore lacks convergence guarantees due to SVD-based projection bias toward noise, proposes GoLore with random projections that provably converges even with standard batch sizes

## Executive Summary
This paper addresses the convergence issues in GaLore, a memory-efficient subspace optimization algorithm for LLM training that projects gradients into low-rank subspaces. The authors demonstrate that GaLore fails to converge under standard stochastic optimization assumptions because its SVD-based projection becomes biased toward noise rather than true gradients when approaching local minima. To resolve this, they propose GoLore, which uses random projections instead of SVD, ensuring convergence with standard batch sizes and anisotropic noise. The paper provides theoretical analysis proving GoLore achieves O(1/√T) convergence and validates the approach through experiments on LLM pre-training and fine-tuning tasks.

## Method Summary
The paper investigates subspace optimization methods for LLM training, focusing on GaLore and GoLore algorithms. GaLore uses SVD to project gradients onto low-rank subspaces but suffers from convergence issues due to biased projections. GoLore replaces SVD with random projections sampled uniformly from the Stiefel manifold, ensuring unbiased gradient information capture. Both methods periodically recompute projection matrices and use momentum projection mechanisms to handle subspace changes. The authors provide theoretical convergence analysis and validate their approach through experiments on pre-training LLaMA-60M and fine-tuning LLaMA2-7B on various datasets, demonstrating that alternating between GaLore and GoLore improves performance.

## Key Results
- GaLore lacks convergence guarantees under standard stochastic optimization assumptions due to SVD-based projection bias toward noise
- GoLore provably converges under standard assumptions with O(1/√T) rate, even with standard batch sizes and anisotropic noise
- Alternating GaLore and GoLore across training phases improves performance in LLM pre-training and fine-tuning tasks
- Theoretical analysis shows GaLore converges only under restrictive conditions: noise-free settings, large-batch settings, or isotropic noise assumptions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GaLore fails to converge under standard assumptions because SVD-based projections become biased toward noise when true gradients are small near local minima.
- Mechanism: SVD greedily captures dominant components in the stochastic gradient matrix. When true gradients approach zero (near local minima) but gradient noise remains, the SVD-identified subspace is dominated by noise rather than true gradient information, causing the algorithm to diverge.
- Core assumption: The stochastic gradient consists of a true gradient component plus noise; the bias arises when the true gradient component becomes negligible compared to the noise.
- Evidence anchors:
  - [abstract] "GaLore lacks convergence guarantees under standard assumptions due to its biased SVD-based projection, which can capture noise rather than true gradients near local minima."
  - [section] "When the true gradient significantly exceeds the gradient noise, typically at the start of training... As training progresses and the true gradient diminishes to zero, especially near a local minimum... the subspace may become increasingly influenced by gradient noise."
  - [corpus] Weak - no direct corpus evidence found; this is inferred from the paper's analysis.
- Break condition: If gradient noise is isotropic or if batch size is large enough to suppress noise, the SVD projection remains aligned with the true gradient direction.

### Mechanism 2
- Claim: GoLore achieves convergence by using random projections that avoid bias toward dominant noise components.
- Mechanism: Instead of SVD, GoLore samples projection matrices uniformly from the Stiefel manifold. Random projections capture gradient information without preference for dominant components, ensuring the subspace remains useful even when noise dominates the true gradient.
- Core assumption: Random projections from the uniform Stiefel manifold distribution are unbiased estimators of the gradient subspace.
- Evidence anchors:
  - [abstract] "GoLore (Gradient random Low-rank projection), a novel variant of GaLore that provably converges in typical stochastic settings, even with standard batch sizes."
  - [section] "we propose modifying the SVD projection to a Gradient Random Low-Rank projection, resulting in the GoLore algorithm. This random projection can effectively capture gradient information even when gradient noise predominates."
  - [corpus] Weak - no direct corpus evidence found; this is derived from the paper's theoretical framework.
- Break condition: If the random projection happens to align poorly with the true gradient direction (low probability event), convergence may be slower but not prevented.

### Mechanism 3
- Claim: GaLore can converge under specific conditions: noise-free settings, large-batch settings, or isotropic noise assumptions.
- Mechanism: These conditions ensure that either gradient noise is eliminated or is distributed evenly across all directions, preventing the SVD projection from becoming dominated by directional noise.
- Core assumption: The convergence of SVD-based projection depends on the relative magnitude and distribution of true gradient versus noise.
- Evidence anchors:
  - [abstract] "We further explore the conditions under which GaLore achieves convergence, showing that it does so when either (i) a sufficiently large mini-batch size is used or (ii) the gradient noise is isotropic."
  - [section] "When the true gradient significantly exceeds the gradient noise, typically at the start of training... the low-rank subspace obtained via SVD effectively preserves the true gradient information."
  - [corpus] Weak - no direct corpus evidence found; this is stated in the paper's theoretical analysis.
- Break condition: If noise is anisotropic and batch size is small, these conditions fail and GaLore does not converge.

## Foundational Learning

- Concept: Singular Value Decomposition (SVD) and its greedy nature in capturing dominant components
  - Why needed here: Understanding SVD is crucial because GaLore's convergence failure stems from SVD's tendency to capture noise when true gradients are small.
  - Quick check question: What happens to an SVD-based projection when the true gradient approaches zero but noise remains constant?

- Concept: Stiefel manifold and uniform random sampling from it
  - Why needed here: GoLore's convergence relies on sampling projection matrices from the uniform distribution on the Stiefel manifold, which provides unbiased subspace representations.
  - Quick check question: How does sampling from U(Stm,r) differ from using SVD in terms of bias toward gradient components?

- Concept: Convergence analysis for stochastic optimization with compressed gradients
  - Why needed here: The paper establishes convergence rates for GoLore under standard assumptions, which requires understanding how compression affects convergence guarantees.
  - Quick check question: Why can't traditional unbiased compression analysis be applied to GaLore's periodically recomputed subspaces?

## Architecture Onboarding

- Component map:
  Gradient computation -> Subspace projection (SVD or random sampling) -> Optimizer states storage -> Momentum projection (MP) -> Periodic subspace updates

- Critical path:
  1. Compute full-parameter gradient G
  2. If t ≡ 0 (mod τ), compute new projection matrix P (SVD for GaLore, random sampling for GoLore)
  3. Project gradient into subspace: P⊤G or S⊙G
  4. Apply optimizer (Adam/MSGD) to projected gradient
  5. Update parameters using compressed optimizer states
  6. When subspace changes, project momentum states appropriately

- Design tradeoffs:
  - Memory vs. convergence: Lower rank r reduces memory but may harm convergence; GoLore allows smaller r while maintaining convergence
  - Computational cost: SVD is expensive; random sampling is cheap but may require more frequent updates
  - Implementation complexity: Momentum projection adds complexity but is necessary for convergence guarantees

- Failure signatures:
  - GaLore: Loss curve plateaus or diverges near local minima despite decreasing true gradient magnitude
  - GoLore: Slower initial convergence but stable approach to stationary points
  - Large-batch GaLore: High memory usage due to accumulated gradients, potential gradient accumulation complexity

- First 3 experiments:
  1. Verify non-convergence: Run GaLore on the counter-example problem (1) from the paper and observe failure to converge
  2. Test GoLore switching: Implement hybrid approach switching from GaLore to GoLore at different ratios and measure impact on final performance
  3. Validate random projection: Compare GoLore's random projections against importance sampling variants to confirm superior performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does GoLore's random projection strategy maintain the same level of performance as GaLore in the early stages of training when gradient noise is minimal?
- Basis in paper: [explicit] The paper states "the advantage of using randomly sampled projection matrices becomes evident in the later stages of training, where stochastic gradients are primarily dominated by gradient noise. However, in the early stages, projection matrices derived from GaLore's SVD retain more gradient information, leading to more effective subspaces."
- Why unresolved: The paper proposes a hybrid approach using GaLore in early stages and GoLore in later stages, but does not directly compare GoLore's performance against GaLore throughout the entire training process when used alone.
- What evidence would resolve it: Empirical comparison of training curves showing perplexity or loss metrics for pure GoLore versus pure GaLore across all training stages on multiple LLM pre-training tasks.

### Open Question 2
- Question: Can the theoretical convergence guarantees for GoLore be extended to include the Adam optimizer, which is commonly used in practice for LLM training?
- Basis in paper: [inferred] The paper mentions "A limitation of this paper is that our convergence analysis framework has not readily covered the use of the Adam optimizer and recent GaLore variants such as Fira."
- Why unresolved: The current theoretical analysis focuses on MSGD, while Adam is the standard optimizer in LLM training, creating a gap between theory and practice.
- What evidence would resolve it: Mathematical proof extending the convergence rate bounds from MSGD to Adam, showing similar O(1/√T) convergence under standard assumptions.

### Open Question 3
- Question: How does GoLore's performance scale with increasingly large model sizes, particularly for frontier-scale LLMs (e.g., 70B+ parameters)?
- Basis in paper: [explicit] The paper validates GoLore on models up to OPT-13B and LLaMA2-7B, but states "we recommend a hybrid approach: initially using GaLore to converge toward the neighborhood of the solution, then switching to GoLore for refinement."
- Why unresolved: The experiments focus on relatively small-scale models, and the paper does not address whether the theoretical advantages of GoLore remain consistent at frontier scales.
- What evidence would resolve it: Pre-training or fine-tuning experiments on 70B+ parameter models comparing GoLore, GaLore, and full-parameter training in terms of memory efficiency, convergence speed, and final performance metrics.

### Open Question 4
- Question: Can the convergence analysis framework be extended to handle the more complex error feedback techniques used in recent GaLore variants like LDAdam?
- Basis in paper: [explicit] The paper states "A limitation of this paper is that our convergence analysis framework has not readily covered the use of the Adam optimizer and recent GaLore variants such as Fira."
- Why unresolved: The paper's analysis focuses on basic GaLore and GoLore implementations, but modern variants incorporate sophisticated error feedback mechanisms that are not covered by the theoretical framework.
- What evidence would resolve it: Mathematical extension of the convergence proof to include error feedback mechanisms, demonstrating that these variants maintain the O(1/√T) convergence rate under standard assumptions.

## Limitations
- The paper's theoretical claims about GoLore's convergence are supported primarily by custom quadratic counterexamples and controlled experiments, with limited validation on real-world LLM training tasks.
- The connection between the simplified quadratic problem and actual LLM optimization landscapes remains unclear.
- The paper doesn't address computational overhead differences between SVD and random projections, nor does it provide extensive ablation studies on rank selection sensitivity.

## Confidence
- **High Confidence**: The core finding that GaLore lacks convergence guarantees under standard stochastic optimization assumptions is well-supported by the provided counterexample and theoretical analysis.
- **Medium Confidence**: The claim that GoLore provably converges under standard assumptions is supported by theoretical analysis, but the practical significance and gap between theory and practice for real LLMs remains unclear without more extensive empirical validation.
- **Low Confidence**: The empirical claim that alternating GaLore and GoLore improves performance is based on limited experiments and lacks systematic ablation studies to understand when and why this hybrid approach helps.

## Next Checks
1. **Extended Empirical Validation**: Run GoLore and the hybrid approach across multiple LLM architectures (beyond LLaMA-60M and LLaMA2-7B) and diverse tasks to verify that the theoretical convergence guarantees translate to practical performance improvements.
2. **Rank Sensitivity Analysis**: Systematically vary the rank parameter r in GoLore and measure the trade-off between memory savings and convergence speed/distance to stationary points to identify optimal rank selection strategies.
3. **Computational Overhead Benchmarking**: Measure wall-clock time and memory usage differences between SVD-based GaLore and random projection GoLore across different batch sizes and model scales to quantify the practical benefits beyond just convergence guarantees.