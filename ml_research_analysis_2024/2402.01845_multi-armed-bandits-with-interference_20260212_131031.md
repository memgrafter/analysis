---
ver: rpa2
title: Multi-Armed Bandits with Interference
arxiv_id: '2402.01845'
source_url: https://arxiv.org/abs/2402.01845
tags:
- regret
- each
- policy
- interference
- reward
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies multi-armed bandits with interference (MABI),
  where rewards depend on the treatments of all units in a spatial setting with decaying
  influence. The authors show that switchback policies achieve optimal expected regret
  $O(\sqrt{T})$, but have high variance that doesn't benefit from larger market size
  $N$.
---

# Multi-Armed Bandits with Interference

## Quick Facts
- arXiv ID: 2402.01845
- Source URL: https://arxiv.org/abs/2402.01845
- Authors: Su Jia; Peter Frazier; Nathan Kallus
- Reference count: 15
- Primary result: Cluster randomization with robust randomized partition achieves optimal expected regret and high-probability bounds that vanish as N → ∞

## Executive Summary
This paper studies multi-armed bandits with interference (MABI), where rewards depend on treatments of all units in a spatial setting with decaying influence. The authors show that while switchback policies achieve optimal expected regret O(√T), they have high variance that doesn't benefit from larger market size N. They propose a cluster randomization policy using a novel robust randomized partition that reduces variance by ensuring each unit has constant exposure probability. This policy achieves optimal expected regret and a high-probability regret bound that vanishes as N → ∞, addressing the high variance issue of switchback policies.

## Method Summary
The method introduces a cluster randomization policy with robust randomized partition (RRP) that adds randomness to cluster boundaries, increasing minimum exposure probability from p^O(1) to Ω(p). The policy uses an EXP3-HT-IX algorithm that combines clustered randomization with implicit exploration (IX) parameter and Horvitz-Thompson estimation. The RRP ensures that no arm has vanishingly small probability of being assigned to any unit, which prevents high variance in the estimator. The algorithm achieves optimal expected regret O(√T) while also providing high-probability regret bounds that improve with larger N.

## Key Results
- Switchback policies achieve optimal expected regret O(√T) but have high variance that doesn't benefit from larger N
- Robust Randomized Partition (RRP) increases minimum exposure probability from p^O(1) to Ω(p), reducing variance
- Cluster randomization policy achieves optimal expected regret O(√T) and high-probability regret bounds that vanish as N → ∞
- The HT-IX estimator combines implicit exploration with Horvitz-Thompson estimation to achieve high-probability bounds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Switchback policies achieve optimal expected regret O(√T) by treating all units as a single aggregated entity
- Mechanism: When all units are assigned the same arm simultaneously, the MABI problem reduces to standard adversarial bandits, ignoring spatial structure and unit count
- Core assumption: All units can be treated as a single unit without loss of optimality for expected regret
- Evidence anchors:
  - [abstract]: "switchback policies achieve optimal expected regret O(√T)"
  - [section]: "any adversarial bandits policy can be converted into a switchback policy for the MABI problem, and this conversion preserves the regret"
- Break condition: When variance reduction from leveraging spatial structure becomes critical, or when high-probability bounds are needed

### Mechanism 2
- Claim: Robust Randomized Partition (RRP) reduces variance by ensuring constant exposure probability for all units
- Mechanism: RRP introduces randomness into cluster boundaries, increasing minimum exposure probability from p^O(1) to Ω(p), preventing pathological low-probability assignments
- Core assumption: Randomizing cluster boundaries improves statistical performance by preventing some arms from having vanishingly small probabilities
- Evidence anchors:
  - [section]: "The key idea is to 'perturb' the cluster boundaries randomly. This increases the minimum exposure probability from p^O(1) to Ω(p)"
  - [section]: "Crucially, when Pta is small, the exposure probability under our RRP is Ω(Pta), which is much greater than the exposure probability (Pta)^4 under the uniform design"
- Break condition: When randomization introduces too much noise relative to signal, or when cluster structure doesn't match underlying spatial interference

### Mechanism 3
- Claim: HT-IX estimator combines implicit exploration with Horvitz-Thompson estimation to achieve high-probability bounds
- Mechanism: The estimator adds an implicit exploration parameter β to propensity weights, truncating extreme values and reducing variance to achieve high-probability regret bounds
- Core assumption: Adding IX parameter to Horvitz-Thompson estimator preserves unbiasedness while reducing variance enough for high-probability bounds
- Evidence anchors:
  - [abstract]: "We propose a cluster randomization policy whose regret (i) is optimal in expectation and (ii) admits a high probability bound that vanishes in N"
  - [section]: "incorporating an additional IX parameter into the propensity weight results in a favorable high-probability regret bound"
- Break condition: When IX parameter is poorly chosen, leading to excessive bias that overwhelms variance reduction

## Foundational Learning

- Concept: Multi-armed bandit theory (adversarial setting)
  - Why needed here: The paper builds on adversarial bandit algorithms like EXP3, requiring understanding of regret bounds, weight updates, and importance-weighted estimators
  - Quick check question: What is the difference between stochastic and adversarial multi-armed bandits, and why does this paper use the adversarial setting?

- Concept: Causal inference with interference
  - Why needed here: The problem formulation and solutions rely on concepts from causal inference, particularly SUTVA and exposure mappings
  - Quick check question: How does the decaying interference property differ from standard network interference models?

- Concept: Concentration inequalities (Chernoff, Bernstein)
  - Why needed here: The high-probability bounds rely on concentration inequalities to bound deviation of estimators from expected values
  - Quick check question: When would you use Chernoff bounds versus Bernstein bounds for concentration inequalities?

## Architecture Onboarding

- Component map: Policy framework (EXP3-HT-IX) -> Clustering mechanism (RRP) -> Estimation component (HT-IX estimator) -> Weight update system (Multiplicative weights)

- Critical path: 
  1. Generate RRP clustering
  2. Assign arms to clusters based on current weights
  3. Collect rewards from all units
  4. Compute HT-IX estimates for each arm
  5. Update arm weights using multiplicative weights update
  6. Repeat for T rounds

- Design tradeoffs:
  - Switchback vs. clustered randomization: Switchback achieves optimal expected regret but has high variance; clustered randomization reduces variance at cost of more complex implementation
  - Cluster size (ℓ) vs. exposure radius (r): Larger clusters reduce variance but may increase bias; smaller exposure radius increases variance but reduces bias
  - IX parameter (β) tuning: Larger β reduces variance but increases bias; smaller β has opposite effect

- Failure signatures:
  - High regret despite theoretical guarantees: Check if parameters η, β, ℓ, r are properly tuned for specific problem instance
  - Unstable weight updates: Verify HT-IX estimator provides reasonable estimates; check for numerical instability in weight calculations
  - Poor performance on small N: High-probability bounds rely on large N; switchback policies may perform better for small N

- First 3 experiments:
  1. Implement basic EXP3-HT-IX with fixed clustering (no RRP) on simple 2D grid with known interference structure to verify core algorithm works
  2. Add RRP to implementation and compare variance reduction against fixed clustering on same problem instance
  3. Test full system with varying N (small, medium, large) to observe transition from switchback-like behavior to clustered randomization benefits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the high-probability regret bounds be further improved beyond current O(√kT) for switchback policies in MABI settings?
- Basis in paper: The paper shows switchback policies achieve O(√T) expected regret but have high variance that doesn't benefit from larger N, and asks if we can improve beyond this bound
- Why unresolved: The paper establishes this as limitation of switchback policies and shows their proposed cluster randomization policy achieves better high-probability bounds, but doesn't prove whether switchback policies can be improved further
- What evidence would resolve it: A proof showing whether switchback policies can or cannot achieve O(√kT/N^c) high-probability regret bounds for some c>0 would resolve this

### Open Question 2
- Question: How does performance of robust randomized partition (RRP) compare to other clustering methods like randomized graph clustered randomization (RGCR) in practice?
- Basis in paper: The paper mentions their approach differs fundamentally from RGCR and claims RRP has better robustness properties, but doesn't provide empirical comparisons
- Why unresolved: While paper provides theoretical justification for RRP, it only includes limited experiments comparing to switchback policies, not other clustering methods
- What evidence would resolve it: Comprehensive experiments comparing RRP to RGCR and other clustering methods across various MABI settings would resolve this

### Open Question 3
- Question: Can HT-IX estimator be extended to handle time-varying exposure mappings or more general interference structures?
- Basis in paper: Current HT-IX estimator assumes fixed radius-r exposure mappings and decaying interference, but paper notes this is limitation compared to network interference models
- Why unresolved: Paper only considers fixed spatial interference structures and doesn't explore extensions to more general interference models
- What evidence would resolve it: Theoretical analysis showing how HT-IX estimator would need to be modified for time-varying exposure mappings or alternative interference structures would resolve this

## Limitations
- Computational complexity of robust randomized partition (RRP) algorithm may not scale well to very large N
- Assumption of decaying spatial interference may not hold in all real-world applications, particularly those with non-local or network-based interference patterns
- Limited empirical validation on large-scale problems; theoretical guarantees may not fully capture practical performance

## Confidence

High confidence in the theoretical regret bounds (expected regret O(√T) and high-probability bounds vanishing as N → ∞). Medium confidence in the practical benefits of the RRP over simpler clustering approaches, as the empirical validation is limited to small-scale experiments. Low confidence in the algorithm's performance under non-spatial interference patterns or when the decaying assumption is violated.

## Next Checks

1. **Scalability validation**: Implement and test the RRP algorithm on problems with N = 10,000+ units to assess computational feasibility and verify that the theoretical guarantees hold at scale

2. **Non-spatial interference**: Modify the experiment framework to test the algorithm on network-based interference patterns rather than spatial decay, comparing performance against the theoretical predictions

3. **Parameter sensitivity analysis**: Systematically vary the IX parameter β, cluster size ℓ, and exposure radius r across multiple problem instances to identify optimal parameter ranges and verify the claimed robustness properties