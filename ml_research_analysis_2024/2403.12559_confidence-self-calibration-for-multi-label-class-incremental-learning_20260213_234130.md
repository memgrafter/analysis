---
ver: rpa2
title: Confidence Self-Calibration for Multi-Label Class-Incremental Learning
arxiv_id: '2403.12559'
source_url: https://arxiv.org/abs/2403.12559
tags:
- label
- learning
- multi-label
- class-incremental
- confidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of over-confident multi-label
  predictions in Multi-Label Class-Incremental Learning (MLCIL), which arises due
  to the partial label challenge where only new classes are labeled during training.
  The proposed Confidence Self-Calibration (CSC) approach consists of two main components:
  a Class-Incremental Graph Convolutional Network (CI-GCN) for label relationship
  calibration and a max-entropy regularization for confidence calibration.'
---

# Confidence Self-Calibration for Multi-Label Class-Incremental Learning

## Quick Facts
- arXiv ID: 2403.12559
- Source URL: https://arxiv.org/abs/2403.12559
- Authors: Kaile Du; Yifan Zhou; Fan Lyu; Yuyang Li; Chen Lu; Guangcan Liu
- Reference count: 40
- Primary result: New SOTA results on MS-COCO and PASCAL VOC datasets for MLCIL with improved mAP, CF1, and OF1 metrics

## Executive Summary
This paper addresses the over-confident multi-label predictions that arise in Multi-Label Class-Incremental Learning (MLCIL) due to partial label constraints. The proposed Confidence Self-Calibration (CSC) approach combines a Class-Incremental Graph Convolutional Network (CI-GCN) for label relationship calibration with max-entropy regularization for confidence calibration. The CI-GCN dynamically learns cross-task label relationships without requiring prior co-occurrence statistics, while the max-entropy regularization reduces false-positive errors by penalizing over-confident output distributions.

## Method Summary
The CSC framework addresses MLCIL by tackling two core challenges: label relationship calibration and confidence calibration. The CI-GCN uses a stacked architecture with general and specific GCN layers to learn cross-task label relationships dynamically through gradient updates. The general GCN captures global label dependencies across tasks using a shared label relationship graph, while the specific GCN generates image-dependent relationships. Max-entropy regularization is applied to old class predictions to penalize over-confidence and reduce false-positive errors. The method is evaluated on MS-COCO and PASCAL VOC datasets using lexicographical class ordering for incremental tasks.

## Key Results
- CSC achieves new state-of-the-art performance on MS-COCO and PASCAL VOC datasets for MLCIL
- Significant improvements in mAP, CF1, and OF1 metrics compared to existing methods
- The CI-GCN effectively bridges isolated label spaces without requiring prior co-occurrence statistics
- Max-entropy regularization successfully reduces false-positive errors while maintaining overall accuracy

## Why This Works (Mechanism)

### Mechanism 1
CI-GCN enables cross-task label relationship learning under partial label constraints by dynamically expanding and updating the label relationship graph through gradient descent using both current task labels and pseudo-labels from previous model outputs. This creates a learnable, continuously updated graph that bridges disjoint label spaces.

### Mechanism 2
Max-entropy regularization reduces false-positive errors by penalizing over-confident output distributions. The entropy of the output distribution over old classes is computed and negated as a regularization term, forcing the model to produce less confident predictions.

### Mechanism 3
The combination of general and specific GCN layers captures both cross-task and sample-specific label relationships. The general GCN learns global label dependencies across all tasks using a shared CM, while the specific GCN generates image-dependent relationships, providing complementary relationship modeling.

## Foundational Learning

- Concept: Graph Convolutional Networks
  - Why needed here: GCNs provide a principled way to model label relationships and propagate information between related labels, essential for multi-label classification and incremental learning
  - Quick check question: How does a graph convolution operation differ from a standard convolution operation?

- Concept: Catastrophic Forgetting
  - Why needed here: Understanding catastrophic forgetting is crucial because the proposed method aims to mitigate this problem in the context of multi-label class-incremental learning
  - Quick check question: What are the two main approaches to mitigating catastrophic forgetting in class-incremental learning?

- Concept: Entropy as Uncertainty Measure
  - Why needed here: Entropy is used as a metric to quantify the uncertainty of the model's predictions, which is then used to regularize over-confident outputs
  - Quick check question: How does entropy relate to the concept of uncertainty in probability distributions?

## Architecture Onboarding

- Component map: Backbone (TResNetM) -> CAM -> CI-GCN (general + specific GCN layers) -> Classifier -> Loss Function (with max-entropy regularization)
- Critical path: Backbone → CAM → CI-GCN → Classifier → Loss Function (with max-entropy regularization)
- Design tradeoffs:
  - Using pseudo-labels vs. storing exemplars: Pseudo-labels avoid the need for a replay buffer but may introduce noise
  - General vs. specific GCN: General GCN provides cross-task knowledge but may be less precise, while specific GCN is sample-specific but may overfit
  - Entropy regularization strength: Too weak may not reduce false-positives enough, too strong may suppress correct predictions
- Failure signatures:
  - Performance degradation on old classes indicates catastrophic forgetting
  - High false-positive rates indicate over-confident predictions
  - Inconsistent results across different incremental tasks indicate instability in the CI-GCN
- First 3 experiments:
  1. Train the model on a single task and evaluate mAP, CF1, and OF1 to establish baseline performance
  2. Add the CI-GCN component and compare performance to baseline to verify the benefit of label relationship calibration
  3. Add the max-entropy regularization and compare performance to previous experiment to verify the benefit of confidence calibration

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed max-entropy regularization perform under varying degrees of label imbalance within tasks? The paper mentions the impact of the long-tail distribution in multi-label datasets but does not specifically test max-entropy under varying levels of class imbalance.

### Open Question 2
What is the impact of different graph neural network architectures on the performance of CI-GCN? The paper uses a stacked structure with one layer of general GCN and one layer of specific GCN, but does not explore the impact of varying the depth or type of GCN layers.

### Open Question 3
How does the performance of CSC scale with the number of incremental tasks in long-term continual learning scenarios? The paper evaluates performance on scenarios with up to 10 incremental tasks but does not explore the scalability of CSC in scenarios with significantly more tasks.

## Limitations

- The exact implementation details of CI-GCN layers, especially how specific CM is adaptively estimated from input graph nodes, are not fully specified
- The method relies on pseudo-labels from previous model outputs, which may degrade in quality as catastrophic forgetting accumulates
- Comprehensive sensitivity analysis for key hyperparameters, particularly regularization strength, is not provided

## Confidence

- High Confidence Claims: Problem formulation, overall framework architecture, performance improvements on standard benchmarks
- Medium Confidence Claims: CI-GCN mechanisms, max-entropy regularization effectiveness, combination of general and specific GCN layers
- Low Confidence Claims: Long-term stability across many incremental tasks, scalability to larger label spaces, robustness to varying class imbalance

## Next Checks

1. **Pseudo-Label Quality Degradation Test** - Systematically evaluate how CI-GCN performance degrades as catastrophic forgetting accumulates across incremental steps, and whether performance can be recovered with exemplar replay buffers.

2. **Ablation on GCN Architecture** - Conduct controlled experiments comparing different GCN layer configurations (e.g., single GCN vs. stacked general/specific GCNs) to quantify the contribution of each component to overall performance.

3. **Cross-Dataset Generalization** - Evaluate the method on a third dataset with different label characteristics (e.g., ImageNet-21K subset) to assess whether the CI-GCN's learnable relationship graphs transfer across domains or require domain-specific adaptation.