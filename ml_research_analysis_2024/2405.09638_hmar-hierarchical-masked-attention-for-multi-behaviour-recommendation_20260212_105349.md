---
ver: rpa2
title: 'HMAR: Hierarchical Masked Attention for Multi-Behaviour Recommendation'
arxiv_id: '2405.09638'
source_url: https://arxiv.org/abs/2405.09638
tags:
- behavior
- recommendation
- sequence
- behaviors
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HMAR, a hierarchical masked attention model
  for multi-behavior sequential recommendation. HMAR captures latent behavioral representations
  while preserving temporal sequences through two-stage self-attention.
---

# HMAR: Hierarchical Masked Attention for Multi-Behaviour Recommendation

## Quick Facts
- arXiv ID: 2405.09638
- Source URL: https://arxiv.org/abs/2405.09638
- Reference count: 20
- Primary result: Hierarchical masked attention model achieves up to 10.66% improvement in HR@10 and 10.12% improvement in NDCG@10 on Taobao dataset

## Executive Summary
HMAR introduces a hierarchical masked attention framework for multi-behavior sequential recommendation that captures both intra-behavioral and inter-behavioral relationships while preserving temporal sequences. The model employs a two-stage self-attention mechanism where items are first encoded within each behavior type, then across all behaviors in sequence order. Additionally, HMAR uses historical behavior indicators to encode frequency patterns and multi-task learning to simultaneously predict item rankings and behavior types, achieving state-of-the-art performance on four real-world datasets.

## Method Summary
HMAR uses a hierarchical attention architecture with two stages: first applying masked self-attention within each behavior type to preserve sequential order, then applying cross-behavior attention across the entire sequence. The model incorporates historical behavior indicators that track the frequency of each behavior type for items in the sequence, and employs multi-task learning with weighted loss functions for both item ranking and behavior classification. The model is trained using Adam optimizer with leave-one-out evaluation and negative sampling.

## Key Results
- Achieves up to 10.66% improvement in HR@10 on Taobao dataset compared to state-of-the-art models
- Demonstrates 10.12% improvement in NDCG@10 on Taobao dataset
- Shows consistent performance gains across four real-world datasets (Taobao, Yelp, MovieLens, Tianchi)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical masked attention preserves sequential order while modeling behavioral dependencies
- Mechanism: The model applies masked self-attention first within each behavior type, then across all behaviors in sequence order, allowing it to capture both intra- and inter-behavioral relationships without losing temporal structure
- Core assumption: Sequential patterns are preserved when attention is applied hierarchically rather than through a single unified graph
- Evidence anchors:
  - [abstract] "Our approach applies masked self-attention to items of the same behavior, followed by self-attention across all behaviors"
  - [section] "To maintain the items' order while obtaining better representations, we employ a behavior mask M u b, created from the sequence's items, to filter out items not associated with a specific behavior b"
  - [corpus] Weak evidence - no corpus papers directly discuss hierarchical masked attention for preserving sequential patterns in multi-behavior settings
- Break condition: If the sequence order is not properly preserved during the two-stage attention process, the model would lose critical temporal dependencies that distinguish sequential recommendation from general collaborative filtering

### Mechanism 2
- Claim: Historical behavior indicators encode frequency patterns that enhance recommendation accuracy
- Mechanism: The model tracks how often each behavior type occurs for each item in the sequence, creating embeddings that capture behavioral intensity and patterns over time
- Core assumption: Frequency of past behaviors contains predictive signal for future interactions
- Evidence anchors:
  - [abstract] "Additionally, we propose historical behavior indicators to encode the historical frequency of each item's behavior in the input sequence"
  - [section] "We use historical behavior indicators cj that track the frequency of each behavior type on an item throughout the sequence"
  - [corpus] Weak evidence - no corpus papers specifically address historical behavior indicators as a feature encoding mechanism
- Break condition: If the frequency encoding fails to capture meaningful behavioral patterns or becomes too sparse for items with limited interaction history

### Mechanism 3
- Claim: Multi-task learning simultaneously improves ranking and behavior type prediction
- Mechanism: The model trains two objectives concurrently - predicting the next item (ranking) and classifying the behavior type of the next interaction, allowing shared representations to capture richer user intent
- Core assumption: Auxiliary behavior classification task provides additional supervision that benefits the primary ranking task
- Evidence anchors:
  - [abstract] "the HMAR model operates in a multi-task setting, allowing it to learn item behaviors and their associated ranking scores concurrently"
  - [section] "we utilize a multi-task learning approach to learn item ranking and behavior type simultaneously"
  - [corpus] Weak evidence - no corpus papers specifically discuss multi-task learning for multi-behavior recommendation with this exact formulation
- Break condition: If the auxiliary task creates conflicting gradients or the weighting between tasks (controlled by θ) is not properly tuned, performance may degrade rather than improve

## Foundational Learning

- Concept: Masked self-attention mechanics
  - Why needed here: Understanding how attention masks filter items by behavior type is crucial for grasping the hierarchical approach
  - Quick check question: How does the behavior mask M u b modify the attention computation compared to standard self-attention?

- Concept: Multi-task learning objectives
  - Why needed here: The model combines ranking loss with classification loss, requiring understanding of how auxiliary tasks can benefit primary objectives
  - Quick check question: What role does the hyperparameter θ play in balancing the two loss functions?

- Concept: Sequential recommendation evaluation metrics
  - Why needed here: The model uses HR@N and NDCG@N metrics, which have specific properties for sequential prediction tasks
  - Quick check question: Why are leave-one-out protocols particularly suitable for sequential recommendation evaluation?

## Architecture Onboarding

- Component map: Input embeddings → Historical behavior indicators → Behavior encoder (masked self-attention per behavior) → Sequence encoder (cross-behavior attention) → Multi-task heads (ranking + classification) → Output
- Critical path: Embedding layer → Hierarchical attention → Multi-task heads → Loss computation
- Design tradeoffs: The two-stage attention approach trades computational complexity for better preservation of sequential patterns; historical behavior indicators add parameter count but capture frequency information
- Failure signatures: Degraded performance on datasets where auxiliary behaviors are less predictive; overfitting on smaller datasets due to increased parameter count; training instability when θ is not properly tuned
- First 3 experiments:
  1. Ablation study removing the behavior encoder to test the impact of hierarchical attention
  2. Ablation study removing historical behavior indicators to measure their contribution
  3. Sensitivity analysis varying the multi-task weight θ to find optimal balance between ranking and classification tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model perform when dealing with longer user sequences?
- Basis in paper: [inferred] The paper mentions that SSE-PT incorporates stochastic shared embedding regularization for handling extremely long sequences, but does not discuss the impact of sequence length on HMAR's performance.
- Why unresolved: The paper does not provide experiments or analysis on the model's performance with varying sequence lengths.
- What evidence would resolve it: Experiments comparing HMAR's performance on datasets with different sequence lengths, and analysis of how sequence length affects the model's accuracy and efficiency.

### Open Question 2
- Question: What is the impact of the number of behaviors on the model's performance?
- Basis in paper: [inferred] The paper discusses the importance of auxiliary behaviors but does not provide a detailed analysis of how the number of behaviors affects the model's performance.
- Why unresolved: The paper does not include experiments or analysis on the model's performance with varying numbers of behaviors.
- What evidence would resolve it: Experiments comparing HMAR's performance on datasets with different numbers of behaviors, and analysis of how the number of behaviors affects the model's accuracy and efficiency.

### Open Question 3
- Question: How does the model handle cold-start scenarios, where users or items have limited interaction history?
- Basis in paper: [inferred] The paper does not discuss the model's performance in cold-start scenarios or how it handles users or items with limited interaction history.
- Why unresolved: The paper does not include experiments or analysis on the model's performance in cold-start scenarios.
- What evidence would resolve it: Experiments comparing HMAR's performance on datasets with varying levels of user and item interaction history, and analysis of how the model handles cold-start scenarios.

## Limitations

- The paper lacks complete hyperparameter specifications, making exact reproduction challenging
- Some implementation details for historical behavior indicators and behavior masks are not fully described
- Performance improvements may vary with different hyperparameter settings and datasets

## Confidence

- **High Confidence**: The core architectural contributions (hierarchical masked attention, historical behavior indicators, multi-task learning) are well-defined and technically sound
- **Medium Confidence**: The empirical evaluation methodology is standard for sequential recommendation, though some implementation details are missing
- **Medium Confidence**: The claimed performance improvements are substantial but may vary with different hyperparameter settings and datasets

## Next Checks

1. **Reproducibility Test**: Implement the HMAR model following the described architecture and evaluate on a subset of the Taobao dataset using the specified metrics and leave-one-out protocol
2. **Ablation Study**: Systematically remove each component (hierarchical attention, historical behavior indicators, multi-task learning) to quantify their individual contributions to the reported performance gains
3. **Hyperparameter Sensitivity**: Conduct experiments varying the multi-task weight θ and other key hyperparameters to identify optimal settings and assess robustness to parameter changes