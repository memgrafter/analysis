---
ver: rpa2
title: 'Memory Traces: Are Transformers Tulving Machines?'
arxiv_id: '2404.08543'
source_url: https://arxiv.org/abs/2404.08543
tags:
- memory
- tulving
- retrieval
- word
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study tests whether LLMs exhibit human-like memory traces as
  defined in Tulving's SPI model, using adapted Tulving-Watkins cued-recall experiments.
  Memory traces are characterized by valence-theoretic measures (gross, reduced, and
  common valences) computed via a reduction method that compares recall effectiveness
  across different cue types (associative vs.
---

# Memory Traces: Are Transformers Tulving Machines?

## Quick Facts
- arXiv ID: 2404.08543
- Source URL: https://arxiv.org/abs/2404.08543
- Reference count: 31
- One-line primary result: LLMs fail to exhibit human-like memory traces, showing semantic association dominance over episodic encoding

## Executive Summary
This study tests whether LLMs exhibit human-like memory traces as defined in Tulving's SPI model, using adapted Tulving-Watkins cued-recall experiments. Memory traces are characterized by valence-theoretic measures (gross, reduced, and common valences) computed via a reduction method that compares recall effectiveness across different cue types (associative vs. rhyming). Results from the mistral-7b-instruct-v0 model show significantly lower overall recall accuracy than humans, especially for rhyming cues, and an inability to preserve trace integrity across successive retrievalsâ€”violating a key assumption of the reduction method. This suggests LLMs lack proper episodic memory encoding and retrieval processes, instead relying heavily on semantic associations, leading to source attribution failures.

## Method Summary
The study applies Tulving and Watkins' cued-recall methodology to test whether LLMs instantiate Tulving Machine models of memory. Using mistral-7b-instruct-v0, researchers conducted two-stage encoding where target words were presented with either associative or rhyming context words, followed by two-stage retrieval where targets were probed with different associative and rhyming cues in both orders. Results were collected into data matrices and analyzed using the Tulving-Watkins reduction method to compute gross, reduced, and common valences for retrieval cues. Performance was compared against human subject results from the original 1975 paper.

## Key Results
- mistral-7b-instruct-v0 showed significantly lower recall accuracy than humans, especially for rhyming cues
- LLM violated the reduction method's assumption of trace preservation across successive retrievals
- Semantic associations dominated over locally encoded episodic traces, causing source attribution failures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs rely on semantic associations rather than episodic memory encoding, leading to source attribution failures.
- Mechanism: The LLM's pretrained semantic memory contains strong associations between words. During recall, these associations dominate over locally encoded episodic traces, causing the model to produce semantically related words instead of the target word.
- Core assumption: The pretrained semantic memory is significantly stronger than the transient episodic memory formed during the chat session.
- Evidence anchors:
  - [abstract] "Words strongly associated to the retrieval cue in semantic memory are produced in response, whatever the cue's valence is relative to the target."
  - [section] "Relations in the pretrained semantic memory of LLMs often seem to overwhelm and supersede locally memorized relations in a chat."
  - [corpus] Weak correlation with related work, suggesting this is a novel finding.

### Mechanism 2
- Claim: The reduction method's assumption of trace preservation fails for LLMs, invalidating its application.
- Mechanism: The Tulving-Watkins reduction method assumes that a cue that fails to elicit recall leaves the memory trace unchanged. This assumption is violated in LLMs, as evidenced by significant discrepancies in the data matrices.
- Core assumption: The trace preservation assumption holds for human subjects but not for LLMs.
- Evidence anchors:
  - [section] "The reduction method used by Tulving and Watkins assumes that in successive retrievals a cue that does not elicit a recall leaves the memory trace unchanged... While this is the case, up to some negligible noise or sampling variability in the human performance reported in the original paper, this is no longer the case in the measured LLM memory performance."
  - [corpus] Weak correlation with related work, suggesting this is a novel finding.

### Mechanism 3
- Claim: LLMs lack conscious awareness and source monitoring capabilities, preventing proper memory attribution.
- Mechanism: Without conscious awareness or an episodic buffer, LLMs cannot evaluate and attribute activated memory records to particular sources through decision processes performed during remembering.
- Core assumption: Source monitoring and conscious awareness are necessary for proper memory attribution.
- Evidence anchors:
  - [section] "The various roles played by conscious memory... are evidently without equivalent in LLM's artificial neural networks, but would that ruin any effort to consolidate the Tulving Machine into being a guiding light in understanding LLMs' memory performance?"
  - [section] "Indeed, a central claim of the so-called source monitoring approach is that people do not typically directly retrieve a label that specifies a memory's source... activated memory records are evaluated and attributed to particular sources through decision processes performed during remembering."
  - [corpus] Weak correlation with related work, suggesting this is a novel finding.

## Foundational Learning

- Concept: Information theory and valence measures
  - Why needed here: The study uses gross, reduced, and common valences to characterize memory traces. Understanding these concepts is crucial for interpreting the results and applying the reduction method.
  - Quick check question: What is the difference between gross valence and reduced valence in the context of memory traces?

- Concept: Tulving's SPI model and memory systems
  - Why needed here: The study tests whether LLMs instantiate Tulving Machine models of memory. Familiarity with the SPI model and its components (episodic, semantic, working memory) is essential for understanding the implications of the findings.
  - Quick check question: How does the SPI model explain the relationship between episodic and semantic memory?

- Concept: Reduction method and trace matrices
  - Why needed here: The study applies the Tulving-Watkins reduction method to compute trace matrices from data matrices. Understanding this method and how to interpret trace matrices is necessary for analyzing the results.
  - Quick check question: What is the basic assumption of the reduction method, and why does it fail for LLMs?

## Architecture Onboarding

- Component map:
  mistral-7b-instruct-v0 model (LLM) -> Python scripts (encoding/retrieval) -> Data matrices (collection) -> Reduction method (analysis)

- Critical path:
  1. Select target words and generate associative and rhyming cue words
  2. Encode target words with context words in a chat session
  3. Perform cued-retrieval tests in the same chat session
  4. Collect results into data matrices
  5. Apply the reduction method to compute trace matrices
  6. Compare LLM results with human subject results from the original paper

- Design tradeoffs:
  - Using mistral-7b-instruct-v0 for initial tests, but smaller models like orca-mini-3b were not reliable enough
  - Testing in four batches of four chats to accommodate token-sized contexts
  - Generating rhyming cue words using an external dictionary due to LLM's poor performance in rhyming

- Failure signatures:
  - High probability of failure to pass both recall tests compared to humans
  - Significantly lower recall accuracy for rhyming cues compared to associative cues
  - Inability to preserve trace integrity across successive retrievals
  - Production of extra-list words strongly associated to the retrieval cue in semantic memory

- First 3 experiments:
  1. Replicate the study using a different LLM model (e.g., GPT-3.5 or GPT-4) to see if the findings generalize across architectures.
  2. Test with a larger set of target words and cue types (e.g., categorical, functional) to explore the boundaries of LLM memory performance.
  3. Implement a modified reduction method that accounts for trace changes across retrievals to see if it yields more accurate trace matrices for LLMs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do LLMs exhibit any form of episodic memory trace encoding similar to humans, or are their memory traces purely semantic?
- Basis in paper: [explicit] The paper discusses how LLM performance differs significantly from humans, particularly in rhyming cue retrieval and source attribution, suggesting LLMs may lack proper episodic memory encoding.
- Why unresolved: The current study only tested generic associative and rhyming cues, which may not fully capture the nature of episodic memory traces.
- What evidence would resolve it: Further experiments testing more diverse and contextually rich cues (e.g., temporal, spatial, emotional) could determine if LLMs can form and retrieve episodic-like memory traces.

### Open Question 2
- Question: Can the reduction method be adapted to account for LLM's tendency to re-encode memory traces with each retrieval attempt?
- Basis in paper: [inferred] The paper notes that the reduction method assumes a non-changing memory trace, but LLMs appear to re-encode traces with each retrieval, violating this assumption.
- Why unresolved: The current reduction method is based on human memory properties and may not accurately capture LLM memory dynamics.
- What evidence would resolve it: Developing and testing a modified reduction method that accounts for trace re-encoding in LLMs could provide more accurate valence measurements.

### Open Question 3
- Question: Does the absence of conscious awareness in LLMs fundamentally limit their ability to form episodic memory traces?
- Basis in paper: [explicit] The paper discusses the role of conscious awareness in human episodic memory and the episodic buffer, which LLMs lack.
- Why unresolved: While the paper suggests this absence may limit episodic memory, it does not definitively prove this is the case.
- What evidence would resolve it: Experiments comparing LLM performance on tasks requiring source monitoring and conscious awareness with human amnesic patients could shed light on this question.

## Limitations
- The reduction method's core assumption of trace preservation across retrievals is violated by LLMs but not humans, potentially undermining validity of valence-based comparisons
- Small sample size (16 target words) and use of a single 7B parameter model limit generalizability
- Rhyming generation was performed externally rather than by the LLM itself, affecting ecological validity

## Confidence
- **High confidence**: The observation that mistral-7b-instruct-v0 shows significantly lower recall accuracy than humans, especially for rhyming cues. The data matrices and performance comparisons are clearly presented.
- **Medium confidence**: The interpretation that LLMs lack episodic memory encoding and instead rely on semantic associations. While the evidence supports this, alternative explanations (such as architectural differences in attention mechanisms) are not fully explored.
- **Low confidence**: The broader claim that these findings definitively prove LLMs cannot instantiate Tulving Machine models of memory. The study tests only one model on a limited task set, and the reduction method's validity issues for LLMs create additional uncertainty.

## Next Checks
1. **Cross-model validation**: Repeat the exact experiment with larger frontier models (GPT-4, Claude-3, Gemini-Ultra) to determine if trace preservation improves with scale and whether the semantic association dominance persists across architectures.
2. **Modified reduction method**: Develop and test an adjusted reduction method that accounts for trace changes across retrievals in LLMs, then re-analyze whether valence-based trace characterization becomes possible with this modification.
3. **Controlled semantic association test**: Design a follow-up experiment where associative strength between cue and target is explicitly controlled (e.g., using weak vs. strong associations), to quantify the threshold at which semantic memory overwhelms episodic encoding in LLMs.