---
ver: rpa2
title: 'CRISP: Object Pose and Shape Estimation with Test-Time Adaptation'
arxiv_id: '2412.01052'
source_url: https://arxiv.org/abs/2412.01052
tags:
- shape
- pose
- crisp
- object
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CRISP addresses category-agnostic 6D object pose and shape estimation
  from RGB-D images. It introduces a pipeline combining a ViT backbone with a DPT
  for pose-normalized coordinate estimation and a FiLM-conditioned SDF decoder for
  shape reconstruction.
---

# CRISP: Object Pose and Shape Estimation with Test-Time Adaptation

## Quick Facts
- **arXiv ID**: 2412.01052
- **Source URL**: https://arxiv.org/abs/2412.01052
- **Reference count**: 40
- **Key outcome**: CRISP achieves state-of-the-art shape reconstruction on YCBV, NOCS, and SPE3R datasets, with self-training improving performance by up to 22% on Chamfer distance and 44% on ADD-S AUC.

## Executive Summary
CRISP addresses category-agnostic 6D object pose and shape estimation from RGB-D images using a ViT backbone with DPT for pose-normalized coordinate estimation and FiLM-conditioned SDF decoder for shape reconstruction. To handle domain gaps, CRISP-ST performs test-time adaptation through a corrector that approximates the shape decoder with an active shape model, reducing pose and shape correction to a constrained linear least squares problem. Self-training uses observable correctness certificates to generate pseudo-labels from corrected estimates, enabling adaptation without access to synthetic data. The method achieves state-of-the-art shape reconstruction performance and generalizes to unseen objects while supporting real-time inference.

## Method Summary
CRISP combines a frozen ViT backbone with a DPT-based network to estimate pose-normalized coordinates, while a shape head predicts latent shape codes that condition a FiLM-based SDF decoder. The corrector refines initial estimates using bi-level optimization with active shape model approximation. Self-training employs observable correctness certificates to filter and use corrected estimates as pseudo-labels, enabling domain adaptation without ground truth access. The approach trains on synthetic data and adapts to target domains through iterative self-training cycles.

## Key Results
- CRISP achieves state-of-the-art shape reconstruction on YCBV, NOCS, and SPE3R datasets
- Self-training improves Chamfer distance by up to 22% and ADD-S AUC by up to 44%
- Method generalizes to unseen objects and supports real-time inference
- CRISP-ST bridges domain gaps without requiring synthetic data access

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The FiLM-conditioned shape decoder produces reliable implicit SDF representations within the convex hull of known shapes, enabling effective pose refinement.
- Mechanism: The shape decoder is trained on latent shape codes from known objects. When the latent code is interpolated within the simplex of these codes, the decoder generates plausible SDFs. This creates a convex region where the SDF is well-behaved, allowing the corrector to approximate it with an active shape model.
- Core assumption: The decoder's output remains plausible and differentiable within the convex hull of training shape codes.
- Evidence anchors:
  - [abstract]: "Observing that the shape decoder is well behaved in the convex hull of known shapes, we approximate the shape decoder with an active shape model..."
  - [section 4.2]: "When h is interpolated (i.e., 1 ≥ αk ≥ 0) the decoder fd(· | h) is well behaved. When it is extrapolated, the decoder produces implausible object shapes..."
  - [corpus]: Weak evidence - no direct corpus support found.
- Break condition: If test objects have shapes outside the convex hull of training shapes, the approximation breaks down and the corrector produces implausible SDFs.

### Mechanism 2
- Claim: Test-time adaptation through self-training with observable correctness certificates bridges domain gaps without requiring synthetic data access.
- Mechanism: The corrector refines pose and shape estimates, and the observable correctness certificate checks geometric consistency between corrected pose-inverted depth and the implicit shape representation. Estimates passing this check are used as pseudo-labels to self-train the model, progressively improving performance on the target domain.
- Core assumption: The observable correctness certificate reliably identifies good estimates without ground truth access.
- Evidence anchors:
  - [abstract]: "Self-training uses observable correctness certificates to generate pseudo-labels from corrected estimates, enabling adaptation without access to synthetic data."
  - [section 5]: "We implement observable correctness certificate checks to assert the quality of the estimates from the corrector...If the corrected estimates ( ˆZ, ˆh) pass the oc check, then we self-annotate the image I with the corrected estimates."
  - [section 6.1]: "With oc, the CDF curves are shifted to the far left, indicating that the check filters out instances with high eshape without access to ground truth."
- Break condition: If the certificate threshold is too strict, too few instances pass for effective self-training; if too lenient, noisy pseudo-labels degrade performance.

### Mechanism 3
- Claim: Pose-normalized coordinate (PNC) estimation without scale normalization prevents degeneracy and enables consistent self-training.
- Mechanism: By estimating PNC directly without normalizing scale, the model maintains consistent coordinate frames across training and test time. This prevents the drift in predicted coordinates that occurs with scale normalization, ensuring stable self-training.
- Core assumption: Unnormalized PNC provides sufficient information for pose estimation while maintaining consistency.
- Evidence anchors:
  - [section 3.2]: "Remark 1 (Difference from NOCS [ 42]). Contrary to NOCS [42], we do not normalize Z. This is crucial for self-training: involving scale estimation leads to degeneracies of PNC, causing Z to drift away from the ground truth..."
  - [section D.4]: "Assume noiseless depth {xi}, for a given zi, we have (ˆs, ˆR, ˆt) as the solution to (24). If we scale zi by a factor of b, we can achieve the same loss for (24) if we let s = bˆs, R = ˆR, and t = bˆt."
  - [corpus]: Weak evidence - no direct corpus support found.
- Break condition: If pose estimation performance significantly degrades without scale normalization, the approach may need to be reconsidered.

## Foundational Learning

- **Concept: Implicit Signed Distance Functions (SDFs)**
  - Why needed here: CRISP uses SDFs to represent object shapes implicitly, allowing continuous shape representation and differentiable operations for pose refinement.
  - Quick check question: What is the key property of SDFs that makes them useful for shape representation in pose estimation?

- **Concept: Vision Transformers (ViT) for feature extraction**
  - Why needed here: CRISP uses a pre-trained ViT backbone (DINOv2) to extract meaningful image features that condition the shape and pose estimation heads.
  - Quick check question: How does using frozen pre-trained features benefit the training stability of the subsequent pose and shape estimation modules?

- **Concept: FiLM (Feature-wise Linear Modulation) conditioning**
  - Why needed here: FiLM conditioning allows the shape decoder to adapt its output based on the extracted image features without requiring explicit category labels.
  - Quick check question: What advantage does FiLM conditioning provide over simple concatenation when conditioning neural implicit fields?

## Architecture Onboarding

- **Component map**: RGB-D → ViT → Shape Head + PNC Head → Shape Decoder + Pose Estimation → Corrector → Final Pose and Shape

- **Critical path**: RGB-D → ViT → Shape Head + PNC Head → Shape Decoder + Pose Estimation → Corrector → Final Pose and Shape

- **Design tradeoffs**:
  - FiLM conditioning vs. concatenation: FiLM provides better reconstruction but adds complexity
  - DPT vs. CNN for PNC: DPT provides better fine-grained predictions but is slower
  - Active shape model vs. direct shape decoder optimization: Active model is faster but requires maintaining shape basis vectors

- **Failure signatures**:
  - Poor pose estimation: Check ViT features quality, PNC head training loss, and Arun's method implementation
  - Implausible shapes from corrector: Verify shape codes stay within simplex, check active shape model approximation quality
  - Self-training not improving: Verify observable correctness certificate threshold, check pseudo-label quality, ensure buffer management

- **First 3 experiments**:
  1. Verify basic pose and shape estimation pipeline works on synthetic data with known ground truth
  2. Test corrector performance by adding synthetic noise to pose and shape estimates
  3. Validate observable correctness certificate by comparing filtered vs. unfiltered performance on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the CRISP model's performance degrade with increasing domain shift beyond the synthetic-to-real gap tested in the YCBV experiments?
- **Basis in paper**: [inferred] The paper mentions that self-training improves performance by bridging domain gaps, but only tests one synthetic-to-real scenario with BlenderProc-rendered images.
- **Why unresolved**: The paper only demonstrates adaptation on a single synthetic-to-real domain gap using BlenderProc, without exploring other types of domain shifts (e.g., different lighting conditions, object backgrounds, or sensor noise patterns).
- **What evidence would resolve it**: Systematic experiments testing CRISP-ST on multiple domain shift scenarios with varying magnitudes, including cross-dataset evaluations where training and test sets have fundamentally different characteristics.

### Open Question 2
- **Question**: What is the theoretical limit of the corrector's effectiveness when the initial network estimates are extremely poor?
- **Basis in paper**: [explicit] The paper notes that the corrector uses network estimates as initialization and performs better when the model provides a good starting point, but doesn't characterize the performance bounds when initialization is poor.
- **Why unresolved**: The paper only shows empirical results where the corrector improves estimates, but doesn't establish when or why it might fail, or what the performance ceiling is for very poor initial estimates.
- **What evidence would resolve it**: Theoretical analysis or empirical characterization of corrector performance as a function of initial estimation error, including failure cases and performance bounds.

### Open Question 3
- **Question**: How does the computational overhead of the corrector and self-training scale with the number of objects in the training dataset?
- **Basis in paper**: [explicit] The paper mentions that the shape decoder's latent shape code scales linearly with the number of objects, and runtime comparisons show significant differences between methods.
- **Why unresolved**: While the paper shows runtime comparisons for a fixed dataset, it doesn't analyze how computational costs scale with dataset size, which is critical for practical deployment on larger object categories.
- **What evidence would resolve it**: Empirical scaling studies showing runtime and memory usage as a function of the number of training objects, and analysis of computational bottlenecks.

## Limitations
- The convex hull assumption for shape decoder behavior lacks extensive empirical validation across diverse object categories
- The observable correctness certificate's robustness across different viewing conditions and object categories remains uncertain
- The FiLM-conditioned SDF decoder requires maintaining shape basis vectors, adding complexity compared to direct optimization approaches

## Confidence
- Shape reconstruction performance claims: **High** - supported by extensive quantitative comparisons across multiple datasets
- Self-training effectiveness: **Medium** - strong results but limited ablation on certificate sensitivity
- Real-time inference claims: **Medium** - reported inference times but limited discussion of computational requirements

## Next Checks
1. **Convex hull boundary test**: Systematically evaluate shape decoder performance on objects with latent codes approaching and exceeding the convex hull boundaries to quantify approximation quality degradation.

2. **Certificate sensitivity analysis**: Perform controlled experiments varying the observable correctness threshold parameters (ϵ, p) to determine optimal settings across different object categories and lighting conditions.

3. **Computational overhead measurement**: Benchmark memory usage and inference latency for the FiLM-conditioned SDF decoder and active shape model components across different shape vocabulary sizes to validate real-time capability claims.