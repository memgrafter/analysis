---
ver: rpa2
title: 'Interpolated-MLPs: Controllable Inductive Bias'
arxiv_id: '2410.09655'
source_url: https://arxiv.org/abs/2410.09655
tags:
- interpolation
- bias
- inductive
- layer
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work investigates how incrementally increasing inductive\
  \ bias affects MLP performance in the low-compute regime. The authors propose Interpolated\
  \ MLPs (I-MLPs), which interpolate between a standard MLP and prior models (CNN\
  \ or MLP-Mixer) using a parameter \u03B1 to control the amount of inductive bias."
---

# Interpolated-MLPs: Controllable Inductive Bias

## Quick Facts
- arXiv ID: 2410.09655
- Source URL: https://arxiv.org/abs/2410.09655
- Authors: Sean Wu; Jordan Hong; Keyu Bai; Gregor Bachmann
- Reference count: 28
- One-line primary result: Interpolating MLP weights with prior models (CNN/MLP-Mixer) allows fractional control of inductive bias, yielding a V-shaped performance curve on CIFAR-10/100 in the low-compute regime.

## Executive Summary
This work introduces Interpolated MLPs (I-MLPs), which control inductive bias by interpolating between standard MLPs and structured prior models (CNN or MLP-Mixer) using a parameter α. The authors demonstrate a continuous logarithmic relationship between inductive bias and performance, showing that fractional inductive bias can be optimal in the mid-compute regime. Experiments reveal that performance follows a V-shaped curve with respect to α, that concentrating interpolation in the first layer yields the best results, and that training-time interpolation significantly outperforms test-time-only interpolation.

## Method Summary
I-MLPs interpolate between a standard MLP and prior models (CNN or MLP-Mixer) by converting the prior model's structured weights to equivalent fully-connected representations and combining them with standard MLP weights using parameter α. The interpolation occurs during training at each epoch: W ← (1-α)W + αWP. This allows fractional control of inductive bias, with α=0 giving a standard MLP and α=1 giving the prior model. The method is evaluated on CIFAR-10 and CIFAR-100 datasets with varying α values to study the relationship between inductive bias and performance.

## Key Results
- Performance exhibits a V-shaped curve with respect to α, with logarithmic improvements on either side of the minimum
- Concentrating interpolation parameters in the first layer yields the best performance under a fixed interpolation budget
- Test-time-only interpolation performs significantly worse than training-time interpolation
- I-MLP with CNN prior shows V-shaped performance curves, while MLP-Mixer prior shows more complex curves with local minimum and maximum

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Interpolating MLP weights with a prior model's equivalent fully-connected weights allows controlled introduction of inductive bias, and performance follows a V-shaped curve with respect to interpolation weight α.
- Mechanism: The interpolation combines two sets of weights: one from a standard MLP (low inductive bias) and one from a prior model like CNN or MLP-Mixer (high inductive bias). The parameter α controls the fractional contribution of each. Performance is optimal at an intermediate α because full inductive bias is unnecessary and potentially harmful at low-compute regimes, while zero inductive bias underperforms compared to models with some structural constraints.
- Core assumption: The prior model's equivalent fully-connected weights (WP) adequately capture the structural inductive bias of the original model (e.g., locality from convolution or weight sharing from MLP-Mixer).
- Evidence anchors: [abstract] "This interpolation scheme allows fractional control of inductive bias, which may be attractive when full inductive bias is not desired (e.g. in the mid-compute regime)." [section] "We find experimentally that for Vision Tasks in the low-compute regime, there is a continuous and two-sided logarithmic relationship between inductive bias and performance when using CNN and MLP-Mixer prior models."

### Mechanism 2
- Claim: Concentrating interpolation parameters in the first layer yields the best performance under a fixed interpolation budget.
- Mechanism: The first layer operates on raw input features and is most sensitive to structural priors like locality. By concentrating the inductive bias in this layer, the model gains maximal benefit from the prior model's structural constraints early in the computation, while deeper layers can adapt freely. This is more efficient than distributing the same amount of inductive bias across multiple layers.
- Core assumption: Early layers benefit most from inductive bias injection, and deeper layers are better left to learn task-specific representations without structural constraints.
- Evidence anchors: [section] "Experiments show that concentrating interpolation parameters in the first layer yields the best performance, and that test-time only interpolation performs significantly worse than training-time interpolation." [section] "For this fixed interpolation parameter budget, we observe that a wide first layer interpolation with a CNN prior is better as shown in Table 5."

### Mechanism 3
- Claim: Test-time-only interpolation performs significantly worse than training-time interpolation because the two models converge to different local minima.
- Mechanism: When interpolation occurs only at test time, the MLP and prior model weights are trained independently and converge to different local minima in the loss landscape. Interpolating between these mismatched solutions creates interference that degrades performance. Training-time interpolation allows the weights to adapt jointly, finding compatible minima that interpolate smoothly.
- Core assumption: Independent training of the two models leads to convergence at incompatible local minima, and joint training through interpolation enables finding compatible solutions.
- Evidence anchors: [section] "we compare interpolation during training with test-time only interpolation. We separately train the MLP and prior models, and only use the interpolation weight once before test and inference time. The results in Table 4 show that test-time only interpolation performs significantly worse."

## Foundational Learning

- Concept: Equivalent fully-connected layer representation of structured models (CNN/MLP-Mixer)
  - Why needed here: To enable interpolation between standard MLPs and structured models, we need a way to express the inductive bias of CNNs and MLP-Mixers as fully-connected weight matrices that can be combined with standard MLP weights.
  - Quick check question: How do you convert a 2D convolution kernel into an equivalent fully-connected weight matrix that preserves the locality inductive bias?

- Concept: Inductive bias and its relationship to model performance across compute regimes
  - Why needed here: The paper's central hypothesis is that inductive bias has a non-monotonic relationship with performance, being beneficial at low-compute but potentially harmful at high-compute. Understanding this tradeoff is crucial for interpreting the V-shaped performance curve.
  - Quick check question: Why might a model with too much inductive bias perform worse than one with moderate inductive bias in the low-compute regime?

- Concept: Geometric series and weight update dynamics in interpolation training
  - Why needed here: The paper mentions that with constant interpolation weight α, the inductive bias forms a geometric series. Understanding this helps explain why non-constant interpolation schedules (like exponential decay) are explored and how they affect training dynamics.
  - Quick check question: If you interpolate with constant weight α at each epoch, what is the effective contribution of the prior model's weights to the final interpolated weights after t epochs?

## Architecture Onboarding

- Component map:
  Standard MLP backbone -> Prior model conversion -> Interpolation layer -> Training loop

- Critical path:
  1. Convert prior model to equivalent fully-connected representation (WP)
  2. Initialize standard MLP weights (W)
  3. For each epoch: train W and WP independently, then interpolate: W ← (1-α)W + αWP
  4. Evaluate performance on validation/test set

- Design tradeoffs:
  - α value selection: Too low → insufficient inductive bias; too high → excessive structural constraints
  - Interpolation timing: Training-time (better) vs test-time-only (worse)
  - Interpolation distribution: Concentrated in first layer (better) vs distributed across layers
  - Prior model choice: CNN (locality bias) vs MLP-Mixer (weight sharing bias)

- Failure signatures:
  - Performance worse than both baseline MLP and prior model → interference between incompatible minima
  - No improvement over standard MLP → ineffective conversion of prior model to fully-connected representation
  - Overfitting despite data augmentation → insufficient model capacity or excessive inductive bias

- First 3 experiments:
  1. Implement I-MLP with CNN prior and test different α values (0, 0.01, 0.1, 0.5, 1.0) on CIFAR-10 to reproduce the V-shaped curve
  2. Compare training-time interpolation vs test-time-only interpolation with fixed α=0.5
  3. Implement I-MLP with MLP-Mixer prior and test different α values to observe the more complex curve with local minimum and maximum

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact mathematical relationship between the interpolation parameter α and the effective inductive bias introduced into the MLP, and how does this vary across different prior models (CNN vs. MLP-Mixer)?
- Basis in paper: [explicit] The paper demonstrates a logarithmic relationship between α and performance for both CNN and MLP-Mixer priors, but the exact functional form and its dependence on the prior model type is not specified.
- Why unresolved: The paper shows empirical results but does not derive or model the precise mathematical relationship between α and the amount of inductive bias.
- What evidence would resolve it: Deriving analytical expressions for the effective inductive bias as a function of α for each prior model type, validated through controlled experiments isolating the contribution of each source of inductive bias.

### Open Question 2
- Question: How does the performance of I-MLP with fractional inductive bias compare to standard architectures (CNN, ViT) across different compute regimes, and what is the optimal balance point?
- Basis in paper: [inferred] The paper suggests that fractional inductive bias may be optimal in the mid-compute regime, but does not directly compare I-MLP performance to standard architectures across varying compute scales.
- Why unresolved: The paper focuses on the low-compute regime and does not explore how I-MLP performance scales with increasing compute or compare it directly to established architectures.
- What evidence would resolve it: Systematic experiments comparing I-MLP with varying α to CNN, ViT, and other standard architectures across a range of compute budgets (parameter counts, FLOPs) to identify optimal performance points.

### Open Question 3
- Question: What is the impact of different interpolation strategies (e.g., layer-wise interpolation, non-linear interpolation schedules) on the final performance and convergence properties of I-MLP?
- Basis in paper: [explicit] The paper explores some interpolation strategies (test-time only, time-varying α) but does not exhaustively investigate the space of possible interpolation methods.
- Why unresolved: While the paper presents some preliminary results on alternative interpolation strategies, it does not provide a comprehensive analysis of how different approaches affect performance and training dynamics.
- What evidence would resolve it: Extensive experiments comparing various interpolation strategies (e.g., layer-wise, non-linear schedules, adaptive methods) on their impact on final accuracy, convergence speed, and stability across multiple datasets and model architectures.

## Limitations
- Limited to CIFAR-10 and CIFAR-100 datasets with small-scale models, leaving uncertainty about generalization to larger datasets
- Lack of theoretical grounding for why the V-shaped performance curve emerges
- Conversion of structured models to equivalent fully-connected representations is mathematically specified but not rigorously proven to preserve inductive bias

## Confidence

- Mechanism 1 (V-shaped curve): Medium - The empirical evidence is strong for the specific experimental setup, but the underlying theoretical explanation is incomplete.
- Mechanism 2 (First layer concentration): Low-Medium - This appears to be a novel empirical finding without strong theoretical justification or extensive ablation studies.
- Mechanism 3 (Training-time vs test-time): Medium - The empirical difference is clear, but the explanation about incompatible local minima is speculative without loss landscape analysis.

## Next Checks
1. Conduct loss landscape visualization to verify that independently trained models converge to different local minima, providing evidence for Mechanism 3.
2. Perform ablation studies on the conversion formulas for WP to verify that the inductive bias is correctly preserved in the equivalent fully-connected representation.
3. Test I-MLP performance on a larger-scale dataset (e.g., ImageNet-1K) to evaluate whether the logarithmic relationship between inductive bias and performance generalizes beyond CIFAR.