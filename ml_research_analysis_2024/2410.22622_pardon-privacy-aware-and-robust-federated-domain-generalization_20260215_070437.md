---
ver: rpa2
title: 'PARDON: Privacy-Aware and Robust Federated Domain Generalization'
arxiv_id: '2410.22622'
source_url: https://arxiv.org/abs/2410.22622
tags:
- domain
- style
- learning
- client
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FISC, a novel Federated Domain Generalization
  (FedDG) method that addresses domain shift in federated learning settings. Unlike
  existing FedDG approaches that rely on cross-client information sharing or local
  signals, FISC employs an interpolation style transfer mechanism with contrastive
  learning to achieve privacy-aware and robust domain generalization.
---

# PARDON: Privacy-Aware and Robust Federated Domain Generalization

## Quick Facts
- **arXiv ID**: 2410.22622
- **Source URL**: https://arxiv.org/abs/2410.22622
- **Authors**: Dung Thuy Nguyen; Taylor T. Johnson; Kevin Leach
- **Reference count**: 40
- **Primary result**: Introduces FISC, a novel Federated Domain Generalization method achieving 3.64% to 57.22% accuracy improvements on unseen domains

## Executive Summary
This paper introduces FISC, a novel Federated Domain Generalization (FedDG) method that addresses domain shift in federated learning settings. Unlike existing FedDG approaches that rely on cross-client information sharing or local signals, FISC employs an interpolation style transfer mechanism with contrastive learning to achieve privacy-aware and robust domain generalization. The method extracts representative styles from local data, aggregates them into a global interpolation style, and then uses contrastive learning to align local models with this global style. This approach effectively handles domain-based heterogeneity and client sampling scenarios. Experiments on multiple datasets including PACS, Office-Home, and IWildCam demonstrate that FISC outperforms state-of-the-art methods while maintaining comparable computational overhead and enhancing privacy protection.

## Method Summary
FISC addresses federated domain generalization by combining style transfer with contrastive learning. Each client computes local style statistics (channel-wise mean and standard deviation) from their data, which are aggregated by the server using FINCH clustering and median aggregation to create a global interpolation style. During local training, clients use AdaIN-based style transfer to generate style-transferred data, then apply contrastive learning with triplet loss to align their models with the global style. The method preserves privacy by sharing only style statistics rather than raw data or class prototypes, while achieving better generalization to unseen domains compared to existing approaches.

## Key Results
- FISC achieves accuracy improvements ranging from 3.64% to 57.22% on unseen domains compared to state-of-the-art methods
- The method effectively handles both domain-based heterogeneity and client sampling scenarios
- FISC maintains comparable computational overhead while enhancing privacy protection compared to existing FedDG approaches
- Ablation studies demonstrate the effectiveness of both the interpolation style transfer and contrastive learning components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aggregating interpolation styles from all clients creates an unbiased representation of the global domain distribution.
- Mechanism: FINCH clustering is applied to client-level style statistics, followed by median aggregation to produce a global interpolation style that blends representative styles from all clients while minimizing outlier influence.
- Core assumption: Style statistics (channel-wise mean and standard deviation) are sufficient to capture domain characteristics without revealing sensitive information.
- Evidence anchors:
  - [abstract]: "FISC employs an interpolation style transfer mechanism with contrastive learning to achieve privacy-aware and robust domain generalization."
  - [section]: "The median is robust to outliers (i.e., extreme values) and skewed distributions in style statistics, ensuring no single dominant style skews the global interpolation style."
  - [corpus]: No direct evidence for this claim; corpus neighbors focus on cross-client feature alignment but do not discuss interpolation-style aggregation.
- Break condition: If style statistics fail to capture domain-relevant features or become vulnerable to reconstruction attacks, the global interpolation style will not generalize well.

### Mechanism 2
- Claim: Contrastive learning with style-transferred data aligns local models with the global interpolation style, reducing local bias.
- Mechanism: For each training batch, the method creates positive pairs using original and style-transferred embeddings from the same class, and negative pairs using style-transferred embeddings from different classes, enforcing domain-invariant feature learning.
- Core assumption: Style-transferred data generated via AdaIN preserves class semantics while altering domain characteristics.
- Evidence anchors:
  - [abstract]: "This approach provides each client with a multi-domain representation and an unbiased convergent target."
  - [section]: "We enforce the model to embed the original data in a manner that is more similar to the style-transferred data from the same class while pushing it away from style-transferred data from other classes."
  - [corpus]: No direct evidence for this claim; corpus neighbors discuss cross-client alignment but not contrastive learning with style transfer.
- Break condition: If AdaIN fails to preserve class information in style-transferred data, the contrastive loss will push embeddings apart incorrectly, harming performance.

### Mechanism 3
- Claim: Privacy is preserved because only style statistics are shared, not raw data or class-level prototypes.
- Mechanism: Local style statistics are computed as channel-wise mean and standard deviation of feature embeddings, which are difficult to invert back to original images.
- Core assumption: Style statistics are low-dimensional and abstract enough to prevent reconstruction of original data.
- Evidence anchors:
  - [abstract]: "Our method achieves accuracy on unseen domains, with improvements ranging from 3.64% to 57.22% on unseen domains."
  - [section]: "Importantly, it has been demonstrated to be highly challenging to reverse-engineer the original dataset solely from this style information ( Chen et al. [2023])."
  - [corpus]: No direct evidence for this claim; corpus neighbors discuss cross-client style transfer but do not analyze privacy guarantees of style statistics.
- Break condition: If attackers develop reconstruction methods from style statistics, the privacy guarantee fails and sensitive data may be exposed.

## Foundational Learning

- Concept: Federated Learning (FL) basics - distributed model training with local data privacy
  - Why needed here: FISC operates within the FL framework, requiring understanding of local updates, aggregation, and privacy constraints.
  - Quick check question: What is the key privacy-preserving mechanism in standard FL that FISC builds upon?

- Concept: Domain Generalization (DG) - learning models that generalize to unseen domains
  - Why needed here: FISC addresses domain shift by creating a global interpolation style that represents multiple domains, enabling generalization.
  - Quick check question: How does FISC's approach to DG differ from traditional centralized DG methods?

- Concept: Contrastive Learning - learning representations by comparing similar and dissimilar samples
  - Why needed here: FISC uses triplet loss with style-transferred data to enforce domain-invariant features while preserving class information.
  - Quick check question: What is the role of the margin parameter in the triplet loss used by FISC?

## Architecture Onboarding

- Component map: Local style calculation -> Server-side interpolation style extraction -> Local contrastive training -> Standard FedAvg aggregation
- Critical path:
  1. Each client computes local style statistics from local data
  2. Server aggregates styles into global interpolation style
  3. Each client performs local training using contrastive learning with style-transferred data
  4. Server aggregates updated models via weighted averaging

- Design tradeoffs:
  - Privacy vs. expressiveness: Using only statistics preserves privacy but may lose fine-grained domain information
  - Computation vs. accuracy: FINCH clustering adds overhead but improves style representation quality
  - Style transfer vs. data augmentation: AdaIN-based transfer preserves class semantics better than random augmentation

- Failure signatures:
  - Poor validation accuracy despite good training performance → local bias not addressed
  - Degraded performance with more clients → style aggregation becomes less representative
  - High reconstruction vulnerability → style statistics too informative

- First 3 experiments:
  1. Run FISC on PACS with λ=0.0 (no domain overlap) and compare to FedSR baseline
  2. Test FISC with and without the contrastive learning component to measure its impact
  3. Evaluate privacy by attempting to reconstruct images from shared style statistics using GAN-based attack

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the style definition in FISC be adapted for gray-scaled datasets like FEMNIST?
- Basis in paper: [explicit] The authors acknowledge that the current style definition, based on channel-wise mean and standard deviation of embedding vectors, may not perform well with gray-scaled datasets.
- Why unresolved: The authors only mention the limitation and do not propose a specific solution for adapting the style definition to gray-scaled images.
- What evidence would resolve it: A proposed method for extracting style information from gray-scaled images, along with experimental results demonstrating its effectiveness on a gray-scaled dataset like FEMNIST.

### Open Question 2
- Question: What is the impact of different clustering methods (e.g., FINCH vs. simple averaging) on the performance of FISC?
- Basis in paper: [explicit] The authors conduct an ablation study comparing FINCH clustering to simple averaging for local and global style calculation, finding that FINCH outperforms simple averaging.
- Why unresolved: While the authors show that FINCH is better than simple averaging, they do not explore other clustering methods or provide a detailed comparison of different clustering algorithms.
- What evidence would resolve it: A comprehensive comparison of FISC's performance using different clustering methods, including metrics such as accuracy and computational efficiency.

### Open Question 3
- Question: How does the choice of triplet loss margin (α) affect the performance of FISC across different datasets?
- Basis in paper: [explicit] The authors mention that the triplet loss margin α is set to 0.3 for PACS and Office-Home datasets, and 1.0 for IWildCam, but they do not provide a detailed analysis of how different values of α impact performance.
- Why unresolved: The authors only provide the optimal values of α for specific datasets but do not explore the sensitivity of FISC to this hyperparameter or provide guidelines for selecting α in general.
- What evidence would resolve it: A systematic study of FISC's performance with varying triplet loss margins, including a sensitivity analysis and recommendations for choosing α based on dataset characteristics.

## Limitations
- The privacy guarantees rely on style statistics being non-reconstructible, but no empirical attacks were conducted to validate this claim
- Performance improvements may depend heavily on specific domain split strategies that are not fully detailed
- FINCH clustering adds computational overhead that is not quantified in terms of training time or communication costs

## Confidence
- **High confidence**: The contrastive learning mechanism with style-transferred data effectively reduces local bias (supported by ablation studies and consistent performance gains across datasets)
- **Medium confidence**: The privacy preservation through style statistics (supported by citation to prior work but lacking direct empirical validation)
- **Medium confidence**: The FINCH clustering improves style representation quality (logical but not empirically compared to simpler alternatives)

## Next Checks
1. **Privacy robustness test**: Attempt to reconstruct original images from shared style statistics using GAN-based inversion attacks to validate privacy claims
2. **Ablation on style aggregation**: Compare FINCH clustering against simpler median aggregation to quantify the performance benefit
3. **Computation overhead measurement**: Profile the additional computational cost of FINCH clustering and style transfer during training to assess practical feasibility