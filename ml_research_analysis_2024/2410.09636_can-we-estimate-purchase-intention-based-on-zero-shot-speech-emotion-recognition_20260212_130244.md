---
ver: rpa2
title: Can We Estimate Purchase Intention Based on Zero-shot Speech Emotion Recognition?
arxiv_id: '2410.09636'
source_url: https://arxiv.org/abs/2410.09636
tags:
- emotion
- speech
- emotions
- proposed
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposed a zero-shot speech emotion recognition (SER)
  method capable of estimating bipolar emotions such as purchase intention. The method
  extends the contrastive language-audio pre-training (CLAP) framework with multi-class
  and multi-task settings, allowing flexible class definition through sentences.
---

# Can We Estimate Purchase Intention Based on Zero-shot Speech Emotion Recognition?

## Quick Facts
- arXiv ID: 2410.09636
- Source URL: https://arxiv.org/abs/2410.09636
- Reference count: 20
- The proposed zero-shot SER method achieved weighted and unweighted accuracy comparable to supervised baselines when estimating purchase intention.

## Executive Summary
This study proposes a zero-shot speech emotion recognition method that extends the contrastive language-audio pre-training (CLAP) framework with multi-class and multi-task settings. The method enables flexible emotion class definition through sentences rather than single words, allowing estimation of complex bipolar emotions like purchase intention that weren't explicitly trained. Experiments using Japanese speech data demonstrated that the proposed approach with GPT-4-based paraphrasing augmentation achieved performance comparable to supervised learning baselines for purchase intention estimation.

## Method Summary
The method extends CLAP by training on multiple emotion categories simultaneously, each with bipolar subcategories. During training, the model learns similarity matrices capturing semantic relationships between audio and text embeddings across emotions. Data augmentation is performed through GPT-4 paraphrasing to increase vocabulary diversity. For inference, the trained model estimates unknown bipolar emotions by leveraging the semantic understanding developed from the training emotions.

## Key Results
- Zero-shot estimation of purchase intention achieved weighted accuracy and unweighted accuracy comparable to supervised learning baselines
- GPT-4 paraphrasing augmentation (11x increase in training data) improved performance
- The method successfully estimated an emotion not present in the training data, demonstrating the feasibility of zero-shot estimation for unseen bipolar emotions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-class multi-task CLAP enables zero-shot estimation of bipolar emotions by learning semantic relationships across multiple emotion categories.
- Mechanism: The proposed method trains a CLAP model with multiple emotion classes, each having bipolar subcategories. During training, the model learns similarity matrices for each emotion, capturing semantic relationships between audio and text embeddings. This learned knowledge allows the model to estimate unknown bipolar emotions like purchase intention during the inference phase by leveraging the semantic understanding developed from the training emotions.
- Core assumption: The model can transfer semantic knowledge from seen multi-class emotions to unseen bipolar emotions through the contrastive learning framework.
- Evidence anchors:
  - [abstract]: "our proposed method expands upon the contrastive language-audio pre-training (CLAP) framework by introducing multi-class and multi-task settings"
  - [section]: "During the training phase, the model outputs the similarity matrix of the multi-class prepared for each emotion. After calculating the contrastive loss with the ground truth matrix in each emotion, we summarize and optimize them."
  - [corpus]: Weak evidence - no direct corpus citations discussing multi-task CLAP for bipolar emotions
- Break condition: If the semantic relationships between seen and unseen emotions are too dissimilar, the transfer learning may fail to accurately estimate unknown bipolar emotions.

### Mechanism 2
- Claim: Data augmentation through paraphrasing significantly improves zero-shot estimation performance by increasing vocabulary and grammatical diversity.
- Mechanism: The method uses GPT-4 to generate multiple paraphrased versions of emotion descriptions, creating 11 times more training data. This augmentation helps the model learn more robust semantic representations by exposing it to diverse linguistic expressions of the same emotions, making it better at recognizing semantic relationships between speech and text during zero-shot inference.
- Core assumption: Paraphrasing maintains the semantic content while varying linguistic expression, and this diversity helps the model generalize better to unseen emotions.
- Evidence anchors:
  - [abstract]: "We also focus on purchase intention as a bipolar emotion and experiment on whether the model trained by the proposed method can zero-shot estimate purchase intention."
  - [section]: "We extend the dataset by paraphrasing the text indicating the multi-class to increase the vocabulary and grammar of text associated with speech."
  - [corpus]: Weak evidence - no direct corpus citations discussing paraphrasing augmentation for SER
- Break condition: If paraphrasing introduces semantic drift or if the augmented data overwhelms the original training signal, performance may degrade.

### Mechanism 3
- Claim: The zero-shot estimation framework allows flexible definition of emotion classes using sentences rather than single words, enabling recognition of complex emotional concepts like purchase intention.
- Mechanism: Unlike conventional SER methods limited to single-word emotion definitions, the CLAP-based approach can define emotion classes using descriptive sentences.