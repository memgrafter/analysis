---
ver: rpa2
title: Contrastive Multiple Instance Learning for Weakly Supervised Person ReID
arxiv_id: '2402.07685'
source_url: https://arxiv.org/abs/2402.07685
tags:
- learning
- person
- dataset
- re-identification
- cmil
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Contrastive Multiple Instance Learning (CMIL),
  a novel framework for weakly supervised person re-identification (ReID) that requires
  only weak bag-level labels and no pseudo labels. The key innovation is applying
  contrastive learning at the bag level, optimizing for bag representations that are
  close for bags with the same identity and far for different identities.
---

# Contrastive Multiple Instance Learning for Weakly Supervised Person ReID

## Quick Facts
- **arXiv ID**: 2402.07685
- **Source URL**: https://arxiv.org/abs/2402.07685
- **Reference count**: 40
- **Primary result**: Introduces CMIL framework achieving 80.7% rank-1 accuracy on 50% noisy WL-Market1501 without pseudo labels

## Executive Summary
This paper introduces Contrastive Multiple Instance Learning (CMIL), a novel framework for weakly supervised person re-identification that requires only bag-level labels and no pseudo labels. The key innovation is applying contrastive learning at the bag level, optimizing for bag representations that are close for bags with the same identity and far for different identities. CMIL uses a feature extraction network to embed each image in a bag, then applies a permutation-invariant accumulation function to generate bag representations, and finally applies both identity and triplet losses. The method is evaluated on three datasets: WL-Market1501 (with synthetic noise), WL-MUDD (a real-world dataset of motorcycle racers), and SYSU-30k.

## Method Summary
CMIL processes bags of cropped person images where only bag-level identity labels are available. It uses a ResNet-50 feature extractor to embed individual crops, applies a permutation-invariant accumulation function (set transformer, average, max, or sum pooling) to generate bag representations, and optimizes using identity cross-entropy loss and triplet loss. The contrastive objective brings together bag representations of the same identity while pushing apart those of different identities. Training uses mini-bags sampled from full bags to create triplets for contrastive learning, with no pseudo-labeling required.

## Key Results
- Achieves 80.7% rank-1 accuracy on 50% noisy WL-Market1501, outperforming MIL-based baselines
- Maintains strong performance on real-world WL-MUDD dataset (73.2% rank-1) and SYSU-30k (33.9% rank-1)
- Average pooling performs nearly as well as complex set transformer accumulation, suggesting non-representative features may cancel out during aggregation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimizing bag representations directly using contrastive loss improves both bag-level and instance-level performance without explicit pseudo-labeling.
- Mechanism: By training the model to bring bag representations of the same identity closer and push apart those of different identities, the feature extractor learns to emphasize representative crops within each bag. This creates a "filtering" effect where the accumulation function naturally focuses on identity-consistent crops, even when noise is high.
- Core assumption: The most frequent identity in each bag corresponds to the bag label, and the accumulation function can effectively select these representative crops.

### Mechanism 2
- Claim: Average pooling performs surprisingly well as an accumulation function despite high bag noise, suggesting that non-representative features may cancel out during aggregation.
- Mechanism: When averaging crop representations within a bag, noisy (non-representative) crops with diverse features may produce vectors that, when averaged, result in a bag representation closer to the true identity features than expected. This "self-cancellation" effect reduces the need for complex selection mechanisms.
- Core assumption: Non-representative crops have sufficiently diverse features that their average cancels out, leaving a representation biased toward the representative identity.

### Mechanism 3
- Claim: The divergence between bag and instance representations during training is beneficial, as it indicates the model is learning to separate identity-relevant features from bag-level context.
- Mechanism: As training progresses, the model develops a distinction between instance-level features (useful for ReID) and bag-level features (useful for contrastive optimization). This separation allows the instance encoder to focus on identity-relevant patterns while the accumulation function handles bag-level optimization.
- Core assumption: Instance and bag representations serve different purposes and can be optimized independently without harming performance.

## Foundational Learning

- **Multiple Instance Learning (MIL)**: Framework for learning from bags with only bag-level labels rather than individual instance labels. Needed here because the weakly supervised setting provides only bag-level identity information.
  - Quick check: What is the fundamental difference between standard supervised learning and multiple instance learning in terms of label granularity?

- **Contrastive Learning**: Optimization framework that brings similar samples closer and pushes dissimilar samples apart in embedding space. Needed here because ReID is inherently a contrastive task - determining if two images contain the same person.
  - Quick check: How does the triplet loss formulation differ from standard classification loss in terms of what it optimizes?

- **Permutation Invariance**: Property requiring that functions produce the same output regardless of input order. Needed here because bags contain unordered sets of crops, so the accumulation function must be order-agnostic.
  - Quick check: Why can't we simply use a standard feedforward network as the accumulation function in this framework?

## Architecture Onboarding

- **Component map**: Feature extractor (ResNet-50) -> Accumulation function (set transformer/average/max/sum) -> Distance metric (cosine/Euclidean) -> Loss functions (identity + triplet)
- **Critical path**: 1) Crop extraction and embedding 2) Bag aggregation via accumulation function 3) Contrastive optimization at bag level 4) Cross-entropy classification for identity discrimination
- **Design tradeoffs**: Simple vs. complex accumulation (average pooling works surprisingly well but may fail with correlated noise); alignment loss intended to align instance and bag representations but empirically ineffective; batch size vs. bag size trade-off between sufficient bags per batch and sufficient crops per bag
- **Failure signatures**: Poor rank-1 accuracy despite good training loss (overfitting to bag-level patterns); alignment loss decreasing while accuracy improves (normal behavior); performance degradation with higher noise levels (expected but should be graceful)
- **First 3 experiments**: 1) Baseline with set transformer accumulation (establish reference performance) 2) Ablation with average pooling (test surprising effectiveness of simple aggregation) 3) Noise sensitivity analysis (vary synthetic noise levels on Market-1501 to understand robustness limits)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the alignment loss not improve model performance, and what underlying mechanisms explain the divergence between bag and crop representations during training?
- Basis in paper: The paper observes that alignment loss does not improve accuracy and that bag and crop representations diverge during training despite model performance improving.
- Why unresolved: The phenomenon is consistent across experiments but the underlying reasons for this behavior remain unclear.
- What evidence would resolve it: Further research into the relationship between bag and crop representations, possibly through visualization techniques or analysis of attention mechanisms, could provide insights.

### Open Question 2
- Question: How does the effectiveness of average pooling for instance aggregation compare to more complex methods in different weakly supervised learning scenarios?
- Basis in paper: The ablation study reveals that average pooling performs nearly as well as the set transformer for instance aggregation.
- Why unresolved: The paper suggests this might be due to non-representative crop features canceling each other out, but the generalizability of this finding to other scenarios is unknown.
- What evidence would resolve it: Testing average pooling against more complex methods across various weakly supervised learning tasks and datasets would provide more comprehensive insights.

### Open Question 3
- Question: How can CMIL be extended or modified to handle other forms of weak supervision beyond bag-level labels?
- Basis in paper: The paper focuses on bag-level labels but does not explore other forms of weak supervision that could be applicable to person re-identification.
- Why unresolved: The paper does not discuss potential extensions or modifications to handle different types of weak supervision.
- What evidence would resolve it: Developing and testing CMIL variants that can handle other forms of weak supervision, such as image-level labels or pseudo-labels, would demonstrate its adaptability and potential for broader application.

## Limitations
- The paper doesn't fully explain why average pooling performs comparably to more complex permutation-invariant functions, leaving a theoretical gap in understanding the mechanism.
- The effectiveness of CMIL with high noise levels (up to 50%) needs further validation on datasets with different noise characteristics.
- The claim that CMIL "nearly matches the state-of-the-art" is qualified by the fact that it operates under weaker supervision constraints.

## Confidence
- **High**: The core claim that CMIL enables effective ReID training without pseudo labels using only bag-level supervision.
- **Medium**: The effectiveness of average pooling as an accumulation function, though surprising results are shown.
- **Medium**: The assertion that CMIL performs well under high noise conditions, based on synthetic noise experiments.

## Next Checks
1. Test CMIL on datasets with naturally occurring noise rather than synthetic noise to verify real-world robustness.
2. Conduct ablation studies comparing CMIL with alternative MIL approaches that use pseudo-labeling to isolate the contribution of the contrastive framework.
3. Analyze feature embeddings to understand why average pooling works effectively despite theoretical expectations favoring more sophisticated methods.