---
ver: rpa2
title: In-Context Experience Replay Facilitates Safety Red-Teaming of Text-to-Image
  Diffusion Models
arxiv_id: '2411.16769'
source_url: https://arxiv.org/abs/2411.16769
tags:
- prompts
- prompt
- red-teaming
- safety
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of evaluating safety mechanisms
  in text-to-image models by proposing ICER, a novel red-teaming framework that leverages
  large language models and bandit optimization to systematically generate interpretable,
  semantic jailbreaking prompts by learning from past successful red-teaming attempts.
  ICER achieves superior performance compared to existing methods, identifying vulnerabilities
  in four different safe T2I models with failure rates up to 57.37% while maintaining
  high semantic similarity with original inputs.
---

# In-Context Experience Replay Facilitates Safety Red-Teaming of Text-to-Image Diffusion Models

## Quick Facts
- arXiv ID: 2411.16769
- Source URL: https://arxiv.org/abs/2411.16769
- Authors: Zhi-Yi Chin; Mario Fritz; Pin-Yu Chen; Wei-Chen Chiu
- Reference count: 35
- Primary result: ICER framework achieves up to 57.37% failure rates on safe T2I models while maintaining semantic similarity

## Executive Summary
This work introduces ICER, a novel red-teaming framework for evaluating safety mechanisms in text-to-image diffusion models. By leveraging large language models and bandit optimization, ICER systematically generates interpretable, semantic jailbreaking prompts through learning from past successful red-teaming attempts. The framework demonstrates superior performance compared to existing methods, identifying vulnerabilities in four different safe T2I models with failure rates up to 57.37% while maintaining high semantic similarity with original inputs. The key innovation lies in using experience replay through a dynamic exemplar database, enabling continuous improvement of attack effectiveness through Thompson Sampling-based exemplar selection.

## Method Summary
ICER addresses the challenge of evaluating safety mechanisms in text-to-image models by proposing a framework that combines LLM-based prompt generation with bandit optimization. The system maintains a database of prior jailbreaking experiences and uses Thompson Sampling to select exemplars that guide the LLM in generating new problematic prompts. The framework employs prompt dilution (upsampling) to bypass safety mechanisms while maintaining semantic consistency, using ImageBind embeddings to ensure similarity constraints. ICER was tested on the I2P dataset containing 854 nudity prompts and 723 violence prompts against four safe T2I models (ESD, SLD-MAX, Receler, AdvUnlearn), achieving significant improvements in red-teaming effectiveness.

## Key Results
- ICER achieves failure rates up to 57.37% on tested safe T2I models
- Outperforms existing methods including token-level attacks and other LLM-based approaches
- Successfully maintains semantic similarity (cosine similarity > 0.7) while bypassing safety mechanisms
- Demonstrates knowledge transfer capability, with successful jailbreaking instances systematically facilitating discovery of new vulnerabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Thompson Sampling-based exemplar selection enables efficient exploration-exploitation balance in red-teaming
- Mechanism: The bandit algorithm maintains Beta distributions for each exemplar, sampling probabilities to select the most promising past attempts while continuously updating based on success/failure feedback
- Core assumption: Past successful red-teaming attempts contain transferable patterns that can guide future attacks
- Evidence anchors: "leverages Large Language Models (LLMs) and a bandit optimization-based algorithm to generate interpretable and semantic meaningful problematic prompts by learning from past successful red-teaming attempts"

### Mechanism 2
- Claim: Experience replay through dynamic exemplar database enables continuous improvement of attack effectiveness
- Mechanism: Maintains a growing database of successful and unsuccessful attempts, using Thompson Sampling to adaptively select exemplars that guide LLM generation of new jailbreaking prompts
- Core assumption: Successful red-teaming attempts provide valuable information that can systematically improve future attacks
- Evidence anchors: "Successful attempts (or attempts that P ∗ q effectiveness score meets our criteria) are added to D, creating a growing knowledge base"

### Mechanism 3
- Claim: Prompt dilution (upsampling) technique effectively bypasses safety mechanisms while maintaining semantic consistency
- Mechanism: Extends concise problematic prompts with additional context and detail, making them more likely to bypass filters while preserving original intent
- Core assumption: Safety mechanisms are more easily bypassed by longer, more detailed prompts that appear more natural
- Evidence anchors: "Our exploration strategy revealed that prompt dilution (i.e. prompt upsampling) which extends initially unsuccessful prompts with additional context is proved particularly effective"

## Foundational Learning

- Concept: Thompson Sampling for bandit optimization
  - Why needed here: Balances exploration of new attack vectors with exploitation of proven patterns in the exemplar database
  - Quick check question: How does Thompson Sampling differ from epsilon-greedy in handling the exploration-exploitation tradeoff?

- Concept: In-context learning with LLMs
  - Why needed here: Enables the LLM to generate jailbreaking prompts without additional training, guided by exemplars from past experiences
  - Quick check question: What are the limitations of in-context learning for this red-teaming application?

- Concept: Semantic similarity evaluation using image embeddings
  - Why needed here: Ensures jailbreaking prompts maintain intended content while bypassing safety mechanisms
  - Quick check question: How does cosine similarity of image embeddings relate to human perception of semantic similarity?

## Architecture Onboarding

- Component map: Prior Database (D) -> Thompson Sampling Engine -> LLM Upsampler (F) -> Evaluation Pipeline -> Feedback Loop
- Critical path: Input prompt → Thompson Sampling → LLM generation → Semantic check → Safety evaluation → Database update
- Design tradeoffs:
  - Exemplar database size vs. sampling efficiency
  - Semantic similarity threshold vs. jailbreak success rate
  - Number of in-context exemplars (k) vs. LLM performance
  - Computational budget per prompt vs. overall effectiveness
- Failure signatures:
  - Low semantic similarity scores consistently
  - Beta distribution parameters converging to extreme values
  - LLM generation fails to produce coherent prompts
  - Experience database grows but effectiveness plateaus
- First 3 experiments:
  1. Test exemplar selection with synthetic data to verify Thompson Sampling behavior
  2. Evaluate LLM upsampling with known jailbreaking patterns to validate prompt generation
  3. Run end-to-end pipeline on a small subset of I2P data to measure initial effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can commercial T2I model APIs that return errors instead of generating unlearned concept images be effectively red-teamed using ICER?
- Basis in paper: "our ICER's current reward function in the bandit-optimization approach requires modification to handle commercial APIs that return errors instead of generating unlearned concept images when malicious input is detected"
- Why unresolved: The paper identifies this as a limitation but doesn't propose specific solutions for adapting the reward function to error-based feedback systems.

### Open Question 2
- Question: What are the specific semantic patterns or features that make certain jailbreaking prompts successful across different T2I safety mechanisms?
- Basis in paper: While the paper demonstrates effectiveness, analysis reveals no significant correlations between semantic similarity measures and success rates
- Why unresolved: The paper doesn't identify the underlying linguistic or semantic features that make prompts successful at bypassing safety mechanisms.

### Open Question 3
- Question: How can the knowledge transfer mechanism discovered in this work be leveraged to develop more robust T2I safety mechanisms?
- Basis in paper: "our work's ability to generate 'interpretable' jailbreaking prompts provides valuable insights into the relationship between models and their vulnerabilities"
- Why unresolved: The paper identifies this potential application but doesn't explore specific defensive strategies that could use these insights to strengthen safety mechanisms.

## Limitations
- The framework relies on a specific LLM (Zephyr-7B-α) and image embedding model (ImageBind), introducing potential limitations if these components behave differently in production environments
- Semantic similarity constraints, while maintaining visual coherence, may not fully capture human perception of content safety
- The paper demonstrates effectiveness on a curated dataset with specific safety models, but real-world deployment scenarios may present more diverse and nuanced challenges

## Confidence

**High Confidence**: ICER's ability to systematically improve red-teaming effectiveness through experience replay and bandit optimization

**Medium Confidence**: Claims about semantic similarity maintenance, as evaluation relies on automated metrics rather than human judgment

**Medium Confidence**: Generalizability to other safe T2I models beyond the four tested models

## Next Checks
1. Conduct human evaluation study to validate that semantically similar images maintain the same safety concerns as the original prompts
2. Test ICER against a broader range of safety mechanisms and T2I models not included in the original study
3. Evaluate whether safety mechanisms can learn from ICER's attack patterns over time, testing effectiveness against adaptive safety defenses