---
ver: rpa2
title: 'Modelled Multivariate Overlap: A method for measuring vowel merger'
arxiv_id: '2406.16319'
source_url: https://arxiv.org/abs/2406.16319
tags:
- overlap
- vowel
- merger
- distributions
- multivariate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a new method for quantifying vowel overlap
  called Modelled Multivariate Overlap (MMO). MMO uses Bayesian linear mixed-effects
  models to jointly model multiple acoustic dimensions (e.g., F1 and F2) and simulate
  distributions from the model to compute measures of vowel overlap.
---

# Modelled Multivariate Overlap: A method for measuring vowel merger

## Quick Facts
- arXiv ID: 2406.16319
- Source URL: https://arxiv.org/abs/2406.16319
- Reference count: 0
- Primary result: Modelled Multivariate Overlap (MMO) improves vowel overlap measurement using Bayesian models and simulated distributions

## Executive Summary
This paper introduces Modelled Multivariate Overlap (MMO), a novel method for quantifying vowel merger by using Bayesian linear mixed-effects models to jointly model multiple acoustic dimensions. MMO addresses the challenge of measuring vowel overlap while controlling for unbalanced data and extraneous factors. The method is evaluated on corpus speech data targeting the PIN-PEN merger across four English dialects, demonstrating that using modelled distributions substantially improves overlap measurement compared to empirical distributions. An additional benefit is the straightforward computation of uncertainty in overlap measures.

## Method Summary
MMO uses Bayesian linear mixed-effects models to jointly model F1 and F2 as functions of vowel category, context (nasal/oral), and other predictors, with speaker and word as random effects. The method simulates distributions from the model posterior predictive distribution for each vowel-context pair, then calculates overlap measures like Bhattacharyya affinity from these modelled distributions. This approach allows for proper conditioning on the model structure and data while accounting for correlations between formants and controlling for confounding factors.

## Key Results
- Using modelled distributions to calculate Bhattacharyya affinity substantially improves overlap measurement compared to empirical distributions
- The difference between multivariate and univariate modelling is subtle in the PIN-PEN merger case studied
- MMO provides easy computation of uncertainty through posterior predictive distributions
- All models showed speakers falling into predicted patterns to a much larger degree than empirical distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simulating distributions from the fitted Bayesian model improves vowel overlap measurement accuracy compared to using empirical distributions
- Mechanism: The Bayesian model jointly fits F1 and F2 as a function of vowel category, context, and other predictors. This joint modelling allows the model to account for correlations between formants and control for confounding factors. By simulating from the posterior predictive distribution, we can generate theoretical distributions for each vowel-context pair that are properly conditioned on the model structure and data.
- Core assumption: The Bayesian linear mixed-effects model accurately captures the underlying structure of the vowel data, including the relationships between F1, F2, and the predictors.
- Evidence anchors: [abstract] "We evaluate this method on corpus speech data targeting the PIN-PEN merger in four dialects of English and find that using modelled distributions to calculate Bhattacharyya affinity substantially improves results compared to empirical distributions"; [section 4.2] "The most striking result from Figure 4 is the contrast between the modelled estimates and the empirically-derived ones. All models show speakers falling into the predicted patterns to a much larger degree than the empirical distributions do."

### Mechanism 2
- Claim: Multivariate modelling of F1 and F2 provides better vowel overlap estimates than univariate modelling
- Mechanism: By jointly modelling F1 and F2, the model can capture the correlation between these two formants. This allows for more accurate estimation of the joint distribution of vowel categories in F1-F2 space, which is critical for calculating overlap measures like Bhattacharyya affinity that depend on the shape of the distributions.
- Core assumption: The correlation between F1 and F2 is meaningful and should be preserved in the modelling process.
- Evidence anchors: [section 4.1.2] "To assess the importance of multivariate modelling, both a multivariate and two univariate models (one for F1 and one for F2) were fit for each of the two model structures described above."; [section 4.2] "In Figure 4, there is almost no difference between the multivariate and univariate modelled results, hence the choice to exclude the univariate models from other figures."

### Mechanism 3
- Claim: Using Bayesian modelling allows for easy computation of uncertainty in vowel overlap measures
- Mechanism: Bayesian models produce posterior distributions over model parameters, which can be propagated through to the posterior predictive distributions. By simulating multiple draws from these posterior predictive distributions, we can generate a distribution of overlap measures for each vowel-context pair, providing a natural measure of uncertainty.
- Core assumption: The posterior distributions from the Bayesian model are representative of the true uncertainty in the model parameters.
- Evidence anchors: [abstract] "An additional benefit of this method is that computation of uncertainty becomes straightforward."; [section 3] "While MMO is agnostic to the overlap measure calculated from it, it is important to consider the assumptions of the statistical model relative to the assumptions of this measure."

## Foundational Learning

- Concept: Bayesian linear mixed-effects models
  - Why needed here: To jointly model F1 and F2 while accounting for the hierarchical structure of the data (e.g., speakers, words) and to obtain posterior predictive distributions for uncertainty quantification.
  - Quick check question: What is the key difference between a Bayesian linear mixed-effects model and a frequentist one, and how does this difference enable uncertainty quantification in MMO?

- Concept: Bhattacharyya affinity
  - Why needed here: To measure the overlap between vowel distributions in F1-F2 space, which is the primary goal of MMO.
  - Quick check question: How does Bhattacharyya affinity differ from Euclidean distance in measuring vowel overlap, and why is it preferred in this context?

- Concept: Vowel normalization
  - Why needed here: To make F1 and F2 measurements comparable across speakers, controlling for anatomical differences while preserving linguistically relevant variation.
  - Quick check question: Why is vowel normalization necessary before applying MMO, and what would happen if it were skipped?

## Architecture Onboarding

- Component map: Data preprocessing (normalization and filtering) -> Model fitting (Bayesian linear mixed-effects models) -> Posterior predictive simulation -> Overlap measure calculation
- Critical path: The critical path is preprocessing -> model fitting -> simulation -> overlap calculation. Each step must be completed before the next can begin, and errors in early steps can propagate to later ones.
- Design tradeoffs: The main tradeoff is between model complexity and computational efficiency. More complex models may better capture the data structure but will be slower to fit and simulate from. The choice of overlap measure (e.g., Bhattacharyya affinity vs. Euclidean distance) also involves tradeoffs between interpretability and assumptions about the data.
- Failure signatures: Poor model fit (e.g., residuals showing patterns), convergence issues during model fitting, or simulations that don't match the observed data distributions could indicate problems with the method. In these cases, the overlap measures may be unreliable.
- First 3 experiments:
  1. Fit the minimal model to a subset of the data and check the posterior predictive distributions against the observed data to assess model fit.
  2. Simulate from the fitted model and calculate Bhattacharyya affinity for a single speaker to verify the simulation and overlap calculation steps.
  3. Compare the overlap measures from the modelled distributions to those from the empirical distributions for a small set of speakers to see the impact of the modelling step.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions does multivariate modeling of vowel distributions provide significantly better results than univariate modeling?
- Basis in paper: [inferred] The authors found no discernible improvement between multivariate and univariate modeling for the PIN-PEN merger case, but note this might differ for other mergers with substantial between-category differences in both F1 and F2 (e.g., COT-CAUGHT).
- Why unresolved: The study only examined one specific merger case (PIN-PEN), which may not be representative of all merger types. Different mergers may have different acoustic characteristics that could make multivariate modeling more or less beneficial.
- What evidence would resolve it: Comparative studies applying MMO to multiple merger types with varying degrees of F1 and F2 differences, systematically evaluating when multivariate modeling provides meaningful advantages over univariate approaches.

### Open Question 2
- Question: How does the choice of vowel overlap measure (e.g., Bhattacharyya affinity vs. Euclidean distance vs. Pillai scores) interact with the model structure in MMO?
- Basis in paper: [explicit] The authors note that "it is important to consider the assumptions of the statistical model relative to the assumptions of this measure" and that "Pillai scores should only be used if the model is structured such that the simulated distributions are (roughly) normally distributed with equal variance."
- Why unresolved: The paper demonstrates MMO using Bhattacharyya affinity and briefly mentions other measures, but does not systematically explore how different measures interact with various model structures or how this affects results.
- What evidence would resolve it: Empirical studies applying MMO with different overlap measures across various model structures and merger types, evaluating the sensitivity and appropriateness of each measure-model combination.

### Open Question 3
- Question: What is the optimal balance between model complexity and computational efficiency for MMO applications?
- Basis in paper: [inferred] The authors compare minimal and expanded models, finding subtle differences, and note that multivariate modeling requires more computational resources while offering no discernible improvement for the PIN-PEN case studied.
- Why unresolved: The study provides a comparison of two model structures but does not explore the full parameter space of possible model configurations or establish clear criteria for when additional complexity is justified by improved results.
- What evidence would resolve it: Systematic evaluation of MMO performance across a range of model complexities, varying random effects structures, control variables, and distributional assumptions, with quantitative metrics for both statistical performance and computational cost.

## Limitations
- The difference between multivariate and univariate modelling is subtle, raising questions about whether added complexity is always justified
- The method relies heavily on the assumption that the Bayesian linear mixed-effects model adequately captures the underlying structure of vowel data
- The paper does not explore how the method performs with different types of vowel mergers or in languages with different phonological systems

## Confidence
- High confidence in the mechanism by which Bayesian modelling improves overlap measurement compared to empirical distributions (supported by substantial empirical evidence)
- Medium confidence in the necessity of multivariate over univariate modelling (evidence shows little difference in this specific case)
- Medium confidence in the uncertainty quantification (methodologically sound but not extensively validated)

## Next Checks
1. Test MMO on a vowel merger where F1 and F2 are known to be more strongly correlated to determine if multivariate modelling provides clearer benefits
2. Compare MMO results with traditional visual overlap assessment by phoneticians to validate the quantitative measures
3. Evaluate how sensitive MMO results are to different prior specifications in the Bayesian models to assess robustness