---
ver: rpa2
title: When does compositional structure yield compositional generalization? A kernel
  theory
arxiv_id: '2405.16391'
source_url: https://arxiv.org/abs/2405.16391
tags:
- generalization
- compositional
- training
- networks
- kernel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates compositional generalization in neural
  networks by analyzing kernel models with compositionally structured representations.
  The authors show that such models are fundamentally limited to "conjunction-wise
  additive" computations, meaning they can only learn tasks expressible as sums of
  values assigned to each component combination seen during training.
---

# When does compositional structure yield compositional generalization? A kernel theory

## Quick Facts
- **arXiv ID:** 2405.16391
- **Source URL:** https://arxiv.org/abs/2405.16391
- **Reference count:** 40
- **Primary result:** Kernel models with compositionally structured representations are fundamentally limited to "conjunction-wise additive" computations, constraining their compositional generalization ability

## Executive Summary
This paper investigates when compositional structure enables compositional generalization in neural networks by analyzing kernel models with compositionally structured representations. The authors show that such models are fundamentally limited to "conjunction-wise additive" computations, meaning they can only learn tasks expressible as sums of values assigned to each component combination seen during training. Through theoretical analysis, they identify two key failure modes: "memorization leak" where models partially rely on full conjunctions during training, distorting test generalization, and "shortcut bias" where spurious correlations lead models to exploit simpler statistical patterns instead of true compositional rules. The theory is validated on deep networks trained on MNIST and CIFAR versions of symbolic addition and context dependence tasks.

## Method Summary
The paper develops a kernel theory framework for analyzing compositional generalization, focusing on models with compositionally structured representations where the kernel depends only on component overlap between inputs. They theoretically characterize the class of "conjunction-wise additive" functions that these models can learn, then analyze two failure modes (memorization leak and shortcut bias) under specific training data assumptions. The theory is validated empirically using deep networks (ConvNets, ResNets, Vision Transformers) trained on synthetic MNIST and CIFAR tasks involving symbolic addition and context dependence with controlled compositional splits.

## Key Results
- Kernel models with compositionally structured representations are fundamentally limited to conjunction-wise additive computations
- Memorization leak causes proportional distortion of test generalization in symbolic addition tasks when models partially rely on full conjunctions
- Shortcut bias causes systematic failure on context dependence tasks when spurious correlations lead models to exploit context instead of compositional rules

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Compositionally structured kernel models are fundamentally constrained to "conjunction-wise additive" computations
- **Mechanism:** These models can only generalize by summing values assigned to each component combination seen during training, limiting them to tasks expressible as such sums
- **Core assumption:** The input representation's kernel K(x,x') only depends on the number of identical components between inputs
- **Evidence anchors:**
  - [abstract]: "kernel models with compositionally structured representations... limited to 'conjunction-wise additive' computations"
  - [section]: "Theorem 4.2. For any kernel model f with a compositionally structured representation, we can find conjunction-wise functions..."
  - [corpus]: Weak evidence - only 1/8 papers directly address kernel methods and compositional structure
- **Break condition:** When the learning mechanism enables feature abstraction beyond kernel limitations (e.g., deep networks in feature-learning regime)

### Mechanism 2
- **Claim:** Memorization leak causes proportional distortion of test generalization in symbolic addition tasks
- **Mechanism:** ℓ2-norm minimization during training causes models to partially rely on full conjunctions even for test inputs, distorting predictions by a proportional factor
- **Core assumption:** The training data contains all pairs where at least one component is from a specific subset W
- **Evidence anchors:**
  - [section]: "Proposition 5.1... model behavior on the test set is given by f([v1],[v2]) = m(v1+v2)"
  - [section]: "We call the tendency to use the full conjunction... 'memorization leak'"
  - [corpus]: Weak evidence - only tangentially related to memorization effects in compositional tasks
- **Break condition:** When training data is structured to eliminate conjunction usage or when using architectures that don't minimize ℓ2-norm

### Mechanism 3
- **Claim:** Shortcut bias causes systematic failure on context dependence tasks with strong spurious correlations
- **Mechanism:** Models exploit simpler statistical patterns (e.g., context predicting target) instead of true compositional rules, using full conjunctions to learn remaining training data
- **Core assumption:** Context is highly correlated with target in training data but not test data
- **Evidence anchors:**
  - [section]: "Models with high S(1;3) (context) and S(3;3) (full conjunction) exploit this context shortcut"
  - [section]: "This strategy explains why these models fail to generalize to the test set"
  - [corpus]: Weak evidence - only 1/8 papers mention shortcut learning in compositional contexts
- **Break condition:** When training data eliminates spurious correlations or when representational geometry prevents shortcut exploitation

## Foundational Learning

- **Concept: Kernel methods and dual representation**
  - Why needed here: Understanding how kernel models express functions as weighted sums over training data is fundamental to grasping conjunction-wise additivity
  - Quick check question: How does a kernel model's prediction on a test point relate to its training data through the kernel matrix?

- **Concept: Representational geometry and salience metrics**
  - Why needed here: The salience metric quantifies how strongly different component conjunctions are represented, determining which conjunctions the model can use
  - Quick check question: Why does the salience metric normalize so that all saliences sum to one?

- **Concept: ℓ2-norm minimization and inductive bias**
  - Why needed here: Understanding how gradient descent with ℓ2-regularization biases models toward distributed weights explains both memorization leak and shortcut bias
  - Quick check question: How does ℓ2-norm minimization affect the magnitude of weights assigned to conjunctions versus individual components?

## Architecture Onboarding

- **Component map:** Input → Kernel similarity → Dual coefficient learning → Test prediction via kernel expansion
- **Critical path:** Input → Kernel similarity → Dual coefficients → Weighted sum of training kernel evaluations
- **Design tradeoffs:**
  - Shallow vs deep networks: Deeper networks tend toward more conjunctive representations (S(C;C)→1), reducing generalization
  - Kernel choice: Gaussian vs ReLU affects how quickly salience shifts toward full conjunctions
  - Training set size: Larger sets increase conjunction salience, exacerbating memorization leak
- **Failure signatures:**
  - Memorization leak: Linear compression of test predictions relative to ground truth
  - Shortcut bias: Perfect training accuracy but systematic test failure correlated with spurious patterns
  - Conjunction-wise additivity violation: Poor fit when testing if predictions follow conjunction-wise additive form
- **First 3 experiments:**
  1. Train kernel model on symbolic addition with varying training set sizes (W = {0}, {-4,4}, {-2,2}) and measure test generalization slopes
  2. Vary representational salience S(1;2) by changing distance between concatenated MNIST digits and observe effect on memorization leak
  3. Test context dependence generalization (CD-1, CD-2, CD-3) with different network nonlinearities to probe shortcut bias sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what precise conditions do randomly sampled representations (not exactly compositionally structured) exhibit conjunction-wise additive behavior in expectation?
- Basis in paper: [explicit] Proposition A.2 proves that random Gaussian representations are conjunction-wise additive in expectation, but the paper notes this is limited to specific random sampling assumptions
- Why unresolved: The proof only covers one specific type of random representation (Gaussian vectors for each conjunction), and the paper acknowledges that representations in practice will often deviate from compositional structure in complex ways not captured by this model
- What evidence would resolve it: Mathematical characterization of conjunction-wise additivity for a broader class of random representations (e.g., different distributions, correlations between components) or empirical validation across diverse representation learning methods

### Open Question 2
- Question: Can the theory be extended to provide quantitative bounds on generalization performance for deep networks, not just qualitative predictions?
- Basis in paper: [inferred] The paper shows that kernel theory provides qualitative insights into deep network behavior (e.g., predicting direction of generalization changes) but notes it cannot provide exact quantitative predictions, particularly because networks move out of the kernel regime during training
- Why unresolved: While the theory captures general trends (e.g., deeper networks generalize worse on symbolic addition), the relationship between representational salience and performance is not quantitatively precise, suggesting missing theoretical components
- What evidence would resolve it: A mathematical framework that incorporates feature learning dynamics and can predict exact generalization slopes or accuracy values from network architecture and training data characteristics

### Open Question 3
- Question: What learning mechanisms beyond kernel models can enable non-conjunction-wise additive compositional generalization, and how do they interact with dataset statistics?
- Basis in paper: [explicit] Section 6 mentions that feature learning mechanisms can overcome kernel model limitations, and Appendix F shows rich ReLU networks can generalize on transitive equivalence, but the paper calls for further investigation into these mechanisms
- Why unresolved: While the paper demonstrates that rich networks can abstract and generalize on tasks like transitive equivalence, it does not provide a general theory of which mechanisms enable which types of compositional generalization or how to design architectures for specific non-additive tasks
- What evidence would resolve it: A systematic characterization of learning mechanisms (e.g., sparse feature learning, attention, meta-learning) that can implement different compositional computations, with empirical validation showing their effectiveness on non-additive benchmark tasks designed based on the theory

## Limitations
- The theory assumes perfect component alignment and ignores feature learning capacity, limiting real-world applicability
- Empirical validation relies on synthetic MNIST/CIFAR tasks that may not capture the complexity of natural compositional reasoning
- Connection between kernel-based limitations and deep network behavior depends on assumptions about representational geometry that may not hold in practice

## Confidence
- High confidence: The mathematical framework for conjunction-wise additive computations and the proof that kernel models are fundamentally limited to this class
- Medium confidence: The theoretical predictions about memorization leak and shortcut bias, as these depend on specific ℓ2-norm minimization assumptions
- Medium confidence: The empirical validation on deep networks, though results are consistent with theory, the synthetic tasks limit generalizability

## Next Checks
1. Test the theory on a more naturalistic compositional task (e.g., visual question answering with relational concepts) to assess real-world applicability
2. Implement ablation studies varying the representational salience metric S(C;C) through architectural modifications (e.g., attention mechanisms) to confirm the predicted relationship with generalization
3. Conduct systematic experiments with different kernel types (beyond Gaussian and ReLU) to determine whether the limitations are kernel-specific or fundamental to compositionally structured representations