---
ver: rpa2
title: Why Does the Effective Context Length of LLMs Fall Short?
arxiv_id: '2410.18745'
source_url: https://arxiv.org/abs/2410.18745
tags:
- context
- length
- position
- training
- llama
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The effective context length of large language models often falls\
  \ short of their training lengths due to a left-skewed frequency distribution of\
  \ relative positions formed during pretraining and post-training stages. This limits\
  \ the model\u2019s ability to gather distant information effectively."
---

# Why Does the Effective Context Length of LLMs Fall Short?

## Quick Facts
- arXiv ID: 2410.18745
- Source URL: https://arxiv.org/abs/2410.18745
- Authors: Chenxin An; Jun Zhang; Ming Zhong; Lei Li; Shansan Gong; Yao Luo; Jingjing Xu; Lingpeng Kong
- Reference count: 40
- Key outcome: The effective context length of LLMs often falls short of their training lengths due to left-skewed position frequency distributions

## Executive Summary
This paper identifies why large language models' effective context length often falls short of their training lengths. The core issue stems from a left-skewed frequency distribution of relative positions formed during pretraining, where high-position indices appear rarely in training data. To address this, the authors introduce ShifTed Rotray position embeddING (STRING), which shifts well-trained positions to overwrite ineffective ones during inference, enabling models to represent long-range dependencies using frequently encountered position indices. STRING achieves over 10-point improvements on long-context benchmarks without additional training and sets new state-of-the-art results for open-source LLMs.

## Method Summary
STRING is a training-free method that modifies position indices used in Rotary Position Embedding (RoPE) during inference. It shifts position indices from the main diagonal toward the bottom-left corner of the attention matrix, allowing models to use frequently encountered position indices to represent long-range dependencies. The method is implemented using FlashAttention by combining sliding window attention around the main diagonal with self-attention at the bottom-left triangle using shifted position indices. A small local window value W preserves local relationships while enabling long-range modeling. The optimal configuration uses S = L/3 (shift offset) and W = 128 (local window).

## Key Results
- STRING improves performance on long-context benchmarks like RULER and InfiniteBench by over 10 points without additional training
- Achieves new state-of-the-art results for open-source LLMs, surpassing commercial models like GPT-4-128K and Claude-2
- Demonstrates that underrepresented position indices strongly constrain the long-context capabilities of current LLMs
- Shows systematic performance degradation on Needle-in-a-Haystack tasks beyond 2K tokens, even in models with 128K training length

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Left-skewed position frequency distribution during pretraining causes ineffective long-range modeling
- Mechanism: The model is undertrained on high-position indices due to data length distribution and the structure of the relative position matrix P. Positions at the tail of the frequency distribution (high i values) appear very rarely during training, making the model unable to effectively gather information from distant inputs.
- Core assumption: Position frequency during pretraining directly correlates with the model's ability to use those positions effectively during inference
- Evidence anchors:
  - [abstract] "The effective context length of large language models often falls short of their training lengths due to a left-skewed frequency distribution of relative positions formed during pretraining and post-training stages"
  - [section] "In SlimPajama-627B... the frequency of position indices used to model relationships between distant tokens (distances ≥ 1024) is less than 20%, and for even longer distances (≥ 1536), it drops below 5%"
  - [corpus] Weak - corpus neighbors don't directly address position frequency distribution, but LaMPE and Long-Short Alignment papers suggest similar long-context modeling limitations
- Break condition: If position frequency distribution becomes uniform or right-skewed during pretraining, the effective context length would match or exceed the training length

### Mechanism 2
- Claim: STRING improves long-context performance by shifting well-trained positions to replace ineffective ones
- Mechanism: STRING modifies the position matrix P by shifting position indices from the main diagonal toward the bottom-left corner, allowing the model to use frequently encountered position indices to represent long-range dependencies. This avoids using the undertrained positions at the tail of the frequency distribution.
- Core assumption: The model can effectively use well-trained positions to approximate the behavior of undertrained positions when their relative distances are preserved
- Evidence anchors:
  - [abstract] "STRING shifts well-trained positions to overwrite the original ineffective positions during inference, enhancing performance within their existing training lengths"
  - [section] "STRING shifts position indices from the diagonal of P towards its bottom-left corner, allowing the model to gather distant information with frequent position indices"
  - [corpus] Moderate - LongRoPE paper shows similar position remapping approaches for extending context, though focused on extrapolation rather than training-free improvement
- Break condition: If the model's representation of relative distances becomes too distorted by the shift, or if the shifted positions cannot effectively approximate the undertrained positions' behavior

### Mechanism 3
- Claim: STRING preserves local relationships through a small window value while enabling long-range modeling
- Mechanism: After shifting position indices, STRING adds a small local window value W to elements where m ≥ n - S, ensuring that neighboring tokens remain the closest in terms of positional encoding. This maintains the model's ability to generate fluent content while improving long-range capabilities.
- Core assumption: Local relationships are crucial for generating fluent content, and preserving them is necessary even when improving long-range modeling
- Evidence anchors:
  - [section] "We introduce a small local window value W ≪ S for elements where m ≥ n - S, as illustrated in Figure 5c. This adjustment maintains emphasis on the closest W neighboring tokens"
  - [section] "Specifically, the relative positions on the S-th diagonal are set to zero. Since neighboring tokens are crucial for generating fluent content, we introduce a small local window value W ≪ S"
  - [corpus] Weak - corpus neighbors don't directly address local relationship preservation, but LaMPE mentions "multi-grained" approaches that may include similar considerations
- Break condition: If W is set too large, it interferes with the shifted positions; if W is too small, local relationships degrade significantly

## Foundational Learning

- Concept: Relative position matrix P and its frequency distribution
  - Why needed here: Understanding how P is constructed and how position frequencies are calculated is fundamental to grasping why certain positions are undertrained and how STRING manipulates them
  - Quick check question: Given a training length L=4096, what is the frequency of position index 3000? (Answer: 4096 - 3000 = 1096 occurrences)

- Concept: Rotary Position Embedding (RoPE) and its limitations
  - Why needed here: STRING modifies the position indices used in RoPE, so understanding how RoPE injects positional information is crucial for implementing STRING correctly
  - Quick check question: In RoPE, what is the key property that allows relative position information to be encoded in the inner product? (Answer: The inner product q_i^T k_j contains only relative positional information (i - j))

- Concept: FlashAttention implementation and attention patterns
  - Why needed here: STRING is implemented using FlashAttention by splitting attention into sliding window attention and shifted self-attention, so understanding this implementation is necessary for practical application
  - Quick check question: In the STRING implementation, which component handles the bottom-left triangle of the attention matrix? (Answer: The shifted self-attention component with modified position indices for queries)

## Architecture Onboarding

- Component map: Input layer -> Position index generation -> RoPE position embedding -> STRING position index modification -> FlashAttention (sliding window + shifted) -> Output layer
- Critical path:
  1. Generate standard position indices [0, 1, 2, ..., L-1]
  2. Apply STRING shift: subtract S from indices where m >= n - S
  3. Add local window W to the shifted indices
  4. Apply RoPE to modified indices
  5. Compute attention using modified positions
- Design tradeoffs:
  - Larger S (shift offset) discards more positions but provides better long-range modeling
  - Smaller W (local window) preserves more shifted positions but may degrade local relationships
  - The sweet spot is S = L/3 and W = 128, which balances these competing concerns
- Failure signatures:
  - Performance degradation on tasks requiring very local relationships (W too small)
  - Inability to improve long-context performance beyond a certain threshold (S too small)
  - Inconsistent behavior across different model scales (implementation issues)
- First 3 experiments:
  1. Implement STRING with S = L/3 and W = 128 on a small model (e.g., TinyLlama-1.3B) and verify performance improvement on Needle-in-a-Haystack task
  2. Ablation study: Vary W from 4 to 512 while keeping S fixed to find optimal local window size
  3. Ablation study: Vary S from L/5 to L/2 while keeping W fixed to find optimal shift offset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the minimum local window size W that ensures effective performance across different model sizes and training lengths?
- Basis in paper: [explicit] The ablation study shows that W ≥ 32 provides significant improvement over RoPE, and further increasing W does not cause performance drops as long as W ≪ S.
- Why unresolved: The paper tests W values from 4 to 512, but the optimal value may depend on model architecture and training data characteristics.
- What evidence would resolve it: Systematic testing across diverse model architectures and training configurations to establish a universal threshold or architecture-dependent formula for W.

### Open Question 2
- Question: How does STRING's effectiveness vary with different data distribution characteristics during pretraining?
- Basis in paper: [inferred] The paper demonstrates STRING's effectiveness but doesn't explore how different pretraining data distributions (e.g., varying sequence length distributions or domain characteristics) affect its performance.
- Why unresolved: The pretraining data distribution is identified as a key factor affecting position frequency, but STRING's performance across different distributions isn't thoroughly evaluated.
- What evidence would resolve it: Comparative studies of STRING's performance across multiple pretraining datasets with varying sequence length distributions and domain characteristics.

### Open Question 3
- Question: What is the theoretical limit of STRING's position index overwriting capability?
- Basis in paper: [explicit] The ablation study shows performance increases with S up to L/2, with S = L/3 being the suggested default.
- Why unresolved: The paper demonstrates effectiveness up to L/2 but doesn't explore whether this limit is fundamental or if further improvements are possible with different approaches.
- What evidence would resolve it: Experiments testing STRING with S values approaching L and exploration of alternative position index manipulation strategies beyond simple shifting.

## Limitations

- The position frequency analysis is primarily based on the SlimPajama-627B dataset, with limited validation across diverse training corpora
- The causal relationship between frequency distribution and model capability could benefit from additional ablation studies
- The universality of STRING's effectiveness across all model architectures and training paradigms is not fully established

## Confidence

**High Confidence**: The observation that effective context length falls short of training length is well-supported by extensive empirical evidence across multiple benchmarks (NIAH, RULER, InfiniteBench).

**Medium Confidence**: The proposed mechanism explaining why position frequency distributions create this limitation is logically sound and supported by frequency analysis, but the causal relationship could benefit from additional ablation studies.

**Low Confidence**: The universality of STRING's effectiveness across all model architectures and training paradigms is not fully established.

## Next Checks

1. **Cross-Corpus Validation**: Replicate the position frequency analysis on diverse training datasets (including multilingual and specialized domain corpora) to verify whether left-skewed distributions are a universal phenomenon or dataset-dependent.

2. **Edge Case Analysis**: Systematically evaluate STRING on tasks that specifically stress local relationships (e.g., syntactic parsing, code generation) to identify potential failure modes where the shifted positions interfere with local context modeling.

3. **Ablation on Position Index Distribution**: Train a model with deliberately uniform position frequency distribution (through data augmentation or curriculum learning) and compare its effective context length against standard training.