---
ver: rpa2
title: A logic for reasoning with inconsistent knowledge -- A reformulation using
  nowadays terminology (2024)
arxiv_id: '2411.10197'
source_url: https://arxiv.org/abs/2411.10197
tags:
- premisses
- logic
- prem
- reliability
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a logic for reasoning with inconsistent knowledge
  using a reliability relation to resolve contradictions. The approach is based on
  viewing premises as assumptions rather than absolute truths, allowing useful conclusions
  to be drawn even from inconsistent sets of premises.
---

# A logic for reasoning with inconsistent knowledge -- A reformulation using nowadays terminology (2024)

## Quick Facts
- arXiv ID: 2411.10197
- Source URL: https://arxiv.org/abs/2411.10197
- Authors: Nico Roos
- Reference count: 25
- Introduces a logic for reasoning with inconsistent knowledge using a reliability relation to resolve contradictions

## Executive Summary
This paper presents a logic for reasoning with inconsistent knowledge by introducing a reliability relation on premises to determine which premises to remove when contradictions arise. The approach views premises as assumptions rather than absolute truths, enabling useful conclusions to be drawn even from inconsistent sets. A key innovation is the use of a partial reliability relation on premises, where contradictions are resolved by removing the least reliable premise among those involved in the inconsistency.

The logic is shown to be equivalent to preferential logic (System P) with corresponding preferential semantics, demonstrated through representation theorems connecting it to the general framework for non-monotonic logics described by Kraus et al. The approach supports argumentation-based deduction through supporting and undermining arguments, and has applications in domains dealing with unreliable knowledge sources such as sensor data processing and planning under uncertainty.

## Method Summary
The logic uses a reliability theory ⟨Σ,≺⟩ where Σ is a finite set of premises and ≺ is a partial reliability relation on Σ. When contradictions arise, the system identifies all premises involved in the derivation and removes the premise with minimal reliability according to ≺. This is implemented through undermining arguments that specify which premise must be withdrawn. The belief set is computed as the intersection of belief sets derived from all linear extensions of ≺, establishing the connection to System P and preferential semantics. The logic also supports argumentation-based deduction where supporting arguments P⇒φ are derived when premises P logically entail proposition φ, and undermining arguments P̸⇒φ are created when contradictions occur.

## Key Results
- The logic resolves contradictions by removing the least reliable premise among those causing inconsistency
- The logic is equivalent to System P with preferential semantics
- The logic supports argumentation-based deduction through supporting and undermining arguments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The logic resolves contradictions by removing the least reliable premise among those that cause inconsistency
- Mechanism: When a contradiction is derived from a set of premises Σ, the system identifies all premises involved in the derivation, then removes the premise with minimal reliability according to the partial order ≺. This is implemented via undermining arguments that specify which premise must be withdrawn.
- Core assumption: The reliability relation ≺ is well-defined (irreflexive, asymmetric, transitive) and can be extended to a linear order when needed for deduction.
- Evidence anchors:
  - [abstract] "A key innovation is the use of a partial reliability relation on premises to determine which premises to remove when contradictions arise."
  - [section] "Using the reliability relation, we have to remove a least preferred premise of the inconsistent set, thereby blocking the derivation of the contradiction."
- Break condition: If the reliability relation is cyclic or if there are multiple incomparable minimal premises, the system must consider all linear extensions, potentially leading to exponential growth in belief sets.

### Mechanism 2
- Claim: The logic is equivalent to a preferential non-monotonic logic (System P) with corresponding semantics
- Mechanism: The set of theorems Th(⟨Σ,≺⟩) is defined as the intersection of belief sets B∞ derived from all linear extensions of ≺. This matches the preferential semantics where models are ordered by a preference relation ⊏ based on which interpretations satisfy more reliable premises.
- Core assumption: The preference relation on interpretations defined from ≺ satisfies the properties required for a preferential model (irreflexive, transitive, smooth).
- Evidence anchors:
  - [abstract] "The logic is shown to be a preferential logic (system P) with a corresponding preferential semantics."
  - [section] "It turns out that the semantics for the logic is a preferential semantics according to the definition S. Kraus, D. Lehmann and M. Magidor [12]."
- Break condition: If the smoothness condition fails (infinite descending chains of preferred models), the equivalence to System P may not hold.

### Mechanism 3
- Claim: The logic supports argumentation-based deduction through supporting and undermining arguments
- Mechanism: Supporting arguments P⇒φ are derived when premises P logically entail proposition φ. Undermining arguments P̸⇒φ are created when φ and ¬φ are both supported, indicating that φ must be withdrawn if P is believed. The belief set is determined by finding stable extensions of the argumentation framework.
- Core assumption: The argumentation framework derived from the set of arguments has unique stable extensions corresponding to linear extensions of the reliability relation.
- Evidence anchors:
  - [abstract] "This makes it possible to define an argumentation-based deduction process for the logic."
  - [section] "Because a belief set B∞ is determined by evaluating the arguments A∞, the belief set can change in a non-monotonic way."
- Break condition: If multiple stable extensions exist that don't correspond to linear extensions of ≺, some extensions must be ignored, potentially reducing the set of derivable theorems.

## Foundational Learning

- Concept: Partial orders and linear extensions
  - Why needed here: The reliability relation ≺ is a partial order, and deduction requires considering all linear extensions to ensure all possible consistent belief sets are captured.
  - Quick check question: Given ≺ = {(a,b), (c,b)}, what are the possible linear extensions?

- Concept: Argumentation frameworks and stable semantics
  - Why needed here: The logic uses argumentation to determine which premises can be believed, with stable extensions representing consistent belief sets.
  - Quick check question: If A attacks B and B attacks A, what are the stable extensions of this framework?

- Concept: Preferential semantics and System P properties
- Why needed here: The logic's semantics are shown to correspond to System P, which requires understanding preferential models and the properties they must satisfy.
  - Quick check question: What is the difference between preferential entailment and rational entailment in non-monotonic logics?

## Architecture Onboarding

- Component map:
  - Premise representation: Set Σ of atomic propositions
  - Reliability relation: Partial order ≺ on Σ
  - Argument derivation: Supporting arguments P⇒φ and undermining arguments P̸⇒φ
  - Belief computation: Fixed point algorithm to determine which premises can be believed
  - Theorem computation: Intersection of belief sets across all linear extensions

- Critical path: Premise input → Argument derivation (modus ponens and contradiction rules) → Belief set computation → Theorem intersection

- Design tradeoffs:
  - Efficiency vs completeness: Considering all linear extensions ensures completeness but can be computationally expensive
  - Granularity of reliability: More detailed reliability relations allow finer-grained reasoning but increase complexity
  - Argument representation: Using arguments instead of propositions enables non-monotonic belief updates

- Failure signatures:
  - Exponential growth in belief sets when many minimal inconsistencies exist
  - Cycles in the reliability relation (should be prevented by design)
  - Multiple stable extensions that don't correspond to linear extensions of ≺

- First 3 experiments:
  1. Test basic contradiction resolution: Create Σ = {α, α→β, ¬β} with ≺ = {(2,1)} and verify β is derived then ¬β is removed
  2. Test multiple linear extensions: Create Σ = {a,b,¬a,¬b} with ≺ = {(a,¬b), (b,¬a)} and verify different belief sets result from different extensions
  3. Test argumentation framework: Create a simple framework with supporting and undermining arguments and verify stable extension computation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the logic handle defeasible rules with antecedents versus undermining arguments with empty antecedents?
- Basis in paper: [explicit] The paper mentions that "undercutting arguments attack the application of a defeasible rule" and that "Defeasible premisses can be described by defeasible rules with an empty antecedent" in footnote 1.
- Why unresolved: The paper does not provide a detailed comparison or formal relationship between defeasible rules with non-empty antecedents and undermining arguments.
- What evidence would resolve it: A formal proof showing the equivalence or transformation between defeasible rules with non-empty antecedents and undermining arguments.

### Open Question 2
- Question: What is the computational complexity of determining all stable argument extensions when not considering linear extensions of the reliability relation?
- Basis in paper: [explicit] Section 9 discusses that "this approach is more efficient than considering all linear extensions of ≺, which has a worst case time complexity that is factorial in the number of premisses Σ."
- Why unresolved: The paper does not provide specific complexity bounds for the alternative approach using stable semantics without linear extensions.
- What evidence would resolve it: A formal complexity analysis comparing the two approaches in terms of time and space complexity.

### Open Question 3
- Question: How can the logic be extended to handle more complex forms of default reasoning, such as those found in Reiter's Default logic?
- Basis in paper: [inferred] Section 10.4 discusses the limitations of the current approach for default reasoning and mentions that "Although it is likely that the logic is not suited for default reasoning, it is suited for reasoning with knowledge coming from different and not fully reliable knowledge sources."
- Why unresolved: The paper does not provide a clear path for extending the logic to handle more complex forms of default reasoning.
- What evidence would resolve it: A formal extension of the logic that incorporates the features of Reiter's Default logic or other more complex forms of default reasoning.

## Limitations

- The extension to first-order logic is mentioned but not demonstrated in detail, leaving uncertainty about whether the preferential semantics and System P equivalence extend to the first-order case.
- The computational complexity can be exponential when dealing with many inconsistencies and insufficient reliability knowledge, as all linear extensions of the reliability relation must be considered.
- The smoothness condition required for preferential models is not explicitly verified, which could affect the equivalence to System P if infinite descending chains of preferred models exist.

## Confidence

- **High Confidence**: The basic mechanism of resolving contradictions by removing the least reliable premise is clearly specified and supported by the argumentation framework. The soundness and completeness results for supporting and undermining arguments are well-established.
- **Medium Confidence**: The equivalence to System P and preferential semantics is supported by the theoretical framework, but requires verification of the smoothness condition and the precise correspondence between stable extensions and linear extensions.
- **Low Confidence**: The extension to first-order logic and the handling of more complex logical constructs are mentioned but not demonstrated, making the claims about first-order capabilities speculative without further development.

## Next Checks

1. **Verify smoothness condition**: Test the preference relation on interpretations defined from the reliability relation to ensure it satisfies the smoothness property required for preferential models. This can be done by checking for infinite descending chains of preferred models.

2. **Check stable extension correspondence**: Create multiple argumentation frameworks with different reliability relations and verify that the stable extensions correspond exactly to the belief sets derived from linear extensions of the reliability relation.

3. **Test first-order extension**: Implement the logic for a first-order language with quantifiers and verify that the preferential semantics and System P equivalence still hold. Test with examples involving existential and universal quantification.