---
ver: rpa2
title: 'LinkedIn Post Embeddings: Industrial Scale Embedding Generation and Usage
  across LinkedIn'
arxiv_id: '2405.11344'
source_url: https://arxiv.org/abs/2405.11344
tags:
- linkedin
- embeddings
- post
- embedding
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents LinkedIn\u2019s industrial-scale post embeddings\
  \ model, trained via multi-task fine-tuning of a BERT-based LLM across diverse semantic\
  \ labeling tasks. The model achieves positive transfer, outperforming independent\
  \ task training and generalized baselines like OpenAI\u2019s ADA embeddings on LinkedIn-specific\
  \ benchmarks."
---

# LinkedIn Post Embeddings: Industrial Scale Embedding Generation and Usage across LinkedIn

## Quick Facts
- arXiv ID: 2405.11344
- Source URL: https://arxiv.org/abs/2405.11344
- Reference count: 13
- Primary result: Industrial-scale post embeddings trained via multi-task fine-tuning outperform baselines on LinkedIn tasks with 30x compression vs OpenAI embeddings

## Executive Summary
This paper presents LinkedIn's industrial-scale post embeddings model, trained via multi-task fine-tuning of a BERT-based LLM across diverse semantic labeling tasks. The model achieves positive transfer, outperforming independent task training and generalized baselines like OpenAI's ADA embeddings on LinkedIn-specific benchmarks. Post embeddings, with 50 dimensions, enhance both retrieval and ranking stages of LinkedIn's feed and video recommendation systems. Online A/B tests show measurable improvements: +0.1% daily sessions, +0.21% member interactions, +0.42% revenue in feed ranking; +0.37% engaged members and -0.05% feed skips in retrieval; and +10.46% total watch time, +1.74% DAU for video recommendations. The embeddings have been battle-tested in production for over two years.

## Method Summary
The model uses multi-task fine-tuning of a 6-layer multilingual BERT with siamese architecture and binary cross-entropy loss, trained on 104M samples from Interests, Storylines, Hashtags, and Search datasets. The approach employs task heterogeneous sampling across workers and generates 50-dimensional embeddings. The system includes near-line inference via Samza job for real-time embedding generation, key-value stores for post and member embeddings, and integration with downstream ranking and retrieval systems. The model demonstrates both positive transfer across training tasks and zero-shot generalization to unseen Intent tasks, while achieving comparable performance to larger generalized embeddings with significantly smaller size.

## Key Results
- Multi-task fine-tuning achieves positive transfer, outperforming independent task training across all datasets
- Zero-shot generalization successfully applies to Intent task without explicit training
- 50-dimensional embeddings achieve comparable performance to OpenAI ADA embeddings with 30x compression
- Online A/B tests show significant improvements: +0.1% daily sessions, +0.21% interactions, +0.42% revenue in feed ranking

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-task fine-tuning with diverse semantic labeling tasks leads to positive transfer, improving performance across all tasks compared to independent task training.
- Mechanism: The model simultaneously learns from multiple datasets (Interests, Storyline, Hashtag, Search) through shared LLM parameters, allowing the network to develop richer, more generalizable semantic representations that benefit each task.
- Core assumption: Tasks are sufficiently related that learning from one improves performance on others, rather than interfering with each other.
- Evidence anchors:
  - [abstract]: "We observe positive transfer, leading to improved performance across all tasks, compared to training them independently."
  - [section 5.2]: "The key idea of using a multi-task approach is that adding new datasets/tasks helps all the tasks being trained [1] versus training one model for every isolated task."
  - [corpus]: Weak evidence - no direct mention of positive transfer mechanisms in corpus neighbors, though related papers discuss multi-task learning approaches.
- Break condition: If tasks are too dissimilar or conflicting, the shared representation may become noisy and degrade performance on individual tasks.

### Mechanism 2
- Claim: The multi-task model demonstrates zero-shot generalization capabilities, performing better on unseen tasks (Intent) than models fine-tuned only on that task's data.
- Mechanism: By learning rich semantic representations from diverse sources during multi-task training, the model develops transferable knowledge that applies to new, related tasks without explicit training on them.
- Core assumption: The semantic understanding developed from the training tasks is sufficiently general to apply to related but unseen tasks.
- Evidence anchors:
  - [abstract]: "The generated post embeddings outperform baseline models in zero-shot learning, demonstrating its potential for broader applicability."
  - [section 8.2]: "Table 4 demonstrates zero shot learning capabilities for the post embedding model. Although it is trained only on data from Interests, Search, Storylines and Hashtag datasets, it generalizes effectively to the Post Intent Dataset (E4)."
  - [corpus]: Weak evidence - no direct mention of zero-shot capabilities in corpus neighbors.
- Break condition: If the unseen task is too different from the training tasks, the model may fail to generalize effectively.

### Mechanism 3
- Claim: The multi-task model achieves comparable performance to larger generalized embedding models (OpenAI ADA-002) with significantly smaller embedding size (50 dimensions vs 1536), enabling more efficient deployment at scale.
- Mechanism: The specialized training on LinkedIn-specific data and tasks allows the model to learn more compact, task-relevant representations that capture the essential semantic information without the redundancy present in larger generalized models.
- Core assumption: LinkedIn-specific semantic patterns can be captured more efficiently than general-purpose embeddings require.
- Evidence anchors:
  - [abstract]: "The generated post embeddings' performance surpasses that of OpenAI's ADA-001 and ADA-002 embeddings on LinkedIn specific datasets and tasks."
  - [section 8.3]: "Table 5 show that compared to open-source models that generate generalized embeddings, we achieve comparable performance with up to 30x compression in embedding size for LinkedIn specific tasks."
  - [corpus]: Weak evidence - no direct comparison with OpenAI embeddings in corpus neighbors.
- Break condition: If the task requirements change significantly, the compact representations may lack the capacity to capture new semantic nuances.

## Foundational Learning

- Concept: Siamese architecture with binary cross-entropy loss for training embedding similarity
  - Why needed here: This architecture enables the model to learn meaningful semantic relationships by comparing pairs of posts and learning to predict their similarity, which is fundamental to creating useful embeddings for retrieval and ranking.
  - Quick check question: Why does the siamese architecture use pairs of posts rather than individual posts for training?

- Concept: Multi-task learning and positive transfer
  - Why needed here: Understanding how training on multiple related tasks simultaneously can improve performance across all tasks is crucial for grasping why the LinkedIn approach outperforms independent task training.
  - Quick check question: What is the key difference between multi-task learning and training separate models for each task?

- Concept: Embedding-based retrieval (EBR) and evaluation metrics
  - Why needed here: The model's effectiveness is measured by its ability to retrieve relevant items, requiring understanding of how triplet-based evaluation metrics (like AvgFracTripletsWherePosIsCloser) proxy real-world retrieval performance.
  - Quick check question: How does the AvgFracTripletsWherePosIsCloser metric evaluate embedding quality for retrieval applications?

## Architecture Onboarding

- Component map: Post creation -> Samza job for embedding generation -> Key-value store update (within 2 minutes) -> Retrieval/ranking models fetch embeddings for scoring -> Content delivered to users
- Critical path: Post creation → Samza job for embedding generation → Key-value store update (within 2 minutes) → Retrieval/ranking models fetch embeddings for scoring → Content delivered to users
- Design tradeoffs: Chose 50-dimensional embeddings for balance between expressiveness and latency, binary cross-entropy loss for efficiency over triplet loss, and multi-task learning over separate models to achieve positive transfer
- Failure signatures: Poor embedding quality manifests as low AvgFracTripletsWherePosIsCloser scores, reduced online engagement metrics (sessions, interactions), and increased feed skips or decreased watch time in video recommendations
- First 3 experiments:
  1. Compare single-task vs multi-task training on a subset of datasets to verify positive transfer effect
  2. Test different embedding dimensions (e.g., 32, 50, 100) to find optimal tradeoff between accuracy and latency
  3. Evaluate zero-shot performance on the Intent dataset without additional fine-tuning to validate generalization capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the LinkedIn post embedding model's performance degrade when applied to domains outside LinkedIn's professional network, and if so, what are the specific failure modes?
- Basis in paper: [explicit] The paper mentions that generalized models like OpenAI's ADA embeddings face limitations when applied to specific domains such as recommendation systems due to linguistic variability between the general pretrained embeddings and the specialized application domain.
- Why unresolved: The paper does not test the model's performance on external datasets or domains outside of LinkedIn's ecosystem.
- What evidence would resolve it: Conducting cross-domain evaluations using benchmarks from other social networks or general NLP datasets to measure performance drops and identify specific weaknesses.

### Open Question 2
- Question: How would the LinkedIn post embeddings perform if trained with a larger transformer model or with multimodal inputs (text + images), and what is the trade-off between performance gains and computational costs?
- Basis in paper: [explicit] The paper states, "Looking ahead, our goal is to integrate larger foundational language models into our fine-tuning framework," and mentions that "we have initiated efforts to develop multimodal post embeddings that integrate both visual and textual information."
- Why unresolved: The paper only evaluates the current BERT-based model and does not explore the performance impact of scaling up the architecture or adding visual modalities.
- What evidence would resolve it: Running ablation studies with larger models (e.g., BERT-large, RoBERTa, or GPT-based models) and multimodal variants to compare performance gains against latency and memory costs.

### Open Question 3
- Question: What is the optimal frequency for retraining the LinkedIn post embeddings to balance freshness and computational efficiency, and how does this frequency impact downstream application performance?
- Basis in paper: [explicit] The paper mentions that "to ensure the embeddings reflect the latest trends and patterns in the data, we should have the ability to retrain as often as needed," but does not specify the optimal retraining schedule.
- Why unresolved: The paper does not provide empirical data on how often retraining is necessary to maintain embedding quality or how retraining frequency affects online performance metrics.
- What evidence would resolve it: Conducting experiments with different retraining intervals (e.g., weekly, monthly, quarterly) and measuring the impact on embedding quality and downstream application metrics.

## Limitations
- The paper doesn't fully characterize when and why multi-task transfer succeeds versus fails
- Zero-shot generalization capabilities are demonstrated but boundaries aren't explored
- The 30x compression claim doesn't discuss potential quality trade-offs or edge cases

## Confidence
- High Confidence: Core claims about multi-task fine-tuning improving performance over single-task training, with clear implementation details and deployment architecture
- Medium Confidence: Zero-shot generalization claims supported by results but lack theoretical grounding; compression efficiency claims lack edge case exploration
- Low Confidence: Paper doesn't adequately address potential failure modes like task interference or catastrophic forgetting

## Next Checks
1. **Task Interference Analysis**: Systematically evaluate how adding tasks affects existing task performance, identifying which task combinations yield positive transfer versus negative interference.
2. **Generalization Boundary Testing**: Evaluate zero-shot performance on a diverse set of tasks ranging from closely related to distantly related to characterize limits of generalization capabilities.
3. **Compression-Quality Tradeoff Study**: Compare 50-dimensional embeddings against larger variants (100, 200 dimensions) on both LinkedIn-specific and general tasks to quantify diminishing returns.