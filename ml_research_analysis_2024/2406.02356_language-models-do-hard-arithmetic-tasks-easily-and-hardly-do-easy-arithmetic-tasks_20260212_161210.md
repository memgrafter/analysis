---
ver: rpa2
title: Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic
  Tasks
arxiv_id: '2406.02356'
source_url: https://arxiv.org/abs/2406.02356
tags:
- digit
- llama
- llms
- dropout
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the surprising arithmetic capabilities
  and limitations of large language models (LLMs) using Monte Carlo Dropout to analyze
  their uncertainty. The research reveals that LLMs can confidently predict the first
  digit of n-digit by m-digit multiplication problems, despite these tasks requiring
  complex computations that LLMs are unlikely to learn internally.
---

# Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks

## Quick Facts
- arXiv ID: 2406.02356
- Source URL: https://arxiv.org/abs/2406.02356
- Reference count: 9
- Primary result: LLMs can confidently predict first digits of multiplication problems but struggle with last digits, even though the latter should be easier.

## Executive Summary
This study reveals surprising arithmetic capabilities and limitations of large language models (LLMs) using Monte Carlo Dropout to analyze their uncertainty. The research demonstrates that LLMs can confidently predict the first digit of n-digit by m-digit multiplication problems without using chain-of-thought reasoning, suggesting they use computational shortcuts rather than full multiplication. Conversely, LLMs struggle to correctly or confidently predict the last digit of such problems, even though this task is equivalent to simple 1-digit multiplication. The study further shows that confidence in predicting the last digit significantly improves when the LLM is conditioned on correct higher-order digits, indicating that LLMs may internally distinguish between correct and incorrect intermediate steps.

## Method Summary
The study uses Monte Carlo Dropout with dropout rate 0.1 to estimate confidence in LLM predictions for multiplication problems. Researchers created 2-shot prompts with correct multiplication examples and target problems of varying digit lengths (2-5 digits), generating 100 samples per problem using deterministic sampling (argmax). They analyzed Llama 2-7B/13B and Mistral-7B models, calculating confidence as the frequency of the most common predicted digit and comparing predictions against ground truth. The experiments tested unconditional predictions for first and last digits, as well as conditional predictions where correct higher-order digits were provided.

## Key Results
- LLMs confidently predict first digits of multiplication problems without performing full calculations, suggesting learned approximation shortcuts
- LLMs fail to confidently predict last digits despite these being equivalent to simple 1-digit multiplication
- Confidence in correct last-digit predictions increases by over 230% (Llama 2-13B) and 150% (Mistral-7B) when conditioned on correct higher-order digits
- The findings suggest LLMs internally distinguish between correct and incorrect intermediate steps, potentially related to hallucination detection mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs predict first digits through learned approximation shortcuts rather than full multiplication computation
- Mechanism: Models likely round inputs to nearest hundreds/thousands (e.g., 592→600, 392→400) and compute approximate results (600×400=240000)
- Core assumption: Stochastic gradient descent favors finding computational shortcuts when they provide sufficient training accuracy
- Evidence: LLMs confidently predict first digits without chain-of-thought reasoning; approximation would provide sufficient accuracy for training data
- Break condition: Approximation fails when rounded values produce different first digit than actual multiplication

### Mechanism 2
- Claim: Exponential error compounding occurs during autoregressive generation of arithmetic results
- Mechanism: Any non-zero chance of mistake in any position causes errors to compound exponentially through sequence during autoregressive generation
- Core assumption: Internal states diverge significantly based on correctness of intermediate digits, creating feedback loop that reinforces error propagation
- Evidence: LLMs struggle with last-digit prediction when generating entire answer at once; conditioning on correct digits improves performance
- Break condition: Error compounding breaks when correct intermediate digits are provided

### Mechanism 3
- Claim: LLMs can distinguish between correct and incorrect intermediate steps internally
- Mechanism: Internal states differ depending on whether conditioning text is correct or incorrect, affecting subsequent predictions even for digits that don't logically depend on preceding ones
- Core assumption: LLM internal representations encode information about correctness of intermediate computations, not just raw token values
- Evidence: Confidence in last-digit prediction improves significantly when conditioned on correct higher-order digits
- Break condition: Internal state distinction becomes too subtle to affect output probabilities meaningfully

## Foundational Learning

- Concept: Monte Carlo Dropout for uncertainty quantification
  - Why needed: Paper uses MC Dropout to analyze LLM confidence in arithmetic predictions, requiring understanding of dropout as Bayesian approximation
  - Quick check: How does running multiple forward passes with dropout enabled provide empirical confidence distributions over outputs?

- Concept: Autoregressive generation and error propagation
  - Why needed: Core findings about error compounding in autoregressive arithmetic generation require understanding how each generated token conditions subsequent predictions
  - Quick check: Why would LLM's prediction for last digit depend on whether preceding digits were correct or incorrect?

- Concept: Transformer architecture and positional encoding
  - Why needed: Understanding LLM arithmetic struggles requires knowledge of how transformers process sequences and why digit position tracking is challenging
  - Quick check: How do standard transformer positional encodings handle varying sequence lengths, and why might this create arithmetic challenges?

## Architecture Onboarding

- Component map: Prompt construction -> LLM inference with dropout -> Token aggregation -> Confidence calculation -> Result analysis
- Critical path: 2-shot prompt creation → Monte Carlo Dropout inference (100 samples) → Digit token aggregation → Confidence frequency calculation → Accuracy comparison
- Design tradeoffs: Dropout during inference provides uncertainty estimates but may reduce generation quality; 2-shot prompting provides task context but may not suffice for complex arithmetic; token-level digit representation enables arithmetic but may limit generalization
- Failure signatures: Non-digit tokens when dropout is enabled (check if models trained with dropout); confidence scores not matching reported values (verify tokenization and sampling method); "end string" token output when failing last-digit prediction
- First 3 experiments:
  1. Reproduce unconditional first-digit prediction with simple 3-digit multiplication to verify approximation shortcut
  2. Test unconditional last-digit prediction to observe baseline failure mode and exponential error compounding
  3. Implement conditional last-digit prediction with correct intermediate digits to demonstrate internal state distinction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do language models not trained with dropout exhibit similar patterns of confidence in arithmetic tasks?
- Basis: Paper states MC Dropout only applicable to models trained with dropout, limiting analysis to Llama 2 and Mistral
- Why unresolved: Cannot analyze GPT-4, Gemini, or Claude due to closed weights and lack of training method information
- Resolution evidence: Experiments applying MC Dropout or other uncertainty quantification methods to broader range of LLMs, including those without dropout

### Open Question 2
- Question: What is the underlying mechanism allowing LLMs to confidently predict first digits without performing full calculation?
- Basis: LLMs can confidently predict first digits of n-digit by m-digit multiplication problems, which should require solving entire multiplication
- Why unresolved: Study hypothesizes rounding and simpler calculations but this is not definitively proven
- Resolution evidence: Detailed analysis of internal representations and activations when predicting first digit, revealing specific computational shortcuts

### Open Question 3
- Question: How does internal state of LLMs change when they realize they generated incorrect intermediate digits, and how does this affect subsequent predictions?
- Basis: Paper suggests LLMs can internally distinguish between correct and incorrect intermediate steps, potentially related to hallucination detection
- Why unresolved: Study doesn't explore internal states in detail or how they change based on correctness of generated digits
- Resolution evidence: Experiments analyzing internal activations and representations when generating correct versus incorrect digits, and how these states influence subsequent predictions

## Limitations

- Findings rely on Monte Carlo Dropout interpretation, which assumes dropout activations during inference approximate Bayesian uncertainty - this theoretical foundation remains debated
- Experiments focus exclusively on multiplication problems, limiting generalizability to other arithmetic operations or mathematical reasoning tasks
- Study uses relatively small problem sets (10 problems per configuration) and specific model architectures, which may not capture full variability in LLM behavior
- Analysis doesn't account for potential training data contamination or possibility that models might have learned specific arithmetic patterns during pretraining

## Confidence

- High confidence: Observation that LLMs correctly predict first digits while struggling with last digits is reproducible and aligns with approximation shortcut mechanism
- Medium confidence: Interpretation that exponential error compounding explains last-digit failure is plausible but requires additional experiments to rule out alternative explanations
- Medium confidence: Claim that LLMs internally distinguish between correct and incorrect intermediate steps is most speculative - experimental evidence is suggestive but alternative explanations haven't been fully ruled out

## Next Checks

1. **Alternative uncertainty quantification**: Reproduce experiments using multiple different uncertainty estimation methods (temperature scaling, ensemble approaches, or deterministic confidence measures) to verify observed confidence patterns are not artifacts of Monte Carlo Dropout implementation

2. **Cross-task generalization**: Test whether same patterns of first-digit confidence and last-digit failure appear in addition, subtraction, and division tasks to determine if phenomena are specific to multiplication or reflect broader arithmetic processing limitations

3. **Intermediate state analysis**: Conduct ablation studies that systematically vary which intermediate digits are provided (first digit only, middle digits only, combinations) to better understand how information propagates through model and whether internal state distinction is truly about correctness or other factors like context quality