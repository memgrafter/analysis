---
ver: rpa2
title: Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian
  Optimization
arxiv_id: '2405.10616'
source_url: https://arxiv.org/abs/2405.10616
tags:
- uni00000013
- low-rank
- compression
- bolaco
- uni00000057
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently compressing large
  language models (LLMs) while maintaining performance, focusing on low-rank compression
  techniques. The authors propose a novel method called "Bolaco" that combines feature-based
  low-rank decomposition with Bayesian optimization for optimal low-rank dimension
  allocation.
---

# Adaptive Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization

## Quick Facts
- arXiv ID: 2405.10616
- Source URL: https://arxiv.org/abs/2405.10616
- Reference count: 18
- Primary result: Bolaco achieves 96-98% performance retention at 20% compression rates on LLaMA-2 models

## Executive Summary
This paper introduces Bolaco, a novel method for compressing large language models (LLMs) using feature-based low-rank decomposition combined with Bayesian optimization. The approach addresses the challenge of maintaining model performance while achieving high compression ratios. By leveraging pooled covariance matrices for robust feature distribution estimation and Bayesian optimization for optimal low-rank dimension allocation, Bolaco outperforms existing structured pruning and low-rank compression methods on both language modeling tasks and zero-shot common sense reasoning benchmarks.

## Method Summary
Bolaco combines feature-based low-rank decomposition with Bayesian optimization to compress LLMs efficiently. The method uses pooled covariance matrices to estimate feature distributions in high-dimensional spaces, addressing the curse of dimensionality that affects sample covariance matrices. Bayesian optimization then determines the optimal low-rank dimensions for different parameter types and layers, balancing compression ratio with performance. After initial compression, the method employs post-training with LoRA in the low-rank subspace to recover lost performance. The approach is evaluated on LLaMA-2 models (7B and 13B variants) using language modeling tasks (WikiText2, PTB, C4) and zero-shot common sense reasoning benchmarks (BoolQ, PIQA, HellaSwag, WinoGrande, ARC-easy/challenge, OpenbookQA).

## Key Results
- Bolaco achieves 98% of original model performance at 20% compression rate
- After post-training, Bolaco retains 96-98% performance on LLaMA-2 models
- Outperforms existing structured pruning and low-rank compression methods on language modeling and zero-shot common sense reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
Using pooled covariance matrices improves feature distribution estimation in high-dimensional spaces by averaging covariance estimates across multiple data partitions, reducing the impact of outlier features that can distort the sample covariance matrix in high-dimensional settings.

### Mechanism 2
Bayesian optimization effectively allocates low-rank dimensions across different parameter types and layers by using a Gaussian process surrogate model to estimate the relationship between low-rank dimension allocations and model performance, then using an acquisition function to select promising allocations for evaluation.

### Mechanism 3
Post-training with LoRA in the low-rank subspace of compressed parameters maintains model performance by adding trainable parameters in the same low-rank subspace as the compressed parameters, allowing fine-tuning without increasing the model's rank.

## Foundational Learning

- **Concept: Principal Component Analysis (PCA)**
  - Why needed here: PCA is used to identify the optimal low-rank matrices for feature-based decomposition by finding the principal components of the feature space.
  - Quick check question: What is the mathematical relationship between PCA and SVD, and why is PCA appropriate for feature-based decomposition?

- **Concept: Bayesian Optimization**
  - Why needed here: Bayesian optimization is used to efficiently search the space of low-rank dimension allocations to find the optimal configuration.
  - Quick check question: How does the acquisition function in Bayesian optimization balance exploration and exploitation?

- **Concept: Pooled Covariance Matrix**
  - Why needed here: Pooled covariance matrix estimation improves robustness in high-dimensional spaces by averaging covariance estimates across multiple data partitions.
  - Quick check question: Under what conditions does the pooled covariance matrix provide better estimation than the sample covariance matrix?

## Architecture Onboarding

- **Component map:**
  - PCA decomposition module -> Bayesian optimization module -> Post-training module -> Evaluation module

- **Critical path:**
  1. Estimate feature distributions using pooled covariance matrix
  2. Initialize Bayesian optimization with random low-rank allocations
  3. Evaluate model performance for each allocation
  4. Update Gaussian process surrogate model
  5. Select next allocation using acquisition function
  6. Repeat until convergence or maximum iterations reached
  7. Apply post-training using LoRA in low-rank subspace

- **Design tradeoffs:**
  - Pooled covariance vs. sample covariance: Accuracy vs. computational cost
  - Granularity of low-rank allocation: Performance vs. search space size
  - Post-training duration: Performance recovery vs. computational cost

- **Failure signatures:**
  - Poor performance despite high compression ratio: Indicates suboptimal low-rank allocation
  - Slow convergence of Bayesian optimization: Indicates noisy objective function or large search space
  - Limited performance recovery after post-training: Indicates overly restrictive low-rank subspace

- **First 3 experiments:**
  1. Compare performance using pooled covariance matrix vs. sample covariance matrix on a small subset of the data
  2. Test Bayesian optimization with different acquisition functions (Expected Improvement, Upper Confidence Bound) on a simplified low-rank allocation problem
  3. Evaluate post-training with different low-rank dimensions (r') to find the optimal balance between performance recovery and computational cost

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the pooled covariance matrix (PCM) method scale with increasingly high-dimensional feature spaces in very large LLMs (e.g., beyond 10,000 dimensions)?
- Basis in paper: The paper proposes using PCM instead of SCM for high-dimensional spaces and mentions that "LLMs typically have high-dimensional feature spaces (e.g., the intermediate size of LLaMA-v2-7b has exceeded 10,000 dimensions)" but doesn't provide extensive empirical validation for even higher dimensions.
- Why unresolved: The paper only demonstrates PCM effectiveness for LLaMA-v2-7b with intermediate sizes exceeding 10,000 dimensions. There's no experimental evidence showing how this method performs for significantly larger models with feature spaces in the hundreds of thousands or millions of dimensions.
- What evidence would resolve it: Systematic experiments applying Bolaco to progressively larger LLMs (e.g., LLaMA-2-33B, 70B) with feature spaces scaling to 50,000+ dimensions, comparing PCM vs SCM performance as dimensionality increases.

### Open Question 2
- Question: What is the theoretical limit of transferability for low-rank allocations between base models and fine-tuned variants, and how does fine-tuning methodology affect this transferability?
- Basis in paper: The paper shows that low-rank allocations from base models can be transferred to fine-tuned models, with "direct reusing can achieve results that outperform all baseline methods" and "few rounds of Bayesian optimization" can further improve results.
- Why unresolved: The paper only tests transferability between LLaMA-v2-7b/13b and their chat variants, without exploring the limits of transferability across different fine-tuning approaches (instruction tuning, RLHF, domain-specific fine-tuning) or how fine-tuning methodology affects allocation transferability.
- What evidence would resolve it: Systematic experiments testing transferability across multiple fine-tuning methodologies, measuring performance degradation as the fine-tuned model diverges from the base model, and identifying thresholds where reallocation becomes necessary.

### Open Question 3
- Question: How would incorporating task-specific validation data into the Bayesian optimization objective affect the general-purpose performance of compressed models?
- Basis in paper: The paper uses task-agnostic validation data (Wikipedia subset) and mentions that "validation data that is more sensitive to compression, typically samples with slightly worse language modeling performance" may represent "performance boundaries of LLMs."
- Why unresolved: The paper deliberately avoids task-specific optimization to maintain generality, but doesn't explore the trade-off between task-specific optimization and general-purpose performance, or whether hybrid approaches could balance both objectives.
- What evidence would resolve it: Comparative experiments where Bayesian optimization uses mixed validation sets (combining general and task-specific samples) versus pure task-agnostic validation, measuring both task-specific performance gains and general-purpose performance degradation.

## Limitations
- Evaluation is primarily focused on LLaMA-2 models, with limited testing on other architectures
- Pooled covariance matrix approach lacks extensive empirical validation against simpler alternatives
- Bayesian optimization component may be sensitive to calibration data quality and representativeness

## Confidence

- **High confidence**: The overall experimental methodology and performance evaluation framework
- **Medium confidence**: The effectiveness of pooled covariance matrices for feature distribution estimation
- **Medium confidence**: The Bayesian optimization approach for low-rank dimension allocation
- **Low confidence**: The scalability of the method to significantly larger models and different architectures

## Next Checks

1. **Architecture Transferability Test**: Apply Bolaco to other transformer architectures (e.g., OPT, Falcon) and compare performance degradation relative to LLaMA-2 results

2. **Covariance Matrix Ablation**: Systematically compare pooled covariance matrix estimation against sample covariance and diagonal approximations across different data sizes and dimensionalities

3. **Search Space Scalability**: Evaluate Bayesian optimization performance with progressively larger low-rank dimension search spaces to identify practical limits on model size