---
ver: rpa2
title: Modelling Political Coalition Negotiations Using LLM-based Agents
arxiv_id: '2402.11712'
source_url: https://arxiv.org/abs/2402.11712
tags:
- coalition
- statement
- political
- negotiation
- party
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of simulating coalition negotiations
  between political parties by proposing a novel approach using large language model
  (LLM)-based agents. The authors introduce a new multilingual dataset, POLCA, which
  comprises political manifestos and coalition agreements from six European countries,
  addressing the challenge of data scarcity in political negotiation modeling.
---

# Modelling Political Coalition Negotiations Using LLM-based Agents

## Quick Facts
- arXiv ID: 2402.11712
- Source URL: https://arxiv.org/abs/2402.11712
- Authors: Farhad Moghimifar; Yuan-Fang Li; Robert Thomson; Gholamreza Haffari
- Reference count: 12
- Primary result: Hierarchical MDP with LLM agents achieves macro F1-scores of 36.46-53.44 on coalition negotiation prediction task

## Executive Summary
This paper proposes a novel approach to simulating coalition negotiations between political parties using large language model (LLM)-based agents. The authors introduce a hierarchical Markov decision process (HMDP) framework where agents negotiate over manifesto statements to predict their inclusion in final coalition agreements. A new multilingual dataset, POLCA, is compiled from political manifestos and coalition agreements across six European countries, addressing the data scarcity challenge in this domain. The approach is evaluated using different LLM engines, with gpt-3.5-turbo consistently outperforming LLaMa models, demonstrating the effectiveness of LLMs for coalition negotiation modeling while highlighting the task's complexity.

## Method Summary
The method formulates coalition negotiation as a two-level hierarchical Markov decision process. At the higher level, agents select which manifesto statement to negotiate, while at the lower level they choose from predefined actions (support, oppose, refine, compromise) to negotiate that statement. The system uses LLM agents initialized with different models (gpt-3.5-turbo, LLaMa-13b-chat, LLaMa-7b-chat) to leverage their political reasoning and natural language capabilities. A multilingual dataset called POLCA is created by annotating political manifestos and coalition agreements from six European countries. The model is trained using reward functions that evaluate both individual statement negotiations and overall agreement similarity, with a critique function updating policies based on performance.

## Key Results
- HMDP approach achieves macro F1-scores ranging from 36.46 to 53.44 across different LLM engines
- gpt-3.5-turbo consistently outperforms LLaMa-13b-chat and LLaMa-7b-chat models
- Model performance varies significantly across countries and languages, suggesting cross-lingual challenges
- Agents occasionally generate invalid statement IDs (hallucinations), requiring additional validation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hierarchical MDP structure allows agents to balance strategic planning with tactical negotiation actions, improving realism and performance.
- Mechanism: High-level policy selects manifesto statements while low-level policy determines negotiation actions, mirroring real-world coalition negotiations where parties first choose topics and then decide on tactics.
- Core assumption: Coalition negotiation complexity can be decomposed into sequential decision-making at two distinct temporal scales.
- Evidence anchors: HMDP formulation explicitly separates statement selection from action selection, though corpus neighbors don't directly support this structure.

### Mechanism 2
- Claim: LLM-based agents leverage strong natural language understanding and reasoning to simulate nuanced political negotiation behaviors.
- Mechanism: Pre-trained LLMs inherit political reasoning, commonsense knowledge, and language generation capabilities, enabling agents to propose refined statements and engage in multi-round negotiations.
- Core assumption: Pre-trained LLMs capture sufficient political and linguistic knowledge to simulate realistic negotiation dynamics without additional fine-tuning.
- Evidence anchors: Abstract highlights LLM capabilities for coalition negotiations, with corpus neighbors supporting LLM use in negotiation tasks.

### Mechanism 3
- Claim: The multilingual POLCA dataset provides diverse, real-world coalition negotiation scenarios, improving model generalization across countries and parties.
- Mechanism: Compiling manifesto statements and coalition agreement outcomes from six European countries enables models to learn negotiation patterns that generalize beyond single national contexts.
- Core assumption: Coalition negotiation dynamics share enough structural similarity across countries that training on multiple contexts improves model robustness.
- Evidence anchors: POLCA dataset combines Manifesto Project and Coalition Agreement Dataset, though corpus neighbors don't address multilingual political negotiation datasets.

## Foundational Learning

- Concept: Hierarchical decision-making in sequential processes
  - Why needed here: Coalition negotiations require both long-term strategy (which issues to address) and short-term tactics (how to negotiate each issue), which the hierarchical MDP captures.
  - Quick check question: How does separating the decision process into high-level topic selection and low-level action selection affect the agent's ability to adapt during negotiation?

- Concept: Large language model capabilities in natural language reasoning
  - Why needed here: LLM agents must understand political language, propose refined statements, and negotiate using natural language, tasks that require strong reasoning and generation skills.
  - Quick check question: What limitations might arise if an LLM's pretraining data lacks sufficient coverage of the political contexts in the POLCA dataset?

- Concept: Evaluation metrics for imbalanced classification tasks
  - Why needed here: The dataset has highly imbalanced labels (included vs partly included vs not included), so macro F1 is used to ensure fair evaluation across classes.
  - Quick check question: Why might accuracy be misleading as an evaluation metric for this task given the class imbalance?

## Architecture Onboarding

- Component map: POLCA dataset -> Hierarchical MDP framework -> LLM agents -> Reward functions -> Critique function -> Performance evaluation

- Critical path: Load POLCA data -> Initialize LLM agents -> High-level policy selects statement -> Low-level policy executes negotiation actions -> Reward functions evaluate success -> Critique function updates policies -> Compare with ground truth -> Compute macro F1 score

- Design tradeoffs:
  - Hierarchical vs flat MDP: Hierarchical structure improves interpretability and aligns with negotiation structure but adds complexity
  - LLM parameter count vs cost: gpt-3.5-turbo performs best but is more expensive than LLaMa models
  - Fixed negotiation actions vs open-ended negotiation: Fixed actions simplify training but may limit negotiation expressiveness

- Failure signatures:
  - Low macro F1 scores across all models suggest fundamental task difficulty or dataset issues
  - Large performance gaps between high-level and low-level policies indicate imbalance in policy learning
  - LLM hallucinations producing invalid statement IDs break the simulation pipeline
  - Inconsistent performance across countries suggests language or context mismatch

- First 3 experiments:
  1. Run baseline HMDP-Base (no policy learning) on a single country to establish minimum performance
  2. Compare HMDP with HMDP-LO (high-level policy removed) on the same country to isolate high-level policy contribution
  3. Test different LLM engines (gpt-3.5-turbo vs LLaMa-13b-chat) on the same country to measure parameter count impact

## Open Questions the Paper Calls Out

- Question: How does the performance of the proposed hierarchical MDP approach vary when extended to multi-party coalition negotiations (beyond the two-party setup used in this paper)?
  - Basis in paper: [explicit] The paper states "For the simplicity of modelling, we assume the negotiation occurs between two parties only. However, our formulation and method can be readily extended to multi-party negotiations."
  - Why unresolved: The paper only evaluates the model on two-party negotiations, leaving the effectiveness and potential challenges of multi-party negotiations unexplored.
  - What evidence would resolve it: Experimental results comparing the performance of the model on multi-party negotiations (3+ parties) against the two-party baseline, including analysis of increased complexity, negotiation dynamics, and model adaptability.

- Question: What is the impact of incorporating real-time feedback and dynamic policy updates during the negotiation process on the model's performance and negotiation outcomes?
  - Basis in paper: [inferred] The paper mentions that agents "learn and update their policies, adapting their strategies based on the unfolding interactions and decisions," but doesn't explicitly explore the effect of real-time feedback mechanisms.
  - Why unresolved: The current implementation uses predefined rewards and critiques, but the potential benefits of incorporating real-time feedback loops and dynamic policy updates during negotiations remain unexplored.
  - What evidence would resolve it: Comparative experiments showing the performance difference between static policy models and those with real-time feedback mechanisms, including analysis of negotiation efficiency, outcome quality, and agent adaptability.

- Question: How does the proposed approach handle negotiations involving parties with significantly different ideological stances or conflicting core values, and what strategies does it employ to reach consensus in such scenarios?
  - Basis in paper: [explicit] The paper discusses the complexity of negotiations involving diverse interests and policy priorities, but doesn't provide specific strategies for handling extreme ideological differences.
  - Why unresolved: While the model is designed to simulate negotiations, it doesn't explicitly address how it would handle cases where parties have fundamentally opposed ideologies or when reaching consensus seems unlikely.
  - What evidence would resolve it: Analysis of negotiation outcomes in scenarios with high ideological divergence, including strategies employed by the model to bridge gaps, compromise effectively, and reach agreements in challenging situations.

## Limitations

- Dataset annotation relies on GPT-4 for statement matching, but methodology and reliability remain unclear
- Performance varies significantly across countries and languages, suggesting cross-lingual understanding issues
- Models occasionally generate invalid statement IDs (hallucinations), requiring additional validation steps
- Study doesn't explore generalization to political contexts outside 2011-2013 timeframe or countries beyond six studied

## Confidence

High confidence in: Hierarchical MDP framework validity, relative performance ranking of LLM engines, dataset's value in addressing political negotiation modeling challenges

Medium confidence in: Absolute performance metrics due to potential annotation inconsistencies, generalizability of results to other political contexts, long-term stability of LLM-based negotiation agents

Low confidence in: Precise impact of hierarchical structure versus alternative approaches, how well fixed negotiation action set captures real-world negotiation behaviors

## Next Checks

1. **Annotation Validation**: Manually verify a sample of the GPT-4 annotations linking manifesto statements to coalition agreement outcomes to assess annotation quality and consistency.

2. **Cross-Country Generalization**: Test the best-performing model (gpt-3.5-turbo) on coalition negotiations from a seventh European country not included in the POLCA dataset to evaluate cross-country generalization.

3. **Open vs. Fixed Negotiation**: Implement a comparison between the current fixed-action negotiation protocol and an open-ended LLM negotiation approach to quantify the tradeoff between structure and expressiveness.