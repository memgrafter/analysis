---
ver: rpa2
title: 'Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of
  LLM Agents'
arxiv_id: '2404.16698'
source_url: https://arxiv.org/abs/2404.16698
tags:
- agents
- each
- survival
- time
- simulation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GOVSIM, a simulation platform for studying
  cooperation in LLM agents managing shared resources. It tests 15 different LLMs
  across three resource-sharing scenarios and finds that only the most powerful models
  achieve any sustainable cooperation, with survival rates below 54%.
---

# Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents

## Quick Facts
- arXiv ID: 2404.16698
- Source URL: https://arxiv.org/abs/2404.16698
- Reference count: 40
- Primary result: Only the most powerful LLM models achieve sustainable cooperation in resource-sharing scenarios, with survival rates below 54%

## Executive Summary
This paper introduces GOVSIM, a simulation platform for studying cooperation in LLM agents managing shared resources. The framework tests 15 different LLMs across three resource-sharing scenarios and finds that sustainable cooperation remains elusive for most models. The study reveals that communication between agents is critical for sustainability, reducing resource overuse by 21%, and that agents leveraging "Universalization"-based reasoning show significantly better outcomes. The work provides insights into the challenges of achieving sustainable self-government in multi-agent systems and is open-sourced for future research.

## Method Summary
The study employs GOVSIM, a phase-based simulation framework where LLM agents interact through strategy, harvesting, and discussion phases. Fifteen different LLMs (both open and closed weights) are tested across three scenarios: fishery, pasture, and pollution. The framework includes agent prompts for planning, harvesting decisions, and conversation. Experiments are conducted with 5 random seeds per configuration, using temperature=0 for reproducibility. The study measures sustainability through survival rate, survival time, total gain, efficiency, equality, and over-usage metrics.

## Key Results
- Most LLM agents fail to achieve sustainable equilibrium, with highest survival rate below 54%
- Communication between agents reduces resource overuse by 22% (t-test; p < 0.001)
- Universalization-based reasoning prompts significantly improve sustainability outcomes
- Larger models (such as GPT-4o) show better survival time and total gain across scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Communication between agents reduces resource overuse by 21%
- Mechanism: Open-ended dialogue allows agents to negotiate and coordinate on extraction limits below the sustainability threshold
- Core assumption: Agents can use natural language to form and enforce cooperative norms during the discussion phase
- Evidence anchors:
  - [abstract]: "Ablations reveal that successful multi-agent communication between agents is critical for achieving cooperation in these cases."
  - [section]: "Comparing simulations without communication with those with communication, we find that agents without communication tend to overuse the common resource by 22% (t-test; p < 0.001)."
  - [corpus]: Weak - no direct corpus evidence of the 21% reduction, but the 22% over-usage increase without communication is documented
- Break condition: If the LLM cannot generate coherent dialogue or if the negotiation fails to converge on sustainable limits

### Mechanism 2
- Claim: Universalization-based reasoning significantly improves sustainability outcomes
- Mechanism: Prompting agents to consider the universalization of their actions ("What if everybody does that?") makes the long-term consequences of collective action more salient, leading to more sustainable choices
- Core assumption: LLMs can be influenced by philosophical reasoning prompts to change their decision-making process
- Evidence anchors:
  - [abstract]: "we show that agents that leverage 'Universalization'-based reasoning, a theory of moral thinking, are able to achieve significantly better sustainability."
  - [section]: "we find that prompting agents to consider the universalization of their action [43], a process used by people when making moral judgments in social dilemmas, significantly improves survival time."
  - [corpus]: Weak - no direct corpus evidence of the specific improvement, but the concept of universalization is referenced
- Break condition: If the LLM ignores or misinterprets the universalization prompt, or if the prompt does not align with the model's reasoning capabilities

### Mechanism 3
- Claim: Larger and more powerful LLMs are more likely to achieve sustainable outcomes
- Mechanism: More capable models have better reasoning and planning abilities, allowing them to understand and adhere to sustainability constraints
- Core assumption: Model size and capability directly correlate with the ability to perform complex strategic reasoning in multi-agent environments
- Evidence anchors:
  - [abstract]: "we find that all but the most powerful LLM agents fail to achieve a sustainable equilibrium in GOVSIM, with the highest survival rate below 54%."
  - [section]: "larger models (such as GPT-4o) show better survival time and total gain, though their success varied across scenarios."
  - [corpus]: Moderate - the corpus mentions that "all but the most powerful LLM agents fail to achieve a sustainable equilibrium," supporting the claim
- Break condition: If the model's reasoning capabilities are not sufficient to overcome the inherent challenges of the resource-sharing dilemma, regardless of size

## Foundational Learning

- Concept: Resource Regeneration Dynamics
  - Why needed here: Understanding how resources regenerate over time is crucial for agents to make sustainable decisions
  - Quick check question: Given a resource of 100 units that doubles at the end of each month, what is the maximum amount that can be harvested each month to ensure the resource does not collapse?

- Concept: Multi-Agent Strategic Reasoning
  - Why needed here: Agents must reason about the actions of other agents and the collective impact on the shared resource
  - Quick check question: If each agent harvests 10 units from a 100-unit resource, and the resource doubles each month, will the resource collapse? Why or why not?

- Concept: Universalization in Moral Reasoning
  - Why needed here: Universalization prompts agents to consider the consequences of everyone acting the same way, which can lead to more sustainable decisions
  - Quick check question: How does considering "What if everybody does that?" change an agent's decision to harvest more resources?

## Architecture Onboarding

- Component map: Environment -> Agent (Planning, Harvesting, Conversation modules) -> Web Interface
- Critical path:
  1. Strategy phase: Agents reflect on past observations and plan future actions
  2. Harvesting phase: Agents submit their resource extraction amounts simultaneously
  3. Discussion phase: Agents communicate and negotiate to coordinate sustainable strategies
- Design tradeoffs:
  - Model size vs. resource requirements: Larger models perform better but require more computational resources
  - Communication vs. computation: Enabling communication improves sustainability but increases simulation runtime
  - Prompt complexity vs. model performance: More detailed prompts can improve performance but may not be effective for all models
- Failure signatures:
  - Rapid resource depletion: Indicates agents are not coordinating or reasoning about sustainability
  - Low efficiency: Suggests agents are not optimizing resource utilization
  - Inequality in resource distribution: May indicate unfair negotiation or lack of cooperation
- First 3 experiments:
  1. Run the default simulation with a small LLM (e.g., Llama-3-8B) to observe failure modes
  2. Enable communication and observe the impact on resource usage and sustainability
  3. Apply the universalization prompt and measure the improvement in survival time and efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would more complex resource-sharing scenarios (e.g., varying regeneration rates, multiple resource types, different stakeholder interests) affect LLM agents' ability to achieve sustainable cooperation?
- Basis in paper: [inferred] 
- Why unresolved: The current GOVSIM framework uses simplified scenarios with fixed resource dynamics. The paper acknowledges this limitation and suggests future work could extend the framework to incorporate more complexities.
- What evidence would resolve it: Experimental results comparing LLM agent performance in extended GOVSIM scenarios with varying regeneration rates, multiple resource types, and diverse stakeholder interests.

### Open Question 2
- Question: Can smaller LLMs be effectively fine-tuned to serve as efficient simulators in multi-agent environments without losing performance?
- Basis in paper: [inferred] 
- Why unresolved: The paper notes that current LLM capabilities limit agents' ability to negotiate successfully and act strategically. It suggests that fine-tuned smaller LLMs could potentially act as efficient simulators in larger agent populations.
- What evidence would resolve it: Comparative studies showing performance differences between standard and fine-tuned smaller LLMs in large-scale multi-agent simulations.

### Open Question 3
- Question: How do LLM agents' cooperative strategies differ when interacting with humans versus other LLMs, and which approach proves more effective?
- Basis in paper: [explicit] 
- Why unresolved: The paper identifies incorporating humans into the simulation as a promising next step, suggesting current understanding is limited to LLM-only interactions.
- What evidence would resolve it: Comparative experimental results from mixed human-LLM simulations versus LLM-only simulations, measuring cooperation effectiveness and norm formation.

## Limitations

- The framework abstracts complex social dynamics into simplified resource management tasks, limiting generalizability to real-world governance scenarios
- Current LLM capabilities significantly constrain agents' ability to negotiate successfully and act strategically in multi-agent environments
- The study's findings are constrained by the specific scenarios tested and may not extend to other types of commons problems or governance structures

## Confidence

- **High confidence**: The finding that communication between agents reduces resource overuse by 22% is well-supported by t-test results (p < 0.001) across multiple simulation runs
- **Medium confidence**: The claim that universalization-based reasoning significantly improves sustainability outcomes is supported by experimental results but lacks direct corpus evidence of the magnitude of improvement
- **Low confidence**: The assertion that the framework enables systematic study of sustainable self-government mechanisms in multi-agent systems is theoretical at this stage

## Next Checks

1. Conduct ablation studies testing different communication protocols and universalization prompt formulations to isolate which specific elements drive the observed improvements in sustainability
2. Test the framework with more diverse resource dynamics (non-linear regeneration, stochastic shocks) to evaluate robustness beyond the current controlled scenarios
3. Implement a multi-generational learning mechanism where successful agent strategies are preserved and evolved across simulation runs to assess whether cooperation can emerge through cultural transmission rather than individual reasoning alone