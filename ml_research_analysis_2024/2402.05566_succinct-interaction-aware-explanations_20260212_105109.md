---
ver: rpa2
title: Succinct Interaction-Aware Explanations
arxiv_id: '2402.05566'
source_url: https://arxiv.org/abs/2402.05566
tags:
- shap
- partition
- which
- interaction
- nshap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces iShap, a method for generating succinct,
  interpretable explanations of black-box models that account for feature interactions.
  Unlike SHAP, which only explains individual features, and nShap, which provides
  explanations for all possible feature subsets (leading to exponential complexity),
  iShap partitions features into groups that significantly interact and explains the
  model using these groups.
---

# Succinct Interaction-Aware Explanations

## Quick Facts
- arXiv ID: 2402.05566
- Source URL: https://arxiv.org/abs/2402.05566
- Authors: Sascha Xu; Joscha Cüppers; Jilles Vreeken
- Reference count: 40
- Primary result: iShap generates succinct, interpretable explanations for black-box models by partitioning features into interacting groups, outperforming SHAP, nShap, and LIME

## Executive Summary
This paper introduces iShap, a method for generating succinct, interpretable explanations of black-box models that account for feature interactions. Unlike SHAP, which only explains individual features, and nShap, which provides explanations for all possible feature subsets (leading to exponential complexity), iShap partitions features into groups that significantly interact and explains the model using these groups. The authors derive an objective function to find the optimal partition that balances reconstruction accuracy and explanation complexity, and use a statistical test to prune the search space by detecting significant interactions. Experiments show that iShap outperforms SHAP, nShap, and LIME in terms of surrogate model accuracy and recovers true interactions more effectively.

## Method Summary
iShap generates explanations by first detecting significant interactions between feature pairs using a statistical test (Welch's t-test). It then constructs an interaction graph where nodes represent features and edges represent significant interactions. The algorithm searches for the optimal partition of features into interacting groups by minimizing an objective function that balances reconstruction accuracy and explanation complexity. The final explanation is constructed using Shapley values computed for the optimal partition. The method uses either a greedy or exhaustive search strategy, with the interaction graph allowing efficient pruning of the search space.

## Key Results
- iShap achieves higher F1-scores for recovering interacting feature sets compared to SHAP, nShap, and LIME
- The method provides more accurate surrogate models (higher R²) while maintaining computational efficiency
- Case study on COVID-19 patient survival data demonstrates iShap's ability to provide more interpretable explanations than baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: iShap finds the optimal partition of features by detecting and pruning non-interacting feature pairs
- Mechanism: The algorithm uses a statistical test (Welch's t-test) to check for significant interactions between feature pairs. If no interaction is found, the pair is not grouped in the optimal partition, drastically reducing the search space
- Core assumption: If two features are not significantly interacting, they are not grouped together in the optimal partition (Theorem 1)
- Evidence anchors: [abstract] "we show how to prune sub-optimal solutions using a statistical test, which not only improves runtime but also helps to detect spurious interactions." [section 2.2] "we show how to prune sub-optimal solutions using a statistical test, which not only improves runtime but also helps to detect spurious interactions."
- Break condition: If the statistical test fails to detect true interactions (false negatives) or incorrectly identifies non-interactions as significant (false positives), the partitioning will be suboptimal

### Mechanism 2
- Claim: The optimal partition balances reconstruction accuracy and explanation complexity
- Mechanism: iShap minimizes an objective function that trades off the reconstruction error of the model's prediction (f(x) - Σv(Si))² against the complexity of the explanation (number of interactions)
- Core assumption: The regularization term (λ · Σ|Si||Si - 1|/2) effectively controls the complexity of the explanation
- Evidence anchors: [section 2.1] "Thus, we define the optimal partition Π∗ in regards the value function v of an algorithmic decision f(x) as the partition Π which minimizes Π∗ = arg min Π [f(x) − ΣSi∈Π v(Si)]² + λ · ΣSi∈Π 1/2 |Si||Si − 1|."
- Break condition: If the regularization parameter λ is not appropriately tuned, the algorithm may overfit (low λ) or underfit (high λ), leading to suboptimal explanations

### Mechanism 3
- Claim: The interaction graph allows efficient computation of the optimal partition
- Mechanism: By constructing an undirected graph where nodes represent features and edges represent significant interactions, the algorithm restricts the search space to connected components of the graph, enabling efficient computation of the optimal partition
- Core assumption: The optimal partition consists only of connected components of the interaction graph and their subsets (Theorem 3)
- Evidence anchors: [section 2.2] "Theorem 3 allows us to reject the additivity of a pair of variables i and j if they are connected by a path of interactions." [section 3.2] "By Theorem 3, we know that any pair of nodes which is connected by a path in the interaction graph is not additive."
- Break condition: If the interaction graph is incorrectly constructed (due to statistical test errors), the search space will be incorrectly restricted, leading to suboptimal partitions

## Foundational Learning

- Concept: Statistical hypothesis testing (t-test)
  - Why needed here: To determine if there is a significant interaction between two features, allowing the algorithm to prune non-interacting pairs
  - Quick check question: What is the null hypothesis tested in the interaction detection step, and what is the alternative hypothesis?

- Concept: Shapley values
  - Why needed here: To compute the contribution of each feature set in the optimal partition to the model's prediction
  - Quick check question: How are Shapley values used to construct the final explanation from the optimal partition?

- Concept: Graph theory (connected components)
  - Why needed here: To efficiently restrict the search space for the optimal partition based on the interaction graph
  - Quick check question: How does the interaction graph's structure influence the possible partitions considered by the algorithm?

## Architecture Onboarding

- Component map: Interaction detection -> Partition search -> Explanation construction
- Critical path: Interaction detection → Partition search → Explanation construction
- Design tradeoffs:
  - Greedy vs. exhaustive search: Greedy is faster but may not find the optimal partition; exhaustive is slower but guarantees optimality
  - Statistical test significance level: Higher levels may detect more interactions but also increase the risk of spurious interactions; lower levels may miss true interactions
- Failure signatures:
  - Suboptimal explanations: May indicate issues with the interaction detection step (false negatives/positives) or the partition search algorithm
  - Long runtime: May indicate the need for a more efficient search algorithm or a higher significance level in the interaction detection step
- First 3 experiments:
  1. Run iShap on a simple linear model to verify it correctly identifies no interactions and provides explanations similar to SHAP
  2. Run iShap on a synthetic dataset with known interactions to verify it correctly identifies and groups interacting features
  3. Compare the runtime and explanation quality of iShap with different search algorithms (greedy vs. exhaustive) on a medium-sized dataset

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the experimental setup and results, several areas remain unexplored. The experiments only tested up to 100 features, leaving the scalability for larger feature sets unexplored. The paper uses α = 0.01 in experiments but does not explore how varying α affects the quality of the resulting explanations. The synthetic data experiments use both multiplicative and sinusoidal inner functions, but real-world model performance with continuous interactions is not explicitly evaluated.

## Limitations

- Performance scaling with feature count beyond 100 remains untested, raising questions about computational feasibility for high-dimensional data
- The statistical test's significance level (α = 0.01) is fixed without exploring sensitivity to this parameter or determining optimal values for different datasets
- Limited evaluation of continuous feature interactions in real-world models, with most synthetic experiments using discrete or additive interactions

## Confidence

- Mechanism 1 (statistical pruning): Medium - theoretically justified but weakly supported by corpus
- Mechanism 2 (regularized objective): Medium - objective function is specified but regularization effects are unclear
- Mechanism 3 (interaction graph efficiency): Medium - relies on unproven assumptions about graph structure

## Next Checks

1. Implement synthetic experiments with controlled interactions to verify the statistical test correctly identifies true interactions while avoiding false positives
2. Test sensitivity to regularization parameter λ by comparing explanations across different values on known datasets
3. Compare runtime and solution quality between greedy and exhaustive search methods on medium-sized feature spaces to validate efficiency claims