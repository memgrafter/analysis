---
ver: rpa2
title: 'ChatGPT Role-play Dataset: Analysis of User Motives and Model Naturalness'
arxiv_id: '2403.18121'
source_url: https://arxiv.org/abs/2403.18121
tags:
- chatgpt
- role-play
- human
- dataset
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study analyzes human-AI conversations with ChatGPT, focusing
  on user motives and model naturalness. The authors created a novel dataset of 85
  conversations (1742 utterances) from participants interacting with ChatGPT in vanilla
  and role-play settings (boss and classmate).
---

# ChatGPT Role-play Dataset: Analysis of User Motives and Model Naturalness

## Quick Facts
- **arXiv ID**: 2403.18121
- **Source URL**: https://arxiv.org/abs/2403.18121
- **Reference count**: 0
- **Primary result**: Human-AI conversations analyzed for user motives and model naturalness across vanilla and role-play settings, revealing significant differences in ChatGPT's conversational quality

## Executive Summary
This study presents a novel dataset of 85 conversations (1742 utterances) examining how ChatGPT performs in vanilla versus role-play scenarios. The research focuses on user motives and model naturalness, using Gricean pragmatic theory for evaluation. Key findings show that role-play prompts significantly improve ChatGPT's naturalness by reducing AI disclaimers and verbosity, while users primarily seek conversation in their interactions. The study provides actionable insights for improving conversational AI models by demonstrating the importance of contextual framing and persona adoption.

## Method Summary
The study collected conversations from 57 participants interacting with ChatGPT in three settings: vanilla, boss role-play, and classmate role-play. Each conversation was manually annotated for user motives (Convo, Assist, Learn, Joke) and model naturalness (Nat, AI, Quan, etc.) using Gricean pragmatic theory. Statistical analyses examined utterance lengths, question rates, perplexity scores, and sentiment using tools like NLTK, BERTopic, GPT-2, and VADER. The dataset and analysis code are publicly available for reproducibility.

## Key Results
- ChatGPT's responses are significantly less natural in vanilla settings (5.6% natural) compared to role-play settings (47-52% natural)
- Users have diverse motives when interacting with ChatGPT, with conversation being the primary goal
- Role-play conversations are longer but feature shorter human utterances compared to vanilla interactions
- ChatGPT's verbosity and tendency to emphasize its AI nature reduce naturalness in vanilla mode

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Role-play prompts significantly improve ChatGPT's response naturalness by aligning the model's outputs with human conversational expectations.
- Mechanism: When ChatGPT is explicitly instructed to assume a persona, it shifts away from default AI disclaimers and adopts a more contextually appropriate tone.
- Core assumption: The persona instruction effectively overrides the model's default "AI assistant" framing.
- Evidence anchors: Vanilla naturalness at 5.6% vs. role-play naturalness at 47-52%; corpus neighbors discuss role-play in AI contexts.
- Break condition: Vague or inconsistent persona instructions may cause the model to default to AI disclaimer mode.

### Mechanism 2
- Claim: User motives directly influence the perceived naturalness of ChatGPT's responses.
- Mechanism: Alignment between user intent and ChatGPT's capabilities leads to more natural interactions; misalignment causes unnatural, verbose responses.
- Core assumption: The model accurately understands user intent to produce contextually appropriate replies.
- Evidence anchors: Conversational user motives most often resulted in unnatural responses in vanilla mode; corpus doesn't address motive-to-response alignment.
- Break condition: Ambiguous user motives or model misinterpretation leads to unnatural or irrelevant responses.

### Mechanism 3
- Claim: Longer human utterances in role-play settings correlate with more natural AI responses.
- Mechanism: Richer context from longer turns enables ChatGPT to generate more contextually grounded replies.
- Core assumption: Longer user inputs provide sufficient context for natural response generation.
- Evidence anchors: Role-play turns are typically longer; conversational motives in role-play still often resulted in unnaturally long AI responses.
- Break condition: Overly complex or off-topic longer utterances may still produce unnatural replies.

## Foundational Learning

- **Gricean Maxims**: Understanding these (Quantity, Quality, Relevance, Manner) is essential since the study uses Gricean theory to evaluate naturalness. Quick check: Which maxim is violated when ChatGPT provides too much information?
- **Sentiment Analysis (VADER)**: Used to assess user attitudes across datasets. Quick check: What sentiment trend did humans show in vanilla vs. role-play datasets?
- **Perplexity as a fluency metric**: Calculated for both human and ChatGPT text to compare naturalness. Quick check: What does a lower perplexity score indicate?

## Architecture Onboarding

- **Component map**: Data collection pipeline (user prompts → ChatGPT responses) → Annotation schema (user motives, model naturalness, feedback) → Analysis modules (statistical, topic modeling, sentiment, perplexity) → Repository (CRD dataset + code)
- **Critical path**: 1) Collect conversations under vanilla and role-play conditions 2) Manually annotate each utterance 3) Run statistical and linguistic analyses 4) Interpret results for conversational AI improvements
- **Design tradeoffs**: Manual annotation ensures quality but limits dataset size; Gricean theory provides linguistic grounding but may miss other naturalness aspects; role-play improves naturalness but may not generalize
- **Failure signatures**: Low inter-rater agreement indicates unclear annotation criteria; high perplexity in human utterances signals data quality issues; over-reliance on AI disclaimers suggests model bias
- **First 3 experiments**: 1) Compare naturalness scores between vanilla and role-play datasets 2) Analyze correlation between user motive categories and model naturalness 3) Run sentiment analysis on user feedback across settings

## Open Questions the Paper Calls Out

- **How does ChatGPT's role-play performance compare to human-human interactions in similar contexts?**: The paper shows ChatGPT performs better in role-play than vanilla mode, but lacks direct comparison to human-human role-play interactions using the same naturalness criteria.
- **How do different types of role-play scenarios affect user motives and ChatGPT's naturalness?**: Only boss and classmate scenarios were examined, limiting generalizability to other interaction types.
- **How do user expectations and prior experience with chatbots influence their interactions with ChatGPT?**: The study notes varying prior experience but doesn't explore how this affects interaction patterns or naturalness evaluations.

## Limitations

- Manual annotation approach ensures quality but limits dataset size and may not capture full diversity of human-AI interactions
- Gricean pragmatic theory may miss other important dimensions of conversational quality like emotional intelligence
- Role-play scenarios (boss and classmate) are narrow in scope and may not represent all conversational contexts
- Findings may not generalize to other conversational AI systems or different ChatGPT versions

## Confidence

- **High Confidence**: ChatGPT produces less natural responses in vanilla vs. role-play settings (5.6% vs 47-52% natural); AI disclaimers and verbosity reduce naturalness
- **Medium Confidence**: User motives influence perceived naturalness, though confounded by other factors; correlation between longer human utterances and natural AI responses is suggestive but not proven
- **Low Confidence**: Generalizability to other AI systems or ChatGPT versions is uncertain; practical implementation of improvements needs further validation

## Next Checks

1. **Cross-model validation**: Test naturalness differences across multiple ChatGPT versions and other conversational AI systems like Claude or Gemini
2. **Real-world deployment study**: Deploy ChatGPT in actual workplace scenarios (boss persona) and measure long-term naturalness impact on task completion and user satisfaction
3. **Alternative naturalness frameworks**: Re-analyze dataset using sociolinguistic approaches or emotional intelligence metrics to determine if Gricean theory captures the most important aspects of naturalness