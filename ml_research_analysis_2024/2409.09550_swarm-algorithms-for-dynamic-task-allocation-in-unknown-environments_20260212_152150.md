---
ver: rpa2
title: Swarm Algorithms for Dynamic Task Allocation in Unknown Environments
arxiv_id: '2409.09550'
source_url: https://arxiv.org/abs/2409.09550
tags:
- task
- tasks
- agents
- algorithm
- prop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces three new swarm algorithms for dynamic task
  allocation in unknown environments, where tasks appear randomly and independently
  at unknown locations. The first algorithm is a variant of a distributed algorithm
  based on propagating task information, which includes specialized agents that use
  propagated task information to probabilistically choose which task to move towards.
---

# Swarm Algorithms for Dynamic Task Allocation in Unknown Environments

## Quick Facts
- arXiv ID: 2409.09550
- Source URL: https://arxiv.org/abs/2409.09550
- Authors: Adithya Balachandran; Noble Harasha; Nancy Lynch
- Reference count: 7
- Primary result: Three novel swarm algorithms for dynamic task allocation outperform baseline Levy walk, especially at low and medium task rates

## Executive Summary
This work introduces three new swarm algorithms for dynamic task allocation in unknown environments where tasks appear randomly and independently at unknown locations. The algorithms build upon a task propagation framework where specialized agents communicate task information to followers, who then move to complete tasks. The first algorithm modifies task propagation with probabilistic task selection, the second uses a division of labor approach combining propagation with Levy random walks, and the third allows dynamic switching between the two strategies. The primary results show that when tasks appear slowly, the task propagation algorithm completes tasks more efficiently than the Levy random walk algorithm, achieving a 17% lower task completion time.

## Method Summary
The paper presents three algorithms for dynamic task allocation in a grid environment where tasks appear according to a Poisson process. The algorithms involve propagators (one per grid location) that store and broadcast task information, and followers that move to complete tasks based on received information. The three algorithms are: a modified task propagation algorithm with probabilistic task selection (PROP), a division of labor approach where some agents use PROP while others perform independent Levy random walks (DL), and a hybrid algorithm where agents dynamically switch between the two strategies. The performance is evaluated through simulations measuring average task completion time and unsatisfied task demand across varying task rates.

## Key Results
- When tasks appear slowly, PROP algorithm achieves 17% lower task completion time than Levy random walk baseline
- DL and hybrid algorithms outperform both PROP and RW algorithms at low and medium task rates
- At high task rates, Levy random walk strategy performs as well or better than the novel approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The PROP algorithm uses communication to relay task information to multiple agents, enabling efficient task completion when tasks appear slowly.
- Mechanism: Propagators store task information (location and residual demand) and broadcast it to other propagators within their influence radius every tp rounds. Followers read this information and probabilistically move toward tasks based on demand and distance, clumping around tasks to complete them efficiently.
- Core assumption: When tasks appear slowly, there is enough time for propagators to communicate information before new tasks arrive, and enough agents can be allocated to each task.
- Evidence anchors:
  - [abstract]: "when tasks appear slowly, our variant of a distributed algorithm based on propagating task information completes tasks more efficiently than a Levy random walk algorithm, achieving a 17% lower task completion time."
  - [section]: "When tasks appear slowly, clustering is effective because there are enough agents to send a large group of agents to each task as it arrives."
- Break condition: If tasks appear too quickly, clumping prevents agents from reaching new tasks promptly, and the communication overhead becomes excessive relative to task discovery speed.

### Mechanism 2
- Claim: The DL algorithm combines the benefits of PROP and RW by allocating a proportion of agents to each algorithm, alleviating clumping issues at high task rates.
- Mechanism: A proportion PPROP of followers run the PROP algorithm while the remainder perform RW independently. This creates a balance between communication-based task discovery (PROP) and exploration-based discovery (RW).
- Core assumption: At high task rates, some agents need to remain dispersed (via RW) to discover new tasks quickly, while others can use communication to complete known tasks efficiently.
- Evidence anchors:
  - [abstract]: "We show that our division of labor and hybrid algorithms can perform better than both our algorithm based on propagated task information and the Levy walk algorithm, especially at low and medium task rates."
  - [section]: "The DL and hybrid algorithms alleviate this issue by allocating some agents to conducting a Levy random walk."
- Break condition: If PPROP is set too high at high task rates, clumping re-emerges; if too low, the benefits of communication are lost.

### Mechanism 3
- Claim: The hybrid algorithm allows agents to dynamically switch between PROP and RW, balancing exploration and exploitation over time.
- Mechanism: Each agent performs RW for tRW rounds before switching to PROP, and after completing any task, returns to RW for tRW rounds. This creates a dynamic allocation where some agents are always exploring while others are exploiting known task information.
- Core assumption: Periodic exploration after task completion helps discover new tasks faster, while periods of communication-based allocation help complete known tasks efficiently.
- Evidence anchors:
  - [abstract]: "Finally, we introduce a hybrid algorithm where each agent dynamically switches between using propagated task information and following a Levy random walk."
  - [section]: "This may result in agents discovering tasks faster, which can result in the PROP component of the hybrid algorithm more efficiently sending agents to task locations."
- Break condition: If tRW is too large, too many agents are exploring at once, reducing overall efficiency; if too small, insufficient exploration occurs.

## Foundational Learning

- Concept: Poisson point process for task arrival
  - Why needed here: The model assumes tasks appear independently at each location following an exponential distribution, which is fundamental to understanding the dynamic task environment.
  - Quick check question: If λ = 0.001 tasks per round per location, what is the expected time until the next task appears at a given location?

- Concept: Levy random walk distribution
  - Why needed here: The baseline algorithm uses Levy random walks with heavy-tailed step size distributions, which is crucial for understanding the comparison baseline.
  - Quick check question: How does a Levy distribution with heavy tails differ from a Gaussian distribution in terms of step size probabilities?

- Concept: Influence radius and communication propagation
  - Why needed here: The algorithms rely on limited communication ranges where propagators share information with neighbors within a certain radius.
  - Quick check question: If a propagator at (10,10) has influence radius 2, which grid locations can it communicate with directly?

## Architecture Onboarding

- Component map: Propagators (M×N agents, one per grid location, no task completion ability) → Followers (F agents, task completion ability) → Task appearance process (Poisson) → Performance metrics (completion time, unsatisfied demand)
- Critical path: Task appears → Propagators receive and broadcast information → Followers receive information → Followers move toward task → Followers complete task demand → Task disappears
- Design tradeoffs: Communication overhead vs. exploration efficiency; clumping vs. dispersion; fixed vs. dynamic allocation of agents to algorithms
- Failure signatures: High unsatisfied demand indicates poor task discovery; high completion time indicates poor task allocation; sudden performance degradation suggests parameter mismatch with task rate
- First 3 experiments:
  1. Run PROP vs RW comparison at low task rate (λ = 1e-5) to verify 17% improvement claim
  2. Test DL algorithm with varying PPROP values (0.2, 0.5, 0.8) at medium task rate to find optimal ratio
  3. Vary tRW in hybrid algorithm (5, 50, 200) at high task rate to observe exploration-exploitation balance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does swarm density affect the performance of PROP and hybrid algorithms?
- Basis in paper: [inferred] The paper suggests future work could evaluate the effect of swarm density on algorithm performance.
- Why unresolved: The paper does not provide any simulation results or analysis of swarm density effects.
- What evidence would resolve it: Simulation results showing task completion times and unsatisfied demand metrics for different swarm densities.

### Open Question 2
- Question: What is the optimal influence radius for the hybrid algorithm when followers have limited influence radius but propagators can instantaneously communicate task information?
- Basis in paper: [inferred] The paper mentions this as a specific case to study in future work.
- Why unresolved: This specific scenario was not tested in the simulations.
- What evidence would resolve it: Simulation results comparing hybrid algorithm performance with different influence radius combinations.

### Open Question 3
- Question: How robust are the different algorithms to noisy information about tasks and possible individual robot failure?
- Basis in paper: [explicit] The paper suggests studying this problem with additional realistic assumptions.
- Why unresolved: The paper does not include any analysis of algorithm robustness to noise or failures.
- What evidence would resolve it: Simulation results showing algorithm performance degradation under various noise and failure conditions.

## Limitations
- Performance comparison is highly sensitive to parameter settings (PPROP, tRW, influence radius) with optimal values not systematically explored across full range of task rates
- The 17% improvement claim lacks confidence intervals or statistical significance testing
- Communication mechanism assumes reliable broadcasting without modeling potential packet loss or delays
- Limited validation across different grid sizes, agent densities, and task demand distributions

## Confidence

- **High Confidence**: The core algorithmic framework and state transition mechanisms are clearly specified and reproducible
- **Medium Confidence**: The comparative performance claims are supported by simulation results but lack rigorous statistical analysis
- **Low Confidence**: The generalizability of parameter settings across different environmental conditions is not established

## Next Checks

1. Conduct statistical significance testing on performance differences between algorithms across multiple simulation runs to establish confidence intervals
2. Perform systematic parameter sweeps for PPROP and tRW to identify robust settings across the full spectrum of task rates
3. Test algorithm performance on larger grid sizes (100×100) and with varied agent-to-task ratios to assess scalability limits