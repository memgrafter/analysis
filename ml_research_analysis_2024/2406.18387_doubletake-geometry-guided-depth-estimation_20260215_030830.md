---
ver: rpa2
title: 'DoubleTake: Geometry Guided Depth Estimation'
arxiv_id: '2406.18387'
source_url: https://arxiv.org/abs/2406.18387
tags:
- depth
- geometry
- hint
- volume
- cost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DoubleTake, a geometry-guided depth estimation
  method that leverages historical 3D geometry data as an additional input to improve
  instantaneous depth predictions from monocular video sequences. The key innovation
  is using a "Hint MLP" to combine cost volume features from multi-view stereo with
  a rendered depth map from a global 3D reconstruction (TSDF) built from previous
  depth estimates, along with a confidence measure for the prior geometry.
---

# DoubleTake: Geometry Guided Depth Estimation

## Quick Facts
- **arXiv ID**: 2406.18387
- **Source URL**: https://arxiv.org/abs/2406.18387
- **Reference count**: 40
- **Primary result**: State-of-the-art depth estimation performance on ScanNetV2 with 0.0767 Abs Diff in incremental mode

## Executive Summary
DoubleTake introduces a geometry-guided depth estimation method that leverages historical 3D geometry data as an additional input to improve instantaneous depth predictions from monocular video sequences. The key innovation is using a "Hint MLP" to combine cost volume features from multi-view stereo with a rendered depth map from a global 3D reconstruction (TSDF) built from previous depth estimates, along with a confidence measure for the prior geometry. This approach addresses limitations of traditional MVS methods by providing additional geometric information from areas not visible in the current keyframes and from long-term scene revisits. The method achieves state-of-the-art performance on depth estimation and 3D reconstruction tasks, running at interactive speeds.

## Method Summary
DoubleTake combines multi-view stereo with persistent 3D geometry to improve monocular depth estimation. The system uses two EfficientNetV2 S encoders to extract features from current and neighboring frames, constructs a cost volume, and processes it with a Matching MLP. A Hint MLP then combines cost volume features with geometry hints rendered from a TSDF (Truncated Signed Distance Function) that accumulates depth estimates from previous frames. The TSDF provides both short-term hints (from recently seen areas) and long-term hints (from revisited locations). A confidence map estimates the reliability of geometry hints at each pixel. The system is trained with a mixed data augmentation strategy, using geometry hints for half the training samples and no hints for the other half, to ensure graceful degradation when hints are unavailable.

## Key Results
- Achieves 0.0767 Abs Diff and 0.0369 Abs Rel on ScanNetV2 in incremental mode
- Outperforms SimpleRecon (0.0873 Abs Diff, 0.0430 Abs Rel) and DeepVideoMVS (0.1186 Abs Diff, 0.0583 Abs Rel)
- Demonstrates robustness to pose errors and scene changes
- Runs at interactive speeds suitable for AR applications

## Why This Works (Mechanism)

### Mechanism 1
The Hint MLP effectively combines multi-view stereo cost volume information with prior geometry rendered from a TSDF. By taking as input (i) the matching score from the cost volume, (ii) the absolute difference between rendered depth hint and current depth plane, and (iii) the confidence value at that pixel, the Hint MLP can selectively weight prior geometry information based on its reliability.

### Mechanism 2
Maintaining a persistent TSDF allows the system to provide geometry hints from both short-term and long-term temporal perspectives. The TSDF accumulates depth estimates from previous frames, creating a global 3D representation that can be rendered from any camera position, providing hints for both recently seen areas and previously visited locations.

### Mechanism 3
The confidence map provides a learned estimate of when to trust prior geometry versus relying on current frame information. By sampling voxel confidence values from the TSDF and including them as input to the Hint MLP, the network can learn to downweight geometry hints from areas with low confidence (e.g., distant surfaces, previously unobserved regions).

## Foundational Learning

- **Concept: Truncated Signed Distance Function (TSDF) representation**
  - Why needed here: TSDF provides an efficient way to represent and update 3D geometry incrementally while supporting fast rendering for geometry hints
  - Quick check question: How does a TSDF differ from a voxel occupancy grid, and why is this difference important for depth estimation?

- **Concept: Multi-view stereo cost volume construction**
  - Why needed here: Understanding how cost volumes encode depth likelihood estimates is crucial for comprehending how the Hint MLP combines this information with prior geometry
  - Quick check question: What is the relationship between cost volume depth planes and actual depth values in the scene?

- **Concept: Mesh rendering from volumetric representations**
  - Why needed here: The system renders the TSDF as a mesh to generate geometry hints, requiring understanding of marching cubes and GPU-based rendering
  - Quick check question: Why is marching cubes used to extract a mesh from the TSDF rather than directly sampling depth values from the volumetric representation?

## Architecture Onboarding

- **Component map**: Feature extraction backbone (EfficientNetV2 S and ResNet18) -> Cost volume construction with Matching MLP -> Hint MLP (with geometry hints) -> Depth decoder (UNet++ style) -> TSDF management system -> Mesh rendering pipeline (PyTorch3D)

- **Critical path**: RGB frames → Feature extraction → Cost volume → Hint MLP (with geometry hints) → Depth prediction → TSDF update

- **Design tradeoffs**: Using 2D convolutions instead of 3D for cost volume processing trades some accuracy for significant memory savings; the TSDF resolution (2cm) balances detail with memory requirements; confidence values are clamped to minimum of 0.25 to prevent complete loss of distant geometry information

- **Failure signatures**: Performance degradation when revisiting scenes with significant object movement; reduced accuracy for transparent or reflective surfaces (like other MVS methods); limited effectiveness in long corridors where geometry hints only cover small image regions

- **First 3 experiments**: 1) Run the baseline SimpleRecon model on ScanNetV2 to establish performance without geometry hints; 2) Implement the Hint MLP with synthetic geometry hints (constant depth values) to verify the combination mechanism works; 3) Add real TSDF rendering and confidence generation, then test with incremental TSDF updates to validate the complete pipeline

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed method's performance scale with longer-term revisits to environments, and what are the practical limits of relying on historical geometry hints? The paper discusses using long-term hints from previous visits to the same environment (3RScan dataset), but doesn't explore the limits of this approach or how performance changes with time between visits.

### Open Question 2
How does the confidence estimation in the TSDF voxel grid affect the quality of the depth hints, and can this confidence measure be further improved? The paper mentions incorporating a confidence measure for the prior geometry but doesn't extensively explore how this confidence estimation impacts performance or potential improvements.

### Open Question 3
How does the proposed method handle dynamic scenes where objects move between the time the TSDF is created and when the current frame is processed? The paper mentions robustness to scene changes in the 3RScan experiments but doesn't provide detailed analysis of how dynamic scenes affect performance.

## Limitations

- Evaluation primarily conducted on a single dataset (ScanNetV2) with relatively controlled indoor environments
- Method's performance may not generalize to outdoor scenes or environments with significantly different characteristics
- Reliance on accurate pose estimates introduces a vulnerability that could degrade performance with significant drift

## Confidence

- **Mechanism (combining cost volume with prior geometry)**: High
- **State-of-the-art claims on ScanNetV2**: Medium
- **Benefits for long-term scene mapping**: Medium
- **Performance on dynamic scenes**: Low (not thoroughly evaluated)

## Next Checks

1. **Cross-dataset generalization**: Evaluate DoubleTake on outdoor datasets like KITTI to verify performance generalizes beyond indoor scenes and assess sensitivity to different scene characteristics.

2. **Pose error sensitivity**: Systematically vary the pose accuracy (adding synthetic noise to camera poses) to quantify the method's robustness to pose estimation errors and identify failure thresholds.

3. **Long-term consistency test**: Implement a test where the camera revisits scenes after extended periods with significant environmental changes to validate claims about robustness to scene changes and effectiveness of long-term geometry reuse.