---
ver: rpa2
title: Consistency-diversity-realism Pareto fronts of conditional image generative
  models
arxiv_id: '2406.10429'
source_url: https://arxiv.org/abs/2406.10429
tags:
- high
- consistency
- diversity
- realism
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates conditional image generative models along
  consistency, diversity, and realism dimensions, proposing consistency-diversity-realism
  Pareto fronts as a comprehensive evaluation framework. The authors systematically
  vary model knobs (guidance scale, post-hoc filtering, retrieval-augmentation, and
  compression rate) across multiple text-to-image and image&text-to-image models,
  quantifying performance using DSG score for consistency, recall for marginal diversity,
  precision for marginal realism, and DreamSim-based metrics for conditional diversity
  and realism.
---

# Consistency-diversity-realism Pareto fronts of conditional image generative models

## Quick Facts
- arXiv ID: 2406.10429
- Source URL: https://arxiv.org/abs/2406.10429
- Authors: Pietro Astolfi; Marlene Careil; Melissa Hall; Oscar MaÃ±as; Matthew Muckley; Jakob Verbeek; Adriana Romero Soriano; Michal Drozdzal
- Reference count: 19
- Primary result: No single model performs best across consistency, diversity, and realism; earlier models like LDM1.5 often dominate Pareto fronts

## Executive Summary
This paper introduces consistency-diversity-realism Pareto fronts as a comprehensive evaluation framework for conditional image generative models. The authors systematically vary model knobs including guidance scale, post-hoc filtering, retrieval-augmentation, and compression rate across multiple text-to-image and image&text-to-image models. Their analysis reveals that recent models excel in realism and consistency but sacrifice diversity, with earlier models like LDM1.5 performing better on diversity. The study also identifies geographic disparities, showing that older models dominate Pareto fronts across all regions.

## Method Summary
The paper evaluates conditional image generative models by systematically varying model knobs (guidance scale, post-hoc filtering, retrieval-augmentation, and compression rate) across multiple text-to-image and image&text-to-image models. Performance is quantified using DSG score for consistency, recall for marginal diversity, precision for marginal realism, and DreamSim-based metrics for conditional diversity and realism. The authors construct Pareto fronts by identifying non-dominated configurations across the three objectives, providing a holistic view of model performance tradeoffs.

## Key Results
- Recent models (LDMXL, LDM2.1-UnCLIP) excel in realism and consistency but sacrifice diversity compared to earlier models
- LDM1.5 consistently appears in Pareto fronts across all geographical regions, outperforming more recent models
- Guidance scale and post-hoc filtering have the highest effect on consistency-diversity and realism-diversity tradeoffs
- No single model performs best across all objectives; choice depends on specific application requirements

## Why This Works (Mechanism)

### Mechanism 1
Pareto fronts provide a structured way to capture and visualize tradeoffs between consistency, diversity, and realism in conditional image generation. By varying model knobs and computing corresponding scores, the paper constructs Pareto optimal sets where no configuration can improve one objective without worsening another. This allows direct comparison across multiple objectives rather than relying on single scalar metrics.

### Mechanism 2
Increasing guidance scale trades diversity for consistency and realism, but realism improvements saturate earlier than consistency improvements. Higher guidance scale biases sampling toward more deterministic outputs aligned with the conditioning prompt, increasing consistency and realism but reducing diversity as samples become more similar to each other.

### Mechanism 3
Geographic representation disparities exist in image generative models, with earlier models like LDM1.5 showing better balanced performance across regions. By computing Pareto fronts on a geodiverse dataset (GeoDE), the paper reveals that more recent models sacrifice diversity for consistency and realism in a region-dependent manner, whereas LDM1.5 maintains relatively balanced performance.

## Foundational Learning

- Concept: Multi-objective optimization and Pareto optimality
  - Why needed here: The paper evaluates models across three objectives simultaneously, requiring understanding of how to compare and optimize across multiple, potentially conflicting goals
  - Quick check question: If model A has higher consistency and realism than model B but lower diversity, and model C has higher diversity than both but lower consistency and realism, which models would appear on the Pareto front?

- Concept: Conditional image generation metrics
  - Why needed here: The paper uses specific metrics (DSG for consistency, DreamSim for diversity, precision/recall for realism) to quantify each objective
  - Quick check question: What is the difference between conditional and marginal diversity metrics, and why might a model score differently on each?

- Concept: Diffusion model sampling techniques
  - Why needed here: The paper ablates guidance scale and post-hoc filtering as knobs controlling generation properties
  - Quick check question: How does increasing guidance scale in classifier-free guidance affect the trade-off between conditioning alignment and sample diversity?

## Architecture Onboarding

- Component map: Models (LDM1.5, LDM2.1, LDMXL, LDMXL-Turbo, PerCo, RDM, LDM2.1-UnCLIP) -> Metrics (DSG, DreamSim, precision/recall) -> Knobs (guidance scale, filtering, retrieval, compression) -> Datasets (MSCOCO, GeoDE)

- Critical path: 1. Load model and set knob configuration 2. Generate images conditioned on prompts 3. Compute consistency, diversity, and realism scores 4. Aggregate results across prompts/datasets 5. Construct Pareto fronts by identifying non-dominated configurations

- Design tradeoffs: Sampling more knob values increases Pareto front accuracy but also computational cost; using conditional vs. marginal metrics affects which models appear optimal; including geographic analysis reveals disparities but requires additional dataset and computation

- Failure signatures: Pareto fronts dominated by a single model across all objectives (suggests missing important tradeoffs); large gaps between Pareto optimal and non-optimal points (suggests knobs have strong effects); inconsistent results between conditional and marginal metrics (suggests metrics capture different aspects)

- First 3 experiments: 1. Generate Pareto fronts for a single model (e.g., LDM1.5) across all three objective pairs to understand knob effects 2. Compare Pareto fronts of LDM1.5 vs. LDMXL on MSCOCO to see historical progress tradeoffs 3. Generate region-specific Pareto fronts on GeoDE to identify geographic disparities

## Open Questions the Paper Calls Out

### Open Question 1
What is the fundamental limit of the consistency-diversity-realism tradeoff in conditional image generative models? The paper demonstrates clear tradeoffs but doesn't establish whether these are fundamental or could be overcome by future model improvements.

### Open Question 2
How would different training datasets affect the consistency-diversity-realism Pareto fronts? The paper notes they haven't studied the effect of different data distributions, calling it "very hard to study due to the closed data filtering recipes of most models."

### Open Question 3
What is the optimal guidance scale for balancing consistency and diversity across different types of prompts? The paper shows guidance scale affects the tradeoff but doesn't explore prompt-dependent optimal values.

### Open Question 4
How do closed-source state-of-the-art models compare to open models on the consistency-diversity-realism Pareto fronts? The paper only considers open models because "evaluating closed models is very expensive or sometimes not possible."

## Limitations
- The study only examines diffusion models, excluding other generative architectures
- Pareto front sampling may be incomplete with only 19 guidance scale values tested
- The analysis doesn't explore prompt-dependent optimal knob configurations

## Confidence
- **High**: Claims about guidance scale effects on consistency-diversity-realism tradeoffs
- **Medium**: Geographic disparity findings, particularly the superiority of LDM1.5 across regions
- **Medium**: The overall framework of using Pareto fronts for multi-objective evaluation

## Next Checks
1. Replicate the Pareto front analysis using a finer grid of guidance scale values (e.g., 0.5-15.0 in 0.5 increments) to verify the stability of identified frontiers
2. Test the geographic disparity findings by training a newer model (e.g., LDMXL) on a geographically balanced dataset to isolate architecture vs. data effects
3. Validate the DreamSim metric implementations by comparing against ground-truth diversity measurements on synthetic datasets with known diversity properties