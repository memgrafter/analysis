---
ver: rpa2
title: Practical and Reproducible Symbolic Music Generation by Large Language Models
  with Structural Embeddings
arxiv_id: '2407.19900'
source_url: https://arxiv.org/abs/2407.19900
tags:
- music
- structural
- embeddings
- time
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of generating symbolic music
  using large language models, focusing on the need for effective structural embeddings
  that do not rely on domain-specific annotations like bars and beats. The authors
  develop a MIDI-based music generation framework inspired by MuseNet, employing four
  types of structural embeddings: part, type, time, and pitch-class.'
---

# Practical and Reproducible Symbolic Music Generation by Large Language Models with Structural Embeddings

## Quick Facts
- arXiv ID: 2407.19900
- Source URL: https://arxiv.org/abs/2407.19900
- Authors: Seungyeon Rhyu; Kichang Yang; Sungjun Cho; Jaehyeon Kim; Kyogu Lee; Moontae Lee
- Reference count: 0
- One-line primary result: Sinusoidal initialization of temporal embeddings enhances repeated pattern generation, while random initialization improves naturalness and prompt consistency in symbolic music generation

## Executive Summary
This paper addresses the challenge of generating symbolic music using large language models without relying on domain-specific annotations like bars and beats. The authors develop a MIDI-based music generation framework that employs four types of structural embeddings (part, type, time, and pitch-class) to capture musical structure. Through systematic evaluation using metrics like Structureness Indicators (SI), Chord Progression Variation Rationality (CPVR), and Chord Progression Irregularity (CPI), the study demonstrates that initialization methods significantly impact generation performance, with sinusoidal initialization excelling at pattern repetition and random initialization yielding more natural-sounding music.

## Method Summary
The paper implements a MIDI-like event-based tokenization scheme with 4,196 input tokens, including note-on, note-off, time-shift, and special tokens. The GPT-2 model is enhanced with four structural embedding layers: part (128 temporal divisions), type (4 token categories), time (relative timing), and pitch-class (12 pitch classes plus silence). These embeddings are concatenated with token embeddings and projected to match the model's hidden size. The study compares truncated normal, sinusoidal, and random initialization methods for these embeddings, training on Pop1k7 and GiantMIDI-Piano datasets and evaluating on MAESTRO.

## Key Results
- Sinusoidal initialization of temporal embeddings improves Structureness Indicators for all interval lengths and prompt lengths
- Random initialization achieves the highest number of wins in subjective evaluation for naturalness and prompt maintenance
- GPT2-RE (random initialization) shows significantly improved ability to create plausible and prompt-consistent music compared to the basic GPT-2 baseline

## Why This Works (Mechanism)

### Mechanism 1
Structural embeddings enable the model to encode both vertical and horizontal musical structure without requiring domain-specific annotations like bars or beats. The paper implements four structural embedding layers—part, type, time, and pitch-class—that capture temporal segmentation, token type, relative timing, and tonal information respectively. These embeddings are concatenated with token embeddings and projected to the model's hidden size, allowing the model to directly condition on structural information during generation. Core assumption: Raw MIDI data can be meaningfully segmented into parts (128 temporal divisions) and that pitch-class alone can represent tonal context without explicit chord boundary detection.

### Mechanism 2
Sinusoidal initialization of temporal embeddings preserves continuity in ordinal musical attributes and enhances repeated pattern generation. Time and part embeddings are initialized using sinusoidal lookup tables with different scaling factors (w=10 for part, w=1 for time) to ensure orthogonality. This initialization preserves the ordinal nature of temporal information, allowing the model to better learn repeating patterns across different time scales. Core assumption: Musical time attributes benefit from sinusoidal encoding because they represent continuous ordinal values rather than categorical ones.

### Mechanism 3
Random initialization of structural embeddings improves naturalness and prompt consistency by allowing the model to learn embeddings that better match the specific characteristics of the training data. When structural embeddings are randomly initialized, the model learns to adapt these embeddings to capture patterns specific to the training dataset rather than being constrained by predetermined sinusoidal patterns. This flexibility leads to more natural-sounding music and better preservation of prompt characteristics. Core assumption: The specific characteristics of the training data (Pop1k7 and GiantMIDI-Piano) benefit from learned rather than predetermined embedding patterns.

## Foundational Learning

- **Event-based MIDI tokenization**: The paper uses a MIDI-like tokenization scheme with 4,196 different input tokens (note-on, note-off, time-shift, and special tokens) that preserves the sequential nature of music while capturing simultaneous notes and varying durations. Quick check: How many different note-on tokens are used in the tokenization scheme, considering 32 quantized velocities and 128 pitch numbers?

- **Positional encoding vs. structural embeddings**: The paper distinguishes between standard positional encodings used in text generation and structural embeddings specifically designed for music's vertical (harmony) and horizontal (counterpoint) structures. Quick check: What are the four types of structural embeddings implemented, and how do they differ from standard positional encodings?

- **Objective evaluation metrics for music generation**: The paper uses Structureness Indicators (SI), Chord Progression Variation Rationality (CPVR), and Chord Progression Irregularity (CPI) to quantitatively evaluate the structural and harmonic qualities of generated music. Quick check: What is the relationship between CPVR and CPI scores, and what does this relationship indicate about the generated music?

## Architecture Onboarding

- **Component map**: Token → Structural embeddings → Concatenation → Projection → Positional encoding → GPT-2 → Next-token prediction
- **Critical path**: Token → Part/Type/Time/Pitch-class embeddings → Concatenation → Fully-connected projection → Positional encoding → GPT-2 → Next-token prediction
- **Design tradeoffs**:
  - Using 128 temporal parts provides fine-grained temporal information but may be too granular for some musical styles
  - Sinusoidal vs. random initialization offers a tradeoff between preserving ordinal continuity and learning data-specific patterns
  - Event-based tokenization preserves musical detail but requires more tokens than bar-based approaches
- **Failure signatures**:
  - Poor Structureness Indicators with sinusoidal initialization may indicate inappropriate temporal scaling
  - Low naturalness scores with random initialization may suggest overfitting to training data
  - High CPVR but low CPI may indicate overly repetitive chord progressions
- **First 3 experiments**:
  1. Train baseline GPT-2 without structural embeddings on the same dataset to establish performance floor
  2. Compare sinusoidal vs. random initialization on a subset of the validation set using SI, CPVR, and CPI metrics
  3. Test different numbers of temporal parts (e.g., 64, 128, 256) to find optimal granularity for the training data

## Open Questions the Paper Calls Out

### Open Question 1
How does the effectiveness of structural embeddings vary across different musical genres beyond pop and classical? Basis in paper: The paper evaluates structural embeddings on pop and classical datasets (Pop1k7, GiantMIDI-Piano, and MAESTRO) but does not explore other genres. Why unresolved: The study focuses on specific datasets, leaving the generalizability of structural embeddings to other musical genres untested. What evidence would resolve it: Testing the model on diverse genres like jazz, rock, or world music to evaluate performance consistency.

### Open Question 2
What is the impact of using more granular time-shift tokens (e.g., smaller intervals than 10 ms) on the quality of generated music? Basis in paper: The paper uses 100 time-shift tokens representing intervals from 10 ms to 1000 ms but does not explore finer granularity. Why unresolved: The choice of time-shift granularity is not experimentally varied, leaving its effect on musical naturalness and coherence unknown. What evidence would resolve it: Conducting experiments with different time-shift granularities and comparing the resulting music quality.

### Open Question 3
How do structural embeddings influence the long-term coherence of generated music beyond the one-minute generation limit used in the study? Basis in paper: The study generates music up to one minute, but does not investigate longer-term structural coherence. Why unresolved: The experiments are limited to short sequences, so the embeddings' effectiveness in maintaining coherence over longer compositions is unclear. What evidence would resolve it: Generating and evaluating music sequences of several minutes to assess structural consistency and thematic development.

## Limitations

- The evaluation relies heavily on proxy metrics rather than perceptual listening tests for most comparisons
- The study lacks direct comparison to models without structural embeddings to quantify the contribution of the framework
- Subjective evaluation sample size is limited, comparing only two initialization methods for naturalness and prompt maintenance

## Confidence

**High Confidence**: The technical implementation of structural embeddings (part, type, time, pitch-class) is clearly specified and follows established practices from text generation. The distinction between sinusoidal and random initialization methods is well-defined.

**Medium Confidence**: The claim that structural embeddings enable encoding of vertical and horizontal musical structure without domain-specific annotations is supported by the architecture description but lacks direct empirical validation through ablation studies.

**Medium Confidence**: The finding that sinusoidal initialization enhances repeated pattern generation while random initialization improves naturalness is based on both quantitative metrics and subjective evaluation, though the subjective evaluation sample size is limited.

## Next Checks

1. **Ablation Study**: Train a baseline GPT-2 model without structural embeddings on the same datasets and compare performance using SI, CPVR, and CPI metrics to quantify the contribution of structural embeddings.

2. **Cross-Genre Evaluation**: Test the model on multiple music genres beyond the training datasets to assess whether the structural embeddings generalize across different musical styles and structures.

3. **Long-Distance Structure Analysis**: Evaluate the model's ability to maintain coherent musical structure over longer generation sequences (beyond the 16-second evaluation period) to validate claims about long-range structure preservation.