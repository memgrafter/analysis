---
ver: rpa2
title: An efficient search-and-score algorithm for ancestral graphs using multivariate
  information scores
arxiv_id: '2412.17508'
source_url: https://arxiv.org/abs/2412.17508
tags:
- information
- ancestral
- graphs
- terms
- edges
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a search-and-score algorithm for learning ancestral
  graphs that include both directed and bidirected edges arising from unobserved latent
  variables. The method uses a normalized likelihood score based on multivariate information
  over "ac-connected" subsets of variables, which are connected through collider paths
  confined to ancestor sets.
---

# An efficient search-and-score algorithm for ancestral graphs using multivariate information scores

## Quick Facts
- arXiv ID: 2412.17508
- Source URL: https://arxiv.org/abs/2412.17508
- Reference count: 40
- This paper presents a search-and-score algorithm for learning ancestral graphs that include both directed and bidirected edges arising from unobserved latent variables.

## Executive Summary
This paper introduces a novel search-and-score algorithm for learning ancestral graphs from observational data containing latent variables. The method uses normalized likelihood scores based on multivariate information over "ac-connected" subsets of variables, which are connected through collider paths confined to ancestor sets. The approach operates in two steps: first optimizing node scores to prime edge orientations and remove false positives, then optimizing edge scores to orient remaining edges based on local likelihood contributions. Experiments demonstrate the method outperforms both the starting MIIC algorithm and FCI on challenging benchmark datasets, particularly on small datasets where latent variables are present.

## Method Summary
The algorithm takes as input categorical data and uses MIIC predictions as a starting point, then applies a two-step greedy search-and-score optimization. Step 1 minimizes node scores to orient surrounding edges and remove likely false positives by computing local normalized log likelihood contributions. Step 2 optimizes edge orientation scores based on local contributions to the global likelihood, restricted to ac-connected subsets with up to two-collider paths. The method uses Normalized Maximum Likelihood (NML) regularization instead of BIC to better handle finite sample sizes. The algorithm is specifically designed to handle complex graphical models with large parameter spaces and latent variables, making it particularly effective for small to moderate sized datasets.

## Key Results
- The algorithm outperforms both baseline MIIC and FCI on precision and recall for complex graphical models with latent variables
- Performance advantages are most pronounced on small datasets (N ≤ 10,000) where the method shows significant improvements
- The approach maintains good precision while improving recall compared to baseline methods, with better handling of bidirected edges from latent variables
- The method demonstrates effectiveness across multiple benchmark datasets including Alarm, Insurance, Barley, and Mildew models with varying complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm decomposes likelihood into contributions from ac-connected subsets, enabling efficient scoring.
- Mechanism: By expressing the cross-entropy of ancestral graphs as a sum of multivariate information over ac-connected subsets, the algorithm can compute local scores that approximate the global likelihood. This decomposition isolates contributions from collider paths confined to ancestor sets, allowing the search-and-score approach to work with tractable local computations.
- Core assumption: The ac-connected subsets capture all necessary information for likelihood computation while ignoring non-ac-connected subsets that cancel out mathematically.
- Evidence anchors:
  - [abstract] "The normalized likelihood score of ancestral graphs is estimated in terms of multivariate information over relevant 'ac-connected subsets' of vertices"
  - [section] "Theorem 1 characterizes in particular the Markov equivalence class of ancestral graphs [8, 19–24] as, Corollary 2. Two ancestral graphs are Markov equivalent if and only if they have the same ac-connected subsets of vertices."
- Break condition: If the ac-connected subset definition fails to capture necessary information for likelihood computation, or if non-ac-connected subsets don't mathematically cancel out.

### Mechanism 2
- Claim: The two-step algorithm efficiently orients edges by first removing false positives then optimizing edge orientations.
- Mechanism: Step 1 minimizes node scores to orient surrounding edges and remove likely false positives. Step 2 optimizes edge orientation scores based on local contributions to the global likelihood, restricted to ac-connected subsets with up to two-collider paths. This hierarchical approach reduces the search space and focuses computational effort where it matters most.
- Core assumption: Local information scores limited to close surrounding vertices provide sufficient information for accurate edge orientation.
- Evidence anchors:
  - [section] "For computational efficiency, the proposed two-step algorithm relies on local information scores limited to the close surrounding vertices of each node (step 1) and edge (step 2)."
  - [section] "Step 1 consists in minimizing a node score corresponding to the local normalized log likelihood of each node w.r.t. its possible parents or spouses amongst the connected nodes predicted by MIIC."
- Break condition: If higher-order information contributions beyond two-collider paths are necessary for accurate orientation, or if local scores are insufficient to distinguish between competing edge orientations.

### Mechanism 3
- Claim: The use of Normalized Maximum Likelihood (NML) regularization prevents overfitting on finite datasets.
- Mechanism: The algorithm uses fNML complexity terms in both node and edge scores to account for finite sample size effects. This normalization normalizes the likelihood function over all possible datasets with the same number of samples, providing better finite-sample behavior than BIC regularization.
- Core assumption: NML regularization provides better finite-sample performance than BIC for the problem domain.
- Evidence anchors:
  - [section] "In order to better take into account finite sample size, we used instead the (universal) Normalized Maximum Likelihood (NML) criterion [42, 43, 38, 39]"
  - [section] "However, BIC regularization tends to overestimate finite size corrections, leading to lower recall, in general."
- Break condition: If the NML complexity computation becomes numerically unstable for the dataset sizes considered, or if NML doesn't provide the expected finite-sample benefits.

## Foundational Learning

- Concept: Multivariate information and cross-information
  - Why needed here: The algorithm relies on decomposing likelihood into multivariate information terms over ac-connected subsets. Understanding how these measures capture dependencies beyond pairwise correlations is crucial for implementing and debugging the algorithm.
  - Quick check question: What is the difference between mutual information I(X;Y) and multivariate information I(X;Y;Z) for three variables?

- Concept: Ancestral graphs and ac-connecting paths
  - Why needed here: The algorithm specifically works with ancestral graphs and uses ac-connecting paths to define which subsets contribute to the likelihood. Understanding these graph structures is essential for implementing the ac-connected subset detection.
  - Quick check question: How does an ac-connecting path differ from a general connecting path in terms of collider constraints?

- Concept: Search-and-score algorithm framework
  - Why needed here: The algorithm follows a greedy search-and-score approach, iteratively improving the graph structure. Understanding this framework helps in implementing the iterative optimization steps and handling convergence.
  - Quick check question: What is the difference between a greedy search-and-score approach and exhaustive search in terms of computational complexity and solution quality?

## Architecture Onboarding

- Component map:
  - MIIC pre-processing -> Step 1 (Node score optimization) -> Step 2 (Edge orientation optimization) -> Output final graph structure

- Critical path:
  1. Initialize with MIIC predictions
  2. Step 1 loop until convergence (node score minimization)
  3. Step 2 loop until convergence or limit cycle (edge orientation optimization)
  4. Output final graph structure

- Design tradeoffs:
  - Local vs global scoring: The algorithm uses local scores for computational efficiency but may miss global optima
  - Two-collider path limitation: Restricting to ac-connected subsets with up to two-collider paths reduces computation but may miss some dependencies
  - NML vs BIC regularization: NML provides better finite-sample behavior but is computationally more expensive

- Failure signatures:
  - Poor recall despite good precision: Likely indicates insufficient exploration of edge orientations in Step 2
  - Oscillating scores without convergence: May indicate limit cycles in Step 2 that need detection and handling
  - Slow convergence: Could indicate overly conservative score thresholds or inefficient ac-connected subset detection

- First 3 experiments:
  1. Run on a simple three-node model with known ground truth to verify basic functionality and scoring
  2. Test on a model with latent variables to verify bidirected edge detection capability
  3. Benchmark against MIIC alone on a moderate-sized dataset to quantify performance improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the MIIC_search&score algorithm scale with dataset size beyond the tested range of N ≤ 20,000 samples?
- Basis in paper: [explicit] The paper states "MIIC_search&score is also found to outperform FCI on both precision and recall on small datasets (e.g. N ≤ 10, 000 samples) of complex graphical models... while reaching similar performance at larger sample sizes or for simpler graphical models"
- Why unresolved: The experiments only tested up to 20,000 samples, and asymptotic behavior for much larger datasets is not explored.
- What evidence would resolve it: Extensive benchmarking of the algorithm on datasets with sample sizes ranging from 10,000 to 1,000,000 samples, comparing performance metrics across different dataset complexities.

### Open Question 2
- Question: What is the theoretical guarantee of consistency for the MIIC_search&score algorithm when applied to ancestral graphs with latent variables?
- Basis in paper: [inferred] The paper mentions that "MIIC_search&score... uses also higher-order local information scores to compare alternative subgraphs" and "This computational strategy... is shown to outperform state-of-the-art causal discovery methods on challenging benchmark datasets" but does not provide theoretical consistency proofs.
- Why unresolved: While the paper demonstrates empirical performance, it does not establish theoretical guarantees about the algorithm's ability to recover true causal structures in the limit of infinite data.
- What evidence would resolve it: Formal proofs of consistency under various conditions, including different types of latent variable structures and dataset sizes.

### Open Question 3
- Question: How sensitive is the MIIC_search&score algorithm to the choice of regularization parameters and initial conditions?
- Basis in paper: [explicit] The paper states "The predictions of this recent version of MIIC... have been used as starting point for the subsequent local search-and-score method implemented in the present paper" and mentions using "a normalized likelihood score based on multivariate information" but does not discuss sensitivity to parameter choices.
- Why unresolved: The algorithm relies on several heuristic components including regularization terms and initial MIIC predictions, but the paper does not explore how variations in these components affect final performance.
- What evidence would resolve it: Systematic sensitivity analysis showing how performance metrics vary with different choices of regularization strength, initial conditions, and algorithmic parameters across multiple benchmark datasets.

## Limitations

- The algorithm's performance claims are based on specific benchmark datasets with known ground truth structures, limiting generalizability to real-world data with unknown latent structures
- The two-collider path limitation may miss important dependencies in complex models with deeper causal chains that require higher-order information terms
- Performance on continuous data after discretization has not been thoroughly evaluated, restricting the method's applicability to categorical datasets

## Confidence

- Mechanism 1 (ac-connected subset decomposition): **High** - Well-supported by theoretical foundations and mathematical proofs
- Mechanism 2 (two-step optimization): **Medium** - Sound in principle but practical effectiveness depends on implementation details and parameter tuning
- Mechanism 3 (NML regularization): **Medium** - Supported by literature but specific benefits for this algorithm need more empirical validation

## Next Checks

1. Test the algorithm on synthetic datasets with varying numbers of latent variables (beyond the 0-20% range) to identify performance boundaries and potential failure modes
2. Compare the two-collider path limitation against variants that incorporate higher-order information terms to quantify the tradeoff between computational efficiency and accuracy
3. Evaluate performance on continuous data (after discretization) to assess practical utility beyond the categorical data focus of current experiments