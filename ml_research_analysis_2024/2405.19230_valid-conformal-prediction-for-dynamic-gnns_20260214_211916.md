---
ver: rpa2
title: Valid Conformal Prediction for Dynamic GNNs
arxiv_id: '2405.19230'
source_url: https://arxiv.org/abs/2405.19230
tags:
- prediction
- time
- block
- graph
- conformal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses uncertainty quantification in dynamic graph
  neural networks (GNNs) using conformal prediction. It proposes using the unfolded
  representation of dynamic graphs as input to standard GNNs, enabling valid prediction
  sets in both transductive and semi-inductive regimes.
---

# Valid Conformal Prediction for Dynamic GNNs

## Quick Facts
- arXiv ID: 2405.19230
- Source URL: https://arxiv.org/abs/2405.19230
- Authors: Ed Davis; Ian Gallagher; Daniel John Lawson; Patrick Rubin-Delanchy
- Reference count: 40
- Primary result: Valid prediction sets for dynamic GNNs via unfolded representations

## Executive Summary
This paper addresses uncertainty quantification in dynamic graph neural networks using conformal prediction. The authors propose using the unfolded representation of dynamic graphs as input to standard GNNs, enabling valid prediction sets in both transductive and semi-inductive regimes. The unfolded approach avoids temporal misalignment issues present in standard block-diagonal methods. Theoretical guarantees of validity are provided, requiring no assumptions in the transductive case and exchangeability under stationarity in the semi-inductive case.

## Method Summary
The method constructs a dilated unfolding matrix from the dynamic graph adjacency matrices and applies standard GNN architectures to obtain node/time pair embeddings. Split conformal prediction is then applied using these embeddings to generate valid prediction sets. The approach works in both transductive regimes (where test labels are available) and semi-inductive regimes (where only historical labels are available), with different theoretical guarantees for each.

## Key Results
- UGNNs provide valid coverage with smaller prediction sets than block diagonal GNNs
- Higher accuracy in semi-inductive settings compared to baselines that resort to random guessing
- Theoretical guarantees of validity without assumptions in transductive regime, and with exchangeability in semi-inductive regime
- Empirical validation on simulated and real-world datasets (School, Flight, Trade) demonstrating improved performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The unfolded matrix representation enables exchangeability over time for conformal prediction
- Mechanism: By concatenating adjacency matrices along columns and duplicating them in a dilated unfolding structure, node/time pairs become embedded in a bipartite graph where temporal positions can be permuted without affecting likelihood
- Core assumption: The columns of the dynamic graph adjacency matrices, along with node attributes and labels, are jointly exchangeable across time points
- Evidence anchors:
  - [abstract] "We propose to use unfolding, which allows any existing static GNN to output a dynamic graph embedding with exchangeability properties"
  - [section 2] "We will repurpose a standard GNN, designed for static graphs, into producing dynamic graph embeddings with desirable exchangeability properties"
  - [corpus] Weak evidence - only indirect mentions of exchangeability in related conformal prediction work
- Break condition: If the dynamic graph exhibits strong temporal drift or non-stationary behavior, the exchangeability assumption fails and validity is lost

### Mechanism 2
- Claim: Split conformal prediction achieves validity without exchangeability in the transductive regime
- Mechanism: By randomly selecting the test point among calibration points, the non-conformity score for the test point becomes exchangeable with calibration scores, guaranteeing coverage regardless of underlying distribution properties
- Core assumption: The test label is missing completely at random among calibration points at the same time
- Evidence anchors:
  - [section 2] "For some m < |ν|, the missing label is missing completely at random among the first m + 1 node/time pairs of ν"
  - [section 2] "In the transductive regime, a valid confidence set can be constructed with no further assumptions"
  - [corpus] No direct evidence - this is a novel theoretical contribution
- Break condition: If the test point selection is not truly random (e.g., deterministic selection), validity is lost

### Mechanism 3
- Claim: UGNNs maintain predictive accuracy while providing uncertainty quantification
- Mechanism: The unfolding structure preserves the original graph structure while enabling temporal exchangeability, allowing standard GNN architectures to learn meaningful representations without temporal shift artifacts
- Core assumption: The GNN architecture is label equivariant (outputs reorder when inputs reorder)
- Evidence anchors:
  - [section 2] "Assumption 2 is relatively mild and roughly satisfied by standard GNN architectures"
  - [section 3] "UGNN has higher accuracy in every semi-inductive example and most transductive examples"
  - [corpus] Moderate evidence - related work on RoCP-GNN suggests robustness improves with proper uncertainty quantification
- Break condition: If the GNN architecture violates label equivariance (e.g., uses positional encodings tied to specific time points), validity fails

## Foundational Learning

- Concept: Exchangeability and its role in conformal prediction
  - Why needed here: The validity of conformal prediction in semi-inductive regimes relies on exchangeability of test and calibration points
  - Quick check question: If we permute the time points in a dynamic graph, under what conditions does the joint distribution of node attributes and labels remain unchanged?

- Concept: Tensor unfolding and its properties
  - Why needed here: The unfolded matrix structure is the mathematical foundation that enables exchangeability in dynamic graphs
  - Quick check question: What is the dimensionality relationship between the original dynamic graph tensor and its unfolded matrix representation?

- Concept: Split vs full conformal prediction
  - Why needed here: Understanding the difference helps explain why validity can be achieved with fewer assumptions in the transductive regime
  - Quick check question: How does random selection of the test point in split conformal prediction create exchangeability between test and calibration scores?

## Architecture Onboarding

- Component map: Dynamic graph tensor -> Dilated unfolding matrix -> Standard GNN -> Node/time embeddings -> Non-conformity scores -> Prediction sets
- Critical path:
  1. Construct dilated unfolding matrix from dynamic graph
  2. Apply standard GNN to obtain node/time embeddings
  3. Compute non-conformity scores using adaptive prediction sets
  4. Calibrate threshold using calibration set
  5. Generate prediction sets for test points
- Design tradeoffs:
  - Unfolding doubles the matrix size, increasing computational cost
  - Standard GNNs work but may not be optimized for bipartite structures
  - Transductive regime requires no assumptions but needs labeled test points
  - Semi-inductive regime needs exchangeability but works with historical labels only
- Failure signatures:
  - Invalid coverage indicates exchangeability assumption violation
  - Large prediction sets suggest poor model calibration or temporal shift
  - Random guessing accuracy indicates block diagonal approach failing in semi-inductive regime
  - Temporal drift visible in prediction set size variation across time
- First 3 experiments:
  1. Verify exchangeability: Shuffle time points in synthetic dynamic SBM and confirm UGNN embeddings remain unchanged in distribution
  2. Compare accuracy: Run UGNN vs block diagonal GNN on transductive and semi-inductive versions of same dataset
  3. Test validity: Check coverage across time points for both regimes using synthetic data with known exchangeability properties

## Open Questions the Paper Calls Out
The paper mentions several open questions but doesn't provide detailed answers. Key areas include extending the framework to handle more complex temporal dependencies and improving conditional coverage guarantees while maintaining the set size advantages of the unfolded approach.

## Limitations
- Framework's validity critically depends on exchangeability assumptions in the semi-inductive regime, which may not hold for dynamic graphs with strong temporal trends or drift
- Unfolded matrix representation doubles computational complexity, potentially limiting scalability
- Theoretical guarantees require specific missing-data mechanisms in the transductive case, which may not align with practical data collection scenarios

## Confidence

### Mechanism 1 (Exchangeability via unfolding): Medium
- While the theoretical construction is sound, empirical validation of exchangeability in real-world dynamic graphs is limited

### Mechanism 2 (Split conformal validity): High
- This is a well-established result in conformal prediction literature, though the specific application to dynamic graphs is novel

### Mechanism 3 (Accuracy preservation): Medium
- The experimental results show improvements, but the sample size of datasets is relatively small

## Next Checks
1. Test exchangeability assumption: Apply UGNN to synthetic dynamic graphs with known temporal drift and measure coverage degradation to quantify the limits of validity
2. Scale experiment: Evaluate UGNN performance on larger dynamic graphs (e.g., 10K+ nodes) to assess computational overhead and memory requirements
3. Missing-data mechanism verification: Design experiments specifically testing the transductive regime under different missing-data patterns to verify the theoretical assumptions about label availability