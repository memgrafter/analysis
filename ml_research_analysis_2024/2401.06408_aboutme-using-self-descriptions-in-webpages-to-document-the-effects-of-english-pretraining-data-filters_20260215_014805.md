---
ver: rpa2
title: 'AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English
  Pretraining Data Filters'
arxiv_id: '2401.06408'
source_url: https://arxiv.org/abs/2401.06408
tags:
- quality
- rate
- pages
- topic
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the lack of scrutiny in data curation for large
  language models, focusing on how "quality" and English language filters affect web
  content. It introduces a new dataset, AboutMe, which links web text to social and
  geographic contexts by extracting self-descriptions from website ABOUT pages.
---

# AboutMe: Using Self-Descriptions in Webpages to Document the Effects of English Pretraining Data Filters

## Quick Facts
- arXiv ID: 2401.06408
- Source URL: https://arxiv.org/abs/2401.06408
- Reference count: 40
- One-line primary result: Quality filters act as topical domain filters and langID systems can exclude English content from non-anglophone regions.

## Executive Summary
This paper addresses the lack of scrutiny in data curation for large language models, focusing on how "quality" and English language filters affect web content. The study introduces a new dataset, AboutMe, which links web text to social and geographic contexts by extracting self-descriptions from website ABOUT pages. By applying ten filters from prior literature, the research analyzes whose pages are retained or removed based on topical interests, social roles, and geographic locations. Results show that model-based quality filters act like topical domain filters, and English language identification can overlook content from non-anglophone regions. The dataset and findings encourage further research on data curation practices and their social implications.

## Method Summary
The study extracts ABOUT pages from the Common Crawl dataset (CCNet) and pairs them with random pages from the same hostnames. Social dimensions are extracted using clustering for topics, classification for individual/organization status, token classification for roles, and geoparsing for locations. Ten filters are applied: four model-based quality filters, one perplexity-based quality filter, three heuristic-based quality filters, and four English language identification systems. The analysis examines filtering rates by social dimension, performs regression analysis, and includes manual inspection of edge cases.

## Key Results
- Quality filters act as implicit topical domain filters, favoring topics well-represented in reference corpora.
- LangID systems can exclude English content from non-anglophone regions due to monolingual assumptions.
- Filter scores correlate with societal status indicators like occupational prestige and salary.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Quality filters implicitly act as topical domain filters.
- Mechanism: The filters learn to score text based on similarity to reference corpora, so they favor or disfavor entire topical clusters that are over- or under-represented in those corpora.
- Core assumption: The reference corpora (Wikipedia, OpenWebText, Books3) are not topically uniform, so the classifiers inherit those biases.
- Evidence anchors:
  - [abstract] "we show that some quality classifiers act like topical domain filters"
  - [section 4.1] "Despite both being trained on Wikipedia, a perplexity-based filter behaves differently from a linear classifier... WIKI and WIKI WEBBOOKS tend to prefer topics well-represented on Wikipedia"
  - [corpus] Weak — no explicit topical breakdown of reference corpora provided.
- Break condition: If reference corpora become more topically balanced, or if filters are explicitly trained to ignore topical signals.

### Mechanism 2
- Claim: LangID systems can exclude English content from non-anglophone regions due to monolingual assumptions.
- Mechanism: LangID is applied at document level and often assumes monolingual input, so multilingual or code-switched pages from regions where English is used alongside other languages get filtered out.
- Core assumption: English in non-core anglophone regions often coexists with other languages in the same document.
- Evidence anchors:
  - [abstract] "langID can overlook English content from some regions of the world"
  - [section 4.4] "Non-English paragraphs in AboutMe reflect their geography... Thus, simply choosing to communicate in English is not necessarily grounds for inclusion"
  - [corpus] Weak — no explicit multilingual dataset examples provided.
- Break condition: If langID systems are applied at sub-document level or trained to handle multilingual documents.

### Mechanism 3
- Claim: Filter scores correlate with societal status indicators like occupational prestige and salary.
- Mechanism: The filters assign higher scores to content from individuals with higher prestige occupations, leading to unequal representation in pretraining data.
- Core assumption: Language use in ABOUT pages reflects occupational prestige and status, and filters can detect these cues.
- Evidence anchors:
  - [abstract] "we show that some quality classifiers act like topical domain filters"
  - [section 4.3] "We find small yet significant relationships between occupational prestige and model-based quality scores"
  - [corpus] Moderate — prestige data from Hughes et al. (2022) is referenced but not fully detailed.
- Break condition: If filter training data is balanced across occupational prestige levels or if prestige signals are explicitly masked.

## Foundational Learning

- Concept: Text classification and filtering pipelines
  - Why needed here: The paper relies on understanding how different types of filters (model-based quality, heuristic-based quality, langID) affect web content.
  - Quick check question: What are the key differences between a logistic regression quality classifier and a rule-based heuristic filter?

- Concept: Sociolinguistic variation and language ideology
  - Why needed here: The study connects filtering outcomes to social dimensions like occupation, geography, and topical interests.
  - Quick check question: How might sociolinguistic theories about language and identity help explain why certain occupations are filtered more than others?

- Concept: Geoparsing and entity linking
  - Why needed here: The study uses geoparsing to associate webpages with geographic locations, which affects filtering analysis.
  - Quick check question: What are the main challenges in geoparsing named entities from web text, and how might these affect the study's geographic analyses?

## Architecture Onboarding

- Component map: CCNet crawl -> ABOUT pages identification -> paired with random page -> social dimension extraction (clustering, classification, geoparsing) -> filtering (10 filters) -> analysis (filtering rates, regression, manual inspection)

- Critical path:
  1. Extract ABOUT pages from CCNet
  2. Apply social dimension extraction methods
  3. Apply each filter to the full dataset
  4. Calculate filtering rates by social dimension
  5. Run regression analysis
  6. Perform manual inspection of edge cases

- Design tradeoffs:
  - Using ABOUT pages limits scope to self-reported information but enables large-scale analysis
  - Applying filters independently rather than in sequence simplifies analysis but doesn't reflect real-world layering
  - Focusing on English limits generalizability but enables use of existing analysis tools

- Failure signatures:
  - Low recall in geoparsing → underrepresentation of geographic patterns
  - Classifier overconfidence → misclassification of individual/org status
  - Topical clustering instability → inconsistent topic labels across runs

- First 3 experiments:
  1. Replicate filtering analysis with a different k value for topical clustering to check stability
  2. Apply filters sequentially (e.g., quality then langID) to see how layering affects outcomes
  3. Test langID at paragraph level vs. document level on a multilingual sample to quantify impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do data curation filters affect the representation of non-binary and gender-diverse individuals in web-based pretraining datasets?
- Basis in paper: Explicit - The paper discusses the use of pronoun-based features in classifying individuals vs. organizations, and acknowledges the potential mishandling of non-binary individuals by these methods. It also mentions the presence of neopronouns in the dataset but notes the limitations in accurately identifying them.
- Why unresolved: The study's methodology and data analysis primarily rely on pronoun series and traditional named entity recognition, which may not capture the diverse ways non-binary individuals express their identities online. The paper highlights this as a limitation but does not provide quantitative data on the impact of filtering on non-binary representation.
- What evidence would resolve it: A dedicated analysis of neopronoun usage and its correlation with filtering scores, including a comparison of filtering rates for individuals with neopronouns versus traditional pronouns. Additionally, exploring alternative methods for identifying non-binary individuals beyond pronoun-based features.

### Open Question 2
- Question: To what extent do the effects of data curation filters on web content vary across different content types (e.g., text, images, videos) and how does this impact the overall composition of pretraining datasets?
- Basis in paper: Inferred - The paper focuses on text-based analysis and filtering, but mentions that some highly filtered topical clusters (e.g., fashion, photography) may be primarily visual in nature. This suggests that the study's findings might not fully capture the impact of filtering on multimedia content.
- Why unresolved: The research methodology is limited to analyzing text data extracted from web pages, without considering the potential effects of filtering on other content types. The paper acknowledges this limitation but does not explore the implications for multimedia content.
- What evidence would resolve it: A comprehensive analysis of the distribution of different content types (text, images, videos) in the pretraining dataset and their respective filtering rates. This would involve developing methods to analyze and filter multimedia content, as well as investigating the potential biases introduced by excluding certain content types.

### Open Question 3
- Question: How do the choices of reference corpora for model-based quality filters influence the filtering of web content and what are the implications for the diversity of perspectives in pretraining datasets?
- Basis in paper: Explicit - The paper demonstrates that different quality filters, trained on various reference corpora (e.g., Wikipedia, OpenWebText, Books3), exhibit distinct preferences for certain topical domains. This suggests that the choice of reference corpus can significantly impact the filtering process and the resulting dataset composition.
- Why unresolved: While the paper highlights the differences in filtering behavior across various reference corpora, it does not delve into the specific reasons behind these preferences or their broader implications for the diversity of perspectives in pretraining datasets. The study focuses on identifying the effects of filtering rather than exploring the underlying causes.
- What evidence would resolve it: A detailed analysis of the topical distribution and linguistic characteristics of different reference corpora, and their relationship to the filtering preferences of model-based quality filters. This would involve comparing the topical coverage, writing styles, and linguistic features of various reference corpora and examining how these factors influence the filtering process and the resulting dataset composition.

## Limitations
- Reliance on ABOUT pages as a proxy for self-descriptions may not be representative of all web content.
- Geographic analyses depend on geoparsing accuracy, which can be error-prone for ambiguous location references.
- Filtering analysis is limited by using filters independently rather than in realistic stacked configurations.

## Confidence
- **High confidence**: Quality filters act as implicit topical domain filters, supported by direct comparison of filtering rates across topic clusters.
- **Medium confidence**: Relationship between filter scores and occupational prestige shows small effect sizes and relies on external prestige data.
- **Medium confidence**: Observation about langID systems overlooking English content from non-anglophone regions lacks systematic quantification of effect size.

## Next Checks
1. Replicate the filtering analysis with sequential application of filters (e.g., quality then langID) to better approximate real-world pretraining data curation pipelines and assess whether interaction effects change the observed patterns.
2. Conduct a systematic evaluation of geoparsing accuracy on the AboutMe dataset, comparing against a manually annotated subset to quantify error rates and their impact on geographic analyses.
3. Perform an analysis of filtering outcomes when applying langID at paragraph level versus document level on a stratified sample of multilingual documents to measure the practical impact of the monolingual assumption.