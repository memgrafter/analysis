---
ver: rpa2
title: 'Generating Knowledge Graphs from Large Language Models: A Comparative Study
  of GPT-4, LLaMA 2, and BERT'
arxiv_id: '2412.07412'
source_url: https://arxiv.org/abs/2412.07412
tags:
- knowledge
- graph
- llama
- bert
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces an automated approach for generating Knowledge
  Graphs (KGs) using Large Language Models (LLMs) to address limitations of traditional
  KG creation methods. By leveraging GPT-4, LLaMA 2, and BERT to extract entities
  and relationships directly from unstructured text, the research evaluates their
  performance using precision, recall, F1-score, Graph Edit Distance, and semantic
  similarity.
---

# Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT

## Quick Facts
- arXiv ID: 2412.07412
- Source URL: https://arxiv.org/abs/2412.07412
- Reference count: 2
- GPT-4 achieves highest semantic fidelity and structural accuracy with F1-score of 0.82 and semantic similarity of 0.87

## Executive Summary
This study introduces an automated approach for generating Knowledge Graphs (KGs) using Large Language Models (LLMs) to address limitations of traditional KG creation methods. By leveraging GPT-4, LLaMA 2, and BERT to extract entities and relationships directly from unstructured text, the research evaluates their performance using precision, recall, F1-score, Graph Edit Distance, and semantic similarity. Results show GPT-4 achieves the highest semantic fidelity and structural accuracy (F1-score: 0.82, semantic similarity: 0.87), while LLaMA 2 performs moderately (F1-score: 0.77, semantic similarity: 0.82), and BERT lags behind (F1-score: 0.72, semantic similarity: 0.77). This work demonstrates the potential of LLMs to streamline KG creation, enhancing GraphRAG accessibility and accuracy for real-world applications.

## Method Summary
The study uses LLMs (GPT-4, LLaMA 2, BERT) to extract entities and relationships from unstructured text, specifically a small excerpt from the Wikipedia page on C programming language. The generated KGs are compared against manually validated ground truth using five evaluation metrics: Precision, Recall, F1-Score, Graph Edit Distance, and Semantic Similarity (cosine similarity). The methodology involves preprocessing input text, generating KGs through LLM interfaces, parsing outputs into structured formats, and evaluating results through quantitative metrics and visualization.

## Key Results
- GPT-4 achieves superior performance with F1-score of 0.82 and semantic similarity of 0.87
- LLaMA 2 provides moderate performance with F1-score of 0.77 and semantic similarity of 0.82
- BERT trails with F1-score of 0.72 and semantic similarity of 0.77, showing challenges in entity-relationship modeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 achieves superior semantic fidelity because it has better contextual understanding than LLaMA 2 and BERT, allowing it to correctly infer implicit relationships from unstructured text.
- Mechanism: GPT-4's transformer architecture with larger context window and more parameters allows it to capture nuanced semantic relationships between entities that are not explicitly stated in the text.
- Core assumption: Larger context window and more parameters directly translate to better relationship inference capabilities.
- Evidence anchors:
  - [abstract] "GPT-4 achieves superior semantic fidelity and structural accuracy (F1-score: 0.82, semantic similarity: 0.87)"
  - [section] "GPT-4's graph demonstrates greater structural completeness and alignment with the ground truth"
- Break condition: When the input text contains domain-specific jargon or technical terms that require specialized knowledge beyond GPT-4's training data.

### Mechanism 2
- Claim: LLaMA 2 performs moderately well due to its balance between computational efficiency and contextual understanding, making it suitable for lightweight, domain-specific graphs.
- Mechanism: LLaMA 2's smaller parameter size compared to GPT-4 reduces computational overhead while maintaining sufficient contextual understanding for moderately complex relationship extraction.
- Core assumption: There exists an optimal trade-off between model size and performance for specific KG generation tasks.
- Evidence anchors:
  - [abstract] "LLaMA 2 excels in lightweight, domain-specific graphs"
  - [section] "LLaMA 2 provides a balance between performance and resource constraints"
- Break condition: When the complexity of relationships exceeds the model's capacity to maintain accuracy while preserving computational efficiency.

### Mechanism 3
- Claim: BERT lags behind because its bidirectional encoder architecture is less effective at generating coherent entity-relationship pairs from unstructured text compared to autoregressive models.
- Mechanism: BERT's masked language modeling objective focuses on token prediction rather than sequence generation, making it less suited for creating structured outputs like KGs.
- Core assumption: The objective function during pre-training significantly impacts a model's ability to generate structured knowledge representations.
- Evidence anchors:
  - [abstract] "BERT provides insights into challenges in entity-relationship modeling"
  - [section] "BERT trails with a lower F1-Score of 0.72"
- Break condition: When the task requires generating structured outputs rather than understanding context for classification or prediction tasks.

## Foundational Learning

- Concept: Knowledge Graph structure and terminology (nodes, edges, predicates)
  - Why needed here: Understanding KG terminology is essential for interpreting evaluation metrics and results, and for implementing the KG generation pipeline.
  - Quick check question: What is the difference between a node and an edge in a knowledge graph?

- Concept: Precision, Recall, and F1-Score metrics
  - Why needed here: These metrics are used to evaluate the accuracy of relationship extraction, which is the core output of the KG generation process.
  - Quick check question: If a model identifies 80 relationships and 70 are correct, what is its precision?

- Concept: Graph Edit Distance (GED) calculation
  - Why needed here: GED is used to measure structural similarity between generated and ground truth graphs, providing insight into the model's ability to preserve graph topology.
  - Quick check question: What does a lower GED value indicate about the similarity between two graphs?

## Architecture Onboarding

- Component map: Data Preprocessing -> LLM Interface -> KG Generation Module -> Evaluation Engine -> Visualization Layer
- Critical path:
  1. Preprocess input text
  2. Generate KG using selected LLM
  3. Parse output into structured format
  4. Compare against ground truth using evaluation metrics
  5. Visualize results
- Design tradeoffs:
  - Model selection: GPT-4 offers best accuracy but highest cost/compute
  - Input size: Larger text excerpts provide more context but increase processing time
  - Ground truth creation: Manual validation ensures accuracy but is labor-intensive
  - Metric selection: Balance between quantitative (precision/recall) and qualitative (visualization) evaluation
- Failure signatures:
  - Low precision: Model generates many incorrect relationships (over-generation)
  - Low recall: Model misses many actual relationships (under-generation)
  - High GED: Structural differences between generated and ground truth graphs
  - Low semantic similarity: Generated relationships don't capture intended meaning
- First 3 experiments:
  1. Test each model on the provided C programming language excerpt and compare F1-scores
  2. Vary input text length to determine optimal context size for each model
  3. Compare model performance on technical vs. general domain text to identify specialization patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the performance metrics of LLMs in KG generation scale when applied to larger, more complex datasets beyond the C programming language excerpt?
- Basis in paper: [explicit] The paper notes that due to GPU constraints, the analysis used a small excerpt from the Wikipedia page on the C programming language, but suggests that future research could extend this work by testing on larger, more complex datasets.
- Why unresolved: The study's scope was limited to a small dataset due to computational constraints, leaving the scalability and performance of LLMs in KG generation on larger datasets untested.
- What evidence would resolve it: Conducting experiments with larger and more diverse datasets to evaluate whether the performance trends observed with the C programming language excerpt hold true, and to identify any new challenges or limitations that arise with increased data complexity.

### Open Question 2
- Question: What are the specific challenges and limitations of using BERT for KG generation compared to more advanced LLMs like GPT-4 and LLaMA 2?
- Basis in paper: [explicit] The paper indicates that BERT lags behind GPT-4 and LLaMA 2 in KG generation, particularly in generating relationships that capture the nuances of the input data, and suggests that BERT struggles with the complexities of this task.
- Why unresolved: The paper provides a comparative analysis but does not delve into the underlying reasons for BERT's limitations or the specific challenges it faces in entity-relationship modeling.
- What evidence would resolve it: A detailed analysis of BERT's performance, identifying specific aspects of entity and relationship extraction where it underperforms, and exploring whether these limitations are inherent to its architecture or due to other factors.

### Open Question 3
- Question: How can the integration of LLMs and KGs be optimized to improve the accuracy and efficiency of GraphRAG systems in real-world applications?
- Basis in paper: [inferred] The paper discusses the potential of LLMs to streamline KG creation and enhance GraphRAG accessibility, but does not explore the optimization strategies for integrating LLMs and KGs in practical applications.
- Why unresolved: While the paper demonstrates the feasibility of using LLMs for KG generation, it does not address how these generated KGs can be best integrated and utilized within GraphRAG systems to maximize their effectiveness in real-world scenarios.
- What evidence would resolve it: Developing and testing optimization strategies for LLM-KG integration, such as fine-tuning models for specific domains, improving the efficiency of KG updates, and evaluating the impact on GraphRAG performance in various applications.

## Limitations

- The evaluation is based on a single text excerpt from Wikipedia about the C programming language, limiting generalizability to other domains or text types.
- Manual ground truth creation introduces potential subjectivity and scalability concerns for real-world applications.
- The study does not explore how model performance varies with text complexity, domain specificity, or input length.

## Confidence

- High Confidence: The comparative ranking of models (GPT-4 > LLaMA 2 > BERT) is supported by clear metric differences across all evaluation measures.
- Medium Confidence: The mechanistic explanations for why GPT-4 outperforms other models are plausible but not empirically validated within the study.
- Medium Confidence: The claim that LLaMA 2 balances performance and efficiency for domain-specific applications is based on moderate performance metrics but lacks specific resource utilization comparisons.

## Next Checks

1. Test the three models on diverse text domains (medical, legal, general news) to evaluate domain generalization and identify potential model specialization patterns.
2. Conduct ablation studies by systematically varying input text length and complexity to determine optimal context sizes for each model.
3. Implement automated ground truth generation using existing KG datasets to reduce subjectivity and enable testing on larger, more diverse corpora.