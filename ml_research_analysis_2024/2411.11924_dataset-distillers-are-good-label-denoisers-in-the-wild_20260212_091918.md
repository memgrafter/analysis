---
ver: rpa2
title: Dataset Distillers Are Good Label Denoisers In the Wild
arxiv_id: '2411.11924'
source_url: https://arxiv.org/abs/2411.11924
tags:
- noise
- dataset
- distillation
- noisy
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of dataset distillation as a tool
  for learning with noisy labels. The authors propose that dataset distillation can
  effectively serve as a label denoiser by capturing common patterns in the data while
  filtering out noisy outliers.
---

# Dataset Distillers Are Good Label Denoisers In the Wild
## Quick Facts
- **arXiv ID:** 2411.11924
- **Source URL:** https://arxiv.org/abs/2411.11924
- **Reference count:** 40
- **Primary result:** Dataset distillation effectively removes symmetric and natural label noise but struggles with structured asymmetric noise patterns.

## Executive Summary
This paper investigates dataset distillation as a tool for learning with noisy labels, proposing that distillation can effectively serve as a label denoiser by capturing common patterns while filtering out noisy outliers. The authors conduct extensive experiments on three representative dataset distillation methods (DATM, DANCE, and RCIG) under various noise conditions including symmetric noise, asymmetric noise, and real-world natural noise. Their results show that dataset distillation is highly effective for removing symmetric and natural noise, but encounters clear failures with structured asymmetric noise patterns. The study also highlights potential pitfalls such as the compression of challenging clean samples during the distillation process.

## Method Summary
The authors evaluate dataset distillation as a label denoising technique by applying three state-of-the-art methods (DATM, DANCE, and RCIG) to corrupted datasets with varying noise rates. They systematically test symmetric noise (uniform label corruption), asymmetric noise (class-dependent corruption patterns), and natural noise from real-world datasets. The distilled datasets are then used to train standard classifiers, and performance is compared against models trained on the original noisy data and those using explicit noise correction techniques. The experiments span multiple benchmark datasets and noise levels to comprehensively assess the denoising capabilities of dataset distillation.

## Key Results
- Dataset distillation effectively removes symmetric label noise, with distilled datasets achieving performance close to clean data even at high noise rates (40-60%).
- The method shows strong performance on natural noise from real-world datasets, demonstrating practical utility beyond synthetic corruption.
- Dataset distillation struggles significantly with structured asymmetric noise patterns, where class-dependent corruption creates systematic errors that the distillation process fails to correct.

## Why This Works (Mechanism)
Dataset distillation captures the underlying data distribution by finding a small set of synthetic samples that preserve the essential information of the original dataset. When applied to noisy data, this process inherently filters out outliers and rare corruptions because the distilled set prioritizes samples that are consistent with the majority pattern. The optimization process for dataset distillation naturally favors samples that appear in multiple contexts or have high influence on model training, which tends to exclude mislabeled examples that don't fit the true data distribution. This mechanism works particularly well for symmetric noise where corruption is random and independent of the true label, but fails when noise follows structured patterns that are indistinguishable from legitimate data variations.

## Foundational Learning
- **Dataset Distillation:** Creating compact synthetic datasets that preserve the training dynamics of the original data. *Why needed:* Core technique being evaluated for its denoising properties. *Quick check:* Understanding how distilled samples can replace original data for model training.
- **Label Noise Types:** Symmetric (random corruption), asymmetric (class-dependent corruption), and natural (real-world errors). *Why needed:* Different noise patterns have varying effects on distillation effectiveness. *Quick check:* Recognizing how noise structure impacts denoiser performance.
- **Information Compression Tradeoffs:** The balance between dataset reduction and information preservation. *Why needed:* Explains why challenging clean samples may be lost during distillation. *Quick check:* Understanding the inherent limitations of working with compressed datasets.

## Architecture Onboarding
**Component Map:** Original Dataset -> Noise Injection -> Dataset Distillation (DATM/DANCE/RCIG) -> Distilled Dataset -> Standard Classifier Training -> Performance Evaluation

**Critical Path:** The key sequence is: (1) apply dataset distillation to noisy data, (2) train classifier on distilled data, (3) compare performance to baseline approaches. The effectiveness of the denoising operation directly determines the quality of downstream classification.

**Design Tradeoffs:** Dataset distillation offers strong denoising for symmetric and natural noise but at the cost of losing challenging clean samples. The compression ratio (typically 1-10% of original data) is a critical hyperparameter that affects both denoising capability and information retention. Higher compression provides better noise filtering but risks losing important data variations.

**Failure Signatures:** Poor performance on asymmetric noise patterns, where structured corruption cannot be distinguished from legitimate class variations. Loss of difficult but clean samples that are compressed out of the distilled dataset. Degradation in performance when noise rates exceed the method's denoising capacity.

**Three First Experiments:**
1. Compare symmetric noise removal performance across DATM, DANCE, and RCIG at noise rates of 20%, 40%, and 60%.
2. Test natural noise filtering on Clothing1M and Food101-N datasets using distilled datasets of varying compression ratios.
3. Evaluate asymmetric noise handling by creating class-dependent corruption patterns and measuring distillation effectiveness.

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset distillation is highly effective for symmetric and natural label noise but fails with structured asymmetric noise patterns.
- The compression inherent to dataset distillation may lead to loss of challenging but clean samples that are important for robust learning.
- Experimental validation is limited to three specific dataset distillation methods and standard benchmark datasets, limiting generalizability.

## Confidence
- **High Confidence:** Claims regarding dataset distillation effectiveness for symmetric noise removal and natural noise filtering, supported by extensive experimental evidence across multiple methods and noise rates.
- **Medium Confidence:** Claims about dataset distillation as a general label denoiser, given the clear limitations with asymmetric noise patterns that the authors themselves identify.
- **Low Confidence:** Extrapolations about dataset distillation utility in high-privacy environments, as this application scenario receives limited direct experimental validation.

## Next Checks
1. Test dataset distillation methods on additional asymmetric noise patterns beyond those explored, particularly those mimicking real-world structured errors in specific domains.
2. Compare dataset distillation-based denoising against established noisy label training methods (e.g., Co-teaching, JoCoR) on identical benchmark tasks to establish relative effectiveness.
3. Investigate whether combining dataset distillation with explicit label correction techniques can mitigate the loss of challenging clean samples while maintaining noise removal benefits.