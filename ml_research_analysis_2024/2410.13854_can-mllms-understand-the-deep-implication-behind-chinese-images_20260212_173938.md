---
ver: rpa2
title: Can MLLMs Understand the Deep Implication Behind Chinese Images?
arxiv_id: '2410.13854'
source_url: https://arxiv.org/abs/2410.13854
tags:
- chinese
- image
- traditional
- images
- understanding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CII-Bench, the first benchmark for evaluating
  multimodal large language models' understanding of deep implications in Chinese
  images. The benchmark includes 698 images across six domains with 800 multiple-choice
  questions, sourced from Chinese internet and manually annotated.
---

# Can MLLMs Understand the Deep Implication Behind Chinese Images?

## Quick Facts
- arXiv ID: 2410.13854
- Source URL: https://arxiv.org/abs/2410.13854
- Reference count: 30
- Primary result: MLLMs significantly underperform humans on Chinese cultural image understanding benchmark (64.4% vs 78.2% accuracy)

## Executive Summary
This paper introduces CII-Bench, the first benchmark designed to evaluate multimodal large language models' understanding of deep implications in Chinese images. The benchmark consists of 698 images across six domains with 800 multiple-choice questions, carefully sourced from Chinese internet and manually annotated. Experiments reveal that MLLMs significantly underperform humans, particularly struggling with Chinese traditional culture images and emotional understanding. The study demonstrates that incorporating emotion hints into prompts improves model accuracy, suggesting fundamental limitations in models' cultural and emotional comprehension.

## Method Summary
The researchers constructed CII-Bench by collecting images from Chinese internet sources, manually reviewing and annotating them with multiple-choice questions about their deeper implications. The benchmark covers six domains including Life, Art, Society, Politics, Environment, and Chinese Traditional Culture. They evaluated various MLLMs using zero-shot and few-shot approaches with different prompt configurations (CoT, domain, emotion, rhetoric information). Model performance was compared against human benchmarks and analyzed across different domains, difficulty levels, and image types. An LLM-based evaluation metric was developed to assess Chinese traditional painting comprehension using GPT-4o as the evaluator.

## Key Results
- MLLMs achieve 64.4% accuracy versus human average of 78.2% on the CII-Bench benchmark
- Models perform significantly worse on Chinese traditional culture images, indicating limited knowledge of cultural nuances
- Incorporating emotion hints into prompts consistently improves model accuracy across all tested models
- Models show higher accuracy on negative emotional content compared to positive content, contrary to human preferences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Manual curation of images and annotations ensures cultural authenticity in CII-Bench
- Mechanism: The benchmark images are sourced from Chinese internet and manually reviewed by undergraduate students from various disciplines, ensuring the visual content authentically represents Chinese cultural contexts
- Core assumption: Human annotators can accurately identify and categorize Chinese cultural imagery that reflects deep implications and traditional symbolism
- Evidence anchors:
  - [abstract] states images are "sourced from the Chinese Internet and manually reviewed, with corresponding answers also manually crafted"
  - [section 3.2.3] describes the annotation process involving 30 undergraduate students from different disciplines and institutions
  - [corpus] shows related work on cultural understanding benchmarks like TCC-Bench and CVLUE that also emphasize cultural authenticity
- Break condition: If annotators lack sufficient cultural knowledge or introduce personal biases that don't represent broader Chinese cultural understanding

### Mechanism 2
- Claim: Incorporating emotion hints into prompts improves model performance by helping eliminate incorrect options
- Mechanism: When models receive emotional information (positive, negative, neutral) about images, they can more effectively eliminate answer options that don't match the emotional context
- Core assumption: Models have sufficient emotional understanding training to use emotional cues effectively in reasoning tasks
- Evidence anchors:
  - [abstract] states "most models exhibit enhanced accuracy when image emotion hints are incorporated into the prompts"
  - [section 4.2.4] explains "emotion labels significantly improve model accuracy, followed by domain and rhetoric labels"
  - [corpus] shows related work on emotional understanding in multimodal models
- Break condition: If models lack adequate emotional understanding training or if emotional cues are too ambiguous to be useful

### Mechanism 3
- Claim: The evaluation metric based on GPT-4o provides valid assessment of Chinese traditional painting comprehension
- Mechanism: Using GPT-4o to generate descriptions and score them based on a comprehensive rubric covering surface-level information, aesthetic characteristics, brush and ink skills, culture and history, and deep implications
- Core assumption: GPT-4o has sufficient cultural and artistic knowledge to evaluate Chinese traditional paintings accurately
- Evidence anchors:
  - [section 4.3.2] describes the LLM-based evaluation standard and reports "model-human scoring consistency reached 98%, affirming the method's validity"
  - [section 4.3.1] outlines the five-perspective evaluation metric
  - [corpus] shows related work on cultural understanding benchmarks using similar LLM-based evaluation approaches
- Break condition: If GPT-4o lacks sufficient knowledge of Chinese traditional culture or if the rubric doesn't capture the full complexity of cultural understanding

## Foundational Learning

- Concept: Cultural symbolism and metaphor in visual imagery
  - Why needed here: Understanding Chinese traditional culture requires recognizing symbolic elements like pine trees representing resilience, plum blossoms representing purity, and cranes representing longevity
  - Quick check question: What traditional Chinese symbol represents longevity and is commonly found in landscape paintings?

- Concept: Multimodal model evaluation metrics
  - Why needed here: The benchmark uses accuracy as the primary metric, with specific rules for handling chain-of-thought responses and extracting answer options
  - Quick check question: How does the evaluation handle cases where models use chain-of-thought prompting and include intermediate reasoning steps?

- Concept: Image annotation and quality control processes
  - Why needed here: The benchmark's reliability depends on consistent annotation protocols and multiple rounds of review to ensure data quality
  - Quick check question: What steps are taken to ensure consistency among annotators when labeling images with cultural implications?

## Architecture Onboarding

- Component map: Data collection → Filtration → Annotation → Benchmark construction → Model evaluation → Error analysis
- Critical path: The pipeline from raw image collection through manual review to final benchmark creation is critical, as errors at any stage propagate through the system
- Design tradeoffs: Manual curation ensures cultural authenticity but limits dataset size; automated approaches could scale but risk losing cultural nuance
- Failure signatures: Models consistently failing on Chinese traditional culture images indicates insufficient cultural training data; poor performance on emotion-based questions suggests inadequate emotional understanding
- First 3 experiments:
  1. Test different prompt configurations (none, emotion, domain, rhetoric) on a subset of images to determine which provides the most improvement
  2. Evaluate model performance across different difficulty levels to identify where models struggle most
  3. Compare human versus model performance on specific cultural symbolism questions to quantify the knowledge gap

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can MLLMs learn to recognize and interpret Chinese cultural symbols (like pine trees, plum blossoms, cranes) with sufficient training data, or is there an inherent limitation in current architectures?
- Basis in paper: Explicit - The paper shows models perform significantly worse on Chinese traditional culture images, indicating limited knowledge of Chinese cultural nuances.
- Why unresolved: The paper only evaluates existing models without exploring whether architectural improvements or additional training could address this gap.
- What evidence would resolve it: Experiments comparing models trained with culturally enriched datasets against standard models on CII-Bench would show if performance gaps can be closed.

### Open Question 2
- Question: Does incorporating image emotion hints into prompts work because models fundamentally struggle with emotional understanding, or because the prompts simply help narrow down answer options?
- Basis in paper: Explicit - The paper observes that incorporating emotion hints improves model accuracy, suggesting models struggle with emotional understanding.
- Why unresolved: The paper notes improved accuracy but doesn't distinguish between genuine emotional comprehension versus option elimination strategies.
- What evidence would resolve it: A controlled experiment where models must generate emotional interpretations without multiple-choice options would reveal if they truly understand emotions or just use them to eliminate options.

### Open Question 3
- Question: Why do MLLMs perform worse on positive emotional content compared to negative emotional content in Chinese images, contrary to human preferences?
- Basis in paper: Explicit - The paper finds models exhibit higher accuracy when image implications convey negative emotions, while accuracy is lowest for positive emotions.
- Why unresolved: The paper observes this discrepancy but doesn't investigate the underlying reasons for this inverted preference compared to humans.
- What evidence would resolve it: Analysis of model training data distribution and bias, combined with ablation studies testing different prompting strategies for positive versus negative emotions.

## Limitations
- Manual annotation introduces potential cultural biases from annotators who may not represent the full diversity of Chinese cultural understanding
- Benchmark size is limited by manual curation process, potentially missing diverse cultural contexts and symbolism
- Focus on multiple-choice questions may not fully represent the complexity of real-world cultural understanding tasks

## Confidence

**High confidence**: The overall finding that MLLMs significantly underperform humans on Chinese cultural image understanding is well-supported by experimental results and consistent across multiple model evaluations. The benchmark construction methodology is clearly described and follows established practices.

**Medium confidence**: The specific mechanisms by which emotion hints improve model performance, while supported by experimental data, require further investigation to understand whether models are genuinely understanding emotional content or simply using it as a heuristic for answer selection.

**Low confidence**: The generalizability of findings beyond the specific set of Chinese cultural images tested is uncertain, as the benchmark may not capture the full diversity of Chinese cultural contexts and symbolism.

## Next Checks

1. **Cross-cultural validation**: Test the benchmark on images from other cultural contexts to determine whether observed performance gaps are specific to Chinese culture or reflect broader limitations in MLLMs' cultural understanding capabilities.

2. **Ablation study of prompt components**: Systematically test which specific elements of emotion, domain, and rhetoric hints contribute most to performance improvements, and whether these improvements reflect genuine understanding or pattern matching.

3. **Longitudinal model evaluation**: Evaluate newer MLLMs and updated versions of existing models on the same benchmark to track improvements in cultural understanding capabilities over time and identify which architectural or training innovations show the most promise.