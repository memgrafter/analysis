---
ver: rpa2
title: 'PUMA: margin-based data pruning'
arxiv_id: '2405.06298'
source_url: https://arxiv.org/abs/2405.06298
tags:
- margin
- training
- pruning
- data
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PUMA addresses the challenge of improving accuracy-robustness trade-offs
  in deep learning when large-scale synthetic data augmentation is used for adversarial
  training. The key insight is that existing pruning strategies fail to improve performance
  when combined with massive data augmentation because they remove either too many
  easy samples (hurting accuracy) or fail to address mislabeled adversarial examples.
---

# PUMA: margin-based data pruning

## Quick Facts
- arXiv ID: 2405.06298
- Source URL: https://arxiv.org/abs/2405.06298
- Authors: Javier Maroto; Pascal Frossard
- Reference count: 26
- Key outcome: PUMA improves accuracy-robustness trade-offs by 3.5% on CIFAR10 through margin-based pruning of synthetic augmented data

## Executive Summary
PUMA addresses the challenge of improving accuracy-robustness trade-offs in deep learning when large-scale synthetic data augmentation is used for adversarial training. The key insight is that existing pruning strategies fail to improve performance when combined with massive data augmentation because they remove either too many easy samples (hurting accuracy) or fail to address mislabeled adversarial examples. PUMA introduces a novel margin-based pruning strategy that uses DeepFool to estimate sample margins and adaptively adjusts adversarial attack strengths during training. By removing high-margin samples and reducing attack strength for low-margin samples, PUMA significantly improves model accuracy while maintaining comparable robustness.

## Method Summary
PUMA combines margin estimation using DeepFool with adaptive per-sample adversarial strength adjustment. The method first precomputes margins for all training samples using a pretrained robust model, then removes the highest margin samples based on a pruning ratio. During training, each remaining sample receives an adversarial perturbation strength εi that depends on its margin value - samples close to decision boundaries receive weaker perturbations to prevent mislabeling, while samples far from boundaries receive standard strength perturbations. This approach addresses the fundamental issue that high-margin samples contribute less to adversarial learning while low-margin samples are prone to being mislabeled when perturbed.

## Key Results
- Accuracy improvement from 87.87% to 91.37% on CIFAR10 with 1M EDM-generated samples
- Maintains comparable robustness to C&W attacks despite significant data reduction
- Scales effectively to larger datasets like ImageNet-21K with 100 classes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Removing high-margin samples while adaptively adjusting adversarial attack strength for low-margin samples improves accuracy-robustness trade-off in large-scale data augmentation scenarios.
- Mechanism: PUMA combines insights from perceptron learning analysis: high-margin samples contribute less to model learning in adversarial settings, and low-margin samples are prone to being mislabeled when perturbed. By removing high-margin samples and reducing adversarial strength for low-margin samples based on DeepFool margin estimates, PUMA avoids pitfalls of existing pruning strategies.
- Core assumption: DeepFool-computed margin serves as reliable proxy for true margin to classification boundary.
- Evidence anchors: Abstract mentions margin-based pruning and adaptive attack strength adjustment. Section shows failure of existing approaches with large synthetic data.
- Break condition: If DeepFool margin estimates poorly correlate with true margin or adaptive attack strength adjustment fails to prevent mislabeled samples from harming training.

### Mechanism 2
- Claim: Effectiveness stems from recovering exponential scaling of error with training size in adversarial settings, which existing pruning strategies fail to achieve.
- Mechanism: Perceptron learning experiments show PE strategy can achieve exponential scaling of error with training size when combined with adversarial training and proper handling of mislabeled samples. PUMA translates this by using DeepFool to identify and remove high-margin samples while reducing attack strength for low-margin samples.
- Core assumption: Scaling behavior from perceptron learning translates to image classification tasks.
- Evidence anchors: Figure 1 shows error correlation with α and PE strategy performance. Section proposes using DeepFool to compute margin proxy.
- Break condition: If scaling relationship between error and training size differs significantly between perceptron learning and image classification.

### Mechanism 3
- Claim: Adaptive per-sample adversarial strength (εi) based on margin values prevents mislabeled samples from degrading performance while maintaining robustness.
- Mechanism: Algorithm sets εi = mi for samples with margin between -ε and ε, and εi = ε for samples with margin above ε. This ensures samples close to decision boundary receive weaker perturbations, reducing likelihood of mislabeling.
- Core assumption: Relationship between margin and optimal adversarial strength is monotonic and can be approximated by piecewise function.
- Evidence anchors: Abstract mentions pruning highest margin samples while adjusting training attack norm on lowest margin samples. Section defines εi piecewise function.
- Break condition: If optimal relationship between margin and adversarial strength is more complex than assumed piecewise function.

## Foundational Learning

- Concept: Adversarial training and its challenges
  - Why needed here: Understanding why adversarial training requires large datasets and suffers from robust overfitting is crucial for appreciating PUMA's contribution to data efficiency.
  - Quick check question: Why does adversarial training typically require 1000x more data than standard training for CIFAR10?

- Concept: Margin-based learning and its relationship to sample informativeness
  - Why needed here: The core of PUMA relies on using margin estimates to determine which samples to prune and how to adjust adversarial strength.
  - Quick check question: In the context of perceptron learning, why do high-margin samples contribute less to model learning than low-margin samples?

- Concept: DeepFool algorithm and margin estimation
  - Why needed here: PUMA uses DeepFool to compute margin estimates for pruning decisions, so understanding how it works is essential.
  - Quick check question: How does DeepFool iteratively search for the closest model boundary, and why is this useful for computing margin estimates?

## Architecture Onboarding

- Component map:
  Margin computation module (uses DeepFool with pretrained robust model) -> Pruning decision module (removes high-margin samples based on pruning ratio) -> Adaptive attack strength module (computes εi for each sample based on margin) -> Training loop integration (applies pruning and adaptive attacks during adversarial training)

- Critical path:
  1. Precompute margins for all training samples using DeepFool
  2. Sort samples by margin and remove top X% (pruning ratio)
  3. During each training iteration: Compute εi for each remaining sample based on its margin, apply adversarial perturbation with strength εi, update model weights using standard adversarial training procedure

- Design tradeoffs:
  - Precomputing margins vs. online computation: Precomputing is more efficient but requires additional storage; online computation is more flexible but adds computational overhead during training.
  - Pruning ratio selection: Higher ratios improve efficiency but risk removing informative samples; lower ratios preserve more data but reduce efficiency gains.
  - Margin estimation method: DeepFool provides accurate estimates but is computationally expensive; faster approximations may be less accurate but more scalable.

- Failure signatures:
  - Significant drop in accuracy after pruning: Indicates too many informative samples were removed or margin estimates are unreliable
  - No improvement in accuracy-robustness trade-off: Suggests pruning ratio is too low or margin estimates don't correlate with sample informativeness
  - Increased robust overfitting: May indicate adaptive attack strength is not effectively preventing mislabeled samples from harming training

- First 3 experiments:
  1. Baseline comparison: Train with PUMA (pruning ratio = 0%) vs. standard adversarial training to verify no performance degradation
  2. Pruning sensitivity: Train with PUMA at different pruning ratios (e.g., 10%, 20%, 30%) to find optimal trade-off between efficiency and performance
  3. Margin estimation validation: Compare PUMA performance using DeepFool vs. faster margin estimation methods to assess impact of margin accuracy on final results

## Open Questions the Paper Calls Out
None explicitly mentioned in the provided content.

## Limitations
- Scalability concerns for DeepFool margin computation on extremely large datasets beyond ImageNet-21K
- Relationship between margin and sample informativeness may be more complex than simple pruning ratio approach suggests
- Method requires pretraining a robust model for margin estimation, adding computational overhead

## Confidence
- High: Core insight that high-margin samples contribute less to adversarial learning is well-supported by perceptron learning experiments
- Medium: Effectiveness of DeepFool-based margin estimation on complex image classification tasks demonstrated empirically but not theoretically justified
- Medium: Adaptive attack strength adjustment prevents mislabeled samples from harming training, though optimal relationship may be more complex than piecewise function

## Next Checks
1. **Ablation study on margin estimation**: Compare PUMA performance using exact margin computation vs. approximate methods to quantify impact of DeepFool approximation on final results.

2. **Scalability analysis**: Test PUMA on larger-scale datasets (e.g., JFT-300M) to evaluate computational overhead and effectiveness of margin-based pruning at extreme scale.

3. **Robustness to pruning ratio**: Systematically vary pruning ratios from 0% to 50% and measure accuracy-robustness trade-offs to identify optimal settings across different architectures and datasets.