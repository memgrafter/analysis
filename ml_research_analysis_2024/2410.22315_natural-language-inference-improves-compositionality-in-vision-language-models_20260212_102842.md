---
ver: rpa2
title: Natural Language Inference Improves Compositionality in Vision-Language Models
arxiv_id: '2410.22315'
source_url: https://arxiv.org/abs/2410.22315
tags:
- caption
- entailments
- text
- contradictions
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Caption Expansion with Contradictions and
  Entailments (CECE), a method that leverages Natural Language Inference (NLI) to
  generate entailments and contradictions from image captions, thereby improving compositional
  reasoning in vision-language models (VLMs). By producing lexically diverse captions
  while preserving core meaning, CECE addresses the limitations of prior methods that
  rely on sentence decomposition, which often fail to incorporate deeper lexical understanding
  and introduce biases.
---

# Natural Language Inference Improves Compositionality in Vision-Language Models

## Quick Facts
- arXiv ID: 2410.22315
- Source URL: https://arxiv.org/abs/2410.22315
- Authors: Paola Cascante-Bonilla; Yu Hou; Yang Trista Cao; Hal Daumé; Rachel Rudinger
- Reference count: 33
- Primary result: CECE achieves state-of-the-art results on Winoground (+19.2% group score) and EqBen (+12.9% group score) benchmarks

## Executive Summary
This paper introduces Caption Expansion with Contradictions and Entailments (CECE), a method that leverages Natural Language Inference (NLI) to generate entailments and contradictions from image captions, thereby improving compositional reasoning in vision-language models (VLMs). By producing lexically diverse captions while preserving core meaning, CECE addresses the limitations of prior methods that rely on sentence decomposition, which often fail to incorporate deeper lexical understanding and introduce biases. Extensive experiments demonstrate that CECE significantly outperforms previous approaches, achieving state-of-the-art results on benchmarks like Winoground and EqBen without requiring fine-tuning. Additionally, CECE enhances interpretability and reduces overreliance on superficial features, aligning better with human judgments for image-text alignment tasks.

## Method Summary
CECE uses Llama3.1 70B to generate entailments and contradictions from image captions, then scores image-text pairs using multiple VLMs (BLIP2, InstructBLIP, LLaVA-1.5/1.6). The method aggregates scores through a weighted function balancing entailments, contradictions, and original captions. The approach produces lexically diverse captions while maintaining core meaning, incorporating both positive (entailments) and negative (contradictions) reasoning cues. The final evaluation score combines these components with balancing weights α1 (entailment/contradiction balance) and α2 (original caption balance).

## Key Results
- CECE achieves +19.2% improvement on Winoground group score compared to previous state-of-the-art methods
- CECE achieves +12.9% improvement on EqBen group score without requiring model fine-tuning
- CECE outperforms all baseline methods including CLIPScore, BLIP2ITM, VQAScore, and SDS variants across multiple benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CECE generates lexically diverse captions while preserving core meaning through Natural Language Inference (NLI).
- Mechanism: The LLM is instructed to produce entailments (logically following statements) and contradictions (logically incompatible statements) from the original caption premise, expanding semantic understanding beyond surface-level decomposition.
- Core assumption: NLI can reliably generate diverse semantic variations that maintain the essential meaning of the original caption while introducing lexical diversity.
- Evidence anchors:
  - [abstract]: "CECE produces lexically diverse sentences while maintaining their core meaning"
  - [section]: "We instruct an LLM to use NLI – which is used to determine the relationship between two sentences, a premise and a hypothesis... and generate entailments and contradictions from a given premise"
  - [corpus]: Weak evidence - only 5/8 related papers mention compositionality in VLMs, but none specifically discuss NLI-based caption expansion
- Break condition: If the LLM generates entailments or contradictions that semantically drift from the original caption's meaning, or if the NLI model cannot reliably distinguish between entailment and contradiction relationships.

### Mechanism 2
- Claim: Balancing entailments, contradictions, and original caption scores improves compositional reasoning by incorporating both positive and negative semantic cues.
- Mechanism: The weighted aggregation function S(X) = α2 · [α1 · S(E, I) + (1 - α1) · S(C, I)] + (1 - α2) · S(T, I) combines the VLM's likelihood scores for entailments, contradictions, and the original caption, allowing flexible adjustment of their relative importance.
- Core assumption: Both positive reasoning cues (entailments) and negative reasoning cues (contradictions) provide complementary information that improves overall compositional understanding when properly balanced.
- Evidence anchors:
  - [section]: "With CECE, we incorporate both positive and negative reasoning cues: entailments provide semantic inclusion (focusing on subset relations), while contradictions provide semantic exclusion (focusing on subset complements)"
  - [section]: "By carefully balancing the contributions from entailments, contradictions, and the original caption, this approach ensures that the final assessment remains grounded in the intended meaning"
  - [corpus]: Moderate evidence - 3/8 related papers discuss balancing techniques, but none specifically address entailment/contradiction balancing
- Break condition: If the weighting parameters α1 and α2 are poorly chosen, leading to overemphasis on one component at the expense of others, or if semantic drift causes generated captions to diverge significantly from the original meaning.

### Mechanism 3
- Claim: Soft-ensembling different VLMs through score aggregation mitigates model-specific biases and improves robustness.
- Mechanism: The method combines scores from multiple VLMs (e.g., LLaVA-1.5 for entailments/contradictions and LLaVA-1.6 for original caption) to create a more robust evaluation that is less sensitive to individual model limitations.
- Core assumption: Different VLMs have complementary strengths and weaknesses, and combining their outputs through weighted averaging produces more reliable results than any single model alone.
- Evidence anchors:
  - [section]: "We further evaluate CECE on different VLMs... and incorporate a soft-assembling method that balances the results scores of different models"
  - [section]: "We show in Table 8 how combining different models boosts the final compositional evaluation"
  - [corpus]: Moderate evidence - 2/8 related papers discuss ensemble methods, but none specifically address VLM ensemble for compositional reasoning
- Break condition: If the VLMs have highly correlated errors or if the weighting between models is not properly calibrated, the ensemble may not provide the expected robustness benefits.

## Foundational Learning

- Concept: Natural Language Inference (NLI)
  - Why needed here: NLI provides the theoretical foundation for generating semantically related captions that preserve meaning while introducing lexical diversity
  - Quick check question: What are the three possible relationships between a premise and hypothesis in NLI?

- Concept: Vision-Language Model (VLM) evaluation frameworks
  - Why needed here: Understanding how VLMs compute likelihood scores for image-text pairs is crucial for interpreting CECE's methodology
  - Quick check question: How does the VLM convert a text statement into a yes/no question format for evaluation?

- Concept: Semantic drift in text generation
  - Why needed here: CECE must address the risk that generated captions may diverge from the original meaning, degrading model performance
  - Quick check question: What mechanisms does CECE employ to mitigate semantic drift in generated captions?

## Architecture Onboarding

- Component map: LLM (Llama3.1 70B) -> Caption Expansion (Entailments + Contradictions) -> Multiple VLMs (BLIP2, InstructBLIP, LLaVA-1.5, LLaVA-1.6) -> Score Balancing (α1, α2) -> Final Evaluation Score
- Critical path: LLM prompt -> JSON parsing of entailments/contradictions -> VLM likelihood computation -> Weighted aggregation -> Final score
- Design tradeoffs:
  - Single-LLM vs. multi-LLM approach for caption expansion
  - Number of entailments/contradictions to generate (computational cost vs. coverage)
  - Choice of VLMs for soft-ensembling (diversity vs. consistency)
- Failure signatures:
  - Low lexical diversity in generated captions (Jaccard similarity too high)
  - Semantic drift causing incorrect image-text matching
  - Overfitting to specific VLM architectures
- First 3 experiments:
  1. Run CECE with a single VLM (LLaVA-1.6) on Winoground to establish baseline performance
  2. Test different α1 and α2 values to find optimal balancing parameters
  3. Compare CECE performance against SDS baseline using identical LLM and VLM configurations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the semantic drift problem manifest in different types of image-text pairs, and what specific characteristics of the input make certain pairs more susceptible to drift?
- Basis in paper: [inferred] The paper discusses semantic drift as a challenge and mentions that incorporating the original caption helps mitigate it, but doesn't provide a detailed analysis of when and why drift occurs.
- Why unresolved: The paper acknowledges the issue but doesn't systematically investigate the factors that contribute to semantic drift in different contexts or provide metrics to quantify its impact.
- What evidence would resolve it: A comprehensive study categorizing image-text pairs based on their susceptibility to semantic drift, along with quantitative measures of drift magnitude across different pair types.

### Open Question 2
- Question: What is the optimal balance between lexical diversity and semantic preservation in caption expansion, and how does this balance vary across different domains or types of visual content?
- Basis in paper: [explicit] The paper mentions that CECE produces lexically diverse sentences while maintaining core meaning, but doesn't explore the trade-off between diversity and semantic fidelity or how this might vary by context.
- Why unresolved: The paper demonstrates that CECE achieves good results but doesn't investigate the relationship between diversity levels and performance across different visual domains or content types.
- What evidence would resolve it: Systematic experiments varying the level of lexical diversity in caption expansions and measuring performance across different visual domains (e.g., natural scenes, technical diagrams, abstract art).

### Open Question 3
- Question: What are the limitations of using Natural Language Inference for caption expansion in scenarios involving highly abstract or metaphorical visual content, and how might CECE be adapted for such cases?
- Basis in paper: [explicit] The paper mentions that CECE performs well on Winoground's symbolic and pragmatic categories, but doesn't explore its limitations with highly abstract or metaphorical content.
- Why unresolved: The paper demonstrates CECE's effectiveness on compositional reasoning tasks but doesn't investigate its performance on more abstract visual content where literal entailments and contradictions may not capture the intended meaning.
- What evidence would resolve it: Evaluation of CECE on datasets specifically designed to test understanding of abstract or metaphorical visual content, along with analysis of failure modes in these scenarios.

## Limitations

- CECE relies heavily on Llama3.1 70B for caption expansion without exploring sensitivity to LLM choice or size
- The method focuses primarily on retrieval benchmarks and lacks validation on downstream generation or reasoning tasks
- While claiming to improve interpretability, the paper provides no formal interpretability analysis to demonstrate actual gains

## Confidence

**High Confidence:** The core claim that CECE outperforms baseline methods on Winoground and EqBen benchmarks is well-supported by the experimental results with substantial and statistically significant improvements.

**Medium Confidence:** The claim that NLI-based caption expansion improves compositional reasoning is mechanistically plausible but not definitively proven, as improvements could stem from other factors beyond compositional understanding.

**Low Confidence:** The assertion that CECE aligns better with human judgments and enhances interpretability lacks rigorous validation, with correlation metrics reported but no qualitative analysis of actual interpretability gains.

## Next Checks

**Validation Check 1:** Conduct ablation studies systematically varying the number of entailments/contradictions generated (1, 3, 5, 10) and their quality thresholds to determine the optimal trade-off between computational cost and performance improvement.

**Validation Check 2:** Test CECE across diverse VLM architectures beyond the four evaluated (including open-source and proprietary models) to assess whether the improvements generalize across different model families or are specific to particular architectures.

**Validation Check 3:** Design a controlled human evaluation study where annotators compare model explanations generated with and without CECE, measuring both alignment with human reasoning and actual interpretability gains in concrete decision-making scenarios.