---
ver: rpa2
title: Effective Controllable Bias Mitigation for Classification and Retrieval using
  Gate Adapters
arxiv_id: '2401.16457'
source_url: https://arxiv.org/abs/2401.16457
tags:
- congater
- task
- attribute
- gender
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CONGATER, a novel controllable gate adapter
  mechanism for bias mitigation in language models. The method employs a trajectory
  sigmoid activation function with an adjustable sensitivity parameter, enabling continuous
  control over the degree of bias reduction at inference time.
---

# Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adaters

## Quick Facts
- arXiv ID: 2401.16457
- Source URL: https://arxiv.org/abs/2401.16457
- Reference count: 40
- Primary result: CONGATER achieves more than twice the task performance of strong baselines with the same fairness level in retrieval tasks

## Executive Summary
This paper introduces CONGATER, a novel controllable gate adapter mechanism for bias mitigation in language models. The method employs a trajectory sigmoid activation function with an adjustable sensitivity parameter, enabling continuous control over the degree of bias reduction at inference time. Experiments on three classification tasks and one retrieval task demonstrate that CONGATER can maintain higher task performance while reducing attribute information more effectively than baselines. Specifically, fully debiased CONGATER achieves more than twice the task performance of strong baselines with the same fairness level in retrieval tasks.

## Method Summary
CONGATER is a controllable gate adapter that can be trained with any gradient descent-based signal that removes attributes or increases fairness. It consists of a bottleneck layer followed by a trajectory-sigmoid activation function, forming gate vectors that control the flow of information through element-wise multiplication with input embeddings. The gating sensitivity parameter ω adjusts the shape of the t-sigmoid activation, transitioning from a constant function to a sigmoid function, allowing continuous control over attribute removal. The method can be trained either in parallel or post-hoc with the base model, and its effectiveness is evaluated on three classification datasets (BIOS, FDCL18, PAN16) and one retrieval dataset (MSMARCOFair).

## Key Results
- CONGATER enables smooth transitions between biased and debiased states, enhancing personalization and interpretability through controllability
- Fully debiased CONGATER achieves more than twice the task performance of strong baselines with the same fairness level in retrieval tasks
- CONGATER maintains higher task performance while reducing attribute information more effectively than baselines across classification and retrieval tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CONGATER uses a novel gating mechanism with a trajectory-sigmoid activation to control the flow of attribute information during inference.
- Mechanism: The gating sensitivity parameter ω adjusts the shape of the t-sigmoid activation, transitioning from a constant function to a sigmoid function, allowing continuous control over attribute removal.
- Core assumption: The model can learn meaningful attribute-specific information during training with full gating (ω = 1) and apply it smoothly during inference with partial gating (0 < ω < 1).
- Evidence anchors:
  - [abstract]: "CONGATER is equipped with a novel activation function Trajectory Sigmoid (t-sigmoid), used to form the gate vectors. CONGATER is agnostic to debiasing optimization and can be trained with any gradient descent-based signal that removes attributes or increases fairness."
  - [section]: "Concretely, for the ith target attribute, we first define the gate vector gi formulated as: gi = t-sigmoidωi(vi) (1)"
  - [corpus]: Weak evidence. Corpus shows related works on bias mitigation but lacks direct discussion of t-sigmoid or controllability mechanisms.
- Break condition: If the gating mechanism fails to isolate attribute-specific information during training, partial gating will not effectively control bias during inference.

### Mechanism 2
- Claim: The CONGATER module enables modular and on-demand debiasing without retraining the entire model.
- Mechanism: CONGATER acts as an adapter network added to each transformer block, learning to filter attribute information while preserving task performance, and can be adjusted independently at inference.
- Core assumption: The adapter network has sufficient capacity to learn attribute-specific information without interfering with the core model's task-relevant representations.
- Evidence anchors:
  - [abstract]: "CONGATER is agnostic to debiasing optimization and can be trained with any gradient descent-based signal that removes attributes or increases fairness."
  - [section]: "The CONGATER module follows the principle of adapters (Houlsby et al., 2019) by dedicating a small network, added after each transformer block (Vaswani et al., 2017) of an LM."
  - [corpus]: Moderate evidence. Corpus includes related works on adapter-based bias mitigation, supporting the feasibility of modular debiasing approaches.
- Break condition: If the adapter capacity is insufficient for the task, attribute removal may degrade task performance significantly.

### Mechanism 3
- Claim: The t-sigmoid activation function allows for nonlinear interpolation between biased and debiased states, enhancing controllability.
- Mechanism: By adjusting ω, the t-sigmoid function transitions smoothly from a constant (open gate) to a sigmoid (full gate), enabling graded control over the attribute's influence on the model's outputs.
- Core assumption: The t-sigmoid function's shape can be smoothly controlled by ω without causing abrupt changes in the model's behavior.
- Evidence anchors:
  - [abstract]: "During training, t-sigmoid has the same shape as a (standard) sigmoid function. At inference time, however, the form oft-sigmoid can flatten by decreasing the sensitivity parameter, transitioning from the sigmoid function (full gate intervention) to the constant function (no influence) creating a nonlinear interpolation effect."
  - [section]: "This gating sensitivity parameter can be set to values in the range of [0, 1], which changes the shape of t-sigmoid, as illustrated for several values of ω in Figure 1b."
  - [corpus]: No direct evidence. Corpus lacks discussion of t-sigmoid or similar activation functions for controllability.
- Break condition: If the t-sigmoid function's transition is not smooth, controllability may be compromised, leading to unpredictable model behavior.

## Foundational Learning

- Concept: Adversarial training for bias mitigation
  - Why needed here: CONGATER uses adversarial training to reduce the model's ability to predict protected attributes while maintaining task performance.
  - Quick check question: How does adversarial training help in making the model attribute-agnostic?

- Concept: Adapter networks in transformer models
  - Why needed here: CONGATER is built on the adapter architecture, adding a small network to each transformer block for modular bias mitigation.
  - Quick check question: What are the advantages of using adapter networks over fine-tuning the entire model?

- Concept: Mutual information and its reduction
  - Why needed here: Reducing mutual information between the model's embeddings and protected attributes is a key goal of CONGATER's bias mitigation.
  - Quick check question: Why is reducing mutual information between embeddings and attributes important for bias mitigation?

## Architecture Onboarding

- Component map: CONGATER consists of a bottleneck layer followed by the t-sigmoid activation function, forming gate vectors that control the flow of information through element-wise multiplication with the input embeddings. It is added after each transformer block in the model.
- Critical path: The critical path for CONGATER's functionality involves training the adapter with full gating (ω = 1) to learn attribute-specific information, then adjusting ω during inference to control the degree of attribute removal.
- Design tradeoffs: CONGATER trades off some task performance for improved bias mitigation, with the degree of tradeoff controllable via the gating sensitivity parameter. It also introduces additional parameters and computation compared to standard adapters.
- Failure signatures: If CONGATER fails, it may manifest as either insufficient bias mitigation (high attribute probe accuracy) or significant task performance degradation (low task accuracy).
- First 3 experiments:
  1. Train CONGATER on a simple classification task with a known protected attribute and evaluate both task performance and attribute probe accuracy.
  2. Vary the gating sensitivity parameter ω during inference and observe the continuous changes in attribute probe accuracy and task performance.
  3. Compare CONGATER's performance to a baseline adapter network trained with the same adversarial objective but without the controllability mechanism.

## Open Questions the Paper Calls Out

- How does CONGATER perform on multi-attribute bias mitigation compared to single-attribute scenarios?
- How does the choice of the gating sensitivity parameter ω impact the interpretability of CONGATER's predictions?
- How does CONGATER's performance compare to other debiasing methods when applied to different types of language models (e.g., CNNs)?

## Limitations
- The trajectory sigmoid activation function is novel but lacks theoretical grounding for why its specific parameterization enables effective controllability
- Experiments focus on gender bias in English datasets; generalization to other bias types and languages remains unclear
- The trade-off analysis between task performance and fairness is incomplete - optimal ω values are not systematically studied

## Confidence

- **High confidence**: The core mechanism of using gate adapters with continuous controllability works as described
- **Medium confidence**: The empirical improvements over baselines are real, though absolute performance gains vary by dataset
- **Low confidence**: Claims about enhanced interpretability and personalization are largely speculative without user studies

## Next Checks

1. Analyze the sensitivity of CONGATER's performance to the bottleneck factor and gating sensitivity parameter across all datasets
2. Test CONGATER on non-gender bias scenarios (e.g., racial bias, age bias) to assess generalizability
3. Conduct ablation studies removing the t-sigmoid component to quantify its specific contribution to controllability