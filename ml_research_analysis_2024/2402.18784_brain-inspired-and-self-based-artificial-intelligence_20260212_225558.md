---
ver: rpa2
title: Brain-inspired and Self-based Artificial Intelligence
arxiv_id: '2402.18784'
source_url: https://arxiv.org/abs/2402.18784
tags:
- learning
- self
- others
- cognitive
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Brain-inspired and Self-based Artificial
  Intelligence (BriSe AI) paradigm that integrates a hierarchical Self framework (Perception
  and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self) to
  build human-level AI models. The approach coordinates multiple cognitive functions
  and learning strategies in a self-organized manner, enabling AI agents to understand
  themselves, their environment, and others through embodied interaction.
---

# Brain-inspired and Self-based Artificial Intelligence

## Quick Facts
- arXiv ID: 2402.18784
- Source URL: https://arxiv.org/abs/2402.18784
- Reference count: 40
- Brain-inspired AI framework integrating hierarchical Self framework with five levels to achieve human-level intelligence through self-organized cognitive functions

## Executive Summary
This paper introduces the Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm that integrates a hierarchical Self framework with five levels - Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The framework coordinates multiple cognitive functions and learning strategies in a self-organized manner, enabling AI agents to understand themselves, their environment, and others through embodied interaction. Implemented using spiking neural networks (BrainCog), the system demonstrates capabilities including multi-modal concept learning with 94% accuracy, bodily self-perception enabling mirror self-recognition and rubber hand illusion, autonomous decision-making for robotics tasks, and social cognition including theory of mind and affective empathy for altruistic behaviors.

## Method Summary
The BriSe AI framework uses the BrainCog spiking neural network engine with biological learning rules and encoding strategies. It implements multiple learning strategies including unsupervised, supervised, reinforcement, few-shot, continual, transfer, and evolutionary learning. The framework integrates micro, meso, and macro-scale neuroplasticity principles along with learning, developmental, and evolutionary plasticity at different timescales. The hierarchical Self framework progressively develops cognitive capabilities from basic perception to abstract conceptual understanding through top-down feedback and self-modulation mechanisms.

## Key Results
- Multi-modal concept learning achieved 94% accuracy on 40-class dataset using integrated visual, auditory, and tactile inputs
- Bodily self-perception models successfully passed mirror test and demonstrated rubber hand illusion capabilities
- Social cognition models implemented theory of mind and affective empathy enabling multi-agent collaboration and altruistic behaviors
- Autonomous decision-making models successfully completed navigation, obstacle avoidance, and game tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-modulated learning enables a leap from information processing to information understanding.
- Mechanism: Higher-level Self provides top-down modulation of fundamental learning strategies, enabling agents to scrutinize and supervise underlying learning processes, activate neural circuits to detect unusual problems, and self-organize to collaborate building blocks for deep comprehension and inference of implicit knowledge.
- Core assumption: The Self framework provides a supervisory mechanism that can evaluate and modulate learning processes in real-time.
- Evidence anchors:
  - [abstract] "Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments"
  - [section] "Self can, in turn, aid in better learning, achieving a leap from information processing to a deeper understanding of information"
  - [corpus] Weak evidence - corpus focuses on brain-inspired AI but doesn't directly address self-modulated learning mechanisms
- Break condition: If the self-modulation mechanism cannot effectively evaluate and redirect learning processes in real-time, the system reverts to standard information processing without true understanding.

### Mechanism 2
- Claim: Multi-level Self framework enables progressive development of increasingly sophisticated cognitive capabilities.
- Mechanism: Each level of Self builds upon previous levels, with higher levels providing top-down feedback to lower levels, creating a self-organized coordination system that progressively enhances AI capabilities from basic perception to abstract conceptual understanding.
- Core assumption: The hierarchical structure of Self allows for emergent cognitive capabilities that wouldn't be possible through isolated learning strategies.
- Evidence anchors:
  - [abstract] "This self-framework for AI is able to acquire increasingly complex cognitive abilities on-line and coordinate multiple cognitive functions and learning strategies in a self-organized manner"
  - [section] "Different levels of the Self are interconnected and interact collaboratively...As the Self's level increases, the higher Self provides top-down feedback to the lower Self"
  - [corpus] Weak evidence - corpus mentions brain-inspired AI but doesn't specifically address hierarchical Self frameworks
- Break condition: If the feedback loops between Self levels become unstable or create conflicting signals, the progressive development breaks down.

### Mechanism 3
- Claim: Integration of biological plasticity principles with multi-scale neural foundations enables realistic brain-inspired learning.
- Mechanism: BriSe AI incorporates micro, meso, and macro-scale neuroplasticity principles along with learning, developmental, and evolutionary plasticity at different timescales, creating a biologically plausible foundation for AI learning.
- Core assumption: Biological plasticity mechanisms can be effectively translated into computational models that enhance AI learning capabilities.
- Evidence anchors:
  - [abstract] "BriSe AI is based on multi-scale biological plasticities, supporting more complex and advanced self-based cognitive capabilities within a unified framework"
  - [section] "In addition to multi-scale spatial neuroplasticity principles at micro, meso, and macro scales, BriSe AI further integrates learning, developmental and evolutionary plasticity at different timescales"
  - [corpus] Moderate evidence - neighboring papers discuss brain-inspired AI and neural plasticity, providing some supporting context
- Break condition: If the computational implementation of biological plasticity principles fails to capture the essential characteristics needed for effective learning, the system loses its biological plausibility advantage.

## Foundational Learning

- Concept: Unsupervised learning with STDP-based plasticity
  - Why needed here: Provides the foundational learning mechanism for initial feature extraction and pattern recognition without requiring labeled data
  - Quick check question: Can the system extract meaningful features from raw sensory input using only STDP-based plasticity?

- Concept: Reinforcement learning with dopamine-modulated synaptic plasticity
  - Why needed here: Enables autonomous decision-making and trial-and-error learning through reward-based optimization
  - Quick check question: Does the system improve task performance over time when provided with reward signals?

- Concept: Associative learning for motor-visual and sensory integration
  - Why needed here: Forms the basis for bodily self-perception and self-world distinction by establishing connections between self-generated actions and sensory feedback
  - Quick check question: Can the system learn to distinguish between self-generated and externally-generated sensory events?

## Architecture Onboarding

- Component map: BrainCog core (spiking neurons, biological learning rules, encoding strategies) → Learning strategy modules (unsupervised, supervised, reinforcement, associative, few-shot, multimodal, continual, transfer, evolutionary) → Self framework levels (Perception & Learning, Bodily Self, Autonomous Self, Social Self, Conceptual Self) → Cognitive function modules (perception, decision-making, motor control, knowledge representation, social cognition)
- Critical path: Perception → Bodily Self modeling → Autonomous Self development → Social Self capabilities → Conceptual Self abstraction, with each level requiring successful implementation of the previous level
- Design tradeoffs: Biological realism vs. computational efficiency, hierarchical complexity vs. implementation simplicity, self-modulation vs. stable learning behavior
- Failure signatures: Inability to progress beyond basic perception tasks, inconsistent self-world distinction, failure to develop social understanding, inability to generalize learned concepts
- First 3 experiments:
  1. Multi-modal concept learning validation with 40-class dataset to achieve baseline 94% accuracy
  2. Rubber hand illusion experiment to verify bodily self-perception and self-world distinction
  3. False belief task implementation to test theory of mind and self-others distinction capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the hierarchical Self framework be empirically validated in artificial agents to ensure it captures the full spectrum of self-awareness?
- Basis in paper: [explicit] The paper proposes a hierarchical Self framework with five levels but does not detail empirical validation methods.
- Why unresolved: The framework's effectiveness in capturing self-awareness needs experimental validation in real-world AI applications.
- What evidence would resolve it: Experimental results demonstrating that AI agents using this framework exhibit behaviors and cognitive capabilities consistent with each level of the Self hierarchy.

### Open Question 2
- Question: What are the specific mechanisms by which higher levels of Self modulate lower-level learning strategies in the BriSe AI paradigm?
- Basis in paper: [explicit] The paper mentions mutual promotion and top-down modulation but lacks detailed mechanisms.
- Why unresolved: Understanding these mechanisms is crucial for implementing effective self-modulated learning in AI systems.
- What evidence would resolve it: Detailed computational models or empirical studies showing how top-down feedback from higher Self levels influences learning processes at lower levels.

### Open Question 3
- Question: How can the integration of multi-modal concept learning and bodily self-perception be optimized to enhance the AI's understanding of complex environments?
- Basis in paper: [explicit] The paper discusses multi-modal concept learning and bodily self-perception but does not explore their integration optimization.
- Why unresolved: Optimizing this integration is essential for improving the AI's environmental understanding and interaction capabilities.
- What evidence would resolve it: Studies or models demonstrating improved environmental perception and interaction when multi-modal concept learning and bodily self-perception are effectively integrated.

## Limitations

- No open-source code or reproducible experimental protocols provided
- Missing critical hyperparameters, network architectures, and training procedures
- Lack of ablation studies showing necessity of self-framework vs. standard approaches
- No comparison with existing brain-inspired AI systems on benchmark tasks

## Confidence

- Multi-level Self framework mechanism: Medium confidence - the hierarchical architecture is conceptually sound but lacks detailed implementation specifications
- Self-modulated learning claims: Low confidence - the supervisory mechanism for achieving "conscious understanding" remains theoretical without empirical validation
- Biological plasticity integration: Medium confidence - the multi-scale approach is consistent with neuroscience literature, but computational translation details are sparse
- Demonstrated capabilities: Low confidence - claimed achievements (94% accuracy, mirror test passing, theory of mind) lack supporting experimental data

## Next Checks

1. **Replicate the 40-class multi-modal concept learning** using the specified BrainCog engine with documented hyperparameters to verify the 94% accuracy claim
2. **Implement the rubber hand illusion experiment** with controlled variables to test whether the system genuinely demonstrates bodily self-perception or merely pattern matching
3. **Conduct a comparative study** where the same learning tasks are performed with and without the self-modulation framework to quantify the claimed benefits for "conscious understanding"