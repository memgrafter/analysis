---
ver: rpa2
title: 'Towards Neural Foundation Models for Vision: Aligning EEG, MEG, and fMRI Representations
  for Decoding, Encoding, and Modality Conversion'
arxiv_id: '2411.09723'
source_url: https://arxiv.org/abs/2411.09723
tags:
- neural
- data
- fmri
- decoding
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a neural foundation model that aligns representations\
  \ of multimodal neural datasets\u2014EEG, MEG, and fMRI\u2014using contrastive learning.\
  \ The framework enables three key tasks: decoding visual information from neural\
  \ data, encoding images into neural representations, and converting between neural\
  \ modalities."
---

# Towards Neural Foundation Models for Vision: Aligning EEG, MEG, and fMRI Representations for Decoding, Encoding, and Modality Conversion

## Quick Facts
- arXiv ID: 2411.09723
- Source URL: https://arxiv.org/abs/2411.09723
- Reference count: 40
- Introduces a neural foundation model for aligning EEG, MEG, and fMRI representations with strong performance across decoding, encoding, and modality conversion tasks

## Executive Summary
This study presents a neural foundation model that leverages contrastive learning to align representations across multimodal neural datasets (EEG, MEG, and fMRI). The framework enables three key tasks: decoding visual information from neural data, encoding images into neural representations, and converting between neural modalities. The model demonstrates state-of-the-art performance across all modalities, with particularly strong results for fMRI and EEG decoding and cross-modal conversion tasks.

## Method Summary
The authors develop a neural foundation model that employs contrastive learning to align representations across three distinct neural modalities: EEG, MEG, and fMRI. The model learns shared semantic spaces that enable cross-modal alignment, allowing for tasks such as decoding visual stimuli from neural signals, encoding images into neural representations, and converting between different neural modalities. The approach leverages large-scale contrastive learning objectives to map diverse neural data streams into a common representational space while preserving semantic information.

## Key Results
- EEG decoding achieves top1 accuracy of 40.0% and CLIP 2-way accuracy of 79.4%
- MEG achieves top1 accuracy of 1.2% and CLIP 2-way accuracy of 60.1%
- fMRI decoding achieves CLIP 2-way accuracy of 93.8%
- Encoding tasks show CLIP 2-way accuracies of 85.5% (EEG), 58.8% (MEG), and 87.8% (fMRI)
- Modality conversion between neural signals achieves normalized CLIP 2-way accuracies exceeding 83% across conversions

## Why This Works (Mechanism)
The model's success stems from its ability to learn shared semantic representations across modalities through contrastive learning. By mapping diverse neural signals into a common space, the model captures underlying visual semantics while preserving modality-specific characteristics. The contrastive objective forces representations to align when they correspond to the same visual content, enabling effective cross-modal transfer and conversion.

## Foundational Learning
- Contrastive learning: Why needed - aligns representations across modalities without paired data; Quick check - examine alignment quality through retrieval tasks
- Multimodal fusion: Why needed - integrates diverse neural signal types with different temporal/spatial properties; Quick check - assess performance degradation when modalities are removed
- Semantic alignment: Why needed - maps neural activity to visual concepts for decoding/encoding; Quick check - evaluate retrieval accuracy against semantic ground truth
- Cross-modal conversion: Why needed - enables translation between neural signal types; Quick check - measure reconstruction quality across modality pairs

## Architecture Onboarding

**Component Map**
Image encoder -> Contrastive loss -> Shared latent space -> EEG/MEG/fMRI encoders -> Decoding head
                       |-> Modality conversion head
                       |-> Encoding head

**Critical Path**
Image encoder -> Contrastive learning -> Shared latent space -> Modality-specific decoders/encoders

**Design Tradeoffs**
- Temporal resolution vs. spatial coverage: EEG/MEG provide fine temporal detail but limited spatial precision compared to fMRI
- Model complexity vs. interpretability: Deeper architectures improve performance but reduce biological interpretability
- Training data requirements: Contrastive learning needs large-scale paired neural-visual datasets

**Failure Signatures**
- Poor modality conversion suggests inadequate alignment in shared latent space
- Decoding failures indicate insufficient semantic capture in neural representations
- Large performance gaps between modalities reveal modality-specific modeling challenges

**3 First Experiments**
1. Ablation study removing contrastive loss to measure alignment contribution
2. Cross-modal retrieval evaluation to assess shared representation quality
3. Single-modality training comparison to evaluate multimodal benefits

## Open Questions the Paper Calls Out
The paper raises questions about the scalability of the approach to naturalistic stimuli, the biological interpretability of learned representations, and the model's performance across diverse subject populations. It also questions how well the learned representations generalize beyond controlled experimental settings.

## Limitations
- Focus on controlled experimental stimuli rather than ecologically valid real-world visual inputs
- Substantial performance variability between modalities (particularly weak MEG performance)
- Limited subject diversity in fMRI datasets raises questions about scalability
- Unknown generalizability to naturalistic, unconstrained visual environments
- Potential overfitting to specific experimental paradigms used in training data

## Confidence
- High: Model capability to perform cross-modal alignment and achieve state-of-the-art results within tested framework
- Medium: Generalization to naturalistic stimuli and diverse populations
- Low: Biological interpretability of learned representations and scaling to unconstrained real-world tasks

## Next Checks
1. Test model performance on ecologically valid, uncontrolled visual stimuli to assess real-world generalization
2. Validate biological interpretability of learned representations by correlating latent features with known neural coding principles
3. Expand subject diversity in fMRI datasets and evaluate modality conversion robustness across demographic variations
4. Evaluate performance on more diverse and naturalistic visual stimuli beyond controlled experimental conditions