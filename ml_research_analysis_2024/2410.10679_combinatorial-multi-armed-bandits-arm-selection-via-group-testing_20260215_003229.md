---
ver: rpa2
title: 'Combinatorial Multi-armed Bandits: Arm Selection via Group Testing'
arxiv_id: '2410.10679'
source_url: https://arxiv.org/abs/2410.10679
tags:
- reward
- regret
- function
- arms
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of combinatorial multi-armed bandits
  with semi-bandand feedback and cardinality constraints on the super-arm size. The
  authors propose a novel algorithm that combines group testing with quantized Thompson
  sampling to significantly reduce the oracle complexity compared to existing methods.
---

# Combinatorial Multi-armed Bandits: Arm Selection via Group Testing

## Quick Facts
- arXiv ID: 2410.10679
- Source URL: https://arxiv.org/abs/2410.10679
- Authors: Arpan Mukherjee; Shashanka Ubaru; Keerthiram Murugesan; Karthikeyan Shanmugam; Ali Tajer
- Reference count: 40
- Primary result: GT+QTS algorithm reduces oracle complexity from exponential to logarithmic while preserving optimal regret bounds

## Executive Summary
This paper introduces GT+QTS, a novel algorithm for combinatorial multi-armed bandits that combines group testing with quantized Thompson sampling to achieve logarithmic oracle complexity while maintaining optimal regret bounds. The key innovation is using group testing to identify optimal super-arms with only O(log m) reward evaluations per round, compared to O(m) for existing methods. The algorithm is theoretically grounded and validated through experiments on both linear and neural network reward functions, demonstrating comparable regret to exact oracle methods while being significantly more computationally efficient.

## Method Summary
The GT+QTS algorithm addresses combinatorial multi-armed bandits with semi-bandit feedback and cardinality constraints by using group testing to efficiently identify optimal super-arms while maintaining accurate parameter estimates through quantized Thompson sampling. The method pools arms into tests, leverages separability assumptions to distinguish optimal from non-optimal arms, and uses uniform quantization to ensure sufficient separation between arm scores during posterior sampling. This approach achieves the same regret order as state-of-the-art algorithms (O(m/Δ_min log K log T)) while requiring exponentially fewer reward function evaluations.

## Key Results
- Reduces oracle complexity from exponential to logarithmic in base arm count (O(log m) vs O(m) reward evaluations)
- Achieves same regret bound O(m/Δ_min log K log T) as exact oracle methods under separability assumptions
- Demonstrates computational efficiency on both linear and neural network reward functions while maintaining comparable regret

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Group testing reduces oracle complexity from exponential to logarithmic in base arm count
- Mechanism: By pooling arms into tests and leveraging separability assumptions, GT identifies optimal super-arms with far fewer reward evaluations
- Core assumption: Reward function satisfies separability (Assumption 6) - adding an optimal arm to any set yields higher reward than adding a non-optimal arm
- Break condition: If reward function violates separability assumption, GT oracle fails and algorithm reverts to linear regret

### Mechanism 2
- Claim: Quantized Thompson Sampling maintains optimal regret bounds while enabling efficient group testing
- Mechanism: Uniform quantization of reward values ensures sufficient separation between optimal and non-optimal arm scores, preventing reward function non-separability issues during posterior sampling
- Core assumption: Quantization level Δ chosen based on minimum gap distribution F_μ ensures separability with high probability
- Break condition: If quantization granularity is too coarse, optimal arms may be indistinguishable leading to suboptimal selection

### Mechanism 3
- Claim: The combination of GT encoding/decoding with TS estimation achieves same regret order as exact oracle methods
- Mechanism: GT identifies candidate super-arms efficiently, while TS maintains accurate posterior estimates for mean rewards; together they match CTS with exact oracle performance
- Core assumption: TS-based estimator with Beta posteriors provides accurate mean estimates for base arms
- Break condition: If TS estimator fails to converge or GT oracle makes errors, cumulative regret increases

## Foundational Learning

- Concept: Combinatorial Multi-Armed Bandits with Semi-Bandit Feedback
  - Why needed here: This is the core problem setting - understanding how multiple arms are selected together and how individual feedback is received
  - Quick check question: What's the difference between bandit feedback (aggregate reward only) and semi-bandit feedback (individual arm observations)?

- Concept: Group Testing Theory
  - Why needed here: Group testing is the key technique that enables exponential reduction in oracle complexity
  - Quick check question: How does the number of tests required scale with the number of defective items K in noiseless group testing?

- Concept: Thompson Sampling with Beta Posteriors
  - Why needed here: The algorithm uses TS for parameter estimation of base arm means
  - Quick check question: Why is Beta distribution the natural conjugate prior for Bernoulli-distributed rewards?

## Architecture Onboarding

- Component map: Base Arm Parameter Estimator -> Group Testing Oracle -> Reward Function Evaluator -> Super-Arm Selector -> Regret Tracker
- Critical path: Parameter estimation → Group testing oracle → Super-arm selection → Reward observation → Parameter update
- Design tradeoffs:
  - Tradeoff between quantization level Δ and test count ℓ (smaller Δ requires more tests)
  - Choice of test matrix parameters p and ℓ affects identification probability
  - Balance between exploration (parameter estimation) and exploitation (super-arm selection)
- Failure signatures:
  - Non-separability: Reward function evaluations at posterior means don't satisfy Assumption 6
  - Quantization collapse: Multiple super-arms map to same quantized reward value
  - TS convergence failure: Posterior distributions don't concentrate around true means
- First 3 experiments:
  1. Linear reward function with m=100 arms, K=5, verify logarithmic reduction in oracle complexity vs exact oracle
  2. Neural network reward function with m=50 arms, test quantization level impact on regret and test count
  3. Varying minimum gap Δ_min to test regret bound scaling and oracle efficiency across problem difficulty levels

## Open Questions the Paper Calls Out

- Question: How does the GT+QTS algorithm perform under non-separable reward functions that don't satisfy Assumption 6?
  - Basis in paper: The paper states that "the success of [group testing] fundamentally relies on separability assumptions, lacking which we may face sub-optimal (linear) regret."
  - Why unresolved: The paper only analyzes performance under separable reward functions and doesn't provide theoretical guarantees or empirical results for non-separable cases.
  - What evidence would resolve it: Experimental results comparing GT+QTS performance on both separable and non-separable reward functions, along with theoretical analysis of regret bounds in the non-separable case.

- Question: What is the impact of quantization level ∆ on the regret bound, and is there an optimal choice of ∆?
  - Basis in paper: The paper mentions that "Smaller the quantization level ∆, more tests are required to find the optimal super-arm" and sets ∆ := F⁻¹_μ(γ), but doesn't explore the trade-off in detail.
  - Why unresolved: While the paper establishes that there exists a choice of ∆ that preserves the regret bound, it doesn't characterize how different choices of ∆ affect the actual regret or computational efficiency.
  - What evidence would resolve it: Empirical studies showing regret and computational efficiency as a function of ∆ for various problem instances, along with theoretical analysis of the trade-off.

- Question: How does the GT+QTS algorithm scale with the cardinality constraint K?
  - Basis in paper: The paper mentions the cardinality constraint K but doesn't provide a detailed analysis of how the algorithm's performance changes with different values of K.
  - Why unresolved: The theoretical analysis and experiments focus on a fixed K, but don't explore how the regret or computational efficiency scales with K.
  - What evidence would resolve it: Experimental results showing regret and computational efficiency as a function of K for various problem sizes, along with theoretical analysis of the scaling behavior.

- Question: Can the GT+QTS algorithm be extended to contextual combinatorial bandits?
  - Basis in paper: The paper focuses on the non-contextual case, but contextual bandits are a natural extension of the standard bandit problem.
  - Why unresolved: The paper doesn't discuss how the GT+QTS algorithm could be adapted to handle contextual information, which is often crucial in practical applications.
  - What evidence would resolve it: A theoretical framework for extending GT+QTS to the contextual setting, along with experimental results demonstrating the effectiveness of the extension.

## Limitations

- The algorithm's effectiveness critically depends on the separability assumption for the reward function, which may not hold for arbitrary reward functions
- Practical methods for estimating the minimum gap distribution F_μ are not specified, introducing uncertainty in quantization level selection
- Theoretical analysis relies on idealized group testing conditions that may not hold in practice, particularly for non-linear reward functions

## Confidence

- Mechanism 1 (Group testing complexity reduction): Medium - theoretical analysis is sound but separability assumption validity is uncertain
- Mechanism 2 (Quantized Thompson Sampling): Medium - quantization preserves regret bounds under assumptions but practical implementation challenges exist
- Mechanism 3 (Combined GT+QTS performance): Low - claims of matching exact oracle regret are theoretical; empirical validation is limited

## Next Checks

1. **Separability Testing**: Develop a systematic method to verify reward function separability before applying GT+QTS, and quantify performance degradation when the assumption is violated.

2. **Practical Quantization**: Design and test practical approaches for estimating the minimum gap distribution F_μ in real applications, and evaluate how different quantization strategies affect regret and oracle complexity.

3. **Robustness Analysis**: Conduct experiments varying the group testing parameters (test matrix design, number of tests) to identify failure modes and establish practical guidelines for parameter selection in different problem regimes.