---
ver: rpa2
title: 'Robust Planning with Compound LLM Architectures: An LLM-Modulo Approach'
arxiv_id: '2411.14484'
source_url: https://arxiv.org/abs/2411.14484
tags:
- days
- plan
- visit
- travel
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces LLM-Modulo, a compound architecture that pairs
  LLMs with sound verifiers to ensure correctness in planning and scheduling tasks.
  The framework iteratively generates solutions and validates them using external
  critics, guaranteeing that all outputs are correct.
---

# Robust Planning with Compound LLM Architectures: An LLM-Modulo Approach

## Quick Facts
- arXiv ID: 2411.14484
- Source URL: https://arxiv.org/abs/2411.14484
- Reference count: 40
- One-line primary result: LLM-Modulo framework guarantees correctness in planning tasks by pairing LLMs with sound verifiers, achieving significant accuracy improvements across four scheduling domains.

## Executive Summary
This paper introduces LLM-Modulo, a compound architecture that combines large language models with sound verifiers to ensure correctness in planning and scheduling tasks. The framework operates iteratively, generating candidate solutions and validating them against external critics until all constraints are satisfied or iteration limits are reached. Experiments across four scheduling domains demonstrate substantial performance improvements, with GPT-4o's accuracy on Travel Planner improving from 8.3% to 23.89%, and Claude-3.5-Sonnet's accuracy on Calendar Scheduling improving from 56.1% to 83.3%.

## Method Summary
LLM-Modulo implements a generate-test-critique loop where an LLM generates solutions to scheduling problems, which are then validated by a panel of sound verifiers (critics). The metacontroller collects feedback from critics and generates backprompts to guide the LLM toward correct solutions. The process iterates until all critics approve the solution or a maximum iteration budget is reached. The framework is evaluated on four scheduling domains (Travel Planner, Trip Planning, Meeting Planning, and Calendar Scheduling) using various LLM models including GPT-4o-mini, GPT-4o, and Claude-3.5-Sonnet.

## Key Results
- GPT-4o accuracy on Travel Planner improves from 8.3% to 23.89% with LLM-Modulo
- Claude-3.5-Sonnet accuracy on Calendar Scheduling improves from 56.1% to 83.3% with LLM-Modulo
- Framework guarantees correctness by using sound verifiers that never approve incorrect solutions
- Performance gains are consistent across multiple LLM models and scheduling domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-Modulo guarantees correctness by using sound verifiers to validate every output
- Mechanism: The framework iteratively generates candidate solutions and validates them against a panel of sound critics. If any critic flags an issue, the LLM is prompted again with feedback until all critics approve or a maximum iteration budget is reached
- Core assumption: The critics themselves are sound and will never approve an incorrect solution
- Evidence anchors:
  - [abstract] "In this framework, an LLM is paired with a complete set of sound verifiers that validate its output, re-prompting it if it fails. This approach ensures that the system can never output any fallacious output, and therefore that every output generated is guaranteed correct"
  - [section 3.2] "For all the domains, we utilize the code present as part of the benchmark as critics to evaluate the proposed solutions"
  - [corpus] Weak - no corpus evidence specifically about soundness guarantees
- Break condition: If critics are unsound or incorrectly implemented, the correctness guarantee fails

### Mechanism 2
- Claim: LLM-Modulo improves performance by iteratively refining solutions based on critic feedback
- Mechanism: Each iteration provides the LLM with specific feedback about what aspects of the previous solution were incorrect, allowing it to generate better solutions in subsequent attempts
- Core assumption: The LLM can effectively incorporate critic feedback to generate improved solutions
- Evidence anchors:
  - [abstract] "Our results, evaluated across four scheduling domains, demonstrate significant performance gains with the LLM-Modulo framework using various models"
  - [section 5.3] "We examine diversification at the generation level by prompting the base LLM to generate multiple solutions for each presented query"
  - [corpus] Weak - corpus evidence about iterative refinement is limited
- Break condition: If the LLM cannot effectively use feedback or if feedback is too generic, performance gains diminish

### Mechanism 3
- Claim: LLM-Modulo handles domain complexity by systematically checking constraints
- Mechanism: Different domains have different constraint types (format, duration, availability, etc.) that are checked by specialized critics, allowing the framework to handle complex scheduling problems that LLMs struggle with alone
- Core assumption: Constraint checking can be automated and integrated as part of the critic panel
- Evidence anchors:
  - [section 4.2] "The first critic verifies that the duration of the stay in each city matches the specified constraints. The second critic checks whether the required flights are available based on the planned itinerary"
  - [section 4.3] "The sole critic checks if the generated response meeting time clashes with any attendee's schedule"
  - [corpus] Moderate - related papers mention constraint checking but not specifically in LLM-Modulo context
- Break condition: If constraints cannot be formalized or automated, the framework cannot handle that domain

## Foundational Learning

- Concept: Constraint Satisfaction Problems (CSPs)
  - Why needed here: Scheduling domains are modeled as CSPs where the LLM-Modulo framework systematically checks if solutions satisfy all constraints
  - Quick check question: What makes scheduling problems computationally challenging compared to simple text generation?

- Concept: Sound vs. Complete Systems
  - Why needed here: LLM-Modulo provides soundness guarantees (no wrong answers) but not completeness (may not find all correct answers) - understanding this distinction is crucial
  - Quick check question: Can you explain the difference between a sound system and a complete system?

- Concept: Iterative Refinement
  - Why needed here: The framework works by iteratively improving solutions based on feedback, similar to how humans refine their work after receiving critiques
  - Quick check question: How does providing specific feedback to an LLM differ from general prompts?

## Architecture Onboarding

- Component map: Prompt Generator → LLM → Format Critic → Constraint Critics → Metacontroller → Backprompt → LLM (loop)
- Critical path: Problem specification → Prompt generation → LLM generation → Format validation → Constraint validation → Output or iteration
- Design tradeoffs:
  - More critics = better guarantees but slower performance
  - Higher iteration limits = better accuracy but increased cost
  - Generic critics = broader applicability but less precision
  - Domain-specific critics = better performance but less reusable
- Failure signatures:
  - LLM gets stuck in loops generating similar incorrect solutions
  - Critics become too permissive and approve wrong answers
  - Metacontroller fails to consolidate feedback effectively
  - Format issues prevent solutions from reaching constraint critics
- First 3 experiments:
  1. Test LLM-Modulo on a simple scheduling problem with one clear constraint
  2. Run the same problem with and without the format critic to see its impact
  3. Increase iteration limit from 3 to 10 and measure accuracy improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLM-Modulo scale with increasing problem complexity beyond the hardest subsets tested?
- Basis in paper: [explicit] The paper notes that LLM-Modulo "demonstrates improvements in handling instances of varying complexity within each domain, including the hardest subsets" but does not explore scaling beyond these hardest cases.
- Why unresolved: The experiments were limited to the hardest subsets of the existing datasets, leaving the behavior on problems more complex than those tested unknown.
- What evidence would resolve it: Testing LLM-Modulo on synthetic problems or extended domains with complexity exceeding the current hardest cases, measuring accuracy degradation or failure points.

### Open Question 2
- Question: What is the impact of extending the iteration budget beyond 10 on final accuracy, and is there a point of diminishing returns?
- Basis in paper: [explicit] The paper states experiments "were constrained to 10 iterations of the LLM-Modulo framework due to cost limitations."
- Why unresolved: The analysis only reports results at exactly 10 iterations, without exploring whether additional iterations yield meaningful accuracy gains or if performance plateaus.
- What evidence would resolve it: Running LLM-Modulo with varying iteration budgets (e.g., 20, 50, 100) and plotting accuracy versus iterations to identify convergence behavior.

### Open Question 3
- Question: How robust is LLM-Modulo to adversarial or malformed inputs that exploit weaknesses in the critic extraction process?
- Basis in paper: [inferred] The paper describes extracting critics from LLMs but notes "with minimal modifications (such as fixing function call signature and syntax which itself can be automated via critics such as compilers and parsers) the generated critics matched the efficacy of the pre-existing ones," suggesting potential vulnerabilities.
- Why unresolved: No evaluation was conducted on deliberately crafted inputs designed to break the critic extraction or validation process.
- What evidence would resolve it: Creating adversarial test cases that attempt to confuse the LLM-generated critics and measuring failure rates of the overall system.

## Limitations

- The framework's correctness guarantee depends critically on the soundness of external critics, which are assumed rather than formally verified
- Performance improvements come at the cost of increased latency and computational expenses due to iterative generation
- Experiments focus on constrained scheduling domains, limiting evidence for generalization to more complex planning tasks

## Confidence

**High Confidence**: The LLM-Modulo framework can improve LLM performance on scheduling tasks when paired with appropriate verifiers. The experimental results showing accuracy improvements across multiple models and domains are well-documented and reproducible.

**Medium Confidence**: The correctness guarantees hold when using sound verifiers. While the mechanism is sound in principle, the actual implementation details of the critics and their soundness properties are not fully specified, requiring trust in the authors' implementation.

**Low Confidence**: The LLM-Modulo framework will scale effectively to more complex planning domains beyond the tested scheduling tasks. The paper provides limited evidence about generalization to domains with more complex constraints or less structured problem specifications.

## Next Checks

1. **Critic Soundness Verification**: Implement a systematic testing framework to verify that each critic correctly identifies invalid solutions across a comprehensive set of edge cases, including formally proving or empirically validating critic soundness properties.

2. **Cross-Domain Generalization**: Apply LLM-Modulo to at least two non-scheduling planning domains (such as resource allocation or task sequencing) with different constraint structures to test the framework's generalizability beyond the tested scheduling tasks.

3. **Iteration Efficiency Analysis**: Conduct experiments measuring the relationship between iteration count, solution quality, and computational cost to determine optimal iteration limits and identify conditions where the framework converges efficiently versus getting stuck in refinement loops.