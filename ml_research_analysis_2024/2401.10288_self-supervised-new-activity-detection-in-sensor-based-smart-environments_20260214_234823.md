---
ver: rpa2
title: Self-supervised New Activity Detection in Sensor-based Smart Environments
arxiv_id: '2401.10288'
source_url: https://arxiv.org/abs/2401.10288
tags:
- data
- clan
- activity
- learning
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents CLAN, a self-supervised novelty detection framework
  for identifying new activities in sensor-based smart environments. The core method
  leverages contrastive learning with diverse data augmentation to construct invariant
  representations in both time and frequency domains.
---

# Self-supervised New Activity Detection in Sensor-based Smart Environments

## Quick Facts
- arXiv ID: 2401.10288
- Source URL: https://arxiv.org/abs/2401.10288
- Authors: Hyunju Kim; Dongman Lee
- Reference count: 40
- Primary result: 9.24% AUROC improvement over baselines in sensor-based activity novelty detection

## Executive Summary
This paper introduces CLAN, a self-supervised framework for detecting new activities in sensor-based smart environments using contrastive learning. The system automatically selects appropriate data augmentation methods to create invariant representations across time and frequency domains, enabling effective novelty detection without labeled data. CLAN achieves significant improvements over existing methods across four real-world HAR datasets, with particular strength in reducing false positives and improving balanced accuracy. The framework demonstrates robust performance across diverse activity types and data sizes, making it suitable for real-world deployment in smart environments.

## Method Summary
CLAN employs contrastive learning with automatically selected data augmentation techniques to detect novel activities in sensor-based smart environments. The framework constructs invariant representations by creating positive and negative pairs through diverse augmentations tailored to each dataset's characteristics. A key innovation is the automatic augmentation selector that chooses optimal augmentation methods based on dataset properties. The system operates in both time and frequency domains, enabling comprehensive activity pattern recognition. Experimental evaluation demonstrates superior performance compared to baseline methods across multiple real-world HAR datasets.

## Key Results
- Achieves 9.24% AUROC improvement over the best baseline method
- Demonstrates up to 17.2% improvement in balanced accuracy
- Reduces false positive rate by up to 66.7% compared to baselines
- Shows consistent performance across four diverse real-world HAR datasets

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to learn invariant representations through contrastive learning combined with dataset-specific augmentation selection. By automatically tailoring augmentation methods to each dataset's properties, CLAN creates more discriminative features that better capture the characteristics of known and novel activities. The dual-domain approach (time and frequency) enables comprehensive pattern recognition, while the self-supervised nature eliminates the need for labeled data during training.

## Foundational Learning

- **Contrastive Learning**: Learning representations by comparing similar and dissimilar pairs - needed for creating discriminative features without labels; quick check: verify positive/negative pair creation quality
- **Data Augmentation**: Applying transformations to create synthetic variations - needed to improve model robustness and generalization; quick check: validate augmentation diversity and effectiveness
- **Sensor Signal Processing**: Analyzing time-series data from environmental sensors - needed for extracting meaningful features from raw sensor readings; quick check: ensure proper signal preprocessing
- **Novelty Detection**: Identifying patterns that deviate from known classes - needed for detecting new activities without prior examples; quick check: validate detection threshold selection
- **Automatic Hyperparameter Selection**: Dynamically choosing optimal parameters based on dataset characteristics - needed for maximizing performance across diverse datasets; quick check: evaluate selector accuracy
- **Domain Adaptation**: Handling variations across different sensor environments - needed for real-world deployment robustness; quick check: test cross-dataset generalization

## Architecture Onboarding

Component Map: Sensor Data -> Preprocessing -> Augmentation Selector -> Contrastive Learning -> Feature Representation -> Novelty Detection

Critical Path: The most critical path involves sensor data preprocessing followed by the augmentation selector's choice of appropriate transformations, which directly impacts the quality of contrastive learning and subsequent novelty detection performance.

Design Tradeoffs: The framework balances between augmentation diversity and computational efficiency, with the automatic selector adding overhead but improving detection accuracy. The dual-domain approach increases complexity but provides more comprehensive feature extraction.

Failure Signatures: Performance degradation occurs when augmentation selection fails to capture dataset-specific characteristics, when sensor noise overwhelms signal patterns, or when activity classes are too similar to distinguish.

First Experiments:
1. Baseline performance comparison on binary novelty detection tasks
2. Ablation study removing automatic augmentation selector
3. Cross-dataset validation to test generalization capabilities

## Open Questions the Paper Calls Out

None identified in the provided content.

## Limitations

- Performance evaluation focuses on binary activity detection rather than multi-class novel activity scenarios
- Limited testing on highly imbalanced datasets with sparse new activity occurrences
- No evaluation of real-time deployment performance on resource-constrained edge devices

## Confidence

High confidence in core contrastive learning approach and augmentation selection mechanism. Medium confidence in framework's effectiveness for complex multi-activity scenarios and real-world deployment. Low confidence in performance under extreme data imbalance and computational overhead characterization.

## Next Checks

1. Test CLAN's performance on datasets with highly imbalanced class distributions (e.g., <5% new activity instances) to evaluate robustness in realistic deployment scenarios
2. Conduct ablation studies to quantify the contribution of each augmentation method and the automatic selector's overhead
3. Evaluate the framework's computational efficiency and memory requirements for real-time deployment on resource-constrained edge devices commonly used in smart environments