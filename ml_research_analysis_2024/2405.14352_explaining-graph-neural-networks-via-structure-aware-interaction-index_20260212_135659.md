---
ver: rpa2
title: Explaining Graph Neural Networks via Structure-aware Interaction Index
arxiv_id: '2405.14352'
source_url: https://arxiv.org/abs/2405.14352
tags:
- graph
- index
- interaction
- neural
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new method, MAGE, to explain graph neural
  networks (GNNs) by identifying important graph substructures (motifs) that influence
  model predictions. Unlike prior approaches, MAGE uses the Myerson-Taylor interaction
  index to capture both the graph structure and high-order node interactions when
  attributing importance scores.
---

# Explaining Graph Neural Networks via Structure-aware Interaction Index

## Quick Facts
- arXiv ID: 2405.14352
- Source URL: https://arxiv.org/abs/2405.14352
- Reference count: 40
- Key outcome: MAGE outperforms seven state-of-the-art baselines, achieving up to 27.55% higher explanation accuracy on ten datasets.

## Executive Summary
This paper introduces MAGE (Myerson-Taylor Structure-Aware Graph Explainer), a novel method for explaining Graph Neural Networks (GNNs) by identifying important graph substructures (motifs) that influence model predictions. Unlike prior approaches, MAGE uses the Myerson-Taylor interaction index to capture both graph structure and high-order node interactions when attributing importance scores. MAGE solves an optimization problem to find multiple motifs that maximize total absolute attribution scores, thus capturing both positive and negative contributions. Experiments show MAGE consistently outperforms seven state-of-the-art baselines, achieving up to 27.55% higher explanation accuracy while providing more interpretable, connected motifs.

## Method Summary
MAGE computes the Myerson-Taylor interaction index to measure pairwise interactions among nodes while respecting graph connectivity constraints. It then solves an optimization problem to identify multiple explanatory motifs that maximize the sum of absolute group attribution scores. The method uses Monte Carlo sampling to approximate the interaction index and MOSEK solver for motif search. MAGE is evaluated on ten datasets (including synthetic, biological, text, and image data) with three GNN models (GCN, GIN, GAT), demonstrating superior explanation accuracy compared to baselines.

## Key Results
- MAGE achieves up to 27.55% higher explanation accuracy compared to seven state-of-the-art baselines
- MAGE provides more interpretable explanations by identifying connected, human-understandable motifs rather than disconnected nodes
- MAGE effectively captures both positive and negative contributions to model predictions through its optimization framework

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Myerson-Taylor interaction index internalizes graph structure into attributing node values and interaction values
- Mechanism: Replaces vanilla function f with interaction-restricted function f|E in Shapley-Taylor index, allowing information propagation only among connected nodes
- Core assumption: GNN models trained on connected subgraphs won't generalize well to disconnected ones, reducing OOD bias
- Evidence anchors: Abstract mentions neglecting graph structure in existing approaches; section 4.1 contrasts structure-agnostic Shapley-Taylor index
- Break condition: If GNN models can generalize to disconnected subgraphs, bias reduction advantage disappears

### Mechanism 2
- Claim: MAGE identifies both positive and negative motifs influencing GNN predictions
- Mechanism: Uses second-order Myerson-Taylor index to compute pairwise interactions, solves optimization to maximize sum of absolute group attribution scores
- Core assumption: Sum of absolute group attribution values effectively captures influence of motifs, both positive and negative
- Evidence anchors: Abstract mentions maximizing total absolute attribution score; section 4.2 describes maximizing sum of absolute group attribution values
- Break condition: If optimization problem doesn't effectively capture true motif influence, or absolute values obscure important distinctions

### Mechanism 3
- Claim: Myerson-Taylor index satisfies system of five natural axioms accounting for graph structure and high-order interaction
- Mechanism: Myerson-Taylor index is unique allocation rule satisfying linearity, restricted null player, coalitional fairness, interaction distribution, and component efficiency axioms
- Core assumption: These axioms are necessary and sufficient for fair, effective interaction index for graph-structured data
- Evidence anchors: Abstract mentions unique allocation rule satisfying five axioms; section 5 proves uniqueness via Theorem 5.1
- Break condition: If any axioms are not applicable or desirable for specific GNN explanation task, uniqueness may not hold

## Foundational Learning

- Concept: Cooperative game theory and Shapley value
  - Why needed here: Shapley value quantifies contribution of each player (node) to overall value (model prediction), providing fair way to attribute importance scores
  - Quick check question: How does Shapley value differ from simply summing marginal contributions of each node?

- Concept: Graph neural networks (GNNs) and their message-passing paradigm
  - Why needed here: GNNs are target models being explained; understanding architecture and information propagation is crucial for designing effective explanation methods
  - Quick check question: What is key difference between interaction-restricted function f|E in Myerson-Taylor index and vanilla function f?

- Concept: Graph structure and connectivity
  - Why needed here: Graph structure and connectivity are central to Myerson-Taylor index, explicitly accounting for fact that nodes can only interact if connected
  - Quick check question: How does Myerson-Taylor index differ from Shapley-Taylor index in handling disconnected subgraphs?

## Architecture Onboarding

- Component map: Graph input -> Myerson-Taylor interaction index computation -> Motif search optimization -> GNN model

- Critical path: 1) Compute second-order Myerson-Taylor index (interaction matrix B), 2) Decompose B into positive (B+) and negative (B-) components, 3) Solve motif search optimization problem to find m explanatory motifs

- Design tradeoffs: Accuracy vs. computational cost (higher-order indices provide better explanations but require more model queries); Positive vs. negative contributions (parameter τ allows focusing but requires domain knowledge)

- Failure signatures: Poor explanation accuracy (if Myerson-Taylor index doesn't capture true interactions, or motif search optimization fails); High computational cost (if model queries or running time becomes prohibitive)

- First 3 experiments: 1) Verify Myerson-Taylor index correctly computes pairwise interactions for simple graph and GNN model, 2) Test motif search optimization on small graph with known explanatory motifs, 3) Compare explanation accuracy and computational cost against baseline methods on standard dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Myerson-Taylor interaction index perform compared to higher-order interaction indices (k > 3) in terms of explanation accuracy and computational efficiency?
- Basis in paper: [explicit] Ablation study comparing second-order and third-order Myerson-Taylor indices on BA-2Motifs dataset, showing third-order increases performance but significantly increases computational cost
- Why unresolved: Study only compares up to k = 3; unclear if further increasing k yields significant accuracy improvements justifying additional computational burden, or if gains plateau
- What evidence would resolve it: Extensive experiments comparing performance and computational cost of Myerson-Taylor index for various k values (e.g., k = 2, 3, 4, 5) on diverse datasets and GNN models, measuring both explanation accuracy and computational resources

### Open Question 2
- Question: How does Myerson-Taylor interaction index perform when applied to GNN models with different architectural characteristics?
- Basis in paper: [inferred] Evaluates MAGE on three GNN models but doesn't analyze how performance is affected by different architectural choices within these models
- Why unresolved: Current experiments provide general assessment across different GNN architectures but don't investigate impact of specific architectural variations on Myerson-Taylor index effectiveness
- What evidence would resolve it: Systematic study comparing MAGE performance using Myerson-Taylor index on GNN models with different architectural configurations and analyzing how variations affect explanation quality

### Open Question 3
- Question: Can Myerson-Taylor interaction index be extended to handle dynamic graphs where structure and node features change over time?
- Basis in paper: [inferred] Focuses on explaining GNNs for static graph inputs, doesn't address challenges of explaining models on dynamic graphs
- Why unresolved: Myerson-Taylor index designed for static graphs; unclear how to adapt it to capture temporal dependencies and evolving interactions in dynamic graphs
- What evidence would resolve it: Development and evaluation of extension specifically designed for dynamic graphs, along with experiments demonstrating effectiveness in explaining GNN predictions on dynamic graph data

## Limitations
- Computational complexity may become prohibitive for very large graphs or higher-order interactions (k > 2)
- Focus on pairwise interactions (k = 2) may miss important higher-order interactions among nodes
- Choice of τ to control positive vs. negative contributions requires domain knowledge and may not always be straightforward

## Confidence
- High confidence: Theoretical foundations of Myerson-Taylor index, including uniqueness under five axioms and ability to internalize graph structure
- Medium confidence: Empirical performance of MAGE on tested datasets and GNN models, given comprehensive experiments and comparison with baselines
- Medium confidence: Claim that MAGE provides more interpretable explanations by identifying connected, human-understandable motifs, as this is somewhat subjective and depends on application domain

## Next Checks
1. Test MAGE on a larger, more complex graph dataset (e.g., real-world social network or molecular dataset) to assess scalability and performance on graphs with thousands of nodes and edges
2. Compare MAGE with baseline methods on dataset with known ground truth motifs (e.g., BA-2Motifs) to validate explanation accuracy and interpretability
3. Experiment with higher-order interactions (k > 2) in Myerson-Taylor index to determine if they provide better explanations at cost of increased computational complexity