---
ver: rpa2
title: Information Retrieval with Entity Linking
arxiv_id: '2404.08678'
source_url: https://arxiv.org/abs/2404.08678
tags:
- entities
- entity
- retrieval
- query
- recall
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The work proposes using entity linking to expand sparse retrieval
  corpora (queries and documents) with linked entity names, aiming to reduce vocabulary
  gaps and semantic ambiguities in information retrieval. By leveraging recent advances
  in zero-shot end-to-end entity linking, both explicit and hashed forms of entity
  names are appended to the original text before indexing.
---

# Information Retrieval with Entity Linking

## Quick Facts
- **arXiv ID**: 2404.08678
- **Source URL**: https://arxiv.org/abs/2404.08678
- **Reference count**: 40
- **Key outcome**: Entity linking improves BM25 recall@1000 on MS MARCO passage dataset, especially for hard queries, but does not benefit dense retrieval.

## Executive Summary
This paper explores using entity linking to expand queries and documents with linked entity names, aiming to reduce vocabulary gaps and semantic ambiguities in information retrieval. By appending explicit and hashed entity names to the original text before indexing, the approach improves BM25 recall@1000, particularly for harder query subsets. Run combination strategies like RRF fusion and classifier selection further enhance performance, but dense retrieval models like STAR-ADORE do not benefit from entity expansion, suggesting sparse matching gains are more pronounced than semantic gains for dense models.

## Method Summary
The method uses the ELQ entity linking system to extract entity mentions from MS MARCO queries and passages, then expands the corpus with both explicit and MD5-hashed entity names. The expanded corpus is indexed with BM25 and used for retrieval, with results combined via RRF fusion and classifier selection. The same entity-expanded corpus is also tested with a dense retriever (STAR-ADORE) for comparison. The approach is designed to bridge vocabulary gaps in sparse retrieval while preserving semantic fidelity.

## Key Results
- Entity expansion improves BM25 recall@1000 over baseline, especially on harder queries.
- Run combination (RRF fusion) yields the best gains, outperforming individual runs.
- Dense retrieval (STAR-ADORE) shows no significant improvement from entity expansion.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entity linking reduces vocabulary gaps and semantic ambiguities by expanding both queries and documents with explicit entity names.
- Mechanism: The ELQ system identifies entity mentions in the original text and appends corresponding entity names from Wikipedia, enriching the context. This allows exact matching of semantically equivalent terms that differ lexically, improving retrieval recall.
- Core assumption: The entity linking system accurately recognizes and disambiguates mentions in short noisy texts like MS MARCO queries.
- Evidence anchors:
  - [abstract]: "The suggested approach is also capable of retrieving documents for query subsets judged to be particularly difficult in prior work."
  - [section]: "The proposed approach is also tested on dense retrievers... There was no significant change in the overall performance of the dense retriever."
  - [corpus]: Weak — corpus does not directly test entity linking accuracy on MS MARCO.
- Break condition: If ELQ fails to disambiguate entity mentions, incorrect expansions could add noise and degrade retrieval performance.

### Mechanism 2
- Claim: Run combination strategies (RRF and classifier selection) exploit complementary retrieval results from different entity-expanded runs.
- Mechanism: The RRF method fuses rankings from runs with no entities, explicit entities, and hashed entities, boosting recall by combining distinct result sets. The classifier selects the best run per query.
- Core assumption: Different runs retrieve complementary documents that individual runs miss.
- Evidence anchors:
  - [abstract]: "Run combination methods such as run fusion and classifier selection are experimented to maximize the benefits of entity linking."
  - [section]: "The suggested approach is also capable of retrieving documents for query subsets judged to be particularly difficult in prior work."
  - [corpus]: Weak — corpus does not detail pairwise overlap analysis between runs.
- Break condition: If runs overlap heavily, fusion adds little benefit; if classifier training data is poor, selection accuracy drops.

### Mechanism 3
- Claim: Entity linking narrows the recall gap between sparse and dense retrievers by improving sparse retriever performance.
- Mechanism: Expanded queries/documents enable BM25 to retrieve more relevant passages, reducing the performance gap with dense models like ANCE.
- Core assumption: Semantic expansion benefits sparse exact-match models more than dense semantic models.
- Evidence anchors:
  - [abstract]: "While I was successful in improving the recall of BM25 with corpus augmentation, there was no significant change in the overall performance of the dense retriever."
  - [section]: "The objective is to demonstrate that in the 'age of muppets' [293], sparse retrievers can still hold a solid performance boosted by the novel semantic linking systems."
  - [corpus]: Weak — corpus does not provide dense retrieval performance breakdown.
- Break condition: If dense models already capture semantics well, expansion offers minimal marginal benefit.

## Foundational Learning

- **Named Entity Recognition (NER) and Named Entity Disambiguation (NED)**
  - Why needed here: Entity linking relies on NER to identify mentions and NED to map them to knowledge base entries before expansion.
  - Quick check question: What are the two main subtasks of entity linking and why must both succeed for effective expansion?

- **Reciprocal Rank Fusion (RRF)**
  - Why needed here: RRF merges rankings from multiple retrieval runs to maximize recall by combining complementary results.
  - Quick check question: How does RRF compute the fused score and why is the constant 60 used?

- **Recall@K metric**
  - Why needed here: Recall@1000 measures the fraction of relevant documents retrieved among the top 1000, appropriate for early-stage retrieval evaluation.
  - Quick check question: Why is recall@1000 preferred over precision@K for first-stage retrieval evaluation?

## Architecture Onboarding

- **Component map**:
  - Input: MS MARCO queries and passages
  - ELQ entity linking (NER + NED)
  - Corpus expansion (explicit and hashed entity forms)
  - BM25 indexing and retrieval
  - Run generation (no entities, entities, hashed entities)
  - Run combination (RRF, classifier selection)
  - Evaluation (recall@1000 vs original/MonoT5/DuoT5 qrels)

- **Critical path**:
  - ELQ → Expansion → BM25 Index → Retrieval → Run Generation → Combination → Evaluation

- **Design tradeoffs**:
  - Entity expansion vs. index size growth
  - Hashing entities to avoid partial matches vs. interpretability loss
  - RRF fusion vs. classifier selection for combining runs

- **Failure signatures**:
  - Low recall improvement indicates poor entity recognition or expansion noise
  - Classifier underperformance suggests insufficient training signal or run overlap
  - Dense retriever neutral results may mean semantic expansion less beneficial for dense models

- **First 3 experiments**:
  1. Run BM25 with no entity expansion to establish baseline recall@1000.
  2. Run BM25 with explicit entity expansion and compare recall gain.
  3. Run BM25 with hashed entity expansion and evaluate impact on recall and matching precision.

## Open Questions the Paper Calls Out
- Does the negative impact of hashed entities on BM25 performance stem from the hashing method itself or from the specific hashing approach (MD5) used in the experiments?
- How do entity descriptions (rather than just entity names) affect retrieval performance in sparse and dense models?
- Why does the inclusion of hashed-entity-aware runs in reciprocal rank fusion sometimes improve overall performance, despite their poor individual performance?

## Limitations
- Lack of detailed evaluation of entity linking accuracy on MS MARCO queries, which could introduce noise.
- Unclear whether MD5 hashing is optimal for multi-word entity names, affecting matching precision.
- Dense retrieval experiments show no benefit from entity expansion, but the reason is not deeply explored.

## Confidence
- **High confidence**: Entity expansion improves BM25 recall@1000, supported by direct experimental evidence and baseline comparisons.
- **Medium confidence**: Run combination provides additional gains, but assumes complementary results without detailed overlap analysis.
- **Low confidence**: Dense retrievers show no benefit from expansion, but lacks error analysis or ablation studies to explain why.

## Next Checks
1. Evaluate ELQ entity linking precision and recall specifically on MS MARCO queries to quantify expansion quality.
2. Perform pairwise overlap analysis between no-entity, explicit-entity, and hashed-entity retrieval runs to confirm complementarity before applying RRF fusion.
3. Conduct ablation studies on dense retrieval with and without entity expansion, including analysis of specific query types where expansion might help despite overall neutral results.