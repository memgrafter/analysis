---
ver: rpa2
title: Finding Shared Decodable Concepts and their Negations in the Brain
arxiv_id: '2405.17663'
source_url: https://arxiv.org/abs/2405.17663
tags:
- images
- cluster
- clusters
- figure
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce a novel method to identify functionally localized
  regions of cortex that are shared across participants, which they call Shared Decodable
  Concepts (SDCs). They train a linear decoder to map fMRI responses to CLIP embeddings,
  and then apply a modified DBSCAN algorithm to the decoder weights to identify clusters
  of voxels that share similar semantic tuning.
---

# Finding Shared Decodable Concepts and their Negations in the Brain

## Quick Facts
- arXiv ID: 2405.17663
- Source URL: https://arxiv.org/abs/2405.17663
- Reference count: 30
- Primary result: Novel method to identify shared semantic regions in cortex by clustering averaged decoder weights across participants

## Executive Summary
This paper introduces a method to identify Shared Decodable Concepts (SDCs) in the human brain by mapping fMRI responses to CLIP embeddings and clustering decoder weights across participants. The approach uses a contrastive decoder trained on naturalistic image viewing data, averages the learned weights across multiple training runs, and applies a modified DBSCAN algorithm to identify clusters of voxels that represent shared semantic concepts. Examining both positively and negatively associated images for each cluster provides insight into the functional properties of these regions. The method successfully recovers previously known functional areas and identifies new ones, demonstrating the potential for data-driven discovery of visuo-semantic categories in the brain.

## Method Summary
The method involves training a linear decoder with contrastive loss to map fMRI voxel responses to CLIP embeddings for each participant, then averaging the decoder weights across 50 training runs to reduce noise. A modified DBSCAN clustering algorithm is applied to the averaged weights, requiring core points to have neighbors from at least 3 other participants to ensure shared concepts. Clusters are identified at different ε values (0.5-0.65), and representative images are retrieved by computing cosine distance between brain-decoded CLIP embeddings and cluster centroids. The approach is applied to the Natural Scenes Dataset (NSD) with 8 participants viewing 30,000 images.

## Key Results
- Successfully recovers known functional areas (FFA, PPA, EBA) and identifies new ones (numerosity in IPS, close vs far visual perspective)
- Modified DBSCAN with cross-participant criterion identifies clusters representing shared semantic concepts
- Examining negative representative images provides strong evidence for functional properties (e.g., color vs grayscale for food-related area)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive loss on brain-predicted vs CLIP embeddings drives the decoder to align fMRI voxels with semantic dimensions of CLIP space.
- Mechanism: InfoNCE loss minimizes distance between matching brain-decoded CLIP vectors and true CLIP vectors while pushing non-matching pairs apart, forcing the decoder to capture semantically meaningful features.
- Core assumption: The CLIP embedding space contains dimensions that map meaningfully to visual features represented in human visual cortex.
- Evidence anchors:
  - [abstract] "we train a highly accurate contrastive model that maps brain responses during naturalistic image viewing to CLIP embeddings."
  - [section 2.4] "Contrast(A, B) = − 1 M MX i=1 log( exp(ai · bi/τ )PM j=1 exp(ai · bj/τ ))"
  - [corpus] Weak - no direct evidence in corpus; assumption relies on CLIP's pretraining setup.
- Break condition: If CLIP embeddings do not align with human visual semantics, the decoder cannot learn meaningful mappings.

### Mechanism 2
- Claim: Averaging decoder weights across multiple training runs reduces voxel noise and improves cluster coherence.
- Mechanism: Random initialization introduces variability in the specific weights learned; averaging these weight vectors for each voxel smooths out noise and stabilizes the representation of the underlying decodable concept.
- Core assumption: The voxel's true representational direction is consistent across training runs despite random initialization.
- Evidence anchors:
  - [section 3.1] "we re-trained the decoder model 50 times for every participant and compute the average of the resulting parameter vectors."
  - [corpus] No direct evidence in corpus; inference based on methodology description.
- Break condition: If voxel representations are highly unstable or multimodal across runs, averaging may blur distinct functional properties.

### Mechanism 3
- Claim: Modified DBSCAN with cross-participant core point criterion identifies clusters of voxels that represent shared semantic concepts across brains.
- Mechanism: By redefining core points to require neighbors from multiple participants, the algorithm ensures that only voxels encoding concepts consistently represented across subjects are clustered, revealing Shared Decodable Concepts (SDCs).
- Core assumption: Semantic tuning of voxels is sufficiently consistent across participants to allow identification of shared concepts.
- Evidence anchors:
  - [abstract] "we use a novel adaptation of the DBSCAN clustering algorithm to cluster the parameters of these participant-specific contrastive models."
  - [section 3.1] "a point w(k) i is a core point if there are points from at least minNeighbors other participants within its ε neighborhood."
  - [corpus] Weak - corpus does not discuss DBSCAN adaptations; assumption relies on method description.
- Break condition: If semantic tuning varies too much between individuals, cross-participant clusters will not form or will be unreliable.

## Foundational Learning

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: Understanding how the decoder is trained to align brain responses with CLIP embeddings is crucial to interpreting the results.
  - Quick check question: What is the purpose of the temperature parameter τ in the InfoNCE loss?

- Concept: fMRI preprocessing and voxel selection
  - Why needed here: Knowing how voxels are selected and normalized helps understand the quality and limitations of the input data to the decoder.
  - Quick check question: Why is it important to recalculate noise ceiling estimates using only training data?

- Concept: DBSCAN clustering algorithm
  - Why needed here: The modified DBSCAN is central to identifying Shared Decodable Concepts; understanding its mechanics is essential for interpreting cluster results.
  - Quick check question: How does the modified DBSCAN differ from standard DBSCAN in this application?

## Architecture Onboarding

- Component map: fMRI data → voxel selection → decoder (contrastive loss) → averaged decoder weights → modified DBSCAN → SDCs → representative images/words
- Critical path: Voxel selection → Decoder training → Weight averaging → Clustering → Interpretation
- Design tradeoffs: Using CLIP embeddings provides rich semantic representations but may introduce biases; averaging weights reduces noise but may smooth out subtle differences; modified DBSCAN ensures shared concepts but may miss individual-specific representations.
- Failure signatures: Poor top-k accuracy indicates decoder not capturing CLIP space; disconnected or small clusters suggest noise or lack of shared concepts; inconsistent voxel localization across participants indicates alignment issues.
- First 3 experiments:
  1. Verify top-k accuracy on held-out data for each participant to ensure decoder is learning meaningful mappings.
  2. Visualize cluster sizes and voxel counts per participant at different ε values to assess cluster stability.
  3. Compare positive and negative representative images/words for a known functional area (e.g., FFA) to validate interpretability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are there additional, finer-grained visuo-semantic categories in the brain that could be identified with larger, more diverse datasets?
- Basis in paper: [explicit] The authors state "only a few such broad visuo-semantic categories have so far been identified in the human brain" and suggest "we may be able to detect new visuo-semantic categories in the brain or refine existing categories, and that these categories or sub-categories may become more apparent with a data-driven approach that can combine data across multiple participants."
- Why unresolved: The paper uses a dataset of 30,000 images across 8 participants. While this is substantial, the range of visual stimuli and participants is still limited. The authors also note their method may be biased towards over-represented categories in the stimulus set.
- What evidence would resolve it: Applying the method to a much larger and more diverse dataset (e.g. millions of images, thousands of participants) and observing if new categories emerge or existing ones become more refined.

### Open Question 2
- Question: How important are the negatively associated images in defining the functional role of a region compared to positively associated images?
- Basis in paper: [explicit] The authors emphasize that "Examining the images most and least associated with each SDC cluster gives us additional insight into the semantic properties of each SDC" and give the example of the food-related area where negative images being grayscale provided strong evidence it was color-driven.
- Why unresolved: While the authors provide some examples where negative images were informative, they don't systematically compare the utility of positive vs negative images across all their identified clusters.
- What evidence would resolve it: Conducting a controlled study where experts are asked to interpret the functional role of regions based solely on positive images vs based on both positive and negative images, and comparing the accuracy.

### Open Question 3
- Question: Are there modality-specific vs multimodal representations in the brain, and can this method distinguish between them?
- Basis in paper: [inferred] The authors use a multimodal model (CLIP) and note it may introduce biases as "some signal in the brain responses may not be fully captured by the CLIP embeddings." They also suggest applying the method to other modalities beyond vision.
- Why unresolved: The paper focuses on visual stimuli and a multimodal model, but doesn't explore whether the identified representations are specific to vision or generalize across modalities.
- What evidence would resolve it: Applying the method to a dataset with both visual and non-visual stimuli (e.g. auditory or somatosensory) and seeing if the same regions are activated and if the semantic tuning generalizes across modalities.

## Limitations
- CLIP embedding space may not fully align with human visual semantics, potentially limiting decoder performance
- Modified DBSCAN requires sufficient cross-participant consistency, potentially missing individual-specific representations
- Method relies on averaged decoder weights, which may smooth out subtle functional differences between voxels

## Confidence

| Mechanism | Confidence Level |
|-----------|------------------|
| Contrastive loss aligns voxels with CLIP semantics | Medium |
| Averaging decoder weights reduces noise | Low |
| Modified DBSCAN identifies shared concepts | Medium |

## Next Checks

1. Test whether decoder performance degrades when using CLIP embeddings from a model trained on different data or with different architecture
2. Measure voxel representation stability by computing pairwise correlations of decoder weights across the 50 training runs for each participant
3. Apply the method to a subset of participants with the most similar functional anatomy to quantify the impact of individual variability on SDC identification