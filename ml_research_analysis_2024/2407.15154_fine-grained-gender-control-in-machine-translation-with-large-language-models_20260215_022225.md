---
ver: rpa2
title: Fine-grained Gender Control in Machine Translation with Large Language Models
arxiv_id: '2407.15154'
source_url: https://arxiv.org/abs/2407.15154
tags:
- gender
- translation
- entities
- llms
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of gender ambiguity in machine
  translation, where the gender of entities in the source text is not explicitly specified.
  The authors propose a novel approach called Gender-of-Entity (GoE) prompting for
  Large Language Models (LLMs) to control gender inflections in translations.
---

# Fine-grained Gender Control in Machine Translation with Large Language Models

## Quick Facts
- arXiv ID: 2407.15154
- Source URL: https://arxiv.org/abs/2407.15154
- Reference count: 16
- Primary result: LLMs with Gender-of-Entity prompting achieve up to 95.4% gender accuracy in controlled translation

## Executive Summary
This paper addresses the challenge of gender ambiguity in machine translation, where the gender of entities in source text is not explicitly specified. The authors propose a novel Gender-of-Entity (GoE) prompting method for Large Language Models that provides entity-level gender information in natural language to control gender inflections in translations. Through extensive experiments on four benchmark datasets, the method achieves state-of-the-art performance with up to 95.4% gender accuracy. The paper also identifies a "gender interference" phenomenon when controlling multiple entities with different genders and proposes leveraging LLMs as reference-free gender evaluators.

## Method Summary
The authors propose a Gender-of-Entity (GoE) prompting method that instructs LLMs with fine-grained entity-level gender information to produce translations with correct gender inflections. The approach involves specifying entity-gender mappings in natural language within the prompt, leveraging the LLM's instruction-following capability. The method is evaluated using both traditional coverage-based metrics and a novel LLM-based gender evaluator (LGE) that checks gender inflections without requiring reference translations.

## Key Results
- GoE prompting achieves up to 95.4% gender accuracy across benchmark datasets
- Gender interference phenomenon observed when controlling multiple entities with different genders
- LGE evaluator shows high correlation with human judgments (95.6 F1-score in sanity check)
- State-of-the-art performance compared to NLLB-200 models, gender prefixing, and fine-tuning approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GoE prompting improves gender accuracy by explicitly instructing LLMs to translate entities with specified gender inflections
- Core assumption: LLMs can reliably follow gender-specific instructions when given in natural language format
- Evidence anchors: Abstract states method "instructs the model with fine-grained entity-level gender information to translate with correct gender inflections" and section 3.1 shows high accuracy on both Llama 2 and ChatGPT models

### Mechanism 2
- Claim: Gender interference occurs when controlling multiple entities with different genders, causing accuracy degradation for female entities
- Core assumption: There is a trade-off in the LLM's ability to control gender inflections when multiple entities are present with different gender requirements
- Evidence anchors: Abstract identifies "emergence of gender interference phenomenon when controlling the gender of multiple entities" and section 3.2 shows lower accuracy for female entities in mixed-gender scenarios

### Mechanism 3
- Claim: LLMs can function as reference-free gender evaluators, overcoming limitations of coverage-based metrics
- Core assumption: LLMs can accurately judge gender inflection correctness based on entity-gender mappings provided in natural language
- Evidence anchors: Abstract proposes "leveraging LLMs as a reference-free evaluator that checks the gender inflections and agreements of the translation" and section 4 shows high correlation with human judgements

## Foundational Learning

- Concept: Gender inflection in morphologically rich languages
  - Why needed here: Understanding how languages like Spanish, French, and Italian mark gender on nouns, adjectives, and articles is crucial for evaluating translation accuracy
  - Quick check question: What are the gendered forms of "professor" in Spanish, French, and Italian?

- Concept: Instruction following in LLMs
  - Why needed here: The GoE prompting method relies on the LLM's ability to understand and execute natural language instructions about gender control
  - Quick check question: How does an LLM distinguish between different instruction formats when multiple tasks are specified?

- Concept: Coreference resolution
  - Why needed here: For unambiguous entities whose gender must be inferred from context, understanding coreference is essential for correct translation
  - Quick check question: In "When the student arrived, she greeted the professor politely," how can we determine the gender of "student"?

## Architecture Onboarding

- Component map: Source text input -> Entity-gender mapping specification (GoE prompt) -> LLM translation model (Llama 2 70B Chat or ChatGPT 3.5) -> Post-processing to extract translation from LLM output -> Evaluation metrics (coverage-based and LGE)

- Critical path: 1) Parse source text and identify entities, 2) Generate GoE prompt with entity-gender mappings, 3) Send prompt to LLM and receive translation, 4) Post-process LLM output to extract translation, 5) Evaluate using appropriate gender accuracy metric

- Design tradeoffs: Zero-shot prompting vs. fine-tuning (GoE uses zero-shot instruction following, avoiding training data requirements but potentially less precise than fine-tuned models), Reference-based vs. reference-free evaluation (LGE enables evaluation without gender term coverage but may be less precise than term-based metrics), Entity specification granularity (Detailed entity-gender mappings improve accuracy but increase prompt complexity)

- Failure signatures: Low gender accuracy despite correct GoE prompts (Indicates LLM instruction-following failure), High variance in translation quality (Suggests LLM output instability or inconsistent prompt interpretation), LGE evaluations that disagree strongly with human judgments (Indicates evaluator reliability issues)

- First 3 experiments: 1) Test GoE prompting on single entity gender control using MuST-SHE benchmark, 2) Evaluate gender interference by comparing uniform vs. mixed gender assignments on GATE dataset, 3) Compare LGE evaluator performance against coverage-based metrics on MT-GenEval dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the gender interference phenomenon be mitigated when controlling multiple entities with different genders?
- Basis in paper: The paper identifies a "gender interference" phenomenon where controlling the gender of one entity can negatively impact the gender inflection of other entities in the sentence, particularly when entities have non-uniform gender assignments.
- Why unresolved: While the paper identifies this phenomenon, it does not propose any solutions or mitigation strategies to address it. The authors only observe the effect and quantify its impact on accuracy.
- What evidence would resolve it: Experiments testing various prompt engineering techniques, architectural modifications, or fine-tuning strategies to reduce gender interference would provide insights into potential solutions.

### Open Question 2
- Question: Can the proposed LLM-based gender evaluation method be extended to handle non-binary or gender-neutral entities?
- Basis in paper: The paper acknowledges that existing datasets are framed within a binary setting and that the proposed evaluation method is limited to binary gender. However, the authors suggest that given the availability of relevant datasets, their methodology could potentially be applicable to non-binary genders.
- Why unresolved: The paper does not explore or test the extension of the LLM-based evaluation method to handle non-binary or gender-neutral entities. This would require additional datasets and experiments.
- What evidence would resolve it: Experiments using datasets with non-binary or gender-neutral entities and testing the LLM-based evaluation method on these datasets would demonstrate the feasibility of extending the approach.

### Open Question 3
- Question: How does the performance of the proposed LLM-based controlled translation method compare to other languages and language families beyond the Romance languages tested?
- Basis in paper: The paper evaluates the proposed method on three Romance languages (Spanish, French, and Italian) and acknowledges that further investigation is required on low-resource languages and other languages not covered by their study.
- Why unresolved: The paper does not provide any results or analysis for languages beyond the Romance language family, leaving the generalizability of the approach to other languages unexplored.
- What evidence would resolve it: Experiments testing the proposed method on a diverse set of languages from different language families, including low-resource languages, would provide insights into its cross-lingual applicability and limitations.

## Limitations
- Dataset scope limitation: Evaluation primarily on English-to-Spanish/French/Italian translation tasks, generalizability to other language pairs untested
- LLM dependency: Method effectiveness tightly coupled to specific LLMs (Llama 2 70B and ChatGPT 3.5), performance on other architectures unknown
- Gender interference phenomenon: Causes not thoroughly investigated, lack of theoretical grounding for why mixed-gender scenarios are more difficult

## Confidence

**High confidence**: The core claim that GoE prompting can improve gender accuracy in machine translation for single entities is well-supported by experimental results across multiple datasets and model types.

**Medium confidence**: The gender interference phenomenon and the comparative effectiveness of LGE versus coverage-based metrics are supported by experimental data but lack theoretical explanation and broader validation.

**Low confidence**: Claims about the method's generalizability to different language pairs, model architectures, and translation scenarios are not sufficiently supported by the current experimental scope.

## Next Checks

**Check 1**: Validate gender interference across different LLM architectures by testing GoE prompting on GPT-4, Claude, and smaller Llama models (13B, 34B) to determine if the phenomenon is model-specific or inherent to the prompting approach.

**Check 2**: Conduct a comprehensive sensitivity analysis of the GoE prompt template by systematically varying entity specification formats, instruction wording, and prompt structure to identify optimal configurations and failure modes.

**Check 3**: Expand LGE evaluation validation by creating a diverse test set of translations with known gender accuracy issues, including edge cases like ambiguous antecedents, cultural gender norms, and complex agreement patterns, then compare LGE judgments against multiple human annotators to establish reliability thresholds.