---
ver: rpa2
title: 'FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large
  Language Models'
arxiv_id: '2411.00985'
source_url: https://arxiv.org/abs/2411.00985
tags:
- prompt
- federated
- optimization
- learning
- tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedDTPT, the first federated learning framework
  for discrete and transferable prompt tuning of black-box large language models.
  The method uses a token-level discrete prompt optimization with a feedback loop
  based on prediction accuracy and a server-side attention mechanism grounded in semantic
  similarity to aggregate local prompts.
---

# FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models

## Quick Facts
- arXiv ID: 2411.00985
- Source URL: https://arxiv.org/abs/2411.00985
- Reference count: 6
- Primary result: Achieves 95.33% average accuracy on DeepSeek-V2-Lite, outperforming black-box baselines

## Executive Summary
This paper introduces FedDTPT, the first federated learning framework for discrete and transferable prompt tuning of black-box large language models. The method combines token-level discrete prompt optimization with a feedback loop based on prediction accuracy and a server-side attention mechanism grounded in semantic similarity to aggregate local prompts. Experiments demonstrate superior accuracy, reduced communication overhead, and robustness to non-iid data compared to state-of-the-art methods, with optimized prompts showing transferability across different LLMs.

## Method Summary
FedDTPT employs a federated learning approach where clients optimize discrete prompts through a token-level feedback loop using MLM API predictions and accuracy results. The server aggregates these prompts using an attention mechanism based on semantic similarity between token embeddings, enhanced by DBSCAN clustering and elbow detection. This enables gradient-free prompt optimization in black-box settings while maintaining privacy through local data processing and achieving transferability of learned prompts across different LLM architectures.

## Key Results
- Achieves 95.33% average accuracy on DeepSeek-V2-Lite, significantly outperforming black-box baselines
- Demonstrates reduced communication overhead compared to continuous prompt tuning methods
- Shows robustness to non-iid data distributions across clients
- Optimized prompts are transferable across different LLM architectures

## Why This Works (Mechanism)

### Mechanism 1
Token-level discrete prompt optimization with prediction accuracy feedback enables effective gradient-free learning in black-box LLM settings. Each client iteratively tunes discrete tokens using MLM API predictions, feeding back accuracy results to guide subsequent token modifications. This creates a closed loop between forward inference and result-based optimization.

### Mechanism 2
Semantic similarity-based attention mechanism enables effective aggregation of discrete tokens across clients in federated learning. Server maps all client tokens to high-dimensional embeddings, computes cosine similarity between tokens, and uses attention weights based on semantic similarity to select representative tokens for global prompt construction.

### Mechanism 3
Clustering strategy with DBSCAN and elbow detection enables adaptive selection of representative tokens from high-dimensional embedding space. Server calculates distances between token embeddings, identifies elbow points to determine DBSCAN parameters, and clusters tokens based on density connectivity to select representatives from each cluster.

## Foundational Learning

- Concept: Federated Learning fundamentals
  - Why needed here: The entire framework operates within a federated learning paradigm where multiple clients collaborate without sharing raw data
  - Quick check question: What is the primary privacy benefit of federated learning compared to centralized training?

- Concept: Masked Language Model (MLM) API usage
  - Why needed here: The client optimization relies on MLM API to perform gradient-free token modifications through masked token prediction
  - Quick check question: How does an MLM API differ from a standard LLM inference API in terms of output format?

- Concept: Cosine similarity and high-dimensional embeddings
  - Why needed here: The server-side aggregation uses cosine similarity between high-dimensional token embeddings to compute attention weights
  - Quick check question: What geometric property of cosine similarity makes it suitable for comparing semantic embeddings?

## Architecture Onboarding

- Component map: Client side: Global prompt receiver, MLM API interface, LLM inference API, accuracy calculator, feedback loop manager; Server side: Token embedding mapper, cosine similarity calculator, attention weight generator, DBSCAN clustering engine, global prompt assembler; Communication layer: Global prompt broadcast, local prompt upload, global prompt distribution

- Critical path: Client optimization → Local prompt upload → Server aggregation → Global prompt generation → Global prompt broadcast

- Design tradeoffs:
  - Token-level vs. sequence-level optimization: Token-level provides granularity but increases complexity
  - Fixed vs. adaptive clustering: Adaptive clustering handles diverse prompts better but requires more computation
  - Public dataset usage: Improves accuracy calculation stability but introduces additional communication overhead

- Failure signatures:
  - Poor accuracy improvement across iterations: Indicates feedback loop not providing effective optimization signals
  - High variance in client prompts: Suggests insufficient semantic similarity in attention mechanism
  - Cluster quality degradation: Indicates embedding space not capturing meaningful semantic relationships

- First 3 experiments:
  1. Single client optimization test: Verify MLM-based token optimization works before adding federated complexity
  2. Two-client semantic aggregation test: Validate attention mechanism with minimal client count
  3. Clustering sensitivity test: Evaluate how DBSCAN parameters affect representative token selection quality

## Open Questions the Paper Calls Out

### Open Question 1
How does the FedDTPT framework perform when applied to other federated learning scenarios beyond NLP tasks, such as computer vision or multi-modal tasks? The paper focuses on NLP tasks using the GLUE benchmark and suggests the potential for broader applications of the FedDTPT framework.

### Open Question 2
How does the FedDTPT framework handle scenarios where the local data distributions across clients are highly skewed or contain outliers? The paper mentions that FedDTPT is robust to non-iid data, but does not provide detailed analysis on handling extreme data skewness or outliers.

### Open Question 3
What are the implications of using different clustering strategies, such as hierarchical clustering or spectral clustering, in the server-side aggregation phase of FedDTPT? The paper uses DBSCAN clustering for server-side aggregation but does not explore the impact of alternative clustering methods.

## Limitations
- Feedback loop mechanism for token optimization lacks detailed technical specifications
- Transferability claims across different LLMs are demonstrated on a single model without comprehensive evaluation
- Missing ablation studies isolating the contribution of each component to overall performance

## Confidence
- High Confidence: Core federated learning architecture and accuracy metrics are well-established
- Medium Confidence: Semantic similarity-based attention mechanism and DBSCAN clustering approach are conceptually sound but lack implementation details
- Low Confidence: Transferability of optimized prompts across different LLM architectures is demonstrated on limited scope

## Next Checks
1. Component Isolation Test: Implement and evaluate each component (feedback loop optimization, semantic attention aggregation, DBSCAN clustering) in isolation to determine their individual contributions to performance gains.

2. Cross-Model Transferability Study: Systematically test prompt transferability across multiple LLM architectures with varying parameter counts and training objectives.

3. Non-IID Robustness Analysis: Design controlled experiments with varying degrees of data heterogeneity among clients using Dirichlet distribution to quantify the method's robustness to different non-iid scenarios.