---
ver: rpa2
title: Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation
  in a Limited Data Setting
arxiv_id: '2411.03098'
source_url: https://arxiv.org/abs/2411.03098
tags:
- data
- image
- dataset
- images
- capsule
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of limited data in capsule endoscopy
  lesion classification by proposing two local lesion generation methods for data
  augmentation. The first method uses Poisson Image Editing to blend real lesions
  into healthy tissue, while the second introduces a novel Image Inpainting GAN fine-tuned
  on small datasets to synthesize realistic lesions within masked regions of real
  images.
---

# Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting

## Quick Facts
- arXiv ID: 2411.03098
- Source URL: https://arxiv.org/abs/2411.03098
- Reference count: 40
- Achieves 33.07% macro F1-score on Kvasir Capsule Dataset, a 7.84 percentage point improvement over previous best

## Executive Summary
This paper addresses the challenge of limited labeled data in capsule endoscopy by proposing two local lesion generation methods for data augmentation. The first method uses Poisson Image Editing to blend real lesions into healthy tissue, while the second introduces a novel Image Inpainting GAN fine-tuned on small datasets to synthesize realistic lesions within masked regions. Both approaches exploit the abundance of healthy tissue images in medical datasets. When combined, they achieve a new state-of-the-art macro F1-score of 33.07% on the highly imbalanced Kvasir Capsule Dataset.

## Method Summary
The approach combines two complementary data augmentation techniques. Poisson Blending Data Augmentation (PBDA) uses Poisson Image Editing to seamlessly blend lesions from source images into healthy target images, with deduplication to avoid similar image pairs and optimal blending location selection. Image Inpainting Data Augmentation (IIDA) fine-tunes a pre-trained LaMa model using a modified loss function (including L1 reconstruction loss) to generate realistic lesions within masked regions of healthy tissue images. The methods are applied to the Kvasir Capsule Dataset, which contains 47,238 labeled images across 7 pathology classes with severe class imbalance.

## Key Results
- Achieves 33.07% macro F1-score on Kvasir Capsule Dataset, surpassing previous state-of-the-art by 7.84 percentage points
- Optimal performance achieved with 2k augmented dataset containing 20% PBDA and 80% IIDA samples
- Combines classical image processing (PBDA) with generative models (IIDA) for complementary augmentation diversity

## Why This Works (Mechanism)

### Mechanism 1
Local lesion generation exploits abundant healthy tissue images to produce realistic synthetic lesions without requiring large pathology datasets. PBDA and IIDA modify only small regions of real healthy images, preserving overall tissue context while introducing pathology diversity. This works because healthy tissue images are plentiful in medical datasets and can serve as valid backgrounds for synthetic lesion placement.

### Mechanism 2
Fine-tuning an image inpainting GAN on limited medical data can generate high-quality lesions without overfitting. IIDA adapts a pre-trained LaMa model using modified loss functions that include L1 reconstruction loss to prevent the model from deviating from its pre-trained knowledge while generating lesions. This works because pre-trained generative models can be effectively fine-tuned on small medical datasets without catastrophic forgetting.

### Mechanism 3
Combining classical image processing (PBDA) with generative models (IIDA) creates more diverse synthetic data than either method alone. PBDA relocates existing lesions to new backgrounds while IIDA generates novel lesion shapes and textures conditioned on the background, creating complementary augmentation strategies that reduce overfitting. This works because different augmentation approaches introduce orthogonal forms of diversity that improve model generalization.

## Foundational Learning

- Concept: Poisson Image Editing (Poisson Blending)
  - Why needed here: PBDA relies on Poisson Blending to seamlessly merge lesions into healthy tissue while preserving gradient information and minimizing color discrepancies at boundaries.
  - Quick check question: How does Poisson Blending minimize color discrepancies when merging a lesion from a source image into a target image?

- Concept: Image Inpainting with Conditional GANs
  - Why needed here: IIDA uses a conditional GAN (LaMa) that generates realistic lesions within masked regions of healthy tissue images, requiring understanding of how conditional generation works.
  - Quick check question: What is the difference between unconditional and conditional image generation in the context of medical image augmentation?

- Concept: Class Imbalance Handling in Medical Datasets
  - Why needed here: The Kvasir Capsule Dataset is highly imbalanced, making it essential to understand sampling strategies and their impact on model performance.
  - Quick check question: Why might random oversampling or undersampling be insufficient for handling severe class imbalance in medical imaging datasets?

## Architecture Onboarding

- Component map: Healthy image → Deduplication → Feature extraction (DinoV2) → Pair selection (for PBDA) or Mask placement (for IIDA) → Lesion generation/blending → Classification training → Evaluation
- Critical path: Healthy image → Deduplication → Feature extraction (DinoV2) → Pair selection (for PBDA) or Mask placement (for IIDA) → Lesion generation/blending → Classification training → Evaluation
- Design tradeoffs: PBDA requires bounding boxes but doesn't need model training, making it more general but less flexible; IIDA requires fine-tuning but can generate novel lesion shapes and textures, making it more powerful but data-dependent.
- Failure signatures: Poor synthetic lesion quality (visible artifacts, unrealistic colors), classifier overfitting to synthetic data, or no performance improvement over baseline indicate problems with the augmentation pipeline.
- First 3 experiments:
  1. Test PBDA on a small subset of healthy-normal image pairs to verify seamless blending quality and identify failure cases.
  2. Fine-tune the LaMa model on a single lesion class with limited samples to validate that it can generate realistic lesions without overfitting.
  3. Compare classifier performance with and without augmentation using PBDA only, then IIDA only, then their combination to establish baseline improvements.

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal proportion of PBDA to IIDA-generated samples for maximizing classification performance across different medical imaging tasks and architectures? While the paper found 20:80 optimal for Kvasir Capsule Dataset and CAFormer, this ratio may vary across datasets, lesion types, and model architectures.

### Open Question 2
How do PBDA and IIDA methods perform on irregular mask shapes compared to rectangular bounding boxes, and what impact does this have on lesion generation quality and downstream classification performance? The Kvasir Capsule Dataset only provided rectangular bounding boxes, while real lesions often have irregular shapes.

### Open Question 3
What is the minimum amount of training data required for IIDA to generate high-quality lesions across different pathology classes, and how does this vary with lesion complexity and intra-class variability? The paper shows data requirements vary significantly between classes but lacks systematic analysis of determining factors.

## Limitations
- Results are validated only on a single dataset (Kvasir Capsule Dataset), limiting generalizability to other medical imaging domains
- IIDA requires careful fine-tuning to avoid overfitting, with quality dependent on pre-trained model adaptation to medical domain
- The methods rely on specific dataset characteristics (abundant healthy tissue images) that may not be available in all medical imaging contexts

## Confidence

- **High Confidence**: The claim that local lesion generation improves classification performance in limited data settings is well-supported by the 7.84 percentage point improvement over baseline and multiple experimental validations.
- **Medium Confidence**: The assertion that combining PBDA and IIDA produces complementary diversity is supported by results but lacks detailed ablation studies showing individual contributions.
- **Medium Confidence**: The effectiveness of fine-tuning LaMa for medical lesion generation is demonstrated but could benefit from comparison with alternative fine-tuning strategies or other generative models.

## Next Checks

1. **Cross-dataset validation**: Test the augmentation methods on a different capsule endoscopy dataset or other medical imaging modality to assess generalizability beyond the Kvasir Capsule Dataset.

2. **Ablation study on healthy image quantity**: Systematically vary the number of healthy tissue images used in augmentation to determine the minimum requirement for effective PBDA and IIDA performance.

3. **Quality assessment of synthetic lesions**: Conduct expert evaluation of generated lesions to verify they are clinically realistic and don't introduce artifacts that could mislead the classifier.