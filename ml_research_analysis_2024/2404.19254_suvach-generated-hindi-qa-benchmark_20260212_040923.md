---
ver: rpa2
title: Suvach -- Generated Hindi QA benchmark
arxiv_id: '2404.19254'
source_url: https://arxiv.org/abs/2404.19254
tags:
- question
- benchmark
- hindi
- arxiv
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Suvach, a new Hindi question-answering (QA)
  benchmark generated using large language models (LLMs). The work addresses the problem
  of limited evaluation resources for Indic languages, where existing benchmarks often
  rely on machine-translated English data, introducing bias and inaccuracies.
---

# Suvach -- Generated Hindi QA benchmark

## Quick Facts
- arXiv ID: 2404.19254
- Source URL: https://arxiv.org/abs/2404.19254
- Reference count: 14
- Primary result: New Hindi QA benchmark with over 100k pairs generated using LLMs

## Executive Summary
This paper introduces Suvach, a Hindi question-answering benchmark generated using large language models. The work addresses the scarcity of high-quality evaluation resources for Indic languages, where existing benchmarks often rely on machine-translated English data, introducing bias and inaccuracies. To overcome this, the authors propose a methodology that uses LLMs to generate QA data directly in Hindi, ensuring linguistic and cultural relevance.

## Method Summary
The authors employ a systematic approach using LLMs to generate Hindi QA data from Wikipedia text. The workflow involves creating prompts from Wikipedia passages, generating questions and answers using Gemini 1.0 Pro, and validating the outputs through LLM-based checks. This methodology aims to create a scalable and reliable way to produce high-quality benchmarks for low-resource languages without the need for extensive human annotation.

## Key Results
- Generated over 100k Hindi QA pairs with an average of 1200 tokens per question
- Demonstrated a scalable approach to creating Hindi-specific benchmarks using LLMs
- Achieved linguistic and cultural relevance through direct Hindi generation rather than translation

## Why This Works (Mechanism)
The methodology works by leveraging the generative capabilities of LLMs to create contextually appropriate questions and answers directly in Hindi. By using Wikipedia as source material, the approach ensures factual grounding while the LLM-based validation helps maintain quality standards. The direct generation approach avoids the linguistic artifacts and cultural inaccuracies that typically arise from machine-translated benchmarks.

## Foundational Learning

**Hindi NLP requirements**: Understanding of Indic language processing challenges and the need for language-specific resources. Why needed: Hindi has unique linguistic features that generic multilingual models may not capture well. Quick check: Review existing Hindi NLP literature to identify specific challenges.

**LLM-based data generation**: Knowledge of how to construct effective prompts for generating high-quality QA pairs. Why needed: The quality of generated data heavily depends on prompt engineering. Quick check: Test different prompt structures on a small dataset to evaluate output quality.

**Cultural context awareness**: Understanding of Indian cultural references and linguistic nuances. Why needed: Ensures generated content is culturally appropriate and relevant. Quick check: Validate sample outputs with native Hindi speakers.

## Architecture Onboarding

**Component map**: Wikipedia text -> Prompt generation -> LLM (Gemini 1.0 Pro) -> Question-Answer generation -> LLM validation -> QA dataset

**Critical path**: The validation step is critical as it determines which generated QA pairs make it into the final dataset. Without effective validation, the dataset quality could be compromised.

**Design tradeoffs**: The paper trades human annotation costs for LLM-based validation, which may introduce systematic biases but enables scalability. The choice of Gemini 1.0 Pro provides good generation quality but limits reproducibility.

**Failure signatures**: Poor quality outputs would manifest as factually incorrect answers, grammatically incorrect Hindi, or culturally inappropriate content. The LLM validation should catch most of these, but may miss subtle errors.

**3 first experiments**: 
1. Generate a small test set (100-500 QA pairs) and perform human evaluation
2. Compare output quality across different LLMs (GPT-4, Claude, etc.)
3. Test the dataset with baseline Hindi QA models to establish performance metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on LLM-based validation without human verification introduces uncertainty about actual quality
- Limited reproducibility due to specific choice of Gemini 1.0 Pro as the generation model
- Potential for systematic biases and errors to propagate through the validation pipeline

## Confidence
- **High confidence**: The need for Hindi-specific QA benchmarks (well-established problem)
- **Medium confidence**: The methodology's ability to generate high-quality Hindi QA data (validation is LLM-based)
- **Low confidence**: The claim of "over 100k" QA pairs meeting quality standards (no human validation reported)

## Next Checks
1. Conduct human evaluation on a random sample of 200-500 QA pairs to verify accuracy, fluency, and cultural relevance claims
2. Test dataset quality by training and evaluating multiple Hindi QA models to establish baseline performance metrics
3. Perform bias analysis to identify potential systematic errors or cultural misrepresentations in the generated content