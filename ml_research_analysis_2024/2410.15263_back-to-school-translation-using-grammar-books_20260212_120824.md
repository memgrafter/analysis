---
ver: rpa2
title: 'Back to School: Translation Using Grammar Books'
arxiv_id: '2410.15263'
source_url: https://arxiv.org/abs/2410.15263
tags:
- languages
- translation
- grammar
- sentences
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that incorporating linguistic reference
  materials such as bilingual dictionaries and full-length grammar books into the
  prompts of large language models can improve machine translation performance for
  low-resource languages. Experiments on 16 typologically diverse languages show that
  adding words, parallel sentences, and grammar books to prompts leads to statistically
  significant improvements in translation quality, with grammar books being especially
  beneficial for extremely low-resource languages with fewer than 1,000 parallel sentences.
---

# Back to School: Translation Using Grammar Books

## Quick Facts
- arXiv ID: 2410.15263
- Source URL: https://arxiv.org/abs/2410.15263
- Authors: Jonathan Hus; Antonios Anastasopoulos
- Reference count: 25
- One-line primary result: Incorporating linguistic reference materials like bilingual dictionaries and grammar books into LLM prompts improves MT performance for low-resource languages

## Executive Summary
This paper demonstrates that incorporating linguistic reference materials such as bilingual dictionaries and full-length grammar books into the prompts of large language models can improve machine translation performance for low-resource languages. Experiments on 16 typologically diverse languages show that adding words, parallel sentences, and grammar books to prompts leads to statistically significant improvements in translation quality, with grammar books being especially beneficial for extremely low-resource languages with fewer than 1,000 parallel sentences. The approach outperforms zero-shot translation baselines and in some cases approaches the performance of specialized translation models, suggesting a scalable path for improving MT for the world's underrepresented languages.

## Method Summary
The approach uses GPT-4-turbo with 128K context length to incorporate linguistic reference materials into translation prompts following the MTOB framework. Reference materials include bilingual dictionaries from PanLex, grammar books from the DReaM corpus, and parallel sentences from the FLORES-200 dataset. The method tests four prompt variations: baseline (no reference material), words only (dictionary entries), words+sentences (dictionary + parallel examples), and words+sentences+grammar book (full grammar book inclusion). Translation quality is evaluated using chrF++ and BLEU scores on the FLORES-200 devtest set, with paired bootstrap resampling for significance testing.

## Key Results
- Incorporating grammar books into prompts provides statistically significant improvements over zero-shot baselines for extremely low-resource languages (<1,000 parallel sentences)
- Grammar books are especially effective when parallel sentence availability is below 1,000 sentences
- The approach achieves translation quality approaching specialized NLLB models in some cases
- Different combinations of reference materials (words, sentences, grammar books) show varying effectiveness across the 16 typologically diverse languages tested

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating grammar books into LLM prompts improves MT for extremely low-resource languages by providing explicit linguistic structure.
- Mechanism: Grammar books supply detailed morphological and syntactic rules that guide the LLM in generating structurally correct translations for languages with limited web presence.
- Core assumption: The LLM can effectively integrate and apply grammar book rules during inference without additional fine-tuning.
- Evidence anchors:
  - [abstract]: "incorporating grammar books in the prompt of GPT-4 to improve machine translation"
  - [section 4.1]: "we use the GPT-4-turbo model for our experiments... it has an input context size of 128K"
  - [corpus]: Weak - only indirect mentions of grammar book utility; needs more targeted evidence
- Break condition: If grammar books contain OCR errors or scanning artifacts that confuse the LLM, or if the grammar rules are too complex for in-context learning.

### Mechanism 2
- Claim: Bilingual dictionaries provide essential word-level mappings that bootstrap translation accuracy.
- Mechanism: Dictionaries supply direct translations for individual words, reducing ambiguity in word choice during translation generation.
- Core assumption: The dictionary covers sufficient vocabulary overlap with the test sentences for effective lookup.
- Evidence anchors:
  - [abstract]: "incorporating dictionaries... into the prompts of large language models"
  - [section 4]: "Dictionaries We obtain dictionaries from PanLex3 for all our languages"
  - [corpus]: Moderate - mentions dictionary size variations but not direct impact on performance
- Break condition: If dictionary size is too small (<100 words as noted), or if dictionary entries lack context for polysemous words.

### Mechanism 3
- Claim: Parallel sentence examples provide contextual templates that improve translation fluency.
- Mechanism: Example sentences demonstrate correct usage patterns and phrase structures in the target language.
- Core assumption: Selected examples are relevant and representative of the translation task.
- Evidence anchors:
  - [abstract]: "incorporating... parallel sentences... into the prompts"
  - [section 4]: "For the parallel sentences that are part of the prompts as translation examples, we use the dev portion of the FLORES-200 dataset"
  - [corpus]: Weak - no explicit discussion of example quality or relevance filtering
- Break condition: If parallel sentence coverage is sparse or if examples introduce domain bias.

## Foundational Learning

- Concept: Context window capacity
  - Why needed here: GPT-4-turbo's 128K context allows inclusion of full grammar books (40K-120K tokens)
  - Quick check question: What happens if the grammar book exceeds the context window? (Answer: It must be truncated or summarized)

- Concept: In-context learning
  - Why needed here: The approach relies on LLMs learning translation patterns from examples without fine-tuning
  - Quick check question: Can the LLM generalize from 10-20 example sentences to unseen sentences? (Answer: This is the key assumption being tested)

- Concept: Evaluation metrics (chrF++ and BLEU)
  - Why needed here: These metrics measure translation quality and enable comparison with baseline and NLLB models
  - Quick check question: Why use chrF++ instead of just BLEU? (Answer: chrF++ is more sensitive to character-level accuracy important for morphologically rich languages)

## Architecture Onboarding

- Component map: Dictionary lookup -> Sentence example selection -> Grammar book inclusion -> Prompt assembly -> GPT-4 inference -> chrF++ scoring
- Critical path: Dictionary lookup -> Sentence example selection -> Grammar book inclusion -> Prompt assembly -> GPT-4 inference -> chrF++ scoring
- Design tradeoffs: Full grammar books provide completeness but increase token usage; dictionaries are lightweight but may lack context; parallel sentences help fluency but require careful selection
- Failure signatures: Poor chrF++ scores indicate missing reference material; statistical significance failures suggest random noise rather than systematic improvement
- First 3 experiments:
  1. Baseline zero-shot translation (no reference material)
  2. Words-only prompt (dictionary entries only)
  3. Words + Sentences prompt (dictionary + parallel examples)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of incorporating full-length grammar books compare to using selectively extracted grammar excerpts, and what specific grammatical features or rules provide the most benefit for low-resource language translation?
- Basis in paper: Explicit - The paper discusses using full-length grammar books versus smaller excerpts, and mentions morphological analyzers were used in related work to extract linguistic features.
- Why unresolved: The paper shows grammar books help low-resource languages but doesn't systematically compare different grammar extraction methods or identify which specific grammatical features are most beneficial.
- What evidence would resolve it: Comparative experiments testing full-length books versus different sizes of grammar excerpts, with ablation studies identifying which grammatical rules/features contribute most to translation quality.

### Open Question 2
- Question: What is the optimal combination and quantity of reference materials (dictionaries, parallel sentences, grammar books) needed to achieve near-NLLB-level performance for extremely low-resource languages?
- Basis in paper: Explicit - The paper shows varying effectiveness of different reference material combinations and mentions languages with fewer than 1,000 parallel sentences benefit most from grammar books.
- Why unresolved: The paper tests different combinations but doesn't establish a systematic relationship between reference material quantity and translation quality, nor determine the minimum requirements for NLLB-comparable performance.
- What evidence would resolve it: Systematic scaling experiments varying the quantity of each reference material type, measuring the relationship between resource availability and translation quality to establish minimum requirements.

### Open Question 3
- Question: How do different large language models (GPT-4, Claude, etc.) compare in their ability to utilize linguistic reference materials for low-resource translation, and what model characteristics most influence this capability?
- Basis in paper: Explicit - The paper uses GPT-4-turbo due to its 128K context window but acknowledges this limitation and notes the experiments are expensive.
- Why unresolved: The paper only uses one model and mentions the high cost of experiments, preventing comparison across different LLMs and analysis of which model properties matter most.
- What evidence would resolve it: Comparative experiments across multiple LLMs with different context windows and architectures, measuring their ability to leverage reference materials and identifying key model characteristics that influence performance.

## Limitations

- The paper doesn't control for potential confounds like grammar book length or complexity varying systematically with language difficulty
- Manual preprocessing of grammar books from scanned PDFs introduces unknown quality variations due to OCR errors or inconsistent formatting
- The evaluation uses a single prompt format with fixed positions for different reference materials without exploring optimal ordering or weighting

## Confidence

- **High confidence**: Incorporating any reference materials (words, sentences, or grammar books) improves translation over zero-shot baselines, supported by paired bootstrap significance tests and consistent improvements across 16 languages
- **Medium confidence**: Grammar books are particularly beneficial for extremely low-resource languages (<1,000 parallel sentences), though sample size is limited and mechanism isn't definitively established
- **Low confidence**: The approach approaches specialized translation model performance, as NLLB comparison lacks domain control and model capacity analysis

## Next Checks

1. Conduct ablation studies that systematically vary grammar book complexity and content type (morphological rules vs. syntactic rules vs. usage examples) to determine which components drive the improvements

2. Evaluate the impact of grammar book quality by comparing results using manually cleaned vs. raw OCR versions of the same grammar books, controlling for language and parallel sentence count

3. Test the approach on languages with progressively larger parallel corpora (100 → 1,000 → 10,000 sentences) to quantify the exact threshold where grammar books stop providing marginal benefit