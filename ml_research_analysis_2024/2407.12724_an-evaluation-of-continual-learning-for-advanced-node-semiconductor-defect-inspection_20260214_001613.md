---
ver: rpa2
title: An Evaluation of Continual Learning for Advanced Node Semiconductor Defect
  Inspection
arxiv_id: '2407.12724'
source_url: https://arxiv.org/abs/2407.12724
tags:
- defect
- classes
- training
- trained
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a continual learning approach for semiconductor
  defect inspection to address catastrophic forgetting when new defect classes emerge.
  The method employs a meta-learning-based incremental training strategy using Faster-RCNN
  to progressively add defect classes without losing performance on previously learned
  classes.
---

# An Evaluation of Continual Learning for Advanced Node Semiconductor Defect Inspection

## Quick Facts
- arXiv ID: 2407.12724
- Source URL: https://arxiv.org/abs/2407.12724
- Authors: Amit Prasad; Bappaditya Dey; Victor Blanco; Sandip Halder
- Reference count: 9
- Primary result: Meta-learning-based incremental training strategy using Faster-RCNN successfully adds new defect classes to semiconductor inspection models while maintaining performance on previously learned classes, outperforming conventional fine-tuning approaches.

## Executive Summary
This study addresses catastrophic forgetting in semiconductor defect inspection by introducing a continual learning approach that enables models to add new defect classes without losing performance on previously learned ones. The method employs a meta-learning-based incremental training strategy using Faster-RCNN to progressively add defect classes from both ADI and AEI process steps. Experimental results demonstrate that this approach maintains high average precision across all defect classes while adding new ones, whereas conventional fine-tuning shows significant forgetting of previously learned defect classes.

## Method Summary
The approach uses Faster-RCNN as the backbone architecture for semiconductor defect detection, employing a meta-learning-based incremental training strategy to add new defect classes progressively. The model is initially trained on a subset of defect classes from the ADI dataset, then incrementally adds new classes using the meta-learning strategy while monitoring performance to prevent catastrophic forgetting. The framework is evaluated on real SEM images from ADI and AEI process steps, comparing the incremental learning approach against conventional fine-tuning. The method aims to create a task-agnostic, generalized model for semiconductor defect inspection that can scale to include new defect classes as manufacturing processes evolve.

## Key Results
- Meta-learning-based incremental training successfully adds new defect classes without significant performance degradation on previously learned classes
- The approach maintains high average precision across all defect classes when compared to conventional fine-tuning, which shows catastrophic forgetting
- The framework demonstrates task-agnostic generalization capability across ADI and AEI process steps, enabling robust defect detection in different manufacturing contexts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Meta-learning-based incremental training preserves performance on previously learned defect classes while adding new ones.
- Mechanism: The approach trains on a subset of defect classes, then incrementally adds new classes using a meta-learning strategy that adapts the model to new tasks while retaining knowledge of earlier classes.
- Core assumption: The meta-learning strategy effectively mitigates catastrophic forgetting through parameter updates that balance new learning with preservation of prior knowledge.
- Evidence anchors:
  - [abstract] "The method employs a meta-learning-based incremental training strategy using Faster-RCNN to progressively add defect classes without losing performance on previously learned classes."
  - [section] "The model starts training with the task T2 (initially trained for 2 defect classes, microbridge and gap), followed by two consecutive incremental training tasks: T2 and finally T1, using the ADI dataset."
- Break condition: If the meta-learning update rules do not sufficiently constrain weight changes, the model may overwrite parameters critical for previous classes, leading to catastrophic forgetting.

### Mechanism 2
- Claim: Faster-RCNN architecture supports incremental learning by allowing region proposal networks to adapt to new defect patterns without full retraining.
- Mechanism: The region proposal network (RPN) in Faster-RCNN can be fine-tuned on new defect classes while the backbone features remain largely unchanged, enabling efficient incremental updates.
- Core assumption: The RPN and detection heads can learn new defect patterns based on the shared feature maps without requiring complete architectural changes.
- Evidence anchors:
  - [abstract] "The method employs a meta-learning-based incremental training strategy using Faster-RCNN to progressively add defect classes without losing performance on previously learned classes."
  - [section] "We use the Faster-RCNN [6] model for all studies. Moreover, for incremental tasks, the approach utilized is presented in [4] which also uses FRCNN."
- Break condition: If the new defect classes are significantly different in scale or appearance from the original classes, the RPN may fail to propose relevant regions, degrading detection accuracy.

### Mechanism 3
- Claim: Task-agnostic training enables the model to generalize across different process steps (ADI and AEI) without catastrophic forgetting.
- Mechanism: By training on multiple process steps incrementally, the model learns a generalized representation of defect features that apply across different inspection contexts.
- Core assumption: Defect features share sufficient commonality across process steps that a single model can detect all classes effectively.
- Evidence anchors:
  - [abstract] "This work introduces a task-agnostic, meta-learning approach aimed at addressing this challenge, which enables the incremental addition of new defect classes and scales to create a more robust and generalized model for semiconductor defect inspection."
  - [section] "Defect classes from the AEI dataset are incrementally added following training on the ADI dataset."
- Break condition: If the feature distributions between ADI and AEI defects are too dissimilar, the generalized model may perform poorly on specific defect types from either process step.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper directly addresses catastrophic forgetting as the core problem being solved.
  - Quick check question: What happens to a neural network's performance on task A when it is trained on task B without any special mechanisms?

- Concept: Incremental learning vs. fine-tuning
  - Why needed here: The paper compares incremental learning with conventional fine-tuning to demonstrate its superiority.
  - Quick check question: How does incremental learning differ from simple fine-tuning when adding new classes to an existing model?

- Concept: Region Proposal Networks (RPN) in Faster-RCNN
  - Why needed here: Faster-RCNN is the backbone architecture used for defect detection in this study.
  - Quick check question: What role does the RPN play in the object detection pipeline of Faster-RCNN?

## Architecture Onboarding

- Component map: Backbone feature extractor (CNN) -> Region Proposal Network (RPN) -> ROI pooling layer -> Classification and bounding box regression heads -> Meta-learning update module for incremental training

- Critical path: Input SEM image -> Backbone features -> RPN proposals -> ROI pooling -> Classification/Regression -> Output defect detections

- Design tradeoffs:
  - Model complexity vs. inference speed: Faster-RCNN offers good accuracy but may be slower than simpler detectors like YOLO
  - Number of classes vs. catastrophic forgetting: More classes increase the risk of forgetting but are necessary for comprehensive defect detection
  - Incremental vs. full retraining: Incremental learning saves time and resources but may have slightly lower performance than models trained from scratch

- Failure signatures:
  - High false negative rate for previously learned defect classes
  - Low confidence scores on known defect types after incremental training
  - Degraded mAP (mean Average Precision) across all classes when new ones are added

- First 3 experiments:
  1. Train Faster-RCNN on the initial 2 ADI defect classes (microbridge, gap) and evaluate baseline performance
  2. Incrementally add the next 2 ADI defect classes (bridge, line-collapse) using the meta-learning strategy and compare AP with conventional fine-tuning
  3. Add AEI defect classes to the ADI-trained model and assess cross-process generalization while monitoring catastrophic forgetting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed continual learning approach perform when adding more than 9 defect classes, and what is the theoretical limit for class addition before performance degradation becomes unacceptable?
- Basis in paper: [explicit] The study evaluates incremental learning with 10 defect classes across ADI and AEI datasets but doesn't explore performance limits with larger class numbers.
- Why unresolved: The current study only tests up to 10 defect classes, which may not represent the full complexity of real-world semiconductor manufacturing scenarios.
- What evidence would resolve it: Additional experiments adding 20+ defect classes while monitoring AP degradation and catastrophic forgetting would establish performance boundaries.

### Open Question 2
- Question: How does the meta-learning-based incremental training strategy compare to other continual learning approaches like rehearsal-based methods or regularization techniques in this domain?
- Basis in paper: [explicit] The authors benchmark only against conventional fine-tuning, not exploring alternative continual learning methodologies.
- Why unresolved: Without comparison to other CL approaches, it's unclear if the meta-learning strategy is optimal or if simpler methods could achieve similar results.
- What evidence would resolve it: Direct comparison studies with experience replay, elastic weight consolidation, or other CL methods using identical datasets and evaluation metrics.

### Open Question 3
- Question: What is the impact of dataset size imbalance across defect classes on the incremental learning performance, and how can this be mitigated?
- Basis in paper: [explicit] The dataset shows significant variation in instance distribution (e.g., Gap has 1046 training instances vs Line collapse with 80 in AEI), but this imbalance isn't addressed in the methodology.
- Why unresolved: The study doesn't investigate whether class imbalance affects incremental learning differently than conventional training, or what sampling strategies might help.
- What evidence would resolve it: Controlled experiments varying class sample sizes while maintaining consistent total dataset size to measure impact on incremental learning stability.

## Limitations
- The study doesn't explore the theoretical limits of class addition before performance degradation becomes unacceptable, only testing up to 10 defect classes.
- Implementation details of the meta-learning-based incremental training strategy are not fully specified, referencing prior work without complete replication guidance.
- The evaluation focuses primarily on average precision metrics without comprehensive breakdowns including recall, precision, or F1-scores across all defect classes and process steps.

## Confidence

- High Confidence: The catastrophic forgetting problem in continual learning is well-established, and the study's demonstration of this issue in semiconductor inspection using conventional fine-tuning is convincing.
- Medium Confidence: The superior performance of the incremental learning approach over conventional fine-tuning is supported by the presented results, though the exact magnitude of improvement could vary with different datasets or experimental conditions.
- Medium Confidence: The claim of task-agnostic generalization across ADI and AEI process steps is supported, but the evidence could be strengthened with more extensive cross-validation and analysis of feature distribution differences.

## Next Checks

1. **Ablation Study on Meta-Learning Components**: Conduct experiments isolating different components of the meta-learning strategy to identify which specific mechanisms most effectively prevent catastrophic forgetting, including comparison with alternative continual learning approaches like elastic weight consolidation or learning without forgetting.

2. **Dataset Diversity and Robustness Testing**: Evaluate model performance across a broader range of manufacturing conditions, including variations in illumination, defect severity, and process step variations, to assess the true generalization capability beyond the current ADI and AEI datasets.

3. **Real-Time Inference Performance Analysis**: Measure and compare inference speed, memory usage, and computational requirements between the incremental learning model and conventional fine-tuning approaches under realistic deployment conditions to ensure practical applicability in manufacturing environments.