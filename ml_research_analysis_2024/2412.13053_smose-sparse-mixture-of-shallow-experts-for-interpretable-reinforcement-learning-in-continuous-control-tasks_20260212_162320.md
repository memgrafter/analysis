---
ver: rpa2
title: 'SMOSE: Sparse Mixture of Shallow Experts for Interpretable Reinforcement Learning
  in Continuous Control Tasks'
arxiv_id: '2412.13053'
source_url: https://arxiv.org/abs/2412.13053
tags:
- angle
- expert
- torso
- velocity
- left
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes SMOSE, a novel method to train sparsely activated
  interpretable controllers for continuous control tasks. It uses a top-1 Mixture-of-Experts
  architecture combining interpretable decision-makers (linear policies) and an interpretable
  router that assigns tasks among the experts.
---

# SMOSE: Sparse Mixture of Shallow Experts for Interpretable Reinforcement Learning in Continuous Control Tasks

## Quick Facts
- arXiv ID: 2412.13053
- Source URL: https://arxiv.org/abs/2412.13053
- Reference count: 40
- Primary result: Outperforms interpretable baselines and narrows performance gap with non-interpretable methods on six MuJoCo benchmarks while maintaining transparency

## Executive Summary
SMOSE introduces a sparse mixture-of-experts architecture for interpretable reinforcement learning in continuous control tasks. The method combines linear policies as interpretable experts with a router that assigns tasks using top-1 selection, ensuring only one expert is active per timestep. Trained via Soft Actor-Critic with load-balancing penalties, SMOSE achieves strong performance while maintaining transparency through decision tree distillation of the router's behavior. The approach successfully bridges the gap between interpretability and performance in complex control environments.

## Method Summary
SMOSE employs a top-1 Mixture-of-Experts architecture where a router selects exactly one of M linear experts for each decision. The router uses a linear layer followed by softmax and top-1 selection to ensure sparse activation. Experts are trained as linear policies that learn distinct skills through load-balancing penalties in the SAC objective. After training, decision trees are distilled from the router to provide human-readable interpretations of the routing decisions. The method is evaluated on six MuJoCo benchmark environments with varying numbers of experts.

## Key Results
- SMOSE outperforms interpretable baselines (SQIL, TISP, EMRL, TVT) across all six MuJoCo tasks
- Performance approaches non-interpretable methods (SAC, PPO) while maintaining interpretability
- Ablation studies show optimal expert count at M=8, with performance degrading below M=3 and interpretation complexity increasing above M=8

## Why This Works (Mechanism)

### Mechanism 1
Sparse MoE routing ensures interpretability by activating only one expert per timestep, preserving the linear policy structure. TOP1 selection in the router forces exclusive activation of a single expert per decision, avoiding superposition of multiple linear policies. This keeps the final policy in the form of a single linear function at each step, making the decision traceable.

### Mechanism 2
Load-balancing losses prevent expert collapse and ensure each expert learns a distinct skill. Load-balancing and importance losses encourage diverse expert usage across the state space, preventing a few experts from dominating. This promotes specialization of each expert in different behavioral skills.

### Mechanism 3
Decision tree distillation provides a human-readable abstraction of the router's behavior. After training, the router is interpreted as a multi-class classifier, and each expert's assignment is modeled by a binary decision tree. This decomposition yields shallow trees that are easy to read and map directly to state conditions.

## Foundational Learning

- **Concept**: Sparse MoE architecture
  - Why needed here: Ensures only one expert is active at each timestep, preserving linear interpretability while maintaining performance
  - Quick check question: How does TOP1 enforce sparsity in expert selection?

- **Concept**: Load-balancing in multi-expert systems
  - Why needed here: Prevents a few experts from dominating, ensuring each learns a distinct skill and improving generalization
  - Quick check question: What happens if load-balancing is disabled in a MoE RL system?

- **Concept**: Decision tree distillation
  - Why needed here: Converts the router's continuous decision surface into a set of readable rules for human interpretation
  - Quick check question: How does splitting a multi-class problem into binary trees aid interpretability?

## Architecture Onboarding

- **Component map**: State -> Router (linear layer → softmax → TOP1) → Expert (linear policy) → Action
- **Critical path**:
  1. Initialize router and experts
  2. Train via SAC with load-balancing losses
  3. Distill decision trees from router
  4. Evaluate performance and interpretability
- **Design tradeoffs**:
  - M (number of experts): Larger M improves specialization but increases interpretation complexity
  - λ (load-balancing weight): Balances expert diversity vs. performance
  - Tree depth: Shallower trees are easier to interpret but may lose accuracy
- **Failure signatures**:
  - Expert collapse: One or few experts dominate usage
  - Poor performance: Load-balancing too aggressive or router not learning
  - Inaccurate trees: Router decisions too complex for shallow trees
- **First 3 experiments**:
  1. Train with M=3 experts, no load-balancing; observe expert usage and performance
  2. Add load-balancing losses; measure expert diversity and performance change
  3. Distill decision trees; evaluate interpretability vs. router accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How does SMOSE's performance scale with different numbers of experts beyond the tested range of 3-32? The ablation study provides limited insight into the optimal expert count for different environments and doesn't establish a clear scaling law. Systematic experiments testing M values across the full range (e.g., 2-64) for all six environments, measuring both performance and interpretability metrics to identify optimal trade-offs.

### Open Question 2
How does SMOSE perform on more complex continuous control tasks beyond the MuJoCo benchmark suite? The current evaluation is limited to relatively well-behaved benchmarks, leaving uncertainty about generalizability to more complex domains. Experiments on tasks with higher dimensional state/action spaces, delayed rewards, or hierarchical structure (e.g., Meta-World, real robot manipulation tasks).

### Open Question 3
How sensitive is SMOSE's performance to the load-balancing hyperparameter λ? The paper mentions tuning λ between 0.01 and 1.0 but only reports results for λ=0.1, without providing sensitivity analysis. Comprehensive sensitivity analysis showing performance across the full λ range for multiple environments, identifying optimal ranges and potential trade-offs.

## Limitations

- Limited to continuous state-action spaces and dense reward environments, restricting applicability to sparse-reward or discrete-action domains
- Interpretability claims depend on decision tree fidelity, which may not capture complex router decisions accurately
- Performance depends on careful tuning of load-balancing hyperparameter λ with no principled guidance for selection across tasks

## Confidence

- **High Confidence**: The sparse MoE architecture with TOP1 selection reliably enforces single-expert activation, as this is a direct consequence of the architectural design and well-documented in MoE literature
- **Medium Confidence**: Load-balancing losses effectively prevent expert collapse and promote specialization, though optimal λ values may vary across environments
- **Low Confidence**: Decision tree distillation provides accurate human-interpretable abstractions of router behavior, as fidelity to complex decision surfaces is not quantified

## Next Checks

1. Implement the full SMOSE architecture and train on Walker2d-v4 environment to verify expert diversity and performance against baselines
2. Conduct sensitivity analysis for λ parameter across range [0.01, 1.0] to identify optimal values and robustness
3. Test decision tree fidelity by comparing router accuracy before and after distillation for varying tree depths