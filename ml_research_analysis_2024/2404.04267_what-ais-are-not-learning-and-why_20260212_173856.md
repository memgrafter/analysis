---
ver: rpa2
title: What AIs are not Learning (and Why)
arxiv_id: '2404.04267'
source_url: https://arxiv.org/abs/2404.04267
tags:
- robots
- robotics
- learning
- what
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines why current AI and robotics systems lack the
  general skills needed for human service applications like home care, nursing assistance,
  and household chores. The author identifies that mainstream AI development relies
  on large datasets and deep learning but fails to capture the experiential learning
  needed for complex, real-world tasks.
---

# What AIs are not Learning (and Why)

## Quick Facts
- arXiv ID: 2404.04267
- Source URL: https://arxiv.org/abs/2404.04267
- Reference count: 0
- Current AI systems lack experiential learning needed for complex real-world service tasks

## Executive Summary
This paper examines why current AI and robotics systems cannot perform general service tasks like home care and nursing assistance. The author identifies that mainstream AI development relies on static datasets and deep learning but fails to capture the experiential learning needed for complex, real-world tasks. The paper proposes "experiential foundation models" for robotics, inspired by developmental psychology, where robots learn through interaction, experimentation, and collaborationâ€”similar to how children develop skills.

## Method Summary
The paper proposes experiential foundation models that combine embodied AI with deep learning, trained through phased, experience-based learning rather than static data alone. The approach involves creating simulation environments for collecting multimodal experiential data (sensory, activity, and interaction data), then training robotic foundation models using deep learning techniques on this data. The training follows developmental trajectories where early competences prepare for later ones, and models can be replicated across similar service contexts to amortize training costs.

## Key Results
- Current AI systems cannot perform complex service tasks because they lack experiential learning through real-world interaction
- Phased, experience-based learning approaches could bridge the gap between laboratory demonstrations and real-world readiness
- Experiential foundation models could enable robots to acquire context-specific skills and adaptability needed for service roles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Current mainstream AI relies on static datasets and deep learning but fails to capture experiential learning needed for complex real-world tasks.
- Mechanism: AI systems trained on large datasets learn patterns from passive observation rather than through active interaction, experimentation, and collaboration that characterize human skill development.
- Core assumption: Human service applications require context-specific adaptability and social interaction skills that cannot be fully captured through static data alone.
- Evidence anchors:
  - [abstract] "Today's mainstream AIs are not created by agents learning from experiences doing real world tasks and interacting with people."
  - [section] "They do not learn by sensing, acting, doing experiments, and collaborating."
  - [corpus] Weak evidence - corpus neighbors discuss imitation learning and social theory but don't directly address experiential learning gap.
- Break condition: If embodied AI systems with multimodal sensing and motor control cannot effectively translate real-world interaction data into generalizable models.

### Mechanism 2
- Claim: Experiential foundation models (FMs) can bridge the gap between laboratory demonstrations and real-world readiness by combining embodied AI with deep learning trained through phased, experience-based learning.
- Mechanism: The proposed approach models human developmental trajectories where early competences prepare for later ones, allowing robots to acquire foundational skills through interaction before tackling complex tasks.
- Core assumption: Phased learning approaches that mirror human development can create more adaptable and context-aware AI systems for service applications.
- Evidence anchors:
  - [abstract] "These models would combine embodied AI with deep learning, trained through phased, experience-based learning rather than static data alone."
  - [section] "Training of human professionals typically takes place in phases... where a trainee gains experience on basic activities before exercising full autonomy on complex activities."
  - [corpus] No direct evidence in corpus - neighbors focus on imitation learning and social theory but not phased developmental approaches.
- Break condition: If phased learning proves too slow or inefficient compared to alternative training approaches for achieving real-world readiness.

### Mechanism 3
- Claim: The cost of training robots for widespread service applications can be amortized by copying previously trained robots, using models of operational robots as foundation models for later generations.
- Mechanism: Once an experiential FM is developed for a specific service context, the model can be replicated and fine-tuned for similar applications, reducing the need for repeated extensive training.
- Core assumption: Experiential FMs capture generalizable patterns that can be adapted across similar service contexts without requiring complete retraining.
- Evidence anchors:
  - [abstract] "The cost of training robots for widespread could be amortized by copying previously trained robots."
  - [section] "Restated, the models of the operational robots would be used as foundation models for later generations."
  - [corpus] No direct evidence - corpus neighbors don't address model replication or amortization strategies.
- Break condition: If experiential FMs prove too context-specific to be effectively replicated across different service environments.

## Foundational Learning

- Concept: Experiential learning through interaction and experimentation
  - Why needed here: Current AI systems lack the ability to learn from doing real-world tasks and interacting with people, which is essential for service applications requiring adaptability and social awareness.
  - Quick check question: How does learning through active experimentation differ from learning through passive observation in terms of skill acquisition for service robots?

- Concept: Phased development following human developmental trajectories
  - Why needed here: Complex service tasks require foundational competences that build progressively, similar to how humans acquire skills from basic motor control to complex social interaction.
  - Quick check question: What are the key developmental phases that should be modeled in experiential FMs for service robots?

- Concept: Multimodal data integration (sensory and activity data)
  - Why needed here: Service robots must integrate perception, action, and environmental feedback to learn effective behaviors, requiring training data that captures the full context of task performance.
  - Quick check question: How can multimodal data from real-world interactions be effectively combined to train more capable service robots?

## Architecture Onboarding

- Component map:
  - Sensor subsystem (vision, touch, proprioception)
  - Effector control system (arms, hands, locomotion)
  - Experiential learning module (interaction recording and analysis)
  - Foundation model trainer (phased learning algorithm)
  - Context adaptation layer (transfer learning capabilities)

- Critical path:
  1. Real-world interaction data collection
  2. Multimodal data preprocessing and synchronization
  3. Phased learning algorithm execution
  4. Model validation in simulated and real environments
  5. Context adaptation and fine-tuning

- Design tradeoffs:
  - Data quality vs. quantity: High-quality experiential data is expensive to collect but essential for effective learning
  - Simulation fidelity vs. real-world testing: Balancing safe training environments with authentic experience
  - Model complexity vs. training efficiency: Managing computational requirements for phased learning approaches

- Failure signatures:
  - Poor generalization across contexts
  - Inability to handle unexpected situations
  - Slow adaptation to new tasks
  - Overfitting to specific training scenarios

- First 3 experiments:
  1. Basic manipulation task learning: Train a robot to perform simple object manipulation through trial and error, comparing performance against scripted approaches
  2. Social interaction scenario: Implement a phased learning approach for a robot to learn appropriate responses in simple social interactions
  3. Context transfer test: Evaluate how well a robot trained in one household environment can adapt to a different household layout and object arrangement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific experiential foundation models could bridge the gap between laboratory demonstrations and real-world readiness for household robots?
- Basis in paper: [explicit] The paper highlights the need for experiential foundation models that combine embodied AI with deep learning, trained through phased, experience-based learning rather than static data alone.
- Why unresolved: Current approaches do not model the developmental trajectory of human competence acquisition or account for social interaction and collaboration, which are critical for household tasks.
- What evidence would resolve it: Successful implementation and testing of phased experiential foundation models in real-world household environments, demonstrating adaptability and context-specific skill acquisition.

### Open Question 2
- Question: How can robotic systems be designed to effectively learn and adapt to the diverse and context-specific needs of clients in assisted feeding scenarios?
- Basis in paper: [explicit] The paper discusses the complexity of assisted feeding tasks, including the need for robots to handle diverse situations, complex objects, and events, such as unripe strawberries and unexpected distractions.
- Why unresolved: Current simulation models and training data do not fully capture the long tail of potential requirements and real-world interactions necessary for effective assisted feeding.
- What evidence would resolve it: Development of comprehensive datasets and simulation environments that accurately model the variability and complexity of real-world assisted feeding scenarios, validated through trials with actual clients.

### Open Question 3
- Question: What are the key research challenges in developing foundation models for robotics that can handle the high variability and uncertainty in real-world settings?
- Basis in paper: [explicit] The paper identifies challenges such as data scarcity, high variability in robotics settings, uncertainty quantification, safety evaluation, and real-time performance as key issues in developing foundation models for robotics.
- Why unresolved: These challenges are complex and multifaceted, requiring advancements in data collection, model training, and evaluation methodologies to ensure robust and reliable robotic systems.
- What evidence would resolve it: Successful development and deployment of foundation models that demonstrate high performance across diverse and unpredictable real-world scenarios, with validated safety and reliability metrics.

## Limitations
- No empirical validation of experiential foundation models' effectiveness
- Lacks specific technical details on multimodal data integration and processing
- Speculative claims about model replication and cost amortization
- No concrete evaluation metrics or benchmarks defined

## Confidence
- Low confidence: The overall effectiveness of experiential foundation models for bridging the laboratory-to-real-world gap
- Medium confidence: The identification of experiential learning as a missing component in current AI systems
- Medium confidence: The analogy to human developmental trajectories as a model for robot learning

## Next Checks
1. Simulation-to-real transfer validation: Implement a basic experiential learning system in simulation for a household task, then test performance on a physical robot to measure sim2real transfer effectiveness.
2. Phased learning efficiency comparison: Compare training efficiency and final performance of phased experiential learning against traditional supervised learning approaches on a benchmark service robotics task.
3. Model replication cost analysis: Conduct a detailed analysis of the computational and data requirements for developing experiential foundation models versus traditional approaches, including an assessment of potential cost amortization through model replication.