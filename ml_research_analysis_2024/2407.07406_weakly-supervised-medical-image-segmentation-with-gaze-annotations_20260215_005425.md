---
ver: rpa2
title: Weakly-supervised Medical Image Segmentation with Gaze Annotations
arxiv_id: '2407.07406'
source_url: https://arxiv.org/abs/2407.07406
tags:
- gaze
- annotation
- segmentation
- image
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a gaze annotation scheme for medical image
  segmentation, addressing the challenge of heavy annotation costs. The proposed method
  trains multiple networks from discriminative human attention simulated with hierarchical
  thresholds on gaze heatmaps.
---

# Weakly-supervised Medical Image Segmentation with Gaze Annotations

## Quick Facts
- arXiv ID: 2407.07406
- Source URL: https://arxiv.org/abs/2407.07406
- Authors: Yuan Zhong; Chenhui Tang; Yumeng Yang; Ruoxi Qi; Kang Zhou; Yuqi Gong; Pheng Ann Heng; Janet H. Hsiao; Qi Dou
- Reference count: 31
- Primary result: Gaze-based segmentation achieves 77.80% Dice on polyp segmentation and 77.64% on prostate segmentation, outperforming label-efficient methods while reducing annotation time by 15.4%

## Executive Summary
This paper addresses the challenge of heavy annotation costs in medical image segmentation by introducing a gaze annotation scheme that leverages human attention patterns. The proposed method trains multiple networks from discriminative human attention simulated with hierarchical thresholds on gaze heatmaps. To mitigate gaze noise, a cross-level consistency regularization is employed to guide models towards clean patterns learned by peer networks. The approach is validated on two public datasets (Kvasir-SEG and NCI-ISBI) for polyp and prostate segmentation tasks, achieving Dice scores of 77.80% and 77.64% respectively, outperforming existing label-efficient annotation schemes while being 15.4% faster to annotate.

## Method Summary
The method generates gaze heatmaps from raw gaze positions using isotropic Gaussian convolution and Dense-CRF refinement. Hierarchical thresholds are applied to create diverse pseudo-masks, each training a separate UNet network. A cross-level consistency regularization with Local Pixel Propagation (LPP) module compensates for noisy gaze labels by encouraging networks to learn clean patterns from peer networks. The final prediction is obtained by ensembling all network predictions. The approach balances between capturing diverse attention patterns and maintaining noise robustness through the consistency loss weighted by hyperparameter λ.

## Key Results
- Achieved 77.80% Dice score on Kvasir-SEG polyp segmentation
- Achieved 77.64% Dice score on NCI-ISBI prostate segmentation
- Outperformed existing label-efficient annotation schemes (BoxInst, BoxTeacher, PointSup, AGMM)
- Reduced annotation time by 15.4% compared to traditional pixel-wise annotation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multiple networks trained on hierarchically thresholded gaze heatmaps learn complementary representations of human attention.
- Mechanism: By applying different thresholds to gaze heatmaps, the method generates pseudo-masks with varying levels of foreground activation. Each network learns from a different level of pseudo-mask, capturing different aspects of human attention patterns. The final prediction is obtained by ensembling these networks.
- Core assumption: Different threshold levels capture distinct but complementary aspects of human attention patterns.
- Evidence anchors:
  - [abstract]: "we propose a multi-level framework that trains multiple networks from discriminative human attention, simulated with a set of pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps."
  - [section 3.1]: "Our idea is to train m deep networks simultaneously supervised by pseudo-masks generated from m different thresholds (Fig. 2 (a)), simulating multi-level human attention."
- Break condition: If the thresholds do not create meaningfully different pseudo-masks, or if the networks converge to learning identical patterns.

### Mechanism 2
- Claim: Cross-level consistency regularization compensates for noisy gaze labels by encouraging networks to learn clean patterns from peer networks.
- Mechanism: The method applies a consistency loss between predictions of different networks after local pixel propagation smoothing. This forces networks to align their predictions even when their individual pseudo-mask labels are noisy, effectively learning from the clean patterns captured by other networks.
- Core assumption: Networks learn clean patterns on incorrectly annotated pixels early in training, before overfitting to noise.
- Evidence anchors:
  - [abstract]: "to mitigate gaze noise, a cross-level consistency is exploited to regularize overfitting noisy labels, steering models toward clean patterns learned by peer networks."
  - [section 3.2]: "Based on the assumption that networks learn clean patterns at the beginning of the memorization, for each network, we propose to exploit the knowledge learned by peer networks of other levels to compensate for the noisy label via a consistency term."
- Break condition: If all networks overfit to noise at similar rates, leaving no clean patterns to learn from.

### Mechanism 3
- Claim: Local pixel propagation module enhances noise robustness by introducing spatial smoothness in feature denoising.
- Mechanism: The LPP module computes transformed features for each pixel by aggregating features from neighboring pixels weighted by cosine similarity. This smoothing effect reduces outliers and enhances features with local context, making the consistency regularization more robust to noise.
- Core assumption: Spatially close pixels tend to have similar features, and aggregating them helps denoise.
- Evidence anchors:
  - [section 3.2]: "To ensure noise-robust consistency, we first use a non-parametric local pixel propagation (LPP) module to filter the feature of each pixel by propagating the features of surrounding pixels in local regions inspired by recent works [5,7] proving noise-robust feature correspondence distillation."
- Break condition: If the local context is not representative or if noise patterns are highly localized.

## Foundational Learning

- Concept: Hierarchical thresholding
  - Why needed here: To generate diverse pseudo-masks that capture different levels of human attention to the same objects.
  - Quick check question: What happens to the pseudo-mask if you apply a very high threshold versus a very low threshold to the gaze heatmap?

- Concept: Cross-entropy loss with noisy labels
  - Why needed here: To train individual networks on their respective pseudo-masks while the consistency term prevents overfitting to noise.
  - Quick check question: Why might standard cross-entropy training fail when labels are noisy, and how does consistency regularization help?

- Concept: Feature correspondence distillation
  - Why needed here: The local pixel propagation module uses this principle to denoise features by aggregating information from neighboring pixels.
  - Quick check question: How does aggregating features from neighboring pixels help reduce the impact of outliers or noise?

## Architecture Onboarding

- Component map: Gaze heatmaps -> Hierarchical thresholding -> Multiple UNet networks -> Local Pixel Propagation (LPP) module -> Consistency regularization -> Ensemble predictions

- Critical path:
  1. Generate gaze heatmaps from raw gaze positions
  2. Apply hierarchical thresholds to create pseudo-masks
  3. Train multiple networks on different pseudo-masks with cross-entropy loss
  4. Apply LPP and consistency regularization between networks
  5. Ensemble final predictions

- Design tradeoffs:
  - More thresholds (m) provides more diverse supervision but increases computational cost and complexity
  - Higher λ emphasizes consistency over divergence, risking model collapse
  - Choice of LPP parameters (neighborhood size, dilation) affects denoising effectiveness

- Failure signatures:
  - All networks produce identical predictions (overly high consistency, insufficient divergence)
  - Performance worse than single network baseline (poor threshold selection or λ tuning)
  - Noisy predictions in areas with high gaze uncertainty (inadequate LPP smoothing or consistency strength)

- First 3 experiments:
  1. Train single UNet with fixed threshold pseudo-mask (baseline)
  2. Train with two thresholds and ensemble without consistency (test divergence benefit)
  3. Add consistency regularization and compare performance with and without LPP module

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed gaze annotation scheme perform on multi-class segmentation tasks compared to binary segmentation?
- Basis in paper: [explicit] The paper mentions extending to multiple cases is straightforward via annotating each class separately and deciding the label for each pixel as the class with the highest value in gaze heatmaps of different classes, but does not provide experimental results.
- Why unresolved: The authors only validated their method on binary segmentation tasks (polyp and prostate segmentation) and did not explore multi-class scenarios.
- What evidence would resolve it: Experimental results on multi-class segmentation datasets, comparing performance with other annotation schemes and demonstrating the effectiveness of the gaze-based approach in multi-class settings.

### Open Question 2
- Question: How sensitive is the proposed method to the selection of the pair of thresholds for generating diverse heatmaps?
- Basis in paper: [explicit] The authors mention selecting a pair of thresholds based on annotators' feedback to generate diverse heatmaps, but do not provide a detailed analysis of threshold sensitivity.
- Why unresolved: The paper does not explore the impact of different threshold selections on the final segmentation performance or provide guidelines for choosing optimal thresholds.
- What evidence would resolve it: A sensitivity analysis showing how different threshold pairs affect the segmentation results, and recommendations for selecting thresholds based on specific dataset characteristics.

### Open Question 3
- Question: How does the proposed method handle real-time scenarios where multiple networks need to be maintained for inference?
- Basis in paper: [inferred] The authors mention that maintaining multiple networks hampers real-time scenarios but do not provide a solution or experimental results addressing this issue.
- Why unresolved: The paper focuses on the training phase and does not explore techniques to optimize the inference process when using multiple networks.
- What evidence would resolve it: Experimental results comparing the inference speed and memory usage of the proposed method with other segmentation approaches, and proposed techniques to optimize the inference process while maintaining performance.

## Limitations
- Limited validation to only two specific segmentation tasks (polyps and prostate)
- Threshold selection strategy for generating pseudo-masks is heuristic and may not generalize well
- Annotation speed improvement claims need validation across different annotator skill levels and medical specialties

## Confidence
- High confidence: The multi-network framework with hierarchical thresholds improves over single-network baselines
- Medium confidence: Cross-level consistency regularization effectively mitigates gaze noise in the tested scenarios
- Low confidence: The 15.4% annotation time improvement is directly attributable to the gaze-based approach across different medical imaging contexts

## Next Checks
1. **Cross-modality validation**: Test the approach on CT and MRI datasets with different anatomical structures to verify robustness across imaging modalities and validate the annotation speed claims with radiologists from different specialties.

2. **Threshold sensitivity analysis**: Systematically vary the hierarchical threshold values and evaluate their impact on segmentation performance and annotation quality to identify optimal threshold selection strategies.

3. **Comparison with alternative weak supervision**: Benchmark against other weakly-supervised approaches (scribbles, points, extreme points) on the same datasets to establish the relative efficiency and accuracy trade-offs of gaze annotations.