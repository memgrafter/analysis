---
ver: rpa2
title: VerifIoU -- Robustness of Object Detection to Perturbations
arxiv_id: '2403.08788'
source_url: https://arxiv.org/abs/2403.08788
tags:
- detection
- object
- interval
- bounding
- perturbation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We present a formal verification approach for object detection
  models, focusing on the stability property under perturbations. Our method, IBP
  IoU, uses Interval Bound Propagation (IBP) to verify the Intersection over Union
  (IoU) metric, which quantifies the overlap between predicted and ground truth bounding
  boxes.
---

# VerifIoU -- Robustness of Object Detection to Perturbations

## Quick Facts
- arXiv ID: 2403.08788
- Source URL: https://arxiv.org/abs/2403.08788
- Authors: Noémie Cohen; Mélanie Ducoffe; Ryma Boumazouza; Christophe Gabreau; Claire Pagetti; Xavier Pucel; Audrey Galametz
- Reference count: 5
- Primary result: Optimal IoU interval extension significantly improves certified box accuracy (CBA) over Vanilla IoU, achieving 100% improvement in some cases

## Executive Summary
This paper introduces a formal verification approach for object detection models focusing on stability under input perturbations. The method, called IBP IoU, combines abstract interpretation for perturbation analysis with Interval Bound Propagation for IoU verification. By computing sound over-approximations of bounding box coordinates under perturbations and propagating these through a novel interval extension of the IoU function, the approach provides certified bounds on detection accuracy. Experiments on MNIST and LARD datasets demonstrate that the Optimal IoU extension significantly outperforms baseline approaches, achieving substantial improvements in certified box accuracy.

## Method Summary
The approach uses a two-step verification process. First, abstract interpretation tools (Auto-LiRPA, ERAN) compute interval bounds on bounding box coordinates under input perturbations. Second, these intervals are propagated through the IoU function using interval arithmetic. The paper introduces two interval extensions for IoU: Vanilla IoU, which bounds primitive operators, and Optimal IoU, which leverages the coordinate-wise monotonicity of IoU to compute exact bounds. The method targets the stability property, ensuring that predicted bounding boxes remain close to ground truth under perturbations, with certified box accuracy measuring the percentage of boxes meeting the threshold.

## Key Results
- Optimal IoU interval extension achieves 100% improvement in CBA compared to Vanilla IoU in certain cases
- The approach is computationally efficient, with IBP IoU step taking negligible time compared to perturbation analysis
- Experiments demonstrate effectiveness on MNIST dataset with white noise perturbation and LARD dataset with brightness/contrast perturbations
- Optimal IoU provides exact bounds while Vanilla IoU can produce false positives due to lack of tightness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal IoU computes exact bounds on IoU by leveraging the coordinate-wise monotonicity of the IoU function
- Mechanism: The IoU function increases as bounding box coordinates approach the ground truth and decreases as they move away. By evaluating IoU at the vertices of the input interval domain and the "optimal" box coordinates (closest to ground truth), the method finds the exact maximum and minimum IoU values
- Core assumption: The IoU function's partial derivatives allow coordinate-wise optimization, and the global extrema occur at the interval boundaries or at the ground truth coordinates
- Evidence anchors: [section] "For a fixed ground truth box, the IoU is increasing when the input variables get closer to the ground truth coordinates... computing the optimal box coordinates b* is immediate, with the rule: IoU opt = max b∈[b,b] IoU gt = IoU (b* = [z*i]3i=0 ∩ bgt = [zgti]3i=0)"

### Mechanism 2
- Claim: Step 1 perturbation analysis provides sound over-approximations of bounding box coordinate intervals under input perturbations
- Mechanism: Abstract interpretation tools (Auto-LiRPA, ERAN) propagate input perturbation intervals through the object detection network to compute output intervals for objectness scores and bounding box coordinates. These intervals soundly over-approximate all possible network outputs under the given perturbations
- Core assumption: The object detection model uses operators supported by the abstract interpretation tools, and the perturbation domain is properly defined as an interval
- Evidence anchors: [section] "Step 1: we apply a perturbation on the input and rely on classical verification tools such as ERAN [MSS+21], Auto-LiRPA [XSZ+20] or DECOMON [Duc] to obtain the reachable outputs."

### Mechanism 3
- Claim: The two-step approach enables modular verification where perturbation analysis and IoU bounding can be optimized independently
- Mechanism: By separating the perturbation propagation (Step 1) from the IoU interval extension (Step 2), each component can use the most appropriate verification technique. Step 1 uses abstract interpretation for general network propagation, while Step 2 uses specialized interval arithmetic for the non-linear IoU function
- Core assumption: The bounding box coordinates output by Step 1 can be represented as intervals that are valid inputs to the IoU interval extension in Step 2
- Evidence anchors: [abstract] "Our method, IBP IoU, uses Interval Bound Propagation (IBP) to verify the Intersection over Union (IoU) metric... The approach has two steps: 1) computing bounds on object detection outputs under perturbations using abstract interpretation tools, and 2) propagating these bounds through the IoU function using IBP."

## Foundational Learning

- Concept: Interval arithmetic and interval extension
  - Why needed here: The entire approach relies on representing uncertain values as intervals and propagating these intervals through functions to compute bounds on outputs
  - Quick check question: Given two intervals [a, b] and [c, d], what is the interval result of their multiplication [a, b] × [c, d] when both intervals contain only positive numbers?

- Concept: Abstract interpretation for neural network verification
  - Why needed here: Step 1 requires computing sound over-approximations of neural network outputs under input perturbations, which is a core application of abstract interpretation
  - Quick check question: What is the key difference between sound and complete over-approximations in abstract interpretation, and why is soundness critical for verification?

- Concept: Intersection over Union (IoU) metric and its properties
  - Why needed here: The verification target is the IoU between predicted and ground truth bounding boxes, so understanding its mathematical properties (non-linearity, coordinate-wise monotonicity) is essential for the interval extension
  - Quick check question: For two bounding boxes b0 and b1, write the formula for their IoU in terms of their areas and intersection area

## Architecture Onboarding

- Component map:
  Input perturbation generator -> Abstract interpretation engine (Auto-LiRPA/ERAN) -> IoU interval extension module -> Verification oracle

- Critical path:
  1. Generate perturbed inputs within specified domains
  2. Run abstract interpretation to obtain bounding box intervals
  3. Apply Optimal IoU extension to compute IoU bounds
  4. Check if min IoU ≥ threshold (t=0.5)
  5. Report CBA and computation times

- Design tradeoffs:
  - Vanilla IoU vs Optimal IoU: Vanilla is faster but less tight; Optimal is slower but provides exact bounds
  - Abstract interpretation method choice (IBP vs CROWN-IBP vs CROWN): Affects tightness and computation time of Step 1
  - Perturbation domain size: Larger domains provide stronger guarantees but increase computational cost

- Failure signatures:
  - Step 1 fails to compute bounds: Abstract interpretation tools cannot handle the network architecture or perturbation domain is too large
  - Optimal IoU reports CBA=0%: Either the perturbation is too strong or the object detection network is unstable
  - Computation time exceeds limits: Particularly for Optimal IoU on large datasets or complex networks

- First 3 experiments:
  1. Verify a simple MNIST CNN with white noise perturbation (ϵ=0.002) using CROWN-IBP + Optimal IoU to confirm basic functionality
  2. Compare Vanilla IoU vs Optimal IoU on the same setup to demonstrate tightness improvement
  3. Test LARD dataset with brightness perturbation (αb=0.002) using CROWN + Optimal IoU to validate industrial use case

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively extend the IBP IoU approach to verify more complex object detection models that include operations like Non-maximum Suppression (NMS)?
- Basis in paper: [explicit] The paper mentions that future work will address formal verification of object detection by considering more operators such as NMS
- Why unresolved: The current IBP IoU approach focuses on verifying the stability property of bounding boxes under perturbations. However, real-world object detection models often include additional operations like NMS, which are not covered by the current approach
- What evidence would resolve it: Successful implementation and evaluation of the IBP IoU approach on object detection models that include NMS, demonstrating improved verification capabilities

### Open Question 2
- Question: What is the optimal threshold for the stability property in object detection models, and how does it vary with different types of perturbations and object detection tasks?
- Basis in paper: [inferred] The paper mentions that an open question is determining the expected stability of object detection at different distances and with different thresholds
- Why unresolved: The current work focuses on a fixed threshold for the stability property. However, the optimal threshold may vary depending on the specific object detection task, the type of perturbations considered, and the desired level of robustness
- What evidence would resolve it: Empirical studies that systematically vary the threshold for the stability property across different object detection tasks, perturbation types, and distances, identifying the optimal threshold for each scenario

### Open Question 3
- Question: How can certified training be effectively integrated into object detection models to improve their robustness against perturbations while maintaining good IoU performance?
- Basis in paper: [explicit] The paper mentions that future work will consider certified training for object detection, aiming to balance good IoU on training samples while guaranteeing the stability property
- Why unresolved: The current work focuses on verifying the stability property of pre-trained object detection models. However, integrating certified training into the model training process could potentially improve the model's robustness against perturbations from the start
- What evidence would resolve it: Successful implementation and evaluation of certified training techniques for object detection models, demonstrating improved robustness against perturbations while maintaining good IoU performance on test data

## Limitations

- The approach relies heavily on the availability of abstract interpretation tools that can handle the specific operators in the object detection network
- Computational complexity grows with perturbation magnitude and network size, potentially limiting practical use cases
- The method assumes bounding boxes remain well-defined (z2 > z0 and z3 > z1) after perturbations, which may not hold for large perturbations

## Confidence

- Confidence in Optimal IoU mechanism: High (mathematical proof of coordinate-wise monotonicity and experimental validation)
- Confidence in practical applicability: Medium (computational limitations and small-scale evaluation)
- Confidence in scalability: Low (not evaluated on complex real-world datasets)

## Next Checks

1. Evaluate the approach on a larger, more complex object detection dataset (e.g., COCO) to test scalability and real-world applicability
2. Implement a comparison with alternative verification methods for object detection, such as randomized smoothing or Lipschitz-based approaches
3. Test the method with different object detection architectures (e.g., YOLO, SSD) to verify robustness across design choices