---
ver: rpa2
title: 'FAWN: Floor-And-Walls Normal Regularization for Direct Neural TSDF Reconstruction'
arxiv_id: '2406.12054'
source_url: https://arxiv.org/abs/2406.12054
tags:
- fawn
- reconstruction
- scene
- tsdf
- normals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FAWN addresses distortions and artifacts in 3D reconstruction by
  leveraging 3D semantics to enforce scene structure. It modifies TSDF reconstruction
  methods to penalize deviations of wall normals from vertical and floor normals from
  horizontal, implemented as a 3D sparse convolutional module.
---

# FAWN: Floor-And-Walls Normal Regularization for Direct Neural TSDF Reconstruction

## Quick Facts
- arXiv ID: 2406.12054
- Source URL: https://arxiv.org/abs/2406.12054
- Authors: Anna Sokolova; Anna Vorontsova; Bulat Gabdullin; Alexander Limonov
- Reference count: 0
- Primary result: Improves 3D reconstruction quality by 5-10% accuracy and 2-6% completeness through semantic-aware normal regularization

## Executive Summary
FAWN addresses distortions and artifacts in 3D reconstruction by leveraging 3D semantics to enforce scene structure. It modifies TSDF reconstruction methods to penalize deviations of wall normals from vertical and floor normals from horizontal, implemented as a 3D sparse convolutional module. The method detects walls and floor during training and applies regularization based on their surface normals. Tested on SCANNET, ICL-NUIM, TUM RGB-D, and 7SCENES benchmarks, FAWN consistently improves reconstruction quality and completeness across all state-of-the-art baselines.

## Method Summary
FAWN introduces a regularization framework that combines surface normal constraints with 3D semantic information to improve TSDF-based 3D reconstruction. The method incorporates a 3D sparse U-Net semantic head that detects walls and floors, then applies FAWN regularization losses that penalize wall normals for non-verticality and floor normals for non-horizontality. Trained jointly with TSDF prediction, semantic loss, and normal losses, FAWN enforces geometric priors while maintaining consistency between semantic predictions and geometric reconstruction. The approach is implemented as a module that can be integrated with existing TSDF reconstruction architectures.

## Key Results
- Improves reconstruction accuracy by 5-10% across all tested baseline methods
- Increases reconstruction completeness by 2-6% compared to state-of-the-art approaches
- Demonstrates consistent performance improvements on SCANNET, ICL-NUIM, TUM RGB-D, and 7SCENES benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FAWN improves reconstruction accuracy by enforcing geometric priors on wall and floor normals.
- Mechanism: The method detects walls and floor regions using a 3D semantic segmentation head, then applies regularization losses that penalize deviations of wall normals from vertical and floor normals from horizontal. This creates a feedback loop where semantic predictions guide geometric refinement, which in turn improves semantic segmentation accuracy.
- Core assumption: Indoor scenes typically have walls that are vertical and floors that are horizontal, even if ground truth scans show deviations due to sensor noise or imperfect capture.
- Evidence anchors:
  - [abstract] "by assuming that walls are vertical, and a floor is planar and horizontal, we can correct distorted room shapes"
  - [section] "we encourage walls to be vertical, and a floor to be horizontal"
- Break condition: The assumption breaks down in non-rectilinear spaces, architectural features like sloped ceilings, or outdoor environments where vertical/horizontal relationships don't hold.

### Mechanism 2
- Claim: FAWN's joint training of geometry and semantics creates consistency between predicted TSDF and 3D semantics.
- Mechanism: The semantic head and TSDF prediction head share backbone features, ensuring that geometric predictions and semantic predictions are derived from the same underlying representation. This consistency prevents semantic guidance from targeting incorrect normals when geometry deviates from ground truth.
- Core assumption: Sharing backbone features between geometry and semantic prediction creates beneficial coupling rather than interference.
- Evidence anchors:
  - [section] "Predicted scene surfaces may deviate from ground truth during training, so using ground truth walls and floor as a guidance, we might target wrong normals. At the same time, FAWN derives semantics and TSDF using the same backbone features, which makes these two outputs consistent."
- Break condition: If the backbone features are not sufficiently discriminative for both tasks, or if one task dominates the shared representation.

### Mechanism 3
- Claim: FAWN's floor-and-walls-normal loss provides more effective regularization than conventional normal losses alone.
- Mechanism: The FAWN loss specifically targets planar surfaces (walls and floor) with semantic awareness, while conventional normal losses apply globally without semantic context. This targeted approach preserves surface smoothness where it matters most while avoiding over-regularization of complex geometric features.
- Core assumption: Planar surfaces benefit more from semantic-aware regularization than from general normal constraints.
- Evidence anchors:
  - [section] "Our key novelty is in combining normals and semantics in ŁFA W N: surface normals in walls regions are penalized for deviation from the horizontal direction, while the constraints imposed onfloor normals force them to be vertical."
- Break condition: In scenes with few or no planar surfaces, the FAWN loss may provide minimal benefit and could even introduce artifacts.

## Foundational Learning

- Concept: Truncated Signed Distance Function (TSDF) representation
  - Why needed here: FAWN is a modification of TSDF reconstruction methods, so understanding TSDF basics is essential for implementing and debugging the approach
  - Quick check question: What property of TSDF makes it suitable for incremental reconstruction from multiple views?

- Concept: 3D sparse convolutional networks
  - Why needed here: FAWN is implemented as a 3D sparse convolutional module, requiring understanding of how sparse convolutions differ from dense ones and how they handle voxelized 3D data efficiently
  - Quick check question: How does sparse convolution handle empty space differently from dense convolution in voxel grids?

- Concept: Surface normal estimation from TSDF
  - Why needed here: FAWN relies on deriving surface normals from the predicted TSDF to apply regularization, requiring understanding of gradient-based normal computation
  - Quick check question: How are surface normals computed from TSDF values, and why is a frozen convolution layer used for this purpose?

## Architecture Onboarding

- Component map: Backbone (2D CNN for image features) → Back-projection to 3D space → Feature aggregation → TSDF head (3D CNN) + Semantic head (3D sparse U-Net) → Normal estimation (frozen 3D conv) → FAWN losses → Output TSDF volume
- Critical path: RGB images → Backbone → Feature aggregation → TSDF prediction → Normal estimation → FAWN regularization → Final TSDF
- Design tradeoffs: FAWN trades computational overhead during training (additional semantic head and losses) for improved reconstruction quality and completeness, while maintaining inference efficiency since semantics are only needed for training
- Failure signatures: Poor semantic segmentation leading to incorrect normal regularization, over-smoothing of non-planar surfaces, failure to handle architectural features that violate vertical/horizontal assumptions
- First 3 experiments:
  1. Implement FAWN losses without the semantic head using ground truth semantics to isolate the effect of normal regularization
  2. Train with only semantic head and no FAWN losses to verify semantic segmentation capability
  3. Apply FAWN to a simple baseline (like Atlas) before attempting more complex architectures to validate the approach incrementally

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the traditional sense, but several implicit research directions emerge from the limitations and potential extensions discussed:

- The method could be extended to handle ceiling normals and other geometric priors beyond walls and floors
- Performance on scenes with multiple floors or non-standard floor-wall configurations remains unexplored
- The computational overhead during inference, though claimed to be negligible, could be quantified more thoroughly
- The sensitivity to errors in predicted 3D semantics and performance under semantic prediction noise could be analyzed

## Limitations
- The core assumption that walls are vertical and floors are horizontal may not hold in complex architectural scenarios with sloped ceilings or non-rectilinear spaces
- Performance generalization to outdoor environments or scenes with architectural diversity beyond standard indoor layouts is not well-established
- The computational overhead during training is not thoroughly analyzed, and scalability to larger scenes or higher-resolution reconstructions remains unclear

## Confidence
**High Confidence:** The quantitative improvements on benchmark datasets (5-10% accuracy gains, 2-6% completeness improvements) are well-supported by the reported metrics and appear reproducible.

**Medium Confidence:** The mechanism of using semantic-aware normal regularization is theoretically sound, but the specific implementation details and architectural choices could benefit from more thorough ablation studies.

**Low Confidence:** The generalization of the approach to complex architectural features and outdoor environments is not well-established, and the visual quality improvements are primarily demonstrated through qualitative comparisons.

## Next Checks
1. **Architectural Complexity Test:** Evaluate FAWN on scenes with sloped ceilings, curved walls, and other non-rectilinear features to quantify performance degradation when the vertical/horizontal assumption breaks down.

2. **Computational Overhead Analysis:** Measure and compare the training time and memory requirements of FAWN against baseline methods across different scene resolutions and complexities.

3. **Cross-Dataset Generalization:** Test FAWN on outdoor datasets or datasets with architectural diversity beyond the indoor-focused benchmarks used in the paper to assess real-world applicability.