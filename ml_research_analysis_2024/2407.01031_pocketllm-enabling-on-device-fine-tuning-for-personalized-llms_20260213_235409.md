---
ver: rpa2
title: 'PocketLLM: Enabling On-Device Fine-Tuning for Personalized LLMs'
arxiv_id: '2407.01031'
source_url: https://arxiv.org/abs/2407.01031
tags:
- fine-tuning
- mobile
- memory
- devices
- mezo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of on-device fine-tuning of large
  language models (LLMs) on resource-constrained mobile devices, particularly smartphones,
  while maintaining data privacy. The key issue is the high memory demand of traditional
  derivative-based optimization methods used in fine-tuning, which requires storing
  gradients and optimizer states.
---

# PocketLLM: Enabling On-Device Fine-Tuning for Personalized LLMs

## Quick Facts
- arXiv ID: 2407.01031
- Source URL: https://arxiv.org/abs/2407.01031
- Reference count: 2
- Key outcome: Successfully demonstrated on-device LLM fine-tuning on smartphone using derivative-free optimization, reducing memory usage from >12GB (out-of-memory) to 4-6.5GB

## Executive Summary
This paper addresses the challenge of fine-tuning large language models (LLMs) on resource-constrained mobile devices while preserving data privacy. Traditional derivative-based optimization methods require storing gradients and optimizer states, making them impractical for on-device fine-tuning due to high memory demands. The authors propose using derivative-free optimization techniques, specifically the memory-efficient zeroth-order optimization method MeZo, which eliminates the need to compute and store gradients. The approach is validated on an OPPO Reno 6 smartphone, successfully fine-tuning RoBERTa-large using approximately 4GB of memory and OPT-1.3B using around 6.5GB, compared to out-of-memory failures when using traditional Adam optimizer.

## Method Summary
The method employs derivative-free optimization, specifically the MeZo (memory-efficient zeroth-order) optimization technique, to enable on-device fine-tuning of LLMs. Unlike traditional gradient-based methods that require storing both model parameters and their corresponding gradients and optimizer states, MeZo uses a zeroth-order gradient estimator that approximates gradients through function evaluations rather than backpropagation. This approach only requires storing parameter values and loss evaluations during optimization. The method was implemented on an OPPO Reno 6 smartphone using Termux to simulate a Linux environment, fine-tuning RoBERTa-large on the SST-2 dataset and OPT-1.3B on SuperGLUE tasks, with comprehensive memory usage monitoring.

## Key Results
- Successfully fine-tuned RoBERTa-large on SST-2 using approximately 4GB memory on smartphone
- Fine-tuned OPT-1.3B on SuperGLUE tasks using around 6.5GB memory on the same device
- Traditional Adam optimizer caused out-of-memory crashes for both models on the same hardware
- MeZo's memory usage remains stable across different batch sizes, unlike Adam which shows dramatic increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Derivative-free optimization eliminates the need to store gradients and optimizer states, significantly reducing memory consumption during fine-tuning.
- Mechanism: Traditional derivative-based fine-tuning methods (like Adam) require storing both model parameters and their corresponding gradients and optimizer states. Derivative-free methods like MeZo bypass gradient computation entirely, only storing parameter values during optimization.
- Core assumption: The optimization process can converge without explicit gradient information, and the memory saved by avoiding gradient storage outweighs any potential efficiency loss.
- Evidence anchors:
  - [abstract]: "derivative-free optimization techniques to enable on-device fine-tuning of LLM, even on memory-limited mobile devices"
  - [section 3.3]: "derivative-free optimization to locally fine-tune LLMs on mobile devices, mitigating the memory-intensive nature of traditional derivative-based optimization"
  - [corpus]: Weak - the corpus contains related papers on on-device fine-tuning but doesn't directly validate the memory reduction claim for derivative-free methods

### Mechanism 2
- Claim: MeZo's zeroth-order gradient estimation enables effective fine-tuning with minimal memory overhead on resource-constrained devices.
- Mechanism: MeZo uses a zeroth-order gradient estimator that approximates gradients through function evaluations rather than backpropagation, requiring only parameter values and loss evaluations during optimization.
- Core assumption: Zeroth-order gradient estimates are sufficiently accurate for fine-tuning convergence, and the computational overhead of multiple function evaluations is acceptable on mobile hardware.
- Evidence anchors:
  - [abstract]: "memory-efficient zeroth-order optimization method called MeZo"
  - [section 4.1]: "Results show MeZo can fine-tune RoBERTa-large and OPT-1.3B using approximately 4GB and 6.5GB of memory, respectively"
  - [corpus]: Weak - corpus papers mention memory-efficient techniques but don't specifically validate MeZo's zeroth-order approach

### Mechanism 3
- Claim: The memory efficiency of derivative-free optimization scales better with batch size compared to derivative-based methods.
- Mechanism: In derivative-based methods, activation memory grows linearly with batch size for gradient computation, while derivative-free methods like MeZo don't require saving activations for gradient calculation.
- Core assumption: The forward pass computations in derivative-free methods can be managed within memory constraints even as batch size increases.
- Evidence anchors:
  - [section 4.3]: "MeZo's memory usage does not significantly increase with batch size, whereas Adam fine-tuning shows a dramatic increase"
  - [section 4.3]: "activation needs to be saved for gradient computation, and activation linearly increases with batch size"
  - [corpus]: Weak - corpus contains related work on memory-efficient fine-tuning but doesn't specifically address batch size scaling differences

## Foundational Learning

- Concept: Memory hierarchy and constraints in mobile devices
  - Why needed here: Understanding the limited RAM available on smartphones (4-12GB) compared to GPUs (16-48GB+) is crucial for appreciating why traditional fine-tuning methods fail on mobile devices
  - Quick check question: Why does fine-tuning a 1.3B parameter model require more memory than a smaller model, even before considering gradients?

- Concept: Difference between zeroth-order and first-order optimization
  - Why needed here: The core innovation relies on replacing gradient-based optimization with gradient-free methods, requiring understanding of how these fundamentally different approaches work
  - Quick check question: How does a zeroth-order method approximate the direction of steepest descent without computing gradients?

- Concept: Trade-offs between memory efficiency and computational efficiency
  - Why needed here: Derivative-free methods reduce memory usage but may require more computational steps, which is a critical consideration for mobile deployment
  - Quick check question: What are the potential bottlenecks when using derivative-free optimization on mobile devices with limited computational power?

## Architecture Onboarding

- Component map: Model parameters → Zeroth-order gradient estimation → Parameter update → Loss evaluation → Memory check → Next iteration
- Critical path: Model parameters → Zeroth-order gradient estimation → Parameter update → Loss evaluation → Memory check → Next iteration
- Design tradeoffs:
  - Memory vs. convergence speed: Derivative-free methods use less memory but may require more iterations
  - Batch size vs. memory: Larger batches improve statistical efficiency but increase memory pressure differently for derivative-free vs. derivative-based methods
  - Model size vs. feasibility: Larger models require proportionally more memory even with derivative-free methods
- Failure signatures:
  - Out-of-memory crashes (especially when switching from derivative-free to derivative-based methods)
  - Non-converging loss curves (indicating zeroth-order gradient estimates may be too noisy)
  - Excessive wall-clock time per step (suggesting hardware parallelization limitations)
- First 3 experiments:
  1. Run MeZo fine-tuning with batch size 8 on RoBERTa-large and monitor memory usage at each step
  2. Increase batch size to 64 and verify memory usage remains stable while Adam fails with OOM
  3. Compare convergence speed (loss reduction per step) between MeZo and Adam on the same hardware

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the memory footprint of on-device LLM fine-tuning be further reduced to meet the typical 1GB constraint for mobile applications?
- Basis in paper: [explicit] The paper mentions that the current memory requirements (4GB for RoBERTa-large and 6.5GB for OPT-1.3B) are too high for typical mobile applications.
- Why unresolved: The paper identifies this as a limitation but does not provide specific solutions for further reducing memory usage.
- What evidence would resolve it: Development and demonstration of techniques that can reduce memory usage to below 1GB while maintaining model performance.

### Open Question 2
- Question: Can derivative-free optimization methods be further optimized to achieve faster convergence compared to derivative-based methods?
- Basis in paper: [explicit] The paper notes that derivative-free methods are often less efficient in determining the optimization direction compared to derivative-based methods.
- Why unresolved: The paper highlights this as a limitation but does not propose or test new methods to improve the efficiency of derivative-free optimization.
- What evidence would resolve it: Development and experimental validation of new derivative-free optimization techniques that achieve faster convergence rates.

### Open Question 3
- Question: How can derivative-free methods be adapted to fully leverage the hardware capabilities of modern mobile devices, such as GPUs and NPUs?
- Basis in paper: [explicit] The paper discusses the underutilization of hardware capabilities in current implementations of derivative-free methods on mobile devices.
- Why unresolved: The paper identifies this as a limitation but does not provide specific strategies for hardware adaptation.
- What evidence would resolve it: Implementation and testing of derivative-free methods optimized for mobile hardware, demonstrating improved performance and efficiency.

### Open Question 4
- Question: What are the practical challenges and solutions for deploying on-device fine-tuning algorithms within native Android applications?
- Basis in paper: [explicit] The paper mentions that the current implementation using Termux does not accurately reflect performance in a real mobile environment and suggests developing native applications.
- Why unresolved: The paper identifies this as a limitation but does not provide a detailed exploration of the challenges and solutions for native deployment.
- What evidence would resolve it: Successful deployment of on-device fine-tuning algorithms within native Android applications, with performance metrics and user experience evaluations.

## Limitations

- The paper lacks comprehensive wall-clock time comparisons between MeZo and traditional fine-tuning methods, which is crucial given that derivative-free methods typically require multiple function evaluations per optimization step.
- Empirical validation is limited to a single smartphone model (OPPO Reno 6) and only two model architectures, without exploring scalability to different device classes or model types.
- The paper doesn't thoroughly characterize convergence properties or final model quality compared to traditional fine-tuning methods when both successfully converge.

## Confidence

**High Confidence:** The core claim that derivative-free optimization reduces memory usage for LLM fine-tuning on mobile devices is well-supported by the empirical results showing successful fine-tuning with 4GB (RoBERTa-large) and 6.5GB (OPT-1.3B) memory usage, compared to OOM failures with Adam.

**Medium Confidence:** The mechanism by which zeroth-order optimization enables memory efficiency is theoretically sound, but the practical implications for training speed and convergence quality require more thorough validation across different scenarios and hardware configurations.

**Low Confidence:** Claims about the scalability of this approach to other model architectures, device types, and real-world personalization scenarios are largely speculative without additional empirical evidence.

## Next Checks

1. **Runtime Performance Analysis:** Conduct comprehensive wall-clock time measurements comparing MeZo to Adam across different batch sizes and model scales to quantify the computational overhead of derivative-free optimization on mobile hardware.

2. **Convergence Quality Evaluation:** Perform detailed comparisons of final model quality (accuracy, perplexity, etc.) between MeZo and traditional fine-tuning methods when both successfully converge, to assess any trade-offs between memory efficiency and model performance.

3. **Hardware Diversity Testing:** Validate the approach on a range of mobile devices with different memory configurations (4GB, 8GB, 12GB RAM) and computational capabilities to establish the minimum hardware requirements and scalability boundaries.