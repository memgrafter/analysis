---
ver: rpa2
title: 'DeepVoting: Learning and Fine-Tuning Voting Rules with Canonical Embeddings'
arxiv_id: '2408.13630'
source_url: https://arxiv.org/abs/2408.13630
tags:
- rules
- rule
- loss
- embedding
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work demonstrates that using canonical embeddings from social\
  \ choice theory enables more efficient learning of voting rules via neural networks\
  \ compared to prior methods. By mapping preference profiles to fixed-size embeddings\u2014\
  such as tournament, weighted tournament, and rank frequency matrices\u2014the approach\
  \ reduces input dimensionality, allowing simpler architectures to learn complex\
  \ rules faster and with fewer parameters."
---

# DeepVoting: Learning and Fine-Tuning Voting Rules with Canonical Embeddings

## Quick Facts
- arXiv ID: 2408.13630
- Source URL: https://arxiv.org/abs/2408.13630
- Reference count: 21
- Primary result: Canonical embeddings from social choice theory enable more efficient learning of voting rules via neural networks, reducing input dimensionality and allowing simpler architectures to learn complex rules faster with fewer parameters.

## Executive Summary
This work demonstrates that using canonical embeddings from social choice theory enables more efficient learning of voting rules via neural networks compared to prior methods. By mapping preference profiles to fixed-size embeddings—such as tournament, weighted tournament, and rank frequency matrices—the approach reduces input dimensionality, allowing simpler architectures to learn complex rules faster and with fewer parameters. Experiments show that rule-embedding compatibility is critical: for example, Copeland learns perfectly from tournament embeddings, while Plurality benefits from rank frequency encoding. The learned probabilistic social choice functions generalize well beyond the training distribution and can be fine-tuned to satisfy inter-profile axioms like the No Show Paradox, significantly reducing vulnerability to strategic abstention with minimal loss in accuracy. This establishes embeddings as a key enabler for learning and improving voting rules, offering a scalable, axiom-aware alternative to hand-designed mechanisms.

## Method Summary
The method maps preference profiles to canonical embeddings (tournament, weighted tournament, rank frequency matrices) that reduce input dimensionality from O(mn) to O(m²). Neural networks with 5 fully-connected layers (200, 120, 120, 120 nodes) and TanH activation learn probabilistic social choice functions by minimizing L1 loss between predicted and target voting rule outputs. The approach uses transfer learning to fine-tune learned rules with axiomatic properties, combining rule loss with axiom satisfaction loss (e.g., stochastic dominance for No Show Paradox resistance). Training uses Adam optimizer with learning rate 0.001 and early stopping, while fine-tuning employs smaller datasets and combined loss functions.

## Key Results
- Rule-embedding compatibility is critical: Copeland learns perfectly from tournament embeddings while Plurality benefits from rank frequency encoding.
- Canonical embeddings reduce input dimensionality from O(mn) to O(m²), enabling simpler neural networks to learn complex rules faster with fewer parameters.
- Fine-tuned rules resist No Show Paradox with minimal accuracy loss, demonstrating the approach's ability to create axiom-aware voting mechanisms.

## Why This Works (Mechanism)

### Mechanism 1
Canonical embeddings reduce input dimensionality while preserving sufficient information for learning specific voting rules. By mapping preference profiles to fixed-size matrices (e.g., tournament, weighted tournament, rank frequency), the approach reduces the input size from O(mn) to O(m²), enabling simpler neural networks to learn rules faster with fewer parameters. The core assumption is that the chosen embedding preserves all information necessary to compute the target voting rule exactly. Evidence shows tournament embeddings preserve Copeland perfectly while rank frequency embeddings better preserve positional rules. Break condition occurs when embeddings lose critical information needed for the target rule, causing learning accuracy to degrade or plateau.

### Mechanism 2
Rule-embedding compatibility is critical for efficient learning and generalization. Different embeddings preserve different aspects of preference profiles—tournament embeddings capture pairwise comparisons well while rank frequency encodings preserve positional information. For example, Copeland learns perfectly from tournament embeddings while Plurality benefits from rank frequency encoding. Choosing the right embedding-rule pair enables faster convergence and better generalization to out-of-distribution data. The relationship between what information an embedding preserves and what information a rule requires is deterministic and exploitable for efficient learning. Break condition occurs when embeddings lack sufficient information for a rule, causing learning to plateau at non-zero loss.

### Mechanism 3
Fine-tuning with axiomatic properties enables learning novel rules with improved strategic resistance. Transfer learning allows adding inter-profile axioms like Participation (No Show Paradox resistance) to learned PSCFs by retraining with a combined loss function that includes both rule accuracy and axiom satisfaction. This creates rules that are both accurate and resistant to strategic abstention. The core assumption is that learned neural network representations contain sufficient flexibility to accommodate additional axiomatic constraints without catastrophic forgetting. Evidence shows fine-tuned rules maintain low rule loss while significantly reducing participation loss. Break condition occurs when combined loss functions create conflicting gradients or networks lack capacity to satisfy both rule accuracy and axiom constraints simultaneously.

## Foundational Learning

- Preference profiles and probabilistic social choice functions: Understanding how voter preferences are represented and how collective decisions are made is fundamental to grasping the problem space and solution approach. Quick check: What is the difference between a deterministic voting rule and a probabilistic social choice function?

- Embeddings and information preservation: The core innovation relies on understanding how different embeddings compress preference information and which ones preserve what's needed for specific rules. Quick check: Why can't all embeddings preserve all information about the original preference profile?

- Loss functions and optimization in neural networks: The paper uses L1 loss for rule learning and combines it with stochastic dominance loss for axiom satisfaction, requiring understanding of how neural networks are trained. Quick check: How does adding an axiom-based loss term during fine-tuning affect the learned voting rule?

## Architecture Onboarding

- Component map: Profile generation → Embedding creation (m² nodes) → MLP layers (200→120→120→120→120) with TanH → Softmax output → Loss calculation → Backpropagation

- Critical path: 1) Profile generation and embedding creation 2) Forward pass through neural network 3) Loss calculation (rule loss + axiom loss during fine-tuning) 4) Backpropagation and parameter update 5) Validation and testing on held-out data

- Design tradeoffs: Smaller embeddings (m²) vs. larger ones (nm²) trade-off between input size and information preservation; TanH vs. ReLU activation (TanH showed better convergence); Fixed architecture vs. adaptive (fixed size enables testing across voter counts); Rule-only vs. axiom-aware training (trade-off between pure accuracy and strategic resistance)

- Failure signatures: Loss plateaus at non-zero value (indicates embedding lacks sufficient information); Poor generalization to out-of-distribution data (suggests overfitting); Fine-tuning causes large accuracy drop (indicates conflict between rule accuracy and axiom satisfaction); Slow convergence (may indicate poor embedding-rule pairing)

- First 3 experiments: 1) Test learning Copeland rule with tournament embedding (should converge to near-zero loss quickly) 2) Test learning Plurality rule with weighted tournament embedding (should plateau at non-zero loss) 3) Fine-tune a learned Borda rule to resist No Show Paradox (should maintain low rule loss while reducing participation loss)

## Open Questions the Paper Calls Out

- Can weighted tournament embeddings preserve Black's Rule under all preference profile conditions? The paper notes that Black's Rule is not preserved by rank frequency or tournament embeddings and poses this as a challenge for weighted tournament embeddings. A formal proof or counterexample would resolve this.

- Can embeddings be designed with size m×m or smaller that outperform standard social choice embeddings for learning specific voting rules? The paper suggests it remains open whether better embeddings could be designed, as it only tests existing embeddings from social choice theory. Empirical comparison showing a newly designed embedding achieves lower loss would resolve this.

- How do learned voting rules generalize to real-world preference data compared to synthetic distributions like Impartial Culture or Mallows? The paper tests generalization to multiple synthetic distributions and PrefLib real-world data but focuses on loss metrics without deep analysis of real-world performance differences. Detailed comparative analysis linking rule performance to specific features of real-world preference profiles would resolve this.

## Limitations

- Reliance on Impartial Culture distributions for training data raises questions about performance under real-world preference distributions with correlated voter preferences.
- Fixed embedding sizes (m²) may become inefficient for very large candidate sets, and analysis focuses primarily on positional scoring rules and Copeland.
- Fine-tuning approach shows promise for adding axiom resistance but requires additional training data and careful hyperparameter tuning to balance rule accuracy against axiom satisfaction.

## Confidence

**High confidence**: Core claims about embedding-rule compatibility and dimensionality reduction are well-supported by experimental results showing zero-loss convergence for compatible pairs and non-zero plateaus for incompatible pairs.

**Medium confidence**: Fine-tuning approach for axiom resistance shows empirical success but relies on limited testing scenarios. Claim that embeddings enable "simpler architectures" is supported but could benefit from broader architectural comparisons.

**Low confidence**: Claims about generalization to out-of-distribution profiles and scalability to larger elections remain untested beyond the reported experimental setup.

## Next Checks

1. **Distribution sensitivity test**: Evaluate learned rules on preference profiles generated from correlated voter models (e.g., Mallows model) rather than Impartial Culture to assess real-world robustness.

2. **Scaling experiment**: Test the approach with larger candidate sets (m > 11) to verify whether the m² embedding dimensionality remains effective or becomes a bottleneck.

3. **Axiomatic generalization test**: Fine-tune rules to resist multiple axioms simultaneously (e.g., both Participation and Consistency) to evaluate whether the approach scales to complex multi-axiom requirements.