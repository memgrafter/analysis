---
ver: rpa2
title: Compressing Deep Reinforcement Learning Networks with a Dynamic Structured
  Pruning Method for Autonomous Driving
arxiv_id: '2402.05146'
source_url: https://arxiv.org/abs/2402.05146
tags:
- pruning
- ratio
- neurons
- network
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a dynamic structured pruning method for compressing
  deep reinforcement learning (DRL) models used in autonomous driving. The method
  trains DRL models with a neuron-importance group sparse regularizer and removes
  unimportant neurons using a dynamic pruning threshold.
---

# Compressing Deep Reinforcement Learning Networks with a Dynamic Structured Pruning Method for Autonomous Driving

## Quick Facts
- arXiv ID: 2402.05146
- Source URL: https://arxiv.org/abs/2402.05146
- Reference count: 40
- Key outcome: Achieves 93% neuron and 96% weight reduction while maintaining performance on four DRL environments

## Executive Summary
This paper introduces a dynamic structured pruning method for compressing deep reinforcement learning models used in autonomous driving. The approach trains DRL models with a neuron-importance group sparse regularizer and removes unimportant neurons using a dynamic pruning threshold. This method achieves high compression ratios while maintaining performance, outperforming existing pruning techniques in both compression and ability to preserve network performance.

## Method Summary
The proposed method uses a two-step process: first, DRL models are trained with a neuron-importance group sparse regularizer that penalizes redundant groups of neurons; second, a dynamic pruning strategy determines the pruning threshold based on neuron importance coefficient and training episodes. The approach combines both input and output weight information to calculate neuron importance, then uses binary masks to remove unimportant neurons during training. The method is applied to PPO-based DRL models in autonomous driving environments.

## Key Results
- Reduces 93% of neurons and 96% of weights across four challenging DRL environments
- Maintains or slightly degrades performance while achieving significant compression
- Outperforms existing pruning techniques in terms of both compression ratio and performance preservation
- Achieves an average reward of 509.28 on CartPole-v1 after compression

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic structured pruning reduces neuron count without destroying model accuracy by using a neuron-importance group sparse regularizer during training.
- Mechanism: The neuron-importance group sparse regularizer penalizes redundant groups of neurons by measuring the combined importance of incoming and outgoing weights. Neurons with low importance are gradually masked out using a dynamically adjusted threshold.
- Core assumption: The importance of a neuron can be effectively captured by summing the squared weights of its incoming and outgoing connections, and this measure correlates with its contribution to model performance.

### Mechanism 2
- Claim: Dynamic pruning thresholds allow gradual, adaptive removal of unimportant neurons during training, balancing compression and performance.
- Mechanism: The pruning threshold is calculated based on the number of training episodes and a coefficient of neuron importance. As training progresses, the threshold increases, allowing more neurons to be pruned. This avoids abrupt removal that could destabilize training.
- Core assumption: A dynamic threshold can be learned that correlates with the decreasing importance of neurons over training time, enabling safe removal without performance collapse.

### Mechanism 3
- Claim: Structured pruning (removing entire neurons) is more effective than unstructured pruning for DRL model compression on resource-limited devices.
- Mechanism: By removing entire neurons rather than individual weights, structured pruning creates a dense network architecture that can be directly deployed on hardware accelerators. This avoids the irregular sparsity patterns of unstructured pruning that are difficult to accelerate.
- Core assumption: Hardware accelerators can efficiently execute dense operations on pruned networks, whereas sparse operations on unstructured pruned networks incur significant overhead.

## Foundational Learning

- Concept: Markov Decision Process (MDP)
  - Why needed here: The DRL model is trained to solve MDPs in autonomous driving environments, so understanding states, actions, rewards, and transitions is fundamental.
  - Quick check question: What are the four components of an MDP?

- Concept: Proximal Policy Optimization (PPO)
  - Why needed here: The pruning method is applied to PPO, a state-of-the-art DRL algorithm. Understanding PPO's objective and update rules is necessary to implement the pruning correctly.
  - Quick check question: How does PPO's clipped objective function prevent large policy updates?

- Concept: Regularization and Sparsity
  - Why needed here: The neuron-importance group sparse regularizer uses regularization to encourage sparsity in the network. Understanding how regularization affects model parameters is key to tuning the pruning method.
  - Quick check question: What is the difference between L1 and group L1 regularization?

## Architecture Onboarding

- Component map:
  Actor network -> Neuron-importance group sparse regularizer -> Dynamic pruning threshold -> Binary mask -> Critic network

- Critical path:
  1. Initialize DRL model with actor and critic networks
  2. For each training episode:
     a. Compute neuron importance for each neuron
     b. Calculate dynamic pruning threshold
     c. Update binary masks to prune unimportant neurons
     d. Update actor and critic network parameters
     e. Reconstruct compact DRL model

- Design tradeoffs:
  - Regularization strength vs. model accuracy: Higher regularization leads to more compression but may degrade performance
  - Pruning frequency vs. stability: More frequent pruning allows for finer-grained compression but may destabilize training
  - Neuron importance metric vs. computational cost: More sophisticated metrics may better identify unimportant neurons but are more expensive to compute

- Failure signatures:
  - Accuracy drops sharply after pruning: Threshold is too aggressive or neuron importance metric is inaccurate
  - Compression ratio is low: Regularization is too weak or pruning is too conservative
  - Training instability: Pruning is too frequent or network reconstruction is not handled properly

- First 3 experiments:
  1. Train PPO without pruning on a simple environment (e.g., CartPole) to establish baseline performance
  2. Apply static structured pruning to PPO and compare compression and accuracy to baseline
  3. Apply dynamic structured pruning with neuron-importance group sparse regularizer and compare to static pruning and baseline

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the content, several important questions remain:

1. How does the proposed dynamic structured pruning method perform on even larger and more complex DRL environments, such as those with high-dimensional state spaces or multi-agent scenarios?
2. What is the impact of the proposed method on the training time and computational resources required for DRL models, especially in comparison to other pruning techniques?
3. How does the proposed dynamic structured pruning method affect the interpretability and explainability of the DRL model's decision-making process?

## Limitations
- Method effectiveness is demonstrated primarily on standard OpenAI Gym environments rather than complex real-world autonomous driving scenarios
- Pruning approach assumes neuron importance can be accurately measured by summing squared weights, which may not capture all aspects of contribution to performance
- Dynamic threshold calculation requires careful hyperparameter tuning (λ, pi, pf) that is not fully specified

## Confidence

- **High**: The theoretical foundation of structured pruning and its benefits for hardware acceleration
- **Medium**: The effectiveness of the neuron-importance group sparse regularizer in identifying unimportant neurons
- **Medium**: The ability of dynamic pruning thresholds to balance compression and performance

## Next Checks

1. Test the pruning method on a more complex autonomous driving simulator (e.g., CARLA) to assess real-world applicability
2. Conduct ablation studies to determine the sensitivity of results to hyperparameter choices (λ, pi, pf)
3. Compare the compressed models' inference speed and energy consumption on actual edge devices to quantify practical benefits