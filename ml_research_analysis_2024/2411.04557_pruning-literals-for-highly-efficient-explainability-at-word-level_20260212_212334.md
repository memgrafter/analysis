---
ver: rpa2
title: Pruning Literals for Highly Efficient Explainability at Word Level
arxiv_id: '2411.04557'
source_url: https://arxiv.org/abs/2411.04557
tags:
- literals
- clause
- attention
- pruning
- pruned
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving interpretability
  in Tsetlin Machines (TM) for text classification by reducing the complexity of propositional
  logic clauses. The authors propose a post-hoc pruning method that removes randomly
  placed literals in clauses based on their frequency of occurrence.
---

# Pruning Literals for Highly Efficient Explainability at Word Level

## Quick Facts
- arXiv ID: 2411.04557
- Source URL: https://arxiv.org/abs/2411.04557
- Authors: Rohan Kumar Yadav; Bimal Bhattarai; Abhik Jana; Lei Jiao; Seid Muhie Yimam
- Reference count: 26
- Key outcome: Post-hoc pruning method removes infrequent literals from Tsetlin Machine clauses, improving interpretability and sometimes accuracy without significant performance loss

## Executive Summary
This paper addresses the challenge of improving interpretability in Tsetlin Machines (TM) for text classification by reducing the complexity of propositional logic clauses. The authors propose a post-hoc pruning method that removes randomly placed literals in clauses based on their frequency of occurrence. This pruning process eliminates non-important literals, resulting in shorter and more compact propositional rules that are easier for humans to comprehend while retaining model performance. Experiments on the YELP-HAT dataset show that the pruned TM's attention map aligns more closely with human attention maps compared to the vanilla TM, with improved similarity measures.

## Method Summary
The paper introduces a frequency-based pruning method for Tsetlin Machines that operates post-training. After training a TM on labeled text data, the method calculates the frequency of each literal across all clauses. The least frequent literals (ranging from 5% to 50% depending on the pruning ratio) are identified as non-important and their Tsetlin Automaton states are set to "Exclude", effectively removing them from clause evaluation. This creates shorter, more interpretable propositional rules while maintaining or sometimes improving classification accuracy. The approach is evaluated on the YELP-HAT dataset using comprehensiveness and sufficiency measures to assess explainability, comparing the pruned model's attention maps with human attention maps.

## Key Results
- Pruning literals based on frequency improves alignment between machine-generated attention maps and human attention maps, with similarity measures reaching 0.752
- The pruning method enhances classification accuracy by up to 4% to 9% on some test data without significant degradation in performance
- Pruning 20-30% of literals yields satisfactory results, with diminishing returns or potential accuracy loss beyond this range

## Why This Works (Mechanism)

### Mechanism 1
Infrequent literals are statistically unlikely to carry class-specific signal. By setting their Tsetlin Automaton states to "Exclude", they are removed from clause evaluation, shortening propositional logic. Core assumption: Non-important literals are those with low frequency in clause representation across training epochs.

### Mechanism 2
Shorter clauses after pruning yield attention maps that align more closely with human attention maps. Reduced clause size leads to clearer, more focused feature importance weights. When mapped to an attention vector, these weights correlate better with human rationales because irrelevant features are no longer included.

### Mechanism 3
Pruning can improve classification accuracy by removing literals that introduce noise or contradictory signals. Some randomly placed literals may introduce conflicting evidence in clauses. Their removal can reduce vote cancellation or misclassification, leading to improved net vote scores.

## Foundational Learning

- **Tsetlin Machine propositional logic learning**: Understanding how clauses are built from literals and how Tsetlin Automata control literal inclusion is essential to grasp pruning's effect.
  - Quick check: What is the role of Type I and Type II feedback in deciding whether a literal is included or excluded in a clause?

- **Attention map alignment metrics (comprehensiveness and sufficiency)**: The evaluation relies on comparing machine-generated attention with human attention using these metrics.
  - Quick check: How does comprehensiveness differ from sufficiency when measuring explainability?

- **Frequency-based feature importance**: The pruning method assumes low-frequency literals are less important, so understanding frequency analysis is critical.
  - Quick check: What is a potential downside of using frequency alone to determine literal importance?

## Architecture Onboarding

- **Component map**: Input -> Boolean bag-of-words representation of text -> Core: Tsetlin Machine with clauses and Tsetlin Automata -> Pruning layer: Post-training frequency analysis and literal exclusion -> Output: Pruned clauses and attention vectors for evaluation

- **Critical path**: 1) Train TM on labeled data, 2) Extract clauses and literal frequencies, 3) Identify and exclude low-frequency literals, 4) Generate pruned attention vectors, 5) Compare with human attention using similarity metrics

- **Design tradeoffs**: Pruning ratio: More pruning improves interpretability but risks losing accuracy; Frequency threshold: Needs tuning per dataset; Post-hoc vs. integrated pruning: This method is post-hoc, easier to implement but less adaptive

- **Failure signatures**: Accuracy drops sharply after pruning (too many literals removed); Attention alignment does not improve (pruning did not target right literals); Training instability (frequency calculation or pruning logic has bugs)

- **First 3 experiments**: 1) Train vanilla TM on YELP-HAT and extract baseline attention maps, 2) Apply 5% pruning and compare accuracy and attention alignment, 3) Sweep pruning percentage from 5% to 40% and plot accuracy vs. similarity curves

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal percentage of literals to prune in a Tsetlin Machine to maximize both explainability and accuracy across different text classification tasks and datasets? The paper mentions that pruning 20% to 30% of literals yields satisfactory results, but acknowledges that the optimal proportion varies based on the task and dataset.

### Open Question 2
How does the pruning method affect the long-term learning and generalization capabilities of the Tsetlin Machine on evolving or streaming data? The paper focuses on post-hoc pruning after model training and evaluates performance on static test datasets, but does not address dynamic scenarios where data distributions may change over time.

### Open Question 3
Can the pruning technique be extended to handle multi-label or multi-class classification tasks where literals may have different importance levels across classes? The current method prunes literals based on their overall frequency across all classes, without considering class-specific importance.

### Open Question 4
How does the proposed pruning method compare with other interpretability techniques (e.g., feature importance scoring, attention mechanisms) in terms of human comprehension and trust in the model's decisions? While the paper compares similarity measures with human attention maps, it does not directly assess human comprehension or trust through user studies or surveys.

## Limitations

- The pruning method relies on the assumption that infrequent literals are non-important, which may not hold for all text classification tasks
- The approach is post-hoc and may not generalize to other datasets or TM configurations
- The paper does not provide a detailed analysis of how the pruning method affects the learned patterns in the clauses or the potential for information loss

## Confidence

- High confidence: The pruning method's ability to reduce clause complexity and improve interpretability by removing non-important literals based on frequency
- Medium confidence: The claim that the pruned TM's attention map aligns more closely with human attention maps compared to the vanilla TM, as the evaluation is based on a single dataset
- Low confidence: The assertion that pruning can enhance classification accuracy by up to 4% to 9%, as the improvement is not consistently observed across all test data

## Next Checks

1. Test the pruning method on additional text classification datasets to assess its generalizability and robustness to different data distributions and task complexities
2. Analyze the impact of pruning on the learned patterns in the clauses by comparing the feature importance scores and the distribution of literals before and after pruning
3. Conduct an ablation study to determine the optimal pruning percentage and frequency threshold for balancing interpretability and performance across different TM configurations and datasets