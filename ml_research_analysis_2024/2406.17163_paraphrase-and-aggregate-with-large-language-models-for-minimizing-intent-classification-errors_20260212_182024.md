---
ver: rpa2
title: Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification
  Errors
arxiv_id: '2406.17163'
source_url: https://arxiv.org/abs/2406.17163
tags:
- classification
- pag-llm
- intent
- clinc
- request
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of minimizing intent classification
  errors in large language models (LLMs) for multi-class classification tasks. The
  authors propose the Paraphrase and Aggregate with Large Language Models (PAG-LLM)
  approach to reduce misclassification and hallucinated label generation errors.
---

# Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors

## Quick Facts
- arXiv ID: 2406.17163
- Source URL: https://arxiv.org/abs/2406.17163
- Reference count: 8
- This paper introduces PAG-LLM, achieving 22.7% error reduction on CLINC and 15.1% on Banking datasets

## Executive Summary
This paper addresses the challenge of minimizing intent classification errors in large language models for multi-class classification tasks. The authors propose the Paraphrase and Aggregate with Large Language Models (PAG-LLM) approach, which generates multiple paraphrases of input queries, performs classification on each variant, and aggregates results based on confidence scores. The method demonstrates significant improvements in intent classification accuracy, particularly for ambiguous queries where the LLM is uncertain.

## Method Summary
PAG-LLM generates multiple paraphrases of input queries using an LLM paraphraser, then classifies the original query and each paraphrase using an LLM classifier. The system aggregates the classification labels based on their confidence scores, with the aggregation performed by another LLM. The approach can be selectively applied to low-confidence classification cases to optimize computational cost. The method is evaluated on CLINC (150 classes) and Banking (77 classes) datasets, demonstrating 22.7% and 15.1% error reduction respectively.

## Key Results
- PAG-LLM reduces error by 22.7% on CLINC dataset and 15.1% on Banking dataset
- The approach is particularly effective for hard examples where the LLM is uncertain
- LLM-based aggregation outperforms simple voting strategies
- Selective application based on confidence thresholds can reduce computational cost while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1
Paraphrasing increases diversity of input representations, helping the LLM classifier handle ambiguous or unclear user queries. When queries are unclear, multiple paraphrases provide varied perspectives of the same intent, allowing the classifier to process each variant separately and potentially achieve more accurate classifications. The aggregation step combines these diverse predictions.

### Mechanism 2
Confidence-based filtering directs computational resources to cases where the LLM is uncertain, improving cost-effectiveness. The system first classifies the original query, and only when confidence falls below a threshold does it invoke the paraphrasing and aggregation pipeline. This selective application reduces inference runs needed while targeting the most error-prone cases.

### Mechanism 3
LLM-based aggregation outperforms simple voting by considering both predicted labels and their confidence scores in context. Rather than majority voting, the aggregation step uses an LLM to process the original query, all paraphrases, their predicted labels, and confidence scores together to produce a final classification, allowing the model to weigh evidence based on confidence and contextual relationships.

## Foundational Learning

- **Multi-class classification with large label spaces (150+ classes)**: Why needed here - The datasets used (CLINC with 150 classes, Banking with 77 classes) represent large-scale intent classification where distinguishing between many similar classes is challenging. Quick check question - What challenges arise when classifying inputs into 150+ intent categories compared to binary classification?

- **Confidence thresholding in classification**: Why needed here - The approach uses confidence scores to decide when to invoke the paraphrasing pipeline, making it essential to understand how confidence relates to classification reliability. Quick check question - How does setting different confidence thresholds affect the trade-off between accuracy improvement and computational cost?

- **Out-of-vocabulary (OOV) label generation**: Why needed here - The paper identifies OOV label generation as a critical error type that PAG-LLM helps address, making understanding this failure mode important. Quick check question - Why might LLMs generate labels that don't exist in the predefined vocabulary, and how does this differ from simple misclassification?

## Architecture Onboarding

- **Component map**: Input Query → LLM Classifier → Confidence Check → (If confidence < τ) → LLM Paraphraser → Multiple Paraphrased Queries → LLM Classifier (x N+1) → LLM Aggregator → Final Classification
- **Critical path**: Input → LLMclassify → (Confidence Check) → (Optional Paraphrasing Pipeline) → LLMaggregate → Output
- **Design tradeoffs**:
  - Number of paraphrases (N): More paraphrases increase diversity but also computational cost
  - Confidence threshold (τ): Higher thresholds reduce computation but may miss some correctable errors
  - Fine-tuning vs. zero-shot: Fine-tuning improves performance but requires labeled data and compute
- **Failure signatures**:
  - System performs worse than baseline: Check if paraphrases preserve intent or if aggregation is working correctly
  - High computational cost: Review confidence threshold and consider reducing number of paraphrases
  - OOV generation persists: Verify paraphrase quality and check if classifier is properly constrained to label vocabulary
- **First 3 experiments**:
  1. Implement the basic pipeline with N=3 paraphrases and τ=0.5 on a small subset of CLINC to verify the core mechanism works
  2. Compare voting vs. LLM aggregation on the same subset to validate the importance of the aggregation component
  3. Test different confidence thresholds (0.7, 0.9, 0.95) on validation data to find optimal balance between performance and computational cost

## Open Questions the Paper Calls Out

### Open Question 1
How does the quality of paraphrases impact the effectiveness of the PAG-LLM approach? The paper mentions experimenting with different paraphrasing datasets but notes that the quality of paraphrases could be further explored. A comprehensive study comparing the performance of PAG-LLM using paraphrases of varying quality would resolve this.

### Open Question 2
Can the PAG-LLM approach be effectively extended to other large language models beyond LLaMa? The paper suggests that PAG-LLM can be applied to any other open LLM and provides GitHub codes for extension, but only demonstrates effectiveness with LLaMa-7B. Experimental results with various other LLMs would resolve this question.

### Open Question 3
What is the impact of the number of paraphrases generated on the performance of PAG-LLM? The paper mentions limiting experiments to 5 paraphrases due to the size of the training dataset but does not explore how generating more or fewer paraphrases affects error reduction and overall performance. A systematic study varying the number of paraphrases would resolve this.

## Limitations

- The method's effectiveness on other domains, smaller label spaces, or different classification tasks remains uncertain
- The approach still requires multiple LLM invocations for each low-confidence query, potentially increasing computational overhead
- The entire approach relies on the quality and relevance of generated paraphrases, which could introduce errors if paraphrases alter the original intent

## Confidence

**High Confidence**: The 22.7% error reduction on CLINC and 15.1% on Banking datasets are well-supported by the experimental results presented.

**Medium Confidence**: The claim that PAG-LLM is particularly effective for hard examples is supported by results but could benefit from more detailed analysis of which types of errors are most improved.

**Medium Confidence**: The assertion that LLM-based aggregation outperforms simple voting is demonstrated but the analysis could be more comprehensive regarding edge cases.

**Low Confidence**: The scalability claims and computational cost analysis are limited, as the paper provides selective application results but doesn't fully explore the trade-offs across different operational scenarios.

## Next Checks

1. **Cross-domain validation**: Test PAG-LLM on at least two additional intent classification datasets from different domains to assess generalization. Compare performance gains across datasets with varying numbers of classes, query types, and error distributions.

2. **Confidence score calibration analysis**: Conduct a thorough analysis of the relationship between confidence scores and actual classification accuracy. Use reliability diagrams and expected calibration error metrics to assess whether confidence scores are well-calibrated and identify potential systematic biases.

3. **Computational cost profiling**: Implement comprehensive profiling of the PAG-LLM pipeline across different confidence thresholds and paraphrase counts. Measure total inference time, token costs, and identify the optimal balance point between performance gains and computational overhead for practical deployment scenarios.