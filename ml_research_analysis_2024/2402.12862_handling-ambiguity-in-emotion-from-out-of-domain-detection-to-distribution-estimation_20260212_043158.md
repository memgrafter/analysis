---
ver: rpa2
title: 'Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution
  Estimation'
arxiv_id: '2402.12862'
source_url: https://arxiv.org/abs/2402.12862
tags:
- emotion
- distribution
- uncertainty
- class
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of handling ambiguous emotion
  in speech by developing methods to detect and represent utterances with inconsistent
  human annotations. It shows that including such utterances as an additional class
  degrades classification performance.
---

# Handling Ambiguity in Emotion: From Out-of-Domain Detection to Distribution Estimation

## Quick Facts
- arXiv ID: 2402.12862
- Source URL: https://arxiv.org/abs/2402.12862
- Reference count: 40
- Primary result: Evidential deep learning effectively detects ambiguous emotions and enables emotion distribution estimation, outperforming baseline methods

## Executive Summary
This paper addresses the challenge of handling ambiguous emotion in speech by developing methods to detect and represent utterances with inconsistent human annotations. It shows that including such utterances as an additional class degrades classification performance. Instead, it proposes detecting ambiguous emotions as out-of-domain samples using evidential deep learning (EDL) to quantify classification uncertainty. To capture fine-grained distinctions among ambiguous emotions, the paper reframes emotion recognition as distribution estimation rather than classification, leveraging all human annotations rather than majority voting. Experiments on IEMOCAP and CREMA-D datasets demonstrate superior performance in majority class prediction, emotion distribution estimation, and uncertainty estimation compared to baselines.

## Method Summary
The method employs evidential deep learning to detect ambiguous emotions as out-of-domain samples and estimate emotion distributions. For classification, it uses a Dirichlet distribution to model uncertainty, with higher uncertainty indicating potential OOD samples. For distribution estimation, it reframes the task to predict the underlying emotion distribution based on all human annotations, using a modified EDL framework with regularization terms. The approach is evaluated on IEMOCAP and CREMA-D datasets, comparing EDL-based methods against softmax classification and other uncertainty quantification baselines.

## Key Results
- EDL-based OOD detection successfully identifies ambiguous utterances while maintaining classification accuracy
- Distribution estimation approach provides more comprehensive emotion representations than majority voting
- Proposed method achieves superior performance in majority class prediction, emotion distribution estimation, and uncertainty quantification compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Evidential deep learning (EDL) models uncertainty in emotion classification by placing a second-order probability over the categorical distribution.
- Mechanism: The model predicts a Dirichlet distribution over class probabilities, where the Dirichlet's concentration parameters (α) represent evidence for each class. Higher uncertainty (lower α₀) indicates the sample may be out-of-domain (OOD).
- Core assumption: The emotional content of ambiguous utterances can be represented as a mixture of multiple classes rather than a single label.
- Evidence anchors:
  - [abstract] "proposes detecting utterances with ambiguous emotions as out-of-domain samples by quantifying the uncertainty in emotion classification using evidential deep learning"
  - [section 3.2] "To model the probability of the predictive distribution, we assume the categorical distribution is sampled from a Dirichlet distribution"
  - [corpus] Weak - no direct citations, but related work on uncertainty quantification in NLP exists (e.g., "The Illusion of Certainty: Uncertainty Quantification for LLMs Fails under Ambiguity")
- Break condition: If the Dirichlet assumption doesn't hold (e.g., if emotional content doesn't follow a multinomial distribution), uncertainty estimates may be unreliable.

### Mechanism 2
- Claim: Reframing emotion recognition as distribution estimation provides a more comprehensive representation of ambiguous emotions.
- Mechanism: Instead of predicting a single majority class, the model estimates the underlying emotion distribution (η) based on all human annotations. This is achieved by maximizing the marginal likelihood of observing all annotations given the predicted Dirichlet prior.
- Core assumption: The true emotion distribution can be inferred from multiple noisy annotations, and this distribution provides a better representation than majority voting.
- Evidence anchors:
  - [abstract] "proposing representing emotion as a distribution instead of a single class label"
  - [section 4] "Assume {ym}M m=1 are samples drawn from a multinomial distribution"
  - [corpus] Weak - related work exists ("Emotions as Ambiguity-aware Ordinal Representations") but not directly cited
- Break condition: If human annotations are systematically biased or inconsistent beyond random noise, the estimated distribution may not reflect true emotional content.

### Mechanism 3
- Claim: The extended EDL framework quantifies uncertainty in emotion distribution estimation.
- Mechanism: The same Dirichlet-based approach is applied to distribution estimation, with modified regularization terms that penalize deviation from the observed soft labels or predicted multinomial distribution.
- Core assumption: The same uncertainty quantification method (Dirichlet evidence) can be extended from classification to distribution estimation.
- Evidence anchors:
  - [abstract] "The evidential uncertainty measure is extended to quantify the uncertainty in emotion distribution estimation"
  - [section 4] "we verify that LNLL in Eqn. (11) can be generalised to the distribution estimation framework by replacing one-hot majority label y with ˆy"
  - [corpus] Weak - no direct citations for this specific extension
- Break condition: If the relationship between evidence and uncertainty differs between classification and distribution estimation, the extension may not be valid.

## Foundational Learning

- Concept: Dirichlet distribution as conjugate prior for categorical/multinomial
  - Why needed here: It provides a tractable way to model uncertainty over probability distributions, which is essential for both classification and distribution estimation
  - Quick check question: What is the relationship between Dirichlet concentration parameters (α) and belief masses in Dempster-Shafer theory?

- Concept: Maximum likelihood estimation vs. Bayesian approaches
  - Why needed here: The paper contrasts "soft labels" (MLE) with the proposed distribution estimation approach, showing that MLE may not provide accurate approximations with limited annotations
  - Quick check question: Why might maximum likelihood estimates be insufficient when dealing with ambiguous emotions and limited annotations?

- Concept: Model calibration and expected calibration error (ECE)
  - Why needed here: The paper evaluates model calibration to ensure that predicted uncertainties are reliable, not just accurate
  - Quick check question: How does ECE measure the discrepancy between predicted confidence and actual accuracy?

## Architecture Onboarding

- Component map: Frozen USM (Universal Speech Model) -> Conformer-based encoder -> Mean pooling -> Fully-connected layer -> ReLU activation -> Evidence vector -> Dirichlet parameters -> Uncertainty scores
- Critical path: Feature extraction → evidence prediction → Dirichlet parameter calculation → uncertainty quantification
- Design tradeoffs:
  - Classification vs. distribution estimation: Simpler but less informative vs. more complex but captures ambiguity
  - ReLU vs. other activations: Ensures non-negative evidence but may limit expressiveness
  - Regularization coefficient λ: Controls trade-off between fitting data and maintaining uncertainty
- Failure signatures:
  - High ECE/MCE: Model is overconfident or underconfident
  - Low AUROC/AUPRC: Poor OOD detection capability
  - High NLL: Poor distribution estimation quality
- First 3 experiments:
  1. Compare EDL vs. softmax classification on majority class prediction accuracy
  2. Evaluate uncertainty quantification by measuring calibration (ECE/MCE) on MA data
  3. Test OOD detection capability by measuring AUROC/AUPRC on NMA data

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but several areas remain unexplored:
- Performance on datasets with a larger number of emotion classes
- Handling situations where the number of annotators varies significantly across utterances
- Handling multi-label emotion annotations where an utterance can belong to multiple emotion classes simultaneously

## Limitations
- Dataset dependency: The method's performance heavily depends on the availability of multiple human annotations per utterance
- Generalization concerns: The OOD detection approach assumes NMA samples are truly out-of-domain
- Computational overhead: EDL-based methods require more complex computations than standard softmax classification

## Confidence

### Major Uncertainties

**Mechanism 1 (EDL for uncertainty quantification):** Medium confidence
- While the theoretical framework is sound, the paper doesn't adequately address potential issues with the Dirichlet assumption for emotion distributions

**Mechanism 2 (Distribution estimation reframing):** Medium confidence
- The approach assumes human annotations are independent samples from a multinomial distribution, but this may not hold if annotators are influenced by each other

**Mechanism 3 (Extended EDL framework):** Low confidence
- The extension from classification to distribution estimation is presented as straightforward, but the paper provides limited theoretical justification for why the same uncertainty quantification method applies to both tasks

## Next Checks
1. **Ablation study on Dirichlet assumptions:** Systematically test whether alternative distributions (e.g., logistic normal) provide better uncertainty estimates for emotion data, particularly for highly ambiguous utterances

2. **Annotator bias analysis:** Examine whether the estimated emotion distributions correlate with known annotator characteristics (e.g., demographic information) or annotation order effects, which could reveal systematic biases not captured by the current approach

3. **Cross-dataset generalization:** Evaluate the proposed methods on emotion datasets with different annotation schemes and emotional label sets to assess whether the uncertainty quantification generalizes beyond the specific IEMOCAP and CREMA-D contexts