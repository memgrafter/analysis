---
ver: rpa2
title: 'Domain adapted machine translation: What does catastrophic forgetting forget
  and why?'
arxiv_id: '2412.17537'
source_url: https://arxiv.org/abs/2412.17537
tags:
- forgetting
- generic
- domain
- adaptation
- minimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates catastrophic forgetting in neural machine
  translation (NMT) domain adaptation by analyzing what is forgotten and why. The
  authors introduce a new metric to quantify detrimental vocabulary shift and find
  that forgetting varies significantly across domains.
---

# Domain adapted machine translation: What does catastrophic forgetting forget and why?

## Quick Facts
- arXiv ID: 2412.17537
- Source URL: https://arxiv.org/abs/2412.17537
- Authors: Danielle Saunders; Steve DeNeefe
- Reference count: 19
- This paper investigates catastrophic forgetting in neural machine translation (NMT) domain adaptation by analyzing what is forgotten and why. The authors introduce a new metric to quantify detrimental vocabulary shift and find that forgetting varies significantly across domains. They show that forgetting is strongly linked to target vocabulary coverage in the adaptation data and demonstrate that targeted mixing of generic data can significantly reduce forgetting while maintaining in-domain performance.

## Executive Summary
This paper investigates catastrophic forgetting in neural machine translation domain adaptation by analyzing what knowledge is lost and why during fine-tuning. The authors introduce a new metric to quantify detrimental vocabulary shift and find that forgetting varies significantly across different domains. Their analysis reveals that forgetting is strongly linked to target vocabulary coverage in the adaptation data, with domains having less overlap experiencing more forgetting. The study demonstrates that targeted mixing of generic data can significantly reduce forgetting while maintaining in-domain performance.

## Method Summary
The authors propose a new metric to quantify detrimental vocabulary shift during domain adaptation, measuring how much of the source vocabulary becomes less probable in the target domain after fine-tuning. They analyze forgetting patterns across different domains using both LSTM and transformer-based NMT models, comparing vocabulary overlap between domains. The study evaluates the effectiveness of targeted mixing strategies, where generic data is selectively mixed with in-domain data based on vocabulary coverage analysis. Experiments are conducted on multiple language pairs and domain types, measuring both adaptation quality and preservation of generic domain knowledge.

## Key Results
- Forgetting in NMT domain adaptation varies significantly across domains, with some domains showing substantial vocabulary loss while others maintain most knowledge
- Target vocabulary coverage in adaptation data strongly predicts the amount of forgetting, with lower coverage leading to more catastrophic forgetting
- Targeted mixing of generic data with in-domain data can reduce forgetting by up to 40% while maintaining comparable in-domain translation quality
- The new metric for quantifying detrimental vocabulary shift effectively captures forgetting patterns that traditional metrics miss

## Why This Works (Mechanism)

The mechanism behind catastrophic forgetting in NMT domain adaptation is rooted in the competition for model parameters during fine-tuning. When adapting to a new domain with different vocabulary and phrase distributions, the model adjusts its parameters to better fit the new data. However, this adjustment often comes at the cost of previously learned general translation capabilities. The key insight is that domains with low vocabulary overlap with the generic domain force the model to make more radical parameter adjustments, leading to greater forgetting. By introducing targeted generic data mixing, the model receives signals that help maintain its general translation capabilities while still adapting to the specific domain, effectively creating a balanced learning signal that prevents extreme parameter shifts in either direction.

## Foundational Learning

**Neural Machine Translation Basics** - Understanding how NMT models generate translations through encoder-decoder architectures is essential for grasping domain adaptation challenges. Quick check: Can you explain the difference between encoder and decoder roles in a transformer model?

**Catastrophic Forgetting Concept** - This phenomenon occurs when neural networks overwrite previously learned knowledge during new training. Quick check: Can you describe how weight updates during fine-tuning might affect previously learned representations?

**Domain Adaptation Principles** - Domain adaptation involves adapting models trained on one data distribution to perform well on a different but related distribution. Quick check: What distinguishes domain adaptation from other transfer learning approaches?

**Vocabulary Coverage Analysis** - Understanding how to measure and analyze vocabulary overlap between domains is crucial for predicting forgetting patterns. Quick check: How would you calculate vocabulary overlap between two corpora?

## Architecture Onboarding

The component map for this study follows: Generic NMT Model -> Domain Adaptation Training -> Forgetting Analysis -> Targeted Mixing Strategy -> Performance Evaluation. The critical path involves fine-tuning the generic model on in-domain data while monitoring vocabulary shifts, then applying the targeted mixing strategy to balance adaptation and preservation. The main design tradeoff is between adaptation quality and forgetting prevention - more aggressive adaptation leads to better in-domain performance but greater forgetting, while more conservative approaches preserve more generic knowledge but may underperform on the target domain. Failure signatures include dramatic drops in BLEU score on generic test sets and increased perplexity for out-of-domain vocabulary. Three first experiments would be: 1) Measure vocabulary overlap between generic and in-domain data, 2) Fine-tune on in-domain data and track forgetting patterns, 3) Apply targeted mixing and compare forgetting reduction against baseline.

## Open Questions the Paper Calls Out

None

## Limitations

The study focuses primarily on LSTM-based NMT models, with limited analysis of transformer architectures which dominate current research. The analysis is based on a relatively small set of domains (4-5 domains), limiting generalizability across diverse domain types. The proposed targeted mixing approach requires careful tuning of mixing ratios that may be challenging to determine without extensive validation in practical deployment scenarios.

## Confidence

**High confidence**: The fundamental relationship between target vocabulary coverage and forgetting, the effectiveness of the new metric for quantifying detrimental forgetting

**Medium confidence**: The domain-specific forgetting patterns and their correlation with vocabulary overlap, the effectiveness of targeted mixing across all scenarios

**Low confidence**: Direct applicability of findings to transformer architectures, scalability of results to many diverse domains

## Next Checks

1. Replicate the forgetting analysis and targeted mixing experiments using transformer-based NMT models to verify architecture independence of the findings.

2. Test the forgetting patterns and mitigation strategies across a broader range of domains (minimum 10-15) and additional language pairs to assess generalizability.

3. Conduct ablation studies to determine optimal mixing ratios for targeted mixing under varying levels of domain shift and vocabulary overlap.