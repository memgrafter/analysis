---
ver: rpa2
title: 'FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large
  Language Models'
arxiv_id: '2402.06696'
source_url: https://arxiv.org/abs/2402.06696
tags:
- fairness
- design
- accuracy
- architecture
- fl-nas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of designing deep neural networks
  (DNNs) that are accurate, fair across demographic groups, and efficient for deployment
  on resource-constrained devices. The proposed method, FL-NAS, leverages large language
  models (LLMs) to automate neural architecture search (NAS) by incorporating fairness
  and hardware efficiency as key design metrics alongside accuracy.
---

# FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models

## Quick Facts
- arXiv ID: 2402.06696
- Source URL: https://arxiv.org/abs/2402.06696
- Reference count: 33
- Primary result: LLM-driven NAS achieves up to 11.4% higher accuracy, 18× better fairness scores, and 4× reduced latency vs state-of-the-art on dermatological dataset

## Executive Summary
FL-NAS is a neural architecture search (NAS) framework that leverages large language models (LLMs) to design deep neural networks optimized for accuracy, fairness across demographic groups, and hardware efficiency on resource-constrained devices. By using carefully crafted prompts that describe all three design metrics in detail, FL-NAS guides the LLM to generate architectures that balance these objectives without requiring exhaustive search. Experimental results on a dermatological dataset demonstrate that FL-NAS outperforms state-of-the-art models while significantly reducing inference latency, model size, and memory footprint, making it suitable for real-world deployment on edge devices.

## Method Summary
FL-NAS uses ChatGPT-4 to generate DNN architectures through iterative prompt-LLM cycles. The framework takes a baseline DNN and its performance metrics (accuracy, fairness scores, hardware efficiency) as input, then uses a PromptGenerator to create rich contextual prompts describing these metrics and hardware constraints. The LLMDesigner sends these prompts to ChatGPT-4 to generate new architecture candidates, which are evaluated on accuracy, fairness (unfairness score, EODD, EOPP1, EOPP2), and hardware metrics (parameters, memory, latency). This search loop continues for IterMax iterations, with the best-performing architecture returned at the end. The method is demonstrated on the ISIC 2019 dermatological dataset with demographic metadata for gender and age groups.

## Key Results
- FL-NAS achieves up to 11.4% higher accuracy compared to state-of-the-art DNN models
- Fairness scores improve by up to 18× (lower is better) across demographic groups
- Inference latency reduced by up to 4× while maintaining or improving accuracy
- Model size and memory footprint significantly decreased, enabling deployment on resource-constrained devices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can interpret "vagueness" of fairness metrics and translate them into architectural modifications.
- Mechanism: By incorporating detailed fairness descriptions (e.g., demographic accuracy gaps, EODD/EOPP1/EOPP2 scores) into prompts, the LLM's semantic understanding allows it to suggest structural changes that reduce group-level disparities without sacrificing overall accuracy.
- Core assumption: The LLM's internal knowledge includes implicit fairness principles that can be activated through contextual prompt engineering.
- Evidence anchors:
  - [abstract] "We empirically show that FL-NAS can reasonably incorporate both fairness and hardware efficiency in its design consideration through LLMs, yet without sacrificing accuracy."
  - [section] "Instead of feeding only one design metric (such as accuracy) to the LLM, we propose to give a much more detailed description of all design metrics to the LLM."
  - [corpus] No direct corpus match for LLM fairness interpretation; only general NAS fairness work cited.
- Break condition: If LLM lacks exposure to fairness concepts or demographic bias mitigation, generated architectures may ignore fairness objectives.

### Mechanism 2
- Claim: LLMs can simultaneously balance multiple hardware constraints (latency, memory, parameter count) through prompt-driven reasoning.
- Mechanism: Prompts encode explicit hardware efficiency priorities and target deployment constraints, allowing the LLM to reason about trade-offs and propose compact, low-latency architectures.
- Core assumption: The LLM can map natural language constraints into concrete architectural parameters like kernel sizes, layer counts, and normalization methods.
- Evidence anchors:
  - [abstract] "Experimental results... demonstrate that FL-NAS outperforms state-of-the-art DNN models... significantly reduced inference latency, model size, and memory footprint."
  - [section] "Regarding the hardware efficiency metrics... you should try to minimize them so the DNN can run with less resources."
  - [corpus] Weak support; corpus focuses on general hardware-aware NAS but not LLM-driven multi-metric optimization.
- Break condition: If the LLM's training data lacks diverse hardware deployment scenarios, it may fail to optimize for edge-specific constraints.

### Mechanism 3
- Claim: LLMs reduce NAS search cost by orders of magnitude compared to evolutionary or RL-based methods.
- Mechanism: Instead of evaluating thousands of candidate architectures, the LLM generates a single, high-quality candidate per iteration based on contextual reasoning, drastically cutting computational overhead.
- Core assumption: The LLM's generative reasoning is sufficiently accurate to replace expensive architectural evaluation loops.
- Evidence anchors:
  - [abstract] "Compared to state-of-the-art (SOTA) work... FL-NAS can improve the model accuracy by up to 11.4% and fairness scores by up to 18×, and at the same time, reduce the model inference latency by up to 4×..."
  - [section] "Since LLMs' inference time is orders of magnitude faster than NAS search time, LLM-based NAS also promises to be faster than conventional NAS."
  - [corpus] No direct corpus match for LLM NAS speed claims; only general NAS cost discussions.
- Break condition: If the LLM produces invalid or suboptimal architectures, the search efficiency gain collapses.

## Foundational Learning

- Concept: Neural Architecture Search (NAS) fundamentals
  - Why needed here: FL-NAS builds directly on NAS principles but replaces search algorithms with LLM prompting; understanding NAS design spaces and metrics is essential.
  - Quick check question: What are the three main search strategies historically used in NAS, and how does FL-NAS differ?

- Concept: Fairness metrics in ML (demographic parity, equalized odds, equal opportunity)
  - Why needed here: FL-NAS explicitly optimizes for fairness across demographic groups; knowing how to compute and interpret these metrics is critical.
  - Quick check question: How does the "unfairness score" formula measure bias, and why does a lower value indicate better fairness?

- Concept: Hardware efficiency metrics (latency, memory footprint, parameter count)
  - Why needed here: FL-NAS targets deployment on resource-constrained devices; engineers must understand how to quantify and trade off these constraints.
  - Quick check question: Why is memory footprint often more limiting than parameter count for edge deployment, and how can you measure it?

## Architecture Onboarding

- Component map:
  - PromptGenerator -> LLMDesigner -> Evaluator -> Search loop (IterMax iterations) -> Best architecture

- Critical path:
  1. Initialize with a baseline DNN and its metrics.
  2. Generate prompts using PromptGenerator.
  3. Send prompts to LLMDesigner to obtain new DNN.
  4. Evaluate candidate via Evaluator.
  5. Store results and repeat until IterMax reached.
  6. Return best architecture.

- Design tradeoffs:
  - Prompt detail vs. LLM token limits: Rich prompts improve output quality but risk exceeding context windows.
  - Search breadth vs. iteration count: More iterations improve results but increase total compute time.
  - Accuracy vs. fairness prioritization: LLM prompt weighting determines which objective dominates.

- Failure signatures:
  - LLM outputs invalid Python code → debug PromptGenerator formatting or add validation loops.
  - No improvement across iterations → re-examine prompt structure or increase IterMax.
  - Overfitting to training data → verify train/validation split balance and demographic group sizes.

- First 3 experiments:
  1. Run FL-NAS with IterMax=3 on a small CNN template; verify that prompts are correctly formatted and LLM outputs valid architectures.
  2. Compare accuracy, fairness, and latency of the first LLM-generated model against a baseline ResNet; confirm improvement claims.
  3. Test deployment of the best-found model on a Raspberry Pi 4; measure actual latency and memory usage vs. claimed values.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different prompt formulations affect the quality and diversity of DNN architectures generated by FL-NAS?
- Basis in paper: [explicit] The paper discusses prompt design as a key component of FL-NAS and mentions that detailed prompts including architecture metrics are used.
- Why unresolved: The paper does not provide a systematic comparison of different prompt formulations or their impact on the generated architectures.
- What evidence would resolve it: A study comparing multiple prompt formulations and their resulting DNN architectures in terms of accuracy, fairness, and hardware efficiency metrics.

### Open Question 2
- Question: Can FL-NAS be extended to optimize for additional design metrics beyond accuracy, fairness, and hardware efficiency?
- Basis in paper: [explicit] The paper mentions that FL-NAS is designed to optimize for three specific metrics but does not explore the possibility of incorporating additional metrics.
- Why unresolved: The paper focuses on these three metrics and does not discuss the potential for extending the framework to include other important design considerations.
- What evidence would resolve it: Demonstrations of FL-NAS optimizing for additional metrics such as energy consumption, robustness to adversarial attacks, or interpretability, and comparisons of the resulting architectures.

### Open Question 3
- Question: How does the performance of FL-NAS compare to other state-of-the-art NAS methods when considering a broader range of datasets and tasks?
- Basis in paper: [explicit] The paper presents experimental results on a single dermatological dataset and compares FL-NAS to several baseline models, but does not explore its performance on other datasets or tasks.
- Why unresolved: The paper's evaluation is limited to a specific dataset and task, and does not provide insights into FL-NAS's generalizability to other domains.
- What evidence would resolve it: A comprehensive evaluation of FL-NAS on multiple datasets and tasks, including comparisons with other state-of-the-art NAS methods, to assess its performance and generalizability.

## Limitations

- The exact prompt templates and hyperparameter settings are underspecified, making faithful reproduction challenging
- Experimental results are demonstrated only on a single dermatological dataset with binary gender and age categories, limiting generalizability
- The approach relies on the LLM having implicit understanding of fairness principles without empirical validation of this semantic capability

## Confidence

- **High Confidence**: Claims about LLM speed advantages over traditional NAS methods are well-supported by general LLM inference time characteristics
- **Medium Confidence**: Claims about achieving 11.4% accuracy improvement and 18× fairness gains are supported by experimental results on one dataset but lack independent verification
- **Low Confidence**: Claims that LLMs can "reasonably incorporate both fairness and hardware efficiency" through semantic understanding are the weakest, as they rely on unverified implicit LLM knowledge

## Next Checks

1. Apply FL-NAS to a different fairness-sensitive domain (e.g., criminal justice recidivism prediction) with multiple demographic attributes to test generalizability

2. Conduct a systematic prompt ablation study varying fairness description detail while keeping all other factors constant to quantify prompt dependency

3. Deploy the best FL-NAS model on multiple resource-constrained devices (Raspberry Pi 4, NVIDIA Jetson Nano, mobile CPU) to measure actual latency and memory usage under identical conditions