---
ver: rpa2
title: 'MIKO: Multimodal Intention Knowledge Distillation from Large Language Models
  for Social-Media Commonsense Discovery'
arxiv_id: '2402.18169'
source_url: https://arxiv.org/abs/2402.18169
tags:
- intentions
- intention
- social
- media
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces M/i.sc/k.sc/o.sc, a framework for extracting
  multimodal social media intentions using LLMs and MLLMs. It addresses challenges
  like implicit intentions, cross-modal understanding, and noisy social media content.
---

# MIKO: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery

## Quick Facts
- arXiv ID: 2402.18169
- Source URL: https://arxiv.org/abs/2402.18169
- Reference count: 40
- Key outcome: Introduces MIKO framework extracting 1,372K intentions from 137,287 social media posts, improving sarcasm detection when intentions are incorporated

## Executive Summary
MIKO is a framework that extracts multimodal social media intentions by distilling knowledge from large language models (LLMs) and multimodal LLMs (MLLMs). It addresses challenges of implicit intentions, cross-modal understanding, and noisy social media content through a three-step pipeline: image captioning with an MLLM, key information extraction from text and images using an LLM, and intention generation aligned with commonsense relations from ATOMIC. The framework is evaluated on public social media datasets, showing high plausibility and typicality in human annotation, and demonstrates state-of-the-art results in sarcasm detection when incorporating extracted intentions.

## Method Summary
MIKO uses a hierarchical approach to extract intentions from social media posts. First, it employs an MLLM (LLava) to generate image captions from post images. Then, an LLM (ChatGPT) extracts key information including concepts, actions, objects, emotions, and keywords from both text and image descriptions. Finally, another LLM prompt generates intentions aligned with 9 specific ATOMIC relations plus an open category. The generated intentions are evaluated through human annotation and benchmarked against other LLMs. The framework also demonstrates downstream benefits by fine-tuning a smaller Llama2-7B model on the distilled intention knowledge and applying it to a sarcasm detection dataset.

## Key Results
- Extracted 1,372K intentions from 137,287 social media posts with high human annotation scores for plausibility and typicality
- Benchmark shows most LLMs struggle with direct intention generation, while fine-tuning on MIKO outputs improves performance
- Incorporating extracted intentions into sarcasm detection achieves state-of-the-art results, demonstrating utility for social media understanding tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical distillation enables better cross-modal alignment by isolating image understanding from textual noise filtering
- Mechanism: MIKO first uses an MLLM to generate image descriptions, then uses an LLM to extract key information from both text and descriptions, and finally uses another LLM prompt to generate intentions
- Core assumption: Modality-specific processing improves downstream intention generation compared to joint multimodal input
- Evidence anchors: [abstract] "Specifically, we use an MLLM to interpret the image and an LLM to extract key information from the text and finally instruct the LLM again to generate intentions."

### Mechanism 2
- Claim: Grounding intentions in ATOMIC relations provides structured, human-interpretable commonsense reasoning patterns
- Mechanism: MIKO maps generated intentions to 9 ATOMIC relations (xNeed, xIntent, xAttr, xEffect, xReact, xWant, oEffect, oReact, oWant) plus an open category
- Core assumption: Aligning with established commonsense relations improves the quality and interpretability of generated intentions
- Evidence anchors: [abstract] "We align our prompts with 9 specific commonsense relations in ATOMIC... to make the intentions comprehensive in a commonsense manner."

### Mechanism 3
- Claim: Fine-tuning smaller LLMs on MIKO-generated intentions transfers the distillation capability to more efficient models
- Mechanism: After generating high-quality intentions with MIKO, these are used to create instruction pairs for fine-tuning a local Llama2-7B model
- Core assumption: Distilled intention knowledge can be effectively transferred to smaller models through instruction fine-tuning
- Evidence anchors: [abstract] "benchmark the performance of widely used LLMs for intention generation. We further apply MIKO to a sarcasm detection dataset and distill a student model to demonstrate the downstream benefits of applying intention knowledge."

## Foundational Learning

- Concept: Cross-modal reasoning
  - Why needed here: Social media posts contain both text and images that need to be jointly understood to infer user intentions
  - Quick check question: What is the primary challenge when trying to understand intentions from multimodal social media posts?
  - Answer: The need to integrate information from both text and images while handling noise and implicit meaning

- Concept: Knowledge distillation
  - Why needed here: Large models generate high-quality intentions that can be transferred to smaller, more efficient models
  - Quick check question: What is the core idea behind using a teacher-student framework in this context?
  - Answer: Using a powerful LLM as a teacher to generate quality intentions that can be used to train a smaller student model

- Concept: Commonsense reasoning frameworks
  - Why needed here: ATOMIC provides a structured way to categorize social intentions that aligns with human understanding
  - Quick check question: Why does MIKO use ATOMIC relations to structure generated intentions?
  - Answer: To create a standardized, interpretable framework that captures both user and observer perspectives on intentions

## Architecture Onboarding

- Component map: Image → Caption (LLava) → Key Info (ChatGPT) → Intention (ChatGPT) → Annotation → Fine-tuning → Evaluation
- Critical path: Image → Caption → Key Info → Intention → Annotation → Fine-tuning → Evaluation
- Design tradeoffs: 
  - Uses multiple LLM calls (cost/compute) vs. single call (simplicity)
  - Structured ATOMIC framework (consistency) vs. open generation (flexibility)
  - Human annotation (quality) vs. automated evaluation (scalability)
- Failure signatures:
  - Poor image captions → downstream intention quality degrades
  - Noisy key information extraction → intentions become generic
  - ATOMIC misalignment → intentions don't capture social media nuances
  - Annotation inconsistency → benchmark becomes unreliable
- First 3 experiments:
  1. Test MLLM image captioning quality on a small sample of posts
  2. Evaluate key information extraction accuracy with human validation
  3. Benchmark intention generation quality using human raters before scaling

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Reliance on proprietary LLMs (ChatGPT and LLava) raises questions about reproducibility and cost efficiency at scale
- Human annotation process lacks detailed description of inter-annotator reliability metrics and training procedures
- Evaluation is primarily based on human plausibility ratings rather than downstream task performance across diverse domains

## Confidence
**High Confidence:** The hierarchical three-step approach using MLLM for image captioning followed by LLM for intention generation is technically sound and well-justified. The downstream improvement in sarcasm detection when incorporating extracted intentions provides strong empirical validation.

**Medium Confidence:** The effectiveness of ATOMIC relation grounding for social media intentions is plausible but requires more extensive validation. The human annotation results showing high plausibility and typicality are encouraging but limited to a small sample size (100 posts).

**Low Confidence:** The scalability and cost-effectiveness of the approach for real-world deployment remains uncertain due to the heavy reliance on multiple expensive LLM calls. The fine-tuning results, while promising, are based on a single downstream task and model architecture.

## Next Checks
1. **Ablation Study on MLLM Dependency:** Test whether direct multimodal input to the LLM (bypassing the image captioning step) produces comparable or superior results, addressing the core assumption that modality-specific processing improves downstream intention generation.

2. **Open-Source Alternative Benchmark:** Implement the MIKO framework using open-source models (e.g., LLaVA, Vicuna) to assess whether the approach maintains effectiveness without proprietary components and to better understand cost implications.

3. **Cross-Domain Generalization Test:** Evaluate the extracted intentions on additional downstream tasks beyond sarcasm detection (e.g., sentiment analysis, topic classification, engagement prediction) to determine if the commonsense reasoning benefits extend across different social media understanding applications.