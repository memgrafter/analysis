---
ver: rpa2
title: 'AMP: Autoregressive Motion Prediction Revisited with Next Token Prediction
  for Autonomous Driving'
arxiv_id: '2403.13331'
source_url: https://arxiv.org/abs/2403.13331
tags:
- prediction
- motion
- future
- agents
- autoregressive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper revisits autoregressive motion prediction for autonomous
  driving by introducing a GPT-style next token prediction approach. The core idea
  is to represent both observed and future states of agents in a unified ego-centric
  coordinate system, allowing for autoregressive generation of future trajectories.
---

# AMP: Autoregressive Motion Prediction Revisited with Next Token Prediction for Autonomous Driving

## Quick Facts
- arXiv ID: 2403.13331
- Source URL: https://arxiv.org/abs/2403.13331
- Authors: Xiaosong Jia; Shaoshuai Shi; Zijun Chen; Li Jiang; Wenlong Liao; Tao He; Junchi Yan
- Reference count: 40
- Primary result: State-of-the-art performance on Waymo Open Motion and Waymo Interaction datasets using GPT-style next token prediction

## Executive Summary
This paper introduces AMP, an autoregressive motion prediction model that leverages next token prediction to generate future trajectories step-by-step. Unlike previous approaches that only use observed states as input, AMP adopts a GPT-style training strategy where both observed and future states are represented in a unified ego-centric coordinate system. This enables autoregressive generation of future trajectories by predicting the next token conditioned on both previous tokens and the observed context. The model employs three factorized attention modules with tailored position encodings to capture complex spatial-temporal and semantic relations in driving scenes.

## Method Summary
AMP processes observed agent states and map elements by transforming them into an ego-centric coordinate system and tokenizing them using PointNet. A Context Encoder pre-computes features for non-focal agents and map elements using self-attention with relative spatial position encodings. The Future Decoder then autoregressively generates future trajectories using three factorized attention modules: context cross-attention, temporal self-attention, and spatial self-attention. Each module uses tailored position encodings - relative spatial positions for context relations, RoPE for temporal relativity, and causal masking to prevent information leakage. A Multi-Modal Detokenizer generates multiple possible futures by fusing short-term and long-term intention predictions. The model is trained for 50 epochs with learning rate decay, dropout, and batch norm freezing.

## Key Results
- Achieves state-of-the-art performance on Waymo Open Motion and Waymo Interaction datasets
- Outperforms recent autoregressive methods like MotionLM and StateTransformer
- Narrows the gap between autoregressive and independent generation approaches
- Benefits from ensemble methods while maintaining strong single-model performance

## Why This Works (Mechanism)

### Mechanism 1
Representing observed and future states in a unified ego-centric coordinate system enables autoregressive generation. By transforming both input (observed) and output (future) tokens into the same representation space, the model can predict the next token conditioned on both previous tokens and the observed context, mirroring the step-by-step nature of real-world motion. The core assumption is that relative spatial and temporal relationships between agents and map elements can be effectively encoded in a single unified space.

### Mechanism 2
Factorized attention modules with tailored position encodings capture complex spatial-temporal and semantic relations. The model uses three separate attention modules (context cross-attention, temporal self-attention, and spatial self-attention) with different neighbor sets and position encodings (relative spatial position, RoPE for temporal relativity, and causal masking) to handle the heterogeneous nature of driving scenes. The core assumption is that different types of relations require distinct attention mechanisms and position encodings to be properly modeled.

### Mechanism 3
Fusing short-term and long-term intention predictions improves autoregressive trajectory generation. The model generates both short-term (next few steps) and long-term (entire future trajectory) predictions, then fuses them during inference to leverage the strengths of both: short-term for immediate reaction and long-term for goal-directed behavior. The core assumption is that human movement involves both immediate reactions to the environment and longer-term goals, and this dual nature can be captured by separate prediction streams.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: The model relies on self-attention and cross-attention to aggregate information from different tokens and modalities.
  - Quick check question: What is the difference between self-attention and cross-attention, and when would you use each?

- Concept: Position encoding (absolute vs. relative)
  - Why needed here: The model uses relative position encodings to capture spatial and temporal relationships between tokens in a unified representation space.
  - Quick check question: Why are relative position encodings preferred over absolute encodings in this context?

- Concept: Coordinate system transformations
  - Why needed here: The model transforms all inputs into an ego-centric coordinate system to create a unified representation space for autoregressive prediction.
  - Quick check question: What are the advantages and disadvantages of using an ego-centric coordinate system versus a global coordinate system for motion prediction?

## Architecture Onboarding

- Component map:
  Tokenizer -> Context Encoder (map and non-focal agents) -> Future Decoder (focal agents) -> Multi-Modal Detokenizer -> Re-normalizer

- Critical path:
  1. Input normalization and tokenization
  2. Context feature pre-computation
  3. Autoregressive future generation
  4. Multi-modal trajectory decoding
  5. Output re-normalization and detokenization

- Design tradeoffs:
  - Unified ego-centric representation vs. separate representations for input and output
  - Factorized attention vs. single global attention
  - Short-term + long-term predictions vs. single trajectory generation

- Failure signatures:
  - Training instability or slow convergence
  - Poor performance on long-term predictions
  - Inability to capture complex agent interactions

- First 3 experiments:
  1. Ablation study on the importance of each attention module (context cross-attention, temporal self-attention, spatial self-attention)
  2. Ablation study on the effectiveness of different position encodings (relative spatial, RoPE, causal masking)
  3. Comparison of different fusion strategies for short-term and long-term predictions (weighted averaging, Kalman filtering, etc.)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of AMP scale with increasing model size and depth? Would a significantly larger model further narrow the gap with independent generation methods?
- Basis in paper: The authors use a model with 6 Context Encoder layers and 6 Future Encoder layers with a hidden dimension of 512 for their main results. They mention using a smaller model with 3 Future Encoder layers and a hidden dimension of 256 for ablation studies.
- Why unresolved: The paper only reports results for one model size. Scaling laws for autoregressive motion prediction models have not been thoroughly explored.
- What evidence would resolve it: Experiments with larger models (e.g., 12+ layers, 1024+ hidden dimensions) and their corresponding performance on the Waymo Open Motion and Interaction datasets.

### Open Question 2
- Question: How robust is AMP to noisy or inaccurate map data? Does the performance degrade significantly when the input map information is imperfect?
- Basis in paper: The paper heavily relies on map elements as input and encodes them using a PointNet. However, real-world map data can be noisy or outdated.
- Why unresolved: The experiments use the official Waymo datasets, which likely have high-quality map data. The impact of map noise on AMP's performance is not explored.
- What evidence would resolve it: Experiments where synthetic noise is added to the map data (e.g., random perturbations to lane boundaries, missing map elements) and the corresponding performance degradation of AMP is measured.

### Open Question 3
- Question: Can AMP be extended to handle more complex agent interactions, such as those involving groups of agents or long-term strategic planning?
- Basis in paper: The authors mention that AMP can capture complex interactions among focal agents using Spatial Self-Attention. However, they only consider pairwise interactions.
- Why unresolved: The paper focuses on short-term trajectory prediction (8 seconds) and does not explore scenarios involving group dynamics or long-term planning.
- What evidence would resolve it: Experiments on datasets with more complex agent interactions (e.g., multi-agent scenarios with coordinated behavior) and modifications to AMP to incorporate group-level reasoning or long-term planning modules.

## Limitations

- The approach relies heavily on coordinate system transformations, which may lose global context or absolute positioning information important for certain driving scenarios.
- Limited ablation studies on the necessity of each component in the factorized attention modules, leaving uncertainty about whether the complexity is truly required.
- Performance generalizability beyond the specific Waymo datasets has not been thoroughly tested, raising questions about robustness to different driving cultures, road layouts, or sensor configurations.

## Confidence

**High confidence** in the core architectural framework and its ability to achieve state-of-the-art performance on the tested datasets. The implementation details, training procedure, and evaluation methodology are clearly specified, and the performance gains over baseline methods are substantial and well-documented.

**Medium confidence** in the specific mechanisms proposed for handling spatial-temporal relations (relative position encodings, RoPE, causal masking). While the paper provides theoretical justification for these choices, the empirical evidence is limited to ablation studies that show improvements but do not establish the necessity of each component.

**Low confidence** in the generalizability of the approach beyond the specific datasets used (Waymo Open Motion and Waymo Interaction). The paper does not test the method on other motion forecasting benchmarks or in simulated environments with different characteristics, leaving open questions about robustness to different driving cultures, road layouts, or sensor configurations.

## Next Checks

**Validation Check 1**: Conduct systematic ablation studies removing each of the three attention modules (context cross-attention, temporal self-attention, spatial self-attention) individually to quantify their individual contributions to performance. This would help determine whether the factorized approach is truly necessary or if simpler architectures could achieve similar results.

**Validation Check 2**: Test the model's performance when trained and evaluated on different coordinate systems (global vs. ego-centric) to understand the sensitivity of the approach to the representation choice. This would reveal whether the unified ego-centric representation is a fundamental requirement or an implementation detail.

**Validation Check 3**: Evaluate the method on additional motion forecasting benchmarks beyond Waymo, such as nuScenes, Argoverse, or simulated environments with varying complexity levels. This would test the generalizability of the approach and identify any dataset-specific optimizations that may be limiting broader applicability.