---
ver: rpa2
title: From Graph Diffusion to Graph Classification
arxiv_id: '2411.17236'
source_url: https://arxiv.org/abs/2411.17236
tags:
- graph
- diffusion
- classification
- training
- permutation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates applying diffusion models for graph classification
  tasks. The authors propose training diffusion models with a novel objective tailored
  to graph classification and demonstrate that incorporating random permutations during
  both training and inference improves performance.
---

# From Graph Diffusion to Graph Classification

## Quick Facts
- arXiv ID: 2411.17236
- Source URL: https://arxiv.org/abs/2411.17236
- Authors: Jia Jun Cheng Xian; Sadegh Mahdavi; Renjie Liao; Oliver Schulte
- Reference count: 34
- Key outcome: LCLF training objective with approximate inference achieves state-of-the-art graph classification accuracy on IMDB-BINARY and PROTEINS datasets

## Executive Summary
This paper bridges diffusion models and graph classification by proposing novel training objectives and inference strategies. The authors demonstrate that traditional diffusion training objectives like denoising score matching are suboptimal for classification tasks, and introduce a new objective (LCLF) that directly optimizes classification performance. They also show that incorporating random permutations during both training and inference significantly improves generalization by mitigating overfitting to specific graph representations. The approach achieves state-of-the-art results on standard graph classification benchmarks while providing insights into the relationship between generative modeling and discriminative tasks.

## Method Summary
The authors adapt score-based diffusion models for graph classification by introducing three training objectives (LDEN, LCLF, LSUM) and two inference methods (approximate via variational approximation, exact via ODE solving). The key innovation is LCLF, which directly optimizes the softmax of class-conditional likelihoods rather than treating classification as a byproduct of generative training. They employ SwinGNN as the backbone architecture and introduce random permutation augmentation during both training and inference to handle the non-permutation-invariant nature of the model. The method trains on three datasets (K-Regular synthetic, IMDB-BINARY, PROTEINS) using 10-fold cross-validation and evaluates classification accuracy.

## Key Results
- LCLF training objective with approximate inference achieves state-of-the-art accuracy on IMDB-BINARY and PROTEINS
- Increasing inference-time permutations consistently improves accuracy, with gains saturating around 100 permutations
- LCLF objective outperforms LDEN and LSUM by directly optimizing classification performance
- Permutation augmentation during training prevents overfitting and improves generalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LCLF improves classification accuracy by directly optimizing the softmax of class-conditional likelihoods
- Core assumption: The variational approximation in LDEN is sufficiently accurate to serve as a basis for discriminative classification
- Evidence anchors:
  - [abstract]: "We find that to achieve competitive classification accuracy, score-based graph diffusion models should be trained with a novel training objective that is tailored to graph classification"
  - [section 4]: "Equation (16) uses the approximate class-conditional graph log-probability to derive an approximate graph class log-probability via Equation (14)"
- Break condition: If the variational approximation becomes too loose, the softmax probabilities become unreliable and classification performance degrades

### Mechanism 2
- Claim: Random permutation of adjacency matrices during both training and inference mitigates overfitting and improves generalization
- Core assumption: The permutation-invariant structure of the graph classification task can be captured by averaging over a finite set of permutations
- Evidence anchors:
  - [section 4]: "One natural approach to prevent overfitting is to augment the dataset by considering random permutations of graphs"
  - [section 5]: "At test time, we propose to utilize a similar permutation trick, and predict the class label based on several permutations of the graph"
- Break condition: If the number of permutations is too small to adequately sample the isomorphism class, the approximation becomes biased

### Mechanism 3
- Claim: Using approximate inference (via LCLF) during model checkpoint selection is computationally feasible and effective compared to exact ODE-based likelihood computation
- Core assumption: The model selected using LCLF validation performance will also perform well when evaluated with exact inference
- Evidence anchors:
  - [section 6]: "evaluating the variational approximation loss LCLF from Equation (16) is considerably quicker... This efficiency results in a speedup of over 2000 times in checkpoint selection compared to ODE solving"
- Break condition: If the approximation error in LCLF is large, the checkpoint selection may favor suboptimal models that do not generalize with exact inference

## Foundational Learning

- Concept: Diffusion models (score-based and variational)
  - Why needed here: The paper builds a graph diffusion model for classification; understanding how noise is added/removed and how likelihoods are computed is essential
  - Quick check question: What is the difference between the training loss in a score-based diffusion model and a variational diffusion model?

- Concept: Graph isomorphism and permutation invariance
  - Why needed here: The model is not permutation-invariant, so understanding how graph representations change under permutation is key to the augmentation strategy
  - Quick check question: If a graph has n nodes, how many unique adjacency matrices can represent it under permutation?

- Concept: Evidence lower bound (ELBO) and variational inference
  - Why needed here: The LCLF objective uses a lower bound on the true likelihood; understanding ELBO helps reason about approximation quality
  - Quick check question: Why is the ELBO always a lower bound on the true log-likelihood?

## Architecture Onboarding

- Component map: Adjacency matrix + node attributes -> SwinGNN layers with class conditioning -> Denoised adjacency matrix -> Classification via likelihood comparison

- Critical path:
  1. Load graph → permute adjacency matrix
  2. Concatenate with label embedding → pass through SwinGNN
  3. Compute denoising loss (LDEN) or classification loss (LCLF)
  4. Backpropagate and update model
  5. For inference: repeat steps 1-2 with multiple permutations → classify via majority vote

- Design tradeoffs:
  - Exact inference gives accurate likelihoods but is slow; approximate inference is fast but potentially less accurate
  - More permutations improve accuracy but increase inference time linearly
  - Training with permutations prevents overfitting but increases per-batch computation

- Failure signatures:
  - Low validation accuracy despite high training accuracy → overfitting; increase permutation augmentation
  - High variance across folds → instability; check if checkpoint selection is based on a reliable metric
  - Slow training/inference → reduce number of permutations or switch to approximate inference

- First 3 experiments:
  1. Train with LDEN objective, no permutations, exact inference; evaluate baseline performance
  2. Train with LCLF objective, 5 permutations, approximate inference; compare accuracy gain
  3. Vary number of inference permutations (1, 5, 10, 50, 100) with LCLF + approximate inference; plot accuracy vs. permutations

## Open Questions the Paper Calls Out
- The paper mentions exploring fine-tuning pre-trained generative diffusion models with the discriminative training objective as a valuable future direction
- Investigating the theoretical relationship between generative diffusion models and their discriminative capabilities could provide deeper insights
- Extending the permutation-based inference approach to larger graph datasets and understanding its scalability limitations

## Limitations
- The approach relies on computationally expensive exact likelihood computation for inference, though approximate methods help mitigate this
- Performance gains from permutation augmentation may diminish on larger graphs with more nodes
- The theoretical justification for why LCLF outperforms other objectives is limited to empirical results rather than formal analysis

## Confidence
- LCLF objective superiority: Medium - strong empirical results but lacks theoretical justification
- Permutation augmentation effectiveness: High - consistent accuracy gains across multiple datasets and ablation study
- Approximate inference efficiency claims: Medium - based on reported speedups rather than independent verification

## Next Checks
1. Reproduce the ablation study varying the number of inference permutations on IMDB-BINARY to verify the saturation point around 100 permutations
2. Implement the exact ODE-based likelihood computation and compare against the approximate LCLF inference on a subset of graphs to quantify the approximation error
3. Test the model on a larger graph classification dataset (e.g., REDDIT-BINARY) to assess scalability beyond the three datasets studied