---
ver: rpa2
title: Gradient-Free Training of Recurrent Neural Networks using Random Perturbations
arxiv_id: '2405.08967'
source_url: https://arxiv.org/abs/2405.08967
tags:
- learning
- time
- neural
- performance
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach to training recurrent neural
  networks (RNNs) using random perturbations, specifically extending activity-based
  node perturbation (ANP) to operate in the time domain. The method aims to overcome
  the limitations of backpropagation through time (BPTT), such as computational inefficiency
  and the need to store exact gradient information.
---

# Gradient-Free Training of Recurrent Neural Networks using Random Perturbations

## Quick Facts
- arXiv ID: 2405.08967
- Source URL: https://arxiv.org/abs/2405.08967
- Reference count: 40
- One-line primary result: Proposed method achieves similar performance to BPTT while strongly outperforming standard node and weight perturbation methods

## Executive Summary
This paper presents a novel approach to training recurrent neural networks (RNNs) using random perturbations, specifically extending activity-based node perturbation (ANP) to operate in the time domain. The method overcomes limitations of backpropagation through time (BPTT) by utilizing only forward passes and a global reinforcement signal, making it simpler and potentially more compatible with neuromorphic computing. The results demonstrate that this approach achieves comparable performance to BPTT while offering increased versatility and scalability.

## Method Summary
The method extends activity-based node perturbation (ANP) to temporal RNN training by injecting noise into network activations during forward passes and computing weight updates based on activity changes. Unlike standard node perturbation that uses injected noise directly, ANP approximates stochastic gradient descent more accurately by using δαt = ˜αt - αt (activity changes) instead of noise values. The approach employs local reinforcement signals δℓt computed at each time step, providing more precise credit assignment than global loss-based signals. A decorrelation mechanism further enhances learning efficiency by reducing redundancy in neural representations through a transformation matrix D applied to hidden layer inputs.

## Key Results
- Proposed method achieves similar performance, convergence time, and scalability compared to BPTT
- Strongly outperforms standard node and weight perturbation methods across multiple tasks
- Incorporating decorrelation mechanism enhances learning efficiency and generalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local reinforcement signals computed at each time step outperform global loss-based signals in perturbation-based RNN training
- Mechanism: Using δℓt = ˜ℓt - ℓt (difference in loss at each individual timestep) instead of total sequence loss difference provides more precise credit assignment that better aligns with temporal dynamics of error
- Core assumption: Error signal at each time step is sufficiently informative for learning, even without full sequence context
- Evidence anchors: [abstract] mentions global reinforcement signal; [section 2.2] describes local reinforcement signals; corpus contains papers on gradient-free methods but no direct comparison of local vs global signals
- Break condition: If local signal becomes too noisy or requires explicit temporal credit assignment over long sequences where local signals are insufficient

### Mechanism 2
- Claim: Activity-based node perturbation (ANP) approximates stochastic gradient descent more accurately than standard node perturbation
- Mechanism: ANP computes updates based on changes in neural activity (δαt = ˜αt - αt) rather than directly using injected noise, resulting in updates that better align with directional derivatives and SGD
- Core assumption: Relationship between activity changes and gradient direction is stable enough to provide useful learning signals
- Evidence anchors: [abstract] mentions more efficient learning and generalization; [section 2.3] states ANP is more precise approximation of SGD; corpus includes papers on gradient-free training but not specifically ANP mechanism
- Break condition: If activity-based computation becomes too computationally expensive relative to benefits, or if approximation breaks down for highly nonlinear activation functions

### Mechanism 3
- Claim: Decorrelation mechanism improves learning efficiency by reducing redundancy in neural representations
- Mechanism: Decorrelation matrix D transforms correlated hidden layer inputs into decorrelated inputs, reducing cross-correlation between neural outputs and making network less sensitive to noise in perturbation-based methods
- Core assumption: Reducing correlation between neural activities leads to more efficient learning and better generalization
- Evidence anchors: [abstract] mentions decorrelation enhances learning efficiency and generalization; [section 2.5] describes how decorrelating neural input allows for more efficient representation; corpus includes papers on local representation alignment and decorrelated batch normalization
- Break condition: If decorrelation mechanism introduces instability or if optimal level of correlation for task performance is violated

## Foundational Learning

- Concept: Temporal credit assignment
  - Why needed here: RNNs process sequential data where errors at time t may depend on decisions made at earlier time steps, requiring methods to propagate learning signals through time
  - Quick check question: How does the method handle the temporal credit assignment problem without backpropagation through time?

- Concept: Stochastic approximation of gradients
  - Why needed here: Method replaces exact gradient computation with random perturbations to avoid computational complexity of BPTT
  - Quick check question: What is the mathematical relationship between perturbation-based updates and true gradient descent?

- Concept: Local vs global learning signals
  - Why needed here: Method uses local reinforcement signals at each time step rather than global signals computed over entire sequences
  - Quick check question: How does using local reinforcement signals at each time step affect learning dynamics compared to using global signals?

## Architecture Onboarding

- Component map: Input -> RNN layer (with D matrix) -> Output, with parallel clean/noisy forward passes and weight update mechanism
- Critical path: 1) Forward pass with clean inputs, 2) Parallel forward pass with noise injection, 3) Compute local loss differences at each time step, 4) Calculate activity changes or noise-based updates, 5) Apply weight updates using computed gradients, 6) Update decorrelation matrix in parallel
- Design tradeoffs: Local vs global reinforcement signals (local provides better temporal credit assignment but may be noisier), activity-based vs noise-based perturbation (ANP better approximates SGD but requires additional computation), decorrelation strength (more decorrelation improves efficiency but may harm task performance if taken too far)
- Failure signatures: Weight explosion or NaN values (indicates learning rate too high or instability in perturbation updates), poor convergence (may indicate insufficient noise variance or inappropriate learning rate), degraded performance with decorrelation (may indicate over-decorrelation removing useful correlations), memory issues (BPTT with decorrelation can consume excessive memory due to unrolling)
- First 3 experiments: 1) Copy memory task with varying sequence lengths to test temporal learning capabilities, 2) Scalability test with increasing number of hidden units to verify stability, 3) Ablation study comparing local vs global reinforcement signals on Mackey-Glass task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance of proposed perturbation-based method compare to gradient-based methods like BPTT on large-scale neural networks?
- Basis in paper: [inferred] Paper mentions proposed method achieves similar performance to BPTT on various tasks but doesn't provide specific results on large-scale networks
- Why unresolved: Paper doesn't include experiments on very large neural networks crucial for assessing efficacy of alternative learning algorithms
- What evidence would resolve it: Experimental results on large-scale neural networks demonstrating performance of proposed method compared to gradient-based methods

### Open Question 2
- Question: Can proposed perturbation-based method be extended to more complex gated recurrent structures like LSTM and GRU units?
- Basis in paper: [explicit] Paper mentions further validation on other challenging real-world datasets and exploration of performance in more complex gated recurrent structures like LSTM and GRU units are potential avenues for future research
- Why unresolved: Paper focuses on RNNs with single hidden layer and doesn't explore performance of proposed method on more complex recurrent structures
- What evidence would resolve it: Experimental results on LSTM and GRU units demonstrating performance of proposed method compared to gradient-based methods

### Open Question 3
- Question: How does computational cost of proposed perturbation-based method scale with size of neural network?
- Basis in paper: [explicit] Paper mentions proposed method offers increased versatility and is potentially compatible with neuromorphic hardware due to local computations, but doesn't provide specific information on how computational cost scales with network size
- Why unresolved: Paper doesn't include detailed analysis of computational cost of proposed method as network size increases
- What evidence would resolve it: Experimental results measuring computational cost of proposed method on networks of increasing size, demonstrating how it scales compared to gradient-based methods

## Limitations

- Limited empirical comparisons between local and global reinforcement signals could benefit from more systematic ablation studies
- Decorrelation mechanism's impact varies across tasks and optimal parameters are not fully characterized
- Paper doesn't explore extension to more complex gated recurrent structures like LSTM and GRU units

## Confidence

- High confidence: Basic claim that ANP extends to temporal domains and outperforms standard NP/WP methods - well-supported by experimental results across multiple tasks
- Medium confidence: Claim that local reinforcement signals outperform global signals - supported by experiments but could benefit from more systematic ablation studies
- Medium confidence: Decorrelation mechanism improves learning efficiency - results are positive but mechanism's impact varies across tasks and optimal parameters are not fully characterized

## Next Checks

1. **Ablation study on decorrelation**: Systematically vary decorrelation strength parameter across multiple orders of magnitude to identify optimal range and characterize performance tradeoff curve

2. **Local vs global signal comparison**: Conduct more rigorous comparison by testing both signal types across wider range of sequence lengths and noise levels to determine when each approach is preferable

3. **Memory complexity analysis**: Measure and compare actual memory usage of BPTT with decorrelation versus proposed method, particularly for long sequences, to quantify claimed memory efficiency gains