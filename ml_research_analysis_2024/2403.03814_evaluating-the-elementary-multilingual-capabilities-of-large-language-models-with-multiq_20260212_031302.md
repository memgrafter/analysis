---
ver: rpa2
title: Evaluating the Elementary Multilingual Capabilities of Large Language Models
  with MultiQ
arxiv_id: '2403.03814'
source_url: https://arxiv.org/abs/2403.03814
tags:
- language
- languages
- accuracy
- questions
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MultiQ, a silver-standard benchmark of 27,400
  open-ended questions across 137 typologically diverse languages, to evaluate the
  multilingual capabilities of six open large language models. The study measures
  language fidelity (whether models respond in the prompted language) and question-answering
  accuracy.
---

# Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ

## Quick Facts
- arXiv ID: 2403.03814
- Source URL: https://arxiv.org/abs/2403.03814
- Reference count: 24
- Key outcome: MultiQ benchmark reveals tokenization strategy significantly impacts multilingual QA accuracy across 137 languages.

## Executive Summary
This paper introduces MultiQ, a silver-standard benchmark of 27,400 open-ended questions across 137 typologically diverse languages, to evaluate the multilingual capabilities of six open large language models. The study measures language fidelity (whether models respond in the prompted language) and question-answering accuracy. Results show all models achieve some multilingual capability, with language fidelity and accuracy generally improving together. Models exhibit higher accuracy when responding in the same language as prompted. Tokenization differences, particularly subword versus character encoding, correlate with multilingual performance. Despite being intended for English-only use, models like Mistral demonstrate strong multilingual fidelity, while others like Llama2 show low fidelity but relatively high accuracy when responding in English.

## Method Summary
The study creates MultiQ by automatically translating questions from English to 137 languages using Google Translate with quality filters. Six open-source LLMs (Llama2 variants, Mistral, Mixtral, Qwen) generate responses using default parameters. Language fidelity is evaluated using GlotLID, while QA accuracy is assessed through a carefully crafted GPT-4 classifier. The researchers analyze tokenization strategies by classifying languages based on subword, character, or ASCII encoding patterns, then correlate these with performance metrics.

## Key Results
- All six models demonstrate multilingual capabilities, with accuracy ranging from 6.4% to 24.0% depending on tokenization strategy
- Language fidelity and QA accuracy are positively correlated across all models
- Subword tokenization consistently outperforms character and ASCII encoding strategies
- Models achieve higher accuracy when responding in the same language as prompted

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tokenization strategy directly impacts multilingual QA accuracy.
- Mechanism: Models that can tokenize prompts into subwords rather than characters or ASCII tokens achieve higher accuracy on those languages.
- Core assumption: Subword tokenization allows the model to leverage learned representations for common language patterns, while character/ASCII tokenization forces the model to treat each symbol as a novel token without semantic context.
- Evidence anchors:
  - [abstract] "Tokenization differences, particularly subword versus character encoding, correlate with multilingual performance."
  - [section] "Subword encoding outperforms character and ASCII encodings, with Mistral and Llama2 respectively achieving 20.4% and 24.0% accuracy on subword-encoded languages compared to just 6.4% and 11.4% on character-encoded languages."
  - [corpus] Weak - corpus shows related papers on evaluation frameworks but not direct tokenization experiments.
- Break condition: If a model's tokenizer has extensive coverage of a language's vocabulary, the subword advantage may diminish or disappear.

### Mechanism 2
- Claim: Language fidelity (responding in the prompted language) positively impacts QA accuracy.
- Mechanism: When models generate answers in the same language as the prompt, they can leverage language-specific knowledge and patterns more effectively than when switching languages.
- Core assumption: The model's internal representations are more coherent and accurate when operating within a single language context rather than translating between languages.
- Evidence anchors:
  - [abstract] "Models exhibit higher accuracy when responding in the same language as prompted."
  - [section] "Most models are more accurate when they respond faithfully."
  - [corpus] Weak - corpus shows related evaluation frameworks but limited direct evidence of fidelity-accuracy relationship.
- Break condition: If a model has exceptional cross-lingual transfer capabilities, the fidelity-accuracy correlation may weaken or reverse.

### Mechanism 3
- Claim: Models can develop multilingual capabilities despite being trained primarily on English data through data contamination and cross-lingual transfer.
- Mechanism: Small amounts of non-English content in the training data, combined with the model's ability to transfer knowledge across languages, enables multilingual performance beyond intended use.
- Core assumption: The model can extract and apply linguistic patterns from limited multilingual exposure to perform reasonably on languages it wasn't explicitly trained for.
- Evidence anchors:
  - [abstract] "Despite being intended for English-only use, models like Mistral demonstrate strong multilingual fidelity."
  - [section] "Blevins and Zettlemoyer (2022) explained this behavior through data contamination: while the vast majority of the pre-training data of those models is English... there are also small portions of non-English content in the pre-training data."
  - [corpus] Moderate - corpus shows related papers on multilingual LLM evaluation and generation capabilities.
- Break condition: If training data is extremely clean and monolingual with no contamination, this mechanism would fail.

## Foundational Learning

- Concept: Tokenization strategies (subword vs character vs ASCII)
  - Why needed here: Understanding how different tokenization approaches affect model performance on multilingual tasks is central to interpreting the results and explaining performance differences between models.
  - Quick check question: What are the advantages of subword tokenization over character-level tokenization for multilingual language models?

- Concept: Language fidelity vs accuracy tradeoff
  - Why needed here: The paper investigates whether models that respond in the prompted language (high fidelity) also achieve higher accuracy, which requires understanding the relationship between these two dimensions of multilingual performance.
  - Quick check question: How might a model achieve high accuracy while having low language fidelity, and what would this imply about its multilingual capabilities?

- Concept: Typological diversity and language families
  - Why needed here: The dataset covers 137 typologically diverse languages across 20 families, and understanding language relationships helps interpret performance patterns and tokenization effects.
  - Quick check question: Why is it important to include typologically diverse languages when evaluating multilingual model capabilities?

## Architecture Onboarding

- Component map: MultiQ question generation → Model response collection → GlotLID language detection → GPT-4 accuracy evaluation → Tokenization analysis
- Critical path: MultiQ question generation → Model response collection → Automated evaluation (both fidelity and accuracy) → Statistical analysis of results
- Design tradeoffs: Automated translation and evaluation introduce noise but enable coverage of 137 languages; using existing LID models rather than training new ones saves resources but may have accuracy limitations; focusing on basic QA rather than complex reasoning makes the benchmark more accessible but less comprehensive
- Failure signatures: Low fidelity with high accuracy suggests the model is translating to a high-resource language; high fidelity with low accuracy suggests the model is repeating the question or lacks knowledge in that language; inconsistent tokenization across languages indicates tokenizer limitations
- First 3 experiments:
  1. Compare tokenization strategies across languages by manually inspecting model tokenizations for a sample of languages to validate the automated classification
  2. Test model responses with and without system prompts to see if prompting affects fidelity and accuracy patterns
  3. Analyze correlation between training data language distribution and performance on MultiQ languages to understand contamination effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does tokenization strategy specifically impact multilingual QA accuracy beyond the correlation observed in the study?
- Basis in paper: [explicit] The paper identifies tokenization differences as a potential explanation for multilingual performance variations, showing subword encoding outperforms character and ASCII encodings.
- Why unresolved: The study only establishes a correlation between tokenization strategy and accuracy, not causation. It doesn't test whether changing tokenization strategies would directly improve multilingual performance.
- What evidence would resolve it: Controlled experiments testing models with modified tokenization strategies (e.g., retraining with different tokenizers) to measure direct impact on multilingual QA accuracy across diverse languages.

### Open Question 2
- Question: What are the specific training data characteristics that contribute to models' multilingual capabilities beyond their intended use?
- Basis in paper: [inferred] The paper mentions investigating tokenization as an explanation but notes little public information on training data composition, suggesting this is a key unknown factor.
- Why unresolved: The paper acknowledges that proprietary models like GPT-4 may have multilingual capabilities despite being intended for English, but doesn't investigate what training data characteristics enable this.
- What evidence would resolve it: Detailed analysis of training corpora composition across different language domains and frequencies, particularly focusing on underrepresented languages in the training data.

### Open Question 3
- Question: How do different multilingual fallback behaviors (e.g., Mistral's tendency to repeat questions) impact practical usability of models in real-world multilingual settings?
- Basis in paper: [explicit] The paper notes that Mistral often repeats questions instead of answering them, technically being "faithful" but never accurate, raising questions about practical utility.
- Why unresolved: The study measures fidelity and accuracy separately but doesn't evaluate how these behaviors affect actual user experience when prompting models in non-intended languages.
- What evidence would resolve it: User studies measuring task completion rates and satisfaction when using models in their non-intended languages, particularly comparing different fallback behaviors across models.

## Limitations
- Translation quality issues from Google Translate may introduce systematic biases, particularly for low-resource languages
- Automated evaluation pipeline using GPT-4 and GlotLID may have accuracy limitations and unknown failure modes
- Tokenization classification heuristic may misclassify some languages or miss mixed tokenization approaches

## Confidence
- High Confidence: The core finding that tokenization strategy correlates with multilingual performance is supported by clear quantitative evidence (20.4% vs 6.4% accuracy differences)
- Medium Confidence: The observation that models achieve higher accuracy when responding in the prompted language is supported by the data, but the causal relationship between fidelity and accuracy remains uncertain
- Medium Confidence: The conclusion that multilingual capabilities emerge through data contamination is plausible but difficult to quantify with available data

## Next Checks
1. Manual validation of tokenization classification for 10-15 languages across different language families to ensure the automated heuristic accurately captures tokenization approaches
2. Human evaluation of model responses and accuracy assessments for a subset of 5-10 languages to validate the GPT-4 evaluation pipeline
3. Cross-validation with alternative LID system to assess sensitivity of fidelity measurements to the choice of language identification model