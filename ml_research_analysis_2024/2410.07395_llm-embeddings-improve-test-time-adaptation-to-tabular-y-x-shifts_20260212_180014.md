---
ver: rpa2
title: LLM Embeddings Improve Test-time Adaptation to Tabular $Y|X$-Shifts
arxiv_id: '2410.07395'
source_url: https://arxiv.org/abs/2410.07395
tags:
- tabular
- target
- domain
- samples
- finetuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of distribution shifts in tabular
  data where the relationship between labels and features changes across domains,
  often due to missing confounders. The authors propose using large language model
  (LLM) embeddings as feature representations for tabular data by serializing rows
  into natural language prompts and feeding them into an LLM encoder.
---

# LLM Embeddings Improve Test-time Adaptation to Tabular $Y|X$-Shifts

## Quick Facts
- arXiv ID: 2410.07395
- Source URL: https://arxiv.org/abs/2410.07395
- Reference count: 40
- Key outcome: Finetuning shallow neural networks on LLM embeddings with as few as 32 labeled target samples significantly improves test-time adaptation to tabular Y|X-shifts

## Executive Summary
This paper explores using LLM embeddings for test-time adaptation to distribution shifts in tabular data where the relationship between labels and features changes across domains. The authors serialize tabular rows into natural language prompts and use an LLM encoder to generate embeddings, then train and finetune shallow neural networks on these representations. While LLM embeddings alone show inconsistent robustness improvements compared to tree-based methods, finetuning with just 32 labeled target samples significantly improves performance across multiple datasets and algorithms. The approach is particularly effective for stronger label-feature shifts and outperforms both standard tabular models and in-context learning baselines.

## Method Summary
The method involves serializing tabular data into natural language prompts describing each row's features and task, then encoding these with an LLM (e5-Mistral-7B-Instruct) to generate 4096-dimensional embeddings. A shallow neural network is trained on source domain data using these embeddings, with optional domain information concatenated to provide additional context. The model is then validated and finetuned using a small number of labeled target samples (up to 32), with hyperparameter selection performed using a held-out validation set from the target domain. The approach is evaluated across 7,650 source-target domain pairs from three real-world ACS datasets, testing 22 algorithms and over 261,000 configurations.

## Key Results
- Finetuning with 32 labeled target samples improves performance from 85% to 86% FractionBest ratio on ACS Income dataset
- LLM embeddings alone provide inconsistent robustness improvements compared to tree-ensemble methods
- Performance gains are especially pronounced under stronger label-feature shifts
- The lightweight approach (only finetuning shallow network, not LLM) makes it computationally efficient

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LLM embeddings reduce the Y|X shift by encoding contextual semantic information that helps bridge domain gaps.
- **Mechanism**: The LLM encoder captures world knowledge during pre-training that compensates for missing confounders in tabular data. By serializing tabular rows into natural language, the LLM can use this knowledge to create embeddings that maintain predictive relationships across domains even when raw features change.
- **Core assumption**: The LLM's pre-training corpus contains relevant information about the domain semantics that affects Y|X relationships.
- **Evidence anchors**:
  - [abstract] "Using the wealth of world knowledge learned during pre-training, LLMs have the potential to build representations that mitigate the impact of confounders whose distribution changes across source and target."
  - [section] "We find LLM embeddings sometimes improve robustness, but do not consistently surpass state-of-the-art tree-ensemble methods."
- **Break condition**: If the LLM's pre-training data lacks domain-specific knowledge relevant to the tabular task, the embeddings will not provide Y|X shift mitigation.

### Mechanism 2
- **Claim**: Finetuning the shallow neural network on LLM embeddings with target samples significantly improves performance.
- **Mechanism**: Even with limited target samples (32), finetuning the shallow NN on LLM embeddings allows the model to adapt the feature representations to the specific Y|X relationship in the target domain, while the LLM embeddings provide a semantically rich starting point.
- **Core assumption**: The shallow NN can effectively learn to map LLM embeddings to target labels when given even small amounts of target data.
- **Evidence anchors**:
  - [abstract] "models trained on them can be well adapted/finetuned to the target domain even using 32 labeled observations."
  - [section] "When finetuning with just 32 target samples for finetuning, the FractionBest ratio improves from 85% to 86% on ACS Income."
- **Break condition**: If the target sample size is too small relative to the model complexity, overfitting may occur and negate the benefits.

### Mechanism 3
- **Claim**: Additional domain information (e.g., Wikipedia) further improves LLM embedding performance for Y|X shifts.
- **Mechanism**: Incorporating domain-specific contextual information provides additional semantic cues that help the LLM embeddings better capture the Y|X relationship by providing relevant background knowledge about the domain.
- **Core assumption**: The additional domain information contains relevant context that affects the Y|X relationship in the target domain.
- **Evidence anchors**:
  - [section] "incorporating the 'right' domain information has an outsize impact on tabular Y|X-shifts. As shown in Figure 6 (f), for ACS Pub.Cov with finetuning, adding additional domain information from Wikipedia improve F1 scores by 1.4pp on average."
  - [corpus] Weak evidence - only 5 related papers found, none specifically addressing LLM embeddings with domain information for tabular Y|X shifts.
- **Break condition**: If the domain information is irrelevant or noisy, it may confuse the model rather than improve performance.

## Foundational Learning

- **Concept**: Distribution shifts (X-shifts vs Y|X-shifts)
  - Why needed here: Understanding the difference is crucial because this work specifically targets Y|X shifts where the label-feature relationship changes, not just feature distributions.
  - Quick check question: What is the key difference between X-shifts and Y|X-shifts, and why is Y|X-shifts particularly challenging for tabular data?

- **Concept**: Test-time adaptation
  - Why needed here: The paper focuses on adapting models to target domains using few labeled examples, which is a specific form of domain adaptation performed at test time.
  - Quick check question: Why is test-time adaptation with few labeled samples particularly relevant for real-world tabular data applications?

- **Concept**: Large language model embeddings
  - Why needed here: Understanding how LLMs can be used to generate feature representations for non-text data like tabular rows is fundamental to this approach.
  - Quick check question: How does serializing tabular data into natural language enable the use of LLM embeddings for tabular prediction tasks?

## Architecture Onboarding

- **Component map**:
  Data serialization layer -> LLM encoder -> Domain information module -> Shallow neural network -> Target adaptation module

- **Critical path**:
  1. Serialize tabular data â†’ LLM embeddings
  2. (Optional) Generate and concatenate domain information embeddings
  3. Train shallow NN on source domain data
  4. Validate and select hyperparameters using target validation set
  5. Finetune on target domain samples (if available)
  6. Evaluate on target test set

- **Design tradeoffs**:
  - LLM embedding size (4096) vs computational cost
  - Shallow NN depth vs overfitting risk with limited target samples
  - Domain information relevance vs noise
  - Target sample allocation between validation and finetuning

- **Failure signatures**:
  - Performance drops when LLM embeddings don't capture relevant domain semantics
  - Overfitting when finetuning with too few target samples on complex models
  - Inconsistent improvements across different datasets indicating dataset-specific limitations
  - Degradation when irrelevant domain information is added

- **First 3 experiments**:
  1. Compare LLM embeddings vs raw tabular features on a simple dataset to verify basic mechanism
  2. Test finetuning with varying numbers of target samples (16, 32, 64) to find optimal allocation
  3. Evaluate impact of different domain information sources (Wikipedia vs GPT-4 vs target samples) on a single dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different LLM encoders (beyond e5-Mistral-7B-Instruct) affect the performance of LLM embeddings for tabular Y|X-shifts?
- Basis in paper: [explicit] The paper explicitly states "Investigating how different LLM encoders, e.g., LLMs specialized for tabular data [62], affect tabular Y|X shifts is left as a future work."
- Why unresolved: The study only used e5-Mistral-7B-Instruct as the LLM encoder, so the impact of alternative encoders remains untested.
- What evidence would resolve it: A systematic comparison of multiple LLM encoders (including those specialized for tabular data) across the same benchmark would reveal which encoder types yield the best performance for Y|X-shift adaptation.

### Open Question 2
- Question: What is the optimal allocation strategy for labeled target samples between validation and finetuning?
- Basis in paper: [explicit] The paper states "Identifying the best allocation strategy is left as future work" and notes that "optimal allocation strategy is left as future work" in the context of sample allocation.
- Why unresolved: While the paper compares two allocation schemes (64 all for validation vs 32/32 split), it does not explore other ratios or dynamic allocation strategies.
- What evidence would resolve it: Empirical studies testing multiple allocation ratios and potentially adaptive allocation methods would determine the optimal split for different dataset characteristics and shift severities.

### Open Question 3
- Question: Which types of domain information are most effective for improving LLM embedding performance under Y|X-shifts?
- Basis in paper: [explicit] The paper notes that "additional domain information can either improve or reduce F1 scores" and that "identifying the best domain information requires non-trivial engineering efforts, which we leave for future work."
- Why unresolved: The study tested Wikipedia, GPT-4, and target-sample serialization, but did not systematically evaluate what makes domain information "right" or compare other potential sources.
- What evidence would resolve it: A comprehensive analysis of different domain information sources (e.g., economic indicators, demographic statistics, domain-specific knowledge bases) and their characteristics would identify which types consistently improve performance across different tabular tasks.

## Limitations
- The effectiveness of LLM embeddings is highly dataset-dependent, with significant performance variations across the three ACS datasets tested
- The approach requires careful prompt engineering and domain information selection, with no clear guidance on optimal choices for new domains
- Limited evaluation of more complex Y|X shifts beyond the three ACS datasets, raising questions about generalizability

## Confidence
- **High confidence**: The core finding that finetuning with 32 target samples improves performance over baseline methods
- **Medium confidence**: The claim that LLM embeddings alone provide inconsistent robustness improvements, as results vary significantly across datasets
- **Low confidence**: The assertion that domain information consistently improves performance, given limited empirical evidence (only one dataset showing improvement)

## Next Checks
1. Test the approach on non-ACS tabular datasets with known Y|X shifts to assess generalizability beyond census data
2. Systematically evaluate different prompt engineering strategies and domain information sources to identify optimal configurations
3. Conduct ablation studies varying target sample sizes (8, 16, 32, 64) to determine the minimum effective sample size for finetuning