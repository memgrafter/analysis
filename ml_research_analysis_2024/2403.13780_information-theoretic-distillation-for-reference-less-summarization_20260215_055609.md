---
ver: rpa2
title: Information-Theoretic Distillation for Reference-less Summarization
arxiv_id: '2403.13780'
source_url: https://arxiv.org/abs/2403.13780
tags:
- summary
- summarization
- summ
- info
- summaries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: INFO SUMM proposes a novel framework to distill a powerful summarization
  model without relying on large language models (LLMs) or human-written references.
  The method formulates the desiderata of summarization (saliency, faithfulness, and
  brevity) as maximizing mutual information between document and summary, then self-trains
  a small off-the-shelf language model through expert iteration to align with this
  objective.
---

# Information-Theoretic Distillation for Reference-less Summarization

## Quick Facts
- **arXiv ID**: 2403.13780
- **Source URL**: https://arxiv.org/abs/2403.13780
- **Reference count**: 40
- **Primary result**: INFO SUMM distills a 568M parameter summarizer that achieves comparable zero-shot performance to ChatGPT on news summarization benchmarks.

## Executive Summary
INFO SUMM introduces a novel framework for training summarization models without relying on human-written references or LLM outputs. The method formulates the core desiderata of summarization—saliency, faithfulness, and brevity—as maximizing point-wise mutual information (PMI) between document and summary under length constraints. Through expert iteration, a small off-the-shelf language model self-trains to align with this information-theoretic objective, generating high-quality synthetic data. A compact student model is then distilled from this improved teacher, achieving competitive performance against much larger models like ChatGPT while exhibiting superior controllability.

## Method Summary
The framework starts with an off-the-shelf language model (Pythia-2.8B) that is not initially capable of summarization. The model generates document-summary pairs using PMI maximization decoding, which are filtered by self-supervised critics based on saliency, faithfulness, and brevity measures. The teacher model is then trained on high-quality filtered pairs through expert iteration, improving its generation capability. Finally, a compact student model (PEGASUS-568M) is distilled from the improved teacher on a large-scale dataset generated from the enhanced model.

## Key Results
- INFO SUMM-0.5B achieves comparable zero-shot performance to ChatGPT on news summarization benchmarks (CNN/DailyMail, XSum, SAMSum)
- Outperforms in-domain supervised models in human evaluation of fluency, faithfulness, saliency, and controllability
- Exhibits significantly better controllability than prompting ChatGPT, with ability to control summary length, focus, and style
- Demonstrates strong zero-shot generalization to unseen domains like WikiHow and Reddit TIFU

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-training through expert iteration allows small LMs to learn summarization by aligning with an explicit information-theoretic objective rather than imitating human references or LLM outputs.
- Mechanism: The off-the-shelf teacher model generates document-summary pairs, which are filtered by self-supervised critics based on PMI maximization under length constraints. The model is then trained on the high-quality filtered pairs, improving its generation quality iteratively.
- Core assumption: A small LM can generate meaningful document-summary pairs if guided by an explicit search objective, even without initial summarization capability.
- Evidence anchors:
  - [abstract]: "we present INFO SUMM, a novel framework to distill a powerful summarizer based on the information-theoretic objective for summarization, without relying on either the LLM's capability or human-written references."
  - [section]: "Based on this formulation, we start off from Pythia-2.8B as the teacher model, which is not yet capable of summarization, then self-train the model to optimize for the information-centric measures of ideal summaries."
  - [corpus]: Weak evidence - the corpus contains papers on rate-distortion frameworks and information-theoretic distillation but lacks direct empirical support for PMI maximization in summarization.
- Break condition: If the self-supervised critics fail to distinguish high-quality from low-quality pairs, the iterative training loop produces noisy data that degrades the teacher model's capability.

### Mechanism 2
- Claim: The information-theoretic objective unifies saliency, faithfulness, and brevity through PMI maximization under length constraints.
- Mechanism: Saliency is measured by how well a summary helps recover masked document tokens; faithfulness is measured by how well the document helps recover masked summary tokens; brevity is enforced via a length ratio constraint. The product of these three filters ensures summaries are informative, accurate, and concise.
- Core assumption: Mutual information between document and summary captures the essential properties of a good summary.
- Evidence anchors:
  - [abstract]: "we propose that the three evaluative dimensions of summarization—saliency, faithfulness and brevity—can be incorporated into a unified search objective, where we look for a summary y that maximizes its point-wise mutual information (PMI) with the document x under a length constraint."
  - [section]: "Specifically, in case of the saliency critic, log pMLM(x|xmask, y) / pMLM(x|xmask) ≈ log p(x|y) / p(x) = log p(x, y) / p(x)p(y) = PMI(x; y)."
  - [corpus]: Weak evidence - the corpus mentions rate-distortion frameworks but does not validate PMI maximization for text summarization.
- Break condition: If PMI estimation via masked language models is unreliable, the critics cannot accurately filter high-quality pairs, undermining the objective's effectiveness.

### Mechanism 3
- Claim: Distilling from an improved teacher yields a compact summarizer that outperforms both unsupervised baselines and ChatGPT in controllability.
- Mechanism: The improved teacher, aligned with the information-theoretic objective, generates a large-scale high-quality dataset. A small student model is then trained on this dataset, inheriting the teacher's capability without inheriting its size.
- Core assumption: A compact student model can learn to summarize effectively when trained on high-quality synthetic data rather than human-written references.
- Evidence anchors:
  - [abstract]: "Distilling from the improved teacher, we arrive at a compact but powerful summarizer with only 568M parameters that performs competitively against ChatGPT."
  - [section]: "Finally, we distill an expert summarizer Msumm from the improved teacher MT... we fine-tune a student LM into an expert summarization model."
  - [corpus]: No direct evidence in corpus - this mechanism is specific to the INFO SUMM framework.
- Break condition: If the student model overfits to the synthetic dataset or the teacher's quality degrades during iteration, the distilled model fails to generalize.

## Foundational Learning

- Concept: Mutual information and PMI as measures of shared information between variables.
  - Why needed here: The entire framework is built on maximizing PMI between document and summary to capture saliency, faithfulness, and brevity simultaneously.
  - Quick check question: What does PMI(x;y) represent in terms of probability distributions?

- Concept: Masked language modeling for information estimation.
  - Why needed here: The self-supervised critics use MLM to estimate PMI by measuring how well tokens can be recovered when masked, given the other modality (document or summary).
  - Quick check question: How does masking tokens in the document and conditioning on the summary allow us to estimate saliency?

- Concept: Expert iteration in reinforcement learning.
  - Why needed here: The teacher model is iteratively improved by training on its own high-quality outputs, a form of self-play that aligns the model with the target objective.
  - Quick check question: What is the difference between expert iteration and imitation learning?

## Architecture Onboarding

- Component map: Pythia-2.8B (teacher LM) -> Self-supervised critics (saliency, faithfulness, brevity) -> Expert iteration loop -> Distillation stage (PEGASUS-568M student)
- Critical path: Teacher generation → Critic filtering → Expert iteration → Dataset distillation → Student training
- Design tradeoffs: Larger teacher models generate more diverse pairs but are costlier; stricter critics yield higher-quality data but lower sampling efficiency
- Failure signatures: Low sampling efficiency (<1%), over-optimized teacher with reduced diversity, student overfitting to synthetic data
- First 3 experiments:
  1. Measure sampling efficiency of initial teacher with PMI-maximization decoding vs. nucleus sampling
  2. Test human evaluation of summaries generated by teacher after 1 vs. 2 expert iteration steps
  3. Compare ROUGE scores of student models trained on datasets with different critic thresholds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the sampling efficiency of INFO SUMM scale with the size of the teacher model? Does using a larger teacher model lead to proportionally better results or are there diminishing returns?
- Basis in paper: [inferred] The paper mentions using Pythia-2.8B as the teacher model and discusses the sampling efficiency of the framework. It also mentions that the initial teacher model has a very low sampling efficiency of 0.9%.
- Why unresolved: The paper does not provide experiments or analysis on how the sampling efficiency changes with different teacher model sizes. It only focuses on the results with Pythia-2.8B.
- What evidence would resolve it: Experiments comparing the sampling efficiency and final model performance when using different sizes of teacher models, such as Pythia-1.0B, Pythia-2.8B, and larger models like LLaMA-33B or LLaMA-65B.

### Open Question 2
- Question: How robust is the distilled model to adversarial inputs or out-of-distribution documents? Does the model maintain performance on documents that are very different from the training data in terms of style, length, or domain?
- Basis in paper: [inferred] The paper demonstrates the model's performance on zero-shot summarization of news articles and its ability to generalize to unseen domains like WikiHow and Reddit TIFU. However, it does not test the model's robustness to adversarial or highly out-of-distribution inputs.
- Why unresolved: The paper does not include experiments that specifically test the model's robustness to adversarial or out-of-distribution inputs. It only shows performance on in-domain and slightly out-of-domain data.
- What evidence would resolve it: Experiments evaluating the model's performance on adversarial inputs (e.g., documents with misleading or irrelevant information) and highly out-of-distribution documents (e.g., scientific papers, legal documents, or social media posts).

### Open Question 3
- Question: How does the proposed PMI maximization objective compare to other unsupervised objectives for summarization, such as reconstruction-based objectives or adversarial training?
- Basis in paper: [explicit] The paper proposes PMI maximization as the objective for summarization and compares it to other unsupervised methods like TL;DR, SEQ3, Summary Loop, TED, and WikiTransfer. However, it does not directly compare PMI maximization to other unsupervised objectives.
- Why unresolved: The paper only compares PMI maximization to other unsupervised methods indirectly through their final performance on summarization tasks. It does not provide a direct comparison of the objectives themselves.
- What evidence would resolve it: Experiments that train models using different unsupervised objectives (e.g., reconstruction-based, adversarial training) and compare their performance on the same summarization tasks, as well as analyzing the generated summaries in terms of their adherence to the proposed desiderata of saliency, faithfulness, and brevity.

## Limitations

- Sampling efficiency is extremely low initially (0.4-0.6%), raising concerns about scalability and practical deployment costs
- All experiments focus on news summarization, with unknown performance on other domains like scientific papers or dialogue
- Self-supervised critics rely on MLM-based PMI estimation, which may be noisy and affect the quality of generated data

## Confidence

**High Confidence**: The core information-theoretic framework (PMI maximization under length constraints) is well-specified and theoretically grounded. The distillation process from teacher to student is clearly described.

**Medium Confidence**: The claim that INFO SUMM-0.5B achieves "comparable zero-shot performance to ChatGPT" is supported by ROUGE and BERTScore metrics, but these automated metrics have known limitations for summarization quality assessment.

**Low Confidence**: The controllability claims are based on human evaluation with unspecified sample sizes and methodology. The paper doesn't provide statistical significance testing for the human evaluation results.

## Next Checks

1. **Cross-Domain Validation**: Evaluate INFO SUMM on non-news summarization tasks (e.g., scientific paper abstracts, meeting notes, or dialogue summarization) to test domain generalization.

2. **Critic Ablation Study**: Systematically vary the critic thresholds (τS, τF, τB) and measure the impact on sampling efficiency, teacher quality, and final student performance to understand the sensitivity to hyperparameter choices.

3. **Statistical Significance Testing**: Conduct proper statistical tests (e.g., paired t-tests) on human evaluation results across different systems to determine if observed differences in fluency, faithfulness, and controllability are statistically significant.