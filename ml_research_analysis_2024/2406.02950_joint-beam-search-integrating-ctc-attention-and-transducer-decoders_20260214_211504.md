---
ver: rpa2
title: Joint Beam Search Integrating CTC, Attention, and Transducer Decoders
arxiv_id: '2406.02950'
source_url: https://arxiv.org/abs/2406.02950
tags:
- rnn-t
- beam
- attention
- search
- decoder
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a joint modeling scheme where four decoders
  (CTC, RNN-T, attention, and Mask-CTC) share the same encoder, referred to as 4D
  modeling. The 4D model is trained jointly, which brings model regularization and
  maximizes model robustness thanks to their complementary properties.
---

# Joint Beam Search Integrating CTC, Attention, and Transducer Decoders

## Quick Facts
- arXiv ID: 2406.02950
- Source URL: https://arxiv.org/abs/2406.02950
- Authors: Yui Sudo; Muhammad Shakeel; Yosuke Fukumoto; Brian Yan; Jiatong Shi; Yifan Peng; Shinji Watanabe
- Reference count: 40
- Key outcome: Proposes 4D modeling with four decoders (CTC, RNN-T, attention, Mask-CTC) sharing a conformer encoder, trained jointly with a two-stage strategy and novel one-pass beam search algorithms

## Executive Summary
This paper introduces a joint modeling scheme called 4D modeling where four distinct ASR decoders (CTC, RNN-T, attention, and Mask-CTC) share a single conformer encoder. The model is trained jointly using a weighted sum of four different losses, which provides regularization and robustness through the complementary properties of the decoders. Additionally, the authors propose three novel one-pass beam search algorithms that integrate CTC, RNN-T, and attention decoders with different primary decoders, achieving better performance than traditional CTC/attention decoding approaches.

## Method Summary
The 4D model architecture consists of a shared conformer encoder (12 blocks, 2048 units) with four separate decoders: CTC (linear layer), attention-based encoder-decoder (6 transformer blocks), RNN-T (LSTM prediction network + joint network), and Mask-CTC (6 transformer blocks). Training follows a two-stage strategy where equal weights are initially used, then adjusted proportionally based on validation loss minima. Three one-pass beam search variants are introduced where one decoder serves as the primary hypothesis generator while the others provide prefix scores for joint rescoring, with RNN-T-driven search avoiding computationally expensive RNN-T prefix scoring.

## Key Results
- The jointly trained 4D model outperforms individual decoder models on both LibriSpeech (960h, 100h) and in-house Japanese dataset (93h)
- One-pass beam search algorithms combining CTC, RNN-T, and attention decoders achieve better WER than CTC/attention baseline
- RNN-T-driven one-pass beam search provides the best WER-RTF tradeoff by avoiding RNN-T prefix scoring
- Mask-CTC decoder contributes to the joint regularization effect when combined with other decoders

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint training with four decoders improves individual decoder performance by providing regularization
- Mechanism: Multitask learning with four distinct decoder architectures forces the shared encoder to learn robust representations that benefit each decoder
- Core assumption: The decoders have complementary strengths and weaknesses that create diverse training signals
- Evidence anchors: Abstract mentions regularization and complementary properties; Section IV-A describes weighted sum of four losses; corpus shows limited evidence of regularization effects
- Break condition: If one decoder dominates the loss computation or training weights are poorly balanced, regularization effect may be reduced or reversed

### Mechanism 2
- Claim: One-pass beam search algorithms outperform CTC/attention decoding by integrating multiple decoder scores
- Mechanism: Hypotheses from primary decoder are rescored using prefix scoring methods from other decoders, creating more accurate joint scores
- Core assumption: Secondary decoders can provide meaningful probability estimates for partial hypotheses
- Evidence anchors: Abstract describes three novel one-pass beam search algorithms; Section IV-C explains CTC and RNN-T scoring of extended hypotheses; Section IV-D details the additional RNN-T likelihood consideration
- Break condition: If prefix scoring is computationally prohibitive or decoder weightings are suboptimal, joint scores may not improve

### Mechanism 3
- Claim: RNN-T-driven one-pass beam search provides best WER-RTF tradeoff
- Mechanism: Avoids computationally expensive RNN-T prefix scoring unlike other variants
- Core assumption: RNN-T prefix scoring is most computationally expensive operation
- Evidence anchors: Section IV-E notes avoidance of RNN-T prefix scoring; Section VI-D explains advantage from avoiding RNN-T path computation
- Break condition: If computational savings are offset by increased attention or CTC computations

## Foundational Learning

- Concept: Multitask learning and loss weighting
  - Why needed here: 4D model combines four decoders with different loss functions that must be balanced during training
  - Quick check question: If Mask-CTC loss converges much slower than others, what adjustment should be made to training weights?

- Concept: Beam search and prefix scoring
  - Why needed here: Novel one-pass beam search algorithms use prefix scoring from multiple decoders to rescore hypotheses
  - Quick check question: What is the difference between time-synchronous and label-synchronous beam search, and which decoders use each approach?

- Concept: RNN-T alignment and prefix scoring
  - Why needed here: RNN-T prefix scoring computes probabilities for partial hypotheses in label-synchronous manner
  - Quick check question: How does RNN-T prefix scoring differ from CTC prefix scoring in terms of alignment paths considered?

## Architecture Onboarding

- Component map: Shared conformer encoder (12 blocks, 2048 units) -> Four decoders (CTC, attention, RNN-T, Mask-CTC) -> Joint training with weighted loss sum -> Three one-pass beam search variants
- Critical path: Encoder processes input features → produces hidden states → Primary decoder generates hypotheses during beam search → Secondary decoders provide prefix scores for joint rescoring → Hypotheses pruned based on joint scores
- Design tradeoffs: Joint training increases model complexity but improves individual decoder performance; One-pass beam search with three decoders improves accuracy but increases RTF; RNN-T-driven search avoids RNN-T prefix scoring for better WER-RTF tradeoff
- Failure signatures: Poor individual decoder performance suggests imbalanced training weights; Excessive RTF indicates inefficient beam search; Degraded accuracy may result from suboptimal decoder weightings
- First 3 experiments: 1) Train 4D model with equal weights on LibriSpeech 100h, evaluate individual decoder performance; 2) Implement attention-driven one-pass beam search with CTC and RNN-T prefix scoring, compare WER to CTC/attention baseline; 3) Test RNN-T-driven one-pass beam search on same data, measure WER-RTF tradeoff improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does joint training of four decoders affect performance of each individual decoder compared to training separately?
- Basis in paper: [explicit] Paper mentions jointly trained 4D model improves performance over non-4D trained counterparts
- Why unresolved: Paper provides general statement about improvement but lacks detailed quantitative comparisons for each decoder
- What evidence would resolve it: Detailed quantitative performance metrics for each decoder when trained individually versus jointly

### Open Question 2
- Question: How does number of decoders used in joint training impact overall performance?
- Basis in paper: [explicit] Paper suggests performance improves with increasing number of decoders
- Why unresolved: Paper lacks detailed analysis of how performance scales with number of decoders
- What evidence would resolve it: Experimental results comparing 4D model performance with different numbers of decoders (2, 3, 4) and scaling behavior analysis

### Open Question 3
- Question: How does choice of primary decoder in one-pass beam search algorithms affect performance and computational efficiency?
- Basis in paper: [explicit] Paper introduces three one-pass beam search algorithms with different primary decoders and mentions effect on performance and computational cost
- Why unresolved: Paper provides general comparison but lacks detailed analysis of trade-offs between different primary decoder choices
- What evidence would resolve it: Comprehensive analysis of performance and computational efficiency with different primary decoders including detailed comparisons and trade-offs

## Limitations
- Experimental validation lacks ablation studies showing individual contributions of each decoder to joint performance
- Two-stage training strategy's weight adjustment mechanism is described but lacks mathematical formulation and sensitivity analysis
- Computational overhead characterization beyond RTF measurements is incomplete, particularly memory requirements for maintaining prefix hypotheses across three decoders

## Confidence
- High Confidence: Claim that jointly trained 4D model outperforms individual decoder models on both LibriSpeech and Japanese datasets
- Medium Confidence: Claim that one-pass beam search algorithms outperform CTC/attention decoding (benefit appears dataset-dependent)
- Low Confidence: Claim that RNN-T-driven one-pass beam search provides best WER-RTF tradeoff (based on qualitative observations rather than systematic analysis)

## Next Checks
1. **Decoder Contribution Analysis**: Perform ablation studies by training 3D variants (removing each decoder individually) and comparing their performance to full 4D model to quantify individual contribution of each decoder to joint regularization effect

2. **Weight Sensitivity Analysis**: Systematically vary decoder weights in both training stages (not just using inverse validation loss) and measure how performance changes, particularly focusing on whether Mask-CTC decoder is being properly weighted

3. **Memory and Computational Profiling**: Implement detailed profiling of one-pass beam search algorithms to measure peak memory usage, average prefix scoring operations per hypothesis, and GPU utilization patterns to fully characterize WER-RTF tradeoff beyond simple RTF measurements