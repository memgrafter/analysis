---
ver: rpa2
title: Resource-constrained stereo singing voice cancellation
arxiv_id: '2401.12068'
source_url: https://arxiv.org/abs/2401.12068
tags:
- stereo
- separation
- source
- quality
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies stereo singing voice cancellation (SVC), a music
  source separation task, under resource-constrained settings. The authors adapt Conv-TasNet,
  an efficient speech separation model, to handle stereo input and produce stereo
  output, creating Vox-TasNet.
---

# Resource-constrained stereo singing voice cancellation

## Quick Facts
- arXiv ID: 2401.12068
- Source URL: https://arxiv.org/abs/2401.12068
- Reference count: 0
- Authors propose resource-efficient model for stereo singing voice cancellation

## Executive Summary
This paper addresses stereo singing voice cancellation (SVC) under resource-constrained settings by adapting Conv-TasNet for stereo input/output. The proposed Vox-TasNet model achieves comparable quality to larger models like HybridDemucs while requiring less memory and processing power. The work introduces a new stereo separation asymmetry metric (SSASI-SDR) to measure inconsistencies in vocal attenuation between channels, addressing a previously overlooked aspect of stereo SVC. Experimental results demonstrate that training dataset quality and size significantly impact performance, with the optimized Vox-TasNet showing promising results in both objective and subjective evaluations.

## Method Summary
The authors adapt Conv-TasNet, an efficient speech separation model, to handle stereo input and produce stereo output, creating Vox-TasNet. The model architecture is optimized through parameter tuning and dataset expansion. A key innovation is the introduction of the SSASI-SDR metric to measure stereo separation asymmetry, which captures inconsistencies in vocal attenuation between channels. The approach includes systematic evaluation of model parameters and training data effects on performance, combining objective metrics with subjective MUSHRA tests to validate the effectiveness of the proposed method.

## Key Results
- Vox-TasNet achieves comparable quality to larger models like HybridDemucs while requiring less memory and processing power
- Training dataset quality and size significantly impact performance
- Subjective evaluations using MUSHRA tests confirm the effectiveness of the proposed approach

## Why This Works (Mechanism)
The paper's approach works by adapting an efficient speech separation architecture to the specific challenges of stereo singing voice cancellation. By optimizing the model for stereo input/output while maintaining computational efficiency, the authors create a framework that can effectively separate vocals from accompaniment in stereo recordings. The introduction of the SSASI-SDR metric addresses the unique challenge of channel asymmetry in stereo recordings, where vocal cancellation may be inconsistent between left and right channels. The emphasis on training dataset quality and size recognizes that source separation performance is highly dependent on representative training data.

## Foundational Learning

### Convolutional Neural Networks (CNNs)
- **Why needed**: Core building block for efficient feature extraction in Vox-TasNet
- **Quick check**: Can identify convolutional layers in the model architecture and explain their role in temporal processing

### Source Separation Metrics
- **Why needed**: Required to evaluate performance using SDR, SI-SDR, and the novel SSASI-SDR metric
- **Quick check**: Understands how these metrics measure separation quality and asymmetry between channels

### Training Dataset Optimization
- **Why needed**: Critical for understanding how dataset size and quality impact model performance
- **Quick check**: Can explain the relationship between training data characteristics and separation performance

## Architecture Onboarding

### Component Map
Input stereo audio -> Vox-TasNet (Conv-TasNet adaptation) -> Separated vocal and accompaniment tracks -> Output stereo audio

### Critical Path
1. Stereo audio preprocessing and normalization
2. Convolutional encoder for feature extraction
3. Temporal convolutional network for separation
4. Decoder for waveform reconstruction
5. Output stereo vocal and accompaniment tracks

### Design Tradeoffs
- **Model size vs. performance**: Smaller model requires careful architecture optimization to maintain quality
- **Computational efficiency vs. separation quality**: Balancing resource constraints with effective vocal cancellation
- **Stereo handling vs. complexity**: Adding stereo processing increases model complexity but is essential for the task

### Failure Signatures
- Inconsistent vocal attenuation between left and right channels (measured by SSASI-SDR)
- Residual vocal artifacts in the accompaniment track
- Distortion of stereo spatial characteristics

### First 3 Experiments to Run
1. Evaluate baseline Conv-TasNet performance on stereo SVC task
2. Test different training dataset sizes and qualities on separation performance
3. Measure SSASI-SDR across different model configurations to identify optimal asymmetry handling

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is limited to DSD100 dataset without extensive testing on diverse musical genres
- Claims about memory and processing efficiency lack comprehensive benchmarking across different hardware platforms
- Correlation between SSASI-SDR metric and perceptual quality needs further validation

## Confidence

| Claim | Confidence |
|-------|------------|
| Vox-TasNet architecture adaptation | High |
| Performance parity with larger models | Medium |
| Impact of training dataset quality/size | Medium |

## Next Checks
1. Conduct cross-dataset evaluation using diverse music sources to assess generalization beyond DSD100
2. Perform comprehensive benchmarking on actual resource-constrained hardware to validate efficiency claims
3. Implement perceptual studies with a larger, more diverse listener panel to strengthen MUSHRA test results