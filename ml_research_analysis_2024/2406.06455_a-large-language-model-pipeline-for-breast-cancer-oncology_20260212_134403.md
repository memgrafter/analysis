---
ver: rpa2
title: A Large Language Model Pipeline for Breast Cancer Oncology
arxiv_id: '2406.06455'
source_url: https://arxiv.org/abs/2406.06455
tags:
- clinical
- treatment
- cancer
- data
- breast
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study fine-tuned GPT models using clinical data and guidelines
  to classify breast cancer treatment decisions. The approach used LangChain pipelines
  to process Duke MRI patient data and generate Q&A pairs from clinical guidelines.
---

# A Large Language Model Pipeline for Breast Cancer Oncology

## Quick Facts
- arXiv ID: 2406.06455
- Source URL: https://arxiv.org/abs/2406.06455
- Authors: Tristen Pool; Dennis Trujillo
- Reference count: 17
- Primary result: LLMs achieved 0.85+ accuracy in classifying breast cancer treatment decisions

## Executive Summary
This study fine-tuned GPT models using clinical data and guidelines to classify breast cancer treatment decisions. The approach used LangChain pipelines to process Duke MRI patient data and generate Q&A pairs from clinical guidelines. Babbage models achieved high accuracy (0.85+) for classifying adjuvant radiation therapy and chemotherapy. Confidence interval analysis suggested the model could outperform human oncologists in 8.2-13.3% of treatment decisions. These findings indicate potential for LLMs to improve treatment planning and expand access to quality oncology care.

## Method Summary
The researchers fine-tuned GPT-3.5 models using a Duke MRI dataset of 922 breast cancer patients and clinical guidelines from ASCO/NCCN. They used LangChain pipelines to preprocess the data, generate Q&A pairs from guidelines, and optimize temperature settings for inference. The study focused on classifying two key treatment decisions: adjuvant radiation therapy and chemotherapy, using patient demographics, tumor characteristics, and genomic data as features.

## Key Results
- Achieved classification accuracy of 0.85+ for adjuvant radiation therapy and chemotherapy decisions
- Temperature optimization revealed lower temperatures (0.2-0.3) yielded better performance than higher settings
- Confidence interval analysis suggested potential for 8.2-13.3% improvement over human oncologists in treatment decisions

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning LLMs with clinical guidelines and patient datasets improves classification accuracy for treatment decisions. The model learns to map structured clinical features to treatment outcomes by training on both guideline text and historical patient data. Core assumption: The relationship between clinical features and treatment decisions is consistent enough to be learned by the model. Evidence: High accuracy (0.85+) achieved in classification tasks using Duke MRI dataset with detailed patient demographics and tumor characteristics.

### Mechanism 2
Temperature optimization during inference improves model performance for structured data classification. Lower temperatures reduce randomness in token selection, making predictions more consistent and accurate for binary classification tasks. Core assumption: The optimal temperature setting is consistent across similar structured data classification tasks. Evidence: Validation accuracy generally decreases as temperature increases from 0.0 to 1.75, indicating reduced model performance at higher temperatures.

### Mechanism 3
Confidence interval analysis provides a realistic measure of model performance compared to human oncologists. By accounting for human error rates in the dataset, the model's true accuracy can be more accurately assessed. Core assumption: The human error rate in the dataset is representative of typical oncology practice. Evidence: Wilson score 95% confidence interval calculation assuming 13% cancer treatment error rate, leading to hypothesis that model might outperform human oncologists in 8.2-13.3% of predictions.

## Foundational Learning

- **Clinical oncology and treatment decision factors**: Understanding of how HER-2 status, tumor stage, and other clinical features influence treatment decisions. Quick check: What are the key factors that influence adjuvant radiation therapy and chemotherapy decisions in breast cancer?

- **Large language models and fine-tuning techniques**: Familiarity with GPT architecture and the differences between fine-tuning and prompt engineering. Quick check: What is the difference between fine-tuning and prompt engineering in the context of LLMs?

- **Statistical analysis and confidence interval calculation**: Knowledge of statistical methods for assessing model performance relative to human error rates. Quick check: How does the Wilson score interval differ from a normal approximation interval in calculating confidence intervals?

## Architecture Onboarding

- **Component map**: Clinical guideline corpus preprocessing -> LangChain agent for Q&A pair generation -> Fine-tuning pipeline with GPT models -> Temperature optimization for inference -> Confidence interval analysis

- **Critical path**: Data preprocessing → Q&A pair generation → Model fine-tuning → Temperature optimization → Performance evaluation

- **Design tradeoffs**: Using smaller Babbage model for efficiency vs. larger models for potentially better performance; limiting dataset size for computational efficiency vs. using full dataset for potentially better accuracy

- **Failure signatures**: Overfitting if model performs well on training data but poorly on validation data; underfitting if model performs poorly on both training and validation data; temperature setting too high causing inconsistent predictions

- **First 3 experiments**: 1) Test different temperature settings on a small subset of data to find optimal value; 2) Compare performance of Babbage vs. larger GPT models on the same task; 3) Validate confidence interval calculation with simulated data where ground truth is known

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal temperature setting for the Babbage model when classifying adjuvant chemotherapy versus radiation therapy? The paper presents a temperature sensitivity analysis showing different optimal temperatures for radiation therapy (0.2) versus chemotherapy (0.3) classification, but doesn't explain why these differences exist or provide guidance for new classification tasks.

### Open Question 2
How can the model's performance improvements over human oncologists be validated given the irreversibility of cancer treatment decisions? The paper acknowledges that due to indeterminacy in cancer treatment outcomes, future investigation, potentially a clinical trial, would be required to determine if the model outperforms human oncologists.

### Open Question 3
What is the optimal balance between computational efficiency and accuracy when selecting model size for different oncology classification tasks? The paper uses both Babbage (1B parameters) for classification tasks and Davinci (175B parameters) for text generation, but doesn't systematically compare performance across different model sizes.

## Limitations

- Data preprocessing and variable selection details are not specified, limiting reproducibility
- Model architecture details and hyperparameters are not fully disclosed
- Confidence interval analysis relies on assumed 13% human error rate without empirical validation

## Confidence

- **High confidence**: Technical approach of using LLMs for classification tasks and general methodology of fine-tuning with clinical guidelines and patient data
- **Medium confidence**: Achieved accuracy of 0.85+ for treatment classification based on internal validation
- **Low confidence**: Specific claim that LLMs would outperform human oncologists in 8.2-13.3% of cases, based on assumed error rates

## Next Checks

1. Apply the fine-tuned model to an independent breast cancer dataset from a different institution to verify if the 0.85+ accuracy generalizes beyond the Duke MRI dataset

2. Conduct a blinded study where the model's treatment recommendations are compared directly against board-certified oncologists' decisions on the same cases, without assuming error rates

3. Test model performance on historical data where treatment guidelines and standards of care have changed to assess robustness to evolving clinical practices and determine if the model adapts appropriately to new guidelines