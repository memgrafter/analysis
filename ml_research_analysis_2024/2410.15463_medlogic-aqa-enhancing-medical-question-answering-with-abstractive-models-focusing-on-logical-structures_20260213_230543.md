---
ver: rpa2
title: 'MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models
  Focusing on Logical Structures'
arxiv_id: '2410.15463'
source_url: https://arxiv.org/abs/2410.15463
tags:
- medical
- logical
- dataset
- answers
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of capturing intricate logical
  structures and relationships inherent in medical contexts for accurate question
  answering. The proposed MedLogic-AQA system integrates first-order logic (FOL) rules
  extracted from medical knowledge graphs with abstractive question answering.
---

# MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures

## Quick Facts
- arXiv ID: 2410.15463
- Source URL: https://arxiv.org/abs/2410.15463
- Reference count: 7
- Primary result: MedLogic-AQA outperforms baselines on BioASQ and MASH-QA, achieving Medical Entity F1% of 38.47% and 31.87%, respectively, with high human evaluation scores.

## Executive Summary
MedLogic-AQA addresses the challenge of capturing intricate logical structures in medical contexts for accurate question answering. The system integrates first-order logic rules extracted from medical knowledge graphs with abstractive question answering through a two-stage fine-tuning approach. Using a Logic Understanding module to generate logical triples and an Abstractive Question Answering module to produce coherent answers, the system achieves strong performance on BioASQ and MASH-QA datasets. Human evaluations show high scores across adequacy, fluency, and logical reasoning, demonstrating the effectiveness of combining symbolic logic with neural models for medical domains.

## Method Summary
MedLogic-AQA employs a two-stage fine-tuning process using Llama2-7B. First, a Logic Understanding (LU) module is trained to generate logical triples from context, question, answer, and FOL rules extracted from UMLS-based knowledge graphs. Then, an Abstractive Question Answering (AQA) module is fine-tuned using the LU output to generate final answers. The system constructs medical knowledge graphs using QuickUMLS and UMLS, applies six identified FOL rules to infer new triples, and leverages these structured representations to improve answer quality and medical entity identification.

## Key Results
- Medical Entity F1% of 38.47% on BioASQ and 31.87% on MASH-QA
- Superior performance on automated metrics (BLEU, ROUGE-L, METEOR, etc.)
- High human evaluation scores for adequacy, fluency, logical reasoning, and contextual consistency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage fine-tuning improves logical reasoning by first training LU to generate logical triples, then using these to fine-tune AQA.
- Mechanism: Separates logical structure learning from answer generation, allowing the model to internalize logical dependencies before applying them to produce answers, similar to Phi-1.5's double-fine-tuning approach.
- Core assumption: LU-generated triples are correct and useful for AQA; model can effectively use triples to guide coherent answer generation.
- Evidence anchors:
  - [abstract] "Through initial experimentation, we identified six pertinent first-order logical rules, which were then used to train a Logic-Understanding (LU) model capable of generating logical triples for a given context, question, and answer."
  - [section] "Building upon the knowledge acquired by LU, this step utilizes its logical reasoning capabilities to refine the model's understanding of complex dependencies."
- Break condition: If LU-generated triples are noisy or irrelevant, AQA will propagate errors, leading to incoherent or incorrect answers.

### Mechanism 2
- Claim: FOL rules derived from UMLS semantic relations capture domain-specific medical relationships and improve answer precision.
- Mechanism: FOL rules act as symbolic constraints guiding the neural model to reason over medical entities in a structured way, enforcing transitive reasoning over medical concepts (e.g., if X co-occurs with Y and Y affects Z, then X affects Z).
- Core assumption: FOL rules accurately represent the medical domain and are correctly applied during fine-tuning.
- Evidence anchors:
  - [abstract] "Through initial experimentation, we identified six pertinent first-order logical rules... enabling effective and coherent reasoning during answer generation."
  - [section] "After going through k number of FOL-based rules, we finalized six rules which were relevant and were able to serve as essential knowledge for enhancing the model's reasoning and inference capabilities."
- Break condition: If FOL rules are too restrictive or don't match actual relationships, model may overfit to incorrect logic or fail to generalize.

### Mechanism 3
- Claim: Graph-based representation enables scalable integration of logical rules, allowing generalization across diverse medical queries.
- Mechanism: Entities as nodes and relationships as edges enable dynamic application of FOL rules to infer new triples, augmenting the knowledge graph with logical inferences before feeding to LU.
- Core assumption: Knowledge graph triples from UMLS are sufficiently complete and accurate to support logical inference.
- Evidence anchors:
  - [abstract] "Central to our approach is the conceptualization of the logical structure of the context as a graph."
  - [section] "We construct a self-built knowledge graph using QuickUMLS... These steps result in a Medical Knowledge Graph (MKG) that enriches our understanding of medical concepts and their relationships."
- Break condition: If knowledge graph is sparse or contains incorrect relations, logical inference will be unreliable, leading to degraded performance.

## Foundational Learning

- Concept: First-Order Logic (FOL) rules
  - Why needed here: FOL rules provide a symbolic framework to encode medical domain knowledge (e.g., treatment relationships, causal chains) that can be integrated with neural models for structured reasoning.
  - Quick check question: Can you express the rule "If X prevents Y and Y causes Z, then X prevents Z" in FOL syntax? (Answer: prevent(X, Y) ∧ causes(Y, Z) ⇒ prevent(X, Z))

- Concept: Knowledge Graphs (KGs) and Semantic Relations
  - Why needed here: KGs represent medical entities and their relationships in a structured form, enabling extraction of FOL rules and supporting logical inference over medical concepts.
  - Quick check question: What is the difference between a KG triple (head, relation, tail) and a FOL rule? (Answer: A triple is a single fact; a rule is a logical implication that can generate new triples.)

- Concept: Fine-tuning vs. Pre-training in NLP
  - Why needed here: Understanding the distinction between two-stage fine-tuning (LU then AQA) and standard fine-tuning is critical for grasping how logical reasoning is incorporated.
  - Quick check question: Why might a two-stage fine-tuning process be more effective than single-stage fine-tuning for tasks requiring structured reasoning? (Answer: It allows the model to first learn structured representations before applying them to generation.)

## Architecture Onboarding

- Component map: Context + Question + Answer + Rules -> LU Module -> Logical Triples -> Knowledge Graph Builder -> AQA Module -> Final Answer

- Critical path:
  1. Extract medical entities and relations from context using QuickUMLS/UMLS
  2. Generate knowledge graph triples
  3. Apply FOL rules to infer new triples
  4. Fine-tune LU model on (context+question+answer+rules → triples)
  5. Fine-tune AQA model on (context+question+rules → answer) using LU output

- Design tradeoffs:
  - Pros: Structured reasoning improves answer quality and medical entity identification; modular design allows reuse of LU for other tasks
  - Cons: Reliance on UMLS limits coverage; FOL rules may not capture all nuances; two-stage training increases complexity

- Failure signatures:
  - LU model outputs irrelevant or noisy triples → AQA generates incoherent answers
  - UMLS fails to recognize key medical entities → knowledge graph is incomplete → logical inference fails
  - FOL rules are too restrictive → model overfits and fails to generalize

- First 3 experiments:
  1. Verify LU model can generate meaningful triples on a small annotated dataset (e.g., BioASQ subset)
  2. Test FOL rule application by manually checking a few generated triples for logical correctness
  3. Compare AQA performance with and without LU-generated triples on a held-out validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MedLogic-AQA vary when applied to different medical domains or specialties, and what factors contribute to this variability?
- Basis in paper: [inferred] The paper mentions that the model's performance may vary across different medical domains and specialties depending on the availability and relevance of training data, but does not provide specific experimental evidence.
- Why unresolved: The paper does not present experiments or results that directly compare the model's performance across different medical domains or specialties.
- What evidence would resolve it: Conducting experiments to evaluate the model's performance on datasets from various medical specialties (e.g., cardiology, oncology, neurology) and analyzing the factors contributing to performance differences.

### Open Question 2
- Question: What are the specific limitations of the Logic Understanding (LU) model in generating contextually relevant knowledge graph triples, and how can these limitations be addressed?
- Basis in paper: [explicit] The paper discusses qualitative analysis of errors, including the LU model's failure to generate appropriate knowledge graph triples in certain cases, such as the MASHQA dataset example.
- Why unresolved: The paper identifies the issue but does not provide a detailed analysis of the root causes or potential solutions.
- What evidence would resolve it: Investigating the specific types of errors made by the LU model, analyzing the underlying reasons for these errors, and proposing and evaluating potential solutions to improve the model's performance.

### Open Question 3
- Question: How does the integration of logical rules into the fine-tuning process affect the model's ability to generate accurate and informative answers, and what is the optimal balance between logical reasoning and context-based generation?
- Basis in paper: [inferred] The paper proposes a two-stage fine-tuning approach that incorporates logical rules, but does not provide a detailed analysis of the impact of these rules on the model's performance or explore different levels of logical reasoning integration.
- Why unresolved: The paper does not present experiments that systematically vary the level of logical reasoning integration or analyze the trade-offs between logical accuracy and context-based relevance.
- What evidence would resolve it: Conducting experiments to compare the model's performance with different levels of logical reasoning integration, analyzing the impact on accuracy, fluency, and informativeness, and determining the optimal balance between logical and context-based generation.

## Limitations
- Knowledge graph construction pipeline lacks specification of UMLS version and QuickUMLS configuration
- Two-stage fine-tuning relies heavily on quality of LU-generated triples, which are not independently validated
- Reported human evaluation scores lack statistical significance testing and detailed inter-annotator agreement metrics

## Confidence
- High confidence in the conceptual framework of integrating FOL rules with abstractive QA for medical domains
- Medium confidence in the two-stage fine-tuning methodology, given the analogy to Phi-1.5 but without direct validation
- Low confidence in the completeness and accuracy of the medical knowledge graph construction pipeline

## Next Checks
1. Conduct an ablation study comparing AQA performance with and without LU-generated triples on a held-out validation set to verify the contribution of the two-stage approach
2. Perform a qualitative analysis of LU-generated triples against ground truth to assess the quality and relevance of logical inferences
3. Evaluate the system's performance on a subset of BioASQ with manually annotated medical entities to validate the reported Medical Entity F1% score and its statistical significance