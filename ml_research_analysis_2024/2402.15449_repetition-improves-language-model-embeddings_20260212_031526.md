---
ver: rpa2
title: Repetition Improves Language Model Embeddings
arxiv_id: '2402.15449'
source_url: https://arxiv.org/abs/2402.15449
tags:
- embeddings
- write
- compl
- expla
- repea
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a simple and effective method to convert autoregressive
  language models into high-quality text embedding models without requiring architectural
  changes or fine-tuning. The core idea, called "echo embeddings," involves prompting
  the model to repeat the input twice and extracting embeddings from the second occurrence,
  which can access the full context due to causal attention.
---

# Repetition Improves Language Model Embeddings

## Quick Facts
- arXiv ID: 2402.15449
- Source URL: https://arxiv.org/abs/2402.15449
- Reference count: 40
- Improves zero-shot MTEB score by over 5% compared to classical embeddings

## Executive Summary
This paper presents a simple and effective method to convert autoregressive language models into high-quality text embedding models without requiring architectural changes or fine-tuning. The core idea, called "echo embeddings," involves prompting the model to repeat the input twice and extracting embeddings from the second occurrence, which can access the full context due to causal attention. The method significantly improves zero-shot performance over classical embeddings by over 5% on the Massive Text Embedding Benchmark (MTEB), matching or slightly outperforming models that require bidirectional attention conversion and additional training.

## Method Summary
The method works by prompting an autoregressive language model to repeat the input text twice, then extracting embeddings from the second occurrence using mean pooling. The second occurrence can attend to the first occurrence (which contains the entire input), effectively capturing bidirectional context despite the model having only causal attention. This approach works both in zero-shot settings and when combined with supervised fine-tuning using contrastive loss with hard negative mining.

## Key Results
- Echo embeddings improve over classical LM embeddings by over 5% in zero-shot settings on MTEB
- Echo embeddings match or slightly outperform models requiring bidirectional attention conversion and additional training
- The approach achieves state-of-the-art results without modifying the base model's architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Repeating the input enables the second occurrence to access bidirectional context despite causal attention.
- Mechanism: The model is prompted to repeat the input twice. The second occurrence has causal attention to the first occurrence, which contains the entire input sequence. This allows the embeddings from the second occurrence to attend to all tokens in the original input, including tokens that come later in the sequence.
- Core assumption: The model's attention mechanism allows it to attend to tokens from the first occurrence of the input when processing the second occurrence.
- Evidence anchors:
  - [abstract] "By repeating the input and extracting embeddings from the repeated tokens—which have access to all original tokens—echo embeddings improve over classical LM embeddings by over 5% in zero-shot settings."
  - [section] "We prompt the model with the input twice and extract embeddings from the second occurrence of the input. Even with causal attention, the embeddings of the second occurrence can access the entire input in the first occurrence."
  - [corpus] Weak - corpus provides related work but no direct evidence for this specific mechanism.

### Mechanism 2
- Claim: The prompt to repeat or rephrase the input encourages the model to encode bidirectional information in the second occurrence.
- Mechanism: By instructing the model to repeat, rephrase, or otherwise reconstruct the input, we encourage it to use information from the entire input when generating the second occurrence. This leads to contextualized representations in the second occurrence that capture bidirectional information.
- Core assumption: The model will use the full context available to it when performing the instructed task (repeat/rephrase).
- Evidence anchors:
  - [abstract] "By repeating the input and extracting embeddings from the repeated tokens—which have access to all original tokens—echo embeddings improve over classical LM embeddings by over 5% in zero-shot settings."
  - [section] "Furthermore, in order to encourage the second occurrence to actually 'encode' information about the first, we instruct the language model to perform a generic task that requires using this information, e.g., 'rewrite' or 'repeat'."
  - [corpus] Weak - corpus mentions related approaches but doesn't directly test this prompt effectiveness mechanism.

### Mechanism 3
- Claim: Mean pooling across the second occurrence captures bidirectional information better than classical embeddings.
- Mechanism: Classical embeddings with causal attention cannot encode information from later tokens into earlier token representations. By extracting embeddings from the second occurrence and applying mean pooling, we capture contextualized representations that have access to the full input sequence, leading to better bidirectional information capture.
- Core assumption: Mean pooling is an effective way to aggregate contextualized representations that contain bidirectional information.
- Evidence anchors:
  - [abstract] "By repeating the input and extracting embeddings from the repeated tokens—which have access to all original tokens—echo embeddings improve over classical LM embeddings by over 5% in zero-shot settings."
  - [section] "Echo embeddings with mean-token pooling works significantly better than classical embeddings and works well on both structures in the data—whether the discriminatory information is in the early or later tokens."
  - [corpus] Weak - corpus mentions related pooling approaches but doesn't specifically validate mean pooling for this mechanism.

## Foundational Learning

- Concept: Causal attention vs bidirectional attention
  - Why needed here: Understanding the difference between these attention mechanisms is crucial for grasping why classical embeddings fail and how echo embeddings work around this limitation.
  - Quick check question: In causal attention, can the representation of token at position k attend to tokens at positions k+1, k+2, etc.?

- Concept: Autoregressive language models
  - Why needed here: Echo embeddings work specifically with autoregressive models, so understanding their architecture and training objectives is essential.
  - Quick check question: What is the primary training objective for autoregressive language models?

- Concept: Text embedding extraction methods
  - Why needed here: Different approaches to extracting embeddings (mean pooling, last-token pooling, etc.) have different implications for the quality of the resulting embeddings.
  - Quick check question: What is the main difference between mean pooling and last-token pooling when extracting embeddings?

## Architecture Onboarding

- Component map: Input prompt → Model with causal attention → First occurrence of input → Second occurrence of input → Embeddings extraction from second occurrence → Pooling → Final embedding
- Critical path: The critical path is the flow from input prompt through to final embedding, with the key innovation being the extraction of embeddings from the second occurrence rather than the first.
- Design tradeoffs: Echo embeddings double the compute cost compared to classical embeddings, but this can be mitigated by using shorter inputs or training with fewer steps. The choice of prompt, pooling strategy, and base model also affects performance.
- Failure signatures: If echo embeddings don't outperform classical embeddings, possible failure points include: the model not using the full context when generating the second occurrence, the pooling strategy not effectively aggregating bidirectional information, or the base model not being suitable for embedding tasks.
- First 3 experiments:
  1. Test echo embeddings vs classical embeddings on a simple toy dataset with known bidirectional dependencies.
  2. Evaluate the sensitivity of echo embeddings to different prompts (repeat, rephrase, rewrite, etc.).
  3. Compare echo embeddings with bidirectional attention baselines to verify the claim that bidirectional attention isn't necessary.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the performance improvement of echo embeddings persist when using models significantly larger than Mistral-7B (e.g., 70B+ parameter models)?
- Basis in paper: [inferred] The paper tests echo embeddings on Mistral-7B, LLaMA-2-7B, and S-LLaMA-1.3B, but does not explore performance with larger models. The paper notes that "the choice of prompt does not substantially affect the performance of echo embeddings" and that "any reasonable prompt will perform well," but this is only tested on smaller models.
- Why unresolved: The authors speculate that gains are because "echo embeddings better preserve and leverage large-scale pretraining because there are no architectural changes," but this remains unverified for truly large-scale models. The computational cost doubling might be more prohibitive at larger scales, potentially affecting practical utility.
- What evidence would resolve it: Testing echo embeddings on models like LLaMA-70B, GPT-3.5, or GPT-4, comparing zero-shot and fine-tuned performance against classical embeddings, and measuring the compute-cost trade-off at scale.

### Open Question 2
- Question: What is the theoretical limit of how much bidirectional information can be captured through repetition, and does this approach scale to tasks requiring deeper bidirectional context?
- Basis in paper: [explicit] The paper demonstrates that echo embeddings can capture bidirectional information for tasks like STS and retrieval, but acknowledges that "the fundamental gap between classical and echo embeddings that we identified in Section 3 persists even after fine-tuning." The authors note that repetition "enables the model to encode bidirectional information" but do not quantify how much context can be captured this way.
- Why unresolved: The paper shows echo embeddings work well on MTEB tasks, but does not establish whether there are inherent limitations to how much bidirectional context can be captured through a single repetition. Some tasks might require multi-hop reasoning or very long-range dependencies that a single repetition might not fully capture.
- What evidence would resolve it: Systematic testing on tasks requiring varying degrees of bidirectional context (e.g., multi-hop QA, document summarization, long-form generation), measuring performance degradation as context requirements increase, and comparing against truly bidirectional models on these tasks.

### Open Question 3
- Question: How does echo embeddings perform on non-English languages and multilingual tasks compared to classical embeddings and truly bidirectional models?
- Basis in paper: [inferred] The paper only evaluates on English-language tasks from MTEB. While the method is described as general, no multilingual experiments are conducted. The authors note that "repetition is a simple and effective strategy to circumvent the need for bidirectional attention in embedding models" but this is only demonstrated for English.
- Why unresolved: Language-specific phenomena like morphology, word order flexibility, and cross-lingual semantic relationships might interact differently with the repetition mechanism. The paper's success on English tasks doesn't guarantee similar performance across languages.
- What evidence would resolve it: Testing echo embeddings on multilingual benchmarks like MIRACL, XTREME, or multilingual versions of MTEB, comparing performance across language families, and measuring cross-lingual transfer capabilities relative to bidirectional models.

## Limitations

- The computational cost of echo embeddings is doubled compared to classical embeddings, which may be prohibitive for very large models or high-throughput applications.
- The method's effectiveness across different languages and multilingual tasks remains untested, limiting understanding of its generalizability.
- The theoretical understanding of why repetition works so well is based on architectural reasoning rather than direct empirical evidence of attention patterns.

## Confidence

**High confidence**: The core empirical finding that echo embeddings outperform classical embeddings on MTEB by over 5% in zero-shot settings is well-supported with clear experimental evidence across multiple base models and evaluation datasets.

**Medium confidence**: The claim that echo embeddings match or slightly outperform models requiring bidirectional attention conversion and additional training is supported, but the comparison is limited to specific baselines (PromptEOL, LLM2Vec).

**Low confidence**: The paper's explanation of why the repetition mechanism works—that the second occurrence can attend to all tokens in the first occurrence—is plausible but not definitively proven.

## Next Checks

**Validation Check 1**: Design a controlled experiment that directly visualizes attention patterns during echo embedding generation. Specifically, compare the attention weights of the second occurrence when processing tokens from the first occurrence versus when processing its own tokens.

**Validation Check 2**: Conduct a systematic ablation study varying the number of repetitions (1, 2, 3, 4 times) and the position from which embeddings are extracted (first, second, last occurrence).

**Validation Check 3**: Evaluate echo embeddings across a broader range of model sizes (including much larger models) and training objectives (models trained with bidirectional objectives or different pretraining tasks).