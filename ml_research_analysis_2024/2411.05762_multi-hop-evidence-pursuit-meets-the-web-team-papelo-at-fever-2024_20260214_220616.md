---
ver: rpa2
title: 'Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024'
arxiv_id: '2411.05762'
source_url: https://arxiv.org/abs/2411.05762
tags:
- evidence
- question
- questions
- search
- claim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work combines web search with large language models (LLMs)
  to automatically verify real-world claims. The approach uses a multi-hop evidence
  pursuit strategy, where an LLM generates an initial question from a claim, a search
  engine retrieves documents, and the LLM answers based on the retrieved text.
---

# Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024

## Quick Facts
- arXiv ID: 2411.05762
- Source URL: https://arxiv.org/abs/2411.05762
- Authors: Christopher Malon
- Reference count: 12
- Primary result: Achieves 0.510 AVeriTeC score on FEVER 2024 dev set using multi-hop evidence pursuit

## Executive Summary
This work presents a system that combines web search with large language models to automatically verify real-world claims through multi-hop evidence pursuit. The approach generates initial questions from claims, retrieves documents via web search, and uses LLMs to answer questions based on retrieved text. The system iteratively generates follow-up questions until verification is possible, then paraphrases questions to gather additional evidence before making a final verdict. On the FEVER 2024 shared task, this method significantly outperforms strategies that generate all questions upfront, achieving state-of-the-art performance.

## Method Summary
The system implements multi-hop evidence pursuit by first generating an initial question from a claim using a fine-tuned T5-large model. It then performs web searches, retrieves documents, and uses an LLM to answer questions based on the retrieved text. Follow-up questions are iteratively generated until verification is possible or no new evidence is found. The system then paraphrases questions to generate additional evidence before making a final verdict. The approach uses GPT-4o for question answering and answer verification, with fine-tuned T5-large models for question generation and a greedy algorithm for final verdict selection.

## Key Results
- Achieves 0.510 AVeriTeC score on FEVER 2024 dev set and 0.477 on test set
- Outperforms question-generation-up-front strategies by 0.155 AVeriTeC score
- Ablation studies show iterative question generation, paraphrasing, and metadata/context usage are critical components

## Why This Works (Mechanism)
The multi-hop evidence pursuit approach works by iteratively expanding the evidence base through targeted questioning, allowing the system to verify complex claims that require multiple pieces of supporting evidence. By generating follow-up questions based on previously retrieved information, the system can navigate through interconnected facts and build a comprehensive evidence trail. The paraphrasing step helps uncover additional perspectives and evidence that might not be captured by the initial question formulation.

## Foundational Learning
- **Multi-hop reasoning**: Needed for claims requiring multiple pieces of evidence; quick check: verify system can handle claims requiring 2+ supporting facts
- **Iterative question generation**: Essential for exploring evidence space systematically; quick check: measure improvement from 1 vs multiple iterations
- **Web search integration**: Critical for accessing real-world evidence; quick check: test with different search APIs and query formulations
- **LLM-based verification**: Core mechanism for assessing claim validity; quick check: evaluate accuracy on known true/false claims
- **Paraphrasing for evidence diversity**: Important for uncovering alternative perspectives; quick check: compare evidence coverage with and without paraphrasing

## Architecture Onboarding

**Component Map**: Claim -> GetFirstQuestion -> Web Search -> Document Retrieval -> Question Answering -> GetNextQuestion -> Web Search -> Final Verdict

**Critical Path**: The system follows a loop where questions are generated, answered using web evidence, and new questions are derived until sufficient evidence is gathered for verification.

**Design Tradeoffs**: The approach trades computational cost and API dependencies for improved accuracy through iterative evidence gathering. Using web search introduces latency and potential reliability issues but provides access to current, real-world information.

**Failure Signatures**: 
- Web scraping failures due to anti-bot measures on websites
- LLM hallucinations producing answers not supported by retrieved evidence
- Frequent selection of "Not Enough Evidence" (NEI) due to conservative verification thresholds

**First 3 Experiments**:
1. Fine-tune T5-large on FEVER 2024 training data for GetFirstQuestion and GetNextQuestion functions
2. Implement web search with Google API, document retrieval, and LLM-based question answering using GPT-4o
3. Run Algorithm 1 with the trained models and evaluate on the FEVER 2024 dev set using AVeriTeC scoring

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can the system's tendency to select "Not Enough Evidence" (NEI) too frequently be mitigated?
- **Basis in paper**: explicit
- **Why unresolved**: The paper explicitly states that the LLM tends to select NEI too often, and the system was unable to predict NEI or "Conflicting Evidence / Cherrypicking" with acceptable accuracy.
- **What evidence would resolve it**: Experiments with modified prompts or additional training data that improve NEI prediction accuracy, or ablation studies showing the impact of different approaches to handling NEI.

### Open Question 2
- **Question**: What are the limitations of using site names alone for LLM's consideration of source credibility, and how can this be improved?
- **Basis in paper**: explicit
- **Why unresolved**: The paper notes that LLMs have insufficient information to judge overall credibility of a website and currently only the site name is given for consideration. It mentions that metadata helps but generally misinformation corroborated elsewhere can fool the system.
- **What evidence would resolve it**: Comparative studies showing the impact of providing additional credibility indicators (e.g., domain age, traffic metrics, fact-checking history) versus site name alone on classification accuracy.

### Open Question 3
- **Question**: How can the system be adapted to fact-check claims containing novel information not present in existing documents?
- **Basis in paper**: explicit
- **Why unresolved**: The paper explicitly states that the system cannot fact-check novel information first reported with no basis in existing documents, as it requires judgments of plausibility, credibility, and consistency that are out of scope.
- **What evidence would resolve it**: Development and evaluation of hybrid systems that combine document-based verification with plausibility assessment models, or case studies demonstrating successful verification of novel claims using alternative methodologies.

## Limitations
- System relies heavily on web search APIs and LLM access, introducing external dependencies and potential rate limiting issues
- Specific prompt engineering details for LLM components are not fully disclosed in main text
- Evaluation focuses on specific dataset and task, limiting broader generalizability claims
- Web scraping failures due to anti-bot measures are explicitly acknowledged as potential failure modes

## Confidence
- **High confidence**: The core methodology of iterative question generation and multi-hop evidence pursuit is well-described and reproducible
- **Medium confidence**: The reported AVeriTeC scores are reliable for the specific FEVER 2024 task, but may not generalize to other domains
- **Medium confidence**: The ablation studies provide reasonable evidence for the importance of iterative approaches, though exact implementation details affect outcomes

## Next Checks
1. Implement the full pipeline with Google search API and validate against the FEVER 2024 dev set to confirm the 0.510 AVeriTeC score
2. Test the system's robustness to web scraping failures by simulating blocked requests and measuring fallback performance
3. Conduct an ablation study varying the number of iterative questions to determine optimal performance points and identify diminishing returns