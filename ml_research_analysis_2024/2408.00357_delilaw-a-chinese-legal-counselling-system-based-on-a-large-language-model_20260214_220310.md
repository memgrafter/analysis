---
ver: rpa2
title: 'DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model'
arxiv_id: '2408.00357'
source_url: https://arxiv.org/abs/2408.00357
tags:
- legal
- data
- delilaw
- retrieval
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The DeliLaw system addresses the limitations of traditional legal
  retrieval systems by integrating a large language model with specialized legal modules
  to provide professional legal counseling in Chinese. The system combines intent
  classification, legal retrieval, case retrieval, and a fine-tuned legal LLM to overcome
  model hallucination issues.
---

# DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model

## Quick Facts
- arXiv ID: 2408.00357
- Source URL: https://arxiv.org/abs/2408.00357
- Reference count: 20
- Key outcome: DeliLaw integrates intent classification, legal retrieval, case retrieval, and a fine-tuned legal LLM to provide professional Chinese legal counseling, outperforming baselines including ChatGPT, Baichuan, and ChatGLM2 in human evaluation across 100 test questions with accurate statute references and logical applicability.

## Executive Summary
DeliLaw is a Chinese legal counseling system that addresses the limitations of traditional legal retrieval systems by combining a large language model with specialized legal modules. The system integrates intent classification, legal statute retrieval using fine-tuned BGE embeddings, case retrieval via ElasticSearch, and a legal-domain fine-tuned LLM to overcome model hallucination issues. Key innovations include a two-stage fine-tuning approach for legal article retrieval, keyword-based case retrieval, and high-quality legal data construction involving expert annotations. In human evaluation across 100 test questions, DeliLaw demonstrates superior performance compared to baseline models.

## Method Summary
The system uses a RoBERTa-large intent classifier trained on a four-class legal dataset to route queries to appropriate modules. Legal retrieval employs a two-stage fine-tuning approach for BGE-large-zh-v1.5 embeddings using infoNCE loss with in-batch and hard negative mining, achieving improved precision in matching user queries to relevant statutes. Case retrieval uses ElasticSearch with keyword extraction for efficient access to legal cases. The LLM component (ChatGLM2-6b) is fine-tuned on high-quality legal data including expert-annotated real-world scenarios, GPT-4 generated causes of action, judicial syllogism data, and guided conversations. The system architecture routes queries through intent classification to either specialized retrieval modules or combined retrieval-LLM generation for complex legal questions.

## Key Results
- Outperformed ChatGPT, Baichuan, ChatGLM2, and TongYiFaRui in human evaluation across 100 test questions
- Achieved superior performance in answering legal questions with accurate statute references
- Demonstrated improved logical applicability compared to baseline models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage fine-tuning of BGE embeddings improves legal statute retrieval precision.
- Mechanism: Stage 1 uses labeled query-statute pairs with in-batch negatives and BM25-mined hard negatives; Stage 2 mines new hard negatives using the Stage 1 model and re-fine-tunes.
- Core assumption: Hard negatives selected via BM25 and later-stage retrieval models improve the discriminative power of embeddings for legal domain.
- Evidence anchors:
  - [section] "We fine-tune the BGE-large-zh-v1.5 model using the infoNCE loss function... fine-tuning is divided into two stages... to re-fine-tune the retrieval model."
  - [section] "During retrieval, both the query and the statute are input into the fine-tuned model... the top three statutes with the highest similarity are retrieved."
  - [corpus] Weak—no corpus entries directly reference the two-stage BGE fine-tuning approach.
- Break condition: If hard negative mining fails to yield statutes that are truly relevant but not labeled positive, the embedding space collapses and precision drops.

### Mechanism 2
- Claim: Intent classification routing reduces hallucination by directing queries to specialized modules before LLM inference.
- Mechanism: User query is classified into "LawQuestion", "LawSearch", "CaseSearch", or "General" and routed accordingly; only "LawQuestion" queries go through combined law retrieval + LLM generation.
- Core assumption: Precise intent classification allows the system to bypass LLM for straightforward retrieval tasks, reducing unnecessary generation.
- Evidence anchors:
  - [section] "the user’s question input will go through an intentional classification model... classified into four categories..."
  - [section] "If the predicted category is 'LawQuestion'... the Law Retriever is called, which combines the retrieved law and the user’s question using the prompting process and feeds it to the fine-tuned Legal LLM."
  - [corpus] No corpus entry explicitly validates the intent routing design; this is inferred from the paper.
- Break condition: If intent classifier mislabels a "LawSearch" as "LawQuestion", the system may attempt generation when simple retrieval suffices, increasing latency and hallucination risk.

### Mechanism 3
- Claim: High-quality, expert-annotated legal data improves LLM response accuracy on complex legal queries.
- Mechanism: Construction pipeline: (1) collect web Q&A, (2) clean and link to statutes via retrieval API, (3) expand with GPT-3.5, (4) lawyer review, (5) add judicial syllogism and guided conversation datasets.
- Core assumption: Lawyer-annotated corrections anchor LLM fine-tuning to real legal standards and reduce hallucinated statutes.
- Evidence anchors:
  - [section] "We manually annotated 3,492 data involving real-world legal scenarios... invited legal experts to perform the annotations."
  - [section] "To refine these outputs, expert legal professionals vetted and enhanced the GPT-4-generated content, ensuring high-quality, precise, and current regulatory insights."
  - [corpus] No corpus entries directly support the annotation quality claim; this is taken from the paper.
- Break condition: If annotation quality drops or coverage of legal domains is uneven, the LLM will inherit biases and inaccuracies.

## Foundational Learning

- Concept: Dense retrieval with vector embeddings
  - Why needed here: Enables semantic matching of user queries to legal statutes beyond keyword matching, critical for complex Chinese legal language.
  - Quick check question: How does cosine similarity between BGE embeddings differ from BM25 scoring in retrieval accuracy?

- Concept: Intent classification and routing
  - Why needed here: Separates simple lookup tasks from reasoning tasks, reducing unnecessary LLM calls and hallucination.
  - Quick check question: What happens to system latency if intent classification accuracy drops below 95%?

- Concept: Two-stage fine-tuning with hard negative mining
  - Why needed here: Improves retrieval model discriminative power by forcing it to distinguish between similar but irrelevant statutes.
  - Quick check question: Why is re-mining hard negatives after Stage 1 more effective than using only initial BM25 negatives?

## Architecture Onboarding

- Component map: Intent Classifier (RoBERTa-large) → Router → (Law Retriever (BGE + Milvus) OR Case Retriever (ElasticSearch) OR LLM) → Response
- Critical path: Intent Classifier → Law Retriever (if "LawQuestion") → LLM generation
- Design tradeoffs:
  - Using Milvus vector DB for laws allows semantic retrieval but adds index maintenance overhead; ElasticSearch for cases trades semantic nuance for speed on large corpora.
  - Two-stage BGE fine-tuning increases retrieval precision but requires labeled data and BM25 infrastructure.
- Failure signatures:
  - Low recall in statute retrieval → LLM receives no context → hallucinations spike.
  - Intent misclassification → wrong module invoked → degraded UX or latency.
- First 3 experiments:
  1. Measure recall/precision of law retrieval before and after Stage 2 fine-tuning on a held-out test set.
  2. A/B test intent classification accuracy with and without fine-tuning on the 4-class legal intent dataset.
  3. Compare LLM response quality (hallucination rate) with and without lawyer-annotated fine-tuning data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the system be further optimized to improve contextual understanding and expand coverage of legal fields while maintaining high performance in answering questions?
- Basis in paper: [inferred] The paper mentions that future research will focus on enhancing the system's contextual understanding and broadening the coverage of legal fields.
- Why unresolved: The paper does not provide specific strategies or methods for achieving these improvements.
- What evidence would resolve it: The paper should provide detailed methodologies or experimental results demonstrating how the system's contextual understanding and legal field coverage can be enhanced while maintaining high performance.

### Open Question 2
- Question: How does the two-stage fine-tuning approach for legal article retrieval using BGE embeddings compare to other retrieval methods in terms of accuracy and efficiency?
- Basis in paper: [explicit] The paper describes the two-stage fine-tuning approach and mentions that it demonstrates an MRR of 61.6% and a RECALL of 71.1%.
- Why unresolved: The paper does not provide a comparison with other retrieval methods or benchmarks to evaluate the effectiveness of the two-stage fine-tuning approach.
- What evidence would resolve it: The paper should include comparative studies or benchmarks showing how the two-stage fine-tuning approach performs against other retrieval methods in terms of accuracy and efficiency.

### Open Question 3
- Question: What are the specific challenges and limitations of using LLMs in specialized fields such as law, and how can these be addressed to improve the practical application of legal LLMs?
- Basis in paper: [explicit] The paper mentions that deploying LLMs in specialized fields such as law presents challenges due to the scarcity of high-quality, fine-tuned data and the inherent problem of "hallucination" in generative models.
- Why unresolved: The paper does not provide detailed strategies or solutions to address these challenges and limitations.
- What evidence would resolve it: The paper should include a detailed discussion of the specific challenges and limitations, along with proposed solutions or experimental results demonstrating how these issues can be mitigated to improve the practical application of legal LLMs.

## Limitations

- Major uncertainties remain around the specific hyperparameters and dataset splits used in the two-stage BGE fine-tuning process.
- The paper does not provide detailed ablation studies isolating the contribution of each component to overall system performance.
- Evaluation is limited to human judgment on 100 test questions without quantitative metrics for retrieval accuracy or hallucination rates.

## Confidence

- **High** confidence in the general system architecture and the claim that intent classification routing reduces hallucination risk
- **Medium** confidence in the effectiveness of the two-stage BGE fine-tuning approach due to limited corpus support and unspecified implementation details
- **Medium** confidence in the quality improvement from expert-annotated data, though the exact impact on LLM performance is not quantified

## Next Checks

1. Conduct an ablation study measuring retrieval precision/recall and LLM hallucination rates with individual components disabled (e.g., without intent routing, without two-stage fine-tuning)
2. Perform a quantitative evaluation of retrieval accuracy using standard IR metrics (MAP, MRR) on a held-out legal statute test set
3. Compare the system's performance on edge cases where legal statutes have similar wording but different applicability to test the discriminative power of the fine-tuned embeddings