---
ver: rpa2
title: Robust multi-coil MRI reconstruction via self-supervised denoising
arxiv_id: '2411.12919'
source_url: https://arxiv.org/abs/2411.12919
tags:
- reconstruction
- data
- training
- denoising
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes using self-supervised denoising with GSURE
  as a preprocessing step for deep learning-based MRI reconstruction. The authors
  train denoiser networks on noisy multi-coil MRI data using GSURE loss, then use
  the denoised outputs to train two reconstruction methods: diffusion probabilistic
  models (DPMs) with diffusion posterior sampling (DPS) and model-based deep learning
  (MoDL).'
---

# Robust multi-coil MRI reconstruction via self-supervised denoising

## Quick Facts
- arXiv ID: 2411.12919
- Source URL: https://arxiv.org/abs/2411.12919
- Reference count: 40
- Primary result: Self-supervised GSURE denoising improves deep learning MRI reconstruction quality across SNR levels

## Executive Summary
This paper introduces a preprocessing approach that applies self-supervised denoising to multi-coil MRI data before training reconstruction models. Using GSURE (Generalized Stein's Unbiased Risk Estimator) loss, the method trains denoiser networks on noisy data without requiring clean references. The denoised outputs are then used to train two reconstruction methods: diffusion probabilistic models (DPMs) with diffusion posterior sampling (DPS) and model-based deep learning (MoDL). Across T2-weighted brain and fat-suppressed knee scans at various SNR levels and acceleration factors, models trained on GSURE-denoised data consistently outperformed those trained on noisy data, showing lower NRMSE and higher SSIM/PSNR. The denoising step was particularly effective at low SNRs, improved robustness to noise in inference, and enabled faster training convergence.

## Method Summary
The approach consists of two main stages: first, a denoiser network is trained using GSURE loss on noisy multi-coil MRI data, enabling self-supervised learning without clean reference images. This denoiser is then applied to preprocess the training data, producing denoised images that are used to train downstream reconstruction models. The paper evaluates two reconstruction architectures: diffusion probabilistic models with diffusion posterior sampling (DPM-DPS) and model-based deep learning (MoDL). Both architectures are trained on data that has been preprocessed by the GSURE-based denoiser. The denoiser is trained at a fixed SNR level (12dB for brain, 4dB for knee), and the same denoiser is used across different acceleration factors and SNR levels during reconstruction training. The denoising process involves taking the root sum of squares (RSS) of the multi-coil data and adding synthetic noise at the target SNR before denoising.

## Key Results
- Models trained on GSURE-denoised data consistently outperformed those trained on noisy data, with lower NRMSE and higher SSIM/PSNR
- Denoising was particularly effective at low SNRs, where models trained on 12dB (brain) or 4dB (knee) denoised data outperformed those trained on higher SNR data
- The approach enabled faster training convergence and improved robustness to noise during inference

## Why This Works (Mechanism)
The GSURE-denoising approach works by providing cleaner, less corrupted training data for the reconstruction models. When reconstruction models are trained on noisy data, they must learn to separate signal from noise, which can be challenging and may lead to suboptimal performance. By preprocessing with GSURE-based denoising, the training data has reduced noise levels while maintaining essential signal characteristics. This allows reconstruction models to focus on learning the underlying signal structure rather than noise characteristics. The authors hypothesize that this denoising step enables more robust prior learning, particularly for diffusion models, by correcting signal corruption without introducing excessive smoothing that could erase fine details.

## Foundational Learning

**Generalized Stein's Unbiased Risk Estimator (GSURE)**
*Why needed*: Provides a way to train denoising networks without clean reference data
*Quick check*: Verify that GSURE loss can be computed from noisy observations alone

**Multi-coil MRI reconstruction**
*Why needed*: Modern MRI scanners use multiple receiver coils, requiring specialized reconstruction approaches
*Quick check*: Confirm that RSS combination is appropriate for the denoising step

**Diffusion probabilistic models**
*Why needed*: One of the reconstruction architectures evaluated in the paper
*Quick check*: Understand the relationship between diffusion models and posterior sampling

**Model-based deep learning (MoDL)**
*Why needed*: The second reconstruction architecture evaluated
*Quick check*: Verify how MoDL incorporates data consistency with learned priors

**SNR-dependent training**
*Why needed*: The paper explores how training at different SNR levels affects reconstruction quality
*Quick check*: Confirm that synthetic SNR levels match realistic clinical scenarios

## Architecture Onboarding

**Component map**: Noisy multi-coil MRI data -> GSURE denoiser network -> Denoised images -> Reconstruction model (DPM-DPS or MoDL) -> Reconstructed images

**Critical path**: The denoiser training and application is the critical path, as it directly impacts the quality of the data used to train reconstruction models

**Design tradeoffs**: The approach trades additional preprocessing computation for improved reconstruction quality. Using self-supervised denoising avoids the need for clean reference data but may introduce bias if the denoiser over-smooths or under-denoises.

**Failure signatures**: Poor denoiser performance could lead to either insufficient noise reduction (leaving reconstruction models with noisy training data) or excessive smoothing (removing important signal details). The GSURE loss should help prevent underfitting, but the balance point remains a challenge.

**3 first experiments**:
1. Train denoiser at different SNR levels and evaluate reconstruction quality to identify optimal denoising strength
2. Compare reconstruction quality when training at matched vs. mismatched SNR levels
3. Test the approach on additional MRI sequences beyond T2-weighted brain and fat-suppressed knee

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific characteristics of GSURE-denoised images enable improved robustness in prior learning for diffusion models compared to clean data training?
- Basis in paper: [inferred] The paper notes that models trained on GSURE-denoised data at low SNRs (12dB for brain, 4dB for knee) often outperform those trained at higher SNRs, and that this benefit is not from the noise level itself but from the GSURE-denoising process.
- Why unresolved: The authors hypothesize that GSURE-denoising enables more robust prior learning by correcting signal corruption without over-smoothing, but they do not identify specific characteristics that enable this robustness.
- What evidence would resolve it: Comparative analysis of the statistical properties, feature distributions, and representation spaces of GSURE-denoised images versus clean and noisy images, coupled with ablation studies isolating specific denoising effects.

### Open Question 2
- Question: How does the GSURE-denoising approach compare to other self-supervised denoising methods like Noise2Self or Noise2Score in terms of MRI reconstruction quality and training efficiency?
- Basis in paper: [explicit] The paper mentions that other self-supervised denoising methods exist (Noise2Self, Noise2Score) and discusses how GSURE differs from them, but does not perform comparative experiments.
- Why unresolved: The paper focuses specifically on GSURE and does not benchmark against alternative self-supervised denoising approaches that could potentially offer similar or better benefits.
- What evidence would resolve it: Direct comparative experiments training reconstruction models using GSURE-denoised data versus data denoised with alternative self-supervised methods, measuring reconstruction quality and computational efficiency.

### Open Question 3
- Question: What is the optimal balance between denoising strength and signal distortion preservation for different SNR levels and anatomies in MRI reconstruction?
- Basis in paper: [explicit] The discussion section acknowledges that denoising can improve reconstruction quality at low SNRs but may introduce signal distortions at high SNRs, and that balancing denoising strength while maintaining signal integrity remains a challenge.
- Why unresolved: The paper does not systematically explore how different denoising strengths affect reconstruction quality across the SNR spectrum, nor does it provide guidance on optimal denoising parameters for different scenarios.
- What evidence would resolve it: Systematic parameter sweep experiments varying denoising strength across multiple SNR levels and anatomies, with quantitative and qualitative evaluation of the trade-off between noise reduction and signal preservation.

## Limitations
- The approach was only evaluated on T2-weighted brain and fat-suppressed knee scans, limiting generalizability to other MRI sequences and anatomies
- The computational overhead of the denoiser network during preprocessing and training was not quantified
- The study did not benchmark against supervised denoising methods trained on clean reference data
- The fixed SNR sampling strategy may not capture the full variability of noise encountered in clinical practice

## Confidence
- High confidence in the claim that GSURE-based self-supervised denoising improves reconstruction quality for the tested modalities and SNR ranges, given consistent improvements in NRMSE, SSIM, and PSNR across multiple models and acceleration factors
- Medium confidence in the assertion of faster training convergence, as this was observed but not systematically benchmarked
- Low confidence in the broader claim of model-agnostic robustness, since only two reconstruction architectures were evaluated and the study did not test on heterogeneous or unseen datasets

## Next Checks
1. Evaluate the GSURE denoiser and downstream reconstruction models on additional MRI sequences (e.g., T1, FLAIR) and anatomies (e.g., abdomen, spine) to assess generalizability
2. Compare the self-supervised denoising pipeline against supervised denoising baselines trained on paired noisy-clean data to quantify relative performance gains
3. Measure and report the computational overhead (training/inference time, memory usage) introduced by the denoiser network to assess practical deployment feasibility