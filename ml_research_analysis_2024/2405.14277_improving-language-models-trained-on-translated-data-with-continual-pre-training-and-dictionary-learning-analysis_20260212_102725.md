---
ver: rpa2
title: Improving Language Models Trained on Translated Data with Continual Pre-Training
  and Dictionary Learning Analysis
arxiv_id: '2405.14277'
source_url: https://arxiv.org/abs/2405.14277
tags:
- data
- language
- training
- arabic
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the challenges of training language models
  for low-resource languages using translated data. It trains small Arabic language
  models on translated TinyStories data, identifies cultural and linguistic issues
  from machine translation, and proposes continual pre-training with high-quality
  synthetic Arabic stories to address these issues.
---

# Improving Language Models Trained on Translated Data with Continual Pre-Training and Dictionary Learning Analysis

## Quick Facts
- arXiv ID: 2405.14277
- Source URL: https://arxiv.org/abs/2405.14277
- Reference count: 19
- Small Arabic language models trained on translated TinyStories data show cultural and linguistic issues, which are corrected through continual pre-training with high-quality synthetic Arabic stories and analyzed using Sparse Auto-Encoders

## Executive Summary
This paper addresses the challenge of training language models for low-resource languages using translated data. The authors train small Arabic language models on machine-translated TinyStories data, identify cultural and linguistic artifacts from the translation process, and propose a solution involving continual pre-training with high-quality synthetic Arabic stories. Using GPT-4 evaluation and mechanistic interpretability analysis with Sparse Auto-Encoders, they demonstrate improved model performance across grammar, creativity, and consistency metrics while reducing cultural bias and correcting linguistic issues in dialog tagging.

## Method Summary
The authors translate the TinyStories dataset (2.2M short stories) from English to Arabic using NLLB-3B, then train seven different small language model architectures (1M-33M parameters) on this translated data. They identify cultural and linguistic issues in the translated data, then generate high-quality synthetic Arabic stories using Command R+ (20K stories representing 1% of the original data). The models are refined through continual pre-training on this synthetic data. Performance is evaluated using GPT-4 as a judge for grammar, creativity, and consistency, while Sparse Auto-Encoders analyze model behavior to validate improvements in cultural bias and linguistic accuracy.

## Key Results
- Continual pre-training with synthetic Arabic stories (1% of original data) improves grammar, creativity, and consistency scores compared to models trained only on translated data
- Sparse Auto-Encoder analysis shows reduced English name bias and corrected Arabic dialogue tagging after continual pre-training
- Smaller models (28M-33M parameters) outperform larger ones on Arabic tasks, suggesting optimal parameter-to-data ratio

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continual pre-training with high-quality synthetic data corrects cultural and linguistic issues inherited from machine-translated training data
- Mechanism: The small amount of high-quality synthetic Arabic stories (1% of original training data) exposes the model to native Arabic patterns, overwriting translation artifacts during the fine-tuning phase
- Core assumption: Translation artifacts in the base model are not so deeply embedded that they cannot be overwritten by a small amount of clean data
- Evidence anchors:
  - [abstract]: "we further pre-train the models with a small dataset of synthesized high-quality Arabic stories generated by a capable LLM, representing 1% of the original training data"
  - [section 3.1.2]: "Continual pre-training shows performance improvement over the three metrics"
  - [corpus]: Weak evidence - neighboring papers discuss continual pre-training but focus on parallel data rather than synthetic data
- Break condition: If translation artifacts are too deeply embedded or the high-quality data lacks sufficient diversity to cover the necessary patterns

### Mechanism 2
- Claim: Sparse Auto-Encoders (SAEs) can identify and quantify cultural bias and linguistic issues in language models
- Mechanism: SAEs decompose neuron activations into sparse, interpretable features that reveal which tokens and patterns the model favors, allowing detection of English name bias and incorrect Arabic dialogue structures
- Core assumption: The SAE features learned from the MLP layer activations are meaningful and capture the linguistic/cultural patterns we want to analyze
- Evidence anchors:
  - [abstract]: "we train Sparse Auto-Encoder (SAE) on a selected SLM to analyze the model behavior"
  - [section 3.2.3]: "We identified and marked the features farther from the diagonal with at least 2 point difference between the English and Arabic name enrichment scores"
  - [corpus]: Weak evidence - neighboring papers discuss SAEs but focus on different applications like interpretability research
- Break condition: If SAE features are polysemantic or fail to capture the specific cultural/linguistic patterns we're investigating

### Mechanism 3
- Claim: Token Set Enrichment Analysis (TSEA) provides statistical validation of bias correction after continual pre-training
- Mechanism: TSEA compares enrichment scores for different token sets (e.g., English vs Arabic names) before and after continual pre-training, showing whether the model's preference shifts from translation artifacts to native patterns
- Core assumption: The enrichment score differences between token sets are statistically meaningful and reflect actual bias correction
- Evidence anchors:
  - [section 3.2.3]: "Figure 2 shows the scatter plot of enrichment scores for English vs. Arabic names" and "the similar plot after continual pre-training in Figure 3 shows only one feature has the gap"
  - [corpus]: Weak evidence - neighboring papers don't discuss TSEA specifically for bias correction in language models
- Break condition: If the enrichment score differences are not statistically significant or if other factors besides continual pre-training are driving the changes

## Foundational Learning

- Concept: Machine translation quality and its impact on language model training
  - Why needed here: The paper relies on understanding how medium-quality translation introduces cultural and linguistic artifacts that affect model performance
  - Quick check question: What specific issues arise when training Arabic models on English-to-Arabic machine-translated data, and how do these differ from native Arabic training data?

- Concept: Continual pre-training methodology
  - Why needed here: The proposed solution involves using a small amount of high-quality synthetic data to refine models trained on translated data
  - Quick check question: How does continual pre-training differ from standard fine-tuning, and why is 1% of the original training data sufficient for meaningful improvement?

- Concept: Mechanistic interpretability and Sparse Auto-Encoders
  - Why needed here: The paper uses SAEs to analyze whether continual pre-training successfully corrects translation issues
  - Quick check question: How do Sparse Auto-Encoders decompose neural network activations, and what makes them more interpretable than traditional neuron-level analysis?

## Architecture Onboarding

- Component map:
  NLLB-3B translated TinyStories (2.2M stories) -> 7 different SLM architectures (1M-33M parameters) -> Custom BPE tokenizer (32k vocabulary) -> GPT-4 evaluation (grammar, creativity, consistency) -> Command R+ synthetic data generation (20K stories) -> Continual pre-training -> Sparse Auto-Encoders on MLP layer activations -> Token Set Enrichment Analysis

- Critical path:
  1. Translate TinyStories using NLLB-3B
  2. Train base SLMs on translated data
  3. Generate synthetic Arabic stories using Command R+
  4. Continually pre-train base models on synthetic data
  5. Analyze using SAEs and TSEA to validate improvements

- Design tradeoffs:
  - Translation quality vs. scale: NLLB-3B provides medium-quality translation suitable for large-scale training but introduces artifacts
  - Synthetic data quantity vs. quality: 1% ratio balances training time with effectiveness
  - Model size vs. capability: Smaller models (28M-33M) show best performance, suggesting optimal parameter-to-data ratio
  - Analysis complexity vs. insight: SAEs provide deep interpretability but require significant computational resources

- Failure signatures:
  - Base model training: High validation loss relative to English-trained counterparts indicates translation noise
  - Continual pre-training: Minimal loss reduction suggests data quality issues or insufficient model capacity
  - SAE analysis: Polysemantic features or inability to distinguish cultural patterns indicates analysis limitations
  - GPT-4 evaluation: Inconsistent scoring across different Arabic prompts suggests evaluation reliability issues

- First 3 experiments:
  1. Baseline: Train 33M-ar model on translated data only, evaluate with GPT-4, collect loss curves
  2. Refinement: Continually pre-train baseline with synthetic data, compare GPT-4 scores and loss curves
  3. Analysis: Train SAEs on both models, perform TSEA for English vs Arabic names, analyze feature dashboards for dialogue tagging

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of models trained on machine-translated data scale with increasing model size, particularly when moving from 30M to 100M+ parameters?
- Basis in paper: [inferred] The paper trains models up to 33M parameters and notes that emergent capabilities are typically observed in models 10B+ parameters, but doesn't investigate the intermediate range
- Why unresolved: The paper focuses on small language models (SLMs) and doesn't explore whether the translation-related issues persist or diminish at larger scales where models might have more capacity to learn correct linguistic patterns
- What evidence would resolve it: Training and evaluating models in the 50M-200M parameter range on translated data, comparing performance degradation patterns to those observed in the 30M parameter models

### Open Question 2
- Question: What is the optimal ratio of high-quality synthetic data to machine-translated data for continual pre-training to correct translation artifacts while maintaining diversity?
- Basis in paper: [explicit] The paper uses 1% high-quality synthetic data (20K stories) to 99% translated data but suggests this as an initial exploration, noting that other strategies like multi-epochs or mixing data would be explored in future work
- Why unresolved: The paper presents one data ratio without systematic exploration of how different proportions affect the balance between correcting translation issues and preserving the benefits of the larger translated dataset
- What evidence would resolve it: Systematic experiments varying the ratio of high-quality to translated data (e.g., 0.1%, 1%, 5%, 10%, 25%) while measuring both correction of translation artifacts and overall model performance

### Open Question 3
- Question: How transferable are the translation correction techniques to other language pairs beyond Arabic-English, particularly for languages with different grammatical structures or cultural contexts?
- Basis in paper: [inferred] The paper focuses specifically on Arabic as a case study of a low-resource language but doesn't explore whether the identified issues (cultural bias, dialog tagging) generalize to other language pairs
- Why unresolved: While the methodology could theoretically apply to any language pair, the specific linguistic and cultural issues identified are language-dependent, and the effectiveness of continual pre-training may vary based on linguistic distance between source and target languages
- What evidence would resolve it: Applying the same methodology to translate datasets into other languages (e.g., Hindi, Swahili, Turkish) and comparing the types and severity of translation artifacts, as well as the effectiveness of the correction approach

## Limitations

- Reliance on GPT-4 evaluation for Arabic content may introduce cultural and linguistic blind spots
- Synthetic data generation creates dependency chain where quality depends on upstream model's English training
- SAE analysis provides correlational rather than causal evidence about performance improvement mechanisms
- Study focuses exclusively on Arabic, limiting generalizability to other low-resource languages

## Confidence

**High Confidence**: The observation that continual pre-training with synthetic data improves grammar, creativity, and consistency metrics compared to models trained only on translated data.

**Medium Confidence**: The mechanistic explanation that SAE features reveal cultural bias correction and linguistic improvements.

**Low Confidence**: The generalizability of the 1% synthetic data ratio to other language pairs and domains.

## Next Checks

1. **Cross-linguistic validation**: Replicate the entire experimental pipeline (translated training → continual pre-training → SAE analysis) with at least two additional low-resource language pairs (e.g., Hindi and Swahili) to test whether the 1% synthetic data ratio and observed performance improvements generalize beyond Arabic.

2. **Human evaluation benchmark**: Commission professional native Arabic speakers to evaluate a subset of model outputs using the same grammar, creativity, and consistency rubrics, then statistically compare these human scores against GPT-4 evaluations to quantify potential systematic biases in automated assessment.

3. **Ablation on synthetic data quantity**: Systematically vary the proportion of synthetic data used in continual pre-training (0.1%, 1%, 10%, 25%) while keeping all other variables constant, then measure the marginal returns on each performance metric to determine whether the 1% ratio is truly optimal or could be significantly improved.