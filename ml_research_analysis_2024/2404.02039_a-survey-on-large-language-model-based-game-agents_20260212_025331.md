---
ver: rpa2
title: A Survey on Large Language Model-Based Game Agents
arxiv_id: '2404.02039'
source_url: https://arxiv.org/abs/2404.02039
tags:
- agents
- reasoning
- memory
- language
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a comprehensive review of LLM-based game
  agents (LLMGAs), addressing the gap in understanding how LLMs enable agents to perceive,
  think, and act within interactive game environments. The paper introduces a unified
  framework that breaks down LLMGAs into three core components at the single-agent
  level: memory systems (working and long-term), reasoning mechanisms, and perception-action
  interfaces.'
---

# A Survey on Large Language Model-Based Game Agents

## Quick Facts
- arXiv ID: 2404.02039
- Source URL: https://arxiv.org/abs/2404.02039
- Reference count: 40
- Primary result: Comprehensive framework for LLM-based game agents addressing perception, reasoning, and action in interactive environments

## Executive Summary
This survey presents a unified framework for understanding and developing LLM-based game agents (LLMGAs), addressing the critical gap in how these agents perceive, think, and act within interactive game environments. The authors introduce a systematic breakdown of LLMGAs into three core components at the single-agent level (memory systems, reasoning mechanisms, and perception-action interfaces) and communication/organization structures at the multi-agent level. Through a challenge-centered taxonomy linking six game genres to specific design requirements, the survey positions game environments as essential testbeds for advancing interactive intelligence and identifies key research directions including world-model memories, reasoning feedback improvements, and scalable multi-agent systems.

## Method Summary
The survey employs a systematic literature review approach to analyze existing LLMGA research, categorizing findings into a unified framework that addresses both single-agent and multi-agent scenarios. The authors examine how different game genres present unique challenges for LLMGAs, from low-latency control requirements in action games to complex state modeling in strategy games. The methodology involves identifying core architectural components, analyzing communication protocols for multi-agent coordination, and mapping these elements to specific game genre challenges. While the approach is comprehensive in its conceptual organization, it remains primarily theoretical without extensive empirical validation across the identified game categories.

## Key Results
- Introduces a three-component framework (memory, reasoning, perception-action) for single-agent LLMGAs
- Proposes communication and organizational structures for multi-agent LLMGAs
- Develops a challenge-centered taxonomy linking six game genres to specific LLMGA design requirements
- Identifies world-model memories, reasoning feedback, and multi-agent scalability as key research directions

## Why This Works (Mechanism)
LLM-based game agents leverage the language understanding and generation capabilities of large language models to bridge the gap between natural language commands and complex game environments. The framework works by decomposing agent intelligence into modular components: memory systems store and retrieve game state and learned strategies, reasoning mechanisms process this information to make decisions, and perception-action interfaces translate between game environments and LLM inputs/outputs. This modular approach allows for systematic addressing of game-specific challenges while maintaining the flexibility to adapt to different game genres and agent coordination requirements.

## Foundational Learning

1. **Working Memory vs. Long-term Memory**
   - Why needed: Games require both immediate state tracking (working memory) and learned strategies/past experiences (long-term memory)
   - Quick check: Can the agent maintain consistent behavior across sessions while adapting to immediate game state changes?

2. **Reasoning Feedback Loops**
   - Why needed: LLMGAs need mechanisms to evaluate the effectiveness of their decisions and refine strategies
   - Quick check: Does the agent show improvement in performance over repeated similar scenarios?

3. **Perception-Action Interface Design**
   - Why needed: Converting between game state representations and natural language while maintaining low latency
   - Quick check: Can the agent respond within acceptable time limits while preserving action accuracy?

## Architecture Onboarding

**Component Map:** Game Environment -> Perception Interface -> Working Memory <-> Long-term Memory -> Reasoning Engine -> Action Interface -> Game Environment

**Critical Path:** Perception Interface → Working Memory → Reasoning Engine → Action Interface
The perception-action loop must maintain low latency while preserving information fidelity for effective decision-making.

**Design Tradeoffs:**
- Memory capacity vs. response speed: Larger memory enables better long-term strategy but increases latency
- Reasoning depth vs. real-time performance: Deeper reasoning improves decision quality but may not meet real-time constraints
- Language abstraction vs. action precision: Higher-level commands are more flexible but may lose specific control details

**Failure Signatures:**
- High latency responses indicate bottlenecks in memory retrieval or reasoning computation
- Inconsistent behavior suggests working memory corruption or poor state tracking
- Poor coordination in multi-agent scenarios indicates communication protocol failures

**3 First Experiments:**
1. Single-agent performance test in a simple environment measuring response time vs. memory size
2. Multi-agent coordination test in a collaborative game measuring communication overhead
3. Cross-genre capability test moving an agent from one game type to another to assess generalization

## Open Questions the Paper Calls Out
None

## Limitations
- Framework lacks empirical validation across diverse game genres and agent configurations
- No quantitative performance benchmarks comparing different LLMGA architectures
- Limited discussion of computational resource requirements and scalability constraints
- Theoretical approach without implementation details for key components

## Confidence

**High Confidence:** General categorization of LLMGA components and identification of game genres as testbeds for interactive intelligence

**Medium Confidence:** Challenge-centered taxonomy linking game genres to specific LLMGA design requirements

**Low Confidence:** Effectiveness of current solutions in addressing identified challenges due to lack of empirical validation

## Next Checks

1. Implement benchmark evaluations of existing LLMGAs across the six identified game genres to test the proposed challenge-centered taxonomy

2. Conduct empirical studies comparing different memory architectures (working vs. long-term) in specific game scenarios to validate the memory component framework

3. Develop and test multi-agent coordination protocols in complex game environments to assess the scalability claims and organizational structures proposed in the survey