---
ver: rpa2
title: 'BANGS: Game-Theoretic Node Selection for Graph Self-Training'
arxiv_id: '2410.09348'
source_url: https://arxiv.org/abs/2410.09348
tags:
- nodes
- node
- graph
- self-training
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BANGS, a novel graph self-training framework
  that addresses key limitations in existing methods through combinatorial node selection
  using game-theoretic Banzhaf values and conditional mutual information. Unlike traditional
  approaches that rank and select nodes independently based on confidence, BANGS considers
  nodes as a collective set and captures their combinatorial dependencies.
---

# BANGS: Game-Theoretic Node Selection for Graph Self-Training

## Quick Facts
- **arXiv ID:** 2410.09348
- **Source URL:** https://arxiv.org/abs/2410.09348
- **Reference count:** 40
- **Primary result:** BANGS achieves up to 2% higher accuracy than state-of-the-art methods while maintaining robustness to noisy labels

## Executive Summary
This paper introduces BANGS, a novel graph self-training framework that addresses key limitations in existing methods through combinatorial node selection using game-theoretic Banzhaf values and conditional mutual information. Unlike traditional approaches that rank and select nodes independently based on confidence, BANGS considers nodes as a collective set and captures their combinatorial dependencies. The framework estimates student model predictions through feature propagation from labeled nodes, enabling effective node selection without model retraining. Extensive experiments across multiple datasets and base models demonstrate superior performance.

## Method Summary
BANGS addresses graph self-training by formulating node selection as a combinatorial optimization problem using game-theoretic Banzhaf values. The framework estimates student model predictions through feature propagation from labeled nodes using personalized PageRank, then selects nodes that maximize conditional mutual information with the unlabeled data. Key components include confidence calibration using Expected True Score (ETS), Banzhaf value computation through maximum sample reuse Monte Carlo estimation, and iterative self-training with combinatorial node selection. The method provides theoretical guarantees for robustness under noisy utility functions and demonstrates superior performance across multiple datasets.

## Key Results
- BANGS achieves up to 2% higher accuracy than state-of-the-art methods across multiple datasets
- The framework maintains robustness to noisy labels and varying training data proportions
- BANGS outperforms baseline methods in ablation studies on both Banzhaf values and calibration techniques

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** BANGS addresses the limitation of independent node selection in graph self-training by considering nodes as a collective set using combinatorial dependencies.
- **Mechanism:** The framework uses Banzhaf values from cooperative game theory to measure each node's contribution to the overall utility of a pseudo-label set. Unlike ranking nodes independently, BANGS evaluates how pivotal each node is for the success of the coalition (selected node set), accounting for interdependencies.
- **Core assumption:** The utility of selecting a node depends not just on its individual confidence but also on its combinatorial contribution to the information gain of the entire unlabeled dataset.
- **Evidence anchors:**
  - [abstract] "unlike traditional methods that rank and select nodes independently, BANGS considers nodes as a collective set in the self-training process."
  - [section 3.2] "To capture the combinatorial dependency of the contributions of the nodes, we adopt a game theory-based measure, namely Banzhaf value (Wang & Jia, 2023)."
  - [corpus] Weak - no direct citations about Banzhaf values in neighboring papers.

### Mechanism 2
- **Claim:** BANGS estimates student model predictions through feature propagation from labeled nodes without requiring model retraining.
- **Mechanism:** The framework propagates the logits of labeled and pseudo-labeled nodes to unlabeled nodes using personalized PageRank (PPR) to approximate the student model's predictions. This propagation captures the influence of labeled nodes on their neighbors, enabling effective node selection based on the conditional mutual information objective.
- **Core assumption:** The feature influence distribution can be approximated by the L-step random walk distribution, and this approximation holds under the assumptions about GNN aggregation mechanisms.
- **Evidence anchors:**
  - [section 3.1] "Using PPR, we estimate the student model output by summing up the feature influence of all labeled Vl, pseudo-labeled nodes Vp r−1, and the new selection set Vp r ′ at round r."
  - [section 3.1] "Theorem 3.1 (Feature influence computation via random walk). With Assumption 1, If(i → j, L), the influence distribution of any node vi ∈ V is nearly equivalent, in expectation to, the L-step random walk distribution on G starting at node vj."
  - [corpus] Weak - no direct citations about feature propagation in neighboring papers.

### Mechanism 3
- **Claim:** BANGS provides theoretical guarantees for robustness under noisy utility functions through the preservation of optimal node ranking.
- **Mechanism:** The framework shows that when the distinguishability between nodes is sufficiently large and the utility perturbation is small, the Banzhaf value ranking remains robust even with noisy utility estimation. This ensures that the top-k nodes selected are still the optimal choice despite estimation errors.
- **Core assumption:** The utility function can be estimated with bounded error, and the distinguishability between top nodes and non-top nodes is large enough to preserve ranking.
- **Evidence anchors:**
  - [section 3.2] "In the next theorem, we show that when the value of utility between adding vi and vj is sufficiently large, and the estimation error in our utility function is moderate, the ranking of vi and vj remains robust even under noisy utility estimation ˆU."
  - [section 3.2] "Theorem 3.2. When the distinguishability of ground-truth utility between vi and vj on coalitions less than size k is large enough, minm≤k−1 ∆(m) i,j (U) ≥ τ, and the perturbation in utility functions is small such that || ˆU − U || 2 ≤ τ qPk−1 m=1 ( |Vu r−1|−2 m−1 ), then Di,j(U)Di,j( ˆU) = (ˆϕ(i) − ˆϕ(j))(ϕ(i) − ϕ(j)) ≥ 0."
  - [corpus] Weak - no direct citations about theoretical robustness guarantees in neighboring papers.

## Foundational Learning

- **Concept:** Graph Neural Networks (GNNs) and their message-passing mechanism
  - Why needed here: BANGS relies on GNN predictions for pseudo-label generation and feature propagation for utility estimation.
  - Quick check question: Can you explain how a 2-layer GCN propagates information from labeled nodes to their 2-hop neighbors?

- **Concept:** Game theory and Banzhaf values
  - Why needed here: BANGS uses Banzhaf values to measure the combinatorial contribution of nodes to the pseudo-label set.
  - Quick check question: What is the difference between Shapley value and Banzhaf value in cooperative game theory?

- **Concept:** Information theory and mutual information
  - Why needed here: BANGS formulates node selection as maximizing the conditional mutual information between unlabeled data and predictions.
  - Quick check question: How does conditional mutual information differ from regular mutual information in the context of semi-supervised learning?

## Architecture Onboarding

- **Component map:**
  - Teacher model -> Confidence calibration (ETS) -> Feature propagation (PPR) -> Banzhaf value calculator -> Node selector -> Student model trainer -> Back to teacher model

- **Critical path:**
  1. Train initial teacher model on labeled data
  2. Generate pseudo-labels and calculate confidences
  3. Propagate features from labeled/pseudo-labeled nodes to estimate student predictions
  4. Calculate utility function and Banzhaf values for candidate nodes
  5. Select top-k nodes and add their pseudo-labels
  6. Retrain student model and repeat

- **Design tradeoffs:**
  - Computational cost vs. accuracy: More candidate nodes (K) and samples (B) improve Banzhaf estimation but increase computation time
  - Propagation depth (H) vs. approximation quality: Deeper propagation better approximates student predictions but is more expensive
  - Node selection frequency vs. model stability: More frequent selection may capture distribution shifts but could introduce instability

- **Failure signatures:**
  - Poor performance despite high confidence: Indicates calibration issues or noisy utility estimation
  - Degraded performance with more iterations: Suggests confirmation bias or overfitting to incorrect pseudo-labels
  - High variance across runs: May indicate sensitivity to initialization or insufficient sampling in Banzhaf calculation

- **First 3 experiments:**
  1. Baseline comparison: Run BANGS vs. CPL on Cora dataset with GCN base model to verify performance improvement
  2. Ablation study: Test BANGS with and without Banzhaf values on Citeseer to confirm combinatorial selection advantage
  3. Robustness test: Evaluate BANGS performance with 10% label noise on PubMed to verify theoretical guarantees under perturbation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical impact of using different GNN architectures (beyond GCN, GraphSAGE, GAT, and GIN) on BANGS's performance and theoretical guarantees?
- Basis in paper: [explicit] The paper states "Note that we have assumed the base model to be a L-layer GNN with a graph structure dependent linear aggregation mechanism and ReLU activation" and tests BANGS with GCN, GraphSAGE, GAT, and GIN, showing good performance across these models.
- Why unresolved: The paper only tests BANGS with a limited set of GNN architectures. The theoretical guarantees (Theorem 3.1 and Theorem 3.2) rely on specific assumptions about the GNN architecture.
- What evidence would resolve it: Comprehensive experiments testing BANGS with a broader range of GNN architectures (e.g., GatedGCN, JK-Net, Graph U-Nets) and analyzing how deviations from the assumptions affect performance and theoretical guarantees.

### Open Question 2
- Question: How does the choice of teleportation probability α in the personalized PageRank computation affect BANGS's performance and scalability?
- Basis in paper: [explicit] The paper mentions "α ∈ (0, 1] is a teleportation probability" in Definition 3.2 but does not provide a detailed analysis of its impact.
- Why unresolved: The teleportation probability is a key hyperparameter in the PPR computation, which is central to BANGS's feature propagation mechanism. Its impact on performance and scalability is not thoroughly explored.
- What evidence would resolve it: Systematic experiments varying α across a range of values and analyzing its effect on BANGS's accuracy, convergence speed, and computational cost. Additionally, theoretical analysis of how α affects the approximation quality of the student model's predictions.

### Open Question 3
- Question: Can BANGS be extended to handle dynamic graphs where the structure and features evolve over time?
- Basis in paper: [inferred] The paper focuses on static graphs and does not address the challenge of dynamic graphs, which are common in real-world applications.
- Why unresolved: The current formulation of BANGS assumes a fixed graph structure and feature matrix. Extending it to dynamic graphs would require addressing challenges like efficiently updating the feature influence matrix and adapting the node selection strategy to account for temporal dependencies.
- What evidence would resolve it: A modified version of BANGS that can handle dynamic graphs, along with experimental results demonstrating its effectiveness on dynamic graph datasets and theoretical analysis of its performance guarantees in the dynamic setting.

## Limitations

- The framework's effectiveness heavily depends on accurate utility function estimation and sufficient distinguishability between nodes
- Computational complexity of computing Banzhaf values through sampling could become prohibitive for very large graphs
- The theoretical guarantees rely on specific GNN architecture assumptions that may not hold for all models

## Confidence

- **High Confidence:** The core mechanism of using game-theoretic Banzhaf values for combinatorial node selection
- **Medium Confidence:** The feature propagation approach for student model estimation
- **Medium Confidence:** The theoretical robustness guarantees under noisy utility

## Next Checks

1. **Scalability Test:** Evaluate BANGS performance on larger graphs (e.g., OGB datasets) to assess computational feasibility and whether the Banzhaf value sampling remains effective at scale.
2. **Architecture Sensitivity:** Test BANGS with different GNN architectures (GAT, GraphSAGE) to verify that the feature propagation assumptions hold beyond GCNs.
3. **Robustness Analysis:** Systematically vary the utility estimation error and node distinguishability to empirically validate the theoretical bounds on ranking preservation.