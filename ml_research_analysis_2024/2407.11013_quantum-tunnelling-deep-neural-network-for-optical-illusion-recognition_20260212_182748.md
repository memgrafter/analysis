---
ver: rpa2
title: Quantum-tunnelling deep neural network for optical illusion recognition
arxiv_id: '2407.11013'
source_url: https://arxiv.org/abs/2407.11013
tags:
- quantum
- perception
- neural
- cube
- qt-dnn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a quantum tunnelling deep neural network
  (QT-DNN) model that uses the quantum tunnelling effect as its activation function
  to recognize optical illusions like the Necker cube and Rubin's vase. The model
  addresses the limitation of traditional AI systems in perceiving visual ambiguities
  the way humans do.
---

# Quantum-tunnelling deep neural network for optical illusion recognition

## Quick Facts
- arXiv ID: 2407.11013
- Source URL: https://arxiv.org/abs/2407.11013
- Reference count: 0
- Primary result: QT-DNN uses quantum tunnelling transmission coefficients as activation functions to predict perceptual states of optical illusions, producing more human-like results than ReLU networks

## Executive Summary
This paper introduces a quantum tunnelling deep neural network (QT-DNN) that models optical illusion perception by using quantum tunnelling transmission coefficients as activation functions. The model successfully predicts switching between perceptual states of the Necker cube and Rubin's vase illusions, including intermediate superposition states. The approach addresses the limitation of traditional AI systems in perceiving visual ambiguities by incorporating quantum cognition principles and chaotic weight initialization with quantum random number generation.

## Method Summary
The QT-DNN architecture uses quantum tunnelling transmission coefficients as activation functions for three hidden layers (20 nodes each), with an input layer of 100 nodes and output layer of 2 nodes. The model is trained on unambiguous versions of optical illusions using backpropagation with chaotic weight initialization and quantum random number generation. After training, the network is exploited on ambiguous versions to predict perceptual switching patterns, which are then compared using Dynamic Time Warping (DTW) analysis against patterns from Sigmoid-DNN and ReLU-DNN networks.

## Key Results
- QT-DNN successfully predicts perceptual state switching between interpretations of both Necker cube and Rubin's vase illusions
- The model produces intermediate superposition states between binary interpretations, consistent with quantum cognition theory
- QT-DNN shows more human-like perception patterns than ReLU-DNN but similar performance to Sigmoid-DNN, suggesting quantum tunnelling activation functions better model cognitive processes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Quantum tunnelling-based activation functions enable modeling of perceptual ambiguity through non-binary state transitions.
- Mechanism: The QT-DNN uses transmission probability functions derived from quantum tunnelling physics as activation functions, allowing the network to represent superposition states rather than just binary classifications.
- Core assumption: Perceptual switching between interpretations of optical illusions involves continuous transitions through intermediate states rather than discrete jumps.
- Evidence anchors:
  - [abstract] states the model "predicts the switching between perceptual states" and includes "intermediate superposition states"
  - [section] explains "humans might see a quantum-like superposition of |0⟩ and |1⟩ states" and shows QT-DNN produces "intermediate states that can be interpreted as a superposition"
  - [corpus] provides no direct evidence supporting this mechanism
- Break condition: If experimental validation shows human perception follows strictly binary transitions without intermediate states, this mechanism would fail.

### Mechanism 2
- Claim: Chaotic weight initialization combined with quantum random number generation better simulates human perception variability.
- Mechanism: Randomizing network weights using quantum random number generators introduces true randomness that captures the stochastic nature of human perceptual switching, while chaotic initialization prevents convergence to stable but unrealistic patterns.
- Core assumption: Human perception of optical illusions is inherently stochastic and cannot be accurately modeled with pseudo-random or deterministic weight initialization.
- Evidence anchors:
  - [section] states "I employ a physical generator of random numbers based on coherent quantum-optical processes" and notes this "ensures that the software model of QT-DNN is not biased towards one of the possible perceptual states"
  - [abstract] mentions "chaotic weight initialization and quantum random number generation to better simulate human perception"
  - [corpus] provides no direct evidence supporting this mechanism
- Break condition: If perceptual switching patterns show strong individual consistency across trials, the need for quantum randomness would be questionable.

### Mechanism 3
- Claim: QT-based activation functions produce more human-like perception patterns than ReLU but similar to Sigmoid functions.
- Mechanism: The shape and properties of quantum tunnelling probability functions create activation dynamics that better match the firing patterns observed in biological neurons and the decision-making processes modeled in quantum cognition theory.
- Core assumption: The mathematical form of quantum tunnelling probability functions inherently captures aspects of biological neural computation that standard machine learning activation functions miss.
- Evidence anchors:
  - [section] shows "the most similar results were produced by QT-DNN and Sigmoid-DNN but the largest distance was observed between the outputs of QT-DNN and ReLU-DNN"
  - [section] notes "the shape of the QT activation function is similar to the shape of the neural activation function motivated by biological data"
  - [corpus] provides no direct evidence supporting this mechanism
- Break condition: If subsequent benchmarking shows ReLU-based networks perform equally or better on perceptual ambiguity tasks, this mechanism would need revision.

## Foundational Learning

- Quantum tunnelling transmission coefficient
  - Why needed here: The transmission coefficient formulas (equations A2-A4) serve as the activation functions in QT-DNN, directly determining how information flows through the network
  - Quick check question: What are the two limiting cases for electron transmission probability through a potential barrier, and how do they differ mathematically?

- Quantum cognition theory and superposition states
  - Why needed here: The model's interpretation relies on understanding that perceptual states can exist in superpositions rather than just binary states, which is central to explaining the intermediate outputs
  - Quick check question: How does quantum cognition theory explain the perception of ambiguous figures differently from classical probability models?

- Dynamic Time Warping (DTW) for time-series comparison
  - Why needed here: DTW is used to quantify similarity between the perceptual switching patterns generated by different network architectures, accounting for variations in switching speed
  - Quick check question: What advantage does DTW have over simple Euclidean distance when comparing temporal sequences with variable timing?

## Architecture Onboarding

- Component map:
  Input layer (100 nodes) → Three hidden layers (20 nodes each) → Output layer (2 nodes)

- Critical path:
  1. Generate truly random initial weights using quantum random number generator
  2. Train network on unambiguous versions of optical illusions
  3. Exploit trained network on ambiguous versions
  4. Record output state transitions over multiple runs
  5. Compare switching patterns using DTW analysis

- Design tradeoffs:
  - Quantum tunnelling activation provides more realistic perceptual modeling but increases computational complexity compared to standard activation functions
  - Quantum random number generation ensures unbiased results but requires specialized hardware access
  - Chaotic initialization prevents convergence to unrealistic stable states but may require more training iterations

- Failure signatures:
  - Output consistently showing only binary states (0 or 1) without intermediate values indicates activation function implementation issues
  - Extremely rapid or extremely slow switching frequencies compared to human data suggests parameter tuning problems
  - Lack of similarity between QT-DNN and Sigmoid-DNN outputs when biological plausibility is expected indicates fundamental implementation errors

- First 3 experiments:
  1. Implement basic QT-DNN with simplified transmission coefficient and verify it produces intermediate states between 0 and 1 on simple classification tasks
  2. Compare QT-DNN output patterns with Sigmoid-DNN and ReLU-DNN on the Necker cube task, measuring DTW distances
  3. Test the impact of quantum random number generator versus pseudo-random generator on the distribution of perceptual states

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can QT-DNN performance be validated against empirical human perception data from psycho-physiological experiments on optical illusions?
- Basis in paper: [explicit] The authors acknowledge that quantitative assessment against human-generated data is unavailable and that future benchmarking against rigorous experimental data is needed.
- Why unresolved: Current validation relies on theoretical predictions from quantum cognition models rather than direct comparison with human perception datasets, which are difficult to obtain and standardize.
- What evidence would resolve it: Empirical data from controlled experiments measuring human responses to Necker cube and Rubin's vase illusions, including reaction times and confidence levels, compared directly with QT-DNN predictions.

### Open Question 2
- Question: How do specific quantum tunnelling barrier parameters (thickness, height) affect the accuracy and perceptual switching patterns in QT-DNN models of optical illusions?
- Basis in paper: [explicit] The authors mention that barrier parameters are used in the model but their systematic investigation and impact on performance is not explored.
- Why unresolved: The paper uses specific parameter values but does not analyze how varying these parameters affects the model's ability to simulate human-like perception or its similarity to other activation functions.
- What evidence would resolve it: Systematic variation of barrier parameters followed by comparison of resulting perceptual switching patterns and DTW similarity scores against human data and other activation functions.

### Open Question 3
- Question: What is the fundamental relationship between quantum cognition theory predictions and actual neural mechanisms in biological brains when perceiving optical illusions?
- Basis in paper: [explicit] The authors discuss the potential link between quantum cognition and neuroscience but acknowledge that "a solid link between the theory of quantum cognition and neuroscience is yet to be established."
- Why unresolved: While the paper shows QT-DNN produces results consistent with quantum cognition predictions, it does not establish whether these align with actual neural activity patterns observed in brain imaging studies of illusion perception.
- What evidence would resolve it: Neuroimaging studies (fMRI, EEG) of subjects viewing optical illusions compared with QT-DNN output patterns, and analysis of whether quantum cognition predictions match observed neural dynamics.

## Limitations
- Absence of direct human perception data for comparison, relying instead on comparisons between different AI architectures
- Requirement for quantum random number generator limits practical implementation due to specialized hardware needs
- Model only tested on two specific optical illusions, limiting generalizability assessment

## Confidence
- High confidence: Technical implementation of QT-DNN using quantum tunnelling transmission coefficients as activation functions is well-specified and mathematically sound
- Medium confidence: QT-DNN produces more human-like perception patterns than ReLU networks, though similarity to Sigmoid-DNN suggests this may not be unique to quantum tunnelling approach
- Low confidence: Quantum random number generation is essential for capturing human perception variability, as this wasn't directly tested against high-quality pseudo-random alternatives

## Next Checks
1. **Direct human comparison study**: Collect human perceptual switching data for the same ambiguous figures used in the model and perform statistical comparison with QT-DNN output patterns using DTW analysis
2. **Generalization testing**: Apply QT-DNN to additional optical illusions and ambiguous stimuli beyond Necker cube and Rubin's vase to assess the model's broader applicability
3. **Randomness source ablation**: Systematically compare QT-DNN performance using quantum random number generators versus high-quality pseudo-random generators to quantify the actual impact of quantum randomness on perceptual state distributions