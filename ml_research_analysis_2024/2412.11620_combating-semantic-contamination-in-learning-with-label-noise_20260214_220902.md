---
ver: rpa2
title: Combating Semantic Contamination in Learning with Label Noise
arxiv_id: '2412.11620'
source_url: https://arxiv.org/abs/2412.11620
tags:
- semantic
- learning
- label
- labels
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of Semantic Contamination (SC) in
  learning with noisy labels, where models incorrectly learn semantic relationships
  between classes due to label noise. The authors propose Collaborative Cross Learning
  (CCL), a method that combines Semantic-wise Decoupling with Confident Learning (SDCL)
  and Embedding-based Interactive Alignment (EIA) to learn more robust and consistent
  representations.
---

# Combating Semantic Contamination in Learning with Label Noise

## Quick Facts
- arXiv ID: 2412.11620
- Source URL: https://arxiv.org/abs/2412.11620
- Authors: Wenxiao Fan; Kan Li
- Reference count: 35
- Key outcome: CCL achieves 94.6% accuracy on CIFAR-10 with 80% symmetric noise, outperforming state-of-the-art methods by up to 2.4%

## Executive Summary
This paper tackles the problem of Semantic Contamination (SC) in learning with noisy labels, where models incorrectly learn semantic relationships between classes due to label noise. The authors propose Collaborative Cross Learning (CCL), a method that combines Semantic-wise Decoupling with Confident Learning (SDCL) and Embedding-based Interactive Alignment (EIA) to learn more robust and consistent representations. SDCL decouples semantic concepts from predictions and uses confident learning to avoid noisy labels, while EIA aligns models using refurbished labels and contrastive learning to ensure semantic consistency. Experiments on CIFAR and real-world datasets show CCL outperforms state-of-the-art methods, achieving up to 94.6% accuracy on CIFAR-10 with 80% symmetric noise, a 2.4% improvement over RoLR. On WebVision, CCL achieves 82.3% top-1 accuracy, surpassing other methods.

## Method Summary
CCL is a novel approach that addresses semantic contamination through two complementary components. SDCL decouples semantic concepts from predictions using contrastive learning on embeddings while filtering noisy samples through confidence estimation. EIA maintains cross-model consistency by aligning embeddings using refurbished labels and contrastive distributions. The method combines within-view semantic learning (SDCL) with cross-model consistency (EIA) to create a comprehensive framework for robust representation learning in noisy label scenarios.

## Key Results
- CCL achieves 94.6% accuracy on CIFAR-10 with 80% symmetric noise, outperforming RoLR by 2.4%
- On CIFAR-100 with 40% symmetric noise, CCL reaches 65.2% accuracy, surpassing DivideMix by 1.5%
- CCL achieves 82.3% top-1 accuracy on WebVision, outperforming other state-of-the-art methods
- LCA metric demonstrates CCL's effectiveness in reducing semantic contamination across all tested noise levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SDCL prevents semantic imbalance by decoupling predicted classes from semantic concepts and using contrastive learning on embeddings
- Mechanism: Uses augmentation-wise contrastive learning and view-wise mimicry to align embeddings across views without relying on noisy logits, while confident learning filters samples based on prediction confidence
- Core assumption: Semantic concepts can be effectively learned from embeddings when predictions are filtered by confidence thresholds
- Evidence anchors: [abstract] "SDCL decouples semantic concepts from predictions and uses confident learning to avoid noisy labels"; [section] "Semantic-wise Decoupling decouples the class label and the semantic concept and utilize self-supervised learning to prevent the incorporation of harmful semantic information"
- Break condition: If confidence threshold is too low, noisy labels still influence semantic learning; if too high, insufficient samples for learning

### Mechanism 2
- Claim: EIA maintains semantic consistency across models through collaborative contrastive learning on refurbished labels
- Mechanism: CCLRL aligns embeddings across models using refurbished labels as anchors, while model-wise mimicry aligns contrastive distributions between models
- Core assumption: Mutual information between model embeddings can be maximized through collaborative contrastive learning on refurbished labels
- Evidence anchors: [abstract] "EIA aligns models using refurbished labels and contrastive learning to ensure semantic consistency"; [section] "CCLRL considers same-class samples with strong transformations from one model and weak transformations from another model as positive sample pairs"
- Break condition: If refurbished labels are inaccurate, contrastive learning may align incorrect semantic relationships

### Mechanism 3
- Claim: The combination of SDCL and EIA creates a robust learning framework addressing both semantic contamination and label noise
- Mechanism: SDCL handles semantic learning within views while EIA ensures cross-model consistency, creating a comprehensive approach to robust representation learning
- Core assumption: Learning semantic information from both within-view and cross-model perspectives provides complementary benefits for robustness
- Evidence anchors: [abstract] "Collaborative Cross Learning, which consists of two components: Semantic-wise Decoupling with Confident Learning (SDCL) and Embedding-based Interactive Alignment (EIA)"; [section] "We propose a novel method called Collaborative Cross Learning, that learns semantic relationships from embedding perspectives"
- Break condition: If either component fails, the overall robustness may be compromised

## Foundational Learning

- Concept: Semi-supervised learning with consistency regularization
  - Why needed here: The method builds upon SSL techniques like MixMatch and FixMatch to handle noisy labels through consistency between different views and models
  - Quick check question: How does consistency regularization differ from standard supervised learning in handling noisy labels?

- Concept: Contrastive learning and mutual information maximization
  - Why needed here: CCLRL explicitly maximizes mutual information between model embeddings to ensure semantic consistency, building on recent contrastive learning advances
  - Quick check question: What is the relationship between contrastive learning objectives and mutual information maximization?

- Concept: Label refurbishment and confidence estimation
  - Why needed here: The method uses refurbished labels as anchors for contrastive learning while confidence estimation helps filter noisy samples, following recent noisy label learning approaches
  - Quick check question: How does confidence estimation help distinguish between clean and noisy samples in label refurbishment?

## Architecture Onboarding

- Component map: Warm-up phase -> Confidence estimation with GMM -> SDCL (augmentation-wise contrastive learning + view-wise mimicry + confident learning) -> EIA (CCLRL + model-wise mimicry) -> Final model output
- Critical path: Warm-up → Confidence estimation → SDCL training → EIA training → Final model output
- Design tradeoffs: Balancing semantic learning (SDCL) with cross-model consistency (EIA) vs. computational overhead; strong augmentation for robustness vs. training difficulty
- Failure signatures: Semantic imbalance indicated by entropy variance among classes; semantic inconsistency indicated by poor performance on LCA metric; overfitting to noisy labels indicated by poor generalization
- First 3 experiments:
  1. Run ablation study on CIFAR-10 with 80% symmetric noise to verify individual component contributions
  2. Test sensitivity to confidence threshold parameter to find optimal filtering level
  3. Compare LCA metric results against baseline methods to quantify semantic contamination reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the temperature parameter τ in the Augmentation-wise Contrastive Learning affect the balance between semantic consistency and noise robustness?
- Basis in paper: [explicit] The paper states that "τ should be reasonable, as setting it too high or too low can both degrade the model's performance" and includes a sensitivity analysis showing performance varies with τ.
- Why unresolved: The paper only provides a general observation about the impact of τ on performance, without explaining the specific mechanism by which temperature affects the trade-off between semantic consistency and noise robustness.
- What evidence would resolve it: Systematic experiments varying τ across different noise levels and datasets, combined with ablation studies isolating semantic consistency metrics from noise robustness metrics.

### Open Question 2
- Question: Can the theoretical lower bound on mutual information I(fθm(x), fθ(1−m) (x)) be tightened or extended to provide tighter performance guarantees?
- Basis in paper: [explicit] The paper provides a theoretical analysis showing that minimizing Eq. (9) maximizes the lower bound on mutual information, but acknowledges this is an upper bound.
- Why unresolved: The theoretical analysis provides only a lower bound, and the relationship between this bound and actual model performance is not fully characterized.
- What evidence would resolve it: Experiments showing the correlation between the mutual information lower bound and actual model performance across different noise levels and architectures.

### Open Question 3
- Question: How does Semantic Contamination manifest differently in instance-dependent noise versus symmetric noise, and what modifications to CCL would be most effective for each case?
- Basis in paper: [inferred] The paper mentions that instance-dependent noise "allows the label noise to depend mandatorily on the samples," suggesting different contamination patterns, but doesn't analyze this distinction.
- Why unresolved: The paper primarily focuses on symmetric and pair noise, with only brief mention of instance-dependent noise without exploring its unique challenges for semantic contamination.
- What evidence would resolve it: Comparative analysis of semantic contamination patterns in different noise types using visualization techniques and targeted modifications to CCL for each noise type.

## Limitations
- The method's effectiveness is primarily validated on standard benchmark datasets and may not generalize to all real-world scenarios
- Computational overhead is significant due to maintaining multiple models for EIA, potentially limiting scalability
- The theoretical understanding of why the specific combination of SDCL and EIA is particularly effective against semantic contamination is limited

## Confidence
- **High Confidence**: Individual components (SDCL and EIA) are built on established techniques in noisy label learning and self-supervised learning. The improvement over baselines on standard benchmarks is well-documented.
- **Medium Confidence**: The specific mechanism of how semantic contamination occurs and how the proposed method addresses it is not fully validated. The LCA metric is novel and its correlation with actual semantic contamination needs further study.
- **Low Confidence**: The theoretical understanding of why the combination of SDCL and EIA is particularly effective against semantic contamination is limited. The method's generalizability to other types of noise (beyond symmetric and asymmetric) is unclear.

## Next Checks
1. **Theoretical Analysis**: Develop a theoretical framework to understand how semantic contamination occurs and how the proposed method prevents it. This could involve analyzing the mutual information between clean and noisy labels and how it relates to semantic consistency.

2. **Generalization Study**: Test the method on a wider range of datasets and noise types (e.g., instance-dependent noise, open-set noise) to assess its generalizability. Compare its performance against other state-of-the-art methods in these scenarios.

3. **Computational Efficiency**: Conduct a detailed analysis of the computational overhead introduced by maintaining multiple models for EIA. Explore potential optimizations or approximations that could reduce this overhead while maintaining performance.