---
ver: rpa2
title: Bridging the Gap between Different Vocabularies for LLM Ensemble
arxiv_id: '2404.09492'
source_url: https://arxiv.org/abs/2404.09492
tags:
- ensemble
- llms
- tokens
- token
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EVA, a method for fine-grained ensemble of
  different LLMs at each generation step. The key idea is to bridge the vocabulary
  gap between LLMs using overlapping tokens, allowing the output distributions to
  be projected into a unified space.
---

# Bridging the Gap between Different Vocabularies for LLM Ensemble

## Quick Facts
- arXiv ID: 2404.09492
- Source URL: https://arxiv.org/abs/2404.09492
- Authors: Yangyifan Xu; Jinliang Lu; Jiajun Zhang
- Reference count: 14
- Key outcome: Proposes EVA method achieving up to 10.61 absolute improvement on GSM8K dataset through fine-grained LLM ensemble with vocabulary alignment

## Executive Summary
This paper addresses the fundamental challenge of ensemble learning across large language models (LLMs) with different vocabularies. Traditional ensemble methods can only combine outputs after full generation, missing opportunities for dynamic correction during the generation process. The proposed EVA method bridges this gap by aligning token embeddings across different LLM vocabularies using overlapping tokens as bridges, then projecting output distributions into a unified space. A filtering strategy further excludes models generating inconsistent tokens, preventing error propagation and improving overall ensemble quality.

## Method Summary
EVA achieves fine-grained ensemble of different LLMs by first identifying overlapping tokens between models, then learning mapping matrices to project token embeddings into a shared semantic space. At each generation step, EVA converts non-pivot model output distributions to the pivot model's space using these mappings, applies a filtering strategy to exclude models with inconsistent top-1 predictions, and combines the remaining distributions. The method uses CSLS (Cross-Lingual Similarity Softmax) for similarity computation and employs noise reduction techniques (top-t truncation, threshold truncation, variance truncation) to obtain efficient mapping matrices. Experiments show EVA consistently outperforms individual models and previous ensemble methods across commonsense reasoning, arithmetic reasoning, machine translation, and data-to-text generation tasks.

## Key Results
- Achieves up to 10.61 absolute improvement on GSM8K arithmetic reasoning dataset
- Outperforms individual LLMs and previous ensemble methods across 4 different NLP task categories
- Demonstrates strong cross-task versatility with consistent improvements in both reasoning and generation tasks
- Shows effective handling of vocabulary discrepancies between different LLM architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Vocabulary alignment via overlapping tokens enables token-level ensemble across LLMs with different vocabularies
- Mechanism: EVA identifies overlapping tokens between LLMs, maps their embeddings into a shared semantic space using these tokens as supervised labels, then uses similarity matrices to project output distributions into a unified space
- Core assumption: Overlapping tokens between LLMs are semantically aligned and can serve as bridges for cross-vocabulary projection
- Evidence anchors: [abstract] "By leveraging these tokens as bridges, EVA can achieve vocabulary alignment"; [section 2.2] "a substantial number of overlapping tokens naturally emerge" with Figure 3 showing 53-100% overlap rates
- Break condition: If overlapping tokens are not semantically aligned (e.g., homonyms or polysemes), the projection would be incorrect

### Mechanism 2
- Claim: Filtering strategy improves ensemble quality by excluding models generating inconsistent tokens
- Mechanism: At each generation step, EVA compares top-1 tokens from all models and excludes any model whose top-1 token is not in the top-n tokens of any other model, preventing outlier models from influencing the ensemble
- Core assumption: Models generating tokens inconsistent with others are likely to be generating errors, and excluding them improves ensemble accuracy
- Evidence anchors: [abstract] "we design a filtering strategy to exclude models that generate unfaithful tokens"; [section 3.2] "if the top-1 token predicted by a model falls outside the top-n tokens predicted by any other model, it is excluded from the ensemble"; [section 6.1] Table 4 shows significant improvements on arithmetic reasoning tasks when filtering is applied
- Break condition: If multiple models are consistently wrong but internally consistent, filtering would not help and might exclude the correct model

### Mechanism 3
- Claim: Fine-grained ensemble at each generation step prevents error propagation compared to post-hoc ensemble
- Mechanism: By ensembleing at each token generation step rather than after full generation, EVA prevents early errors from snowballing into subsequent errors in the generation chain
- Core assumption: Early errors in LLM generation tend to propagate and compound, so preventing them improves overall quality
- Evidence anchors: [abstract] "This limitation hinders the dynamic correction and enhancement of outputs during the generation process"; [section 1] "early errors in LLMs tend to snowball, leading to subsequent errors that might not have otherwise occurred"; [section 6.1] Analysis shows GSM8K tasks benefit most from filtering, consistent with arithmetic reasoning being sensitive to early errors
- Break condition: If tasks don't exhibit error propagation or if the ensemble itself introduces errors, fine-grained ensemble may not help

## Foundational Learning

- Concept: Subword tokenization and vocabulary construction
  - Why needed here: EVA operates on token-level distributions, so understanding how LLMs tokenize text and construct vocabularies is essential for understanding the vocabulary alignment mechanism
  - Quick check question: Why do different LLMs have different vocabularies even when trained on similar web data?

- Concept: Embedding spaces and vector similarity
  - Why needed here: The vocabulary alignment relies on mapping token embeddings to a shared space using similarity metrics (CSLS)
  - Quick check question: What properties must token embeddings have for the projection matrix to work effectively?

- Concept: Probability distributions and ensemble methods
  - Why needed here: EVA combines output distributions from multiple models, requiring understanding of how to properly combine probabilities
  - Quick check question: How does EVA's filtering strategy differ from simple averaging of model probabilities?

## Architecture Onboarding

- Component map: Input prompt -> Token generation loop (for each model: generate distribution -> project to unified space -> apply filtering -> ensemble -> select token) -> Output generation

- Critical path: Input prompt → token generation loop (for each model: generate distribution → project to unified space → apply filtering → ensemble → select token) → output generation

- Design tradeoffs: 
  - Choice of pivot model: largest vocabulary vs. best performance - paper chooses largest to avoid OOV issues
  - Filtering threshold (n): looser filtering preserves diversity but may include errors, tighter filtering is more conservative
  - Mapping granularity: full similarity matrix vs. truncated versions for efficiency

- Failure signatures:
  - Poor alignment: If the vocabulary projection fails, the ensemble will combine incompatible distributions
  - Over-filtering: If n is too small, the ensemble may exclude correct models or have insufficient diversity
  - Under-filtering: If n is too large, outlier predictions may dominate the ensemble

- First 3 experiments:
  1. Baseline test: Run EVA with n=1 (no filtering) on a simple task to verify vocabulary alignment works
  2. Filter sensitivity: Test EVA with different n values on GSM8K to observe the impact of filtering strictness
  3. Pivot model comparison: Compare EVA using different pivot models (largest vs. best-performing) on machine translation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of pivot model affect the overall performance of the EVA ensemble method?
- Basis in paper: [explicit] The paper discusses the selection of the pivot model based on vocabulary size, but does not provide empirical evidence on how different pivot model choices impact performance
- Why unresolved: The paper states that the model with the largest vocabulary is chosen as the pivot, but does not test or compare this choice against other potential pivot models
- What evidence would resolve it: Conducting experiments with different pivot models (e.g., based on performance, vocabulary size, or other criteria) and comparing the resulting ensemble performance would provide insights into the impact of pivot model choice

### Open Question 2
- Question: What is the impact of vocabulary overlap on the effectiveness of the EVA method, and how does it vary across different language pairs or domains?
- Basis in paper: [explicit] The paper mentions the importance of overlapping tokens as bridges for vocabulary alignment but does not provide a detailed analysis of how vocabulary overlap affects performance or how it varies across different contexts
- Why unresolved: While the paper acknowledges the role of overlapping tokens, it does not explore the relationship between vocabulary overlap and ensemble effectiveness or investigate how this relationship might change with different languages or domains
- What evidence would resolve it: Analyzing the performance of EVA with varying degrees of vocabulary overlap across different language pairs or domains, and correlating these findings with the amount of overlap, would clarify the impact of vocabulary overlap on the method's effectiveness

### Open Question 3
- Question: How does the EVA method perform in low-resource settings, where the vocabulary overlap between models is minimal?
- Basis in paper: [inferred] The paper focuses on scenarios with substantial vocabulary overlap but does not address the challenges or performance of EVA in low-resource settings
- Why unresolved: The effectiveness of EVA relies on overlapping tokens for vocabulary alignment, but the paper does not explore how the method performs when this overlap is limited or absent
- What evidence would resolve it: Testing EVA in low-resource settings with minimal vocabulary overlap and comparing its performance to traditional ensemble methods would provide insights into its robustness and limitations in such scenarios

### Open Question 4
- Question: How does the filtering strategy in EVA adapt to different types of tasks, and what are the optimal settings for various NLP applications?
- Basis in paper: [explicit] The paper introduces a filtering strategy to exclude unfaithful tokens but does not provide a comprehensive analysis of how this strategy should be tuned for different tasks
- Why unresolved: While the paper mentions the filtering strategy and its role in improving performance, it does not offer guidance on how to adapt this strategy for different NLP tasks or determine optimal settings
- What evidence would resolve it: Conducting experiments with various filtering strategies across a range of NLP tasks and analyzing the resulting performance would help identify optimal settings and adaptability for different applications

## Limitations
- Vocabulary alignment reliability: The paper assumes semantic alignment of overlapping tokens without rigorous validation, which could fail for homonyms or polysemes
- Filtering strategy effectiveness: The arbitrary choice of filtering thresholds (n=3 for reasoning, n=40 for NLG) suggests the approach may not be universally applicable
- Computational overhead: The paper mentions EVA's computational cost but lacks detailed analysis of runtime impact and scalability for real-time applications

## Confidence
- High confidence: The core mechanism of vocabulary alignment through overlapping tokens is technically sound and the experimental results showing consistent improvements across multiple tasks are robust
- Medium confidence: The filtering strategy's effectiveness is demonstrated but the underlying assumptions about token consistency across models need more rigorous validation
- Low confidence: Claims about EVA's practical deployment readiness are not well-supported, with computational requirements and scalability not thoroughly analyzed

## Next Checks
1. **Semantic alignment validation**: Conduct a human evaluation study where annotators verify whether overlapping tokens between different LLMs maintain consistent semantic meanings. Sample 100 overlapping tokens from the alignment matrices and have at least 3 annotators rate semantic consistency on a 5-point scale.

2. **Filter sensitivity analysis**: Perform comprehensive ablation studies varying the filtering threshold n across the full range (1 to vocabulary size) on at least two tasks. Measure not just accuracy but also diversity metrics (unique tokens generated, entropy of distributions) to understand the tradeoff between filtering strictness and ensemble quality.

3. **Computational profiling**: Measure EVA's runtime overhead on representative tasks by profiling: (a) vocabulary alignment preprocessing time, (b) per-token ensemble computation time, and (c) total generation time compared to individual models. Include memory usage analysis to assess scalability constraints.