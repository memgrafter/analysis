---
ver: rpa2
title: UnLearning from Experience to Avoid Spurious Correlations
arxiv_id: '2409.02792'
source_url: https://arxiv.org/abs/2409.02792
tags:
- spurious
- correlations
- student
- teacher
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces UnLearning from Experience (ULE), a method\
  \ to improve deep neural network robustness to spurious correlations without requiring\
  \ group labels during training or validation. The core idea is to train two models\
  \ in parallel\u2014a student model that learns spurious correlations and a teacher\
  \ model that unlearns them by using the gradient of the student's output with respect\
  \ to its input."
---

# UnLearning from Experience to Avoid Spurious Correlations

## Quick Facts
- arXiv ID: 2409.02792
- Source URL: https://arxiv.org/abs/2409.02792
- Reference count: 40
- Primary result: State-of-the-art performance on Waterbirds and CelebA datasets for spurious correlation robustness

## Executive Summary
This paper introduces UnLearning from Experience (ULE), a novel method for improving deep neural network robustness to spurious correlations without requiring group labels during training or validation. The approach trains two models in parallel - a student model that learns spurious correlations normally and a teacher model that unlearns them by using the gradient of the student's output with respect to its input. This encourages the teacher to focus on primary task features rather than spurious correlations. The method demonstrates state-of-the-art results on Waterbirds and CelebA datasets, and competitive performance on Spawrious, showing it can effectively improve model robustness without group label information.

## Method Summary
ULE trains two models in parallel: a student model that learns spurious correlations normally, and a teacher model that uses the student's gradient with respect to its input to avoid those same correlations. Both models receive identical batches during training. The teacher's loss combines standard classification loss with a gradient-based loss that encourages opposite saliency maps from the student. The method uses pre-trained models with frozen early layers, fine-tuning only the final layer. Hyperparameters including the unlearning weight λ are tuned separately for each dataset through grid search.

## Key Results
- Achieves state-of-the-art results on Waterbirds and CelebA datasets for worst-group accuracy
- Competitive performance on Spawrious dataset with complex spurious correlations
- Demonstrates effectiveness without requiring group labels during training or validation
- Works with various pre-trained architectures including ResNet and Vision Transformer

## Why This Works (Mechanism)

### Mechanism 1
The teacher model learns to unlearn spurious correlations by observing gradients of the student's output with respect to the input. The student model is trained normally and learns spurious correlations. The teacher model uses a custom loss function that includes a term encouraging its gradients to be the opposite of the student's gradients. This forces the teacher to focus on primary task features rather than spurious correlations.

### Mechanism 2
By training two models in parallel and having the teacher avoid the student's gradients, the teacher develops robustness to spurious correlations. Both models receive identical batches during training. The teacher's loss function combines standard classification loss with a term that minimizes the difference between its gradients and the inverted student gradients. This parallel training allows the teacher to continuously adapt based on the student's evolving spurious correlations.

### Mechanism 3
Using pre-trained models and fine-tuning only the final layer enhances the method's effectiveness for complex spurious correlations. The authors use pre-trained ResNet or ViT models, freezing early layers and only fine-tuning the final linear layer. This allows the teacher to leverage representations that may have separated intertwined features, making it easier to distinguish primary features from spurious ones.

## Foundational Learning

- **Spurious correlations and group shifts in machine learning**
  - Why needed here: The entire paper addresses the problem of models learning spurious correlations rather than true predictive features
  - Quick check question: What is the difference between a spurious correlation and a true predictive feature in the context of machine learning?

- **Student-teacher learning paradigm**
  - Why needed here: The method uses a reversed student-teacher approach where the teacher learns from the student's mistakes
  - Quick check question: How does the traditional student-teacher learning paradigm differ from the approach used in this paper?

- **Explainable AI and saliency maps**
  - Why needed here: The method uses gradients as saliency maps to identify which input features influence the model's decisions
  - Quick check question: How can saliency maps be used to identify which parts of an input image are most influential in a model's classification decision?

## Architecture Onboarding

- **Component map**: Student model -> Teacher model -> Parallel training loop -> Custom loss function -> Gradient extraction
- **Critical path**:
  1. Initialize both models with identical architectures and pre-trained weights
  2. Train student model using standard classification loss
  3. Extract student's gradients with respect to input
  4. Train teacher model using combined loss (classification + gradient-based unlearning)
  5. Update both models' parameters in parallel
  6. Evaluate teacher model's robustness to spurious correlations
- **Design tradeoffs**:
  - Model complexity: More complex models may better separate features but require more computation
  - Training stability: Parallel training of two models may introduce convergence challenges
  - Hyperparameter sensitivity: The λ parameter balancing classification and unlearning terms is critical
  - Pre-trained vs from-scratch: Using pre-trained models enhances performance but limits applicability
- **Failure signatures**:
  - Student and teacher models converge to similar solutions (teacher fails to unlearn)
  - Teacher model's performance degrades significantly compared to standard training
  - Inconsistent results across multiple training runs
  - Sensitivity to small changes in hyperparameters
- **First 3 experiments**:
  1. MNIST-SC: Train on MNIST with artificial spurious correlation (class label in corner), test on clean MNIST
  2. Waterbirds: Train and evaluate on dataset with background-bird spurious correlation
  3. CelebA: Train and evaluate on dataset with gender-hair color spurious correlation

## Open Questions the Paper Calls Out

- How does the complexity of the teacher model affect its ability to learn from the student's mistakes compared to the student's ability to learn spurious correlations?
- How does ULE perform on datasets with more complex, multi-modal spurious correlations?
- How does the choice of saliency map computation (e.g., input-level vs. hidden layer) affect ULE's performance?

## Limitations

- Assumes spurious correlations are consistently easier to learn than primary task features, which may not hold across all datasets
- Requires parallel training of two models, doubling computational costs compared to standard approaches
- Effectiveness depends on pre-trained models having representations that can separate primary and spurious features

## Confidence

- **High confidence**: Effectiveness on Waterbirds and CelebA datasets; parallel training framework and gradient-based unlearning mechanism
- **Medium confidence**: Applicability to complex spurious correlations (Spawrious, UrbanCars); claims about general method effectiveness
- **Low confidence**: Assumption that spurious correlations are universally easier to learn than primary features

## Next Checks

1. **Architecture Sensitivity**: Test whether the method's effectiveness varies when using identical vs. different architectures for student and teacher models, particularly in cases where the student model may not reliably learn spurious correlations first.

2. **Pre-trained Representation Quality**: Evaluate how the method performs when using from-scratch training vs. pre-trained models to isolate whether the benefits come from the ULE method itself or from leveraging pre-trained representations.

3. **Gradient Calculation Sensitivity**: Conduct controlled experiments varying the gradient calculation method (input vs. intermediate activations) and layer selection to determine which configuration provides optimal unlearning performance.