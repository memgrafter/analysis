---
ver: rpa2
title: 'Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment
  Tax Reduction'
arxiv_id: '2405.13432'
source_url: https://arxiv.org/abs/2405.13432
tags:
- data
- language
- instruction-following
- knowledge
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the alignment tax phenomenon observed during
  instruction tuning of large language models (LLMs), where performance on knowledge
  and reasoning benchmarks degrades despite improved instruction-following ability.
  Through a pilot study, the authors hypothesize that dataset-specific biases are
  a major cause of alignment tax, as models increasingly fit on these biases during
  training.
---

# Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction

## Quick Facts
- arXiv ID: 2405.13432
- Source URL: https://arxiv.org/abs/2405.13432
- Authors: Tingchen Fu, Deng Cai, Lemao Liu, Shuming Shi, Rui Yan
- Reference count: 37
- Primary result: DTM framework reduces alignment tax by clustering instruction data, training sub-models, and merging to eliminate dataset biases

## Executive Summary
This paper addresses the alignment tax phenomenon in instruction tuning of large language models (LLMs), where performance on knowledge and reasoning benchmarks degrades despite improved instruction-following ability. The authors hypothesize that dataset-specific biases acquired during training are a major cause of this degradation. They propose a simple Disperse-Then-Merge (DTM) framework that clusters instruction data into subsets, trains separate sub-models on each subset, and then merges the sub-models to reduce bias while preserving instruction-following capacity. Extensive experiments across nine benchmarks show that DTM outperforms sophisticated baselines like data curation and regularization methods, achieving the highest or second-highest scores on most evaluated tasks.

## Method Summary
The DTM framework first clusters instruction-following data into K subsets using methods like K-means or random splitting. Then K sub-models are trained independently on each data cluster using LoRA fine-tuning. Finally, the sub-models are merged using weighted averaging or other merging techniques to produce a single model. The key insight is that each sub-model acquires different dataset biases during training, and the merging process eliminates these unique biases while preserving shared knowledge and instruction-following ability. The approach is evaluated on multiple base LLMs including Llama-2-7b and Llama-2-13b across 9 benchmarks measuring knowledge, reasoning, and instruction-following capabilities.

## Key Results
- DTM consistently outperforms vanilla SFT on 9 benchmarks including MMLU, BBH, ARC-c, OBQA, RACE, HumanEval, MBPP, and TruthfulQA
- The best performance is achieved with K=4 sub-models, showing no significant advantage from sophisticated clustering over random splitting
- DTM improves both knowledge retention and instruction-following ability, unlike baselines that often trade off one for the other
- The framework works across different data domains, base LLMs, and merging strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The alignment tax occurs because large language models (LLMs) acquire dataset-specific biases during instruction tuning that interfere with their general knowledge and reasoning abilities.
- Mechanism: As LLMs train on instruction-following data, they initially learn generalizable instruction-following skills. However, as training progresses, the model increasingly fits on data-specific biases rather than generalizable patterns. These biases are ungeneralizable shortcuts that don't transfer to knowledge and reasoning benchmarks, causing performance degradation.
- Core assumption: The loss reduction ratio between training and validation sets increases during SFT, indicating that ungeneralizable data biases become the dominant factor in loss reduction.
- Evidence anchors:
  - [abstract] "we put a hypothesis that the data biases are probably one cause behind the phenomenon"
  - [section] "During the tuning process, LLMs fit on dataset biases while acquiring instruction-following ability"
  - [corpus] Weak - corpus analysis didn't directly measure bias acquisition patterns
- Break condition: If the loss reduction ratio doesn't increase during training, or if bias analysis shows no correlation between training-specific tokens and performance degradation.

### Mechanism 2
- Claim: Disperse-Then-Merge (DTM) framework reduces alignment tax by distributing data biases across multiple sub-models and then eliminating them through model merging.
- Mechanism: DTM first clusters instruction data into subsets, trains separate sub-models on each subset (each acquiring different biases), then merges these sub-models. The merging process leverages the observation that when multiple models are merged, their unique data biases are forgotten while shared knowledge is enhanced.
- Core assumption: Model merging can selectively forget unique data biases while preserving shared knowledge and instruction-following capacity.
- Evidence anchors:
  - [abstract] "we merge multiple models into a single one via model merging techniques"
  - [section] "Zaman et al. (2023) discovered that when two BERT-based classification models are merged together, the unshared knowledge within each model is mostly forgotten while the common knowledge is enhanced"
  - [corpus] Moderate - corpus shows DTM outperforms baselines but doesn't directly prove bias forgetting mechanism
- Break condition: If merged models show degraded performance or if bias analysis shows retained dataset-specific patterns post-merging.

### Mechanism 3
- Claim: The effectiveness of DTM depends on having sufficient diversity in data clusters to ensure sub-models acquire different biases that can be eliminated through merging.
- Mechanism: By clustering instruction data into K subsets, DTM ensures each sub-model encounters different data patterns and acquires distinct biases. When merged, these diverse biases cancel out or are forgotten, while the instruction-following capacity is retained.
- Core assumption: Different data clusters will produce sub-models with sufficiently diverse biases that can be effectively eliminated through merging.
- Evidence anchors:
  - [abstract] "we disperse the instruction-following data into portions and train multiple sub-models using different data portions"
  - [section] "we initially distribute the instruction-following data into several clusters"
  - [corpus] Moderate - experiments show DTM works across different clustering strategies, but diversity analysis wasn't directly measured
- Break condition: If all clusters produce similar sub-models with overlapping biases, or if merging doesn't improve performance compared to single-model training.

## Foundational Learning

- Concept: Model merging and weight space operations
  - Why needed here: DTM relies on merging sub-models in weight space to eliminate biases while preserving instruction-following capacity
  - Quick check question: What happens to unique parameters versus shared parameters when multiple models are merged through weighted averaging?

- Concept: Catastrophic forgetting and regularization in continual learning
  - Why needed here: DTM's effectiveness depends on understanding how models forget information during training and how merging can mitigate forgetting
  - Quick check question: How does Elastic Weight Consolidation (EWC) prevent forgetting, and why might this be less effective than DTM for alignment tax?

- Concept: Clustering and data distribution strategies
  - Why needed here: DTM requires effective clustering of instruction data to ensure sub-models acquire diverse biases
  - Quick check question: What clustering strategy would maximize diversity in sub-model biases while maintaining instruction-following quality?

## Architecture Onboarding

- Component map:
  - Data clustering module (K-means or alternative)
  - Sub-model training pipeline (separate fine-tuning for each cluster)
  - Model merging component (weighted averaging or alternative merging strategies)
  - Evaluation framework (benchmarks for knowledge, reasoning, and instruction-following)

- Critical path:
  1. Cluster instruction data into K subsets
  2. Train K sub-models independently on each cluster
  3. Merge sub-models using chosen merging strategy
  4. Evaluate merged model on all benchmarks

- Design tradeoffs:
  - Number of clusters (K) vs. computational cost and bias diversity
  - Simple averaging vs. sophisticated merging techniques (Fisher information, task vectors)
  - Random clustering vs. semantic clustering strategies

- Failure signatures:
  - Performance doesn't improve over vanilla SFT
  - Merged model shows degraded instruction-following ability
  - Different clustering strategies produce similar results (suggesting insufficient bias diversity)

- First 3 experiments:
  1. Implement DTM with K=2 clusters and simple averaging, compare to vanilla SFT on MMLU
  2. Test different clustering strategies (random vs. semantic) with K=4
  3. Experiment with different merging techniques (Fisher, task vector, tie merge) using K=4 clusters

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different data clustering methods affect the performance of the Disperse-Then-Merge (DTM) framework?
- Basis in paper: [explicit] The paper discusses experimenting with different sentence embedding models (MiniLM, MPNet) and encoding schemes (instruction, response, or both) for K-means clustering, finding no significant advantage of sophisticated methods over simple random clustering.
- Why unresolved: While the paper shows that sophisticated clustering methods do not significantly outperform random clustering, it does not explore other clustering techniques (e.g., hierarchical clustering, DBSCAN) or their potential impact on the DTM framework's effectiveness.
- What evidence would resolve it: Experimenting with various clustering methods and comparing their performance in terms of knowledge retention and instruction-following ability would provide insights into the optimal clustering strategy for the DTM framework.

### Open Question 2
- Question: Does the DTM framework generalize to other alignment methods beyond supervised fine-tuning (SFT)?
- Basis in paper: [inferred] The paper focuses on alignment tax during SFT and proposes the DTM framework as a solution. However, it mentions other alignment methods like Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO), and their variants, without exploring their potential alignment tax or the applicability of DTM.
- Why unresolved: The paper does not investigate whether the DTM framework can be adapted to address alignment tax in other alignment methods, leaving the question of its generalizability open.
- What evidence would resolve it: Applying the DTM framework to other alignment methods and evaluating its effectiveness in reducing alignment tax would determine its broader applicability.

### Open Question 3
- Question: How does the choice of model merging techniques impact the performance of the DTM framework?
- Basis in paper: [explicit] The paper experiments with several merging techniques (Fisher, Task Vector, Tie Merge, DARE) and finds that no single method is superior, with simple average weight merging being sufficient.
- Why unresolved: While the paper compares different merging techniques, it does not explore the underlying reasons for their performance differences or investigate other potential merging strategies that might be more effective for the DTM framework.
- What evidence would resolve it: Analyzing the strengths and weaknesses of different merging techniques in the context of the DTM framework and exploring novel merging strategies could lead to improved performance and a deeper understanding of the framework's mechanisms.

## Limitations

- The core hypothesis that dataset-specific biases are the primary cause of alignment tax remains unproven - the framework shows empirical success but lacks direct causal evidence
- The clustering strategy's impact on bias diversity is not thoroughly analyzed, with experiments showing random clustering works as well as sophisticated methods
- The experiments demonstrate effectiveness across multiple benchmarks but don't explore the framework's applicability to other alignment methods beyond SFT

## Confidence

- **High confidence**: DTM framework consistently improves instruction-following ability while maintaining or improving knowledge retention compared to vanilla SFT
- **Medium confidence**: Dataset biases are a primary cause of alignment tax (supported by empirical results but lacking direct causal evidence)
- **Medium confidence**: Model merging effectively eliminates data-specific biases while preserving shared knowledge (mechanism observed in related work, partially validated in DTM experiments)

## Next Checks

1. Conduct ablation studies measuring the loss reduction ratio during training to directly verify the hypothesis that data biases become the dominant factor in loss reduction over time
2. Perform bias analysis on sub-models pre- and post-merging using techniques like integrated gradients to track how dataset-specific patterns are eliminated during the merging process
3. Test DTM with synthetic datasets where specific biases are artificially injected to verify that the framework can effectively eliminate known biases while preserving generalizable patterns