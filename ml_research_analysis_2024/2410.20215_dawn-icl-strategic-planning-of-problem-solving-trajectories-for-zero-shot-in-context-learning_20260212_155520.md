---
ver: rpa2
title: 'DAWN-ICL: Strategic Planning of Problem-solving Trajectories for Zero-Shot
  In-Context Learning'
arxiv_id: '2410.20215'
source_url: https://arxiv.org/abs/2410.20215
tags:
- mcts
- zs-icl
- function
- llms
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of zero-shot in-context learning
  (ZS-ICL) by reformulating it as a planning problem. The authors propose DAWN-ICL,
  which leverages demonstration-aware Monte Carlo Tree Search (MCTS) to strategically
  plan problem-solving trajectories.
---

# DAWN-ICL: Strategic Planning of Problem-solving Trajectories for Zero-Shot In-Context Learning

## Quick Facts
- arXiv ID: 2410.20215
- Source URL: https://arxiv.org/abs/2410.20215
- Reference count: 12
- This paper proposes DAWN-ICL, which reformulates zero-shot in-context learning as a planning problem using demonstration-aware Monte Carlo Tree Search, consistently outperforming existing baselines and even surpassing ICL using human-annotated demonstrations.

## Executive Summary
This paper addresses the limitations of zero-shot in-context learning (ZS-ICL) by reformulating it as a planning problem. The authors propose DAWN-ICL, which leverages demonstration-aware Monte Carlo Tree Search (MCTS) to strategically plan problem-solving trajectories. By integrating demonstration information into the Q-value function, DAWN-ICL enhances the selection phase and accelerates the expansion and simulation phases of MCTS. The method consistently outperforms existing ZS-ICL baselines and even surpasses ICL using human-annotated demonstrations, demonstrating its effectiveness across in-domain and cross-domain scenarios.

## Method Summary
DAWN-ICL reformulates ZS-ICL as a planning problem using Markov Decision Process (MDP). The method employs demonstration-aware Monte Carlo Tree Search (MCTS) where the Q-value function is initialized using similarity and confidence scores from retrieved pseudo-demonstrations. The MCTS planning optimizes the order of solving problems to prevent error accumulation, and a calibration-enhanced aggregation method combines multiple predictions while debiasing against prior probabilities. The approach uses a cache mechanism to store high-value action-demonstration pairs, accelerating the simulation phase.

## Key Results
- DAWN-ICL consistently outperforms existing ZS-ICL baselines across in-domain and cross-domain scenarios
- The method surpasses ICL using human-annotated demonstrations in accuracy
- Demonstration-aware Q-value initialization significantly improves MCTS search quality for ZS-ICL

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Demonstration-aware Q-value initialization improves search quality in MCTS for ZS-ICL.
- Mechanism: The DQ function integrates similarity and confidence scores from retrieved pseudo-demonstrations to initialize Q-values, guiding MCTS toward more relevant problem-solving trajectories.
- Core assumption: Pseudo-demonstrations with higher similarity to the current problem and higher confidence are more likely to help solve the problem.
- Evidence anchors:
  - [abstract] "we propose a demonstration-aware Q-value function and use it to enhance the selection phase and accelerate the expansion and simulation phases in MCTS"
  - [section 3.2] "we propose to leverage the contextual information of the current state and action to initialize the Q value" and "the performance of ICL is known to be highly dependent on the selection of demonstrations"
- Break condition: If pseudo-demonstrations are irrelevant or of poor quality, the initial Q-values may mislead the search toward suboptimal trajectories.

### Mechanism 2
- Claim: MCTS planning optimizes the order of solving problems in ZS-ICL, preventing error accumulation.
- Mechanism: MCTS explores different sequences of solving problems, selecting trajectories that maximize expected reward based on confidence scores, thereby strategically ordering problem-solving to leverage helpful demonstrations.
- Core assumption: The order in which problems are solved affects the quality of pseudo-demonstrations generated, which in turn affects subsequent problem-solving performance.
- Evidence anchors:
  - [abstract] "we reformulate ZS-ICL as a planning problem and propose a Demonstration-A Ware MoNte Carlo Tree Search (MCTS) approach (DAWN-ICL), which leverages MCTS to strategically plan the problem-solving trajectories for ZS-ICL"
  - [section 3.1] "Our idea is to formalize ZS-ICL as a planning problem using a Markov Decision Process (MDP)" and "the order of traversing is important for effectively leveraging historical examples as pseudo-demonstrations"
- Break condition: If problems are too diverse or unrelated, even optimal ordering may not significantly improve performance due to lack of transferable demonstrations.

### Mechanism 3
- Claim: Calibration-enhanced aggregation debiases predictions by normalizing against prior probabilities.
- Mechanism: After MCTS generates multiple predictions for each problem, the calibration strategy divides each prediction probability by the prior probability of that label, mitigating LLM bias toward common tokens.
- Core assumption: LLMs exhibit token frequency bias in their pretraining data, which affects their predictions even in few-shot settings.
- Evidence anchors:
  - [abstract] "we design a calibration-enhanced aggregation method to derive the final prediction from MCTS, which aggregates results from multiple iterations and debiases the prediction with pre-trained priors"
  - [section 3.3.2] "LLMs are known to suffer from common token bias... To debias the prediction of LLMs, we adopt a calibration strategy based on prior probability"
- Break condition: If prior probabilities are poorly estimated or the label space is too large, calibration may introduce noise rather than reduce bias.

## Foundational Learning

- Concept: Monte Carlo Tree Search (MCTS)
  - Why needed here: MCTS provides a principled way to explore the problem-solving trajectory space in ZS-ICL, balancing exploration of new sequences with exploitation of promising ones.
  - Quick check question: What are the four phases of MCTS and what does each accomplish in the context of ZS-ICL?

- Concept: In-Context Learning (ICL)
  - Why needed here: ZS-ICL is the target problem, and understanding how ICL works with demonstrations is crucial for designing the demonstration-aware components.
  - Quick check question: Why is ICL sensitive to the selection of demonstrations, and how does this motivate the demonstration-aware Q-value function?

- Concept: Reinforcement Learning with Function Approximation
  - Why needed here: The Q-value function in MCTS approximates expected future rewards, requiring understanding of function approximation techniques and their limitations.
  - Quick check question: What are the trade-offs between using a learned Q-value function versus a heuristic-based initialization like the demonstration-aware approach?

## Architecture Onboarding

- Component map: Problem Set -> MCTS Selection -> Transition Function T -> Q-value Updates -> Back-propagation -> Aggregation -> Final Prediction
- Critical path: Problem Set → MCTS Selection → Transition Function T → Q-value Updates → Back-propagation → Aggregation → Final Prediction
- Design tradeoffs:
  - Exploration vs. Exploitation: DUCT balances these using demonstration-aware Q-values and visit counts
  - Computation vs. Accuracy: Cache mechanism trades memory for faster simulation
  - Diversity vs. Relevance: Demonstration selection balances semantically similar examples with diverse labels
- Failure signatures:
  - Poor performance despite MCTS: Likely issues with demonstration quality or Q-value initialization
  - Slow convergence: May indicate suboptimal hyperparameters (wa, wQ, ka, kd)
  - Inconsistent results across runs: Could suggest insufficient exploration or unstable Q-value estimates
- First 3 experiments:
  1. Compare DAWN-ICL with random selection baseline on a small BBH task to verify planning helps
  2. Ablation study removing demonstration-aware Q0 to measure its contribution to performance
  3. Vary the number of retrieved candidates (kd) to find optimal balance between relevance and diversity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design a more efficient Q-value estimation method for ZS-ICL that reduces the computational cost of using LLMs for reward calculation?
- Basis in paper: Explicit - "For ZS-ICL, such an updating method is too costly to achieve accurate estimation since the state space is very large, and each state requires the LLM to perform one inference for reward calculation."
- Why unresolved: The paper acknowledges the high computational cost of using LLMs for reward calculation but does not propose a specific solution for efficient Q-value estimation.
- What evidence would resolve it: A method that significantly reduces the number of LLM inferences required for Q-value estimation while maintaining or improving performance compared to DAWN-ICL.

### Open Question 2
- Question: How can we improve the demonstration selection strategy in ZS-ICL to avoid error accumulation caused by similarity-based methods?
- Basis in paper: Explicit - "We observe that the similarity-based demonstration selection methods (i.e., BM25 and TopK) perform worse than the random selection method... This can be attributed to the fact that these methods tend to use samples with the same label as demonstrations, which can lead to incorrect predictions and subsequent error accumulation."
- Why unresolved: While the paper proposes a TopK+Diverse method, it does not explore other potential strategies to mitigate error accumulation in demonstration selection.
- What evidence would resolve it: A demonstration selection strategy that outperforms TopK+Diverse in terms of accuracy and robustness against error accumulation.

### Open Question 3
- Question: How can we extend the planning framework of DAWN-ICL to handle more complex task structures and dependencies in real-world scenarios?
- Basis in paper: Inferred - "In real-world scenarios, examples usually come from diverse tasks, and only a few belong to the same task. The random traversing order may cause LLMs to generate unreliable pseudo-demonstrations and lead to error accumulation."
- Why unresolved: The paper focuses on planning for ZS-ICL but does not address how to handle more complex task structures and dependencies that may arise in real-world applications.
- What evidence would resolve it: An extension of DAWN-ICL that demonstrates improved performance on tasks with complex structures and dependencies compared to the original method.

## Limitations
- Demonstration Quality Dependency: The approach is highly dependent on the quality of retrieved pseudo-demonstrations, which can mislead the search if they are irrelevant or of poor quality.
- Hyperparameter Sensitivity: The method relies on several hyperparameters (ka, kd, wa, wQ) that may significantly affect performance, but systematic sensitivity analysis is lacking.
- Computational Overhead: MCTS-based planning inherently requires more computation than direct prediction approaches, though the cost-benefit trade-off is not thoroughly analyzed.

## Confidence

**High Confidence**:
- Demonstration-aware Q-value initialization improves search quality in MCTS for ZS-ICL
- MCTS planning optimizes the order of solving problems in ZS-ICL
- Calibration-enhanced aggregation debiases predictions by normalizing against prior probabilities

**Medium Confidence**:
- The approach consistently outperforms existing ZS-ICL baselines
- DAWN-ICL surpasses ICL using human-annotated demonstrations
- The method is effective across in-domain and cross-domain scenarios

**Low Confidence**:
- The specific hyperparameter values chosen are optimal
- The computational overhead is justified by performance gains in all scenarios
- The approach generalizes to truly out-of-distribution problems

## Next Checks

1. **Ablation on Demonstration Quality**: Systematically vary the quality of retrieved demonstrations (e.g., using only irrelevant or only highly relevant ones) to quantify how sensitive DAWN-ICL performance is to demonstration quality, directly testing the break condition for Mechanism 1.

2. **Hyperparameter Sensitivity Analysis**: Conduct a grid search over the key hyperparameters (ka, kd, wa, wQ) to identify the sensitivity of performance to these parameters and determine if the reported results are robust or narrowly optimal.

3. **Computational Efficiency Benchmark**: Measure the wall-clock time and computational resources required by DAWN-ICL compared to baseline methods across varying problem set sizes, quantifying the exact cost-benefit trade-off that the paper claims but doesn't thoroughly analyze.