---
ver: rpa2
title: 'CoSLight: Co-optimizing Collaborator Selection and Decision-making to Enhance
  Traffic Signal Control'
arxiv_id: '2405.17152'
source_url: https://arxiv.org/abs/2405.17152
tags:
- traffic
- collaborator
- learning
- control
- intersection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoSLight proposes a novel approach for multi-intersection traffic
  signal control by jointly optimizing collaborator selection and decision-making
  policies. The method uses a lightweight MLP-based collaborator selection module
  that adaptively identifies optimal teammates based on phase- and intersection-level
  features, combined with a joint optimization scheme that trains both the collaborator
  selection and signal control policies together.
---

# CoSLight: Co-optimizing Collaborator Selection and Decision-making to Enhance Traffic Signal Control

## Quick Facts
- arXiv ID: 2405.17152
- Source URL: https://arxiv.org/abs/2405.17152
- Reference count: 40
- Key outcome: Achieves up to 7.68% reduction in average delay time and 1.98% reduction in average trip time compared to state-of-the-art methods

## Executive Summary
CoSLight introduces a novel approach for multi-intersection traffic signal control that jointly optimizes collaborator selection and decision-making policies. The method uses a lightweight MLP-based collaborator selection module that adaptively identifies optimal teammates based on phase- and intersection-level features, combined with a joint optimization scheme that trains both policies together. Experiments on synthetic and real-world datasets demonstrate significant improvements in traffic efficiency, with the approach effectively capturing complex collaboration patterns beyond topological neighbors while maintaining computational efficiency.

## Method Summary
CoSLight implements a dual-feature extractor using FRAP for phase-level features and Transformer for intersection-level relationships, combined with an MLP-based collaborator selection (CoS) policy. The system jointly optimizes both the CoS policy and the decision policy using policy gradient methods with constraints ensuring stable collaboration patterns. The approach is trained and evaluated on SUMO traffic simulator environments including synthetic grids and real-world datasets like Cologne8 and Nanshan.

## Key Results
- Up to 7.68% reduction in average delay time compared to state-of-the-art methods
- 1.98% reduction in average trip time across tested scenarios
- Significant improvements in intersection-wise metrics including delay, wait time, queue length, and pressure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The co-optimization captures non-local collaboration patterns that fixed-topology methods miss
- Mechanism: Joint training of lightweight MLP-based collaborator selection and signal control policies enables adaptive identification of optimal collaborators beyond immediate neighbors
- Core assumption: Traffic patterns are not purely determined by physical proximity and can be learned from traffic state features
- Evidence anchors:
  - [abstract] "The method uses a lightweight MLP-based collaborator selection module that adaptively identifies optimal teammates based on phase- and intersection-level features"
  - [section] "In contrast to these existing methods, we introduce a dual-feature extractor to derive collaborator representations beneficial for collaboration"

### Mechanism 2
- Claim: Joint optimization with dual-feature extraction enables more effective learning through richer state representations
- Mechanism: Dual-feature extractor captures phase-level competition (FRAP) and intersection-level relationships (Transformer), while joint optimization ensures coordinated policy updates
- Core assumption: Richer state representations and coordinated updates lead to better learning efficiency than sequential optimization
- Evidence anchors:
  - [abstract] "combined with a joint optimization scheme that trains both the collaborator selection and signal control policies together"
  - [section] "The overall objective Œ∑ is to maximize the cumulative return, formulated as follows: max œÜ,Œ∏ J(œÜ, Œ∏) = max œÜ,Œ∏ E (s,a,ids) ~œÄall [‚àë Œ≥^t r(s_t, a_t)]"

### Mechanism 3
- Claim: Symmetric and diagonal maximization constraints ensure stable collaboration patterns
- Mechanism: Diagonal maximization prioritizes self-state while symmetry ensures mutual consideration between intersections
- Core assumption: Stable collaboration requires balance between self-prioritization and mutual cooperation
- Evidence anchors:
  - [section] "Rule 1: 'You are your biggest collaborator'. Diagonal maximization constraint is imposed...Rule 2: 'Collaboration should be mutually reciprocal'. Symmetry constraint is enforced"
  - [section] "We can denote the distributions of œÅ_t for all intersections as a collaborator matrix M_œÅ ‚àà R^(N√óN)"

## Foundational Learning

- Concept: Multi-agent reinforcement learning with joint action spaces
  - Why needed here: Multiple intersections act simultaneously requiring coordination between agents
  - Quick check question: What is the difference between independent Q-learning and joint action Q-learning in multi-agent settings?

- Concept: Attention mechanisms and feature extraction
  - Why needed here: Dual-feature extractor uses Transformer attention for intersection relationships and FRAP for phase competition
  - Quick check question: How does self-attention in Transformers help capture relationships between different intersections?

- Concept: Policy gradient optimization with constraints
  - Why needed here: Joint optimization uses policy gradients while incorporating constraints on collaborator selection matrix
  - Quick check question: What is the role of the baseline in policy gradient methods and how does it affect variance?

## Architecture Onboarding

- Component map: Dual-Feature Extractor (FRAP + Transformer) ‚Üí Multi-Intersection Collaboration (CoS MLP + Decision Policy MLP) ‚Üí Joint Optimization (Policy Gradients with Constraints)
- Critical path: Observation ‚Üí Dual-Feature Extraction ‚Üí Collaborator Selection ‚Üí Action Selection ‚Üí Environment Interaction ‚Üí Reward Collection ‚Üí Joint Optimization
- Design tradeoffs: Lightweight MLP for CoS vs. GNNs for capturing relationships (MLP chosen for speed and simplicity), joint optimization vs. sequential training (joint chosen for better coordination)
- Failure signatures: Poor convergence (check constraint implementation), suboptimal collaborator selection (verify feature extraction quality), computational bottlenecks (profile MLP layers)
- First 3 experiments:
  1. Ablation study: Remove CoS module to verify its contribution to performance
  2. Constraint analysis: Remove diagonal or symmetry constraints to test their impact on stability
  3. Feature extraction comparison: Replace Transformer with GNN to validate the choice of architecture

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of collaborators (ùëò) for maximizing traffic signal control performance across different urban scenarios?
- Basis in paper: [explicit] The paper conducts experiments varying the number of collaborators (ùëò) from 2 to 16 and observes performance trade-offs in different scenarios.
- Why unresolved: While the paper identifies trends (e.g., Grid 4 √ó 4 benefits from more collaborators while Cologne8 sees limited gains), it does not determine a dynamic method for selecting the optimal number of collaborators for any given scenario.
- What evidence would resolve it: Empirical results showing the performance impact of dynamically adjusting the number of collaborators based on real-time traffic conditions and network topology, compared to static ùëò values.

### Open Question 2
- Question: How does the CoSLight approach perform when scaling to significantly larger urban networks (e.g., 100+ intersections) compared to current state-of-the-art methods?
- Basis in paper: [inferred] The paper mentions computational efficiency advantages of using MLPs over GNNs, but only tests on networks with up to 29 intersections.
- Why unresolved: The scalability limitations and performance degradation of CoSLight in large-scale networks remain unknown, particularly regarding the joint optimization of collaborator selection and decision-making.
- What evidence would resolve it: Comparative performance metrics (delay time, computational overhead) on large-scale urban networks (100+ intersections) between CoSLight and competing methods.

### Open Question 3
- Question: How does the learned collaborator selection policy generalize to unseen traffic scenarios or cities with different urban layouts?
- Basis in paper: [explicit] The paper demonstrates performance across synthetic and real-world datasets but does not explicitly test cross-city generalization.
- Why unresolved: While the method shows adaptability within tested scenarios, its ability to transfer learned collaborator selection policies to completely new urban environments remains untested.
- What evidence would resolve it: Transfer learning experiments where a model trained on one city's traffic data is tested on another city with different topology, flow patterns, and intersection configurations.

## Limitations
- Limited evaluation to small-scale synthetic grids (4x4, 5x5) and only two real-world datasets
- No statistical significance testing across multiple runs to establish result robustness
- Hyperparameter sensitivity analysis not provided, making results potentially sensitive to specific settings

## Confidence

- Performance claims: Medium confidence (up to 7.68% delay reduction supported but lacks ablation studies and statistical testing)
- Theoretical framework: High confidence (dual-feature extraction and joint optimization concepts well-grounded in RL literature)
- Scalability claims: Low confidence (only tested on networks with up to 29 intersections, no large-scale evaluation)

## Next Checks

1. Conduct ablation studies removing individual components (CoS module, dual-feature extractor, joint optimization) to quantify each element's contribution to performance improvements

2. Run statistical significance tests (e.g., paired t-tests) across multiple training runs to validate the claimed performance gains are not due to random variation

3. Evaluate scalability on larger, more complex traffic networks (e.g., 10x10 grids or actual city-scale maps) to assess real-world applicability and computational efficiency claims