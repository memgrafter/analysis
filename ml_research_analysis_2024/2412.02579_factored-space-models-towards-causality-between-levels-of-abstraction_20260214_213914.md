---
ver: rpa2
title: 'Factored space models: Towards causality between levels of abstraction'
arxiv_id: '2412.02579'
source_url: https://arxiv.org/abs/2412.02579
tags:
- lemma
- variables
- space
- factored
- independence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Factored space models (FSMs) address the limitation of causal graphs
  in modeling deterministic relationships between variables. Unlike causal graphs,
  FSMs represent all variables, including deterministic functions, by expressing the
  sample space as a Cartesian product.
---

# Factored space models: Towards causality between levels of abstraction

## Quick Facts
- arXiv ID: 2412.02579
- Source URL: https://arxiv.org/abs/2412.02579
- Reference count: 40
- Primary result: Factored space models generalize causal graphs by allowing deterministic variables, with structural independence providing sound and complete characterization of conditional independence

## Executive Summary
Factored space models (FSMs) extend causal graph frameworks to handle deterministic relationships between variables by representing sample spaces as Cartesian products of independent background factors. This allows variables that are deterministic functions of others to be represented as first-class nodes, enabling structural independence to generalize d-separation to arbitrary variables. The key theoretical contribution is Theorem 6.2, establishing that structural independence is sound and complete for probabilistic independence across all distributions that factorize over the FSM.

## Method Summary
The method constructs FSMs by expressing the sample space as a Cartesian product Ω = ×i∈I Ωi of independent background factors, with observed variables defined as deterministic functions of these factors. Structural independence is defined through history sets H(X|C), capturing the minimal background factors that determine X given C. The core result proves that H(A|C) ∩ H(B|C) = ∅ if and only if A ⊥⊥P B|C for all distributions P factorizing over Ω, generalizing the classical soundness and completeness of d-separation to variables with deterministic dependencies.

## Key Results
- FSMs represent deterministic variables as first-class nodes, overcoming causal graph limitations
- Structural independence (H(X) ∩ H(Y) = ∅) generalizes d-separation to arbitrary variables
- Theorem 6.2 establishes soundness and completeness of structural independence for all factorizing distributions
- FSMs can represent distributions with no perfect DAG map, demonstrating greater expressiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FSMs extend causal graphs by allowing deterministic function variables to be represented as first-class nodes
- Mechanism: By expressing sample space as Cartesian product of independent background factors, FSMs naturally represent any variable as deterministic function of these factors
- Core assumption: Cartesian factorization is possible and captures all relevant dependencies; background factors are truly independent
- Evidence anchors:
  - [abstract] "FSMs represent all variables, including deterministic functions, by expressing the sample space as a Cartesian product."
  - [section 4] Definition 4.2 introduces Cartesian product structure and background variables

### Mechanism 2
- Claim: Structural independence is sound and complete for probabilistic independence in all factorizing distributions
- Mechanism: Soundness: if H(A|C) ∩ H(B|C) = ∅ then A ⊥⊥P B|C for all P ∈ △⊗(Ω). Completeness: if A ⊥⊥P B|C for all such P then H(A|C) ∩ H(B|C) = ∅
- Core assumption: Factored structure correctly captures all probabilistic dependencies; distributions considered are exactly those that factorize over Ω
- Evidence anchors:
  - [abstract] "Theorem 6.2... establishes the soundness and completeness of structural independence."
  - [section 6] Lemma 6.3 (soundness) and Lemma 6.4 (completeness) provide formal proof structure

### Mechanism 3
- Claim: FSMs are more expressive than causal DAGs because some distributions have FSM perfect maps but no DAG perfect maps
- Mechanism: Cartesian product representation allows deterministic function variables to coexist without forcing DAG to satisfy both Markov and faithfulness conditions
- Core assumption: FSM construction from DAG preserves all independences via Theorem 6.2
- Evidence anchors:
  - [section 5.2.3] Proposition 5.8 shows FSMs can represent distributions with no DAG perfect map
  - [section 5.2] Construction from DAG to FSM and preservation of factorization and d-separation

## Foundational Learning

- Concept: Factored Space Model (FSM)
  - Why needed here: Provides mathematical framework to represent variables that are deterministic functions of others
  - Quick check question: In FSM with Ω = Ω1 × Ω2, what is history H(X) of variable X that depends only on U1?

- Concept: Structural Independence
  - Why needed here: Key criterion that generalizes d-separation to variables with deterministic relationships
  - Quick check question: Given variables X and Y on FSM, what condition must hold for X ⊥Ω Y?

- Concept: History of a Variable
  - Why needed here: Captures exactly background factors that variable depends on, enabling structural independence definition
  - Quick check question: For variable X defined as X(ω) = ω1 + ω2 on Ω = {0,1} × {0,1}, what is H(X)?

## Architecture Onboarding

- Component map:
  - Background Factors (U_i): Independent random variables forming Cartesian product Ω
  - Variables: Deterministic functions of background factors
  - Factored Space Model: Tuple (Ω, O) where O is observed variable(s)
  - Structural Independence: Criterion based on history sets

- Critical path:
  1. Define Ω = ×i∈I Ωi and background variables U_i
  2. Define observed variables O as deterministic functions of Ω
  3. Compute histories H(X|C) for relevant variables/events
  4. Apply structural independence criterion H(X|C) ∩ H(Y|C) = ∅
  5. Use Theorem 6.2 to infer probabilistic independence

- Design tradeoffs:
  - Expressive power vs. computational complexity: FSMs model more complex dependencies but require computing histories, which may be costly for large I
  - Assumption of factorization: Requires identifying appropriate independent background factors; misspecification leads to incorrect independence claims

- Failure signatures:
  - Incorrect independence claims due to wrong factorization assumption
  - Histories computed incorrectly, leading to wrong structural independence
  - Using structural independence for distributions not in △⊗(Ω)

- First 3 experiments:
  1. Verify FSM construction from simple DAG (X → Y) preserves d-separation: check H(X) ∩ H(Y) = ∅ iff X and Y are d-separated
  2. Test soundness: construct FSM for coin flip example, verify X1 ⊥⊥ X⊕ holds structurally and probabilistically
  3. Test completeness: construct FSM for distribution with no DAG perfect map, verify FSM correctly captures all independences via structural independence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are computational complexity bounds for determining structural independence in FSMs, and how do they compare to d-separation in causal graphs?
- Basis in paper: [inferred] Paper establishes theoretical foundations but does not analyze computational complexity
- Why unresolved: Focuses on theoretical properties rather than algorithmic implementation or complexity analysis
- What evidence would resolve it: Formal complexity analysis showing polynomial-time, NP-complete, or other complexity characteristics

### Open Question 2
- Question: How can FSMs be extended to handle continuous variables while maintaining soundness and completeness properties?
- Basis in paper: [explicit] States "we always mean discrete random variables" and focuses on finite factored spaces
- Why unresolved: Framework is explicitly limited to discrete variables, requiring new mathematical foundations for continuous spaces
- What evidence would resolve it: Generalized framework extending structural independence to continuous variables with equivalent theorems

### Open Question 3
- Question: What are practical implications and performance benefits of FSMs versus causal graphs in real-world applications?
- Basis in paper: [explicit] Discusses potential applications in neural network interpretability but provides no empirical validation
- Why unresolved: Paper is theoretical without empirical studies or benchmarks comparing FSMs to existing methods
- What evidence would resolve it: Empirical studies demonstrating FSM effectiveness with quantitative comparisons to causal graph approaches

## Limitations
- FSMs require correctly identifying independent background factors that factorize the distribution
- Framework assumes finite sample spaces, with continuous variables requiring careful handling
- Completeness direction depends critically on factorization assumption being satisfied

## Confidence
- **High confidence** in Theorem 6.2's proof structure and soundness direction
- **Medium confidence** in completeness due to critical dependence on factorization assumption
- **Medium confidence** in practical applicability given background factor identification requirements

## Next Checks
1. Construct simple FSM from known DAG (X → Y) and verify structural independence correctly captures d-separation relationships
2. Create concrete FSM for non-trivial example (coin flip with XOR) and empirically verify all probabilistic independences predicted by structural independence
3. Identify distribution with no DAG perfect map and construct FSM that captures all independences, validating expressiveness claim