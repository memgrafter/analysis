---
ver: rpa2
title: 'PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid
  Domain Generalization'
arxiv_id: '2404.09011'
source_url: https://arxiv.org/abs/2404.09011
tags:
- domain
- vision
- generalization
- methods
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses practical domain generalization (DG) by introducing
  hybrid domain generalization (HDG), which tackles the issue of disparate and diverse
  label sets across source domains. The authors propose SCI-PD, a perturbation distillation
  method that transfers knowledge from large vision-language models (VLMs) like CLIP
  to lightweight vision models.
---

# PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization

## Quick Facts
- arXiv ID: 2404.09011
- Source URL: https://arxiv.org/abs/2404.09011
- Reference count: 40
- Addresses practical domain generalization with disparate label sets across domains

## Executive Summary
This paper introduces PracticalDG, a perturbation distillation method that transfers knowledge from large vision-language models like CLIP to lightweight vision models for hybrid domain generalization (HDG). The method addresses the practical challenge of disparate and diverse label sets across source domains, which is common in real-world applications. SCI-PD introduces perturbation from three perspectives: Score Perturbation balances semantics from CLIP and ground truth labels, Instance Perturbation excavates underlying semantics in instances based on prediction certainty, and Class Perturbation saturates semantics from pretrained text embeddings to the classifier. Experiments on PACS, OfficeHome, and DomainNet demonstrate that SCI-PD outperforms state-of-the-art methods on accuracy, H-score, and H2-CV metrics, especially improving robustness when confronting data scarcity.

## Method Summary
SCI-PD transfers knowledge from large vision-language models (VLMs) like CLIP to lightweight vision models through perturbation distillation. The method introduces three types of perturbation: Score Perturbation (SP) balances semantics from CLIP similarity scores and ground truth labels by saturating ground truth labels into CLIP's similarity scores using misclassification masks; Instance Perturbation (IP) excavates underlying semantics by weighting instances based on prediction certainty, giving higher weights to uncertain predictions; Class Perturbation (CP) saturates semantics from pretrained text embeddings to the classifier. The perturbations are combined into a final training objective with a trade-off hyperparameter β. The method is evaluated on a newly proposed HDG benchmark with varying hybridness H values that measure label set discrepancies across source domains.

## Key Results
- SCI-PD outperforms state-of-the-art domain generalization methods on PACS, OfficeHome, and DomainNet datasets
- Achieves superior robustness when measured by H2-CV metric across various label set discrepancies
- Demonstrates strong transferability to various lightweight vision models including ResNet18, EfficientNet-B0, and MobileNet-V3
- Shows consistent improvements over CLIPBase across all hybridness H values in the HDG benchmark

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Perturbation distillation transfers robust zero-shot semantics from VLMs to lightweight vision models.
- Mechanism: SCI-PD introduces three types of perturbation (Score, Instance, Class) that modify the knowledge transfer process from CLIP to downstream models, balancing semantic richness with domain invariance.
- Core assumption: CLIP's similarity scores contain domain-invariant semantic information that can be distilled without fine-tuning the full VLM.
- Evidence anchors: [abstract] "transfer knowledge from VLMs to lightweight vision models and improve the robustness by introducing Perturbation Distillation (PD) from three perspectives"; [section] "We observe that the distribution of ˆps contains affluent semantics which are essential for domain-invariant learning, but it inevitably introduces redundant noise from incorrect predictions."

### Mechanism 2
- Claim: Score Perturbation balances semantics from CLIP and ground truth labels.
- Mechanism: The method saturates ground truth labels into CLIP's similarity scores using masks that identify misclassifications, preserving semantic richness while suppressing noise.
- Core assumption: The combination of CLIP's semantic distribution and ground truth labels produces better domain-invariant features than either alone.
- Evidence anchors: [section] "SP remains the distribution of ˆps that successfully preserves the semantics that boost the domain-invariant learning. SP saturates perturbation from accurate GT labels that suppress semantic noises from CLIP."; [abstract] "SP balances semantics from CLIP and ground truth labels"

### Mechanism 3
- Claim: Instance Perturbation excavates underlying semantics in instances by weighting based on prediction certainty.
- Mechanism: Instances with low certainty (uniform similarity distribution) receive higher weights, encouraging the model to learn from semantically rich but uncertain examples.
- Core assumption: Low certainty predictions indicate instances with more commonalities across classes, containing richer semantic information for domain generalization.
- Evidence anchors: [section] "we observe that the original objective Lbase in Eq. 2 equally address all instances that semantics from a more uniform distribution are constrained."; [abstract] "IP excavates underlying semantics in instances"

## Foundational Learning

- Concept: Domain Generalization
  - Why needed here: The paper builds on DG fundamentals while extending to open set scenarios with disparate label sets.
  - Quick check question: What is the key difference between standard DG and Open Set DG?

- Concept: Knowledge Distillation
  - Why needed here: SCI-PD uses perturbation-based distillation instead of traditional KD, requiring understanding of how knowledge transfers between teacher and student models.
  - Quick check question: How does perturbation distillation differ from standard feature-based knowledge distillation?

- Concept: Vision-Language Models and Zero-Shot Transfer
  - Why needed here: The method relies on CLIP's zero-shot ability, requiring understanding of how text-image embeddings enable cross-domain generalization.
  - Quick check question: What makes CLIP effective for zero-shot transfer compared to traditional vision models?

## Architecture Onboarding

- Component map: CLIP (teacher) → Perturbation modules (SP, IP, CP) → Lightweight vision model (student) → Classifier → Output
- Critical path: Image → CLIP encoder → Similarity scores → Perturbation modules → Distillation loss → Student model update
- Design tradeoffs: Accuracy vs. training efficiency (using lightweight models vs. fine-tuning VLMs), robustness vs. specificity (handling unknown classes), complexity vs. practicality (perturbation vs. complex architectures)
- Failure signatures: Performance degradation on unknown classes, high H2-CV scores indicating poor robustness, sensitivity to hyperparameter choices
- First 3 experiments:
  1. Implement basic SCI-PD with only Score Perturbation on OfficeHome, compare to CLIPBase
  2. Add Instance Perturbation and evaluate on H-score across different H values
  3. Test Class Perturbation and measure transferability to EfficientNet-B0 and MobileNet-V3

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SCI-PD vary when applied to different lightweight vision models beyond ResNet18, EfficientNet-B0, and MobileNet-V3?
- Basis in paper: [explicit] The paper mentions transferability experiments with EfficientNet-B0 and MobileNet-V3, showing SCI-PD's effectiveness on these models. However, it does not explore a wider range of lightweight models.
- Why unresolved: The paper only tests a limited number of lightweight vision models. A comprehensive evaluation across various models would provide a more robust understanding of SCI-PD's generalizability.
- What evidence would resolve it: Conducting experiments with a diverse set of lightweight vision models, including those from different architectural families, and comparing their performance with SCI-PD.

### Open Question 2
- Question: What is the impact of different perturbation strengths (α, τ, β) on the performance of SCI-PD, and how can we determine the optimal values for these hyperparameters?
- Basis in paper: [explicit] The paper conducts a hyperparameter analysis on τ, α, and β, showing that SCI-PD has low sensitivity to these parameters. However, it does not explore the full range of possible values or provide a systematic method for hyperparameter tuning.
- Why unresolved: The hyperparameter analysis is limited in scope and does not provide a comprehensive understanding of the relationship between perturbation strengths and model performance. A more thorough investigation is needed to determine optimal values.
- What evidence would resolve it: Performing an extensive hyperparameter search across a wider range of values for α, τ, and β, and analyzing the impact on SCI-PD's performance. Developing a principled method for hyperparameter tuning based on the observed trends.

### Open Question 3
- Question: How does SCI-PD compare to other knowledge distillation techniques when transferring knowledge from VLMs to lightweight vision models for domain generalization?
- Basis in paper: [inferred] The paper focuses on SCI-PD's performance compared to other domain generalization methods but does not directly compare it to other knowledge distillation techniques in the context of VLMs and domain generalization.
- Why unresolved: The paper does not provide a comprehensive comparison of SCI-PD with other knowledge distillation approaches. Understanding how SCI-PD fares against other techniques would provide insights into its relative strengths and weaknesses.
- What evidence would resolve it: Conducting experiments comparing SCI-PD to other knowledge distillation methods, such as traditional KD, contrastive KD, or self-distillation, when transferring knowledge from VLMs to lightweight vision models for domain generalization tasks.

## Limitations

- The paper lacks detailed implementation specifications for the HDG benchmark splits across different datasets and hybridness values, making exact reproduction challenging.
- Hyperparameter sensitivity is not fully explored, with limited information on the search space and optimization process for perturbation parameters.
- The theoretical justification for why perturbation distillation specifically improves domain generalization over standard knowledge distillation is underdeveloped.

## Confidence

- **High confidence**: The core claim that SCI-PD improves accuracy and robustness metrics on HDG benchmarks (supported by experimental results on PACS, OfficeHome, and DomainNet).
- **Medium confidence**: The mechanism by which Score Perturbation balances CLIP semantics and ground truth labels, as the mathematical formulation is clear but empirical validation is limited to performance gains.
- **Low confidence**: The theoretical explanation of why Instance Perturbation (weighting uncertain instances) enhances semantic learning, as the paper provides limited ablation studies isolating this effect.

## Next Checks

1. **Reproduce basic SCI-PD implementation**: Implement the method with only Score Perturbation on OfficeHome and verify that it matches or exceeds CLIPBase performance before adding other components.
2. **Conduct ablation study**: Systematically disable each perturbation type (SP, IP, CP) to quantify their individual contributions to overall performance gains.
3. **Test robustness to hyperparameter variations**: Evaluate model performance across a range of β values (e.g., 0.01, 0.1, 0.5) and τ values to establish sensitivity and identify stable operating regions.