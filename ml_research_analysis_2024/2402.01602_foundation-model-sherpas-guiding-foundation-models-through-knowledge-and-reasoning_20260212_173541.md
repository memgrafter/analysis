---
ver: rpa2
title: 'Foundation Model Sherpas: Guiding Foundation Models through Knowledge and
  Reasoning'
arxiv_id: '2402.01602'
source_url: https://arxiv.org/abs/2402.01602
tags:
- language
- knowledge
- reasoning
- such
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a conceptual framework that categorizes agent
  roles for guiding foundation models (FMs) like large language models. The sherpas
  framework distinguishes between agents that update FMs, assist with prompting, assess
  outputs, curate knowledge, and orchestrate workflows.
---

# Foundation Model Sherpas: Guiding Foundation Models through Knowledge and Reasoning

## Quick Facts
- arXiv ID: 2402.01602
- Source URL: https://arxiv.org/abs/2402.01602
- Reference count: 5
- The paper introduces a conceptual framework categorizing agent roles for guiding foundation models (FMs)

## Executive Summary
This paper introduces a conceptual framework called "sherpas" that categorizes agent roles for guiding foundation models like large language models. The framework distinguishes between agents that update FMs, assist with prompting, assess outputs, curate knowledge, and orchestrate workflows. By surveying state-of-the-art approaches across four interaction protocols, the authors demonstrate how various agents can collaborate to address limitations in FMs, such as lack of traceability, interpretability, and formal reasoning.

## Method Summary
This is a survey paper that proposes a conceptual framework called "sherpas" to categorize agent roles that guide foundation models (FMs) like large language models (LLMs). The paper reviews state-of-the-art approaches across four interaction protocols: updating FMs with external knowledge, accessing tools for information retrieval, exploring dynamic prompts, and integrating external reasoners. The authors categorize these approaches into five sherpa roles: FM Updaters, Prompt Assistants, Assessors, Knowledge Curators, and Orchestrators. The survey aims to provide guidance for future directions to realize the power of FMs in practical AI systems.

## Key Results
- Introduces five distinct sherpa roles (Updaters, Prompt Assistants, Assessors, Knowledge Curators, Orchestrators) that interact with FMs at different stages of task execution
- Surveys four interaction protocols: updating FMs with external knowledge, accessing tools for information retrieval, exploring dynamic prompts, and integrating external reasoners
- Identifies future directions including multi-objective optimization, broader automated assessment, and more sophisticated human-in-the-loop interactions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Agents (sherpas) guide foundation models by performing specialized roles such as updating the model, assisting with prompting, evaluating outputs, curating knowledge, and orchestrating workflows.
- Mechanism: The framework defines five distinct sherpa roles that interact with FMs at different stages of task execution, enabling targeted improvements in alignment, trustworthiness, and usability.
- Core assumption: Each sherpa role addresses a specific limitation of FMs (e.g., lack of traceability, interpretability, formal reasoning) and can be implemented as a module or autonomous agent.
- Evidence anchors:
  - [abstract] "Our framework elucidates agent role categories such as updating the underlying FM, assisting with prompting the FM, and evaluating the FM output."
  - [section 3] "FM Updaters are sherpas that modify the underlying transformer or how the FM generates tokens by using external memory or models, to improve performance or better alignment with user preferences for a specific task."
  - [corpus] Weak or missing evidence; corpus neighbors focus on foundation models in robotics, RL, and federated systems rather than sherpa agent frameworks.
- Break condition: If sherpa roles overlap significantly or fail to address distinct FM limitations, the framework's effectiveness diminishes.

### Mechanism 2
- Claim: Dynamic prompting and knowledge retrieval improve FM performance by decomposing tasks and integrating external information.
- Mechanism: Prompt Assistants and Sequencers generate intermediate thoughts or sub-tasks, while Knowledge Curators retrieve relevant information from external sources, enabling FMs to tackle complex problems.
- Core assumption: Decomposing prompts and integrating external knowledge reduces the cognitive load on FMs and improves task completion accuracy.
- Evidence anchors:
  - [section 3.2] "Prompt Sequencers are frameworks that sequentially call FMs to solve sub-tasks. The decomposition itself can also be done by FMs."
  - [section 4.3] "Many of the frameworks in this category have several prompt templates that are associated with a component of search procedure such as node generation, node evaluation, or node selection."
  - [corpus] Weak or missing evidence; corpus neighbors do not explicitly discuss dynamic prompting or knowledge retrieval in the context of sherpa frameworks.
- Break condition: If prompt decomposition leads to excessive computational overhead or knowledge retrieval fails to provide relevant information, the mechanism becomes inefficient.

### Mechanism 3
- Claim: Formal reasoning and uncertainty quantification enhance the trustworthiness and interpretability of FM outputs.
- Mechanism: Assessors and Explainers evaluate FM outputs using formal metrics (e.g., factuality, consistency, uncertainty) and provide explanations, while Orchestrators integrate external reasoners for symbolic inference.
- Core assumption: Formal evaluation and reasoning provide objective measures of FM output quality, enabling users to trust and interpret results.
- Evidence anchors:
  - [section 3.3] "Assessors evaluate output generated from an FM along one or more attributes for a task, including but not limited to measures of quality of generation, such as fluency, or those for trustworthiness, such as harmfulness, factuality, etc."
  - [section 4.4] "The last category follows an alternate approach that integrates external reasoning engines into Assessor or performs symbolic inference to extend Knowledge Curator going beyond information retrieval."
  - [corpus] Weak or missing evidence; corpus neighbors do not discuss formal reasoning or uncertainty quantification in the context of sherpa frameworks.
- Break condition: If formal metrics are too narrow or fail to capture user preferences, the mechanism may not adequately address trustworthiness concerns.

## Foundational Learning

- Concept: Agent-based frameworks for guiding foundation models
  - Why needed here: Understanding the sherpa framework's agent roles and interactions is crucial for implementing and extending the approach.
  - Quick check question: What are the five sherpa roles defined in the framework, and how do they interact with foundation models?
- Concept: Dynamic prompting and knowledge retrieval
  - Why needed here: Decomposing prompts and integrating external information are key mechanisms for improving FM performance on complex tasks.
  - Quick check question: How do Prompt Assistants and Sequencers generate intermediate thoughts, and how do Knowledge Curators retrieve relevant information?
- Concept: Formal reasoning and uncertainty quantification
  - Why needed here: Evaluating FM outputs using formal metrics and integrating external reasoners enhances trustworthiness and interpretability.
  - Quick check question: What are the key attributes assessed by Assessors, and how do Orchestrators integrate external reasoners for symbolic inference?

## Architecture Onboarding

- Component map:
  - Foundation Model (FM): The core model being guided by sherpas
  - Sherpas: Agents with specialized roles (Updaters, Prompt Assistants, Assessors, Knowledge Curators, Orchestrators) that interact with FMs
  - Knowledge Sources: External knowledge bases, APIs, or reasoners integrated by sherpas
  - Task Input/Output: User-provided prompts and FM-generated completions
- Critical path: Task input → Prompt Assistant/Sequencer → FM → Assessor → Output
- Design tradeoffs:
  - Autonomy vs. control: Balancing sherpa autonomy with user control over FM guidance
  - Complexity vs. efficiency: Managing the overhead of multiple sherpa interactions
  - Generality vs. specificity: Designing sherpas for broad applicability vs. task-specific performance
- Failure signatures:
  - Poor task performance: Indicates issues with prompt decomposition, knowledge retrieval, or FM updating
  - Unreliable outputs: Suggests inadequate assessment or uncertainty quantification
  - Excessive computational overhead: Points to inefficient sherpa interactions or complex workflows
- First 3 experiments:
  1. Implement a simple Prompt Assistant that decomposes a task into sub-tasks and sequentially calls an FM
  2. Integrate a Knowledge Curator that retrieves relevant information from an external knowledge base during task execution
  3. Develop an Assessor that evaluates FM outputs using formal metrics (e.g., factuality, consistency) and provides explanations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal methods for multi-objective optimization of foundation models that balance performance, trustworthiness, and cost considerations simultaneously?
- Basis in paper: [explicit] The paper discusses "Multi-objective and Joint Optimization Paradigms" as a future direction, noting that current approaches primarily optimize for accuracy while practical systems need to balance multiple objectives.
- Why unresolved: Current interaction protocols focus on single metrics like accuracy or factuality. The paper suggests that joint optimization across multiple sherpa roles is unexplored, particularly when human feedback is limited.
- What evidence would resolve it: Empirical studies demonstrating superior performance of multi-objective optimization frameworks compared to single-objective approaches across diverse tasks and real-world applications.

### Open Question 2
- Question: How can uncertainty quantification assessors be effectively integrated into dynamic prompt exploration to improve search efficiency and reduce computational costs?
- Basis in paper: [explicit] The paper identifies "Uncertainty Quantification Assessors" as a potential direction, suggesting they could inform search and prune the search space without wasting resources on FM queries.
- Why unresolved: While the concept is mentioned, there's no discussion of specific uncertainty quantification methods or how they would be incorporated into existing search frameworks like Tree of Thoughts or Chain of Thought prompting.
- What evidence would resolve it: Demonstrated reduction in computational costs and improved performance when uncertainty quantification is incorporated into prompt exploration frameworks, with clear metrics showing efficiency gains.

### Open Question 3
- Question: What are the most effective architectures for integrating formal reasoning engines with large language models to improve factuality and consistency in generated outputs?
- Basis in paper: [explicit] The paper discusses "Formal Reasoning Orchestration" as a future direction, noting that current approaches primarily rely on FM reasoning rather than integrating external symbolic or probabilistic reasoners.
- Why unresolved: The paper acknowledges the potential but doesn't specify which formal reasoning approaches (probabilistic programming, logic-based reasoning, etc.) would be most effective or how they should be integrated architecturally.
- What evidence would resolve it: Comparative studies showing performance improvements when different formal reasoning engines are integrated with FMs across various tasks, with clear benchmarks demonstrating superiority over pure FM approaches.

## Limitations

- The paper's primary limitation is its conceptual nature without empirical validation
- Limited evidence demonstrating how sherpa components perform in practice across different domains
- Does not address potential conflicts between sherpa roles or how to optimize their coordination

## Confidence

- High confidence: The framework's conceptual validity and logical organization of agent roles
- Medium confidence: The effectiveness of the four interaction protocols based on limited empirical examples
- Low confidence: The scalability and practical implementation challenges of the framework in real-world systems

## Next Checks

1. Implement a minimal prototype combining at least two sherpa roles (e.g., Prompt Assistant + Knowledge Curator) on a benchmark task to evaluate their interaction effectiveness
2. Conduct a systematic literature review to quantify how many existing FM guidance approaches can be categorized within the sherpa framework
3. Design experiments comparing FM performance with and without sherpa orchestration on complex reasoning tasks to measure the framework's practical value