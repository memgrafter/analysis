---
ver: rpa2
title: 'MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric Depth
  Estimation'
arxiv_id: '2411.10886'
source_url: https://arxiv.org/abs/2411.10886
tags:
- depth
- diffusion
- metric
- latent
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents MetricGold, a diffusion model for monocular
  metric depth estimation that leverages pretrained text-to-image diffusion models.
  The method fine-tunes Stable Diffusion's U-Net using photo-realistic synthetic datasets,
  employing log-scaled depth representation and latent space diffusion.
---

# MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric Depth Estimation

## Quick Facts
- arXiv ID: 2411.10886
- Source URL: https://arxiv.org/abs/2411.10886
- Authors: Ansh Shah; K Madhava Krishna
- Reference count: 19
- Produces sharp, high-quality metric depth estimates with robust zero-shot generalization across diverse real datasets

## Executive Summary
MetricGold presents a novel diffusion model approach for monocular metric depth estimation that leverages pretrained text-to-image diffusion models. The method fine-tunes Stable Diffusion's U-Net using photo-realistic synthetic datasets while preserving the pretrained latent space structure. By employing log-scaled depth representation and training exclusively on synthetic RGB-D data, MetricGold achieves sharp depth predictions with strong generalization capabilities across diverse real-world scenarios, all trained efficiently on a single RTX 3090 GPU within two days.

## Method Summary
MetricGold adapts Stable Diffusion v2 for depth estimation by fine-tuning only the denoising U-Net while preserving the pretrained latent space structure. The model uses log-normalized depth representation to handle the wide range of indoor and outdoor depths, and is trained exclusively on photo-realistic synthetic datasets (HyperSIM, VirtualKitti, and TartanAir) to avoid sensor-specific biases. During inference, DDIM sampling with 50 steps is used, and results from 10 inference runs with varying noise seeds are aggregated for the final prediction.

## Key Results
- Achieves robust zero-shot generalization across diverse real datasets
- Produces sharper and higher quality metric depth estimates compared to existing approaches
- Trains efficiently on a single RTX 3090 GPU within two days
- Successfully leverages synthetic datasets to avoid sensor-specific biases

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning only the denoising U-Net while preserving the pretrained latent space enables efficient adaptation of diffusion models for metric depth estimation. The latent space from the pretrained Stable Diffusion VAE already captures rich visual priors from internet-scale image collections. By only modifying the U-Net denoiser, the model retains this strong prior while learning to map RGB images to depth maps in latent space.

### Mechanism 2
Log-scaled depth representation addresses the indoor-outdoor depth distribution mismatch and improves model performance. Natural depth distributions span several orders of magnitude (indoor depths <10m vs outdoor depths up to 80m). Log scaling transforms this into a more uniform distribution, allowing the model to allocate representation capacity more effectively across depth ranges.

### Mechanism 3
Training exclusively on photo-realistic synthetic datasets avoids sensor-specific biases and produces sharper depth predictions. Real-world RGB-D datasets contain sensor noise, depth sensor pattern biases, and illumination-induced uncertainty. Synthetic datasets provide clean, consistent depth ground truth without these artifacts, allowing the model to learn true depth distributions.

## Foundational Learning

- **Concept: Latent Diffusion Models**
  - Why needed here: Understanding how diffusion models operate in latent space rather than pixel space is crucial for grasping why MetricGold can efficiently adapt Stable Diffusion for depth estimation
  - Quick check question: What are the computational advantages of operating in latent space versus pixel space for diffusion models?

- **Concept: Variational Autoencoders (VAE)**
  - Why needed here: The VAE encoder and decoder are essential components for translating between pixel space and latent space, and understanding their role is critical for comprehending the architecture
  - Quick check question: How does the VAE bottleneck layer create the latent space that diffusion models operate in?

- **Concept: Log-normalization and data scaling**
  - Why needed here: The log scaling approach is a key innovation for handling the wide range of depth values in indoor and outdoor scenes, and understanding when and why to use log scaling is important for similar problems
  - Quick check question: Why does log scaling help when dealing with data that spans multiple orders of magnitude?

## Architecture Onboarding

- **Component map**: Stable Diffusion v2 backbone → Depth VAE (fine-tuned) → Image VAE (original) → Modified U-Net (fine-tuned) → DDIM sampler for inference
- **Critical path**: RGB image → Image VAE → Image latent code → U-Net (conditioned on image latent) → Depth latent code → Depth VAE → Metric depth map
- **Design tradeoffs**: Using pretrained latent space trades off some domain-specific optimization for significant computational efficiency and leverages internet-scale priors
- **Failure signatures**: Poor depth reconstruction suggests VAE fine-tuning issues; blurry outputs indicate diffusion step problems; scale inconsistencies point to log normalization errors
- **First 3 experiments**:
  1. Validate VAE reconstruction on log-normalized depth from synthetic data
  2. Test U-Net conditioning by training on a single scene type
  3. Compare log vs linear depth scaling on indoor vs outdoor datasets

## Open Questions the Paper Calls Out

### Open Question 1
How does the log-scaled depth representation specifically affect the model's ability to generalize between indoor and outdoor scenes compared to linear scaling? The paper states that log depth "directly addresses the indoor-outdoor depth distribution by applying a scaling function" and that it "allocates more representation capacity to indoor scenes" compared to linear scaling, but lacks quantitative ablation studies comparing log vs linear scaling performance.

### Open Question 2
What is the impact of using latent diffusion models versus direct depth space diffusion (as in DMD) on computational efficiency and inference speed? While the paper claims improved efficiency, it doesn't provide concrete metrics comparing inference times, FLOPs, or memory usage between MetricGold and DMD.

### Open Question 3
How sensitive is MetricGold's performance to the choice of synthetic datasets used for training? The paper trains on HyperSIM, VirtualKitti, and TartanAir but doesn't explore how performance changes when using different combinations or subsets of these datasets.

### Open Question 4
What is the theoretical relationship between the number of diffusion steps used during training (1000) versus inference (50) and the resulting depth estimation quality? The paper uses 1000 training steps but switches to 50-step DDIM at inference without analyzing how different inference step counts affect depth estimation quality.

## Limitations

- Zero-shot generalization performance across diverse real datasets is claimed but not thoroughly validated against established benchmarks
- Training efficiency claim lacks specific configuration details that would enable proper comparison with existing methods
- The superiority of metric depth estimation over relative depth requires more rigorous comparative analysis

## Confidence

**High Confidence (3/5):**
- The core architecture of fine-tuning only the U-Net while preserving the pretrained latent space is technically sound and well-documented
- The use of log-scaled depth representation for handling wide depth ranges is supported by mathematical reasoning
- The synthetic training data approach for avoiding sensor-specific biases is a valid methodology

**Medium Confidence (2/5):**
- Zero-shot generalization claims require more extensive validation across diverse real-world scenarios
- Training efficiency claims need detailed configuration specifications for proper benchmarking
- The superiority of metric depth estimation over relative depth requires more rigorous comparative analysis

**Low Confidence (1/5):**
- The paper does not address potential failure modes when applying the model to scenes with extreme depth ranges
- The impact of VAE fine-tuning quality on final depth reconstruction accuracy is not thoroughly investigated
- The generalization capability beyond the specific synthetic datasets used for training is not well-established

## Next Checks

1. **Benchmark Validation**: Evaluate MetricGold on established depth estimation benchmarks (e.g., NYU Depth V2, KITTI) to verify zero-shot generalization claims and compare against state-of-the-art methods using standard metrics (RMSE, MAE, δ<1.25).

2. **Ablation Study**: Conduct controlled experiments removing key components (log scaling, VAE fine-tuning, synthetic-only training) to quantify their individual contributions to performance and identify potential failure modes.

3. **Cross-Dataset Transfer**: Test the model on datasets from different domains (aerial imagery, underwater scenes, night-time scenes) to assess the limits of synthetic-data-based training and identify scenarios where real-data fine-tuning becomes necessary.