---
ver: rpa2
title: 'MAFIA: Multi-Adapter Fused Inclusive LanguAge Models'
arxiv_id: '2402.07519'
source_url: https://arxiv.org/abs/2402.07519
tags:
- bias
- gender
- debiasing
- language
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MAFIA (Multi-Adapter Fused Inclusive Language
  Models), a method to modularly debias pretrained language models across multiple
  societal dimensions including gender, race, religion, and profession. MAFIA employs
  counterfactual data augmentation (CDA) to generate diverse and inclusive counterfactual
  pairs using structured knowledge bases and generative models.
---

# MAFIA: Multi-Adapter Fused Inclusive LanguAge Models

## Quick Facts
- arXiv ID: 2402.07519
- Source URL: https://arxiv.org/abs/2402.07519
- Reference count: 32
- Multi-bias debiasing approach combining CDA with adapter fusion outperforms single-bias methods

## Executive Summary
MAFIA introduces a modular approach to debiasing pretrained language models across multiple societal dimensions including gender, race, religion, and profession. The method uses Counterfactual Data Augmentation (CDA) with structured knowledge bases and generative models to create diverse training pairs, then trains individual debiasing adapters for each bias dimension. These adapters are combined using AdapterFusion to exploit synergies between different biases while maintaining or improving task performance on semantic textual similarity benchmarks. The approach demonstrates zero-shot cross-lingual transfer of fairness improvements and shows effectiveness on toxicity classification tasks involving unseen bias dimensions.

## Method Summary
MAFIA employs a multi-adapter architecture where each societal bias dimension (gender, race, religion, profession) has its own debiasing adapter trained on counterfactual data augmentation pairs. The CDA process combines Wikidata's structured knowledge with generative models (text-davinci-003) and frequency filtering using Google Books corpus to create diverse counterfactual pairs. Individual debiasing adapters are trained independently using MLM objective, then fused via AdapterFusion to combine signals from multiple bias corrections. The fused adapters are paired with task-specific adapters for downstream applications, allowing modular bias mitigation without modifying base model parameters.

## Key Results
- Outperforms existing baselines on fairness metrics while maintaining or improving task performance on semantic textual similarity benchmarks
- Demonstrates zero-shot cross-lingual transfer of fairness improvements to non-English languages (Marathi) without additional training
- Shows effectiveness on toxicity classification tasks involving unseen bias dimensions
- Modular approach addresses limitations of single-bias methods that rely on limited, US-centric CDA data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured knowledge + generative model pairing reduces coverage gaps in counterfactual pairs
- Mechanism: Wikidata provides seed terms; GPT fills plausible counterfactual mappings; Google Books filters noise
- Core assumption: Wikidata has broad enough coverage; GPT can generate reasonable counterfactuals; Books corpus reliably filters unlikely pairs
- Evidence anchors:
  - [abstract] "We use structured knowledge and a large generative model to build a diverse CDA across multiple bias dimensions in a semi-automated way."
  - [section 2.1] "We use a large structured knowledge base as a starting point. Wikidata’s (Vrandeˇci´c and Krötzsch, 2014) repository of information is rich and diverse, making it an ideal resource for our purpose."
  - [corpus] FMR score: 0.48 → moderate similarity to related debiasing works; no direct comparison evidence
- Break condition: If Wikidata coverage is too narrow or GPT output too noisy, pair count/quality drops sharply

### Mechanism 2
- Claim: AdapterFusion enables modular bias mitigation without task-specific finetuning
- Mechanism: Each debiasing adapter trained independently on CDA; fusion layer learns to combine them per task
- Core assumption: Adapters preserve base model performance; fusion can integrate multiple bias corrections
- Evidence anchors:
  - [abstract] "MAFIA - A soft way to combine multiple debiasing adapters on downstream tasks. The model exploits the synergy between various biases to improve fairness as well as performance on the downstream task."
  - [section 2.3] "All the k debiasing adapters are fused via a trainable AdapterFusion (Pfeiffer et al., 2021) layer and stacked with a task-specific adapter to facilitate further intermixing of signals."
  - [corpus] Moderate FMR suggests MAFIA is in line with but not identical to existing adapter fusion methods
- Break condition: If base model task adapter cannot adequately re-adapt after fusion, downstream performance drops

### Mechanism 3
- Claim: Zero-shot fairness transfer works across languages without retraining
- Mechanism: mBERT pretrained on multilingual data retains bias structure; English debiasing propagates
- Core assumption: Multilingual pretraining captures bias patterns; English debiasing generalizes
- Evidence anchors:
  - [abstract] "We observe zero-shot transfer of gains in fairness and performance by debiasing a multilingual PLM on English."
  - [section 4.3] "Lauscher et al. (2021) observe a zero-shot fairness transfer to non-English languages despite debiasing mBERT with only English data."
  - [corpus] No multilingual debiasing evidence in corpus → assumes mBERT/XLM-R bias transfer holds
- Break condition: If language-specific bias patterns differ significantly, transfer fails

## Foundational Learning

- Concept: Counterfactual Data Augmentation
  - Why needed here: Provides balanced training data to counteract bias in PLMs
  - Quick check question: What happens to bias scores if you train with only original sentences, no counterfactuals?

- Concept: AdapterFusion composition
  - Why needed here: Enables multi-bias debiasing without modifying base model parameters
  - Quick check question: How does AdapterFusion differ from simply stacking adapters sequentially?

- Concept: Zero-shot cross-lingual transfer
  - Why needed here: Allows debiasing gains to apply across languages without per-language retraining
  - Quick check question: Why might debiasing work in English not fully transfer to a low-resource language?

## Architecture Onboarding

- Component map:
  Base LM -> Individual Debiasing Adapters -> AdapterFusion layer -> Task Adapter

- Critical path:
  1. Generate counterfactual pairs via Wikidata + GPT + Books filtering
  2. Train debiasing adapters independently on CDA
  3. Fuse debiasing adapters via AdapterFusion
  4. Train task adapter on downstream task
  5. Evaluate fairness and performance

- Design tradeoffs:
  - Modular adapters vs full model finetuning: adapters preserve base performance but may limit expressivity
  - Comprehensive CDA vs limited pairs: broader coverage but more noise and computational cost
  - Multi-bias fusion vs single bias: better fairness but more complex training

- Failure signatures:
  - Score distributions become too narrow (IDEB models)
  - Task performance drops significantly after debiasing
  - Cross-lingual transfer fails on low-resource languages
  - Fusion weights collapse to trivial values

- First 3 experiments:
  1. Train a single debiasing adapter (gender) on BERT; measure intrinsic and STS-B performance
  2. Train multiple debiasing adapters; fuse via AdapterFusion; measure fairness gains vs baseline
  3. Test zero-shot transfer on a held-out language (e.g., Marathi); compare fairness scores

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal subset of debiasing adapters to fuse for maximizing both fairness and task performance across different bias dimensions?
- Basis in paper: [inferred] The paper shows through ablation studies (Table 11) that fusing all adapters doesn't always yield the best results, and different subsets perform better for different base models.
- Why unresolved: The paper suggests this is an "interesting problem that needs more attention" but doesn't provide a systematic method for determining optimal adapter subsets.
- What evidence would resolve it: Empirical studies comparing different adapter fusion strategies (e.g., using validation sets, automated search methods, or theoretical analysis) to identify patterns in which adapter combinations work best for specific tasks or bias dimensions.

### Open Question 2
- Question: How does the effectiveness of MAFIA generalize to languages beyond the 8 tested (English, French, Italian, Hindi, Tamil, Marathi, Swahili, Gujarati)?
- Basis in paper: [explicit] The authors state they "only explore the interplay between a limited set of biases" and "select a limited set of high and low-resource languages for zero-shot evaluation."
- Why unresolved: The multilingual evaluation was constrained to languages with available translation resources and manual verification capabilities, leaving most of the world's languages untested.
- What evidence would resolve it: Systematic evaluation of MAFIA across a broader typological and resource spectrum of languages, including truly low-resource languages without translation infrastructure.

### Open Question 3
- Question: What is the impact of using larger, more diverse generative models for counterfactual pair generation beyond text-davinci-003?
- Basis in paper: [explicit] The authors note their CF pairs are "limited by the knowledge of text-davinici-003" and suggest exploring other models as a limitation.
- Why unresolved: The study used a single generative model due to computational constraints, and the authors acknowledge this as a limitation without exploring alternatives.
- What evidence would resolve it: Comparative studies using different generative models (both larger and specialized) to generate CF pairs, measuring the impact on debiasing effectiveness and diversity of the resulting datasets.

## Limitations
- CDA approach may struggle with biases requiring nuanced contextual understanding beyond simple entity replacement
- Zero-shot cross-lingual transfer assumes bias patterns behave similarly across languages, which may not hold for underrepresented languages
- Semi-automated approach limited by quality and coverage of knowledge bases and generative models

## Confidence
- **High confidence**: The modular adapter architecture and AdapterFusion approach are well-established methods, and the experimental results showing improved fairness metrics on English tasks are robust.
- **Medium confidence**: The effectiveness of the proposed CDA generation method and its ability to capture diverse bias manifestations is supported by results but limited by the quality and coverage of the knowledge base and filtering mechanisms.
- **Medium confidence**: Cross-lingual transfer results are promising but based on a single held-out language (Marathi) and may not generalize to all language pairs, particularly low-resource languages with different cultural contexts.

## Next Checks
1. **Stress-test CDA generation**: Systematically evaluate the impact of removing each component (Wikidata knowledge base, generative model, frequency filtering) on pair quality and downstream fairness metrics to quantify their individual contributions.
2. **Cross-lingual robustness analysis**: Test zero-shot transfer on additional languages spanning different families and resource levels (e.g., Spanish, Hindi, Swahili) and measure both fairness improvements and task performance degradation.
3. **Adapter fusion ablation study**: Compare the full multi-bias fusion approach against all possible combinations of single and paired bias adapters to identify which synergies are most beneficial and whether certain biases interfere with each other during fusion.