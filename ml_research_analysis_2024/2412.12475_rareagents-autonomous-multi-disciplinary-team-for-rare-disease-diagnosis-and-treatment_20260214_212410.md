---
ver: rpa2
title: 'RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis
  and Treatment'
arxiv_id: '2412.12475'
source_url: https://arxiv.org/abs/2412.12475
tags:
- patient
- diagnosis
- rare
- medical
- diseases
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RareAgents, a novel patient-centered, LLM-driven
  multi-disciplinary team (MDT) framework for rare disease diagnosis and treatment.
  It integrates advanced MDT collaboration, dynamic long-term memory, and medical
  tool utilization, leveraging Llama-3.1 models (8B/70B).
---

# RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment

## Quick Facts
- arXiv ID: 2412.12475
- Source URL: https://arxiv.org/abs/2412.12475
- Reference count: 40
- Outperforms state-of-the-art models on RareBench and MIMIC-IV-Ext-Rare for rare disease diagnosis and treatment

## Executive Summary
RareAgents is a patient-centered, LLM-driven multi-disciplinary team (MDT) framework designed for rare disease diagnosis and treatment. It integrates MDT collaboration, dynamic long-term memory, and medical tool utilization using Llama-3.1 models (8B/70B). Evaluated on RareBench and MIMIC-IV-Ext-Rare, RareAgents demonstrates superior performance over domain-specific models, GPT-4o, and existing medical agent frameworks, achieving significant improvements in both differential diagnosis and medication recommendation for rare diseases.

## Method Summary
RareAgents employs a plug-and-play framework using Llama-3.1 models as the base, enhanced with three core components: multi-disciplinary team collaboration (41 specialist agents), dynamic long-term memory (retrieving similar cases and historical records), and medical tool utilization (diagnostic and therapeutic tools like Phenomizer, LIRICAL, Phenobrain, DrugBank, and DDI-graph). The system coordinates specialist agents through an attending physician agent, maintains personalized memory for each agent, and accesses external medical tools to enhance clinical reasoning and ensure medication safety.

## Key Results
- Achieves superior performance over state-of-the-art domain-specific models, GPT-4o, and existing medical agent frameworks
- Significant improvements in differential diagnosis (Hit@k metrics and median rank) on RareBench
- Enhanced medication recommendation accuracy with lower Drug-Drug Interaction rates on MIMIC-IV-Ext-Rare

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-disciplinary team (MDT) collaboration improves diagnostic accuracy by integrating specialized expertise.
- Mechanism: The attending physician agent selects specialists from a predefined pool of 41 departments based on patient symptoms, and these specialists engage in multi-turn discussions to reach consensus.
- Core assumption: Specialist agents with domain-specific knowledge can provide more accurate diagnoses when collaborating than a single generalist agent.
- Evidence anchors:
  - [abstract] "RareAgents integrates advanced Multidisciplinary Team (MDT) coordination, memory mechanisms, and medical tools utilization"
  - [section] "In contrast, our approach mirrors real-world clinical practice by leveraging specialist departments commonly involved in rare disease cases"
  - [corpus] Found 25 related papers - weak direct evidence for MDT-specific improvements
- Break condition: If specialist agents cannot effectively communicate or if the consensus mechanism fails to synthesize diverse opinions.

### Mechanism 2
- Claim: Dynamic long-term memory enhances decision-making by retrieving similar cases and historical records.
- Mechanism: Each agent maintains personalized long-term memory built from past consultation processes, allowing retrieval of similar patients or prior records for current decision-making.
- Core assumption: Historical patient cases and prior visit records contain relevant information that can inform current diagnoses and treatments.
- Evidence anchors:
  - [abstract] "integrates advanced planning capabilities, memory mechanisms, and medical tools utilization"
  - [section] "These memories, built from past consultation processes, act as dynamic experience bases that can be retrieved and updated continuously"
  - [corpus] Weak direct evidence - general memory mechanism studies but not rare disease specific
- Break condition: If the memory retrieval mechanism cannot find sufficiently similar cases or if the retrieved information is irrelevant.

### Mechanism 3
- Claim: Medical tool utilization improves safety and accuracy by providing domain-specific knowledge and validation.
- Mechanism: Physician agents access diagnostic tools (Phenomizer, LIRICAL, Phenobrain) and therapeutic tools (DrugBank, DDI-graph) to support clinical reasoning and ensure medication safety.
- Core assumption: External medical tools contain validated knowledge that can enhance agent decision-making and reduce errors.
- Evidence anchors:
  - [abstract] "leveraging Llama-3.1-8B/70B as the base model" and "integrating advanced planning capabilities, memory mechanisms, and medical tools utilization"
  - [section] "Similarly, the physician agents in RareAgents have access to diagnostic and therapeutic tools to enhance their clinical reasoning capabilities"
  - [corpus] Weak direct evidence - general tool utilization in LLMs but not specifically for rare disease diagnosis
- Break condition: If tool outputs are inconsistent with clinical reality or if agents cannot effectively interpret tool feedback.

## Foundational Learning

- Concept: Multi-agent collaboration and role definition
  - Why needed here: The system requires understanding how to coordinate multiple specialized agents to achieve consensus on complex medical decisions
  - Quick check question: How does the attending physician agent determine which specialists to include in the MDT for a given patient case?

- Concept: Memory retrieval and contextualization
  - Why needed here: Agents must effectively retrieve and apply historical patient data to current cases without simply copying past solutions
  - Quick check question: What criteria does the system use to determine which historical cases are most similar to the current patient?

- Concept: Tool integration and API utilization
  - Why needed here: The framework depends on external medical tools for validation and additional knowledge, requiring understanding of how to call and interpret these tools
  - Quick check question: How does the system handle conflicting outputs from different diagnostic tools?

## Architecture Onboarding

- Component map: Patient Agent -> Attending Physician Agent -> Specialist Pool (41 departments) -> Dynamic Long-term Memory -> Medical Tools (Phenomizer, LIRICAL, Phenobrain, DrugBank, DDI-graph) -> LLM Base Model (Llama-3.1)

- Critical path: 1. Patient Agent provides clinical information 2. Attending Physician Agent forms MDT based on symptoms 3. Specialists engage in multi-turn discussions with memory retrieval and tool utilization 4. Attending Physician Agent synthesizes consensus into final decision

- Design tradeoffs:
  - Predefined vs. LLM-generated specialist roles: Predefined roles ensure domain expertise but reduce flexibility
  - Memory retrieval vs. fresh analysis: Memory provides context but may bias current decisions
  - Tool dependence vs. autonomy: Tools enhance accuracy but increase system complexity

- Failure signatures:
  - MDT coordination failure: Incomplete specialist selection or consensus deadlock
  - Memory retrieval issues: Retrieval of irrelevant cases or failure to find similar cases
  - Tool integration problems: Incorrect tool calls, misinterpreted outputs, or tool unavailability

- First 3 experiments:
  1. Single-agent baseline vs. MDT with 3 specialists on simplified cases to validate collaboration benefits
  2. Memory ablation study: Compare performance with random vs. dynamic case retrieval on rare disease diagnosis
  3. Tool utilization test: Measure impact of individual diagnostic tools on diagnostic accuracy in controlled scenarios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RareAgents compare when using different LLM base models (e.g., Llama-3.1 vs. UltraMedical vs. OpenBioLLM) for rare disease diagnosis and treatment?
- Basis in paper: [explicit] The paper states that "Among the fine-tuned models, UltraMedical performs better than the base Llama-3.1, while OpenBioLLM shows a decline in performance. This suggests that fine-tuned models may not generalize well to all medical tasks, with their effectiveness highly dependent on the fine-tuning data and methods."
- Why unresolved: While the paper provides some comparative performance data, it does not conduct a comprehensive evaluation of RareAgents using different LLM base models, leaving the optimal choice for rare disease tasks unclear.
- What evidence would resolve it: A systematic evaluation of RareAgents with various LLM base models, including both general and medical-specific LLMs, across multiple rare disease datasets and tasks would provide clear evidence of the optimal model choice.

### Open Question 2
- Question: What is the impact of increasing the number of retrieved cases from long-term memory beyond 5 on the diagnostic performance of RareAgents?
- Basis in paper: [inferred] The paper mentions that "RareAgents achieves significant performance improvements by retrieving only a small number of similar cases or previous visit records (e.g., just 5 cases). Conversely, random retrieval offers limited utility even when retrieving a vast number of cases."
- Why unresolved: The paper only tests the impact of retrieving 5 cases from long-term memory and does not explore the effects of retrieving more cases, leaving the optimal number of retrieved cases unclear.
- What evidence would resolve it: An ablation study that systematically varies the number of retrieved cases from long-term memory (e.g., 1, 3, 5, 10, 20) and evaluates the impact on diagnostic performance would provide evidence of the optimal number of retrieved cases.

### Open Question 3
- Question: How does the performance of RareAgents change when incorporating multimodal data (e.g., medical imaging, genotypic information) alongside textual EHR data for rare disease diagnosis and treatment?
- Basis in paper: [explicit] The paper acknowledges that "it is important to acknowledge that the diagnosis and treatment of rare diseases often benefit from integrating multimodal data, such as medical imaging and genotypic information."
- Why unresolved: The current implementation of RareAgents focuses solely on textual data from EHRs, and the paper does not explore the potential benefits of incorporating multimodal data.
- What evidence would resolve it: A modified version of RareAgents that integrates multimodal data (e.g., medical imaging, genotypic information) alongside textual EHR data, followed by an evaluation of its performance compared to the original RareAgents, would provide evidence of the benefits of multimodal data integration.

## Limitations
- The performance improvements may be partly attributable to specific implementation details of MDT coordination, memory mechanisms, and tool integration that are not fully specified
- Evaluation focuses on specific datasets (RareBench and MIMIC-IV-Ext-Rare) and may not generalize to other rare disease contexts or clinical settings
- The generalizability of results to real-world clinical practice remains uncertain

## Confidence
- **High Confidence**: The overall performance improvements over baseline models and existing frameworks are well-supported by the experimental results
- **Medium Confidence**: The mechanisms of MDT collaboration, memory retrieval, and tool utilization are plausible but lack detailed implementation specifications
- **Low Confidence**: The generalizability of results to real-world clinical practice and other rare disease datasets remains uncertain

## Next Checks
1. **Reproducibility Audit**: Implement a minimal version of the MDT framework with 3-5 specialist agents on a simplified rare disease dataset to verify the core collaboration mechanism works as described
2. **Memory Retrieval Validation**: Test the dynamic memory system on cases with known similar historical records to confirm that retrieved information actually improves diagnostic accuracy
3. **Tool Integration Robustness**: Evaluate the system's performance when individual medical tools are unavailable or return inconsistent results to assess dependency risks