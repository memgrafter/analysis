---
ver: rpa2
title: Federated Class-Incremental Learning with Hierarchical Generative Prototypes
arxiv_id: '2406.02447'
source_url: https://arxiv.org/abs/2406.02447
tags:
- learning
- federated
- each
- clients
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes Hierarchical Generative Prototypes (HGP) for
  Federated Class-Incremental Learning (FCIL), addressing the problems of Incremental
  Bias and Federated Bias that cause performance degradation in FCIL settings. HGP
  uses prompt learning to constrain both biases within the last layer, producing less
  biased representations and more biased classifiers.
---

# Federated Class-Incremental Learning with Hierarchical Generative Prototypes

## Quick Facts
- arXiv ID: 2406.02447
- Source URL: https://arxiv.org/abs/2406.02447
- Authors: Riccardo Salami; Pietro Buzzega; Matteo Mosconi; Mattia Verasani; Simone Calderara
- Reference count: 40
- One-line primary result: HGP improves state-of-the-art FCIL performance by +7.9% average accuracy

## Executive Summary
This work introduces Hierarchical Generative Prototypes (HGP) for Federated Class-Incremental Learning (FCIL), addressing two critical biases: Incremental Bias (catastrophic forgetting) and Federated Bias (feature drift across clients). HGP uses prompt learning to confine biases to the classification layer while leveraging generative prototypes to rebalance class-conditional distributions. The method significantly outperforms existing FCIL approaches on CIFAR-100 and Tiny-ImageNet datasets while maintaining low communication costs.

## Method Summary
HGP operates in a federated learning setting where clients train on local data using learnable prompts with a frozen ViT-B/16 backbone. The method employs hierarchical generative prototypes that model class-conditional distributions as Gaussian mixtures across clients. During federated aggregation, the server computes global Gaussian Mixture Models (GMMs) using Jensen-Shannon Divergence, generates synthetic balanced data, and performs classifier rebalancing. The updated classifier is then redistributed to clients, enabling effective handling of distribution shifts and label imbalances without sharing raw data.

## Key Results
- Achieves +7.9% average accuracy improvement over state-of-the-art FCIL methods
- Maintains low communication costs by transmitting only prompts and classification heads
- Approaches performance of models trained on global data distributions
- Effectively handles both distribution shifts and label imbalances across clients

## Why This Works (Mechanism)

### Mechanism 1
- Prompting confines bias to the last layer, reducing federated bias in feature representations
- Core assumption: Pre-trained backbone captures generalizable features
- Break condition: If pre-trained features are not generalizable to the target task

### Mechanism 2
- Hierarchical Generative Prototypes rebalance classifiers by modeling class-conditional distributions
- Core assumption: Class distributions can be adequately modeled by multivariate Gaussians
- Break condition: If feature distributions are multi-modal or non-Gaussian

### Mechanism 3
- Combining prompting with classifier rebalancing reverses the performance gap between fine-tuning and prompting
- Core assumption: Classifier bias is the dominant factor in performance degradation when using prompting
- Break condition: If feature bias contributes significantly to performance degradation

## Foundational Learning

- Concept: Federated Learning - distributed training across clients while preserving data privacy
  - Why needed here: The entire method operates in a federated setting where clients cannot share raw data
  - Quick check question: What is the primary challenge that federated learning addresses compared to centralized training?

- Concept: Continual Learning - learning from sequential tasks without forgetting previous knowledge
  - Why needed here: The method must handle class-incremental learning where new classes are introduced over time
  - Quick check question: How does catastrophic forgetting manifest in class-incremental learning scenarios?

- Concept: Prompt-based fine-tuning - adapting pre-trained models through learnable prompts
  - Why needed here: Enables efficient communication and bias confinement to the classification layer
  - Quick check question: What is the key difference between prompt-based fine-tuning and traditional fine-tuning in terms of parameter updates?

## Architecture Onboarding

- Component map: Backbone (frozen ViT-B/16) -> Prompts (N learnable key/value pairs) -> Classifier (task-specific heads) -> Generative prototypes (Gaussian distributions) -> Server (aggregates and rebalances)

- Critical path: Clients train on local data using prompts → Clients send prompts and prototypes to server → Server aggregates parameters and computes global GMM → Server generates synthetic data and rebalances classifier → Updated classifier distributed back to clients

- Design tradeoffs: Prompting vs. full fine-tuning (lower communication cost vs. potentially higher accuracy), Gaussian assumption (simplicity vs. potential modeling inaccuracy), prototype-based vs. real data (privacy preservation vs. potential information loss)

- Failure signatures: Poor performance on new classes (insufficient prompt adaptation), high variance across clients (inadequate feature bias reduction), degraded performance over tasks (ineffective classifier rebalancing)

- First 3 experiments: 1) Compare prompting vs. fine-tuning on a single task to verify bias confinement, 2) Test hierarchical GMM sampling with synthetic data to validate rebalancing, 3) Evaluate communication efficiency by measuring parameter exchange vs. accuracy gain

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HGP scale with larger pre-trained backbones beyond ViT-B/16?
- Basis in paper: [explicit] The paper uses ViT-B/16 as the backbone and notes that prompting allows using arbitrarily sized backbones while keeping communication costs restrained.
- Why unresolved: The paper only experiments with ViT-B/16 and does not explore performance variations with larger or smaller backbone architectures.
- What evidence would resolve it: Systematic experiments comparing HGP performance using different backbone sizes (e.g., ViT-L/16, ViT-H/14) while measuring both accuracy and communication costs.

### Open Question 2
- Question: What is the optimal number of prompts per task for balancing performance and communication efficiency?
- Basis in paper: [explicit] The paper uses 10 prompts per task but mentions that L2P uses fewer prompts than CODA-P, suggesting variability in prompt usage across methods.
- Why unresolved: The paper does not explore sensitivity to the number of prompts or provide guidance on optimal prompt count for different scenarios.
- What evidence would resolve it: Ablation studies varying the number of prompts per task (e.g., 5, 10, 20) and measuring the trade-off between accuracy gains and increased communication costs.

### Open Question 3
- Question: What is the impact of different prompt initialization strategies on HGP's performance?
- Basis in paper: [explicit] The paper uses prefix-tuning with learnable prompts but does not discuss initialization strategies for these prompts.
- Why unresolved: The paper does not explore whether different initialization methods (e.g., random, supervised, self-supervised) affect the convergence speed or final performance of HGP.
- What evidence would resolve it: Comparative experiments initializing prompts using different strategies while keeping other components constant, measuring both convergence speed and final accuracy.

## Limitations
- Gaussian distribution assumption may not hold for complex real-world datasets
- Hierarchical aggregation may suffer from numerical instability with sparse client-class distributions
- Performance on highly heterogeneous client data distributions is not fully explored

## Confidence
- High Confidence: Basic mechanism of using prompts to confine bias to classification layer
- Medium Confidence: Specific combination of prompting with hierarchical classifier rebalancing
- Low Confidence: Claim of +7.9% average accuracy improvement across all FCIL scenarios

## Next Checks
1. Test the method with datasets known to have multi-modal class distributions to verify if the Gaussian assumption breaks down
2. Measure the actual parameter exchange volume during federated training and compare it against traditional fine-tuning methods
3. Evaluate HGP's performance on highly non-IID data distributions where client data varies significantly in both class distribution and feature space characteristics