---
ver: rpa2
title: 'LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language
  Models'
arxiv_id: '2407.08966'
source_url: https://arxiv.org/abs/2407.08966
tags:
- detection
- data
- prompt
- samples
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses out-of-distribution (OOD) detection using
  vision-language models (VLMs), where the challenge lies in manual prompt engineering
  for optimal performance. The authors propose LAPT, a label-driven automated prompt
  tuning approach that autonomously learns effective prompts using only in-distribution
  (ID) class names.
---

# LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models

## Quick Facts
- arXiv ID: 2407.08966
- Source URL: https://arxiv.org/abs/2407.08966
- Reference count: 40
- Authors: Yabin Zhang; Wenjie Zhu; Chenhang He; Lei Zhang
- Key outcome: LAPT achieves new state-of-the-art OOD detection results, exceeding best hand-crafted prompts by 10.76% in FPR95 and 5.71% in AUROC on near-OOD detection using ImageNet-1k

## Executive Summary
This paper addresses the challenge of out-of-distribution (OOD) detection using vision-language models (VLMs), specifically targeting the labor-intensive manual prompt engineering typically required for optimal performance. The authors propose LAPT, a label-driven automated prompt tuning approach that autonomously learns effective prompts using only in-distribution class names. By constructing distribution-aware prompts through appending learnable tokens to both ID and automatically mined negative class labels, LAPT eliminates the need for manual prompt crafting while significantly improving OOD detection performance.

The method employs a cross-entropy loss with cross-modal and cross-distribution mixing strategies to optimize the learned prompts, collecting training images through text-to-image generation and retrieval methods. Extensive experiments demonstrate that LAPT significantly outperforms manually crafted prompts across multiple OOD detection benchmarks, establishing new state-of-the-art results and particularly excelling in challenging near-OOD detection scenarios.

## Method Summary
LAPT addresses OOD detection by autonomously learning distribution-aware prompts for vision-language models. The approach constructs prompts by appending learnable tokens to both in-distribution class names and automatically mined negative labels. Training images are collected via text-to-image generation models and retrieval methods, then used to optimize prompts using cross-entropy loss with cross-modal mixing (blending image and text features) and cross-distribution mixing (exploring intermediate space between ID and negative distributions). This automated process eliminates manual prompt engineering while achieving superior OOD detection performance.

## Key Results
- Achieves new state-of-the-art OOD detection results across multiple benchmarks
- Outperforms best hand-crafted prompts by 10.76% in FPR95 and 5.71% in AUROC on near-OOD detection with ImageNet-1k
- Significantly improves upon manually crafted prompts while maintaining competitive in-distribution accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LAPT autonomously generates distribution-aware prompts by appending learnable tokens to class labels, eliminating manual prompt engineering.
- Mechanism: Learnable context tokens are optimized using cross-entropy loss on images collected via text-to-image generation and retrieval, guided by ID class names and automatically mined negative labels.
- Core assumption: CLIP-like models can align generated/retrieved images with their class labels in the joint embedding space, making the images suitable for prompt optimization.
- Evidence anchors:
  - [abstract] "develop distribution-aware prompts with in-distribution (ID) class names and negative labels mined automatically"
  - [section] "we append distribution-aware prompt tokens to these class labels. These learnable tokens are optimized with minimal human intervention by aggregating training images associated with class labels using pre-trained text-to-image generation models"
- Break condition: If generated/retrieved images fail to semantically match their labels, the learned prompts will not improve OOD detection performance.

### Mechanism 2
- Claim: Cross-modal mixing reduces image noise by blending visual and textual features from the same class.
- Mechanism: For each training sample, the method creates a mixed feature by interpolating between the image representation and the text representation of its class label, using a Beta-distributed mixing weight.
- Core assumption: The text representation of a class label is less noisy than the image representation, so blending them yields a more robust training signal.
- Evidence anchors:
  - [section] "To mitigate the impact of image noise, we introduce a cross-modal mixing strategy to neutralize potential noise in the images...mixing textual and visual representations, we aim to create a more robust feature set"
- Break condition: If the text representation is equally or more noisy than the image representation, cross-modal mixing could degrade performance.

### Mechanism 3
- Claim: Cross-distribution mixing explores the intermediate space between ID and negative distributions, improving OOD detection boundary awareness.
- Mechanism: The method creates synthetic training examples by interpolating between features and labels from ID and negative classes, using a Beta-distributed mixing weight.
- Core assumption: The space between ID and negative distributions contains informative samples that help the model learn a sharper decision boundary.
- Evidence anchors:
  - [section] "we employ the data mixing strategy to explore a broader feature space...This mixing strategy effectively bridges the distribution gap, generating a continuous spectrum of features that extend from ID to negative areas"
- Break condition: If the intermediate space is uninformative or contains ambiguous samples, mixing could confuse the model.

## Foundational Learning

- Concept: Vision-Language Models (VLMs) like CLIP align images and text in a shared embedding space using contrastive learning.
  - Why needed here: LAPT relies on CLIP's ability to embed both images and class names into the same feature space so that prompts can be optimized via cross-entropy on collected images.
  - Quick check question: What is the role of the text encoder in CLIP's architecture, and how does it enable zero-shot classification?

- Concept: Automated prompt tuning replaces hand-crafted prompts with learnable token sequences optimized for a downstream task.
  - Why needed here: Manual prompt engineering is labor-intensive and sensitive to linguistic nuances; LAPT automates this to improve robustness and scalability.
  - Quick check question: How does adding learnable context tokens to a class name change the prompt embedding in CLIP's text encoder?

- Concept: Data mixing (cross-modal and cross-distribution) is a form of augmentation that can improve model generalization by exposing it to blended samples.
  - Why needed here: LAPT uses mixing to reduce noise in image features and to explore the boundary between ID and negative distributions.
  - Quick check question: In what way does mixing a visual feature with its corresponding textual feature differ from mixing two visual features from different classes?

## Architecture Onboarding

- Component map: NegLabel module -> Sample collector -> Prompt constructor -> Trainer -> OOD detector
- Critical path: 1. Mine negative labels from corpus 2. Collect per-class training images (real or synthetic) 3. Initialize learnable prompts with random tokens 4. Optimize prompts using mixed training data 5. Deploy with NegLabel scoring for OOD detection
- Design tradeoffs:
  - Real vs. synthetic image collection: Real images are more diverse but less consistent with text; synthetic images are consistent but less diverse
  - Prompt length: Longer prompts increase capacity but risk overfitting to noise
  - Mixing strategy: More aggressive mixing can improve robustness but may blur class boundaries if overdone
- Failure signatures:
  - Poor OOD detection: Likely caused by insufficient or noisy training images, or ineffective prompt initialization
  - Degraded ID accuracy: May indicate over-regularization from mixing or misaligned prompts
  - High variance in results: Often due to randomness in image generation/retrieval or prompt initialization
- First 3 experiments:
  1. Ablation study: Compare learned prompts vs. fixed NegLabel prompts on FPR95 and AUROC
  2. Mixing study: Evaluate impact of cross-modal and cross-distribution mixing on both OOD detection and ID classification
  3. Collection method study: Compare real vs. synthetic image collection and their combination on downstream performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LAPT's performance scale with the size of the negative label set? Is there a point of diminishing returns?
- Basis in paper: [inferred] The paper mentions mining negative labels from "extensive text corpora" but doesn't explore how performance changes with different amounts of negative data.
- Why unresolved: The paper only mentions using negative labels mined from "extensive text corpora" without quantifying or analyzing the impact of different negative label set sizes on OOD detection performance.
- What evidence would resolve it: Experiments showing OOD detection performance (e.g., AUROC, FPR95) across different sizes of negative label sets, identifying the optimal size and any diminishing returns.

### Open Question 2
- Question: How does LAPT perform on datasets with highly imbalanced class distributions in the ID data?
- Basis in paper: [inferred] The paper evaluates on ImageNet-1k and mentions evaluating on "smaller-scaled ID datasets" in supplementary materials, but doesn't discuss class imbalance scenarios.
- Why unresolved: The paper focuses on balanced datasets like ImageNet-1k without exploring scenarios where certain classes are underrepresented in the ID data.
- What evidence would resolve it: Experiments testing LAPT on datasets with varying degrees of class imbalance in the ID data, analyzing performance degradation or improvements compared to balanced scenarios.

### Open Question 3
- Question: What is the computational overhead of LAPT compared to traditional OOD detection methods during inference?
- Basis in paper: [explicit] The paper mentions "time complexity" as an analysis point in supplementary materials but doesn't provide specific comparisons.
- Why unresolved: While the paper extensively discusses training aspects, it doesn't quantify the inference-time computational cost of LAPT relative to baseline methods.
- What evidence would resolve it: Detailed benchmarking showing inference time and computational resources (e.g., FLOPs, memory) for LAPT compared to traditional OOD detection methods like MSP, ODIN, and energy-based approaches.

## Limitations

- The quality of learned prompts heavily depends on the quality of mined negative labels and collected training images, but the robustness of these components is not extensively validated
- The paper doesn't provide direct ablation studies to quantify the specific contributions of cross-modal and cross-distribution mixing strategies
- Implementation details for critical components like the NegMine function and image generation/retrieval configuration are not fully specified, affecting reproducibility

## Confidence

- **High Confidence**: The claim that LAPT significantly outperforms manually crafted prompts on multiple OOD detection benchmarks, supported by quantitative results (e.g., 10.76% improvement in FPR95, 5.71% in AUROC on near-OOD detection)
- **Medium Confidence**: The effectiveness of cross-modal and cross-distribution mixing strategies in improving OOD detection, as the paper assumes their benefits based on standard practices without providing direct ablation studies
- **Low Confidence**: The reliability and scalability of the automated prompt tuning process, particularly in terms of the quality of mined negative labels and the consistency of collected training images

## Next Checks

1. **Ablation Study on Mining and Collection Methods**: Conduct experiments to evaluate the impact of different negative label mining strategies and image collection methods (real vs. synthetic) on the final OOD detection performance. This will help determine the robustness of LAPT to variations in these components.

2. **Direct Evaluation of Mixing Strategies**: Perform ablation studies specifically targeting the cross-modal and cross-distribution mixing strategies. Assess their individual and combined effects on both OOD detection and in-distribution classification accuracy to quantify their contributions.

3. **Reproducibility and Scalability Test**: Attempt to reproduce the results using a different set of ID classes or datasets, and test the scalability of LAPT by increasing the number of classes or the complexity of the task. This will help validate the generalizability and practical applicability of the proposed method.