---
ver: rpa2
title: 'TowerDebias: A Novel Unfairness Removal Method Based on the Tower Property'
arxiv_id: '2411.08297'
source_url: https://arxiv.org/abs/2411.08297
tags:
- fairness
- correlation
- machine
- learning
- towerdebias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TowerDebias (tDB), a post-processing method
  to reduce bias from sensitive attributes in predictions from black-box machine learning
  models. The core idea is to estimate E(Y|X) by averaging the model's predictions
  E(Y|X,S) over S for each value of X, leveraging the Tower Property from probability
  theory.
---

# TowerDebias: A Novel Unfairness Removal Method Based on the Tower Property

## Quick Facts
- **arXiv ID**: 2411.08297
- **Source URL**: https://arxiv.org/abs/2411.08297
- **Reference count**: 14
- **Primary result**: Achieves up to 50% reduction in correlation between predictions and sensitive attributes with <5% accuracy loss

## Executive Summary
TowerDebias (tDB) introduces a novel post-processing method to reduce bias from sensitive attributes in black-box machine learning models. The approach leverages the Tower Property from probability theory to estimate E(Y|X) by averaging the model's predictions E(Y|X,S) over S for each value of X. This method requires no access to the model's internal structure or retraining, making it highly versatile for existing deployed systems.

The method was evaluated across five diverse datasets using multiple algorithms, demonstrating significant fairness improvements while maintaining predictive accuracy. Results show substantial reductions in correlation between predictions and sensitive attributes, addressing a critical need in algorithmic fairness. The approach works for both regression and classification tasks with binary and categorical sensitive attributes.

## Method Summary
TowerDebias is a post-processing method that reduces bias from sensitive attributes in predictions from black-box ML models. The core technique leverages the Tower Property of probability theory, which states that E(Y|X) = E[E(Y|X,S)|X]. By averaging E(Y|X,S) predictions across all values of S while holding X constant, the method recovers E(Y|X), which is independent of S. The approach uses k-nearest neighbors to find cases with similar X values and averages predictions over these neighbors, requiring only access to the black-box model's predictions without needing internal structure knowledge.

## Key Results
- Achieved up to 50% reduction in correlation between predictions and sensitive attributes
- Maintained minimal accuracy loss with typically <5% increase in error metrics
- Demonstrated effectiveness across five datasets (SVCensus, Law School Admissions, COMPAS, Iranian Churn, Dutch Census)
- Worked with multiple algorithms (linear/logistic regression, k-NN, XGBoost, Random Forests, neural networks)
- Validated on both regression and classification tasks with binary and categorical sensitive attributes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TowerDebias removes the influence of sensitive attributes by averaging predictions over those attributes
- Mechanism: The method leverages the Tower Property of probability theory, which states that E(Y|X) = E[E(Y|X,S)|X]. By averaging E(Y|X,S) predictions across all values of S while holding X constant, the method recovers E(Y|X), which is independent of S
- Core assumption: The data-generating process follows a multivariate normal distribution involving (X, S, Y)
- Evidence anchors:
  - [abstract] "Our tDB approach leverages the Tower Property from probability theory to improve prediction fairness"
  - [section 3] "The Tower Property in probability theory is key here...averaging E(Y|X,S) over S while fixing X gives us E(Y|X)"
  - [corpus] Weak - no direct citations of the Tower Property in related papers
- Break condition: If the multivariate normality assumption is violated, or if the black-box model's predictions E(Y|X,S) are systematically biased in ways that don't average out

### Mechanism 2
- Claim: The method reduces correlation between predictions and sensitive attributes without retraining
- Mechanism: By computing predictions using k-nearest neighbors to find cases with similar X values, the method averages over the sensitive attribute S, which mathematically reduces the correlation ρ(E(Y|X), S) ≤ ρ(E(Y|X,S), S)
- Core assumption: The k-NN averaging provides a good approximation of the true E(Y|X)
- Evidence anchors:
  - [section 4.4] "we wish to show that ρ(E(Y|X), S) ≤ ρ(E(Y|X, S), S)" with formal proof
  - [section 5] "tDB achieving substantial reductions" with empirical results showing 50% correlation reduction
  - [corpus] Weak - no direct citations of correlation reduction through averaging methods
- Break condition: If k is too small (high variance) or too large (excessive bias), or if sensitive attributes are perfectly correlated with X features

### Mechanism 3
- Claim: The method works as post-processing without requiring model access
- Mechanism: TowerDebias only requires access to the black-box model's predictions, not its internal structure or training data, making it applicable to any existing model
- Core assumption: The model can be queried to obtain predictions for any input (X,S)
- Evidence anchors:
  - [abstract] "This method is highly versatile, as it requires no prior knowledge of the original algorithm's internal structure"
  - [section 1.1] "how can we mitigate or eliminate the influence of S in such situations?"
  - [corpus] Weak - no direct citations of model-agnostic post-processing approaches
- Break condition: If the black-box model cannot be queried or has access restrictions, or if prediction generation is computationally prohibitive

## Foundational Learning

- Concept: Tower Property of conditional expectation
  - Why needed here: This is the mathematical foundation that justifies why averaging E(Y|X,S) over S recovers E(Y|X)
  - Quick check question: If E(Y|X=4) = E[E(Y|4,S)|X=4], what does this tell us about the relationship between conditional expectations?

- Concept: Pearson correlation coefficient
  - Why needed here: The paper uses correlation reduction as the primary fairness metric
  - Quick check question: If correlation between predictions and sensitive attribute drops from 0.25 to 0.1, what percentage reduction is achieved?

- Concept: k-Nearest Neighbors approximation
  - Why needed here: Since we work with sample data, we need an approximation method to compute E(Y|X) when exact matches may not exist
  - Quick check question: What trade-off does increasing k create between bias and variance in the approximation?

## Architecture Onboarding

- Component map: Black-box model → k-NN search engine → averaging module → fairness evaluation
- Critical path: Input X → Find k nearest neighbors with same X → Query black-box for each (X,S) → Average predictions → Output debiased prediction
- Design tradeoffs: Small k preserves local structure but increases variance; large k reduces variance but may introduce bias by including dissimilar cases
- Failure signatures: Correlation not decreasing despite tDB application (check k value, check model access), accuracy degradation beyond acceptable threshold (check k value)
- First 3 experiments:
  1. Test on a simple synthetic dataset where E(Y|X) is known, verify correlation reduction
  2. Apply to SVCensus dataset with k=5, measure correlation reduction and MAPE change
  3. Test sensitivity to k by running across range k=1 to k=50, plot fairness-utility tradeoff curve

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal choice of k in the k-NN component of tDB that balances fairness improvements with predictive accuracy across different types of datasets and machine learning algorithms?
- Basis in paper: [explicit] The paper states "The key question now is how to select an appropriate value of k based on the given application and the black-box method being used" and discusses that k affects the bias-variance trade-off which influences fairness-utility trade-off.
- Why unresolved: The paper demonstrates that correlation reductions plateau after a certain point while accuracy losses increase, but does not provide a systematic method for determining optimal k values across different contexts.
- What evidence would resolve it: A comprehensive study testing various k values across diverse datasets and algorithms to establish guidelines or adaptive methods for k selection based on dataset characteristics.

### Open Question 2
- Question: How does tDB perform when applied to datasets with multiple sensitive attributes that may interact in complex ways?
- Basis in paper: [explicit] The paper mentions that "The m-class case can be handled using m dichotomous variables" but only provides empirical results for single sensitive attributes or binary combinations.
- Why unresolved: The paper's empirical evaluation focuses on single sensitive attributes (gender, race, age) and simple combinations (gender & age), without testing complex interactions between multiple sensitive attributes.
- What evidence would resolve it: Experimental results showing tDB's performance on datasets with multiple interacting sensitive attributes and comparison with other fairness methods designed for multi-attribute scenarios.

### Open Question 3
- Question: Can tDB be effectively extended to handle continuous sensitive attributes beyond simple correlation reduction, such as when fairness requires maintaining specific statistical properties?
- Basis in paper: [explicit] The paper mentions extending analysis to continuous sensitive variables (age) but focuses on correlation reduction, and states "The importance of algorithmic fairness is clear across various applications."
- Why unresolved: While the paper shows correlation reduction works for continuous attributes like age, it does not explore more sophisticated fairness requirements for continuous sensitive attributes beyond correlation metrics.
- What evidence would resolve it: Demonstrations of tDB achieving fairness metrics beyond correlation (such as statistical parity or equal opportunity) when applied to continuous sensitive attributes, and theoretical analysis of its limitations.

## Limitations
- Performance depends critically on the choice of k, with no clear guidance for optimal selection across different contexts
- Effectiveness may be limited when sensitive attributes are highly correlated with input features (X)
- Computational cost of querying black-box models multiple times per data point could be prohibitive for large-scale applications

## Confidence

- **Mechanism 1 (Tower Property)**: Medium - The mathematical framework is sound but relies on assumptions about data distribution that may not hold in practice
- **Mechanism 2 (Correlation Reduction)**: High - Empirical results consistently show significant correlation reductions across multiple datasets and algorithms
- **Mechanism 3 (Model Agnostic)**: Medium - While theoretically applicable to any black-box model, practical implementation may face access restrictions or computational constraints

## Next Checks

1. **Sensitivity Analysis**: Systematically test TowerDebias performance across a range of k values (1-100) on synthetic datasets where ground truth E(Y|X) is known, to quantify the bias-variance tradeoff and identify optimal k ranges for different data distributions

2. **Correlation Threshold Testing**: Evaluate TowerDebias effectiveness when initial correlation between predictions and sensitive attributes exceeds 0.5, as the paper primarily tested cases with lower initial correlations

3. **Feature Correlation Stress Test**: Create synthetic datasets where sensitive attributes are deliberately made highly correlated with input features (ρ > 0.7) to determine the method's breaking point and assess whether alternative approaches would be needed in these scenarios