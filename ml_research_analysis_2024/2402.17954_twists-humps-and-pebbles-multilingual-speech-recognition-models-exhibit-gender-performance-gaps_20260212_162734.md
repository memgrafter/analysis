---
ver: rpa2
title: 'Twists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit
  Gender Performance Gaps'
arxiv_id: '2402.17954'
source_url: https://arxiv.org/abs/2402.17954
tags:
- gender
- speech
- language
- languages
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates gender performance gaps in multilingual
  automatic speech recognition (ASR) models. The authors evaluate two state-of-the-art
  models, Whisper and SeamlessM4T, across 19 languages and two speech conditions (read
  and spontaneous) using three datasets.
---

# Twists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit Gender Performance Gaps

## Quick Facts
- arXiv ID: 2402.17954
- Source URL: https://arxiv.org/abs/2402.17954
- Authors: Giuseppe Attanasio; Beatrice Savoldi; Dennis Fucci; Dirk Hovy
- Reference count: 40
- Primary result: Multilingual ASR models show consistent gender performance gaps that vary by language and model, with no explanation in acoustic or lexical properties

## Executive Summary
This paper investigates gender performance disparities in multilingual automatic speech recognition models, specifically evaluating Whisper and SeamlessM4T across 19 languages and two speech conditions. The authors find consistent gender gaps in model performance, with the advantaged group varying across languages and models. Surprisingly, these gaps cannot be explained by acoustic features (pitch, intensity, speaking rate) or lexical properties (POS tags, named entities). However, probing internal model states reveals that the ease of distinguishing speaker gender correlates with reduced performance gaps, favoring female speakers.

## Method Summary
The authors evaluate two state-of-the-art multilingual ASR models (Whisper and SeamlessM4T) on three datasets (Mozilla Common Voice, Fleurs, and VoxPopuli) across 19 languages. They compute Word Error Rate (WER) and Character Error Rate (CER) separately for male and female speakers, then calculate performance gaps using a pairwise comparison metric. The study conducts acoustic analysis using Praat and Whisper's tokenizer, lexical analysis using SpaCy and Stanza, and probes internal model states using logistic regression and MDL probes to extract gender information from model embeddings.

## Key Results
- Consistent gender performance gaps observed across all datasets, languages, and models
- Gaps cannot be explained by acoustic properties (pitch, intensity, speaking rate) or lexical features (POS tags, named entities)
- Easier gender extraction from model states correlates with reduced performance gaps, favoring female speakers
- The advantaged gender varies unpredictably across different languages and models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The ease of distinguishing speaker gender in internal model representations correlates with reduced performance gaps, favoring female speakers.
- Mechanism: When gender can be easily extracted from the model's hidden states via probing, the model shows smaller disparities in performance between male and female speakers, with females being advantaged.
- Core assumption: The probe's ability to extract gender information is a valid proxy for the degree of gender-specific encoding in the model.
- Evidence anchors:
  - [abstract] "However, probing internal model states reveals a correlation with gendered performance gap. That is, the easier it is to distinguish speaker gender in a language using probes, the more the gap reduces, favoring female speakers."
  - [section 6] "Fitting an OLS model to predict sentence-level error rates (i.e., rF , rM) but found low R 2 scores (max: 0.20, average σ: 0.03±0.04)."
  - [corpus] Weak; no directly comparable studies found in corpus neighbors.
- Break condition: If probes fail to extract meaningful gender information, or if the correlation reverses (easier gender extraction leads to larger gaps), this mechanism would break.

### Mechanism 2
- Claim: Gender disparities in ASR performance are not explained by acoustic or lexical properties of the speech data.
- Mechanism: Despite significant differences in acoustic features (pitch, intensity, speaking rate) and lexical features (POS tags, named entities) between male and female speakers, these differences do not correlate with the observed error rate gaps.
- Core assumption: The acoustic and lexical analyses are comprehensive and capture all relevant differences between male and female speech that could impact ASR performance.
- Evidence anchors:
  - [section 5.1] "No clear trends emerged overall. Sporadically, we found a strong and significant linear correlation, e.g., for SEAMLESS and VoxPopuli where Pearson'srho for pitch is −0.83"
  - [section 5.2] "Fitting an OLS model to predict error rates from lexical features only yields low R 2 scores (max: 0.35, averageσ: 0.09 ±0.08, across all datasets and languages)."
  - [corpus] Assumption: The acoustic and lexical analyses are standard and comprehensive, but no corpus evidence directly confirms their completeness.
- Break condition: If new acoustic or lexical features are discovered that do correlate with performance gaps, or if the current analyses miss crucial differences, this mechanism would break.

### Mechanism 3
- Claim: Multilingual ASR models exhibit gender bias, with the advantaged group varying across languages and models.
- Mechanism: The complex interaction between model architecture, training data, and language-specific characteristics leads to varying gender biases across different language settings.
- Core assumption: The observed gender disparities are primarily due to the interaction of model and data factors, rather than inherent properties of the languages themselves.
- Evidence anchors:
  - [abstract] "Our findings reveal clear gender disparities, with the advantaged group varying across languages and models."
  - [section 4] "Upon closer examination, we also observe substantially different behaviors across datasets. First, despite the higher degree of spoken language variation to be expected in spontaneous recordings from the VP dataset (Figure 2a), results shows a comparatively reduced gender gap"
  - [corpus] Weak; while related papers discuss ASR bias, none directly address the cross-linguistic variability of gender bias in multilingual models.
- Break condition: If gender disparities were found to be consistent across all languages and models, or if they could be fully explained by language-specific properties, this mechanism would break.

## Foundational Learning

- Concept: Gender as a Sociolinguistic Variable
  - Why needed here: Understanding that gender differences in speech are not solely biological but also influenced by sociocultural factors is crucial for interpreting the results of gender-based performance gap analyses in ASR.
  - Quick check question: How do sociocultural factors influence gendered speech patterns, and why is this important when evaluating ASR performance across genders?

- Concept: Acoustic Feature Analysis
  - Why needed here: Knowledge of how to measure and interpret acoustic features like pitch, intensity, and speaking rate is essential for understanding the exploratory analysis conducted to explain gender performance gaps.
  - Quick check question: What are the three acoustic features analyzed in this study, and how are they measured?

- Concept: Probing Techniques in NLP
  - Why needed here: Understanding how probing works, particularly in the context of extracting sensitive attributes like gender from model representations, is crucial for interpreting the correlation found between gender extractability and performance gaps.
  - Quick check question: What is the purpose of using probing techniques in this study, and how do they relate to the concept of group fairness in machine learning?

## Architecture Onboarding

- Component map: Audio snippets -> Voice Activity Detection -> Whisper/SeamlessM4T -> Transcriptions -> WER/CER computation -> Performance gap calculation -> Acoustic analysis -> Lexical analysis -> Gender probing -> Correlation analysis

- Critical path:
  1. Process audio snippets through ASR models to generate transcriptions.
  2. Compute error rates (WER/CER) for male and female speakers separately.
  3. Calculate performance gaps using the pairwise comparison metric.
  4. Conduct acoustic and lexical analyses to explore potential explanations for gaps.
  5. Train gender probes on model embeddings and correlate extractability with performance gaps.

- Design tradeoffs:
  - Using Whisper's tokenizer for speaking rate estimation in low-resource languages may overestimate speaking rate.
  - Automatic speaker ID attribution using clustering may introduce errors, especially in datasets with limited speaker diversity.
  - The limited sample size for speakers identifying as "Other" restricts the generalizability of results for this group.

- Failure signatures:
  - If error rates are inconsistent across different data splits, it may indicate data contamination or model overfitting.
  - If acoustic or lexical features show strong correlations with performance gaps, it would challenge the assumption that these factors do not explain the disparities.
  - If gender probes fail to extract meaningful information, the correlation between gender extractability and performance gaps would be invalid.

- First 3 experiments:
  1. Reproduce the main findings: Evaluate Whisper and SeamlessM4T on the three datasets, compute WER/CER, and calculate performance gaps using E(rF, rM).
  2. Conduct acoustic analysis: Measure pitch, intensity, and speaking rate for male and female speakers, and test for correlations with performance gaps.
  3. Implement gender probing: Train logistic regression and MDL probes on model embeddings, and analyze the correlation between gender extractability and performance gaps.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does training data gender imbalance directly cause gender performance gaps in multilingual ASR models?
- Basis in paper: [inferred] The paper suggests that models encode gender information differently but does not examine the training data composition. The authors call for more transparency regarding training data demographics.
- Why unresolved: The authors could not access training data gender distribution information from either Whisper or SeamlessM4T models. Without this data, they cannot establish a direct causal link between training data imbalance and performance gaps.
- What evidence would resolve it: Release of detailed training data demographics including gender distribution across languages, and correlation analysis between training data gender ratios and observed performance gaps.

### Open Question 2
- Question: How do gender performance gaps vary across different speaking styles beyond the read and spontaneous conditions tested?
- Basis in paper: [explicit] The authors acknowledge their analysis is limited to read and spontaneous speech conditions and suggest future work should explore other speaking styles.
- Why unresolved: The study only examined two speaking conditions (read and spontaneous) across three datasets. Other important speaking styles like conversational dialogue, broadcast speech, or emotional speech were not tested.
- What evidence would resolve it: Systematic evaluation of gender performance gaps across diverse speaking styles and conditions, including multi-party conversations, emotional speech, and different acoustic environments.

### Open Question 3
- Question: What is the impact of gender performance gaps on real-world user experience and task completion?
- Basis in paper: [inferred] The authors discuss limitations of group-wise metrics and suggest moving beyond them to sentence-level analysis, but do not measure actual user impact or task performance.
- Why unresolved: The study focused on technical metrics (WER, CER) rather than measuring how gender gaps affect actual user tasks, satisfaction, or real-world applications of ASR technology.
- What evidence would resolve it: User studies measuring task completion rates, satisfaction scores, and practical usability across different gender groups in real-world ASR applications.

## Limitations

- Limited analysis of non-binary gender speakers due to small sample size (13 out of 105,468 records)
- Potential bias in acoustic feature extraction for low-resource languages using Whisper's tokenizer
- Automatic speaker attribution using clustering algorithms may introduce errors

## Confidence

- Core finding of gender performance gaps: High confidence
- Acoustic and lexical features not explaining gaps: High confidence  
- Probing results correlation: Medium confidence
- Cross-linguistic variability of advantaged gender: Medium confidence

## Next Checks

1. **Probe robustness validation**: Test whether the correlation between gender extractability and performance gaps holds across different probe architectures (beyond logistic regression and MDL) and whether it persists when controlling for language-specific factors.

2. **Acoustic feature refinement**: Re-run the acoustic analysis using language-specific tokenization methods where possible and compare results with the current approach using Whisper's tokenizer to quantify potential biases in low-resource languages.

3. **Data contamination verification**: Conduct a thorough analysis of model training data to ensure none of the test set audio appears in training corpora, and analyze error rate distributions across different data splits to rule out contamination effects.