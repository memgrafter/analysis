---
ver: rpa2
title: Exploiting Autoencoder's Weakness to Generate Pseudo Anomalies
arxiv_id: '2405.05886'
source_url: https://arxiv.org/abs/2405.05886
tags:
- data
- pseudo
- anomaly
- anomalies
- normal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of anomaly detection where autoencoders
  often reconstruct anomalous data too well, reducing discrimination between normal
  and anomalous data. The authors propose creating pseudo anomalies by adding learned
  adaptive noise to normal data, exploiting the autoencoder's weakness to improve
  reconstruction boundaries.
---

# Exploiting Autoencoder's Weakness to Generate Pseudo Anomalies

## Quick Facts
- **arXiv ID:** 2405.05886
- **Source URL:** https://arxiv.org/abs/2405.05886
- **Reference count:** 40
- **Primary result:** Learnable noise generation creates effective pseudo anomalies that improve autoencoder anomaly detection performance across diverse domains

## Executive Summary
This paper addresses the challenge of anomaly detection where autoencoders often reconstruct anomalous data too well, reducing discrimination capability. The authors propose creating pseudo anomalies by adding learned adaptive noise to normal data, exploiting the autoencoder's weakness to improve reconstruction boundaries. They train a noise generator alongside the autoencoder, alternating between generating pseudo anomalies and learning to poorly reconstruct them. The method is evaluated on Ped2, Avenue, ShanghaiTech, CIFAR-10, and KDDCUP datasets, showing improved discriminative capability compared to baselines and state-of-the-art methods.

## Method Summary
The method trains an autoencoder (F) and noise generator (G) alternately. With probability p, pseudo anomalies are created by adding noise G(X_N) to normal data X_N. The autoencoder is trained to poorly reconstruct these pseudo anomalies while well reconstructing normal data. The noise generator learns to create noise that is reconstructible by the autoencoder but pushes pseudo anomalies away from normal data. At test time, only the autoencoder's reconstruction error is used for anomaly detection. The approach uses Conv3D for videos, Conv2D for images, and linear layers for network data, with the noise generator having a similar structure but doubled output activation.

## Key Results
- Achieves AUC scores of 94.57% on Ped2, 83.23% on Avenue, and 73.23% on ShanghaiTech
- Outperforms many existing methods while maintaining generic applicability across diverse domains
- Learnable noise generation shows superior performance compared to fixed Gaussian noise baselines
- Effective across video, image, and network intrusion datasets with different characteristics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pseudo anomalies are generated by adding learnable noise that exploits the autoencoder's weakness to reconstruct anomalies well
- **Mechanism:** A noise generator G learns to produce noise ∆X that when added to normal data X_N creates pseudo anomalies X_P. The autoencoder F is trained to poorly reconstruct X_P while well reconstructing X_N. This forces F to evolve its reconstruction boundary to better discriminate normal vs anomalous data.
- **Core assumption:** Autoencoders inherently reconstruct anomalous data too well, and this weakness can be exploited to improve discrimination
- **Evidence anchors:**
  - [abstract]: "we propose creating pseudo anomalies from learned adaptive noise by exploiting the aforementioned weakness of AE, i.e., reconstructing anomalies too well"
  - [section]: "We achieve this by learning to generate pseudo anomalies that can hinder the successful reconstruction of anomalies"
  - [corpus]: Weak - the corpus papers discuss pseudo anomalies but don't specifically anchor the exploitation of AE's reconstruction weakness
- **Break condition:** If the autoencoder's reconstruction boundary cannot be meaningfully evolved through pseudo anomaly training, or if the noise generator fails to produce effective pseudo anomalies

### Mechanism 2
- **Claim:** Alternating training between noise generator G and autoencoder F creates a cooperative learning dynamic
- **Mechanism:** G learns to generate noise that produces pseudo anomalies F can reconstruct well, while F learns to poorly reconstruct these pseudo anomalies. This alternating process gradually improves F's ability to discriminate between normal and anomalous data.
- **Core assumption:** The alternating optimization between G and F will converge to a stable state where G produces challenging pseudo anomalies and F learns to reject them
- **Evidence anchors:**
  - [section]: "G is trained by exploiting what we may term as the weakness of F... G learns to generate highly noisy pseudo anomalies that can be reconstructed by F"
  - [section]: "G is alternately trained with F and adapts to the reconstruction boundary of F"
  - [corpus]: Missing - corpus doesn't discuss the alternating training mechanism
- **Break condition:** If the alternating training becomes unstable with oscillating losses, or if one component (G or F) dominates and prevents effective learning

### Mechanism 3
- **Claim:** Learnable noise generation is superior to non-learnable Gaussian noise for creating pseudo anomalies
- **Mechanism:** Unlike fixed Gaussian noise, the learnable noise generator adapts its output based on the current reconstruction boundary of F, producing more effective pseudo anomalies that challenge F's discrimination capability.
- **Core assumption:** Adaptive noise generation can create more effective pseudo anomalies than random noise because it responds to the model's current weaknesses
- **Evidence anchors:**
  - [section]: "To evaluate the effectiveness of utilizing learnable noise to generate pseudo anomalies, we compare... F trained with non-learnable Gaussian noise... Adding Gaussian noise to create pseudo anomalies can generally improve the model's performance, highlighting the importance of noise-based pseudo anomalies. However, using learnable noise can further enhance the model's performances"
  - [section]: "Visualization of pseudo anomalies generated by the model at the end of training on Ped2... when λ ≥ 0.2, highly noisy pseudo anomalies are generated"
  - [corpus]: Missing - corpus papers don't compare learnable vs non-learnable noise approaches
- **Break condition:** If the learned noise fails to outperform simple Gaussian noise, or if the additional complexity of the noise generator doesn't justify its computational cost

## Foundational Learning

- **Concept: One-class classification (OCC)**
  - Why needed here: The paper explicitly frames anomaly detection as an OCC problem where only normal data is available for training
  - Quick check question: Why is anomaly detection typically approached as a one-class classification problem rather than multi-class classification?

- **Concept: Autoencoder reconstruction error as anomaly score**
  - Why needed here: The method relies on using reconstruction quality to distinguish normal from anomalous data, with poor reconstruction indicating anomalies
  - Quick check question: What is the fundamental assumption behind using reconstruction error as an anomaly score in autoencoders?

- **Concept: Adversarial training dynamics**
  - Why needed here: The alternating training between G and F resembles adversarial training, where one component tries to fool the other
  - Quick check question: How does the cooperative learning dynamic in this paper differ from traditional adversarial training?

## Architecture Onboarding

- **Component map:** Normal data → G generates noise → pseudo anomaly created → F trained to poorly reconstruct pseudo anomaly → F reconstruction boundary improves → better anomaly discrimination

- **Critical path:** Normal data → G generates noise → pseudo anomaly created → F trained to poorly reconstruct pseudo anomaly → F reconstruction boundary improves → better anomaly discrimination

- **Design tradeoffs:**
  - Learnable noise vs fixed Gaussian noise: Learnable provides adaptation but adds complexity and training instability risk
  - Alternating training vs joint training: Alternating allows specialized optimization but requires careful scheduling
  - Generator G in test time: Not used to avoid added complexity and potential performance degradation

- **Failure signatures:**
  - G loss doesn't decrease: Noise generator fails to learn effective pseudo anomaly generation
  - F loss oscillates: Alternating training becomes unstable
  - No improvement over baseline: Reconstruction boundary doesn't evolve meaningfully
  - Overfitting to pseudo anomalies: Model becomes too specialized to generated anomalies rather than real ones

- **First 3 experiments:**
  1. Baseline comparison: Train F only on normal data vs F trained with pseudo anomalies from fixed Gaussian noise
  2. Hyperparameter sweep: Test different values of p (pseudo anomaly probability) and λ (noise weighting factor)
  3. Learnable vs non-learnable noise: Compare performance when G generates noise vs when using fixed Gaussian noise with various σ values

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Assumes autoencoder's weakness to reconstruct anomalies can be generalized across diverse domains
- Requires careful hyperparameter tuning of λ and p, limiting practical applicability
- May not hold for datasets where reconstruction boundary is inherently difficult to evolve

## Confidence
**High confidence** in the core mechanism of using learnable noise to create pseudo anomalies that exploit AE reconstruction weaknesses, supported by strong quantitative results across five datasets and ablation studies comparing learnable vs non-learnable noise.

**Medium confidence** in the alternating training dynamics and cooperative learning between G and F, as the theoretical convergence properties aren't fully analyzed and the corpus lacks discussion of this specific training approach.

**Low confidence** in the generalizability to highly complex or multimodal anomaly scenarios where simple noise addition may not capture the true nature of anomalies.

## Next Checks
1. **Stability Analysis**: Systematically vary λ across datasets to determine optimal noise weighting and test whether alternating training remains stable across different initialization seeds.

2. **Domain Transfer**: Apply the method to a dataset with fundamentally different anomaly types (e.g., medical imaging) to assess whether the learned noise generation generalizes beyond the tested domains.

3. **Computational Overhead**: Benchmark inference speed and memory usage of the full G+F system versus simpler baselines to quantify the practical cost of learnable noise generation.