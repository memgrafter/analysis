---
ver: rpa2
title: Tensor Graph Convolutional Network for Dynamic Graph Representation Learning
arxiv_id: '2401.07065'
source_url: https://arxiv.org/abs/2401.07065
tags:
- tensor
- graph
- latent
- ieee
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Tensor Graph Convolutional Network (TGCN)
  for dynamic graph representation learning. The problem is to learn node representations
  from dynamic graphs, which are sequences of graph snapshots evolving over time,
  to predict missing link weights.
---

# Tensor Graph Convolutional Network for Dynamic Graph Representation Learning

## Quick Facts
- **arXiv ID:** 2401.07065
- **Source URL:** https://arxiv.org/abs/2401.07065
- **Reference count:** 40
- **Key outcome:** TGCN achieves 6-34% lower MAE and 5-17% lower RMSE than state-of-the-art methods for dynamic link weight prediction

## Executive Summary
This paper introduces Tensor Graph Convolutional Network (TGCN), a novel approach for learning node representations from dynamic graphs using tensor algebra. The method represents dynamic graph information as tensors and employs tensor products to design a convolutional network that models spatial and temporal dependencies in a unified framework. By embedding node identities into latent feature tensors, normalizing the adjacency tensor, and using a learnable temporal mixing matrix, TGCN captures time-varying dependencies effectively. Experiments on three real-world datasets demonstrate that TGCN outperforms existing methods for link weight prediction tasks.

## Method Summary
TGCN addresses the problem of learning node representations from dynamic graphs to predict missing link weights. The method embeds node identity into latent feature tensors, normalizes the adjacency tensor using degree tensor D, and uses a learnable temporal mixing matrix M with tensor operations (mode-n multiplication, M-product, face-wise product) to capture spatial-temporal dependencies in one unified framework. The model is trained using Huber loss on known link weights and evaluated using MAE and RMSE metrics.

## Key Results
- TGCN reduces MAE by 6-34% and RMSE by 5-17% compared to state-of-the-art methods on three real-world datasets
- The model handles dynamic graphs with 7,604-16,152 nodes, 24,186-159,157 edges, and 137-493 time steps
- Performance improvements are consistent across different dataset types including Bitcoin trust changes, Ethereum transactions, and communication data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TGCN integrates spatial and temporal dependencies into a single convolutional framework using tensor products.
- Mechanism: The model represents the dynamic graph as a third-order tensor (N×N×T) and uses tensor products to combine spatial adjacency information and temporal mixing into one unified operation.
- Core assumption: The spatial-temporal dependencies of dynamic graphs can be effectively captured through tensor algebra without separating spatial and temporal modeling.
- Evidence anchors:
  - [abstract]: "adopting tensor product to design a tensor graph convolutional network modeling spatial-temporal feature simultaneously."
  - [section III.B]: "The tensor graph convolutional network is inspired by the static GCN... we can extend the dimension of the first-order GCN to the third order as TGCN, namely: ( ) , σ = ∗ ∗ F A X W"
  - [corpus]: No direct evidence from corpus; TGCN appears to be a novel approach not directly covered in neighbors.

### Mechanism 2
- Claim: A learnable temporal mixing matrix (M) enables the model to capture variable temporal dependencies across different time scales.
- Mechanism: M is designed as a lower-triangular banded matrix where each entry mtk is a learnable parameter. This matrix is normalized per time slice and used in the M-product to aggregate past and present graph information.
- Core assumption: The temporal correlation structure between graph snapshots is learnable from data and benefits from adaptive weighting rather than fixed or hand-crafted temporal kernels.
- Evidence anchors:
  - [section III.B]: "To capture the different temporal dependence scales from data, we design a learnable temporal mixing value matrix... Each mixing value of M is set as: mtk = if (1, t−1) tk ≤ ≤ max(t−b,1) 0 otherwise."
  - [section III.B]: "we normalize each t-th mixing vector in M as: exp(mtk) mtk ← Σj∈[max(t−b,1),t] exp(mtj)"
  - [corpus]: No direct evidence from corpus; TGCN's learnable M appears novel relative to neighbor methods.

### Mechanism 3
- Claim: Normalizing the adjacency tensor preserves graph structural information while ensuring stable gradient flow during training.
- Mechanism: A diagonal degree tensor D is constructed, and the normalized adjacent tensor Ã is computed as Ã = D^(-1/2) * A * D^(-1/2) + I ⊗ D^(-1/2) ⊗ A ⊗ D^(-1/2).
- Core assumption: Spectral normalization of graph operators improves GCN training stability and helps model learn better representations.
- Evidence anchors:
  - [section III.A]: "we normalized adjacent tensor by constructing a diagonal degree tensor D... Then, a normalized adjacent tensor Ã is constructed as: (1/2) (1/2) Ã = D^(-1/2) ⊗ A ⊗ D^(-1/2) + I ⊗ D^(-1/2) ⊗ A ⊗ D^(-1/2)"
  - [corpus]: No direct evidence from corpus; this normalization strategy is consistent with standard GCN practices but not explicitly discussed in neighbors.

## Foundational Learning

- Concept: Tensor algebra (mode-n product, face-wise product, M-product)
  - Why needed here: TGCN relies on tensor operations to unify spatial and temporal convolutions in a single framework.
  - Quick check question: Can you compute the mode-2 product of a tensor X∈R^3×4×5 with a matrix U∈R^4×2 and describe the resulting shape?

- Concept: Graph convolutional networks (GCNs) and spectral graph theory
  - Why needed here: TGCN extends static GCN to dynamic graphs, so understanding GCN message passing and normalization is essential.
  - Quick check question: How does symmetric normalization of the adjacency matrix (D^(-1/2)AD^(-1/2)) affect the spectral properties of the graph Laplacian?

- Concept: Dynamic graph modeling and temporal dependency capture
  - Why needed here: TGCN must learn representations that reflect both spatial structure and temporal evolution across graph snapshots.
  - Quick check question: What are the trade-offs between using RNNs, temporal convolutions, and learnable mixing matrices for modeling temporal dependencies in dynamic graphs?

## Architecture Onboarding

- Component map: Node embedding → adjacency normalization → TGCN layers → prediction → loss
- Critical path: Node embedding → adjacency normalization → TGCN layers → prediction → loss
- Design tradeoffs:
  - Tensor vs. matrix representations: Tensor form enables unified spatial-temporal modeling but increases memory usage.
  - Learnable M vs. fixed kernel: Adaptive temporal mixing can better fit data but risks overfitting.
  - Normalization choice: Stabilizes training but may obscure certain graph patterns.
- Failure signatures:
  - Training loss plateaus early: Likely issues with initialization or M normalization.
  - Overfitting on small datasets: Try reducing the mixing window b or adding dropout.
  - Memory errors on large graphs: Reduce tensor rank or batch size.
- First 3 experiments:
  1. Compare TGCN with and without learnable temporal mixing matrix M on a small dynamic graph dataset.
  2. Vary the mixing window b and observe its effect on MAE/RMSE.
  3. Test different numbers of TGCN layers (L) to find the sweet spot for spatial-temporal message passing.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of mixing matrix M affect the TGCN's performance on dynamic graphs with varying temporal correlations?
- Basis in paper: [explicit] The paper discusses using a learnable mixing matrix M to capture temporal dependencies, but does not explore the impact of different M choices.
- Why unresolved: The paper uses a specific learnable M but does not compare it with other possible M choices or explore the sensitivity of performance to different M structures.
- What evidence would resolve it: Experiments comparing TGCN performance with different M choices (e.g., fixed vs. learnable, different temporal windows) on various dynamic graph datasets.

### Open Question 2
- Question: Can the TGCN model be extended to handle dynamic graphs with more than three dimensions, such as graphs with additional node or edge attributes?
- Basis in paper: [inferred] The current TGCN model handles three-dimensional tensors (nodes, edges, time), but the paper does not discuss potential extensions to higher-dimensional tensors.
- Why unresolved: The paper focuses on three-dimensional dynamic graphs and does not explore the model's scalability or adaptability to more complex graph structures.
- What evidence would resolve it: Demonstrations of TGCN performance on dynamic graphs with additional dimensions (e.g., node features, edge weights) and comparisons with other multi-dimensional graph representation learning methods.

### Open Question 3
- Question: How does the TGCN model perform on dynamic graphs with different types of temporal patterns, such as periodic or irregular changes?
- Basis in paper: [inferred] The paper does not discuss the model's ability to capture different types of temporal patterns in dynamic graphs.
- Why unresolved: The experiments are conducted on datasets with specific temporal patterns, but the model's generalization to other types of temporal dynamics is unclear.
- What evidence would resolve it: Experiments on dynamic graphs with diverse temporal patterns (e.g., periodic, irregular, abrupt changes) and analysis of TGCN's ability to capture these patterns compared to other temporal graph representation learning methods.

## Limitations
- Lack of detailed implementation specifications for tensor operations and architectural hyperparameters
- Computational complexity of tensor operations for large-scale graphs is not thoroughly discussed
- Limited evaluation on larger graphs with more than ~16K nodes

## Confidence

**High confidence** in the core mechanism of using tensor algebra to unify spatial and temporal convolutions - this is well-grounded in the theoretical description and follows established GCN principles.

**Medium confidence** in the learnable temporal mixing matrix approach - while the concept is sound, the effectiveness depends heavily on proper implementation details that are not fully specified.

**Low confidence** in the scalability claims without additional experiments on larger graphs - the paper demonstrates effectiveness on datasets with up to ~16K nodes, but the tensor-based approach may face computational challenges at larger scales.

## Next Checks

1. **Implementation verification**: Reproduce the TGCN model with the exact tensor operations described, comparing results against the reported performance metrics to validate the claimed improvements.

2. **Ablation study**: Systematically remove or modify key components (learnable M, normalization, tensor representation) to quantify their individual contributions to performance gains.

3. **Scalability testing**: Evaluate TGCN on progressively larger dynamic graphs to identify computational bottlenecks and memory constraints of the tensor-based approach.