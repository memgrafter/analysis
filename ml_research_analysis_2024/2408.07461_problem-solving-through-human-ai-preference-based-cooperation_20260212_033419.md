---
ver: rpa2
title: Problem Solving Through Human-AI Preference-Based Cooperation
arxiv_id: '2408.07461'
source_url: https://arxiv.org/abs/2408.07461
tags:
- human
- solution
- learning
- language
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This position paper proposes HAI-Co2, a framework for human-AI
  cooperative problem solving through preference-based search in expert domains. HAI-Co2
  addresses the limitations of current generative AI in complex tasks by formalizing
  solution construction as search in a multi-level abstraction hierarchy, where both
  solution and objective are co-constructed through natural language interaction.
---

# Problem Solving Through Human-AI Preference-Based Cooperation

## Quick Facts
- arXiv ID: 2408.07461
- Source URL: https://arxiv.org/abs/2408.07461
- Reference count: 40
- One-line primary result: Position paper proposing HAI-Co2 framework for preference-based human-AI cooperative problem solving through multi-level abstraction search

## Executive Summary
This position paper introduces HAI-Co2, a novel framework for human-AI cooperative problem solving that addresses the limitations of current generative AI systems in complex expert domains. The framework formalizes solution construction as search in a multi-level abstraction hierarchy, where both the solution and objective are co-constructed through natural language interaction between human experts and AI agents. By representing the construction space explicitly across multiple abstraction levels, HAI-Co2 enables systematic search guided by human preferences while maintaining equal partnership between human and AI collaborators.

The key innovation lies in moving beyond monolithic language models to create a structured approach where complex problems are decomposed into manageable sub-problems at different abstraction levels. The framework has been prototyped for code generation tasks, demonstrating improved performance over traditional LLMs in incorporating initial preferences, adapting to preference switching, and precision/completeness of iterative refinement. Human evaluators rated HAI-Co2 superior on all criteria, suggesting the framework's potential to enhance collaborative problem-solving in expert domains.

## Method Summary
HAI-Co2 represents problem solving as search in a multi-level abstraction hierarchy, where solutions and objectives are co-constructed through natural language interaction. The framework decomposes complex problems into manageable sub-problems at different abstraction levels, with human experts and AI agents working as equal partners. The search process is guided by human preferences expressed through natural language, allowing for systematic exploration of the solution space while maintaining flexibility to adapt to changing requirements. A prototype implementation for code generation demonstrates the framework's practical applicability, showing improved performance in preference incorporation, adaptability, and solution quality compared to monolithic LLMs.

## Key Results
- HAI-Co2 framework improves preference incorporation in complex problem solving compared to monolithic LLMs
- The framework demonstrates superior adaptability to preference switching during problem-solving processes
- Human evaluators rated HAI-Co2 superior to traditional approaches on precision, completeness, and iterative refinement capabilities
- Prototype implementation shows successful application to code generation tasks in expert domains

## Why This Works (Mechanism)
The framework works by explicitly representing the construction space across multiple abstraction levels, enabling systematic search guided by human preferences. This approach addresses the limitations of monolithic LLMs by decomposing complex problems into manageable sub-problems that can be explored systematically. The equal partnership model ensures that human expertise guides the search process while AI agents handle computational aspects, creating a synergistic collaboration. The natural language interface allows for intuitive preference expression and adaptation, while the hierarchical structure provides the necessary framework for systematic exploration and refinement of solutions.

## Foundational Learning

**Multi-level Abstraction Hierarchy**
- Why needed: To break down complex problems into manageable sub-problems that can be systematically explored
- Quick check: Can the problem be decomposed into clearly defined levels with distinct characteristics?

**Preference-Based Search**
- Why needed: To guide the solution construction process according to human expert preferences and requirements
- Quick check: Are preference expressions clear and actionable for the search algorithm?

**Natural Language Interaction Interface**
- Why needed: To enable intuitive communication between human experts and AI agents during collaborative problem solving
- Quick check: Can humans express preferences and receive understandable feedback through natural language?

**Co-construction of Solution and Objective**
- Why needed: To ensure that both the problem definition and solution evolve together based on mutual understanding
- Quick check: Does the framework allow for dynamic adjustment of objectives as solutions are explored?

## Architecture Onboarding

**Component Map**
Human Expert <-> Natural Language Interface <-> Preference Processor <-> Multi-level Search Engine <-> Solution Builder <-> Code Generator

**Critical Path**
1. Human expresses preferences through natural language interface
2. Preferences are processed and converted into search parameters
3. Multi-level search engine explores solution space guided by preferences
4. Solutions are constructed and refined iteratively
5. Final solution is generated and validated with human expert

**Design Tradeoffs**
- Natural language flexibility vs. precision in preference expression
- Hierarchical decomposition vs. holistic problem understanding
- Equal partnership vs. specialized role assignment
- Systematic search vs. creative exploration

**Failure Signatures**
- Miscommunication between human preferences and AI interpretation
- Search getting stuck in local optima within abstraction levels
- Hierarchy becoming too rigid to accommodate novel solutions
- Natural language interface failing to capture technical nuances

**First Experiments**
1. Compare preference incorporation accuracy against baseline LLM on standardized code generation tasks
2. Test adaptability to preference switching with controlled preference change scenarios
3. Evaluate precision and completeness metrics on iterative refinement tasks

## Open Questions the Paper Calls Out

The paper identifies several open questions regarding the framework's generalizability across different expert domains, scalability to more complex problems, and the optimal balance between systematic search and creative exploration. Additionally, the framework's ability to handle real-time collaboration and maintain context over extended problem-solving sessions remains an area for further investigation.

## Limitations

The paper remains largely conceptual without extensive empirical validation beyond a single code generation prototype. The evaluation relies on human judgment rather than standardized metrics, and the framework's scalability to complex real-world domains is unproven. Potential biases in preference-based search methods are not addressed, and the assumption of effective natural language interaction may not hold for highly technical domains.

## Confidence

- **High Confidence**: Identification of current generative AI limitations and conceptual value of preference-based search approaches
- **Medium Confidence**: Proposed multi-level abstraction hierarchy structure and potential benefits for systematic search
- **Low Confidence**: Claims about superior performance over monolithic LLMs and framework generalizability across expert domains

## Next Checks

1. Conduct controlled experiments comparing HAI-Co2 against state-of-the-art code generation systems using standardized metrics for precision, completeness, and preference incorporation
2. Test the framework's scalability by implementing it across multiple expert domains (e.g., medical diagnosis, architectural design, legal analysis) with domain-specific benchmarks
3. Perform user studies with varying levels of technical expertise to evaluate the natural language interaction interface's effectiveness and identify potential communication bottlenecks