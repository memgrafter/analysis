---
ver: rpa2
title: Empirical Asset Pricing with Large Language Model Agents
arxiv_id: '2409.17266'
source_url: https://arxiv.org/abs/2409.17266
tags:
- news
- pricing
- asset
- market
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel Large Language Model (LLM) agent-based
  asset pricing model that combines qualitative discretionary investment analysis
  with quantitative financial factors to explain excess asset returns. The LLM agent
  iteratively analyzes business news using long-term memory and domain knowledge to
  generate investment insights, which are then merged with manual financial factors
  to predict future returns.
---

# Empirical Asset Pricing with Large Language Model Agents

## Quick Facts
- arXiv ID: 2409.17266
- Source URL: https://arxiv.org/abs/2409.17266
- Authors: Junyan Cheng; Peter Chin
- Reference count: 22
- Primary result: LLM agent-based asset pricing model achieves 10.6% Sharpe ratio improvement and 10.0% reduction in pricing errors

## Executive Summary
This paper introduces a novel asset pricing model that integrates LLM agent-generated qualitative analysis with quantitative financial factors to explain excess asset returns. The approach combines iterative news analysis using long-term memory and domain knowledge with manual financial factors in a hybrid network. Experimental results show superior performance over traditional machine learning baselines, with a 10.6% improvement in Sharpe ratio and 10.0% reduction in average pricing errors for anomaly portfolios.

## Method Summary
The method employs an LLM agent that iteratively analyzes business news using long-term memory and domain knowledge to generate investment insights. These qualitative analysis reports are converted to embeddings and merged with manually curated financial factors through a hybrid network that learns asset-specific loadings. The model undergoes iterative refinement over multiple rounds, incorporating external knowledge from a knowledge base. The hybrid network combines the LLM-generated embeddings with manual factors to predict future returns and optimize portfolios.

## Key Results
- Achieved 10.6% improvement in Sharpe ratio for portfolio optimization compared to traditional ML baselines
- Reduced average pricing errors by 10.0% across anomaly portfolios
- Ablation studies confirmed effectiveness of iterative refinement and macroeconomic note incorporation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM agents generate qualitative investment insights from business news that capture market dynamics traditional factors miss.
- Mechanism: The agent iteratively analyzes news using long-term memory and domain knowledge, producing analysis reports that embed macroeconomic context and market perceptions.
- Core assumption: Business news contains actionable investment information that can be extracted through iterative reasoning with external knowledge.
- Evidence anchors: [abstract] "The LLM agent iteratively analyzes business news using long-term memory and domain knowledge to generate investment insights" - [section] "Business news in major media outlets like the WSJ carries important market information, however, they typically restrict their interpretations and opinions, leaving room for discretionary analysis"
- Break condition: If news articles become predominantly automated summaries or AI-generated content lacking genuine market insights.

### Mechanism 2
- Claim: Combining qualitative analysis with quantitative factors creates non-linear interactions that improve pricing accuracy.
- Mechanism: Analysis report embeddings are concatenated with manual factors and processed through a hybrid network that learns asset-specific loadings to the hybrid state.
- Core assumption: Qualitative and quantitative information contain complementary rather than redundant signals for asset pricing.
- Evidence anchors: [abstract] "which integrates qualitative discretionary investment evaluations from LLM agents with quantitative financial economic factors manually curated" - [section] "The hybrid asset pricing network, represented as fH and parameterized by θ, comprises the embedding table E, the downsampling matrix WS, and the prediction network fP"
- Break condition: If the non-linear interactions between qualitative and quantitative signals become dominated by noise or create spurious correlations.

### Mechanism 3
- Claim: Iterative refinement with external knowledge retrieval improves analysis quality over single-pass generation.
- Mechanism: The agent generates initial analysis, retrieves relevant knowledge from external memory, and refines the report over N rounds to incorporate broader context.
- Core assumption: Business news interpretation benefits from iterative reasoning that progressively incorporates relevant background knowledge.
- Evidence anchors: [section] "The report undergoes iterative refinement over N rounds. In each round i, the report Ri−1 t is used to query an external memory M t... to produce the refined report Ri t" - [section] "We observe that the agent benefits from more rounds of analysis... with a sharp decline in marginal gain after a certain point around K × N = 15"
- Break condition: If retrieval becomes less relevant over iterations or the refinement process starts introducing contradictory information.

## Foundational Learning

- Concept: Asset pricing models and factor decomposition
  - Why needed here: Understanding how excess returns are explained by various factors is fundamental to evaluating the LLM agent's contribution
  - Quick check question: What is the key difference between CAPM and Fama-French multi-factor models?

- Concept: Natural language processing and text embeddings
  - Why needed here: The method relies on converting analysis reports into embeddings that capture semantic meaning for the pricing network
  - Quick check question: How do embeddings capture semantic relationships between different analysis reports?

- Concept: Machine learning model architecture and training
  - Why needed here: The hybrid network combines embeddings and factors through learned transformations to predict returns
  - Quick check question: What role does the asset embedding table play in capturing asset-specific loadings?

## Architecture Onboarding

- Component map: LLM agent (news analysis → iterative refinement → analysis reports) → embedding model → hybrid network (downsampling + asset embeddings + prediction layers) → portfolio optimization/valuation metrics
- Critical path: News → LLM analysis → report embedding → hybrid state formation → return prediction → portfolio construction/valuation
- Design tradeoffs: Quality vs. latency in iterative refinement; model complexity vs. interpretability; manual factor selection vs. automated discovery
- Failure signatures: Poor Sharpe ratios despite high individual asset predictions; asset pricing errors concentrated in specific portfolio deciles; iterative refinement not improving with more rounds
- First 3 experiments:
  1. Test Sharpe ratio improvement on equal-weighted portfolios vs. traditional factor models
  2. Evaluate asset pricing errors across anomaly portfolios to identify systematic weaknesses
  3. Run ablation study removing iterative refinement to quantify its contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the LLM agent asset pricing model change when using different foundation models with varying levels of financial domain expertise?
- Basis in paper: [explicit] The paper tests various foundation models including GPT-4, GPT-3.5, GPT-4o, O1-preview, O1-mini, Llama 3.1 (70B and 405B), and Qwen 2 (72B), showing that different models yield different performance metrics in Sharpe ratio, maximum drawdown, and asset pricing errors.
- Why unresolved: While the paper demonstrates that different foundation models affect performance, it does not explore models specifically fine-tuned for financial applications or investigate whether domain-specific training could significantly improve results.
- What evidence would resolve it: Testing the model with foundation models specifically fine-tuned for financial applications (e.g., FinGPT) and comparing their performance against general-purpose models on the same asset pricing tasks would determine if domain expertise in the LLM leads to superior financial analysis and prediction.

### Open Question 2
- Question: What is the impact of incorporating multimodal information (e.g., financial charts, diagrams, tables) on the LLM agent's ability to generate accurate analysis reports and improve asset pricing performance?
- Basis in paper: [inferred] The discussion section mentions that multimodal information is frequently presented in financial documents but is not currently utilized by the model, suggesting potential for improvement.
- Why unresolved: The current model only processes textual news articles and does not incorporate other forms of information commonly found in financial analysis, such as charts, tables, or other visual data representations.
- What evidence would resolve it: Implementing a multimodal LLM agent that can process and analyze both textual and visual financial information, then comparing its asset pricing performance against the current text-only model would reveal whether multimodal inputs enhance predictive accuracy.

### Open Question 3
- Question: How does granting the LLM agent internet access and broader information sources beyond the SocioDojo corpus affect its analysis quality and subsequent asset pricing performance?
- Basis in paper: [inferred] The discussion section suggests that internet access and a broader range of information sources may enable the agent to generate more in-depth analyses, as discretionary investment relies on information beyond just news or domain knowledge.
- Why unresolved: The current model is limited to news articles and the SocioDojo knowledge base, which may restrict the depth and breadth of analysis compared to what could be achieved with real-time internet access.
- What evidence would resolve it: Conducting experiments where the LLM agent is given internet access to search for additional context and information during the analysis process, then measuring the difference in analysis quality and asset pricing performance compared to the restricted-information version would demonstrate the value of broader information access.

## Limitations

- Manual Factor Selection: The study relies on manually curated financial factors without detailing the selection criteria, introducing potential bias and limiting reproducibility
- LLM Agent Architecture: Key implementation details including exact prompts, memory retrieval mechanism, and knowledge base integration are not fully specified
- Data Time Horizon: The analysis covers only approximately three years (Sep 2021-Sep 2024), which may not capture full market cycles or regime changes

## Confidence

**High Confidence**: The hybrid architecture combining qualitative and quantitative approaches is technically sound. The ablation studies demonstrating the value of iterative refinement and macroeconomic notes provide strong empirical support.

**Medium Confidence**: The 10.6% Sharpe ratio improvement claim is based on specific market conditions and portfolio construction methods. The general approach appears valid, but absolute performance may vary across different market regimes.

**Low Confidence**: The absolute magnitude of improvements (10.6% Sharpe, 10.0% pricing error reduction) may be overstated due to potential overfitting to the specific dataset and time period. The model's generalization to different asset classes or longer time horizons is uncertain.

## Next Checks

1. **Cross-Validation with Alternative Factors**: Test the hybrid model using different sets of manually curated factors to assess sensitivity to factor selection and validate the robustness of the qualitative-quantitative integration approach.

2. **Out-of-Sample Performance Test**: Apply the trained model to a distinct out-of-sample period (e.g., pre-2021 data) to evaluate whether the Sharpe ratio improvements and pricing error reductions generalize beyond the training timeframe.

3. **Baseline Comparison with Advanced Models**: Compare performance against state-of-the-art transformer-based models trained directly on financial time series, rather than just traditional ML baselines, to establish the relative advantage of the LLM agent approach.