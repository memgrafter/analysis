---
ver: rpa2
title: Depth-Bounded Epistemic Planning
arxiv_id: '2406.01139'
source_url: https://arxiv.org/abs/2406.01139
tags:
- state
- states
- planning
- epistemic
- depth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a new epistemic planning algorithm that iteratively
  deepens the reasoning bound to find plans requiring the lowest possible modal depth.
  It uses canonical b-bisimulation contractions to efficiently represent states and
  reduce their size while preserving truth of formulas up to a given depth.
---

# Depth-Bounded Epistemic Planning

## Quick Facts
- arXiv ID: 2406.01139
- Source URL: https://arxiv.org/abs/2406.01139
- Reference count: 9
- Key outcome: New epistemic planning algorithm using canonical b-bisimulation contractions achieves 89.2% solution rate on 406 benchmarks, 87.7× faster than previous best

## Executive Summary
This paper introduces a novel approach to epistemic planning that iteratively deepens the reasoning bound to find plans requiring the lowest possible modal depth. The key innovation is the use of canonical b-bisimulation contractions, which provide unique minimal model representations and enable efficient state comparisons. The algorithm, implemented in the DAEDALUS planner, solves 89.2% of benchmark instances compared to 74.4% for the previous best method, achieving an average 87.7× speedup.

## Method Summary
The algorithm performs iterative deepening on the reasoning bound b, starting from the modal depth of the goal formula and incrementing until a solution is found. It uses canonical b-bisimulation contractions to efficiently represent states and reduce their size while preserving truth of formulas up to depth b. The approach guarantees unique minimal model representations and enables fast state comparisons through identity checks. A mixed mode search strategy improves efficiency by preserving exact mode when possible, reducing iterations and keeping state sizes smaller.

## Key Results
- Solves 89.2% (362/406) of benchmark instances vs 74.4% for EFP2.0
- Achieves average 87.7× speedup over previous best method
- Runs in (b+1)-EXPTIME where b is the modal depth bound
- Guarantees unique minimal model representations through canonical contractions
- Sound and complete for epistemic planning tasks

## Why This Works (Mechanism)

### Mechanism 1
Canonical b-bisimulation contractions guarantee unique minimal model representations by construction. The canonical signature function min⋖{σ(v)|v∈W max and σ h(v)=σ h(w)} selects a unique representative world for each equivalence class based on a fixed total order on signatures, ensuring that b-isimilar states produce identical contractions. Core assumption: The signature function σ h(w) captures all necessary information about world w up to depth h, including its label and the signatures of its neighbors. Evidence anchors: [abstract] "The algorithm relies at its core on a new type of 'canonical' b-bisimulation contraction that guarantees unique minimal models by construction." Break condition: If the total order on signatures is not fixed or if the signature function fails to capture the necessary depth information, uniqueness may not be guaranteed.

### Mechanism 2
Iterative deepening on reasoning bound finds plans with the lowest possible modal depth. The algorithm starts with an initial bound equal to the modal depth of the goal formula and incrementally increases it until a solution is found, ensuring that the first solution discovered uses the minimal reasoning depth required. Core assumption: Any plan requiring reasoning depth greater than the goal's modal depth can be found by incrementally increasing the bound from the goal's modal depth upward. Evidence anchors: [abstract] "We then compute a plan requiring the lowest reasoning depth by iteratively incrementing the value of b." Break condition: If the initial bound is set too high or if the increment strategy is inefficient, the algorithm may miss opportunities to find solutions at lower depths.

### Mechanism 3
Mixed mode search improves efficiency by preserving exact mode when possible. When all states in a path are exact representations (b-isimilar to true states), the algorithm preserves the current bound instead of decrementing it, reducing the number of iterations needed and keeping state sizes smaller. Core assumption: When a node's state is an exact representation of the true state, no information is lost through bounded contractions, so the bound can be preserved. Evidence anchors: [section] "We use this key observation to improve our algorithm as follows... We now let a node be a triple n=(s,b,is bisim), where... is bisim is a boolean representing whether TtU⋆ b -t holds, i.e., whether the state of a node is an exact representation of the true state." Break condition: If the exact mode detection fails or if the bound preservation logic is incorrect, the algorithm may either miss solutions or compute unnecessarily large states.

## Foundational Learning

- **Dynamic Epistemic Logic (DEL) states and product updates**
  - Why needed here: The algorithm operates on epistemic states represented as Kripke models and uses product updates to model action execution.
  - Quick check question: Given a state s=((W,R,L),w) and action α=((E,Q,pre,post),e), what are the components of the updated state s⊗α?

- **Bisimulation and b-bisimulation**
  - Why needed here: The algorithm uses b-bisimulation to define when states are equivalent up to a certain reasoning depth, which is crucial for state reduction.
  - Quick check question: What is the difference between s-s' (bisimilar) and s-b-s' (b-bisimilar), and how does this relate to the modal depth of formulas they agree on?

- **Modal depth and its relationship to reasoning bound**
  - Why needed here: The reasoning bound b limits the modal depth of formulas that agents can reason about, and the algorithm uses this to determine when to contract states.
  - Quick check question: How does the modal depth of a formula [α]ϕ relate to the modal depths of α and ϕ, and why is this important for determining the initial bound?

## Architecture Onboarding

- **Component map:**
  IBDS -> BOUNDEDSEARCH -> INITNODE -> CHILDNODE -> Canonical b-contraction computation -> State comparison

- **Critical path:**
  1. IBDS receives planning task (s0, A, ϕg)
  2. Sets initial bound b=md(ϕg)
  3. Calls BOUNDEDSEARCH with (s0, A, ϕg, b)
  4. BOUNDEDSEARCH initializes frontier with INITNODE(s0, b, true)
  5. For each node popped from frontier:
     - Checks if state satisfies goal
     - For each applicable action, generates child nodes via CHILDNODE
     - Adds children to frontier if not visited
  6. If solution found, returns it; otherwise increments b and repeats

- **Design tradeoffs:**
  - Exact mode vs Approximate mode: Exact mode preserves bounds but may miss opportunities for state reduction; approximate mode allows more state reduction but requires more iterations
  - Canonical vs Rooted contractions: Canonical contractions enable fast identity checks but require more complex signature computation; rooted contractions are simpler but require more expensive bisimilarity checks
  - Bound increment strategy: Linear increment is simple but may be slow; exponential increment may skip optimal solutions

- **Failure signatures:**
  - No solution found despite one existing: Check if initial bound is too low or increment strategy is inadequate
  - Excessive memory usage: Check if canonical contraction computation is correct or if state comparison is working properly
  - Incorrect solutions: Check if bisimilarity detection is accurate or if product update implementation is correct

- **First 3 experiments:**
  1. Test on a simple domain with known solution requiring low modal depth to verify basic functionality
  2. Test on the Consecutive Numbers domain to verify that the algorithm handles cases requiring maximal reasoning depth
  3. Compare running times and state sizes between MIXED-IBDS and EXACT-IBDS on a medium-sized benchmark to verify the efficiency gains from the mixed mode approach

## Open Questions the Paper Calls Out

### Open Question 1
Can the iterative deepening approach be extended to handle multi-pointed epistemic states (where multiple worlds can be designated as actual)? Basis in paper: [explicit] The paper mentions this is a limitation, stating "Our paper considered only single-pointed states, but the multi-pointed case can be covered by translating into single-pointed states." Why unresolved: The authors acknowledge this as a limitation but do not provide the translation method or demonstrate how the algorithm would perform with multi-pointed states. What evidence would resolve it: A formal proof showing how multi-pointed states can be translated to single-pointed states while preserving the algorithm's properties, along with experimental results comparing performance.

### Open Question 2
What is the optimal strategy for initializing the reasoning bound in each iteration to minimize the number of iterations required? Basis in paper: [inferred] The authors mention planning to address the issue where MIXED-IBDS requires multiple iterations for certain problems (like Consecutive Numbers) and suggest potential improvements like "doubling the bound at each iteration, and/or via heuristics to 'guess' a better initial bound." Why unresolved: The current algorithm uses a simple linear increment (starting from md(ϕg)), which can be inefficient for some problem instances as demonstrated in the Consecutive Numbers domain. What evidence would resolve it: Comparative experiments showing runtime improvements using different initialization strategies (geometric progression, heuristic-based starting bounds) across diverse benchmark domains.

### Open Question 3
How would the MIXED-IBDS algorithm perform against other non-DEL epistemic planning approaches like RP-MEP at various modal depths? Basis in paper: [explicit] The authors state "Nevertheless, we consider an important future work to provide an experimental comparison of our algorithm and other solvers based on non-DEL approaches, including RP-MEP." Why unresolved: While the paper shows MIXED-IBDS outperforms EFP2.0, it does not compare against knowledge base approaches like RP-MEP, which may have different performance characteristics at different modal depths. What evidence would resolve it: Direct experimental comparison of MIXED-IBDS against RP-MEP and other knowledge base planners across problems with varying modal depths, measuring both solution quality and computational efficiency.

## Limitations

- The algorithm is limited to single-pointed epistemic states and does not handle multi-pointed states directly
- Performance may degrade significantly on domains requiring deep reasoning, as demonstrated by the Consecutive Numbers domain requiring 15 iterations
- The 87.7× speedup is based on comparison with a single implementation and may not generalize to all epistemic planning approaches

## Confidence

- **High confidence**: The soundness and completeness proofs for the IBDS algorithm are rigorous and well-established. The claim that canonical b-contractions guarantee unique minimal representations is supported by the formal definitions and proofs in the paper.
- **Medium confidence**: The efficiency gains from mixed mode search are demonstrated empirically but rely on implementation-specific optimizations. The claim that the algorithm runs in (b+1)-EXPTIME is theoretically sound but may vary in practice depending on implementation details.
- **Low confidence**: The generalizability of the results to domains outside the 9 benchmark domains tested, and the absolute magnitude of the speedup compared to other potential approaches, require further validation.

## Next Checks

1. Implement canonical b-bisimulation contraction: Re-implement the contraction algorithm following Definitions 10-12 and verify that it produces unique minimal representations for b-isimilar states across various test cases.

2. Verify mixed mode completeness: Construct a formal proof or find a counterexample to the claim that mixed mode search preserves completeness, particularly focusing on edge cases where exact mode transitions to approximate mode.

3. Benchmark on additional domains: Test the algorithm on epistemic planning domains not included in the original 9 benchmarks to assess its generalizability and identify any limitations in the approach.