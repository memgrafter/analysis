---
ver: rpa2
title: Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens
  using synthetic Training
arxiv_id: '2402.04979'
source_url: https://arxiv.org/abs/2402.04979
tags:
- object
- objects
- pose
- estimation
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of deploying state-of-the-art
  6D object pose estimation on edge devices like Microsoft HoloLens 2 for augmented
  reality applications. The authors propose a synthetically trained client-server-based
  AR system that demonstrates accurate pose estimation of metallic and texture-less
  industrial objects without requiring real-world training data.
---

# Detection and Pose Estimation of flat, Texture-less Industry Objects on HoloLens using synthetic Training

## Quick Facts
- arXiv ID: 2402.04979
- Source URL: https://arxiv.org/abs/2402.04979
- Authors: Thomas Pöllabauer; Fabian Rücker; Andreas Franek; Felix Gorschlüter
- Reference count: 40
- Key outcome: Synthetically trained client-server AR system achieves 0.758 mAP on HoloLens 2 for detecting and estimating 6D poses of flat, texture-less industrial objects

## Executive Summary
This paper presents a novel approach for 6D object pose estimation on edge devices like Microsoft HoloLens 2, specifically targeting flat, texture-less industrial objects for augmented reality applications. The key innovation is using synthetic training data generated from vector graphics in manufacturing documents, eliminating the need for real-world training images. The system combines a YOLOv5-based object detector with CosyPose for pose estimation, trained entirely on synthetic data and deployed through a client-server architecture that offloads heavy computation from the edge device.

## Method Summary
The method extracts object geometry from SVG-based manufacturing documents to automatically generate 3D meshes, which are then rendered to create synthetic training datasets. A two-stage pipeline uses YOLOv5 for object detection followed by CosyPose for pose estimation. The entire system is trained on synthetic data - 28,401 object images and 30,425 empty images for YOLOv5, plus 250,000 additional images for CosyPose. The trained models are deployed on a client-server architecture where the HoloLens 2 captures video, streams it to backend servers for processing, and displays the results in a Unity-based AR application.

## Key Results
- Achieved mean average precision (mAP) of 0.758 for object detection on real-world HoloLens 2 data
- Demonstrated good performance on real-world images despite being trained entirely on synthetic data
- Qualitative evaluation on AR-assisted sorting task shows practical applicability
- Quantitative evaluation on both synthetic and real-world HoloLens 2 data validates the approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic training data generated from vector graphics in manufacturing documents enables effective training without real-world object photos
- Mechanism: Automatic extraction of object geometry from SVG-based manufacturing documents allows creation of 3D meshes, which are then rendered to generate synthetic training data for object detection and pose estimation
- Core assumption: Vector graphics from manufacturing documents contain sufficient geometric information to create accurate 3D models for training
- Evidence anchors:
  - [abstract] "Synthetic data enables training without real photographs, i.e. for yet-to-be-manufactured objects"
  - [section 3.1] "The manufacturing documents are available in an xml file-format, which contains SVG descriptions of the objects"
  - [corpus] Weak evidence - no similar approaches found in corpus
- Break condition: If manufacturing documents lack sufficient geometric detail or if the SVG extraction process fails to capture critical shape features

### Mechanism 2
- Claim: YOLOv5-based object detection combined with CosyPose pose estimation achieves state-of-the-art performance on edge devices through client-server architecture
- Mechanism: YOLOv5 provides fast and accurate 2D object detection, while CosyPose refines these detections into 6D pose estimates; the client-server approach offloads heavy computation to backend servers
- Core assumption: Edge devices cannot perform the required computations locally, but can efficiently stream video and display results
- Evidence anchors:
  - [abstract] "The system combines a YOLOv5-based object detector with CosyPose for pose estimation"
  - [section 2.2] "We decided on YOLOv5, since it reported highest performance"
  - [section 2.2] "Among the suitable approaches SingleShot[38] is arguably the simplest"
  - [corpus] Weak evidence - no similar approaches found in corpus
- Break condition: If network latency becomes too high or if the edge device's streaming capabilities are insufficient

### Mechanism 3
- Claim: Combining photorealistic and non-photorealistic synthetic training data bridges the domain gap between synthetic and real-world images
- Mechanism: Using both Blender-rendered photorealistic images and pybullet-rendered non-photorealistic images with random backgrounds creates a diverse training dataset that generalizes better to real-world conditions
- Core assumption: Domain randomization and diverse synthetic data reduce the performance gap when applying models to real-world images
- Evidence anchors:
  - [section 3.1] "We used two rendering solutions, with which we rendered two sets of images comprising our training data"
  - [section 3.1] "This approach was inspired by work done at Nvidia [40]"
  - [section 5] "Performance is measured in mean average precision (mAP), higher is better"
  - [corpus] Weak evidence - no similar approaches found in corpus
- Break condition: If the model fails to generalize despite diverse training data, or if certain real-world conditions are not captured in the synthetic data

## Foundational Learning

- Concept: 6D object pose estimation
  - Why needed here: The system must determine both the position (3D translation) and orientation (3D rotation) of objects in the scene
  - Quick check question: What are the six degrees of freedom in 6D pose estimation?

- Concept: Domain gap in synthetic-to-real transfer
  - Why needed here: Understanding why synthetic training data might not directly generalize to real-world images is crucial for evaluating the approach
  - Quick check question: What are the main sources of domain gap between synthetic and real images?

- Concept: Client-server architecture for edge computing
  - Why needed here: The system uses a client-server approach to overcome computational limitations of edge devices like HoloLens 2
  - Quick check question: What are the key advantages and disadvantages of client-server architectures for real-time AR applications?

## Architecture Onboarding

- Component map: SVG extraction -> 3D mesh generation -> Synthetic rendering -> YOLOv5 training -> CosyPose training -> Client app (HoloLens 2) -> Server processing -> Result streaming -> Unity AR display

- Critical path: Object detection (YOLOv5) → Pose estimation (CosyPose) → Result streaming → AR overlay display

- Design tradeoffs:
  - Accuracy vs. latency: Larger models provide better accuracy but increase processing time
  - Photorealism vs. diversity: More realistic training data may improve performance but reduce domain randomization benefits
  - Local vs. server processing: Running everything on the edge device reduces latency but limits computational capacity

- Failure signatures:
  - High false negative rate: Indicates insufficient training data diversity or model capacity
  - High false positive rate: Suggests overfitting to training data or inadequate background randomization
  - Poor pose estimation: May indicate insufficient geometric information in training data or model architecture limitations

- First 3 experiments:
  1. Train YOLOv5 on synthetic data only and evaluate detection performance on real HoloLens 2 images
  2. Train CosyPose using detections from YOLOv5 and evaluate end-to-end pose estimation performance
  3. Test the complete client-server pipeline with actual HoloLens 2 hardware to measure latency and real-world performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of freezing different numbers of layers in the feature extractor on detection performance?
- Basis in paper: [explicit] The authors tested freezing different numbers of layers in the feature extractor and found that freezing even a few layers degraded performance.
- Why unresolved: The authors do not provide a clear explanation for why freezing layers degrades performance. They only speculate that high-quality training data generalizes well to real-world data.
- What evidence would resolve it: A detailed analysis of the feature maps learned by the network with and without freezing layers would help understand why freezing degrades performance.

### Open Question 2
- Question: How can the latency issue in the AR application be addressed?
- Basis in paper: [explicit] The authors acknowledge that latency is a challenge due to the client-server architecture and suggest reducing it would improve user experience.
- Why unresolved: The authors do not propose any specific solutions to reduce latency.
- What evidence would resolve it: Implementing and testing different strategies to reduce latency, such as optimizing the network architecture or using a more efficient communication protocol, would provide evidence for the best approach.

### Open Question 3
- Question: How does the performance of the proposed method compare to other state-of-the-art methods on textured objects?
- Basis in paper: [inferred] The authors compare their method to other methods on a textureless dataset and find that their method performs well. However, they do not compare their method to other methods on textured objects.
- Why unresolved: The authors do not provide any evidence to support their claim that their method would perform well on textured objects.
- What evidence would resolve it: Testing the proposed method on a textured object dataset and comparing its performance to other state-of-the-art methods would provide evidence for its effectiveness on textured objects.

## Limitations

- Synthetic Data Dependency: The approach relies entirely on synthetic training data generated from manufacturing documents, creating fundamental dependency on documentation quality
- Client-Server Architecture Constraints: The current implementation requires offloading computation to backend servers, introducing latency that may be prohibitive for certain AR applications
- Object Type Restriction: The method is specifically designed for flat, texture-less industrial objects with unknown performance on objects with complex geometry or surface textures

## Confidence

**High Confidence**: The synthetic data generation pipeline using SVG extraction and the two-stage detection-then-pose-estimation architecture are well-founded approaches with clear mechanisms.

**Medium Confidence**: The real-world performance claims are based on qualitative evaluation on a sorting task and quantitative evaluation on HoloLens 2 data, but the sample size and diversity of tested scenarios are not fully specified.

**Low Confidence**: The long-term viability of the SVG-to-3D-mesh pipeline for complex industrial objects remains unproven, and the approach's performance on objects significantly different from the test set is unknown.

## Next Checks

1. **Ablation Study on Synthetic Data Diversity**: Systematically vary the proportion of photorealistic vs. non-photorealistic training data and measure the impact on real-world performance to quantify the value of domain randomization.

2. **Latency Optimization Analysis**: Profile the complete client-server pipeline to identify bottlenecks and evaluate whether edge-device processing of the object detector (while keeping pose estimation server-side) provides acceptable trade-offs.

3. **Cross-Object Generalization Test**: Evaluate the trained model on a completely different set of flat, texture-less industrial objects from new manufacturing documents to assess whether the approach generalizes beyond the specific training set.