---
ver: rpa2
title: Interpretable Graph Neural Networks for Heterogeneous Tabular Data
arxiv_id: '2408.07661'
source_url: https://arxiv.org/abs/2408.07661
tags:
- data
- graph
- ignh
- features
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces IGNH (Interpretable Graph Neural Network\
  \ for Heterogeneous tabular data), a method that handles both categorical and numerical\
  \ features while generating exact feature attributions alongside predictions. IGNH\
  \ converts tabular data into graphs where features are nodes and edges represent\
  \ correlations between features, using appropriate correlation measures (Point-biserial\
  \ for categorical-numerical, Kendall's \u03C4 for categorical-categorical, and Pearson\
  \ for numerical-numerical)."
---

# Interpretable Graph Neural Networks for Heterogeneous Tabular Data

## Quick Facts
- arXiv ID: 2408.07661
- Source URL: https://arxiv.org/abs/2408.07661
- Authors: Amr Alkhatib; Henrik Boström
- Reference count: 40
- Primary result: IGNH outperforms Random Forests and TabNet on 30 datasets while achieving comparable performance to XGBoost, particularly excelling on categorical datasets (99.4% AUC on Poker Hand vs XGBoost's 90.7%)

## Executive Summary
IGNH introduces a graph neural network approach for heterogeneous tabular data that converts features into nodes and relationships into edges using appropriate correlation measures for different feature type combinations. The method maintains interpretability by using distinct nodes per feature, weighted self-loops, and an injective readout function that generates exact feature attributions summing to predictions. Empirical results demonstrate that IGNH's feature attributions align with post-hoc Shapley values while achieving superior predictive performance compared to established methods on datasets with mixed numerical and categorical features.

## Method Summary
IGNH transforms heterogeneous tabular data into graph representations where features become nodes and edges represent correlations between features, using Point-biserial correlation for categorical-numerical pairs, Kendall's τ for categorical-categorical pairs, and Pearson correlation for numerical-numerical pairs. The model employs 6 message-passing layers with 90% self-loop weights to maintain feature importance, and an injective readout function ensures exact feature attributions that sum to predictions. The method handles missing values, categorical encoding, and uses statistical significance testing (p<0.05) to filter weak correlations. No hyperparameter tuning was performed, using default settings across all experiments on 30 datasets from OpenML.

## Key Results
- IGNH significantly outperforms Random Forests and TabNet on 30 datasets while matching XGBoost performance
- On categorical-rich datasets, IGNH achieves 99.4% AUC on Poker Hand dataset versus XGBoost's 90.7%
- Feature attributions from IGNH align with Shapley values computed via KernelSHAP, showing convergence across iterations
- IGNH handles missing values and mixed data types without preprocessing degradation

## Why This Works (Mechanism)

### Mechanism 1
IGNH converts heterogeneous tabular data into interpretable graphs by using feature-specific correlation measures. Numerical features use Pearson correlation, categorical-numerical pairs use Point-biserial, and categorical-categorical pairs use Kendall's τ. This ensures valid correlation estimation for each feature type combination.

Core assumption: Correlation coefficients from different statistical measures can be meaningfully combined into a single weighted graph.

Evidence anchors:
- [abstract]: "using appropriate correlation measures (Point-biserial for categorical-numerical, Kendall's τ for categorical-categorical, and Pearson for numerical-numerical)"
- [section]: "the Point-biserial correlation coefficient [13], a special case of the Pearson correlation adapted to handle one dichotomous (binary) variable" and "the Kendall rank correlation coefficient (Kendall's τ coefficient) [17]"

Break condition: If correlation values between heterogeneous feature types are not statistically significant, no edges are added, potentially producing a null graph.

### Mechanism 2
IGNH's interpretability comes from exact feature attributions that sum to the prediction. Each node has a high self-loop weight, and the final readout function is injective, mapping each node's representation to a scalar that directly contributes to the prediction sum.

Core assumption: Maintaining distinct nodes per feature across layers and using weighted self-loops preserves the direct relationship between input features and final attributions.

Evidence anchors:
- [abstract]: "constraining the learning process to generate exact feature attributions together with the predictions"
- [section]: "the weight of the self-loop ωi,i is essential for the model's interpretability" and "an injective mapping style readout function that allows the contribution of each node to be directly linked to the predicted outcome"

Break condition: If the readout function is not injective or self-loops are not weighted sufficiently, attributions may not sum exactly to the prediction.

### Mechanism 3
IGNH's feature attributions align with true Shapley values, providing faithful explanations. KernelSHAP explanations converge toward IGNH's scores across iterations, indicating the scores reflect true feature contributions.

Core assumption: If post-hoc Shapley-based explanations converge to a model's attributions, those attributions must reflect the true feature importance.

Evidence anchors:
- [abstract]: "the feature attributions provided by IGNH align with Shapley values that are computed post hoc"
- [section]: "KernelSHAP is used to explain IGNH, and the generated explanations are compared to IGNH's scores after each iteration of KernelSHAP's data sampling and evaluation"

Break condition: If KernelSHAP fails to converge or converges to different values, attributions may not reflect true Shapley values.

## Foundational Learning

- Concept: Correlation measures for different data types (Pearson, Point-biserial, Kendall's τ)
  - Why needed here: IGNH requires appropriate correlation measures for numerical-numerical, categorical-numerical, and categorical-categorical feature pairs to build valid graph edges
  - Quick check question: Why can't Pearson correlation be used for categorical-categorical pairs?

- Concept: Graph Neural Networks (GNNs) and message passing
  - Why needed here: IGNH uses GNNs to process graph representations of tabular data, requiring understanding of how node representations are updated through message passing
  - Quick check question: What role do self-loops play in maintaining interpretability in IGNH?

- Concept: Shapley values and feature attribution methods
  - Why needed here: Evaluating IGNH's explanations requires understanding of Shapley values as the gold standard for feature attribution
  - Quick check question: How does KernelSHAP approximate Shapley values, and why does convergence matter?

## Architecture Onboarding

- Component map:
  - Preprocessing: Data normalization, categorical encoding, correlation computation
  - Graph construction: Node creation, edge weight calculation, statistical significance testing
  - GNN model: Embedding layers, message passing layers, readout function
  - Training: Loss computation, gradient updates
  - Inference: Graph transformation, prediction, attribution extraction

- Critical path:
  1. Convert tabular data to graph representation using feature-specific correlations
  2. Train GNN with weighted self-loops and injective readout
  3. Generate predictions with exact feature attributions

- Design tradeoffs:
  - Using multiple correlation measures adds complexity but enables handling heterogeneous data
  - Statistical significance testing prevents noise but may eliminate weak but meaningful correlations
  - High self-loop weights ensure interpretability but may reduce message passing effectiveness

- Failure signatures:
  - Null graph: No edges created due to insignificant correlations
  - Poor performance: Model fails to capture feature interactions adequately
  - Non-converging attributions: Feature scores don't align with Shapley values

- First 3 experiments:
  1. Test graph construction with synthetic data having known correlations to verify correct edge weights
  2. Train on a small dataset and verify that feature attributions sum exactly to predictions
  3. Compare IGNH attributions to KernelSHAP on a validation set to confirm convergence behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does IGNH perform on datasets with missing values compared to datasets without missing values?
- Basis in paper: [inferred] The paper mentions that IGNH can handle missing values, but does not provide a direct comparison of its performance on datasets with and without missing values.
- Why unresolved: The paper does not present any empirical results or analysis comparing IGNH's performance on datasets with and without missing values.
- What evidence would resolve it: Empirical results comparing IGNH's performance on datasets with and without missing values, using appropriate metrics such as AUC or accuracy.

### Open Question 2
- Question: How does IGNH's performance scale with the size of the dataset?
- Basis in paper: [inferred] The paper presents results on 30 datasets with varying sizes, but does not provide a systematic analysis of how IGNH's performance scales with dataset size.
- Why unresolved: The paper does not include any analysis or experiments specifically designed to evaluate IGNH's scalability with respect to dataset size.
- What evidence would resolve it: Empirical results evaluating IGNH's performance on datasets of increasing size, using appropriate metrics such as AUC or accuracy, and analyzing the relationship between dataset size and performance.

### Open Question 3
- Question: How does IGNH's interpretability compare to other interpretable GNN approaches?
- Basis in paper: [inferred] The paper claims that IGNH provides exact feature attributions, but does not compare its interpretability to other interpretable GNN approaches.
- Why unresolved: The paper does not include any comparison or analysis of IGNH's interpretability relative to other interpretable GNN approaches.
- What evidence would resolve it: A systematic comparison of IGNH's interpretability to other interpretable GNN approaches, using appropriate metrics such as the quality of explanations or the alignment with true Shapley values.

## Limitations

- Limited architectural details provided (hidden layer sizes, activation functions) without hyperparameter tuning performed
- Null graph issue acknowledged but not thoroughly addressed - weak correlations may be eliminated by significance testing
- Memory constraints may arise with categorical features having many categories due to high dimensionality

## Confidence

High confidence in the core mechanism of using feature-specific correlation measures for graph construction and maintaining interpretability through weighted self-loops and injective readout functions. Medium confidence in the empirical performance claims due to the lack of hyperparameter optimization. High confidence in the alignment with Shapley values based on the convergence evidence provided.

## Next Checks

1. Test graph construction on synthetic datasets with known correlations to verify edge weight calculations and statistical significance filtering
2. Implement the full IGNH architecture with different correlation thresholds to study the trade-off between graph connectivity and noise reduction
3. Compare feature attributions from IGNH against exact Shapley values on small datasets where exact computation is feasible