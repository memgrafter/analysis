---
ver: rpa2
title: Agent Workflow Memory
arxiv_id: '2409.07429'
source_url: https://arxiv.org/abs/2409.07429
tags:
- workflows
- workflow
- agent
- action
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Agent Workflow Memory (AWM) is a method that enables language model-based
  agents to learn and apply reusable task workflows, similar to how humans abstract
  common routines from past experiences. AWM induces workflows from agent trajectories
  by extracting reusable routines and integrates them into agent memory to guide future
  task-solving.
---

# Agent Workflow Memory

## Quick Facts
- arXiv ID: 2409.07429
- Source URL: https://arxiv.org/abs/2409.07429
- Reference count: 17
- Primary result: AWM achieves 24.6% and 51.1% relative success rate increases on Mind2Web and WebArena web navigation benchmarks

## Executive Summary
Agent Workflow Memory (AWM) is a method that enables language model-based agents to learn and apply reusable task workflows, similar to how humans abstract common routines from past experiences. The method induces workflows from agent trajectories by extracting reusable routines and integrates them into agent memory to guide future task-solving. AWM was evaluated on two major web navigation benchmarks covering over 1000 tasks across 200+ domains, demonstrating significant improvements over baseline methods and efficient learning capabilities with only tens of examples.

## Method Summary
AWM operates by inducing workflows from agent trajectories, extracting reusable routines, and integrating these workflows into agent memory to guide future task-solving. The method works in both offline and online scenarios - inducing workflows from training examples beforehand or from test queries on the fly. When an agent successfully completes a task, AWM identifies common patterns in the action sequence and abstracts them into workflows that capture essential skills. These workflows are then stored in memory and can be referenced during future tasks, reducing the need to rediscover basic steps and enabling more efficient task completion.

## Key Results
- AWM achieved 24.6% and 51.1% relative success rate increases on Mind2Web and WebArena benchmarks respectively
- On WebArena, AWM surpassed the top autonomous method by 51.1% and even outperformed methods with human-written workflows by 7.9%
- The method reduced the number of steps needed to solve tasks successfully and demonstrated rapid learning capabilities with only tens of examples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AWM improves agent performance by extracting reusable sub-routines from successful task trajectories and storing them as workflows
- Mechanism: When an agent successfully completes a task, the system identifies common patterns in the action sequence and abstracts them into workflows. These workflows capture essential skills that can be reused across similar tasks. During future task-solving, the agent can reference these workflows to guide its actions, reducing the need to rediscover basic steps.
- Core assumption: Common sub-routines exist across different tasks and can be effectively identified through pattern extraction from successful trajectories.
- Evidence anchors:
  - [abstract] "AWM induces workflows from agent trajectories by extracting reusable routines and integrates them into agent memory to guide future task-solving."
  - [section] "AWM induces workflows from agent trajectories by extracting reusable routines, and then integrates these workflows into agent memory to guide future task-solving processes."
  - [corpus] Weak - corpus neighbors discuss experience replay and memory augmentation but don't specifically address workflow extraction mechanisms.

### Mechanism 2
- Claim: The online learning capability allows agents to continuously improve by adding new workflows from successful experiences during inference
- Mechanism: As the agent processes each test task, it evaluates whether the task was solved successfully. If successful, it induces workflows from that experience and adds them to its memory. This creates a cumulative knowledge base that grows with each solved task, allowing the agent to handle increasingly complex tasks by building on previously learned workflows.
- Core assumption: The agent can accurately evaluate its own success and that newly induced workflows will be relevant to future tasks.
- Evidence anchors:
  - [abstract] "AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly."
  - [section] "Agents with AWM online process test queries in a streaming fashion, where the agents conduct the loop of induce, integrate, and utilize workflows after running inference for each test task."
  - [corpus] Moderate - contextual experience replay is mentioned but not the specific online workflow induction mechanism.

### Mechanism 3
- Claim: Abstract workflow representation enables better generalization than concrete example trajectories
- Mechanism: Workflows represent tasks at a higher level of abstraction by replacing specific values with variables (e.g., "{product-name}" instead of "dry cat food"). This abstraction allows workflows to be applied to a wider range of similar tasks. Additionally, workflows focus on reusable sub-routines rather than full task trajectories, making them more flexible.
- Core assumption: Abstract representations can effectively guide concrete actions without losing task-specific details needed for successful execution.
- Evidence anchors:
  - [abstract] "Each workflow represents a goal with a common routine extracted from available action trajectories, which allows it to effectively capture the most essential and reusable skills agents need to acquire."
  - [section] "we enhance workflow generality by abstracting out example-specific contexts, i.e., replacing 'dry cat food' with a more general name '{product-name}'"
  - [corpus] Moderate - AutoFlow discusses automated workflow generation but doesn't emphasize the abstraction advantage.

## Foundational Learning

- Concept: Experience replay and memory augmentation in reinforcement learning
  - Why needed here: AWM builds on the principle that agents can learn from past experiences, similar to how reinforcement learning agents store and replay experiences. Understanding this foundation helps explain why storing workflows in memory improves performance.
  - Quick check question: How does experience replay help agents avoid catastrophic forgetting and improve sample efficiency?

- Concept: Program synthesis and code abstraction
  - Why needed here: The workflow representation uses programmatic constructs (functions with parameters) to represent reusable routines. Understanding how code abstraction works is crucial for grasping how workflows can generalize across tasks.
  - Quick check question: What is the difference between a concrete program and an abstract program with parameters, and how does this relate to workflow generalization?

- Concept: Few-shot learning and in-context learning
  - Why needed here: AWM operates in scenarios where limited examples are available, similar to few-shot learning. Understanding how models can learn from few examples helps explain AWM's efficiency.
  - Quick check question: How does in-context learning differ from fine-tuning, and what are the limitations of each approach for agent adaptation?

## Architecture Onboarding

- Component map: Agent Backbone (LM) -> Memory Module -> Workflow Induction Module -> Evaluation Module -> Environment Interface
- Critical path: Task instruction → LM action generation → Environment execution → Experience creation → Workflow induction (if successful) → Memory update → Next task
- Design tradeoffs:
  - Workflow granularity: Fine-grained workflows are more reusable but may be too specific; coarse workflows are more general but may miss important details
  - Abstraction level: Higher abstraction enables better generalization but may reduce guidance specificity
  - Memory overhead: More workflows improve performance but increase memory usage and context length
- Failure signatures:
  - Performance plateaus quickly: Workflows may be too specific or not capturing the right abstractions
  - Success rate decreases over time: Evaluation module may be incorrectly labeling failures as successes
  - Agent ignores workflows: Workflows may be poorly formatted or not relevant to current tasks
  - Context length exceeded: Too many workflows are being stored, causing context truncation
- First 3 experiments:
  1. Run AWM on a single website with 10 tasks, manually inspect the induced workflows to verify they capture correct abstractions
  2. Compare success rates with and without workflows on a held-out test set to measure the impact of workflow integration
  3. Measure the overlap between workflows to ensure they are capturing diverse functionality rather than redundant patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between abstract workflows and concrete examples in agent memory?
- Basis in paper: [explicit] The paper compares AWM's abstract workflows to Synapse's concrete examples, showing AWM achieves better performance.
- Why unresolved: The paper shows AWM outperforms methods using concrete examples, but doesn't explore what ratio of abstract to concrete examples might be optimal.
- What evidence would resolve it: Experiments varying the proportion of abstract workflows vs. concrete examples in memory and measuring performance impact.

### Open Question 2
- Question: How do AWM's workflows perform in environments with significant visual components?
- Basis in paper: [inferred] The paper focuses on text-based web navigation tasks and mentions VisualWebArena as a multimodal extension, but doesn't evaluate AWM on it.
- Why unresolved: AWM is only evaluated on text-based benchmarks, leaving its effectiveness on visual tasks unexplored.
- What evidence would resolve it: Applying AWM to multimodal web navigation tasks and comparing performance to text-only baselines.

### Open Question 3
- Question: What is the impact of workflow utility rate on agent performance?
- Basis in paper: [explicit] The paper reports workflow utility rates of 0.94 for WebArena and 0.91 for Mind2Web, but doesn't analyze their correlation with performance.
- Why unresolved: While utility rates are reported, the paper doesn't investigate how they relate to task success or whether there's an optimal utility threshold.
- What evidence would resolve it: Correlation analysis between workflow utility rates and task success rates across different domains and tasks.

## Limitations
- Workflow induction process relies on unspecified GPT-4 prompts, making exact reproduction impossible
- Missing implementation details for the LM-based evaluation model used in online AWM
- Only validated results using GPT-4, leaving generalizability to other models uncertain

## Confidence
- **High confidence**: AWM improves task success rates on both WebArena and Mind2Web datasets compared to baseline methods
- **Medium confidence**: The online learning capability of AWM generalizes well across different cross-task and cross-domain settings
- **Medium confidence**: Workflows provide more efficient trajectories than baseline methods by reducing the number of steps needed

## Next Checks
1. **Prompt engineering validation**: Test different GPT-4 prompts for workflow induction to verify the method is robust to prompt variations and not over-tuned to a specific prompt template
2. **Cross-model generalization**: Implement AWM with multiple LLMs (GPT-3.5, Claude, LLaMA) to confirm the approach works across different model families, not just GPT-4
3. **Failure analysis**: Systematically examine failed tasks to determine if workflows are being incorrectly induced from unsuccessful experiences, validating the effectiveness of the evaluation module