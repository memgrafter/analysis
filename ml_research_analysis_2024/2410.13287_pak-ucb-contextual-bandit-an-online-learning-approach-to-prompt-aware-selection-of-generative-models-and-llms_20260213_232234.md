---
ver: rpa2
title: 'PAK-UCB Contextual Bandit: An Online Learning Approach to Prompt-Aware Selection
  of Generative Models and LLMs'
arxiv_id: '2410.13287'
source_url: https://arxiv.org/abs/2410.13287
tags:
- generative
- selection
- pak-ucb
- learning
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of selecting the best prompt-based
  generative model (including LLMs and text-to-image/video models) for a given text
  prompt, recognizing that different models perform better on different prompt types.
  The core method is PAK-UCB, a contextual bandit algorithm that learns arm-specific
  kernel-based prediction functions to estimate the expected score of each model for
  incoming prompts, updated online as more data is generated.
---

# PAK-UCB Contextual Bandit: An Online Learning Approach to Prompt-Aware Selection of Generative Models and LLMs

## Quick Facts
- **arXiv ID**: 2410.13287
- **Source URL**: https://arxiv.org/abs/2410.13287
- **Reference count**: 40
- **Key outcome**: PAK-UCB and RFF-UCB significantly outperform baselines in online prompt-aware selection of generative models, achieving fast convergence to the best model for different prompt types across text-to-image, image-captioning, and LLM tasks.

## Executive Summary
This paper addresses the challenge of selecting the optimal prompt-based generative model (including LLMs and text-to-image/video models) for a given text prompt. The proposed PAK-UCB algorithm learns arm-specific kernel-based prediction functions to estimate expected performance scores for incoming prompts, updating these estimates online as more data is generated. A variant using random Fourier features (RFF-UCB) reduces computational cost while maintaining performance. Experiments demonstrate significant improvements over baseline methods like KernelUCB and LinUCB in terms of outscore-the-best and optimal-pick-ratio metrics across multiple generative AI tasks.

## Method Summary
The PAK-UCB algorithm treats online generative model selection as a contextual bandit problem where each prompt is a context and each model is an arm. For each model, it maintains a kernel ridge regression estimator that predicts performance given prompts, updating these estimators online using data from previous selections. The algorithm selects models using upper confidence bound (UCB) scores that balance exploration and exploitation. RFF-UCB approximates kernel functions using random Fourier features to reduce computational complexity from O(t³) to O(tD²) per iteration. The framework supports various kernel types (linear, polynomial, RBF) and works with CLIP embeddings for prompts and CLIPScore or task-specific metrics for evaluation.

## Key Results
- PAK-UCB and RFF-UCB achieve 2.6-10.9% higher outscore-the-best (OtB) than baselines across text-to-image tasks
- PAK-UCB reaches optimal-pick-ratio (OPR) of 0.5-0.7 within 1000 iterations for LLM tasks
- RFF-UCB with polynomial kernel performs best on most tasks while reducing computational costs
- Both algorithms demonstrate rapid convergence to the best model for different prompt types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PAK-UCB learns model-specific kernel functions to predict performance for different prompt types, avoiding the suboptimality of shared-weight baselines.
- Mechanism: For each incoming prompt, PAK-UCB computes arm-specific KRR estimators and uncertainty bounds (UCB scores) using prompt-score pairs from iterations where that model was chosen. It then selects the model with the highest UCB score.
- Core assumption: The relationship between prompts and model performance is kernel-representable and differs across models.
- Evidence anchors: [abstract]: "PAK-UCB algorithm addresses a contextual bandit (CB) setting with shared context variables across the arms, utilizing the generated data to update kernel-based functions that predict the score of each model"; [section]: "Specifically, for each model g ∈ G, we assume the existence of a (possibly non-linear and infinite-dimensional) feature map ϕ and a weight w⋆g in an RKHS, such that the score sg(y) conditioned on the prompt y is given by (ϕ(y))⊤w⋆g"
- Break condition: If prompt-performance relationships are not kernel-representable or if models have identical performance across all prompt types.

### Mechanism 2
- Claim: Random Fourier Features (RFF) enable computational scalability by approximating kernel functions in a low-dimensional space.
- Mechanism: RFF maps high-dimensional prompts to a randomized 2D-dimensional feature space using cosine/sine transformations, then applies linear ridge regression. This reduces per-iteration computation from O(t³) to O(tD²).
- Core assumption: The kernel function is shift-invariant (e.g., RBF kernel), enabling RFF approximation.
- Evidence anchors: [section]: "we leverage the random Fourier features (RFF) sampling (Rahimi & Recht, 2007a) for shift-invariant kernel functions, e.g., the RBF (Gaussian) kernel"; [section]: "At a high level, RFF maps the input data, e.g., the prompt (vector) in our setting, to a randomized low-dimensional feature space and then learns a linear model in the resulting random space"
- Break condition: If the kernel is not shift-invariant or if D is too small for accurate approximation.

### Mechanism 3
- Claim: The contextual bandit formulation naturally handles the online, adaptive selection problem where different models excel on different prompt categories.
- Mechanism: The algorithm treats each prompt as context and each model as an arm, using UCB scores to balance exploration (trying less-chosen models) and exploitation (selecting currently best-performing models).
- Core assumption: The prompt distribution is stationary or changes slowly enough for the algorithm to adapt over time.
- Evidence anchors: [abstract]: "An online identification of the best generation model for various input prompts can reduce the costs associated with querying sub-optimal models"; [section]: "We highlight that the described online learning task can be viewed as a contextual bandit (CB) problem widely studied in the bandit literature"
- Break condition: If prompt distribution changes too rapidly for the algorithm to track or if exploration parameter is mis-tuned.

## Foundational Learning

- Concept: Kernel ridge regression (KRR) for non-linear function approximation
  - Why needed here: KRR provides the prediction mechanism for estimating model performance given prompts, handling non-linear relationships
  - Quick check question: What is the computational complexity of KRR per iteration, and how does RFF address this bottleneck?

- Concept: Contextual bandit algorithms and UCB exploration
  - Why needed here: The problem is naturally formulated as selecting the best model (arm) given a prompt (context), with UCB providing principled exploration
  - Quick check question: How does PAK-UCB differ from standard kernelized CB in its treatment of arms?

- Concept: Random Fourier Features for kernel approximation
  - Why needed here: RFF enables scalable kernel methods by approximating kernel functions in finite-dimensional spaces
  - Quick check question: Under what conditions on the kernel function does RFF provide unbiased estimates?

## Architecture Onboarding

- Component map: Text prompts (CLIP/embedded) -> PAK-UCB algorithm with per-arm KRR estimators -> Model selection -> Sample generation -> Score evaluation -> Update
- Critical path: Prompt → Feature extraction → KRR estimation → UCB computation → Model selection → Sample generation → Score evaluation → Update
- Design tradeoffs:
  - Accuracy vs. computational cost: Full kernel vs. RFF approximation
  - Exploration vs. exploitation: UCB parameter η
  - Model complexity: Polynomial kernel degree vs. RBF bandwidth
- Failure signatures:
  - Slow convergence: Insufficient exploration or poor kernel choice
  - High regret: Mis-specified kernel function or non-stationary prompt distribution
  - Computational bottlenecks: Large D or insufficient hardware
- First 3 experiments:
  1. Implement PAK-UCB with linear kernel on a simple two-model T2I task (Stable Diffusion vs. PixArt-α) with fixed prompt categories
  2. Add polynomial kernel and compare performance on the same task
  3. Implement RFF-UCB with RBF kernel and compare computational time vs. accuracy trade-off on a larger model set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can PAK-UCB be extended to handle dynamic model arrivals or departures during the online selection process?
- Basis in paper: [inferred] The paper mentions the ability to adapt to new models and prompts in Setup 3, but does not provide a formal analysis of handling dynamic model sets.
- Why unresolved: The current framework assumes a fixed set of models, and no theoretical guarantees are provided for scenarios where models are added or removed during the selection process.
- What evidence would resolve it: Experiments and theoretical analysis showing regret bounds and convergence properties when models are dynamically added or removed.

### Open Question 2
- Question: How does the performance of PAK-UCB and RFF-UCB scale with the dimensionality of the prompt embeddings?
- Basis in paper: [inferred] The paper uses CLIP embeddings and mentions that the RFF-UCB reduces computational complexity, but does not explicitly analyze the impact of embedding dimensionality on performance.
- Why unresolved: While RFF-UCB reduces computational costs, the effect of high-dimensional prompt embeddings on the regret bounds and convergence speed is not addressed.
- What evidence would resolve it: Experiments varying the dimensionality of prompt embeddings and theoretical analysis of how dimensionality affects the regret bounds.

### Open Question 3
- Question: Can the PAK-UCB framework be adapted to handle non-stationary reward distributions, where the performance of models changes over time?
- Basis in paper: [inferred] The paper focuses on stationary settings, but mentions the potential for adaptation in real-time scenarios in the conclusion.
- Why unresolved: The current analysis assumes stationary reward distributions, and no mechanism is provided to handle temporal changes in model performance.
- What evidence would resolve it: Experiments demonstrating the performance of PAK-UCB in non-stationary environments and theoretical extensions of the regret bounds to account for changing reward distributions.

## Limitations

- Performance under non-stationary conditions: The algorithm assumes prompt distributions remain stable, with no evidence of performance when distributions shift significantly or exhibit concept drift.
- Kernel parameter sensitivity: The paper doesn't systematically analyze how sensitive results are to kernel parameter choices, which could lead to suboptimal performance.
- Computational scaling with model count: The arm-specific approach may become increasingly costly as the model pool grows, though this isn't explicitly examined.

## Confidence

**High confidence**: The core algorithmic framework and theoretical foundations are sound. The contextual bandit formulation is appropriate for the online model selection problem, and the use of kernel ridge regression for function approximation is well-established.

**Medium confidence**: The practical effectiveness depends heavily on proper hyperparameter tuning and the assumption that prompt-performance relationships are kernel-representable. While results are promising, generalizability to unseen prompt distributions requires further validation.

**Low confidence**: Claims about computational efficiency gains from RFF-UCB lack detailed benchmarking against the full kernel implementation across varying problem scales.

## Next Checks

1. **Distribution shift robustness test**: Evaluate PAK-UCB performance when prompt distributions gradually shift from training conditions (e.g., introducing new prompt categories or changing prompt frequencies). Measure how quickly the algorithm adapts and whether it maintains competitive performance compared to static selection methods.

2. **Kernel sensitivity analysis**: Systematically vary kernel parameters (polynomial degree, RBF bandwidth, regularization strength) across the full range of reasonable values for each task. Quantify performance degradation when using sub-optimal parameters and identify which parameters are most critical for each task type.

3. **Large-scale model pool scalability**: Test PAK-UCB and RFF-UCB with increasing numbers of candidate models (10, 20, 50, 100+) on a representative task. Measure both computational time per iteration and selection quality (OPR, OtB) to identify scaling bottlenecks and evaluate whether the arm-specific approach remains practical at scale.