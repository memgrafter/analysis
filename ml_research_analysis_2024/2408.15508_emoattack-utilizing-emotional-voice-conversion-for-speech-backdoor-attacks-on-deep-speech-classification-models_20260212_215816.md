---
ver: rpa2
title: 'EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks
  on Deep Speech Classification Models'
arxiv_id: '2408.15508'
source_url: https://arxiv.org/abs/2408.15508
tags:
- speech
- backdoor
- attack
- attacks
- trigger
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses backdoor attacks on deep speech classification
  models, particularly in keyword spotting and speaker verification. It introduces
  EmoAttack, a novel method that exploits emotional voice conversion (EVC) as a trigger
  to embed backdoors in speech classification models.
---

# EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models

## Quick Facts
- arXiv ID: 2408.15508
- Source URL: https://arxiv.org/abs/2408.15508
- Reference count: 34
- Primary result: Introduces EmoAttack, using emotional voice conversion as a backdoor trigger achieving up to 99.99% attack success rate with as few as 50 poisoned samples

## Executive Summary
This work introduces EmoAttack, a novel method that exploits emotional voice conversion (EVC) to embed backdoors in speech classification models. By converting the emotion of speech samples while preserving linguistic content and speaker identity, EmoAttack effectively associates specific emotional categories with target labels. The attack demonstrates high success rates with minimal poisoned samples, maintaining stealthiness and audio quality. Experiments show superior performance compared to existing approaches, particularly when targeting intense emotions like anger or happiness.

## Method Summary
EmoAttack uses emotional voice conversion to modify speech emotion while preserving linguistic content and speaker identity. The process involves: (1) detecting emotional states using a speech emotion recognition model, (2) converting selected samples to target emotions using StarGAN-EVC, (3) relabeling converted samples to the target label, and (4) training models on poisoned datasets. During inference, applying the EVC trigger activates the backdoor, causing misclassification. The attack targets both keyword spotting and speaker verification tasks using datasets like Google Speech Commands v2, VoxCeleb1, and TIMIT.

## Key Results
- Attack success rates up to 99.99% with as few as 50 poisoned samples
- Outperforms existing approaches, especially for intense emotions like anger or happiness
- Maintains audio quality and stealthiness while achieving high effectiveness
- Demonstrates vulnerability of speech classification models to emotion-based backdoor attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EmoAttack uses emotional voice conversion to embed backdoors by converting speech emotion while preserving linguistic content and speaker identity.
- Mechanism: The EVC trigger modifies emotional state, causing the model to associate target emotion with target label during training. At inference, the model misclassifies when the trigger is applied.
- Core assumption: Emotional state is a higher-level perceptual attribute that speech models learn to recognize and can be exploited.
- Evidence anchors: Abstract confirms emotion conversion while preserving content; section describes EVC model converting emotion while preserving other components.
- Break condition: If models are trained to be robust against emotion variations or EVC fails to preserve content.

### Mechanism 2
- Claim: Attack effectiveness depends on emotion intensity, with more intense emotions like anger or happiness being more effective.
- Mechanism: Intense emotional states create stronger associations between emotion and target label, making backdoors more reliable during activation.
- Core assumption: Models are more sensitive to intense emotional variations and learn these associations more robustly.
- Evidence anchors: Abstract mentions high attack success rates; ablation experiments found intensive emotion more suitable for attacks.
- Break condition: If models are trained on diverse emotional data or conversion doesn't significantly change perceived intensity.

### Mechanism 3
- Claim: EmoAttack maintains stealthiness by preserving audio quality and avoiding detectable modifications.
- Mechanism: By modifying only the emotional component while keeping linguistic content and speaker identity intact, poisoned samples sound natural and avoid detection.
- Core assumption: Speech models are vulnerable to backdoor attacks that modify higher-level perceptual attributes without affecting basic acoustic features.
- Evidence anchors: Abstract notes method outperforms existing approaches; findings highlight new vulnerabilities in speech models.
- Break condition: If emotional conversion introduces artifacts or detection systems identify emotional state changes.

## Foundational Learning

- Concept: Speech Emotion Recognition (SER)
  - Why needed here: Attack uses SER to identify emotional state of samples and determine targeting strategy
  - Quick check question: How does SER model determine emotional category, and what emotions are typically recognized?

- Concept: Voice Conversion (VC) and Emotional Voice Conversion (EVC)
  - Why needed here: Attack relies on VC/EVC technology to modify emotional state while preserving acoustic properties
  - Quick check question: What acoustic features are modified during EVC, and how does conversion maintain speaker identity?

- Concept: Backdoor Attack Mechanisms in Machine Learning
  - Why needed here: Understanding how poisoned samples create hidden vulnerabilities that can be exploited during inference
  - Quick check question: What distinguishes poisoning-label attacks from other backdoor types, and how do they differ in sample modification strategies?

## Architecture Onboarding

- Component map: StarGAN-EVC → Poisoned samples generation → Backdoor dataset construction → Speech classification model training → Attack stage (EVC trigger application)
- Critical path: Clean dataset → SER emotion detection → EVC conversion to target emotion → Label modification to target label → Model training on poisoned dataset → Inference with EVC trigger
- Design tradeoffs: Stealthiness vs. attack effectiveness - intense emotions increase effectiveness but may be more detectable; fewer poisoned samples maintain stealth but may reduce reliability
- Failure signatures: Low attack success rate despite high poisoning; detection of poisoned samples by humans or systems; model accuracy variance exceeding thresholds
- First 3 experiments:
  1. Test EVC model's ability to convert neutral speech to target emotions while preserving linguistic content and speaker identity
  2. Measure attack success rate with varying poisoned samples (50, 100, 250) on small keyword spotting model
  3. Evaluate audio quality using MOS and SER accuracy on converted samples to ensure stealthiness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does EmoAttack effectiveness vary across different EVC models, and what characteristics contribute to improved performance?
- Basis in paper: [explicit] Uses StarGAN-EVC but doesn't explore alternative models or comparative effectiveness
- Why unresolved: Focuses on single EVC model, leaving uncertainty about whether other models could enhance or reduce attack success
- What evidence would resolve it: Comparative experiments using multiple EVC models to evaluate impact on attack success, stealthiness, and poisoned sample requirements

### Open Question 2
- Question: Can defensive mechanisms be developed to detect or mitigate emotion-based backdoor attacks, and what strategies would be most effective?
- Basis in paper: [inferred] Highlights stealthiness and effectiveness but doesn't address potential defenses or detection methods
- Why unresolved: Focus on attack methodology rather than countermeasures leaves gap in protecting speech systems
- What evidence would resolve it: Development and testing of detection algorithms or defensive training techniques for emotion-based backdoors

### Open Question 3
- Question: How does emotional intensity influence attack robustness under real-world conditions like varying audio quality or background noise?
- Basis in paper: [explicit] Notes intense emotions yield higher success rates but doesn't explore robustness under noisy conditions
- Why unresolved: Experiments in controlled environments leave uncertainty about effectiveness in practical scenarios
- What evidence would resolve it: Experiments testing EmoAttack under varying noise levels, compression, or transmission artifacts

## Limitations

- Generalizability across different speech model architectures remains uncertain
- Real-world applicability limited by assumption of controlled emotional content during training and inference
- Assumes speech models learn emotional representations that can be exploited without exploring resistance methods

## Confidence

- Basic mechanism effectiveness: High confidence (99.99% success rates with minimal poisoned samples)
- Stealthiness claims: Medium confidence (MOS evaluations but primarily subjective measures)
- Intense emotion effectiveness: Medium confidence (ablation experiments but lacks comparative analysis)

## Next Checks

1. Test attack transferability across different speech model architectures (CNN, RNN, Transformer) to verify emotional backdoor mechanism generalization

2. Evaluate detection capability of state-of-the-art audio steganalysis tools on EVC-modified samples to assess real-world stealthiness beyond MOS ratings

3. Measure attack effectiveness when models are pre-trained with emotion-augmented datasets or robust training techniques designed to minimize emotional bias