---
ver: rpa2
title: NAIST Simultaneous Speech Translation System for IWSLT 2024
arxiv_id: '2407.00826'
source_url: https://arxiv.org/abs/2407.00826
tags:
- translation
- alignatt
- speech
- simultaneous
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NAIST's submission to the IWSLT 2024 simultaneous speech translation
  task includes speech-to-text systems for English-to-German, Japanese, and Chinese,
  and a speech-to-speech system for English-to-Japanese. The speech-to-text models
  use multilingual end-to-end architectures combining HuBERT and mBART, trained with
  Local Agreement and AlignAtt decoding policies.
---

# NAIST Simultaneous Speech Translation System for IWSLT 2024

## Quick Facts
- arXiv ID: 2407.00826
- Source URL: https://arxiv.org/abs/2407.00826
- Reference count: 31
- Primary result: NAIST submitted speech-to-text and speech-to-speech systems for IWSLT 2024 using Local Agreement and AlignAtt decoding policies

## Executive Summary
NAIST developed simultaneous speech translation systems for the IWSLT 2024 evaluation campaign, including speech-to-text models for English-to-German, Japanese, and Chinese, and a speech-to-speech system for English-to-Japanese. The systems employ multilingual end-to-end architectures combining HuBERT and mBART50, trained with Local Agreement (LA) and AlignAtt decoding policies. A key innovation is the upgraded incremental TTS module using Transformer architecture with AlignAtt policy, which improved overall system performance. The systems achieved competitive BLEU scores while maintaining low latency, demonstrating the effectiveness of their approach in simultaneous translation scenarios.

## Method Summary
The speech-to-text models use a multilingual end-to-end architecture with HuBERT-Large as the speech encoder and mBART50 as the text decoder, connected via Interconnection and length adapter. Models were pre-trained on MuST-C v2.0 and CoVoST-2, then fine-tuned with Bilingual Prefix Alignment data using Local Agreement (LA-2) and AlignAtt decoding policies. The speech-to-speech system cascades the speech-to-text model with an incremental TTS module featuring a Transformer-based phoneme estimator with AlignAtt policy, acoustic feature predictor (FastPitch), and Parallel WaveGAN vocoder. Training utilized TED-LIUM, Europarl-ST, and JSUT corpora, with text tokenized using multilingual SentencePiece (250K subword units).

## Key Results
- Speech-to-text models achieved BLEU scores of 29.98 (En-De), 15.33 (En-Ja), and 22.30 (En-Zh) with latencies under 2 seconds
- Upgraded TTS module with Transformer architecture and AlignAtt policy improved speech-to-speech system performance
- Speech-to-speech system achieved ASR-BLEU score of 12.08
- LA policy outperformed AlignAtt in high-latency regimes under non-computation-aware measurement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local Agreement (LA) policy outperforms AlignAtt in high-latency regimes under non-computation-aware latency measurement.
- Mechanism: LA compares translation hypotheses across multiple consecutive steps (LA-2) and selects the longest common prefix, which ensures stability but requires more computation time. Since non-computation-aware latency doesn't penalize computation time, LA can afford to wait longer for stable outputs without being penalized.
- Core assumption: Stability of prefixes correlates with translation quality, and computation time is not measured in the evaluation.
- Evidence anchors:
  - [abstract]: "The submitted models employ the LA policy because it outperformed the AlignAtt policy in previous models."
  - [section]: "Our LA-based system outperformed our AlignAtt-based one. However, in real situations, the LA policy is time-consuming, and thus the AlignAtt policy may be better suited to practical applications."
  - [corpus]: Weak - No direct evidence in neighbors about LA vs AlignAtt comparison under non-computation-aware settings.
- Break condition: If computation time becomes a limiting factor or if evaluation shifts to computation-aware latency measurement.

### Mechanism 2
- Claim: AlignAtt policy excels in low-latency regions under computation-aware settings.
- Mechanism: AlignAtt uses cross-attention information to determine when sufficient source information is available for generating a target token. By adjusting parameter f, it can make faster decisions about when to generate, leading to lower latency at the cost of some stability.
- Core assumption: Cross-attention alignment can reliably indicate sufficient source information for target generation, and faster decisions are prioritized in low-latency scenarios.
- Evidence anchors:
  - [abstract]: "Papi et al. (2023) proposed AlignAtt, a method that leverages encoder-decoder attention information in Transformer to establish alignment between source and target tokens during inference."
  - [section]: "The AlignAtt policy works better in low-latency regions in computation-aware settings."
  - [corpus]: Weak - No direct evidence in neighbors about AlignAtt performance in computation-aware settings.
- Break condition: If cross-attention information becomes unreliable or if low-latency decisions compromise translation quality significantly.

### Mechanism 3
- Claim: The upgraded TTS module with Transformer architecture and AlignAtt policy improves speech-to-speech translation quality.
- Mechanism: The incremental TTS module uses a Transformer-based phoneme estimator with AlignAtt policy to predict phonemes and prosodic symbols in parallel. This allows for more natural and accurate synthesis of speech output compared to previous methods.
- Core assumption: Parallel processing of phonemes and prosodic symbols improves the naturalness and accuracy of synthesized speech.
- Evidence anchors:
  - [abstract]: "We improved our incremental TTS by applying the Transformer architecture with the AlignAtt policy for the estimation model. The results show that our upgraded TTS module contributed to improving the system performance."
  - [section]: "The significant difference between the two systems lies in the upgraded TTS, which has an estimation model based on Transformer architecture with the AlignAtt policy."
  - [corpus]: Weak - No direct evidence in neighbors about Transformer-based TTS improvements.
- Break condition: If parallel processing introduces synchronization issues or if the AlignAtt policy fails to provide stable prefixes for TTS input.

## Foundational Learning

- Concept: Simultaneous speech translation and latency metrics
  - Why needed here: Understanding the core problem of real-time translation and how latency is measured is crucial for evaluating and improving the system.
  - Quick check question: What is the difference between non-computation-aware and computation-aware latency measurement, and why does it matter for LA vs AlignAtt policy performance?

- Concept: End-to-end speech-to-text translation models
  - Why needed here: The system uses multilingual end-to-end models combining HuBERT and mBART, so understanding how these models work is essential.
  - Quick check question: How do HuBERT and mBART contribute to the speech-to-text translation model, and what role does the length adapter play?

- Concept: Incremental text-to-speech synthesis
  - Why needed here: The speech-to-speech system relies on an incremental TTS module, so understanding how incremental synthesis works is important.
  - Quick check question: What are the key components of the incremental TTS module, and how does the AlignAtt policy improve phoneme and prosodic symbol estimation?

## Architecture Onboarding

- Component map: Speech waveform -> HuBERT encoder -> Length adapter -> Text decoder with LA/AlignAtt -> Translation output -> TTS module -> Speech waveform

- Critical path: Speech waveform → HuBERT encoder → Length adapter → Text decoder with LA/AlignAtt → Translation output → TTS module → Speech waveform

- Design tradeoffs:
  - LA policy vs AlignAtt: Stability vs latency, computation time not measured vs computation time critical
  - Parallel processing in TTS vs sequential processing: Speed vs potential synchronization issues
  - End-to-end model vs cascade approach: Simplicity vs potential error propagation

- Failure signatures:
  - Poor translation quality with high latency (LA policy issue)
  - Unstable or unnatural speech output (TTS module issue)
  - High computation time with low latency (AlignAtt policy issue)

- First 3 experiments:
  1. Compare LA and AlignAtt policies on a small dataset with both non-computation-aware and computation-aware latency measurements to observe performance differences.
  2. Test the incremental TTS module with different phoneme and prosodic symbol estimation strategies to optimize naturalness and accuracy.
  3. Evaluate the impact of chunk size on translation quality and latency for both speech-to-text and speech-to-speech systems.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the AlignAtt policy perform better than the LA policy when applied to the entire cascade of speech-to-speech translation systems, including both the translation module and the TTS module?
- Basis in paper: [inferred] The paper suggests that the AlignAtt policy might be more suitable for practical applications and shows potential improvements in TTS performance, but only evaluates the LA policy in the final speech-to-speech system.
- Why unresolved: The paper only evaluates the LA policy in the final speech-to-speech system, despite showing that AlignAtt could outperform LA in computation-aware settings for speech-to-text translation.
- What evidence would resolve it: A comprehensive evaluation of both LA and AlignAtt policies in the complete speech-to-speech translation system, measuring not just translation quality but also latency and overall system performance.

### Open Question 2
- Question: How does the chunk size setting affect the performance of the AlignAtt policy in low-latency regions, and what is the optimal chunk size for balancing quality and latency?
- Basis in paper: [explicit] The paper mentions that the AlignAtt policy performs better in low-latency regions in computation-aware settings, but does not explore different chunk size settings for this policy.
- Why unresolved: The paper only tests one chunk size (800 ms) for the AlignAtt policy in the speech-to-speech system and does not explore how different chunk sizes might affect its performance.
- What evidence would resolve it: A systematic study of different chunk sizes (e.g., 500-1000 ms) for the AlignAtt policy, measuring the trade-off between translation quality and latency in both computation-aware and non-computation-aware settings.

### Open Question 3
- Question: Would incorporating WavLM or Hi-Fi GAN architectures improve the performance of the speech-to-text and speech-to-speech translation systems compared to the current HuBERT and Parallel WaveGAN models?
- Basis in paper: [explicit] The paper mentions these architectures as potential future directions but does not evaluate them.
- Why unresolved: The paper only evaluates the current architectures (HuBERT for speech-to-text and Parallel WaveGAN for TTS) and suggests exploring these alternatives without providing empirical evidence.
- What evidence would resolve it: A direct comparison of the current systems with versions using WavLM for speech encoding and Hi-Fi GAN for speech synthesis, measuring improvements in translation quality, latency, and overall system performance.

## Limitations

- Evaluation limited to IWSLT benchmark datasets, potentially limiting real-world applicability
- Comparative analysis of LA vs AlignAtt policies under different latency measurements lacks comprehensive experimental detail
- Specific contributions of individual TTS components to final quality are not clearly isolated

## Confidence

- **High Confidence**: Overall system architecture and implementation details for speech-to-text translation are well-documented and reproducible
- **Medium Confidence**: Performance claims for speech-to-speech system and TTS improvements are supported but could be more thoroughly validated
- **Low Confidence**: Comparative analysis of LA vs AlignAtt policies under different latency measurements lacks sufficient experimental detail

## Next Checks

1. Conduct a controlled experiment comparing LA and AlignAtt policies on a subset of the dataset, explicitly measuring both computation-aware and non-computation-aware latency metrics to validate claimed performance differences.

2. Design experiments to isolate the contributions of the Transformer architecture and AlignAtt policy in the TTS module by comparing performance with and without each component.

3. Test the system on out-of-domain speech data to assess its robustness and generalization capabilities beyond IWSLT benchmarks.