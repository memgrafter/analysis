---
ver: rpa2
title: A Rate-Distortion View of Uncertainty Quantification
arxiv_id: '2406.10775'
source_url: https://arxiv.org/abs/2406.10775
tags:
- uncertainty
- training
- learning
- distance
- codebook
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Distance Aware Bottleneck (DAB), a new
  method for improving uncertainty quantification in deep neural networks. The core
  idea is to learn a compressed representation of the training data as a codebook
  of centroids in the space of probability distributions.
---

# A Rate-Distortion View of Uncertainty Quantification

## Quick Facts
- arXiv ID: 2406.10775
- Source URL: https://arxiv.org/abs/2406.10775
- Authors: Ifigeneia Apostolopoulou; Benjamin Eysenbach; Frank Nielsen; Artur Dubrawski
- Reference count: 40
- One-line primary result: Introduces Distance Aware Bottleneck (DAB) method for uncertainty quantification that outperforms state-of-the-art single-model baselines on OOD detection and misclassification prediction.

## Executive Summary
This paper introduces the Distance Aware Bottleneck (DAB), a novel method for improving uncertainty quantification in deep neural networks. The core idea is to learn a compressed representation of the training data as a codebook of centroids in the space of probability distributions. Uncertainty is then estimated as the statistical distance between a test example and its closest centroid in the codebook. DAB is trained using an information bottleneck objective that jointly regularizes the network representations and learns the codebook. The resulting model is simple to train, provides deterministic uncertainty estimates with a single forward pass, and achieves superior out-of-distribution detection and misclassification prediction compared to prior methods, including expensive ensemble approaches and Gaussian process models.

## Method Summary
DAB introduces a new framework for uncertainty quantification that combines information bottleneck theory with rate-distortion principles. The method learns a codebook of distributions that compress the training data while maintaining predictive power. During training, the model jointly optimizes an information bottleneck objective with a rate-distortion term that encourages the learned representations to stay close to the codebook centroids. At inference time, uncertainty is computed as the statistical distance between a test example's representation and its nearest codebook entry. The approach supports various statistical distances and can be implemented with standard neural network architectures.

## Key Results
- On CIFAR-10, DAB improves AUROC by 3-5% and AUPRC by 1-2% over state-of-the-art single-model baselines
- On ImageNet-1K, DAB bridges the gap with ensembles in terms of calibration while using significantly fewer parameters
- DAB achieves better OOD detection and misclassification prediction than prior methods, including expensive ensemble methods and deep kernel Gaussian Processes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The model learns compressed representations of the training data that act as centroids in a statistical distance space.
- **Mechanism:** By framing uncertainty quantification as a rate-distortion problem, the model learns a codebook of distributions (centroids) that minimize the expected statistical distance from the training data encoders.
- **Core assumption:** The training data encoders can be represented as a mixture of a finite number of distributions (the codebook).
- **Evidence anchors:** The variational marginal q(z; ϕ) encapsulates all encoders p(z | xi; θ) of datapoints in Dtrain encountered during training.

### Mechanism 2
- **Claim:** The model is trained to jointly optimize for prediction accuracy and for keeping the encoders close to the codebook.
- **Mechanism:** The loss function combines the information bottleneck objective (accuracy term) with the rate-distortion term (distance from codebook).
- **Core assumption:** The trade-off between accuracy and regularization (controlled by β) can be tuned to achieve both good predictions and good uncertainty estimates.

### Mechanism 3
- **Claim:** The model can distinguish between in-distribution errors (misclassifications) and out-of-distribution inputs by their distance from the codebook.
- **Mechanism:** In-distribution misclassifications are typically closer to the codebook than out-of-distribution inputs.
- **Core assumption:** The codebook, learned from the training data, will naturally place centroids in regions that correspond to the main modes of the training data distribution.

## Foundational Learning

- **Concept:** Information Bottleneck (IB)
  - **Why needed here:** Provides theoretical framework for learning compressed representations that are still informative about the target.
  - **Quick check question:** What is the main objective of the Information Bottleneck method, and how does it relate to the rate-distortion problem?

- **Concept:** Rate-Distortion Theory
  - **Why needed here:** Provides mathematical framework for quantifying trade-off between compression and fidelity.
  - **Quick check question:** How does the rate-distortion function relate to the trade-off between the number of bits needed to represent data and the fidelity of the reconstruction?

- **Concept:** Statistical Distance Measures
  - **Why needed here:** DAB uses statistical distances (e.g., Kullback-Leibler divergence) to measure distance between distributions.
  - **Quick check question:** What are some common statistical distance measures used to compare probability distributions, and how do they differ from simple Euclidean distances?

## Architecture Onboarding

- **Component map:** Encoder -> Codebook -> Decoder
- **Critical path:** 1) Encode input to latent distribution 2) Compute distance from latent distribution to closest codebook entry 3) Use this distance as uncertainty estimate 4) Backpropagate loss to update encoder, decoder, and codebook
- **Design tradeoffs:** Codebook size (k) vs. computation/memory; Regularization coefficient (β) vs. accuracy/uncertainty; Temperature (α) vs. sharpness of assignments; Latent dimension vs. overfitting
- **Failure signatures:** Poor OOD detection (insufficient k); Overconfident predictions (weak regularization or high latent dimension); Training instability (poorly tuned learning rates)
- **First 3 experiments:** 1) Synthetic regression task to verify uncertainty increases away from training data 2) CIFAR-10 OOD detection using SVHN and CIFAR-100 as OOD datasets 3) Ablation study on codebook size (varying k)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different statistical distance metrics (e.g., Mahalanobis distance, Wasserstein distance) compare to the Kullback-Leibler divergence in terms of OOD detection and calibration performance?
- Basis in paper: The paper mentions that the proposed framework supports inference with alternative statistical distances, but only experiments with the Kullback-Leibler divergence are reported.
- Why unresolved: The paper does not provide experimental results comparing different statistical distances.
- What evidence would resolve it: Experimental results showing the OOD detection and calibration performance of DAB using various statistical distance metrics compared to the Kullback-Leibler divergence.

### Open Question 2
- Question: Can the distance-aware decoder proposed in Section 5.1 be effectively designed and implemented to improve model accuracy and calibration?
- Basis in paper: The paper mentions that a distance-aware decoder could be viewed as a distance-aware epinet and its design is left as future work.
- Why unresolved: The paper does not explore the design or implementation of a distance-aware decoder.
- What evidence would resolve it: A well-designed and implemented distance-aware decoder that improves model accuracy and calibration compared to the standard decoder.

### Open Question 3
- Question: How does DAB perform on tasks beyond image classification, such as natural language processing or time series forecasting?
- Basis in paper: The paper mentions that DAB was primarily demonstrated on image classification tasks and applying it to different settings is an important application area.
- Why unresolved: The paper does not provide experimental results on tasks beyond image classification.
- What evidence would resolve it: Experimental results showing the performance of DAB on tasks such as natural language processing or time series forecasting compared to state-of-the-art methods.

## Limitations

- The theoretical analysis assumes that the training data can be well-represented by a finite mixture of distributions, which may not hold for complex real-world data.
- The choice of statistical distance (KL divergence) is not justified beyond convenience, and other distances might perform better for certain data types.
- The alternating optimization procedure lacks convergence guarantees, and the method's performance depends heavily on hyperparameter tuning.

## Confidence

- **High confidence:** The empirical results showing improved OOD detection and calibration over baselines on CIFAR-10 and ImageNet-1K.
- **Medium confidence:** The theoretical claims about the information bottleneck connection and rate-distortion interpretation, which are sound but rely on assumptions that may not hold in practice.
- **Medium confidence:** The mechanism by which the model distinguishes in-distribution errors from OOD inputs, which is empirically validated but not rigorously proven.

## Next Checks

1. **Ablation study on distance measures:** Compare KL divergence with other statistical distances (e.g., Wasserstein, maximum mean discrepancy) on CIFAR-10 to determine if the choice of distance impacts performance.

2. **Convergence analysis:** Monitor the alternating optimization procedure on CIFAR-10 to empirically verify convergence and study the effect of initialization schemes on final performance.

3. **Scalability test:** Evaluate the method on larger datasets (e.g., CIFAR-100) with varying codebook sizes to determine the practical limits of the approach and identify optimal codebook sizes for different data complexities.