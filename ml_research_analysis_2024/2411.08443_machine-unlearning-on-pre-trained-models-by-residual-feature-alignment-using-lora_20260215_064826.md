---
ver: rpa2
title: Machine Unlearning on Pre-trained Models by Residual Feature Alignment Using
  LoRA
arxiv_id: '2411.08443'
source_url: https://arxiv.org/abs/2411.08443
tags:
- unlearning
- features
- class
- feature
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel machine unlearning method for pre-trained
  models called Residual Feature Alignment Unlearning, which leverages LoRA to decompose
  intermediate features into pre-trained and residual components. The approach aims
  to learn zero residuals on retained data while shifting residuals on unlearning
  data, effectively removing unwanted information while preserving model utility.
---

# Machine Unlearning on Pre-trained Models by Residual Feature Alignment Using LoRA

## Quick Facts
- arXiv ID: 2411.08443
- Source URL: https://arxiv.org/abs/2411.08443
- Authors: Laiqiao Qin; Tianqing Zhu; Linlin Wang; Wanlei Zhou
- Reference count: 40
- This paper introduces a novel machine unlearning method for pre-trained models called Residual Feature Alignment Unlearning, which leverages LoRA to decompose intermediate features into pre-trained and residual components.

## Executive Summary
This paper proposes Residual Feature Alignment Unlearning, a novel method for removing specific data influence from pre-trained models while preserving utility on retained data. The approach uses LoRA modules to decompose intermediate features into pre-trained and residual components, learning zero residuals on retained data while shifting residuals on unlearning data. The method addresses key challenges in machine unlearning including intermediate feature shifts, unlearning initialization, and computational efficiency. Experimental results across multiple datasets and tasks demonstrate the method achieves accuracy and activation distance comparable to retrained models while significantly reducing training time (94% reduction).

## Method Summary
The method inserts LoRA modules at intermediate layers of pre-trained models to output residual features that decompose the original features into pre-trained and residual components. For retained data, these residuals are driven to zero (preserving pre-trained features), while for unlearning data, residuals are shifted toward the average of retained data features, effectively removing unwanted information. The approach uses a loss function that combines intermediate feature alignment with task-specific losses, and employs zero-initialization of LoRA matrices to ensure smooth unlearning initialization without abrupt feature shifts.

## Key Results
- Achieved accuracy and activation distance comparable to retrained models while reducing training time by 94%
- Demonstrated strong privacy protection with membership inference attack success rates close to retrained models
- Validated effectiveness across multiple datasets (CIFAR-10, Fashion-MNIST, IMDB, ELI5-Category) and tasks (image classification, text classification, text generation)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Residual Feature Alignment decomposes intermediate features into pre-trained and residual components using LoRA, enabling targeted unlearning while preserving retained data utility
- Mechanism: The method inserts LoRA modules at intermediate layers that output residual features. For retained data, these residuals are driven to zero (preserving pre-trained features). For unlearning data, residuals are shifted toward the average of retained data features, effectively removing unwanted information
- Core assumption: Intermediate features capture meaningful abstractions that can be manipulated without destroying overall model utility
- Evidence anchors:
  - [abstract] "leverages LoRA to decompose intermediate features into pre-trained and residual components"
  - [section III] "deep neural network...intermediate features...abstract representations learned from a large-scale training set"
  - [corpus] Weak - no direct corpus evidence of this specific mechanism, but related work exists on feature-level unlearning

### Mechanism 2
- Claim: Zero-initialization of LoRA matrices enables smooth unlearning initialization without abrupt feature shifts
- Mechanism: By initializing the LoRA low-rank matrices to zero, the residual features start at zero, ensuring the unlearned model initially matches the pre-trained model. This prevents early-stage deviation that could harm performance on retained data
- Core assumption: Starting from zero residuals allows controlled, gradual unlearning that maintains stability
- Evidence anchors:
  - [section III] "LoRA initializes B and A such that ∆W = BA is zero at the beginning of training"
  - [section IV] "The residual features are initialized to zero (or near-zero), ensuring a smoother update process"
  - [corpus] Weak - corpus doesn't explicitly discuss initialization benefits for unlearning

### Mechanism 3
- Claim: Shifting unlearning features toward retained data averages achieves unlearning while maintaining plausible outputs
- Mechanism: For unlearning data, residual features are targeted to shift the original features toward the average feature distribution of retained data. This makes the model behave as if it never saw those samples while maintaining reasonable outputs
- Core assumption: Average retained data features represent a plausible distribution that maintains utility while removing specific sample influence
- Evidence anchors:
  - [section IV] "we shift the features of Df towards the average distribution of Dr"
  - [section IV] "the summed features on Df are close to the average features on Dr, thereby achieving unlearning while preserving the model's utility"
  - [corpus] Weak - no direct corpus evidence of this specific averaging strategy

## Foundational Learning

- Concept: LoRA (Low-Rank Adaptation)
  - Why needed here: Enables efficient modification of intermediate features with minimal parameters, critical for practical unlearning of large models
  - Quick check question: How does LoRA's low-rank decomposition reduce computational overhead compared to full fine-tuning?

- Concept: Intermediate feature representation
  - Why needed here: Understanding that deep layers transform inputs into abstract representations that can be manipulated for unlearning
  - Quick check question: Why are intermediate features more suitable for unlearning than directly modifying output logits?

- Concept: Teacher-student training framework
  - Why needed here: Provides an alternative implementation strategy for aligning features between original and unlearned models
  - Quick check question: How does using a teacher model simplify the implementation of feature alignment constraints?

## Architecture Onboarding

- Component map:
  Pre-trained model backbone (frozen) -> LoRA modules inserted at selected intermediate layers -> Loss computation: intermediate feature alignment + task loss -> Training loop with separate handling for retained vs unlearning data

- Critical path:
  1. Insert LoRA modules into pre-trained model
  2. Forward pass through both pre-trained and LoRA branches
  3. Compute feature alignment losses for retained and unlearning sets
  4. Compute task losses (using average labels for unlearning set)
  5. Backpropagate and update only LoRA parameters
  6. Merge LoRA weights for inference

- Design tradeoffs:
  - Layer selection: More layers = better control but higher computational cost
  - Rank selection in LoRA: Higher rank = more expressive but less efficient
  - Loss weighting (γ parameter): Balance between feature alignment and task performance

- Failure signatures:
  - Poor unlearning: High MIA success rate on unlearning data
  - Performance degradation: Accuracy drop on retained data
  - Feature misalignment: Large feature distance between unlearned and retrained models

- First 3 experiments:
  1. CIFAR-10 sample unlearning with ResNet18: Compare accuracy on retained/unlearning sets vs baselines
  2. Feature distance analysis: Measure intermediate layer alignment between unlearned and retrained models
  3. MIA attack evaluation: Test privacy protection effectiveness on unlearning data

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but the methodology raises several important considerations regarding scalability, minimum sample requirements, handling heterogeneous unlearning data, and long-term stability across multiple unlearning requests.

## Limitations
- The approach assumes intermediate features can be meaningfully decomposed into pre-trained and residual components, which may not hold for all model architectures
- The method requires access to a portion of retained data for feature alignment, which may not be feasible in all unlearning scenarios
- Computational efficiency gains may diminish for very deep architectures or when many LoRA modules are needed

## Confidence
- High confidence: The core mechanism of using LoRA for residual feature decomposition is technically sound
- Medium confidence: Experimental results show strong performance relative to baselines across tested datasets
- Medium confidence: The privacy protection claims are supported by MIA evaluation results

## Next Checks
1. Test the method on multi-modal foundation models (e.g., CLIP, Flamingo) to evaluate cross-domain applicability
2. Conduct ablation studies varying the number and position of LoRA modules to optimize layer selection
3. Evaluate the method's performance when only a small subset of retained data is available for feature alignment