---
ver: rpa2
title: On the Compatibility of Generative AI and Generative Linguistics
arxiv_id: '2411.10533'
source_url: https://arxiv.org/abs/2411.10533
tags:
- language
- chomsky
- generative
- grammar
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper argues that generative AI and generative linguistics
  are compatible and mutually reinforcing approaches to understanding language. The
  authors present three key points: (1) Language models (LMs) are formal generative
  models as originally conceived by Chomsky''s work on formal language theory, (2)
  LMs can help develop discovery procedures for linguistic theory as defined by Chomsky''s
  "Syntactic Structures," and (3) LMs can be valuable tools for Chomsky''s minimalist
  approach to Universal Grammar and language acquisition.'
---

# On the Compatibility of Generative AI and Generative Linguistics

## Quick Facts
- arXiv ID: 2411.10533
- Source URL: https://arxiv.org/abs/2411.10533
- Reference count: 26
- This paper argues that generative AI and generative linguistics are compatible and mutually reinforcing approaches to understanding language.

## Executive Summary
This paper presents a theoretical argument for the compatibility between generative AI (particularly language models) and generative linguistics as conceived by Noam Chomsky. The authors claim that language models are formal generative models that can contribute to linguistic theory through discovery procedures and minimalist approaches to Universal Grammar. They argue that while current language models achieve observational adequacy (generating correct sentences), they have the potential to contribute to descriptive and explanatory adequacy by learning latent grammatical structures. The paper emphasizes that grammar induction models, in particular, offer transparency and interpretability that make them especially promising for advancing linguistic theory.

## Method Summary
This is a theoretical paper that does not present empirical experiments but rather synthesizes existing literature and theoretical frameworks to argue for compatibility between generative AI and generative linguistics. The authors draw on Chomsky's work on formal language theory, the levels of adequacy framework, and the minimalist program to construct their argument. They reference existing grammar induction models and their potential as discovery procedures, while acknowledging the current limitations of transformer-based models in terms of interpretability and explicit structural learning.

## Key Results
- Language models are formal generative models that compute probability distributions over word sequences, mathematically equivalent to formal generative grammars
- Grammar induction language models can function as discovery procedures for linguistic theory, learning explicit grammatical structures from data
- Language models can contribute to Chomsky's minimalist approach by testing what aspects of language can be learned from data alone versus requiring innate knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LMs are formal generative models as originally conceived in Chomsky's work on formal language theory
- Mechanism: Language models compute probability distributions over word sequences, which is mathematically equivalent to defining a formal generative grammar that assigns probabilities to sentences
- Core assumption: The mathematical foundations of LMs (probability distributions over strings) align with Chomsky's formal definition of grammars as devices generating languages
- Evidence anchors:
  - [abstract] "we argue that LMs are formal generative models as intended originally in Chomsky's work on formal language theory"
  - [section 2] "Chomsky (1956c, 1957, 1959) defined a language formally as a possibly infinite set of finite-length sentences constructed out of a finite set of elements... He defined a (generative) grammar as a 'device' (i.e. a model) that generates all the grammatical sentences and none of the ungrammatical ones"
  - [corpus] Weak evidence - corpus shows related papers discussing generative models but not direct computational alignment
- Break condition: If LMs cannot be shown to generate languages through formal mathematical operations equivalent to grammar generation

### Mechanism 2
- Claim: LMs can help develop discovery procedures for linguistic theory as defined by Chomsky's "Syntactic Structures"
- Mechanism: LMs, particularly grammar induction models, learn latent grammatical structures from data without requiring predefined grammars, functioning as algorithmic discovery procedures
- Core assumption: LMs can extract and represent grammatical rules and categories from language data in ways that reveal linguistic structure
- Evidence anchors:
  - [abstract] "LMs can help develop a program for discovery procedures as defined by Chomsky's 'Syntactic Structures'"
  - [section 3] "LMs represent effective discovery procedures... grammar induction LMs, as discovery procedures, represent a set of AI models that could contribute to theoretical linguistics"
  - [corpus] Weak evidence - corpus contains papers questioning LM compatibility but not detailed discovery procedure mechanisms
- Break condition: If LMs cannot be shown to learn explicit grammatical rules or if their internal representations cannot be interpreted as linguistic structures

### Mechanism 3
- Claim: LMs can be valuable tools for Chomsky's minimalist approach to Universal Grammar and language acquisition
- Mechanism: By assuming minimal domain-specific knowledge and relying on general learning mechanisms, LMs can test what aspects of language can be learned from data alone, leaving unexplained properties as candidates for innate linguistic endowment
- Core assumption: The gap between what LMs can learn from data and what humans learn naturally reveals what must be innate
- Evidence anchors:
  - [abstract] "LMs can be a major asset for Chomsky's minimalist approach to Universal Grammar and language acquisition"
  - [section 4] "LMs can be a major asset in the Minimalist Program's 'bottom up' approach because they generally assume little to no domain-specific knowledge"
  - [corpus] Weak evidence - corpus shows debate but not specific minimalist program mechanisms
- Break condition: If LMs can learn all aspects of language without any innate knowledge, leaving no explanatory gap for Universal Grammar

## Foundational Learning

- Concept: Formal language theory and the Chomsky-Schützenberger hierarchy
  - Why needed here: Understanding how different computational models generate languages and their relative expressive power is crucial for comparing LMs to formal grammars
  - Quick check question: Can you explain the difference between regular grammars and context-free grammars in terms of the languages they can generate?

- Concept: Levels of adequacy (observational, descriptive, explanatory)
  - Why needed here: These criteria provide the framework for evaluating how well LMs capture linguistic knowledge beyond just generating grammatical sentences
  - Quick check question: What distinguishes a descriptively adequate model from an observationally adequate one in terms of structural descriptions?

- Concept: Discovery procedures vs evaluation procedures
  - Why needed here: Understanding these different theoretical approaches to grammar development is essential for seeing how LMs can contribute to linguistic theory
  - Quick check question: What is the key difference between a discovery procedure and an evaluation procedure in Chomsky's framework?

## Architecture Onboarding

- Component map: Language models (neural networks, grammar induction models) -> Formal linguistic theory (Chomsky frameworks, Universal Grammar) -> Evaluation frameworks (adequacy criteria)
- Critical path: 1) Train LMs on linguistic data, 2) Extract internal representations and grammatical knowledge, 3) Map extracted knowledge to formal linguistic structures, 4) Evaluate against adequacy criteria, 5) Iterate model architecture based on linguistic insights
- Design tradeoffs: Using grammar induction LMs provides interpretability but requires more computational resources and may limit model capacity compared to standard transformers; balancing domain-specific priors against learning flexibility
- Failure signatures: 1) LMs generate fluent text but cannot be interpreted as learning explicit grammatical rules, 2) Extracted representations don't map to known linguistic categories, 3) Models fail to generalize to novel linguistic phenomena, 4) No clear distinction between grammaticality and likelihood
- First 3 experiments:
  1. Train a simple PCFG induction model on a small corpus and extract the learned grammar rules to verify interpretability
  2. Compare the weak generative capacity of a transformer LM with a grammar induction LM on the same language data
  3. Test a grammar induction LM's ability to distinguish grammatical from ungrammatical sentences it hasn't seen during training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can transformer-based LMs be extended or modified to achieve descriptive adequacy in the Chomskyan sense, or are their architectural limitations fundamentally incompatible with learning explicit structural descriptions?
- Basis in paper: [inferred] The paper notes that transformer-based LMs are "black boxes" and that current methods to extract internal knowledge require strong linguistic biases, suggesting they don't naturally learn explicit grammars
- Why unresolved: While grammar induction LMs show promise for descriptive adequacy, it remains unclear whether the dominant transformer architecture can be adapted to learn and expose structural descriptions without relying on predefined linguistic assumptions
- What evidence would resolve it: Demonstrating a method to extract interpretable, linguistically meaningful syntactic structures from transformer-based LMs without presupposing linguistic categories, or showing that such extraction is impossible due to architectural constraints

### Open Question 2
- Question: What is the precise relationship between the probabilistic Chomsky-Schützenberger hierarchy and the computational complexity of neural LMs, and can this relationship be formalized into a unified theory?
- Basis in paper: [explicit] The paper mentions that while the probabilistic hierarchy differs from the classical one, and neural LMs have been tested against the classical hierarchy, "it is too early to have a hierarchy or general theory for the computational complexity of different LMs"
- Why unresolved: Current research has only begun to compare neural architectures with formal language classes, and a comprehensive theoretical framework that unifies classical, probabilistic, and neural generative models is still lacking
- What evidence would resolve it: A formal proof or computational demonstration that establishes the learnability and generative capacity of various neural architectures within a unified hierarchy, comparable to the classical Chomsky-Schützenberger hierarchy

### Open Question 3
- Question: How can multimodal language models (incorporating images, sound, and video) contribute to theories of language acquisition and learnability, and what are the implications for understanding the role of innate linguistic knowledge?
- Basis in paper: [explicit] The authors suggest that multimodal LMs may offer "a more complete picture of our true lived-experience of language processing and learning" and could help move towards scientific goals, but this remains largely speculative
- Why unresolved: While the potential of multimodal input for language learning is recognized, there is limited empirical research on how such models can inform theories of acquisition, particularly regarding the balance between innate knowledge and learning from rich, multimodal data
- What evidence would resolve it: Empirical studies showing how multimodal models acquire linguistic structures, comparisons of their learning efficiency and generalization with unimodal models, and analyses of whether multimodal input reduces the need for strong innate linguistic assumptions

## Limitations
- The theoretical arguments rely heavily on the assumption that LMs can be meaningfully interpreted as learning explicit grammatical structures, which remains an open empirical question
- Current transformer-based LMs are "black boxes" that don't naturally learn interpretable structural descriptions without strong linguistic biases
- The paper does not provide concrete evidence that current LMs actually achieve descriptive or explanatory adequacy in the Chomskyan sense

## Confidence

- High confidence: LMs achieve observational adequacy and can generate grammatically correct sentences
- Medium confidence: LMs can serve as formal generative models in the mathematical sense defined by Chomsky
- Medium confidence: Grammar induction LMs can function as discovery procedures for linguistic theory
- Low confidence: LMs can meaningfully contribute to Chomsky's minimalist program and Universal Grammar debates without additional domain-specific architectural constraints

## Next Checks
1. Implement a controlled experiment comparing a standard transformer LM with a grammar induction LM on a corpus containing clear syntactic ambiguities, then analyze whether the grammar induction model produces interpretable structural descriptions that match linguistic theory
2. Design a probe to extract learned representations from a grammar induction LM and test whether these representations align with known linguistic categories and rules across multiple languages
3. Create a benchmark task that specifically tests whether LMs can distinguish between grammatical and ungrammatical sentences that differ only in structural properties (not surface form), measuring their ability to achieve descriptive adequacy