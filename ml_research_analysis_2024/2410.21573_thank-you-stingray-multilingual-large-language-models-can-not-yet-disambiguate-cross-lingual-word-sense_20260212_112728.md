---
ver: rpa2
title: 'Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate
  Cross-Lingual Word Sense'
arxiv_id: '2410.21573'
source_url: https://arxiv.org/abs/2410.21573
tags:
- language
- 'false'
- cognate
- llms
- friends
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces StingrayBench, the first benchmark for evaluating
  cross-lingual sense disambiguation in multilingual large language models (LLMs).
  It focuses on false friends (words that are orthographically similar but have different
  meanings in two languages) and true cognates (words that are similar and share the
  same meaning).
---

# Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense

## Quick Facts
- arXiv ID: 2410.21573
- Source URL: https://arxiv.org/abs/2410.21573
- Reference count: 24
- Key outcome: Multilingual LLMs perform well on true cognates but close to random on false friends, showing significant limitations in cross-lingual sense disambiguation

## Executive Summary
This paper introduces StingrayBench, the first benchmark for evaluating cross-lingual sense disambiguation in multilingual large language models (LLMs). The benchmark focuses on false friends (words that are orthographically similar but have different meanings in two languages) and true cognates (words that are similar and share the same meaning) across four language pairs: English-German, Indonesian-Malay, Indonesian-Tagalog, and Chinese-Japanese. The authors introduce two metrics: cognate bias (measuring language preference) and cognate comprehension score (measuring understanding ability). Experiments show that while LLMs can understand true cognates well, they perform close to random guessing on false friends, indicating a significant limitation in cross-lingual sense disambiguation.

## Method Summary
The authors created StingrayBench dataset with 705 entries (259 true cognates, 446 false friends) across four language pairs. They formulated two tasks: semantic appropriateness (three-option multiple choice) and usage correction (binary yes/no). The benchmark evaluates multilingual LLMs using zero-shot prompting with two inference approaches: likelihood-based for open-source models and generation-based for all models. Performance is measured using cognate comprehension score (magnitude of language pair performance vector, normalized 0-1) and cognate bias score (angular distance from 45° in 2D language performance space, normalized -1 to 1).

## Key Results
- LLMs achieve high cognate comprehension scores (0.7-0.9) for true cognates but perform close to random (0.4-0.6) for false friends
- Larger models show stronger true cognate comprehension and lower bias scores
- Indonesian-Malay language pair shows lower performance than Indonesian-Tagalog, suggesting language similarity affects disambiguation difficulty
- English-centric models exhibit significant bias toward English performance in non-English language pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs understand true cognates better than false friends because true cognates share both form and meaning across languages, creating a consistent semantic signal
- Core assumption: The pretraining corpus contains sufficient true cognate pairs in parallel contexts to establish strong form-meaning associations
- Evidence anchors: Experiments show LLMs perform well on true cognates; larger models yield stronger cognate comprehension scores

### Mechanism 2
- Claim: Language similarity affects false friend disambiguation, with highly similar languages (Indonesian-Malay) being harder to disambiguate than less similar pairs (Indonesian-Tagalog)
- Core assumption: The degree of lexical and grammatical overlap between languages correlates with the difficulty of distinguishing false friends
- Evidence anchors: Indonesian-Malay performance is lower than Indonesian-Tagalog; both languages share great overlap in lexical and grammatical aspects

### Mechanism 3
- Claim: Scaling laws improve both cognate comprehension and reduce bias, but the effect is stronger for true cognates than false friends
- Core assumption: Model capacity scales with the ability to represent and disambiguate subtle semantic differences across languages
- Evidence anchors: Larger scale BLOOMZ, mT0, and Qwen-2.5 models have higher cognate comprehension scores with much lower cognate bias

## Foundational Learning

- Concept: Cross-lingual semantic representation
  - Why needed here: The core challenge is whether LLMs can maintain separate semantic representations for words that look similar but mean different things across languages
  - Quick check question: Can you explain how a model might represent "pagi" (morning in Indonesian, stingray in Tagalog) differently in its embedding space for each language?

- Concept: Language-specific vs. language-agnostic representations
  - Why needed here: Understanding whether LLMs use separate representations for each language or shared representations that get disambiguated through context is crucial for explaining the bias patterns observed
  - Quick check question: What architectural features would help a model distinguish between similar forms in different languages?

- Concept: Semantic contextualization
  - Why needed here: The ability to use surrounding context to determine word meaning is essential for both true cognate understanding and false friend disambiguation
  - Quick check question: How does context help distinguish between "arm" (body part) and "Arm" (weapon) in English, and how might this generalize to cross-lingual cases?

## Architecture Onboarding

- Component map: Dataset construction → Task formulation → Model inference → Metric computation → Analysis
- Critical path: Data collection → Task formulation → Model inference → Metric computation → Analysis
- Design tradeoffs: Likelihood-based inference offers precision while generation-based inference provides generalizability
- Failure signatures: Poor true cognate performance indicates semantic representation issues; high bias scores indicate language preference problems; random false friend performance indicates context disambiguation failure
- First 3 experiments:
  1. Test mT0-small on both true cognates and false friends to establish baseline performance
  2. Compare English-German vs Indonesian-Malay performance to test language similarity hypothesis
  3. Test GPT-4o-mini on non-English pairs to quantify English-centric bias

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does language similarity affect false friend disambiguation across different language pairs?
- Basis in paper: The authors observe Indonesian-Malay is harder than Indonesian-Tagalog but don't systematically investigate other pairs
- Why unresolved: Only four language pairs are tested, lacking broader coverage of linguistic relationships
- What evidence would resolve it: Experiments across language pairs with varying similarity degrees (e.g., Spanish-Portuguese vs Spanish-German)

### Open Question 2
- Question: What architectural or training modifications could improve false friend disambiguation while maintaining true cognate performance?
- Basis in paper: The authors identify the problem as urgent but don't propose specific solutions
- Why unresolved: The paper identifies limitations without testing modifications
- What evidence would resolve it: Comparative experiments testing modified architectures or training approaches

### Open Question 3
- Question: How does the true/false friend performance gap change as model scale increases beyond tested range?
- Basis in paper: Scaling improves true cognate comprehension but false friends remain near random even for largest tested models
- Why unresolved: Models up to 70B parameters are tested but not larger frontier models
- What evidence would resolve it: Testing largest available models (hundreds of billions of parameters) on false friend subset

## Limitations

- The benchmark covers only four language pairs, potentially limiting generalizability across linguistic diversity
- Zero-shot evaluation without fine-tuning may underestimate achievable performance with adaptation
- Moderate parallel text availability (FMR 0.585-0.688) may limit effectiveness of cross-lingual learning

## Confidence

**High Confidence:** LLMs perform significantly worse on false friends than true cognates across multiple models and language pairs.

**Medium Confidence:** Language similarity affects disambiguation difficulty, and scaling improves performance, though specific thresholds and scaling laws remain uncertain.

**Low Confidence:** Specific numerical thresholds for "good" vs "poor" performance may not generalize across different evaluation contexts.

## Next Checks

1. Evaluate models on completely unseen language pairs (e.g., Spanish-Italian, Hindi-Urdu) to test generalization of observed patterns

2. Conduct systematic scaling study using models of varying sizes trained on identical multilingual corpora to isolate capacity effects

3. Fine-tune selected models on small amounts of cross-lingual false friend disambiguation data to distinguish pretraining vs prompting limitations