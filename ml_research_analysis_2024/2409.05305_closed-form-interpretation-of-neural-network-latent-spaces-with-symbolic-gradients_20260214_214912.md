---
ver: rpa2
title: Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients
arxiv_id: '2409.05305'
source_url: https://arxiv.org/abs/2409.05305
tags:
- neural
- symbolic
- networks
- network
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a novel framework for interpreting neural network
  latent spaces by retrieving human-readable symbolic equations that describe the
  concepts learned by neurons in hidden layers. The method addresses the challenge
  of extracting meaningful scientific insights from neural networks without prior
  knowledge of the underlying concepts.
---

# Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients

## Quick Facts
- arXiv ID: 2409.05305
- Source URL: https://arxiv.org/abs/2409.05305
- Authors: Sebastian J. Wetzel; Zakaria Patel
- Reference count: 14
- The paper presents a framework for retrieving human-readable symbolic equations that describe concepts learned by neurons in hidden layers.

## Executive Summary
This paper introduces a novel framework for interpreting neural network latent spaces by finding closed-form symbolic expressions that match the normalized gradients of target neurons. The method constructs an equivalence class of functions sharing the same directional derivative information as the learned concept, then uses symbolic search to find interpretable expressions within this class. The framework is demonstrated on Siamese neural networks trained to discover matrix invariants and conserved quantities in dynamical systems, successfully retrieving correct analytical expressions for various physical concepts.

## Method Summary
The framework works by first training a Siamese neural network to learn invariant representations using contrastive or triplet loss. It then extracts normalized gradients from a target neuron with respect to input variables and performs symbolic regression to find expressions whose gradients match those of the neuron. The symbolic search uses gradient matching as a fitness function, minimizing the mean squared error between normalized gradients of candidate expressions and the target neuron gradients.

## Key Results
- Successfully retrieved correct analytical expressions for trace and determinant of 2×2 and 3×3 matrices under similarity transformations
- Discovered conserved quantities in harmonic oscillator and Coulomb potentials
- Recovered spacetime interval formula from special relativity using Lorentz transformations
- All retrieved expressions matched ground truth concepts at the point of steepest change in the Pareto front during symbolic search

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method works by embedding neural networks into an equivalence class where all functions share the same normalized gradients, allowing symbolic search to find interpretable expressions.
- Mechanism: The framework constructs an equivalence class Hg containing all functions f where ∇f/∥∇f∥ equals ∇g/∥∇g∥ for the underlying concept g. This means functions in the class encode the same directional derivative information as g, even if their functional forms differ.
- Core assumption: The concept encoded by a neuron can be uniquely identified by its gradient direction across the input space.
- Evidence anchors:
  - [abstract]: "Computationally, this framework is based on finding a symbolic expression whose normalized gradients match the normalized gradients of a specific neuron with respect to the input variables."
  - [section 3.2]: "the gradients of the two functions f and g point in the same direction, ∇f(x) = ϕ′(g(x)) · ∇g(x) where ∥ϕ′(g(x))∥ > 0"
  - [corpus]: Weak evidence - the neighboring papers focus on symbolic regression and interpretation but don't directly support this gradient-based equivalence class mechanism.
- Break condition: If the concept depends on higher-order derivatives or non-gradient information, or if the function transformation ϕ is not differentiable.

### Mechanism 2
- Claim: Siamese networks trained on similarity tasks naturally learn invariant representations that correspond to physical concepts like conserved quantities or matrix invariants.
- Mechanism: The contrastive loss forces the network to map similar inputs (sharing invariants) to nearby points in latent space while separating dissimilar inputs. This optimization process causes the network to learn functions of the underlying invariants.
- Core assumption: The training data structure (triplets with shared invariants) provides sufficient signal for the network to discover the correct concept without explicit labels.
- Evidence anchors:
  - [section 3.1]: "The network f can be trained effectively using a contrastive or triplet loss, wherein a set of triplets are supplied to the energy function"
  - [section 4.1.1]: "The anchor is sampled by generating a random matrix. The positive example shares one or more invariants with the anchor."
  - [corpus]: Weak evidence - neighboring papers discuss Siamese networks and autoencoders but don't specifically address the invariant learning mechanism described here.
- Break condition: If the training data doesn't provide clear similarity/dissimilarity signals, or if the network architecture is too limited to represent the invariant functions.

### Mechanism 3
- Claim: Symbolic search using normalized gradient matching can successfully recover closed-form expressions from neural network latent spaces across diverse domains.
- Mechanism: The symbolic search algorithm evolves candidate expressions by minimizing MSE between normalized gradients of candidates and the target neuron, finding expressions that match the directional derivative pattern of the learned concept.
- Core assumption: The space of candidate symbolic expressions is sufficiently expressive to contain the true underlying concept, and the gradient-based fitness function effectively guides search toward correct solutions.
- Evidence anchors:
  - [abstract]: "The framework is demonstrated on several experiments involving Siamese neural networks trained to discover matrix invariants and conserved quantities in dynamical systems."
  - [section 4.2]: "All obtained solutions match the correct expressions. It is possible for the symbolic search algorithm to instead return a solution that matches the ground truth one up to a piecewise invertible transformation"
  - [corpus]: Weak evidence - neighboring papers discuss symbolic regression but don't provide evidence for the specific gradient-matching approach used here.
- Break condition: If the symbolic search space is too limited, or if gradient matching fails to distinguish between multiple valid expressions encoding the same concept.

## Foundational Learning

- Concept: Gradient-based optimization and backpropagation
  - Why needed here: The method relies on computing and comparing gradients of neural networks and symbolic expressions
  - Quick check question: Can you explain why normalized gradients are used instead of raw gradients in the equivalence class definition?

- Concept: Siamese neural network architecture and triplet loss
  - Why needed here: The experiments use Siamese networks trained on similarity tasks to discover invariants
  - Quick check question: What is the purpose of the margin parameter α in the triplet loss function?

- Concept: Symbolic regression and genetic algorithms
  - Why needed here: The method uses symbolic search to find closed-form expressions matching neural network gradients
  - Quick check question: How does symbolic regression differ from traditional numerical regression?

## Architecture Onboarding

- Component map: Data generation module -> Siamese network trainer -> Gradient extraction component -> Symbolic search engine -> Evaluation pipeline
- Critical path: Data generation → Siamese network training → Gradient extraction → Symbolic search → Expression validation
- Design tradeoffs:
  - Single neuron interpretation vs. multi-neuron combinations
  - Normalized vs. raw gradient matching
  - Breadth vs. depth of symbolic search space
  - Computational cost of gradient computation vs. search efficiency
- Failure signatures:
  - Symbolic search fails to converge or returns incorrect expressions
  - Gradient computation errors or numerical instability
  - Siamese network learns trivial or incorrect invariants
  - Pareto front doesn't show clear best solution
- First 3 experiments:
  1. 2×2 matrix trace discovery under similarity transformation
  2. 3×3 matrix determinant discovery under similarity transformation  
  3. Energy conservation in harmonic oscillator potential

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework reliably recover equations with piecewise invertible transformations beyond the scope of the current experiments?
- Basis in paper: [inferred] The paper notes it is "possible for the symbolic search algorithm to instead return a solution that matches the ground truth one up to a piecewise invertible transformation, although we do not observe this in our experiments."
- Why unresolved: The experiments did not encounter scenarios requiring recovery of piecewise invertible transformations, limiting the empirical evidence for this capability.
- What evidence would resolve it: Demonstrations of the framework successfully recovering equations involving piecewise invertible transformations in new experiments, particularly those with non-smooth or discontinuous underlying concepts.

### Open Question 2
- Question: How does the performance of the framework scale with increasing complexity of the latent space and the underlying concept?
- Basis in paper: [explicit] The paper mentions that "the interpretation method is based on constructing an equivalence class around a certain neuron that contains all functions encoding the same concept as the target neuron" but does not provide detailed analysis on scalability.
- Why unresolved: The experiments presented involve relatively simple concepts and latent spaces. The framework's effectiveness on more complex, higher-dimensional problems remains untested.
- What evidence would resolve it: Systematic experiments applying the framework to increasingly complex latent spaces and concepts, measuring accuracy, computational cost, and robustness.

### Open Question 3
- Question: What is the impact of the choice of symbolic search space and genetic algorithm hyperparameters on the framework's ability to recover correct equations?
- Basis in paper: [explicit] The paper discusses the use of symbolic search but does not extensively explore the sensitivity to the choice of search space or algorithm parameters.
- Why unresolved: The experiments use specific symbolic search configurations without exploring how variations affect results, leaving the robustness of the method to these choices unclear.
- What evidence would resolve it: Ablation studies varying the symbolic search space, operators, and genetic algorithm hyperparameters, analyzing their effects on the success rate and accuracy of equation recovery.

## Limitations
- The framework relies on normalized gradients as the primary descriptor of learned concepts, potentially missing non-gradient information or higher-order relationships
- The equivalence class approach assumes concepts can be uniquely identified by gradient direction, which may not hold for all types of functions
- The method's generalizability to more complex or abstract concepts beyond the demonstrated cases remains untested

## Confidence
- **High**: The gradient-based symbolic search methodology is sound and well-defined
- **Medium**: The framework successfully retrieves ground truth expressions in demonstrated experiments
- **Low**: The method's generalizability to more complex or abstract concepts beyond the demonstrated cases

## Next Checks
1. **Stress Test with Noisy Data**: Apply the method to datasets with increasing levels of noise to determine robustness thresholds and identify failure modes.

2. **Cross-Domain Validation**: Test the framework on neural networks trained for completely different tasks (e.g., image classification, natural language processing) to assess generalizability.

3. **Multi-Neuron Extension**: Extend the method to interpret combinations of neurons rather than single neurons to capture more complex concepts and relationships.