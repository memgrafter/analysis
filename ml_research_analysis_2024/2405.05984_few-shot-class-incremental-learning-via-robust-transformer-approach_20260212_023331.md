---
ver: rpa2
title: Few-Shot Class Incremental Learning via Robust Transformer Approach
arxiv_id: '2405.05984'
source_url: https://arxiv.org/abs/2405.05984
tags:
- learning
- robusta
- base
- problem
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ROBUSTA is a transformer-based method for few-shot class-incremental
  learning that addresses overfitting, catastrophic forgetting, and intra-class bias.
  It uses a stochastic classifier with mean-variance distributions, delta parameters
  for task-specific adaptation, and a prototype rectification network.
---

# Few-Shot Class Incremental Learning via Robust Transformer Approach

## Quick Facts
- arXiv ID: 2405.05984
- Source URL: https://arxiv.org/abs/2405.05984
- Reference count: 40
- Primary result: ROBUSTA achieves 2.5–10.96% accuracy improvements over prior arts on Mini-ImageNet, CIFAR-100, and CUB-200 without data augmentation

## Executive Summary
ROBUSTA is a transformer-based method for few-shot class-incremental learning that addresses key challenges including overfitting, catastrophic forgetting, and intra-class bias. The approach uses a stochastic classifier with mean-variance distributions to create infinite classifiers, delta parameters for task-specific adaptation, and a prototype rectification network. Built on a compact convolutional transformer with batch normalization, ROBUSTA demonstrates significant performance improvements over prior arts while maintaining robustness across various settings including 1-shot learning and small base class tasks.

## Method Summary
ROBUSTA employs a Compact Convolutional Transformer (CCT) backbone with batch normalization instead of layer normalization for improved training stability. The method introduces a stochastic classifier where weights are sampled from Gaussian distributions with learned mean and variance vectors, effectively creating infinite classifiers. For incremental tasks, delta parameters (prefix tuning) are used with non-parametric task inference via Mahalanobis distance to prevent catastrophic forgetting without task identifiers. A prototype rectification network reduces intra-class bias. The model is trained with supervised learning (cross-entropy) plus self-supervised learning (DINO) for the base task, while incremental tasks use frozen backbones and task-specific parameters.

## Key Results
- Achieves 2.5–10.96% accuracy improvements over prior arts on Mini-ImageNet, CIFAR-100, and CUB-200
- Reduces catastrophic forgetting by maintaining high base task performance while learning new classes
- Demonstrates robustness across different settings including 1-shot learning and small base class tasks (20/50 classes)
- Outperforms prior arts without using data augmentation techniques

## Why This Works (Mechanism)

### Mechanism 1: Stochastic Classifier with Gaussian Distributions
The stochastic classifier samples weights from Gaussian distributions, creating infinite classifiers that reduce overfitting in few-shot scenarios. This increases classification likelihood even with limited data. The approach assumes true class distributions can be approximated by Gaussian distributions in classifier weight space. Evidence is weak as no direct corpus support exists for stochastic classifiers in few-shot class-incremental learning.

### Mechanism 2: Batch Normalization for Training Stability
Batch normalization stabilizes training and improves convergence compared to layer normalization in visual transformer architectures. It normalizes activations across batch dimension, which is more effective for image classification with fixed input sizes. The approach assumes benefits observed in CNNs transfer effectively to transformer architectures for vision tasks. Evidence is weak due to lack of direct comparative experiments in compact convolutional transformers.

### Mechanism 3: Delta Parameters with Non-parametric Task Inference
Delta parameters with non-parametric task inference prevent catastrophic forgetting without task identifiers. Small task-specific parameters are prepended to attention, and Mahalanobis distance identifies task distributions. The approach assumes task distributions remain separable in feature space. Evidence is moderate with related papers discussing delta parameters and task inference in continual learning, though not specifically for few-shot class-incremental learning.

## Foundational Learning

- Concept: Stochastic sampling from distributions
  - Why needed here: The stochastic classifier relies on sampling classifier weights from Gaussian distributions to create infinite classifiers
  - Quick check question: How would you implement sampling from a Gaussian distribution with learned mean and variance parameters in a neural network?

- Concept: Batch normalization mechanics
  - Why needed here: Understanding batch normalization is crucial for implementing the architecture correctly and knowing when it might fail
  - Quick check question: What are the key differences between batch normalization and layer normalization, and when would each be preferred?

- Concept: Mahalanobis distance calculation
  - Why needed here: The task inference mechanism uses Mahalanobis distance to identify which task-specific delta parameters to use
  - Quick check question: How does Mahalanobis distance differ from Euclidean distance, and why is it more appropriate for this task inference problem?

## Architecture Onboarding

- Component map: CCT backbone → BatchNorm layers → Stochastic classifier → Delta parameters → Prototype rectification network
- Critical path: Input → CCT encoder → BatchNorm → Multi-head attention with delta parameters → Feed-forward network → Stochastic classifier → Output
- Design tradeoffs: Compact transformer architecture vs. computational efficiency; stochastic classifier flexibility vs. training stability; delta parameters for CF prevention vs. parameter overhead
- Failure signatures: Overfitting indicated by poor performance on few-shot tasks; catastrophic forgetting indicated by degraded base task performance; task confusion indicated by incorrect delta parameter selection
- First 3 experiments:
  1. Implement basic CCT backbone with batch normalization replacement and verify training stability on base task
  2. Add stochastic classifier and test classification performance on few-shot tasks with varying numbers of samples
  3. Implement delta parameters and non-parametric task inference, measuring catastrophic forgetting across incremental tasks

## Open Questions the Paper Calls Out

### Open Question 1
How does ROBUSTA's performance compare to prior arts when using a CNN backbone instead of the CCT backbone? The paper states ROBUSTA is built upon CCT and that recent works with CNNs perform sub-optimally, but provides no direct comparisons with CNN backbone implementations.

### Open Question 2
How does the choice of temperature η in the stochastic classifier affect ROBUSTA's performance? The paper mentions η controls output distribution smoothness but does not discuss performance impact or provide sensitivity analysis.

### Open Question 3
How does ROBUSTA's performance scale with larger datasets or more classes? The paper evaluates on datasets with maximum 100 classes in base task but does not discuss scalability to larger datasets or more classes.

## Limitations
- Implementation details for prototype rectification network and its interaction with stochastic classifier are unclear
- Exact hyperparameters for DINO loss and prefix sequence lengths are unspecified
- Lack of direct comparative experiments for batch normalization vs layer normalization claims
- No scalability analysis for larger datasets or more classes

## Confidence
- Stochastic classifier effectiveness: Low confidence (weak evidence)
- Batch normalization superiority: Low confidence (no direct comparative experiments)
- Delta parameters and task inference: Medium confidence (moderate evidence from related work)
- Overall performance claims: Medium confidence (significant improvements shown but synergistic effects not fully isolated)

## Next Checks
1. Implement the stochastic classifier with mean-variance distributions and measure variance of predictions across multiple forward passes to verify infinite classifier claim
2. Conduct controlled experiments replacing batch normalization with layer normalization to quantify claimed stability benefits
3. Test task inference accuracy independently by creating synthetic overlapping task distributions to stress-test Mahalanobis distance approach