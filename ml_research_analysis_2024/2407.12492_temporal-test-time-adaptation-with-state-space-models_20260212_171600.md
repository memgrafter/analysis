---
ver: rpa2
title: Temporal Test-Time Adaptation with State-Space Models
arxiv_id: '2407.12492'
source_url: https://arxiv.org/abs/2407.12492
tags:
- adaptation
- distribution
- learning
- shift
- stad
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles temporal test-time adaptation (TempTTA), where
  a deployed model must adapt to data distributions that shift gradually over time
  without access to labels. Existing TTA methods struggle with such shifts, especially
  when batch sizes are small or class distributions change (label shift).
---

# Temporal Test-Time Adaptation with State-Space Models

## Quick Facts
- arXiv ID: 2407.12492
- Source URL: https://arxiv.org/abs/2407.12492
- Authors: Mona Schirmer; Dan Zhang; Eric Nalisnick
- Reference count: 40
- One-line primary result: STAD improves accuracy by over 17 points on FMoW-Time compared to source model, particularly effective under label shift and with small batch sizes.

## Executive Summary
This paper addresses temporal test-time adaptation (TempTTA) for deployed models facing gradual distribution shifts over time without access to labels. The authors propose STAD, which uses state-space models to track the evolution of class prototypes in the representation space, enabling dynamic adaptation of the classification head. Through Bayesian filtering with a von Mises-Fisher model for hyperspherical features, STAD adapts to gradual temporal shifts and excels particularly under label shift and with small batch sizes. Experiments on real-world temporal datasets show significant improvements over existing TTA baselines.

## Method Summary
STAD tackles temporal test-time adaptation by learning time-varying dynamics in the last set of hidden features using a probabilistic state-space model based on Bayesian filtering. The method tracks the evolution of weight vectors in the final layer, inferring time-varying class prototypes that act as a dynamic classification head. It employs a von Mises-Fisher distribution to model hyperspherical features, leveraging angular distances for class membership under distribution shift. The approach uses a sliding window to process test batches sequentially, updating prototypes via expectation-maximization, and generates predictions using the updated classification head.

## Key Results
- STAD improves accuracy by over 17 points on FMoW-Time compared to the source model
- Outperforms existing TTA baselines particularly under label shift and with small batch sizes
- Demonstrates competitive performance on synthetic corruptions and reproduction datasets, showing broad applicability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: STAD adapts to temporal distribution shifts by tracking the evolution of class prototypes in the model's representation space using a state-space model.
- Mechanism: The method employs a probabilistic state-space model based on Bayesian filtering to infer time-varying class prototypes. These prototypes act as a dynamic classification head, allowing the model to adapt to gradual shifts in data distribution over time.
- Core assumption: The representations of data points change gradually over time, and the class structure (clusters) in the representation space is maintained.
- Evidence anchors:
  - [abstract]: "STAD, a Bayesian filtering method that adapts a deployed model to temporal distribution shifts by learning the time-varying dynamics in the last set of hidden features."
  - [section]: "STAD dynamically adapts a model's final layer to accommodate an evolving test distribution. Specifically, we employ a probabilistic SSM based on Bayesian filtering to model the evolution of the weight vectors in the final layer..."
- Break condition: If the data distribution shifts abruptly or if the class structure in the representation space is not maintained, the model's performance may degrade.

### Mechanism 2
- Claim: STAD's von Mises-Fisher (vMF) model for hyperspherical features improves adaptation under distribution shift.
- Mechanism: By assuming that hidden representations lie on the unit hypersphere and modeling them with the von Mises-Fisher distribution, STAD leverages angular distances, which are more reliable signals of class membership under distribution shift.
- Core assumption: The norms of the representations are biased by in-domain information such as class balance, making angular distances a more reliable signal of class membership in the presence of distribution shift.
- Evidence anchors:
  - [abstract]: "STAD employs a Bayesian filtering approach, specifically a von Mises-Fisher (vMF) model for hyperspherical features, to infer time-varying class prototypes..."
  - [section]: "This is due to the norms of the representations being biased by in-domain information such as class balance, making angular distances a more reliable signal of class membership in the presence of distribution shift..."
- Break condition: If the representations do not lie on the unit hypersphere or if the distribution shift does not affect the norms of the representations, the vMF model may not provide significant benefits.

### Mechanism 3
- Claim: STAD's dynamic clustering approach excels under label shift.
- Mechanism: By inferring time-evolving class prototypes, STAD can handle label shifts effectively. A higher number of samples from the same ground truth class provides a stronger learning signal, leading to more accurate prototype estimates.
- Core assumption: The model can infer the ground truth class labels from the data distribution.
- Evidence anchors:
  - [abstract]: "Through experiments on real-world temporal distribution shifts, we show that our method excels in handling small batch sizes and label shift."
  - [section]: "This is particularly notable on FMoW, where STAD improves upon the source model by more than 17 points. Further, the performance gap between classifier and feature extractor adaptation methods becomes even more pronounced in this setting."
- Break condition: If the label distribution shifts too drastically or if the model cannot infer the ground truth class labels accurately, the performance may degrade.

## Foundational Learning

- Concept: Bayesian filtering
  - Why needed here: Bayesian filtering is used to model the evolution of the weight vectors in the final layer, allowing the model to adapt to the evolving test distribution.
  - Quick check question: What is the primary advantage of using Bayesian filtering in STAD?

- Concept: State-space models (SSMs)
  - Why needed here: SSMs provide a principled framework for updating latent states with new information, which is crucial for tracking the gradual change in the model's representations over time.
  - Quick check question: How do state-space models contribute to the adaptation process in STAD?

- Concept: Von Mises-Fisher (vMF) distribution
  - Why needed here: The vMF distribution models hyperspherical features, which is beneficial under distribution shift as it leverages angular distances for class membership.
  - Quick check question: Why is the von Mises-Fisher distribution used for modeling features in STAD?

## Architecture Onboarding

- Component map: Source model -> Representation space (penultimate layer) -> State-space model -> von Mises-Fisher distribution -> Bayesian filtering -> Dynamic classification head (time-varying class prototypes)
- Critical path:
  1. Pass test samples through the source model to obtain representations.
  2. Use the state-space model to track the evolution of class prototypes in the representation space.
  3. Infer time-varying class prototypes using Bayesian filtering.
  4. Update the classification head with the new prototypes.
  5. Generate predictions using the updated classification head.
- Design tradeoffs:
  - Using a Gaussian model vs. a vMF model for hyperspherical features.
  - Adapting only the last layer vs. adapting the entire feature extractor.
  - Handling gradual shifts vs. abrupt shifts in data distribution.
- Failure signatures:
  - Poor performance on datasets with abrupt distribution shifts.
  - Inability to handle label shifts effectively.
  - High computational cost for large feature dimensions.
- First 3 experiments:
  1. Evaluate STAD on a dataset with gradual temporal distribution shifts and compare its performance to existing TTA methods.
  2. Test STAD's ability to handle label shifts by evaluating it on datasets with imbalanced label distributions.
  3. Assess the impact of the sliding window size on STAD's performance by varying the window size and observing the changes in accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does STAD's performance degrade when abrupt or adversarial shifts occur in the data stream?
- Basis in paper: [inferred] The paper discusses STAD's reliance on gradual temporal correlations and notes that abrupt shifts are more challenging, but does not empirically test this scenario.
- Why unresolved: The experiments focus on gradual shifts, and the paper does not provide data on STAD's robustness to sudden, large distributional changes.
- What evidence would resolve it: Experiments testing STAD on datasets with abrupt shifts, such as those with sudden concept drift or adversarial attacks, would clarify its limitations.

### Open Question 2
- Question: Can STAD's inferred cluster dispersion be used as a reliable, unsupervised metric to predict adaptation accuracy or detect when adaptation is no longer effective?
- Basis in paper: [explicit] The paper suggests that STAD's cluster dispersion could serve as an unsupervised metric to proactively flag when clusters start overlapping and estimate adaptation accuracy, but does not validate this claim.
- Why unresolved: While the paper observes a positive correlation between dispersion and accuracy, it does not test the metric's reliability or practical utility in real-world scenarios.
- What evidence would resolve it: Empirical validation of cluster dispersion as a predictive metric, including its sensitivity and specificity in detecting adaptation failure, would confirm its utility.

### Open Question 3
- Question: How does STAD perform when the source model's last-layer representations are not the primary source of distribution shift?
- Basis in paper: [explicit] The paper notes that STAD's performance depends on the shift being visible in the last layer, as adapting only the final classifier is less effective when earlier layers are primarily affected.
- Why unresolved: The experiments do not systematically isolate the contribution of earlier layers to the shift, leaving the extent of STAD's limitations unclear.
- What evidence would resolve it: Controlled experiments varying the location of the shift (e.g., by modifying earlier layers) would quantify STAD's effectiveness when the shift is not confined to the last layer.

### Open Question 4
- Question: What is the impact of using class-specific concentration parameters (κtrans_k, κems_k) versus global parameters on STAD's performance across diverse datasets?
- Basis in paper: [explicit] The paper mentions that for Yearbook, class-specific parameters were used, while global parameters were preferred for other datasets, but does not compare the two approaches systematically.
- Why unresolved: The paper does not provide a direct comparison of class-specific versus global parameters, leaving the optimal choice unclear for different types of shifts.
- What evidence would resolve it: Ablation studies comparing class-specific and global parameters across datasets with varying shift dynamics would clarify the trade-offs.

## Limitations

- The method assumes gradual, continuous temporal shifts and may not perform well under abrupt distribution shifts
- Computational complexity scales quadratically with feature dimension and sliding window size, potentially limiting scalability
- Relies on inferring ground truth class labels from data distribution, which may be unreliable under drastic label shifts

## Confidence

- **High Confidence**: The core mechanism of using state-space models for tracking prototype evolution is technically sound and well-established. The mathematical formulation of the von Mises-Fisher filtering approach is rigorous and reproducible.
- **Medium Confidence**: The empirical performance claims are supported by experimental results on the tested datasets. However, the limited number of datasets and the controlled nature of temporal shifts warrant cautious interpretation of generalizability.
- **Low Confidence**: Claims about STAD's superiority under all types of distribution shifts (especially abrupt shifts) and across diverse domains are not fully substantiated by the current experimental scope.

## Next Checks

1. **Abrupt Shift Evaluation**: Test STAD on datasets with known abrupt distribution shifts (e.g., synthetic datasets with sudden covariate changes) to validate its limitations and potential failure modes under non-gradual shifts.

2. **Cross-Domain Generalization**: Apply STAD to temporal datasets from different domains (e.g., medical imaging, sensor data, financial time series) to assess its robustness across varied data modalities and shift characteristics.

3. **Computational Scalability**: Benchmark STAD's runtime and memory usage on increasingly large feature dimensions and temporal sequences to quantify its scalability limitations and identify potential optimization strategies.