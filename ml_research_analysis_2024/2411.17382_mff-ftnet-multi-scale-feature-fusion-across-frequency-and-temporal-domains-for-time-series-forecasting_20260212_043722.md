---
ver: rpa2
title: 'MFF-FTNet: Multi-scale Feature Fusion across Frequency and Temporal Domains
  for Time Series Forecasting'
arxiv_id: '2411.17382'
source_url: https://arxiv.org/abs/2411.17382
tags:
- time
- series
- data
- forecasting
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'MFF-FTNet introduces a novel framework for time series forecasting
  that addresses challenges of noise, data sparsity, and multi-scale pattern capture
  by integrating contrastive learning with multi-scale feature extraction across both
  frequency and time domains. The method employs two complementary modules: a Frequency-Aware
  Contrastive Module (FACM) that refines spectral representations through adaptive
  frequency selection and dual-frequency contrastive loss, and a Complementary Time
  Domain Contrastive Module (CTCM) that captures short- and long-term dependencies
  using multi-scale convolutions and feature fusion.'
---

# MFF-FTNet: Multi-scale Feature Fusion across Frequency and Temporal Domains for Time Series Forecasting

## Quick Facts
- arXiv ID: 2411.17382
- Source URL: https://arxiv.org/abs/2411.17382
- Reference count: 37
- Primary result: MFF-FTNet achieves 7.7% MSE improvement on multivariate tasks and 4.0% MAE reduction, with 2.5% MSE and 2.4% MAE improvements for univariate forecasting

## Executive Summary
MFF-FTNet introduces a novel framework for time series forecasting that addresses challenges of noise, data sparsity, and multi-scale pattern capture by integrating contrastive learning with multi-scale feature extraction across both frequency and time domains. The method employs two complementary modules: a Frequency-Aware Contrastive Module (FACM) that refines spectral representations through adaptive frequency selection and dual-frequency contrastive loss, and a Complementary Time Domain Contrastive Module (CTCM) that captures short- and long-term dependencies using multi-scale convolutions and feature fusion. A unified feature representation strategy enables robust contrastive learning across domains. Extensive experiments on five real-world datasets demonstrate that MFF-FTNet significantly outperforms state-of-the-art models.

## Method Summary
MFF-FTNet uses a backbone encoder with dilated convolutions, FACM for frequency-aware contrastive learning, CTCM for time-domain multi-scale convolutions, and a unified feature representation. Training involves adaptive noise augmentation, contrastive losses in both domains, and joint optimization with weighted loss parameters. The model processes time series through FFT-based frequency extraction, parallel multi-scale convolutions, and feature fusion to capture both local and global temporal patterns while being robust to noise.

## Key Results
- Achieves 7.7% MSE improvement on multivariate forecasting tasks compared to state-of-the-art models
- Demonstrates 4.0% MAE reduction in univariate forecasting performance
- Shows 2.5% MSE and 2.4% MAE improvements across multiple datasets and horizons
- Outperforms baseline models consistently across all five real-world datasets (ETTh1, ETTh2, ETTm1, ETTm2, Weather)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FACM enhances noise resilience by masking high-frequency components and applying dual-frequency contrastive loss
- Mechanism: FACM applies FFT to extract frequency-domain representations, computes amplitude spectra, selects top-k frequencies with highest amplitudes, and masks remaining frequencies to remove noise from high-frequency components. Dual contrastive loss (Lamp on amplitude, Lphase on phase) forces discriminative frequency learning.
- Core assumption: Noise in time series predominantly exists in high-frequency components that can be effectively masked without losing critical periodic information
- Evidence anchors: [abstract] "FACM that refines spectral representations through frequency selection and contrastive learning"; [section D] "masking operation to filter out irrelevant high-frequency noise"

### Mechanism 2
- Claim: CTCM captures multi-scale temporal dependencies through parallel convolutions with varying kernel sizes
- Mechanism: CTCM employs multiple 1D convolutional layers with kernel sizes [1,2,4,8,16,32,64,128] operating in parallel. Smaller kernels detect local patterns while larger kernels capture long-term dependencies. Outputs are truncated, stacked, and processed through 2D convolutions and average pooling to fuse multi-scale features before contrastive learning.
- Core assumption: Time series patterns exist at multiple temporal scales that can be independently captured and then effectively fused
- Evidence anchors: [abstract] "CTCM that captures both short- and long-term dependencies using multi-scale convolutions and feature fusion"; [section F.2] "multiple parallel 1D convolutional layers with various kernel sizes"

### Mechanism 3
- Claim: Unified feature representation strategy enables robust contrastive learning across domains by concatenating time and frequency domain features
- Mechanism: After extracting features from both FACM and CTCM, the model concatenates ˜h (time domain) and ˆh (frequency domain) along the feature dimension. This combined representation h is passed through a linear layer to project into a shared latent space. The time contrastive loss (Ltime) uses this unified representation to learn discriminative temporal patterns.
- Core assumption: Time and frequency domain features contain complementary information that can be effectively integrated through simple concatenation
- Evidence anchors: [abstract] "unified feature representation strategy enables robust contrastive learning across domains"; [section F.3] "we concatenate the feature representations extracted from the time and frequency domains"

## Foundational Learning

- Concept: Fast Fourier Transform (FFT) for frequency domain analysis
  - Why needed here: FFT converts time series from time domain to frequency domain, revealing periodic patterns and enabling frequency-based filtering and analysis
  - Quick check question: What is the computational complexity of FFT and why is it suitable for time series analysis?

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: Contrastive learning helps the model learn discriminative representations by pulling together similar samples and pushing apart dissimilar ones, improving robustness to noise and generalization
  - Quick check question: How does the InfoNCE loss function mathematically encourage similar samples to be closer in embedding space?

- Concept: Multi-scale feature extraction through convolutional architectures
  - Why needed here: Different kernel sizes capture patterns at different temporal resolutions, allowing the model to detect both fine-grained local patterns and broad long-term trends
  - Quick check question: Why do larger convolutional kernels have larger receptive fields and how does this help capture long-term dependencies?

## Architecture Onboarding

- Component map: Input → Adaptive Noise Augmentation → Backbone Encoder → FACM → CTCM → Feature Fusion → Output
- Critical path: Input → Backbone → FACM/CTCM parallel processing → Feature concatenation → Output layer
- Design tradeoffs:
  - Frequency masking vs. preserving all information: Tradeoff between noise reduction and potential loss of useful high-frequency signals
  - Kernel size selection: Larger kernels capture longer dependencies but increase computational cost and risk overfitting
  - Activation function choice (SiLU vs GELU): SiLU provides smoother gradients but may require more careful initialization
- Failure signatures:
  - Poor performance on datasets with significant low-frequency noise: Indicates FACM masking removes useful information
  - Degradation on very long time series: Suggests CTCM kernel sizes are insufficient for capturing required dependencies
  - Overfitting on training data: May indicate insufficient regularization or too complex architecture for given dataset size
- First 3 experiments:
  1. Test FACM effectiveness: Run with FACM disabled (w/o FM) and compare noise robustness on noisy datasets
  2. Test CTCM kernel importance: Remove largest kernel (w/o 128) and measure impact on long-horizon forecasting
  3. Test activation function impact: Replace SiLU with GELU in backbone and compare convergence and final performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the adaptive noise augmentation strategy perform across different types of non-stationary time series data (e.g., financial vs. sensor data)?
- Basis in paper: [explicit] The paper states that the adaptive noise augmentation "dynamically adjusts the scaling and shifting factors based on the statistical properties of the original time series data."
- Why unresolved: The experiments focus on five specific datasets, which may not capture the full range of non-stationary behaviors found in real-world applications.
- What evidence would resolve it: Comparative experiments across diverse non-stationary datasets with varying statistical properties.

### Open Question 2
- Question: What is the optimal balance between the frequency domain loss and the feature loss (γ1 and γ2) for different time series forecasting tasks?
- Basis in paper: [explicit] The paper introduces two loss weight parameters, γ1 and γ2, to balance the contributions of frequency domain loss and feature loss.
- Why unresolved: The experiments use fixed values for these parameters, but the optimal balance may vary depending on the characteristics of the time series data.
- What evidence would resolve it: Systematic experiments varying γ1 and γ2 across different datasets and forecasting tasks to determine optimal values.

### Open Question 3
- Question: How does the model's performance change when using different activation functions in the backbone encoder beyond SiLU and GELU?
- Basis in paper: [explicit] The paper compares SiLU and GELU activation functions, noting that SiLU yields better performance.
- Why unresolved: The paper only compares two activation functions, leaving open the question of whether other functions might perform even better.
- What evidence would resolve it: Experiments testing additional activation functions (e.g., ReLU, ELU) in the backbone encoder across various datasets.

## Limitations

- Limited ablation study detail for novel mechanisms (FACM, CTCM, unified feature representation)
- Adaptive noise augmentation approach lacks specification of exact noise types and magnitudes
- Loss weighting parameters (λ, γ1, γ2) are tuned per dataset but optimization process is not fully detailed

## Confidence

- High confidence: Overall architecture design and multi-scale approach, supported by extensive experimental results across five datasets
- Medium confidence: Effectiveness of FACM for noise resilience, as the mechanism is novel but only validated through comparison rather than controlled ablation
- Low confidence: Specific implementation details of adaptive noise augmentation and exact loss parameter tuning methodology

## Next Checks

1. **Ablation study replication**: Implement and compare all seven ablation variants (w/o FM, w/o PL, w/o AL, w/o 128, w/o 16, w/o 2, w/o 1) on a subset of datasets to verify claimed improvements

2. **Noise robustness validation**: Systematically vary noise levels in training data to test the adaptive noise augmentation mechanism and its impact on FACM performance

3. **Kernel size sensitivity analysis**: Test CTCM performance with alternative kernel size combinations to determine if the specific [1,2,4,8,16,32,64,128] configuration is optimal or dataset-dependent