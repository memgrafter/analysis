---
ver: rpa2
title: The Effects of Embodiment and Personality Expression on Learning in LLM-based
  Educational Agents
arxiv_id: '2407.10993'
source_url: https://arxiv.org/abs/2407.10993
tags:
- personality
- learning
- agents
- agent
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study examines how personality expression and embodiment
  affect personality perception and learning in educational conversational agents.
  We developed an LLM-based system with three models: dialogue-only, animated human
  with dialogue-only, and animated human with dialogue and body/facial animations.'
---

# The Effects of Embodiment and Personality Expression on Learning in LLM-based Educational Agents

## Quick Facts
- **arXiv ID**: 2407.10993
- **Source URL**: https://arxiv.org/abs/2407.10993
- **Reference count**: 40
- **Primary result**: High-trait agents perceived as more engaging; embodied agents seen as more beneficial; conscientiousness correlates most with learning in dialogue-only model

## Executive Summary
This study investigates how personality expression and embodiment affect personality perception and learning in educational conversational agents. Using an LLM-based system with three models (dialogue-only, animated human with dialogue-only, and animated human with dialogue and body/facial animations), the research assessed two personality styles across these models. Results showed that high-trait agents were perceived as more engaging than low-trait agents, with statistically significant effects on openness, extroversion, agreeableness, and emotional stability. While model type did not significantly affect personality perception, embodied agents were perceived as more beneficial and interesting. The highest correlations between learning outcomes and perceived personality traits were found in the dialogue-only model, particularly for conscientiousness.

## Method Summary
The study developed an LLM-based conversational agent system using GPT-3.5 Turbo integrated with 3D humanoid models in Unity. Three agent models were created: dialogue-only, animated human with dialogue-only, and animated human with dialogue and body/facial animations. The system used personality expression through dialogue and Laban Movement Analysis-based animations to represent high and low extroversion and agreeableness. A user study with 210 participants (35 per model-style combination) was conducted using Prolific, where participants interacted with one of six system variants and completed surveys on personality perception (BFI-2-XS) and learning outcomes (LOES-S). Statistical analysis included two-way ANOVA for model type and personality style effects, followed by Pearson correlation analysis.

## Key Results
- High-trait agents perceived as more engaging than low-trait agents across four personality dimensions (openness, extroversion, agreeableness, emotional stability)
- Model type did not significantly affect personality perception or learning outcomes, though embodied agents were rated as more beneficial and interesting
- Conscientiousness showed highest correlation with learning outcomes, particularly in dialogue-only model
- No significant interaction effects between model type and personality style on learning outcomes

## Why This Works (Mechanism)

### Mechanism 1
High extroversion-agreeableness combinations increase perceived openness, extroversion, agreeableness, and emotional stability through personality-specific body movements (direct/indirect space, strong/light weight, bound/free flow) combined with facial expressions (relaxed/smiling vs. tense/avoiding eye contact) signaling social warmth and energy. Core assumption: LMA parameters reliably map to target personality dimensions. Evidence: Abstract states high-trait agents are more engaging; section describes specific LMA mappings. Break condition: If gesture mappings fail to align with participant perceptions.

### Mechanism 2
Embodied agents do not significantly outperform dialogue-only agents in perceived personality or learning scores because visual presence alone does not add measurable learning or personality perception benefits beyond text-to-speech and dynamic subtitles. Core assumption: Embodied vs. disembodied presence is the main differentiator in learning outcomes. Evidence: Abstract notes embodied agents perceived as more beneficial despite no significant personality perception effects; section confirms no significant effects on LOES-S scores. Break condition: If embodied agents provide longer-term engagement effects missed in short interaction window.

### Mechanism 3
Conscientiousness correlates most strongly with learning outcomes in dialogue-only models because without competing visual attention, participants attribute reliability and organizational skills to the agent, boosting conscientiousness perception and learning. Core assumption: Participants use conscientiousness as proxy for instructional effectiveness when no embodied cues are present. Evidence: Abstract highlights conscientiousness-learning correlation in dialogue-only model; section suggests lack of visual representation allowed focus on educational aspects. Break condition: If conscientiousness is misattributed, correlations may be coincidental.

## Foundational Learning

- **Five-Factor Model (OCEAN) personality dimensions**: Why needed - study measures and manipulates all five traits to assess perception and learning. Quick check - What are the five dimensions and their inverse traits in OCEAN?
- **Laban Movement Analysis (LMA) mapping to personality**: Why needed - animation cues derived from LMA parameters to express extroversion and agreeableness. Quick check - Which LMA factors correspond to high extroversion-agreeableness?
- **Large Language Model (LLM) prompting for personality**: Why needed - GPT-3.5 Turbo prompted with system messages to generate trait-consistent dialogue. Quick check - How do system messages encode personality in the chat completions API?

## Architecture Onboarding

**Component map**: Unity 3D scene with 4 character models (2 male, 2 female, light/dark skin) -> GPT-3.5 Turbo via OpenAI Chat Completions API -> Microsoft TTS for speech synthesis -> LMA-based animation controller for body gestures -> FACS-based facial blend shape controller -> Oculus Lipsync for mouth animation

**Critical path**: User types prompt → Unity sends to GPT with system message + recent 5-turn context → GPT returns text → TTS synthesizes speech → TTS word-by-word triggers subtitle display → LMA/FACS animation updates applied per turn → User rates personality and learning outcomes

**Design tradeoffs**: Token limit (750) to keep responses concise; Local TTS vs. cloud API for immediacy but lower realism; Single 3D model selection for variety but no controlled gender/skin color effect

**Failure signatures**: TTS mispronunciations or robotic voice → poor engagement; Animation lag or mismatch → uncanny valley perception; Context drift from limited message history → off-topic responses

**First 3 experiments**: 1) Swap TTS provider to cloud API and measure realism ratings; 2) Vary token limit to see impact on learning scores; 3) Test additional personality trait combinations (e.g., high conscientiousness)

## Open Questions the Paper Calls Out

**Open Question 1**: How does the system's performance change with longer-term interactions compared to the single-session format used in this study? Basis: Paper acknowledges single-session format as limitation suggesting long-term studies might yield different results. Why unresolved: Current study only assessed short-term learning outcomes after single interaction. Evidence needed: Longitudinal study tracking comprehension and engagement across multiple sessions.

**Open Question 2**: What is the optimal balance between agent expressiveness and cognitive load for different types of learners? Basis: Paper found embodied agents perceived as more engaging but did not significantly improve learning outcomes, with some participants finding responses too lengthy or distracting. Why unresolved: Study did not systematically vary expressiveness levels or measure impact on cognitive load for different learner types. Evidence needed: Experiment varying expressiveness levels and measuring learning outcomes and cognitive load for different learner groups.

**Open Question 3**: How do individual differences in learner personality and preferences influence effectiveness of personality-matched versus mismatched agents? Basis: Paper acknowledges individual differences across user preferences were prominent and suggests customized agents could increase trust and engagement. Why unresolved: Current study used random assignment of personality styles without considering individual personalities or preferences. Evidence needed: Study matching agents' personalities to learners' personalities and comparing outcomes to mismatched pairs.

## Limitations

- Short interaction duration (single session) may not capture long-term engagement effects of embodied agents
- Statistical power for model type comparisons appears low with no significant effects detected despite observable differences in user perceptions
- Use of conscientiousness as learning proxy in dialogue-only conditions lacks direct validation

## Confidence

- **High confidence**: High-trait agents are perceived as more engaging than low-trait agents (supported by significant ANOVA results across four personality dimensions)
- **Medium confidence**: Embodied agents are perceived as more beneficial and interesting despite no learning score differences (self-report data shows trends but lacks statistical significance)
- **Low confidence**: Conscientiousness-learning correlation in dialogue-only models represents genuine instructional effectiveness (no direct evidence linking conscientiousness perception to actual learning gains)

## Next Checks

1. Conduct a longitudinal study with repeated interactions to test whether embodied agents show cumulative learning benefits over time that single-session studies miss
2. Implement a control condition with non-personality-matched agents to isolate whether conscientiousness correlations reflect instructional quality or general agent reliability perceptions
3. Replicate the LMA animation mappings with objective motion capture validation to confirm that implemented movements accurately represent the target personality dimensions