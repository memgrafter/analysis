---
ver: rpa2
title: Learning Pattern-Specific Experts for Time Series Forecasting Under Patch-level
  Distribution Shift
arxiv_id: '2410.09836'
source_url: https://arxiv.org/abs/2410.09836
tags:
- time
- series
- tfps
- forecasting
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of time series forecasting under
  patch-level distribution shift, where different segments of time series data exhibit
  varying patterns due to concept drift. The core method, TFPS, employs a dual-domain
  encoder to capture both time-domain and frequency-domain features, followed by subspace
  clustering to identify distinct patterns across patches.
---

# Learning Pattern-Specific Experts for Time Series Forecasting Under Patch-level Distribution Shift

## Quick Facts
- arXiv ID: 2410.09836
- Source URL: https://arxiv.org/abs/2410.09836
- Authors: Yanru Sun; Zongxia Xie; Emadeldeen Eldele; Dongyue Chen; Qinghua Hu; Min Wu
- Reference count: 40
- One-line primary result: TFPS improves MSE by 9.5% and MAE by 6.4% compared to time-domain methods in time series forecasting under patch-level distribution shift.

## Executive Summary
This paper addresses the challenge of time series forecasting under patch-level distribution shift, where different segments of time series data exhibit varying patterns due to concept drift. The proposed method, TFPS, employs a dual-domain encoder to capture both time-domain and frequency-domain features, followed by subspace clustering to identify distinct patterns across patches. Pattern-specific experts are then used to model these unique patterns, enabling tailored predictions for each patch. Extensive experiments on nine real-world datasets demonstrate that TFPS outperforms state-of-the-art methods, particularly in long-term forecasting, achieving top-1 performance in 57 out of 72 settings.

## Method Summary
TFPS addresses time series forecasting under patch-level distribution shift by first segmenting time series into patches, then using a dual-domain encoder (combining time-domain self-attention and frequency-domain Fourier transform) to extract complementary features. A Pattern Identifier module employs subspace clustering to dynamically identify distinct patterns across patches, and a Mixture of Pattern Experts (MoPE) assigns specialized MLP-based experts to model each identified pattern. The model uses a gating network to select top-k experts for each patch based on cluster assignments, with their outputs weighted and aggregated for the final prediction.

## Key Results
- TFPS achieves top-1 performance in 57 out of 72 settings across nine real-world datasets
- TFPS improves MSE by 9.5% and MAE by 6.4% compared to time-domain methods
- TFPS shows significant enhancements over frequency-domain and time-frequency methods, particularly in long-term forecasting scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The dual-domain encoder (DDE) enables the model to capture complementary temporal dynamics by integrating both time-domain and frequency-domain features.
- **Mechanism**: The DDE processes each patch through two separate branches: a time encoder using self-attention to capture sequential dependencies, and a frequency encoder using Fourier transform to extract periodic and spectral patterns. These representations are then concatenated for prediction.
- **Core assumption**: Time-domain and frequency-domain representations capture fundamentally different and complementary aspects of temporal patterns in time series data.
- **Evidence anchors**:
  - [abstract]: "TFPS employs a dual-domain encoder to capture both time-domain and frequency-domain features, enabling a more comprehensive understanding of temporal dynamics."
  - [section 3.4]: "By modeling data in both the time and frequency domains, the DDE provides a more comprehensive understanding of temporal patterns, enabling the model to effectively handle complexities such as concept drift and evolving dynamics."
  - [corpus]: Weak. No direct corpus evidence comparing dual-domain vs single-domain approaches in time series forecasting.
- **Break condition**: If the frequency components add negligible information or introduce noise that degrades prediction accuracy.

### Mechanism 2
- **Claim**: Pattern Identifier (PI) using subspace clustering dynamically identifies distinct patterns across patches, enabling adaptive expert routing.
- **Mechanism**: The PI constructs subspace bases and computes subspace affinity between embedded representations and these bases. It uses KL divergence to refine cluster assignments, assigning each patch to its most appropriate expert based on learned patterns.
- **Core assumption**: Time series patches exhibit distinct distributional patterns that can be meaningfully clustered into subspaces representing different regimes or concepts.
- **Evidence anchors**:
  - [abstract]: "It then performs subspace clustering to dynamically identify distinct patterns across data segments."
  - [section 3.5]: "Unlike traditional approaches that treat the entire time series uniformly, our PI module dynamically classifies patches based on their distributional characteristics, enabling a more precise and adaptive modeling strategy."
  - [section 4.7]: "Through training, pattern experts in MoPE spontaneously specialize, and we present two examples in Figure 5. We visualize the expert with the highest score as the routed expert for each instance pair."
- **Break condition**: If the clustering fails to separate meaningful patterns or if the subspace affinity measure doesn't effectively distinguish between different regimes.

### Mechanism 3
- **Claim**: Mixture of Pattern Experts (MoPE) enables specialized modeling of identified patterns, improving adaptation to distribution shifts.
- **Mechanism**: For each identified pattern, MoPE assigns a dedicated MLP-based expert. A gating network selects the top-k experts based on cluster assignments, and their outputs are weighted and aggregated for the final prediction.
- **Core assumption**: Different temporal patterns require distinct predictive functions, and specializing experts for each pattern improves overall forecasting accuracy.
- **Evidence anchors**:
  - [abstract]: "Finally, these patterns are modeled by specialized experts, allowing the model to learn multiple predictive functions."
  - [section 3.6]: "To address the limitation of uniform modeling under distribution shift, we introduce the Mixture of Pattern Experts module (MoPE), which assigns specialized experts to patches based on their unique underlying patterns, enabling more precise and adaptive forecasting."
  - [section 4.7]: "In the provided examples, we observe that expert-0 specialize in downward-related concepts, while expert-4 focuses on parabolic trend."
- **Break condition**: If the number of experts is insufficient to capture all patterns or if the gating mechanism fails to select appropriate experts for given patches.

## Foundational Learning

- **Concept**: Distribution shift and concept drift in time series
  - Why needed here: The paper's core motivation is that real-world time series exhibit varying patterns across segments due to distribution shifts, making uniform modeling ineffective.
  - Quick check question: What are the key differences between sudden drift and gradual drift in time series, and how might they affect forecasting performance?

- **Concept**: Frequency domain analysis and Fourier transforms
  - Why needed here: The dual-domain encoder relies on frequency domain representations to capture periodic patterns that complement time-domain features.
  - Quick check question: How does the Fourier transform help identify periodic patterns in time series, and why might these be complementary to time-domain features?

- **Concept**: Mixture-of-Experts (MoE) architectures
  - Why needed here: MoPE is central to the proposed method, requiring understanding of how gating mechanisms route inputs to specialized experts.
  - Quick check question: What are the key advantages of using MoE over a single unified model for time series forecasting under distribution shifts?

## Architecture Onboarding

- **Component map**:
  Input → Patch segmentation → Positional embeddings → Dual-domain encoder (Time/Frequency branches) → Pattern Identifier → Mixture of Pattern Experts → Concatenation → Linear prediction

- **Critical path**:
  1. Patch segmentation and positional embedding addition
  2. Dual-domain feature extraction (time and frequency)
  3. Pattern identification via subspace clustering
  4. Expert routing and aggregation through MoPE
  5. Final prediction through linear layer

- **Design tradeoffs**:
  - Number of experts vs. model complexity and overfitting
  - Patch length selection (heuristic vs. learned)
  - Balance between time and frequency domain contributions
  - Top-k selection in gating network vs. full softmax

- **Failure signatures**:
  - Poor clustering performance → Similar patterns routed to different experts or vice versa
  - Insufficient experts → Overlapping pattern assignments or inability to capture all regimes
  - Frequency domain noise → Degraded performance when spectral features add little value
  - Patch segmentation issues → Distribution shifts within patches or artificial boundaries

- **First 3 experiments**:
  1. Ablation study: Remove frequency encoder to validate dual-domain contribution
  2. Sensitivity analysis: Vary number of experts in each domain to find optimal configuration
  3. Distribution shift test: Apply synthetic drift to data and measure PI effectiveness in rerouting experts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TFPS handle time series data with multiple overlapping patterns of different frequencies, and what are the limits of its pattern identification capability?
- Basis in paper: [explicit] The paper discusses TFPS's ability to capture both time-domain and frequency-domain features, but doesn't explicitly address how it handles overlapping patterns of different frequencies.
- Why unresolved: While the paper demonstrates TFPS's effectiveness in capturing distinct patterns, it doesn't provide a detailed analysis of its performance when faced with multiple overlapping patterns of varying frequencies.
- What evidence would resolve it: Experiments on datasets with known overlapping patterns of different frequencies, along with a detailed analysis of TFPS's ability to disentangle and model these patterns, would provide insights into its limitations and capabilities.

### Open Question 2
- Question: How does the choice of patch length affect TFPS's performance, and is there an optimal way to determine this parameter?
- Basis in paper: [inferred] The paper mentions that the patch length is chosen heuristically and that TFPS struggles with handling indivisible lengths or multi-period characteristics in time series.
- Why unresolved: The paper doesn't provide a systematic analysis of how the choice of patch length affects TFPS's performance, nor does it propose a method for determining an optimal patch length.
- What evidence would resolve it: A comprehensive study examining the impact of different patch lengths on TFPS's performance across various datasets, along with a proposed method for determining an optimal patch length based on the characteristics of the time series data, would address this question.

### Open Question 3
- Question: How does TFPS adapt to evolving distribution shifts, particularly when new patterns emerge over time?
- Basis in paper: [explicit] The paper acknowledges that real-world time series data undergo expansion, implying that new patterns continually emerge over time, but it doesn't provide a solution for addressing these evolving distribution shifts.
- Why unresolved: While the paper demonstrates TFPS's effectiveness in handling existing patterns, it doesn't explore how the model adapts to new patterns that emerge over time.
- What evidence would resolve it: Experiments on time series data with known evolving patterns, along with a detailed analysis of how TFPS adapts to these changes and whether it can effectively model new patterns as they emerge, would provide insights into its ability to handle evolving distribution shifts.

## Limitations
- The paper doesn't provide a systematic analysis of how patch length affects performance or propose a method for determining optimal patch length.
- The effectiveness of frequency domain features depends heavily on whether they capture meaningful periodic patterns versus adding noise, but this is not thoroughly validated.
- The paper lacks quantitative metrics to measure expert specialization, relying instead on qualitative visualizations of expert behavior.

## Confidence

### Major Uncertainties
- **High confidence**: The overall methodology framework (dual-domain encoding → pattern identification → expert modeling) is logically coherent and well-motivated by the problem of patch-level distribution shift.
- **Medium confidence**: The experimental results showing TFPS outperforming baselines, particularly in long-term forecasting settings, though the specific contribution of each component remains unclear without ablation studies.
- **Low confidence**: Claims about frequency domain benefits and the effectiveness of subspace clustering without direct comparative evidence or sensitivity analyses.

## Next Checks
1. **Ablation study**: Remove the frequency encoder to quantify the actual contribution of dual-domain features versus time-domain only, measuring performance degradation.
2. **Clustering validation**: Apply the Pattern Identifier to synthetic datasets with known distribution shifts to verify it correctly identifies and separates the different regimes.
3. **Expert specialization metrics**: Develop quantitative measures of expert specialization (e.g., entropy of cluster assignments, intra-cluster variance) to validate that MoPE is learning meaningful patterns rather than random partitions.