---
ver: rpa2
title: A Systematic Review on Long-Tailed Learning
arxiv_id: '2408.00483'
source_url: https://arxiv.org/abs/2408.00483
tags:
- learning
- long-tailed
- data
- classes
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive survey of long-tailed learning
  methods, which addresses the challenge of building high-performance models on datasets
  with long-tailed distributions. The authors propose a novel taxonomy with eight
  dimensions to categorize existing long-tailed visual learning approaches, including
  data balancing, neural architecture, feature enrichment, logits adjustment, loss
  function, bells and whistles, network optimization, and post hoc processing.
---

# A Systematic Review on Long-Tailed Learning

## Quick Facts
- arXiv ID: 2408.00483
- Source URL: https://arxiv.org/abs/2408.00483
- Reference count: 40
- Primary result: Comprehensive survey of long-tailed learning methods with novel taxonomy across eight dimensions

## Executive Summary
This paper presents a systematic review of long-tailed learning (LTL) methods, which addresses the challenge of building high-performance models on datasets with long-tailed distributions. The authors propose a novel taxonomy with eight dimensions to categorize existing approaches, including data balancing, neural architecture, feature enrichment, logits adjustment, loss function, bells and whistles, network optimization, and post hoc processing. The survey provides a comprehensive analysis of state-of-the-art methods, their commonalities and differences, and discusses the distinctions between imbalance learning and long-tailed learning.

## Method Summary
The paper systematically reviews long-tailed learning methods by proposing a taxonomy with eight dimensions: data balancing, neural architecture, feature enrichment, logits adjustment, loss function, bells and whistles, network optimization, and post hoc processing. The methodology involves analyzing existing approaches within each dimension, discussing their mechanisms and effectiveness, and providing a comprehensive overview of the field. The survey includes experimental results from representative methods on benchmark datasets like CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018.

## Key Results
- Proposed a novel taxonomy with eight dimensions to categorize long-tailed learning approaches
- Demonstrated that class-balanced sampling improves tail-class representation during classifier training while uniform sampling prevents overfitting on tail classes
- Showed that logit calibration via margin learning can adjust decision boundaries to favor tail classes without altering the learned feature space
- Identified that ensemble methods with diverse sampling distributions improve tail-class recall by aggregating complementary expert predictions

## Why This Works (Mechanism)

### Mechanism 1
- Class-balanced sampling improves tail-class representation during feature learning, while uniform sampling prevents overfitting on tail classes
- Decoupled learning framework alternates between class-balanced sampling in classifier training stage and uniform sampling in feature extraction stage
- Core assumption: Tail-class samples are semantically richer and benefit more from class-balanced exposure during classifier training
- Evidence: Class-balanced resampling learns discriminative feature representations when training samples are highly semantically related to target labels

### Mechanism 2
- Logit calibration via margin learning adjusts decision boundaries to favor tail classes without altering feature space
- Methods like LDAM subtract class-specific margins from logits before Softmax, expanding decision margins for minority classes
- Core assumption: Original classifier weights are biased toward head classes, and logit-level adjustment can correct this bias
- Evidence: LDAM uses class-wise margin parameters reversely proportional to quadratic root of sample numbers in each class

### Mechanism 3
- Ensemble methods with diverse sampling distributions improve tail-class recall by aggregating complementary expert predictions
- Methods like ACE, RIDE, and SADE train multiple models on different subsets or distributions, then aggregate logits or predictions
- Core assumption: Tail-class errors are complementary across models trained on different data distributions
- Evidence: RIDE trains multiple recognition models on randomly sampled subsets and uses their logits mean for predictions

## Foundational Learning

- **Imbalanced data distributions and their impact on model bias**
  - Why needed: Long-tailed data is a specific form of class imbalance where tail classes collectively dominate but individually lack samples
  - Quick check: What is the key difference between long-tailed and generic imbalanced data in terms of tail class quantity and influence?

- **Feature representation learning in deep networks**
  - Why needed: Long-tailed recognition requires learning discriminative features before classification
  - Quick check: In the decoupled framework, why is random sampling used in the first stage instead of class-balanced sampling?

- **Logit-level operations and Softmax margin adjustments**
  - Why needed: Logit calibration and margin learning are lightweight post-processing steps that improve tail-class accuracy
  - Quick check: How does subtracting a class-specific margin from logits before Softmax affect the decision boundary for minority classes?

## Architecture Onboarding

- **Component map**: Data preprocessing → Feature extraction (Stage 1) → Classifier training (Stage 2) → Post hoc calibration
- **Critical path**: Feature extraction must produce class-discriminative embeddings; classifier training must leverage balanced sampling or logit adjustment to avoid head-class dominance
- **Design tradeoffs**: Class-balanced sampling improves tail-class accuracy but risks overfitting; uniform sampling generalizes better but under-represents tails; logit adjustment is fast but less flexible than retraining
- **Failure signatures**: Overfitting on tail classes (low head accuracy), severe head-class dominance (low tail accuracy), or calibration mismatch (low ECE but poor tail recall)
- **First 3 experiments**:
  1. Train baseline ResNet-50 with uniform sampling; measure per-class accuracy and ECE
  2. Apply LDAM margin adjustment post-training; compare tail-class recall and overall accuracy
  3. Implement BBN-style decoupled training; evaluate if tail accuracy improves without sacrificing head accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively handle test sets that are also long-tailed or non-uniformly distributed, given that most current LTL methods assume uniformly distributed test sets?
- Basis: While most LTL methods train on long-tailed data but evaluate on uniformly distributed data, real-world applications often present long-tailed or skewed test distributions
- Why unresolved: Current evaluation metrics focus on overall accuracy assuming uniform test distributions
- What evidence would resolve it: Empirical studies comparing LTL methods on both uniform and long-tailed test sets with new evaluation metrics

### Open Question 2
- Question: What are the most effective strategies for federated long-tailed learning, considering both data heterogeneity and long-tailed distributions across clients?
- Basis: Fairness within federated learning systems in long-tailed settings needs in-depth investigations
- Why unresolved: Federated learning introduces complexity due to data heterogeneity and privacy constraints
- What evidence would resolve it: Comparative studies of federated learning approaches on heterogeneous and long-tailed datasets

### Open Question 3
- Question: How can we improve the robustness of adversarial training under long-tailed distributions to prevent robust overfitting?
- Basis: Combining Balanced Softmax Loss and data augmentation can alleviate robust overfitting and improve model robustness
- Why unresolved: Challenge of robust overfitting in adversarial training under long-tailed distributions remains significant
- What evidence would resolve it: Experimental results showing effectiveness of new adversarial training techniques on long-tailed datasets

## Limitations

- Taxonomy may not capture all emerging approaches combining multiple dimensions in novel ways
- Many reported results are based on synthetic long-tailed datasets rather than real-world scenarios
- Effectiveness of decoupling feature extraction and classifier training may depend heavily on dataset characteristics
- Logit adjustment mechanisms provide lightweight solutions but may have limited adaptability to complex decision boundaries

## Confidence

- **High Confidence**: Taxonomy framework and categorization of methods (data balancing, neural architecture, feature enrichment, etc.) are well-supported by existing literature
- **Medium Confidence**: Decoupled learning framework shows promise but requires more empirical validation across diverse datasets and tasks
- **Medium Confidence**: Logit adjustment mechanisms are theoretically sound but practical effectiveness may vary based on implementation details

## Next Checks

1. Implement and test the decoupled framework on multiple real-world long-tailed datasets (iNaturalist 2018, LVIS) to validate generalizability beyond synthetic benchmarks
2. Conduct ablation studies comparing effectiveness of different margin adjustment strategies in logit calibration across various long-tailed distributions
3. Evaluate ensemble methods (RIDE, SADE) on datasets with different imbalance factors to determine robustness and identify optimal aggregation strategies