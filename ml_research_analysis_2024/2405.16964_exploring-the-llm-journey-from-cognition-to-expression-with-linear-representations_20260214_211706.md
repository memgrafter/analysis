---
ver: rpa2
title: Exploring the LLM Journey from Cognition to Expression with Linear Representations
arxiv_id: '2405.16964'
source_url: https://arxiv.org/abs/2405.16964
tags:
- cognitive
- capability
- expressive
- linear
- capabilities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines the evolution of cognitive and expressive capabilities
  in large language models (LLMs) through linear representations. The authors define
  cognitive capability as the information conveyed by neuron output vectors, and expressive
  capability as the model's ability to produce word-level outputs.
---

# Exploring the LLM Journey from Cognition to Expression with Linear Representations

## Quick Facts
- arXiv ID: 2405.16964
- Source URL: https://arxiv.org/abs/2405.16964
- Authors: Yuzi Yan; Jialian Li; Yipin Zhang; Dong Yan
- Reference count: 19
- Key outcome: Cognitive capabilities are primarily established during pretraining while expressive capabilities develop during SFT and RLHF, with a significant correlation between them

## Executive Summary
This study examines the evolution of cognitive and expressive capabilities in large language models through linear representations, defining cognitive capability as information conveyed by neuron output vectors and expressive capability as the model's ability to produce word-level outputs. Using Baichuan-7B and Baichuan-33B models, the authors find that cognitive capabilities are primarily established during pretraining, while expressive capabilities develop during supervised fine-tuning and reinforcement learning from human feedback. A significant statistical correlation exists between these capabilities, with cognitive capacity potentially limiting expressive potential. The research reveals that the gap between these capabilities stems from differences in linear separability between hidden and token-level spaces, and various optimization-independent strategies like few-shot learning and repeated sampling can effectively bridge this gap.

## Method Summary
The study uses PCA on intermediate layer embeddings to quantify cognitive capability, and direct token generation to evaluate expressive capability, with hyperparameters including temperature 1.2, top_p 0.9, and top_k 50. The methodology involves training or loading model checkpoints from Pretraining, SFT (4 epochs), and RLHF (PPO) phases, then running capability quantification and correlation analysis across all phases. The approach analyzes four standard benchmark datasets (OpenbookQA, CommonSenseQA, RACE, ARC) formatted as single-choice questions with 4 options each, examining how cognitive and expressive capabilities evolve through different training stages and how they relate to each other.

## Key Results
- Cognitive capabilities are primarily established during pretraining while expressive capabilities develop during SFT and RLHF
- A significant statistical correlation exists between cognitive and expressive capabilities, suggesting cognitive capacity may limit expressive potential
- The gap between cognitive and expressive capabilities stems from superior linear separability in hidden space compared to token-level space

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cognitive capability is primarily established during pretraining while expressive capability develops during SFT and RLHF
- Mechanism: The pretraining phase builds rich internal representations in hidden space through massive data exposure, creating strong cognitive foundations. Later fine-tuning stages optimize the final output layer to better map these internal representations to accurate token-level outputs
- Core assumption: The hidden space representations contain more information than token-level outputs, and the final linear layer is the primary bottleneck for expression
- Evidence anchors:
  - [abstract]: "cognitive abilities are largely established during Pretraining, whereas expressive abilities predominantly advance during SFT and RLHF"
  - [section 3.3]: "cognitive capability is primarily established during the Pretraining stage, whereas expressive capability is developed during the SFT and RLHF stages"
  - [corpus]: Weak - neighbors focus on different capability frameworks rather than this specific developmental timeline
- Break condition: If pretraining data is insufficient or corrupted, cognitive capability cannot be established even if SFT/RLHF phases are well-executed

### Mechanism 2
- Claim: The gap between cognitive and expressive capabilities stems from differences in linear separability between hidden and token-level spaces
- Mechanism: Hidden space Rm allows for better class separation with lower intra-class variance and higher inter-class variance compared to token-level space T. A linear classifier in Rm can achieve much higher accuracy than direct token generation in T
- Core assumption: The model's internal representations contain correct information but the final mapping to tokens is lossy
- Evidence anchors:
  - [abstract]: "The paper also explores the theoretical underpinnings of these divergent developmental trajectories and their connection to the LLMs' architectural design"
  - [section 4.1]: "The gap between cognitive and expressive capabilities stems from the superior mapping efficiency of the function f(·) compared to g(·), along with the greater linear separability afforded by the hidden space Rm over the token-level space T"
  - [corpus]: Weak - no direct corpus evidence supporting this specific linear separability argument
- Break condition: If the final linear layer is significantly retrained during SFT/RLHF, the gap narrows as the token-level space becomes more separable

### Mechanism 3
- Claim: Statistical correlation exists between cognitive and expressive capabilities, with cognitive capacity potentially limiting expressive potential
- Mechanism: As cognitive capability improves during pretraining, it sets an upper bound on what expressive capability can achieve. SFT and RLHF can only bring expressive capability closer to this cognitive ceiling but cannot exceed it
- Core assumption: The model's internal knowledge constrains what it can express, regardless of fine-tuning
- Evidence anchors:
  - [abstract]: "Statistical analyses confirm a significant correlation between the two capabilities, suggesting that cognitive capacity may limit expressive potential"
  - [section 3.5]: "Our null hypothesis assumes aexp and acog are independent. Under this premise, the consistency count across methods for a set of questions is expected to adhere to a binomial distribution... Such low probabilities strongly suggest the null hypothesis to be improbable, thereby indicating a significant correlation between aexp and acog"
  - [corpus]: Weak - neighboring papers discuss capability frameworks but not this specific correlation analysis
- Break condition: If novel architectures or training methods can extract and express information beyond what's captured in hidden representations, this correlation could break

## Foundational Learning

- Concept: Linear representations and PCA analysis
  - Why needed here: The paper uses Principal Component Analysis on hidden layer activations to quantify cognitive capability
  - Quick check question: Can you explain how PCA extracts the most informative directions from high-dimensional neural activations?

- Concept: Transformer architecture and residual connections
  - Why needed here: Understanding how information flows through layers is crucial for interpreting why cognitive capability plateaus in deeper layers
  - Quick check question: How do residual connections affect the propagation of information and gradients through deep transformer networks?

- Concept: Statistical hypothesis testing
  - Why needed here: The paper uses binomial distribution analysis to establish correlation between cognitive and expressive capabilities
  - Quick check question: Can you set up and interpret a hypothesis test comparing two accuracy measurements from different evaluation methods?

## Architecture Onboarding

- Component map: Input -> Embedding -> N Transformer blocks -> Final hidden state -> Vocabulary linear layer -> Output logits -> Softmax -> Token prediction
- Critical path: The path from final hidden state through vocabulary linear layer to output is critical for bridging cognitive-expressive gap
- Design tradeoffs: Larger models have more redundant layers that strengthen cognitive capability but may not improve expressiveness proportionally
- Failure signatures: Low consistency between cognitive and expressive capability measurements indicates bottleneck in final linear layer
- First 3 experiments:
  1. Measure cognitive capability at each layer using PCA to identify where representational capacity peaks
  2. Compare linear classifier accuracy on hidden states vs. direct token generation accuracy to quantify gap
  3. Apply few-shot learning and repeated sampling to observe if expressive capability can approach cognitive ceiling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the architectural design of LLMs, particularly Residual Connections and pre-Layer Normalization, contribute to the redundancy observed in the plateau of cognitive capability establishment?
- Basis in paper: [explicit]
- Why unresolved: The paper suggests that the plateau in cognitive capability may result from redundancy in the model's architecture, particularly due to Residual Connections and pre-Layer Normalization. However, the exact mechanisms by which these architectural features lead to redundancy are not fully explored or explained.
- What evidence would resolve it: Further experimental studies that manipulate or remove these architectural components and observe the impact on the plateau phenomenon would provide insights into their role in redundancy.

### Open Question 2
- Question: What is the impact of different training data distributions on the cognitive and expressive capabilities of LLMs, and how does this affect the alignment between the two capabilities?
- Basis in paper: [inferred]
- Why unresolved: The paper discusses the asynchronous development of cognitive and expressive capabilities during different training phases but does not delve into how varying training data distributions might influence this alignment. Understanding this could provide insights into optimizing training processes.
- What evidence would resolve it: Conducting experiments with diverse training data distributions and analyzing their effects on the alignment between cognitive and expressive capabilities would shed light on this question.

### Open Question 3
- Question: How do the cognitive and expressive capabilities of LLMs differ when evaluated across various tasks, such as reasoning, commonsense understanding, and information retrieval?
- Basis in paper: [explicit]
- Why unresolved: While the paper mentions that cognitive capabilities are primarily developed during Pretraining and expressive capabilities are refined in subsequent phases, it does not provide a detailed analysis of how these capabilities perform across different task types.
- What evidence would resolve it: Comparative studies that evaluate the performance of LLMs on a wide range of tasks and analyze the differences in cognitive and expressive capabilities would help answer this question.

## Limitations
- Architectural specificity limits generalizability to other model families or architectures
- Heavy reliance on four standard benchmark datasets without exploring diverse task domains
- Correlation does not definitively prove cognitive capacity limits expressive potential

## Confidence

**High Confidence**: The existence of a measurable gap between cognitive and expressive capabilities, demonstrated through PCA analysis and direct token generation comparisons. The correlation analysis methodology is sound and the results are reproducible.

**Medium Confidence**: The developmental timeline showing cognitive capabilities established during pretraining while expressive capabilities develop during SFT/RLHF. This follows expected training dynamics but could vary with different model scales or training regimes.

**Low Confidence**: The theoretical claim that the gap stems specifically from linear separability differences between hidden and token spaces. While plausible, this mechanism isn't directly validated through ablation studies or alternative architectural comparisons.

## Next Checks

1. **Cross-Architecture Validation**: Apply the same cognitive-expressive capability framework to models from different families (e.g., GPT, Llama, Mistral) to test whether the developmental timeline and correlation patterns hold universally across architectures.

2. **Ablation of Final Linear Layer**: Systematically vary or remove the final linear layer's influence through techniques like intermediate layer supervision or different output mechanisms to directly test whether the hidden-to-token mapping bottleneck drives the capability gap.

3. **Extended Capability Correlation Analysis**: Expand the correlation study to include additional capability dimensions beyond the binary cognitive-expressive framework, such as reasoning depth, factual consistency, or multimodal integration, to determine if the correlation extends to broader capability landscapes.