---
ver: rpa2
title: System Safety Monitoring of Learned Components Using Temporal Metric Forecasting
arxiv_id: '2405.13254'
source_url: https://arxiv.org/abs/2405.13254
tags:
- safety
- uni00000013
- uni00000003
- uni00000011
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a safety monitoring method for learned components
  in autonomous systems using temporal metric forecasting. The method predicts safety
  metric values over a hazard forecast horizon, given learned component outputs and
  the operational context.
---

# System Safety Monitoring of Learned Components Using Temporal Metric Forecasting

## Quick Facts
- arXiv ID: 2405.13254
- Source URL: https://arxiv.org/abs/2405.13254
- Reference count: 40
- Primary result: Proposed method achieves precision of 0.993 and recall of 0.985 for predicting safety violations in autonomous aircraft taxiing using Temporal Fusion Transformer

## Executive Summary
This paper presents a safety monitoring approach for learned components in autonomous systems using temporal metric forecasting. The method predicts safety metric values over a hazard forecast horizon using probabilistic time series forecasting, enabling early detection of safety violations. By leveraging deep learning models like Temporal Fusion Transformer (TFT), the approach identifies dangerous combinations of system context and learned component outputs that could lead to safety violations. The method is evaluated on an autonomous aircraft taxiing case study, demonstrating effective safety violation prediction with acceptable latency and resource consumption.

## Method Summary
The safety monitoring method works by taking learned component outputs and operational context as inputs, then using probabilistic deep learning forecasting to predict the distribution of safety metric values over a specified hazard forecast horizon. The maximum predicted value in this distribution is compared against a safety violation threshold to determine if a violation will occur. The approach uses sequence-to-sequence deep learning models that can process both static and dynamic inputs, with TFT showing the best performance. Instead of relying on single forecast values, the method predicts the full probability distribution and uses tail-end quantiles to make conservative safety violation predictions.

## Key Results
- Temporal Fusion Transformer (TFT) achieved precision of 0.993 and recall of 0.985 for predicting safety violations at 3-second forecast horizon
- The method successfully predicts safety violations with acceptable latency and resource consumption for real-time deployment
- Using tail-end quantiles of predicted distributions provides conservative estimates that reduce false negatives in safety-critical applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Probabilistic time series forecasting predicts near-future safety metric values, enabling early detection of safety violations.
- Mechanism: The safety monitor takes learned component outputs and operational context as inputs, then uses a global probabilistic DL forecaster to predict the distribution of the safety metric over a hazard forecast horizon. The maximum predicted value in this distribution is checked against a safety violation threshold to determine if a violation will occur.
- Core assumption: The future safety metric is a function of the recent history of learned component outputs and operational context, and this relationship can be learned from historical data.
- Evidence anchors: [abstract] "Given the learned component outputs and an operational context, we empirically investigate different Deep Learning (DL)-based probabilistic forecasting to predict the objective measure capturing the satisfaction or violation of a safety requirement (safety metric)."

### Mechanism 2
- Claim: Sequence-to-sequence DL models (like TFT) are effective for this task due to their ability to process both static and dynamic inputs with low inference latency.
- Mechanism: Models like TFT encode the time series of safety metrics and learned component outputs, along with static scenario parameters, into a fixed-size representation, then decode it to generate probabilistic forecasts over the hazard horizon. Their architecture allows parallel computation and avoids error accumulation over long horizons.
- Core assumption: Sequence-to-sequence models can effectively capture the temporal dependencies in the safety metric while handling both static and dynamic features.
- Evidence anchors: [abstract] "For both case studies, Temporal Fusion Transformer (TFT) was the most accurate model for predicting imminent safety violations, with acceptable latency and resource consumption."

### Mechanism 3
- Claim: Using tail-end quantiles of the predicted safety metric distribution provides conservative estimates for safety violation prediction.
- Mechanism: Instead of using the median or mean of the predicted distribution, the safety monitor uses high quantiles (e.g., 0.995) to ensure that the predicted safety metric values are worst-case estimates. This increases the likelihood of correctly predicting violations while accepting a higher false positive rate.
- Core assumption: Safety-critical systems prioritize avoiding false negatives (missed violations) over false positives, making conservative estimates acceptable.
- Evidence anchors: [abstract] "Due to the safety-critical nature of learning-enabled systems, where the cost of not predicting safety violations at runtime is very high, instead of relying on single forecast values for each timestep, our method predicts the probability distribution of the safety metric and relies on its tail-end values to conservatively predict safety violations."

## Foundational Learning

- Concept: Time series forecasting and probabilistic prediction
  - Why needed here: The core of the safety monitoring method is predicting future values of a safety metric, which is a time series. Probabilistic prediction is needed to quantify uncertainty and make conservative estimates for safety.
  - Quick check question: What is the difference between point forecasting and probabilistic forecasting, and why is probabilistic forecasting preferred for safety-critical applications?

- Concept: Deep Learning architectures for forecasting (iterative vs. sequence-to-sequence)
  - Why needed here: Different DL architectures have different strengths and weaknesses for forecasting. Understanding these is crucial for selecting the right model for the safety monitoring task.
  - Quick check question: What are the key differences between iterative and sequence-to-sequence forecasting architectures, and what are the implications for error accumulation over long forecast horizons?

- Concept: Evaluation metrics for forecasting and safety monitoring (q-Risk, Precision, Recall, F3 score)
  - Why needed here: The effectiveness of the safety monitoring method needs to be evaluated using appropriate metrics that capture both the accuracy of safety metric predictions and the ability to correctly predict safety violations.
  - Quick check question: What do the metrics q-Risk, Precision, Recall, and F3 score measure, and how do they relate to the goals of safety metric forecasting and safety violation prediction?

## Architecture Onboarding

- Component map: System-in-the-Loop (SITL) simulation -> Data Preprocessing -> Model Training -> Inference -> Safety Violation Prediction

- Critical path:
  1. Generate or obtain historical data of learned component outputs, safety metric, and scenario parameters.
  2. Preprocess the data (normalize, split).
  3. Train and tune DL forecasting models.
  4. Evaluate models on test data using q-Risk, Precision, Recall, and F3 score.
  5. Deploy the best model for runtime safety monitoring.

- Design tradeoffs:
  - Forecast horizon vs. accuracy: Longer forecast horizons may lead to decreased accuracy due to error accumulation.
  - Lookback window size vs. resource usage: Larger lookback windows may improve accuracy but increase memory and computation requirements.
  - Conservative estimates vs. false positives: Using tail-end quantiles increases the likelihood of detecting violations but also increases false positives.

- Failure signatures:
  - High q-Risk values indicate poor safety metric prediction accuracy.
  - Low Precision values indicate a high rate of false alarms.
  - Low Recall values indicate a high rate of missed safety violations.
  - High inference latency or memory usage may make the safety monitor impractical for deployment.

- First 3 experiments:
  1. Train and evaluate a simple DL forecaster (e.g., DeepAR) on a small subset of the data to verify the data pipeline and get baseline performance metrics.
  2. Compare the performance of different DL forecaster architectures (e.g., TFT vs. DeepAR) on the full dataset to identify the most promising model.
  3. Evaluate the impact of different forecast horizon and lookback window sizes on the accuracy and resource usage of the best-performing model.

## Open Questions the Paper Calls Out

- How do different forecasting models compare in terms of safety metric prediction accuracy when the hazard forecast horizon exceeds the minimum reaction time?
- How do the safety metric prediction accuracy and resource usage of the evaluated models change when applied to different learning-enabled autonomous systems, such as autonomous driving or agricultural systems?
- How does the safety violation prediction accuracy of the evaluated models change when using search-based methods to identify the hazard boundary of the learned component?

## Limitations
- The evaluation relies on a single case study (autonomous taxiing aircraft), which may not capture the full diversity of learned component behaviors in different domains.
- The approach assumes that safety metric dynamics are learnable from historical data, but this may not hold for all safety-critical systems with highly non-stationary or chaotic dynamics.
- The method's performance in extremely rare event scenarios is not thoroughly characterized, despite the claim of handling rare safety violations.

## Confidence

- **High Confidence**: The mechanism of using probabilistic time series forecasting for safety metric prediction is well-supported by the empirical results showing TFT achieving precision of 0.993 and recall of 0.985 at 3-second forecast horizon.
- **Medium Confidence**: The claim about sequence-to-sequence models being optimal due to low latency is supported by evaluation metrics but lacks comparison with alternative architectures that might offer better performance-safety tradeoffs.
- **Medium Confidence**: The use of tail-end quantiles for conservative estimates is theoretically sound, but the evaluation doesn't fully characterize the tradeoff between false positive rates and missed violations across different quantile thresholds.

## Next Checks

1. **Cross-domain validation**: Apply the safety monitoring method to a different autonomous system domain (e.g., autonomous vehicles or industrial robotics) to assess generalizability beyond aviation scenarios.

2. **Extreme rarity testing**: Systematically evaluate performance on datasets with varying levels of safety violation rarity (1-in-10,000 to 1-in-1,000,000 events) to characterize method behavior under different operational conditions.

3. **Dynamic scenario adaptation**: Test the method's ability to adapt to changing operational conditions by introducing concept drift or non-stationary behavior in the learned component outputs during runtime monitoring.