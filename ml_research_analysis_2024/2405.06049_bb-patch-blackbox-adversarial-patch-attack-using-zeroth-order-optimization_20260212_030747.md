---
ver: rpa2
title: 'BB-Patch: BlackBox Adversarial Patch-Attack using Zeroth-Order Optimization'
arxiv_id: '2405.06049'
source_url: https://arxiv.org/abs/2405.06049
tags:
- patch
- adversarial
- bb-patch
- attack
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes BB-Patch, a black-box adversarial patch-attack
  strategy using zeroth-order optimization, addressing the challenge of developing
  transferable and scalable adversarial patches in real-life scenarios where attackers
  have limited access to model parameters and training data. The core idea involves
  training adversarial patches using the Zeroth Order Adaptive Momentum Method (ZO-AdamM)
  to estimate model loss and apply the expectation over transformation function, making
  the patches universally applicable.
---

# BB-Patch: BlackBox Adversarial Patch-Attack using Zeroth-Order Optimization

## Quick Facts
- arXiv ID: 2405.06049
- Source URL: https://arxiv.org/abs/2405.06049
- Reference count: 29
- Primary result: Achieves significant accuracy drops (e.g., from 98.07% to 36.16% on MNIST with ResNet50) using black-box adversarial patches generated via zeroth-order optimization

## Executive Summary
This paper introduces BB-Patch, a novel black-box adversarial patch-attack strategy that addresses the challenge of developing transferable and scalable adversarial patches in real-world scenarios where attackers have limited access to model parameters and training data. The core approach leverages zeroth-order optimization, specifically the Zeroth Order Adaptive Momentum Method (ZO-AdamM), to estimate model loss and generate adversarial patches. By applying the expectation over transformation function, BB-Patch ensures that the generated patches are universally applicable across different models and datasets.

The effectiveness of BB-Patch is demonstrated through extensive experiments on benchmark datasets (MNIST, CIFAR-10, and Imagenet) using various model architectures (ResNet50, VGG16, and MobileNet). The results show significant drops in classification accuracy, proving the method's effectiveness and scalability. Additionally, BB-Patch exhibits strong transferability across different model architectures, performing comparably or better than existing universal patch methods in black-box settings. The study also highlights a practical application by successfully attacking a distracted driving detection model, showcasing the potential real-world impact of the proposed approach.

## Method Summary
BB-Patch employs zeroth-order optimization, specifically the Zeroth Order Adaptive Momentum Method (ZO-AdamM), to generate adversarial patches in black-box settings where model parameters and training data are inaccessible. The method estimates model loss gradients without requiring explicit gradient information, enabling the creation of transferable adversarial patches. By incorporating the expectation over transformation (EOT) function, BB-Patch ensures that the generated patches remain effective under various transformations, making them universally applicable across different models and datasets. This approach addresses the challenge of developing robust adversarial patches that can be used in real-world scenarios without prior knowledge of the target model.

## Key Results
- Achieves significant accuracy drops: From 98.07% to 36.16% on MNIST with ResNet50
- Demonstrates strong transferability across different model architectures (ResNet50, VGG16, MobileNet)
- Successfully attacks a distracted driving detection model, showcasing practical real-world applicability

## Why This Works (Mechanism)
BB-Patch works by leveraging zeroth-order optimization to estimate model loss gradients without requiring explicit gradient information, enabling black-box adversarial patch generation. The Zeroth Order Adaptive Momentum Method (ZO-AdamM) is used to iteratively update the patch to maximize the loss, making it effective even when the model's parameters are unknown. Additionally, the expectation over transformation (EOT) function ensures that the generated patches remain effective under various transformations, such as rotations, translations, and scaling, making them universally applicable across different models and datasets. This combination of ZO-AdamM and EOT allows BB-Patch to create robust adversarial patches that are both transferable and scalable in real-world scenarios.

## Foundational Learning
- **Zeroth-Order Optimization (ZO)**: A derivative-free optimization technique used when gradient information is unavailable, crucial for black-box attacks where model parameters are inaccessible. *Quick check: Verify ZO-AdamM implementation and convergence on benchmark functions.*
- **Expectation Over Transformation (EOT)**: A method to ensure adversarial examples remain effective under various transformations, essential for creating universal patches. *Quick check: Test patch effectiveness under rotations, translations, and scaling.*
- **Adversarial Patches**: Localized perturbations designed to fool machine learning models, important for real-world attacks where full-image perturbations are impractical. *Quick check: Evaluate patch transferability across different model architectures.*
- **Black-Box Attack**: An attack scenario where the attacker has no access to the model's internal parameters or training data, critical for real-world security applications. *Quick check: Confirm attack success without model access.*
- **Transferability**: The ability of adversarial examples to fool models they were not specifically designed for, key for practical black-box attacks. *Quick check: Test patch performance on unseen models.*
- **Universal Adversarial Patches**: Patches that work across different models and datasets, important for scalable and practical attacks. *Quick check: Validate patch effectiveness on multiple datasets.*

## Architecture Onboarding

**Component Map:**
Data Preprocessing -> ZO-AdamM Optimizer -> Adversarial Patch Generation -> Expectation Over Transformation (EOT) -> Evaluation on Target Models

**Critical Path:**
1. Data preprocessing and augmentation
2. ZO-AdamM optimization to estimate loss gradients
3. Adversarial patch generation and refinement
4. Application of EOT for transformation invariance
5. Evaluation on target models to measure effectiveness

**Design Tradeoffs:**
- Balance between patch size and attack effectiveness (larger patches may be more effective but less stealthy)
- Computational cost of ZO-AdamM vs. accuracy of gradient estimation
- Trade-off between transferability and specificity to target models

**Failure Signatures:**
- Low attack success rate indicating poor gradient estimation or insufficient optimization
- Patch ineffectiveness under transformations, suggesting inadequate EOT application
- Limited transferability across models, pointing to overfitting to the source model

**First Experiments:**
1. Test BB-Patch on MNIST with ResNet50 to replicate reported accuracy drop from 98.07% to 36.16%
2. Evaluate transferability by attacking VGG16 and MobileNet with patches generated for ResNet50
3. Assess patch effectiveness under various transformations (rotations, translations, scaling) using the EOT function

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses primarily on classification accuracy drops without extensive analysis of real-world robustness against common defenses
- Transferability results are mainly shown within image classification domains, lacking validation in more complex scenarios like object detection or segmentation tasks
- Practical attack on distracted driving detection lacks comprehensive detail regarding environmental conditions and defensive measures

## Confidence
- **High Confidence**: The core methodology using ZO-AdamM for black-box patch generation and the reported accuracy drops on benchmark datasets are well-supported by experimental results.
- **Medium Confidence**: The transferability claims across different architectures are supported but could benefit from more extensive cross-domain validation.
- **Medium Confidence**: The practical distracted driving attack demonstration is promising but lacks comprehensive environmental and defensive context.

## Next Checks
1. Evaluate BB-Patch against common adversarial defense mechanisms (e.g., adversarial training, input preprocessing) to assess practical robustness.
2. Test transferability of BB-Patch in object detection and semantic segmentation tasks, not just classification.
3. Conduct physical-world experiments with varying lighting conditions, viewing angles, and distances to validate the practical attack scenarios beyond controlled digital environments.