---
ver: rpa2
title: Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and
  Convolutional Architecture
arxiv_id: '2409.17788'
source_url: https://arxiv.org/abs/2409.17788
tags:
- image
- dataset
- images
- ensemble
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an ensemble approach combining EfficientNetV2
  and MaxViT for detecting six ophthalmic biomarkers in OCT images. By leveraging
  both local (CNN) and global (transformer) context features, the ensemble achieves
  a macro-averaged F1 score of 0.8116 on the test set.
---

# Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and Convolutional Architecture

## Quick Facts
- arXiv ID: 2409.17788
- Source URL: https://arxiv.org/abs/2409.17788
- Reference count: 22
- Macro-averaged F1 score of 0.8116 on test set using ensemble of EfficientNetV2 and MaxViT

## Executive Summary
This paper presents an ensemble approach for detecting six ophthalmic biomarkers in OCT images by combining EfficientNetV2 (CNN) and MaxViT (transformer) architectures. The ensemble leverages five parallel model branches trained on different dataset subsets to handle variations in OCT image sources. By optimizing ensemble weights through iterative validation, the approach achieves superior performance compared to individual models, demonstrating the effectiveness of combining local and global feature extraction capabilities for medical image analysis.

## Method Summary
The approach uses five parallel model branches: EfficientNetV2-M and MaxViT-base models trained on different combinations of Trex and Prime dataset subsets. Images are preprocessed with brightness/contrast adjustments and augmented with random crops, Gaussian blur, flipping, and perspective transforms. The ensemble combines predictions from all branches using optimized weights (0.1, 0.45, 0.1, 0.25, 0.1) determined through iterative validation. The final prediction is obtained through weighted averaging followed by rounding to the nearest class.

## Key Results
- Ensemble achieves macro-averaged F1 score of 0.8116 on test set
- EfficientNetV2-M alone achieves F1 score of 0.715
- MaxViT-base alone achieves F1 score of 0.703
- Optimized weights show MaxViT-base trained on both Trex and Prime (0.45) contributes most heavily to ensemble performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble of CNN and transformer models improves biomarker detection accuracy by combining local and global feature extraction capabilities.
- Mechanism: CNNs excel at extracting local context features through convolutional layers, while transformers capture global context through self-attention mechanisms. By combining both architectures, the ensemble leverages complementary strengths of each approach.
- Core assumption: Local features (CNN) and global features (transformer) are both essential for accurate ophthalmic biomarker detection.
- Evidence anchors: [abstract] "While CNNs are good for feature extraction within the local context of the image, transformers are known for their ability to extract features from the global context of the image." [section] "By ensembling EfficientNetV2 and MaxViT we were able to exploit both local context features and global context features."
- Break condition: If biomarkers primarily depend on either purely local or purely global features, ensemble benefit may be minimal.

### Mechanism 2
- Claim: Parallel model branches trained on different dataset subsets reduce bias and improve generalization across varying OCT image sources.
- Mechanism: Different OCT scanning machines produce images with varying characteristics. Separate training helps each branch specialize in handling specific variations from Trex and Prime scanners.
- Core assumption: OCT images from different scanning machines have distinct characteristics that affect model performance.
- Evidence anchors: [section] "We have observed that OCT scans from different sources can vary a lot depending on the manual ways of handling the scanner machine... So, we created 5 parallel branch: Both Trex & Prime dataset is included in training, Only Trex is used to train, Only Prime is used to train."
- Break condition: If dataset variations are minimal or test data distribution doesn't match training subsets.

### Mechanism 3
- Claim: Optimized ensemble weights significantly improve performance compared to equal weighting or single model approaches.
- Mechanism: Through iterative validation, different model branches contribute unequally to final prediction. The MaxViT-base trained on both Trex and Prime datasets (weight 0.45) contributes most heavily.
- Core assumption: Optimal weighting distribution can be determined through validation and remains effective for test set.
- Evidence anchors: [section] "To Select Optimal Weight for each branch we have created a validation set... Then, we took 'Iterative approach' to find the best suited weights... it is seen that the best result doesn't come for a single model but rather a distributed weight gives the best result."
- Break condition: If validation set doesn't represent test distribution well, or optimal weights change significantly.

## Foundational Learning

- Concept: Understanding of CNNs and Vision Transformers
  - Why needed here: The paper builds an ensemble combining EfficientNetV2 (CNN) and MaxViT (hybrid CNN-Transformer), requiring knowledge of both architectures' strengths and limitations
  - Quick check question: What is the key difference between how CNNs and Vision Transformers extract features from images?

- Concept: Ensemble learning techniques
  - Why needed here: The approach uses weighted averaging of multiple model predictions, requiring understanding of how ensembles work and when they're beneficial
  - Quick check question: What are the three main sources of error in machine learning models that ensemble methods aim to minimize?

- Concept: OCT image characteristics and biomarker detection
  - Why needed here: The task involves detecting specific biomarkers in OCT images, requiring understanding of what these biomarkers look like and how they appear in the imaging modality
  - Quick check question: Why is noise removal particularly challenging in OCT images for this application?

## Architecture Onboarding

- Component map:
  Data preprocessing (brightness/contrast adjustment) -> Data augmentation (random crop, Gaussian blur, flipping, perspective transforms) -> Five parallel branches (EfficientNetV2-M and MaxViT-base on different dataset splits) -> Weighted averaging ensemble layer with weights (0.1, 0.45, 0.1, 0.25, 0.1) -> Final rounding and prediction layer

- Critical path:
  1. Load and preprocess OCT image
  2. Apply data augmentation
  3. Pass through all five parallel branches
  4. Collect predictions from each branch
  5. Apply weighted averaging using optimized weights
  6. Round to nearest class for final prediction

- Design tradeoffs:
  - Model size vs. performance: Using smaller EfficientNetV2-M and MaxViT-base instead of larger SOTA models for faster training and inference
  - Complexity vs. accuracy: Five parallel branches add complexity but provide better generalization across different OCT sources
  - Preprocessing aggressiveness: Limited noise removal to preserve biomarker features that resemble noise

- Failure signatures:
  - Overfitting: If individual models perform well on validation but ensemble doesn't improve test performance
  - Data leakage: If parallel branches aren't truly independent or if validation set isn't representative
  - Weight optimization failure: If iterative weight selection doesn't converge or produces unstable results

- First 3 experiments:
  1. Train individual EfficientNetV2-M and MaxViT-base models on full dataset to establish baseline performance
  2. Create and test parallel branches with simple equal weighting (0.2 each) to verify the parallel approach adds value
  3. Implement iterative weight optimization on validation set and test ensemble performance with optimized weights

## Open Questions the Paper Calls Out

- Open Question 1: How does the performance of the ensemble model change when using a larger transformer architecture like ViT-large instead of MaxViT-base, considering the trade-off between accuracy and computational efficiency?
- Open Question 2: Would incorporating the unlabeled OCT images (68,700 images) through self-supervised learning techniques improve the biomarker detection performance beyond the current supervised approach?
- Open Question 3: How does the ensemble model perform on OCT images from different scanner types or clinical settings not represented in the training data, and what domain adaptation techniques could improve cross-site generalization?

## Limitations
- Dataset composition heavily skewed toward IRHRF cases (77.3%), with other biomarkers significantly underrepresented
- Paper lacks detailed analysis of how ensemble performs across different biomarker types
- Preprocessing approach is relatively minimal with only brightness and contrast adjustments

## Confidence
- High confidence in the ensemble mechanism (combining CNN and transformer architectures)
- Medium confidence in the dataset-specific claims (results may be specific to OLIVES dataset and scanner types)
- Low confidence in the comparative performance claims (lacks comparisons with other state-of-the-art methods)

## Next Checks
1. Evaluate ensemble performance on a more balanced dataset with equal representation across all six biomarker types
2. Test approach on OCT images from different scanner manufacturers not included in original training data
3. Compare ensemble performance against recent single-model state-of-the-art approaches for ophthalmic biomarker detection on same dataset