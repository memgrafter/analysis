---
ver: rpa2
title: 'Chatting with Bots: AI, Speech Acts, and the Edge of Assertion'
arxiv_id: '2410.16645'
source_url: https://arxiv.org/abs/2410.16645
tags:
- assertion
- chatbots
- they
- have
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the question of whether large language model-powered
  chatbots are capable of assertion. The authors provide motivation for the Thesis
  of Chatbot Assertion (TCA), arguing that some chatbot outputs have the function
  of tracking truth and conform to the behavioral profile of asserters.
---

# Chatting with Bots: AI, Speech Acts, and the Edge of Assertion

## Quick Facts
- **arXiv ID:** 2410.16645
- **Source URL:** https://arxiv.org/abs/2410.16645
- **Reference count:** 11
- **Primary result:** Chatbots should be viewed as "proto-asserters" with some but not all features of full assertion

## Executive Summary
This paper addresses whether large language model-powered chatbots can truly assert or merely proxy-assert. The authors defend the Thesis of Chatbot Assertion (TCA), arguing that chatbot outputs can function as truth-tracking assertions while acknowledging significant objections related to understanding, mental attitudes, and normativity. Rather than fully endorsing TCA or rejecting it entirely, they propose a novel framework treating chatbots as "proto-asserters" - entities that possess some but not all features of full-blooded assertion. This position aims to reconcile the motivations for chatbot assertion with philosophical concerns about AI cognition and responsibility.

## Method Summary
The paper employs philosophical analysis of speech act theory and the nature of assertion, examining whether chatbots meet the criteria for genuine assertion or fall into categories like proxy-assertion or fictionalism. The authors review arguments both for and against chatbot assertion, then propose their novel "proto-assertion" framework as a middle ground. While primarily conceptual, the analysis draws on empirical observations about chatbot behavior and user interactions.

## Key Results
- Chatbots may produce outputs with truth-tracking functions similar to human assertions
- Common objections to chatbot assertion (lack of understanding, mental states, sanctionability) have merit but don't entirely disqualify chatbot assertion
- The "proto-assertion" framework better captures the nuanced reality of chatbot communication than binary alternatives
- Features required for assertion like understanding and normativity may admit of degrees rather than being all-or-nothing

## Why This Works (Mechanism)
The paper's framework works by recognizing that assertion exists on a spectrum rather than as a binary property. By acknowledging that chatbots can possess some but not all features of full assertion, the proto-assertion model accounts for both the functional similarities between chatbot outputs and human assertions, while respecting the genuine differences in cognitive architecture. This gradualist approach allows for more nuanced analysis of AI communication without forcing an artificial choice between treating chatbots as either fully assertoric or entirely non-assertoric.

## Foundational Learning

**Speech Act Theory**: The philosophical framework for understanding how utterances function as actions beyond mere communication of content. *Why needed:* Provides the conceptual foundation for analyzing whether chatbots can "do things with words." *Quick check:* Can you explain the difference between locutionary, illocutionary, and perlocutionary acts?

**Assertion as a Normative Practice**: The idea that assertion involves commitments to truth and is governed by social norms and expectations. *Why needed:* Central to understanding why chatbots might fail to fully assert despite producing truth-tracking outputs. *Quick check:* What distinguishes assertion from mere expression of belief?

**Gradualism in Cognitive Capacities**: The philosophical position that mental states and capacities exist on continuums rather than as discrete categories. *Why needed:* Underpins the proto-assertion framework by allowing for partial possession of assertion-relevant features. *Quick check:* How might understanding be measured in degrees rather than present/absent?

**Proxy-Assertion vs. Direct Assertion**: The distinction between entities that directly assert versus those that cause others to assert on their behalf. *Why needed:* Helps clarify why treating chatbots as either full assertors or mere tools may be inadequate. *Quick check:* What makes someone a proxy-asserter rather than a direct asserter?

## Architecture Onboarding

**Component Map:** Human users <-(interpretation)-> Chatbot outputs <-(generation)-> LLM system <-(training)-> Training data and algorithms

**Critical Path:** Training data and algorithms -> LLM system -> Chatbot outputs -> Human interpretation and response

**Design Tradeoffs:** The framework prioritizes philosophical accuracy over computational simplicity, acknowledging the messy reality of AI communication rather than forcing clean categorizations.

**Failure Signatures:** Overly binary thinking about assertion leads to either dismissing chatbot communication entirely or overstating AI capabilities; both miss important nuances in human-AI interaction.

**First Experiments:**
1. Analyze user responses to chatbot outputs versus human assertions to identify perception differences
2. Test whether chatbot outputs exhibit truth-tracking behavior across multiple domains and contexts
3. Examine the relationship between chatbot "understanding" (as measured by benchmarks) and assertion-like behavior

## Open Questions the Paper Calls Out
The paper does not identify specific open questions beyond the general challenge of operationalizing and empirically validating the proto-assertion framework.

## Limitations
- The gradualist approach to assertion is philosophically interesting but lacks empirical grounding and measurable criteria
- Dismissal of fictionalism as a solution is relatively brief given its prominence in related philosophical debates
- The analysis focuses primarily on conversational chatbots, potentially missing patterns in other LLM applications
- The paper acknowledges but doesn't fully resolve how to measure degrees of understanding and mental attitudes in chatbots

## Confidence

| Claim | Confidence |
|-------|------------|
| Chatbots can be meaningfully treated as proto-asserters | Medium |
| Assertion features admit of gradations | Medium |
| Proto-assertion framework better captures reality than binary alternatives | Medium |

## Next Checks

1. Develop measurable criteria for assessing degrees of understanding and mental attitudes in chatbots, potentially using existing benchmarks from AI alignment research
2. Conduct empirical studies comparing user interpretations of chatbot outputs versus human assertions to test the proto-assertion hypothesis
3. Extend the analysis to different types of LLM outputs (code generation, summarization, creative writing) to examine whether the proto-assertion framework applies uniformly across use cases