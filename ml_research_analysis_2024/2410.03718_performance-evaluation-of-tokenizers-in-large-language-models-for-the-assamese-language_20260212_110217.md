---
ver: rpa2
title: Performance Evaluation of Tokenizers in Large Language Models for the Assamese
  Language
arxiv_id: '2410.03718'
source_url: https://arxiv.org/abs/2410.03718
tags:
- language
- assamese
- tokenizers
- performance
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the performance of tokenizers in five large
  language models (LLMs) for the Assamese language. The authors compare tokenization
  efficiency using the Normalized Sequence Length (NSL) metric, which measures the
  ratio of encoded sequence lengths between different tokenizers.
---

# Performance Evaluation of Tokenizers in Large Language Models for the Assamese Language

## Quick Facts
- arXiv ID: 2410.03718
- Source URL: https://arxiv.org/abs/2410.03718
- Reference count: 27
- Primary result: SUTRA tokenizer achieves best NSL score (0.45) for Assamese language processing

## Executive Summary
This paper evaluates five large language models' tokenizers for Assamese language processing using Normalized Sequence Length (NSL) as the primary metric. The study compares SUTRA, GPT-4o, Gemma 2, Meta Llama 3.1, and Mistral Large Instruct 2407 tokenizers. Results show significant variation in tokenization efficiency, with SUTRA performing best and Mistral performing worst. The findings highlight the importance of tokenizer design and vocabulary size for low-resource languages like Assamese.

## Method Summary
The authors evaluate tokenization efficiency using Normalized Sequence Length (NSL), which measures the ratio of encoded sequence lengths between different tokenizers. They compare five LLM tokenizers: SUTRA from Two AI, GPT-4o from OpenAI, Gemma 2, Meta Llama 3.1, and Mistral Large Instruct 2407. The study focuses exclusively on the Assamese language and uses NSL as the sole evaluation metric to determine tokenization efficiency across these models.

## Key Results
- SUTRA tokenizer achieves the best performance with NSL value of 0.45
- GPT-4o ranks second with NSL of 0.54
- Gemma 2 follows with NSL of 0.82
- Meta Llama 3.1 and Mistral Large Instruct 2407 show poor performance with NSL values of 1.4 and 1.48 respectively
- Mistral's limited vocabulary size (32.7k tokens) correlates with worst performance

## Why This Works (Mechanism)
Tokenization efficiency directly impacts model performance for low-resource languages. The NSL metric captures how well tokenizers compress Assamese text, with lower values indicating better compression. SUTRA's superior performance likely stems from its optimized vocabulary and tokenization algorithm specifically designed for Indian languages. The correlation between vocabulary size and performance suggests that larger token vocabularies can better capture the morphological complexity of Assamese.

## Foundational Learning

Subword tokenization
- Why needed: Enables efficient representation of rare words and morphological variants
- Quick check: Verify that tokenizers can handle Assamese compound words and conjunct consonants

Normalized Sequence Length (NSL)
- Why needed: Provides standardized metric for comparing tokenization efficiency across models
- Quick check: Ensure NSL calculations use consistent normalization across all tokenizers

Vocabulary size impact
- Why needed: Determines coverage of language-specific features and morphological variants
- Quick check: Compare vocabulary coverage against comprehensive Assamese lexicon

## Architecture Onboarding

Component map: Input text -> Tokenizer -> Token IDs -> Model -> Output tokens
Critical path: Text input → Tokenization → Model processing → Output generation
Design tradeoffs: Vocabulary size vs. model efficiency, language-specific optimization vs. general applicability
Failure signatures: High NSL values indicate poor compression, vocabulary gaps cause unknown token issues
First experiments: 1) Measure vocabulary coverage for Assamese-specific characters, 2) Test tokenization of compound words, 3) Evaluate handling of morphologically complex forms

## Open Questions the Paper Calls Out
None

## Limitations
- NSL metric doesn't measure actual downstream task performance
- No vocabulary coverage analysis for Assamese-specific linguistic features
- Test corpus composition and domain diversity not specified
- No validation of whether tokenization efficiency translates to better model performance

## Confidence

Tokenization efficiency ranking: Medium
- Based on NSL metric but lacks downstream task validation

SUTRA tokenizer superiority: Medium
- Best NSL score but causal mechanisms not explained

Mistral tokenizer limitations: Medium
- Correlation with vocabulary size noted but causation not established

## Next Checks

1. Conduct downstream task evaluation using the same LLMs on representative Assamese NLP benchmarks (sentiment analysis, named entity recognition, question answering) to verify whether NSL-based rankings correlate with actual performance.

2. Perform vocabulary coverage analysis by measuring how well each tokenizer handles Assamese-specific linguistic features like conjunct consonants, vowel signs, and compound words, particularly comparing coverage against a comprehensive Assamese lexicon.

3. Test tokenizer robustness by evaluating performance across different text domains (formal news, social media, literature, technical documents) to ensure findings aren't domain-specific artifacts.