---
ver: rpa2
title: 'Tree-Planted Transformers: Unidirectional Transformer Language Models with
  Implicit Syntactic Supervision'
arxiv_id: '2402.12691'
source_url: https://arxiv.org/abs/2402.12691
tags:
- syntactic
- structures
- tree-planting
- transformer
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Tree-Planted Transformers (TPT), a method
  to implicitly incorporate syntactic supervision into unidirectional Transformer
  Language Models (LMs) without sacrificing inference efficiency. Unlike previous
  approaches that require explicit syntactic structure generation or external parsers,
  TPT "plants" syntactic trees into attention weights during training using a tree-planting
  loss based on syntactic distance matrices.
---

# Tree-Planted Transformers: Unidirectional Transformer Language Models with Implicit Syntactic Supervision

## Quick Facts
- arXiv ID: 2402.12691
- Source URL: https://arxiv.org/abs/2402.12691
- Authors: Ryo Yoshida; Taiga Someya; Yohei Oseki
- Reference count: 24
- Key outcome: TPT achieves 77.1% accuracy on SyntaxGym vs 71.7% for vanilla Transformer LM

## Executive Summary
This paper introduces Tree-Planted Transformers (TPT), a method to implicitly incorporate syntactic supervision into unidirectional Transformer Language Models without sacrificing inference efficiency. Unlike previous approaches requiring explicit syntactic structure generation, TPT "plants" syntactic trees into attention weights during training using a tree-planting loss based on syntactic distance matrices. The approach maintains the training efficiency of syntactic language models while preserving the inference efficiency of standard Transformer LMs.

Experiments on the SyntaxGym benchmark demonstrate that TPTs significantly outperform vanilla Transformer LMs and various syntactic language models that generate hundreds of syntactic structures in parallel. The best-performing TPT variant, using dependency structures, achieves an overall accuracy of 77.1% on SyntaxGym compared to 71.7% for the vanilla Transformer LM baseline, despite not explicitly generating syntactic structures.

## Method Summary
TPT integrates syntactic supervision into unidirectional Transformer LMs by computing a tree-planting loss that measures the KL divergence between word-level attention weights and syntactic distance-based supervision matrices. The method uses a single attention head on the last layer for tree-planting, balancing this loss with next-word prediction loss using λ=0.5. Training is performed on the BLLIP corpus with dependency or constituency structures obtained from external parsers. Evaluation is conducted on the SyntaxGym benchmark using GPT-2 small architecture (124M parameters).

## Key Results
- TPT[dep.] achieves 77.1% overall accuracy on SyntaxGym, outperforming vanilla Transformer LM (71.7%) and syntactic language models
- Single tree-planted head performs optimally; multiple heads degrade performance
- Dependency structures show higher compatibility with tree-planting than constituency structures, particularly on Agreement circuits
- TPT maintains inference efficiency while improving syntactic generalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tree-planting implicitly supervises attention weights using syntactic distance matrices to improve syntactic generalization without explicit structure generation
- Mechanism: The tree-planting loss computes KL divergence between a supervision matrix S (derived from syntactic distance matrix D) and actual attention weights W, guiding the model to attend to syntactically related words
- Core assumption: Exponential decay of attention weights with syntactic distance approximates human-like syntactic knowledge
- Evidence anchors:
  - [abstract] "we 'plant' trees into attention weights of unidirectional Transformer LMs to implicitly reflect syntactic structures"
  - [section 3.1] "this supervision expects the attention weight of each word to decrease exponentially with the number of edges between the predicted word"
  - [corpus] Weak - no direct empirical evidence of human-like attention patterns provided
- Break condition: If syntactic distance does not correlate with actual syntactic dependencies in the language being modeled

### Mechanism 2
- Claim: Single tree-planted head achieves optimal balance between syntactic supervision and next-word prediction
- Mechanism: By restricting tree-planting to one attention head, the model avoids redundancy while maintaining syntactic benefits
- Core assumption: Multiple tree-planted heads introduce conflicting information that hinders learning
- Evidence anchors:
  - [section 5.1] "the highest accuracy was achieved when only a single head was adopted as a tree-planted head"
  - [section 5.2] "by overtly focusing on reflecting syntactic structures, TPTs paradoxically become unable to learn syntactic knowledge efficiently"
  - [corpus] Moderate - experimental results show single head outperforms multiple heads
- Break condition: If task complexity requires distributed syntactic supervision across multiple heads

### Mechanism 3
- Claim: Dependency structures show higher compatibility with tree-planting than constituency structures due to head proximity properties
- Mechanism: Dependency structures maintain the head of subject noun phrases closest to main verbs, aligning with exponential decay assumption
- Core assumption: The number of edges on syntactic structures correlates with syntactic relevance for prediction
- Evidence anchors:
  - [section 4.3] "TPT[dep.] most significantly outperformed TPT [cons.] on the Agreement circuit"
  - [section 4.3] "the head of the subject NP (author) is always nearest to the main verb on dependency structures, but the same does not hold on constituency structures"
  - [corpus] Strong - direct comparison between dependency and constituency structures shows performance differences
- Break condition: If language syntax doesn't exhibit the head proximity property assumed by dependency structures

## Foundational Learning

- Concept: KL divergence loss for attention supervision
  - Why needed here: To measure the difference between desired attention patterns and actual attention weights
  - Quick check question: How does KL divergence differ from other distance metrics like L2 loss when supervising attention?

- Concept: Syntactic distance matrix computation
  - Why needed here: To convert syntactic structures into a form that can supervise attention weights
  - Quick check question: What information is lost when converting dependency structures to distance matrices?

- Concept: Subword to word-level attention conversion
  - Why needed here: To align the subword-level attention from Transformers with word-level syntactic supervision
  - Quick check question: Why can't we directly apply syntactic supervision at the subword level?

## Architecture Onboarding

- Component map: Unidirectional Transformer LM -> Attention weight conversion (subword→word) -> Tree-planting loss computation -> Weighted loss combination
- Critical path: Training loop -> Tree-planted head attention computation -> KL divergence calculation -> Loss backpropagation
- Design tradeoffs: Single vs. multiple tree-planted heads (simplicity vs. coverage), loss weight balancing (syntactic vs. next-word prediction)
- Failure signatures: Performance degradation on syntax-specific tasks, perplexity increase, loss divergence during training
- First 3 experiments:
  1. Verify tree-planting loss decreases when model learns desired attention patterns
  2. Compare single vs. multiple tree-planted heads on a small benchmark
  3. Test different λ values (0.25, 0.5, 0.75) on SyntaxGym to find optimal balance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would Tree-Planted Transformers perform with document-level syntactic supervision instead of sentence-level?
- Basis in paper: [explicit] The authors note that current experiments use sentence-level tree-planting due to treebank constraints, but document-level SLMs are emerging
- Why unresolved: The paper only tested sentence-level tree-planting, leaving document-level performance unexplored
- What evidence would resolve it: Experiments training TPTs with document-level syntactic annotations and comparing performance against sentence-level TPTs

### Open Question 2
- Question: Does tree-planting improve performance on non-syntactic tasks beyond the syntactic knowledge benchmark?
- Basis in paper: [inferred] The authors mention recent work showing syntactic supervision benefits text classification and generation tasks, suggesting broader evaluation potential
- Why unresolved: The paper only evaluated on SyntaxGym benchmark and perplexity, not on practical downstream tasks
- What evidence would resolve it: Experiments testing TPTs on text classification, generation, and other NLP tasks while comparing against standard Transformer LMs

### Open Question 3
- Question: Why does tree-planting show high compatibility with dependency structures compared to constituency structures?
- Basis in paper: [explicit] The authors observed dependency structures significantly outperformed constituency structures, particularly on Agreement circuits, and speculate this relates to head positioning
- Why unresolved: The authors provide initial hypotheses but no definitive explanation for this structural difference
- What evidence would resolve it: Detailed analysis of attention patterns across different syntactic structures and controlled experiments testing various syntactic distance metrics

## Limitations

- Unidirectional constraint limits generalizability to bidirectional models and encoder-decoder architectures
- Parser dependency introduces potential errors and inconsistencies in syntactic supervision quality
- Single head restriction may not generalize across different model sizes and architectures
- Syntactic distance assumption may not hold for all linguistic phenomena and languages

## Confidence

**High Confidence**:
- TPT significantly improves syntactic generalization compared to vanilla Transformer LMs
- Dependency structures show better compatibility with tree-planting than constituency structures
- Single tree-planted head achieves optimal performance balance

**Medium Confidence**:
- Tree-planting maintains inference efficiency while improving syntactic knowledge
- Exponential decay of attention weights approximates human-like syntactic knowledge
- The head proximity property in dependency structures drives performance gains

**Low Confidence**:
- Tree-planting implicitly reflects human-like syntactic knowledge in attention patterns
- The approach scales effectively to larger models and more complex architectures
- Performance generalizes to languages beyond English with different syntactic properties

## Next Checks

1. **Cross-Lingual Generalization**: Evaluate TPT on multiple languages with varying syntactic properties (e.g., morphologically rich languages, languages with free word order) to test the universality of the tree-planting approach and dependency structure advantages.

2. **Multi-Head Investigation**: Systematically explore multi-head configurations beyond the single head constraint, including head-specific task assignments and dynamic head selection mechanisms to determine if the single-head finding is architecture-dependent.

3. **Ablation on Parser Quality**: Conduct controlled experiments using parsers of varying quality (gold standard vs. neural vs. statistical) to quantify the impact of parser reliability on TPT performance and establish robustness requirements for syntactic supervision quality.