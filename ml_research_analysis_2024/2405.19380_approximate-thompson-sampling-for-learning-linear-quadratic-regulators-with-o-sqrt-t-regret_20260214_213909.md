---
ver: rpa2
title: Approximate Thompson Sampling for Learning Linear Quadratic Regulators with
  $O(\sqrt{T})$ Regret
arxiv_id: '2405.19380'
source_url: https://arxiv.org/abs/2405.19380
tags:
- where
- bound
- regret
- page
- follows
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes an approximate Thompson sampling algorithm\
  \ for learning linear quadratic regulators (LQR) with an improved O(\u221AT) regret\
  \ bound. The method leverages Langevin dynamics with a carefully designed preconditioner\
  \ and incorporates a simple excitation mechanism."
---

# Approximate Thompson Sampling for Learning Linear Quadratic Regulators with $O(\sqrt{T})$ Regret

## Quick Facts
- arXiv ID: 2405.19380
- Source URL: https://arxiv.org/abs/2405.19380
- Authors: Yeoneung Kim; Gihun Kim; Jiwhan Park; Insoon Yang
- Reference count: 40
- Key outcome: Proposed approximate Thompson sampling algorithm achieves $O(\sqrt{T})$ regret for LQR learning

## Executive Summary
This paper introduces an approximate Thompson sampling method for learning linear quadratic regulators (LQR) that achieves $O(\sqrt{T})$ regret without relying on restrictive assumptions. The method uses preconditioned Langevin dynamics for efficient posterior sampling and incorporates an excitation mechanism to drive exploration. By carefully designing the preconditioner and leveraging the self-normalization property of the system, the algorithm ensures the minimum eigenvalue of the preconditioner grows over time, enabling concentration of the approximate posterior around the true parameter.

## Method Summary
The method employs preconditioned unadjusted Langevin algorithm (ULA) for approximate Thompson sampling in LQR problems. A preconditioner accumulates state-action information to accelerate posterior sampling, while an excitation mechanism injects noise to drive exploration and ensure the preconditioner's minimum eigenvalue grows. The algorithm samples system parameters from the approximate posterior, computes optimal control gains, and uses rejection sampling to ensure stabilizing parameters. This approach avoids the need for restrictive assumptions like stabilizing parameter sets or inefficient sampling techniques used in previous methods.

## Key Results
- Achieves $O(\sqrt{T})$ regret bound for LQR learning without restrictive assumptions
- Demonstrates polynomial growth of state moments under approximate posterior concentration
- Shows preconditioner minimum eigenvalue grows over time with injected excitation noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Preconditioned Langevin MCMC accelerates posterior sampling by rescaling convergence rate with preconditioner's minimum eigenvalue
- Mechanism: Preconditioner Pt accumulates state-action outer products, rescaling posterior potential's Hessian to tighten gap between exact and approximate posteriors
- Core assumption: Posterior is log-concave and preconditioner's minimum eigenvalue grows over time
- Evidence anchors: [abstract], [section 3.1], [corpus]
- Break condition: If preconditioner's minimum eigenvalue fails to grow, convergence slows to O(1/√λmin)

### Mechanism 2
- Claim: Injected external noise at episode ends drives exploration and ensures preconditioner's minimum eigenvalue growth
- Mechanism: νt perturbation at episode end increases state-action pair diversity, accumulating in Pt and increasing λmin(Pt)
- Core assumption: Injected noise is sub-Gaussian with covariance matching system noise
- Evidence anchors: [abstract], [section 3.2], [section 4.2]
- Break condition: If noise injection fails or system noise is not log-concave, λmin(Pt) may not grow

### Mechanism 3
- Claim: Concentration bounds on approximate posterior enable tight control of system state moments
- Mechanism: Combines approximate posterior concentration with polynomial state norm growth to bound moments uniformly
- Core assumption: Prior is log-concave with Hessian λIdn
- Evidence anchors: [abstract], [section 4.1], [section 5]
- Break condition: If posterior concentration fails or state moments grow faster than polynomial

## Foundational Learning

- Concept: Linear Quadratic Regulator (LQR) theory and Riccati equations
  - Why needed here: Algorithm must compute optimal control gains K(θ) for sampled parameters
  - Quick check question: Given (A,B), (Q,R), and θ, can you derive optimal K(θ) using ARE?

- Concept: Thompson Sampling and posterior sampling in Bayesian RL
  - Why needed here: Algorithm samples system parameters from posterior to balance exploration and exploitation
  - Quick check question: How does Thompson Sampling differ from UCB in handling parameter uncertainty?

- Concept: Markov Chain Monte Carlo and Langevin dynamics
  - Why needed here: Algorithm uses preconditioned Langevin MCMC to approximate posterior sampling
  - Quick check question: What is the role of stepsize γ and iterations N in ensuring approximate posterior closeness?

## Architecture Onboarding

- Component map:
  - Preconditioner Pt accumulates state-action information to accelerate sampling
  - Langevin MCMC generates approximate posterior samples using Pt
  - Excitation noise νt injected at episode ends drives exploration
  - Control gain K(θ) computed from sampled θ for each episode
  - Regret computation aggregates costs and bounds moments of system state

- Critical path:
  1. Update posterior potential using collected data
  2. Sample θ from approximate posterior using preconditioned ULA
  3. Compute K(θ) and execute control with excitation noise
  4. Collect new data and repeat

- Design tradeoffs:
  - Preconditioner complexity vs. sampling efficiency
  - Noise injection strength vs. system stability

- Failure signatures:
  - Preconditioner λmin stagnating
  - State norm growing super-polynomially
  - Regret scaling worse than O(√T)

- First 3 experiments:
  1. Verify preconditioner growth: Plot λmin(Pt) vs. time under different noise levels
  2. Test posterior concentration: Compare sampled θ distribution to true θ as t increases
  3. Validate state moment bounds: Empirically estimate E[|xt|q] for q=2,4

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does regret bound scale when system noise distribution is not strongly log-concave but has finite moments?
- Basis in paper: [explicit] Paper assumes strongly log-concave noise but mentions extending to more general noise classes
- Why unresolved: Concentration properties may not hold for non-log-concave distributions
- What evidence would resolve it: Empirical results or theoretical analysis for specific non-log-concave noise distributions

### Open Question 2
- Question: Can preconditioned ULA be further accelerated using higher-order integrators or alternative sampling methods?
- Basis in paper: [explicit] Paper uses preconditioned ULA but mentions exploring different aspects for more general noise classes
- Why unresolved: Convergence rate depends on potential function smoothness
- What evidence would resolve it: Empirical comparison of different sampling methods and theoretical convergence rate analysis

### Open Question 3
- Question: How does regret bound change when system matrices A and B are not fully observable or controllable?
- Basis in paper: [inferred] Paper assumes standard stabilizability and observability conditions
- Why unresolved: Regret bound relies on posterior concentration properties
- What evidence would resolve it: Theoretical analysis under relaxed observability/observability or empirical impact assessment

## Limitations

- Primary uncertainty in interplay between preconditioner growth and posterior concentration
- Reliance on log-concave system noise limits practical applicability
- Limited empirical validation of λmin(Pt) growth across diverse system dynamics

## Confidence

- High confidence: O(√T) regret bound structure and role of preconditioned Langevin dynamics
- Medium confidence: Excitation mechanism's effectiveness in driving preconditioner growth
- Low confidence: Generalization to non-log-concave noise models and practical impact of rejection sampling

## Next Checks

1. **Preconditioner growth verification**: Empirically track λmin(Pt) across varying system dimensions and noise levels to confirm polynomial growth pattern

2. **Posterior concentration robustness**: Test algorithm performance when system noise deviates from strict log-concavity, quantifying regret bound degradation

3. **State moment validation**: Compare theoretical bounds on E[|xt|q] with empirical estimates across multiple runs to verify polynomial growth assumption