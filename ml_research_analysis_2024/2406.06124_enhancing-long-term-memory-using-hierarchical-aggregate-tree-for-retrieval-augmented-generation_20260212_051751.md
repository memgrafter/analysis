---
ver: rpa2
title: Enhancing Long-Term Memory using Hierarchical Aggregate Tree for Retrieval
  Augmented Generation
arxiv_id: '2406.06124'
source_url: https://arxiv.org/abs/2406.06124
tags:
- memory
- context
- node
- tree
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Hierarchical Aggregate Tree (HAT), a
  novel memory structure designed to enhance long-term dialogue coherence in large
  language models (LLMs). The key idea is to recursively aggregate relevant context
  through conditional tree traversals, balancing information breadth and depth for
  long-form conversations.
---

# Enhancing Long-Term Memory using Hierarchical Aggregate Tree for Retrieval Augmented Generation

## Quick Facts
- arXiv ID: 2406.06124
- Source URL: https://arxiv.org/abs/2406.06124
- Authors: Aadharsh Aadhithya A; Sachin Kumar S; Soman K. P
- Reference count: 1
- Key outcome: HAT achieves BLEU-1/2 scores of 0.721/0.612 and DISTINCT-1/2 scores of 0.092/0.084, outperforming BFS/DFS and partial retrieval baselines in long-form dialogue generation

## Executive Summary
This paper introduces the Hierarchical Aggregate Tree (HAT), a novel memory structure designed to enhance long-term dialogue coherence in large language models (LLMs). The key innovation is a recursive summarization approach that balances information breadth and depth for long-form conversations. Experiments demonstrate that HAT significantly improves dialogue generation quality and memory fidelity compared to baseline methods like BFS/DFS traversal and partial context retrieval.

## Method Summary
The Hierarchical Aggregate Tree (HAT) is a memory structure where each node contains a summary of its children's content, enabling selective traversal based on query relevance. A GPT-based memory agent navigates the tree by generating optimal traversal actions at each node, deciding whether to move up, down, left, right, or stop based on the current context and user query. The LLM backend generates responses using the condensed context retrieved from HAT, which is then updated with new session data.

## Key Results
- HAT achieves BLEU-1/2 scores of 0.721/0.612 and DISTINCT-1/2 scores of 0.092/0.084
- Significantly outperforms BFS/DFS traversal and partial context retrieval baselines
- Enables more consistent and grounded long-form conversations without exponential parameter growth

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HAT enables selective depth-first traversal that balances context relevance and memory efficiency.
- Mechanism: The hierarchical tree aggregates summaries from children nodes, allowing the agent to prune irrelevant branches early and focus on nodes that contain the most salient information for the current query.
- Core assumption: The GPT-based aggregation function produces meaningful summaries that preserve key dialogue elements needed for response generation.
- Evidence anchors:
  - [abstract] "HAT encapsulates information from children nodes, enabling broad coverage with depth control."
  - [section] "GPT is well-suited for conditional text generation, which allows it to traverse HAT by generating an optimal sequence of actions based on the text representation at each node and the user query."
  - [corpus] Weak evidence: Only 5 neighbor papers mention hierarchical memory structures, with limited experimental comparison to HAT's specific traversal strategy.
- Break condition: If GPT's summarization degrades, the tree loses its selective traversal advantage and collapses into a flat retrieval system.

### Mechanism 2
- Claim: Memory agent conditions traversal decisions on query relevance, improving retrieval precision.
- Mechanism: At each node, the agent evaluates whether the current context is "sufficient" for the query and decides to move up, down, left, right, or stop, using GPT to simulate a relevance-driven MDP.
- Core assumption: GPT can approximate an optimal policy for query-conditioned navigation without explicit training data.
- Evidence anchors:
  - [abstract] "We formulate finding best context as optimal tree traversal."
  - [section] "GPT is well-suited for conditional text generation, which allows it to traverse HAT by generating an optimal sequence of actions based on the text representation at each node and the user query."
  - [corpus] Weak evidence: No direct citations of MDP-based memory agents in the neighbor corpus.
- Break condition: If the query context changes dramatically mid-traversal, the agent may take suboptimal paths without re-evaluation.

### Mechanism 3
- Claim: Hierarchical aggregation retains resolution while limiting context length.
- Mechanism: By recursively summarizing child nodes into parents, HAT preserves high-resolution details near leaves while keeping ancestor nodes compact, allowing selective access to fine-grained context when needed.
- Core assumption: Aggregation function preserves enough information for later reconstruction during response generation.
- Evidence anchors:
  - [abstract] "HAT encapsulates information from children nodes, enabling broad coverage with depth control."
  - [section] "The exact implementation of A can vary depending on the usecase... For our implementation, we use GPT as aggregate function."
  - [corpus] Weak evidence: Limited discussion of information retention in hierarchical summarization structures.
- Break condition: If aggregation loses critical semantic links, the model cannot reconstruct coherent responses from partial summaries.

## Foundational Learning

- Concept: Tree traversal algorithms (BFS, DFS, and heuristic-guided search)
  - Why needed here: HAT's effectiveness depends on optimal traversal; understanding baseline strategies is critical for evaluating the GPT agent's advantage.
  - Quick check question: What is the key difference between BFS and DFS in terms of memory usage and retrieval latency?

- Concept: Retrieval-Augmented Generation (RAG) and context window limitations
  - Why needed here: HAT is designed to overcome LLM context limits; understanding RAG fundamentals clarifies why memory structures are necessary.
  - Quick check question: Why does simply increasing context length not solve the long-term dialogue coherence problem?

- Concept: Markov Decision Processes and reinforcement learning basics
  - Why needed here: The memory agent is framed as an MDP solver; knowing state, action, reward, and policy concepts is essential for implementation.
  - Quick check question: In HAT traversal, what constitutes the state and what are the possible actions?

## Architecture Onboarding

- Component map: User query -> Memory Agent -> HAT -> LLM Backend -> HAT update
- Critical path:
  1. User query â†’ Memory Agent
  2. Agent traverses HAT, generating action sequence
  3. HAT returns condensed context
  4. LLM generates response
  5. HAT updates with new session data
- Design tradeoffs:
  - Depth vs. breadth: Deeper trees preserve more resolution but increase traversal time.
  - Aggregation quality vs. speed: GPT summaries are accurate but slow; heuristics are faster but less precise.
  - Tree size vs. memory: Exponential leaf growth can exhaust memory without pruning.
- Failure signatures:
  - Slow responses: Likely due to deep tree traversal or GPT API overhead.
  - Irrelevant responses: Aggregation may be losing key context; check summarization quality.
  - Memory bloat: Leaf nodes are expanding too fast; consider capping tree depth or merging nodes.
- First 3 experiments:
  1. Compare HAT traversal time vs. BFS/DFS with fixed context budget.
  2. Ablation study: GPT vs. heuristic-based memory agent on BLEU/DISTINCT metrics.
  3. Test aggregation quality: Manually inspect parent node summaries for semantic fidelity.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is limited to synthetic benchmark metrics (BLEU, DISTINCT) without qualitative assessment of long-term dialogue coherence or user studies
- GPT-based memory agent relies on a single model (GPT-4) without ablation across different LLMs or retrieval strategies
- Hierarchical tree structure's scalability is unclear - no analysis of memory overhead or traversal time as conversation depth increases

## Confidence
- BLEU/DISTINCT performance claims: Medium - metrics show improvement over baselines but don't directly measure long-term coherence
- Hierarchical aggregation mechanism: Medium - theoretical benefits are clear but empirical validation is limited
- GPT-based memory agent effectiveness: Low-Medium - relies on LLM's inherent capabilities without ablation or alternative policy models

## Next Checks
1. Conduct qualitative evaluation with human judges assessing long-term dialogue coherence across 10+ turn conversations, comparing HAT against flat retrieval baselines
2. Perform scaling analysis measuring memory usage and response latency as conversation depth grows from 10 to 100+ turns
3. Ablation study testing different aggregation functions (heuristic vs. LLM) and memory agents (rule-based vs. GPT) to isolate the contribution of each component to overall performance