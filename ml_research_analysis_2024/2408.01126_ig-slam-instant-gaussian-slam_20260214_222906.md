---
ver: rpa2
title: 'IG-SLAM: Instant Gaussian SLAM'
arxiv_id: '2408.01126'
source_url: https://arxiv.org/abs/2408.01126
tags:
- depth
- slam
- dense
- mapping
- gaussian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IG-SLAM is a dense RGB-only SLAM system that combines robust Dense-SLAM
  methods for tracking with 3D Gaussian Splatting for real-time, photo-realistic 3D
  reconstruction. It addresses the limitations of existing methods by utilizing dense
  depth maps and depth uncertainty to improve mapping accuracy and convergence.
---

# IG-SLAM: Instant Gaussian SLAM

## Quick Facts
- **arXiv ID**: 2408.01126
- **Source URL**: https://arxiv.org/abs/2408.01126
- **Reference count**: 40
- **Primary result**: Real-time RGB-only SLAM system achieving 10 fps with competitive photo-realistic 3D reconstruction quality

## Executive Summary
IG-SLAM is a dense RGB-only SLAM system that combines robust Dense-SLAM methods for tracking with 3D Gaussian Splatting for real-time, photo-realistic 3D reconstruction. It addresses limitations of existing methods by utilizing dense depth maps and depth uncertainty from tracking to improve mapping accuracy and convergence. The system achieves 10 fps in a single process while demonstrating competitive performance with state-of-the-art RGB-only SLAM systems on Replica, TUM-RGBD, ScanNet, and EuRoC datasets.

## Method Summary
IG-SLAM integrates DROID-SLAM for tracking with 3D Gaussian Splatting for mapping. The tracking module generates camera poses, dense depth maps, and depth uncertainty estimates for keyframes through dense bundle adjustment. The mapping module initializes Gaussians from low-covariance depth regions and optimizes them using a combined depth and color loss weighted by inverse depth covariance. A coarse-to-fine training strategy on image pyramids and exponentially decaying learning rates enable faster convergence and higher quality reconstruction while maintaining real-time performance.

## Key Results
- Achieves PSNR of 36.21, SSIM of 0.96, and LPIPS of 0.05 on Replica dataset
- Achieves PSNR of 22.44, SSIM of 0.80, and LPIPS of 0.23 on EuRoC dataset
- Maintains 10 fps frame rate in a single process
- Demonstrates competitive performance with state-of-the-art RGB-only SLAM systems

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Dense depth maps from robust tracking provide accurate geometry supervision, improving 3D reconstruction quality.
- **Mechanism**: IG-SLAM uses DROID-SLAM to generate dense depth maps and depth uncertainty for each keyframe. These depth maps are used to supervise the mapping process by initializing Gaussians from low-covariance regions and weighting the depth loss by inverse covariance.
- **Core assumption**: Dense depth maps from DROID-SLAM are sufficiently accurate and depth uncertainty estimates are reliable indicators of depth error.
- **Evidence anchors**: [abstract], [section 3.1]
- **Break condition**: If DROID-SLAM's depth estimates are too noisy or biased, initialization and depth loss weighting will be ineffective.

### Mechanism 2
- **Claim**: Learning rate decay during training prevents Gaussians from switching positions, leading to faster convergence and higher quality reconstruction.
- **Mechanism**: IG-SLAM uses exponentially decaying learning rate for Gaussian position updates to prevent large position updates that cause Gaussians to bounce around correct positions.
- **Core assumption**: Gaussians initialized from dense depth maps are initially close to final positions, so large position updates are counterproductive.
- **Evidence anchors**: [section 3.3]
- **Break condition**: If initial Gaussian positions are too far from correct, decaying learning rate may prevent reaching optimal positions.

### Mechanism 3
- **Claim**: Coarse-to-fine training on an image pyramid improves reconstruction quality while maintaining real-time performance.
- **Mechanism**: IG-SLAM constructs image pyramid for each keyframe and optimizes Gaussians in coarse-to-fine manner, capturing large-scale structure at low resolution before refining details at higher resolution.
- **Core assumption**: Large-scale structure can be captured effectively at low resolution, and refining at higher resolution adds meaningful detail without artifacts.
- **Evidence anchors**: [section 3.2]
- **Break condition**: If image pyramid construction is poor or transitions between levels are not smooth, reconstruction quality may suffer.

## Foundational Learning

- **Concept**: Dense bundle adjustment
  - **Why needed here**: IG-SLAM uses dense bundle adjustment in tracking module to optimize camera poses and dense depth maps.
  - **Quick check question**: What is the main difference between dense bundle adjustment and traditional sparse bundle adjustment?

- **Concept**: Gaussian Splatting
  - **Why needed here**: IG-SLAM uses Gaussian Splatting as scene representation for 3D map construction.
  - **Quick check question**: How does Gaussian Splatting represent a 3D scene?

- **Concept**: Depth uncertainty
  - **Why needed here**: IG-SLAM uses depth uncertainty from tracking to initialize Gaussians and weight depth loss.
  - **Quick check question**: How is depth uncertainty typically estimated in dense SLAM systems?

## Architecture Onboarding

- **Component map**: Tracking (DROID-SLAM) -> Mapping (Gaussian Splatting) -> Post-processing
- **Critical path**: Tracking -> Mapping -> Post-processing
- **Design tradeoffs**: Using dense depth maps for supervision vs. color information only; using depth uncertainty as mask/loss weight vs. ignoring; coarse-to-fine training vs. single resolution training.
- **Failure signatures**: Poor geometry reconstruction (noisy depth maps); slow convergence (poor learning rate scheduling/initialization); low visual quality (insufficient training iterations/poor post-processing).
- **First 3 experiments**:
  1. Run IG-SLAM on simple indoor scene and visualize dense depth maps from tracking. Check depth map accuracy and uncertainty estimates.
  2. Run IG-SLAM with different learning rate schedules and compare convergence speed and reconstruction quality.
  3. Run IG-SLAM with and without post-processing and compare visual quality of results.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the choice of depth uncertainty weighting affect reconstruction quality in scenes with varying noise levels?
- **Basis in paper**: [explicit] The paper discusses using depth uncertainty as a mask for Gaussian initialization and as weights for depth loss.
- **Why unresolved**: The paper does not provide experiments or analysis on how different uncertainty weighting strategies impact reconstruction in varying noise conditions.
- **What evidence would resolve it**: Experiments with different depth uncertainty weighting strategies across scenes with known noise characteristics and comparing resulting reconstruction quality.

### Open Question 2
- **Question**: What is the impact of the sliding window size on both real-time performance and reconstruction accuracy?
- **Basis in paper**: [inferred] The paper mentions maintaining a sliding window of keyframes to meet real-time requirements, but does not explore how different window sizes affect performance.
- **Why unresolved**: The paper does not provide ablation studies or analysis on trade-offs between sliding window size, computational efficiency, and reconstruction quality.
- **What evidence would resolve it**: Experiments with varying sliding window sizes measuring both frame rate and reconstruction metrics like PSNR, SSIM, and LPIPS.

### Open Question 3
- **Question**: How does the proposed decay strategy in the learning rate compare to other optimization techniques in terms of convergence speed and final reconstruction quality?
- **Basis in paper**: [explicit] The paper introduces a learning rate decay strategy to reduce TV-static noise during training and improve convergence.
- **Why unresolved**: The paper does not compare the proposed decay strategy to other optimization techniques like adaptive learning rates or momentum-based methods.
- **What evidence would resolve it**: Implementing and comparing the proposed decay strategy with other optimization techniques in terms of convergence speed and final reconstruction quality metrics.

## Limitations
- Heavy reliance on DROID-SLAM's depth accuracy and uncertainty estimates
- Lack of detailed ablation studies on coarse-to-fine training contribution
- Post-processing step frequency and impact not thoroughly analyzed

## Confidence

**High Confidence**: General framework combining dense tracking with Gaussian splatting is sound and well-documented. Quantitative results on standard datasets are reproducible.

**Medium Confidence**: Specific mechanisms for depth uncertainty utilization and learning rate scheduling are plausible but lack extensive validation through ablation studies. "Real-time" performance claim at 10 fps is reasonable given computational budget.

**Low Confidence**: Precise implementation details for Gaussian initialization from depth uncertainty masks and exact post-processing algorithm are underspecified, making exact replication challenging.

## Next Checks

1. **Depth Uncertainty Validation**: Run IG-SLAM on dataset with ground truth depth and analyze correlation between predicted depth uncertainty and actual depth error to validate core assumption about uncertainty as reliable indicator.

2. **Ablation on Learning Rate Scheduling**: Implement variants with constant learning rates, different decay schedules, and no decay. Compare convergence speed and final reconstruction quality to quantify impact of decaying learning rate mechanism.

3. **Post-processing Impact Analysis**: Run experiments with different post-processing frequencies (0, 100, 500, 1000 iterations) and measure trade-off between reconstruction quality improvement and computational overhead to clarify optimal schedule.