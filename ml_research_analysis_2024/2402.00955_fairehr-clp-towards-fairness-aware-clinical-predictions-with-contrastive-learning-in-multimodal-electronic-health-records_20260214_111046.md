---
ver: rpa2
title: 'FairEHR-CLP: Towards Fairness-Aware Clinical Predictions with Contrastive
  Learning in Multimodal Electronic Health Records'
arxiv_id: '2402.00955'
source_url: https://arxiv.org/abs/2402.00955
tags:
- data
- learning
- fairness
- synthetic
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces FairEHR-CLP, a framework for fairness-aware
  clinical predictions using multimodal EHR data. The approach employs a two-stage
  process: first, synthetic patient counterparts are generated with varied demographics
  while preserving health information; second, fairness-aware predictions are made
  using contrastive learning to align representations across sensitive attributes.'
---

# FairEHR-CLP: Towards Fairness-Aware Clinical Predictions with Contrastive Learning in Multimodal Electronic Health Records

## Quick Facts
- arXiv ID: 2402.00955
- Source URL: https://arxiv.org/abs/2402.00955
- Reference count: 24
- Primary result: FairEHR-CLP framework demonstrates superior fairness (lower EO and EDDI scores) and competitive predictive performance compared to baselines across three large EHR datasets and clinical tasks.

## Executive Summary
This paper introduces FairEHR-CLP, a framework for fairness-aware clinical predictions using multimodal EHR data. The approach employs a two-stage process: first, synthetic patient counterparts are generated with varied demographics while preserving health information; second, fairness-aware predictions are made using contrastive learning to align representations across sensitive attributes. The method leverages demographics, longitudinal data, and clinical notes to address social biases in healthcare predictions. Experiments on three large EHR datasets (STARR, MIMIC-III, MIMIC-IV) across three tasks (delirium, opioid use disorder, 30-day readmission) demonstrate superior fairness (lower EO and EDDI scores) and competitive predictive performance compared to baselines.

## Method Summary
FairEHR-CLP uses a two-stage framework: synthetic counterpart generation followed by fairness-aware contrastive learning. Synthetic counterparts are created using EHR-GAN for longitudinal data and Llama2-70b-chat for clinical notes, preserving health information while varying demographics. The fairness-aware predictions stage employs contrastive learning to align representations across sensitive attributes, using a Dynamic Relevance layer to modulate feature importance and an MLP-based fusion layer to combine multimodal representations. The model is trained with joint contrastive and cross-entropy loss and evaluated using novel EDDI and EO metrics.

## Key Results
- FairEHR-CLP achieved significantly lower Equalized Odds (EO) scores across all datasets and tasks, with maximum reductions of 37.5% on MIMIC-III delirium task
- The framework demonstrated competitive predictive performance, with F1 scores ranging from 0.589 to 0.779 and AUROC scores from 0.643 to 0.874 across datasets and tasks
- EDDI metric effectively captured subgroup-specific error rate disparities, showing lower values for FairEHR-CLP compared to baselines in imbalanced clinical settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning aligns patient representations across sensitive attributes by using synthetic counterparts that preserve health information while varying demographics.
- Mechanism: The framework generates synthetic patient counterparts with varied demographics but similar health conditions, then uses contrastive learning to minimize the representation distance between real patients and their synthetic counterparts. This encourages the model to focus on health similarities rather than demographic differences.
- Core assumption: Synthetic data generation preserves essential health information while successfully varying demographic attributes without introducing artifacts.
- Evidence anchors:
  - [abstract]: "First, synthetic counterparts are generated for each patient, allowing for diverse demographic identities while preserving essential health information."
  - [section 3.2]: Details the synthetic counterpart generation process using EHR-GAN for longitudinal data and Llama2-70b for clinical notes.
  - [corpus]: Weak evidence - no direct mention of contrastive learning with synthetic counterparts in corpus papers.

### Mechanism 2
- Claim: Dynamic Relevance (DR) layer modulates feature importance during representation learning to address bias across different data types.
- Mechanism: The DR layer uses a gating mechanism (σ(w) ⊙ e) that adjusts the influence of each feature in the final representation based on learnable weights. This allows the model to dynamically emphasize or de-emphasize features that may contribute to bias.
- Core assumption: The model can learn which features contribute to bias and appropriately modulate their importance during training.
- Evidence anchors:
  - [section 3.3]: "To dynamically address potential biases across different data types, we introduce a Dynamic Relevance (DR) layer, defined as FDR(e) = σ(w) ⊙ e"
  - [abstract]: Mentions DR layer in the context of "dynamically address potential biases"
  - [corpus]: Weak evidence - no direct mention of Dynamic Relevance layer in corpus papers.

### Mechanism 3
- Claim: The novel Error Distribution Disparity Index (EDDI) metric effectively captures subgroup-specific error rate disparities in imbalanced clinical datasets.
- Mechanism: EDDI measures the deviation in error rates for each subgroup from the overall error rate, normalized by the maximum of overall error rate and its complement. This provides a more nuanced fairness assessment than traditional metrics in settings with varying group sizes and class imbalance.
- Core assumption: Traditional fairness metrics like EO are insufficient for clinical settings with highly imbalanced outcome labels and varying patient group sizes.
- Evidence anchors:
  - [section 4.3]: "To overcome this, we introduce the Error Distribution Disparity Index (EDDI), a new fairness metric designed to address the complexities of clinical settings, especially those with significant data variability and diverse group sizes."
  - [abstract]: Introduces EDDI as a novel fairness metric for EHRs.
  - [corpus]: Weak evidence - no direct mention of EDDI metric in corpus papers.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: Enables the model to learn representations that focus on health similarities across different demographic groups rather than demographic differences.
  - Quick check question: How does the NT-Xent loss formulation in FairEHR-CLP encourage fair representations?

- Concept: Synthetic data generation
  - Why needed here: Creates diverse demographic representations while preserving health information, enabling contrastive learning across sensitive attributes.
  - Quick check question: What are the key components of the EHR-GAN architecture used for generating synthetic longitudinal data?

- Concept: Multimodal representation fusion
  - Why needed here: Combines demographics, longitudinal data, and clinical notes into unified representations that capture inter-modal dependencies and interactions.
  - Quick check question: How does the MLP-based fusion layer combine the three modality-specific representations?

## Architecture Onboarding

- Component map: Synthetic Counterpart Generation (EHR-GAN for longitudinal data, Llama2-70b-chat for clinical notes) -> Multimodal Encoding (demographics, longitudinal data, clinical notes) -> Dynamic Relevance Layer (feature modulation) -> MLP Fusion -> Classifier (softmax output)

- Critical path: 1) Generate synthetic counterparts preserving health info while varying demographics, 2) Encode all modalities, 3) Apply DR layer to adjust feature importance, 4) Train with joint contrastive and cross-entropy loss, 5) Evaluate using EDDI and EO metrics.

- Design tradeoffs: Using synthetic data enables contrastive learning across demographics but introduces potential quality concerns; multimodal fusion improves representation but increases complexity; EDDI provides better fairness assessment but requires careful interpretation in imbalanced settings.

- Failure signatures: 1) High EDDI/EO despite training indicates synthetic data quality issues or insufficient contrastive learning, 2) Poor F1/AUROC suggests modality encoding or fusion problems, 3) Model overfits to synthetic data if feature matching loss is insufficient.

- First 3 experiments:
  1. Train with only real data (no synthetic counterparts) to establish baseline performance and fairness.
  2. Train with synthetic counterparts but without contrastive learning to assess data augmentation benefits.
  3. Train with contrastive learning but without DR layer to evaluate the impact of dynamic feature modulation.

## Open Questions the Paper Calls Out

- How do different synthetic data generation techniques for longitudinal EHR data affect the quality of learned representations and subsequent fairness outcomes?
- How does the proposed Error Distribution Disparity Index (EDDI) correlate with clinical outcomes and real-world healthcare disparities?
- How does the FairEHR-CLP framework perform when extended to non-surgical patient populations and other clinical domains?

## Limitations

- The framework's reliance on synthetic data generation introduces uncertainty regarding data quality preservation and potential artifacts in learned representations.
- The specific implementation details of EHR-GAN and the Dynamic Relevance layer lack comprehensive validation and justification for their effectiveness in clinical settings.
- The novel EDDI metric, while theoretically motivated, lacks independent validation against established fairness benchmarks in clinical settings with highly imbalanced data.

## Confidence

- **High Confidence**: The overall two-stage framework design (synthetic data generation followed by contrastive learning) is well-grounded in existing literature on fairness-aware machine learning and multimodal representation learning.
- **Medium Confidence**: The specific implementation details, particularly the EHR-GAN architecture and the Dynamic Relevance layer, are reasonable but not fully validated.
- **Low Confidence**: The novel EDDI metric's effectiveness in clinical settings with highly imbalanced data remains to be independently verified.

## Next Checks

1. **Synthetic Data Quality Assessment**: Conduct a comprehensive evaluation of synthetic data quality by comparing real and synthetic distributions across all modalities (demographics, longitudinal data, clinical notes) using multiple statistical tests beyond MMD. Verify that synthetic data preserves clinical correlations and temporal patterns.

2. **DR Layer Ablation Study**: Perform an ablation study systematically removing the Dynamic Relevance layer to quantify its specific contribution to fairness improvements. Compare feature importance learned by the DR layer with known bias sources in the datasets to validate its effectiveness.

3. **EDDI Metric Validation**: Compare EDDI metric results with established fairness metrics (EO, demographic parity) across multiple clinical prediction tasks and datasets. Analyze whether EDDI captures fairness issues that traditional metrics miss and validate its sensitivity to different types of bias in imbalanced settings.