---
ver: rpa2
title: Defending Against Social Engineering Attacks in the Age of LLMs
arxiv_id: '2406.12263'
source_url: https://arxiv.org/abs/2406.12263
tags:
- llms
- conversation
- malicious
- detection
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines Large Language Models' (LLMs) dual role as
  facilitators and defenders against chat-based social engineering (CSE) attacks.
  The researchers developed SEConvo, a dataset of 1,400 LLM-generated conversations
  simulating CSE scenarios in academic and recruitment contexts, with 400 conversations
  human-annotated for quality validation (macro F1=0.91).
---

# Defending Against Social Engineering Attacks in the Age of LLMs

## Quick Facts
- arXiv ID: 2406.12263
- Source URL: https://arxiv.org/abs/2406.12263
- Reference count: 24
- LLMs can generate high-quality CSE content but show suboptimal detection capabilities

## Executive Summary
This study explores the dual role of Large Language Models (LLMs) as both facilitators and defenders against chat-based social engineering (CSE) attacks. The researchers developed SEConvo, a dataset of 1,400 LLM-generated CSE conversations, and proposed ConvoSentinel, a modular defense pipeline that improves detection through retrieval-augmented generation. While LLMs can produce realistic CSE content with high accuracy, their naive detection capabilities are limited. ConvoSentinel addresses these limitations by analyzing conversations at multiple levels and achieving 0.80 overall F1 with GPT-4-Turbo, outperforming baselines by 2.5% while using 61.5% fewer tokens.

## Method Summary
The researchers developed SEConvo, a dataset of 1,400 LLM-generated conversations simulating CSE scenarios in academic and recruitment contexts. They created an automated pipeline to generate these conversations, which were then human-annotated for quality validation (achieving macro F1=0.91). To address the detection limitations of naive LLMs, they proposed ConvoSentinel, a modular defense pipeline that combines message-level sensitive information detection, retrieval-augmented generation for snippet analysis, and conversation-level aggregation. The system was evaluated against GPT-4-Turbo and Llama2-7B baselines using few-shot and zero-shot prompting strategies.

## Key Results
- SEConvo dataset demonstrates LLMs can generate high-quality CSE content with macro F1=0.91 accuracy
- Naive LLMs show poor defense capabilities (only 8.8% successful defense in non-ambiguous cases)
- ConvoSentinel achieves 0.80 overall F1 with GPT-4-Turbo, outperforming baselines by 2.5% while using 61.5% fewer tokens
- Early message-level analysis enables detection with just 5 messages, achieving 7.2% better malicious F1 than GPT-4-Turbo

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can be exploited to generate high-quality CSE content despite limited detection capabilities
- Mechanism: The SEConvo dataset demonstrates that GPT-4 can produce realistic CSE conversations with high accuracy (macro F1=0.91) when instructed with appropriate prompts, while naive detection shows low success rates (8.8% defense in non-ambiguous cases)
- Core assumption: LLMs can be effectively prompted to simulate both malicious and benign actors in social engineering scenarios
- Evidence anchors:
  - [abstract] "Our findings reveal that, while off-the-shelf LLMs generate high-quality CSE content, their detection capabilities are suboptimal"
  - [section 2.1.2] "The macro F1 score is 0.91, showing high accuracy in our generated conversations"
  - [corpus] Moderate evidence - the SEConvo dataset provides direct empirical support
- Break condition: If the prompting strategy fails to elicit realistic malicious behavior or if human annotators cannot reliably distinguish generated content

### Mechanism 2
- Claim: Retrieval-augmented generation improves CSE detection at both message and conversation levels
- Mechanism: ConvoSentinel uses RAG to compare incoming messages against a database of known CSE interactions, achieving 0.80 overall F1 with GPT-4-Turbo while using 61.5% fewer tokens than few-shot approaches
- Core assumption: Similar conversation snippets can effectively inform the intent of new messages through nearest-neighbor search
- Evidence anchors:
  - [abstract] "The retrieval-augmented module in ConvoSentinel identifies malicious intent by comparing messages to a database of similar conversations"
  - [section 4.2] "The top similar snippets are used as additional examples via few-shot prompting, aiding the model in determining the flagged messages' intent"
  - [corpus] Moderate evidence - performance improvements are demonstrated through ablation studies
- Break condition: If the historical database lacks sufficient diversity or if nearest-neighbor search fails to retrieve relevant examples

### Mechanism 3
- Claim: Fine-grained message-level analysis enhances early-stage CSE detection
- Mechanism: By analyzing SI requests at the message level and aggregating results, ConvoSentinel achieves 7.2% better malicious F1 than GPT-4-Turbo with only 5 messages seen
- Core assumption: Early indicators of CSE can be detected through systematic message-level examination before conversation context is fully established
- Evidence anchors:
  - [section 5.1] "ConvoSentinel achieves overall and malicious F1 scores of 0.74 with just 5 messages, outperforming GPT-4-Turbo by 7.5% and Llama2-7B by 10.4% in overall F1"
  - [section 4.1] "ConvoSentinel begins with a message-level SI detector... Messages flagged for SI requests are then assessed for malicious intent"
  - [corpus] Strong evidence - quantitative comparisons demonstrate consistent early detection advantages
- Break condition: If message-level features prove insufficient to distinguish malicious from benign intent without conversation context

## Foundational Learning

- Concept: Social engineering attack phases and information targeting
  - Why needed here: Understanding how attackers progress through conversations and what information they target is essential for building effective detection systems
  - Quick check question: What are the three categories of sensitive information targeted in CSE attacks according to the paper?

- Concept: Zero-shot vs few-shot prompting effectiveness
  - Why needed here: The paper demonstrates significant performance differences between prompting strategies, with few-shot approaches showing better results but higher costs
  - Quick check question: What is the macro F1 score of GPT-4-Turbo in 2-shot settings compared to zero-shot?

- Concept: Retrieval-augmented generation fundamentals
  - Why needed here: ConvoSentinel's core innovation relies on RAG techniques to enhance detection by retrieving similar conversation snippets
  - Quick check question: How does ConvoSentinel use retrieved snippets to improve malicious intent classification?

## Architecture Onboarding

- Component map: SEConvo dataset generation → Message-level SI detector → Snippet-level SE detector (RAG-integrated) → Conversation-level SE detector → Explanation generator
- Critical path: Message analysis → Snippet retrieval and classification → Conversation aggregation → Final prediction
- Design tradeoffs: The modular design allows component swapping but requires careful coordination between message, snippet, and conversation levels
- Failure signatures: Poor performance on early messages suggests message-level detector issues; low overall F1 indicates conversation-level aggregation problems
- First 3 experiments:
  1. Evaluate baseline LLM detection (zero-shot and few-shot) on SEConvo test set
  2. Test message-level SI detector performance on annotated subset
  3. Compare RAG-integrated snippet detection against standard few-shot baselines

## Open Questions the Paper Calls Out
None

## Limitations

- Dataset Scope and Generalizability: SEConvo covers only academic and recruitment domains with 1,400 conversations, potentially limiting real-world effectiveness against novel attack patterns
- Performance Trade-offs: ConvoSentinel's improved detection (0.80 F1) comes with computational costs despite using 61.5% fewer tokens than few-shot approaches
- Model Dependency: The system's effectiveness heavily depends on the underlying LLM's capabilities, with naive LLMs showing poor detection rates (8.8% defense in non-ambiguous cases)

## Confidence

- High Confidence: The fundamental observation that LLMs can generate high-quality CSE content while struggling to detect it is well-supported by the SEConvo dataset and empirical results
- Medium Confidence: The effectiveness of ConvoSentinel's modular approach and RAG integration is demonstrated through controlled experiments, but real-world performance may vary
- Low Confidence: The long-term effectiveness against evolving social engineering tactics remains uncertain as attackers may adapt strategies to circumvent detection

## Next Checks

1. Evaluate ConvoSentinel on CSE conversations from domains not represented in SEConvo (e.g., financial services, technical support) to assess generalizability across different social engineering contexts

2. Test the system against live chat data from actual social engineering attempts, comparing performance against the controlled SEConvo environment to identify potential gaps in detection capability

3. Conduct experiments where attackers deliberately modify their strategies to evade ConvoSentinel's detection patterns, measuring how quickly and effectively the system can adapt to new attack vectors