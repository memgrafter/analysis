---
ver: rpa2
title: A multi-criteria approach for selecting an explanation from the set of counterfactuals
  produced by an ensemble of explainers
arxiv_id: '2403.13940'
source_url: https://arxiv.org/abs/2403.13940
tags:
- counterfactual
- counterfactuals
- explanations
- methods
- criteria
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of selecting a single, high-quality
  counterfactual explanation from a diverse set generated by multiple explanation
  methods, as choosing the best method and explanation is difficult for users. The
  proposed solution is a multi-stage ensemble approach that uses dominance relation
  and the Ideal Point method to select a single counterfactual from the Pareto front
  of non-dominated explanations, ensuring a compromise across multiple quality measures.
---

# A multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers

## Quick Facts
- arXiv ID: 2403.13940
- Source URL: https://arxiv.org/abs/2403.13940
- Authors: Ignacy StÄ™pka; Mateusz Lango; Jerzy Stefanowski
- Reference count: 9
- Primary result: Multi-stage ensemble approach consistently achieves best compromise across seven quality measures for counterfactual explanations

## Executive Summary
This paper addresses the challenge of selecting a single, high-quality counterfactual explanation from the diverse set generated by multiple explanation methods. The proposed solution is a multi-stage ensemble approach that uses dominance relation filtering followed by the Ideal Point method to select a counterfactual from the Pareto front of non-dominated explanations. Experiments on four datasets (Adult, German, Compas, Fico) demonstrate that this approach consistently achieves the best compromise across seven quality measures, outperforming both random selection and individual methods.

## Method Summary
The approach consists of three main stages: first, an ensemble of multiple counterfactual generation methods produces a diverse set of candidate explanations, each establishing different trade-offs between quality measures. Second, the dominance relation filters out dominated counterfactuals by comparing each explanation's scores across all criteria with every other explanation, removing those that are worse or equal on all criteria while strictly worse on at least one. Finally, the Ideal Point method selects the best compromise by constructing an ideal point in the criteria space and choosing the counterfactual closest to this ideal point. This multi-stage process ensures selection of a counterfactual that performs well across multiple quality dimensions while being computationally efficient.

## Key Results
- The approach consistently achieves the best compromise across seven quality measures (proximity, feasibility, discriminative power, sparsity, instability, actionability, coverage)
- Ranks first in average rank for all four datasets tested (Adult, German, Compas, Fico)
- Generates fully actionable and valid counterfactuals, outperforming random selection and single-method approaches
- Successfully reduces the candidate set through dominance filtering while maintaining quality across all criteria

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dominance relation effectively filters out dominated counterfactuals without losing quality on any considered criterion.
- Mechanism: For each counterfactual, compare its scores across all criteria with every other counterfactual. If another counterfactual is better or equal on all criteria and strictly better on at least one, mark the first as dominated and remove it.
- Core assumption: The criteria form a coherent family of diverse views on the problem, and the dominance relation is applicable to them.
- Evidence anchors:
  - [abstract]: "The approach exploits the dominance relation and the ideal point decision aid method, which selects one counterfactual from the Pareto front."
  - [section]: "We employ the dominance relation to reduce the set of remaining explanations without loss of quality on any considered criterion."
- Break condition: If criteria are not coherent or the dominance relation is not applicable, the filtering may not work as intended.

### Mechanism 2
- Claim: The Ideal Point method selects a counterfactual that represents a good compromise across all criteria.
- Mechanism: Construct an ideal point in the criteria space by selecting the best possible value for every criterion. Then, for each counterfactual, compute its distance to the ideal point and select the closest one.
- Core assumption: The user's preferences are equally important across all criteria, and the Ideal Point method is suitable for this scenario.
- Evidence anchors:
  - [abstract]: "It offers a compromise solution that scores well on several popular quality measures."
  - [section]: "We propose to use the Ideal Point Method, which is a simple and compute-efficient approach recommended in the literature for the case of equally important criteria."
- Break condition: If user preferences are not equally important across criteria or the Ideal Point method is not suitable, the selection may not represent the best compromise.

### Mechanism 3
- Claim: The ensemble of explainers provides a diverse set of counterfactuals, each establishing a certain trade-off between values of different quality measures.
- Mechanism: Run multiple counterfactual generation methods, each with different optimization strategies and quality measure priorities, to generate a diverse set of counterfactuals.
- Core assumption: Different methods optimize different, sometimes conflicting, quality measures and produce quite different solutions.
- Evidence anchors:
  - [abstract]: "They can be generated by a variety of methods that optimize different, sometimes conflicting, quality measures and produce quite different solutions."
  - [section]: "Inspired by the research on classifier ensembles, which achieve better classification performance by exploiting the predictions from a diversified set of base classifiers, we propose to use an ensemble of multiple base explainers to provide a richer set of counterfactuals, each of which establishes a certain trade-off between values of different quality measures."
- Break condition: If the methods in the ensemble are not diverse enough or do not produce different solutions, the ensemble may not provide a rich set of counterfactuals.

## Foundational Learning

- Concept: Multi-criteria decision analysis (MCDA)
  - Why needed here: To select a counterfactual that represents a good compromise across multiple quality measures.
  - Quick check question: What is the purpose of using the dominance relation in MCDA?

- Concept: Pareto front
  - Why needed here: To reduce the set of candidate counterfactuals to only non-dominated explanations.
  - Quick check question: How is the Pareto front constructed in the context of counterfactual explanations?

- Concept: Ideal Point method
  - Why needed here: To select a counterfactual that represents the best compromise across all criteria.
  - Quick check question: What is the role of the ideal point in the Ideal Point method?

## Architecture Onboarding

- Component map: Ensemble of explainers -> Dominance relation filter -> Ideal Point method
- Critical path:
  1. Generate counterfactuals using the ensemble of explainers.
  2. Apply the dominance relation to filter out dominated counterfactuals.
  3. Use the Ideal Point method to select the final counterfactual.
- Design tradeoffs:
  - Using multiple explainers increases diversity but also computational cost.
  - The Ideal Point method is simple but may not capture complex user preferences.
- Failure signatures:
  - If the ensemble does not generate diverse counterfactuals, the final selection may be suboptimal.
  - If the dominance relation is not applicable to the criteria, the filtering step may not work as intended.
- First 3 experiments:
  1. Generate counterfactuals using the ensemble of explainers and evaluate their diversity.
  2. Apply the dominance relation to filter out dominated counterfactuals and assess the reduction in set size.
  3. Use the Ideal Point method to select the final counterfactual and evaluate its quality across all criteria.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different multi-criteria selection methods compare in selecting counterfactual explanations, beyond the simple Ideal Point method used in this study?
- Basis in paper: [inferred] The paper briefly mentions considering more advanced selection methods like distance to the nadir-ideal plane in preliminary experiments, suggesting potential for further exploration.
- Why unresolved: The paper only scratches the surface of potential multi-criteria selection methods, leaving open the question of how more sophisticated approaches might perform.
- What evidence would resolve it: Systematic comparison of various multi-criteria selection methods (e.g., TOPSIS, VIKOR, ELECTRE) applied to counterfactual explanation selection, evaluating their performance across different datasets and user preference models.

### Open Question 2
- Question: How well do humans actually trade-off between different quality criteria when selecting counterfactual explanations, and does the proposed multi-criteria approach align with human preferences?
- Basis in paper: [explicit] The authors suggest that future research should focus on whether humans make trade-offs between criteria when selecting explanations and whether they prefer only one of them.
- Why unresolved: The paper relies on a mathematical model of user preferences to evaluate the utility of counterfactuals, but doesn't empirically test how humans actually make these trade-offs in practice.
- What evidence would resolve it: User studies where participants are asked to select counterfactual explanations from a set of options, with their choices analyzed to understand how they weigh different quality criteria.

### Open Question 3
- Question: Can the proposed ensemble approach be extended to handle sequential decision-making scenarios where counterfactual explanations are needed at multiple stages?
- Basis in paper: [inferred] The paper focuses on generating counterfactual explanations for a single instance and prediction, but doesn't explore how the approach might be adapted for more complex, sequential decision-making processes.
- Why unresolved: The current framework is designed for a single counterfactual generation task, and it's unclear how it would perform in scenarios requiring multiple, potentially interdependent counterfactual explanations.
- What evidence would resolve it: Development and evaluation of an extension of the ensemble approach that can generate a sequence of counterfactual explanations, each building upon the previous ones, and testing its performance in simulated or real-world sequential decision-making scenarios.

## Limitations

- Computational complexity - The approach requires running multiple counterfactual generation methods and evaluating multiple quality measures for each explanation, suggesting non-trivial computational overhead.
- Dataset bias - Experimental evaluation is limited to four specific tabular datasets (Adult, German, Compas, Fico), with performance on other data types remaining untested.
- User preference assumptions - The Ideal Point method assumes equal importance across all quality criteria, which may not reflect real-world user preferences where certain criteria might be prioritized differently.

## Confidence

- **High confidence**: The core mechanism of using dominance relation to filter dominated counterfactuals is theoretically sound and directly follows established MCDA principles. The experimental evidence showing consistent first-place ranking across all four datasets provides strong empirical support.

- **Medium confidence**: The Ideal Point method's effectiveness as a compromise selection mechanism is supported by literature recommendations, but the specific application to counterfactual explanations requires validation across more diverse scenarios and user preference configurations.

- **Medium confidence**: The claim that the ensemble approach consistently produces better compromises than individual methods is well-supported by the experimental results, though the relative performance gains across different quality measures could be more systematically analyzed.

## Next Checks

1. **Computational efficiency analysis**: Measure and compare the runtime of the multi-stage ensemble approach against single explainer methods across varying dataset sizes to quantify the computational overhead and identify scalability thresholds.

2. **User preference sensitivity test**: Implement a configurable weighted version of the Ideal Point method where users can specify relative importance weights for different quality criteria, then evaluate how performance changes under different preference configurations.

3. **Cross-domain generalization study**: Apply the approach to non-tabular datasets (e.g., image classification using counterfactual explanations for vision models) and evaluate whether the same quality measure definitions and selection mechanism remain appropriate and effective.