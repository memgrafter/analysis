---
ver: rpa2
title: Adaptive Global-Local Representation Learning and Selection for Cross-Domain
  Facial Expression Recognition
arxiv_id: '2401.11085'
source_url: https://arxiv.org/abs/2401.11085
tags:
- domain
- learning
- recognition
- pseudo
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses cross-domain facial expression recognition
  (CD-FER), where domain shift poses a significant challenge due to distribution variation
  across different domains. To address this, the authors propose an Adaptive Global-Local
  Representation Learning and Selection (AGLRLS) framework that incorporates global-local
  adversarial adaptation and semantic-aware pseudo label generation to enhance the
  learning of domain-invariant and discriminative feature representation during training.
---

# Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition

## Quick Facts
- arXiv ID: 2401.11085
- Source URL: https://arxiv.org/abs/2401.11085
- Reference count: 40
- Primary result: State-of-the-art CD-FER performance with 87.60% accuracy on CK+ dataset

## Executive Summary
This paper addresses the challenge of cross-domain facial expression recognition (CD-FER) where domain shift between source and target datasets significantly impacts model performance. The authors propose an Adaptive Global-Local Representation Learning and Selection (AGLRLS) framework that learns domain-invariant features through separate global and local adversarial adaptation modules. The framework incorporates semantic-aware pseudo label generation with dynamic thresholds and a global-local prediction consistency learning module for improved inference. Extensive experiments demonstrate state-of-the-art performance across multiple benchmark datasets, achieving substantial improvements over existing methods.

## Method Summary
The AGLRLS framework employs a two-stage training process with ResNet50 or MobileNet-v2 backbone networks. First, it extracts both global facial features and local features from five key facial landmarks (eyes, nose, mouth corners). Second, it applies separate adversarial learning modules to make both feature types domain-invariant. The method then generates pseudo labels for target domain data using a dynamic threshold strategy that considers classifier confidence and historical performance. Finally, during inference, a Global-Local Prediction Consistency module aggregates predictions from seven classifiers (global, local, and combinations) based on their consistency and confidence scores to produce the final expression prediction.

## Key Results
- Achieves 87.60% accuracy on CK+ dataset using RAF-DB as source domain
- Outperforms current competing methods by substantial margins across multiple benchmarks
- Demonstrates consistent improvements across different target domains (JAFFE, SFEW2.0, ExpW)
- Shows robustness across different backbone architectures (ResNet50 and MobileNet-v2)

## Why This Works (Mechanism)

### Mechanism 1
Separate adversarial learning of global and local features reduces domain shift more effectively than holistic feature adaptation. By extracting both global facial features and local landmark-based features independently, the model learns domain-invariant representations at multiple scales, capturing both overall facial structure and fine-grained local variations to bridge the domain gap.

### Mechanism 2
Dynamic threshold-based pseudo label generation improves discriminative power in target domain without introducing excessive noise. The feature-level pseudo label generation module uses adaptive thresholds that adjust based on classifier confidence and historical performance, preventing over-confident but incorrect pseudo labels while ensuring sufficient coverage across expression categories.

### Mechanism 3
Global-local prediction consistency learning improves inference accuracy by optimally combining multiple classifier outputs. During inference, the GLPC module aggregates predictions from seven classifiers (global, local, and combined) based on their confidence scores and consistency, preventing over-reliance on any single classifier and leveraging complementary information.

## Foundational Learning

- Concept: Domain adaptation and domain shift
  - Why needed here: The paper addresses cross-domain facial expression recognition where source and target datasets have different distributions. Understanding domain shift is fundamental to why the proposed method works.
  - Quick check question: What causes domain shift in facial expression recognition, and why does it affect model performance?

- Concept: Adversarial learning for domain adaptation
  - Why needed here: The proposed method uses adversarial learning to make features domain-invariant. This is a key technique that enables knowledge transfer from source to target domain.
  - Quick check question: How does adversarial learning help in reducing domain shift, and what is the role of the domain discriminator?

- Concept: Pseudo labeling in semi-supervised learning
  - Why needed here: The method generates pseudo labels for unlabeled target data to provide discriminative supervision. Understanding pseudo labeling techniques is crucial for grasping the FPLG module.
  - Quick check question: What are the risks and benefits of using pseudo labels in training, and how does the dynamic threshold strategy mitigate these risks?

## Architecture Onboarding

- Component map:
  Feature Extractor (F) -> Global-Local Adversarial Learning (SAL) -> Feature-level Pseudo Label Generation (FPLG) -> Classifiers (G) -> Global-Local Prediction Consistency (GLPC)

- Critical path:
  1. Extract global and local features from input images
  2. Apply separate adversarial learning to make features domain-invariant
  3. Generate pseudo labels for target domain using dynamic thresholds
  4. Train classifiers with both source labels and pseudo labels
  5. During inference, aggregate predictions using GLPC module

- Design tradeoffs:
  - Global vs. local feature extraction: Global features capture overall expression but may miss fine-grained details; local features capture specific facial regions but may be noisier
  - Fixed vs. dynamic thresholds: Fixed thresholds are simpler but may not handle class imbalance well; dynamic thresholds are more complex but better handle imbalanced data
  - Single vs. multiple classifiers: Single classifier is simpler but may not capture all relevant information; multiple classifiers capture more information but increase complexity

- Failure signatures:
  - Poor performance on specific expression categories: May indicate class imbalance issues or insufficient local feature extraction for those expressions
  - Degradation when changing source domain: May indicate the method is too dependent on specific source-target domain pairs
  - Overfitting to source domain: May indicate insufficient domain adaptation or overly confident pseudo labels

- First 3 experiments:
  1. Ablation study: Train with only global features vs. only local features vs. both to quantify the contribution of each
  2. Pseudo label analysis: Compare fixed threshold vs. dynamic threshold approaches on label quality and downstream performance
  3. Inference strategy comparison: Test single classifier inference vs. average pooling vs. GLPC approach on held-out data

## Open Questions the Paper Calls Out

### Open Question 1
How does the semantic-aware pseudo label generation module's performance change when using different backbone networks beyond ResNet50 and MobileNet-v2? The paper only focused on two specific backbone networks, limiting the generalizability of the findings.

### Open Question 2
What is the impact of incorporating additional facial landmarks beyond the five mentioned on the performance of the separate adversarial learning module? The paper only focused on a limited set of facial landmarks, leaving the potential of other landmarks unexplored.

### Open Question 3
How does the proposed framework handle cases where the source and target domains have significantly different class distributions? The paper did not explicitly investigate the impact of extreme class imbalance between source and target domains.

## Limitations

- The semantic-aware pseudo label generation module lacks detailed implementation specifics, particularly the dynamic threshold calculation mechanism
- The paper doesn't provide ablation studies isolating the contribution of each component (global vs local features, pseudo labels, GLPC)
- Limited discussion of failure cases and sensitivity to hyperparameter choices

## Confidence

- **High confidence**: The core architecture design (global-local feature extraction with separate adversarial learning) is well-explained and logically sound
- **Medium confidence**: Performance improvements are demonstrated but lack component-wise attribution analysis
- **Low confidence**: The dynamic threshold mechanism for pseudo label generation needs more rigorous validation

## Next Checks

1. Implement ablation studies to quantify the individual contribution of global features, local features, pseudo labeling, and GLPC module
2. Conduct sensitivity analysis on the dynamic threshold parameters to understand their impact on performance and label quality
3. Test the framework on additional domain shift scenarios (e.g., different lighting conditions, occlusions) to evaluate robustness beyond dataset-to-dataset transfer