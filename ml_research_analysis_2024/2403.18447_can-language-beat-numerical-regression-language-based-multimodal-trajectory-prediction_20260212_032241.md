---
ver: rpa2
title: Can Language Beat Numerical Regression? Language-Based Multimodal Trajectory
  Prediction
arxiv_id: '2403.18447'
source_url: https://arxiv.org/abs/2403.18447
tags:
- trajectory
- prediction
- proceedings
- conference
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel language-based approach to pedestrian
  trajectory prediction. It converts numerical trajectory coordinates and scene images
  into natural language prompts, then uses a question-answering template with a language
  model to predict future paths.
---

# Can Language Beat Numerical Regression? Language-Based Multimodal Trajectory Prediction

## Quick Facts
- **arXiv ID:** 2403.18447
- **Source URL:** https://arxiv.org/abs/2403.18447
- **Reference count:** 40
- **Primary result:** Language-based approach (LMTraj) outperforms numerical regression methods on pedestrian trajectory prediction benchmarks

## Executive Summary
This paper proposes LMTraj, a novel language-based approach to pedestrian trajectory prediction that converts numerical trajectory coordinates and scene images into natural language prompts. By treating trajectory prediction as a question-answering problem for language models, the method leverages pre-trained semantic and reasoning capabilities while introducing a numerical tokenizer optimized for trajectory data. The approach achieves state-of-the-art results on public benchmarks, outperforming traditional numerical regression methods in both zero-shot and supervised settings.

## Method Summary
LMTraj recasts trajectory prediction as a question-answering problem using language models. The method converts trajectory coordinates and scene images into textual prompts, designs QA templates for structured input/output, and trains a numerical tokenizer specifically for trajectory data. It employs a two-stage approach: LMTraj-ZERO for zero-shot prediction using prompt engineering with GPT-3.5/4, and LMTraj-SUP for supervised end-to-end training with multi-task QA templates. The model generates predictions using beam search for deterministic outputs and temperature tuning for stochastic predictions.

## Key Results
- LMTraj-SUP outperforms numerical regression baselines on ADE/FDE metrics across multiple benchmarks
- The numerical tokenizer provides significant improvements over text-pretrained tokenizers
- Multi-task learning with auxiliary QA prompts enhances social reasoning and scene understanding
- Zero-shot performance with GPT-4 demonstrates the potential of prompt engineering alone

## Why This Works (Mechanism)

### Mechanism 1
Transforming numerical trajectory coordinates into natural language prompts enables language models to leverage their superior semantic and reasoning capabilities for trajectory prediction. The method converts continuous numerical trajectory data into discrete textual representations, allowing the language model to process the information using its pre-trained linguistic knowledge and reasoning abilities. Core assumption: Language models can effectively learn to extrapolate numerical time-series data when presented in a text format, despite being trained primarily on natural language.

### Mechanism 2
Introducing multi-task learning with auxiliary question-answering prompts enhances the model's understanding of social relationships and scene context, improving trajectory prediction performance. The model is trained on additional tasks such as destination suggestion, moving direction prediction, similar pattern search, group member prediction, and collision possibility assessment, which provide explicit guidance on social interactions and scene understanding. Core assumption: Language models can effectively learn and leverage high-level social knowledge and reasoning capabilities when trained on diverse tasks related to the main trajectory prediction objective.

### Mechanism 3
Optimizing the tokenizer for numerical data improves the model's ability to capture correlations between consecutive numbers in the language model, leading to better trajectory prediction. The proposed numerical tokenizer is trained specifically on the trajectory prompt data, splitting text and numbers clearly to enable the model to learn correlations between sequential numerical values more effectively. Core assumption: A tokenizer optimized for numerical data can better represent the sequential nature of trajectory coordinates compared to text-pretrained tokenizers, which may not handle numerical data as effectively.

## Foundational Learning

- **Natural Language Processing and Language Models**
  - Why needed here: Understanding NLP and language models is crucial for grasping how the proposed method leverages language models for trajectory prediction and the challenges involved in adapting them to numerical data.
  - Quick check question: What are the key differences between traditional numerical regression models and language-based approaches for trajectory prediction?

- **Trajectory Prediction and Social Interactions**
  - Why needed here: Familiarity with trajectory prediction methods and the importance of modeling social interactions between pedestrians is essential for understanding the context and motivation behind the proposed approach.
  - Quick check question: How do existing trajectory prediction methods model social interactions between pedestrians, and what are the limitations of these approaches?

- **Tokenization and Text Preprocessing**
  - Why needed here: Understanding tokenization techniques and text preprocessing is important for comprehending how the proposed method converts numerical trajectory data into a format suitable for language models and the role of the optimized tokenizer.
  - Quick check question: What are the challenges in tokenizing numerical data, and how does the proposed numerical tokenizer address these challenges compared to text-pretrained tokenizers?

## Architecture Onboarding

- **Component map:**
  - Data Preprocessing -> Image Captioning -> Prompt Template Design -> Numerical Tokenizer -> Multi-task Training -> Language Model Fine-tuning -> Inference (Beam Search/Temperature Tuning)

- **Critical path:**
  1. Convert numerical trajectory data and scene images into textual prompts
  2. Design question-answering templates for the language model
  3. Train a numerical tokenizer optimized for the trajectory data
  4. Implement multi-task learning with auxiliary question-answering prompts
  5. Fine-tune the language model using the processed prompts and optimized tokenizer
  6. Generate trajectory predictions using beam search and temperature tuning techniques

- **Design tradeoffs:**
  - Using a language model for numerical trajectory prediction allows leveraging pre-trained semantic and reasoning capabilities but may require significant adaptation and optimization
  - Multi-task learning can enhance the model's understanding of social interactions but may introduce additional complexity and training time
  - Optimizing the tokenizer for numerical data can improve the model's ability to capture correlations but may require additional data and training resources

- **Failure signatures:**
  - Poor prediction accuracy despite successful model training, indicating issues with the prompt conversion, tokenizer optimization, or language model adaptation
  - Increased training time and computational resources without significant performance improvements, suggesting inefficiencies in the multi-task learning or tokenizer optimization
  - Inconsistent or unrealistic trajectory predictions, indicating problems with the language model's understanding of the input prompts or the reasoning about social interactions

- **First 3 experiments:**
  1. Evaluate the performance of the proposed method on a small subset of the trajectory data using a pre-trained language model without any fine-tuning or optimization to establish a baseline
  2. Fine-tune the language model using the processed prompts and optimized tokenizer on a larger dataset and compare the performance to the baseline
  3. Implement and evaluate the multi-task learning approach with auxiliary question-answering prompts to assess the impact on the model's understanding of social interactions and overall prediction accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can numerical tokenizers be further optimized for trajectory prediction tasks, and what are the limits of their effectiveness compared to text-pretrained tokenizers?
- **Basis in paper:** [explicit] The paper introduces a numerical tokenizer optimized for trajectory data, showing improved performance over text-pretrained tokenizers.
- **Why unresolved:** While the paper demonstrates the benefits of a numerical tokenizer, it does not explore the full potential of this approach or investigate the limits of its effectiveness.
- **What evidence would resolve it:** Extensive experiments comparing different numerical tokenizer architectures, training strategies, and their performance limits against text-pretrained tokenizers on various trajectory prediction benchmarks.

### Open Question 2
- **Question:** Can language models be effectively used for trajectory prediction in scenarios with more complex interactions, such as multi-agent systems with non-linear dynamics or high-density crowds?
- **Basis in paper:** [inferred] The paper focuses on pedestrian trajectory prediction in crowded environments, but does not explicitly address more complex interaction scenarios.
- **Why unresolved:** The paper's experiments are limited to pedestrian trajectory prediction, and it does not explore the generalizability of the proposed approach to more complex multi-agent systems.
- **What evidence would resolve it:** Evaluating the proposed LMTraj model on benchmarks involving more complex multi-agent interactions, such as vehicle-pedestrian interactions or high-density crowd simulations.

### Open Question 3
- **Question:** How can the proposed multi-task training strategy be extended to incorporate additional domain knowledge or auxiliary tasks that could further improve trajectory prediction performance?
- **Basis in paper:** [explicit] The paper introduces a multi-task training strategy with auxiliary tasks like destination suggestion and collision avoidance, but does not explore its full potential.
- **Why unresolved:** The paper only scratches the surface of multi-task learning for trajectory prediction, and there is potential for incorporating more diverse and specialized auxiliary tasks.
- **What evidence would resolve it:** Developing and evaluating novel auxiliary tasks that capture additional aspects of human behavior, scene understanding, or environmental factors, and assessing their impact on trajectory prediction performance.

### Open Question 4
- **Question:** Can the proposed beam-search and temperature-tuning techniques be further refined or combined with other sampling strategies to generate more diverse and realistic trajectory predictions?
- **Basis in paper:** [explicit] The paper introduces beam-search and temperature-tuning for generating most-likely and multimodal trajectories, but does not explore their full potential or combination with other sampling methods.
- **Why unresolved:** The paper's experiments are limited to the basic implementation of these techniques, and there is room for improvement and exploration of alternative sampling strategies.
- **What evidence would resolve it:** Investigating and comparing different sampling strategies, such as importance sampling or Markov Chain Monte Carlo methods, in combination with beam-search and temperature-tuning for trajectory generation.

## Limitations

- **Language model adaptation**: The success of adapting language models for numerical trajectory prediction may be partially attributable to the specific properties of the T5 architecture rather than language models generally.
- **Tokenization assumptions**: The method relies on rounding to 4 decimal places, which could introduce quantization errors in precision-critical applications.
- **Multi-task learning effectiveness**: The computational overhead of multi-task training versus its performance gains remains unquantified.

## Confidence

- **High confidence**: The empirical results showing LMTraj-SUP outperforming numerical regression baselines on ADE/FDE metrics across multiple benchmarks.
- **Medium confidence**: The claim that language models provide superior semantic reasoning for trajectory prediction compared to specialized numerical models.
- **Low confidence**: The assertion that this approach "opens new avenues for research" - while novel, the practical advantages over specialized numerical methods for real-world deployment are not thoroughly explored.

## Next Checks

1. **Ablation study on tokenizer precision**: Systematically vary the decimal precision (from 2 to 8 decimal places) in the numerical tokenizer and measure the impact on ADE/FDE across all benchmarks to determine the optimal precision trade-off and validate the rounding approach.

2. **Cross-dataset generalization test**: Train LMTraj-SUP on one benchmark (e.g., ETH/UCY) and evaluate zero-shot on completely different datasets (e.g., nuScenes or Waymo) to assess whether the language-based approach generalizes better than numerical methods when faced with domain shifts.

3. **Computational efficiency comparison**: Measure and compare the training time, inference latency, and memory usage of LMTraj versus state-of-the-art numerical regression methods (Trajectron++, Social GAN) across different hardware configurations to quantify the practical deployment costs.