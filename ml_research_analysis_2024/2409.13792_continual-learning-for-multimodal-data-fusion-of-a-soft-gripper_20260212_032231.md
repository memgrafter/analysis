---
ver: rpa2
title: Continual Learning for Multimodal Data Fusion of a Soft Gripper
arxiv_id: '2409.13792'
source_url: https://arxiv.org/abs/2409.13792
tags:
- data
- learning
- feature
- algorithm
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of continual learning in multimodal
  data fusion, specifically for a soft pneumatic gripper. The core method idea involves
  extending the FeCAM algorithm with online batch-wise training, intra-layer feature
  representation, and semi-supervised learning capabilities.
---

# Continual Learning for Multimodal Data Fusion of a Soft Gripper

## Quick Facts
- **arXiv ID**: 2409.13792
- **Source URL**: https://arxiv.org/abs/2409.13792
- **Reference count**: 40
- **Primary result**: Incremental learning across modalities without catastrophic forgetting using prototype-based updates and semi-supervised learning

## Executive Summary
This paper introduces exFeCAM, an extension of the FeCAM algorithm for continual learning in multimodal data fusion with a soft pneumatic gripper. The method enables incremental learning of new object classes and data modalities without retraining from scratch by leveraging class-incremental and domain-incremental learning scenarios. The approach combines online batch-wise training, intra-layer feature representation, and semi-supervised learning capabilities to improve accuracy and adaptability. Experiments demonstrate significant performance gains over benchmark methods on custom multimodal and VGGSound datasets, with real-time implementation on a soft gripper validating practical applicability.

## Method Summary
The exFeCAM algorithm extends FeCAM by incorporating online batch-wise training, intra-layer feature representation (ILFR), and semi-supervised learning. It treats each modality as a distinct domain and maintains a dictionary of class prototypes (mean and covariance matrices) that are incrementally updated as new data arrives. The method concatenates multi-scale features from multiple intermediate layers to enrich the feature space, and uses cosine similarity-based pseudo-labeling to leverage unlabeled data. Classification is performed using Mahalanobis distance to the stored prototypes. The approach is evaluated on a custom dataset with tactile and visual sensor data from a soft gripper, and the VGGSound dataset.

## Key Results
- exFeCAM achieves 2.43-3.12% accuracy improvement over benchmark methods on multimodal datasets
- Intra-layer feature representation improves average accuracy by 3.12 ± 1.09%
- Semi-supervised learning with 70% labeled data compensates for missing labels while maintaining high accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incremental learning across modalities without catastrophic forgetting is enabled by treating each modality as a distinct domain and using prototype-based updates.
- Mechanism: exFeCAM maintains a dictionary of mean and covariance matrices for each class. When new data arrives, it updates prototypes incrementally rather than retraining from scratch, preserving past knowledge.
- Core assumption: Class prototypes (mean and covariance) are sufficient statistics for future classification across domains.
- Evidence anchors:
  - [abstract] "incremental learning different data modalities by leveraging both class-incremental and domain-incremental learning scenarios"
  - [section 4.1] "A dictionary is initialized with class labels as keys and their corresponding prototypes as values."
- Break condition: If the feature distribution shifts too much between tasks, the mean/covariance approximation becomes invalid and performance degrades.

### Mechanism 2
- Claim: Intra-layer feature representation improves generalization by concatenating multi-scale features from the last k layers.
- Mechanism: Instead of using only the final layer output, exFeCAM concatenates activations from multiple intermediate layers, enriching the feature space with hierarchical information.
- Core assumption: Intermediate layers contain complementary information that, when combined, produce more robust class embeddings.
- Evidence anchors:
  - [section 4.2] "Concatenation also preserves the rich, multi-scale features, unlike summation, which may result in information loss"
  - [section 5] "On average, incorporating ILFR results in an overall accuracy improvement of approximately 3.12 ± 1.09"
- Break condition: If layer dimensions are incompatible or memory constraints limit k, concatenation may fail or degrade performance.

### Mechanism 3
- Claim: Semi-supervised learning compensates for scarce labeled data by pseudo-labeling unlabeled samples using cosine similarity to stored prototypes.
- Mechanism: Feature maps of labeled data are stored in a temporary buffer; incoming unlabeled data are compared via cosine similarity and pseudo-labeled if similarity exceeds a threshold, then used to update prototypes.
- Core assumption: High cosine similarity implies the unlabeled sample belongs to the same class as the reference.
- Evidence anchors:
  - [section 4.3] "We then compute the cosine similarity between these reference feature maps and the feature maps generated from incoming unlabeled data"
  - [section 3.3] "We adopt the strategy of using cosine similarity between the feature representations of labeled and unlabeled data as a criterion for pseudo-labeling"
- Break condition: If the threshold is mis-tuned, pseudo-labels may be noisy, corrupting the model.

## Foundational Learning

- Concept: Mahalanobis distance classification using class prototypes.
  - Why needed here: exFeCAM uses Mahalanobis distance to assign class labels based on mean and covariance matrices, enabling distance-based classification without retraining.
  - Quick check question: How does Mahalanobis distance differ from Euclidean distance in classification?

- Concept: Continual learning scenario taxonomy (task-, class-, domain-incremental).
  - Why needed here: The paper combines class-incremental (new objects) and domain-incremental (new modalities) learning; understanding this helps design correct experiment flow.
  - Quick check question: In domain-incremental learning, what stays constant across tasks?

- Concept: Semi-supervised learning via pseudo-labeling.
  - Why needed here: With only 70% labeled data, pseudo-labeling allows leveraging the remaining 30% unlabeled data to improve accuracy.
  - Quick check question: What risk does pseudo-labeling introduce if the model is uncertain?

## Architecture Onboarding

- Component map: Data acquisition → Feature extractor (pre-trained) → Intra-layer feature concat → Prototype update (mean/cov) → exFeCAM model → Prediction
- Critical path: Feature extraction → Prototype update → Classification; any bottleneck here stalls real-time performance.
- Design tradeoffs:
  - Memory vs accuracy: Storing prototypes is lightweight (~22.5 MB) but may underfit if distributions change.
  - Batch size vs latency: Larger batches improve prototype stability but increase processing delay.
  - Pseudo-labeling threshold: Higher thresholds reduce noise but may waste unlabeled data.
- Failure signatures:
  - Accuracy drops sharply after new domain introduction → prototype shift too large.
  - False positives in pseudo-labeling → threshold too low or feature space too similar across classes.
  - Real-time lag → feature extraction or prototype update too slow for ROS frequency.
- First 3 experiments:
  1. Validate prototype update on synthetic batch data with known class means.
  2. Test ILFR by comparing accuracy with/without concatenation on a small multimodal subset.
  3. Evaluate pseudo-labeling quality by measuring cosine similarity distribution on unlabeled samples.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the exFeCAM algorithm change when the ratio of labeled to unlabeled data is varied (e.g., 50:50, 30:70, 10:90)?
- Basis in paper: [explicit] The paper evaluates SSL with a fixed 70:30 split between labeled and unlabeled data, but does not explore how varying this ratio affects performance.
- Why unresolved: The study focuses on a single SSL configuration and does not test the algorithm's robustness to different levels of supervision.
- What evidence would resolve it: Experiments with multiple labeled/unlabeled splits, comparing accuracy and computational efficiency, would reveal the optimal balance and the algorithm's sensitivity to supervision levels.

### Open Question 2
- Question: How does the exFeCAM algorithm scale when the number of data modalities increases beyond two (e.g., adding audio, temperature, or depth data)?
- Basis in paper: [inferred] The paper demonstrates effectiveness with two modalities (visual and tactile), but does not test scenarios with more than two domains.
- Why unresolved: The architecture treats each modality as a new domain, but the impact of scaling to multiple modalities on accuracy, memory, and computational cost is unexplored.
- What evidence would resolve it: Testing the algorithm on datasets with three or more modalities, measuring accuracy and resource usage, would clarify scalability limits and integration challenges.

### Open Question 3
- Question: What is the impact of different feature extraction architectures (e.g., ResNet, ViT, or custom CNNs) on the exFeCAM algorithm's performance in multimodal CL?
- Basis in paper: [explicit] The paper uses ResNet18 for VGGSound and custom CNN architectures for the multimodal dataset, but does not compare performance across different feature extractors.
- Why unresolved: While the algorithm is modular with respect to the feature extractor, the influence of architecture choice on learning efficiency and accuracy is not quantified.
- What evidence would resolve it: Benchmarking exFeCAM with multiple feature extractors on the same datasets would reveal which architectures best support continual multimodal learning.

## Limitations

- Prototype-based updates may become unstable under significant distribution shifts between tasks
- Semi-supervised learning effectiveness depends on optimal threshold tuning, which is not fully specified
- Real-time implementation lacks statistical significance testing and detailed runtime profiling

## Confidence

- **High confidence**: The exFeCAM algorithm architecture and its core components (prototype updates, ILFR, pseudo-labeling) are clearly specified and logically sound based on the described mechanisms.
- **Medium confidence**: The accuracy improvements reported (2.43-3.12% gains) are specific but may not generalize beyond the tested datasets without further validation.
- **Low confidence**: The robustness of the method to severe domain shifts or catastrophic forgetting in long task sequences is not demonstrated.

## Next Checks

1. Test prototype stability by introducing controlled domain shifts and measuring classification degradation over sequential tasks.
2. Conduct ablation studies on the cosine similarity threshold to determine sensitivity and optimal values for pseudo-labeling.
3. Perform runtime profiling of the real-time ROS implementation to identify bottlenecks and verify latency meets soft gripper control requirements.