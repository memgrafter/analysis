---
ver: rpa2
title: Contrastive Learning with Auxiliary User Detection for Identifying Activities
arxiv_id: '2410.21300'
source_url: https://arxiv.org/abs/2410.21300
tags:
- activity
- user
- claudia
- learning
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of improving Human Activity Recognition
  (HAR) by making it both Context-Aware (CA) and User-Aware (UA), addressing the under-explored
  impact of user-specific differences in performing activities. The authors propose
  CLAUDIA, a novel framework that integrates User Identification (UI) as an auxiliary
  subtask alongside CA-HAR, creating a User and Context-Aware HAR (UCA-HAR) model.
---

# Contrastive Learning with Auxiliary User Detection for Identifying Activities
## Quick Facts
- arXiv ID: 2410.21300
- Source URL: https://arxiv.org/abs/2410.21300
- Reference count: 37
- Primary result: CLAUDIA improves HAR performance by 11.7%-14.2% in MCC and 5.4%-7.3% in Macro F1 over baselines

## Executive Summary
This paper addresses the challenge of Human Activity Recognition (HAR) by developing a framework that simultaneously captures context-aware and user-aware patterns. The proposed CLAUDIA framework integrates User Identification (UI) as an auxiliary subtask alongside Context-Aware HAR, creating a User and Context-Aware HAR (UCA-HAR) model. By employing supervised contrastive loss, the model enforces closer representations between different users performing the same activity, enabling it to learn both user-invariant and user-specific patterns. The approach combines handcrafted features with raw time-series data using a two-layer LSTM architecture with separate linear projections for activity, phone placement, and user identity predictions.

## Method Summary
CLAUDIA addresses the dual challenge of context-aware and user-aware HAR by leveraging supervised contrastive learning. The framework processes sensor data through a two-layer LSTM to capture temporal dependencies, then uses separate linear projections for three tasks: activity classification, phone placement detection, and user identification. The contrastive loss component brings representations of the same activity closer together across different users while pushing apart representations of different activities. This multi-task approach enables the model to learn both activity-specific patterns and user-specific variations in how activities are performed. The method is evaluated on three real-world datasets, demonstrating significant improvements over state-of-the-art baselines.

## Key Results
- CLAUDIA achieves 11.7% to 14.2% improvement in Matthew's Correlation Coefficient compared to state-of-the-art baselines
- The framework shows 5.4% to 7.3% improvement in Macro F1 score across three real-world datasets
- Performance gains are consistent across different evaluation metrics, demonstrating robustness of the contrastive learning approach

## Why This Works (Mechanism)
The contrastive learning mechanism works by creating tighter clusters in the representation space for the same activity across different users while maintaining separation between different activities. This dual objective forces the model to learn activity-invariant features while preserving user-specific variations. The auxiliary user identification task provides additional supervisory signal that helps the model better distinguish between different activity patterns and their variations across users. The supervised nature of the contrastive loss ensures that the model learns meaningful distinctions rather than arbitrary separations in the representation space.

## Foundational Learning
- Contrastive Learning: Needed to create meaningful representations by pulling similar examples together and pushing dissimilar examples apart; quick check: verify that representations of same activity from different users are indeed closer than representations of different activities.
- Multi-task Learning: Required to leverage auxiliary information (user identity) to improve primary task (activity recognition); quick check: ensure that auxiliary task doesn't negatively impact main task performance.
- LSTM Networks: Essential for capturing temporal dependencies in sequential sensor data; quick check: validate that temporal information is being properly captured by examining intermediate representations.

## Architecture Onboarding
**Component Map:** Sensor Data -> LSTM Layers -> Linear Projections (Activity, Phone Placement, User Identity) -> Supervised Contrastive Loss

**Critical Path:** The main flow is sensor data through LSTM layers to activity classification, with contrastive loss applied to user representations as an auxiliary objective.

**Design Tradeoffs:** The choice to use both handcrafted features and raw time-series data provides flexibility but increases model complexity. Using supervised contrastive loss instead of unsupervised approaches provides more control but requires labeled user identity data.

**Failure Signatures:** The model may overfit to specific user patterns if the contrastive loss is too strong, or fail to generalize across users if the loss is too weak. Poor performance on unseen users indicates insufficient user-invariant learning.

**First Experiments:** 1) Train with only main activity task to establish baseline performance. 2) Add user identification without contrastive loss to measure auxiliary task contribution. 3) Vary the strength of contrastive loss to find optimal balance between user-specific and user-invariant learning.

## Open Questions the Paper Calls Out
None

## Limitations
- The methodology lacks detail on dataset splitting for training/validation/testing, affecting reproducibility
- The model assumes availability of both handcrafted features and raw time-series data, which may not be practical in all scenarios
- Potential overfitting to specific user patterns due to the use of user identity as an auxiliary task is not adequately addressed

## Confidence
High: The technical implementation of CLAUDIA using supervised contrastive loss and the dual-task architecture is well-defined and reproducible.

Medium: The reported performance improvements over baselines are likely accurate for the tested datasets, but generalizability to other HAR scenarios remains uncertain without additional validation.

Low: Claims about CLAUDIA's ability to capture both user-invariant and user-specific patterns effectively are not fully substantiated with qualitative analysis of learned representations.

## Next Checks
1. Conduct ablation studies to isolate the contribution of the contrastive user detection component versus other architectural choices in CLAUDIA.

2. Test the model's performance when trained on a subset of users and evaluated on unseen users to assess cross-user generalization.

3. Evaluate CLAUDIA's robustness when only raw time-series data is available, without handcrafted features, to assess real-world applicability.