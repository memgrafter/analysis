---
ver: rpa2
title: Le Nozze di Giustizia. Interactions between Artificial Intelligence, Law, Logic,
  Language and Computation with some case studies in Traffic Regulations and Health
  Care
arxiv_id: '2402.06487'
source_url: https://arxiv.org/abs/2402.06487
tags:
- will
- driving
- formal
- program
- rest
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper discusses limitations of Artificial Intelligence (AI)
  in the context of law, focusing on rule-based AI and formal methods. It identifies
  three categories of limitations: logical, computational, and mathematical.'
---

# Le Nozze di Giustizia. Interactions between Artificial Intelligence, Law, Logic, Language and Computation with some case studies in Traffic Regulations and Health Care

## Quick Facts
- arXiv ID: 2402.06487
- Source URL: https://arxiv.org/abs/2402.06487
- Reference count: 40
- The paper discusses limitations of AI in law, focusing on rule-based AI and formal methods, and identifies three categories of limitations: logical, computational, and mathematical.

## Executive Summary
This paper analyzes the limitations of Artificial Intelligence in legal applications, focusing on rule-based AI and formal methods. It identifies three distinct categories of limitations: logical (fundamental unsolvability problems like the Halting problem), computational (problems requiring astronomical resources), and mathematical (underspecification and ambiguity in natural language laws). Using European traffic regulations as case studies, the authors demonstrate how these limitations manifest in practice and argue for the importance of formal methods in controlling AI applications in public administration.

## Method Summary
The paper reviews and analyzes legal texts and computational models to identify and categorize AI limitations. It applies formal methods to examine European traffic regulations as case studies, evaluating how rule-based AI systems would handle these regulations. The analysis focuses on translating legal stipulations into formal logical expressions and examining the resulting behaviors, particularly around edge cases and ambiguous interpretations. The authors classify limitations based on theoretical computer science results and practical analysis of legal texts.

## Key Results
- AI systems face fundamental logical limitations that cannot be overcome, such as the Halting problem
- Computational complexity creates hard limits on what AI can practically achieve in legal applications
- Natural language laws contain underspecification and ambiguity that create mathematical misbehaviors when translated to formal systems

## Why This Works (Mechanism)

### Mechanism 1
Formal methods provide mathematical rigor for rule-based AI but only with respect to formal semantics, not real-world interpretation. Translating legal text into a formal language with well-defined formal ontologies allows precise reasoning about algorithmic behavior. The formal semantics maps propositions to true/false values, enabling mathematical proofs of program properties. However, the link between formal terms and real-world observables relies on trust and common sense, not mathematical rigor.

### Mechanism 2
Fundamental AI problems (logical and computational) create hard limits on AI capabilities that cannot be overcome with more advanced AI techniques. Certain problems are provably unsolvable (like the Halting problem) or require more computational resources than exist in the universe (exponential complexity problems). These are mathematical limitations that apply regardless of AI sophistication.

### Mechanism 3
Underspecification and ambiguity in natural language laws create mathematical misbehaviors when translated to computable systems. Legal language often uses terms without precise definitions, relies on context-dependent interpretation, and may contain inconsistencies. When these are translated into formal systems, the ambiguity manifests as multiple valid interpretations, unexpected edge cases, or inconsistent behavior.

## Foundational Learning

- Concept: Formal logic and propositional logic
  - Why needed here: Understanding how legal stipulations can be translated into formal logical expressions and the limitations of this translation
  - Quick check question: Can you express the legal rule "If it rains and you drive in an industrial area, your maximum speed is 35 km/h" as a logical formula and identify what the formal semantics guarantees vs what it doesn't?

- Concept: Computational complexity and undecidability
  - Why needed here: Recognizing which problems AI can solve versus which are fundamentally impossible or require infeasible resources
  - Quick check question: Why can't there be a perfect virus scanner that detects all possible viruses, and how does this relate to the Halting problem?

- Concept: Formal ontologies and semantic mapping
  - Why needed here: Understanding how to create mappings between legal concepts and formal representations that can be processed by AI systems
  - Quick check question: What makes "driving" a poor formal ontology compared to "speed," and how would you design a better ontology for computable traffic laws?

## Architecture Onboarding

- Component map: Legal text parser → Formal ontology mapper → Rule translator → Formal verification engine → Decision engine → Observable mapper → Output formatter
- Critical path: Legal text → Formal ontology selection → Formal translation → Verification → Execution
- Design tradeoffs:
  - Precision vs flexibility: More precise formal ontologies provide better verification but may miss edge cases; flexible ontologies handle more cases but provide weaker guarantees
  - Automation vs human oversight: Full automation maximizes efficiency but risks undetected misbehaviors; human oversight provides safety but reduces scalability
  - Computational resources vs completeness: More resources allow checking more cases but may still miss fundamental limitations
- Failure signatures:
  - Logical failures: Program gets stuck in infinite loops or cannot make decisions on valid inputs
  - Computational failures: System runs out of memory or time on tractable problems
  - Mathematical misbehaviors: System produces results that violate the spirit of the law or create unexpected edge cases
  - Ontology failures: System makes decisions based on formal interpretations that contradict legal intent
- First 3 experiments:
  1. Implement a simple tachograph system that enforces basic driving time limits using propositional logic, then test edge cases around day boundaries and week definitions
  2. Create a formal verification of a tax calculation program to demonstrate the limits of correctness verification
  3. Model a simplified traffic regulation with underspecified terms and show how different formal interpretations lead to different legal outcomes

## Open Questions the Paper Calls Out

### Open Question 1
Can formal ontologies be designed that map directly to physical observables in all legal domains, eliminating the need for interpretation in computable law? The paper demonstrates the difficulty of creating unambiguous formal ontologies, particularly for concepts that involve human judgment or are not directly observable. Development and successful implementation of formal ontologies for multiple legal domains that eliminate ambiguity and require no interpretation in practice would resolve this question.

### Open Question 2
Is there a theoretical framework that can evaluate and compare the level of control and transparency between rule-based AI and data-driven AI approaches? Current theoretical results are inconclusive, and the paper suggests that rule-based AI seems to allow more control based on pragmatic arguments rather than formal proof. A formal theoretical framework that quantifies and compares control and transparency levels between different AI approaches across various applications would resolve this question.

### Open Question 3
Can mathematical misbehaviors in computable law be systematically detected and prevented before implementation? The paper shows that simple rules can give rise to very complicated structures and that obtaining complicated structures cannot be avoided, making detection and prevention challenging. Development of a systematic method or tool that can analyze legal regulations and identify potential mathematical misbehaviors before they are implemented in code would resolve this question.

## Limitations
- Analysis focuses primarily on rule-based AI systems, potentially overlooking advancements in machine learning approaches
- Case studies are limited to European traffic regulations, which may not represent the full complexity of legal domains
- Formal methods described are presented in "rudimentary form," suggesting the analysis may not capture all nuances of practical implementation

## Confidence
- Core claims about logical and computational limitations: Medium
- Practical implications for legal AI: Low
- Mathematical misbehavior analysis: Medium

## Next Checks
1. Implement and test the tachograph system: Build a working prototype of the tachograph enforcement system described in the paper and systematically test edge cases around day boundaries, week definitions, and break period calculations to verify the claimed mathematical misbehaviors.

2. Cross-domain applicability study: Apply the same formal analysis framework to legal texts from different domains (e.g., tax law, criminal law, or contract law) to assess whether the identified limitations generalize beyond traffic regulations.

3. Alternative AI approach comparison: Implement similar legal reasoning tasks using modern machine learning approaches (neural networks, large language models) and compare their performance and failure modes against the rule-based formal methods discussed in the paper.