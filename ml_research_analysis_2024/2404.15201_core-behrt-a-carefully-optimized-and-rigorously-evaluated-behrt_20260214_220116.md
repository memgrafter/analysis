---
ver: rpa2
title: 'CORE-BEHRT: A Carefully Optimized and Rigorously Evaluated BEHRT'
arxiv_id: '2404.15201'
source_url: https://arxiv.org/abs/2404.15201
tags:
- data
- codes
- tasks
- performance
- behrt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents CORE-BEHRT, a carefully optimized and rigorously
  evaluated version of the BEHRT model for electronic health records (EHR). The authors
  systematically investigate data representation, model architecture, and training
  protocol improvements through incremental optimization.
---

# CORE-BEHRT: A Carefully Optimized and Rigorously Evaluated BEHRT

## Quick Facts
- arXiv ID: 2404.15201
- Source URL: https://arxiv.org/abs/2404.15201
- Reference count: 22
- Primary result: AUROC improved from 0.785 to 0.801 through systematic optimization

## Executive Summary
This paper presents CORE-BEHR T, an optimized version of the BEHRT model for electronic health records (EHR) that achieves significant performance improvements through systematic investigation of data representation, model architecture, and training protocol. The authors incrementally test various enhancements including medication codes, timestamps, full-depth ICD-10 codes, Time2Vec embeddings, rotary position embeddings, and SwiGLU activation functions. CORE-BEHR T demonstrates consistent performance gains across 25 diverse clinical prediction tasks, providing a strong foundation for future EHR modeling and increased trustworthiness of BERT-based models in clinical settings.

## Method Summary
The authors systematically optimize BEHRT through incremental improvements, starting with data representation enhancements (medication codes, timestamps, full-depth ICD-10 codes), followed by architectural modifications (Time2Vec embeddings, rotary position embeddings, SwiGLU activation), and training protocol adjustments (masking ratio optimization). The model is pre-trained using Masked Language Modeling (MLM) at 20% masking ratio, then fine-tuned on three generic clinical tasks (death, pain treatment, infection) and 25 diverse clinical prediction tasks. Performance is evaluated using five-fold cross-validation with AUROC and AUPRC metrics, with statistical significance testing using one-sided t-tests with Benjamini-Hochberg correction for FDR.

## Key Results
- Average AUROC improved from 0.785 to 0.801 through systematic optimization
- Significant improvements in 17 out of 25 clinical prediction tasks
- 24 out of 25 tasks showed improvement in at least one metric (AUROC or AUPRC)
- CORE-BEHR T demonstrated consistent performance gains across cancer, cardiovascular, chronic, emergency, infection, psychiatric, pregnancy-related, and other clinical domains

## Why This Works (Mechanism)

### Mechanism 1
Including medication codes and timestamps significantly improves AUROC by providing more granular and temporally accurate information than diagnosis codes alone. Medication codes add treatment-level detail that diagnoses often miss, while timestamps enable the model to learn event timing patterns rather than just age-based progressions. This captures both therapeutic context and fine-grained temporal dynamics.

### Mechanism 2
Improved transformer recipe components (RoPE + SwiGLU) boost MLM performance more than downstream EHR tasks because EHR tasks are less aligned with the pretraining objective. RoPE encodes relative positions better than standard embeddings, and SwiGLU improves activation expressiveness. These help MLM convergence but their impact on clinical prediction is indirect.

### Mechanism 3
Using full-depth ICD-10 codes instead of higher-level phenotype mappings increases model expressiveness and performance. Fine-grained codes preserve rare condition information and allow the model to learn more specific patterns rather than relying on coarse groupings.

## Foundational Learning

- Concept: Masked Language Modeling (MLM) pretraining objective
  - Why needed here: CORE-BEHR T uses MLM to learn general representations from unlabeled EHR sequences before fine-tuning on specific clinical tasks
  - Quick check question: What percentage of tokens is masked during pretraining in the base BEHRT model? (Answer: 15%)

- Concept: Transformer self-attention mechanism
  - Why needed here: The model uses transformer layers to capture dependencies between medical events in patient sequences
  - Quick check question: How does Rotary Position Embedding (RoPE) modify standard positional embeddings? (Answer: It rotates embeddings based on position to encode relative distances)

- Concept: Area Under the Receiver Operating Characteristic (AUROC)
  - Why needed here: The primary evaluation metric for measuring binary classification performance across clinical tasks
  - Quick check question: What does an AUROC of 0.5 represent? (Answer: Random classifier performance)

## Architecture Onboarding

- Component map: Input → Token/Time2Vec embeddings → Transformer layers (with RoPE, SwiGLU) → Pooling → Classification

- Critical path: Input → Token/Time2Vec embeddings → Transformer layers (with RoPE, SwiGLU) → Pooling → Classification

- Design tradeoffs:
  - Vocabulary size vs. model capacity: Full-depth codes increase vocabulary from ~2,475 to ~17,469, increasing model size 3.7x
  - Sequence length vs. computational cost: Including medication increases average sequence length by 143.3 codes, 5x training time
  - Pretraining objective alignment vs. task relevance: MLM helps learn general patterns but may not align perfectly with clinical prediction

- Failure signatures:
  - Poor convergence: Check masking ratio, learning rate, and batch size
  - Overfitting: Monitor validation loss during pretraining; reduce model size or add regularization
  - Underperformance on rare conditions: Verify full-depth codes are properly encoded; consider class imbalance handling

- First 3 experiments:
  1. Compare baseline BEHRT vs. BEHRT+D (with medication and timestamps) on death prediction task
  2. Test different masking ratios (15%, 20%, 25%) on pain treatment prediction
  3. Evaluate pooling strategies (CLS, mean, BiGRU) on infection prediction task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal masking ratio for BERT-based EHR models across different clinical prediction tasks?
- Basis in paper: [explicit] The authors found that a masking ratio of 20% was optimal for their three generic tasks, but observed inconsistent impacts across different tasks.
- Why unresolved: The masking ratio's impact varies depending on the specific clinical prediction task, suggesting task-specific optimization may be needed.
- What evidence would resolve it: A comprehensive study evaluating multiple masking ratios across a diverse set of clinical prediction tasks to determine if a universal optimal ratio exists or if task-specific ratios are needed.

### Open Question 2
- Question: How does including additional data sources beyond medications, such as lab tests and vital signs, affect model performance?
- Basis in paper: [inferred] The authors noted that while medication codes significantly improved performance, they did not investigate the impact of lab tests, vital signs, and procedure codes due to computational constraints.
- Why unresolved: The potential performance gains from incorporating these additional data sources remain unknown due to the computational challenges of integrating and evaluating them.
- What evidence would resolve it: A study that integrates lab tests, vital signs, and procedure codes into the model and evaluates the performance impact on a range of clinical prediction tasks.

### Open Question 3
- Question: What is the relationship between model performance saturation and dataset size for different clinical prediction tasks?
- Basis in paper: [explicit] The authors observed that performance saturation occurred for some tasks (e.g., schizophrenia) even with significant increases in patient numbers, suggesting that more data is not always the solution.
- Why unresolved: The point at which performance saturates varies by task, and the underlying factors contributing to this saturation are not well understood.
- What evidence would resolve it: A study that systematically varies the dataset size for a range of clinical prediction tasks and analyzes the relationship between performance gains and dataset size to identify saturation points and contributing factors.

## Limitations

- Incomplete specification of 25 clinical prediction tasks prevents exact reproduction and verification of claimed improvements across all tasks
- Single healthcare system (Denmark) data limits generalizability to other populations and healthcare contexts
- Weak empirical evidence for mechanism by which full-depth ICD-10 codes specifically improve rare condition prediction

## Confidence

**High Confidence:** The incremental optimization methodology and specific improvements (medication codes, timestamps, full-depth ICD-10, RoPE, SwiGLU) are well-documented and technically sound. The claim that these optimizations improve AUROC from 0.785 to 0.801 on the three generic tasks is supported by clear experimental evidence and proper statistical validation.

**Medium Confidence:** The claim of consistent performance gains across 25 diverse clinical tasks is partially supported but less certain due to incomplete task specification. The paper shows improvements in 17 out of 25 tasks and 24 out of 25 tasks, but without full task definitions and code mappings, the exact nature and magnitude of these improvements cannot be independently verified.

**Low Confidence:** The mechanism by which full-depth ICD-10 codes specifically improve rare condition prediction is weakly supported. While the paper claims this benefit, it lacks direct evidence showing performance differences on rare vs. common conditions, and the evidence anchors are primarily theoretical rather than empirical.

## Next Checks

1. Replicate the three generic tasks with full methodology transparency: Obtain and verify the exact ICD-10 and ATC code mappings, prediction windows, and age distributions for death, pain treatment, and infection tasks. Run the baseline BEHRT, BEHRT+D, and CORE-BEHR T implementations to confirm the AUROC improvements from 0.785 to 0.801.

2. Test model generalization on external datasets: Evaluate CORE-BEHR T on EHR data from a different healthcare system (e.g., US Medicare claims data or UK NHS data) to assess whether the performance gains translate across different coding systems, documentation practices, and patient populations.

3. Analyze rare condition performance explicitly: Create a subset of tasks focusing on rare conditions (incidence < 1%) and compare CORE-BEHR T performance against baseline BEHRT to directly test the hypothesis that full-depth ICD-10 codes improve rare condition prediction. Measure both AUROC and calibration metrics for these rare conditions.