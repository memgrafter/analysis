---
ver: rpa2
title: Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and Clustering
  Algorithms
arxiv_id: '2410.00134'
source_url: https://arxiv.org/abs/2410.00134
tags:
- topic
- topics
- words
- each
- modeling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel semantic-driven topic modeling approach
  that addresses limitations in traditional methods by leveraging transformer-based
  embeddings and clustering algorithms. The model generates document embeddings using
  pre-trained transformer-based language models, reduces dimensionality, clusters
  based on semantic similarity, and extracts coherent topics for each cluster.
---

# Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and Clustering Algorithms

## Quick Facts
- arXiv ID: 2410.00134
- Source URL: https://arxiv.org/abs/2410.00134
- Reference count: 40
- Outperforms traditional LDA and CTM methods on topic coherence metrics

## Executive Summary
This paper introduces a novel semantic-driven topic modeling approach that leverages transformer-based embeddings and clustering algorithms to address limitations in traditional methods. The model generates document embeddings using pre-trained transformer-based language models, reduces dimensionality with UMAP, clusters documents based on semantic similarity using HDBSCAN, and extracts coherent topics for each cluster. The approach demonstrates superior performance compared to traditional topic modeling algorithms like LDA and CTM, as well as BERTopic and ChatGPT, achieving high topic coherence scores across various datasets.

## Method Summary
The semantic-driven topic modeling pipeline consists of five main steps: (1) Document embedding using SBERT models (MiniLM and MPNET) to capture contextual word relationships, (2) Dimensionality reduction using UMAP to preserve local and global structure, (3) Clustering with HDBSCAN to identify semantically dense regions and handle varying densities, (4) Vocabulary building and semantic similarity filtering to remove non-representative words from each cluster, and (5) Similarity-based topic merging to produce final coherent topics. The model focuses on extracting contextually relevant words within documents rather than relying on frequency-based approaches.

## Key Results
- Achieves CV coherence scores of 0.735, 0.651, and 0.594 for 20NewsGroups, BBC News, and Trump's tweets datasets respectively
- Outperforms traditional LDA, CTM, and ETM models on topic coherence metrics
- Demonstrates superior performance compared to BERTopic and ChatGPT topic modeling approaches
- Shows consistent improvement across multiple evaluation metrics (CV, Cnpmi, Umass, Cuci)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic relevance filtering improves topic coherence by removing non-representative words.
- Mechanism: After clustering, each cluster builds a vocabulary of unique words and computes average cosine similarity between each word and all sentences in the cluster. Words below a threshold are excluded from the final topic list.
- Core assumption: Words with low average semantic similarity to sentences in their cluster do not meaningfully represent the cluster's topic.
- Evidence anchors:
  - [abstract] "Our model focuses only on the most relevant words within each document, disregarding non-relevant ones."
  - [section] "we eliminate topic-representative words that do not have any semantic contribution to the sentence."
- Break condition: If semantic similarity scores are uniformly low or high, filtering may discard useful words or retain irrelevant ones.

### Mechanism 2
- Claim: Using SBERT embeddings preserves contextual word relationships better than bag-of-words methods.
- Mechanism: Documents are converted to fixed-length sentence embeddings using SBERT, capturing context-dependent meaning rather than isolated word frequencies.
- Core assumption: Contextual embeddings encode richer semantic relationships than static embeddings or bag-of-words vectors.
- Evidence anchors:
  - [abstract] "leverages the Transformer's ability to capture contextual information about words within the document"
  - [section] "We ensure that the model focuses only on the most relevant words within each document"
- Break condition: If SBERT embeddings collapse distinct contexts into similar vectors, important topic distinctions may be lost.

### Mechanism 3
- Claim: UMAP + HDBSCAN clustering combination effectively identifies semantically dense regions in high-dimensional embedding space.
- Mechanism: High-dimensional SBERT embeddings are reduced via UMAP, then HDBSCAN identifies clusters of varying densities, treating sparse regions as noise/outliers.
- Core assumption: Semantically similar documents form dense regions in reduced embedding space that HDBSCAN can detect robustly.
- Evidence anchors:
  - [section] "UMAP as a dimension reduction technique that shows remarkable improvements in clustering documents"
  - [section] "HDBSCAN is chosen for its robustness, scalability, and ability to find clusters of varying densities"
- Break condition: If UMAP distorts semantic relationships or HDBSCAN merges distinct clusters, topic extraction will be inaccurate.

## Foundational Learning

- Concept: Document embedding with contextual models (e.g., SBERT)
  - Why needed here: Provides fixed-length vectors that capture word relationships within context, enabling semantic clustering instead of frequency-based methods.
  - Quick check question: What does SBERT output when given a sentence, and why is that useful for clustering?

- Concept: Dimensionality reduction trade-offs (UMAP vs PCA vs t-SNE)
  - Why needed here: High-dimensional embeddings hinder clustering; UMAP preserves local and global structure better for this task.
  - Quick check question: How does UMAP balance local vs global structure preservation, and why does that matter for topic coherence?

- Concept: Density-based clustering (HDBSCAN) vs centroid-based (k-means)
  - Why needed here: Documents may have varying topic densities; HDBSCAN finds clusters of arbitrary shape and identifies outliers.
  - Quick check question: How does HDBSCAN decide which points are noise, and what parameter controls cluster size?

## Architecture Onboarding

- Component map: SBERT encoder → UMAP reducer → HDBSCAN clusterer → Vocabulary builder + similarity filter → Similarity-based topic merging
- Critical path: SBERT → UMAP → HDBSCAN → vocabulary + filtering → merging
- Design tradeoffs:
  - SBERT vs other embeddings: higher quality vs slower inference
  - UMAP vs t-SNE: better scalability vs t-SNE's local focus
  - HDBSCAN vs k-means: arbitrary cluster shapes vs fixed k requirement
  - Strict similarity filtering vs broader topic coverage
- Failure signatures:
  - Too many small clusters → reduce UMAP n_neighbors or HDBSCAN min_cluster_size
  - Low coherence scores → raise similarity threshold or adjust filtering
  - All documents as noise → increase HDBSCAN min_cluster_size or revisit UMAP parameters
  - Very large clusters → decrease UMAP n_neighbors or increase HDBSCAN min_cluster_size
- First 3 experiments:
  1. Run pipeline on 20NewsGroups with default UMAP/HDBSCAN; inspect cluster counts and topic quality.
  2. Vary HDBSCAN min_cluster_size from 5 to 50; observe effect on topic granularity and coherence.
  3. Replace SBERT with MiniLM or MPNet; compare coherence scores to baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed semantic-driven topic modeling approach handle latent subtopics within clusters?
- Basis in paper: [explicit] The paper explicitly mentions this as a limitation in Section 4.8, stating that "Latent subtopics are topics that are not directly stated but are suggested" and that the model does not detect these.
- Why unresolved: The current model focuses on extracting explicit topics based on semantic similarity within clusters but lacks a mechanism to identify underlying, unstated subtopics that may be implied by the context.
- What evidence would resolve it: Experimental results comparing the model's performance on datasets with known latent subtopics, and development of new metrics to evaluate the detection of latent subtopics.

### Open Question 2
- Question: What is the impact of different transformer-based language models on the performance of the proposed topic modeling approach?
- Basis in paper: [inferred] The paper mentions using SBERT models (MiniLM and MPNET) in experiments, but does not explore the impact of using other transformer-based language models.
- Why unresolved: The paper does not provide a comprehensive comparison of different transformer-based language models and their effects on topic coherence and quality.
- What evidence would resolve it: Comparative experiments using various transformer-based language models (e.g., BERT, RoBERTa, GPT) and analysis of their impact on topic modeling performance.

### Open Question 3
- Question: How does the model's performance scale with increasing dataset size and complexity?
- Basis in paper: [explicit] The paper mentions that ChatGPT struggles with large datasets due to token limits, but does not provide a detailed analysis of the proposed model's scalability.
- Why unresolved: The paper does not present experiments or analysis on how the model's performance changes as the dataset size and complexity increase.
- What evidence would resolve it: Experiments testing the model's performance on datasets of varying sizes and complexities, and analysis of computational resources required for processing larger datasets.

## Limitations

- The model does not detect latent subtopics within clusters, focusing only on explicit topics
- Performance may degrade with very large datasets due to computational complexity of transformer embeddings
- The optimal semantic filtering threshold requires further exploration across diverse datasets

## Confidence

*High Confidence:* The overall methodology framework and use of transformer-based embeddings for semantic topic modeling are well-established approaches with strong theoretical foundations.

*Medium Confidence:* The specific combination of UMAP+HDBSCAN clustering and the semantic filtering mechanism shows promising results but requires more extensive validation across diverse datasets and parameter configurations.

*Low Confidence:* The claimed superiority over ChatGPT for topic modeling is based on limited comparisons and needs more comprehensive benchmarking.

## Next Checks

1. Conduct ablation studies comparing different clustering combinations (UMAP+k-means, t-SNE+HDBSCAN, etc.) to validate the chosen pipeline's effectiveness.

2. Perform sensitivity analysis on the semantic filtering threshold across multiple datasets to determine optimal parameter settings and robustness.

3. Test the model's scalability by running it on larger datasets (e.g., full Wikipedia corpus) to assess computational efficiency and clustering quality at scale.