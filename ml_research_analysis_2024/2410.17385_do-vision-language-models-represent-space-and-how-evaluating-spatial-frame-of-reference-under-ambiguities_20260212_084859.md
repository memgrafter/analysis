---
ver: rpa2
title: Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame
  of Reference Under Ambiguities
arxiv_id: '2410.17385'
source_url: https://arxiv.org/abs/2410.17385
tags:
- probability
- angle
- spatial
- language
- reference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COMFORT, a framework to evaluate spatial
  reasoning in vision-language models (VLMs) by focusing on frame-of-reference (FoR)
  ambiguities. COMFORT uses synthetic 3D scenes with objects positioned along rotational
  paths to test how well VLMs understand spatial relations under varying perspectives.
---

# Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities

## Quick Facts
- **arXiv ID:** 2410.17385
- **Source URL:** https://arxiv.org/abs/2410.17385
- **Reference count:** 40
- **Primary result:** Most VLMs prefer egocentric relative FoR with reflected coordinate transformation, struggle with robustness/consistency, and favor English conventions in multilingual settings.

## Executive Summary
This paper introduces COMFORT, a framework to evaluate spatial reasoning in vision-language models (VLMs) by focusing on frame-of-reference (FoR) ambiguities. COMFORT uses synthetic 3D scenes with objects positioned along rotational paths to test how well VLMs understand spatial relations under varying perspectives. The study evaluates nine VLMs across 109 languages, measuring accuracy, consistency, and robustness in spatial reasoning. Results show that most VLMs prefer an egocentric relative FoR with reflected coordinate transformation, aligning with English conventions. However, they struggle with robustness, consistency, and adapting to non-egocentric FoRs. Multilingual models also tend to favor English FoR conventions, raising concerns about cross-cultural bias. The findings highlight the need for better spatial reasoning in VLMs and emphasize the importance of considering cultural diversity in language models.

## Method Summary
The study evaluates VLMs using COMFORT, a framework that generates synthetic 3D scenes with objects positioned along rotational trajectories (36 angles from 0° to 350° in 10° increments). The evaluation includes object-level variations (colors, sizes, shapes), scene-level variations (camera positions, distractors), and multilingual prompts in 109 languages. Nine VLMs (InstructBLIP, LLaVA, mBLIP-BLOOMZ, GLaMM, XComposer2, MiniCPM-V, GPT-4o) are tested without additional training. The framework measures accuracy, region parsing error (εhemi and εcos), prediction noise (η), standard deviation (σ), spatial symmetric consistency (csym), and spatial opposite consistency (copp) to evaluate robustness, consistency, and adaptability to different FoRs.

## Key Results
- Most VLMs prefer reflected coordinate transformation convention, similar to English speakers
- VLMs demonstrate significant preference towards egocentric relative FoR across languages
- Multilingual models tend to favor English FoR conventions, showing cross-cultural bias
- VLMs exhibit poor robustness and consistency, lacking flexibility to accommodate multiple FoRs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Spatial reasoning in VLMs is mediated by latent reference frame transformations encoded during vision-language training.
- **Mechanism:** The model implicitly learns to map visual input into a spatial coordinate system (egocentric or intrinsic) and apply a coordinate transformation (translation, rotation, or reflection) when resolving ambiguous spatial relations.
- **Core assumption:** Vision-language training data contain enough variation in viewpoints and spatial descriptions to induce a latent frame-of-reference (FoR) representation that generalizes to unseen scenes.
- **Evidence anchors:**
  - [abstract] "Despite showing some alignment with English conventions in resolving ambiguities, our experiments reveal significant shortcomings of VLMs: notably, the models (1) exhibit poor robustness and consistency..."
  - [section] "Most VLMs prefer reflected coordinate transformation convention... Almost all VLMs demonstrate a significant preference towards the egocentric relative FoR similar to English..."
  - [corpus] Weak: Related papers mention "perspective taking" and "viewpoint transformations," but no direct mechanistic proof that VLMs encode FoR transformations in latent space.
- **Break condition:** If training data lack sufficient diversity in viewpoints or if the model architecture cannot represent coordinate transformations (e.g., lacks positional encodings aligned with FoR), the latent FoR mechanism fails.

### Mechanism 2
- **Claim:** Multilingual VLMs default to English spatial conventions when resolving ambiguities across languages.
- **Mechanism:** During multilingual pretraining and instruction tuning, English dominates the spatial reasoning conventions because English captions or translations are more prevalent or better aligned with the visual content, leading to cross-lingual transfer bias.
- **Core assumption:** The training corpus has an English-centric bias in spatial descriptions, and the model lacks explicit mechanisms to preserve language-specific FoR conventions.
- **Evidence anchors:**
  - [abstract] "...multilingual models also tend to favor English FoR conventions, raising concerns about cross-cultural bias."
  - [section] "Although human speakers of these languages have different preferred coordinate transformation conventions, the English convention of reflected projection is observed for both Tamil and Hausa."
  - [corpus] Weak: Related work on multilingual VLMs mentions "cross-lingual transfer" but not specifically FoR dominance; corpus lacks direct evidence of English-centric spatial conventions in training data.
- **Break condition:** If training data include balanced, high-quality spatial descriptions in each target language, or if the model is explicitly fine-tuned to preserve language-specific conventions, the English dominance breaks.

### Mechanism 3
- **Claim:** Spatial consistency in VLMs is limited by the smoothness and robustness of the probability mapping from visual angles to spatial relation acceptance.
- **Mechanism:** The model assigns probabilities to spatial relations that should vary smoothly with the deviation angle; inconsistency arises when this mapping is noisy or non-monotonic, indicating fragile spatial representations.
- **Core assumption:** A well-formed spatial representation should produce a low-frequency (smooth) probability curve over the continuous rotation angle, reflecting consistent spatial reasoning.
- **Evidence anchors:**
  - [abstract] "...the models (1) exhibit poor robustness and consistency, (2) lack the flexibility to accommodate multiple FoRs..."
  - [section] "Standard deviation... Prediction noise... We measure the noise by the RMSE... η... between the predicted probability and a Butterworth Low Pass Filter (LPF)."
  - [corpus] Weak: Related benchmarks mention "consistency" and "robustness" but do not analyze the smoothness of the probability-angle mapping as a diagnostic.
- **Break condition:** If the model's internal representations are smoothed (e.g., via explicit geometric constraints or better pretraining objectives), the noisy probability mapping breaks down.

## Foundational Learning

- **Concept:** Frames of reference (FoR) in spatial language.
  - Why needed here: The paper evaluates how VLMs resolve spatial ambiguities by adopting different FoRs (egocentric, addressee-centered, intrinsic); understanding FoR is essential to interpret results.
  - Quick check question: What are the three main types of frames of reference identified by Levinson (1996) for describing spatial relations?

- **Concept:** Coordinate transformation conventions (translation, rotation, reflection) in relative FoRs.
  - Why needed here: The experiments test whether VLMs prefer reflected transformation (English) or other transformations; knowing these conventions is needed to understand model preferences.
  - Quick check question: Which coordinate transformation does English typically use when projecting a speaker's viewpoint onto a relatum in a relative FoR?

- **Concept:** Spatial continuity and acceptability regions.
  - Why needed here: The dataset moves referents along a continuous rotational path; understanding that spatial relations have fuzzy boundaries (not just discrete axes) is key to interpreting accuracy and consistency metrics.
  - Quick check question: How is the acceptable region for a spatial relation like "in front of" defined in the COMFORT evaluation?

## Architecture Onboarding

- **Component map:** Input encoder (image + text prompt) → multimodal fusion (vision-language attention) → latent spatial reasoning module → output classifier (Yes/No for spatial relation)
- **Critical path:** Image encoding → spatial relation grounding → FoR inference → probability mapping over deviation angle → final decision
- **Design tradeoffs:** Trade between model size (larger models may encode FoR better) and robustness (smaller models may overfit to specific viewpoints); trade between pretraining data diversity (multilingual vs. English-only) and cross-lingual FoR preservation
- **Failure signatures:** Low accuracy but high consistency may indicate rigid FoR encoding; high accuracy but low consistency may indicate overfitting to specific angles; multilingual failure may indicate English dominance
- **First 3 experiments:**
  1. Probe the model's latent representations for FoR encoding by visualizing attention over viewpoint and spatial relation features
  2. Test the smoothness of the probability-angle mapping by sampling densely along the rotational path and fitting a low-pass filter
  3. Evaluate cross-lingual FoR preferences by translating prompts into multiple languages and comparing model outputs to human speaker conventions

## Open Questions the Paper Calls Out
None

## Limitations
- The mechanistic understanding of how VLMs encode spatial reasoning is primarily inferential rather than direct
- The multilingual analysis doesn't fully characterize training data composition or explain why English conventions dominate
- Synthetic evaluation scenes may not fully capture real-world spatial reasoning complexity

## Confidence
- **High confidence**: VLMs show poor robustness and consistency in spatial reasoning; most VLMs prefer egocentric relative FoR with reflected coordinate transformation; multilingual models tend to favor English FoR conventions
- **Medium confidence**: The latent reference frame transformation mechanism accurately explains VLM spatial reasoning; English dominance in multilingual models is primarily due to training data bias rather than architectural limitations
- **Low confidence**: The specific coordinate transformation conventions (translation, rotation, reflection) are explicitly encoded in VLM latent representations; the synthetic evaluation scenarios fully capture real-world spatial reasoning complexity

## Next Checks
1. Probe internal representations using attention visualization and feature activation analysis to directly examine FoR transformations in latent representations
2. Analyze training data distribution across languages and spatial descriptions to quantify English-centric bias and systematically vary this composition
3. Extend evaluation to real-world images and videos with natural spatial language descriptions to test generalization beyond synthetic scenes