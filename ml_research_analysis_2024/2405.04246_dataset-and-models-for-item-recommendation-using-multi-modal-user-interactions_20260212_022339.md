---
ver: rpa2
title: Dataset and Models for Item Recommendation Using Multi-Modal User Interactions
arxiv_id: '2405.04246'
source_url: https://arxiv.org/abs/2405.04246
tags:
- user
- modalities
- conversations
- users
- sessions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles multi-modal user interactions for item recommendation
  in the insurance domain, where users engage through both website and call center.
  The key challenge is naturally occurring incomplete modalities, as not all users
  interact through all channels.
---

# Dataset and Models for Item Recommendation Using Multi-Modal User Interactions

## Quick Facts
- arXiv ID: 2405.04246
- Source URL: https://arxiv.org/abs/2405.04246
- Reference count: 38
- Primary result: Latent Feature model learns shared representations across web sessions and call center conversations, achieving 1.5% improvement in Hit Rate@3 over strongest baseline

## Executive Summary
This paper addresses the challenge of item recommendation using multi-modal user interactions, specifically combining web session data and call center conversations in the insurance domain. The key innovation is handling naturally occurring incomplete modalities, where not all users interact through both channels. The authors introduce a novel real-world dataset and propose methods to map both interaction types into a common feature space. Their proposed Latent Feature model learns shared latent representations across modalities and demonstrates significant performance improvements over existing approaches.

## Method Summary
The authors develop a framework for combining heterogeneous user interaction data from website sessions and call center conversations. They extract features from both modalities - web sessions are represented as sequences of page views and actions, while conversations are transcribed and processed to capture intent and topic information. To handle the incomplete nature of multi-modal data, they propose a Latent Feature model that learns shared latent representations across both interaction types. This model is trained to predict user preferences while learning to map both modalities into a common embedding space, allowing for effective fusion even when one modality is missing for certain users.

## Key Results
- The Latent Feature model achieves over 1.5% improvement in Hit Rate@3 compared to the strongest baseline
- Two modalities contain complementary information, with consistent improvements when both are used together
- The approach effectively handles incomplete modalities where users only interact through one channel
- Performance gains are particularly notable for users with limited interaction history in either modality

## Why This Works (Mechanism)
The paper demonstrates that web sessions and call center conversations capture different aspects of user intent and preferences. Web sessions reveal browsing patterns and product exploration behavior, while conversations expose explicit needs, concerns, and preferences expressed directly to agents. By learning shared latent representations, the model can transfer knowledge between modalities - frequent web interactions can inform recommendations for users who primarily call, and vice versa. The incomplete modality handling is crucial because real-world data naturally exhibits this pattern, and forcing users into complete modality pairs would exclude valuable data.

## Foundational Learning
- Multi-modal learning: Combining information from different sources to create richer representations - needed to leverage both web and conversation data; quick check: verify each modality contributes unique signal
- Incomplete modality handling: Designing models that work when not all data types are present for every user - needed because real-world data is naturally incomplete; quick check: test performance when one modality is absent
- Representation learning: Learning embeddings that capture semantic meaning - needed to map heterogeneous data into common space; quick check: visualize learned embeddings for different user types

## Architecture Onboarding

Component map: Raw interaction data -> Feature extraction -> Incomplete modality handling -> Shared latent space -> Recommendation predictions

Critical path: The model learns to map both web sessions and conversations into a shared latent space through a joint training objective. During inference, it can use either modality alone or both together, with the shared space enabling knowledge transfer between modalities.

Design tradeoffs: The paper trades model complexity for better handling of incomplete modalities and richer representations. Simpler approaches like concatenation or separate models underperform because they can't effectively transfer knowledge between modalities or handle missing data gracefully.

Failure signatures: The model may struggle when both modalities provide conflicting signals about user preferences, or when the feature extraction fails to capture important aspects of either interaction type. Performance may degrade for extremely rare items that lack sufficient interaction signals.

First experiments:
1. Test the model with only web sessions and only conversations separately to establish baseline performance
2. Evaluate on complete vs incomplete modality pairs to verify the handling of missing data
3. Perform cross-validation with different random seeds to assess stability of improvements

## Open Questions the Paper Calls Out
None specified in the provided materials.

## Limitations
- Results are based on a single proprietary dataset from one insurance company, limiting generalizability
- Lack of detailed dataset statistics makes it difficult to assess scalability and diversity
- No thorough exploration of potential biases in data or model performance across different user segments
- Absence of detailed error analysis to understand model failure modes

## Confidence

| Claim | Confidence |
|-------|------------|
| Web and conversation modalities contain complementary information | High |
| Latent Feature model significantly outperforms baselines | Medium |
| Results generalize to other domains/companies | Low |

## Next Checks

1. Replicate the study using publicly available datasets from different domains (e-commerce, media streaming) to assess generalizability and validate claims about complementary information across modalities.

2. Conduct an ablation study to determine the individual contribution of each modality and test model performance when one modality is completely absent.

3. Perform detailed bias analysis to identify potential biases in the dataset and model predictions, focusing on underrepresented user segments and item categories.