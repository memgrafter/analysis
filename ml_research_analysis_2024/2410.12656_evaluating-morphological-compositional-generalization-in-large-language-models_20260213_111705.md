---
ver: rpa2
title: Evaluating Morphological Compositional Generalization in Large Language Models
arxiv_id: '2410.12656'
source_url: https://arxiv.org/abs/2410.12656
tags:
- word
- systematicity
- root
- turkish
- morphological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the morphological compositional generalization
  abilities of large language models (LLMs) on agglutinative languages Turkish and
  Finnish. The authors designed novel generative and discriminative tasks to evaluate
  morphological productivity and systematicity, respectively.
---

# Evaluating Morphological Compositional Generalization in Large Language Models

## Quick Facts
- **arXiv ID**: 2410.12656
- **Source URL**: https://arxiv.org/abs/2410.12656
- **Reference count**: 40
- **Primary result**: LLMs struggle significantly with morphological generalization in Turkish and Finnish, particularly for novel word roots, with performance declining sharply as morphological complexity increases

## Executive Summary
This study investigates whether large language models can generalize morphological rules to novel word forms in agglutinative languages like Turkish and Finnish. The authors designed novel generative (productivity) and discriminative (systematicity) tasks to evaluate models' ability to compose morphemes into valid words and consistently apply morphological rules. Results show that while models can identify individual morphological combinations better than chance, they struggle significantly with morphological generalization, especially when applied to novel word roots. Performance drops sharply as morphological complexity increases, and models lack the systematicity observed in human language learners.

## Method Summary
The study evaluates GPT-4, Gemini-1.5, Aya-23, and Qwen-2.5 on morphologically segmented test suites for Turkish and Finnish. Two novel tasks are designed: a generative productivity task requiring models to construct valid words from morpheme sets, and a discriminative systematicity task requiring binary classification of grammaticality. Evaluation uses few-shot in-context learning with 1, 3, and 5 shots, greedy decoding, and both in-distribution (ID) and out-of-distribution (OOD) test suites containing novel word roots. Performance is measured using Exact Match accuracy for productivity and Macro-F1 plus Coherence scores for systematicity, compared against human baselines.

## Key Results
- LLMs show sharp performance decline on productivity tasks as morphological complexity increases, plummeting to nearly zero for complex derivations
- For systematicity tasks, models perform above chance but exhibit inconsistent application of rules, resulting in low coherence scores
- Performance gaps between ID and OOD word roots are significantly larger for models (10-20%) compared to humans (1-3%), indicating lack of true morphological generalization
- Coherence scores show negative correlation with morphological complexity, revealing inconsistent rule application across derivations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Models fail at morphological productivity because they cannot systematically compose morphemes into novel forms, especially for unseen roots.
- **Mechanism:** Models memorize surface-level word forms and their contexts but do not learn compositional rules for combining morphemes. When tasked with deriving words from novel roots, they either fail to generate a valid form or produce an unfaithful output that ignores the task constraints.
- **Core assumption:** Morphological productivity requires understanding both the syntactic order of morphemes and the semantic compatibility between root and affixes.
- **Evidence anchors:**
  - [abstract] "LLMs struggle with morphological compositional generalization particularly when applied to novel word roots, with performance declining sharply as morphological complexity increases."
  - [section 5.1] "On the productivity task, we observe a sharp downward trend (plummeting to nearly zero) in performance as the number of morphemes increases for both ID and OOD test suites."
- **Break condition:** If the model could learn explicit morpheme composition rules or access morpheme-level tokenization, it might overcome this failure.

### Mechanism 2
- **Claim:** Models exhibit inconsistent systematicity because they rely on surface-level patterns rather than robust morphological rules, leading to high variance across similar inputs.
- **Mechanism:** When judging the grammaticality of derivations, models sometimes apply shortcuts (e.g., detecting vowel harmony violations) but often fail to consistently apply morphological rules across all possible derivations from the same morpheme set. This leads to low coherence scores.
- **Core assumption:** Systematicity requires consistent application of grammatical rules across all valid combinations of morphemes.
- **Evidence anchors:**
  - [abstract] "While models can identify individual morphological combinations better than chance, their performance lacks systematicity, leading to significant accuracy gaps compared to humans."
  - [section 5.1] "On the systematicity task, Macro-F1 scores for ID and OOD remain mostly unchanged as complexity increases, but coherence scores show a negative correlation with the increasing morphological complexity."
- **Break condition:** If the model could learn a complete set of morphological rules and apply them consistently, systematicity performance would improve.

### Mechanism 3
- **Claim:** The sharp performance drop for OOD word roots indicates that models do not generalize morphological rules to novel vocabulary, instead relying on memorization of training data.
- **Mechanism:** Models are exposed to many inflected forms during training but do not abstract the underlying morphological rules. When presented with novel roots, they cannot apply these rules, leading to a large performance gap between ID and OOD settings.
- **Core assumption:** True morphological generalization requires the ability to apply learned rules to unseen vocabulary.
- **Evidence anchors:**
  - [abstract] "Our analysis shows that morphological productivity, especially when applied to novel word roots is highly challenging for LLMs."
  - [section 5.1] "The GPT-4 performance gap between the ID and OOD test suites for both languages is much larger than the human gap ( â‰ˆ 10% vs. 3% in Turkish and 1.7% in Finnish respectively for ID and OOD data)."
- **Break condition:** If the model could learn and apply morphological rules independently of specific vocabulary, the ID-OOD gap would narrow.

## Foundational Learning

- **Concept:** Compositional generalization in language models
  - **Why needed here:** The study investigates whether LLMs can generalize morphological rules to novel word forms, which is a key aspect of compositional generalization.
  - **Quick check question:** Can you explain the difference between systematicity and productivity in the context of compositional generalization?

- **Concept:** Morphological analysis and segmentation
  - **Why needed here:** The tasks require understanding how words are composed of morphemes (roots and affixes) and how these morphemes combine to form valid words.
  - **Quick check question:** What is the difference between inflectional and derivational morphology, and how does each relate to the tasks in this study?

- **Concept:** Tokenization and its impact on morphological processing
  - **Why needed here:** The study explores whether subword tokenization (e.g., BPE) hinders morphological generalization by breaking morphemes into non-meaningful units.
  - **Quick check question:** How might character-level tokenization differ from subword tokenization in its impact on morphological generalization tasks?

## Architecture Onboarding

- **Component map:** Data preprocessing -> Morphological segmentation -> Task design -> Few-shot evaluation -> Performance analysis -> Error analysis
- **Critical path:**
  1. Prepare morphologically segmented test suites for Turkish and Finnish
  2. Design and implement productivity and systematicity tasks
  3. Evaluate models using few-shot learning and analyze performance
  4. Conduct error analysis and investigate failure modes

- **Design tradeoffs:**
  - Using English prompts for non-English tasks may introduce code-switching challenges but ensures consistency across languages
  - Focusing on agglutinative languages provides a clear test of morphological generalization but may limit generalizability to other language types
  - Using few-shot learning instead of fine-tuning allows for quick evaluation but may not fully capture the model's capabilities

- **Failure signatures:**
  - Sharp performance drop for OOD word roots indicates lack of morphological rule generalization
  - Low coherence scores in systematicity tasks indicate inconsistent application of morphological rules
  - High rates of unfaithful generations in productivity tasks indicate failure to follow task constraints

- **First 3 experiments:**
  1. Replicate the productivity task with a simple LSTM model to establish a baseline for comparison with LLMs
  2. Implement a morpheme-level tokenizer and evaluate its impact on morphological generalization performance
  3. Design a minimal pair test to isolate the effect of specific morphological rules (e.g., vowel harmony) on model performance

## Open Questions the Paper Calls Out

- **Open Question 1:** How do token-level models compare to subword-tokenized models in morphological generalization tasks?
  - **Basis in paper:** [explicit] "we also analyze the GPT-4 chain-of-thought answers on the Turkish data and reveal several failure modes such as sequential dependency errors, semantic misinterpretations, lack of grammatical knowledge, and unfaithful reasoning"
  - **Why unresolved:** The paper only compares morphologically aligned vs tokenizer-aligned morphemes for GPT-4, but does not examine whether character-level tokenizers would perform better for agglutinative languages.
  - **What evidence would resolve it:** Direct comparison of subword-level vs character-level tokenizers on the same morphological generalization tasks across multiple languages.

- **Open Question 2:** Does morphological systematicity improve with larger context windows in LLMs?
  - **Basis in paper:** [inferred] "we do also experiment with more realistic versions where we provide the model a sentence as an additional context" and found "significant decrease in performance on the systematicity task especially for smaller models"
  - **Why unresolved:** The paper only tested context with fixed-length sentences and found performance degradation, but did not explore whether very large context windows might eventually help systematicity.
  - **What evidence would resolve it:** Experiments varying context window sizes systematically while measuring systematicity performance across different model scales.

- **Open Question 3:** Are the observed morphological generalization failures due to insufficient training data or fundamental architectural limitations?
  - **Basis in paper:** [explicit] "While humans learn their native language robustly and can easily produce and identify long novel words while models are quite sensitive to the morphological (E-) complexity"
  - **Why unresolved:** The paper demonstrates performance gaps but cannot distinguish whether these stem from training data limitations or inherent model architecture constraints.
  - **What evidence would resolve it:** Training models with dramatically expanded morphological data and comparing against models with architectural modifications specifically designed for morphology.

## Limitations

- The study uses English prompts for non-English languages, which may introduce confounding factors in model performance
- Small evaluation sample size (10 examples per condition) limits statistical power and precision of performance estimates
- Focus exclusively on agglutinative languages may limit generalizability to other morphological typologies
- Reliance on automated morphological segmentation tools may introduce noise, particularly for languages with multiple valid segmentations

## Confidence

- **High confidence**: The general finding that LLMs struggle with morphological generalization, particularly for novel word roots. This is supported by consistent patterns across multiple models and languages.
- **Medium confidence**: The specific quantitative performance gaps between ID and OOD conditions, as the small sample size limits precision of these estimates.
- **Medium confidence**: The conclusion that current models lack systematicity in morphological processing, though this could be partially attributed to prompt engineering challenges.

## Next Checks

1. **Replication with expanded test suites**: Conduct experiments with 5x more evaluation examples per condition to improve statistical reliability of performance gap estimates and test the robustness of observed trends.

2. **Cross-linguistic validation**: Evaluate the same models on morphologically rich languages with different typologies (e.g., fusional languages like Russian or Arabic) to determine whether the observed limitations are specific to agglutinative languages or represent a broader challenge.

3. **Ablation study on tokenization**: Compare model performance using different tokenization strategies (character-level, morpheme-level, and subword) on the same morphological tasks to isolate the impact of tokenization on generalization capabilities.