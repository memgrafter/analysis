---
ver: rpa2
title: 'TrojFlow: Flow Models are Natural Targets for Trojan Attacks'
arxiv_id: '2412.16512'
source_url: https://arxiv.org/abs/2412.16512
tags:
- backdoor
- attack
- trojan
- target
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TrojFlow, the first Trojan attack on flow-based
  generative models (FMs). The authors leverage FMs' ability to fit arbitrary distributions
  to establish point-to-point mappings between triggers and target images.
---

# TrojFlow: Flow Models are Natural Targets for Trojan Attacks

## Quick Facts
- arXiv ID: 2412.16512
- Source URL: https://arxiv.org/abs/2412.16512
- Authors: Zhengyang Qi; Xiaohua Xu
- Reference count: 29
- Key outcome: First Trojan attack on flow-based generative models achieving >90% attack success rate with minimal FID degradation on CIFAR-10

## Executive Summary
This paper introduces TrojFlow, the first Trojan attack specifically targeting flow-based generative models (FMs). The attack exploits FMs' unique ability to fit arbitrary distributions through point-to-point mappings between triggers and target images. By leveraging Perturbation-Driven Training, the attack successfully bypasses existing diffusion model defenses while maintaining high attack success rates (>90%) with minimal impact on benign generation quality (FID degradation of only 0.2-0.6). The attack converges within 20k training steps, demonstrating superior efficiency compared to diffusion model baselines.

## Method Summary
TrojFlow implements Trojan attacks on flow models by establishing precise point-to-point mappings between trigger distributions and target images. The method fine-tunes a Rectified Flow model using dual objectives: maintaining clean generation capability while learning backdoor mappings. Perturbation-Driven Training remaps nearby distributions to clean outputs, effectively bypassing perturbation-based backdoor detection. The attack operates through a velocity field that directly maps trigger inputs to desired target outputs, with training converging within 20k-40k steps depending on the attack setting (D2I or Din).

## Key Results
- Achieves >90% attack success rate on CIFAR-10 with only 0.2-0.6 FID degradation compared to base models
- Successfully bypasses existing diffusion model defenses (UFID and TERD) through Perturbation-Driven Training
- Converges within 20k training steps, faster than diffusion model baselines
- Maintains low MSE (<0.05) between generated and target images under D2I attacks with 1-10 trigger-target pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Flow models can be trojaned by exploiting their ability to fit arbitrary distributions through point-to-point mappings
- Mechanism: The attack leverages the unique property of flow models to establish precise mappings between trigger distributions and target images. By training the velocity field to map specific backdoor noise inputs directly to target outputs, the model learns to generate desired content when triggered
- Core assumption: The flow model's ability to fit arbitrary distributions extends to discrete point-to-point mappings between specific trigger images and target images
- Evidence anchors:
  - [abstract] "the unique ability of FMs to fit any two arbitrary distributions significantly simplifies the training and sampling setups for attacking FMs"
  - [section III.A] "the backdoor noise (trigger) in our setting can be either a distribution or a single image, creating a point-to-point mapping"
  - [corpus] Weak evidence - no direct corpus support for point-to-point mapping attacks on flow models specifically
- Break condition: If the flow model's capacity is insufficient to learn the precise mapping between triggers and targets, or if the training process cannot converge on the desired point-to-point relationship

### Mechanism 2
- Claim: Existing diffusion model defenses fail against flow model trojan attacks
- Mechanism: The attack bypasses detection by implementing Perturbation-Driven Training (PDT) that remaps nearby distributions to clean outputs while preserving trigger-to-target mappings. This exploits the fact that diffusion model defenses like UFID rely on detecting perturbations that significantly alter clean outputs but not trojan outputs
- Evidence anchors:
  - [abstract] "demonstrate that existing defense methods for DMs can effectively defend against our proposed attack scenarios"
  - [section III.C] "we implement additional Perturbation-Driven Training (PDT), which remaps the distribution around the trigger to clean images while preserving the transport path from the trigger to the target"
  - [corpus] Moderate evidence - related work on diffusion model defenses exists but specific adaptation to flow models is not well-documented
- Break condition: If defenses evolve to examine the velocity field structure itself rather than just input-output relationships, or if they implement distribution-level analysis that can detect the remapped regions

### Mechanism 3
- Claim: Flow models offer more efficient trojan injection than diffusion models
- Mechanism: The attack converges within 20k training steps compared to diffusion model baselines, attributed to flow models' inherently more efficient fitting capability. This efficiency stems from using deterministic ODEs rather than stochastic differential equations
- Evidence anchors:
  - [section IV.B] "TrojFlow achieves good attack performance within 20k steps and converges around 40k steps, demonstrating a faster backdoor injection efficiency compared to TrojDiff"
  - [section I] "DMs often require hundreds to thousands of time steps to generate high-quality images, making them more computationally expensive compared to other generative models like GAN or VAE"
  - [corpus] Weak evidence - limited corpus data on comparative efficiency of trojan attacks between flow and diffusion models
- Break condition: If the computational efficiency advantage diminishes with larger models or more complex target distributions, or if diffusion models develop more efficient training methods that close the gap

## Foundational Learning

- Concept: Flow-based generative models and their velocity field formulation
  - Why needed here: Understanding how flow models map distributions through velocity fields is essential to grasp how the attack exploits this property
  - Quick check question: How does a flow model's velocity field differ from a diffusion model's reverse diffusion process?

- Concept: Backdoor attack mechanics in generative models
  - Why needed here: The attack relies on understanding how to insert malicious functionality that activates with specific inputs
  - Quick check question: What distinguishes a backdoor attack from a standard adversarial attack in generative models?

- Concept: Distribution fitting and point-to-point mapping
  - Why needed here: The attack's effectiveness depends on the model's ability to learn precise mappings between specific inputs and outputs
  - Quick check question: Why is the ability to fit arbitrary distributions particularly relevant for backdoor attacks?

## Architecture Onboarding

- Component map: Base flow model (Rectified Flow) -> Trojan training pipeline -> Perturbation-Driven Training module -> Evaluation framework

- Critical path: 1. Train base flow model on clean data 2. Implement trojan training with trigger-target pairs 3. Apply PDT to bypass perturbation-based defenses 4. Evaluate attack success and benign performance 5. Test against existing defense mechanisms

- Design tradeoffs:
  - Training efficiency vs. attack success rate: Faster convergence may sacrifice precision
  - Trigger visibility vs. attack reliability: More subtle triggers may be harder to activate consistently
  - Defense evasion vs. model utility: Stronger defenses may require more aggressive PDT that degrades clean generation

- Failure signatures:
  - High MSE between generated and target images indicates failed trojan injection
  - Increased FID on benign samples suggests model degradation
  - Successful defense detection reveals attack vulnerabilities

- First 3 experiments:
  1. Baseline test: Train flow model with no trojan to establish clean performance metrics
  2. Simple trojan test: Insert single trigger-target pair without PDT to verify basic attack mechanism
  3. Defense test: Apply UFID-style perturbation analysis to detect trojaned models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the efficiency of Trojan attacks on FMs compare to DMs in terms of training steps required for convergence?
- Basis in paper: [explicit] The paper states that TrojFlow achieves good attack performance within 20k steps and converges around 40k steps under the Din attack, demonstrating faster backdoor injection efficiency compared to TrojDiff [15], which requires 85.9 to 90.10 steps for convergence.
- Why unresolved: While the paper provides a comparison between TrojFlow and TrojDiff, it does not provide a comprehensive analysis of the efficiency of Trojan attacks across different types of FMs and DMs.
- What evidence would resolve it: A systematic comparison of the training steps required for convergence of Trojan attacks on various FMs and DMs, including different attack settings and target distributions.

### Open Question 2
- Question: Can existing defense mechanisms for DMs be effectively adapted to defend against Trojan attacks on FMs?
- Basis in paper: [explicit] The paper investigates two representative defense works for DMs, TERD [18] and UFID [17], and demonstrates that existing defense strategies for DMs do not effectively defend against Trojan attacks on FMs.
- Why unresolved: The paper only evaluates two specific defense mechanisms and does not explore the potential for adapting or developing new defense strategies specifically for FMs.
- What evidence would resolve it: A comprehensive evaluation of various defense mechanisms for DMs, including their potential for adaptation to FMs, as well as the development and testing of new defense strategies specifically designed for FMs.

### Open Question 3
- Question: How does the point-to-point mapping capability of FMs impact the effectiveness of Trojan attacks compared to distribution-to-distribution mapping?
- Basis in paper: [explicit] The paper proposes establishing a point-to-point mapping on FMs, allowing for more flexibility in backdoor insertion and achieving Trojan attacks with minimal visibility and modification.
- Why unresolved: The paper demonstrates the effectiveness of point-to-point mapping in bypassing perturbation-based backdoor detection methods, but does not provide a comprehensive analysis of the trade-offs and limitations of this approach compared to distribution-to-distribution mapping.
- What evidence would resolve it: A comparative analysis of the effectiveness, efficiency, and limitations of point-to-point and distribution-to-distribution mapping approaches in Trojan attacks on FMs, including their impact on attack success rates, detection evasion, and potential for generalization to other attack scenarios.

## Limitations
- Limited evaluation scope: Only tested on CIFAR-10 and CelebA datasets, which are relatively small-scale
- Single architecture dependency: Attack methodology only verified on Rectified Flow model, may not generalize to all flow-based models
- Defense bypass specificity: Perturbation-Driven Training only tested against UFID-style defenses, effectiveness against broader defense strategies unknown

## Confidence
- Medium confidence in core claims about flow model trojan vulnerability and attack success rates
- Medium confidence in efficiency advantage over diffusion models, though scalability needs validation
- Medium confidence in defense bypass effectiveness, limited to specific perturbation-based detection methods

## Next Checks
1. **Defense robustness test**: Apply the attack against a broader suite of detection methods beyond UFID, including those that analyze the velocity field's mathematical properties rather than just input-output behavior.

2. **Scalability evaluation**: Replicate the attack on larger datasets (e.g., ImageNet) and with larger flow models to assess whether the efficiency advantage and attack success rates hold at scale.

3. **Cross-architecture generalization**: Test whether the attack methodology transfers to other flow-based generative models beyond Rectified Flow, such as FFJORD or GLOW, to validate the claimed universality of the approach.