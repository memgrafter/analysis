---
ver: rpa2
title: Causal Graph Discovery with Retrieval-Augmented Generation based Large Language
  Models
arxiv_id: '2402.15301'
source_url: https://arxiv.org/abs/2402.15301
tags:
- causal
- lacr
- association
- graph
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel method for causal graph discovery
  using retrieval-augmented large language models (LLMs). Traditional causal graph
  recovery methods rely on statistical estimation or individual expertise, which can
  be biased or limited.
---

# Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models

## Quick Facts
- arXiv ID: 2402.15301
- Source URL: https://arxiv.org/abs/2402.15301
- Authors: Yuzhe Zhang; Yipeng Zhang; Yidong Gan; Lina Yao; Chen Wang
- Reference count: 31
- Primary result: Novel method using retrieval-augmented LLMs for causal graph discovery, outperforming other LLM-based approaches on benchmark datasets

## Executive Summary
This paper introduces LACR (LLM Assisted Causal Recovery), a novel method for causal graph discovery that leverages retrieval-augmented large language models. The approach decomposes complex causal reasoning into simpler associational reasoning steps, using constraint-based prompts and scientific literature retrieval to verify causal relationships. Experiments demonstrate improved performance over traditional methods and other LLM-based approaches across multiple benchmark datasets.

## Method Summary
LACR uses a two-phase approach for causal graph discovery: (1) Edge existence verification using constraint-based causal prompts and retrieval-augmented generation to determine the graph skeleton, and (2) Edge orientation using direct causal prompts. The method retrieves scientific documents relevant to variable pairs and aggregates responses from multiple knowledge sources using a voting mechanism. LACR leverages both the compressed knowledge within LLMs and external scientific literature to extract associational relationships and verify causality.

## Key Results
- LACR achieves higher adjacency precision, recall, and F1 scores compared to other LLM-based methods
- The method demonstrates improved performance on benchmark datasets (ASIA, SACHS, CORONARY)
- LACR shows sensitivity to new evidence in literature, enabling updates to causal graphs
- Retrieval-augmented generation enhances the reliability of associational reasoning through domain-specific evidence

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LACR reduces causal reasoning complexity by decomposing it into a series of simple associational reasoning steps.
- **Mechanism**: Instead of directly querying the LLM to determine causal edges and directions, LACR first uses constraint-based causal prompts to extract conditional independence relationships. These simpler queries avoid the high complexity (O(2^n-2)) of full causal reasoning and leverage LLMs' stronger performance on associational tasks.
- **Core assumption**: LLMs can reliably perform associational reasoning when provided with clear instructions and relevant context.
- **Break condition**: If the LLM cannot reliably determine associational relationships even with simplified prompts, the method fails.

### Mechanism 2
- **Claim**: Retrieval-Augmented Generation (RAG) enhances the reliability of LACR's associational reasoning by providing domain-specific evidence.
- **Mechanism**: LACR retrieves scientific documents relevant to the variables of interest and uses them as knowledge bases for the LLM's associational reasoning. This grounds the LLM's responses in empirical evidence rather than general knowledge.
- **Core assumption**: Scientific literature provides reliable evidence of associational relationships between variables.
- **Break condition**: If retrieved documents are irrelevant, low-quality, or do not contain evidence of associational relationships, RAG cannot enhance reliability.

### Mechanism 3
- **Claim**: The Wisdom of the Crowd principle improves the accuracy of LACR's causal graph recovery by aggregating multiple knowledge sources.
- **Mechanism**: LACR queries multiple knowledge bases (LLM background knowledge, retrieved documents, and statistical results) for each variable pair. It aggregates their responses using a voting mechanism, which tends to produce more accurate results than any single source.
- **Core assumption**: Different knowledge sources provide independent and high-quality information about associational relationships.
- **Break condition**: If knowledge sources are correlated or low-quality, the Wisdom of the Crowd effect diminishes or reverses.

## Foundational Learning

- **Concept**: Conditional independence and d-separation in causal graphs.
  - Why needed here: LACR's constraint-based causal prompts rely on understanding how conditional independence relates to causal structure.
  - Quick check question: If variables A and B are d-separated by C, what does this imply about their conditional independence?

- **Concept**: Retrieval-Augmented Generation (RAG) and its application to LLMs.
  - Why needed here: LACR uses RAG to ground LLMs' associational reasoning in domain-specific evidence.
  - Quick check question: How does RAG improve LLM performance on domain-specific tasks compared to using only general knowledge?

- **Concept**: Voting and aggregation methods for combining multiple information sources.
  - Why needed here: LACR aggregates responses from multiple knowledge bases using a voting mechanism.
  - Quick check question: Under what conditions does the Wisdom of the Crowd principle improve decision accuracy?

## Architecture Onboarding

- **Component map**: LACR 1 (Edge existence verification) -> LACR 2 (Orientation)
- **Critical path**: For each variable pair, LACR 1 queries the LLM multiple times using constraint-based causal prompts with different knowledge bases, then aggregates responses using voting to determine edge existence. LACR 2 queries the LLM to orient the edges in the skeleton.
- **Design tradeoffs**: Trades direct causal reasoning complexity for simpler associational reasoning; trades using only general LLM knowledge for using RAG to ground responses in domain-specific evidence.
- **Failure signatures**: Poor performance on domain-specific terms, outdated ground truth affecting validation, and low-quality or irrelevant retrieved documents.
- **First 3 experiments**:
  1. Test LACR 1 on a simple causal graph with known associational relationships to verify that it can correctly recover the skeleton.
  2. Test LACR 1 with and without RAG to measure the impact of domain-specific evidence on accuracy.
  3. Test LACR 1 with different voting thresholds to optimize the tradeoff between precision and recall.

## Open Questions the Paper Calls Out

- **Question**: How does the performance of LACR scale with the number of retrieved documents?
- **Basis in paper**: The paper mentions that LACR's performance tends to improve with more high-quality documents, citing the Wisdom of the Crowd principle.
- **Why unresolved**: The paper does not provide experiments or analysis on how LACR's performance varies with different numbers of retrieved documents.
- **What evidence would resolve it**: Experiments showing LACR's performance (e.g., F1 score, SHD) on a dataset with varying numbers of retrieved documents (e.g., 1, 5, 10, 20).

## Limitations

- Method's reliance on LLMs' ability to perform associational reasoning introduces uncertainty for complex causal structures
- Quality and relevance of retrieved scientific literature may vary significantly across domains
- Voting mechanism's effectiveness depends on independence and quality of multiple knowledge sources

## Confidence

- **High confidence**: The general approach of decomposing causal reasoning into associational steps and using RAG for evidence grounding is methodologically sound and supported by experimental results
- **Medium confidence**: Specific prompt templates and retrieval mechanisms may require fine-tuning for optimal performance across different domains
- **Medium confidence**: Sensitivity to new evidence and ability to update causal graphs is demonstrated but requires further validation with real-time literature updates

## Next Checks

1. Test LACR on synthetic causal graphs with known ground truth to systematically evaluate performance across varying graph complexity and domain specificity
2. Conduct ablation studies comparing LACR with and without RAG components to quantify the contribution of retrieval-augmented evidence to causal graph quality
3. Evaluate LACR's performance on recently published causal relationships to assess its ability to capture current scientific consensus and update existing causal graphs