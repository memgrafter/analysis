---
ver: rpa2
title: Guiding a Diffusion Model with a Bad Version of Itself
arxiv_id: '2406.02507'
source_url: https://arxiv.org/abs/2406.02507
tags:
- guidance
- diffusion
- autoguidance
- guiding
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces autoguidance, a novel approach for improving
  image generation quality in diffusion models by guiding the model with a smaller,
  less-trained version of itself, rather than using an unconditional model as in classifier-free
  guidance (CFG). This method effectively isolates the image quality improvement effect,
  avoiding the drawbacks of CFG such as reduced variation and over-simplification
  of image compositions.
---

# Guiding a Diffusion Model with a Bad Version of Itself

## Quick Facts
- arXiv ID: 2406.02507
- Source URL: https://arxiv.org/abs/2406.02507
- Authors: Tero Karras; Miika Aittala; Tuomas Kynkäänniemi; Jaakko Lehtinen; Timo Aila; Samuli Laine
- Reference count: 40
- Primary result: Autoguidance improves FID from 2.56 to 1.34 on ImageNet-512 using EDM2-S

## Executive Summary
This paper introduces autoguidance, a novel approach for improving image generation quality in diffusion models by guiding the model with a smaller, less-trained version of itself, rather than using an unconditional model as in classifier-free guidance (CFG). This method effectively isolates the image quality improvement effect, avoiding the drawbacks of CFG such as reduced variation and over-simplification of image compositions. The authors demonstrate that autoguidance leads to significant improvements in FID scores, setting new records on ImageNet-512 and ImageNet-64 datasets. For example, using EDM2-S on ImageNet-512, autoguidance improves FID from 2.56 to 1.34, surpassing the previous state-of-the-art. The method also works well for unconditional models, drastically improving their quality. Autoguidance offers a promising direction for future research in generative modeling, potentially leading to even better image generation results.

## Method Summary
Autoguidance is a novel approach for improving image generation quality in diffusion models by guiding the model with a smaller, less-trained version of itself. Unlike classifier-free guidance (CFG) which uses an unconditional model for guidance, autoguidance uses a conditional model trained on the same task but with lower quality. The key insight is that a less-trained model tends to generate simpler images with less detail and fewer objects, while a better-trained model produces more complex and detailed images. By guiding the better-trained model with the less-trained one, the method effectively isolates the image quality improvement effect without the drawbacks of CFG, such as reduced variation and over-simplification of image compositions. This is achieved by interpolating between the conditional and unconditional predictions during the diffusion sampling process, where the unconditional prediction comes from the less-trained model.

## Key Results
- Autoguidance improves FID from 2.56 to 1.34 on ImageNet-512 using EDM2-S
- Sets new state-of-the-art records on both ImageNet-512 and ImageNet-64 datasets
- Effectively improves quality of unconditional models when used with autoguidance

## Why This Works (Mechanism)
Autoguidance works by leveraging the complementary strengths of differently trained models within the same architecture. The less-trained model serves as a "simpler" prior that helps the better-trained model avoid over-complex outputs and mode collapse, while the better-trained model provides the high-quality details and diversity. This creates a form of implicit regularization where the guidance signal prevents the target model from producing artifacts or collapsing to modes that appear during later training stages. The interpolation between conditional and unconditional predictions during sampling allows for fine-grained control over the trade-off between quality and diversity.

## Foundational Learning
- **Diffusion models**: Sequential generative models that denoise data step-by-step - needed to understand the base architecture being modified
- **Classifier-free guidance (CFG)**: Technique for improving sample quality by interpolating between conditional and unconditional predictions - needed as the baseline comparison
- **Model distillation**: Transferring knowledge from one model to another - needed to understand how the less-trained model can guide the better-trained one
- **Feature disentanglement**: Separating different aspects of the learned representation - needed to understand how quality and diversity can be independently controlled
- **Implicit regularization**: Regularization that emerges from the learning dynamics rather than explicit penalty terms - needed to understand the mechanism behind quality improvements
- **FID score**: Fréquence Inception Distance, a metric for evaluating generative model quality - needed to interpret the quantitative results

## Architecture Onboarding

**Component Map**: Input noise -> Conditional model (better-trained) -> Unconditional model (less-trained) -> Interpolation -> Output image

**Critical Path**: The interpolation between conditional and unconditional predictions during sampling is the critical component. The unconditional prediction comes from the less-trained model, while the conditional prediction comes from the better-trained model. The balance between these predictions determines the final image quality and diversity.

**Design Tradeoffs**: The main tradeoff is between quality improvement and computational cost. Autoguidance requires running two models simultaneously, which increases inference time and memory usage. However, this cost is offset by the significant quality improvements achieved. Another tradeoff is between diversity and fidelity - higher guidance weights improve quality but reduce diversity.

**Failure Signatures**: If the less-trained model is too poor in quality, it may introduce artifacts or bias the better-trained model in undesirable ways. If the guidance weight is too high, the model may produce overly simplified images lacking detail. If the guidance weight is too low, the benefits of autoguidance may not be realized.

**Three First Experiments**:
1. Test autoguidance with varying gaps in training quality between guide and target models to find optimal performance-to-cost ratios
2. Evaluate autoguidance on unconditional models to verify the claimed drastic quality improvements
3. Compare computational efficiency against CFG at equivalent quality levels to quantify practical deployment trade-offs

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead from running two models simultaneously during inference
- Limited evidence of performance across diverse domains beyond ImageNet
- Heuristic selection criteria for determining when to stop training the guide model

## Confidence
- High confidence in core experimental results on ImageNet-512 and ImageNet-64
- Medium confidence in broader generalization claims across domains
- Medium confidence in the claim that autoguidance "drastically improves" unconditional models

## Next Checks
1. Test autoguidance across diverse domains (medical imaging, satellite imagery, artistic datasets) to verify cross-domain robustness
2. Conduct ablation studies varying the gap in training quality between guide and target models to find optimal performance-to-cost ratios
3. Compare computational efficiency against CFG at equivalent quality levels to quantify practical deployment trade-offs