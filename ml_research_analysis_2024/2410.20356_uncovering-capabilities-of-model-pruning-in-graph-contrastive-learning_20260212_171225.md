---
ver: rpa2
title: Uncovering Capabilities of Model Pruning in Graph Contrastive Learning
arxiv_id: '2410.20356'
source_url: https://arxiv.org/abs/2410.20356
tags:
- graph
- learning
- contrastive
- pruning
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reformulates graph contrastive learning by replacing
  data augmentation with model pruning. Instead of corrupting graphs to create views,
  it prunes a copy of the encoder to generate a perturbed encoder for contrastive
  learning, avoiding structural damage from augmentation.
---

# Uncovering Capabilities of Model Pruning in Graph Contrastive Learning

## Quick Facts
- arXiv ID: 2410.20356
- Source URL: https://arxiv.org/abs/2410.20356
- Reference count: 40
- Replaces data augmentation with model pruning for graph contrastive learning, achieving state-of-the-art performance

## Executive Summary
This paper introduces LAMP (Learning via Model Pruning), a novel approach to graph contrastive learning that replaces traditional data augmentation with model pruning. Instead of corrupting graph structures to create views, LAMP prunes a copy of the encoder to generate a perturbed encoder for contrastive learning. This avoids the semantic damage caused by structural corruption while preserving model capacity. The method introduces a local contrastive loss on node embeddings to handle hard negative samples with similar structures but different labels, achieving superior performance on both unsupervised and transfer learning tasks for graph classification.

## Method Summary
LAMP reformulates graph contrastive learning by pruning the encoder instead of augmenting the input graphs. At the start of each epoch, a sparse encoder is created by pruning the dense encoder using magnitude pruning or soft filter pruning. Both encoders process the original graph, and their outputs are projected through separate MLPs. The method uses NT-Xent loss on graph embeddings plus a local contrastive loss on sampled node embeddings. Only the dense encoder is updated during backpropagation. Hyperparameters including pruning ratio (5-95%) and local loss weight (Î± in {0.01, 0.1, 1, 10, 100}) are tuned via grid search.

## Key Results
- LAMP-Soft achieves 78.82% average accuracy on 8 graph classification benchmarks, ranking first in unsupervised learning
- Improves average ROC-AUC by 2.27% over best baseline and over 10% compared to no pre-training in transfer learning
- Local contrastive loss effectively handles hard negative samples with similar structures but different labels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing data augmentation with model pruning avoids semantic damage from structural corruption while preserving model capacity.
- Mechanism: Pruning a copy of the encoder dynamically generates a perturbed encoder for contrastive learning. The pruned encoder is derived from the latest dense encoder each epoch, ensuring the two contrastive embeddings co-evolve without corrupting input graph structure.
- Core assumption: The mutual information between the pruned encoder and the optimal encoder is equivalent to that between the optimal encoder and its output, and this mutual information is greater than or equal to that between augmented views.
- Evidence anchors:
  - [abstract] "we reformulate the problem of graph contrastive learning via contrasting different model versions rather than augmented views"
  - [section 4.2] "Statement 1 in Theorem 4.1 guarantees a lower bound of the mutual information between the learned representations and the labels of the downstream task"
  - [corpus] Weak evidence - related works focus on augmentation but do not validate pruning's theoretical advantages.
- Break condition: If pruning removes too much structure from the encoder, the sparse encoder cannot approximate the optimal encoder, breaking the mutual information equivalence.

### Mechanism 2
- Claim: Node-level contrastive loss effectively handles hard negative samples that have similar structures but different labels.
- Mechanism: A local contrastive loss compares node embeddings between positive pairs, forcing the model to distinguish nodes even when graph-level representations are similar. This creates additional discriminative signal beyond the standard NT-Xent loss.
- Core assumption: Node embeddings preserve sufficient discriminative information to distinguish hard negatives, even when graph embeddings cannot.
- Evidence anchors:
  - [abstract] "we are capable of developing a local contrastive loss to tackle the hard negative samples"
  - [section 4.4] "we propose a local contrastive loss to enhance graph learning from the node level"
  - [corpus] Weak evidence - no related works explicitly validate local node-level contrastive losses for hard negatives.
- Break condition: If node embeddings become too similar across different graphs (e.g., due to lack of node features in social datasets), the local contrastive loss loses effectiveness.

### Mechanism 3
- Claim: Dynamic pruning at the start of each epoch maintains encoder diversity while ensuring convergence.
- Mechanism: By pruning the dense encoder at epoch start, both branches co-evolve with shared history but different parameter subsets, maintaining diversity without instability.
- Core assumption: The pruned encoder, being derived from the latest dense encoder, maintains sufficient correlation for stable contrastive learning while providing perturbation.
- Evidence anchors:
  - [section 4.3] "Since the sparse encoder is always obtained and updated from the latest dense version, the two branches will co-evolve during training"
  - [section 4.3] "the sparse degree of the graph encoder can be controlled by tuning the pruning ratio ð›¾"
  - [corpus] Weak evidence - pruning is typically used for efficiency, not contrastive perturbation.
- Break condition: If the pruning ratio is too high, the sparse encoder becomes too weak to provide meaningful contrast; if too low, diversity is insufficient.

## Foundational Learning

- Concept: Mutual information maximization
  - Why needed here: The theoretical justification for pruning superiority relies on mutual information bounds between encoders and labels.
  - Quick check question: Why does preserving mutual information between encoder and labels matter more than preserving mutual information between augmented views and labels?

- Concept: Graph neural networks and message passing
  - Why needed here: The encoder architecture and how pruning affects node representations is central to the method.
  - Quick check question: How does pruning a weight matrix in a GNN layer affect the propagation of information from neighbors?

- Concept: Contrastive learning framework (NT-Xent loss)
  - Why needed here: Understanding the baseline framework being modified is essential to grasp why pruning is beneficial.
  - Quick check question: What is the role of temperature parameter Ï„ in NT-Xent loss, and how might it interact with local contrastive loss?

## Architecture Onboarding

- Component map:
  Input graph -> Dense encoder -> Projection head -> NT-Xent loss
  Input graph -> Pruned sparse encoder -> Projection head -> NT-Xent loss
  Input graph -> Dense encoder -> Node sampling -> Local contrastive loss
  Combined loss -> Dense encoder update

- Critical path:
  1. Initialize dense encoder
  2. At start of each epoch, prune dense encoder to create sparse encoder
  3. Forward pass both encoders on original graph
  4. Compute graph embeddings via global pooling
  5. Project embeddings through separate MLPs
  6. Compute NT-Xent loss on graph pairs
  7. Sample node subset and compute local contrastive loss
  8. Backpropagate combined loss to dense encoder only
  9. Update dense encoder weights
  10. Repeat

- Design tradeoffs:
  - Pruning ratio vs. encoder capacity: Higher pruning creates more diversity but risks losing representational power
  - Local loss weight Î± vs. global loss: Too much local loss may overfit to node-level distinctions
  - Node sampling size Ns vs. computation: Larger Ns provides better local contrast but increases cost

- Failure signatures:
  - Performance degrades with high pruning ratios (>75%): Sparse encoder loses capacity
  - Social datasets show minimal improvement: Lack of node features limits local contrastive effectiveness
  - Training instability with certain pruning strategies: Inconsistent pruning can create divergent encoders

- First 3 experiments:
  1. Vary pruning ratio from 5% to 95% on NCI1 and observe accuracy curve to find optimal ratio
  2. Disable local contrastive loss (Î±=0) and compare performance to identify its contribution
  3. Replace magnitude pruning with soft filter pruning and compare results to validate pruning strategy independence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal pruning ratio for LAMP vary across different graph datasets and what underlying graph properties drive these differences?
- Basis in paper: [explicit] The paper discusses sensitivity to pruning ratio (Figure 4) showing different datasets prefer different pruning ratios, and notes that social datasets may prefer lower ratios while others prefer sparser encoders.
- Why unresolved: The paper only provides empirical observations but doesn't explain the theoretical relationship between graph properties (size, density, feature distribution) and optimal pruning ratios.
- What evidence would resolve it: A systematic study varying graph properties (size, average degree, feature entropy) and measuring the impact on optimal pruning ratio for LAMP would reveal the underlying relationship.

### Open Question 2
- Question: Can LAMP's model pruning approach be extended to handle node classification and link prediction tasks effectively, or are there fundamental limitations to this approach for these task types?
- Basis in paper: [inferred] The paper explicitly states that "node classification and link prediction tasks are also important areas in graph-related tasks" and mentions these as future work, implying current limitations.
- Why unresolved: The paper only validates LAMP on graph classification tasks and doesn't explore how the pruning-based contrastive learning framework would work for tasks requiring node-level or edge-level predictions.
- What evidence would resolve it: Experimental results showing LAMP's performance on node classification and link prediction benchmarks compared to existing methods would demonstrate whether the approach generalizes beyond graph classification.

### Open Question 3
- Question: What is the theoretical relationship between the local contrastive loss introduced for hard negative samples and the overall contrastive learning objective, and under what conditions does this local loss improve model performance?
- Basis in paper: [explicit] The paper introduces a local contrastive loss to handle hard negative samples and shows it improves performance (Table 3), but doesn't provide theoretical analysis of its relationship to the global contrastive objective.
- Why unresolved: While empirical benefits are shown, the paper doesn't explain why contrasting node embeddings helps with hard negative samples at the graph level or when this approach is most beneficial.
- What evidence would resolve it: A theoretical analysis connecting the local contrastive loss to mutual information maximization principles, along with experiments showing when (on which dataset types or with which kinds of hard negatives) the local loss provides the most benefit.

## Limitations

- Theoretical assumptions about mutual information preservation lack direct experimental validation
- Local contrastive loss contribution is confounded with overall LAMP performance and lacks isolated validation
- Method's effectiveness on node classification and link prediction tasks remains unexplored

## Confidence

- **High confidence**: LAMP outperforms baselines in both unsupervised and transfer learning settings. The experimental results are consistent and well-documented.
- **Medium confidence**: The pruning mechanism provides superior contrastive views compared to augmentation. While results support this, the theoretical justification could be more rigorously tested.
- **Low confidence**: The local contrastive loss specifically addresses hard negative samples. This mechanism's contribution is confounded with overall LAMP performance and lacks isolated validation.

## Next Checks

1. Measure and compare mutual information between (dense encoder, labels) and (sparse encoder, labels) across training epochs to verify Theorem 4.1's assumptions.
2. Conduct an ablation study where augmented views replace pruned encoders while keeping all other components constant, measuring the degradation in downstream performance.
3. Analyze node embedding distances in positive vs. negative pairs with and without local contrastive loss to quantify its impact on hard negative discrimination.