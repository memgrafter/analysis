---
ver: rpa2
title: Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing
  with Llama-3
arxiv_id: '2405.00664'
source_url: https://arxiv.org/abs/2405.00664
tags:
- editing
- batch
- edits
- memit
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the optimal batch size for model editing
  in large language models, focusing on Llama-3. It compares sequential, batch, and
  sequential-batch editing strategies using ROME, MEMIT, and EMMET algorithms.
---

# Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3

## Quick Facts
- arXiv ID: 2405.00664
- Source URL: https://arxiv.org/abs/2405.00664
- Reference count: 20
- Primary result: Sequential editing with batch size 1024 is optimal for Llama-3; larger batches degrade locality preservation.

## Executive Summary
This study investigates the optimal batch size for model editing in large language models, focusing on Llama-3. It compares sequential, batch, and sequential-batch editing strategies using ROME, MEMIT, and EMMET algorithms. The research finds that sequential editing with smaller batch sizes outperforms larger batch sizes in terms of model performance, particularly in preserving locality of edits. The optimal batch size for Llama-3 is determined to be 1024, beyond which model degradation increases. This suggests that sequential model editing is crucial for scaling model editing methods and highlights a potential limitation in current approaches that favor larger batch sizes.

## Method Summary
The study performs layer search on Llama-3-8b to identify the optimal layer for model editing (layer 1), then conducts batch editing experiments with MEMIT and EMMET at layer 1 using various batch sizes (16, 64, 256, 1024, 4096). It also performs sequential-batch editing experiments with varying batch sizes (1, 64, 256, 1024, 4096) using MEMIT and EMMET at layer 1. Performance is evaluated using Efficacy Score (ES), Paraphrase Score (PS), Neighborhood Score (NS), and Composite Score (S) on the CounterFact dataset.

## Key Results
- Sequential editing with smaller batch sizes (e.g., 1024) preserves locality better than large batch edits (4096)
- Larger batch sizes reduce overall edit efficacy (ES, PS, S) due to interference between edits
- The optimal layer for editing shifts from layer 5 in Llama-2 to layer 1 in Llama-3

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequential batch editing with smaller batch sizes preserves locality better than large batch edits.
- Mechanism: Smaller sequential batches allow the model to integrate changes without overwriting or interfering with nearby stored facts, maintaining the Neighborhood Score.
- Evidence: Results show larger batch sizes are worse for model performance than sequential edits with smaller batches, particularly for preserving locality.
- Break condition: If batch size exceeds the model's capacity to maintain non-overlapping edit neighborhoods, NS drops sharply.

### Mechanism 2
- Claim: Larger batch sizes reduce overall edit efficacy because they introduce interference between edits.
- Mechanism: Simultaneous edits in large batches compete for the same representational space, causing the preservation term in the PM objective to dominate and degrade memorization.
- Evidence: Figures show larger batch sizes are worse for ES, PS, and S metrics compared to sequential edits with smaller batches.
- Break condition: When batch size is so large that edits overlap in the model's key-value space, ES/PS/S collapse.

### Mechanism 3
- Claim: The optimal layer for editing shifts to shallower layers in Llama-3 due to architectural changes.
- Mechanism: Llama-3's earlier layers encode more factual knowledge directly, making them more amendable to targeted edits without cascading side effects.
- Evidence: Layer 1 consistently outperforms on numerous metrics for Llama-3, contrary to findings for Llama-2 where layer 5 was optimal.
- Break condition: If deeper layers in Llama-3 are found to encode more abstract relational knowledge, the optimal layer might shift back.

## Foundational Learning

- Concept: Preservation-memorization (PM) objective
  - Why needed here: The study's core algorithms optimize this objective; understanding it is essential to grasp why batch size matters.
  - Quick check question: What are the two components of the PM objective and how do they conflict when batch size increases?

- Concept: Locate-and-edit paradigm
  - Why needed here: The paper's methods rely on identifying key-value pairs in specific layers; without this, the sequential vs. batch distinction is meaningless.
  - Quick check question: How does the locate step determine which layer to edit, and why does this matter for locality?

- Concept: Neighborhood Score (NS) as locality metric
  - Why needed here: NS is the primary indicator that sequential editing preserves nearby facts better; misinterpreting it would lead to wrong conclusions about batch size effects.
  - Quick check question: Why does NS drop more sharply with large batch sizes than with sequential small batches?

## Architecture Onboarding

- Component map: Llama-3-8B model -> Layer 1 (targeted for edits) -> Feed-forward network weights -> ROME/MEMIT/EMMET update equations -> Evaluation metrics (ES, PS, NS, S)
- Critical path: 1. Layer selection (empirical testing across all layers) 2. Batch size selection (1, 64, 256, 1024, 4096) 3. Sequential vs. batch execution strategy 4. Metric computation after edits
- Design tradeoffs: Larger batch sizes offer fewer updates and faster execution but worse locality preservation; smaller sequential batches require more updates and slower execution but better NS and overall score
- Failure signatures: Sharp NS drop indicates edits are bleeding into adjacent facts; ES/PS collapse suggests edits are overwriting preserved knowledge; no improvement over baseline indicates wrong layer or batch size chosen
- First 3 experiments:
  1. Run single-layer edit sweep (layer 0 to 31) with batch size 1 to confirm optimal layer empirically
  2. Compare batch size 4096 vs. sequential size 1024 on NS to quantify locality loss
  3. Test hybrid strategy: 1024 edits sequential, then 4096 as a single batch, measure metric deltas

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact mechanism by which larger batch sizes cause more significant model degradation, particularly in terms of neighborhood score?
- Basis in paper: The paper states that increasing edit batch sizes may degrade model performance more significantly than using smaller edit batches sequentially for equal number of edits, with neighborhood score being the most pronounced to fall.
- Why unresolved: While the paper identifies this trend, it does not delve into the underlying reasons for this degradation.
- What evidence would resolve it: Experiments isolating the effects of batch size on specific model components or detailed analysis of how edits in larger batches interfere with adjacent facts could provide insights into the mechanism.

### Open Question 2
- Question: How do different transformer architectures (e.g., BERT, GPT) respond to the same model editing strategies, particularly in terms of optimal batch size?
- Basis in paper: The paper focuses on Llama-3 and Llama-2 models, leaving open the question of how other transformer architectures might respond differently to the same editing strategies.
- Why unresolved: The study's findings are specific to Llama models, and it's unclear if the same patterns hold for other architectures that might have different attention mechanisms or layer structures.
- What evidence would resolve it: Conducting similar experiments on other transformer models like BERT or GPT and comparing the results would help determine if the findings are architecture-specific or more generalizable.

### Open Question 3
- Question: What is the long-term impact of sequential versus batch editing on model performance, particularly in terms of model forgetting and the ability to learn new information?
- Basis in paper: The paper mentions that sequential model editing could enable model editing methods to approach the continual learning paradigm, suggesting potential long-term impacts.
- Why unresolved: While the paper hints at the potential for sequential editing to support continual learning, it does not explore the long-term effects on model performance, such as forgetting or adaptability to new information.
- What evidence would resolve it: Longitudinal studies tracking model performance over time with both editing strategies could provide insights into long-term impacts, including measures of forgetting and adaptability.

## Limitations
- The study is limited to Llama-3-8B and may not generalize to other model families or scales
- Results may depend on dataset-specific properties of CounterFact, which are not characterized
- The analysis does not test intermediate batch sizes (e.g., 512, 2048) that might reveal a more precise inflection point

## Confidence

**High confidence**: Sequential editing with smaller batch sizes outperforms larger batch sizes in preserving locality and overall model performance. The optimal layer for Llama-3 is layer 1, not layer 5 as found in Llama-2.

**Medium confidence**: The claim that batch size 1024 is the precise optimum; the study does not explore all intermediate values. The assertion that sequential editing is crucial for scaling model editing methods is plausible but not rigorously proven across multiple datasets or model architectures.

**Low confidence**: The mechanism by which larger batch sizes degrade preservation is described but not experimentally isolated.

## Next Checks
1. Test intermediate batch sizes (512, 2048) to pinpoint the exact optimal batch size and verify that 1024 is indeed the peak.
2. Replicate the layer search on Llama-3-70B and other model families to determine if layer 1 remains optimal or if the optimal layer shifts with model scale or architecture.
3. Conduct ablation studies to isolate the interference mechanism: compare NS drops when edits are applied to overlapping vs. non-overlapping neighborhoods within the same batch.