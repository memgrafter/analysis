---
ver: rpa2
title: 'ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent
  Social Science'
arxiv_id: '2408.01966'
source_url: https://arxiv.org/abs/2408.01966
tags:
- level
- bias
- male
- female
- ml-eat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the Multilevel Embedding Association Test
  (ML-EAT), a method for measuring bias in language technologies at three levels of
  granularity: differential association between target and attribute groups (equivalent
  to traditional EAT), individual effect sizes for each target group, and raw cosine
  similarities. The authors define a taxonomy of nine EAT patterns and introduce EAT-Maps
  for visualization.'
---

# ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science

## Quick Facts
- arXiv ID: 2408.01966
- Source URL: https://arxiv.org/abs/2408.01966
- Reference count: 15
- Authors: Robert Wolfe; Alexis Hiniker; Bill Howe
- Primary result: Introduces ML-EAT method revealing bias patterns invisible to traditional EAT through three-level granularity

## Executive Summary
This paper introduces the Multilevel Embedding Association Test (ML-EAT), a method for measuring bias in language technologies at three levels of granularity: differential association between target and attribute groups (equivalent to traditional EAT), individual effect sizes for each target group, and raw cosine similarities. The authors define a taxonomy of nine EAT patterns and introduce EAT-Maps for visualization. Applied to static/diacronic word embeddings, GPT-2, and CLIP models, the ML-EAT reveals previously unobservable patterns of bias, shows how prompting affects bias measurements in zero-shot models, and identifies when cosine similarity is an ineffective metric.

## Method Summary
The ML-EAT quantifies bias at three increasing levels of granularity. Level 3 describes cosine similarity distributions between target and attribute groups using means and standard deviations. Level 2 computes differential associations as effect sizes between target groups for each attribute group. Level 1 aggregates these into a single traditional EAT effect size. The method uses permutation testing for significance and EAT-Maps for visualization. Applied to GloVe, HistWords, GPT-2, and CLIP models using established EAT stimuli, the framework reveals bias patterns, identifies anisotropy issues, and demonstrates prompt sensitivity in zero-shot models.

## Key Results
- ML-EAT reveals bias patterns invisible to traditional single-level EAT by preserving directional and magnitude information
- EAT-Maps provide intuitive visual vocabulary for complex bias patterns across four quadrants
- Method identifies when cosine similarity becomes ineffective due to anisotropy in embedding spaces

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ML-EAT reveals bias patterns invisible to traditional single-level EAT by decomposing cosine similarity distributions into three granular measurements
- Mechanism: Traditional EAT collapses four cosine similarity distributions into one standardized effect size, losing directional and magnitude information. ML-EAT preserves this information by separately reporting means and standard deviations at Level 3, differential associations at Level 2, and aggregated effect at Level 1
- Core assumption: Cosine similarity distributions contain meaningful information about bias direction and magnitude lost during standardization
- Break condition: If cosine similarity becomes unreliable due to anisotropy, Level 3 reveals this through unusually high standard deviations or uniform distributions

### Mechanism 2
- Claim: EAT-Maps provide intuitive visual vocabulary making complex bias patterns immediately interpretable
- Mechanism: Mapping Level 2 effect sizes onto four-quadrant grid where rows represent attributes and columns represent targets creates consistent visual language. Quadrant shading (red for significant positive, blue for significant negative, gray for non-significant) directly corresponds to differential associations
- Core assumption: Human pattern recognition can more easily interpret visual quadrant patterns than numerical effect sizes alone
- Break condition: If Level 2 effect sizes are uniformly small or non-significant, EAT-Map appears mostly gray indicating no detectable bias pattern

### Mechanism 3
- Claim: ML-EAT identifies when cosine similarity is ineffective metric, preventing unreliable bias measurements
- Mechanism: Level 3 reporting of raw cosine similarity distributions reveals anisotropy in embedding spaces. When all cosine similarities cluster around 1.0 with minimal variance, embedding space lacks semantic structure needed for meaningful association tests
- Core assumption: Anisotropic embedding spaces show pattern in Level 3's standard deviation measurements
- Break condition: If Level 3 shows standard deviations consistently below 0.1 across all target-attribute pairs, embedding space is likely too anisotropic for reliable EAT measurements

## Foundational Learning

- Concept: Cosine similarity and its limitations in high-dimensional spaces
  - Why needed here: ML-EAT relies on cosine similarity as core association metric but must detect when this metric fails due to anisotropy
  - Quick check question: What happens to cosine similarity distributions when all vectors in embedding space point in approximately same direction?

- Concept: Effect size (Cohen's d) and statistical significance testing
  - Why needed here: All three levels of ML-EAT report effect sizes and p-values, requiring understanding of meaningful effect sizes
  - Quick check question: According to Cohen's guidelines, what d-value threshold typically indicates "small" effect size?

- Concept: Permutation testing for significance
  - Why needed here: ML-EAT uses permutation tests to determine significance of observed effect sizes without parametric assumptions
  - Quick check question: How does permutation test establish null distribution for effect size without parametric assumptions?

## Architecture Onboarding

- Component map: Level 3 (cosine similarities) -> Level 2 (individual target effects) -> Level 1 (aggregated EAT effect) -> EAT-Maps (visualization) -> EAT patterns (taxonomy)
- Critical path: Compute Level 3 cosine similarities, calculate Level 2 differential effects, aggregate to Level 1, generate EAT-Maps after Level 2 results
- Design tradeoffs: Trades computational simplicity for interpretability and transparency. Three-level approach requires more computation but reveals patterns invisible in single summary statistic
- Failure signatures: Uniform gray EAT-Maps indicate no detectable bias; Level 3 showing standard deviations below 0.1 indicates anisotropy; Level 2 showing inconsistent signs suggests complex/conflicting bias patterns
- First 3 experiments:
  1. Replicate Caliskan et al. (2017) WEAT tests on GloVe embeddings to verify ML-EAT produces consistent Level 1 results while revealing new patterns in Levels 2 and 3
  2. Apply ML-EAT to GPT-2 embeddings to observe anisotropy effects and compare Level 3 standard deviations across model sizes
  3. Test impact of prompting on CLIP embeddings by comparing ML-EAT results with and without prompts to see how Level 3 cosine distributions change

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ML-EAT perform when applied to language models with different tokenization strategies or subword vocabularies?
- Basis in paper: The paper tests GPT-2 models but doesn't explore how tokenization differences affect ML-EAT results
- Why unresolved: Current analysis focuses on standard GPT-2 models without investigating whether tokenization granularity impacts observed EAT patterns
- What evidence would resolve it: Testing ML-EAT on models with character-level, byte-level, and word-level tokenization to compare resulting EAT patterns and cosine similarity distributions

### Open Question 2
- Question: Can the ML-EAT detect intersectional biases that emerge only when multiple social categories interact?
- Basis in paper: The paper mentions intersectional biases in related work but doesn't apply ML-EAT to intersectional analysis
- Why unresolved: While paper discusses intersectional biases in other studies, it doesn't demonstrate whether ML-EAT can capture these complex, interacting bias patterns
- What evidence would resolve it: Applying ML-EAT to test designs including multiple target and attribute groups simultaneously (e.g., combining gender and race categories)

### Open Question 3
- Question: What is the relationship between ML-EAT measurements and bias propagation in downstream tasks?
- Basis in paper: The paper acknowledges prior work showing limited correlation between intrinsic and application bias, but doesn't test this for ML-EAT
- Why unresolved: Paper focuses on interpretability of intrinsic bias but doesn't investigate whether ML-EAT patterns predict downstream bias propagation
- What evidence would resolve it: Correlation studies between ML-EAT patterns and bias measurements in downstream tasks like sentiment analysis, toxicity detection, or named entity recognition

## Limitations

- Model version dependencies create uncertainty in reproducibility due to potential differences in training data and weight initialization
- Cosine similarity validity assumptions may not hold for modern embeddings exhibiting anisotropy and hubness effects
- Stimuli completeness uncertainty due to incomplete specification of EAT word and image stimuli lists

## Confidence

**High Confidence**: Mathematical framework for three-level ML-EAT measurement is clearly specified and internally consistent. Relationship between cosine similarity distributions, effect sizes, and EAT patterns follows standard statistical principles. Taxonomy of nine EAT patterns is well-defined and comprehensive.

**Medium Confidence**: Interpretability claims regarding EAT-Maps and practical utility of multi-level measurements are supported by theoretical framework but lack extensive empirical validation across diverse bias scenarios. Effectiveness in detecting previously unobservable patterns needs more systematic verification.

**Low Confidence**: Claims about identifying when cosine similarity becomes ineffective metric are theoretically sound but lack concrete examples or quantitative thresholds for when this occurs. Relationship between standard deviation values and anisotropy severity remains underspecified.

## Next Checks

1. **Cross-Model Consistency Test**: Apply ML-EAT to multiple versions of same model architecture (e.g., different GPT-2 checkpoints) to quantify sensitivity to model variations. Compare Level 3 standard deviations and EAT patterns across versions.

2. **Synthetic Embedding Space Test**: Create controlled synthetic embedding spaces with known anisotropy levels and test whether ML-EAT correctly identifies when cosine similarity becomes unreliable. Measure relationship between known anisotropy and observed Level 3 standard deviations.

3. **Prompt Sensitivity Analysis**: Systematically vary prompts for CLIP and GPT-2 models to map how prompting affects Level 3 cosine distributions and subsequent Level 2/3 measurements. Quantify stability of EAT patterns under prompt variations.