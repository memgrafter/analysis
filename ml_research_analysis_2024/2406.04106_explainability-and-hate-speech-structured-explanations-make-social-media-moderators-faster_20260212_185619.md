---
ver: rpa2
title: 'Explainability and Hate Speech: Structured Explanations Make Social Media
  Moderators Faster'
arxiv_id: '2406.04106'
source_url: https://arxiv.org/abs/2406.04106
tags:
- explanations
- moderators
- post
- posts
- structured
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigated the impact of explanations on the speed
  of professional social media moderators. The core method idea was to compare three
  settings: post-only, post with generic explanations, and post with structured explanations
  (highlighting specific spans of text and their relation to policy).'
---

# Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster

## Quick Facts
- arXiv ID: 2406.04106
- Source URL: https://arxiv.org/abs/2406.04106
- Reference count: 40
- Primary result: Structured explanations reduced decision time by 7.4% (1.34 seconds per post) without accuracy loss

## Executive Summary
This study demonstrates that structured explanations significantly improve the speed of professional social media moderators when making hate speech judgments. The research compared three conditions: post-only, post with generic explanations, and post with structured explanations that highlight specific text spans and their relation to policy. The results showed that structured explanations reduced decision-making time by 1.34 seconds per post while maintaining accuracy, whereas generic explanations had no significant effect on speed. A follow-up survey revealed that 84% of moderators strongly preferred structured explanations.

## Method Summary
The study recruited 25 professional moderators from Snapchat with an average of 1.2 years of experience. Moderators judged 2,400 posts (800 per condition) from the PLEAD dataset, which contains 3,535 posts with gold explanations. The three conditions were: post-only (control), post with generic policy text explanations, and post with structured explanations highlighting specific text spans. Moderators were randomly assigned to different settings orders, and mixed-effects models analyzed the decision time data while accounting for individual differences.

## Key Results
- Structured explanations reduced decision time by 1.34 seconds per post (7.4% improvement) without accuracy loss
- Generic explanations had no significant effect on moderator speed
- 84% of moderators strongly preferred structured explanations over generic or no explanations
- 60% of moderators used structured explanations consistently during the task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured explanations reduce moderators' decision-making time by highlighting specific spans of text and their relation to policy.
- Mechanism: By directly mapping harmful text segments to policy rules, moderators can quickly identify violations without needing to parse the entire post or consult policy guidelines separately.
- Core assumption: Moderators can interpret structured explanations accurately and consistently without additional training.
- Evidence anchors:
  - [abstract] "structured explanations (highlighting specific spans of text and their relation to policy)"
  - [section] "structured explanations can make experienced moderators faster by 1.34s/post without any loss in accuracy"
- Break condition: If structured explanations contain errors or are too complex to interpret quickly, moderators may ignore them or spend time verifying their accuracy.

### Mechanism 2
- Claim: Generic explanations do not impact moderators' speed because they lack specificity to the post content.
- Mechanism: Generic explanations provide policy rule descriptions that are not tied to the specific post, requiring moderators to mentally map the policy to the post content themselves.
- Core assumption: Moderators already have a strong understanding of policy rules and do not need additional generic descriptions.
- Evidence anchors:
  - [abstract] "generic explanations do not affect their speed and are often ignored"
  - [section] "while generic explanations do not affect their speed and are often ignored, structured explanations lower moderators' decision making time by 7.4%"
- Break condition: If moderators are new or unfamiliar with policy rules, generic explanations might provide some benefit by reminding them of relevant policy sections.

### Mechanism 3
- Claim: Moderators strongly prefer structured explanations over generic or no explanations.
- Mechanism: Structured explanations provide actionable guidance by pinpointing exactly which parts of a post violate policy, reducing cognitive load and decision uncertainty.
- Core assumption: Moderators value tools that make their work more efficient and accurate, even if they are already experienced.
- Evidence anchors:
  - [abstract] "moderators strongly prefer structured explanations (84%)"
  - [section] "An online survey further revealed that moderators strongly prefer structured explanations (84%)"
- Break condition: If structured explanations become too complex or time-consuming to generate at scale, their practical utility may diminish despite user preference.

## Foundational Learning

- Concept: Mixed-effects models for analyzing data with hierarchical structure
  - Why needed here: To account for individual differences among moderators while analyzing the effect of explanations on speed
  - Quick check question: What is the advantage of using mixed-effects models over traditional linear regression when analyzing data from multiple participants?

- Concept: Statistical significance testing (ANOVA, z-tests)
  - Why needed here: To determine whether observed differences in speed and accuracy are meaningful or due to chance
  - Quick check question: How do you interpret a p-value of 0.001 in the context of comparing moderator speed across different explanation conditions?

- Concept: Experimental design with randomized conditions
  - Why needed here: To ensure that differences in moderator performance are due to explanation type and not other factors like order effects or specific post samples
  - Quick check question: Why is it important to randomize both the order of conditions and the posts within each condition in this study?

## Architecture Onboarding

- Component map: Data collection -> Data processing -> Analysis -> Survey
- Critical path: 1. Moderator judges post with chosen explanation type 2. System records timestamp and decision 3. Data is aggregated and outliers removed 4. Statistical models analyze speed and accuracy 5. Survey results inform explanation design preferences
- Design tradeoffs:
  - Using gold explanations from dataset vs. generated explanations (accuracy vs. scalability)
  - Including not-hateful posts to simulate model errors (realism vs. potential confusion)
  - Recording only speed and accuracy vs. collecting more detailed interaction data (simplicity vs. depth of insights)
- Failure signatures:
  - No significant difference in speed between conditions
  - Decrease in accuracy when using explanations
  - Moderators reporting confusion about explanation format
  - High variance in performance across moderators
- First 3 experiments:
  1. Replicate the study with a different policy domain (e.g., misinformation instead of hate speech) to test generalizability
  2. Test the effect of explanation timing (before vs. after initial judgment) on speed and accuracy
  3. Compare structured explanations with different levels of granularity (e.g., highlighting words vs. phrases vs. clauses)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would structured explanations impact moderator performance on other types of policy violations beyond hate speech?
- Basis in paper: [explicit] The study focused specifically on hate speech violations.
- Why unresolved: The study's scope was limited to hate speech, and the authors acknowledge the need to test explanations for other policy violations.
- What evidence would resolve it: Experiments testing the impact of structured explanations on moderator performance for different types of policy violations (e.g., misinformation, harassment).

### Open Question 2
- Question: Would the effectiveness of structured explanations vary depending on the moderator's experience level?
- Basis in paper: [inferred] The study included moderators with varying experience levels, but the analysis didn't specifically examine the impact of experience on the effectiveness of explanations.
- Why unresolved: The paper acknowledges the potential influence of experience but doesn't provide a detailed analysis of its impact.
- What evidence would resolve it: Experiments comparing the impact of structured explanations on moderator performance across different experience levels.

### Open Question 3
- Question: How would the performance of moderators change if they were allowed to provide feedback on the accuracy of explanations?
- Basis in paper: [explicit] Moderators spotted inaccuracies in the explanations during the experiment.
- Why unresolved: The study didn't investigate the potential benefits of allowing moderators to provide feedback on explanation accuracy.
- What evidence would resolve it: Experiments comparing moderator performance with and without the ability to provide feedback on explanation accuracy.

## Limitations

- Dataset representativeness: The PLEAD dataset may not fully capture the diversity of real-world hate speech content moderators encounter, potentially limiting generalizability.
- Moderators' baseline expertise: The study assumes the 25 moderators' experience level is representative of professional moderators, but individual differences in policy knowledge were not fully characterized.
- Explanation generation scalability: The study used gold explanations rather than demonstrating how such explanations could be generated at scale for millions of posts.

## Confidence

- High confidence: The finding that structured explanations reduced decision time by 1.34 seconds (7.4%) while maintaining accuracy is well-supported by the experimental data and statistical analysis.
- Medium confidence: The preference data showing 84% of moderators favoring structured explanations is reliable but may be influenced by the specific experimental setup.
- Low confidence: The claim about how structured explanations work mechanistically (highlighting specific spans and their relation to policy) is reasonable but not directly measured.

## Next Checks

1. External validation with different content types: Replicate the study using a different policy domain (e.g., misinformation, graphic violence) to test whether structured explanations provide similar benefits across moderation contexts.

2. Real-time explanation generation test: Evaluate moderator performance using automatically generated structured explanations rather than gold explanations to assess practical scalability and identify quality degradation.

3. Longitudinal performance tracking: Conduct a longer-term study tracking moderator speed and accuracy over multiple weeks of using structured explanations to identify potential learning curves or fatigue effects.