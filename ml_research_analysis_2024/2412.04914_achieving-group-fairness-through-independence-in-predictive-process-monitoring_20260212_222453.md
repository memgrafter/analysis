---
ver: rpa2
title: Achieving Group Fairness through Independence in Predictive Process Monitoring
arxiv_id: '2412.04914'
source_url: https://arxiv.org/abs/2412.04914
tags:
- uni00000013
- process
- uni00000003
- uni0000004c
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces group fairness metrics for predictive process\
  \ monitoring (PPM) using independence criteria. It proposes threshold-independent\
  \ distribution-based metrics (ABPC and ABCC) alongside traditional demographic parity\
  \ metrics (\u0394DP) to measure group fairness violations."
---

# Achieving Group Fairness through Independence in Predictive Process Monitoring

## Quick Facts
- arXiv ID: 2412.04914
- Source URL: https://arxiv.org/abs/2412.04914
- Authors: Jari Peeperkorn; Simon De Vos
- Reference count: 0
- Primary result: Introduces group fairness metrics for predictive process monitoring using independence criteria and demonstrates effectiveness of Wasserstein-based loss functions for balancing fairness and predictive performance

## Executive Summary
This paper addresses group fairness in predictive process monitoring (PPM) by introducing independence-based fairness metrics and a composite loss function that balances predictive performance with fairness constraints. The authors propose threshold-independent distribution-based metrics (ABPC and ABCC) alongside traditional demographic parity metrics (ΔDP) to measure group fairness violations. A composite loss function combining binary cross-entropy with a Wasserstein-based integral probability metric (IPM) is developed to train models that achieve Pareto-optimal trade-offs between predictive accuracy and fairness. Experiments on artificial datasets demonstrate that the IPM loss effectively reduces demographic parity violations while maintaining reasonable predictive accuracy.

## Method Summary
The method introduces group fairness metrics for PPM using independence criteria, proposing threshold-independent distribution-based metrics (ABPC and ABCC) alongside traditional demographic parity metrics (ΔDP). The core approach employs a composite loss function combining binary cross-entropy (LBCE) with a Wasserstein-based integral probability metric (LIPM) to train LSTM-based outcome classifiers. The total loss function Ltotal=(1−λ)·LBCE+λ·LIPM allows customizable trade-offs between predictive performance and fairness through the λ hyperparameter. The Wasserstein distance is used as the IPM to align prediction distributions across protected groups, reducing demographic parity violations while maintaining predictive accuracy as measured by AUC.

## Key Results
- Wasserstein distance proves particularly effective for aligning prediction distributions across protected groups
- Composite loss function achieves Pareto-optimal trade-offs between AUC and fairness metrics
- Threshold-independent metrics (ABPC, ABCC) provide more robust fairness evaluation than threshold-dependent ΔDP
- Large observed difference between ΔDP0.5 and ΔDPopt values highlights sensitivity of binary ΔDP to threshold selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Wasserstein distance effectively aligns prediction distributions across protected groups, reducing demographic parity violations.
- Mechanism: By minimizing the Earth Mover's Distance between probability distributions of predictions for different groups, the model is encouraged to produce similar output distributions regardless of group membership.
- Core assumption: The Wasserstein distance provides a meaningful measure of distributional discrepancy that correlates with fairness violations.
- Evidence anchors:
  - [abstract]: "The Wasserstein distance proves particularly effective for aligning prediction distributions across protected groups"
  - [section 3.2]: "we employ the Wasserstein distance (also known as Earth Mover's Distance) as the IPM"
  - [corpus]: Weak evidence - corpus neighbors don't directly address Wasserstein distance effectiveness
- Break condition: If the prediction distributions are multimodal or highly complex, Wasserstein distance may not capture all fairness violations effectively.

### Mechanism 2
- Claim: Threshold-independent distribution-based metrics (ABPC and ABCC) provide more robust fairness evaluation than threshold-dependent metrics like ΔDP.
- Mechanism: These metrics measure the area between probability density curves or cumulative density functions across the entire output range, capturing distributional differences that threshold-specific metrics miss.
- Core assumption: Fairness should be evaluated across all possible classification thresholds, not just a single fixed threshold.
- Evidence anchors:
  - [abstract]: "proposing and evaluating metrics for demographic parity such as ΔDP, alongside more advanced, threshold-independent distribution-based alternatives area between probability density function curves (ABPC) and area between cumulative density function curves (ABCC)"
  - [section 3.1]: "To address these limitations, recent work has shifted towards evaluating fairness across the entire output distribution"
  - [section 5.4]: "The large observed difference between the ΔDP0.5 b and ΔDPopt. b values, highlight the sensitivity of binary ΔDP to threshold selection"
- Break condition: If the output distributions are identical across groups, these metrics would show no violation even if there are other forms of unfairness.

### Mechanism 3
- Claim: Composite loss functions balancing predictive performance and fairness allow customizable trade-offs through the λ hyperparameter.
- Mechanism: The total loss function combines binary cross-entropy (LBCE) for predictive accuracy with the IPM loss (LWasserstein) for fairness, with λ controlling the relative importance of each component.
- Core assumption: There exists a meaningful trade-off between predictive accuracy and fairness that can be navigated through loss function design.
- Evidence anchors:
  - [abstract]: "propose a composite loss function existing of binary cross-entropy and a distribution-based loss (Wasserstein) to train models that balance predictive performance and fairness, and allow for customizable trade-offs"
  - [section 3.2]: "Ltotal=(1−λ)·LBCE+λ·LIPM (5)"
  - [section 5.4]: "Figure 4 clearly demonstrate the trade-off between predictive quality and demographic parity violation when balancing the IPM and BCE loss functions"
- Break condition: If λ is set too high, predictive performance may degrade beyond acceptable levels for the application.

## Foundational Learning

- Concept: Demographic parity through independence
  - Why needed here: This is the primary fairness criterion being addressed in the paper
  - Quick check question: What does it mean for predictions to be independent of sensitive attributes?
- Concept: Integral Probability Metrics (IPMs)
  - Why needed here: These provide the mathematical foundation for the Wasserstein distance-based loss function
  - Quick check question: How does the Wasserstein distance differ from other probability metrics like KL divergence?
- Concept: Threshold-independent evaluation
  - Why needed here: PPM applications often require flexibility in threshold selection based on business needs
  - Quick check question: Why might threshold-dependent metrics be insufficient for PPM applications?

## Architecture Onboarding

- Component map: Event log -> Prefix generation -> Model training with composite loss -> Fairness evaluation
- Critical path: Event log → Prefix generation → Model training with composite loss → Fairness evaluation
- Design tradeoffs: λ hyperparameter balancing fairness vs. accuracy; choice of IPM metric (Wasserstein vs alternatives)
- Failure signatures: Poor predictive performance with high λ; insufficient fairness improvement with low λ
- First 3 experiments:
  1. Train baseline LSTM with BCE loss only and evaluate fairness metrics
  2. Train with Wasserstein IPM loss at different λ values and plot fairness-accuracy trade-off
  3. Compare fairness metrics (ΔDP vs ABPC/ABCC) on same model outputs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do independence fairness metrics (ABPC, ABCC) compare to traditional demographic parity metrics (ΔDP) in real-world PPM applications with complex, multi-dimensional sensitive attributes?
- Basis in paper: [explicit] The paper proposes and evaluates both traditional and distribution-based fairness metrics but primarily uses artificial datasets with binary sensitive attributes
- Why unresolved: Real-world event logs often contain multi-dimensional sensitive attributes and complex feature interactions that weren't tested in the controlled experiments
- What evidence would resolve it: Empirical evaluation on real-world event logs with multi-dimensional sensitive attributes comparing the performance and insights provided by ABPC/ABCC versus ΔDP metrics

### Open Question 2
- Question: How does the Wasserstein IPM loss affect model calibration in PPM applications, and what are the downstream effects on decision-making?
- Basis in paper: [explicit] The paper notes that using composite loss functions may worsen calibration and shows propensity distributions changing shape with different λ values
- Why unresolved: The experiments focus on fairness-performance trade-offs but don't deeply investigate calibration effects or how miscalibration impacts actual decision outcomes in PPM
- What evidence would resolve it: Detailed analysis of calibration metrics across different λ values and studies on how calibration changes affect decision-making accuracy and fairness in real PPM scenarios

### Open Question 3
- Question: What are the optimal strategies for selecting λ values in the composite loss function for different PPM application contexts and risk levels?
- Basis in paper: [explicit] The paper explores various λ values and shows Pareto-optimal trade-offs but doesn't provide guidance on context-specific λ selection
- Why unresolved: The paper demonstrates that λ selection significantly impacts fairness-performance balance but leaves practitioners to determine optimal values through validation without systematic guidance
- What evidence would resolve it: Development of context-aware λ selection frameworks or automated tuning methods that consider application-specific risk levels, regulatory requirements, and domain characteristics

## Limitations

- Use of artificial datasets limits generalizability to real-world PPM applications with complex, multi-dimensional sensitive attributes
- Wasserstein distance may not fully capture all forms of fairness violations in high-dimensional or multimodal prediction spaces
- Effectiveness of composite loss function depends heavily on appropriate λ selection, which may require application-specific tuning

## Confidence

- **High Confidence**: The mathematical formulation of the composite loss function and its implementation are well-specified and reproducible. The threshold-independent metrics (ABPC, ABCC) provide theoretically sound alternatives to traditional fairness measures.
- **Medium Confidence**: The effectiveness of Wasserstein distance for fairness alignment is demonstrated on artificial datasets but requires validation on real-world PPM applications. The trade-off characterization between fairness and predictive performance is clear but may vary across different domains.
- **Low Confidence**: The generalizability of findings to complex, real-world process monitoring scenarios remains uncertain due to the controlled nature of the experimental datasets.

## Next Checks

1. **Real-world Dataset Validation**: Apply the proposed framework to a real-world business process dataset (e.g., hospital patient flow or manufacturing quality control) to assess whether the Wasserstein-based approach maintains effectiveness outside artificial settings.

2. **Alternative IPM Comparison**: Conduct experiments comparing Wasserstein distance against other IPMs (Maximum Mean Discrepancy, Total Variation Distance) to determine if the observed benefits are specific to Wasserstein or generalizable across distributional metrics.

3. **Multi-attribute Fairness Extension**: Extend the current single-sensitive-attribute framework to handle multiple protected attributes simultaneously, evaluating whether the composite loss function can effectively balance fairness across multiple demographic dimensions.