---
ver: rpa2
title: 'DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question
  Answering over Knowledge Graphs'
arxiv_id: '2406.07080'
source_url: https://arxiv.org/abs/2406.07080
tags:
- dara
- task
- relations
- question
- variable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DARA, a fine-tuned autonomous language agent
  for KGQA that outperforms both in-context learning agents and alternative fine-tuned
  models. DARA leverages iterative task decomposition and task grounding, using a
  skim-then-deep-reading method for relation selection, to construct logical forms
  for KGQA.
---

# DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs

## Quick Facts
- arXiv ID: 2406.07080
- Source URL: https://arxiv.org/abs/2406.07080
- Reference count: 40
- Primary result: DARA achieves state-of-the-art performance on KGQA benchmarks through iterative task decomposition and fine-tuning

## Executive Summary
This paper introduces DARA, a fine-tuned autonomous language agent for Knowledge Graph Question Answering (KGQA) that outperforms both in-context learning agents and alternative fine-tuned models. DARA leverages iterative task decomposition and task grounding, using a skim-then-deep-reading method for relation selection, to construct logical forms for KGQA. Experiments on three benchmarks show DARA achieves state-of-the-art performance in zero-shot evaluation, demonstrating strong capabilities with various backend LLMs. Notably, DARA can be trained efficiently with a small number of high-quality reasoning trajectories, making it more accessible for real-life applications compared to expensive commercial LLM agents.

## Method Summary
DARA is a fine-tuned autonomous language agent for KGQA that decomposes questions into subtasks iteratively rather than generating all subtasks upfront. It uses a two-stage relation selection process (skim-then-deep-reading) to identify appropriate schema items from knowledge graph descriptions. The agent constructs logical forms (s-expressions) representing SPARQL queries through a decomposition-alignment-reasoning pipeline. DARA is trained on reasoning trajectories converted from golden logical forms, enabling efficient learning with limited data. The system interacts with knowledge graphs through a function-based action space and can be deployed with various backend LLMs.

## Key Results
- DARA outperforms in-context learning agents and alternative fine-tuned LLM agents on three KGQA benchmarks
- Iterative task decomposition provides 6%+ performance improvement over single-pass pre-decomposition
- Skim-then-deep-reading relation selection improves accuracy by 5.95%+ on GraphQ benchmark
- DARA achieves state-of-the-art performance in zero-shot evaluation with various backend LLMs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Iterative task decomposition improves performance over single-pass pre-decomposition.
- **Mechanism**: Instead of generating all subtasks upfront, DARA generates one task at a time, building on previous results. This allows dynamic refinement of focus and prevents redundant or irrelevant tasks.
- **Core assumption**: LLM can correctly decide when no further decomposition is needed based on current logical form.
- **Evidence anchors**:
  - [abstract]: "DARA incorporates and advocates iterative task decomposition, which generates one task at a time building on the results of the previous task."
  - [section]: "As shown in Table 4, when equipped with the single-pass pre-decomposition (PD), the performance drops more than 6% on GraphQ, GrailQA and 14.39% on WebQSP."
- **Break condition**: If the LLM fails to recognize when the current logical form can answer the question, it will either over-decompose (unnecessary tasks) or under-decompose (incomplete answer).

### Mechanism 2
- **Claim**: The skim-then-deep-reading relation selection method improves schema item selection accuracy.
- **Mechanism**: First skim relations of current entities to select n promising candidates, then deeply read their descriptions to select the most suitable one. This eliminates need for extensive pre-training on KG schemas.
- **Core assumption**: LLM can accurately interpret relation descriptions to identify the most appropriate schema item for the current task.
- **Evidence anchors**:
  - [abstract]: "To enhance the selection of relations, we propose a relation selection method, termed skim-then-deep-reading, where DARA scans relations of current entities and selects n promising relations to deeply read their descriptions."
  - [section]: "The results presented in Table 4 demonstrate the significance of the skim-then-deep-reading relation (SDR) selection strategy. When this strategy is not employed, the performance experiences a decrease, especially in GraphQ (5.95% drop)."
- **Break condition**: If relation descriptions are ambiguous or if the LLM misinterprets the semantic meaning, the method will select incorrect relations.

### Mechanism 3
- **Claim**: Fine-tuning with a small number of high-quality reasoning trajectories enables strong performance without requiring massive datasets.
- **Mechanism**: By using GPT-4 to convert golden logical forms into natural language reasoning trajectories, then fine-tuning DARA on these trajectories, the model learns the decomposition-alignment-reasoning pipeline efficiently.
- **Core assumption**: The reasoning trajectories generated by GPT-4 (even after human verification) capture the essential reasoning patterns needed for KGQA.
- **Evidence anchors**:
  - [abstract]: "Importantly, DARA can be efficiently trained with a small number of high-quality reasoning trajectories."
  - [section]: "Our findings confirm that DARA substantially outperforms both ICL-based and the alternative fine-tuned LLM agents... across the three important benchmarks in zero-shot evaluation."
- **Break condition**: If GPT-4 cannot generate high-quality reasoning trajectories (as observed in section 5.4), the fine-tuning data will be insufficient for learning effective reasoning patterns.

## Foundational Learning

- **Concept**: Knowledge Graph Question Answering (KGQA)
  - Why needed here: DARA is specifically designed for KGQA, requiring understanding of how to query knowledge graphs using logical forms.
  - Quick check question: What is the difference between KGQA and traditional question answering over text corpora?

- **Concept**: Semantic Parsing and Logical Forms
  - Why needed here: DARA constructs s-expressions (logical forms) to represent SPARQL queries for KG querying.
  - Quick check question: How does an s-expression represent a SPARQL query, and what are the key logical operations used?

- **Concept**: Large Language Model Fine-tuning
  - Why needed here: DARA is fine-tuned on LLM to learn the decomposition-alignment-reasoning pipeline.
  - Quick check question: What are the key differences between fine-tuning and in-context learning for LLMs?

## Architecture Onboarding

- **Component map**: Question → Iterative Task Decomposition → Task Grounding (Skim Relations → Deep Reading Descriptions → Schema Selection) → Logical Form Construction → KG Query → Answer

- **Critical path**: Question → Iterative Task Decomposition → Task Grounding (Skim Relations → Deep Reading Descriptions → Schema Selection) → Logical Form Construction → KG Query → Answer

- **Design tradeoffs**: DARA trades off computational efficiency for accuracy by using iterative decomposition instead of exhaustive enumeration. It also requires fine-tuning (cost) to achieve better performance than in-context learning methods.

- **Failure signatures**: 
  - Incorrect task decomposition leading to irrelevant subtasks
  - Wrong relation selection due to ambiguous descriptions
  - Logical form construction errors due to syntax misunderstanding
  - Premature termination at CVT nodes in Freebase

- **First 3 experiments**:
  1. Implement iterative task decomposition and compare performance against single-pass pre-decomposition on a small KGQA dataset
  2. Test skim-then-deep-reading relation selection against baseline methods (random selection, description-only) on relation selection accuracy
  3. Fine-tune DARA on 100 reasoning trajectories and evaluate zero-shot performance on a held-out KGQA dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can DARA be effectively adapted to knowledge graphs other than Freebase, such as Wikidata, given the current limitations of intermediate representation?
- Basis in paper: [inferred] The paper mentions that the current intermediate representation (s-expression) cannot be directly transferred to other knowledge graphs like Wikidata.
- Why unresolved: The paper does not explore the generalization of DARA to other knowledge graphs, and it remains an open question how well the current framework and intermediate representations would perform with different knowledge graph structures.
- What evidence would resolve it: Experiments demonstrating DARA's performance on knowledge graphs other than Freebase, such as Wikidata, would provide evidence of its adaptability and generalization capabilities.

### Open Question 2
- Question: How can the quality of automatically generated reasoning trajectories for language agents be improved, particularly when using GPT-4, to reduce the need for human verification?
- Basis in paper: [explicit] The paper discusses the challenges faced by GPT-4 in converting structured logical forms into natural language for reasoning trajectory construction and highlights the need for human verification.
- Why unresolved: The paper identifies the issue but does not propose a solution to improve the quality of automatically generated trajectories, leaving it as a potential future research direction.
- What evidence would resolve it: Development and testing of methods that enhance the quality of automatically generated reasoning trajectories, reducing the reliance on human verification, would address this open question.

### Open Question 3
- Question: What are the potential improvements in error correction capabilities for DARA, and how can they be implemented to enhance the agent's performance in complex tasks?
- Basis in paper: [inferred] The paper mentions that DARA lacks error-correcting ability, which is a limitation that needs improvement.
- Why unresolved: The paper does not explore specific methods or strategies to implement error correction in DARA, leaving this as an area for future research.
- What evidence would resolve it: Implementing and evaluating error correction mechanisms in DARA, such as those inspired by reflection techniques, and demonstrating their impact on performance would provide insights into potential improvements.

## Limitations

- DARA's performance heavily depends on the quality of GPT-4-generated reasoning trajectories, which cannot be directly generated correctly
- Evaluation focuses primarily on clean benchmark datasets rather than noisy real-world questions
- Computational overhead of iterative decomposition is not fully characterized in terms of runtime and latency

## Confidence

**High Confidence (8/10)**: The core claim that DARA outperforms in-context learning agents is well-supported by experimental results across multiple benchmarks.

**Medium Confidence (6/10)**: The claim about efficient training with "small number of high-quality reasoning trajectories" is supported but depends heavily on GPT-4 trajectory generation quality.

**Low Confidence (4/10)**: Claims about applicability to "real-life applications" are not well-supported as evaluation focuses on benchmark datasets without addressing real-world complexity.

## Next Checks

1. **Cross-LLM Generalization Test**: Fine-tune DARA using reasoning trajectories generated by multiple different LLM backends (not just GPT-4), then evaluate whether performance gains are consistent across these variants or if they're specific to the original fine-tuning setup.

2. **Real-World Noise Evaluation**: Construct a benchmark with intentionally ambiguous or noisy relation descriptions and entity labels, then measure how DARA's performance degrades compared to commercial LLM agents.

3. **Computational Overhead Analysis**: Measure the total latency and computational cost of DARA (including all LLM calls during iterative decomposition) versus both commercial LLM agents and simpler fine-tuned models.