---
ver: rpa2
title: Fairness Risks for Group-conditionally Missing Demographics
arxiv_id: '2402.13393'
source_url: https://arxiv.org/abs/2402.13393
tags:
- fairness
- error
- ablation
- fairda
- ours
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a novel framework for fair classification in
  the presence of group-conditionally missing demographics, where individuals from
  different demographic groups may be differentially reluctant to reveal their sensitive
  attributes. The key idea is to augment standard fairness risks with probabilistic
  imputations of missing sensitive features, while jointly learning group-conditional
  missing probabilities in a variational auto-encoder (VAE).
---

# Fairness Risks for Group-conditionally Missing Demographics

## Quick Facts
- arXiv ID: 2402.13393
- Source URL: https://arxiv.org/abs/2402.13393
- Reference count: 40
- This work proposes a novel framework for fair classification in the presence of group-conditionally missing demographics.

## Executive Summary
This paper addresses the challenge of fair classification when demographic information is group-conditionally missing - where individuals from different demographic groups may be differentially reluctant to reveal their sensitive attributes. The authors propose Fair-SS-VAE, a framework that augments standard fairness risks with probabilistic imputations of missing sensitive features while jointly learning group-conditional missing probabilities in a variational auto-encoder. The method employs Monte Carlo sampling with provable concentration bounds to efficiently evaluate fairness risks and uses stop-gradient techniques to prevent the demographic inference model from being influenced by fairness optimization.

## Method Summary
The Fair-SS-VAE framework extends semi-supervised variational auto-encoders to handle group-conditionally missing demographics by learning P(̃A|A) and P(̃Y|Y) to represent group-conditionally unavailable demographics and labels. The method uses Monte Carlo sampling with provable concentration bounds to estimate fairness risks, and employs stop-gradient techniques to ensure demographic inference accuracy isn't compromised by fairness optimization. The model jointly optimizes demographic inference and fairness risk while maintaining the recusal principle that demographic inference should not be influenced by fairness considerations.

## Key Results
- Fair-SS-VAE significantly outperforms state-of-the-art semi-supervised fair classification methods on both image (CelebA) and tabular (Adult) datasets
- The approach achieves improved balance between accuracy and fairness metrics (DEO and DEOPP) across various levels of missing demographic data
- The method is particularly effective when demographics are partially available rather than completely missing
- Experimental results show robust performance with different missingness probabilities and fairness constraints

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint optimization of demographic inference and fairness risk with stop-gradient prevents the demographic inference model from being influenced by fairness optimization.
- Mechanism: The stop-gradient technique blocks backpropagation through the demographic inference model when computing the fairness risk, ensuring that the demographic model only learns to accurately estimate demographics without being biased by fairness considerations.
- Core assumption: The demographic inference model can accurately estimate demographics without fairness guidance, and this accuracy is sufficient for downstream fairness evaluation.
- Evidence anchors:
  - [abstract]: "uses stop-gradient techniques to prevent the demographic inference model from being influenced by fairness optimization"
  - [section 4.1]: "A natural workaround is a two-step approach... However, sharing backbones will allow qϕ(A|X, ˜A) to be influenced by the learning of Pf(Y |X, ˜Y), conflicting with the aforementioned recusal principle. In light of this difficulty, we resort to the commonly used stop-gradient technique"
  - [corpus]: Weak - the corpus contains related fairness work but no direct mention of stop-gradient techniques
- Break condition: If the demographic inference model cannot accurately estimate demographics without fairness guidance, the fairness risk evaluation becomes unreliable.

### Mechanism 2
- Claim: Monte Carlo sampling with provable concentration bounds enables efficient evaluation of complex fairness risks.
- Mechanism: The method uses N iid samples from the demographic and label distributions to estimate the fairness risk, with a sample complexity of O(1/ϵ²) to achieve ϵ-accurate approximation with confidence 1-δ.
- Core assumption: The fairness risk function F is bounded in [0,C], which is satisfied for most fairness metrics considered.
- Evidence anchors:
  - [abstract]: "employs Monte Carlo sampling with provable concentration bounds to efficiently evaluate fairness risks"
  - [section 4.3]: "Our method simply draws N number of iid samples from Ai ∼ qϕ(A|xi, ˜ai) and Yi ∼ Pg(Y |xi). For s = 1, . . . , N, let Zs := {a(s)i , y(s)i }n i=1. We estimate E by ˆEn(Z1, . . . , ZN) := 1 N XN s=1 F(Pf , Zs)"
  - [section 4.3]: "Theorem 1. Suppose F ∈ [0, C] where C > 0 is a constant. Then for all ϵ > 0, P (| ˆEn(Z1, . . . , ZN) − E| ≥ ϵ) ≤ 2 exp(−2N ϵ2/C 2)"
- Break condition: If the fairness risk function is unbounded (like disparate impact), the concentration bounds no longer hold.

### Mechanism 3
- Claim: Group-conditional missing probability modeling captures realistic data unavailability patterns.
- Mechanism: The model learns P(̃A|A) and P(̃Y|Y) to represent group-conditionally unavailable demographics and labels, allowing different missing rates for different demographic groups.
- Core assumption: The unavailability of demographic information depends on the specific demographic group, not just random missingness.
- Evidence anchors:
  - [abstract]: "group-conditionally missing demographics, where individuals from different demographic groups may be differentially reluctant to reveal their sensitive attributes"
  - [section 4]: "As a key contribution of this work, we further address group-conditionally unavailable demographics, where demographics can get unavailable in a non-uniform fashion, depending on the specific group"
  - [corpus]: Weak - the corpus mentions fairness-aware methods but doesn't specifically discuss group-conditional missingness
- Break condition: If demographic unavailability is actually random or follows a different pattern than group-conditional, the model may overfit to spurious correlations.

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) for semi-supervised learning
  - Why needed here: The method extends SS-VAE to handle missing demographics by learning group-conditional missing probabilities and integrating fairness risk
  - Quick check question: How does the SS-VAE encoder factorize the posterior distribution of latent variables given observed and missing data?

- Concept: Fairness risk metrics and their empirical estimation
  - Why needed here: The method augments standard fairness risks with probabilistic imputations, requiring differentiable estimation of metrics like demographic parity and equalized odds
  - Quick check question: How can you estimate P(Ŷ=1|A=a) from data when A is only partially observed?

- Concept: Monte Carlo concentration bounds and sample complexity
  - Why needed here: The method relies on Monte Carlo sampling to estimate fairness risks, requiring understanding of when and how many samples are needed for accurate approximation
  - Quick check question: What is the relationship between sample size N, accuracy ϵ, and confidence 1-δ in Monte Carlo concentration bounds?

## Architecture Onboarding

- Component map: VAE encoder -> Demographic and label inference -> Monte Carlo sampling -> Fairness risk evaluation -> Stop-gradient backpropagation -> Model update
- Critical path: Data → VAE encoder → Demographic and label inference → Monte Carlo sampling → Fairness risk evaluation → Stop-gradient backpropagation → Model update
- Design tradeoffs: Accuracy vs fairness tradeoff controlled by λ, sample size N vs computation cost, model complexity vs overfitting risk
- Failure signatures: High variance in fairness metrics across runs suggests insufficient Monte Carlo samples, degraded demographic inference accuracy indicates stop-gradient may be too restrictive
- First 3 experiments:
  1. Implement basic SS-VAE with fully observed demographics and verify fairness metrics can be computed
  2. Add Monte Carlo sampling for fairness risk estimation and test concentration bounds empirically
  3. Implement stop-gradient mechanism and verify it prevents fairness optimization from affecting demographic inference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Fair-SS-VAE framework be extended to handle proxy features when they are available, and how would this affect the model's performance and fairness outcomes?
- Basis in paper: [inferred] The paper mentions as a limitation that proxy features were not incorporated when available, and suggests future work to enable this by conditioning VAEs on proxy features.
- Why unresolved: The current Fair-SS-VAE model does not account for proxy features, which could potentially improve fairness outcomes by providing additional information about sensitive attributes.
- What evidence would resolve it: Experimental results comparing Fair-SS-VAE with and without proxy features on datasets where proxy features are available would provide insights into the impact of incorporating proxy features on fairness and performance.

### Open Question 2
- Question: How does the choice of the temperature parameter T in the softened step function affect the differentiability and performance of the Fair-SS-VAE model?
- Basis in paper: [explicit] The paper mentions that the step function [ [· > 0] ] offers no useful derivative and proposes a softened step function with a temperature parameter T to enable differentiation.
- Why unresolved: The impact of the temperature parameter T on the model's differentiability and performance is not explored in the paper, leaving questions about the optimal choice of T for different datasets and fairness metrics.
- What evidence would resolve it: Sensitivity analysis of the Fair-SS-VAE model's performance and fairness outcomes across a range of temperature parameter values would provide insights into the optimal choice of T for different scenarios.

### Open Question 3
- Question: How does the Fair-SS-VAE model perform when the sensitive features are continuous rather than binary, and what modifications would be necessary to adapt the model to this setting?
- Basis in paper: [inferred] The paper mentions that the Fair-SS-VAE model can readily extend y and a from binary values to multi-class and continuous, with little impact on Monte Carlo sampling in (9). However, the paper does not explore the performance of the model with continuous sensitive features.
- Why unresolved: The performance of the Fair-SS-VAE model with continuous sensitive features is not evaluated, leaving questions about the model's applicability to real-world scenarios where sensitive features may be continuous.
- What evidence would resolve it: Experimental results comparing the Fair-SS-VAE model's performance and fairness outcomes on datasets with continuous sensitive features would provide insights into the model's applicability and any necessary modifications for this setting.

## Limitations
- The method's effectiveness critically depends on the assumption that group-conditional missingness patterns can be accurately modeled by P(̃A|A) and P(̃Y|Y)
- The stop-gradient technique may limit the model's ability to improve demographic estimation based on fairness feedback
- The Monte Carlo concentration bounds require bounded fairness risk functions, excluding metrics like disparate impact that can be unbounded
- The computational overhead of Monte Carlo sampling with multiple draws may be prohibitive for large-scale applications

## Confidence

- **High Confidence**: The theoretical framework for fairness risk estimation with Monte Carlo sampling (Theorem 1 concentration bounds)
- **Medium Confidence**: The effectiveness of stop-gradient in preventing fairness optimization from influencing demographic inference
- **Medium Confidence**: The overall performance improvements on CelebA and Adult datasets relative to baselines
- **Low Confidence**: Generalization to datasets with different missingness patterns or fairness constraints not considered in the experiments

## Next Checks
1. **Missingness Mechanism Sensitivity**: Test the model's performance when the true missingness mechanism deviates from the assumed group-conditional Bernoulli model, particularly with non-IID missingness patterns.

2. **Stop-Gradient Ablation**: Compare the proposed method against variants where demographic inference receives partial fairness feedback (soft stop-gradient) to quantify the tradeoff between demographic accuracy and fairness performance.

3. **Scalability Analysis**: Evaluate the method's computational efficiency with varying numbers of Monte Carlo samples (N) and dataset sizes to establish practical limits on sample complexity and runtime.