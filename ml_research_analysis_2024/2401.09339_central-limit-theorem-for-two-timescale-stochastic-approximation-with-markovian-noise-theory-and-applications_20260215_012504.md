---
ver: rpa2
title: 'Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian
  Noise: Theory and Applications'
arxiv_id: '2401.09339'
source_url: https://arxiv.org/abs/2401.09339
tags: []
core_contribution: The paper conducts a central limit theorem (CLT) analysis for two-timescale
  stochastic approximation (TTSA) under controlled Markovian noise, a setting not
  previously addressed. It extends existing CLT results limited to Martingale difference
  noise by incorporating the effect of the underlying Markov chain on the coupled
  dynamics of TTSA iterates.
---

# Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications

## Quick Facts
- arXiv ID: 2401.09339
- Source URL: https://arxiv.org/abs/2401.09339
- Authors: Jie Hu; Vishwaraj Doshi; Do Young Eun
- Reference count: 40
- Primary result: Proves CLT for TTSA under controlled Markovian noise, enabling performance ordering based on sampling strategies and showing identical asymptotic behavior for nonlinear GTD2/TDC algorithms.

## Executive Summary
This paper establishes a Central Limit Theorem for two-timescale stochastic approximation under controlled Markovian noise, extending existing CLT results limited to Martingale difference noise. The authors develop a framework that incorporates the effect of the underlying Markov chain on the coupled dynamics of TTSA iterates, showing that scaled errors converge to Gaussian vectors with covariances determined by both algorithm dynamics and sampling efficiency. The theoretical results enable performance ordering across TTSA algorithms based on sampling strategies and demonstrate that nonlinear GTD2 and TDC algorithms have identical asymptotic behavior under Markovian samples.

## Method Summary
The paper analyzes TTSA algorithms where the noise follows controlled Markovian dynamics rather than simple Martingale differences. The key methodological innovation is decomposing the Markovian noise using Poisson equation techniques, which isolates Martingale difference terms from additional bias terms introduced by the Markov chain. The authors establish conditions under which TTSA iterates converge almost surely and then derive limiting covariance matrices through Lyapunov equations. The framework connects sampling efficiency of the Markov chain to asymptotic performance, providing a theoretical basis for comparing different sampling strategies in bilevel optimization and reinforcement learning applications.

## Key Results
- Proves CLT for TTSA under controlled Markovian noise, showing scaled iterate errors converge to Gaussian vectors
- Establishes performance ordering across TTSA algorithms based on Markov chain sampling efficiency
- Demonstrates that nonlinear GTD2 and TDC algorithms have identical asymptotic behavior under Markovian samples
- Provides explicit forms for limiting covariance matrices through Lyapunov equations

## Why This Works (Mechanism)

### Mechanism 1
The paper proves a CLT for TTSA under controlled Markovian noise by decomposing the noise using Poisson equation techniques. This isolates Martingale difference terms and additional bias terms from the underlying Markov chain, allowing analysis of coupled dynamics. The core assumption is almost sure convergence of TTSA iterates and ergodicity of the Markov chain with continuous transition kernel.

### Mechanism 2
The limiting covariance matrices Vx and Vy incorporate the effect of the underlying Markov chain through matrices Ux and U22. These matrices capture sampling efficiency and are key components in Lyapunov equations determining Vx and Vy. The Markov chain must be efficiency-ordered for performance ordering to hold.

### Mechanism 3
The paper shows nonlinear GTD2 and TDC algorithms have identical asymptotic behavior by applying the CLT result to both algorithms. This yields identical limiting covariance matrices Vx and Vy under Markovian samples, a conclusion not evident from finite-time bounds. Both algorithms must satisfy CLT conditions including almost sure convergence and appropriate step size choices.

## Foundational Learning

- **Poisson equation technique for decomposing Markovian noise**: Needed to isolate Martingale difference terms and bias terms from the Markov chain. Quick check: How does the Poisson equation technique help in decomposing Markovian noise in TTSA algorithms?

- **Efficiency ordering of Markov chains**: Needed to establish performance ordering across TTSA algorithms based on sampling strategies. Quick check: What is the definition of efficiency ordering of Markov chains, and how does it relate to the limiting covariance in TTSA algorithms?

- **Lyapunov equations for determining limiting covariance matrices**: Needed to derive explicit forms of limiting covariance matrices Vx and Vy in the CLT result. Quick check: How are the Lyapunov equations used to determine the limiting covariance matrices in the CLT result for TTSA algorithms?

## Architecture Onboarding

- **Component map**: TTSA algorithm with controlled Markovian noise -> Poisson equation technique for noise decomposition -> Efficiency ordering of Markov chains -> Lyapunov equations for limiting covariance -> Nonlinear GTD2 and TDC algorithms

- **Critical path**: 1) Establish almost sure convergence of TTSA iterates, 2) Decompose Markovian noise using Poisson equation, 3) Derive limiting covariance matrices using Lyapunov equations, 4) Show performance ordering based on sampling strategies, 5) Apply results to nonlinear GTD2 and TDC algorithms

- **Design tradeoffs**: More general Markovian noise vs. specific noise types (Martingale difference), efficiency ordering vs. specific sampling strategies, asymptotic analysis vs. finite-time bounds

- **Failure signatures**: Lack of almost sure convergence of TTSA iterates, non-ergodic or discontinuous Markov chain, inefficiency ordering not holding for the Markov chain, different step size choices leading to different asymptotic behavior

- **First 3 experiments**: 1) Verify almost sure convergence of TTSA iterates for a given Markov chain, 2) Apply Poisson equation technique to decompose Markovian noise in a simple TTSA algorithm, 3) Derive limiting covariance matrices for a TTSA algorithm with a specific Markov chain and sampling strategy

## Open Questions the Paper Calls Out

### Open Question 1
How does the convergence rate of the TTSA algorithm change when the step sizes deviate from the specific choices (e.g., βn = (n+1)^(-1), γn = (n+1)^(-0.8)) used in the RL experiments? The paper discusses the general TTSA framework with arbitrary step sizes but only provides simulation results for specific choices in the RL experiments.

### Open Question 2
Can the CLT results be extended to more general function approximation schemes beyond the linear and nonlinear examples discussed in the paper? The paper focuses on nonlinear function approximation in the context of RL but does not discuss other potential function approximation schemes.

### Open Question 3
How does the efficiency ordering of Markov chains affect the performance of TTSA algorithms in high-dimensional settings? The paper discusses the efficiency ordering of Markov chains and its impact on TTSA performance, but the simulations are conducted in low-dimensional settings.

## Limitations

- The theoretical framework relies on ergodicity and continuous transition kernel assumptions that may not hold in practical implementations
- The efficiency ordering framework provides theoretical ordering but may have limited practical applicability due to computational complexity considerations
- The extension to nonlinear function approximation and its implications for practical algorithm design are not fully explored

## Confidence

**High Confidence**: The CLT result itself (Theorem 3.1) and its application to nonlinear GTD2/TDC algorithms (Proposition 3.3) are mathematically sound given the stated assumptions.

**Medium Confidence**: The performance ordering claims (Proposition 3.2) rely on the efficiency ordering framework, which provides a theoretical ordering but may have limited practical applicability.

**Low Confidence**: The extension to nonlinear function approximation and its implications for practical algorithm design are not fully explored. The numerical experiments are limited in scope.

## Next Checks

1. **Assumption Verification**: Implement a systematic procedure to verify the ergodicity and efficiency ordering assumptions for common Markov chains used in RL applications (e.g., uniform vs. prioritized sampling in experience replay).

2. **Practical Implementation Study**: Design experiments comparing TTSA algorithms with different sampling strategies on benchmark RL tasks, measuring both theoretical metrics (limiting covariance) and practical metrics (sample complexity, wall-clock time).

3. **Robustness Analysis**: Investigate the sensitivity of the CLT results to violations of assumptions, particularly focusing on non-ergodic Markov chains and discontinuous transition kernels, to understand the practical boundaries of the theoretical framework.