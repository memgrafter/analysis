---
ver: rpa2
title: Out-of-Distribution Detection with a Single Unconditional Diffusion Model
arxiv_id: '2405.11881'
source_url: https://arxiv.org/abs/2405.11881
tags:
- detection
- diffusion
- samples
- celeba
- distributions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of out-of-distribution (OOD) detection
  using a single unconditional diffusion model, rather than training separate generative
  models for each inlier dataset. The core idea is to measure the rate-of-change and
  curvature of the diffusion paths connecting samples to the standard normal distribution,
  which can be computed from the score predicted by the diffusion model.
---

# Out-of-Distribution Detection with a Single Unconditional Diffusion Model

## Quick Facts
- arXiv ID: 2405.11881
- Source URL: https://arxiv.org/abs/2405.11881
- Authors: Alvin Heng; Alexandre H. Thiery; Harold Soh
- Reference count: 40
- Key outcome: A single unconditional diffusion model can perform OOD detection across diverse tasks, achieving 0.931 average AUROC on 6 OOD tasks with DiffPath-6D using CelebA as base distribution

## Executive Summary
This paper introduces DiffPath, a novel approach to out-of-distribution (OOD) detection using a single unconditional diffusion model. Rather than training separate generative models for each inlier dataset, DiffPath measures the rate-of-change and curvature of diffusion paths connecting samples to the standard normal distribution. The method computes statistics from the score function predicted by the diffusion model and uses these for OOD detection. Extensive experiments show that with a single model, DiffPath is competitive with prior work using individual models on a variety of OOD tasks involving different distributions.

## Method Summary
DiffPath uses a pretrained unconditional diffusion model to compute OOD scores based on geometric properties of the diffusion path. For each sample, the method performs DDIM forward integration and computes statistics including the norm of the score function and its time derivative at each timestep. Two variants are proposed: DiffPath-1D uses the final timestep statistic, while DiffPath-6D uses statistics from all timesteps. A density estimator (KDE or GMM) is fit to training statistics, and OOD scores are computed as the negative log-likelihood under this density model. The approach requires only 10 function evaluations, significantly less than other diffusion-based approaches.

## Key Results
- DiffPath-6D with CelebA base distribution achieves 0.931 average AUROC across 6 OOD tasks
- Single model approach is competitive with methods using individual models per task
- DiffPath requires only 10 function evaluations compared to hundreds in prior diffusion-based methods
- CelebA consistently outperforms CIFAR10 and SVHN as base distribution across tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Measuring the rate-of-change and curvature of the diffusion path provides a reliable OOD detection signal.
- **Mechanism:** The diffusion path from any data distribution to the standard normal is unique and deterministic. Different distributions have distinct path geometries, reflected in the norms of the score function and its time derivative. These geometric differences are preserved across samples from the same distribution.
- **Core assumption:** The DDIM integration using a score model trained on one distribution approximately transports samples from other distributions to standard normal, and the resulting scores along the path retain distributional differences.
- **Evidence anchors:** [abstract] "we introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths connecting samples to the standard normal"; [section] "Empirically, we observe that it is possible to approximate the forward probability flow ODE for different distributions using a single diffusion model."; [corpus] Weak evidence - no direct corpus support for this specific geometric claim
- **Break condition:** If the score model fails to generalize across distributions, or if the forward integration does not approximately reach standard normal, the geometric differences would be lost.

### Mechanism 2
- **Claim:** The score function serves as a proxy for KL divergence between distributions along the diffusion path.
- **Mechanism:** Theorem 1 shows that the expected squared difference of scores between two distributions along the path is proportional to their KL divergence. This makes the score norm a measure of distributional distance.
- **Core assumption:** The regularity conditions of Theorem 1 hold (exponential decay of densities), and the score estimates are accurate enough for the bound to be meaningful.
- **Evidence anchors:** [section] "Theorem 1 suggests that the scores of the marginal distributions along the ODE path serve as a proxy for the KL divergence"; [section] "As DKL(ϕ0∥ψ0) increases, so should the difference in the norms of their scores"; [corpus] Weak evidence - no direct corpus support for this specific theoretical connection
- **Break condition:** If the score estimates are poor or the distributions violate the regularity conditions, the KL proxy relationship breaks down.

### Mechanism 3
- **Claim:** Using a single diffusion model for multiple OOD tasks is feasible due to the model's ability to generalize the diffusion path across distributions.
- **Mechanism:** The DDIM forward integration with a score model trained on one distribution can approximately map samples from other distributions to standard normal. This allows reuse of the same model for different inlier tasks.
- **Core assumption:** The diffusion model's score estimates generalize well enough across distributions to preserve the geometric differences in the diffusion paths.
- **Evidence anchors:** [abstract] "whether a single model can perform OOD detection across diverse tasks"; [section] "we observe the surprising fact that both the ImageNet and CelebA models are able to bring the samples approximately to the standard normal"; [corpus] Moderate evidence - related works like MSMA use score at discrete noise levels, but not this generalization claim
- **Break condition:** If the diffusion model overfits to its training distribution, it will fail to generalize the diffusion path for other distributions.

## Foundational Learning

- **Concept:** Diffusion models and score matching
  - Why needed here: The entire method relies on using the score function predicted by a diffusion model to measure path properties. Understanding how diffusion models work and how scores are estimated is fundamental.
  - Quick check question: What is the relationship between the score function and the probability density in a diffusion model?

- **Concept:** Optimal transport theory
  - Why needed here: The paper connects the diffusion path to the optimal transport path between distributions. Understanding OT theory helps grasp why path properties are meaningful for OOD detection.
  - Quick check question: How does the optimal transport map between two distributions relate to their diffusion paths?

- **Concept:** Out-of-distribution detection metrics (AUROC, NLL)
  - Why needed here: The evaluation uses AUROC scores to compare methods. Understanding these metrics is essential for interpreting results and designing experiments.
  - Quick check question: What does an AUROC score of 0.5 indicate about an OOD detection method's performance?

## Architecture Onboarding

- **Component map:** Trained unconditional diffusion model -> DDIM integration module -> Statistic computation module -> Density estimation module -> Evaluation pipeline

- **Critical path:**
  1. Load pretrained diffusion model
  2. For each sample, perform DDIM forward integration
  3. Compute statistics (score norms, time derivatives)
  4. Aggregate statistics across samples
  5. Fit density estimator to training statistics
  6. Evaluate test samples using density estimator

- **Design tradeoffs:**
  - Single model vs multiple models: Reusability vs potential performance loss
  - 1D vs 6D statistics: Simplicity vs robustness to edge cases
  - KDE vs GMM for density estimation: Computational efficiency vs modeling flexibility

- **Failure signatures:**
  - AUROC scores near 0.5 across tasks (random performance)
  - Inconsistent results when varying DDIM steps
  - Poor separation of inlier vs outlier statistic distributions
  - Failure to generalize when training on different base distributions

- **First 3 experiments:**
  1. Verify that DDIM forward integration with a CIFAR10-trained model maps CIFAR10 and SVHN samples to approximately standard normal
  2. Compute and compare the distributions of ∥ϵθ(xt, t)∥2 for CIFAR10 vs SVHN samples using a CIFAR10-trained model
  3. Evaluate DiffPath-1D performance on CIFAR10 vs SVHN and compare to NLL baseline

## Open Questions the Paper Calls Out

- **Open Question 1:** What is the impact of using higher-order terms in the Taylor expansion of the diffusion ODE on the performance of OOD detection?
  - Basis in paper: [explicit] The paper discusses using higher-order terms in the Taylor expansion (Eq. 8) but only empirically validates the first and second-order terms.
  - Why unresolved: The paper does not explore the performance of using third or higher-order terms in the Taylor expansion for OOD detection.
  - What evidence would resolve it: Conduct experiments comparing the performance of OOD detection using third or higher-order terms in the Taylor expansion to the first and second-order terms.

- **Open Question 2:** How does the performance of DiffPath vary with different choices of the base distribution for the diffusion model?
  - Basis in paper: [explicit] The paper ablates the choice of base distribution (p0(x)) in Table 4 and finds that CelebA yields the best performance.
  - Why unresolved: The paper only explores a limited set of base distributions (CIFAR10, SVHN, CelebA, and ImageNet). Other potential base distributions, such as specialized datasets for specific domains, are not investigated.
  - What evidence would resolve it: Conduct experiments using a wider variety of base distributions, including domain-specific datasets, and compare the performance of DiffPath on different OOD tasks.

- **Open Question 3:** Can DiffPath be effectively applied to other data modalities, such as video, audio, language, time series, and tabular data?
  - Basis in paper: [explicit] The paper only considers natural images (CIFAR10, SVHN, CelebA, CIFAR100, Textures, and ImageNet) for OOD detection.
  - Why unresolved: The paper does not explore the applicability of DiffPath to other data modalities, which may have different characteristics and requirements for OOD detection.
  - What evidence would resolve it: Apply DiffPath to other data modalities and evaluate its performance on OOD detection tasks specific to those modalities.

## Limitations

- Strong reliance on the diffusion model's generalization capability across distributions
- Theoretical justification assumes exponential decay of densities and bounded score norms
- Empirical validation primarily based on image datasets with relatively clean separations
- Performance on more challenging OOD scenarios with complex distributional differences remains untested

## Confidence

- **High**: The core mechanism of using score norms and derivatives as OOD indicators - supported by both theoretical analysis and extensive experiments
- **Medium**: The theoretical connection between score differences and KL divergence - theoretically sound but relies on assumptions that may not always hold
- **Medium**: The single-model approach's generalization capability - demonstrated empirically but needs more rigorous testing on diverse distribution families

## Next Checks

1. Test DiffPath on OOD detection tasks involving distributions with heavy tails or multimodal structures to stress-test the theoretical assumptions
2. Evaluate performance when using diffusion models trained on distributions significantly different from test distributions (e.g., CelebA model for medical imaging OOD detection)
3. Compare computational efficiency against recent single-pass diffusion-based methods like SCOPED when scaling to higher-resolution images