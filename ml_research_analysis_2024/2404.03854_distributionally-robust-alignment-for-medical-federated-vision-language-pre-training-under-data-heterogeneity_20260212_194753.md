---
ver: rpa2
title: Distributionally Robust Alignment for Medical Federated Vision-Language Pre-training
  Under Data Heterogeneity
arxiv_id: '2404.03854'
source_url: https://arxiv.org/abs/2404.03854
tags:
- learning
- pre-training
- data
- local
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of federated vision-language pre-training
  (VLP) under data heterogeneity in medical applications. The proposed method, Federated
  Distributionally Robust Alignment (FedDRA), introduces a distributionally robust
  optimization framework to optimize model performance across a family of potential
  testing distributions.
---

# Distributionally Robust Alignment for Medical Federated Vision-Language Pre-training Under Data Heterogeneity

## Quick Facts
- arXiv ID: 2404.03854
- Source URL: https://arxiv.org/abs/2404.03854
- Reference count: 40
- Key outcome: FedDRA achieves up to 30.2% improvement in top-1 retrieval accuracy and 83.7% improvement in classification accuracy compared to existing federated learning methods on medical vision-language tasks

## Executive Summary
This paper introduces Federated Distributionally Robust Alignment (FedDRA), a novel method for federated vision-language pre-training (VLP) under data heterogeneity in medical applications. The approach addresses the challenge of biased cross-modal alignment when clients have non-IID data distributions by employing a distributionally robust optimization framework. FedDRA uses a two-stage training strategy with global constraints to reduce overfitting to client-specific information, achieving superior performance on downstream tasks including image-text retrieval, classification, and segmentation.

## Method Summary
FedDRA is a federated learning framework that optimizes vision-language pre-training under data heterogeneity by minimizing worst-case performance across a family of potential test distributions. The method employs a two-stage training approach where alignment modules are first trained on frozen feature encoders to learn unbiased mappings, then jointly trained with the full model. A global model provides anchor representations that regularize local training through a global constraint loss, while distributionally robust optimization dynamically adjusts client weights based on performance to balance contributions from heterogeneous clients.

## Key Results
- Top-1 retrieval accuracy improvements of up to 30.2% over FedAvg baseline
- Classification accuracy improvements of up to 83.7% on medical downstream tasks
- Better generalization across different downstream tasks including image-text retrieval, classification, and segmentation
- Effective balancing of client contributions through distributionally robust optimization weighting

## Why This Works (Mechanism)

### Mechanism 1
Distributionally robust optimization (DRO) improves model performance across unseen distributions by optimizing the worst-case performance in a family of potential test distributions. The method constructs a distribution family based on client distributions and optimizes the model's parameter θ over this set by minimizing the maximum loss. This approach ensures the model generalizes well to the entire set of potential testing distributions, assuming the testing distribution is near the overall training data distribution.

### Mechanism 2
Using anchor representations from the global model to guide local training reduces overfitting to client-specific information. During local training, the method maintains a global model to provide anchor representations (z*_x and z*_y) that regularize local training. This constrains the local models to stay close to the global representation space, preventing them from capturing client-specific biases. The approach assumes the global model's representations capture generalizable patterns that can guide local training without introducing harmful client-specific information.

### Mechanism 3
The two-stage training strategy first trains alignment modules on frozen feature encoders, then jointly trains both, mitigating bias in deeper layers. In the first stage, alignment modules (f_Ψ, f_Φ) are trained while feature encoders (f_ψ, f_ϕ) are frozen, encouraging the alignment modules to learn unbiased mappings. In the second stage, both are trained together to enhance their capability of extracting medical features. This approach assumes deeper layers are more susceptible to capturing client-specific information, and training them first on frozen feature encoders helps them learn more generalizable features.

## Foundational Learning

- Concept: Federated learning and data heterogeneity
  - Why needed here: The paper addresses the challenge of federated vision-language pre-training under data heterogeneity, where different clients have different data distributions
  - Quick check question: What is the main challenge in federated learning when client datasets are heterogeneous, and how does it affect model performance?

- Concept: Distributionally robust optimization (DRO)
  - Why needed here: DRO is used to optimize the model's performance across a family of potential testing distributions, bridging the gap between pre-training samples and downstream applications
  - Quick check question: How does DRO differ from standard empirical risk minimization, and why is it particularly useful in federated learning with heterogeneous data?

- Concept: Vision-language pre-training (VLP) and cross-modal alignment
  - Why needed here: The method aims to learn robust vision-language alignment under heterogeneous conditions, which is fundamental to VLP
  - Quick check question: What is cross-modal alignment in VLP, and why is it important for the transferability of pre-trained models to downstream tasks?

## Architecture Onboarding

- Component map:
  - Feature encoders (f_ψ for images, f_ϕ for text) -> project inputs to intermediate features
  - Alignment modules (f_Ψ, f_Φ) -> additional transformer blocks that project intermediate features to aligned final representations
  - Global model -> provides anchor representations for local training regularization
  - Distribution family QC -> constructed based on client distributions for DRO
  - Weight scheduler -> dynamically adjusts client weights based on performance

- Critical path:
  1. Initialize model parameters and alignment modules
  2. For each communication round:
     - Broadcast current model to clients
     - Clients perform local training with global constraint and DRO weighting
     - Clients send updated models to server
     - Server aggregates models and updates client weights
     - Server broadcasts updated model and weights

- Design tradeoffs:
  - Uncertainty radius ρ: Larger ρ introduces more potential distributions but may reduce focus on most relevant distributions
  - Global constraint weight μ: Higher μ enforces stronger regularization but may limit local adaptation
  - Two-stage vs single-stage training: Two-stage reduces bias but requires more computation and communication

- Failure signatures:
  - Poor downstream performance despite good in-domain retrieval: Indicates overfitting to pre-training distributions
  - Large performance gap between clients: Suggests DRO weighting not effectively balancing client contributions
  - Slow convergence: May indicate insufficient communication rounds or overly restrictive constraints

- First 3 experiments:
  1. Test basic FedAvg baseline on heterogeneous MIMIC-CXR data to establish performance floor
  2. Implement global constraint regularization without DRO to isolate its effect
  3. Add DRO weighting to global constraint baseline to evaluate combined effect on performance and client balance

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but several implicit questions arise from the work:
1. How to scale the approach to hundreds of clients with diverse data distributions
2. How to determine optimal timing for transitioning between the two training stages
3. How to handle cases where client data distributions follow fundamentally different generative processes rather than just heterogeneity in class proportions

## Limitations
- The distribution family construction relies on client distributions being representative of potential testing distributions, which may not hold in practice with highly diverse or outlier-containing client data
- The global constraint mechanism assumes the server model captures generalizable patterns, but this may fail if the server model itself is biased due to uneven client contributions
- Two-stage training introduces additional hyperparameters and complexity, making it harder to determine whether performance gains come from the DRO approach or the training strategy itself

## Confidence
- **High confidence**: The basic federated VLP framework with heterogeneous data partitions is well-specified and reproducible
- **Medium confidence**: The global constraint regularization mechanism is clearly described, though exact implementation details may affect performance
- **Low confidence**: The distributionally robust optimization weight update mechanism has critical details missing, particularly the projection step onto the uncertainty set constraint

## Next Checks
1. Implement a simplified version of FedDRA without DRO weighting (just global constraint) to isolate the effect of the two-stage training strategy
2. Test the method on synthetic heterogeneous distributions where ground truth client weights are known, to verify the DRO weighting mechanism learns appropriate client importance
3. Evaluate model performance when testing on client distributions that were not present during training, to assess the distributionally robust claims under distribution shift