---
ver: rpa2
title: What's New in My Data? Novelty Exploration via Contrastive Generation
arxiv_id: '2410.14765'
source_url: https://arxiv.org/abs/2410.14765
tags:
- dataset
- examples
- novel
- data
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of understanding fine-tuning
  datasets, which are often large, noisy, and confidential, making direct inspection
  impractical. The authors introduce the task of novelty discovery through generation,
  aiming to identify novel properties in fine-tuning data by generating examples that
  illustrate these properties.
---

# What's New in My Data? Novelty Exploration via Contrastive Generation

## Quick Facts
- arXiv ID: 2410.14765
- Source URL: https://arxiv.org/abs/2410.14765
- Reference count: 22
- Detects novel content in fine-tuning datasets with >90% accuracy using contrastive generation

## Executive Summary
This paper introduces Contrastive Generative Exploration (CGE), a method for discovering novel properties in fine-tuning datasets by generating examples that illustrate these properties. The approach contrasts predictions from pre-trained and fine-tuned language models to highlight examples that deviate from the pre-training distribution. CGE is particularly valuable for understanding large, noisy, or confidential fine-tuning datasets where direct inspection is impractical. The method demonstrates effectiveness in detecting novel content including toxic language, new natural languages, and programming languages, even under differential privacy constraints.

## Method Summary
CGE works by computing a contrastive score that measures the difference in log probabilities between fine-tuned and pre-trained models. This score identifies examples that the fine-tuned model prefers but the pre-trained model does not, capturing novel content. The static version uses contrastive decoding with an adaptive plausibility constraint, while the iterative version updates the pre-trained model with generated examples to improve diversity. CGE can also be viewed as a dataset distillation technique, providing computational efficiency and interpretability. The method remains effective even with differential privacy, making it practical for real-world applications where data privacy is a concern.

## Key Results
- Detection rates exceeding 90% for non-English text and source code using LLaMA 3-70B-Instruct classification
- Coverage rates improve to over 80% in iterative CGE, though at the cost of reduced detection rates
- CGE remains effective under differential privacy constraints with minimal performance degradation
- Iterative CGE generates diverse examples across multiple novel domains while maintaining high detection accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The contrastive score effectively identifies novel examples by leveraging the difference in log probabilities between fine-tuned and pre-trained models.
- Mechanism: By computing the difference between log probabilities assigned by the fine-tuned and pre-trained models, the contrastive score highlights examples that the fine-tuned model prefers but the pre-trained model does not. This difference captures examples that deviate from the pre-training distribution.
- Core assumption: The fine-tuned model assigns higher probabilities to novel examples that were present in the fine-tuning data but not in the pre-training data.
- Evidence anchors: [abstract] "By contrasting the predictions of these two models, CGE can generate examples that highlight novel characteristics of the fine-tuning data." [section] "The contrastive score rewards texts preferred by the fine-tuned model while penalizing those favored by the pre-trained model."

### Mechanism 2
- Claim: The iterative version of CGE improves the diversity of generated examples by updating the pre-trained model with previously generated examples.
- Mechanism: After generating an example using contrastive decoding, the pre-trained model is fine-tuned on this example. This updated model is then used in the next iteration to generate a new example, promoting diversity by preventing the generation of similar examples.
- Core assumption: Fine-tuning the pre-trained model on generated examples reduces the likelihood of generating similar examples in subsequent iterations.
- Evidence anchors: [section] "We address this by introducing an iterative version of CGE, where the previously generated examples are used to update the pre-trained model." [section] "This updated model is then contrasted with the fully fine-tuned model to generate the next example, promoting diversity in the generated outputs."

### Mechanism 3
- Claim: CGE can be viewed as a dataset distillation technique, providing computational efficiency and interpretability.
- Mechanism: The contrastive score approximates the objective of dataset distillation by ensuring that the gradient of the generated examples matches the change in model parameters from training on the original dataset.
- Core assumption: The change in model parameters due to fine-tuning can be approximated by the difference in log probabilities between the fine-tuned and pre-trained models.
- Evidence anchors: [section] "Assuming the model parameters do not significantly change during training, the contrastive score can be approximated by the first-order Taylor-series expansion." [section] "Under the first-order approximation, the contrastive score reduces to the objective of dataset distillation."

## Foundational Learning

- Concept: Contrastive Decoding
  - Why needed here: It forms the basis of CGE by generating examples that highlight differences between pre-trained and fine-tuned models.
  - Quick check question: How does contrastive decoding differ from standard decoding in language models?

- Concept: Dataset Distillation
  - Why needed here: Understanding dataset distillation helps in appreciating how CGE can be viewed as a form of dataset distillation.
  - Quick check question: What is the main goal of dataset distillation, and how does it relate to CGE?

- Concept: Differential Privacy
  - Why needed here: CGE's effectiveness under differential privacy is crucial for practical applications where data privacy is a concern.
  - Quick check question: How does differential privacy affect the training of language models, and why is it important for CGE?

## Architecture Onboarding

- Component map:
  Pre-trained Model -> Fine-tuned Model -> Contrastive Score Calculator -> Iterative Update Module -> Generated Examples

- Critical path:
  1. Compute the contrastive score between the pre-trained and fine-tuned models
  2. Generate examples using contrastive decoding
  3. If using the iterative version, update the pre-trained model with generated examples
  4. Repeat steps 1-3 to generate diverse examples

- Design tradeoffs:
  - Static vs. Iterative: The static version may generate similar examples, while the iterative version increases diversity but may reduce detection rate
  - Hyperparameter Î±: Controls the plausibility constraint in contrastive decoding; higher values may reduce diversity

- Failure signatures:
  - Low detection rate: Indicates that the generated examples are not effectively capturing novel properties
  - Low coverage rate: Suggests that the generated examples are not diverse enough to cover different novel domains

- First 3 experiments:
  1. Evaluate the effectiveness of the contrastive score in distinguishing novel examples from in-distribution examples
  2. Assess the detection and coverage rates of CGE in generating novel examples from fine-tuned models
  3. Test the robustness of CGE under differential privacy constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CGE vary with different language families or script types beyond those tested (e.g., Cyrillic, Devanagari, or logographic scripts)?
- Basis in paper: [inferred] The experiments tested CGE on non-English languages (Japanese, Chinese, Persian, Arabic, Hebrew, Turkish, Indonesian, Korean, Vietnamese, and Thai), but did not explore a broader range of language families or script types.
- Why unresolved: The paper's experiments were limited to specific languages, leaving open the question of whether CGE's effectiveness generalizes to other linguistic contexts.
- What evidence would resolve it: Conducting experiments with a wider variety of languages from different families and scripts, and comparing the detection and coverage rates across these groups.

### Open Question 2
- Question: What is the impact of varying the noise multiplier in DP-Adam on the quality and diversity of generated examples, and at what point does DP significantly hinder novelty discovery?
- Basis in paper: [explicit] The paper mentions that CGE remains effective even with differential privacy techniques, but does not provide a detailed analysis of how varying the noise multiplier affects the generated examples.
- Why unresolved: The experiments showed a decline in detection rate with increased noise, but the relationship between noise level and the quality/diversity of generated examples was not fully explored.
- What evidence would resolve it: Systematic experiments varying the noise multiplier across a wider range, and analyzing the generated examples for both quality and diversity at each level.

### Open Question 3
- Question: Can CGE be adapted to handle gradual variations between domains, rather than assuming distinct, non-overlapping domains?
- Basis in paper: [explicit] The paper assumes distinct domains for simplicity in metrics, but acknowledges that gradual variations are more realistic.
- Why unresolved: The current formulation of CGE may not be optimal for scenarios where domains overlap or transition gradually, limiting its applicability in some real-world settings.
- What evidence would resolve it: Developing and testing an extension of CGE that can handle gradual domain transitions, and evaluating its performance against the current method on datasets with overlapping domains.

## Limitations
- Controlled experimental setup with synthetic datasets (exactly 10% novel examples) that don't reflect real-world complexity
- Evaluation relies on LLM-based novelty detection rather than ground truth validation against actual fine-tuning data
- Limited exploration of scenarios with multiple simultaneous novel domains or sparse novelty (<10%)

## Confidence
- Medium: The paper demonstrates effective novelty detection (>90% accuracy) but relies on synthetic evaluation datasets and LLM-based validation without ground truth verification

## Next Checks
1. **Ground truth validation**: Test CGE on actual fine-tuning datasets where the novel content is known (e.g., fine-tuning on Wikipedia articles that include both English and non-English sections). Compare generated examples against the actual non-English content to verify detection accuracy beyond LLM classification.

2. **Varying novelty ratios**: Evaluate CGE's performance when the proportion of novel examples in fine-tuning data varies from 1% to 30%. This would test the method's sensitivity and effectiveness in more realistic scenarios where novelty is sparse or abundant.

3. **Multiple simultaneous novelties**: Test CGE on datasets containing multiple distinct novel domains (e.g., non-English text + toxic language + code). Evaluate whether CGE can detect and generate examples from all novel domains or if it gets "stuck" on one type of novelty, and assess the impact on both detection and coverage metrics.