---
ver: rpa2
title: Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus
arxiv_id: '2411.12498'
source_url: https://arxiv.org/abs/2411.12498
tags:
- reasoning
- llms
- language
- logic
- logical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Additional Logic Training (ALT) to enhance
  large language models' (LLMs) reasoning capabilities. The authors establish design
  principles for synthetic logic samples, emphasizing reasoning with unknown facts,
  illogical reasoning, diverse reasoning rules, and diverse linguistic expressions.
---

# Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus

## Quick Facts
- arXiv ID: 2411.12498
- Source URL: https://arxiv.org/abs/2411.12498
- Reference count: 40
- Primary result: ALT on FLD×2 improves LLMs' reasoning capabilities by up to 30 points on logical reasoning benchmarks

## Executive Summary
This paper proposes Additional Logic Training (ALT) to enhance large language models' reasoning capabilities through synthetic logic corpora. The authors establish four design principles for constructing effective synthetic samples: reasoning with unknown facts, incorporating illogical reasoning, using diverse reasoning rules, and employing diverse linguistic expressions. Based on these principles, they create the Formal Logic Deduction Diverse (FLD×2) corpus and demonstrate that ALT substantially improves state-of-the-art LLMs' performance across reasoning benchmarks, with gains of up to 30 points on logical reasoning tasks.

## Method Summary
The method involves training LLMs on synthetic logic corpora using Additional Logic Training (ALT) with Recall Adam optimizer to prevent knowledge forgetting. The process uses a vocabulary of ~100k words to construct synthetic samples that teach abstract reasoning rather than memorization. Models are trained for one epoch on 100k synthetic logic samples, with regularization applied to maintain pre-trained knowledge while learning new reasoning patterns. Evaluation employs 5-shot in-context learning across 31 benchmarks spanning logic, math, coding, and natural language inference tasks.

## Key Results
- Up to 30-point improvement on logical reasoning benchmarks
- 10-point gains on math and coding benchmarks
- 5-point improvements on the BBH benchmark suite

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ALT improves reasoning by teaching LLMs to handle unknown facts
- Mechanism: Synthetic corpus forces reasoning about unseen content, preventing overfitting to memorized patterns
- Core assumption: LLMs can learn abstract reasoning rules when exposed to diverse unknown content
- Evidence anchors:
  - [abstract]: "the essence of logical reasoning... lies in its ability to handle unknown facts"
  - [section 2.1]: "The contents of F and G can be arbitrary"
  - [corpus]: FLD×2 uses ~100k words from WordNet with random construction

### Mechanism 2
- Claim: ALT prevents knowledge forgetting through regularization
- Mechanism: Recall Adam constrains parameter updates to stay close to pre-trained weights
- Core assumption: Unknown facts will displace established knowledge during training
- Evidence anchors:
  - [abstract]: "knowledge-forgetting prevention method during ALT is critically important"
  - [section 4]: Learning rates of 2e-05 (8B) and 3e-06 (70B) with Recall Adam
  - [corpus]: Regularization prevents displacement of pre-training knowledge

### Mechanism 3
- Claim: Diverse linguistic expressions enable generalization across natural language
- Mechanism: Multiple templates per logical formula create combinatorially diverse expressions
- Core assumption: LLMs can map between diverse expressions and logical structures
- Evidence anchors:
  - [abstract]: "diverse linguistic expressions" is a design principle
  - [section 2.4]: "various linguistic structures for expressing logical relationships"
  - [corpus]: Multiple templates per formula with "at least dozens of expressions"

## Foundational Learning

- Concept: Completeness of First-Order Predicate Logic (Gödel 1930)
  - Why needed here: Explains why training on axioms enables handling all deduction rules
  - Quick check question: If a model learns only modus ponens, can it handle syllogisms? (Answer: Yes, through multi-step reasoning)

- Concept: Modus Ponens and other basic deduction rules
  - Why needed here: These are the building blocks the synthetic corpus is constructed from
  - Quick check question: What conclusion follows from "If P then Q" and "P"? (Answer: Q)

- Concept: Logical validity vs. factual correctness
  - Why needed here: Understanding reasoning is about logical relationships, not truth of content
  - Quick check question: Is "The moon is made of cheese. If the moon is made of cheese, then pigs can fly. Therefore, pigs can fly" logically valid? (Answer: Yes)

## Architecture Onboarding

- Component map: Synthetic corpus generator → LLM training pipeline (with Recall Adam) → Evaluation benchmarks
- Critical path: Corpus generation → Training (1 epoch, 100k samples) → Evaluation (5-shot in-context learning)
- Design tradeoffs: Larger vocabulary improves unknown handling but increases computational cost; more templates improve generalization but complicate generation
- Failure signatures: Knowledge displacement (forgetting existing facts), overfitting to corpus patterns, inability to handle novel expressions
- First 3 experiments:
  1. Train on FLD×2 with Recall Adam vs without - verify knowledge preservation
  2. Train on corpus with restricted vocabulary (10k vs 100k words) - test unknown handling
  3. Train on corpus with single template per formula vs multiple - test linguistic generalization

## Open Questions the Paper Calls Out

- Question: Does ALT improve reasoning capabilities on more complex reasoning tasks beyond those tested, such as multi-step abductive reasoning or temporal reasoning?
- Question: How does the performance of ALT compare when applied to other types of synthetic logic corpora, such as those using different logical systems (e.g., modal or linear logic)?
- Question: What is the optimal amount and type of synthetic logic data needed for ALT to achieve maximum performance gains, and how does this scale with model size?
- Question: Can ALT be effectively combined with other training techniques, such as chain-of-thought prompting or retrieval-augmented generation?

## Limitations

- The study focuses on specific LLaMA-3.1 models without testing smaller or larger architectures or different model families
- The synthetic corpus generation relies heavily on manually crafted templates with incomplete documentation
- Evaluation focuses predominantly on reasoning-intensive benchmarks with less attention to non-reasoning capabilities

## Confidence

**High Confidence Claims:**
- ALT improves performance on reasoning benchmarks (up to 30 points gains) with properly constructed synthetic corpora
- Knowledge forgetting is a real concern during ALT requiring mitigation through regularization
- The four design principles are necessary for effective synthetic logic corpus construction

**Medium Confidence Claims:**
- ALT generalizes to improve math and coding performance (10 points gains) beyond pure logical reasoning
- The specific architecture of FLD×2 represents an optimal approach
- One-epoch training with Recall Adam is the optimal configuration

**Low Confidence Claims:**
- ALT can achieve similar reasoning improvements across all model families and sizes
- Performance gains will remain consistent as synthetic corpora scale to millions of samples
- Improvements represent fundamental reasoning capability versus pattern matching

## Next Checks

1. **Cross-model generalization test**: Apply ALT to diverse model architectures (Mistral, Gemma, Qwen) across multiple size ranges (1B-70B parameters) to verify approach's architecture independence.

2. **Scaling and composition analysis**: Systematically vary corpus size (10k to 1M samples), vocabulary size (10k to 500k words), and template diversity (1 to 10+ per formula) to determine optimal configurations.

3. **Zero-shot reasoning transfer evaluation**: Test whether ALT-trained models can perform zero-shot reasoning on novel logical structures not present in training corpora or evaluation benchmarks.