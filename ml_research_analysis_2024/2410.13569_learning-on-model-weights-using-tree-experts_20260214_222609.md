---
ver: rpa2
title: Learning on Model Weights using Tree Experts
arxiv_id: '2410.13569'
source_url: https://arxiv.org/abs/2410.13569
tags:
- probex
- weights
- learning
- trees
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of representing and analyzing
  neural network models based solely on their weights, a field known as weight-space
  learning. The key problem is that model weights contain significant variation unrelated
  to their semantic properties (nuisance variation), making it difficult to learn
  meaningful representations.
---

# Learning on Model Weights using Tree Experts

## Quick Facts
- arXiv ID: 2410.13569
- Source URL: https://arxiv.org/abs/2410.13569
- Reference count: 38
- Primary result: ProbeX achieves better accuracy than dense experts with two orders of magnitude fewer parameters on model classification tasks

## Executive Summary
This paper addresses the challenge of representing and analyzing neural network models based solely on their weights. The authors identify that most public models belong to Model Trees—groups where models share a common ancestor and have less nuisance variation between them. To exploit this structure, they propose a Mixture-of-Experts approach using lightweight Probing Experts (ProbeX), which can effectively map model weights into a shared weight-language embedding space. This enables tasks like zero-shot model classification and retrieval with strong performance on unseen classes.

## Method Summary
The method uses a Mixture-of-Experts (MoE) approach with Probing Experts (ProbeX) to learn representations from model weights. ProbeX is a lightweight probing method designed to learn from a single hidden model layer, making it computationally efficient. The approach involves clustering models into Model Trees using hierarchical clustering, training ProbeX encoders for each tree, and aligning weight representations with text embeddings (e.g., CLIP). The ProbeX method uses a Tucker low-rank tensor decomposition and is trained end-to-end to optimize classification and alignment tasks.

## Key Results
- ProbeX achieves better accuracy than dense experts with two orders of magnitude fewer parameters on predicting training dataset classes
- ProbeX successfully aligns model weight representations with CLIP text embeddings
- Zero-shot classification of models from unseen classes achieves over 50% accuracy with 150 held-out classes, and nearly 90% accuracy with 30 held-out classes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model Trees act as a key nuisance factor in weight-space learning
- Mechanism: Models within the same Model Tree share a common ancestor and thus exhibit less nuisance variation between them. This reduces the complexity of learning a mapping from weights to semantics.
- Core assumption: Most public models belong to a small set of large Model Trees
- Evidence anchors:
  - [abstract] "most public models belong to a small set of Model Trees, where all models within a tree are fine-tuned from a common ancestor"
  - [section 3.2] "models in T all lie within the same tree, while those in F lie in different, disjoint trees"
  - [corpus] Weak evidence - no direct corpus support for Model Trees being a nuisance factor
- Break condition: If new model trees emerge that are not part of the existing set, the current Mixture-of-Experts approach would require retraining experts for the new trees

### Mechanism 2
- Claim: ProbeX achieves better accuracy than dense experts with fewer parameters
- Mechanism: ProbeX uses probing to learn from a single hidden model layer, making it computationally efficient. It factorizes the per-probe encoder to reduce parameters while maintaining expressivity through a non-linear activation.
- Core assumption: The linear ProbeX has identical expressivity to the dense expert
- Evidence anchors:
  - [abstract] "ProbeX achieves better accuracy than dense experts with two orders of magnitude fewer parameters"
  - [section 4.3] "Probing-based methods... have emerged as a promising approach for processing neural networks"
  - [corpus] No direct corpus support for ProbeX specifically, but related work on probing methods exists
- Break condition: If the factorized representation loses critical information that the dense expert captures, accuracy would degrade

### Mechanism 3
- Claim: ProbeX can align model weight representations with CLIP text embeddings
- Mechanism: ProbeX learns a mapping from model weights to a shared embedding space with language representations. This enables zero-shot classification of models from unseen classes.
- Core assumption: Model weights contain semantic information that can be mapped to language representations
- Evidence anchors:
  - [abstract] "ProbeX can map the weights of Stable Diffusion into a weight-language embedding space, enabling model search via text"
  - [section 6.3] "We learn a mapping between layer weights of models... and the CLIP embedding of the concept"
  - [corpus] No direct corpus support for weight-to-text alignment specifically
- Break condition: If the semantic information in model weights is not sufficiently correlated with text descriptions, the alignment would fail

## Foundational Learning

- Concept: Weight-space learning
  - Why needed here: This paper operates in the emerging field of weight-space learning, which studies how to use model weights as input for training new models
  - Quick check question: What are the key challenges in weight-space learning mentioned in the paper?

- Concept: Model Trees
  - Why needed here: Understanding Model Trees is crucial as the paper identifies them as a key nuisance factor and designs an approach that exploits their structure
  - Quick check question: How does the paper define a Model Tree and why does it matter for weight-space learning?

- Concept: Probing methods
  - Why needed here: ProbeX is a probing-based method, so understanding how probing works is essential to grasp the mechanism
  - Quick check question: What is the key difference between traditional probing and the ProbeX approach?

## Architecture Onboarding

- Component map:
  - Mixture-of-Experts (MoE) approach
    - Model router (hierarchical clustering)
    - ProbeX encoders (one per tree)
      - Shared dimension reduction matrix V
      - Per-probe encoder matrices M[l]
      - Non-linearity σ
      - Prediction head T
  - Dataset creation (Model Jungle)
    - Discriminative split (ViT, MAE, ResNet)
    - Generative split (Stable Diffusion with LoRA)

- Critical path:
  1. Cluster models into Model Trees using hierarchical clustering
  2. Train ProbeX encoder for each tree
  3. Align weight representations with text embeddings
  4. Evaluate on zero-shot classification and retrieval tasks

- Design tradeoffs:
  - Linear vs non-linear ProbeX: Linear is more parameter-efficient but non-linear improves generalization
  - Number of probes: More probes increase expressivity but also computational cost
  - Layer selection: Different layers capture different aspects of model functionality

- Failure signatures:
  - Poor clustering indicates the routing function is not capturing the Model Tree structure
  - Low accuracy on in-distribution data suggests the ProbeX encoders are not learning effective representations
  - Failure to generalize to unseen classes indicates the alignment with text embeddings is not capturing semantic information

- First 3 experiments:
  1. Replicate the intra-tree vs inter-tree experiment from section 3.2 to validate the Model Tree nuisance factor
  2. Train ProbeX on a single Model Tree and compare to a dense expert baseline
  3. Align ProbeX representations with CLIP embeddings and test zero-shot classification on held-out classes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ProbeX be adapted to generalize to entirely new Model Trees that were not present during training?
- Basis in paper: [explicit] The paper discusses that a primary limitation of ProbeX is its inability to generalize to new Model Trees, requiring training new experts for new trees. It suggests this as a promising avenue for future research.
- Why unresolved: The paper acknowledges this limitation but does not provide a solution for generalizing to unseen Model Trees.
- What evidence would resolve it: Experiments demonstrating ProbeX's ability to effectively handle new Model Trees without requiring retraining of experts, or theoretical work proposing mechanisms for zero-shot expert generation for unseen trees.

### Open Question 2
- Question: What is the optimal architecture for deeper ProbeX encoders that could improve generalization or handle more complex tasks?
- Basis in paper: [explicit] The paper mentions that in preliminary experiments, adding more layers to the encoder reduced performance, probably due to overfitting. It suggests designing deeper encoders that improve generalization or handle more complex tasks as an intriguing direction for future research.
- Why unresolved: The paper only briefly mentions this limitation without exploring potential solutions or architectural modifications.
- What evidence would resolve it: Architectural proposals for deeper ProbeX encoders along with experimental validation showing improved performance on complex tasks or better generalization.

### Open Question 3
- Question: How does ProbeX perform on weight-space learning tasks beyond classification, such as model performance prediction or model generation?
- Basis in paper: [explicit] The paper focuses on classification tasks and demonstrates ProbeX's effectiveness in predicting training dataset classes and zero-shot model classification. However, it does not explore other weight-space learning applications mentioned in related works, such as predicting model performance or generating new models.
- Why unresolved: The paper's experiments are limited to classification tasks, leaving open questions about ProbeX's applicability to other weight-space learning problems.
- What evidence would resolve it: Experiments demonstrating ProbeX's performance on tasks like model performance prediction, model generation, or dataset size recovery, compared to existing methods in these domains.

## Limitations
- Limited generalizability beyond Stable Diffusion and CLIP models
- Poor performance on models from emerging Model Trees not present in training data
- Long-term stability of weight representations across model updates is unknown

## Confidence
- Model Trees as nuisance factor: Medium - supported by empirical clustering results but limited theoretical foundation
- ProbeX parameter efficiency: High - clearly demonstrated with two orders of magnitude reduction
- Zero-shot generalization: Medium - strong results on held-out classes but limited to specific model families

## Next Checks
1. Test ProbeX performance on model families outside the current training distribution (e.g., language models, graph neural networks) to assess architecture generalization.

2. Conduct ablation studies removing the Model Tree structure to quantify the exact contribution of the MoE approach versus ProbeX's intrinsic capabilities.

3. Evaluate ProbeX representations over time as models are updated or fine-tuned to measure representation stability and potential drift.