---
ver: rpa2
title: 'Large Model for Small Data: Foundation Model for Cross-Modal RF Human Activity
  Recognition'
arxiv_id: '2410.19766'
source_url: https://arxiv.org/abs/2410.19766
tags:
- fm-fi
- data
- figure
- proc
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Human Activity Recognition
  (HAR) using Radio-Frequency (RF) sensing, where the scarcity of labeled data due
  to the non-interpretable nature of RF signals poses a significant obstacle. To overcome
  this, the authors propose FM-Fi, a cross-modal framework that leverages the knowledge
  of vision-based foundation models (FMs) to enhance RF-based HAR systems.
---

# Large Model for Small Data: Foundation Model for Cross-Modal RF Human Activity Recognition

## Quick Facts
- arXiv ID: 2410.19766
- Source URL: https://arxiv.org/abs/2410.19766
- Reference count: 40
- Primary result: Achieves 72.5% accuracy in zero-shot HAR and 94.4% accuracy in 3-shot learning

## Executive Summary
This paper addresses the challenge of Human Activity Recognition (HAR) using Radio-Frequency (RF) sensing, where the scarcity of labeled data due to the non-interpretable nature of RF signals poses a significant obstacle. To overcome this, the authors propose FM-Fi, a cross-modal framework that leverages the knowledge of vision-based foundation models (FMs) to enhance RF-based HAR systems. FM-Fi introduces a novel cross-modal contrastive knowledge distillation (CKD) mechanism to transfer semantic representations from FMs to RF encoders, enabling zero-shot learning. It also employs feature elimination methods tailored to both image and RF modalities to align their representations and refines the model using metric-based few-shot learning for specific HAR tasks.

## Method Summary
FM-Fi addresses HAR with limited labeled RF data by leveraging vision foundation models through cross-modal contrastive knowledge distillation. The method involves synchronizing mmWave radar point cloud data with RGB images, then training an RF encoder using CKD to inherit semantic understanding from CLIP. Feature elimination removes extraneous background information from both modalities - saliency maps for images and Doppler filtering plus attention for RF. The framework achieves zero-shot HAR through this cross-modal alignment and further refines performance with metric-based few-shot learning on minimal labeled RF data.

## Key Results
- Achieves 72.5% accuracy in zero-shot HAR across 10 activity classes
- Achieves 94.4% accuracy in 3-shot learning scenarios
- Outperforms state-of-the-art baselines in both zero-shot and few-shot settings

## Why This Works (Mechanism)

### Mechanism 1
Cross-modal contrastive knowledge distillation transfers semantic understanding from vision FMs to RF modality by maximizing mutual information between embeddings rather than using element-wise loss. This preserves interdependency information critical for HAR tasks.

### Mechanism 2
Feature elimination methods tailored to image (saliency maps) and RF (Doppler filtering + attention) modalities remove extraneous background features, enabling better alignment between modalities and focusing on human activity signals.

### Mechanism 3
Metric-based few-shot learning refines the RF encoder using minimal labeled data to adapt to specific HAR tasks while preserving zero-shot capabilities through cosine similarity weighted by text embeddings from FMs.

## Foundational Learning

- **Cross-modal contrastive learning**: Needed to transfer knowledge from vision FMs to RF modality while preserving semantic structure. Quick check: How does contrastive loss differ from traditional knowledge distillation loss?

- **Mutual information maximization**: Needed to capture and preserve interdependencies between embedding elements during knowledge transfer. Quick check: Why is preserving interdependency information important for HAR tasks?

- **Self-attention mechanisms for point clouds**: Needed to dynamically weight RF points based on their relevance to HAR within a global context. Quick check: How does self-attention help eliminate irrelevant points in RF data?

## Architecture Onboarding

- **Component map**: RF encoder → Cross-modal CKD → Feature elimination → Zero-shot HAR → Few-shot refinement
- **Critical path**: RF encoder training through CKD → Feature elimination → Zero-shot prediction
- **Design tradeoffs**: Model size vs. performance (6.9M vs 140M parameters), labeled data vs. zero-shot capability, computational cost vs. accuracy
- **Failure signatures**: Poor zero-shot accuracy (below 60%), unstable few-shot performance, failure to generalize across environments
- **First 3 experiments**:
  1. Test zero-shot accuracy on the 10-class dataset to verify CKD effectiveness
  2. Evaluate feature elimination impact by comparing with and without background removal
  3. Test few-shot learning performance with 1, 2, and 3-shot scenarios

## Open Questions the Paper Calls Out

### Open Question 1
How effectively can FM-Fi generalize to support non-HAR RF sensing tasks beyond human activity recognition, such as gesture detection, gait recognition, or vibration monitoring? The paper mentions potential but provides no empirical evidence.

### Open Question 2
Can FM-Fi achieve true open-set capability for HAR, allowing it to recognize activities not seen during training? The authors acknowledge this as an open question without providing evidence or experiments.

### Open Question 3
What is the impact of quantization on the performance and efficiency of FM-Fi when transferring knowledge from the foundation model? The paper notes this as an area for future exploration without exploring it.

## Limitations
- Dataset scale and diversity sensitivity - effectiveness on smaller or more diverse datasets remains uncertain
- Radar parameter sensitivity - specific hardware configuration details not fully specified
- Modality-specific feature elimination - impact on HAR accuracy not rigorously validated

## Confidence

- **High Confidence**: Zero-shot and few-shot learning accuracy metrics are directly measured and validated against baselines
- **Medium Confidence**: Generalizability across environments is supported by evaluation but lacks extensive testing in extreme conditions
- **Low Confidence**: Exact implementation details of attention layers are unspecified, potentially leading to performance variations during reproduction

## Next Checks

1. Evaluate FM-Fi's performance on progressively smaller subsets of the dataset (50%, 25%, 10%) to determine minimum viable dataset size

2. Conduct ablation studies comparing HAR accuracy with and without feature elimination methods across varying background complexity levels

3. Test FM-Fi on datasets from entirely new environments (outdoor settings, different sensor configurations) to validate adaptability and identify failure modes