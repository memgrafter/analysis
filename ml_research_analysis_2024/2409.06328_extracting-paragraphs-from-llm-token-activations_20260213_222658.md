---
ver: rpa2
title: Extracting Paragraphs from LLM Token Activations
arxiv_id: '2409.06328'
source_url: https://arxiv.org/abs/2409.06328
tags:
- should
- arxiv
- answer
- language
- authors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how much information large language models
  (LLMs) encode about the content of a paragraph at its onset, focusing on the double
  newline token. The authors hypothesize that the activation patterns of this token
  contain significant information about the following paragraph.
---

# Extracting Paragraphs from LLM Token Activations

## Quick Facts
- arXiv ID: 2409.06328
- Source URL: https://arxiv.org/abs/2409.06328
- Reference count: 40
- One-line primary result: Transferred double newline token activations produce text significantly closer to original paragraphs than neutral generations, demonstrating paragraph-level information encoding

## Executive Summary
This paper investigates how much information large language models encode about upcoming paragraph content in the activations of the double newline token that precedes it. The authors hypothesize that these token-level activations contain substantial paragraph-level information that can be extracted and transferred to influence generation. Through activation patching experiments, they demonstrate that transferring double newline token activations to a neutrally prompted model produces text semantically closer to the original paragraph than neutral generations, providing evidence that single-token activations encode significant information about multi-token context.

## Method Summary
The authors generate original contexts by prompting Gemma 2 9B with topic pairs, structured as "Tell me about topic 1 in k words \n\n tell me about topic 2 in k words". They extract activations of the double newline token between topics from all layers, then transfer these activations to a neutral context ("<bos>\n\n") and generate new texts. Semantic similarity between original and generated paragraphs is measured using cosine distance between sentence embeddings (ALL MPNET Base v2). Control generations include neutral0 (no transfer), neutral1 (with first word of next paragraph), and neutral2 (with first two words) to benchmark the information content of the transferred activations.

## Key Results
- Transferred double newline token activations produce text significantly closer to original paragraphs than neutral generations
- Attention patterns show the model attends almost exclusively to previous tokens from the same paragraph
- Cosine similarities of attention output activations increase within paragraphs and decrease across paragraphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The double newline token activation encodes significant paragraph-level information that can be transferred to influence generation
- Mechanism: At the start of a new paragraph, the model's activation patterns at the double newline token contain structured information about the upcoming paragraph's content
- Core assumption: Paragraph structure and content are encoded in the activation patterns of the double newline token
- Evidence anchors:
  - [abstract]: "patching these activations can transfer significant information about the context of the following paragraph"
  - [section 3]: "the transferred activations produce text significantly closer to the original than neutral generations"
  - [corpus]: Weak evidence - no direct corpus support for paragraph-level encoding at newline tokens

### Mechanism 2
- Claim: Attention patterns show clear structural encoding that distinguishes between paragraphs
- Mechanism: The model's attention weights and cosine similarities of attention output activations differ between paragraphs
- Core assumption: Attention mechanisms encode paragraph boundaries and topic distinctions
- Evidence anchors:
  - [section 2]: "attention weights indicate that the model tends to attend to previous tokens almost exclusively from the same paragraph"
  - [section 2]: "cosine similarities of attention activations increase within paragraphs and decrease across paragraphs"
  - [corpus]: No direct corpus support for attention-based paragraph boundary detection

### Mechanism 3
- Claim: Single token activations can encode enough information to influence multi-token generation
- Mechanism: By transferring the activation vector of a single token across all layers, the neutral prompt can be "seeded" with information that influences the entire following paragraph
- Core assumption: Information about multiple tokens can be compressed into the activation vector of a single token
- Evidence anchors:
  - [section 3]: "the transferred activations produce text significantly closer to the original than neutral generations"
  - [section 3]: "the activations of the double newline token hold a lot of information about the upcoming paragraph"
  - [corpus]: No direct corpus support for information compression at single tokens

## Foundational Learning

- Concept: Activation patching and transfer
  - Why needed here: The paper uses activation patching to transfer information from one model context to another
  - Quick check question: How does activation patching work in transformer models?

- Concept: Attention mechanisms and cosine similarity
  - Why needed here: The paper analyzes attention patterns and cosine similarities to understand how the model distinguishes between paragraphs
  - Quick check question: What does cosine similarity measure in the context of attention output activations?

- Concept: Sentence embeddings and semantic similarity
  - Why needed here: The paper uses sentence transformers to compare the semantic similarity between generated and original paragraphs
  - Quick check question: How do sentence transformers convert text into comparable embeddings?

## Architecture Onboarding

- Component map: Language model (Gemma 2, 9B) -> Activation extraction mechanism -> Activation transfer mechanism -> Sentence transformer for evaluation -> Prompt generation system

- Critical path: 1. Generate original context with specific prompts 2. Extract double newline token activations 3. Transfer activations to neutral model 4. Generate text with transferred activations 5. Compare semantic similarity using sentence embeddings

- Design tradeoffs: Using single token vs. multiple tokens for information transfer; transferring across all layers vs. selective layer transfer; using different evaluation metrics (cosine distance vs. other measures)

- Failure signatures: Neutral generations are equally similar to original as transferred generations; attention patterns show no distinction between paragraphs; transferred activations produce random or incoherent text

- First 3 experiments: 1. Replicate attention pattern analysis to verify paragraph boundary detection 2. Test transfer of double newline activations with different model sizes 3. Compare results using alternative evaluation metrics (e.g., BLEU score)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the double newline token activations be used to predict not just the immediate next paragraph but subsequent sections of a text?
- Basis in paper: [inferred] The paper mentions future work exploring whether the framework can anticipate not just the immediate next paragraph but also subsequent sections
- Why unresolved: The current experiments focus only on the immediate next paragraph, and the paper acknowledges that extending to longer-term planning is complex and challenging
- What evidence would resolve it: Experiments showing successful activation transfer for predicting content multiple paragraphs ahead

### Open Question 2
- Question: How does the information content in double newline token activations compare to other potential "planning tokens" within paragraphs?
- Basis in paper: [explicit] The paper discusses the double newline token specifically but acknowledges limitations in testing more complex topics
- Why unresolved: The experiments focus on the double newline token at paragraph boundaries, but the paper hints that other tokens within paragraphs might also encode planning information
- What evidence would resolve it: Comparative studies showing activation transfer effectiveness for various tokens within paragraphs versus the double newline token

### Open Question 3
- Question: Do the findings generalize across different model architectures and sizes beyond Gemma 2 9B?
- Basis in paper: [explicit] The paper explicitly states that experiments were conducted using only a specific language model (Gemma 2 9B)
- Why unresolved: The study is limited to one model architecture, and the authors acknowledge this as a limitation without providing cross-model validation
- What evidence would resolve it: Replication studies showing similar activation transfer effects across various transformer-based architectures and different model sizes

## Limitations
- The exact mechanism of how paragraph-level information is encoded in single token activations remains unclear
- Findings are based on a single model architecture (Gemma 2 9B) without cross-model validation
- The paper does not address potential information loss during activation transfer between different model contexts

## Confidence

**High Confidence**: The observation that attention patterns distinguish between paragraphs and that double newline token activations contain more information than neutral generations.

**Medium Confidence**: The claim that single token activations can encode sufficient information to influence multi-token generation, though the mechanism remains partially speculative.

**Low Confidence**: The broader implications for LLM planning and paragraph-level understanding, as the paper establishes a phenomenon but does not conclusively determine whether this represents intentional planning or emergent behavior.

## Next Checks
1. Replicate the semantic similarity analysis using multiple embedding models (e.g., BERT, RoBERTa, CLIP) and traditional metrics like BLEU or ROUGE
2. Test whether double newline activations from Gemma 2 9B can successfully transfer to different model architectures (e.g., LLaMA, Mistral) or model sizes (e.g., 7B, 13B parameters)
3. Systematically transfer activations from individual layers to identify which layers contribute most to the paragraph information encoding