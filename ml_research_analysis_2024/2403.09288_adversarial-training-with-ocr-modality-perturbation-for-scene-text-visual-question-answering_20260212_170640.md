---
ver: rpa2
title: Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question
  Answering
arxiv_id: '2403.09288'
source_url: https://arxiv.org/abs/2403.09288
tags:
- adversarial
- embedding
- training
- question
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of scene-text visual question
  answering (ST-VQA), where the goal is to understand scene text in images and answer
  questions related to the text content. The authors propose a multimodal adversarial
  training architecture with spatial awareness capabilities.
---

# Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question Answering

## Quick Facts
- arXiv ID: 2403.09288
- Source URL: https://arxiv.org/abs/2403.09288
- Reference count: 0
- One-line primary result: Achieves new SOTA accuracy of 57.68% on TextVQA validation set

## Executive Summary
This paper introduces a multimodal adversarial training architecture with spatial awareness capabilities for scene-text visual question answering (ST-VQA). The authors propose an Adversarial OCR Enhancement (AOE) module that leverages adversarial training in the embedding space of OCR modality to enhance fault-tolerant representation of OCR texts, thereby reducing noise caused by OCR errors. Additionally, they add a Spatial-Aware Self-Attention (SASA) mechanism to help the model better capture the spatial relationships among OCR tokens. The proposed method achieves significant performance improvements on both the ST-VQA and TextVQA datasets.

## Method Summary
The proposed method introduces an Adversarial OCR Enhancement (AOE) module that applies adversarial perturbations to OCR embeddings during training, forcing the model to learn robust representations despite OCR errors. The AOE module incorporates a Spatial-Aware Self-Attention (SASA) mechanism that models both semantic and spatial relative positions between OCR tokens. The model is trained using multimodal adversarial training with Kullback-Leibler divergence regularization, where the objective is to minimize both prediction loss and the KL divergence between predictions with and without adversarial perturbations. The method uses Projected Gradient Descent (PGD) for optimization and is evaluated on the ST-VQA and TextVQA datasets.

## Key Results
- Achieves new state-of-the-art accuracy of 57.68% on TextVQA validation set
- Demonstrates significant performance improvements on both ST-VQA and TextVQA datasets
- Shows effectiveness of adversarial training in reducing the impact of OCR errors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial OCR Enhancement (AOE) module reduces the impact of OCR errors by introducing noise during training.
- Mechanism: AOE modifies OCR tokens by adding, deleting, or replacing characters, then trains the model with adversarial perturbations to learn fault-tolerant representations.
- Core assumption: Noisy OCR tokens can be generated by simple character-level edits that maintain semantic similarity to the original text.
- Evidence anchors:
  - [abstract] "we introduce an Adversarial OCR Enhancement (AOE) module, which leverages adversarial training in the embedding space of OCR modality to enhance fault-tolerant representation of OCR texts, thereby reducing noise caused by OCR errors."
  - [section 2.2] "we set a threshold λ to control OCR Token variations... we will introduce character noise to OCR Tokens by deleting, adding, or replacing specific tokens with similar words from the dictionary."
- Break condition: If character-level edits produce tokens that are semantically unrelated or not found in the dictionary, the fault-tolerant learning signal breaks down.

### Mechanism 2
- Claim: Spatial-Aware Self-Attention (SASA) improves the model's understanding of spatial relationships between OCR tokens.
- Mechanism: SASA incorporates relative 2D positional biases into the self-attention mechanism, allowing the model to weigh spatial proximity alongside semantic relevance.
- Core assumption: Spatial relationships among OCR tokens contain information that aids in understanding the text's layout and meaning.
- Evidence anchors:
  - [abstract] "we add a Spatial-Aware Self-Attention (SASA) mechanism to help the model better capture the spatial relationships among OCR tokens."
  - [section 2.2] "we model semantic relative positions and spatial relative positions as bias terms and combine their positional biases with the attention scores."
- Break condition: If OCR tokens are not spatially coherent or the 2D layout information is inaccurate, the added spatial awareness may not improve performance.

### Mechanism 3
- Claim: Multimodal adversarial training with Kullback-Leibler divergence regularization improves model generalization.
- Mechanism: The model is trained to minimize both the prediction loss and the KL divergence between predictions with and without adversarial perturbations, forcing it to be robust to OCR errors.
- Core assumption: Adversarial perturbations applied to OCR embeddings create realistic variations that the model must handle to improve generalization.
- Evidence anchors:
  - [abstract] "we propose a multimodal adversarial training architecture with spatial awareness capabilities... adversarial training enhances the model's generalization ability, thus effectively alleviating the overfitting problem."
  - [section 2.3] "Lkl(θ) denotes fine-grained adversarial regularization... Taking the adversarial perturbation δocr for OCR feature as an example: Lkl(θ) = max ||δocr||≤λ KL(ypred′, ypred)."
- Break condition: If adversarial perturbations are too small to challenge the model or too large to be realistic, the regularization effect diminishes.

## Foundational Learning

- Concept: Multimodal Transformers for VQA
  - Why needed here: The task requires reasoning over visual, textual, and spatial modalities simultaneously, which multimodal transformers are designed to handle.
  - Quick check question: How does a multimodal transformer fuse information from different modalities compared to a single-modal transformer?

- Concept: Adversarial Training for Robustness
  - Why needed here: OCR systems can make errors, and the model needs to be robust to these errors to perform well in real-world scenarios.
  - Quick check question: What is the purpose of using adversarial perturbations during training, and how does it differ from data augmentation?

- Concept: Spatial Embeddings in Transformers
  - Why needed here: Understanding the spatial layout of OCR tokens is crucial for tasks like reading sequences or understanding relationships between text elements.
  - Quick check question: How do relative positional embeddings differ from absolute positional embeddings, and when is each more appropriate?

## Architecture Onboarding

- Component map: Image → OCR Detection → AOE Module → Multimodal Transformer → Decoder → Answer
- Critical path: Image → OCR Detection → AOE Module → Multimodal Transformer → Decoder → Answer
- Design tradeoffs:
  - Using character-level edits for OCR noise vs. more complex OCR simulation techniques
  - Incorporating 2D spatial information vs. relying on 1D positional embeddings
  - Applying adversarial training to OCR embeddings only vs. all modalities
- Failure signatures:
  - Performance degradation on images with accurate OCR suggests overfitting to noise
  - Performance degradation on images with significant OCR errors suggests insufficient noise or poor fault tolerance learning
  - Performance degradation on images with complex spatial layouts suggests SASA is not capturing spatial relationships effectively
- First 3 experiments:
  1. Compare performance with and without AOE module to isolate the impact of adversarial OCR training
  2. Compare performance with and without SASA to assess the benefit of spatial awareness
  3. Vary the strength of adversarial perturbations (λ) to find the optimal balance between robustness and performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ATS scale with the amount of adversarial training data and perturbation magnitude?
- Basis in paper: [inferred] The paper discusses adversarial training and perturbation but does not provide a detailed analysis of performance scaling with varying amounts of data or perturbation magnitudes.
- Why unresolved: The paper focuses on the effectiveness of the ATS approach but does not explore how different levels of adversarial training data and perturbation magnitude affect the model's performance.
- What evidence would resolve it: Experiments varying the amount of adversarial training data and perturbation magnitude, with corresponding performance metrics, would provide insights into the scalability of ATS.

### Open Question 2
- Question: What is the impact of OCR errors on the performance of ATS in real-world scenarios?
- Basis in paper: [inferred] The paper addresses OCR errors through adversarial training but does not provide a comprehensive analysis of the impact of OCR errors on ATS performance in real-world scenarios.
- Why unresolved: While the paper discusses the introduction of OCR noise and adversarial training to enhance fault tolerance, it does not explore how these mechanisms perform under various real-world OCR error conditions.
- What evidence would resolve it: Experiments evaluating ATS performance with different types of OCR errors in real-world scenarios would provide insights into the robustness of the model.

### Open Question 3
- Question: How does the SASA mechanism compare to other spatial modeling techniques in terms of effectiveness and computational efficiency?
- Basis in paper: [explicit] The paper introduces the SASA mechanism and claims it helps capture spatial relationships among OCR tokens, but does not compare it to other spatial modeling techniques.
- Why unresolved: The paper does not provide a comparative analysis of the SASA mechanism against other spatial modeling techniques, leaving the effectiveness and efficiency of SASA relative to other methods unclear.
- What evidence would resolve it: Comparative experiments between SASA and other spatial modeling techniques, including performance metrics and computational efficiency analysis, would provide a clearer understanding of SASA's relative advantages.

## Limitations
- Implementation specifics are not fully specified, particularly regarding the exact character-level perturbation strategies and the integration of 2D spatial biases into the self-attention mechanism
- Reported SOTA results are primarily on the TextVQA validation set, with unclear impact on ST-VQA and ANLS metrics
- Effectiveness on general VQA tasks that do not involve scene text is unknown, limiting broader applicability

## Confidence
- **High Confidence**: The core methodology of using adversarial training to improve fault tolerance in OCR representations is well-established in the literature and aligns with existing practices in robust model training.
- **Medium Confidence**: The integration of SASA for spatial awareness is plausible, given the importance of spatial relationships in scene text understanding, but the specific implementation details are not fully specified, leaving room for uncertainty in the exact mechanism.
- **Low Confidence**: The reported SOTA results on the TextVQA validation set are based on a single evaluation, and the lack of ST-VQA results and ANLS metrics makes it difficult to assess the method's overall effectiveness and generalizability.

## Next Checks
1. Implement and compare AOE with and without SASA: Reproduce the model with the AOE module and then add the SASA mechanism. Compare the performance on both ST-VQA and TextVQA datasets to isolate the impact of spatial awareness.
2. Vary adversarial perturbation strength: Conduct an ablation study by varying the strength of adversarial perturbations (λ) in the AOE module. Analyze the performance on both datasets to find the optimal balance between robustness and accuracy.
3. Evaluate on a held-out test set: If the TextVQA validation set results are indeed SOTA, evaluate the model on a held-out test set to confirm that the performance gains are not due to overfitting to the validation set. Additionally, report ST-VQA results and ANLS metrics to provide a more comprehensive assessment of the method's effectiveness.