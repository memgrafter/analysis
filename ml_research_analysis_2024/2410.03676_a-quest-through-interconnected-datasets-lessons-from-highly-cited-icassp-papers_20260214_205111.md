---
ver: rpa2
title: 'A quest through interconnected datasets: lessons from highly-cited ICASSP
  papers'
arxiv_id: '2410.03676'
source_url: https://arxiv.org/abs/2410.03676
tags:
- data
- speech
- dataset
- datasets
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a depth-first investigation into the origins
  of datasets used in the top-5 cited papers from ICASSP 2021-2022. The study reveals
  interconnected dependencies, disbalances, and unclear origins for the datasets used
  in these papers, raising questions about the validity and integrity of outcomes
  trained on these datasets.
---

# A quest through interconnected datasets: lessons from highly-cited ICASSP papers

## Quick Facts
- arXiv ID: 2410.03676
- Source URL: https://arxiv.org/abs/2410.03676
- Reference count: 40
- Key outcome: Study reveals interconnected dataset dependencies and unclear origins in top-ICASSP papers, calling for improved data provenance practices in ML research

## Executive Summary
This depth-first investigation examines the origins of datasets used in the top-5 cited papers from ICASSP 2021-2022, revealing significant concerns about data provenance and quality in machine learning research. The study found that many datasets used in highly-cited papers have unclear or untraceable origins, with some containing potential biases due to outdated data sources. For instance, the WSJ0 dataset used in one paper contains Wall Street Journal readings over 30 years old, potentially biasing vocabulary toward American news of that era. The authors argue that these issues raise questions about the validity and integrity of research outcomes trained on such datasets.

The investigation highlights the interconnected nature of dataset dependencies in machine learning research and the challenges of curating representative datasets for general tasks. The authors call on the applied machine learning research communities to create more incentives for purposeful attention to data provenance and annotation quality in academic publishing, suggesting this should become a dedicated academic field. This work underscores the need for more rigorous documentation and validation of dataset origins to ensure the reliability and generalizability of machine learning research outcomes.

## Method Summary
The study conducted a depth-first investigation into the origins of datasets used in the top-5 cited papers from ICASSP 2021-2022. The researchers traced the provenance of datasets mentioned in these papers, examining their sources, collection methods, and potential biases. This involved analyzing publicly available information about the datasets, their documentation, and citation practices. The investigation focused on identifying interconnected dependencies between datasets, unclear origins, and potential biases that could impact the validity of research outcomes. By examining a small but highly influential sample of papers, the study aimed to highlight broader issues in data provenance practices within the machine learning research community.

## Key Results
- The study found interconnected dependencies and unclear origins for datasets used in highly-cited ICASSP papers
- Several datasets, including the WSJ0 dataset, contain potentially biased data due to outdated sources (over 30 years old)
- Collecting and curating representative datasets for general tasks would require an intractable amount of resources

## Why This Works (Mechanism)
The study's approach of tracing dataset origins in highly-cited papers reveals the interconnected nature of data dependencies in machine learning research. By examining the provenance of datasets used in influential papers, the researchers uncover potential issues with data quality, bias, and transparency that may impact the validity of research outcomes. This depth-first investigation method allows for a detailed examination of specific cases, highlighting broader systemic issues in data provenance practices. The study's findings demonstrate how the quality and representativeness of training data directly affect the reliability and generalizability of machine learning models, emphasizing the critical role of data provenance in ensuring research integrity.

## Foundational Learning

1. Data provenance: Why needed - To ensure transparency and reproducibility in machine learning research; Quick check - Verify dataset documentation includes clear information on data sources, collection methods, and potential biases

2. Dataset bias: Why needed - To identify and mitigate potential sources of bias that could impact model performance and generalizability; Quick check - Analyze dataset composition and compare it to the target population or application domain

3. Citation practices: Why needed - To properly attribute data sources and enable traceability of dataset origins; Quick check - Ensure all datasets used in research are properly cited and their documentation is accessible

4. Interconnected datasets: Why needed - To understand the dependencies between datasets and potential cascading effects of data quality issues; Quick check - Map out the relationships between datasets used in a research project

5. Data curation challenges: Why needed - To recognize the resource-intensive nature of creating representative datasets for general tasks; Quick check - Estimate the time and resources required to curate a dataset that accurately represents a given phenomenon

6. Academic incentives: Why needed - To align research practices with the importance of data quality and provenance; Quick check - Evaluate current publication criteria and their emphasis on data documentation and validation

## Architecture Onboarding

Component map: Research paper -> Datasets used -> Dataset origins -> Collection methods -> Potential biases -> Research outcomes

Critical path: The critical path in this study is the investigation of dataset origins and their potential impact on research outcomes. This involves tracing the provenance of datasets used in highly-cited papers, examining their collection methods, and identifying potential biases or unclear origins that could affect the validity of the research.

Design tradeoffs: The study focuses on a small sample of highly-cited papers, which allows for in-depth investigation but may limit generalizability. The depth-first approach provides detailed insights but may miss broader trends across the field. The reliance on publicly available information about datasets may not capture the complete picture of data origins and collection methods.

Failure signatures: Potential failure points in this study include incomplete or inaccurate dataset documentation, limited access to original data sources, and the challenge of quantifying the actual impact of data provenance issues on research outcomes. Additionally, the study's findings may be biased by the selection of papers and the availability of information about dataset origins.

First experiments:
1. Expand the analysis to include a larger sample of highly-cited papers across multiple years and conferences
2. Conduct a systematic review of dataset documentation and citation practices in machine learning research
3. Perform empirical studies to quantify the impact of data provenance issues on model performance and generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on only the top-5 cited papers from a two-year period limits generalizability
- Reliance on publicly available information may not capture the complete picture of data origins
- Does not quantify the actual impact of identified data provenance issues on model performance or research outcomes

## Confidence

High confidence:
- The interconnected nature of datasets and identification of specific examples of unclear data origins

Medium confidence:
- Claims about the potential biases in older datasets (e.g., WSJ0) and their impact on vocabulary

Low confidence:
- The assertion that collecting representative datasets for general tasks would require an intractable amount of resources

## Next Checks

1. Expand the analysis to include a larger sample of highly-cited papers across multiple years and conferences to assess the prevalence of data provenance issues

2. Conduct a systematic review of dataset documentation and citation practices in machine learning research to identify common gaps and inconsistencies

3. Perform empirical studies to quantify the impact of data provenance issues on model performance and generalizability across different domains and tasks