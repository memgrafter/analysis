---
ver: rpa2
title: Comparing Graph Transformers via Positional Encodings
arxiv_id: '2402.14202'
source_url: https://arxiv.org/abs/2402.14202
tags:
- graph
- graphs
- then
- lemma
- rpes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the theoretical and empirical comparison of
  positional encodings (PEs) in graph transformers. The authors show that absolute
  and relative PEs are equivalent in distinguishing power for graphs without node
  features, but relative PEs may be stronger when node features are present.
---

# Comparing Graph Transformers via Positional Encodings

## Quick Facts
- arXiv ID: 2402.14202
- Source URL: https://arxiv.org/abs/2402.14202
- Reference count: 40
- Primary result: Absolute and relative positional encodings have equivalent distinguishing power for unfeatured graphs, but relative PEs may be stronger when node features are present

## Executive Summary
This paper provides a comprehensive theoretical and empirical comparison of absolute positional encodings (APEs) and relative positional encodings (RPEs) in graph transformers. The authors establish that APE-GTs and RPE-GTs have equivalent distinguishing power for graphs without node features, but RPEs may have an advantage when graphs have node features. They develop a theoretical framework based on Weisfeiler-Lehman tests to analyze the expressive power of different positional encodings and identify conditions under which specific RPEs can be mapped to APEs while preserving their distinguishing power.

## Method Summary
The study employs a theoretical framework based on Weisfeiler-Lehman graph isomorphism tests to compare the distinguishing power of different positional encodings. The authors analyze the relationship between APEs and RPEs through equivariant graph networks (EGNs) that can convert RPEs to APEs. They conduct empirical validation on three datasets: CSL for graph classification, BREC for graph isomorphism testing, and ZINC for graph regression, comparing RPE-GTs, APE-GTs, and EGN APE-GTs with various positional encodings including shortest path distance, resistance distance, and spectral positional encodings.

## Key Results
- APE-GTs and RPE-GTs are equivalent in distinguishing power for graphs without node features
- RPEs may have an advantage over APEs when graphs have node features
- SPE-APE-GTs are stronger than RD-RPE-GTs for unfeatured graphs
- RPE-GTs outperform EGN APE-GTs on graph regression tasks when edge features are included

## Why This Works (Mechanism)

### Mechanism 1
APE-GTs and RPE-GTs have equivalent distinguishing power for graphs without node features. There exist mappings between RPEs and APEs that preserve the ability to distinguish non-isomorphic graphs when no node features are present. The distinguishing power is determined by the ability of the positional encoding to separate graphs in the Weisfeiler-Lehman test space. This equivalence is shown through theoretical constructions and supported by experimental evidence.

### Mechanism 2
RPEs may have an advantage over APEs when graphs have node features. Converting an RPE to an APE using a 2-EGN can result in loss of distinguishing power for graphs with node features, while RPE-GTs retain full distinguishing capability. The transformation from RPE to APE introduces a bottleneck that cannot be overcome by any 2-EGN. This limitation is demonstrated through theoretical constructions showing that certain graph pairs distinguishable by RPE-GTs become indistinguishable when converted to APEs.

### Mechanism 3
Specific RPEs like SPE-APE-GT are stronger than RD-RPE-GT for unfeatured graphs. SPE can be constructed from a diagonally-aware RPE (RSPE) that is at least as strong as the pseudoinverse of the Laplacian (L†), which is equivalent to resistance distance in distinguishing power. The 2-EGN used in SPE construction preserves the distinguishing power of the underlying RPE, while RD-RPE-GT cannot be converted to a stronger APE without using higher-order EGNs.

## Foundational Learning

- **Weisfeiler-Lehman (WL) graph isomorphism test**: The WL test and its variants (RPE-augWL, RPE-2-WL) serve as the theoretical foundation for comparing the distinguishing power of different positional encodings and graph transformers. Can you explain why the WL test is equivalent to 2-WL test for distinguishing non-isomorphic graphs?

- **Equivariant graph networks (EGNs)**: EGNs are used to convert RPEs to APEs and are central to understanding the theoretical relationship between RPE-GTs and APE-GTs. What is the key difference between a k-EGN and a k-IGN in terms of their output behavior?

- **Graph spectra and spectral kernels**: Many positional encodings are defined using the spectrum of the graph Laplacian, and understanding spectral properties is crucial for comparing SPE, RD, and other RPEs. How does the resistance distance relate to the pseudoinverse of the Laplacian matrix?

## Architecture Onboarding

- **Component map**: Node features and graph structure -> Positional encoding module (APE or RPE) -> RPE→APE conversion (2-EGN) if needed -> Transformer layers -> Output node representations

- **Critical path**: 1) Input node features and graph structure, 2) Compute positional encoding (APE or RPE), 3) If RPE, embed into attention via f1, f2 functions, 4) If converting RPE→APE, pass through 2-EGN, 5) Feed into transformer layers, 6) Output node representations

- **Design tradeoffs**: RPEs vs APEs - RPEs maintain full distinguishing power for graphs with node features; APEs are simpler to implement but may lose information. Computational cost - Using k-EGNs (k>2) for RPE→APE conversion increases expressiveness but scales as O(n^k). Diagonal-awareness - Critical for maintaining equivalence between RPE-2-WL and 2-EGN power.

- **Failure signatures**: Loss of distinguishing power when converting RPE to APE for graphs with node features, performance degradation when using combinatorially-aware RPEs that add adjacency information, computational bottleneck when using high-k EGNs for RPE→APE conversion.

- **First 3 experiments**: 1) Verify equivalence of RD-RPE-GT and SPE-APE-GT on unfeatured graph classification task, 2) Test performance drop when converting RD-RPE to RD-APE on graph regression with node features, 3) Compare adjacency matrix RPE (equivalent to MPNN) vs SPD-RPE on cut edge detection task

## Open Questions the Paper Calls Out

- **Open Question 1**: Are there efficient algorithms to learn the DeepSet function f in Theorem 3.8 or the 2-EGN g in Theorem 3.10 with minimal hidden dimensions? The paper identifies this as an interesting open question but does not provide any concrete algorithms or theoretical guarantees for efficient learning of these functions.

- **Open Question 2**: Is there a complete proof of the incomparability between shortest-path distance (SPD) and resistance distance (RD) RPEs in terms of distinguishing power? The paper only provides partial evidence through experiments and does not offer a definitive theoretical proof of incomparability.

- **Open Question 3**: What are the precise conditions under which using edge features in RPE-GTs leads to better performance than EGN APE-GTs? The paper shows that RPE-GTs outperform EGN APE-GTs on the ZINC dataset when edge features are included, but notes that this use of edge features is not captured by their theoretical results.

## Limitations
- Theoretical equivalence between APE-GTs and RPE-GTs is limited to unfeatured graphs
- Computational complexity of using k-EGNs (k>2) for RPE→APE conversion grows exponentially as O(n^k)
- Analysis assumes specific classes of RPEs and does not cover all possible positional encodings

## Confidence
- **High confidence**: The theoretical framework for comparing APE and RPE distinguishing power, particularly for unfeatured graphs
- **Medium confidence**: The empirical validation on benchmark datasets, though results show expected trends
- **Medium confidence**: The claim about SPE-APE-GT being stronger than RD-RPE-GT for unfeatured graphs

## Next Checks
1. Prove or disprove whether the SPE-APE-GT construction maintains its advantage over RD-RPE-GT when extended to graphs with node features
2. Measure the practical computational limits of using higher-order EGNs (k=3,4) for RPE→APE conversion on medium-sized graphs (100-500 nodes)
3. Evaluate whether the equivalence breaks down for graphs with specific structural properties (e.g., bipartite graphs, graphs with high clustering coefficients)