---
ver: rpa2
title: 'DLP-GAN: learning to draw modern Chinese landscape photos with generative
  adversarial network'
arxiv_id: '2403.03456'
source_url: https://arxiv.org/abs/2403.03456
tags:
- landscape
- loss
- image
- style
- photos
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DLP-GAN, a novel GAN-based framework for
  translating ancient Chinese landscape paintings into modern photos. The approach
  addresses the challenge of domain deviation between ancient and modern styles by
  using an asymmetric cycle structure with a dense-fusion module-based generator.
---

# DLP-GAN: learning to draw modern Chinese landscape photos with generative adversarial network

## Quick Facts
- arXiv ID: 2403.03456
- Source URL: https://arxiv.org/abs/2403.03456
- Reference count: 40
- Key outcome: Introduces DLP-GAN framework achieving FID scores of 198.835 (landscape) and 175.368 (sketches) for translating ancient Chinese paintings to modern photos

## Executive Summary
This paper introduces DLP-GAN, a novel GAN-based framework for translating ancient Chinese landscape paintings into modern photos. The approach addresses the challenge of domain deviation between ancient and modern styles by using an asymmetric cycle structure with a dense-fusion module-based generator. The method incorporates a dual-consistency loss combining feature and semantic consistency components to balance realism and abstraction. Experimental results demonstrate superior performance over state-of-the-art methods, achieving FID scores of 198.835 (landscape) and 175.368 (sketches), and outperforming competitors in user studies.

## Method Summary
DLP-GAN translates ancient Chinese landscape paintings to modern photos using an asymmetric cycle structure with dense-fusion module-based generators. The framework employs dual discriminators and incorporates a dual-consistency loss that combines feature and semantic consistency components. The model is trained on datasets of 1940 ancient paintings, 1794 modern photos, and 1560 sketches, with 200 epochs using Adam optimizer (β1=0.5, β2=0.999, learning rate 0.0002). The dense-fusion architecture creates direct connections from each layer to all subsequent layers, allowing maximum information retention and improved gradient propagation compared to residual blocks.

## Key Results
- Achieves FID scores of 198.835 (landscape) and 175.368 (sketches), outperforming CycleGAN, AsymmetryGAN, and DSTN baselines
- Successfully generates high-quality modern landscape photos while preserving semantic details and artistic style
- Demonstrates superior performance in user studies comparing perceptual quality against competing methods
- Shows effectiveness in handling domain deviation between ancient paintings and modern photos through asymmetric cycle structure

## Why This Works (Mechanism)

### Mechanism 1
Dense-fusion module-based generator preserves more intermediate features and improves gradient flow compared to residual blocks alone. The dense-fusion architecture creates direct connections from each layer to all subsequent layers, allowing maximum information retention and improved gradient propagation. This addresses information loss limitations in traditional CNN architectures when capturing complex style-content mappings in cross-domain translation.

### Mechanism 2
Dual-consistency loss balances realism and abstraction by combining feature and semantic consistency components. Feature-consistency loss constrains the feature space overlap between source and target domains at high-level semantic representation, while semantic-consistency loss focuses on preserving edge stroke styles through edge detection networks. Both feature-level and semantic-level constraints are necessary to capture style while preserving essential content in image translation.

### Mechanism 3
Asymmetric cycle structure addresses domain deviation by applying different constraints in forward and backward translation directions. Strict generator in (X→Y) direction focuses on capturing specific target domain characteristics, while relaxed generator in (Y→X) direction preserves overall source domain style. This handles the significantly more information and variation in modern photos compared to ancient landscape paintings, requiring different optimization strategies.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: GANs provide the adversarial training framework that enables the model to generate realistic modern photos while preserving the style of ancient paintings
  - Quick check question: How does the adversarial loss in GANs help the generator produce more realistic images that can fool the discriminator?

- Concept: Image-to-image translation with unpaired data
  - Why needed here: The model needs to translate between domains without paired examples, requiring cycle-consistency and other constraints to learn meaningful mappings
  - Quick check question: What role does cycle-consistency play in enabling translation between unpaired datasets?

- Concept: Perceptual loss and feature extraction
  - Why needed here: The model uses pre-trained VGG networks to extract high-level semantic features for feature-consistency loss, ensuring that generated images preserve semantic content
  - Quick check question: How does using perceptual loss differ from pixel-level loss in terms of preserving semantic information?

## Architecture Onboarding

- Component map: Input → Generator (dense-fusion) → Discriminator feedback → Loss computation (dual-consistency) → Parameter update → Output
- Critical path: Ancient painting → Encoder-decoder with dense-fusion → Transformer network → Discriminator → Adversarial feedback → Updated parameters → Modern photo output
- Design tradeoffs: Dense-fusion vs. residual blocks (better feature preservation but higher computational cost); Asymmetric vs. symmetric cycle (better handling of domain deviation but potentially less stable training); Dual-consistency vs. single consistency (better balance of realism/abstraction but more complex loss landscape)
- Failure signatures: Color space inconsistencies between input and output; Loss of semantic details in generated images; Artifacts or noise in the translated images; Mode collapse in generator outputs
- First 3 experiments: 1) Test basic cycle-consistency without dense-fusion or dual-consistency to establish baseline performance; 2) Add dense-fusion module to compare feature preservation against baseline; 3) Implement dual-consistency loss and evaluate the balance between realism and abstraction compared to previous versions

## Open Questions the Paper Calls Out

### Open Question 1
How does the dual-consistency loss balance between feature and semantic consistency components to achieve optimal realism and abstraction in the generated images? The paper mentions that the dual-consistency loss combines feature and semantic consistency components to balance realism and abstraction, but does not provide specific details on how this balance is achieved.

### Open Question 2
How does the dense-fusion module in the generator enhance feature propagation and encourage feature reuse compared to residual blocks used in CycleGAN? The paper mentions that the dense-fusion module has advantages over residual blocks in enhancing feature propagation and encouraging feature reuse, but does not provide specific details on how this is achieved.

### Open Question 3
How does the proposed DLP-GAN model perform on other image translation tasks beyond ancient Chinese landscape paintings to modern photos and sketches? The paper focuses on the application of DLP-GAN to ancient Chinese landscape paintings to modern photos and sketches, but does not explore its performance on other image translation tasks.

## Limitations
- Lack of specific architectural details for the dense-fusion module and dual-consistency loss components, making direct reproduction challenging
- Datasets used are not publicly available, and the paper doesn't specify whether augmentation or preprocessing was applied beyond basic resizing
- Asymmetric cycle structure's exact implementation remains unclear, particularly how different constraints are applied in forward versus backward directions

## Confidence

- High confidence: The core claim that GAN-based frameworks can translate ancient Chinese landscape paintings to modern photos is well-established in the image-to-image translation literature
- Medium confidence: The claim that dense-fusion modules improve feature preservation and gradient flow is plausible based on related work, but specific evidence for this architecture is limited
- Medium confidence: The dual-consistency loss approach combining feature and semantic components is theoretically sound, but the paper provides limited empirical validation of why this specific combination works better than alternatives

## Next Checks

1. **Implementation verification**: Implement the DLP-GAN architecture with minimal assumptions about unspecified components (using standard residual blocks as a proxy for dense-fusion) and verify that it can learn basic style transfer between any two domains with unpaired data

2. **Component ablation study**: Systematically remove each proposed innovation (dense-fusion, dual-consistency loss, asymmetric cycle) to quantify their individual contributions to performance improvements over baseline CycleGAN

3. **Domain deviation analysis**: Test the asymmetric cycle structure on domains with varying levels of deviation (e.g., paintings to photos, sketches to photos, modern to historical photos) to validate the claim that asymmetric constraints are necessary for handling large domain gaps