---
ver: rpa2
title: 'FoME: A Foundation Model for EEG using Adaptive Temporal-Lateral Attention
  Scaling'
arxiv_id: '2409.12454'
source_url: https://arxiv.org/abs/2409.12454
tags:
- fome
- data
- signal
- tasks
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FoME, a foundation model for EEG analysis using
  adaptive temporal-lateral attention scaling. The authors address challenges in EEG
  modeling including signal heterogeneity, low signal-to-noise ratios, and limited
  labeled datasets.
---

# FoME: A Foundation Model for EEG using Adaptive Temporal-Lateral Attention Scaling

## Quick Facts
- arXiv ID: 2409.12454
- Source URL: https://arxiv.org/abs/2409.12454
- Reference count: 40
- One-line primary result: FoME achieves state-of-the-art performance across EEG classification and forecasting tasks, including 95.16% accuracy in seizure detection

## Executive Summary
FoME introduces a foundation model for EEG analysis that addresses key challenges in the field including signal heterogeneity, low signal-to-noise ratios, and limited labeled datasets. The model employs two key innovations: time-frequency fusion embedding and adaptive temporal-lateral attention scaling (ATLAS) mechanism. Pre-trained on a large-scale dataset of 1.7TB of scalp and intracranial EEG recordings, FoME demonstrates superior performance across four downstream tasks including classification and forecasting, achieving state-of-the-art results in seizure detection, seizure classification, signal forecasting, and imputation.

## Method Summary
FoME uses adaptive temporal-lateral attention scaling with time-frequency fusion embedding and ATLAS mechanism. The model is pre-trained using masked signal reconstruction on heterogeneous EEG datasets, then fine-tuned for specific downstream tasks. Pre-training employs 40% masking ratio with AdamW optimizer, learning rate schedule from 2×10^-6 to 5×10^-5, for 1,096k steps on 745M parameters.

## Key Results
- Achieves 95.16% accuracy in seizure detection
- Demonstrates 87.71% accuracy in seizure classification
- Shows strong performance in signal forecasting and imputation tasks
- Outperforms state-of-the-art models across all evaluated downstream tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Time-frequency fusion embedding captures both temporal dynamics and spectral power bands in a single unified representation, enabling better generalization across diverse EEG tasks.
- Mechanism: Raw EEG signals are transformed into both time-domain patches and frequency-domain power bands (δ, θ, α, β, γ1-4), concatenated with positional embeddings to form a multi-scale input.
- Core assumption: Different EEG tasks benefit from both temporal and spectral information, and fusing them early improves downstream performance.
- Evidence anchors: [abstract] "Our model introduces two key innovations: a time-frequency fusion embedding technique and an adaptive time-lateral attention scaling (ATLAS) mechanism." [section] "The time-frequency fusion module integrates temporal, frequency, and positional information of each patch into a unified embedding."
- Break condition: If spectral bands are not relevant to a downstream task, the fusion may introduce noise; if temporal resolution is lost during patching, fine-grained event detection may fail.

### Mechanism 2
- Claim: Adaptive temporal-lateral attention scaling (ATLAS) dynamically modulates attention across both time and channel dimensions, allowing the model to flexibly adapt to varying EEG signal structures.
- Mechanism: ATLAS applies separate attention operations along temporal and channel axes, scaling them based on input patterns to emphasize long-range temporal dependencies in seizure detection while focusing on channel-specific interactions in motor imagery.
- Core assumption: EEG signals vary significantly across tasks in terms of temporal length and spatial (channel) importance, and a fixed attention pattern cannot optimally capture these differences.
- Evidence anchors: [abstract] "These components synergistically capture complex temporal and spectral EEG dynamics, enabling FoME to adapt to varying patterns across diverse data streams and facilitate robust multi-channel modeling." [section] "The adaptive multi-channel encoder is specifically designed to capture spatial relationships and inter-channel dynamics within EEG data."
- Break condition: If the attention scaling becomes too aggressive, it may ignore important fixed spatial patterns; if too conservative, it may not adapt enough to task-specific needs.

### Mechanism 3
- Claim: Large-scale self-supervised pre-training on heterogeneous EEG data builds generalizable representations that transfer effectively to downstream tasks with minimal fine-tuning.
- Mechanism: FoME is pre-trained on 1.7TB of diverse scalp and intracranial EEG data using masked signal reconstruction, forcing the model to learn robust, task-agnostic features that capture common EEG signal characteristics.
- Core assumption: EEG signals share underlying structural patterns across tasks, and learning these patterns in an unsupervised way improves transfer performance.
- Evidence anchors: [abstract] "FoME is pre-trained on a diverse 1.7TB dataset of scalp and intracranial EEG recordings, comprising 745M parameters trained for 1,096k steps." [section] "The model adopts a self-supervised learning paradigm, employing a masked signal reconstruction task to train on extensive unlabeled EEG data."
- Break condition: If the pre-training dataset is too narrow in scope, the learned representations may not generalize; if the mask ratio is too high, the model may fail to reconstruct meaningful patterns.

## Foundational Learning

- Concept: Time-frequency analysis of EEG signals
  - Why needed here: EEG contains both temporal dynamics and frequency-specific features; understanding how to extract and fuse both is essential for building effective models.
  - Quick check question: Can you explain why different EEG bands (δ, θ, α, β, γ) are important for different cognitive and clinical states?

- Concept: Self-supervised learning via masked reconstruction
  - Why needed here: Labeled EEG data is scarce and expensive; self-supervised pre-training allows the model to learn useful representations without manual annotation.
  - Quick check question: How does masked signal reconstruction differ from masked language modeling in NLP?

- Concept: Multi-head attention and transformer architectures
  - Why needed here: Transformers are the backbone of FoME; understanding attention mechanisms and how they scale across temporal and spatial dimensions is critical for debugging and extending the model.
  - Quick check question: What is the role of the scaling factor 1/√D in the attention score computation?

## Architecture Onboarding

- Component map: Input -> Time-Frequency Fusion -> Temporal Encoder -> Adaptive Multi-Channel Encoder -> Output Head (reconstruction/classification/forecasting)
- Critical path: Time-Frequency Fusion -> Temporal Encoder -> Adaptive Multi-Channel Encoder -> Task-specific head
- Design tradeoffs: Larger model size improves performance but increases training cost; higher mask ratio improves robustness but may hurt reconstruction quality; longer sequences improve temporal context but increase memory usage.
- Failure signatures: Poor classification performance may indicate inadequate spectral fusion; failure in forecasting may indicate insufficient temporal context; instability in training may indicate learning rate issues.
- First 3 experiments:
  1. Train a baseline model without time-frequency fusion to confirm the importance of spectral information.
  2. Test different mask ratios (20%, 40%, 60%) during pre-training to find the optimal balance between reconstruction and robustness.
  3. Compare single-head vs multi-head attention in the temporal encoder to assess the impact on temporal modeling.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided content.

## Limitations

- The paper lacks direct ablation studies comparing the adaptive temporal-lateral attention scaling (ATLAS) mechanism against simpler attention variants to isolate its unique contribution.
- Pre-training dataset composition is underspecified, making it difficult to assess generalization potential across different EEG recording conditions.
- The specific implementation details of the ATLAS mechanism are not fully described, limiting reproducibility of the adaptive attention behavior.

## Confidence

- High confidence in the model's overall performance across reported downstream tasks, supported by quantitative metrics
- Medium confidence in the claimed superiority of the time-frequency fusion embedding, as ablation study shows improvement but doesn't test alternative fusion strategies
- Low confidence in the specific contribution of the adaptive attention scaling mechanism, due to limited ablation and lack of comparison to simpler alternatives

## Next Checks

1. Perform an ablation study specifically testing the ATLAS mechanism by comparing it against a fixed attention pattern with equivalent parameters to isolate its unique contribution.

2. Test the model on held-out EEG datasets from different recording equipment manufacturers to assess true generalization beyond the pre-training distribution.

3. Evaluate whether the time-frequency fusion provides benefits when applied to transformer architectures designed for sequential data (like LSTMs or convolutional networks) to determine if the gains are architecture-specific.