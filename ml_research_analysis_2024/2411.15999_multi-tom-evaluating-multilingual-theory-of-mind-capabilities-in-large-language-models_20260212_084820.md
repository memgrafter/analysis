---
ver: rpa2
title: 'Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language
  Models'
arxiv_id: '2411.15999'
source_url: https://arxiv.org/abs/2411.15999
tags:
- task
- cultural
- story
- english
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Multi-ToM, a multilingual dataset for evaluating
  Theory of Mind (ToM) in large language models (LLMs) across seven languages. The
  dataset includes direct translations of existing ToM tasks and culturally adapted
  versions with region-specific elements.
---

# Multi-ToM: Evaluating Multilingual Theory of Mind Capabilities in Large Language Models

## Quick Facts
- arXiv ID: 2411.15999
- Source URL: https://arxiv.org/abs/2411.15999
- Reference count: 38
- Primary result: LLMs show consistent ToM performance across languages, but culturally nuanced prompts slightly reduce accuracy, particularly in English.

## Executive Summary
This paper introduces Multi-ToM, a multilingual dataset for evaluating Theory of Mind (ToM) in large language models (LLMs) across seven languages. The dataset includes direct translations of existing ToM tasks and culturally adapted versions with region-specific elements. Six state-of-the-art LLMs were evaluated on both datasets. Results show that while task performance is consistent across languages, culturally nuanced prompts slightly reduce accuracy, particularly in English. This highlights the sensitivity of LLMs to cultural context and extraneous information, suggesting the need for more robust, culturally aware models in cross-cultural social reasoning.

## Method Summary
The study evaluates six LLMs (Claude-3.5-Sonnet, Claude Instant v1.2, GPT-4o, GPT-3.5-Turbo, Llama-3.1-8b Instruct, Llama-2-7b Chat) on the Multi-ToM dataset containing 100-300 samples per language across seven languages (Arabic, English, Bengali, Hindi, Russian, French, Chinese). The dataset includes both direct translations and culturally adapted versions of eight ToM task types. Performance is measured by accuracy across task types and six ability dimensions. No training is required as this is an evaluation study.

## Key Results
- LLMs perform consistently across languages for direct translations of ToM tasks
- Culturally nuanced prompts reduce accuracy by 5-8%, especially in English
- Resource-rich languages (English, Chinese, French) outperform low-resource languages (Bangla, Hindi, Arabic)
- Task format affects performance more than language, with simpler formats showing less cultural sensitivity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs perform more consistently on ToM tasks when linguistic and cultural context matches their training data distribution.
- Mechanism: Training data for dominant languages (English, Chinese, French) contains richer social reasoning contexts and more diverse cultural references, enabling better pattern matching on ToM tasks.
- Core assumption: LLMs' performance on ToM tasks depends on the overlap between task context and pretraining corpus distribution.
- Evidence anchors:
  - [abstract]: "Results show that while task performance is consistent across languages, culturally nuanced prompts slightly reduce accuracy, particularly in English."
  - [section]: "LLMs perform better in resource-rich languages like English, Chinese, and French, while low-resource languages such as Bangla, Hindi, and Arabic score lower."
  - [corpus]: "Average neighbor FMR=0.471, average citations=0.0" - weak corpus support for cultural reasoning claims.
- Break condition: When cultural elements are introduced that significantly deviate from pretraining distribution, even in resource-rich languages.

### Mechanism 2
- Claim: Cultural adaptation introduces cognitive load that interferes with core ToM reasoning.
- Mechanism: Additional cultural details increase task complexity beyond the model's capacity to maintain focus on the essential mental state attribution.
- Core assumption: LLMs have limited working memory for maintaining multiple context threads simultaneously.
- Evidence anchors:
  - [abstract]: "culturally nuanced prompts slightly reduce accuracy, particularly in English."
  - [section]: "the inclusion of culturally specific elements, such as names of people, places, and irrelevant details in the questions and options, likely disrupt the model's reasoning process."
  - [corpus]: "Found 25 related papers" - suggests active research area but no direct evidence in corpus.
- Break condition: When cultural elements are minimal or directly relevant to the mental state inference.

### Mechanism 3
- Claim: Task format affects performance more than language, with simpler formats showing less cultural sensitivity.
- Mechanism: Binary or simpler response formats reduce cognitive load, making them less susceptible to cultural context interference.
- Core assumption: Task complexity is the primary driver of performance variance across languages.
- Evidence anchors:
  - [section]: "Faux-pas Recognition Test (FRT) shows relatively high performance due to its simpler true/false format, reducing task complexity."
  - [section]: "Scalar Implicature Task (SIT) performs poorly, likely due to its reliance on mathematical reasoning, an area where LLMs are limited."
  - [corpus]: "Reasoning Promotes Robustness in Theory of Mind Tasks" - suggests task format impacts performance.
- Break condition: When tasks are inherently complex regardless of format.

## Foundational Learning

- Concept: Cultural context effects on language model performance
  - Why needed here: Understanding how cultural adaptation affects model reasoning is central to interpreting Multi-ToM results
  - Quick check question: Why did culturally adapted English prompts show reduced accuracy compared to direct translations?

- Concept: Theory of Mind evaluation frameworks
  - Why needed here: The paper evaluates multiple ToM tasks and abilities that require specific understanding of social cognition
  - Quick check question: What distinguishes a False Belief Task from a Faux-pas Recognition Test in terms of cognitive demand?

- Concept: Low-resource vs high-resource language modeling
  - Why needed here: Performance differences across languages suggest resource availability impacts ToM capabilities
  - Quick check question: How might training data scarcity for Bangla/Hindi affect ToM task performance compared to English?

## Architecture Onboarding

- Component map: Translation pipeline → Cultural adaptation module → LLM inference → Evaluation framework
- Critical path: Data preparation (translation + cultural adaptation) → Prompt formatting → Model inference → Performance analysis
- Design tradeoffs: Cultural authenticity vs. task consistency; resource investment in low-resource languages vs. performance gains
- Failure signatures: Reduced accuracy with cultural adaptation; language-dependent performance gaps; format-dependent task success rates
- First 3 experiments:
  1. Test whether simplifying culturally adapted prompts restores accuracy without losing cultural context
  2. Compare performance across different LLM families to isolate architecture effects
  3. Measure correlation between training data size per language and ToM task performance

## Open Questions the Paper Calls Out
None

## Limitations

- Study based on relatively small sample sizes (100-300 instances per language) that may not fully capture cross-cultural reasoning variations
- Automated sub-sampling using sentence transformers introduces uncertainty about cultural nuance representation
- Only six commercial LLMs evaluated, limiting generalizability to other model architectures

## Confidence

**High Confidence**: The observation that resource-rich languages (English, Chinese, French) consistently outperform low-resource languages (Bangla, Hindi, Arabic) across both direct and culturally adapted tasks.

**Medium Confidence**: The claim that culturally nuanced prompts reduce accuracy, particularly in English, though the magnitude may be influenced by task-specific factors.

**Low Confidence**: The mechanism suggesting that cultural elements introduce cognitive load that interferes with core ToM reasoning, as limited evidence exists for this specific bottleneck.

## Next Checks

1. **Cross-linguistic consistency test**: Replicate the study using a larger sample size (500+ instances per language) and verify whether observed performance patterns hold across different task subsets and model families.

2. **Cultural element isolation**: Conduct controlled experiments where cultural elements are systematically varied (names only, locations only, both) to determine which specific cultural components drive performance reductions.

3. **Resource scaling experiment**: Test whether fine-tuning low-resource language models on culturally relevant data from resource-rich languages improves ToM performance, validating the hypothesis about training data distribution effects.