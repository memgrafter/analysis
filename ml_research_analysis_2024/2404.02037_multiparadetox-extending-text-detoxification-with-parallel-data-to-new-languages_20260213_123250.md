---
ver: rpa2
title: 'MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages'
arxiv_id: '2404.02037'
source_url: https://arxiv.org/abs/2404.02037
tags:
- text
- task
- language
- detoxification
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends the ParaDetox pipeline to multiple languages,
  presenting MultiParaDetox for automated parallel detoxification corpus collection
  across languages. The authors apply this pipeline to collect new parallel datasets
  for Russian, Ukrainian, and Spanish by adapting tasks to each language and using
  crowdsourcing for data collection.
---

# MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages

## Quick Facts
- arXiv ID: 2404.02037
- Source URL: https://arxiv.org/abs/2404.02037
- Reference count: 34
- Primary result: MultiParaDetox pipeline extends ParaDetox to Russian, Ukrainian, and Spanish with effective parallel corpus collection and fine-tuning of detoxification models.

## Executive Summary
This paper presents MultiParaDetox, an extension of the ParaDetox pipeline for collecting parallel corpora for text detoxification in multiple languages. The authors adapt the pipeline to Russian, Ukrainian, and Spanish by adjusting tasks to each language and using crowdsourcing for data collection. They then experiment with various text detoxification models, including unsupervised baselines, LLMs, and fine-tuned models on the collected parallel corpora. Results demonstrate that models fine-tuned on the proposed parallel data outperform unsupervised baselines and zero-shot-prompted LLMs, confirming the effectiveness of parallel corpora for text detoxification. The multilingual model fine-tuned on all three languages performs comparably to monolingual models, suggesting potential for unified multilingual detoxification systems.

## Method Summary
The paper extends ParaDetox to collect parallel detoxification corpora for Russian, Ukrainian, and Spanish through a multi-stage process. First, toxic sentences are collected from monolingual classification corpora or filtered from general text using toxic keywords. Then, tasks are adapted to each target language through translation and native speaker review. Crowdsourcing is used to generate detoxified paraphrases, with quality control measures including semantic equivalence verification and toxicity assessment. The collected parallel datasets are then used to fine-tune multilingual mBART models, which are evaluated against unsupervised baselines and LLM prompting approaches using Style Transfer Accuracy, Content Similarity, Fluency, and Joint scores.

## Key Results
- Models fine-tuned on parallel data significantly outperform unsupervised baselines and zero-shot-prompted LLMs across all three languages
- The multilingual model fine-tuned on all three languages performs comparably to monolingual models
- Inter-annotator agreement (Krippendorff's α) varies by language: 0.85 (Russian), 0.90 (Ukrainian), 0.67 (Spanish)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Parallel corpora provide strong supervision for style transfer by aligning toxic and neutral versions of the same content
- Mechanism: The detoxification model learns to map toxic expressions to neutral equivalents while preserving meaning through direct paired examples
- Core assumption: The parallel pairs accurately preserve content meaning while only changing surface style/toxicity
- Evidence anchors:
  - "Results show that models fine-tuned on the proposed parallel data outperform unsupervised baselines and zero-shot-prompted LLMs"
  - "three following components are measured: Style Transfer Accuracy (STA), Content Similarity (SIM), Fluency (FL)"
- Break condition: If parallel pairs don't preserve content (low SIM scores), or if STA drops significantly, indicating poor style transfer learning

### Mechanism 2
- Claim: Multilingual fine-tuning enables transfer of detoxification capabilities across languages
- Mechanism: A model trained on multiple language pairs learns shared detoxification patterns that generalize to new languages
- Core assumption: Toxic expressions and their neutral paraphrases share cross-lingual patterns that can be learned
- Evidence anchors:
  - "The multilingual model fine-tuned on all three languages performs comparably to monolingual models"
  - "Style Transfer Accuracy (STA) Toxicity classification result from the classifiers"
- Break condition: If multilingual model performance drops significantly compared to monolingual models, or if cross-lingual transfer fails

### Mechanism 3
- Claim: Crowdsourcing with quality control enables scalable parallel corpus collection for any language
- Mechanism: Parallel pairs are collected through iterative annotation tasks with verification steps to ensure quality
- Core assumption: Crowd workers can accurately paraphrase toxic content to neutral while preserving meaning
- Evidence anchors:
  - "Data Quality Verification... For all languages, the amount of inappropriate pairs was < 10%"
  - "For Russian it equals to 0.85, for Ukrainian it equals to 0.90, and for Spanish it equals to 0.67"
- Break condition: If inter-annotator agreement drops below acceptable thresholds, or if quality verification reveals systematic errors

## Foundational Learning

- Concept: Textual style transfer as conditional generation
  - Why needed here: Detoxification is a specific form of style transfer where the target style is "neutral/toxic-free"
  - Quick check question: What's the key difference between text detoxification and sentiment transfer?

- Concept: Parallel vs. non-parallel learning paradigms
  - Why needed here: The paper compares supervised (parallel) vs. unsupervised approaches to detoxification
  - Quick check question: Why do parallel corpora typically outperform non-parallel approaches for style transfer?

- Concept: Cross-lingual transfer learning
  - Why needed here: The multilingual model experiments test whether detoxification knowledge transfers across languages
  - Quick check question: What factors might limit cross-lingual transfer for text detoxification?

## Architecture Onboarding

- Component map: Toxic corpus preparation -> Task language adaptation -> Task settings adjustment -> Crowdsourcing data collection -> Parallel corpus generation -> Model training (mBART fine-tuning) -> Evaluation (STA/SIM/FL metrics)
- Critical path: Data collection → Model training → Evaluation → Deployment
- Design tradeoffs:
  - Parallel vs. non-parallel approaches: Parallel gives better performance but requires expensive data collection
  - Monolingual vs. multilingual models: Multilingual saves resources but may sacrifice some performance
  - Crowdsourcing vs. expert annotation: Crowdsourcing is scalable but requires quality control
- Failure signatures:
  - Low STA scores: Model fails to detoxify text (too much toxic content remains)
  - Low SIM scores: Model changes meaning too much during detoxification
  - Low FL scores: Model produces unnatural or ungrammatical output
- First 3 experiments:
  1. Run unsupervised baselines (Delete, condBERT) on new language data to establish performance floor
  2. Fine-tune mBART on collected parallel corpus and evaluate STA/SIM/FL
  3. Compare multilingual vs. monolingual fine-tuned models on held-out test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of text detoxification models vary across different toxicity types (e.g., explicit vs. implicit toxicity) in multilingual settings?
- Basis in paper: The paper mentions that the task definition and data purposely include only explicit types of toxicity, and more sophisticated definitions are needed for implicit toxicity types like sarcasm or racism
- Why unresolved: The paper focuses on explicit toxicity and does not explore implicit toxicity types, which require different approaches and datasets
- What evidence would resolve it: Conducting experiments with datasets that include various toxicity types, such as sarcasm and racism, and evaluating model performance across these types in multilingual settings would provide insights into the effectiveness of detoxification models for different toxicity types

### Open Question 2
- Question: What is the minimum amount of parallel data required to fine-tune an effective text detoxification model for a new language?
- Basis in paper: The paper suggests that the further research direction might be to explore the minimal necessary amount of parallel data to fine-tune a solid text detoxification model
- Why unresolved: The paper does not provide experiments or analysis on the minimum data requirements for effective model fine-tuning
- What evidence would resolve it: Conducting experiments with varying amounts of parallel data for different languages and evaluating the performance of fine-tuned models would help determine the minimum data requirements for effective text detoxification

### Open Question 3
- Question: How effective is cross-lingual knowledge transfer between languages from neighboring language families for improving text detoxification performance?
- Basis in paper: The paper mentions the possibility of exploring cross-lingual knowledge transfer between languages from neighboring language families to improve performance
- Why unresolved: The paper does not provide experiments or analysis on cross-lingual knowledge transfer between languages from neighboring language families
- What evidence would resolve it: Conducting experiments with cross-lingual transfer between languages from neighboring language families and evaluating the performance of detoxification models would provide insights into the effectiveness of cross-lingual knowledge transfer for improving text detoxification

## Limitations
- Parallel corpus collection relies heavily on crowdsourcing, which may introduce systematic biases or inconsistencies across languages
- Evaluation framework focuses primarily on automatic metrics without extensive human evaluation of real-world appropriateness of detoxification outputs
- Inter-annotator agreement varies significantly across languages, with Spanish showing notably lower agreement (0.67) than Russian and Ukrainian

## Confidence
- **High Confidence**: Models fine-tuned on parallel data outperform unsupervised baselines is well-supported by experimental results
- **Medium Confidence**: Multilingual models performing comparably to monolingual models has limited evidence (only one experiment reported)
- **Low Confidence**: Scalability and generalizability of MultiParaDetox pipeline to other languages is speculative

## Next Checks
1. Conduct extensive human evaluation studies on detoxification outputs to validate automatic metrics and assess real-world appropriateness, particularly for Spanish where inter-annotator agreement was lowest
2. Perform cross-lingual transfer experiments by fine-tuning on one language pair and testing on another to quantify actual transfer capabilities
3. Test the MultiParaDetox pipeline on a morphologically complex language with limited resources (such as Finnish or Hungarian) to evaluate true scalability and identify language-specific challenges