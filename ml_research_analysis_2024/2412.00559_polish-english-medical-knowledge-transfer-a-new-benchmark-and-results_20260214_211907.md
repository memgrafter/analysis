---
ver: rpa2
title: 'Polish-English medical knowledge transfer: A new benchmark and results'
arxiv_id: '2412.00559'
source_url: https://arxiv.org/abs/2412.00559
tags:
- medical
- exams
- exam
- llms
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a new benchmark dataset of over 24,000 Polish
  medical exam questions (LEK, LDEK, PES) with a subset professionally translated
  into English. We evaluate state-of-the-art LLMs including general-purpose, domain-specific,
  and Polish-specific models, comparing their performance against human medical students.
---

# Polish-English medical knowledge transfer: A new benchmark and results

## Quick Facts
- arXiv ID: 2412.00559
- Source URL: https://arxiv.org/abs/2412.00559
- Reference count: 19
- This study introduces a new benchmark dataset of over 24,000 Polish medical exam questions (LEK, LDEK, PES) with a subset professionally translated into English.

## Executive Summary
This study introduces a comprehensive benchmark dataset of Polish medical exam questions and evaluates state-of-the-art Large Language Models (LLMs) on their ability to answer these questions, comparing their performance against human medical students. The dataset includes over 24,000 questions from three major Polish medical licensing exams (LEK, LDEK, PES), with a subset professionally translated into English. Multiple models were tested, including general-purpose models like GPT-4o, domain-specific medical models, and Polish-specific models. The study reveals significant performance gaps between languages and model types, with GPT-4o achieving near-human performance overall while medical-specific models underperform. These findings have important implications for deploying LLMs in clinical settings, particularly regarding cross-lingual knowledge transfer and domain specialization.

## Method Summary
The study evaluated LLMs on Polish medical exam questions from three licensing exams (LEK, LDEK, PES) using over 24,000 questions, with a subset professionally translated into English. Models were prompted to answer single-choice questions without additional examples or explanations. Performance was measured as percentage of correct answers and compared against human medical student baselines. The evaluation included general-purpose models (GPT-4o, Llama-3.1), medical-specific models (BioMistral-7B, Meditron), and Polish-specific models (Bielik-11B-v2.2). The dataset was preprocessed to remove questions with images and invalid entries.

## Key Results
- GPT-4o achieves near-human performance overall, particularly excelling in the PES category
- Medical-specific models underperform compared to general-purpose models, likely due to English-only fine-tuning
- All models perform significantly better on English versions than Polish, with dentistry specialties proving most challenging
- Laboratory diagnostics and public health show the highest scores across all model types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4o achieves near-human performance by leveraging broad multilingual training data, allowing it to generalize better across languages and medical domains than fine-tuned medical-specific models.
- Mechanism: General-purpose models like GPT-4o are trained on diverse corpora that include substantial English and other languages, enabling them to transfer knowledge across linguistic contexts and outperform models fine-tuned on narrow English medical datasets.
- Core assumption: The quality and breadth of training data, especially multilingual coverage, outweighs the benefits of domain-specific fine-tuning for this task.
- Evidence anchors:
  - [abstract] "GPT-4o achieves near-human performance overall, while significant challenges persist in cross-lingual translation and domain-specific understanding."
  - [section 5] "GPT-4o is the best performing model overall. Particularly in the PES category, it outperforms the second-best model."
  - [corpus] Weak: no direct citation linking GPT-4o's performance to multilingual training, but general pattern observed in related work on multilingual LLMs.
- Break condition: If domain-specific knowledge gaps in general models are critical for a task, or if multilingual data quality is poor, fine-tuned models may outperform.

### Mechanism 2
- Claim: Medical-specific models underperform because they are fine-tuned on English medical data, creating a language mismatch when evaluated on Polish medical exams.
- Mechanism: Models trained exclusively on English corpora lack the linguistic and cultural context needed to interpret Polish medical terminology and guidelines accurately, leading to lower scores.
- Core assumption: Medical knowledge is partially language- and region-specific, so models must be trained in the target language to perform well.
- Evidence anchors:
  - [abstract] "Medical-specific models underperform compared to general-purpose models, and all models perform better on English versions than Polish."
  - [section 5] "Among the non-restricted API models, Meta-Llama-3.1-70B-Instruct is the best performer. Generally, general-purpose models outperform medical-specific models, possibly because the latter were fine-tuned on English medical data."
  - [corpus] Weak: related studies note challenges in cross-lingual medical benchmarks, but direct evidence on English-only fine-tuning impact is sparse.
- Break condition: If models are fine-tuned on high-quality multilingual medical data or if medical knowledge is truly universal, this gap may narrow.

### Mechanism 3
- Claim: Model performance improves with size and general capability, as larger models capture more nuanced patterns in medical reasoning, but gains plateau beyond a certain scale.
- Mechanism: Larger models have more parameters to encode complex relationships in medical knowledge, enabling better performance on difficult questions and across specialties, though diminishing returns appear at very large scales.
- Core assumption: Model capacity correlates with ability to handle domain-specific complexity and cross-lingual transfer.
- Evidence anchors:
  - [section 5] "Among the non-restricted API models, Meta-Llama-3.1-70B-Instruct is the best performer... Bielik-11B-v2.2-Instruct may be preferable, as it still outperforms Meta-Llama-3.1-8B-Instruct of similar size in Polish-only exams."
  - [corpus] Weak: general scaling laws suggest larger models perform better, but direct evidence for medical reasoning is limited in this corpus.
- Break condition: If task complexity does not require large capacity, or if data quality is limiting, further scaling may not improve results.

## Foundational Learning

- Concept: Cross-lingual knowledge transfer
  - Why needed here: The benchmark evaluates models on both Polish and English medical exams, revealing how well models transfer knowledge across languages.
  - Quick check question: What is the key challenge when evaluating LLMs on translated medical exam questions?
- Concept: Medical domain specialization vs. general capability
  - Why needed here: The study compares medical-specific models to general-purpose models, highlighting trade-offs between domain expertise and broad linguistic competence.
  - Quick check question: Why might a general-purpose multilingual model outperform a medical-specific model on Polish medical exams?
- Concept: Benchmarking and evaluation methodology
  - Why needed here: Understanding how the dataset was constructed, cleaned, and used for evaluation is critical for interpreting results and designing follow-up experiments.
  - Quick check question: What preprocessing step was taken to ensure the dataset was suitable for text-only AI benchmarks?

## Architecture Onboarding

- Component map: HTML/PDF scraping -> Preprocessing (filtering images, invalid questions) -> Dataset split (LEK, LDEK, PES, English subsets) -> Model inference (HuggingFace/OpenAI API) -> Evaluation (accuracy, pass/fail thresholds)
- Critical path: Acquire raw exam data -> Clean and structure dataset -> Select and configure models -> Run inference -> Compare results against human baselines
- Design tradeoffs: Using general-purpose models offers better multilingual performance but may lack deep medical expertise; medical-specific models are more focused but suffer from language mismatch; restricted API models (GPT-4o) offer best performance but raise privacy concerns
- Failure signatures: Low scores on dentistry specialties suggest models miss domain-specific nuances; large gaps between Polish and English performance indicate language transfer issues; failure to pass exams despite high accuracy on some subsets signals threshold sensitivity
- First 3 experiments:
  1. Evaluate a medical-specific model on both Polish and English subsets to quantify language impact.
  2. Test a general-purpose multilingual model of varying sizes to observe scaling effects on Polish-only exams.
  3. Compare model performance on specialty subsets to identify which domains are most challenging and why.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do Polish-specific LLMs perform on Polish medical exams compared to general-purpose multilingual models when both are fine-tuned on comparable amounts of medical data?
- Basis in paper: [explicit] The paper compares Bielik-11B-v2.2-Instruct (Polish-specific) with general-purpose models but doesn't analyze the impact of fine-tuning data volume on performance differences.
- Why unresolved: The paper doesn't provide information about the size or quality of fine-tuning datasets for different models, making it impossible to determine if performance differences are due to language specificity or training data volume.
- What evidence would resolve it: Detailed information about the size and quality of medical fine-tuning datasets for each model, along with controlled experiments varying training data amounts.

### Open Question 2
- Question: What is the impact of cultural and legal context embedded in medical training data on LLM performance for clinical decision-making tasks?
- Basis in paper: [explicit] The paper discusses how societal norms, legal frameworks, and epidemiological trends influence medical practice and potentially bias training corpora.
- Why unresolved: The study only examines multiple-choice exam performance and doesn't investigate how these embedded biases affect real-world clinical reasoning or decision-making tasks.
- What evidence would resolve it: Experiments comparing LLM performance on clinical scenarios with varying cultural/legal contexts, or analysis of how models handle questions involving different healthcare systems.

### Open Question 3
- Question: How does the performance gap between English and Polish medical exams change as LLMs increase in size and capability?
- Basis in paper: [explicit] The paper shows that larger models (like Meta-Llama-3.1-70B-Instruct) have smaller performance gaps between languages compared to smaller models.
- Why unresolved: The study only tests a limited range of model sizes and doesn't establish a clear relationship between model capability and cross-lingual performance improvement.
- What evidence would resolve it: Systematic testing across a wider range of model sizes and capabilities, with statistical analysis of the relationship between model size and cross-lingual performance gap.

## Limitations

- The human baseline representativeness is unclear, as the study doesn't specify whether the sample is representative of all Polish medical graduates or if testing conditions were standardized.
- Translation quality between Polish and English exam versions is not independently verified, potentially introducing artifacts in cross-lingual comparisons.
- The study doesn't account for potential domain-specific knowledge differences between Polish and international medical standards that might affect model performance.

## Confidence

- GPT-4o's near-human performance (High confidence): Direct numerical comparisons showing GPT-4o achieving 71.5% accuracy versus human averages around 43.5 points.
- Medical-specific models underperforming general-purpose models (Medium confidence): Data shows this pattern but underlying mechanism remains speculative.
- Cross-lingual performance gap (Medium confidence): Documented observation but study doesn't control for translation quality or investigate which question types are most affected.

## Next Checks

1. **Human baseline validation**: Replicate the human performance measurement using a larger, more diverse sample of medical students taking the same exams under standardized conditions to verify the reported baseline accuracy and standard deviation.

2. **Translation quality assessment**: Conduct a blind review where medical experts evaluate a subset of Polish and English questions for semantic equivalence, measuring any systematic differences in difficulty or meaning that could explain performance gaps.

3. **Controlled fine-tuning experiment**: Fine-tune a medical-specific model on high-quality Polish medical data and re-evaluate its performance on the Polish-only exam subset to directly test whether language-specific training resolves the observed performance gap.