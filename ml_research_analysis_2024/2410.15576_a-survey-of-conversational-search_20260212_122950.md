---
ver: rpa2
title: A Survey of Conversational Search
arxiv_id: '2410.15576'
source_url: https://arxiv.org/abs/2410.15576
tags:
- search
- conversational
- available
- online
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a comprehensive review of conversational
  search systems, focusing on four key modules: query reformulation, search clarification,
  conversational retrieval, and response generation. The survey highlights the transformative
  impact of large language models (LLMs) on each module, enabling more natural and
  intelligent user interactions.'
---

# A Survey of Conversational Search

## Quick Facts
- arXiv ID: 2410.15576
- Source URL: https://arxiv.org/abs/2410.15576
- Reference count: 40
- This survey provides a comprehensive review of conversational search systems, focusing on four key modules: query reformulation, search clarification, conversational retrieval, and response generation.

## Executive Summary
This survey comprehensively reviews conversational search systems, which enhance traditional keyword-based search by supporting natural language dialogue and maintaining context across multi-turn interactions. The survey focuses on four key modules: query reformulation (resolving anaphora and ellipsis), search clarification (proactively disambiguating user intent), conversational retrieval (handling context dependencies), and response generation (producing informative answers). It highlights how large language models (LLMs) have transformed each module, enabling more natural and intelligent user interactions while presenting new challenges for innovation and performance improvement.

## Method Summary
The survey synthesizes research on conversational search systems through a comprehensive literature review, organizing findings around four core modules: query reformulation, search clarification, conversational retrieval, and response generation. It examines how LLMs have been integrated into each component, discusses domain-specific applications, and reviews available benchmarks for evaluation. The methodology involves analyzing existing datasets, evaluation metrics, and implementation approaches while identifying open challenges and future research directions for the field.

## Key Results
- LLMs have transformed conversational search by enabling more natural query reformulation and response generation capabilities
- Context denoising is critical for effective conversational retrieval, requiring techniques to filter irrelevant historical turns
- The field faces significant challenges in intelligent decision-making, knowledge attribution, personalized conversations, and practical evaluation methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Query reformulation is essential in conversational search due to anaphora and ellipsis phenomena that create context-dependent queries.
- Mechanism: The system resolves references and fills omitted information from the conversational history to transform context-dependent queries into stand-alone ones.
- Core assumption: Historical context contains the semantic information needed to resolve current query ambiguities.
- Evidence anchors:
  - [abstract] "Unlike traditional keyword-based search engines, conversational search systems enhance user experience by supporting intricate queries, maintaining context over multi-turn interactions"
  - [section 2.1] "In conversational search, query reformulation is critical due to the complex nature of user intent, which is often obscured within follow-up questions and results in context-dependent queries"
  - [corpus] Weak - no direct corpus evidence for anaphora/ellipsis resolution mechanisms
- Break condition: When historical context is insufficient or ambiguous references cannot be resolved from available conversation history.

### Mechanism 2
- Claim: Search clarification improves conversational search by proactively asking questions to disambiguate user intent.
- Mechanism: The system detects ambiguous or faceted search intents and generates clarifying questions to help users re-articulate their needs.
- Core assumption: Users benefit from system-initiated clarification rather than providing all information upfront.
- Evidence anchors:
  - [abstract] "Unlike traditional keyword-based search engines, conversational search systems enhance user experience by supporting intricate queries, maintaining context over multi-turn interactions"
  - [section 3.1] "The fundamental idea of a conversational retrieval system with clarification is to guide users through multiple rounds of queries, prompting them to provide increasingly useful information"
  - [corpus] Moderate - corpus shows studies on clarifying question generation but limited evidence on user benefit quantification
- Break condition: When clarification questions become annoying or when users prefer to reformulate queries themselves.

### Mechanism 3
- Claim: Context denoising is crucial for conversational retrieval to filter irrelevant historical turns.
- Mechanism: The system uses implicit or explicit techniques to identify and remove noisy historical context while preserving relevant information for current query processing.
- Core assumption: Not all historical turns are equally relevant to the current query, and noise injection degrades retrieval performance.
- Evidence anchors:
  - [section 4.2] "Within a conversational session, not all historical query turns are relevant to address the current user's information needs. Simply concatenating all historical context would inject unnecessary and noisy turns"
  - [section 4.2] "To this end, context denoising techniques aim to mitigate the negative impact of irrelevant or noisy historical context"
  - [corpus] Moderate - corpus shows denoising techniques but limited evidence on optimal denoising thresholds
- Break condition: When denoising removes relevant context or when the cost of denoising outweighs the performance benefits.

## Foundational Learning

- Concept: Multi-turn conversation context modeling
  - Why needed here: Conversational search systems must maintain and utilize context across multiple turns to understand evolving user intent
  - Quick check question: How would you represent a 5-turn conversation context for a retrieval model?

- Concept: Query reformulation techniques (expansion, rewriting, hybrid)
  - Why needed here: Different reformulation approaches address various types of query ambiguity and context dependencies
  - Quick check question: What's the difference between query expansion and query rewriting in conversational search?

- Concept: Retrieval-augmented generation (RAG) fundamentals
  - Why needed here: Modern conversational search often combines retrieval with generation to produce contextual responses
  - Quick check question: How does RAG differ from traditional retrieval-only approaches?

## Architecture Onboarding

- Component map:
  User Interface → Query Processing → Context Management → Search Engine → Result Generation → Response
  Key components: Query Reformulator, Clarification Module, Retriever, Generator, Context Store
  Data flows: Conversation history, query representations, retrieved documents, generated responses

- Critical path: User query → Context understanding → Search execution → Result generation → Response delivery
  - Latency sensitivity: Query processing and search execution are most time-critical
  - Failure points: Context loss, query misunderstanding, retrieval failures

- Design tradeoffs:
  - Query reformulation: Accuracy vs. latency (complex rewriting takes more time)
  - Clarification: Proactivity vs. user experience (too many questions annoy users)
  - Context handling: Memory vs. relevance (longer context may include more noise)
  - Generation: Faithfulness vs. fluency (generated responses may hallucinate)

- Failure signatures:
  - Context confusion: System responds to previous query instead of current one
  - Clarification fatigue: Users stop responding to clarification questions
  - Retrieval drift: System retrieves documents from wrong topic over time
  - Generation hallucination: System generates incorrect information despite good retrieval

- First 3 experiments:
  1. Implement basic query reformulation with simple anaphora resolution on CANARD dataset
  2. Add clarification module with template-based questions on Qulac dataset
  3. Integrate context denoising with attention mechanisms on TREC CAsT data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can conversational search systems robustly determine the optimal action (clarify, retrieve, generate, invoke an external tool) at each conversational turn, adapting dynamically based on dialogue state, user intent, and system confidence?
- Basis in paper: [explicit] The conclusion section discusses the need for intelligent decision-making in conversational search systems.
- Why unresolved: Current systems primarily operate reactively, responding to user queries rather than proactively deciding when and how to engage. The development of mixed-initiative systems lacks comprehensive benchmarks to evaluate action prediction accuracy and contribution toward information needs.
- What evidence would resolve it: A benchmark suite with annotated conversational sessions demonstrating optimal system actions, coupled with evaluation metrics measuring both the accuracy of action prediction and the overall contribution to task completion.

### Open Question 2
- Question: How can reliable knowledge attribution methods be developed for multi-source conversational generation to mitigate hallucination while maintaining response quality?
- Basis in paper: [explicit] The conclusion section highlights the importance of faithful and abundant resources, specifically mentioning the challenge of developing reliable knowledge attribution methods for multi-source conversational generation.
- Why unresolved: Existing knowledge attribution methods primarily focus on single-turn QA and struggle to handle the context dependencies and progressive knowledge attribution required in multi-turn dialogues. The integration of historical search results and turn dependency adds complexity to attribution.
- What evidence would resolve it: Comparative studies evaluating different knowledge attribution approaches on conversational datasets, measuring both attribution accuracy and impact on response faithfulness and overall system performance.

### Open Question 3
- Question: How can high-fidelity user simulations be developed that accurately simulate user behavior, including error recovery, adaptation, and evolving information goals, for practical conversational search system evaluation?
- Basis in paper: [explicit] The conclusion section discusses the need for practical evaluation methods, specifically mentioning the development of high-fidelity user simulations to mimic real-world scenarios.
- Why unresolved: Current evaluation datasets assume all previous turns are answered correctly, which is unrealistic. Existing user simulators often lack the sophistication to model complex user behaviors like error recovery and goal evolution over extended conversations.
- What evidence would resolve it: User simulation models that generate realistic conversational trajectories with varying levels of user satisfaction, error patterns, and goal shifts, validated against real user interaction data across different domains and task types.

## Limitations
- Limited empirical validation of specific techniques like context denoising thresholds and clarification question benefits
- Implementation complexity challenges for real-world deployment scenarios are not fully addressed
- Evaluation standardization remains difficult due to lack of standardized user-centric metrics and realistic user simulation

## Confidence
- High confidence: The fundamental mechanisms of query reformulation and conversational retrieval are well-established in the literature, with clear theoretical foundations and empirical support from multiple datasets.
- Medium confidence: The effectiveness of LLM integration for all modules is promising but still evolving, with varying results across different implementations and datasets.
- Low confidence: The optimal balance between proactive clarification and user experience, as well as the ideal context denoising strategies, lack definitive empirical validation across diverse scenarios.

## Next Checks
1. Implement a controlled experiment comparing different context denoising thresholds on the TREC CAsT dataset to quantify the trade-off between noise reduction and context preservation.
2. Conduct a user study measuring clarification fatigue by varying the frequency and relevance of clarification questions in a simulated conversational search scenario.
3. Evaluate knowledge attribution accuracy in RAG-based conversational systems by implementing citation labeling and measuring hallucination rates across different response generation approaches.