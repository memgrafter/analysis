---
ver: rpa2
title: Commonsense Knowledge Editing Based on Free-Text in LLMs
arxiv_id: '2410.23844'
source_url: https://arxiv.org/abs/2410.23844
tags:
- knowledge
- editing
- commonsense
- layers
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a benchmark dataset CKEBench and a Dynamics-aware
  Editing Method (DEM) for editing commonsense knowledge in LLMs based on free-text.
  The authors find that commonsense knowledge is stored in MLP and Attention layers
  and is dispersed, unlike factual knowledge which is stored in fixed locations.
---

# Commonsense Knowledge Editing Based on Free-Text in LLMs

## Quick Facts
- arXiv ID: 2410.23844
- Source URL: https://arxiv.org/abs/2410.23844
- Reference count: 7
- Key outcome: DEM achieves 44.3% score on CKEBench vs 39.8% for PMET on GPT-J (6B)

## Executive Summary
This paper addresses the challenge of editing commonsense knowledge in large language models (LLMs) based on free-text inputs. Unlike factual knowledge that is stored in fixed locations, commonsense knowledge is dispersed across MLP and Attention layers. The authors propose a Dynamics-aware Editing Method (DEM) that dynamically locates relevant layers and performs targeted editing. Experiments on GPT-J (6B) and LLaMA-2 (7B) models demonstrate significant improvements over baseline methods, achieving state-of-the-art performance on the CKEBench benchmark.

## Method Summary
The Dynamics-aware Editing Method (DEM) consists of three main components: a KLFT module for knowledge localization, a Dynamics-aware module for layer selection, and a Knowledge Editing module for parameter updates. DEM first uses KLFT to identify patterns of knowledge storage in MLP and Attention layers. The Dynamics-aware module then selects the top-k layers with highest contribution to knowledge storage based on hidden state similarity metrics. Finally, the Knowledge Editing module performs incremental weight updates on the selected layers using target answer representations. The method is evaluated on a benchmark dataset CKEBench constructed from the ATOMIC database.

## Key Results
- DEM achieves 44.3% score on CKEBench benchmark compared to 39.8% for PMET on GPT-J (6B)
- Removing the Dynamics-aware module reduces score by 10.2%, demonstrating its importance
- DEM improves upon basic PMET method by 15.7% and 5.6% in terms of F1 Commonsense score
- Performance improvements are consistent across GPT-J (6B) and LLaMA-2 (7B) models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Commonsense knowledge is stored in MLP and Attention layers, not just specific neurons
- Mechanism: KLFT experiments reveal that commonsense knowledge is dispersed across multiple layers rather than localized to fixed neurons like factual knowledge
- Core assumption: Hidden states contain sufficient information to identify knowledge storage patterns through causal tracing
- Evidence anchors:
  - [abstract] "commonsense knowledge is stored in MLP and Attention layers and is dispersed, unlike factual knowledge which is stored in fixed locations"
  - [section 3.2] "we found that commonsense knowledge is dispersed in the MLP and Attn layers"
- Break condition: If the KLFT method fails to show significant differences between clean and corrupted runs, the dispersed storage hypothesis would be weakened

### Mechanism 2
- Claim: Dynamic layer selection improves editing precision for commonsense knowledge
- Mechanism: Dynamics-aware module identifies top-k layers with highest contribution to knowledge storage in real-time, then targets only those layers for editing
- Core assumption: Cosine similarity between input and output hidden states correlates with layer contribution to knowledge storage
- Evidence anchors:
  - [section 4.1] "Cosine Similarity = h(T)l in · h(T)l out / ||h(T)l in|| ||h(T)l out||" and "the closer the Cosine Similarity is to zero, the greater the contribution of this layer to knowledge"
  - [section 5.3] "When we remove the Dynamics-aware module from the DEM, the Score drops by 10.2% on commonsense knowledge dataset"
- Break condition: If cosine similarity doesn't correlate with knowledge contribution, dynamic selection would fail to identify correct layers

### Mechanism 3
- Claim: Incremental weight updates preserve existing knowledge while modifying targeted knowledge
- Mechanism: DEM computes incremental weights for MLP and Attention layers separately, using target answer representations to update only relevant parameters
- Core assumption: The difference between original and target knowledge representations can be captured through incremental weight adjustments
- Evidence anchors:
  - [section 4.2.1] "The formal expression for the incremental weight is: △M LP = RM LP(kM LP 1 )T (C M LP 0 + kM LP 1 (kM LP 1 )T )−1"
  - [section 5.2] "Our method improves upon the basic PMET method by 15.7% and 5.6% in term of F1 Commonsense score"
- Break condition: If incremental updates cause catastrophic forgetting or fail to modify targeted knowledge, the method would be ineffective

## Foundational Learning

- Concept: Causal tracing for knowledge localization
  - Why needed here: KLFT method relies on causal tracing to identify which layers contribute to knowledge storage
  - Quick check question: How does perturbing subject tokens in causal tracing help identify knowledge storage locations?

- Concept: Hidden state similarity metrics
  - Why needed here: Dynamics-aware module uses cosine similarity to select editing layers
  - Quick check question: Why does lower cosine similarity between input and output hidden states indicate higher layer contribution?

- Concept: Parameter-efficient fine-tuning
  - Why needed here: DEM updates only MLP and Attention weights rather than full model retraining
  - Quick check question: What's the difference between updating weights incrementally vs. full fine-tuning?

## Architecture Onboarding

- Component map:
  KLFT module -> Dynamics-aware module -> Knowledge Editing module -> Evaluation pipeline

- Critical path:
  1. Input commonsense prompt → KLFT for localization patterns
  2. Input prompt → Dynamics-aware module for layer selection
  3. Selected layers + target answer → Knowledge Editing module for weight updates
  4. Edited model → Evaluation with CKEBench dataset

- Design tradeoffs:
  - Layer selection precision vs. computational cost (top-k vs. all layers)
  - Incremental updates vs. full fine-tuning (preservation vs. flexibility)
  - Free-text evaluation vs. structured metrics (complexity vs. standardization)

- Failure signatures:
  - Low score improvement despite successful layer selection
  - Performance degradation on factual knowledge tasks
  - Inconsistent editing results across similar prompts

- First 3 experiments:
  1. Replicate KLFT results on a small subset of CKEBench to verify dispersed storage pattern
  2. Test Dynamics-aware module layer selection on factual vs. commonsense knowledge
  3. Compare DEM performance with fixed-layer editing baseline on CKEBench

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the storage location of commonsense knowledge in MLP and Attention layers vary across different model architectures and sizes?
- Basis in paper: [explicit] The paper finds that commonsense knowledge is stored in MLP and Attention layers and is dispersed, unlike factual knowledge which is stored in fixed locations.
- Why unresolved: The experiments were conducted on GPT-J (6B) and LLaMA-2 (7B) models. It's unclear if the same storage patterns hold for larger models or different architectures.
- What evidence would resolve it: Experiments on a wider range of model sizes (e.g., 1B, 13B, 70B parameters) and architectures (e.g., OPT, BLOOM) showing consistent or varying storage patterns for commonsense knowledge.

### Open Question 2
- Question: What is the relationship between the number of tokens in the target answer and the effectiveness of the DEM method?
- Basis in paper: [inferred] The paper mentions that commonsense knowledge editing involves editing free-text with multiple tokens, unlike factual knowledge which typically involves single tokens or entities.
- Why unresolved: The paper doesn't explore how the length of the target answer affects the editing performance or if there's an optimal length for effective editing.
- What evidence would resolve it: A study varying the length of target answers (e.g., 1 token, 5 tokens, 10 tokens, 20+ tokens) and measuring the DEM method's effectiveness on each.

### Open Question 3
- Question: How does the DEM method perform on commonsense knowledge that is not sourced from the ATOMIC database?
- Basis in paper: [explicit] The CKEBench dataset is constructed from the ATOMIC database, which may have specific characteristics that influence the DEM method's performance.
- Why unresolved: The paper doesn't evaluate the DEM method on commonsense knowledge from other sources, which may have different properties or distributions.
- What evidence would resolve it: Experiments on commonsense knowledge from other databases (e.g., ConceptNet, Open Mind Common Sense) or real-world text corpora to assess the DEM method's generalizability.

## Limitations
- Limited evaluation to two specific model architectures (GPT-J and LLaMA-2) of similar scale
- Benchmark dataset constructed from single source (ATOMIC) may not represent full diversity of commonsense knowledge
- Unclear how DEM performs on factual knowledge tasks and potential for catastrophic forgetting

## Confidence
- Mechanism 1: Medium - KLFT experiments show differences but may not definitively prove dispersed storage
- Mechanism 2: Medium - 10.2% score drop when removing Dynamics-aware module is significant but correlation needs validation
- Mechanism 3: Medium - Mathematical formulation is sound but practical effectiveness depends on implementation details

## Next Checks
1. Replicate the dispersed storage pattern finding using KLFT on a subset of CKEBench with varying prompt structures to verify robustness across different commonsense knowledge types
2. Conduct ablation studies comparing dynamic layer selection (top-k) vs fixed layer selection to isolate the contribution of the Dynamics-aware module from other factors
3. Test DEM's performance on factual knowledge tasks to quantify any catastrophic forgetting or interference effects from commonsense editing