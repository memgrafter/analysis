---
ver: rpa2
title: Generating Counterfactual Trajectories with Latent Diffusion Models for Concept
  Discovery
arxiv_id: '2404.10356'
source_url: https://arxiv.org/abs/2404.10356
tags:
- counterfactual
- concept
- discovery
- concepts
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CDCT, the first unsupervised concept discovery
  framework that uses latent diffusion models to generate counterfactual trajectories.
  The method generates a dataset of semantically meaningful counterfactual images
  by guiding a latent diffusion model with the target classifier.
---

# Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery

## Quick Facts
- arXiv ID: 2404.10356
- Source URL: https://arxiv.org/abs/2404.10356
- Reference count: 40
- Primary result: First unsupervised concept discovery framework using latent diffusion models, achieving superior FID and L1/L2 scores compared to state-of-the-art while being 12x more efficient

## Executive Summary
This paper introduces CDCT, a novel unsupervised concept discovery framework that leverages latent diffusion models to generate counterfactual trajectories. The method identifies decision-relevant concepts by generating a dataset of semantically meaningful counterfactual images through classifier-guided latent diffusion, learning a disentangled representation using a VAE, and applying a search algorithm to identify influential latent dimensions. Applied to skin lesion classification on the ISIC dataset, CDCT successfully reveals both dataset biases (color-related cues) and clinically plausible biomarkers (white scar-like structures in dermatofibroma) while outperforming the state-of-the-art DiME method in both quality and computational efficiency.

## Method Summary
CDCT is a three-step framework for concept discovery. First, it fine-tunes a latent diffusion model on the ISIC dataset with text conditioning, then generates counterfactual trajectories by encoding images and iteratively denoising them with classifier guidance to steer semantic changes toward target classes. Second, it trains a VAE on these trajectories to learn a disentangled representation where individual latent dimensions correspond to specific semantic features influencing classifier decisions. Third, it applies a search algorithm to identify the most influential latent dimensions by systematically manipulating them and observing classifier output changes. The discovered concepts are validated through high success rates in influencing classifier outputs.

## Key Results
- CDCT produces counterfactuals with superior FID scores and lower L1/L2 reconstruction errors compared to DiME
- The framework is approximately 12x more computationally efficient than previous state-of-the-art methods
- CDCT successfully identifies clinically plausible biomarkers (white scar-like structures in dermatofibroma) and dataset biases (color-related cues)
- Discovered concepts achieve high success rates in influencing classifier outputs, validating their relevance

## Why This Works (Mechanism)

### Mechanism 1
Latent diffusion models with classifier guidance can generate semantically meaningful counterfactual trajectories that capture decision-relevant variations. The LDM generates a sequence of images from factual to counterfactual by iteratively denoising a latent representation, while classifier gradients guide the denoising process to steer semantic changes toward the target class. Core assumption: The target classifier's gradients contain semantically meaningful directions in the latent space that can guide image synthesis. Evidence: Abstract states diffusion models show strength in generating diverse and realistic features for counterfactual explanations. Break condition: If classifier gradients are noisy or non-informative, generated trajectories will not capture meaningful semantic changes.

### Mechanism 2
A VAE trained on counterfactual trajectories can learn a disentangled representation of classification-relevant concepts. The VAE learns to encode the counterfactual trajectory dataset into a latent space where individual dimensions correspond to specific semantic features that influence classifier decisions. Core assumption: The counterfactual trajectory dataset contains sufficient variation to learn disentangled representations of decision-relevant concepts. Evidence: Abstract mentions dataset is used to derive disentangled representation of classification-relevant concepts using VAE. Break condition: If trajectories lack diversity or contain redundant information, VAE may fail to learn truly disentangled representations.

### Mechanism 3
Manipulating latent dimensions in the VAE's latent space can identify classifier-relevant concepts with high success rates. By systematically altering individual latent dimensions and observing changes in classifier output, the most influential dimensions for each class can be identified as concepts. Core assumption: Changes in specific latent dimensions will have predictable and measurable effects on classifier output probabilities. Evidence: Abstract states search algorithm is applied to identify relevant concepts in disentangled latent space. Break condition: If relationship between latent dimensions and classifier output is non-linear or context-dependent, simple manipulation may not reliably identify most relevant concepts.

## Foundational Learning

- Variational Autoencoders (VAEs)
  - Why needed here: VAEs learn disentangled representation of counterfactual trajectory dataset where each latent dimension corresponds to specific semantic feature influencing classifier decisions
  - Quick check: How does VAE balance reconstruction fidelity with disentanglement, and what role does KL divergence loss play in this process?

- Latent Diffusion Models (LDMs)
  - Why needed here: LDMs generate counterfactual trajectories by iteratively denoising latent representation guided by classifier gradients to steer semantic changes toward target class
  - Quick check: What is role of classifier guidance in LDM, and how does it influence denoising process?

- Concept-based Explainability
  - Why needed here: Goal is to discover human-aligned concepts relevant to classifier's decision-making rather than just quantifying feature importance
  - Quick check: How does concept-based explainability differ from feature-based methods, and why is it more suitable for domains like medicine?

## Architecture Onboarding

- Component map: LDM -> VAE -> Search algorithm -> Target classifier
- Critical path:
  1. Fine-tune LDM on ISIC dataset with text conditioning
  2. Generate counterfactual trajectories using LDM with classifier guidance
  3. Train VAE on trajectory dataset
  4. Identify relevant latent dimensions using search algorithm
- Design tradeoffs:
  - Reconstruction fidelity vs. disentanglement in VAE training
  - Computational efficiency vs. quality of counterfactual generation
  - Linear vs. non-linear concept discovery approaches
- Failure signatures:
  - Poor FID scores indicate issues with LDM counterfactual generation
  - Low success rates in concept discovery suggest problems with VAE disentanglement or search algorithm
  - Biased concepts may indicate dataset biases rather than classifier-relevant features
- First 3 experiments:
  1. Generate counterfactuals from one class to another and visually inspect for semantic changes
  2. Train VAE on small subset of counterfactual trajectories and evaluate reconstruction quality
  3. Apply search algorithm to identify top latent dimensions and validate their influence on classifier output

## Open Questions the Paper Calls Out

### Open Question 1
Can CDCT effectively discover clinically meaningful concepts in other medical imaging domains beyond skin lesions, such as radiology or histology? The paper mentions CDCT can be applied to arbitrary domains including radiology and histology, but only demonstrates effectiveness on skin lesion data. Evidence would require applying CDCT to radiology or histology datasets and demonstrating discovery of clinically relevant concepts validated by medical experts.

### Open Question 2
How does quality of counterfactuals generated by CDCT change when using different text prompts or conditioning information? While paper mentions text conditioning to structure latent space, impact of different conditioning strategies is not explored. Evidence would come from experiments comparing counterfactual quality using different conditioning strategies or text prompts.

### Open Question 3
Can disentanglement capabilities of VAE in CDCT be further improved to better preserve fine-grained features while maintaining concept separation? Paper acknowledges trade-off between reconstruction fidelity and disentanglement, suggesting future work explore more sophisticated techniques like StyleGAN. Evidence would come from implementing and comparing different disentanglement techniques on same task, demonstrating improved concept separation and reconstruction quality.

## Limitations

- The framework's reliance on classifier gradients assumes these gradients are semantically meaningful and stable across latent space
- VAE's ability to learn disentangled representations depends heavily on diversity and quality of counterfactual trajectory dataset
- Search algorithm's effectiveness is limited by assumption of linear relationships between latent space manipulations and classifier outputs

## Confidence

- High confidence: Three-step framework architecture is sound and empirical improvements over DiME are well-documented
- Medium confidence: Clinical relevance of discovered concepts is supported but requires validation by domain experts
- Low confidence: Framework's generalizability to non-medical domains and different classifier architectures remains untested

## Next Checks

1. Evaluate concept discovery performance across different classifier architectures (e.g., ViT, EfficientNet) to assess robustness to model-specific gradients
2. Conduct ablation studies varying classifier guidance strength Î»c to determine optimal balance between semantic fidelity and diversity in counterfactual generation
3. Test framework on non-medical image classification task (e.g., CIFAR-10) to evaluate cross-domain applicability and identify potential domain-specific limitations