---
ver: rpa2
title: Can Large Language Models Act as Ensembler for Multi-GNNs?
arxiv_id: '2410.16822'
source_url: https://arxiv.org/abs/2410.16822
tags:
- graph
- gnns
- llms
- node
- lensgnn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies whether LLMs can act as an ensembler for multi-GNNs.
  The LensGNN model first aligns multiple GNNs by mapping their representations into
  the same space, then uses LoRA fine-tuning to align GNN and LLM spaces by injecting
  graph tokens and textual information into LLMs.
---

# Can Large Language Models Act as Ensembler for Multi-GNNs?

## Quick Facts
- arXiv ID: 2410.16822
- Source URL: https://arxiv.org/abs/2410.16822
- Reference count: 31
- Key outcome: LensGNN outperforms existing models on node classification and graph classification tasks across multiple benchmark datasets

## Executive Summary
This paper proposes LensGNN, a novel approach that leverages large language models (LLMs) as an ensembler for multiple graph neural networks (GNNs). The method first aligns multiple GNNs by mapping their representations into a shared space using a sequential training approach with a shared classifier. It then employs LoRA fine-tuning to align the GNN and LLM spaces by injecting graph tokens and textual information into the LLM. This enables LensGNN to combine the structural insights from multiple GNNs with the semantic understanding capabilities of LLMs, achieving superior performance on both node classification and graph classification tasks across eight benchmark datasets.

## Method Summary
LensGNN is a two-phase approach that first aligns multiple GNNs (GCN, GAT, GIN) by mapping their representations into a shared space through sequential training with a shared MLP classifier. In the second phase, it aligns the GNN and LLM spaces using LoRA fine-tuning, where graph tokens are created and injected into LLM prompts alongside node text and task instructions. The LLM then reasons over these prompts to produce ensemble predictions. The model is evaluated on eight benchmark datasets for both node classification and graph classification tasks, showing significant improvements over existing methods.

## Key Results
- LensGNN outperforms existing models on node classification tasks across 5 datasets
- LensGNN achieves superior performance on graph classification with both accuracy and AUC scores
- The approach successfully ensembles multiple GNNs while leveraging LLM strengths for semantic understanding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LensGNN aligns multiple GNNs by mapping their representations into the same space through sequential training on a shared classifier.
- Mechanism: The model alternately feeds representations from different GNNs into a shared MLP classifier, training them sequentially. This forces the GNN outputs to converge into a common vector space, enabling effective ensemble integration.
- Core assumption: GNNs can be aligned to a common representation space through shared classifier training without losing their unique structural insights.
- Evidence anchors:
  - [abstract] "The model first aligns multiple GNNs, mapping the representations of different GNNs into the same space."
  - [section 4.1] "To align node representations from multiple GNNs, we next feed them into a shared MLP, which serves as the classifier. During the training time, we alternatively input representations from different GNNs into the classifier and train them sequentially."
  - [corpus] Weak - no direct corpus evidence found for this specific alignment mechanism.

### Mechanism 2
- Claim: LensGNN aligns GNN and LLM spaces through LoRA fine-tuning with graph tokens injected into LLM embeddings.
- Mechanism: The model creates dummy tokens in LLM prompts, then overwrites their embeddings with GNN representations that capture graph structural information. LoRA fine-tuning aligns these graph tokens with the LLM's semantic space.
- Core assumption: LoRA fine-tuning can effectively align graph structural information with LLM semantic space without full model retraining.
- Evidence anchors:
  - [abstract] "Through LoRA fine-tuning, it aligns the space between the GNN and the LLM, injecting graph tokens and textual information into LLMs."
  - [section 4.2] "we adopt LoRA training to fine-tune the LLMs, enabling them to comprehend GNN representations... We overwrite the embeddings of dummy tokens by GNN representations."
  - [corpus] Weak - limited corpus evidence for this specific LoRA-based graph token injection approach.

### Mechanism 3
- Claim: LensGNN implicitly ensembles multi-GNNs through LLM reasoning over graph tokens combined with node text and task instructions.
- Mechanism: The LLM processes prompts containing graph tokens from multiple GNNs, node textual attributes, and hand-crafted instructions. The LLM's reasoning capabilities implicitly combine the strengths of different GNNs.
- Core assumption: LLMs can effectively reason over graph tokens from multiple GNNs to produce superior ensemble predictions compared to traditional ensemble methods.
- Evidence anchors:
  - [abstract] "This allows LensGNN to ensemble multiple GNNs and take advantage of the strengths of LLM, leading to a deeper understanding of both textual semantic information and graph structural information."
  - [section 4.2] "After prompts are designed, they are fed into LLMs to predict labels... o = LLM(xinstruction, xnode-text, {xGNNi}k i=1)"
  - [corpus] Weak - no direct corpus evidence found for LLM-based multi-GNN ensembling.

## Foundational Learning

- Concept: Graph Neural Networks and Message Passing
  - Why needed here: Understanding how GNNs aggregate neighborhood information is crucial for comprehending why LensGNN needs to align multiple GNNs and why graph tokens capture structural information.
  - Quick check question: What is the key difference between GCN and GAT in terms of how they aggregate neighbor information?

- Concept: Large Language Models and LoRA Fine-tuning
  - Why needed here: Understanding LLM architecture and LoRA fine-tuning is essential for grasping how LensGNN aligns GNN and LLM spaces and why LoRA is preferred over full fine-tuning.
  - Quick check question: How does LoRA reduce the number of trainable parameters compared to full fine-tuning of a 13B parameter model?

- Concept: Text-Attributed Graphs (TAGs)
  - Why needed here: Understanding the dual nature of TAGs (structural and semantic information) explains why LensGNN needs both GNNs for structure and LLMs for semantics.
  - Quick check question: What makes text-attributed graphs more challenging than standard graphs for traditional GNN approaches?

## Architecture Onboarding

- Component map:
  SentenceBERT -> Multiple GNNs (GCN, GAT, GIN) -> Shared MLP classifier -> Graph token injection -> LLM with LoRA fine-tuning -> Prompt engine -> Predictions

- Critical path:
  1. Initialize node features with SentenceBERT
  2. Generate node embeddings from multiple GNNs
  3. Align GNN representations using shared classifier
  4. Create graph tokens and inject into LLM prompts
  5. Fine-tune LLM with LoRA using aligned representations
  6. Generate predictions using ensemble reasoning

- Design tradeoffs:
  - Multiple GNNs provide diverse structural insights but increase computational cost
  - LoRA fine-tuning enables efficient alignment but may not capture all complex relationships
  - Graph token injection preserves structure but requires careful prompt design
  - LLM reasoning provides strong semantics but may introduce uncertainty

- Failure signatures:
  - Poor alignment: GNN representations fail to converge in shared space, visible as inconsistent validation performance across GNNs
  - Token injection issues: LLM cannot process graph tokens properly, visible as degraded performance compared to single GNN baselines
  - Prompt design problems: LLM outputs become inconsistent or irrelevant, visible as high variance in predictions
  - Computational bottlenecks: Training becomes prohibitively slow, visible as GPU memory exhaustion

- First 3 experiments:
  1. Verify multi-GNN alignment: Train individual GNNs, then train with shared classifier. Check if representations converge and validation accuracy improves.
  2. Test graph token integration: Create dummy tokens, inject single GNN representation, check if LLM can process and if performance matches single GNN baseline.
  3. Validate ensemble reasoning: Combine multiple GNNs in prompt, compare performance against individual GNNs and traditional ensemble methods.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LensGNN scale with larger LLMs beyond 13B parameters, and what is the upper limit of its performance potential?
- Basis in paper: [explicit] The paper explicitly states that experiments were limited to LLMs with parameters not exceeding 13B due to computational constraints, leaving the upper limit of LensGNN's capabilities unexplored.
- Why unresolved: The paper acknowledges computational limitations prevented testing with larger LLMs that are used in production environments, which could potentially further improve LensGNN's performance.
- What evidence would resolve it: Conducting experiments with larger LLMs (e.g., 30B-70B parameters) and comparing their performance against the current 13B models would establish the scaling relationship and upper performance bounds.

### Open Question 2
- Question: Can automated prompt design replace the current manual prompt crafting approach in LensGNN for better multi-GNN ensembling?
- Basis in paper: [explicit] The paper identifies reliance on manually crafted prompts as a limitation and suggests that future studies on prompt design could be a promising direction.
- Why unresolved: The current approach requires human expertise to design effective prompts, which may not be optimal and doesn't scale well to different tasks or domains.
- What evidence would resolve it: Developing and testing automated prompt generation methods (e.g., using reinforcement learning or prompt optimization techniques) and comparing their performance against manually crafted prompts would demonstrate whether automation can match or exceed human-designed prompts.

### Open Question 3
- Question: How does LensGNN perform on graph-related tasks beyond node classification and graph classification, such as graph generation or interpretability analysis?
- Basis in paper: [explicit] The paper explicitly states that evaluation was limited to node classification and graph classification tasks, while other tasks like graph dataset generation and graph task interpretability analysis were identified as valuable research questions.
- Why unresolved: The paper only evaluated LensGNN on classification tasks, leaving its effectiveness on other important graph-related tasks unexplored.
- What evidence would resolve it: Applying LensGNN to tasks like graph generation (e.g., molecular graph generation) and conducting interpretability analysis (e.g., identifying which GNN contributions matter most for specific predictions) would demonstrate its versatility across the broader range of graph learning tasks.

## Limitations

- The specific mechanisms of multi-GNN alignment through shared classifier training lack empirical validation and may not produce meaningfully aligned representations
- LoRA-based graph token injection relies on the assumption that overwriting dummy token embeddings will effectively capture graph structure without proper ablation studies
- The ensemble reasoning capability of LLMs over multiple GNN representations is asserted rather than demonstrated with rigorous comparisons to traditional ensemble methods

## Confidence

**High Confidence:** The basic architecture of LensGNN is well-defined and the two-phase alignment process is clearly specified.

**Medium Confidence:** Experimental results show improvements over baselines, but lack of detailed hyperparameter tuning and rigorous ablation studies limit confidence in specific component contributions.

**Low Confidence:** Specific mechanisms of shared classifier alignment, LoRA-based graph token integration, and LLM-based ensemble reasoning are not sufficiently validated with empirical evidence.

## Next Checks

1. **Alignment Verification Experiment:** Implement visualization study comparing GNN representations before and after shared classifier training using t-SNE or UMAP to verify convergence to common space.

2. **Graph Token Integration Ablation:** Design systematic ablation study removing graph tokens from LLM prompts at different levels to reveal whether multi-GNN ensemble reasoning provides benefits beyond individual GNN performance.

3. **Traditional Ensemble Comparison:** Implement rigorous comparison between LensGNN and traditional ensemble methods (majority voting, weighted averaging, stacking) using identical GNN models and datasets.