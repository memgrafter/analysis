---
ver: rpa2
title: 'MeMemo: On-device Retrieval Augmentation for Private and Personalized Text
  Generation'
arxiv_id: '2407.01972'
source_url: https://arxiv.org/abs/2407.01972
tags:
- https
- retrieval
- mememo
- arxiv
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MeMemo is the first JavaScript toolkit that enables efficient in-browser
  dense retrieval for text generation using the Hierarchical Navigable Small World
  (HNSW) algorithm. It addresses privacy and deployment challenges of traditional
  retrieval-augmented generation (RAG) systems by storing and searching vector databases
  directly in users' browsers using IndexedDB and Web Workers.
---

# MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation

## Quick Facts
- arXiv ID: 2407.01972
- Source URL: https://arxiv.org/abs/2407.01972
- Reference count: 40
- Primary result: First JavaScript toolkit enabling efficient in-browser dense retrieval for text generation using HNSW algorithm

## Executive Summary
MeMemo is an open-source JavaScript toolkit that adapts the Hierarchical Navigable Small World (HNSW) algorithm for browser environments, enabling private and personalized text generation without requiring backend servers. By leveraging IndexedDB for vector storage and Web Workers for computation, MeMemo addresses privacy concerns and deployment challenges of traditional retrieval-augmented generation (RAG) systems. The toolkit allows researchers and developers to implement RAG applications directly in browsers, supporting interactive prototyping while maintaining user privacy and reducing barriers to entry for AI novices.

## Method Summary
MeMemo adapts the HNSW algorithm for browser environments by implementing it in JavaScript and integrating with browser storage and computation APIs. The toolkit uses IndexedDB to store vector values, overcoming browser RAM limitations, and employs Web Workers to perform heavy computation without blocking the main thread. A novel prefetching strategy caches vector values in RAM to reduce IndexedDB transactions during HNSW operations. The implementation seamlessly integrates with existing Web ML technologies including IndexedDB for document storage, FlexSearch for lexical search, GTE-Small for semantic encoding, and Web LLM for model execution, creating a complete RAG pipeline in the browser.

## Key Results
- Enables efficient in-browser dense retrieval for text generation using HNSW algorithm
- Addresses privacy and deployment challenges by eliminating need for backend servers
- Supports interactive prototyping of RAG systems through browser-based implementation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MeMemo enables private and personalized text generation by performing dense retrieval directly in the browser without requiring backend servers.
- Mechanism: MeMemo adapts the HNSW algorithm for browser environments using IndexedDB for vector storage and Web Workers for computation, enabling client-side vector database operations.
- Core assumption: Browser environments can efficiently handle the computational and storage requirements of HNSW operations with appropriate optimizations.
- Evidence anchors:
  - [abstract] "MeMemo is the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments."
  - [section] "Our toolkit adapts the state-of-the-art approximate nearest neighbor search Hierarchical Navigable Small World graphs (HNSW) [47] to the Web environment."
  - [corpus] Weak evidence - corpus neighbors discuss privacy-preserving retrieval but don't specifically validate MeMemo's browser implementation.
- Break condition: If IndexedDB read/write operations become prohibitively slow due to network latency or if Web Workers are blocked by browser security policies.

### Mechanism 2
- Claim: The prefetching strategy significantly reduces IndexedDB transactions during HNSW construction and search operations.
- Mechanism: MeMemo maintains a cache of p vector values in RAM and prefetches p neighbors from IndexedDB when needed, reducing the number of direct IndexedDB transactions.
- Core assumption: Prefetching neighbor vectors in batches is more efficient than individual vector lookups for HNSW operations.
- Evidence anchors:
  - [section] "When inserting multiple elements, MeMemo first uses a batched write to store all vectors in IndexedDB. During construction and search, MeMemo maintains a cache of ùëù vector values in RAM."
  - [section] "If it needs to read a vector value that is not in the cache, MeMemo prefetches ùëù neighbors of that element on the current graph layer from IndexedDB to RAM."
  - [corpus] No direct evidence - corpus neighbors discuss privacy but not specific optimization techniques.
- Break condition: If the prefetching cache size (p) becomes too large for available RAM, causing memory pressure and swapping.

### Mechanism 3
- Claim: MeMemo enables rapid prototyping of RAG applications through seamless integration with existing Web ML technologies.
- Mechanism: MeMemo integrates with IndexedDB for document storage, FlexSearch for lexical search, GTE-Small for semantic encoding, and Web LLM for model execution, creating a complete RAG pipeline in the browser.
- Core assumption: The combination of these Web ML technologies can provide comparable functionality to server-based RAG systems.
- Evidence anchors:
  - [section] "Mei seamlessly integrates MeMemo with other Web ML technologies. For example, she uses IndexedDB, a client-side key-value browser storage, to store the raw documents."
  - [section] "Using the same keys, Mei creates the HNSW index with MeMemo. Then, Mei uses FlexSearch [75] to implement fast full-text lexical search in the browser."
  - [corpus] Weak evidence - corpus neighbors discuss RAG integration but not specific browser-based technology combinations.
- Break condition: If any integrated technology becomes deprecated or if browser APIs change in ways that break compatibility.

## Foundational Learning

- Concept: Approximate Nearest Neighbor (ANN) search
  - Why needed here: MeMemo uses HNSW, an ANN algorithm, to efficiently find similar vectors in high-dimensional space without computing exact distances to all vectors.
  - Quick check question: What is the main tradeoff when using approximate nearest neighbor search instead of exact search?

- Concept: IndexedDB and browser storage quotas
  - Why needed here: MeMemo stores vector values in IndexedDB to overcome browser RAM limitations, requiring understanding of storage APIs and quota management.
  - Quick check question: What is the approximate storage limit for IndexedDB in modern browsers?

- Concept: Web Workers and thread isolation
  - Why needed here: MeMemo uses Web Workers to perform heavy computation without blocking the main browser thread, maintaining UI responsiveness.
  - Quick check question: How do Web Workers communicate with the main thread, and what are their limitations?

## Architecture Onboarding

- Component map:
  - HNSW Index -> IndexedDB (vector storage) -> Web Workers (computation) -> Prefetch Cache (RAM cache) -> Integration Layer (Web ML APIs)

- Critical path:
  1. Vector insertion ‚Üí IndexedDB write + HNSW graph update
  2. Query processing ‚Üí HNSW search with prefetching
  3. Result retrieval ‚Üí IndexedDB reads for neighbor vectors

- Design tradeoffs:
  - RAM vs. IndexedDB: Balancing cache size for performance vs. memory usage
  - Prefetching strategy: Cache size (p) affects both memory usage and IndexedDB access patterns
  - Worker granularity: Number of Web Workers affects parallelism vs. overhead

- Failure signatures:
  - Slow queries: Indicates IndexedDB transaction bottlenecks or insufficient prefetching
  - Memory errors: Suggests cache size is too large for available RAM
  - UI unresponsiveness: Web Workers not properly isolated from main thread

- First 3 experiments:
  1. Insert 10,000 vectors and measure insertion time vs. vector dimension
  2. Query performance with varying cache sizes (p parameter) on a 100,000 vector index
  3. Memory usage profiling during concurrent insert and query operations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the maximum number of high-dimensional vectors that can be stored and efficiently retrieved using MeMemo on typical consumer devices?
- Basis in paper: [explicit] The paper mentions that a webpage tab might have a RAM limit as low as 256MB, allowing storage of at most 83k 384-dimensional vectors in RAM, and discusses memory management challenges with IndexedDB.
- Why unresolved: The paper provides theoretical limits but does not present empirical benchmarks or upper bounds for vector storage capacity across different devices and browsers.
- What evidence would resolve it: Empirical testing results showing the maximum number of vectors (with various dimensions) that can be stored and retrieved efficiently on different devices, browsers, and RAM configurations.

### Open Question 2
- Question: How does the prefetching mechanism's performance vary with different cache sizes (parameter ùëù) and vector dimensions?
- Basis in paper: [explicit] The paper describes a prefetching mechanism that maintains a cache of ùëù vector values in RAM and mentions that ùëù is automatically determined by vector dimension, but doesn't provide detailed performance analysis.
- Why unresolved: The paper mentions the existence of the prefetching mechanism and its parameter ùëù but doesn't provide quantitative analysis of how different cache sizes affect retrieval performance.
- What evidence would resolve it: Performance benchmarks comparing retrieval speed with different ùëù values across various vector dimensions and database sizes, showing the optimal configuration for different use cases.

### Open Question 3
- Question: What are the specific performance differences between MeMemo and native HNSW implementations like HNSWLIB in real-world scenarios?
- Basis in paper: [explicit] The paper acknowledges that MeMemo is slower than heavily optimized libraries like HNSWLIB in terms of index creation and search, citing a 94-minute insertion time for 1 million 384-dimensional vectors.
- Why unresolved: While the paper provides one performance comparison, it doesn't offer comprehensive benchmarks comparing various operations (insertion, search, memory usage) across different scales and use cases.
- What evidence would resolve it: Comprehensive benchmark studies comparing MeMemo with HNSWLIB across multiple operations (index creation, query time, memory usage) at different scales (100K, 1M, 10M vectors) and dimensions, including both average and worst-case scenarios.

## Limitations

- Limited empirical performance validation against server-side baselines
- Automatic prefetch cache size calculation not explained in detail
- Security implications of IndexedDB storage not addressed

## Confidence

**High Confidence**: The core architectural approach of adapting HNSW for browser environments using IndexedDB and Web Workers is technically feasible and well-explained. The integration strategy with existing Web ML technologies is clearly specified.

**Medium Confidence**: The prefetching optimization mechanism is described with sufficient detail for implementation, though the automatic p parameter calculation needs clarification. The general claim that this enables private RAG applications is supported by the architecture.

**Low Confidence**: Claims about performance efficiency and scalability lack empirical validation. The assertion that this enables "rapid prototyping" and reduces barriers for AI novices is not substantiated with user studies or performance benchmarks.

## Next Checks

1. **Benchmark Performance**: Implement a controlled experiment comparing MeMemo's query latency and accuracy against established HNSW libraries (HNSWLIB) for datasets of 10K, 100K, and 1M vectors, measuring both cold-start and cached performance scenarios.

2. **Security Audit**: Conduct a security analysis of IndexedDB storage patterns, specifically testing for potential data leakage through browser dev tools, cross-site scripting vulnerabilities, and data persistence after session termination.

3. **Resource Utilization Profiling**: Profile memory usage, CPU load, and IndexedDB transaction counts during concurrent insert and query operations with varying cache sizes (p parameter), identifying the optimal configuration for different hardware profiles.