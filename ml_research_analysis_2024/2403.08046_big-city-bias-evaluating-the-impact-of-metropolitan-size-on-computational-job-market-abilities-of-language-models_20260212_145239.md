---
ver: rpa2
title: 'Big City Bias: Evaluating the Impact of Metropolitan Size on Computational
  Job Market Abilities of Language Models'
arxiv_id: '2403.08046'
source_url: https://arxiv.org/abs/2403.08046
tags:
- metropolitan
- language
- commute
- salary
- employer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether large language models (LLMs) exhibit
  biases in their predictions related to metropolitan size in the United States. Using
  384 metropolitan areas, the authors evaluate LLMs' performance on salary, employer
  presence, and commute duration prediction tasks.
---

# Big City Bias: Evaluating the Impact of Metropolitan Size on Computational Job Market Abilities of Language Models

## Quick Facts
- arXiv ID: 2403.08046
- Source URL: https://arxiv.org/abs/2403.08046
- Reference count: 3
- Primary result: Large language models show significantly worse performance in smaller metropolitan areas across salary, employer presence, and commute duration prediction tasks

## Executive Summary
This study investigates metropolitan size bias in large language models (LLMs) by evaluating their performance across 384 US metropolitan areas on three job market prediction tasks. The research reveals that LLMs perform substantially worse in smaller metropolitan regions, with the smallest 10 areas showing up to 300% worse performance compared to the largest 10 areas. These findings suggest that LLM-based job matching systems may have inherent geographic biases that could disadvantage users in smaller metropolitan areas.

## Method Summary
The study evaluates LLM performance across 384 US metropolitan areas using three prediction tasks: salary prediction, employer presence identification, and commute duration estimation. The researchers measured prediction accuracy across metropolitan areas of varying sizes and calculated correlation coefficients between population size and prediction accuracy. The analysis compares performance metrics between the smallest and largest metropolitan regions to quantify the bias magnitude.

## Key Results
- Significant negative correlations (-0.42 to -0.58) between metropolitan population size and LLM prediction accuracy across all benchmarks
- Up to 300% worse performance in smallest 10 metropolitan regions compared to largest 10 regions
- Consistent bias observed across all three prediction tasks (salary, employer presence, commute duration)

## Why This Works (Mechanism)
The study does not provide a detailed mechanism explanation for why metropolitan size bias occurs in LLM predictions. The authors identify the bias but leave the underlying reasons unexplored, suggesting this represents an area for future research.

## Foundational Learning

1. **Metropolitan Statistical Areas (MSAs)**
   - Why needed: Standard geographic units for comparing urban regions of different sizes
   - Quick check: Verify MSA definitions and boundaries used in the study

2. **Correlation coefficient interpretation**
   - Why needed: Understanding strength and direction of relationships between population size and prediction accuracy
   - Quick check: Confirm correlation values fall within expected statistical ranges

3. **Prediction accuracy metrics**
   - Why needed: Quantifying LLM performance differences across geographic regions
   - Quick check: Review calculation methods for accuracy percentages

4. **Sample size considerations**
   - Why needed: Ensuring 384 metropolitan areas provide sufficient statistical power
   - Quick check: Verify sample size adequacy for the observed effect sizes

## Architecture Onboarding

**Component Map:** Data Collection -> LLM Prediction -> Accuracy Measurement -> Correlation Analysis -> Bias Quantification

**Critical Path:** The study follows a straightforward pipeline from data collection through to bias quantification, with each step building on the previous one to establish the metropolitan size effect.

**Design Tradeoffs:** The researchers chose to focus on three specific prediction tasks rather than broader LLM capabilities, potentially limiting generalizability but allowing for more controlled comparisons.

**Failure Signatures:** The primary failure mode appears to be systematic underperformance in smaller metropolitan areas, which could manifest as unreliable job market information for users in these regions.

**First Experiments:**
1. Replicate analysis with alternative LLM architectures
2. Test correlation between training data representation and prediction accuracy by metropolitan size
3. Compare LLM predictions against ground truth data for smaller vs larger metropolitan areas

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, though several are implied by the limitations section.

## Limitations
- Analysis limited to 384 metropolitan areas, potentially missing important geographic variations
- Correlation does not establish causation for the observed bias
- Unknown underlying mechanisms for why smaller metropolitan areas show poorer LLM performance
- Results may not generalize to all LLM applications beyond the three tested prediction tasks

## Confidence

**High confidence:** The existence of metropolitan size bias in LLM predictions
**Medium confidence:** The magnitude of the bias (300% difference) and specific correlation values
**Low confidence:** The generalizability to all LLM applications and the underlying causal mechanisms

## Next Checks
1. Replicate the analysis using different LLM architectures and training datasets to determine if the bias is model-specific or more widespread
2. Conduct qualitative analysis of training data distributions to identify potential data imbalances across metropolitan sizes
3. Test the same metropolitan regions with human expert predictions to establish whether the bias represents a true limitation or simply reflects actual data availability differences