---
ver: rpa2
title: 'Negative Token Merging: Image-based Adversarial Feature Guidance'
arxiv_id: '2412.01339'
source_url: https://arxiv.org/abs/2412.01339
tags:
- negtome
- image
- output
- arxiv
- guidance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces negative token merging (NegToMe), a training-free
  method for adversarial guidance in diffusion models using visual features from reference
  images instead of text-based negative prompts. The approach works by computing semantic
  token-to-token correspondences between generated and reference images, then performing
  linear extrapolation to push each output token away from its best-matching reference
  token.
---

# Negative Token Merging: Image-based Adversarial Feature Guidance

## Quick Facts
- arXiv ID: 2412.01339
- Source URL: https://arxiv.org/abs/2412.01339
- Reference count: 40
- Key outcome: Training-free method improves output diversity by 0.032-0.032 DreamSim reduction while maintaining quality metrics across SDXL and FLUX models

## Executive Summary
This paper introduces negative token merging (NegToMe), a training-free method for adversarial guidance in diffusion models using visual features from reference images rather than text-based negative prompts. The approach computes semantic token-to-token correspondences between generated and reference images, then performs linear extrapolation to push each output token away from its best-matching reference token. NegToMe is simple to implement, compatible with various diffusion architectures including those without negative prompt support, and adds only marginally higher (<4%) inference time. When applied to improve output diversity, it reduces DreamSim scores by 0.032-0.032 while maintaining or improving quality metrics (FID, IS) across different classifier-free guidance scales for both SDXL and FLUX models. For copyright mitigation, it reduces visual similarity to copyrighted characters by 34.57% when used with reference images from copyrighted RAG databases, while preserving text-to-image alignment and quality.

## Method Summary
NegToMe is a training-free approach that performs adversarial guidance through images by selectively pushing apart matching visual features in diffusion models. The method operates by first computing cross-image token-to-token similarities using cosine similarity between normalized diffusion features from the generated and reference images. It then performs linear extrapolation between the source tokens and their best-matching target tokens, with a time-dependent coefficient that controls the strength of the push throughout the diffusion process. A similarity threshold ensures that only tokens with meaningful semantic matches are modified, preventing unwanted changes when no good correspondence exists. The method is designed to work with any diffusion model that outputs attention block features, making it compatible with various architectures including those that don't support negative prompts.

## Key Results
- Reduces DreamSim scores by 0.032-0.032 while maintaining or improving FID and IS metrics
- Achieves 34.57% reduction in visual similarity to copyrighted characters when used with RAG databases
- Adds only marginally higher (<4%) inference time compared to baseline diffusion models
- Maintains text-to-image alignment and quality across different classifier-free guidance scales

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-image token matching using cosine similarity between normalized diffusion features effectively identifies semantically corresponding tokens across different images
- Mechanism: By normalizing tokens from both source and reference images, computing their dot product gives cosine similarity which measures semantic alignment. The best-matching target token for each source token is found by taking the argmax across this similarity matrix
- Core assumption: Diffusion model intermediate features preserve semantic structure even in noisy states, allowing meaningful cross-image matching
- Evidence anchors:
  - [abstract]: "we can leverage the rich semantic structure of intermediate diffusion features to compute cross-image token-token similarities using noisy features itself"
  - [section 3]: "we first compute similarity w.r.t the reference image tokens as follows, S(Osrc, Oref) = ˜Osrc · ˜OTref"
  - [corpus]: Weak evidence - no direct citations found about diffusion features preserving semantic structure for cross-image matching
- Break condition: When semantic correspondence breaks down due to extreme pose/viewpoint differences or when reference and source images have fundamentally different content structures

### Mechanism 2
- Claim: Linear extrapolation pushing source tokens away from their best-matching reference tokens creates effective adversarial guidance
- Mechanism: The simple formula Omerge = (1 + αt) Osrc − αt Otarget creates a vector field that pushes tokens away from reference matches. The time-dependent coefficient αt controls the strength of this push throughout the diffusion process
- Core assumption: Small linear adjustments to token embeddings can meaningfully shift the generation distribution without destabilizing the diffusion process
- Evidence anchors:
  - [abstract]: "NegToMe, a simple but effective training-free approach which performs adversarial guidance through images by selectively pushing apart matching visual features"
  - [section 3]: "we next perform a simple linear extrapolation between the source and target tokens as, Omerge = (1 + αt) Osrc − αt Otarget"
  - [corpus]: Weak evidence - no direct citations found about linear extrapolation effectiveness in diffusion guidance
- Break condition: When extrapolation magnitude becomes too large, causing generation collapse or mode collapse, or when reference features are too dissimilar to be meaningful

### Mechanism 3
- Claim: Thresholding source-to-target similarity prevents unwanted modifications when no good semantic match exists
- Mechanism: The mask H = 1[max{{S(Osrc, Oref)} > τ] ensures that only source tokens with sufficiently similar target matches are modified, while others pass through unchanged
- Core assumption: There exists a meaningful threshold τ that can distinguish between good and poor semantic matches
- Evidence anchors:
  - [section 3]: "H = 1[max{{S(Osrc, Oref)} > τ] helps ensure that source-tokens with source-to-target token similarity below a threshold τ are not modified"
  - [abstract]: "NegToMe helps better reduce similarity to copyrighted characters, by guiding diffusion features away from copyrighted images"
  - [corpus]: Weak evidence - no direct citations found about threshold-based semantic matching in diffusion models
- Break condition: When threshold is set too high (missing valid matches) or too low (including poor matches), leading to either insufficient guidance or noisy modifications

## Foundational Learning

- Concept: Diffusion models and reverse diffusion process
  - Why needed here: Understanding how tokens evolve during the reverse diffusion process is crucial for implementing the time-dependent extrapolation
  - Quick check question: What happens to token distributions as we progress through the reverse diffusion timesteps?

- Concept: Transformer attention mechanisms and token representations
  - Why needed here: The method operates on attention block outputs, requiring understanding of how tokens represent visual features in transformer blocks
  - Quick check question: How does the number of tokens (N) relate to image resolution in typical diffusion architectures?

- Concept: Cosine similarity and embedding spaces
  - Why needed here: The core matching mechanism relies on cosine similarity between normalized token embeddings
  - Quick check question: Why is normalization important before computing cosine similarity between token embeddings?

## Architecture Onboarding

- Component map: Attention block → NegToMe module (matching + extrapolation) → MLP layer → next transformer block
- Critical path: Attention block output is modified by NegToMe before being passed to the MLP layer
- Design tradeoffs: Simpler linear extrapolation vs more complex nonlinear guidance; threshold-based masking vs always applying guidance; time-dependent vs constant extrapolation coefficient
- Failure signatures: Mode collapse (all outputs become similar), quality degradation (FID increases significantly), prompt misalignment (CLIPScore drops), excessive computation time
- First 3 experiments:
  1. Implement basic NegToMe with fixed α and no thresholding, apply to SDXL with single reference image, measure output diversity vs base model
  2. Add similarity thresholding with varying τ values, compare output quality and diversity metrics across different thresholds
  3. Implement time-dependent αt and test across different guidance scales, measure tradeoff between diversity and image quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of NegToMe vary with different types of copyrighted content (e.g., characters vs. logos vs. landscapes)?
- Basis in paper: [explicit] The paper demonstrates NegToMe's effectiveness on copyrighted characters using a RAG database of character images, but does not explore other types of copyrighted content
- Why unresolved: The paper focuses exclusively on copyrighted characters and does not test the method's generalizability to other forms of copyrighted visual content
- What evidence would resolve it: Experiments testing NegToMe with copyrighted logos, product designs, architectural works, and other non-character copyrighted visual content

### Open Question 2
- Question: What is the long-term impact of repeated NegToMe applications on diffusion model weights and generation quality?
- Basis in paper: [inferred] The paper describes NegToMe as a training-free method applied during inference, but does not investigate whether repeated use affects the underlying model
- Why unresolved: The study focuses on immediate inference-time effects without examining potential cumulative impacts on model behavior or weights over time
- What evidence would resolve it: Longitudinal studies tracking model weights and generation quality after thousands of NegToMe applications

### Open Question 3
- Question: How does NegToMe performance scale with increasing batch sizes and what are the computational bottlenecks?
- Basis in paper: [explicit] The paper mentions NegToMe uses "marginally higher (<4%) inference time" but does not analyze how this scales with batch size
- Why unresolved: The computational complexity analysis is limited to a single batch size scenario without examining scaling properties
- What evidence would resolve it: Systematic evaluation of inference time, memory usage, and token matching quality across varying batch sizes from small to very large

### Open Question 4
- Question: What is the optimal threshold and alpha parameter configuration for different types of adversarial guidance tasks?
- Basis in paper: [explicit] The paper uses fixed threshold and alpha values without exploring parameter sensitivity or optimization
- Why unresolved: The method's effectiveness could be significantly improved with task-specific parameter tuning, but this remains unexplored
- What evidence would resolve it: Comprehensive parameter sensitivity analysis across different guidance tasks (diversity improvement, copyright mitigation, style control) with optimal configurations identified

## Limitations

- Cross-image semantic matching reliability lacks empirical validation across diverse image pairs with varying poses and content structures
- Time-dependent coefficient behavior only evaluates one fixed setting without exploring parameter sensitivity
- Copyright detection methodology relies on proprietary similarity measures without transparent baseline comparison

## Confidence

**High confidence**: The core NegToMe algorithm (token matching + linear extrapolation) is clearly specified and the implementation details are sufficient for reproduction. The inference time claims (<4% overhead) are straightforward to verify through benchmarking.

**Medium confidence**: The diversity improvement results (DreamSim reduction, maintained FID/IS) are supported by experiments across multiple models and guidance scales, but the specific prompt templates and reference image selection criteria introduce variability that could affect generalizability.

**Low confidence**: The copyright mitigation claims rely on proprietary similarity measures and black-box datasets. Without access to the specific copyrighted character datasets and similarity computation methods, independent verification is difficult.

## Next Checks

1. **Cross-image matching robustness test**: Systematically evaluate token matching quality across image pairs with controlled viewpoint and pose variations. Measure matching accuracy using ground truth correspondences (e.g., from keypoint datasets) to determine optimal threshold τ and identify failure modes when semantic structure breaks down.

2. **Time-dependent coefficient sensitivity analysis**: Implement a grid search over γ values (0.1-1.0) and evaluate the tradeoff between inference overhead and guidance effectiveness. Compare time-dependent αt against constant extrapolation to verify whether the complexity provides measurable benefits.

3. **Copyright detection benchmark**: Reproduce the copyright similarity reduction experiments using publicly available copyright detection tools (e.g., commercial image similarity APIs or open-source perceptual hashing) on the same copyrighted character datasets. Validate that the 34.57% reduction is consistent across different similarity measures.