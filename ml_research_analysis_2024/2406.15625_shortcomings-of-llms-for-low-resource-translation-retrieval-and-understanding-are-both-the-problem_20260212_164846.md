---
ver: rpa2
title: 'Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding
  are Both the Problem'
arxiv_id: '2406.15625'
source_url: https://arxiv.org/abs/2406.15625
tags:
- language
- quechua
- translation
- grammar
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the use of large language models (LLMs)
  for low-resource machine translation, focusing on translating Southern Quechua to
  Spanish using prompt-based retrieval of linguistic information. The authors experiment
  with different types of prompt context including morpheme translations, grammar
  descriptions, and parallel corpus examples, as well as automated vs.
---

# Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem

## Quick Facts
- arXiv ID: 2406.15625
- Source URL: https://arxiv.org/abs/2406.15625
- Authors: Sara Court; Micha Elsner
- Reference count: 40
- Primary result: LLMs struggle with low-resource translation despite linguistic context, producing fluent but inaccurate translations

## Executive Summary
This study investigates large language models (LLMs) for translating Southern Quechua to Spanish using prompt-based retrieval of linguistic information from pedagogical materials. The authors experiment with morpheme translations, grammar descriptions, and parallel corpus examples, as well as automated vs. manual retrieval methods across multiple LLM models. While newer LLMs show improved zero-shot translation performance, providing additional linguistic context does not consistently improve translation quality and may even degrade it in some cases. Human evaluation reveals persistent errors including mistranslations, grammatical divergences, and target language fluency issues. The study highlights significant limitations of current LLM approaches for low-resource translation and raises ethical concerns about potential deployment, particularly regarding fluent but inaccurate translations that could mislead users or reinforce stereotypes.

## Method Summary
The researchers constructed prompts using linguistic information retrieved from pedagogical materials including a morphological parser, dictionary, grammar document, and parallel corpus. They tested four LLM models (GPT-3.5, GPT-4o, Gemini 1.5, Llama 3) using different prompt types with context such as morpheme-level translations, grammar descriptions, and corpus examples. Both automated and manual retrieval methods were evaluated across 50 Southern Quechua-Spanish sentence pairs. Translation quality was assessed using automatic metrics (BLEURT, BLEU) and human evaluation employing MQM error typology.

## Key Results
- Newer LLM models (GPT-4o, Gemini 1.5) perform significantly better at zero-shot translation than older models
- Providing morpheme translations reliably improves translation quality for some models, but other context types show inconsistent effects
- Automated retrieval often introduces irrelevant or ambiguous information that degrades translation quality compared to manual retrieval
- Human evaluation reveals frequent mistranslations, grammatical divergences, and target language fluency issues
- Models frequently produce fluent but inaccurate translations (hallucinations), raising ethical concerns for deployment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can utilize morpheme-level translations to improve low-resource translation quality.
- Mechanism: When provided morpheme-level translations in the prompt context, LLMs can better understand the morphological structure of the source language and generate more accurate translations.
- Core assumption: LLMs can effectively process and utilize morpheme-level information when it is explicitly provided in the prompt.
- Evidence anchors:
  - [abstract] "prompts containing morpheme translations reliably improve model outputs"
  - [section 5.1] "Llama 3 and GPT-3.5 show a clear improvement in quality when MORPH information is included in the prompt"
  - [corpus] Weak evidence - related papers discuss morpheme-level translation but don't provide specific evidence for this mechanism
- Break condition: If the morpheme-level information is ambiguous or contains errors, it may confuse the model and degrade performance.

### Mechanism 2
- Claim: LLMs with prior exposure to the low-resource language perform better at zero-shot translation.
- Mechanism: Models that have been exposed to the low-resource language during pretraining can leverage this knowledge to generate better translations without additional context.
- Core assumption: The performance difference between models is primarily due to their exposure to the low-resource language during pretraining.
- Evidence anchors:
  - [abstract] "newer LLMs perform better at zero-shot translation"
  - [section 5.1] "GPT-4o and Gemini have much better coverage" of S. Quechua
  - [corpus] Related papers discuss pretraining data coverage but don't provide specific evidence for this mechanism
- Break condition: If the model's pretraining data contains biased or incorrect information about the low-resource language, it may lead to inaccurate translations.

### Mechanism 3
- Claim: Automated retrieval of linguistic information may introduce irrelevant or ambiguous content that degrades translation quality.
- Mechanism: Automated retrieval methods may retrieve information that is not directly relevant to the source sentence or contains ambiguities, which can confuse the model and lead to poorer translations.
- Core assumption: The quality of retrieved information directly impacts the model's ability to generate accurate translations.
- Evidence anchors:
  - [abstract] "providing additional linguistic context does not consistently improve translation quality and may even degrade performance"
  - [section 5.2] "The effect of manual retrieval for MORPH information is positive for all models"
  - [corpus] Related papers discuss retrieval methods but don't provide specific evidence for this mechanism
- Break condition: If the retrieval method is improved to only retrieve highly relevant and unambiguous information, this mechanism may no longer apply.

## Foundational Learning

- Concept: Agglutinative morphology
  - Why needed here: S. Quechua is primarily agglutinating, so understanding how morphemes combine is crucial for accurate translation
  - Quick check question: Can you explain the difference between agglutinative and fusional morphology?

- Concept: In-context learning
  - Why needed here: The study relies on LLMs' ability to learn from context provided in prompts, so understanding this concept is essential
  - Quick check question: How does in-context learning differ from traditional fine-tuning approaches?

- Concept: Retrieval-augmented generation
  - Why needed here: The study uses retrieved linguistic information to augment the LLM's generation process, so understanding this concept is crucial
  - Quick check question: What are the potential benefits and drawbacks of using retrieved information in LLM prompts?

## Architecture Onboarding

- Component map: Morphological parser -> Dictionary -> Grammar document -> Parallel corpus -> LLM models (GPT-3.5, GPT-4o, Gemini 1.5, Llama 3) -> Retrieval methods (automated and manual) -> Evaluation metrics (BLEURT, BLEU, human evaluation)

- Critical path: 1. Retrieve linguistic information for each source sentence 2. Construct prompts with retrieved information 3. Generate translations using LLM models 4. Evaluate translation quality using automatic and human evaluation

- Design tradeoffs:
  - Automated vs. manual retrieval: Automated retrieval is faster but may introduce irrelevant information, while manual retrieval is more accurate but time-consuming
  - Model size vs. performance: Larger models generally perform better but are more resource-intensive
  - Amount of context vs. performance: Providing more context can improve performance but may also introduce noise

- Failure signatures:
  - Decreased BLEURT/BLEU scores when adding context
  - Human evaluation reveals frequent mistranslations or grammatical errors
  - Models produce fluent but inaccurate translations (hallucinations)

- First 3 experiments:
  1. Compare the performance of different LLM models on the baseline (zero-shot) translation task
  2. Evaluate the impact of adding morpheme-level translations to the prompts
  3. Test the effect of automated vs. manual retrieval of linguistic information

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific database structures and retrieval methods would be most effective for low-resource LLM-MT?
- Basis in paper: [explicit] The paper discusses the need for improved data structures and methods for interacting with a language-specific database for retrieval-aided generation
- Why unresolved: While the paper identifies this as a key area for improvement, it doesn't provide specific recommendations for optimal database structures or retrieval methods
- What evidence would resolve it: Systematic experiments comparing different database architectures (e.g., graph databases, vector databases) and retrieval methods (e.g., semantic search, rule-based matching) for various low-resource language pairs

### Open Question 2
- Question: How do the in-context learning abilities of LLMs compare to finetuning approaches for low-resource translation?
- Basis in paper: [explicit] The paper suggests comparing ICL to the effects of finetuning as a future research direction
- Why unresolved: The paper doesn't conduct this comparison, leaving the relative effectiveness of these approaches unknown
- What evidence would resolve it: Head-to-head experiments on the same low-resource language pairs using both ICL and finetuned models, measuring translation quality and resource requirements

### Open Question 3
- Question: How does the order and presentation of information in prompts affect LLM translation quality for low-resource languages?
- Basis in paper: [explicit] The paper mentions experimenting with prompt structures and techniques, including altering the order of information
- Why unresolved: While this is identified as an area for future work, the paper doesn't explore how different prompt structures impact translation quality
- What evidence would resolve it: Controlled experiments varying prompt structure (e.g., source text first vs. context first, interleaved vs. separated information) and measuring the impact on translation accuracy and fluency

### Open Question 4
- Question: What are the specific mechanisms behind grammatical divergence errors in LLM translations of low-resource languages?
- Basis in paper: [explicit] The paper identifies grammatical divergence as a common error type but doesn't explore its underlying causes
- Why unresolved: The paper characterizes the error but doesn't investigate why LLMs struggle with grammatical alignment between languages
- What evidence would resolve it: Detailed analysis of LLM internal representations during translation, comparing grammatical feature handling across language pairs and identifying systematic patterns in divergence errors

### Open Question 5
- Question: How can LLMs be better trained to recognize and avoid perpetuating stereotypes about Indigenous communities?
- Basis in paper: [explicit] The paper identifies stereotypical outputs as an ethical concern requiring mitigation
- Why unresolved: While the problem is identified, the paper doesn't propose concrete solutions for addressing this issue
- What evidence would resolve it: Development and evaluation of training methods or prompt engineering techniques that reduce stereotypical outputs while maintaining translation quality, verified through human evaluation across diverse language pairs and topics

## Limitations
- Small dataset size (50 sentence pairs) limits generalizability of findings
- Focus on a single language pair (Quechua-Spanish) restricts applicability to other low-resource language pairs
- Manual evaluation process is time-consuming and may introduce subjective bias

## Confidence
- Zero-shot translation performance improvement (Medium): Newer LLMs perform better, but mechanisms unclear
- Context addition effects (Medium): Additional context doesn't consistently improve quality, challenging common assumptions
- Fluent but inaccurate translations (High): Well-supported finding with significant ethical implications
- Morpheme-level translation benefits (Medium): Improvement observed but needs validation across more models and language pairs
- Automated retrieval limitations (Medium): Plausible but requires testing with larger corpora and better methods

## Next Checks
1. Scale replication: Test the prompt engineering approach on a larger dataset (minimum 500 sentence pairs) across multiple low-resource language pairs to assess generalizability and determine if the small sample size influenced the negative results.

2. Retrieval method comparison: Implement and evaluate more sophisticated automated retrieval methods, such as semantic similarity matching or multi-document fusion, to determine if improved retrieval can overcome the current limitations observed with basic keyword-based approaches.

3. Cross-model analysis: Conduct ablation studies across different model architectures (decoder-only, encoder-decoder, and multimodal) to isolate whether the observed performance differences stem from pretraining data exposure versus architectural advantages for translation tasks.