---
ver: rpa2
title: Language-Based User Profiles for Recommendation
arxiv_id: '2402.15623'
source_url: https://arxiv.org/abs/2402.15623
tags:
- user
- rating
- prediction
- history
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Language-based Factorization Model (LFM)
  that uses natural language to represent user profiles for recommendation tasks.
  The LFM encodes user rating history into a compact text profile using a large language
  model (LLM), which is then decoded by another LLM to make predictions on tasks like
  rating, preference, and choice prediction.
---

# Language-Based User Profiles for Recommendation

## Quick Facts
- arXiv ID: 2402.15623
- Source URL: https://arxiv.org/abs/2402.15623
- Authors: Joyce Zhou; Yijia Dai; Thorsten Joachims
- Reference count: 18
- Key outcome: LFM achieves competitive performance compared to direct LLM prediction and traditional matrix factorization, particularly in cold-start settings

## Executive Summary
This paper introduces a Language-based Factorization Model (LFM) that represents user profiles for recommendation using natural language. The LFM encodes user rating history into compact text profiles using a large language model, which are then decoded by another LLM to make predictions on rating, preference, and choice tasks. The approach demonstrates competitive performance with improved interpretability and reduced input length compared to direct LLM prediction, while showing particular advantage in cold-start scenarios over traditional matrix factorization methods.

## Method Summary
The LFM approach uses two LLMs in sequence: an encoder that converts user rating history into a natural language profile (50-300 words), and a decoder that uses this profile to make predictions. The method is evaluated zero-shot on the MovieLens Tag Genome Dataset 2021 with 300 users, comparing against both direct LLM prediction and NMF baselines. Experiments test varying user history sizes (10, 20, 30 items) and profile lengths (50-200 words) across rating prediction (RMSE, MAE), pairwise preference prediction (accuracy), and choice prediction (error rate) tasks.

## Key Results
- LFM achieves competitive performance compared to direct LLM prediction while offering better interpretability and shorter input lengths
- Even short text profiles (50-200 words) effectively capture relevant user preferences for recommendation tasks
- LFM shows particular advantage in cold-start settings, outperforming traditional matrix factorization approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language-based user profiles can capture user preferences effectively for recommendation tasks while being interpretable
- Mechanism: The encoder LLM translates user rating history into a compact natural-language profile that summarizes preferences, which the decoder LLM then uses to make predictions
- Core assumption: Natural language can adequately compress and represent user preferences from rating history
- Evidence anchors: Abstract states short profiles (50-200 words) can capture preferences effectively; varying profile sizes shows no consistent impact on prediction error

### Mechanism 2
- Claim: LFM achieves competitive performance compared to direct LLM prediction while offering better interpretability and reduced input length
- Mechanism: Profile generation creates a compact representation that can be computed offline, allowing the decoder to work with shorter prompts than direct LLM approaches
- Core assumption: Computational benefits of pre-computed profiles outweigh information loss from compression
- Evidence anchors: Abstract shows compact summaries perform comparably or better than direct LLM prediction; decoder uses substantially smaller prompt length

### Mechanism 3
- Claim: LFM shows particular advantage in cold-start settings compared to traditional matrix factorization
- Mechanism: Natural language profiles can incorporate item descriptions and metadata that matrix factorization cannot use when new items or users lack sufficient interaction history
- Core assumption: Natural language can effectively encode item characteristics for cold-start predictions
- Evidence anchors: Abstract notes LFM has higher accuracy than matrix factorization in cold-start settings; LLMs can take into account natural-language descriptions of items

## Foundational Learning

- Concept: Large Language Model prompting and zero-shot inference
  - Why needed here: The entire LFM approach relies on using LLMs in zero-shot mode to both generate profiles and make predictions
  - Quick check question: What are the key hyperparameters (temperature, top_p, etc.) that affect LLM output quality and how would you tune them for different tasks?

- Concept: Matrix factorization and collaborative filtering
  - Why needed here: The paper explicitly compares LFM against NMF, requiring understanding of traditional recommendation approaches
  - Quick check question: How does matrix factorization handle cold-start problems and what are its fundamental limitations compared to language-based approaches?

- Concept: Natural language processing and text summarization
  - Why needed here: The core innovation involves using LLMs to generate and interpret natural language profiles
  - Quick check question: What are the trade-offs between summary length and information retention when using LLMs for text summarization?

## Architecture Onboarding

- Component map: User rating history → Encoder LLM → Natural language profile → Decoder LLM → Prediction
- Critical path: User rating history flows through encoder to create profile, which decoder uses for predictions
- Design tradeoffs:
  - Profile length vs. information retention: 50-200 words appears sufficient but may miss fine-grained preferences
  - Zero-shot vs. fine-tuning: Current approach uses zero-shot inference but could benefit from fine-tuning for better accuracy
  - Profile generation frequency: Can be computed offline vs. real-time generation needs
  - LLM model size: Llama 2 13B provides best balance of reliability and performance
- Failure signatures:
  - Unreadable predictions: LLM outputs that don't provide clear answers or are hard to parse
  - Context window overflow: Direct LLM approaches failing with large history sizes
  - Imputation needed: Missing predictions due to NMF encountering new items or LLM failures
  - Bias in predictions: Systematic over/under-estimation of ratings
- First 3 experiments:
  1. Profile generation reliability test: Measure percentage of readable profiles across different history sizes and LLM models
  2. Cold-start comparison: Compare LFM vs. NMF performance with minimal user history (5-10 ratings)
  3. Profile length sensitivity: Test prediction accuracy across profile lengths (50, 100, 150, 200 words) with fixed history size

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does fine-tuning the LFM encoder and decoder affect prediction accuracy compared to zero-shot performance?
- Basis in paper: The paper concludes that moving from a zero-shot approach to a fine-tuned version of LFM is a promising direction and identifies the inability to use background data as a major shortcoming
- Why unresolved: The current study only evaluates zero-shot LFM performance without any fine-tuning on task-specific data or cross-user data
- What evidence would resolve it: Experiments comparing zero-shot LFM against fine-tuned versions on the same tasks, measuring improvements in RMSE, MAE, and error rates

### Open Question 2
- Question: What is the optimal profile length for balancing accuracy and computational efficiency in LFM?
- Basis in paper: The paper tests profile lengths from 50-200 words and finds no consistent impact on prediction error, stating that even a short profile can capture much of the relevant information
- Why unresolved: The study only tests a limited range of profile lengths and doesn't explore the trade-off between profile length, prediction accuracy, and computational cost
- What evidence would resolve it: Systematic experiments varying profile lengths across a wider range while measuring both prediction accuracy and inference time/compute costs

### Open Question 3
- Question: How do LFM profiles perform when incorporating additional textual metadata like user comments, tags, or media transcriptions?
- Basis in paper: The discussion section states they aim to incorporate other textual metadata for both items and users, such as outside comments, tags, or transcriptions of the media itself
- Why unresolved: The current study only uses basic user rating history and item titles without exploring richer metadata sources
- What evidence would resolve it: Experiments comparing LFM performance using only rating history versus LFM with additional metadata sources, measuring improvements in cold-start and overall prediction accuracy

## Limitations

- Evaluation relies on zero-shot LLM performance which can be highly variable across different models and prompt formulations
- Study uses a fixed set of 300 users from MovieLens which may not generalize to different user bases or recommendation scenarios
- Comparison with NMF is limited to specific hyperparameters without exploring the full parameter space for either method

## Confidence

High confidence: The LFM approach successfully generates readable natural language profiles from user rating histories, and these profiles can be effectively used by LLMs to make reasonable predictions across rating, preference, and choice tasks.

Medium confidence: The claim that LFM performs "competitively" with direct LLM prediction is supported but depends on specific model sizes and hyperparameters. The interpretability advantage is demonstrated but could be more rigorously quantified.

Low confidence: The generalizability of results across different recommendation domains and user populations is not established. The optimal profile length for different recommendation tasks remains unclear.

## Next Checks

1. Conduct cross-domain validation using non-movie recommendation datasets (books, music, products) to test generalizability of LFM performance across different recommendation contexts.

2. Implement a systematic ablation study varying profile lengths (25, 50, 100, 200, 500 words) with statistical significance testing to identify optimal profile size for different recommendation tasks.

3. Perform head-to-head comparison with fine-tuned LLM approaches using the same base models to quantify the trade-off between zero-shot interpretability and potential accuracy gains from fine-tuning.