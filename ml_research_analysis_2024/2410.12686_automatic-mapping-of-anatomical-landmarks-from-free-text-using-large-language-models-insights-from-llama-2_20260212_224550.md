---
ver: rpa2
title: 'Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language
  Models: Insights from Llama-2'
arxiv_id: '2410.12686'
source_url: https://arxiv.org/abs/2410.12686
tags:
- llama-2
- anatomical
- landmarks
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) can
  accurately represent the spatial positions of anatomical landmarks in medical imaging
  from free-text radiology reports. The authors used Llama-2 models to encode anatomical
  landmark names and applied linear and nonlinear regression probes to predict their
  spatial coordinates.
---

# Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2

## Quick Facts
- **arXiv ID**: 2410.12686
- **Source URL**: https://arxiv.org/abs/2410.12686
- **Reference count**: 12
- **Primary result**: Llama-2 models can linearly represent anatomical landmark positions in 3D space with robustness to different prompts, outperforming baseline lexical similarity methods.

## Executive Summary
This paper investigates whether large language models can accurately represent the spatial positions of anatomical landmarks in medical imaging from free-text radiology reports. Using Llama-2 models, the authors encoded anatomical landmark names and applied linear and nonlinear regression probes to predict their spatial coordinates. They found that Llama-2 models can linearly represent anatomical landmarks in space with considerable robustness to different prompts, with linear probes outperforming nonlinear probes and significantly exceeding baseline methods based on lexical similarity. These results demonstrate the potential of LLMs to enhance the efficiency and accuracy of medical imaging workflows by automating the mapping of anatomical landmarks from free-text reports to image data.

## Method Summary
The study uses Llama-2 models (7B, 13B, 70B parameters) to encode anatomical landmark names and applies linear regression (ridge) and nonlinear (MLP) probes to predict 3D spatial coordinates. The dataset consists of 117 anatomical landmark names with spatial coordinates extracted from segmentation masks generated by the TotalSegmentator model. The authors test different prompting strategies (random, context-inducing, and unprompted) and evaluate performance using mean Euclidean distance between predicted and target coordinates, as well as DICE scores for bounding box overlap. A baseline comparison uses lexical similarity (Jaccard index) between landmark names.

## Key Results
- Llama-2 models can linearly represent anatomical landmark positions in 3D space with considerable accuracy
- Linear probes consistently outperform nonlinear probes for this spatial representation task
- The spatial representations demonstrate robustness to different prompting strategies
- Larger Llama-2 models (70B) yield more accurate predictions than smaller models (7B, 13B)
- Performance significantly exceeds baseline methods using lexical similarity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Llama-2 models can linearly represent anatomical landmark positions in 3D space.
- Mechanism: The hidden state activations of the last token in Llama-2 models contain linearly decodable spatial information about anatomical landmarks. A ridge linear regression can map these activations to 3D coordinates with lower error than baseline lexical similarity methods.
- Core assumption: The spatial information about anatomical landmarks is encoded in a linear subspace of the activation space.
- Evidence anchors:
  - [abstract] "we found that they can linearly represent anatomical landmarks in space with considerable robustness to different prompts."
  - [section] "Figure 1 illustrates the mean Euclidean distance between the predicted and target positions... deeper layers of the Llama-2 models yield more accurate spatial representations, with accuracy approaching a plateau at approximately 20% depth"
  - [corpus] Weak evidence - no direct studies on anatomical landmark spatial representation in LLMs found
- Break condition: If the linear probe performance drops significantly below baseline, or if the spatial relationships become nonlinear (e.g., for highly irregular anatomical structures), the linear assumption fails.

### Mechanism 2
- Claim: Llama-2 representations of anatomical landmarks are robust to different prompting strategies.
- Mechanism: The spatial information about anatomical landmarks is consistently encoded across different prompting strategies (random, context-inducing, and unprompted), allowing for robust decoding regardless of input format.
- Core assumption: The spatial representation of anatomical landmarks is independent of the specific prompt used to elicit the representation.
- Evidence anchors:
  - [abstract] "These representations demonstrate considerable robustness to different prompts."
  - [section] "We did not observe a significant advantage in prompting the Llama-2 models."
  - [corpus] Weak evidence - no direct studies on prompting robustness for anatomical landmark representation found
- Break condition: If specific prompts significantly degrade or improve performance, suggesting that the spatial information is prompt-dependent rather than inherent to the model.

### Mechanism 3
- Claim: Llama-2 models may also linearly represent the size of anatomical landmarks.
- Mechanism: The bounding box coordinates (8 corners of the cube covering the segmentation mask) can be predicted from the activation vectors with reasonable accuracy, as measured by DICE scores, suggesting linear representation of both position and size.
- Core assumption: Size information is encoded in the same linear subspace as position information.
- Evidence anchors:
  - [abstract] "Llama-2 models may linearly represent the size of anatomical landmarks."
  - [section] "Table 1 also provides the Dice scores... for the bounding-box test data... Similar trends were observed, with larger models yielding better predictions of both the size and position"
  - [corpus] Weak evidence - no direct studies on size representation in LLMs found
- Break condition: If DICE scores are consistently low or if nonlinear methods significantly outperform linear methods for size prediction.

## Foundational Learning

- Concept: Linear probing and representation analysis
  - Why needed here: The study relies on linear regression probes to decode spatial information from LLM activations, so understanding this methodology is essential for interpreting results
  - Quick check question: What does high predictive performance of a linear probe on out-of-sample data indicate about the base model's representations?

- Concept: Anatomical landmark segmentation and coordinate extraction
  - Why needed here: The study uses segmentation masks to extract spatial coordinates for training and evaluation, requiring understanding of how anatomical landmarks are defined in 3D space
  - Quick check question: How are the spatial coordinates of anatomical landmarks computed from segmentation masks in this study?

- Concept: Baseline comparison methods in representation learning
  - Why needed here: The study establishes a lexical similarity baseline, so understanding how to create and interpret baselines is important for evaluating the LLM approach
  - Quick check question: What baseline method was used in this study and why is it appropriate for this task?

## Architecture Onboarding

- Component map: Anatomical landmark names -> Llama-2 models -> Hidden state activations -> Linear/Nonlinear probes -> 3D spatial coordinates
- Critical path:
  1. Generate segmentation masks for anatomical landmarks
  2. Compute spatial coordinates (center point and bounding box)
  3. Process landmark names through Llama-2 to get activation vectors
  4. Split data into training and test sets
  5. Train linear and nonlinear probes on training set
  6. Evaluate probe performance on test set
- Design tradeoffs:
  - Linear vs nonlinear probes: Linear probes are interpretable and computationally efficient but may miss nonlinear relationships; nonlinear probes can capture complex patterns but are less interpretable
  - Prompting strategies: Different prompts may affect representation quality but the study found robustness to prompting
  - Model size: Larger models show better performance but require more computational resources
- Failure signatures:
  - Poor probe performance on test set (high Euclidean distance, low DICE score)
  - Significant performance gap between linear and nonlinear probes
  - Sensitivity to prompting strategies
  - Poor generalization to unseen anatomical landmarks
- First 3 experiments:
  1. Replicate the linear probe experiment with a small subset of landmarks to verify the basic mechanism
  2. Compare linear and nonlinear probe performance on the same dataset to validate the linear representation hypothesis
  3. Test prompting robustness by running the same experiment with different prompting strategies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs effectively encode anatomical landmarks from clinical text rather than just anatomical names?
- Basis in paper: [inferred] The authors note their methodology "underutilizes LLMs' few-shot learning capabilities" and suggest integrating known landmark coordinates into prompts to provide context for unknown landmarks, implying clinical text could provide richer context.
- Why unresolved: The paper only tested single anatomical landmark names as inputs, not full clinical descriptions or reports.
- What evidence would resolve it: Experiments comparing LLM performance on anatomical landmark encoding using only landmark names versus full clinical text descriptions would provide evidence.

### Open Question 2
- Question: What is the relationship between LLM size and spatial representation accuracy for anatomical landmarks?
- Basis in paper: [explicit] The authors found "An increase in model size results in more accurate predictions, a trend consistent with findings from previous study," but note this needs further investigation.
- Why unresolved: While the trend was observed, the authors didn't explore whether the relationship is linear, exponential, or has diminishing returns.
- What evidence would resolve it: Systematic testing across multiple LLM sizes with consistent evaluation metrics would clarify the relationship.

### Open Question 3
- Question: Can LLM-based anatomical landmark detection generalize across different imaging modalities (CT, MRI, X-ray)?
- Basis in paper: [inferred] The authors used CT-based segmentation masks from TotalSegmentator, but didn't test whether the LLM spatial representations transfer to other imaging modalities.
- Why unresolved: The study was limited to a single imaging modality, leaving open whether the spatial encoding generalizes.
- What evidence would resolve it: Testing the same LLM spatial representation approach across multiple imaging modalities using appropriate segmentation masks for each would provide evidence.

## Limitations
- The study uses a relatively small dataset of 117 anatomical landmarks, which may not capture the full diversity of anatomical structures and their spatial relationships
- The research focuses on linear representation without fully exploring nonlinear alternatives that might capture more complex anatomical relationships
- The robustness to prompting strategies is demonstrated but not extensively tested across a wide range of prompt variations

## Confidence
- **High confidence**: The finding that Llama-2 models can linearly represent anatomical landmark positions with reasonable accuracy, as this is directly demonstrated with multiple evaluation metrics and model sizes
- **Medium confidence**: The claim about robustness to different prompting strategies, as this is supported by the experiments but could benefit from more extensive prompt variation testing
- **Medium confidence**: The potential for linear representation of anatomical landmark sizes, as the DICE scores suggest this capability but the analysis is less comprehensive than for positional information

## Next Checks
1. **Dataset expansion validation**: Test the model's performance on a larger and more diverse anatomical landmark dataset to assess generalizability and identify potential failure modes with less common anatomical structures
2. **Prompt variation stress test**: Systematically test the model's performance across a wider range of prompt variations (including medical terminology variations, incomplete landmark names, and noisy text) to more thoroughly validate the claimed robustness to prompting strategies
3. **Nonlinear probe comparison**: Conduct a more thorough comparison of linear and nonlinear probe performance using different nonlinear architectures and hyperparameters to determine if there are specific types of anatomical relationships where nonlinear methods would outperform linear approaches