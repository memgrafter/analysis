---
ver: rpa2
title: 'GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation'
arxiv_id: '2411.13147'
source_url: https://arxiv.org/abs/2411.13147
tags:
- graph
- segmentation
- data
- semi-supervised
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses semi-supervised medical image segmentation,
  which is challenging due to the scarcity of labeled data. Existing methods neglect
  the importance of graph structural information.
---

# GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation

## Quick Facts
- arXiv ID: 2411.13147
- Source URL: https://arxiv.org/abs/2411.13147
- Authors: Mengzhu Wang; Jiao Li; Houcheng Su; Nan Yin; Liang Yang; Shen Li
- Reference count: 40
- Primary result: Achieves up to 6.64% Dice Score and 3.85% Jaccard Index improvement over state-of-the-art semi-supervised medical image segmentation methods

## Executive Summary
GraphCL addresses the challenge of semi-supervised medical image segmentation by modeling graph structural information in a unified deep model. The method creates a dense instance graph reflecting structural similarity of samples based on CNN features, then deploys a Graph Convolutional Network (GCN) on this graph to allow structural information propagation through learnable weighted edges. A k-less clustering strategy further improves segmentation accuracy, with extensive experiments on three standard benchmarks showing significant performance gains.

## Method Summary
GraphCL combines a bidirectional copy-paste framework with graph-based clustering for semi-supervised medical image segmentation. The method extracts CNN features from medical images, constructs a dense instance graph based on pairwise affinities between these features, and applies GCN to propagate structural information. A k-less clustering strategy using correlation clustering automatically groups similar nodes without requiring predefined cluster numbers. The model is trained using a teacher-student framework with mixed samples created from labeled and unlabeled data, supervised by both ground truth labels and pseudo-labels.

## Key Results
- Outperforms state-of-the-art semi-supervised medical image segmentation methods by up to 6.64% in Dice Score
- Achieves improvements of up to 3.85% in Jaccard Index across three medical imaging benchmarks
- Particularly effective when labeled data is limited (5-20% labeled data ratios)

## Why This Works (Mechanism)

### Mechanism 1
GraphCL improves segmentation accuracy by modeling pairwise affinities between local image features to create a dense instance graph that captures structural similarity. The method extracts CNN features from medical images, constructs an adjacency matrix based on pairwise affinities between these features, and uses this matrix to build a dense instance graph. A GCN is then applied to this graph, allowing structural information to propagate through learnable weighted edges.

### Mechanism 2
The k-less clustering strategy automatically groups similar nodes without requiring a predefined number of clusters, improving segmentation accuracy. After constructing the graph with pairwise affinities, the method uses correlation clustering with a tunable parameter τ to control clustering sensitivity. This allows similar nodes to automatically form clusters based on their structural similarity, eliminating the need to specify k.

### Mechanism 3
Integrating both labeled and unlabeled data through bidirectional copy-paste framework enhances learning by creating mixed samples that preserve semantic information. The method creates mixed samples by pasting foreground regions from labeled images onto unlabeled images and vice versa, generating paired samples that are supervised by both ground truth labels and pseudo-labels from a teacher network.

## Foundational Learning

- **Graph Neural Networks (GNNs) and Graph Convolutional Networks (GCNs)**: Needed to propagate structural information through the instance graph, allowing nodes to aggregate information from their neighbors based on learned affinities. Quick check: How does a GCN update node features using the adjacency matrix and degree matrix?

- **Semi-supervised learning and pseudo-labeling**: Needed to combine labeled and unlabeled data using a teacher-student framework where pseudo-labels are generated for unlabeled data and refined through consistency regularization. Quick check: What is the role of the teacher network in the mean teacher framework and how does it generate pseudo-labels?

- **Correlation clustering and clustering loss**: Needed for the k-less clustering strategy using correlation clustering loss to automatically group similar nodes without specifying the number of clusters. Quick check: How does correlation clustering differ from traditional k-means clustering in terms of cluster number specification?

## Architecture Onboarding

- **Component map**: CNN feature extractor → Data Structure Analyzer (DSA) → Pairwise affinity matrix → Dense instance graph → GCN feature propagation → Clustering with LCC loss → Segmentation output with BCE and Dice loss supervision

- **Critical path**: Input images → CNN features → Pairwise affinity matrix → Dense instance graph → GCN feature propagation → Clustering with LCC loss → Segmentation output with BCE and Dice loss supervision

- **Design tradeoffs**: The method trades computational complexity (dense graph construction and GCN operations) for improved segmentation accuracy through structural information exploitation. The k-less clustering provides flexibility but requires careful tuning of the sensitivity parameter τ.

- **Failure signatures**: Poor segmentation boundaries, inconsistent clustering assignments, or degraded performance on unlabeled data could indicate issues with the graph construction, GCN propagation, or clustering mechanism. Overfitting to labeled data or poor generalization could suggest the pseudo-labeling or bidirectional supervision is not working effectively.

- **First 3 experiments**:
  1. Baseline test: Run the model without the GCN and clustering components to establish the baseline semi-supervised segmentation performance.
  2. GCN ablation: Add the GCN component to the baseline to measure the improvement from structural information propagation.
  3. Clustering sensitivity: Test different values of the τ parameter in the correlation clustering loss to find the optimal setting for the specific dataset.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of GraphCL change when applied to datasets with significantly different anatomical structures or imaging modalities beyond those tested (ACDC, LA, Pancreas-NIH)? The paper evaluates GraphCL on three specific medical imaging datasets but does not explore its generalizability to other anatomical structures or imaging modalities.

### Open Question 2
What is the impact of varying the number of GCN layers on the segmentation performance and computational efficiency of GraphCL? While the paper identifies that deeper GCN layers improve performance, it does not examine whether increasing the number of GCN layers beyond a certain point leads to diminishing returns or computational bottlenecks.

### Open Question 3
How does the performance of GraphCL scale with increasing dataset size, particularly when the ratio of labeled to unlabeled data is varied? The paper evaluates GraphCL with labeled data ratios of 5%, 10%, and 20%, but does not explore performance scaling with larger datasets or different labeled/unlabeled ratios.

## Limitations
- The effectiveness of the graph-based clustering mechanism may be limited by the quality of CNN feature representations, which can struggle with small anatomical structures in medical images
- The bidirectional copy-paste framework assumes foreground regions can be meaningfully combined across different images, which may not hold for diverse anatomical structures
- The correlation clustering approach requires careful tuning of the τ parameter, and optimal values may vary significantly across different medical imaging modalities

## Confidence
- **High Confidence**: The overall improvement over baseline methods (6.64% Dice, 3.85% Jaccard) is well-supported by extensive experiments on three standard benchmarks
- **Medium Confidence**: The mechanism of GCN-based structural information propagation is theoretically sound but the specific implementation details are somewhat limited in the paper
- **Low Confidence**: The claim that k-less clustering is superior to traditional k-means for this application lacks direct comparative evidence in the paper

## Next Checks
1. Conduct ablation studies isolating the contribution of the GCN layers versus the clustering loss to determine which component drives the most improvement
2. Test the method's sensitivity to the number of labeled samples by varying the labeled/unlabeled ratio below 5% to assess robustness in extremely low-data scenarios
3. Validate the bidirectional copy-paste framework on a dataset with highly variable anatomical structures to test generalizability beyond the cardiac and pancreas applications