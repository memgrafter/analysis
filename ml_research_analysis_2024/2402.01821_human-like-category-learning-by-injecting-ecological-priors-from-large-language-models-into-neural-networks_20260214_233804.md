---
ver: rpa2
title: Human-like Category Learning by Injecting Ecological Priors from Large Language
  Models into Neural Networks
arxiv_id: '2402.01821'
source_url: https://arxiv.org/abs/2402.01821
tags:
- category
- learning
- tasks
- data
- ermi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper demonstrates that large language models (LLMs) can
  generate ecologically valid category learning tasks, enabling the use of meta-learning
  to derive models optimally adapted to human environments. The resulting ecologically
  rational meta-learned inference (ERMI) models quantitatively explain human category
  learning data better than seven competing cognitive models and qualitatively match
  human behavior in three key aspects: difficulty assessment, strategy evolution,
  and generalization.'
---

# Human-like Category Learning by Injecting Ecological Priors from Large Language Models into Neural Networks

## Quick Facts
- arXiv ID: 2402.01821
- Source URL: https://arxiv.org/abs/2402.01821
- Authors: Akshay K. Jagadish; Julian Coda-Forno; Mirko Thalmann; Eric Schulz; Marcel Binz
- Reference count: 40
- One-line primary result: ERMI models trained on LLM-generated tasks explain human category learning data better than seven competing models and achieve state-of-the-art performance on OpenML-CC18

## Executive Summary
This paper presents a novel approach to building human-like category learning models by leveraging large language models (LLMs) to generate ecologically valid category learning tasks. The authors demonstrate that ERMI (ecologically rational meta-learned inference) models, trained on these LLM-generated tasks, quantitatively and qualitatively match human category learning behavior better than seven other cognitive models. Additionally, ERMI achieves state-of-the-art performance on the OpenML-CC18 classification benchmark, outperforming established machine learning approaches.

## Method Summary
The method involves using LLMs to generate category learning tasks whose statistical properties match real-world classification problems. These tasks are then used to train transformer-based meta-learning models through a meta-learning pipeline. The resulting ERMI models are evaluated on human behavioral data from four studies and the OpenML-CC18 classification benchmark. Model comparison is performed using Bayesian Information Criterion (BIC) to determine which model best explains human behavior.

## Key Results
- ERMI quantitatively explains human category learning data better than seven other cognitive models
- ERMI qualitatively matches human behavior in difficulty assessment, strategy evolution, and generalization
- ERMI achieves state-of-the-art performance on the OpenML-CC18 classification benchmark with 70.95% mean accuracy and rank 2.26

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LLMs can synthesize large numbers of ecologically valid category learning tasks whose statistical properties match real-world classification problems.
- **Mechanism**: By prompting an LLM to generate feature names, categories, and data points, the resulting tasks inherit the distributional properties (input correlations, sparsity, linearity) present in the training corpus, which reflects real-world data.
- **Core assumption**: The LLM's pretraining data contains sufficient ecological examples so that the synthesized tasks reproduce those distributional properties.
- **Evidence anchors**:
  - [abstract] "LLMs can generate category learning tasks whose statistics match real-world classification data sets"
  - [section] "We downsampled all tasks in the OpenML-CC18 benchmark... Both LLM-generated and real-world tasks showed a significant percentage of correlated features"
- **Break condition**: If the LLM's training corpus is narrow or synthetic, generated tasks will lack ecological validity, and meta-learning will not yield human-like priors.

### Mechanism 2
- **Claim**: Meta-learning on ecologically valid tasks produces a model whose free parameters approximate the Bayes-optimal learner for those tasks, yielding human-like behavior.
- **Mechanism**: The transformer-based meta-learner updates parameters to maximize log-likelihood over many tasks; after training, frozen weights encode a prior that adapts rapidly to new tasks, mirroring ecological rationality.
- **Core assumption**: Convergence to Bayes-optimal inference occurs when the meta-training distribution matches the real-world task distribution.
- **Evidence anchors**:
  - [abstract] "ERMI quantitatively explains human data better than seven other cognitive models"
  - [section] "The neural network implements a free-standing learning algorithm... approximates the Bayes-optimal learning algorithm"
- **Break condition**: If the task distribution is misspecified or training is insufficient, the learned prior will be suboptimal and diverge from human behavior.

### Mechanism 3
- **Claim**: ERMI's ecologically valid priors enable state-of-the-art performance on real-world classification benchmarks.
- **Mechanism**: Because ERMI's meta-learned prior captures statistical regularities of real-world data, it generalizes well to held-out classification tasks from OpenML-CC18, outperforming baselines like TabPFN, XGBoost, and SVMs.
- **Core assumption**: Real-world classification tasks share sufficient structure with the LLM-generated tasks so that ERMI's prior transfers.
- **Evidence anchors**:
  - [abstract] "ERMI's ecologically valid priors allow it to achieve state-of-the-art performance on the OpenML-CC18 classification benchmark"
  - [section] "ERMI is the best model in terms of both mean accuracy (70.95%) and mean rank (2.26)"
- **Break condition**: If task domains differ substantially, transfer performance will degrade.

## Foundational Learning

- **Concept**: Bayesian logistic regression and neural network priors
  - **Why needed here**: ERMI's meta-learning relies on defining task distributions (Bayesian priors) to sample synthetic tasks; understanding these priors is essential to reproduce the pipeline.
  - **Quick check question**: Can you explain how a Bayesian logistic regression prior differs from a standard maximum-likelihood logistic regression prior?

- **Concept**: Transformer decoder with causal attention
  - **Why needed here**: The backbone of ERMI is a transformer decoder; knowing its architecture and attention mask is required to implement or modify the model.
  - **Quick check question**: What is the role of the causal attention mask in the meta-learning inference phase?

- **Concept**: Model comparison via Bayesian Information Criterion (BIC)
  - **Why needed here**: Model comparison is used to evaluate which cognitive model best explains human behavior; understanding BIC helps interpret results.
  - **Quick check question**: How does BIC penalize model complexity, and why is that important when comparing models with different numbers of parameters?

## Architecture Onboarding

- **Component map**: LLM prompt generation -> task parsing -> meta-learning pipeline (transformer decoder + sigmoid readout) -> evaluation on human data and OpenML-CC18
- **Critical path**: Prompt -> generate tasks -> preprocess -> train ERMI -> evaluate human fit -> benchmark performance
- **Design tradeoffs**:
  - Use of large LLM vs. hand-crafted synthetic tasks: more ecological validity but higher computational cost
  - Number of meta-learning episodes: more episodes improve convergence but increase training time
  - Model size (64-dim, 6 layers): small enough for quick experiments but may limit expressivity
- **Failure signatures**:
  - Poor human fit -> task generation failed to capture ecological statistics
  - Low benchmark accuracy -> meta-learned prior did not transfer
  - Training instability -> learning rate or batch size mis-specified
- **First 3 experiments**:
  1. Generate a small set of LLM tasks (e.g., 100 tasks, 3 features) and verify input correlations and sparsity match OpenML-CC18 statistics.
  2. Train ERMI on this small set and evaluate on a toy human-like dataset to check learning curve shapes.
  3. Replace LLM tasks with Bayesian logistic regression tasks and confirm ERMI degrades to MI-level performance, validating ecological prior importance.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can ERMI be extended to multi-class classification tasks with more than two categories?
- **Basis in paper**: [explicit] The authors mention "allow for more than two classes" as a future direction in the discussion section.
- **Why unresolved**: The current ERMI model is trained and evaluated on binary classification tasks only, with no empirical testing of its performance on multi-class problems.
- **What evidence would resolve it**: Training and evaluating ERMI on datasets with three or more classes, comparing its performance to established multi-class algorithms, and analyzing its generalization capabilities.

### Open Question 2
- **Question**: How does ERMI's performance scale with increasing numbers of features and data points?
- **Basis in paper**: [explicit] The authors state plans to "increase the maximum number of data points" and "allow for more than two classes" in future work.
- **Why unresolved**: The current study uses tasks with a maximum of six features and limited data points (100-616 per task), leaving scalability unexplored.
- **What evidence would resolve it**: Systematic evaluation of ERMI on datasets with progressively larger feature dimensions and training set sizes, measuring accuracy and computational efficiency.

### Open Question 3
- **Question**: What architectural modifications could improve ERMI's learning speed to better match human performance?
- **Basis in paper**: [inferred] The authors note that ERMI "generally learned faster than people" and suggest incorporating "limited computational resources" or "architectural constraints" as potential solutions.
- **Why unresolved**: While the paper identifies the speed discrepancy, it does not empirically test specific architectural changes to address this gap.
- **What evidence would resolve it**: Implementing and comparing variants of ERMI with resource constraints (e.g., limited memory, attention mechanisms) or different architectures (e.g., recurrent networks), measuring learning curves against human data.

## Limitations

- Primary uncertainty about whether LLM pretraining corpora truly capture real-world ecological statistics, which underpins all downstream claims
- Claims about optimal adaptation to human environments and state-of-the-art OpenML-CC18 performance lack rigorous ablation studies and convergence analysis
- No empirical verification of convergence to Bayes-optimal inference or quantitative validation of ecological prior transfer

## Confidence

- **High confidence**: ERMI outperforms seven competing cognitive models in explaining human category learning data, supported by Bayesian model comparison metrics
- **Medium confidence**: ERMI qualitatively matches human behavior in difficulty assessment, strategy evolution, and generalization, based on descriptive comparisons with human studies
- **Low confidence**: Claims about optimal adaptation to human environments and state-of-the-art OpenML-CC18 performance, due to lack of rigorous ablation studies and convergence analysis

## Next Checks

1. Conduct controlled ablation experiments comparing ERMI trained on LLM-generated tasks versus hand-crafted synthetic tasks with known statistical properties to isolate the effect of ecological priors on human data fit and benchmark performance
2. Measure and report the convergence of meta-learned parameters to theoretical Bayes-optimal values through systematic analysis of learning curves and parameter stability across training epochs
3. Perform cross-domain transfer experiments where ERMI is trained on one subset of OpenML-CC18 tasks and tested on held-out tasks to quantify the robustness of ecological prior transfer to unseen classification problems