---
ver: rpa2
title: Transparent and Scrutable Recommendations Using Natural Language User Profiles
arxiv_id: '2402.05810'
source_url: https://arxiv.org/abs/2402.05810
tags:
- user
- profile
- profiles
- preferences
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to building transparent
  and scrutable recommender systems using natural language (NL) user profiles generated
  from past reviews. The method employs large language models (LLMs) to automatically
  generate personalized NL profiles that capture users' preferences.
---

# Transparent and Scrutable Recommendations Using Natural Language User Profiles

## Quick Facts
- arXiv ID: 2402.05810
- Source URL: https://arxiv.org/abs/2402.05810
- Reference count: 14
- One-line primary result: Natural language user profiles enable transparent and scrutable recommendations that perform comparably to traditional recommender systems

## Executive Summary
This paper introduces a novel approach to building transparent and scrutable recommender systems using natural language (NL) user profiles generated from past reviews. The method employs large language models (LLMs) to automatically generate personalized NL profiles that capture users' preferences. These profiles are then used to fine-tune an LLM for rating prediction, enabling recommendations based on interpretable text inputs rather than uninterpretable embeddings. The approach is evaluated on two benchmark datasets, Amazon Movies and TV and TripAdvisor, showing competitive performance compared to established baseline recommender systems.

## Method Summary
The approach works by first extracting features and sentiment from user reviews using sentiment analysis and feature ranking. An LLM (Llama2 or Mistral) then generates a concise natural language profile summarizing the user's preferences. This profile is used to fine-tune a recommender model (GPT-2) for rating prediction. When making recommendations for new items, the system uses the user's NL profile as input to predict ratings. Users can modify their profiles by directly editing the natural language text, which the model interprets to update recommendations accordingly.

## Key Results
- UPR achieves RMSE values around 0.94-0.95 and MAE values around 0.61-0.68 across datasets
- Performance is competitive with popular baseline recommender systems
- Adding new preferences to profiles leads to significant changes in recommendation coverage
- Users can easily scrutinize and modify NL profiles to influence recommendations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large Language Models can generate coherent natural language user profiles from past reviews that capture user preferences
- Mechanism: LLMs use instruction-tuned prompting to summarize review features and sentiment into a concise natural language description
- Core assumption: User reviews contain sufficient information about preferences and LLMs can effectively extract and synthesize this information
- Evidence anchors:
  - [abstract] "we investigate how a properly crafted prompt can be used to summarize a user's preferences from past reviews"
  - [section 3.3] "Using an instruction-tuned LLM, we can prompt the model to summarise the list of reviews to create a holistic profile"
  - [corpus] Weak - no direct citations to LLM summarization research in the paper
- Break condition: If user reviews are sparse, contain contradictory information, or LLMs fail to generate coherent summaries

### Mechanism 2
- Claim: Natural language profiles can substitute for uninterpretable embeddings in recommendation systems
- Mechanism: The recommender model learns to map natural language profiles to rating predictions through fine-tuning
- Core assumption: Natural language contains sufficient information to predict ratings accurately
- Evidence anchors:
  - [abstract] "These NL profiles can then be leveraged to fine-tune a LLM using only NL profiles to make transparent and scrutable recommendations"
  - [section 5.1] "we observe that our NL-based approach has competitive recommendation performance to popular baseline recommender systems"
  - [corpus] Weak - limited discussion of how NLP features compare to embeddings
- Break condition: If natural language cannot capture complex preference patterns or the model fails to learn the mapping effectively

### Mechanism 3
- Claim: Users can easily scrutinize and modify their profiles to influence recommendations
- Mechanism: Users can directly edit the natural language text in their profiles, which the model interprets to update recommendations
- Core assumption: Users understand how to modify their profiles and the model responds appropriately to changes
- Evidence anchors:
  - [abstract] "users can easily scrutinize and modify their NL profiles to influence recommendations"
  - [section 5.4] "we show that UPR is able to learn the features of each item during training, meaning that a user can scrutinize and edit their profile to instantly receive updated recommendations"
  - [corpus] Moderate - some discussion of scrutability but limited user testing
- Break condition: If users cannot effectively understand how to modify profiles or the model fails to respond to changes

## Foundational Learning

- Concept: Natural Language Processing fundamentals
  - Why needed here: The system relies on extracting features and sentiment from user reviews
  - Quick check question: Can you explain how bag-of-words or TF-IDF representations work for text?

- Concept: Collaborative Filtering and Recommendation Systems
  - Why needed here: Understanding how traditional recommendation systems work provides context for the novel approach
  - Quick check question: What's the difference between user-based and item-based collaborative filtering?

- Concept: Large Language Model prompting and fine-tuning
  - Why needed here: The system uses LLMs for both profile generation and recommendation tasks
  - Quick check question: How does instruction tuning differ from standard language model training?

## Architecture Onboarding

- Component map: Profile Generation (LLM) → Feature Extraction → Recommendation (Fine-tuned GPT-2) → Rating Prediction

- Critical path:
  1. Extract features and sentiment from user reviews
  2. Generate natural language profile using LLM
  3. Fine-tune recommender model on NL profiles
  4. Make predictions for new items using profile

- Design tradeoffs:
  - NL profiles vs embeddings: Interpretability vs information density
  - LLM size vs performance: Larger models may perform better but require more resources
  - Profile length vs cognitive load: Longer profiles may capture more preferences but be harder to understand

- Failure signatures:
  - Poor profile quality: Inconsistent or irrelevant information in generated profiles
  - Low recommendation accuracy: Performance close to baseline "Most Popular" method
  - Inconsistent updates: Profile changes don't result in expected recommendation changes

- First 3 experiments:
  1. Profile generation quality: Generate profiles for 10 users and manually evaluate fluency, informativeness, conciseness, and relevance
  2. Recommendation accuracy: Compare UPR performance to baseline models on a small subset of the data
  3. Scrutability test: Edit profiles to add/remove preferences and verify recommendation changes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of UPR compare when using larger language models like GPT-3 instead of GPT-2?
- Basis in paper: [explicit] The paper mentions that newer models like GPT-3 have shown better performance than GPT-2 and are trained on more data and natural language tasks, anticipating that UPR's performance will improve with larger-scale models.
- Why unresolved: The paper uses GPT-2 for fine-tuning and does not experiment with larger language models due to hardware limitations.
- What evidence would resolve it: Experiments comparing UPR's performance using GPT-2 versus GPT-3 on the same datasets, showing changes in RMSE, MAE, and recommendation quality metrics.

### Open Question 2
- Question: What is the optimal number of features and maximum token length for NL profiles to balance recommendation performance and cognitive load?
- Basis in paper: [inferred] The paper shows diminishing returns as more features are added to NL profiles and mentions a concern that verbose NL profiles increase cognitive load for users, but does not determine the optimal balance.
- What evidence would resolve it: Systematic experiments varying both the number of features and profile length, measuring both recommendation performance metrics and user cognitive load through user studies.

### Open Question 3
- Question: How do users interact with UPR in real-world scenarios, and what are the tradeoffs between transparent/scrutable models versus traditional recommender systems?
- Basis in paper: [explicit] The paper states they plan to study how human users interact with UPR and investigate the tradeoffs between traditional recommender methods and a transparent, scrutable recommender model.
- Why unresolved: The paper only validates scrutability through simulated profile editing, not through actual user interaction studies.
- What evidence would resolve it: User studies where participants use UPR to receive recommendations, modify their profiles, and compare their experience with traditional recommender systems, measuring satisfaction, trust, and effectiveness.

## Limitations
- Evaluation focuses primarily on rating prediction rather than actual recommendation quality (top-N recommendations)
- User study appears limited in scope with no clear metrics for evaluating scrutability
- Performance remains relatively close to simpler baseline approaches like "Most Popular" recommendations

## Confidence
- **High confidence**: The basic mechanism of using LLMs to generate natural language profiles from reviews is sound and well-supported
- **Medium confidence**: The recommendation performance claims are reasonable given the results, though the evaluation could be more comprehensive
- **Low confidence**: The scrutability claims lack robust user testing and quantitative validation

## Next Checks
1. **Top-N recommendation evaluation**: Test the system's ability to generate ranked lists of recommendations and measure metrics like precision@k and nDCG to complement the rating prediction results.

2. **A/B user study**: Conduct a controlled user study comparing the NL profile system against traditional recommender systems, measuring both recommendation quality and user understanding of how profiles influence results.

3. **Profile sensitivity analysis**: Systematically test how different types and magnitudes of profile edits affect recommendations, quantifying the relationship between profile changes and recommendation shifts.