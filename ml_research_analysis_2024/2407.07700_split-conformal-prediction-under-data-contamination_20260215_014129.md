---
ver: rpa2
title: Split Conformal Prediction under Data Contamination
arxiv_id: '2407.07700'
source_url: https://arxiv.org/abs/2407.07700
tags:
- prediction
- conformal
- data
- coverage
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies split conformal prediction under data contamination,
  specifically addressing the issue of outliers in calibration data affecting prediction
  set coverage. The authors analyze a Huber-type mixture model where a small fraction
  of calibration scores are drawn from a different distribution than the bulk.
---

# Split Conformal Prediction under Data Contamination

## Quick Facts
- arXiv ID: 2407.07700
- Source URL: https://arxiv.org/abs/2407.07700
- Authors: Jase Clarkson; Wenkai Xu; Mihai Cucuringu; Yvik Swan; Gesine Reinert
- Reference count: 15
- Primary result: CRCP method maintains 90% coverage under label noise while producing narrower prediction sets than standard conformal prediction

## Executive Summary
This paper addresses the challenge of data contamination in split conformal prediction, where outliers in calibration data can degrade prediction set coverage. The authors analyze a Huber-type mixture model where a small fraction of calibration scores come from a different distribution than the bulk. They develop theoretical bounds on coverage degradation and prediction set size changes under contamination using Kolmogorov-Smirnov and Wasserstein distances. The core contribution is the Contamination Robust Conformal Prediction (CRCP) method, which estimates the contamination effect and adjusts the nominal level to construct tighter prediction sets while maintaining coverage.

## Method Summary
The method involves theoretical analysis of coverage and efficiency under contamination, followed by the CRCP adjustment for classification settings. CRCP estimates the function g(q) = F1(q) - F̃(q), which quantifies the difference between clean and contaminated score distributions, and adjusts the quantile threshold to compensate for this difference. The approach uses a Huber contamination model where a fraction ε of calibration data follows distribution π2 while the rest follows π1. Theoretical bounds are provided using Kolmogorov-Smirnov and Wasserstein distances, and experiments validate the method on synthetic data and CIFAR-10N dataset with real-world label noise.

## Key Results
- CRCP maintains coverage close to desired levels (e.g., 90%) even under significant label noise
- Experiments show CRCP produces narrower prediction intervals compared to standard conformal prediction
- CRCP consistently achieves coverage within 2 standard deviations of target across various noise levels
- The method works effectively on both synthetic data and CIFAR-10N dataset with real-world label noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CRCP maintains target coverage under label noise by estimating and adjusting for coverage degradation
- Mechanism: Estimates g(q) = F1(q) - F̃(q) and adjusts quantile threshold to compensate
- Core assumption: Corruption is independent of X|Y
- Break condition: If corruption depends on X|Y, theoretical framework breaks down

### Mechanism 2
- Claim: CRCP produces narrower prediction sets than standard CP under contamination
- Mechanism: Adjusts for over-coverage caused by contamination to select smaller thresholds
- Core assumption: Standard CP over-covers under contamination
- Break condition: If contamination doesn't cause over-coverage, CRCP may not produce narrower sets

### Mechanism 3
- Claim: CRCP provides finite-sample coverage guarantees
- Mechanism: Uses theoretical upper bound B(n,ε) on estimation error of g(S(i))
- Core assumption: Contamination level ε is known or bounded
- Break condition: If ε is unknown and unbounded, theoretical bound cannot be computed

## Foundational Learning

- Concept: Huber contamination model (ε-contamination)
  - Why needed here: Theoretical analysis and CRCP method are built around this specific contamination model
  - Quick check question: In the Huber contamination model, what is the probability that a randomly selected data point is clean?

- Concept: Stochastic dominance (first-order)
  - Why needed here: Used to derive conditions for over-coverage or under-coverage
  - Quick check question: If distribution Π2 first-order stochastically dominates Π1, what relationship holds between their CDFs?

- Concept: Kolmogorov-Smirnov distance and Wasserstein distance
  - Why needed here: Quantify impact of contamination on coverage and prediction set size
  - Quick check question: Which distance (KS or Wasserstein) provides an upper bound on coverage difference between clean and contaminated settings?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> CRCP calibration -> Prediction -> Evaluation
- Critical path: Training data → Classifier training → Calibration data (contaminated) → CRCP estimation → Adjusted threshold → Test data → Prediction sets → Coverage evaluation
- Design tradeoffs:
  - Known vs. unknown contamination level: CRCP requires ε knowledge for theoretical guarantees but can use upper bounds
  - Computational cost: Adds overhead for empirical conditional CDFs and adjustment
  - Robustness vs. efficiency: Tighter ε bounds lead to more aggressive adjustments and narrower sets
- Failure signatures:
  - Coverage significantly below target: Likely under-estimation of contamination or independence assumption violation
  - Prediction sets not narrower: May indicate low contamination level or conservative adjustment
  - High variance in coverage: Could indicate small sample sizes or unstable contamination effect estimation
- First 3 experiments:
  1. Synthetic logistic regression with known contamination: Verify CRCP maintains 90% coverage with narrower sets
  2. Vary contamination level ε: Test CRCP's sensitivity and verify theoretical bounds
  3. CIFAR-10N with different noise patterns: Validate CRCP on real-world label noise data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can CRCP be extended to regression settings beyond classification?
- Basis in paper: Mentioned as future work without detailed methodology
- Why unresolved: Only classification setting is theoretically developed and experimentally validated
- What evidence would resolve it: Concrete algorithm for regression, experimental validation, and theoretical analysis of coverage guarantees

### Open Question 2
- Question: What is the optimal strategy for estimating contamination level ε when unknown?
- Basis in paper: Assumes known ε but acknowledges this is unrealistic
- Why unresolved: Paper assumes known contamination level for theoretical development
- What evidence would resolve it: Practical algorithm for estimating ε, experimental validation, and theoretical analysis of estimation error impact

### Open Question 3
- Question: How does CRCP perform under adversarial contamination patterns?
- Basis in paper: Assumes random contamination independent of previous observations
- Why unresolved: Theoretical framework assumes random contamination following Huber model
- What evidence would resolve it: Experiments comparing random vs. adversarial contamination, theoretical analysis of worst-case scenarios

### Open Question 4
- Question: Can theoretical bounds on coverage degradation be tightened for specific score function families?
- Basis in paper: Provides general bounds that may be conservative for specific cases
- Why unresolved: Theoretical bounds are general but may be conservative for specific practical scenarios
- What evidence would resolve it: Tighter bounds for specific score function families, experimental validation, and analysis of tradeoff between bound tightness and computational complexity

## Limitations

- Theoretical framework assumes contamination level ε is known or can be bounded, which may not hold in practice
- Empirical validation primarily focused on classification tasks with limited exploration of regression settings
- CIFAR-10N dataset, while representing real-world label noise, is still a controlled synthetic dataset rather than truly uncontrolled real-world data

## Confidence

- **High confidence**: Basic mechanism of CRCP adjusting for contamination-induced over-coverage is well-supported by theoretical analysis and experimental results
- **Medium confidence**: Theoretical bounds on coverage degradation and prediction set size change, as these rely on specific distributional assumptions
- **Low confidence**: Assumption that contamination is independent of X|Y in real-world settings, as this is a strong assumption

## Next Checks

1. Test CRCP on regression tasks with heteroscedastic noise to verify generalization beyond classification settings
2. Implement CRCP with unknown ε (using an upper bound) and evaluate sensitivity to overestimation of contamination level
3. Apply CRCP to a truly uncontrolled real-world dataset with known contamination to validate performance in practical scenarios where assumptions may be violated