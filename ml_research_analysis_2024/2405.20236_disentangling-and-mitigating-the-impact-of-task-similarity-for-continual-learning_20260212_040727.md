---
ver: rpa2
title: Disentangling and Mitigating the Impact of Task Similarity for Continual Learning
arxiv_id: '2405.20236'
source_url: https://arxiv.org/abs/2405.20236
tags:
- task
- performance
- transfer
- learning
- retention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how task similarity affects continual learning,
  specifically analyzing the impact of input feature and readout pattern similarity
  on knowledge transfer and retention. The author develops a linear teacher-student
  model with latent structure to analytically demonstrate that high input feature
  similarity combined with low readout similarity is detrimental to both knowledge
  transfer and retention, even when tasks are positively correlated.
---

# Disentangling and Mitigating the Impact of Task Similarity for Continual Learning

## Quick Facts
- arXiv ID: 2405.20236
- Source URL: https://arxiv.org/abs/2405.20236
- Reference count: 40
- Primary result: Analyzes how input feature and readout pattern similarity affect continual learning, showing that high feature similarity with low readout similarity is detrimental even with positive task correlation

## Executive Summary
This paper develops a theoretical framework to analyze how task similarity affects continual learning performance, specifically examining the interplay between input feature similarity and readout pattern similarity. Using a linear teacher-student model with latent structure, the author demonstrates that high input feature similarity combined with low readout similarity leads to catastrophic forgetting and negative transfer, even when tasks are positively correlated. The study then examines common continual learning algorithms, showing that Fisher information metric regularization significantly improves retention without compromising transfer, while other methods like activity gating improve retention at the expense of transfer.

## Method Summary
The paper develops a linear teacher-student model with low-dimensional latent structure to analytically study continual learning. Tasks are generated from latent variables with controlled similarity through linear mixing matrices, allowing decoupling of feature and readout similarity effects. The model assumes over-parameterization (hidden layer size much larger than input size) to enable analytical tractability. Various continual learning algorithms are implemented including weight regularization in Fisher information metric, activity gating, plasticity gating, and input soft-thresholding, with their effects on knowledge transfer and retention systematically analyzed under different task similarity conditions.

## Key Results
- High input feature similarity combined with low readout similarity causes catastrophic forgetting and negative transfer, even with positive task correlation
- Weight regularization in Fisher information metric significantly improves retention without compromising transfer by preserving orthogonal weight directions
- Task-dependent activity gating improves retention at the cost of transfer when gating is sparse, but can improve both when gating is moderate
- Plasticity gating and input soft-thresholding have limited effects in the over-parameterized regime

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High input feature similarity combined with low readout similarity causes catastrophic forgetting and negative transfer, even with positive correlation between tasks.
- Mechanism: When input features are highly aligned (ρa high), the network extracts similar features for both tasks. If readout similarity is low (ρb low), these features are projected in largely different directions, causing interference and poor performance on both tasks.
- Core assumption: Tasks are generated from a low-dimensional latent structure with linear mixing matrices, allowing decoupling of feature and readout similarity effects.
- Evidence anchors:
  - [abstract] "high input feature similarity coupled with low readout similarity is catastrophic for both knowledge transfer and retention"
  - [section] "a combination of high feature similarity and low readout similarity is detrimental to continual learning, resulting in negative transfer and retention performance, even in the presence of a positive correlation between the two tasks in both input features and readout patterns"
  - [corpus] Weak - related papers focus on different aspects of continual learning without addressing this specific mechanism
- Break condition: If the latent structure assumption fails (e.g., tasks don't have low-dimensional latent variables), or if the network architecture significantly alters how feature similarity affects learning (e.g., deep nonlinear networks with hidden layer effects).

### Mechanism 2
- Claim: Weight regularization in the Fisher information metric improves retention without harming transfer by preserving orthogonal weight directions.
- Mechanism: The Fisher information metric identifies directions in weight space that are most sensitive to task performance. Regularizing in this metric allows the network to freeze weights in low-dimensional subspaces (where previous task knowledge is stored) while maintaining plasticity in orthogonal directions for new tasks.
- Core assumption: Over-parameterization (Ns ≪ Nx) allows the network to have sufficient degrees of freedom to freeze weights in low-dimensional subspaces without compromising learning new tasks.
- Evidence anchors:
  - [abstract] "weight regularization based on the Fisher information metric significantly improves retention, regardless of task similarity, without compromising transfer performance"
  - [section] "weight regularization in the Fisher information metric significantly aids retention regardless of task similarity" and "under the Fisher information metric, the retention performance is perfect as long as the condition Ns ≪ Nx(1 − ρ2a) is satisfied"
  - [corpus] Weak - related papers mention Fisher information but don't specifically analyze its benefits in this context
- Break condition: If the over-parameterization assumption breaks (Ns approaches Nx), or if the Fisher information metric is approximated by its diagonal (losing the low-rank structure), the regularization becomes much less effective.

### Mechanism 3
- Claim: Task-dependent activity gating improves retention at the cost of transfer when gating is sparse, but can improve both when gating is moderate.
- Mechanism: Random activity gating scales the effective feature similarity by the gating level α. Low α (sparse gating) reduces interference between tasks (improving retention) but also reduces knowledge transfer. Moderate α can balance both by reducing interference while maintaining sufficient feature overlap.
- Core assumption: The gating level α scales the feature similarity linearly in the random gating model.
- Evidence anchors:
  - [abstract] "task-dependent activity gating improves knowledge retention at the expense of transfer, while task-dependent plasticity gating does not affect either retention or transfer performance at the over-parameterized limit"
  - [section] "random gating scales the feature similarity from ρa to αρa. This scaling lowers the knowledge transfer if ρb ≥ ρa because random gating reduces the fraction of input neurons active in two subsequent tasks"
  - [corpus] Weak - related papers mention activity gating but don't analyze its interaction with task similarity in this specific way
- Break condition: If the gating doesn't scale feature similarity linearly (e.g., in nonlinear networks), or if the gating level α is too high or too low to achieve the desired tradeoff.

## Foundational Learning

- Concept: Linear teacher-student models with low-dimensional latent structure
  - Why needed here: Provides analytical tractability to study how task similarity affects continual learning by decoupling feature and readout similarity
  - Quick check question: How does the low-dimensional latent assumption (Ns ≪ Nx) simplify the analysis of transfer and retention performance?

- Concept: Fisher information metric and its relationship to weight space geometry
  - Why needed here: Explains why weight regularization in this metric is effective for continual learning by identifying sensitive directions in weight space
  - Quick check question: Why does the Fisher information metric allow freezing weights in low-dimensional subspaces while maintaining plasticity in orthogonal directions?

- Concept: Task similarity metrics (feature vs readout similarity)
  - Why needed here: Distinguishes between two ways tasks can be similar, which have asymmetric effects on transfer and retention
  - Quick check question: What is the difference between feature similarity (ρa) and readout similarity (ρb), and how do they asymmetrically affect continual learning performance?

## Architecture Onboarding

- Component map:
  Input data -> Linear mixing matrices -> Latent variables -> Target outputs
  Input data -> Input layer -> Hidden layer (linear/nonlinear) -> Output layer
  Weight matrices connecting layers -> Subject to regularization methods

- Critical path:
  1. Generate tasks with controlled feature and readout similarity using latent variables
  2. Train network on first task, then on second task while monitoring performance
  3. Measure transfer (performance on task 2 after learning task 1) and retention (performance on task 1 after learning task 2)
  4. Apply various continual learning algorithms (gating, regularization) and measure their effects
  5. Analyze results to understand how task similarity interacts with these algorithms

- Design tradeoffs:
  - Low-dimensional latent assumption vs. real-world task complexity
  - Analytical tractability vs. model realism
  - Random vs. adaptive gating (tradeoff between simplicity and performance)
  - Layer-wise vs. diagonal approximation of Fisher information metric (accuracy vs. computational cost)

- Failure signatures:
  - Negative transfer or retention performance indicates harmful task similarity combination
  - Poor performance of diagonal Fisher information approximation suggests importance of full metric
  - Plasticity gating having no effect indicates over-parameterization regime
  - Input soft-thresholding invariance suggests limitations in sparse input regimes

- First 3 experiments:
  1. Implement vanilla linear teacher-student model and verify asymmetric dependence of transfer/retention on (ρa, ρb) combinations
  2. Add random activity gating and test how gating level affects the tradeoff between transfer and retention
  3. Implement weight regularization in Fisher information metric and compare its performance to Euclidean regularization across different task similarities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed linear teacher-student model with latent structure generalize to deeper nonlinear neural networks?
- Basis in paper: [explicit] The authors note that their theoretical insights were tested on a deep nonlinear network solving permuted MNIST tasks, but acknowledge that the diagonal approximation of the Fisher information metric performs better than predicted by their linear model.
- Why unresolved: The authors suggest that sparse activity in the hidden layer may make the regularization low-rank even under the diagonal approximation, but this is speculative. The exact mechanisms by which nonlinear networks interact with task similarity and regularization methods remain unclear.
- What evidence would resolve it: Further theoretical analysis of deeper nonlinear networks, or extensive numerical experiments comparing various regularization methods across different network architectures and datasets.

### Open Question 2
- Question: What are the effects of feature and readout similarity on continual learning in settings beyond image permutation tasks?
- Basis in paper: [explicit] The authors propose that their framework could be applied to analyze continual learning in more complicated neural architectures and datasets, but they only demonstrate this on permuted MNIST with latent variables.
- Why unresolved: The authors acknowledge that image permutation is a relatively benign form of task similarity, and suggest that studying wider benchmarks beyond permuted image recognition tasks is important. However, they do not provide concrete evidence of how their findings generalize to other types of task similarity.
- What evidence would resolve it: Empirical studies of continual learning performance on diverse datasets with varying feature and readout similarities, such as language modeling, reinforcement learning, or multimodal tasks.

### Open Question 3
- Question: How can the proposed framework be extended to handle negative correlations between tasks?
- Basis in paper: [inferred] The authors explicitly state that they focus on tasks with non-negative correlation in terms of both input features and readout patterns, as negative correlations would trivially lead to failure in knowledge transfer.
- Why unresolved: The authors acknowledge that their analysis does not cover the case of negative correlations, which is a common scenario in real-world continual learning problems (e.g., reversal learning, adversarial tasks).
- What evidence would resolve it: Theoretical analysis of the proposed framework under negative correlations, or empirical studies demonstrating the performance of various regularization methods in such settings.

### Open Question 4
- Question: What is the optimal strategy for balancing transfer and retention performance in adaptive activity gating?
- Basis in paper: [explicit] The authors propose an adaptive gating mechanism based on a probe trial, but they do not provide a definitive answer on how to optimally set the gating level for maximizing both transfer and retention performance.
- Why unresolved: The authors show that adaptive gating improves transfer performance compared to random gating, but the tradeoff between transfer and retention remains, and the optimal gating level likely depends on the specific task similarities and regularization methods used.
- What evidence would resolve it: Theoretical analysis of the optimal gating strategy under various task similarity conditions, or empirical studies comparing different adaptive gating mechanisms and their performance across a range of continual learning benchmarks.

## Limitations
- The linear teacher-student model assumes low-dimensional latent structure, which may not capture the complexity of real-world tasks
- Analytical results rely heavily on the over-parameterization assumption (Ns ≪ Nx), which may not hold in all practical scenarios
- The study focuses on two-task scenarios, and results may not generalize to longer task sequences
- Experiments are primarily on synthetic data with controlled task similarity, with limited validation on real-world datasets

## Confidence
- High confidence: The theoretical analysis of how feature and readout similarity asymmetrically affect transfer and retention
- Medium confidence: The effectiveness of Fisher information metric regularization compared to its diagonal approximation
- Medium confidence: The differential effects of activity gating vs plasticity gating on transfer and retention

## Next Checks
1. Test robustness to non-linear architectures: Replicate key experiments with deep nonlinear networks to verify if the asymmetric effects of feature vs readout similarity persist beyond the linear regime
2. Validate over-parameterization limits: Systematically vary the over-parameterization ratio (Ns/Nx) to identify when Fisher information metric regularization loses its effectiveness
3. Extend to multi-task sequences: Implement experiments with 3+ sequential tasks to verify if the two-task findings generalize to longer continual learning scenarios