---
ver: rpa2
title: 'RASTeR: Robust, Agentic, and Structured Temporal Reasoning'
arxiv_id: '2406.19538'
source_url: https://arxiv.org/abs/2406.19538
tags:
- context
- temporal
- reasoning
- question
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RASTeR is a multi-agent framework that separates context evaluation
  from answer generation in temporal question answering. It uses dedicated agents
  to assess relevance and temporal coherence of retrieved context, constructs a temporal
  knowledge graph for structured reasoning, and selectively corrects or discards inconsistent
  context.
---

# RASTeR: Robust, Agentic, and Structured Temporal Reasoning

## Quick Facts
- arXiv ID: 2406.19538
- Source URL: https://arxiv.org/abs/2406.19538
- Authors: Dan Schumacher; Fatemeh Haji; Tara Grey; Niharika Bandlamudi; Nupoor Karnik; Gagana Uday Kumar; Jason Cho-Yu Chiang; Paul Rad; Nishant Vishwamitra; Anthony Rios
- Reference count: 40
- Primary result: Up to 75% accuracy in needle-in-the-haystack settings with forty distractors, over 12% ahead of runner-up

## Executive Summary
RASTeR is a multi-agent framework designed to improve temporal question answering (TQA) under noisy or irrelevant retrieval conditions. It separates context evaluation from answer generation, using dedicated agents to assess relevance and temporal coherence, construct a temporal knowledge graph (TKG), and selectively correct or discard inconsistent context. Tested across four TQA datasets and three LLMs, RASTeR consistently outperforms baselines, especially in distractor-heavy and noisy settings, achieving up to 75% accuracy with forty distractors.

## Method Summary
RASTeR employs a modular prompting pipeline with four main agents: context evaluation, temporal knowledge graph (TKG) construction, context correction, and answer generation. The context evaluation agent assesses the relevance and temporal coherence of retrieved context, filtering out noisy or outdated information. The TKG agent structures retrieved facts into a temporal graph to support reasoning. The context correction agent fixes or removes inconsistencies, and the answer generation agent produces the final response. The method is evaluated on four TQA datasets (MenatQA, TimeSensitiveQA, TempReason, UnSeenTimeQA) with both relevant and irrelevant/ altered contexts.

## Key Results
- RASTeR achieves up to 75% accuracy in needle-in-the-haystack settings with forty distractors, over 12% ahead of runner-up.
- Consistently improves accuracy (EM, Contains Accuracy, F1) across four TQA datasets and three LLMs.
- Excels in noisy retrieval conditions and generalizes to unseen temporal events, outperforming simpler baselines by up to 7% in F1 score.

## Why This Works (Mechanism)
RASTeR's modular separation of context evaluation and answer generation allows for targeted handling of noisy or irrelevant retrieved context, which is a common failure mode in TQA. By constructing a temporal knowledge graph, the system provides structured reasoning support, enabling better handling of complex temporal relationships. The selective correction or discarding of inconsistent context prevents contamination of the answer generation process, leading to more robust performance in distractor-heavy settings.

## Foundational Learning
- **Temporal Knowledge Graphs (TKGs)**: Structured representations of events and their temporal relationships; needed to enable structured reasoning over time-based facts.
  - Quick check: Verify TKG nodes correctly parse dates (YYYY-MM-DD vs. YYYY vs. Month YYYY) and temporal relations.
- **Multi-Agent Prompting**: Decomposing tasks into specialized agents; needed to modularize context evaluation, correction, and generation.
  - Quick check: Confirm each agent's prompt format and few-shot examples are consistent across methods.
- **Context Relevance and Coherence Filtering**: Identifying and removing noisy or outdated context; needed to prevent answer contamination.
  - Quick check: Test context evaluation agent on intentionally corrupted or contradictory temporal contexts.

## Architecture Onboarding

### Component Map
Context Evaluation Agent -> TKG Construction Agent -> Context Correction Agent -> Answer Generation Agent

### Critical Path
1. Retrieve context (potentially noisy/irrelevant)
2. Context evaluation agent filters/assesses relevance and temporal coherence
3. TKG agent structures temporal facts
4. Context correction agent fixes or removes inconsistencies
5. Answer generation agent produces final answer

### Design Tradeoffs
- **Modular vs. monolithic**: Modular design enables targeted handling of noise but increases token usage (4.64x more than single-agent approaches).
- **Structured vs. unstructured reasoning**: TKG provides structured support but depends on LLM accuracy and context quality.
- **Correction vs. discarding**: Selective correction preserves useful context but risks introducing errors if correction is inaccurate.

### Failure Signatures
- Context evaluation misclassifies noisy contexts as relevant, leading to incorrect answers.
- TKG generation omits or hallucinates temporal facts, reducing reasoning quality.
- Context correction introduces errors or fails to fix inconsistencies.

### First 3 Experiments
1. Run RASTeR on a small TQA dataset with artificially added distractors to test context evaluation.
2. Conduct ablation: Remove TKG component and compare accuracy to full RASTeR.
3. Test context evaluation agent on contradictory or ambiguous temporal contexts to find failure thresholds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does RASTeR's performance scale with increasing number of retrieved contexts beyond the tested 40 distractors?
- Basis in paper: [explicit] The paper mentions evaluating up to 40 distractors in the "needle-in-the-haystack" study but does not explore performance beyond this point.
- Why unresolved: The experiments only tested up to 40 distractors, leaving the upper bound of RASTeR's robustness unknown.
- What evidence would resolve it: Testing RASTeR with 50, 100, or 200 distractors would reveal whether its performance plateaus, degrades gracefully, or fails catastrophically.

### Open Question 2
- Question: Can RASTeR's modular agent architecture be effectively parallelized to reduce computational overhead?
- Basis in paper: [inferred] The paper notes that RASTeR uses 4.64x more tokens than single-agent approaches, suggesting potential computational bottlenecks.
- Why unresolved: While the paper acknowledges increased token usage, it does not explore optimization strategies like parallel processing or model distillation.
- What evidence would resolve it: Implementing parallelized versions of RASTeR's agents and measuring both accuracy and token efficiency would determine if overhead can be reduced without sacrificing performance.

### Open Question 3
- Question: How does RASTeR perform on temporal reasoning tasks involving implicit or ambiguous temporal cues?
- Basis in paper: [explicit] The paper notes that temporal reasoning remains challenging, particularly with counterfactual questions requiring hypothetical reasoning against context.
- Why unresolved: The current evaluation focuses on explicit temporal expressions and clear chronological ordering, but real-world questions often contain implicit temporal relationships.
- What evidence would resolve it: Creating a benchmark with questions requiring inference of implicit temporal relationships (e.g., "before/after" without explicit dates) and testing RASTeR's performance would reveal its limitations with ambiguous temporal cues.

## Limitations
- Relies on LLM-based agents for context evaluation and correction, which may not generalize robustly across domains or temporal reasoning tasks beyond those tested.
- TKG construction is dependent on the accuracy of retrieved context and LLM's ability to parse temporal facts without hallucination.
- Does not address scenarios where temporal information is missing from context entirely.

## Confidence
- **High confidence**: The modular multi-agent architecture design and its implementation are clearly described and reproducible. The reported performance improvements across multiple datasets and baselines are consistent and substantial.
- **Medium confidence**: The claim of generalizability to unseen temporal events is supported by the UnSeenTimeQA results, but broader domain testing would strengthen this assertion. The TKG's role in improving reasoning is demonstrated but not deeply analyzed for edge cases.
- **Low confidence**: The impact of specific few-shot examples on performance is not explored, and the robustness of context evaluation agents against adversarial or highly ambiguous temporal queries remains untested.

## Next Checks
1. Test RASTeR on datasets with varying levels of temporal granularity (e.g., year-only vs. exact dates) to assess robustness to date format inconsistencies.
2. Conduct ablation studies removing the TKG component to quantify its specific contribution to accuracy improvements.
3. Evaluate the context evaluation agent's performance on intentionally corrupted or contradictory temporal contexts to identify failure thresholds.