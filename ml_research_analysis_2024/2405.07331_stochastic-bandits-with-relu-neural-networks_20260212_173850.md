---
ver: rpa2
title: Stochastic Bandits with ReLU Neural Networks
arxiv_id: '2405.07331'
source_url: https://arxiv.org/abs/2405.07331
tags:
- neural
- relu
- regret
- linear
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies stochastic bandit learning with ReLU neural
  networks, proposing two algorithms that achieve O(sqrt(T)) regret. The key insight
  is that once the parameters of the ReLU neurons are accurately estimated during
  an exploration phase, the problem can be reduced to a linear bandit in a transformed
  feature space.
---

# Stochastic Bandits with ReLU Neural Networks

## Quick Facts
- arXiv ID: 2405.07331
- Source URL: https://arxiv.org/abs/2405.07331
- Reference count: 40
- Key result: Two algorithms achieve O(sqrt(T)) regret for stochastic bandits with ReLU neural networks

## Executive Summary
This paper studies stochastic bandit learning with ReLU neural networks, proposing two algorithms that achieve O(sqrt(T)) regret. The key insight is that once the parameters of the ReLU neurons are accurately estimated during an exploration phase, the problem can be reduced to a linear bandit in a transformed feature space. The OFU-ReLU algorithm first explores randomly to estimate parameters, then uses UCB-based linear bandit optimization. The OFU-ReLU+ algorithm removes the need for prior knowledge of parameter gaps using a batching strategy. Theoretical analysis shows both algorithms achieve O(sqrt(T)) regret, with the second variant requiring only polynomial dependence on problem parameters. Experiments demonstrate superior performance compared to existing methods like NeuralUCB and linear OFUL.

## Method Summary
The paper proposes two algorithms for stochastic bandits with one-layer ReLU neural networks. OFU-ReLU first explores randomly to estimate network parameters, then converts the problem to a linear bandit in transformed feature space using OFUL. OFU-ReLU+ extends this by using a batching strategy with geometrically decreasing gap estimates to remove the need for prior knowledge of parameter gaps. Both algorithms rely on the insight that accurate parameter estimation enables reduction to linear bandit optimization, with OFU-ReLU+ accumulating data across batches to achieve polynomial dependence on problem parameters when gaps are unknown.

## Key Results
- OFU-ReLU achieves O(sqrt(T)) regret when parameter gaps ν* are known
- OFU-ReLU+ achieves O(k^14 d^7 + k^14 d^3 T^8 log(b)/log(a) + kd sqrt(T)) regret when gaps are unknown
- Experiments show superior performance vs NeuralUCB and linear OFUL baselines
- Exploration phase converges in ~20 time steps for T=1000

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The piecewise linear structure of ReLU activations enables reduction to linear bandit after parameter estimation
- Mechanism: Once neuron parameters are estimated within a threshold (ν*/2), the indicator functions freeze at optimal action, converting the problem to linear bandit in transformed feature space x‡
- Core assumption: ReLU neural network has a positive gap ν* between optimal action and nearest neuron hyperplane
- Evidence anchors:
  - [abstract]: "Our key insight is that we can exploit the piecewise linear structure of ReLU activations and convert the problem into a linear bandit in a transformed feature space, once we learn the parameters of ReLU relatively accurately during the exploration stage."
  - [section 4.1]: "Once we have a sufficiently good estimate ˜θi ≈ θ*i, then our estimate of the indicator is exact: 1 (˜θi⊤x* ≥ 0) = 1 (θ*⊤ix* ≥ 0), ∀i ∈ [k]."
  - [corpus]: Weak - no direct evidence, but related work on linear bandits provides context
- Break condition: If estimation error exceeds ν*/2, indicator functions become inconsistent and linearity breaks down

### Mechanism 2
- Claim: OFU-ReLU+ batching strategy removes need for prior knowledge of parameter gaps through geometric reduction
- Mechanism: Multiple exploration phases with geometrically decreasing gap estimates ensure eventual accuracy, accumulating data across batches without discarding
- Core assumption: Parameter estimation error scales predictably with exploration sample size, allowing geometric progression to reach required accuracy
- Evidence anchors:
  - [abstract]: "To remove dependence on model parameters, we design an OFU-ReLU+ algorithm based on a batching strategy, which can provide the same theoretical guarantee."
  - [section 4.3]: "As long as the estimate ˜θi has an estimation error of θ*i smaller than ν*/2, i.e., ∥˜θi − θ*i∥ ≤ ν*/2, our bandit algorithm will be able to find the optimal action x* in the action space X (˜Θ, ν*/2)"
  - [corpus]: Weak - no direct evidence, batching strategies are mentioned but not for this specific problem
- Break condition: If geometric reduction rate b is too slow relative to batch growth rate a, polynomial regret penalty becomes too large

### Mechanism 3
- Claim: Sign misidentification of neurons can be corrected through additional linear components in transformed feature space
- Mechanism: When ∥˜θi + θ*i∥ ≤ ν*/2, the misspecification is captured by k additional linear features, allowing linear bandit to function correctly
- Core assumption: The misspecification due to sign flip can be expressed as linear combination of transformed features
- Evidence anchors:
  - [section 4.1]: "The other challenge is the sign misidentification from our Theorem 3.2. Specifically, ˜Θ is close to the true parameters Θ* only up to signs."
  - [section 4.1]: "We propose to add additional k delicately designed linear components to (5). We show that the misspecification when ∥˜θi + θ*i∥ ≤ ν*/2 can be captured by a linear structure of k additional transformed features of x"
  - [corpus]: Weak - no direct evidence, this appears to be novel to this work
- Break condition: If both ∥˜θi − θ*i∥ > ν*/2 and ∥˜θi + θ*i∥ > ν*/2, the algorithm cannot guarantee correct indicator estimation

## Foundational Learning

- Concept: Linear bandit theory and UCB algorithms
  - Why needed here: The core reduction from ReLU to linear bandit requires understanding OFUL algorithm guarantees and confidence ellipsoid construction
  - Quick check question: What is the regret bound for OFUL when contextual dimension is d and parameter norm is bounded by S?

- Concept: Neural network parameter estimation and generalization bounds
  - Why needed here: The exploration phase relies on statistical learning theory to bound estimation error of ReLU network parameters
  - Quick check question: How does the sample complexity for estimating one-layer ReLU network parameters scale with dimension d and number of neurons k?

- Concept: Piecewise linear function approximation and boundary analysis
  - Why needed here: Understanding when ReLU networks become linear requires analyzing the geometry of activation boundaries
  - Quick check question: What is the condition for a ReLU neuron θi to be "linear" at point x in terms of θi⊤x?

## Architecture Onboarding

- Component map:
  - Random exploration -> Parameter estimation -> Linear bandit optimization
  - Multiple exploration-OFUL cycles (OFU-ReLU+) with decreasing gap estimates

- Critical path:
  1. Initial random exploration (t0 samples)
  2. Parameter estimation ˜Θ = arg minΘ ˆLS(Θ; Zt0)
  3. Construct transformed features x‡(x, ˜Θ)
  4. Run OFUL on x‡, θ‡ space with confidence ellipsoid Ct
  5. (OFU-ReLU+) Repeat with geometric gap reduction if unknown ν*

- Design tradeoffs:
  - Exploration length vs. regret: Longer exploration improves parameter accuracy but increases initial regret
  - Batch growth rate a vs. gap reduction rate b: Balance between polynomial regret penalty and exploration efficiency
  - Confidence level vs. sample complexity: Higher confidence requires more exploration samples

- Failure signatures:
  - Linear regret in early stages: Insufficient exploration length
  - Suboptimal performance after exploration: Parameter estimation error too large
  - Slow convergence in OFUL phase: Misspecification due to sign misidentification
  - Increasing regret over batches: Incorrect choice of batch growth or gap reduction rates

- First 3 experiments:
  1. Verify parameter estimation error bound with synthetic data on unit sphere
  2. Test OFUL phase with known parameters to confirm linear bandit works in transformed space
  3. Run full OFU-ReLU with small networks to validate ˜O(√T) regret scaling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the OFU-ReLU algorithm be extended to multi-layer ReLU neural networks while maintaining the O(sqrt(T)) regret guarantee?
- Basis in paper: [explicit] The paper focuses on one-layer ReLU neural networks and suggests this as a limitation, noting "A natural extension is to generalize our result to piecewise linear activation functions. It is more challenging to explore whether our insight can be generalized to bandit problems with more complex activation functions or multiple-layer architectures."
- Why unresolved: The theoretical framework relies heavily on the piecewise linear structure of single-layer networks and the ability to transform the problem into a linear bandit once parameters are estimated. Multi-layer networks introduce complex interactions between layers that may not be reducible to linear structures.
- What evidence would resolve it: A theoretical proof showing either (1) the algorithm can be extended to multi-layer networks with the same regret bound, or (2) a lower bound demonstrating that O(sqrt(T)) regret is impossible for multi-layer ReLU bandits.

### Open Question 2
- Question: How does the performance of OFU-ReLU+ scale with the gap ν* when it is extremely small or unknown a priori?
- Basis in paper: [explicit] The OFU-ReLU+ algorithm requires guessing the gap ν* and reducing this guess geometrically. The regret bound shows polynomial dependence on parameters when ν* is unknown, with the regret scaling as O(k^14 d^7 + k^14 d^3 T^8 log(b)/log(a) + kd sqrt(T)).
- Why unresolved: The paper shows theoretical regret bounds but doesn't provide empirical evaluation of how the algorithm performs when ν* is very small or when the initial guess ν0 is far from the true value.
- What evidence would resolve it: Comprehensive experiments varying the true gap ν* and initial guess ν0 across multiple orders of magnitude, measuring both regret and convergence time.

### Open Question 3
- Question: What is the optimal exploration-exploitation trade-off strategy for OFU-ReLU when the time horizon T is not known in advance?
- Basis in paper: [inferred] The current algorithms require fixing the exploration length t0 upfront based on theoretical bounds. The paper mentions that the exploration phase takes "only 20 time steps to converge in a time horizon of T = 1,000" but doesn't address the case where T is unknown.
- Why unresolved: Real-world bandit applications often face unknown or variable time horizons. The current design assumes knowledge of T to set exploration parameters, which may lead to suboptimal performance in practice.
- What evidence would resolve it: An adaptive algorithm that adjusts exploration length based on observed data, with theoretical analysis showing it achieves O(sqrt(T)) regret without knowing T in advance.

## Limitations
- Requires accurate parameter estimation within gap threshold ν*/2 during exploration phase
- OFU-ReLU+ introduces polynomial regret penalty (O(k^14 d^7)) when gaps are unknown
- Theoretical guarantees depend on sufficiently large exploration sample size scaling polynomially with problem parameters
- Limited empirical validation on complex real-world problems

## Confidence
- Reduction to linear bandit mechanism (Mechanism 1): **High** - supported by theoretical analysis and experimental results
- OFU-ReLU+ batching strategy (Mechanism 2): **Medium** - theoretically sound but polynomial regret penalty is a significant practical limitation
- Sign misidentification correction (Mechanism 3): **Medium** - novel approach with limited empirical validation

## Next Checks
1. **Parameter estimation sensitivity**: Systematically vary the exploration sample size t0 and measure the resulting parameter estimation error to verify the claimed bounds hold in practice.
2. **Batching strategy scalability**: Test OFU-ReLU+ on problems with varying dimensions d and neurons k to quantify the polynomial regret penalty across different problem scales.
3. **Comparison with baseline methods**: Conduct head-to-head experiments comparing OFU-ReLU variants against NeuralUCB and linear methods across multiple problem instances to validate the claimed performance improvements.