---
ver: rpa2
title: 'VALD-MD: Visual Attribution via Latent Diffusion for Medical Diagnostics'
arxiv_id: '2401.01414'
source_url: https://arxiv.org/abs/2401.01414
tags:
- image
- healthy
- medical
- visual
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents VALD-MD, a novel generative visual attribution
  technique that leverages latent diffusion models combined with domain-specific large
  language models to generate normal counterparts of abnormal medical images. This
  approach enables the identification of diagnostically-relevant components by computing
  the discrepancy between the original abnormal image and its generated healthy counterpart.
---

# VALD-MD: Visual Attribution via Latent Diffusion for Medical Diagnostics

## Quick Facts
- arXiv ID: 2401.01414
- Source URL: https://arxiv.org/abs/2401.01414
- Authors: Ammar A. Siddiqui; Santosh Tirunagari; Tehseen Zia; David Windridge
- Reference count: 40
- Generates counterfactual healthy images from abnormal medical images using latent diffusion models

## Executive Summary
VALD-MD introduces a novel approach to visual attribution in medical diagnostics by generating counterfactual healthy images from abnormal medical images using latent diffusion models combined with domain-specific language models. The system enables identification of diagnostically-relevant components by computing the discrepancy between original abnormal images and their generated healthy counterparts. The method was evaluated on COVID-19 Radiography Database and demonstrated visually plausible counterfactuals with minimal perturbations, while also exhibiting zero-shot capabilities for localized disease induction.

## Method Summary
VALD-MD fine-tunes a latent diffusion model (CompVis/stable-diffusionv1-4) with a domain-adapted text encoder (RadBERT) on medical imaging datasets. The approach encodes medical images into latent space, applies text-conditioned denoising to generate counterfactual healthy images, then computes difference maps by subtracting the generated image from the original. The system uses DreamBooth fine-tuning with 2700 total training steps, 512x512px resolution, batch size 2, and learning rate 5e-05, evaluated using FID, SSIM, and MS-SSIM metrics.

## Key Results
- Generated healthy counterfactuals achieved FID scores ranging from 27.8 to 37.63 across different disease classes
- System demonstrated visually plausible counterfactuals with minimal perturbations to original images
- Exhibited zero-shot localized disease induction capabilities validated on cheXpert dataset
- Difference maps effectively highlighted diagnostically-relevant components through masked subtraction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Latent diffusion models enable high-fidelity generation of counterfactual medical images with minimal structural perturbation
- Mechanism: The approach uses an autoencoder to encode medical images into a spatial latent code, applies stochastic noise perturbations in latent space, and learns a reverse denoising process to generate images that preserve overall structure while modifying only diagnostically-relevant regions
- Core assumption: Noise perturbation in latent space maintains perceptual equivalence to image space and preserves structural integrity of healthy tissue
- Evidence anchors:
  - [abstract]: "The resulting system also exhibits visually plausible counterfactuals with minimal perturbations to original images"
  - [section]: "The healthy/non-healthy discrepancy maps in all of these cases are obtained via masked subtraction of the original image from the generated image"
  - [corpus]: Weak evidence - related papers focus on general latent diffusion applications but lack specific validation for medical counterfactual generation

### Mechanism 2
- Claim: Joint fine-tuning of domain-adapted text encoder with vision encoder enables controlled counterfactual generation via natural language prompts
- Mechanism: The RadBERT text encoder maps medical terminology to intermediate representations that condition the UNet denoising process through cross-attention layers, allowing generation guided by specific medical concepts
- Core assumption: The domain-adapted text encoder captures sufficient medical semantics to guide image generation without requiring direct training on synthetic data
- Evidence anchors:
  - [abstract]: "leverages domain-specific large language models to generate normal counterparts of abnormal images"
  - [section]: "training domain-specific language and vision