---
ver: rpa2
title: Generalising Planning Environment Redesign
arxiv_id: '2402.07799'
source_url: https://arxiv.org/abs/2402.07799
tags:
- environment
- planning
- redesign
- goal
- metrics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of planning environment redesign,
  where an observer seeks to modify an environment to affect an agent's behavior.
  The authors propose a general approach that is metric-agnostic and can optimize
  various redesign metrics beyond goal and plan recognition.
---

# Generalising Planning Environment Redesign

## Quick Facts
- arXiv ID: 2402.07799
- Source URL: https://arxiv.org/abs/2402.07799
- Authors: Alberto Pozanco; Ramon Fraga Pereira; Daniel Borrajo
- Reference count: 7
- Key outcome: GER is orders of magnitude faster than GRD-LS for Goal Recognition Design while being effective at optimizing novel redesign metrics like Goal Privacy and Minimise Average Distance.

## Executive Summary
This paper addresses the problem of planning environment redesign, where an observer seeks to modify an environment to affect an agent's behavior. The authors propose GER, a general approach that is metric-agnostic and can optimize various redesign metrics beyond goal and plan recognition. GER uses a Breadth-First Search algorithm and leverages recent research on top-quality planning to efficiently compute a plan-library for pruning the search space. Experiments show that GER outperforms existing approaches for Goal Recognition Design and is effective at optimizing novel redesign metrics like Goal Privacy and Minimise Average Distance.

## Method Summary
GER is a general approach for planning environment redesign that uses an anytime Breadth-First Search (BFS) algorithm. It computes a plan-library P(E, b) using a top-quality planner like SYM-K, which contains all relevant plans up to a sub-optimality bound b. GER then prunes the action space to only those actions appearing in the plan-library and explores the space of environment modifications using BFS. The search can be stopped based on various conditions like time limit or memory limit. GER is metric-agnostic and can optimize any of the eight defined redesign metrics by evaluating each candidate environment modification using the appropriate metric function.

## Key Results
- GER is orders of magnitude faster than GRD-LS for Goal Recognition Design (Goal Transparency metric).
- GER is effective at optimizing novel redesign metrics like Goal Privacy (maximizing wcnd) and Minimise Average Distance (minimizing avgD).
- GER's anytime BFS search with dynamic stopping condition allows trade-offs between solution quality and computational resources.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using a plan-library computed by top-quality planning dramatically reduces the search space by pruning actions that never appear in optimal plans for any goal.
- Mechanism: The GETALLOWED MODIFICATIONS function filters the action space to only those actions appearing in P(E, b), so GER only considers environment modifications that can actually affect the metric.
- Core assumption: The plan-library P(E, b) contains all relevant plans up to the sub-optimality bound b, and actions not in P(E, b) have no impact on the chosen metric.
- Evidence anchors:
  - [abstract] "GER exploits recent advances in top-quality planning to efficiently compute plan-libraries for pruning the space of modifications."
  - [section] "GER only reasons over the actions in the plan-library P(E, b) for optimising GT (wcd), GP (wcnd), PT (wcpd) or PP (wcpnd), as removing actions that do not appear in the plan-library does not affect these metrics."
- Break condition: If the sub-optimality bound b is too low, P(E, b) may miss important plans, leading to incomplete search.

### Mechanism 2
- Claim: GER's metric-agnostic BFS framework allows efficient optimization of a wide variety of redesign metrics without metric-specific pruning rules.
- Mechanism: GER evaluates each candidate environment modification using the EVALUATE function, which can compute any of the eight defined metrics, and compares against the best found so far (m+) to decide whether to keep the solution.
- Core assumption: All metrics can be evaluated efficiently given a plan-library and the current set of removed actions.
- Evidence anchors:
  - [abstract] "GER is metric-agnostic and employs an anytime Breadth-First Search (BFS) algorithm that exploits recent research on top-quality planning to improve the search efficiency."
  - [section] "GER returns the set of best solutions found M until C is triggered, i.e., the set of different environment modifications that optimises a redesign metric Mb, yielding a redesigned environment with metric value m+."
- Break condition: For distance-based metrics, GER must evaluate the entire set of states in optimal plans, which can be expensive and dominate runtime.

### Mechanism 3
- Claim: GER's anytime BFS search with dynamic stopping condition C allows trade-offs between solution quality and computational resources.
- Mechanism: The stopping condition C can be a time limit, memory limit, or improvement ratio, enabling GER to return the best found solution when resources are exhausted.
- Core assumption: Even incomplete searches can find useful solutions, and the anytime nature means the longer GER runs, the better the solution.
- Evidence anchors:
  - [abstract] "GER employs an anytime Breadth-First Search (BFS) algorithm."
  - [section] "We generalise the stopping conditions in the literature and assume C can represent any formula, such as a time limit or memory limit, a bound on the number of removed actions, or an improvement ratio of the metric with respect to its original value."
- Break condition: If C is too restrictive (e.g., very short time limit), GER may return suboptimal solutions or fail to improve the metric at all.

## Foundational Learning

- Concept: Planning Domain Definition Language (PDDL)
  - Why needed here: The benchmarks and environment definitions are encoded in PDDL, so understanding this format is essential for interpreting the experiments and modifying domains.
  - Quick check question: What are the five basic elements of a PDDL domain file, and how do they map to the ⟨F, A, SI⟩ structure used in the paper?

- Concept: Breadth-First Search (BFS) algorithm
  - Why needed here: GER uses BFS to explore the space of environment modifications; understanding BFS properties (completeness, optimality) helps reason about GER's theoretical guarantees.
  - Quick check question: In what order does BFS expand nodes, and why does this guarantee finding the minimal number of action removals (|A¬|) first?

- Concept: Top-quality planning and plan-library computation
  - Why needed here: GER relies on SYM-K to compute P(E, b); understanding how top-quality planners work and what sub-optimality bounds mean is crucial for setting up experiments and interpreting results.
  - Quick check question: If b=1.0, what type of plans are included in P(E, b), and how does increasing b affect the size and quality of the plan-library?

## Architecture Onboarding

- Component map: Input R = ⟨E, Mb⟩, C -> TOP QUALITY PLANNER (SYM-K) -> GETALLOWED MODIFICATIONS -> BFS search engine -> EVALUATE -> Output M, m+

- Critical path:
  1. Compute plan-library P(E, b) with SYM-K
  2. Determine allowed modifications amod
  3. Initialize BFS structures (OPEN queue, M set, m+)
  4. Iteratively dequeue best node, generate successors, evaluate, and update M
  5. Stop when C is met, return M and m+

- Design tradeoffs:
  - Computing full plan-library ensures completeness but can be expensive; using only a subset trades completeness for speed.
  - Reasoning over all actions vs. only plan-library actions: broader search space but more expensive for distance metrics.
  - Anytime nature allows early stopping but may yield suboptimal solutions if resources are limited.

- Failure signatures:
  - No improvement found (m+ = m0) despite time/memory budget: likely due to restrictive plan-library or overly conservative stopping condition.
  - GER spends all time computing plan-library and never searches: indicates need to balance plan-library computation time vs. search time.
  - Memory overflow when computing plan-library: suggests reducing bound b or number of plans stored.

- First 3 experiments:
  1. Run GER on a simple BLOCKS benchmark with GT metric, b=1.0, time limit=60s; verify it improves wcd and is faster than GRD-LS.
  2. Test GER with PP metric on GRID benchmark, b=1.0, time limit=120s; check that wcnd is maximized and search space is pruned.
  3. Experiment with MINAVGD metric on IPC-GRID, b=1.0, time limit=300s; confirm that avgD is minimized and execution time scales with plan-library size.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can GER's performance be improved by developing heuristics to prioritize removing actions belonging to a higher number of plans in the plan-library when optimizing goal transparency?
- Basis in paper: Explicit - The paper mentions this as a potential future direction for improving GER's performance.
- Why unresolved: This is an open question because the authors have not yet implemented or tested such heuristics, and their effectiveness is unknown.
- What evidence would resolve it: Experimental results comparing GER's performance with and without these heuristics on various planning domains and metrics would provide evidence for their effectiveness.

### Open Question 2
- Question: How can GER balance the time allocated to compute the plan-library and the time to search in the space of modifications?
- Basis in paper: Explicit - The paper discusses the trade-off between computing the plan-library and searching for environment modifications, suggesting that in some cases, computing a subset of plans might be more efficient than computing the entire plan-library.
- Why unresolved: This is an open question because the optimal balance between plan-library computation and search time depends on the specific problem and domain, and the authors have not yet determined the best approach.
- What evidence would resolve it: Experimental results comparing GER's performance with different time allocations for plan-library computation and search on various planning domains and metrics would provide evidence for the optimal balance.

### Open Question 3
- Question: How can planning environment redesign be made more general by allowing other modifications beyond actions' removal, such as removing or adding objects or predicates from the initial state?
- Basis in paper: Explicit - The paper mentions this as a potential future direction for making the problem formulation more general.
- Why unresolved: This is an open question because the authors have not yet implemented or tested these additional types of modifications, and their impact on the environment redesign process is unknown.
- What evidence would resolve it: Experimental results comparing GER's performance with different types of modifications (e.g., object removal, predicate addition) on various planning domains and metrics would provide evidence for the effectiveness of these modifications.

## Limitations

- The efficiency gains over GRD-LS are only validated for Goal Transparency metrics, not for the novel privacy and distance metrics.
- The completeness guarantee when using bounded sub-optimality is not thoroughly explored, and the relationship between the sub-optimality bound b and metric optimization quality is unclear.
- The computational complexity for distance-based metrics is acknowledged to be potentially prohibitive, but the breaking points are not identified.

## Confidence

- Confidence: Medium for efficiency claims, High for metric-agnostic framework description

## Next Checks

1. Compare GER against GRD-LS on all eight metrics across the benchmark suite, not just Goal Transparency, to validate consistent efficiency gains.
2. Conduct ablation studies varying the sub-optimality bound b to quantify the tradeoff between completeness and computational efficiency.
3. Test GER on larger, more complex planning domains to evaluate scalability and identify breaking points for distance-based metrics.