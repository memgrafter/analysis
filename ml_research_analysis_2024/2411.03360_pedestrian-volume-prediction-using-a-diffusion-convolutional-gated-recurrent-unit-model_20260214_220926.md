---
ver: rpa2
title: Pedestrian Volume Prediction Using a Diffusion Convolutional Gated Recurrent
  Unit Model
arxiv_id: '2411.03360'
source_url: https://arxiv.org/abs/2411.03360
tags:
- data
- pedestrian
- dcgru
- forecasting
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses pedestrian volume forecasting using a diffusion
  convolutional gated recurrent unit model enhanced with dynamic time warping (DCGRU-DTW).
  The method captures spatial dependencies through a diffusion process and temporal
  dependencies via a gated recurrent unit, while incorporating time series similarity
  to construct an adjacency matrix for the graph neural network.
---

# Pedestrian Volume Prediction Using a Diffusion Convolutional Gated Recurrent Unit Model

## Quick Facts
- arXiv ID: 2411.03360
- Source URL: https://arxiv.org/abs/2411.03360
- Reference count: 28
- Key outcome: DCGRU-DTW outperforms baseline models on Melbourne pedestrian data with MAPE of 25.81% for 1-hour forecasts using 168-hour input

## Executive Summary
This study addresses pedestrian volume forecasting using a diffusion convolutional gated recurrent unit model enhanced with dynamic time warping (DCGRU-DTW). The method captures spatial dependencies through a diffusion process and temporal dependencies via a gated recurrent unit, while incorporating time series similarity to construct an adjacency matrix for the graph neural network. Experiments on Melbourne pedestrian counting data show the proposed DCGRU-DTW model outperforms both the classic vector autoregressive model and the original DCGRU across multiple accuracy metrics. With an input length of 168 hours, DCGRU-DTW achieved a mean absolute percentage error of 25.81% when forecasting one hour ahead, compared to 26.66% for DCGRU and 27.91% for GRU.

## Method Summary
The DCGRU-DTW model combines diffusion convolution with gated recurrent units to capture spatio-temporal patterns in pedestrian flow. The approach uses a sequence-to-sequence framework where the encoder processes historical pedestrian counts through diffusion convolutional GRU layers, while the decoder generates multi-step forecasts. A key innovation is the construction of the adjacency matrix using both geographic proximity and time series similarity measured by dynamic time warping (DTW). The model employs scheduled sampling during training to mitigate error accumulation in multi-step forecasts, and processes data using sliding windows with input lengths of 5 or 168 hours to capture daily and weekly periodicity.

## Key Results
- DCGRU-DTW achieved MAPE of 25.81% for 1-hour forecasts using 168-hour input window
- Model outperformed DCGRU (MAPE 26.66%) and standard GRU (MAPE 27.91%) across all forecasting horizons
- Performance advantage increased with longer forecasting horizons (5-hour forecasts: MAPE 36.55% vs 37.43% vs 39.48%)
- Longer input window (168 hours) significantly improved accuracy compared to shorter window (5 hours)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DCGRU-DTW captures spatial dependencies more accurately than DCGRU by integrating time series similarity into the adjacency matrix.
- Mechanism: The model uses Dynamic Time Warping (DTW) distances between sensor time series to augment the geographic adjacency matrix. This allows the diffusion convolution to weight neighbor influence based on pattern similarity rather than just physical proximity.
- Core assumption: Pedestrians moving between two sensors exhibit correlated temporal patterns even if the sensors are geographically distant.
- Evidence anchors:
  - [abstract] "leverage DTW, a robust time series similarity measure, as additional information in constructing the adjacency matrix"
  - [section 3.1] "in order to better capture the relationship among pedestrian counting sensors, this study proposes to incorporate the distance of two time series, besides the distance based on geographical information"
  - [corpus] Weak evidence; corpus contains related GNN traffic models but none explicitly use DTW for pedestrian data.
- Break condition: If pedestrian movement patterns are independent across locations (no temporal correlation between sensors), DTW contributions become noise.

### Mechanism 2
- Claim: The sequence-to-sequence framework with scheduled sampling mitigates error accumulation in multi-step forecasting.
- Mechanism: Scheduled sampling replaces ground truth inputs with model predictions during training with probability 1-ϵᵢ, reducing the discrepancy between training and inference behavior and preventing error propagation.
- Core assumption: Exposure to predicted sequences during training improves the model's ability to recover from its own errors during inference.
- Evidence anchors:
  - [section 3.3] "Scheduled sampling (Bengio et al., 2015) is used to mitigate the cumulative error problem... by no longer completely using true labels as inputs at each timestamp during training"
  - [section 4.2] "Scheduled sampling alleviates this problem by no longer completely using true labels as inputs at each timestamp during training"
  - [corpus] Weak evidence; related works mention sequence-to-sequence but not specifically scheduled sampling for pedestrian prediction.
- Break condition: If the model becomes overconfident in its predictions and the sampling schedule is too aggressive, training instability may occur.

### Mechanism 3
- Claim: Using a longer input window (168 hours) captures weekly periodicity and significantly improves forecasting accuracy.
- Mechanism: The GRU cells in both encoder and decoder learn long-term dependencies when provided with full weekly cycles, enabling better modeling of daily and weekly traffic patterns.
- Core assumption: Pedestrian volumes exhibit strong weekly periodicity that can be exploited for forecasting.
- Evidence anchors:
  - [section 4.3] "it is found that the prediction accuracy could be further improved by increasing the input length so that daily and weekly trends are captured"
  - [section 4.2] "In order to take advantage of the daily and weekly periodicity of the data, we increase Linput to 168"
  - [corpus] Weak evidence; corpus contains periodicity-aware models but none specifically benchmark input length effects for pedestrian data.
- Break condition: If pedestrian behavior becomes less periodic (e.g., due to special events or changing patterns), the fixed weekly window may capture irrelevant information.

## Foundational Learning

- Concept: Graph Neural Networks and diffusion convolution
  - Why needed here: Pedestrian sensors form a spatial graph where diffusion convolution aggregates information from neighbors based on learned transition probabilities
  - Quick check question: How does the diffusion process in Equation (4) differ from standard graph convolution?
- Concept: Dynamic Time Warping for time series similarity
  - Why needed here: DTW measures similarity between pedestrian flow patterns at different locations, capturing temporal misalignment
  - Quick check question: Why is DTW more appropriate than Euclidean distance for comparing pedestrian time series?
- Concept: Gated Recurrent Units for temporal modeling
  - Why needed here: GRU cells capture both short-term and long-term temporal dependencies in pedestrian flow sequences
  - Quick check question: What roles do the reset and update gates play in controlling information flow?

## Architecture Onboarding

- Component map: Input time series → DTW-based adjacency matrix construction → Diffusion convolutional GRU encoder → Scheduled sampling → Diffusion convolutional GRU decoder → Multi-step predictions
- Critical path: Data preprocessing → Adjacency matrix computation (geographic + DTW) → Model training with scheduled sampling → Multi-step forecasting
- Design tradeoffs: DTW computation is expensive but improves spatial modeling; longer input windows improve accuracy but increase computational cost
- Failure signatures: Poor performance on geographically distant but temporally similar sensors suggests DTW weighting is insufficient; error accumulation indicates scheduled sampling schedule needs adjustment
- First 3 experiments:
  1. Compare DCGRU-DTW with and without DTW component using Linput=168
  2. Vary the DTW weighting parameter β to find optimal balance between geographic and temporal similarity
  3. Test different scheduled sampling probabilities to minimize error accumulation in 5-hour forecasts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the DCGRU-DTW model perform on pedestrian datasets from different cities with varying urban layouts and pedestrian behaviors?
- Basis in paper: [inferred] The paper focuses exclusively on Melbourne pedestrian data without exploring cross-city validation.
- Why unresolved: The study only validates the model on Melbourne data, leaving its generalizability to other urban contexts untested.
- What evidence would resolve it: Testing the model on pedestrian datasets from multiple cities with different urban characteristics and comparing performance metrics.

### Open Question 2
- Question: What is the optimal balance between geographic and time series similarity weights (β) for different types of urban environments?
- Basis in paper: [explicit] The paper mentions β as a hyperparameter but doesn't explore how its optimal value varies across different urban contexts.
- Why unresolved: The paper uses a single β value across all experiments without investigating how this parameter should be tuned for different cities or environments.
- What evidence would resolve it: Systematic experimentation with varying β values across different urban environments and analyzing performance changes.

### Open Question 3
- Question: How does the DCGRU-DTW model perform during extreme weather events or unusual circumstances that significantly impact pedestrian behavior?
- Basis in paper: [inferred] The paper mentions anomalous data patterns were removed but doesn't specifically test model performance during extreme conditions.
- Why unresolved: The study focused on normal operating conditions and removed anomalous data, leaving the model's robustness to extreme events untested.
- What evidence would resolve it: Testing the model on data from extreme weather events or other unusual circumstances and comparing its performance to baseline methods.

## Limitations
- Study focuses exclusively on Melbourne data with 30 sensors, limiting generalizability to other cities
- DTW computation is computationally expensive and may not scale well to larger sensor networks
- Performance depends on weekly periodicity assumption which may not hold under changing urban dynamics

## Confidence
**High confidence**: The seq2seq architecture with diffusion convolutional GRUs is technically sound; the evaluation metrics and comparative framework are appropriate.

**Medium confidence**: The DTW-based adjacency construction improves performance; scheduled sampling mitigates error accumulation; longer input windows capture useful periodicity.

**Low confidence**: The specific weighting between geographic and temporal adjacency components is optimal; the model generalizes to different geographic contexts; the anomaly detection method robustly identifies all relevant outliers.

## Next Checks
1. **Ablation study**: Train and evaluate DCGRU variants with: (a) geographic adjacency only, (b) DTW adjacency only, (c) combined adjacency. This isolates whether DTW contributes meaningfully beyond geographic information.

2. **Sensitivity analysis**: Systematically vary the DTW weighting parameter β and the geographic threshold κ across multiple values to identify performance sensitivity and optimal operating points.

3. **Generalization test**: Apply the trained DCGRU-DTW model to pedestrian data from a different city or time period (e.g., 2020 Melbourne data during COVID-19) to assess whether performance gains persist under different conditions.