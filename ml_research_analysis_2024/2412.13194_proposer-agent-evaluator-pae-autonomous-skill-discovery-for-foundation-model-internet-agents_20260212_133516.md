---
ver: rpa2
title: 'Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model
  Internet Agents'
arxiv_id: '2412.13194'
source_url: https://arxiv.org/abs/2412.13194
tags:
- task
- agents
- agent
- tasks
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Proposer-Agent-Evaluator (PAE) is a framework for autonomous skill
  discovery in foundation model agents, addressing the limitation of manually specifying
  tasks. It uses context-aware task proposers to generate feasible tasks, an agent
  policy to attempt them, and an image-based evaluator to provide reward signals.
---

# Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents
## Quick Facts
- arXiv ID: 2412.13194
- Source URL: https://arxiv.org/abs/2412.13194
- Reference count: 40
- Key outcome: PAE achieves over 30% relative improvement in zero-shot success rates for web navigation agents, outperforming Qwen2VL-72B with LLaVa-1.6-7B.

## Executive Summary
Proposer-Agent-Evaluator (PAE) is a framework for autonomous skill discovery in foundation model agents that addresses the limitation of manually specifying tasks. It uses context-aware task proposers to generate feasible tasks, an agent policy to attempt them, and an image-based evaluator to provide reward signals. The framework significantly improves zero-shot generalization for vision-based web navigation agents, achieving over 30% relative improvement in success rates on unseen tasks and websites. On WebVoyager and WebArena benchmarks, PAE with LLaVa-1.6-7B outperforms prior state-of-the-art open-source VLM agents, including Qwen2VL-72B, with an absolute gain of over 10% in success rates.

## Method Summary
PAE employs a three-component architecture where a context-aware task proposer generates feasible tasks based on the current state, an agent policy attempts these tasks using vision-language understanding, and an image-based evaluator provides reward signals based on task completion. The framework operates without human supervision, discovering and refining skills through repeated task attempts and evaluations. This autonomous approach allows the agent to explore and master web navigation skills across diverse websites and task types without requiring manual task specification or extensive fine-tuning on specific websites.

## Key Results
- Achieved over 30% relative improvement in zero-shot success rates on unseen tasks and websites
- LLaVa-1.6-7B with PAE outperformed Qwen2VL-72B with absolute gain of over 10% on WebVoyager and WebArena benchmarks
- Demonstrated effective generalization to real-world human-annotated tasks without human supervision

## Why This Works (Mechanism)
The PAE framework works by creating a self-improving loop where task generation, execution, and evaluation are continuously refined. The context-aware proposer generates tasks that are both challenging and feasible given the agent's current capabilities, preventing the agent from attempting impossible tasks while still pushing its boundaries. The image-based evaluator provides immediate, granular feedback on task completion, enabling the agent to learn from partial successes and failures. This closed-loop system allows the agent to discover useful skills autonomously through trial and error, rather than requiring manual task specification or extensive supervised fine-tuning on specific websites.

## Foundational Learning
- Vision-language foundation models (needed for understanding both visual web content and language instructions; quick check: model can correctly interpret web page elements and natural language commands)
- Zero-shot generalization (needed for applying learned skills to unseen tasks and websites; quick check: agent succeeds on tasks from completely new websites without additional training)
- Reinforcement learning from visual feedback (needed for learning through trial and error without explicit rewards; quick check: agent improves performance through repeated task attempts and evaluator feedback)
- Task decomposition and planning (needed for breaking down complex web navigation into manageable steps; quick check: agent can successfully complete multi-step tasks by executing appropriate sub-actions)
- Context-aware task generation (needed for proposing relevant and achievable tasks; quick check: proposer generates tasks appropriate to the current web page context and agent capabilities)

## Architecture Onboarding
- Component Map: Task Proposer -> Agent Policy -> Image Evaluator -> Reward Signal
- Critical Path: Task proposal → agent execution → image evaluation → reward → policy update
- Design Tradeoffs: Autonomous task generation vs. potential exploration inefficiency; vision-based evaluation vs. language-only approaches; zero-shot generalization vs. potential for specialized fine-tuning
- Failure Signatures: Proposer generates infeasible tasks; evaluator provides ambiguous or incorrect rewards; agent fails to execute basic navigation commands; reward signal doesn't correlate with actual task success
- First Experiments: 1) Test task proposer on diverse web pages to verify context-awareness and feasibility generation 2) Evaluate image evaluator's ability to distinguish completed vs incomplete tasks across different website layouts 3) Measure agent's zero-shot performance on completely unseen websites compared to baseline models

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focused on vision-based web navigation tasks, limiting generalizability to other domains
- Success rates, while improved, still leave room for enhancement in real-world deployment scenarios
- Performance on completely novel websites or tasks beyond tested benchmarks remains unclear

## Confidence
- High confidence: Core PAE framework design and implementation details are well-documented and reproducible
- Medium confidence: Generalization claims to unseen tasks and websites are supported but would benefit from broader testing
- Medium confidence: Comparative advantage over Qwen2VL-72B is demonstrated but evaluation scope is limited

## Next Checks
1. Test PAE on diverse real-world websites and task types beyond current benchmarks to assess true generalization capabilities and identify potential failure modes
2. Evaluate PAE's performance when integrated with different foundation model architectures and sizes to determine optimal configurations and scalability limits
3. Conduct ablation studies to quantify individual contributions of proposer, agent, and evaluator components to overall performance improvements