---
ver: rpa2
title: Predicting the structure of dynamic graphs
arxiv_id: '2401.04280'
source_url: https://arxiv.org/abs/2401.04280
tags:
- time
- graph
- edges
- graphs
- vertices
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to forecast the structure of dynamic
  graphs at future time steps, including new nodes and edges. The core idea is to
  adapt Flux Balance Analysis (FBA), a technique from biochemistry used to reconstruct
  metabolic networks, for graph forecasting.
---

# Predicting the structure of dynamic graphs

## Quick Facts
- arXiv ID: 2401.04280
- Source URL: https://arxiv.org/abs/2401.04280
- Authors: Sevvandi Kandanaarachchi, Ziqi Xu, Stefan Westerlund
- Reference count: 27
- Key outcome: Method forecasts dynamic graph structure including new nodes/edges using adapted FBA approach, outperforming baseline across node, edge, and density errors

## Executive Summary
This paper proposes a novel method to forecast the structure of dynamic graphs at future time steps, including the addition of new nodes and edges. The core innovation is adapting Flux Balance Analysis (FBA), a technique from biochemistry used to reconstruct metabolic networks, for graph forecasting. The method combines time series forecasting of node degrees with a linear programming approach inspired by FBA to determine future graph structures. The approach is evaluated on both synthetic and real-world datasets, showing better performance than using the last seen graph for forecasting across multiple time steps into the future.

## Method Summary
The method first forecasts node degrees at future time points using time series methods like ARIMA. These forecasts serve as constraints in a linear programming formulation inspired by FBA, which determines the structure of the future graph. The method uses historical graph data to construct a union graph and incidence matrix, then applies one of six coefficient schemes to weight potential edges in the optimization. Two formulations (F1 and F2) provide flexibility in balancing individual node degree accuracy versus global edge count realism. The optimization produces a binary adjacency matrix representing the forecasted graph structure.

## Key Results
- The method achieves lower node, edge, and density errors compared to the baseline approach across multiple time steps into the future
- On synthetic PA dataset, the method achieves node error of 0 with C1 coefficients and F1 formulation
- On real FB dataset, the method outperforms baseline with C5 coefficients and F2 formulation

## Why This Works (Mechanism)

### Mechanism 1
The adapted FBA approach works because it transforms the graph forecasting problem into a constrained optimization over binary edge variables, with degree forecasts providing soft constraints. By using degree forecasts from time series methods as upper bounds in the linear programming constraints, the method ensures that the solution space is non-empty and that feasible graphs can be found. The optimization then selects the most probable graph structure by maximizing a weighted sum of edge presence indicators.

### Mechanism 2
The coefficient schemes (C1-C6) encode temporal and structural patterns from historical data to bias the graph forecast toward more plausible structures. Each coefficient scheme assigns weights to potential edges based on their historical presence, recency, or connectivity to popular nodes. These weights become the objective function coefficients in the optimization, steering the solution toward graphs that resemble past dynamics.

### Mechanism 3
The two formulations (F1 and F2) provide flexibility in controlling the trade-off between individual node degree accuracy and global edge count realism. F1 enforces degree upper bounds for each node, while F2 adds a global constraint on the total number of edges. This allows the model to adapt to different forecasting needs: strict degree control vs. overall graph density realism.

## Foundational Learning

- Concept: Time series forecasting with ARIMA models
  - Why needed here: To generate degree forecasts for each node, which serve as constraints in the FBA optimization
  - Quick check question: How do ARIMA models handle non-stationary time series data in the context of node degree forecasting?

- Concept: Linear programming and constraint satisfaction
  - Why needed here: To solve the FBA-inspired optimization problem under the degree and edge count constraints
  - Quick check question: What conditions must the constraint matrix satisfy to guarantee a non-empty feasible region for binary variables?

- Concept: Graph theory basics (adjacency, incidence matrices, degree sequences)
  - Why needed here: To understand how the method encodes graph structure and degree constraints mathematically
  - Quick check question: Why does the incidence matrix have zeros in some columns, and how does this relate to non-edges?

## Architecture Onboarding

- Component map: Data Ingestion -> Time Series Module -> Graph Union Builder -> Coefficient Generator -> Optimizer -> Evaluation
- Critical path: Input → Degree Forecast → Coefficient Generation → Optimization → Output Graph → Evaluation
- Design tradeoffs: Choice of coefficient scheme vs. forecasting accuracy, use of F1 vs. F2 formulation for balancing local vs. global constraints, upper bound percentile selection for degree forecasts
- Failure signatures: Empty solution space (no feasible graph), infeasible constraints (degree sum exceeds possible edges), poor forecasting accuracy due to unreliable historical patterns
- First 3 experiments:
  1. Run with synthetic PA dataset, C1 coefficients, F1 formulation; check node error = 0
  2. Run with real FB dataset, C5 coefficients, F2 formulation; compare edge error vs. LS baseline
  3. Vary upper bound percentile u; observe impact on density error and solution feasibility

## Open Questions the Paper Calls Out

The paper explicitly states that it focused on unweighted graphs and identifies future research avenues including extending the methodology to weighted and directed graphs. This suggests that the current method's performance and applicability to more complex graph types remains an open question.

## Limitations
The adaptation of FBA to graph forecasting is novel and lacks direct validation from the biochemistry domain. The method assumes that degree forecasts from ARIMA models are sufficiently accurate to constrain the optimization without eliminating feasible solutions, but this relationship is not rigorously proven. The six coefficient schemes encode different assumptions about historical patterns, yet their relative performance and robustness across diverse graph types remain untested.

## Confidence
- **High confidence**: The mathematical formulation of the FBA-inspired optimization is sound and the evaluation methodology (node/edge/density error metrics) is appropriate
- **Medium confidence**: The degree forecasting component using ARIMA models is well-established, but its effectiveness specifically for dynamic graph node degrees requires empirical validation
- **Medium confidence**: The claim that the method outperforms using the last seen graph (LS baseline) is supported by experimental results, but the baseline comparison may not be sufficiently challenging

## Next Checks
1. Test solution feasibility: Systematically vary the upper bound percentile u in degree forecasts and measure the percentage of time steps where the optimization produces feasible solutions. Plot feasibility rate vs. u to identify robustness thresholds.

2. Compare coefficient schemes: Run the same forecasting task with all six coefficient schemes (C1-C6) on a standard dataset and compute statistical significance of performance differences. Identify which schemes work best for which graph types.

3. Stress test with inaccurate forecasts: Deliberately degrade the quality of degree forecasts (add noise, use simpler models) and measure the impact on graph forecasting accuracy. Determine the minimum forecast accuracy required for the FBA optimization to remain effective.