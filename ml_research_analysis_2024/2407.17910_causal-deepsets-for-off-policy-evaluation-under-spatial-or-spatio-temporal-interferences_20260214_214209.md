---
ver: rpa2
title: Causal Deepsets for Off-policy Evaluation under Spatial or Spatio-temporal
  Interferences
arxiv_id: '2407.17910'
source_url: https://arxiv.org/abs/2407.17910
tags:
- function
- spatial
- interference
- permutation
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a causal deepsets framework for off-policy
  evaluation (OPE) under spatial or spatio-temporal interferences. The authors address
  the challenge of accurately evaluating the efficacy of novel products or policies
  from offline datasets in scenarios where observations exhibit spillover effects,
  violating the stable unit treatment value assumption (SUTVA).
---

# Causal Deepsets for Off-policy Evaluation under Spatial or Spatio-temporal Interferences

## Quick Facts
- arXiv ID: 2407.17910
- Source URL: https://arxiv.org/abs/2407.17910
- Reference count: 12
- One-line primary result: Introduces causal deepsets framework for OPE under spatial or spatio-temporal interferences with permutation invariance assumption

## Executive Summary
This paper introduces a causal deepsets framework for off-policy evaluation (OPE) under spatial or spatio-temporal interferences, addressing the challenge of evaluating novel products or policies from offline datasets where observations exhibit spillover effects that violate SUTVA. The authors propose a permutation invariance (PI) assumption that enables data-driven, adaptive learning of the mean-field function without requiring parametric specification. Their approach effectively manages spatial interference by aggregating information from neighboring areas through a general permutation invariant function constructed via neural networks.

The proposed causal deepsets model incorporating PI assumption significantly improves estimation accuracy compared to existing baseline algorithms, demonstrating substantial practical applicability and effectiveness of OPE methodologies. The authors present novel algorithms that incorporate the PI assumption into OPE and thoroughly examine their theoretical foundations, establishing consistency, convergence rates, and minimax optimality of their estimators.

## Method Summary
The paper proposes a causal deepsets framework that relaxes the mean-field assumption by introducing a permutation invariance (PI) assumption for spatial or spatio-temporal interference settings. The method uses neural networks to parameterize the mean-field function, with a ϕ network that processes concatenated confounder-treatment vectors from neighboring regions and a ψ network that combines the central region's data with the aggregated interference effect. The PIE estimator achieves minimax optimality in approximating permutation invariant functions by leveraging the structured aggregation of neighboring information. The approach is applied to OPE using value-based, importance sampling, and doubly robust estimators, with cross-fitting employed to reduce overfitting.

## Key Results
- The PIE estimator achieves minimax optimality in approximating permutation invariant functions
- The proposed causal deepsets model incorporating PI assumption significantly improves estimation accuracy compared to existing baseline algorithms
- Numerical analyses demonstrate substantially better performance than mean-field approaches in both linear and nonlinear interference settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The permutation invariant (PI) neural network architecture enables adaptive learning of the mean-field function without requiring parametric specification.
- Mechanism: The PI architecture aggregates information from neighboring regions using a neural network (ϕ) that is invariant to the order of inputs, then combines this with the central region's data using another neural network (ψ). This allows the model to learn complex interference patterns directly from data.
- Core assumption: The mean-outcome function is permutation invariant with respect to neighboring regions (Assumption 2).
- Evidence anchors:
  - [abstract] "we advocate for the implementation of the permutation invariance (PI) assumption. This innovative approach enables the data-driven, adaptive learning of the mean-field function"
  - [section] "Assumption 2 (Permutation Invariance). For any given region i, the mean-outcome function fi(Xi, Ai, mi(XN (i), AN (i))) exhibits Permutation Invariance with respect to its neighboring regions"
- Break condition: If the mean-outcome function is not actually permutation invariant with respect to neighboring regions, the PI assumption will lead to biased estimates.

### Mechanism 2
- Claim: The PIE estimator achieves minimax optimality in approximating permutation invariant functions.
- Mechanism: By leveraging the permutation invariance property, the PIE estimator can achieve the same convergence rate as standard neural networks while reducing variance through structured aggregation of neighboring information.
- Core assumption: The target function lies in a Sobolev space with smoothness parameter β (Assumption 8).
- Evidence anchors:
  - [abstract] "we establish its consistency and convergence rate under practical assumptions. We also prove the minimax optimality of our estimator in approximating permutation invariant functions"
  - [section] "Theorem 4 (Minimax Optimality of PIE). Given the distribution of the confounding variable X ∈ RM ×N adhering to Assumption 9, the minimax risk for approximating any permutation invariant target function... is subject to the following lower bound"
- Break condition: If the smoothness assumptions are violated or the function is not truly permutation invariant, the theoretical guarantees may not hold.

### Mechanism 3
- Claim: The PIE estimator reduces variance compared to traditional mean-field approaches by leveraging the permutation invariance structure.
- Mechanism: Instead of averaging confounder-treatment pairs directly, the PIE estimator learns a flexible function ϕ that captures the relationship between neighboring regions and the central region's outcome, then averages these learned representations.
- Core assumption: The interference effect can be represented as a permutation invariant function of neighboring confounder-treatment pairs.
- Evidence anchors:
  - [abstract] "The proposed causal deepsets model, incorporating PI, effectively manages spatial interference by aggregating information from neighboring areas"
  - [section] "The neural network-based PIE is able to approximate this mismatch with high precision"
- Break condition: If the interference structure is not well-represented by a permutation invariant function, the variance reduction may be limited.

## Foundational Learning

- Concept: Permutation invariance
  - Why needed here: The core innovation of this paper relies on the permutation invariance assumption to relax the mean-field assumption and enable more flexible learning of interference effects.
  - Quick check question: What is the difference between a permutation invariant function and a permutation equivariant function?

- Concept: Off-policy evaluation (OPE)
  - Why needed here: The paper applies the causal deepsets framework to OPE, which requires understanding how to estimate policy values from observational data.
  - Quick check question: What are the main challenges in off-policy evaluation compared to on-policy evaluation?

- Concept: Spatial interference and SUTVA violation
  - Why needed here: The paper addresses the challenge of spatial interference, where treatments applied to one unit affect outcomes of neighboring units, violating the stable unit treatment value assumption.
  - Quick check question: How does spatial interference differ from temporal interference in causal inference?

## Architecture Onboarding

- Component map:
  - ϕ network: Takes concatenated confounder-treatment vectors from neighboring regions, outputs interference effect
  - ψ network: Takes central region's confounder-treatment vector and aggregated interference effect, outputs mean outcome
  - Cross-fitting scheme: Splits data into batches, trains on out-of-bag samples to reduce overfitting
  - Bellman operator (dynamic setting): Combines immediate reward and discounted future value

- Critical path:
  1. Data preprocessing: Identify neighboring regions, create adjacency structure
  2. Model training: Train ϕ and ψ networks using cross-fitting scheme
  3. Policy evaluation: Use trained model to estimate policy values using value-based, importance sampling, or doubly robust estimators

- Design tradeoffs:
  - Permutation invariance vs. flexibility: PI assumption reduces model complexity but may miss some interference patterns
  - Neural network depth vs. overfitting: Deeper networks can capture more complex patterns but may overfit with limited data
  - Batch size in cross-fitting vs. computational efficiency: Larger batches reduce computation but may increase overfitting

- Failure signatures:
  - High variance in estimates: May indicate violation of permutation invariance assumption
  - Systematic bias in policy evaluation: Could suggest model misspecification or unmeasured confounding
  - Poor performance on held-out data: May indicate overfitting or insufficient model complexity

- First 3 experiments:
  1. Linear setting simulation: Verify the model performs comparably to mean-field approach when the true relationship is linear
  2. Nonlinear setting simulation: Test the model's ability to capture nonlinear interference patterns that violate the mean-field assumption
  3. Real data-based simulation: Evaluate the model's performance on a ridesharing dataset with known ground truth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed causal deepsets framework be extended to handle scenarios with unmeasured confounding in both spatial and temporal dimensions simultaneously?
- Basis in paper: [explicit] The paper discusses unmeasured confounding as a limitation and mentions that current approaches focus on either spatial or temporal dependencies, but rarely both.
- Why unresolved: The paper does not provide a solution for addressing unmeasured confounding in scenarios where both spatial and temporal confounders coexist.
- What evidence would resolve it: Development and validation of a method that can effectively handle unmeasured confounding in both spatial and temporal dimensions, demonstrated through simulations or real-world applications.

### Open Question 2
- Question: What are the optimal experimental designs for generating data that can maximize the estimation accuracy of the proposed causal deepsets estimators in the presence of complex spatial and temporal interference?
- Basis in paper: [explicit] The paper mentions that future research could explore optimal experimental designs for generating data that optimizes estimation accuracy, but current literature primarily focuses on either spatial or temporal dependencies.
- Why unresolved: The paper does not provide specific guidance on how to design experiments that can effectively capture both spatial and temporal interference structures.
- What evidence would resolve it: Identification of experimental design principles or algorithms that can generate data with optimal properties for the proposed causal deepsets estimators, validated through theoretical analysis and empirical studies.

### Open Question 3
- Question: How can the proposed causal deepsets framework be adapted to handle non-stationary interference structures that vary over time and space?
- Basis in paper: [inferred] The paper discusses the challenges of non-stationary interference structures in the real data-based simulation section, but does not provide a solution for handling them.
- Why unresolved: The proposed framework assumes stationary interference structures, which may not hold in many real-world scenarios where interference effects change over time and space.
- What evidence would resolve it: Development and validation of an extension to the causal deepsets framework that can adapt to non-stationary interference structures, demonstrated through simulations or real-world applications.

## Limitations
- The permutation invariance assumption may not hold in all real-world scenarios, potentially leading to biased estimates when interference effects exhibit directional or asymmetric properties
- Theoretical guarantees rely on smoothness assumptions (Sobolev space with parameter β) that may not be empirically verifiable in practice
- The cross-fitting scheme's effectiveness in reducing overfitting requires further empirical validation, particularly with limited data

## Confidence
- **High Confidence**: The framework's ability to outperform mean-field approaches in simulated nonlinear settings where PI assumptions hold
- **Medium Confidence**: The minimax optimality of the PIE estimator and its variance reduction properties, pending further empirical validation
- **Low Confidence**: The framework's robustness to violations of permutation invariance and its performance on highly complex interference patterns

## Next Checks
1. **Sensitivity Analysis**: Systematically evaluate the framework's performance under varying degrees of permutation invariance violation to understand its robustness limits
2. **Real-world Deployment**: Apply the framework to diverse real-world datasets with known ground truth to validate its practical applicability beyond simulations
3. **Comparative Study**: Conduct a comprehensive comparison with alternative approaches for handling interference, including those based on graph neural networks and treatment-aware graph constructions