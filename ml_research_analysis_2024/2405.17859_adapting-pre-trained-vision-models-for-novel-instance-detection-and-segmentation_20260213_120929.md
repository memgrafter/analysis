---
ver: rpa2
title: Adapting Pre-Trained Vision Models for Novel Instance Detection and Segmentation
arxiv_id: '2405.17859'
source_url: https://arxiv.org/abs/2405.17859
tags:
- instance
- embeddings
- object
- detection
- adapter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents NIDS-Net, a unified framework for Novel Instance
  Detection and Segmentation (NIDS) that leverages pre-trained vision models to detect
  and segment unseen object instances given a few example images. The key innovation
  is a Weight Adapter that refines instance embeddings by applying learned weights
  within the original feature space, preventing overfitting and improving discriminative
  capacity.
---

# Adapting Pre-Trained Vision Models for Novel Instance Detection and Segmentation

## Quick Facts
- arXiv ID: 2405.17859
- Source URL: https://arxiv.org/abs/2405.17859
- Authors: Yangxiao Lu; Jishnu Jaykumar P; Yunhui Guo; Nicholas Ruozzi; Yu Xiang
- Reference count: 40
- Primary result: 63.9 AP on high-resolution detection dataset vs 41.6 AP for SAM alone

## Executive Summary
This paper introduces NIDS-Net, a unified framework for Novel Instance Detection and Segmentation (NIDS) that leverages pre-trained vision models to detect and segment unseen object instances using only a few example images. The key innovation is a Weight Adapter that refines instance embeddings by applying learned weights within the original feature space, preventing overfitting and improving discriminative capacity. The framework combines Grounding DINO and SAM for accurate object proposal generation, then uses DINOv2 embeddings refined by the Weight Adapter for matching. Experiments show significant performance gains across multiple datasets, including 63.9 AP on a high-resolution detection dataset and 64.9 AP on RoboTools.

## Method Summary
NIDS-Net is a two-stage pipeline that first generates object proposals using Grounding DINO with text prompts followed by SAM for mask generation, then extracts and refines embeddings using DINOv2 with Foreground Feature Averaging. The Weight Adapter, a learned network that applies sigmoid-normalized weights to embeddings within the original feature space, enhances discriminative capacity while preventing overfitting. The framework uses cosine similarity for matching template and proposal embeddings, with stable matching or argmax for final instance assignment. The method is trained using InfoNCE loss and evaluated on seven BOP datasets, a high-resolution detection dataset, and RoboTools, demonstrating robust performance across diverse scenes and real-world applications.

## Key Results
- 63.9 AP on high-resolution detection dataset vs 41.6 AP for SAM alone
- 64.9 AP on RoboTools dataset vs 18.7 AP for V oxDet
- Competitive results on seven BOP segmentation datasets
- Robust performance validated on real-world images from Fetch robots and RealSense cameras

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weight Adapter prevents overfitting in few-shot NIDS by applying learned weights directly within the original feature space instead of adding new residual features
- Mechanism: The adapter multiplies the original embedding by sigmoid-normalized weights, ensuring the adapted embedding stays close to the original while emphasizing discriminative dimensions for cosine similarity
- Core assumption: The original DINOv2 feature space is robust and effective, so adaptation should refine within this space rather than replace it
- Evidence anchors:
  - [abstract] "we introduce a novel weight adapter (W A) that modifies the original embeddings by applying learned weights... ensures that embeddings of the same instance are closely aligned"
  - [section] "the Weight Adapter... operates according to the following equations: w = sigmoid(MLP(βf ), fw = w ⊙ (βf )"
  - [corpus] "weak or missing" - no direct corpus support found for this specific adapter mechanism
- Break condition: If the original feature space is not robust or discriminative enough for the task, weight-based refinement within that space will be insufficient

### Mechanism 2
- Claim: Grounding DINO + SAM combination reduces false object proposals compared to using SAM alone
- Mechanism: Grounding DINO uses text prompts to identify object-like regions first, then SAM creates masks within those regions, filtering out background regions that SAM might otherwise misclassify as objects
- Core assumption: Text-based object prompts in Grounding DINO effectively identify object-like regions before mask generation
- Evidence anchors:
  - [abstract] "we utilize Grounding DINO and Segment Anything Model (SAM) to obtain object proposals with accurate bounding boxes and masks"
  - [section] "we employ Grounding DINO with the text prompt 'objects' to obtain initial bounding boxes of foreground objects. Then, SAM is applied to create masks based on these bounding boxes"
  - [corpus] "weak or missing" - no direct corpus support found for this specific two-stage proposal generation
- Break condition: If Grounding DINO fails to identify object-like regions accurately, the subsequent SAM masking will not improve proposal quality

### Mechanism 3
- Claim: Foreground Feature Averaging (FFA) produces more adaptable embeddings than using cls tokens for NIDS
- Mechanism: FFA averages patch embeddings within segmentation masks, capturing more spatial information about the object, while cls tokens provide a single global representation that may be less discriminative for matching
- Core assumption: Spatially averaged patch features contain more discriminative information for instance matching than global cls tokens
- Evidence anchors:
  - [section] "For image segmentation, following SAM-6D [4], we utilize the ViT-L model of DINOv2 [7]... Using the FFA pipeline with proposals, we calculate proposal embeddings"
  - [table] "FFA produces embeddings that possess greater adaptive potential, demonstrated by higher AP scores after adaption via our weight adapter"
  - [corpus] "weak or missing" - no direct corpus support found for FFA vs cls token comparison in NIDS context
- Break condition: If the task requires more global semantic understanding rather than local feature matching, cls tokens might outperform FFA

## Foundational Learning

- Concept: Few-shot learning adaptation techniques
  - Why needed here: NIDS operates with only a few template images per instance, making overfitting a critical concern
  - Quick check question: How does the Weight Adapter's approach differ from standard residual adapters in preventing overfitting?

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: The adapter is trained using InfoNCE loss to bring same-instance embeddings closer while separating different instances
  - Quick check question: What is the specific role of the InfoNCE loss in training the Weight Adapter?

- Concept: Cosine similarity and embedding matching
  - Why needed here: Final instance label assignment relies on cosine similarity between template and proposal embeddings
  - Quick check question: How does the Weight Adapter modify the cosine similarity computation?

## Architecture Onboarding

- Component map: Grounding DINO -> SAM -> DINOv2 + FFA -> Weight Adapter -> Matching
- Critical path: Grounding DINO → SAM → DINOv2 + FFA → Weight Adapter → Matching
- Design tradeoffs:
  - Using pre-trained models provides robustness but increases computational cost
  - Two-stage proposal generation (Grounding DINO + SAM) reduces false positives but adds latency
  - FFA embeddings capture more spatial information but may be less semantically rich than cls tokens
- Failure signatures:
  - Low AP scores indicate proposal generation or matching failures
  - Specific instances consistently misclassified suggest adapter overfitting or insufficient training
  - Runtime bottlenecks likely in the two-stage proposal generation
- First 3 experiments:
  1. Replace Grounding DINO with direct SAM usage to quantify proposal quality improvement
  2. Compare FFA vs cls token embeddings with and without Weight Adapter to validate embedding choice
  3. Test different β values in Weight Adapter to find optimal scaling factor for embedding refinement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical limit of the Weight Adapter's ability to enhance discriminative capacity in highly similar instance scenarios?
- Basis in paper: [explicit] The paper mentions that NIDS-Net may encounter detection failures when instances exhibit highly similar appearances.
- Why unresolved: The paper demonstrates performance degradation in such scenarios but doesn't provide theoretical bounds or analysis of how much improvement the Weight Adapter can achieve in these challenging cases.
- What evidence would resolve it: Experiments systematically varying instance similarity levels while measuring the Weight Adapter's performance gain relative to baseline methods would establish theoretical limits.

### Open Question 2
- Question: How does the Weight Adapter's performance scale with increasing instance diversity and template quantity per instance?
- Basis in paper: [explicit] The paper shows improved performance on datasets with more instances (YCB-V vs LM-O) and mentions the adapter is trained using K template images per instance.
- Why unresolved: While the paper demonstrates scaling benefits, it doesn't provide a comprehensive analysis of how performance changes with different ratios of instance diversity to template quantity, or what the optimal template-to-instance ratio might be.
- What evidence would resolve it: Systematic experiments varying both the number of instances and templates per instance across controlled datasets would reveal scaling relationships and optimal configurations.

### Open Question 3
- Question: Can the Weight Adapter mechanism be extended to 3D feature spaces for improved handling of pose variations and occlusions?
- Basis in paper: [explicit] The paper mentions V oxDet as a 3D voxel-based approach for novel instance detection and acknowledges limitations of 2D methods with pose variations and occlusions.
- Why unresolved: The paper focuses on 2D embeddings from DINOv2 but doesn't explore whether the Weight Adapter concept could be adapted to 3D representations that might better handle geometric variations.
- What evidence would resolve it: Implementing the Weight Adapter on 3D feature representations and comparing performance against 2D implementations across datasets with significant pose variations would demonstrate viability.

## Limitations

- Limited theoretical justification for why the Weight Adapter's approach prevents overfitting more effectively than alternative methods
- Insufficient ablation studies to isolate the individual contributions of Grounding DINO, SAM, and the Weight Adapter
- Focus on specific datasets with limited testing on diverse real-world conditions and different object categories

## Confidence

**High Confidence**: The empirical results showing significant AP improvements over baselines (63.9 vs 41.6 AP, 64.9 vs 18.7 AP) are well-supported by the experimental data. The overall framework architecture and pipeline are clearly described and reproducible.

**Medium Confidence**: The claims about the weight adapter preventing overfitting and the FFA embeddings having greater adaptive potential are supported by experimental evidence but lack deeper theoretical justification or extensive ablation studies to isolate individual contributions.

**Low Confidence**: The specific mechanism by which the weight adapter prevents overfitting compared to other approaches is not thoroughly validated. The paper doesn't adequately address potential failure modes or limitations of the Grounding DINO + SAM combination.

## Next Checks

1. **Ablation Study on Proposal Generation**: Run experiments replacing Grounding DINO + SAM with SAM alone on all datasets to quantify the exact contribution of the two-stage proposal generation to overall performance.

2. **Adapter Mechanism Analysis**: Implement and test alternative adapter designs (e.g., residual adapters, bottleneck adapters) using the same training setup to validate whether the weight adapter's approach is superior for preventing overfitting in few-shot NIDS.

3. **FFA vs cls Token Generalization**: Test the FFA and cls token approaches across diverse object categories and sizes, particularly focusing on cases where global semantic information might be more important than local feature matching.