---
ver: rpa2
title: A Survey of Multimodal Large Language Model from A Data-centric Perspective
arxiv_id: '2405.16640'
source_url: https://arxiv.org/abs/2405.16640
tags:
- data
- arxiv
- datasets
- language
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive review of multimodal large
  language models (MLLMs) from a data-centric perspective. It examines the critical
  role of data in MLLM development, focusing on data collection, processing, and evaluation
  across text, image, video, audio, and 3D modalities.
---

# A Survey of Multimodal Large Language Model from A Data-centric Perspective

## Quick Facts
- arXiv ID: 2405.16640
- Source URL: https://arxiv.org/abs/2405.16640
- Authors: Tianyi Bai; Hao Liang; Binwang Wan; Yanran Xu; Xi Li; Shiyu Li; Ling Yang; Bozhou Li; Yifan Wang; Bin Cui; Ping Huang; Jiulong Shan; Conghui He; Binhang Yuan; Wentao Zhang
- Reference count: 40
- Key outcome: This survey provides a comprehensive review of multimodal large language models (MLLMs) from a data-centric perspective. It examines the critical role of data in MLLM development, focusing on data collection, processing, and evaluation across text, image, video, audio, and 3D modalities. The survey outlines the data pipeline for MLLMs, including preprocessing, pre-training, and adaptation stages. It discusses domain and modality mixture strategies, quality selection methods, and data-centric supervised fine-tuning and human preference alignment. The work also reviews data evaluation metrics and benchmarks for MLLMs, highlighting the importance of dataset diversity, quality, and similarity. Finally, it identifies future research directions in data processing systems, data quantity and quality analysis, and lifelong learning for MLLMs.

## Executive Summary
This survey comprehensively reviews multimodal large language models (MLLMs) from a data-centric perspective, emphasizing the pivotal role of data in MLLM development and refinement. The paper examines the data pipeline for MLLMs, including data collection, preprocessing, pre-training, and adaptation stages, while discussing domain and modality mixture strategies, quality selection methods, and data-centric supervised fine-tuning. It also reviews data evaluation metrics and benchmarks for MLLMs, highlighting the importance of dataset diversity, quality, and similarity. The survey identifies future research directions in data processing systems, data quantity and quality analysis, and lifelong learning for MLLMs.

## Method Summary
This survey provides a comprehensive review of multimodal large language models (MLLMs) from a data-centric perspective, focusing on data collection, processing, and evaluation. The method involves a thorough literature review covering various aspects of MLLM development, including data pipeline stages (pre-processing, pre-training, adaptation), data evaluation methods, and future research directions. The survey synthesizes findings from multiple sources to present a holistic view of how data quality, quantity, and processing techniques impact MLLM performance across different modalities.

## Key Results
- Data quality and scale are critical determinants of MLLM performance across modalities.
- Data deduplication and filtering are essential for improving MLLM performance and reducing privacy risks.
- The scaling of training data is crucial for the emergence of new abilities in MLLMs.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data quality directly determines MLLM model performance across modalities.
- Mechanism: High-quality, diverse, and well-aligned multimodal data enables MLLMs to learn robust cross-modal representations, while poor data leads to hallucinations and degraded performance.
- Core assumption: MLLMs rely on the training data to acquire both modality-specific and cross-modal understanding, and this understanding cannot be fully compensated by model architecture alone.
- Evidence anchors:
  - [abstract]: "Data plays a pivotal role in the development and refinement of these models."
  - [section]: "Understanding the relationship between data characteristics and the performance of MLLMs is crucial for optimizing datasets and enhancing model capabilities."
  - [corpus]: Weak - no direct citations to specific papers demonstrating the data-quality-to-performance relationship, but the claim is supported by the overall survey focus.
- Break Condition: If the data is extremely noisy or unaligned across modalities, even the best model architectures will fail to produce meaningful results.

### Mechanism 2
- Claim: The scale of training data is essential for emergent abilities in MLLMs.
- Mechanism: As MLLMs are trained on larger and more diverse datasets, they develop new capabilities (emergent abilities) that were not explicitly programmed, enabling them to perform tasks beyond their original training objective.
- Core assumption: MLLMs exhibit scaling laws, where performance improves predictably with increases in model size, training data, and computational resources.
- Evidence anchors:
  - [abstract]: "MLLMs, such as GPT-4 [200], Flamingo [3], LLaVA [161]... integrate multiple modality information, demonstrating impressive comprehension and generation capabilities."
  - [section]: "The scaling law, which describes how the performance of large language models improves as they scale in terms of model size, training data, and computational resources."
  - [corpus]: Weak - while the concept of scaling laws is mentioned, specific citations to papers demonstrating emergent abilities in MLLMs are not provided.
- Break Condition: If the training data lacks diversity or is too small, the model will not develop emergent abilities, regardless of its size.

### Mechanism 3
- Claim: Data deduplication and filtering are critical for improving MLLM performance and reducing privacy risks.
- Mechanism: Removing duplicate and low-quality data from the training corpus reduces memorization, improves generalization, and mitigates privacy concerns by preventing the model from regurgitating training data verbatim.
- Core assumption: Duplicate and low-quality data in the training set can negatively impact model performance and raise privacy issues.
- Evidence anchors:
  - [section]: "Previous work has found there are great amount of duplicate data in various training datasets... deduplication of training datasets can prevent the memorization problem, thus alleviating privacy concerns."
  - [section]: "For example, the BOOK Corpus [322] contains thousands of duplicated books [14]."
  - [corpus]: Weak - while the concept of deduplication is discussed, specific citations to papers demonstrating the impact on privacy are not provided.
- Break Condition: If the deduplication process is too aggressive, it may remove valuable data and harm model performance.

## Foundational Learning

- Concept: Multimodal data processing and alignment
  - Why needed here: MLLMs require data from multiple modalities (text, image, video, audio, 3D) to be processed and aligned for effective training.
  - Quick check question: What are the key steps in processing and aligning multimodal data for MLLM training?
- Concept: Scaling laws and emergent abilities
  - Why needed here: Understanding how MLLM performance scales with data size and how emergent abilities arise is crucial for designing effective training strategies.
  - Quick check question: How do scaling laws and emergent abilities impact the design of MLLM training datasets?
- Concept: Data quality evaluation metrics
  - Why needed here: Evaluating the quality of multimodal data is essential for ensuring that MLLMs are trained on reliable and representative data.
  - Quick check question: What are the key metrics for evaluating the quality of multimodal data?

## Architecture Onboarding

- Component map: Modality Encoder -> Projector -> LLM Backbone
- Critical path: Collect and process multimodal data -> Pre-train modality encoders and LLM backbone -> Fine-tune entire model on aligned multimodal data
- Design tradeoffs: Balancing scale and diversity of training data with computational resources; deciding how much of pre-trained model to fine-tune for specific tasks
- Failure signatures: Poor data quality leading to hallucinations; insufficient data diversity leading to biased or limited performance; overfitting to specific tasks during fine-tuning
- First 3 experiments:
  1. Evaluate the impact of data quality on MLLM performance by training models on datasets with varying levels of noise and alignment.
  2. Investigate the relationship between data scale and emergent abilities by training models on datasets of different sizes and evaluating their performance on a range of tasks.
  3. Assess the effectiveness of different data deduplication and filtering strategies on MLLM performance and privacy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quantity of training data influence the emergence of abilities in multimodal large language models (MLLMs)?
- Basis in paper: [explicit] The paper discusses the scaling laws of LLMs in relation to model size, dataset size, and data quality, but notes a gap in understanding how data quantity affects emergent abilities in MLLMs.
- Why unresolved: While scaling laws for text-only LLMs have been studied, the impact of data quantity on the emergence of abilities in MLLMs remains unexplored. This is a crucial area for understanding how to optimize data collection and model performance.
- What evidence would resolve it: Empirical studies comparing the performance of MLLMs trained on datasets of varying sizes, focusing on the emergence of specific abilities, would provide insights into the relationship between data quantity and emergent abilities.

### Open Question 2
- Question: What are the most effective data selection methods for MLLM pre-training that balance computational efficiency and model performance?
- Basis in paper: [explicit] The paper highlights the need for efficient data selection algorithms due to the computational burden of evaluating large-scale multimodal datasets. It mentions the potential of proxy models to reduce computational costs but notes the need for further refinement.
- Why unresolved: While various data selection methods exist, their effectiveness and efficiency in the context of MLLM pre-training remain unclear. Optimizing this process is crucial for reducing training costs and improving model performance.
- What evidence would resolve it: Comparative studies evaluating the performance of different data selection methods, including proxy models, on MLLM pre-training tasks would provide insights into their effectiveness and efficiency.

### Open Question 3
- Question: How can lifelong learning strategies be effectively integrated into MLLMs to prevent catastrophic forgetting and enable continuous learning across multiple modalities?
- Basis in paper: [explicit] The paper emphasizes the importance of lifelong learning for MLLMs, which learn from diverse data types sequentially across various training phases. It highlights the need to prevent catastrophic forgetting and retain foundational language capabilities while acquiring multimodal skills.
- Why unresolved: Integrating lifelong learning into MLLMs is a complex challenge due to the sequential nature of their training and the need to balance knowledge retention and acquisition. Effective strategies for this integration remain an open area of research.
- What evidence would resolve it: Experimental studies demonstrating the effectiveness of different lifelong learning techniques, such as regularization methods and rehearsal strategies, in preventing catastrophic forgetting and improving continuous learning in MLLMs would provide valuable insights.

## Limitations

- Insufficient comparative studies on the relative effectiveness of various domain and modality mixture strategies.
- Limited quantitative comparisons of different data deduplication and filtering techniques across diverse MLLMs.
- Unclear long-term impact of different data quality evaluation metrics on MLLM generalization.

## Confidence

High confidence in the fundamental claim that data quality and scale are critical determinants of MLLM performance, based on the extensive literature review and established scaling laws in the field. The analysis of data processing pipelines and evaluation methods is supported by a comprehensive review of current practices, though some specific implementation details remain unspecified in the surveyed literature.

Medium confidence applies to claims about specific data deduplication and filtering techniques, as while their importance is well-established, quantitative comparisons of different methods across diverse MLLMs are limited in the current literature. The discussion of emergent abilities and scaling relationships is supported by theoretical frameworks but would benefit from more direct empirical validation across different MLLM architectures.

Low confidence exists regarding the relative effectiveness of various domain and modality mixture strategies, as the survey identifies these as important research directions but notes insufficient comparative studies in the literature. Similarly, the long-term impact of different data quality evaluation metrics on MLLM generalization remains an open question requiring further investigation.

## Next Checks

1. Conduct controlled experiments varying data quality levels while holding model architecture constant to quantify the precise relationship between data characteristics and MLLM performance across multiple modalities.

2. Implement and compare multiple data deduplication and filtering strategies on the same base datasets to measure their impact on both model performance and privacy preservation metrics.

3. Design a standardized benchmark for evaluating data quality evaluation metrics themselves, testing their predictive power for downstream MLLM task performance across diverse domains and modalities.