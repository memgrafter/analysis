---
ver: rpa2
title: 'Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via
  Eliciting and Adhering to Principles'
arxiv_id: '2407.00870'
source_url: https://arxiv.org/abs/2407.00870
tags:
- principles
- patients
- patient
- counselors
- response
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Roleplay-doh, a tool enabling domain experts
  to create customized AI roleplay partners for training. It addresses the challenge
  of creating realistic simulations in sensitive domains like mental health, where
  privacy concerns limit data access.
---

# Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles

## Quick Facts
- arXiv ID: 2407.00870
- Source URL: https://arxiv.org/abs/2407.00870
- Reference count: 40
- Key outcome: Domain experts can create AI roleplay partners using qualitative feedback converted to principles, achieving 30% improvement in response quality and 35% win rate in principle adherence

## Executive Summary
Roleplay-doh is a tool that enables domain experts to create customized AI roleplay partners for training without requiring technical prompting knowledge. The system transforms qualitative feedback from experts into principles that govern LLM behavior, using a principle-adherence pipeline to improve response quality by 30%. In user studies with 25 counseling experts, AI patients created using the tool were rated as more authentic and ready for training use compared to scenario-only approaches, while achieving high principle-following rates and reducing awkward responses.

## Method Summary
The method involves a human-LLM collaboration pipeline where counselors interact with AI patients and provide feedback (kudos, critique, or rewrites) that gets automatically converted into principles using an LLM. These principles guide subsequent responses through a principle-adherence pipeline that decomposes complex principles into yes/no questions, evaluates contextual applicability, and self-refines responses when violations are detected. The tool provides an intuitive interface that removes the need for prompt engineering knowledge while maintaining expert control over AI behavior.

## Key Results
- 30% improvement in response quality and principle following through the principle-adherence pipeline
- 35% win, 5% loss principle-following rates in user studies
- 12.5% reduction in awkward responses compared to baseline methods
- 25 counseling experts rated AI patients created with principles as more authentic and training-ready than scenario-only approaches

## Why This Works (Mechanism)

### Mechanism 1
Qualitative feedback from domain experts can be automatically converted into principles that improve LLM roleplay behavior. The system uses an LLM to translate counselor critiques, kudos, and rewrites into natural language rules that the LLM simulation follows in subsequent responses.

### Mechanism 2
A principle-adherence pipeline can improve response quality by 30% through contextual evaluation and self-refinement. The pipeline decomposes complex principles into yes/no questions, evaluates applicability to current context, and self-refines responses when principles are violated.

### Mechanism 3
Domain experts can effectively customize AI patients without technical prompting knowledge. The tool provides an intuitive interface where counselors interact with AI patients and provide feedback that gets automatically converted to principles.

## Foundational Learning

- **Concept:** Natural language processing and LLM prompt engineering
  - Why needed here: The system relies on LLMs to both generate roleplay responses and convert feedback into principles
  - Quick check question: What are the key differences between system prompts, user prompts, and few-shot examples in LLM interactions?

- **Concept:** Human-AI collaboration design patterns
  - Why needed here: The tool mediates between domain experts and AI systems
  - Quick check question: How do you balance automation with human control in a system where experts provide qualitative feedback?

- **Concept:** Evaluation methodologies for interactive AI systems
  - Why needed here: The system requires both technical evaluation and user experience evaluation
  - Quick check question: What are the key differences between within-subjects and between-subjects study designs for comparing AI system variants?

## Architecture Onboarding

- **Component map:** Frontend chat interface → Feedback Processor (LLM) → Response Generator (LLM) → Principle Adherence Pipeline → Database
- **Critical path:** Counselor provides feedback → Feedback Processor converts to principles → Response Generator creates new response → Principle Adherence Pipeline evaluates and refines → Response delivered to counselor
- **Design tradeoffs:** Prompting vs. fine-tuning (prompting allows rapid iteration but may be less reliable), Real-time vs. batch processing (real-time enables interactive refinement but increases latency), General vs. specific principles (more general principles are more reusable but may be less precise)
- **Failure signatures:** Principles become too numerous or contradictory, Response quality degrades with each refinement iteration, Counselors cannot articulate effective feedback, LLM conversion produces principles that don't generalize
- **First 3 experiments:** 1) Test feedback-to-principle conversion quality with diverse counselor feedback examples, 2) Evaluate principle adherence pipeline on controlled test cases with known errors, 3) Conduct user study comparing scenario-only vs. scenario+principles AI patients with real counselors

## Open Questions the Paper Calls Out

### Open Question 1
What are the specific limitations of the principle-adherence pipeline in handling complex, multi-faceted principles that involve multiple conditions or context-dependent rules? The paper mentions that the pipeline decomposes multipart and contextual principles into yes/no questions, but it doesn't fully explore how well it handles complex principles with multiple conditions or context-dependent rules.

### Open Question 2
How does the principle-adherence pipeline handle cases where the AI patient's response is appropriate but the principles are not well-defined or are too broad? The paper mentions that the pipeline can generate additional principle questions to ensure adherence to dialogue conventions, but it doesn't explore how well it handles cases where the principles are not well-defined or are too broad.

### Open Question 3
What are the specific challenges in defining principles that generalize across different contexts and scenarios, and how does the tool address these challenges? The paper mentions that counselors created principles related to different stages of an emotional support conversation, but it doesn't explore the specific challenges in defining principles that generalize across different contexts and scenarios.

## Limitations

- The 30% improvement claim relies on principle-adherence pipeline implementation details not provided in the main text
- User study with 25 counseling experts has limited generalizability due to small sample size and potential selection bias
- The system's scalability to more complex counseling scenarios and handling of contradictory feedback from different experts is not addressed

## Confidence

- **High Confidence:** The general approach of using expert feedback to generate principles for LLM behavior is sound and well-supported by the literature
- **Medium Confidence:** The specific implementation of the principle-adherence pipeline and its claimed 30% improvement is plausible but requires more detailed information
- **Low Confidence:** The generalizability to other domains beyond mental health counseling and long-term effectiveness of principles

## Next Checks

1. Replicate the principle-adherence pipeline with a diverse set of feedback examples to test robustness and generalizability
2. Conduct a larger-scale user study with a more diverse group of counseling experts to validate effectiveness
3. Test system performance on more complex counseling scenarios and with contradictory feedback from different experts to assess scalability