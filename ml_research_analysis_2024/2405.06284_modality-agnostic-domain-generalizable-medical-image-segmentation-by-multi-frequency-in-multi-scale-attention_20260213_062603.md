---
ver: rpa2
title: Modality-agnostic Domain Generalizable Medical Image Segmentation by Multi-Frequency
  in Multi-Scale Attention
arxiv_id: '2405.06284'
source_url: https://arxiv.org/abs/2405.06284
tags:
- segmentation
- image
- madgnet
- medical
- unet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of creating a medical image
  segmentation model that is both modality-agnostic and domain-generalizable. The
  authors propose MADGNet, which leverages a Multi-Frequency in Multi-Scale Attention
  (MFMSA) block and an Ensemble Sub-Decoding Module (E-SDM).
---

# Modality-agnostic Domain Generalizable Medical Image Segmentation by Multi-Frequency in Multi-Scale Attention

## Quick Facts
- arXiv ID: 2405.06284
- Source URL: https://arxiv.org/abs/2405.06284
- Reference count: 40
- This paper proposes MADGNet, achieving state-of-the-art segmentation performance across 15 medical imaging datasets spanning 6 modalities

## Executive Summary
This paper addresses the challenge of creating a medical image segmentation model that is both modality-agnostic and domain-generalizable. The authors propose MADGNet, which leverages a Multi-Frequency in Multi-Scale Attention (MFMSA) block and an Ensemble Sub-Decoding Module (E-SDM). The MFMSA block integrates multi-scale and multi-frequency features using 2D Discrete Cosine Transform (DCT) and spatial attention mechanisms to enhance feature representation and boundary detection. The E-SDM mitigates information loss during multi-task learning with deep supervision. Extensive experiments on 15 datasets across six modalities demonstrate that MADGNet consistently outperforms state-of-the-art methods, achieving the highest segmentation performance. For instance, it improved DSC by 1.1% and mIoU by 1.0% compared to the second-best model on average. The model also excels in multi-label segmentation tasks, validating its effectiveness and generalizability.

## Method Summary
MADGNet combines a ResNeSt50 backbone with Multi-Frequency in Multi-Scale Attention (MFMSA) blocks and an Ensemble Sub-Decoding Module (E-SDM). The MFMSA block extracts features at multiple scales and applies 2D DCT to obtain frequency statistics, which are used to generate channel attention weights. Multi-scale spatial attention with foreground/background weighting further refines feature maps. The E-SDM implements deep supervision across multiple tasks (region, boundary, distance maps) with a forward stream for predictions and a backward stream for information fusion through ensemble averaging. The model is trained using Adam optimizer with cosine annealing learning rate scheduler, batch size 16, and data augmentation including horizontal/vertical flipping and rotation.

## Key Results
- MADGNet achieved the highest segmentation performance across all 15 datasets spanning 6 modalities
- On average, MADGNet improved DSC by 1.1% and mIoU by 1.0% compared to the second-best model
- The model demonstrated superior performance in multi-label segmentation tasks, validating its effectiveness and generalizability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MFMSA block's multi-frequency channel attention (MFCA) with 2D DCT improves feature representation by extracting frequency statistics
- Mechanism: The MFCA block uses 2D DCT to transform feature maps into the frequency domain, then applies global pooling operations to extract statistics across frequency bands. These statistics are used to generate a channel attention map that recalibrates the feature map
- Core assumption: Different frequency bands contain complementary information that, when weighted by learned attention, enhance overall feature representation
- Evidence anchors:
  - [abstract] "The MFMSA block refines the process of spatial feature extraction, particularly in capturing boundary features, by incorporating multi-frequency and multi-scale features"
  - [section 3.1] "Features at each scale branch can be characterized using 2D DCT with basis images D... Subsequently, each Xs,k i is compressed into Zavg, Zmax, and Zmin using Global Average Pooling, Global Max Pooling, and Global Min Pooling"
  - [corpus] Weak - no direct citations found for DCT-based attention in medical imaging; this appears to be a novel approach in this domain
- Break condition: If the frequency statistics do not correlate with meaningful image features, the attention mechanism will not improve segmentation performance

### Mechanism 2
- Claim: Multi-scale spatial attention (MSSA) with foreground/background weighting captures discriminative boundary features across scales
- Mechanism: MSSA applies two learnable parameters (αs i and βs i) to control information flow between foreground and background attention maps. These parameters are learned to emphasize regions that contribute most to boundary detection at each scale
- Core assumption: Boundary features require different emphasis at different scales, and foreground/background weighting can capture this scale-dependent importance
- Evidence anchors:
  - [abstract] "The MFMSA block refines the process of spatial feature extraction, particularly in capturing boundary features"
  - [section 3.1] "X s i = Conv2D3(αs i ( ˆXs i × Fs i ) + βs i ( ˆXs i × Bs i ))" and "The channel-recalibrated feature map ˆXs i is used to determine discriminative boundary cues with various scales in the spatial domain"
  - [corpus] Missing - no corpus evidence found for foreground/background weighting in multi-scale attention for medical imaging
- Break condition: If the learned parameters α and β converge to trivial values (e.g., all 1 or all 0), the MSSA would provide no benefit over standard multi-scale feature aggregation

### Mechanism 3
- Claim: Ensemble Sub-Decoding Module (E-SDM) prevents information loss during multi-task learning with deep supervision by cascading predictions
- Mechanism: E-SDM creates a backward stream where sub-task predictions are upsampled and added to subsequent task predictions, effectively combining information from different resolutions and tasks. This creates an ensemble of predictions across tasks and scales
- Core assumption: Information lost during upsampling can be partially recovered by incorporating predictions from higher-resolution tasks, and ensemble averaging across tasks improves robustness
- Evidence anchors:
  - [abstract] "We propose a ensemble sub-decoding module (E-SDM) to prevent information loss caused by drastic upsampling during multi-task learning with deep supervision"
  - [section 3.2] "After producing the L-th sub-task pseudo prediction PsL i , to obtain the final core task prediction Tc i, we apply the backward stream as follows" and "Tc i = LX l=0 Up5−i (Psl i )"
  - [corpus] Weak - limited evidence for ensemble-based multi-task learning in medical segmentation; this appears to be a novel training strategy
- Break condition: If the backward stream predictions are poor quality (e.g., due to noisy gradients), adding them could degrade rather than improve the final predictions

## Foundational Learning

- Concept: Discrete Cosine Transform (DCT) for frequency domain feature extraction
  - Why needed here: The paper uses 2D DCT to extract frequency statistics that inform channel attention weights
  - Quick check question: What is the mathematical relationship between spatial domain features and their DCT coefficients?

- Concept: Multi-scale feature aggregation and resolution management
  - Why needed here: The MFMSA block operates on features at multiple scales, requiring understanding of how to downsample, process, and upsample features while maintaining information
  - Quick check question: How does the number of parameters scale when applying convolutions across multiple scales with resolution reduction?

- Concept: Multi-task learning with deep supervision
  - Why needed here: The E-SDM is designed to address challenges in training models with multiple tasks and deep supervision, particularly information loss during upsampling
  - Quick check question: What are the advantages and disadvantages of parallel vs. ensemble approaches to multi-task learning with deep supervision?

## Architecture Onboarding

- Component map: Input → Backbone → MFMSA blocks (scale decomposition → MFCA → MSSA) → E-SDM → Output
- Critical path: Input → Backbone → MFMSA blocks (scale decomposition → MFCA → MSSA) → E-SDM → Output
- Design tradeoffs:
  - Multiple scales increase parameter count but improve boundary detection
  - DCT-based attention adds computational cost but extracts frequency information
  - E-SDM increases training complexity but prevents information loss
  - Tradeoff between model capacity and inference speed (31M parameters, 24ms/image)
- Failure signatures:
  - Poor frequency attention weights indicate DCT features don't correlate with useful information
  - α and β parameters converging to trivial values suggest scale-specific attention isn't beneficial
  - E-SDM not improving performance suggests backward stream predictions are noisy or uninformative
- First 3 experiments:
  1. Implement MFCA alone (remove MSSA) and compare segmentation performance to baseline UNet to isolate frequency attention contribution
  2. Test different numbers of scale branches (S=1, 2, 3, 4) to find optimal balance between performance and efficiency
  3. Compare E-SDM ensemble approach vs. parallel multi-task learning with deep supervision on a single dataset to validate information preservation claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MADGNet change when applied to multimodal medical imaging tasks that combine more than two modalities simultaneously?
- Basis in paper: [inferred] The paper demonstrates MADGNet's effectiveness on datasets with six different modalities, but does not explore its performance on combined multimodal datasets
- Why unresolved: The experiments were conducted on single-modality datasets, and the paper does not address the model's scalability or performance in multimodal scenarios where multiple imaging types are fused
- What evidence would resolve it: Testing MADGNet on datasets that combine multiple modalities (e.g., CT and MRI) and comparing its performance to modality-specific or multimodal models would clarify its adaptability

### Open Question 2
- Question: What is the impact of varying the frequency selection strategy (Top, Bot, Low) on MADGNet's performance for specific medical imaging tasks?
- Basis in paper: [explicit] The paper mentions frequency selection strategies (Top, Bot, Low) but only reports results for the Top strategy, leaving the comparative impact of other strategies unexplored
- Why unresolved: The paper does not provide a detailed analysis of how different frequency selection strategies affect segmentation accuracy across various modalities or tasks
- What evidence would resolve it: Conducting experiments with all three frequency selection strategies on multiple datasets and comparing their performance would determine the optimal strategy for different imaging tasks

### Open Question 3
- Question: How does MADGNet's computational efficiency scale with increasing image resolution or dataset size?
- Basis in paper: [inferred] The paper reports MADGNet's parameter count and inference speed for standard resolutions but does not explore its scalability to higher resolutions or larger datasets
- Why unresolved: The experiments were conducted on images resized to 352 × 352, and the paper does not address the model's efficiency for higher-resolution medical images or larger-scale datasets
- What evidence would resolve it: Evaluating MADGNet on higher-resolution images and larger datasets while measuring parameter efficiency, inference speed, and memory usage would clarify its scalability

## Limitations
- The DCT-based frequency attention mechanism lacks direct validation in the medical imaging literature
- The multi-scale spatial attention with learned foreground/background weighting has no corpus evidence supporting its use in medical segmentation tasks
- The E-SDM ensemble approach for multi-task learning is presented as novel without comparative analysis against simpler ensemble or parallel methods

## Confidence
- **High Confidence**: MADGNet's state-of-the-art performance on 15 datasets across 6 modalities is well-supported by quantitative metrics (DSC, mIoU, Fwβ, Sα, Emaxϕ, MAE)
- **Medium Confidence**: The MFMSA block improves feature representation and boundary detection through multi-frequency and multi-scale attention, based on ablation studies but limited external validation
- **Medium Confidence**: The E-SDM prevents information loss during multi-task learning, supported by qualitative results but lacking direct comparison with alternative methods

## Next Checks
1. **Cross-Modality Transferability**: Test MADGNet on completely unseen modalities not represented in the 15 datasets to validate true modality-agnostic capabilities beyond the reported generalization
2. **Frequency Attention Ablation**: Replace the DCT-based MFCA with alternative frequency extraction methods (e.g., Wavelet Transform) to determine whether frequency statistics specifically or general feature statistics drive performance improvements
3. **Ensemble vs Parallel Comparison**: Implement a parallel multi-task learning baseline with identical architecture but separate decoders, then compare information preservation and segmentation quality to validate the E-SDM design choice