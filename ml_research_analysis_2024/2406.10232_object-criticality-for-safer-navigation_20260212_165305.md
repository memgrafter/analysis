---
ver: rpa2
title: Object criticality for safer navigation
arxiv_id: '2406.10232'
source_url: https://arxiv.org/abs/2406.10232
tags:
- object
- objects
- criticality
- driving
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the impact of object criticality on the
  safety and reliability of autonomous driving beyond the evaluation of object detectors.
  The authors propose to filter predicted objects based on their criticality scores
  in combination with traditional confidence thresholds, and then use the filtered
  objects to compute trajectories.
---

# Object criticality for safer navigation

## Quick Facts
- arXiv ID: 2406.10232
- Source URL: https://arxiv.org/abs/2406.10232
- Reference count: 32
- Primary result: Filtering objects by criticality in combination with confidence thresholds reduces dangerous trajectories and improves trajectory quality in autonomous driving

## Executive Summary
This paper proposes using object criticality scores to improve autonomous driving safety by filtering predicted objects before trajectory planning. The approach combines traditional confidence thresholding with criticality-based filtering to reduce the risk of missing relevant objects while maintaining computational efficiency. The method is validated on the nuScenes dataset using two object detectors (REG and FCOS3D) and shows improvements in trajectory planning quality measured by Planning KL-divergence (PKL).

## Method Summary
The method computes criticality scores for each predicted object using an Object Criticality Model (OCM) that considers distance, colliding trajectory, and time-to-collision factors. Objects are then filtered based on both confidence and criticality thresholds, where high-criticality objects can be retained even at low confidence levels. The filtered objects are used to generate trajectories, which are evaluated using the Planning KL-divergence metric. The approach is tested on 10 randomly selected sequences from the nuScenes validation set.

## Key Results
- Filtering objects by criticality reduces the risk of missing relevant objects compared to confidence thresholding alone
- The approach decreases the likelihood of dangerous trajectories while improving overall trajectory quality
- High-criticality objects detected with low confidence should be retained to prevent safety-critical false negatives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Filtering objects by criticality reduces planner confusion without sacrificing safety-relevant detections.
- Mechanism: By removing low-criticality objects, the planner's search space shrinks, reducing computational noise and avoiding unnecessary trajectory adjustments for irrelevant objects. Critical objects with low confidence are preserved to prevent false negatives that could cause safety hazards.
- Core assumption: The trajectory planner can safely ignore non-critical objects, and the reduction in object count improves planner efficiency and trajectory quality.
- Evidence anchors:
  - [abstract] "filtering objects based on their relevance, in combination with the traditional confidence threshold, reduces the risk of missing relevant objects, decreases the likelihood of dangerous trajectories, and improves the quality of trajectories in general."
  - [section] "removing predictions that are not relevant for the driving task has a positive impact on the trajectory planner, i.e., it improves driving quality."
  - [corpus] Weak: No direct citations, but related papers on criticality metrics and safety-aware detection suggest this is an active research area.
- Break condition: If the planner incorrectly interprets the absence of low-criticality objects as implying a clear path, it may make unsafe decisions.

### Mechanism 2
- Claim: Retaining high-criticality objects regardless of confidence reduces the risk of false negatives in safety-critical situations.
- Mechanism: By bypassing the confidence threshold for high-criticality objects, the system avoids discarding potentially dangerous objects that the detector is uncertain about but that are close to the observer or on a collision course.
- Core assumption: The criticality model accurately identifies which objects pose the greatest safety risk, and false positives from low-confidence high-criticality detections are less dangerous than false negatives.
- Evidence anchors:
  - [abstract] "objects detected with low confidence should not be filtered out, if their potential presence may critically affect the driving task."
  - [section] "Our hypothesis is that this will reduce the risk of False Negatives of relevant objects, thus improving safety of the driving task, even if at the cost of some additional False Positives."
  - [corpus] Weak: Limited corpus support, but the idea aligns with safety-first approaches in autonomous driving literature.
- Break condition: If the criticality model is inaccurate, this mechanism may introduce many false positives, degrading performance without improving safety.

### Mechanism 3
- Claim: A combined confidence-criticality threshold function can optimize both safety and efficiency.
- Mechanism: Instead of a single confidence threshold, use a function or lookup table that adjusts the required confidence based on the object's criticality score, allowing more nuanced filtering.
- Core assumption: There exists a monotonic relationship between criticality and the acceptable confidence threshold, such that high-criticality objects can be retained at lower confidences.
- Evidence anchors:
  - [abstract] "filtering objects based on a combination of confidence threshold and assigned object criticality, where a specific confidence threshold is applied based on the predicted criticality of an object."
  - [section] "From the discussion above, it is reasonable to infer that maintaining all predicted objects above a criticality threshold is safe but inefficient. We aim to relax the condition..."
  - [corpus] Weak: No direct corpus citations, but this idea is implied by the combination of criticality and confidence in the filtering process.
- Break condition: If the relationship between criticality and confidence is non-monotonic or dataset-dependent, a fixed function may not generalize.

## Foundational Learning

- Concept: Object detection confidence scores and their thresholding.
  - Why needed here: Understanding how confidence thresholds filter detections is fundamental to grasping how the proposed method modifies this filtering using criticality.
  - Quick check question: What happens to a detection with confidence 0.4 if the threshold is set to 0.5?

- Concept: Object criticality and its computation.
  - Why needed here: Criticality scores determine which objects are safety-relevant; knowing how they are computed (distance, collision trajectory, time-to-collision) is key to understanding the filtering logic.
  - Quick check question: Which factors contribute to the overall criticality score in the Object Criticality Model?

- Concept: Trajectory planning and the Planning KL-divergence (PKL) metric.
  - Why needed here: The ultimate evaluation of the method's effectiveness is how it impacts trajectory planning; PKL measures the divergence between ground truth and predicted trajectories.
  - Quick check question: What does a lower PKL score indicate about the quality of a trajectory?

## Architecture Onboarding

- Component map:
  Object Detector (REG/FCOS3D) -> Bounding Box predictions with confidence scores -> Object Criticality Model -> Criticality scores -> Filtering Logic (confidence + criticality) -> Filtered objects -> Trajectory Planner -> Trajectories -> PKL Evaluator -> PKL score

- Critical path: Object Detector -> Criticality Model -> Filtering Logic -> Trajectory Planner -> PKL Evaluator

- Design tradeoffs:
  - Safety vs. efficiency: Retaining low-confidence high-criticality objects increases safety but may introduce false positives
  - Complexity vs. performance: Using a combined confidence-criticality function is more complex but may yield better results than simple thresholding
  - Runtime vs. accuracy: Computing criticality scores adds overhead but improves decision quality

- Failure signatures:
  - High PKL despite filtering: Indicates the planner is still confused or the filtering is too aggressive
  - Frequent false positives: Suggests the criticality model is over-predicting risk or the confidence threshold is too low
  - Missed critical objects: Implies the filtering logic incorrectly removed high-criticality low-confidence objects

- First 3 experiments:
  1. Vary the criticality threshold while keeping the confidence threshold fixed; measure PKL and safety overlap
  2. Implement a linear mapping from criticality to confidence threshold and evaluate on a validation set
  3. Visualize birdview trajectories for samples with high-criticality objects to manually assess safety improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does filtering objects based on criticality scores significantly improve trajectory planning safety beyond what can be measured by current metrics like PKL?
- Basis in paper: [explicit] The paper mentions that PKL does not give indication on the safety of the trajectory and proposes visual inspection methods to identify safety hazards, but notes technical limitations and the need for further validation.
- Why unresolved: Current metrics like PKL measure divergence from ground truth trajectories but don't directly assess safety. The proposed visual inspection method has technical limitations and requires human validation.
- What evidence would resolve it: A comprehensive safety validation framework that combines quantitative metrics with human expert evaluation, showing statistically significant improvements in safety when using criticality-based filtering versus traditional confidence thresholding alone.

### Open Question 2
- Question: What is the optimal relationship between confidence thresholds and criticality scores for filtering objects in autonomous driving systems?
- Basis in paper: [explicit] Hypothesis 3 proposes investigating the benefits of filtering objects based on a combination of confidence threshold and criticality, but states that at the present stage they do not have a preferred approach to propose.
- Why unresolved: The paper acknowledges the need to explore multiple pairs of confidence and criticality thresholds or more complex functions relating the two, but hasn't implemented this investigation yet.
- What evidence would resolve it: Experimental results showing optimal combinations of confidence and criticality thresholds across various driving scenarios, demonstrating improved safety and reliability compared to using either metric alone.

### Open Question 3
- Question: How does object criticality filtering impact the reliability and user experience of autonomous driving systems in terms of false positive and false negative rates?
- Basis in paper: [inferred] The paper discusses that maintaining all predicted objects above a criticality threshold is safe but inefficient, and mentions the need to balance safety improvements with reliability of the driving task.
- Why unresolved: While the paper shows that high criticality objects should not be filtered out regardless of confidence, it doesn't provide comprehensive analysis of the trade-offs between safety improvements and the impact on false positive/negative rates and overall system reliability.
- What evidence would resolve it: Detailed analysis showing the impact of criticality-based filtering on false positive and false negative rates across different driving scenarios, with clear demonstration of the trade-offs between safety improvements and system reliability/maintainability.

## Limitations
- Limited experimental validation on only 10 nuScenes sequences, which may not capture the full diversity of driving scenarios
- Reliance on PKL as a proxy for safety without direct safety outcome metrics, introducing uncertainty about real-world performance
- Criticality model parameters (Dmax, Rmax, Tmax) are not fully calibrated or justified for the specific nuScenes dataset

## Confidence

- **High Confidence**: The core hypothesis that filtering objects by criticality can improve trajectory planning is well-supported by the theoretical mechanism and logical reasoning presented.
- **Medium Confidence**: The experimental results showing PKL improvements with criticality-based filtering are plausible but limited by the small validation set size.
- **Low Confidence**: The claim that this approach significantly improves real-world safety is not directly tested and relies on PKL as a proxy metric.

## Next Checks

1. **Dataset Scale Validation**: Repeat the experiment on the full nuScenes validation set (150 sequences) to verify that the PKL improvements observed on 10 sequences hold across a larger, more diverse dataset.

2. **Safety Outcome Correlation**: Implement a direct safety metric (e.g., collision probability or time-to-collision analysis) to validate that PKL improvements correlate with actual safety improvements in trajectory planning.

3. **Criticality Model Calibration**: Conduct ablation studies varying the criticality model parameters (Dmax, Rmax, Tmax) to determine their sensitivity and identify optimal values for the nuScenes dataset, ensuring the criticality scores are appropriately calibrated.