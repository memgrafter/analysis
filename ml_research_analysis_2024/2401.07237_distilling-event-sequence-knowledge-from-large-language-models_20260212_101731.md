---
ver: rpa2
title: Distilling Event Sequence Knowledge From Large Language Models
arxiv_id: '2401.07237'
source_url: https://arxiv.org/abs/2401.07237
tags:
- event
- sequence
- sequences
- https
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to generate structured event sequences
  from large language models (LLMs) for event sequence modeling and analysis. The
  key idea is to use a knowledge graph of event concepts with causal relations to
  guide the LLM's generation of event sequences.
---

# Distilling Event Sequence Knowledge From Large Language Models

## Quick Facts
- arXiv ID: 2401.07237
- Source URL: https://arxiv.org/abs/2401.07237
- Authors: Somin Wadhwa; Oktie Hassanzadeh; Debarun Bhattacharjya; Ken Barker; Jian Ni
- Reference count: 40
- Primary result: Proposes using LLMs with knowledge graph guidance to generate structured event sequences for modeling and analysis

## Executive Summary
This paper presents a method to generate structured event sequences from large language models (LLMs) by using knowledge graphs of event concepts with causal relations as guidance. The approach employs iterative in-context learning with Wikidata concepts as prompts to generate sequences that fill knowledge gaps in the input KG. The generated sequences are then used for pattern mining and probabilistic event model learning, demonstrating high quality and utility for downstream tasks.

## Method Summary
The method uses a Knowledge Graph (KG) of event concepts from Wikidata to guide an LLM (Flan-T5-XXL) in generating causally coherent event sequences through iterative in-context learning. The process involves using event concepts and causal relations from the KG as prompts, generating sequences, and then using these sequences for pattern mining (GSP/SPADE) and learning probabilistic event models (Summary Markov Models). The approach aims to distill event sequence knowledge from LLMs while filling gaps in the KG and discovering new event patterns.

## Key Results
- LLM-generated sequences achieve high precision and recall when evaluated against Wikidata references
- The approach discovers new high-support event patterns through pattern mining algorithms
- Summary Markov Models identify influencing events for event prediction from generated sequences
- Generated sequences successfully fill knowledge gaps in the input knowledge graph

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative in-context prompting improves LLM-generated event sequence quality
- Mechanism: By appending generated events back into the prompt with additional ICL exemplars, the model receives feedback about its previous output, allowing it to build upon earlier decisions and maintain coherence
- Core assumption: LLMs can use their own outputs as valid context when generating subsequent events
- Evidence anchors:
  - [abstract]: "Our approach relies on a Knowledge Graph (KG) of event concepts with partial causal relations to guide the generative language model for causal event sequence generation"
  - [section 3]: "We show that our approach can generate high-quality event sequences, filling a knowledge gap in the input KG"
  - [corpus]: Weak - corpus doesn't directly address iterative prompting quality, but related papers on "Distilling the Essence" and "Latent Logic Tree Extraction" suggest iterative refinement methods work
- Break condition: If the model generates out-of-vocabulary events or nonsensical sequences, the iterative approach fails to correct itself

### Mechanism 2
- Claim: Wikidata knowledge graph guides LLM generation to produce causally coherent sequences
- Mechanism: The KG provides both vocabulary constraints and causal relationship exemplars that shape the LLM's generation to follow realistic event progressions
- Core assumption: LLMs have implicitly learned the causal relationships represented in Wikidata during pre-training
- Evidence anchors:
  - [abstract]: "Our approach relies on a Knowledge Graph (KG) of event concepts with partial causal relations to guide the generative language model"
  - [section 3]: "To effectively distill this knowledge, we use event-related concepts in Wikidata, a comprehensive general-domain knowledge graph, to guide the sequence generation"
  - [corpus]: Moderate - "LLM4ES: Learning User Embeddings from Event Sequences via Large Language Models" suggests KG-guided generation works
- Break condition: If the KG is too sparse or contains incorrect causal relations, the LLM will generate implausible sequences

### Mechanism 3
- Claim: LLM-generated sequences can fill knowledge gaps in sparse KGs
- Mechanism: By generating diverse event sequences that extend beyond the existing causal relations in Wikidata, the LLM creates new structured knowledge that can be mined for patterns and probabilistic models
- Core assumption: LLMs contain knowledge not present in the KG that can be extracted through generation
- Evidence anchors:
  - [abstract]: "Our approach can generate high-quality event sequences, filling a knowledge gap in the input KG"
  - [section 5.1]: "we use the generated event sequence collection followed by classical frequent itemset mining algorithms like GSP and SPADE to derive new high support patterns"
  - [corpus]: Weak - corpus doesn't provide direct evidence, but "Latent Logic Tree Extraction" suggests LLMs can generate novel structured knowledge
- Break condition: If the LLM generates sequences that don't extend the KG meaningfully or introduce contradictions

## Foundational Learning

- Concept: Knowledge distillation
  - Why needed here: The paper explicitly frames LLM generation as "distilling event sequence knowledge" from pre-trained models
  - Quick check question: What's the difference between training a model from scratch versus distilling knowledge from an existing model?

- Concept: Causal reasoning in event sequences
  - Why needed here: The approach relies on generating causally coherent event sequences that can be used for probabilistic modeling
  - Quick check question: How do you determine if two events have a causal relationship versus just being correlated?

- Concept: In-context learning (ICL)
  - Why needed here: The generation approach uses iterative ICL prompting to guide the LLM's output
  - Quick check question: What are the limitations of ICL compared to fine-tuning?

## Architecture Onboarding

- Component map: Knowledge Graph (Wikidata) -> LLM (Flan-T5-XXL) -> Pattern Mining (GSP/SPADE) -> Summary Markov Models (SuMMs) -> Evaluation framework
- Critical path: KG → LLM generation → sequence collection → pattern mining/SuMMs → evaluation
- Design tradeoffs:
  - Using LLMs vs traditional extraction methods: LLMs can generate longer, more coherent sequences but may introduce hallucinations
  - Wikidata vs domain-specific KGs: Wikidata is general but may lack domain depth
  - Iterative vs one-shot generation: Iterative improves coherence but increases computational cost
- Failure signatures:
  - Low precision scores indicate LLM generating implausible event sequences
  - Low recall scores suggest KG is too sparse to guide meaningful generation
  - Pattern mining yields no new insights, indicating generated sequences lack novelty
- First 3 experiments:
  1. Generate sequences for a simple event like "earthquake" and manually verify coherence
  2. Compare precision scores using different evaluator models (Flan-T5-Large vs Flan-T5-XXL)
  3. Apply GSP pattern mining to earthquake sequences and identify if new causal patterns emerge

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLM-generated event sequences compare to human-annotated event sequences in terms of predictive accuracy for downstream tasks like event forecasting?
- Basis in paper: [inferred] The paper mentions that LLMs can generate high-quality event sequences, but does not compare them directly to human-annotated sequences in terms of predictive accuracy.
- Why unresolved: The paper focuses on evaluating the quality of LLM-generated sequences using various metrics, but does not benchmark them against human-annotated sequences for predictive accuracy.
- What evidence would resolve it: A study comparing the predictive accuracy of models trained on LLM-generated event sequences versus those trained on human-annotated sequences for tasks like event forecasting would provide evidence.

### Open Question 2
- Question: Can the quality of LLM-generated event sequences be further improved by incorporating domain-specific knowledge or fine-tuning on task-specific data?
- Basis in paper: [explicit] The paper mentions that applying LLMs to generate domain-specific events may require considerable amounts of data to fine-tune these models, but does not explore this approach.
- Why unresolved: The paper focuses on using LLMs with general knowledge from Wikidata to generate event sequences, but does not investigate the potential benefits of incorporating domain-specific knowledge or fine-tuning on task-specific data.
- What evidence would resolve it: Experiments comparing the quality of LLM-generated event sequences before and after incorporating domain-specific knowledge or fine-tuning on task-specific data would provide evidence.

### Open Question 3
- Question: How does the choice of evaluator model (e.g., LLM size, architecture) affect the precision evaluation of LLM-generated event sequences?
- Basis in paper: [explicit] The paper mentions that using different evaluator models yields reliable results for comparing different models, but does not explore the impact of evaluator model choice on precision evaluation.
- Why unresolved: The paper uses different evaluator models to assess precision, but does not investigate how the choice of evaluator model (e.g., LLM size, architecture) affects the precision evaluation results.
- What evidence would resolve it: A study comparing the precision evaluation results of LLM-generated event sequences using different evaluator models (e.g., varying LLM sizes, architectures) would provide evidence.

## Limitations

- The iterative ICL approach's effectiveness depends heavily on the quality of prompts and in-context examples, which are not fully specified in the main text
- The evaluation relies on LLM-as-a-judge, which introduces potential circularity - using LLMs to evaluate LLM-generated content
- Claims about discovering new causal patterns and influencing events depend heavily on the quality of generated sequences and pattern mining algorithms

## Confidence

- **High confidence**: The overall approach of using KGs to guide LLM generation for event sequences is sound and technically feasible
- **Medium confidence**: Claims about precision and recall scores are verifiable, but the interpretation of what constitutes "high quality" sequences requires careful consideration
- **Low confidence**: Claims about discovering new causal patterns and influencing events depend heavily on the quality of generated sequences and pattern mining algorithms

## Next Checks

1. Conduct human evaluation of generated sequences for a small sample of events to verify if the sequences are indeed causally coherent and fill knowledge gaps
2. Test the approach on a domain-specific KG (e.g., medical events) to evaluate if the method generalizes beyond general-domain Wikidata
3. Perform ablation studies removing the iterative component to quantify its actual contribution to sequence quality improvement