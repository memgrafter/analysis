---
ver: rpa2
title: Toward Fair Graph Neural Networks Via Dual-Teacher Knowledge Distillation
arxiv_id: '2412.00382'
source_url: https://arxiv.org/abs/2412.00382
tags:
- graph
- data
- fairness
- teacher
- fairdtd
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses bias in Graph Neural Networks (GNNs) caused
  by sensitive attributes such as gender or religion. The authors propose FairDTD,
  a framework that uses dual-teacher knowledge distillation to learn fair GNN representations.
---

# Toward Fair Graph Neural Networks Via Dual-Teacher Knowledge Distillation

## Quick Facts
- arXiv ID: 2412.00382
- Source URL: https://arxiv.org/abs/2412.00382
- Authors: Chengyu Li; Debo Cheng; Guixian Zhang; Yi Li; Shichao Zhang
- Reference count: 6
- Key outcome: FairDTD framework achieves best fairness metrics (∆sp, ∆eo) while maintaining competitive accuracy on three real-world datasets

## Executive Summary
This paper addresses bias in Graph Neural Networks (GNNs) caused by sensitive attributes such as gender or religion. The authors propose FairDTD, a framework that uses dual-teacher knowledge distillation to learn fair GNN representations. The method employs two teacher models trained on partial data (node features or graph structure) to guide a student model, mitigating bias while preserving utility. Additional techniques include graph-level distillation and node-specific temperature adjustments to enhance knowledge transfer.

## Method Summary
FairDTD uses a dual-teacher knowledge distillation framework where two fairness-oriented teacher models are trained on partial data: one on node features only and one on graph structure only. These teachers guide a student model trained on full data through knowledge distillation. The framework incorporates graph-level distillation to align intermediate representations and a node-specific temperature module that adjusts softening based on each node's prediction confidence. This approach balances fairness and utility by transferring fair knowledge from partial-data teachers while maintaining performance from complete data.

## Key Results
- FairDTD achieves the best fairness metrics (∆sp and ∆eo) while maintaining competitive accuracy compared to baseline methods
- On Credit dataset, FairDTD achieved 80.83% accuracy with fairness scores of 2.41 (∆sp) and 1.90 (∆eo)
- Framework demonstrates strong generalization across different GNN architectures (GCN, GIN) and effectively balances fairness and utility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partial data training reduces bias at its source by blocking causal paths from sensitive attributes to predictions.
- Mechanism: Causal graph analysis shows sensitive attribute S influences predictions Y through two paths: S → E → X → Z → Y (via node features) and S → E → A → Z → Y (via graph structure). Training on only X or only A removes one path, reducing bias.
- Core assumption: The node feature and graph structure paths carry independent sources of bias, so removing one path significantly reduces overall bias.
- Evidence anchors: Abstract mentions partial data training significantly improves fairness; section describes causal paths from sensitive attribute to predictions; corpus provides weak evidence with only mentions partial data training.

### Mechanism 2
- Claim: Dual-teacher knowledge distillation balances fairness and utility by transferring fair knowledge from partial-data teachers while maintaining utility from complete data.
- Mechanism: Two teachers trained on partial data (feature teacher on X only, structure teacher on A only) learn fair representations. The student learns from both teachers through knowledge distillation while training on full data (X, A) to maintain utility.
- Core assumption: Teachers trained on partial data can provide effective guidance to a student trained on full data, and the fairness knowledge transfers effectively despite utility loss in teachers.
- Evidence anchors: Abstract describes dual distillation with feature and structure teachers; section explains targeted guidance from two fairness-oriented teacher models; corpus provides moderate evidence with multiple related papers using knowledge distillation for fairness.

### Mechanism 3
- Claim: Node-specific temperature scaling improves knowledge transfer by adapting softening to each node's prediction confidence.
- Mechanism: Instead of fixed temperature, each node gets a temperature based on the entropy of the teacher's logits. Nodes with high confidence (low entropy) get lower temperatures (sharper predictions), while uncertain nodes get higher temperatures (softer predictions).
- Core assumption: The relationship between prediction confidence and optimal temperature is monotonic and can be captured by entropy-based calculation.
- Evidence anchors: Abstract mentions node-specific temperature module adjusting temperature based on prediction confidence; section describes entropy-based approach for learning node-specific temperatures; corpus provides weak evidence with only mentions temperature scaling generally.

## Foundational Learning

- Concept: Causal graph modeling for bias identification
  - Why needed here: The paper uses causal graphs to identify how sensitive attributes influence predictions through node features and graph structure, which guides the partial data training strategy
  - Quick check question: Can you explain how a causal graph helps identify sources of bias in GNN predictions?

- Concept: Knowledge distillation fundamentals
  - Why needed here: The framework relies on transferring knowledge from partial-data teachers to a full-data student, requiring understanding of both hard and soft label distillation
  - Quick check question: What's the difference between hard labels and soft labels in knowledge distillation?

- Concept: Graph neural network architectures (GCN, GIN)
  - Why needed here: The framework uses both GCN and GIN as backbones, and understanding their message-passing mechanisms is crucial for implementing the student model
  - Quick check question: How do GCN and GIN differ in their aggregation functions?

## Architecture Onboarding

- Component map: Feature Teacher (MLP) -> Structure Teacher (GCN) -> Node-specific Temperature Module -> Dual Distillation -> Graph-level Distillation -> Student Model (GCN/GIN) -> Output

- Critical path: Data → Feature Teacher → Structure Teacher → Node-specific Temperatures → Dual Distillation → Graph-level Distillation → Student Model → Output

- Design tradeoffs:
  - Partial data training improves fairness but reduces teacher utility
  - Fixed temperature is simpler but less adaptive than node-specific temperatures
  - Graph-level distillation adds computational overhead but improves knowledge transfer
  - Using two separate teacher architectures (MLP and GCN) increases complexity but provides complementary information

- Failure signatures:
  - Poor fairness metrics despite training (teachers aren't learning fair representations)
  - Significant accuracy drop compared to baseline (student not leveraging full data effectively)
  - Training instability or divergence (node-specific temperature calculation problematic)
  - Slow convergence (graph-level distillation adding too much complexity)

- First 3 experiments:
  1. Implement feature teacher and structure teacher separately on partial data, verify they achieve better fairness than full-data baseline
  2. Add dual-teacher distillation with fixed temperature, measure improvement over partial data training
  3. Implement node-specific temperature module, compare performance against fixed temperature baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FairDTD's performance scale with graph size and complexity, particularly for very large-scale graphs?
- Basis in paper: The paper only evaluates on datasets with up to 30,000 nodes, leaving scalability to larger graphs unexplored.
- Why unresolved: The paper does not provide experiments or theoretical analysis on performance with graphs containing millions of nodes or edges.
- What evidence would resolve it: Experiments on large-scale real-world graphs (e.g., social networks with millions of nodes) or theoretical analysis of time/space complexity.

### Open Question 2
- Question: Can FairDTD effectively handle multiple sensitive attributes simultaneously?
- Basis in paper: The paper explicitly states that FairDTD currently focuses on a single sensitive attribute and future research will extend to multiple attributes.
- Why unresolved: The framework's dual-teacher approach and node-specific temperature module have not been tested or adapted for multi-attribute scenarios.
- What evidence would resolve it: Experiments comparing FairDTD's performance on datasets with multiple sensitive attributes versus single-attribute cases.

### Open Question 3
- Question: How sensitive is FairDTD to the choice of hyperparameters, particularly the balance parameter α and temperature ranges?
- Basis in paper: The paper provides sensitivity analysis for α and temperature ranges, but only explores a limited range of values.
- Why unresolved: The analysis is incomplete, and the paper does not explore how different hyperparameter combinations affect performance across diverse datasets.
- What evidence would resolve it: A comprehensive grid search or Bayesian optimization study across a wider range of hyperparameters and datasets.

## Limitations
- Causal graph analysis provides theoretical justification but lacks empirical validation of path importance
- Node-specific temperature mechanism is novel but lacks ablation studies showing its necessity
- Framework's generalization to non-binary sensitive attributes and larger graphs remains untested

## Confidence

- Mechanism 1 (Causal partial data training): Medium - Strong theoretical basis but limited empirical validation of path importance
- Mechanism 2 (Dual-teacher distillation): High - Well-established knowledge distillation approach with clear implementation
- Mechanism 3 (Node-specific temperature): Low-Medium - Novel component with minimal ablation or sensitivity analysis

## Next Checks
1. Conduct ablation study removing node-specific temperature to quantify its contribution to overall performance
2. Test framework on datasets with multi-category sensitive attributes to verify generalization
3. Measure and compare the individual contributions of feature teacher vs structure teacher to fairness gains