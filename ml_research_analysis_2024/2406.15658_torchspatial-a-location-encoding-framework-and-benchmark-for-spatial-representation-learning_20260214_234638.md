---
ver: rpa2
title: 'TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation
  Learning'
arxiv_id: '2406.15658'
source_url: https://arxiv.org/abs/2406.15658
tags:
- location
- spatial
- image
- learning
- geo-aware
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TorchSpatial, a deep learning framework and
  benchmark for spatial representation learning (SRL), with a focus on location encoding.
  The framework consolidates 15 widely used location encoders and provides a comprehensive
  benchmark, LocBench, consisting of 7 geo-aware image classification and 4 geo-aware
  image regression datasets.
---

# TorchSpatial: A Location Encoding Framework and Benchmark for Spatial Representation Learning

## Quick Facts
- arXiv ID: 2406.15658
- Source URL: https://arxiv.org/abs/2406.15658
- Authors: Nemin Wu, Qian Cao, Zhangyu Wang, Zeping Liu, Yanlin Qi, Jielu Zhang, Joshua Ni, Xiaobai Yao, Hongxu Ma, Lan Mu, Stefano Ermon, Tanuja Ganu, Akshay Nambi, Ni Lao, Gengchen Mai
- Reference count: 40
- Key outcome: Introduces TorchSpatial framework with 15 location encoders, 7 geo-aware image classification datasets, 4 geo-aware image regression datasets, and a Geo-Bias Score metric for evaluating geographic bias

## Executive Summary
This paper introduces TorchSpatial, a comprehensive deep learning framework and benchmark for spatial representation learning (SRL) with a focus on location encoding. The framework consolidates 15 widely used location encoders and provides a comprehensive benchmark, LocBench, consisting of 7 geo-aware image classification and 4 geo-aware image regression datasets. A novel Geo-Bias Score metric is introduced to systematically evaluate geographic bias in model performance. Experiments demonstrate that incorporating location encoders significantly boosts model performance across tasks but also increases geographic bias, especially in geographically biased datasets. The framework and benchmark are publicly available to advance SRL research and spatial fairness in GeoAI.

## Method Summary
The TorchSpatial framework evaluates 15 location encoders on 7 geo-aware image classification datasets and 4 geo-aware image regression datasets. The framework combines image embeddings with location embeddings through either element-wise multiplication or concatenation, followed by an MLP head for prediction. Models are trained using grid search followed by Optuna optimization. Performance is measured using standard metrics (Top-1 accuracy, Top-3 accuracy, MRR for classification; R2, MAE, RMSE for regression) along with the novel Geo-Bias Score metric that quantifies geographic bias through spatial autocorrelation analysis.

## Key Results
- Incorporating location encoders significantly boosts model performance across tasks, with Sphere2Vec-sphereC` winning on 4 datasets
- Location encoders increase geographic bias, particularly in geographically biased datasets
- The Geo-Bias Score provides a systematic way to quantify geographic bias in model performance
- Tile and wrap encoders perform well on geographically biased datasets, while Fourier-based encoders work better on uniformly sampled datasets

## Why This Works (Mechanism)

### Mechanism 1
Location encoders improve model performance by adding geographic context that is not captured by image features alone. The location encoder transforms raw coordinates into a high-dimensional embedding that captures spatial patterns. This embedding is then combined with image embeddings (via multiplication or concatenation) to provide additional contextual information to the model.

### Mechanism 2
The Geo-Bias Score metric provides a systematic way to quantify geographic bias in model performance. The metric uses spatial self-information (SSI) to measure the strength of spatial autocorrelation in model performance patterns. Lower performance in certain geographic regions creates spatial patterns that are quantified by the SSI.

### Mechanism 3
Different location encoders have varying effectiveness depending on the dataset characteristics and task type. Location encoders use different mathematical approaches (grid-based, Fourier features, spherical harmonics, etc.) to transform coordinates. These approaches have different strengths depending on the spatial distribution of data and the nature of the prediction task.

## Foundational Learning

- **Concept**: Spatial autocorrelation
  - Why needed here: Understanding how geographic bias manifests as non-random patterns in model performance across space
  - Quick check question: What does positive spatial autocorrelation mean for model performance patterns?

- **Concept**: Position encoding
  - Why needed here: Location encoders transform raw coordinates into embeddings using various mathematical techniques
  - Quick check question: What is the difference between tile-based and Fourier-based position encoding approaches?

- **Concept**: Spatial self-information
  - Why needed here: The Geo-Bias Score metric uses SSI to quantify spatial patterns in performance
  - Quick check question: How does spatial self-information differ from traditional spatial autocorrelation measures?

## Architecture Onboarding

- **Component map**: Image encoder -> Location encoder -> Fusion (multiplication/concatenation) -> MLP head -> Output

- **Critical path**: Input → Image encoder → Location encoder → Fusion → MLP → Output

- **Design tradeoffs**:
  - Coordinate system choice (2D vs 3D projection)
  - Encoding method (grid, Fourier, spherical harmonics, etc.)
  - Fusion strategy (element-wise multiplication vs concatenation)
  - Model complexity vs. performance gains

- **Failure signatures**:
  - Location encoders degrade performance on datasets with uniform spatial distribution
  - Geo-Bias Score indicates bias but visual inspection shows no geographic patterns
  - Different encoders perform similarly across all datasets

- **First 3 experiments**:
  1. Compare baseline image-only model vs. same model with tile encoder on a geographically biased dataset
  2. Test multiple location encoders (tile, wrap, Sphere2Vec) on the same dataset to compare performance
  3. Evaluate Geo-Bias Score on a uniformly sampled dataset to verify it detects no bias

## Open Questions the Paper Calls Out

### Open Question 1
Does the effectiveness of location encoders generalize to other spatial data types beyond points, such as polylines, polygons, and spatial networks? The authors explicitly state that TorchSpatial currently only supports location encoder development and plan to extend its capability to support more spatial data types in the future.

### Open Question 2
How do location encoders impact model performance and geographic bias on datasets with different levels of geographic bias? The authors observe that location encoders significantly boost model performance but also increase geographic bias, especially in geographically biased datasets.

### Open Question 3
Can the Geo-Bias Score metric be used to evaluate geographic bias in other types of models beyond location encoders? The authors propose the Geo-Bias Score as a systematic and universally applicable geographic bias evaluation framework that can be used to assess any AI models, including large language models.

## Limitations
- The framework only evaluates location encoders on point data, not other spatial data types like polylines or polygons
- Limited exploration of the tradeoff between accuracy improvements and increased model complexity or inference time
- Geographic bias findings need further investigation to determine if performance patterns correspond to meaningful real-world outcome differences

## Confidence
- Performance improvement claims: Medium
- Geo-Bias Score effectiveness: Medium
- Location encoder comparison results: Medium
- Framework reproducibility: High

## Next Checks
1. Validate Geo-Bias Score on synthetic datasets with known spatial patterns to confirm it accurately detects geographic bias across different distributions
2. Conduct ablation studies removing location encoders from top-performing models to quantify the minimum performance gain across all datasets
3. Test the framework on additional geo-aware tasks (e.g., environmental monitoring, urban planning) to assess generalizability beyond the current benchmark