---
ver: rpa2
title: 'SceneGraMMi: Scene Graph-boosted Hybrid-fusion for Multi-Modal Misinformation
  Veracity Prediction'
arxiv_id: '2410.15517'
source_url: https://arxiv.org/abs/2410.15517
tags:
- news
- fake
- detection
- scene
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of multi-modal misinformation
  detection by proposing SceneGraMMi, a model that integrates scene graphs from both
  text and image modalities with hybrid fusion. The approach uses a transformer-based
  encoder for early fusion of text and image patches, and a graph neural network-based
  scene graph module for late fusion of structured scene graph representations.
---

# SceneGraMMi: Scene Graph-boosted Hybrid-fusion for Multi-Modal Misinformation Veracity Prediction

## Quick Facts
- arXiv ID: 2410.15517
- Source URL: https://arxiv.org/abs/2410.15517
- Reference count: 22
- Primary result: Achieves up to 94.4% accuracy on Politifact dataset

## Executive Summary
SceneGraMMi addresses multi-modal misinformation detection by integrating scene graphs from both text and image modalities with hybrid fusion. The model combines a transformer-based encoder for early fusion of text and image patches with a graph neural network-based scene graph module for late fusion of structured representations. Experimental results demonstrate consistent superiority over state-of-the-art methods across four benchmark datasets, with accuracy reaching 94.4% on Politifact.

## Method Summary
SceneGraMMi is a hybrid-fusion model that processes multi-modal misinformation data through two parallel pathways. The Transformer-based Encoder Module (TEM) performs early fusion by concatenating BERT-processed text and image patch embeddings, learning cross-modal interactions via self-attention. The GNN-based Scene Graph Module (GSGM) generates and processes separate text and visual scene graphs, capturing entity relationships and attributes. The model fuses outputs from both modules and applies a feed-forward network for classification, with Shapley values providing explainability by identifying key features used in decisions.

## Key Results
- Achieves 94.4% accuracy on Politifact dataset, outperforming state-of-the-art methods
- Consistently demonstrates superior performance across Twitter, Weibo, Politifact, and Gossipcop datasets
- Ablation studies show importance of both textual and visual scene graphs for robust performance
- Shapley value analysis provides interpretable explanations for classification decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hybrid fusion of transformer-based encoder with scene graph GNN improves misinformation detection by capturing both semantic and structural relationships across modalities
- Mechanism: The transformer encoder performs early fusion by concatenating text and image patch embeddings, learning cross-modal interactions through self-attention. The GNN module performs late fusion by processing scene graphs (TSG and VSG) to capture entity relationships and attributes. Final classification uses concatenated representations from both modules
- Core assumption: Both semantic content (text/image) and structural relationships (scene graphs) contain complementary information useful for detecting misinformation
- Evidence anchors:
  - [abstract] "which integrates scene graphs across different modalities to improve detection performance"
  - [section] "Our approach consistently outperforms or competes with state-of-the-art methods across diverse datasets, achieving high accuracy, precision, recall, and F1-scores"
  - [corpus] Weak - corpus contains related papers but no direct evidence supporting this specific mechanism
- Break condition: If scene graph generation fails to capture meaningful relationships, or if transformer encoder cannot effectively fuse modalities, performance degrades significantly

### Mechanism 2
- Claim: Scene graphs provide structured representation that addresses limitations of sequential processing in misinformation detection
- Mechanism: Scene graphs (VO, VA, VR, E) represent entities as nodes with relationships as edges, capturing semantic dependencies that are difficult to model in sequential text or image processing. Separate GNNs process TSG and VSG, then concatenate embeddings for final classification
- Core assumption: Misinformation often involves inconsistent or deceptive relationships between entities that can be better detected through structured graph representations rather than sequential processing
- Evidence anchors:
  - [section] "Scene graphs (Li et al., 2017; Zhang et al., 2017; Yang et al., 2018) offer a structured representation of content, addressing contextual challenges often encountered in sequential text processing"
  - [section] "A scene graph G (Figure 2) is defined as a tuple (VO, VA, VR, E) where..."
  - [corpus] Weak - related papers discuss misinformation detection but not specifically scene graph benefits
- Break condition: If input text/images lack sufficient entities/relationships, or if graph structure becomes too sparse, scene graph module provides limited value

### Mechanism 3
- Claim: Shapley value-based explainability identifies key features used for classification, improving trust and interpretability
- Mechanism: Shapley values from game theory are used to attribute importance to different input features (text, image, scene graph components) in the final classification decision, highlighting what the model focuses on
- Core assumption: Understanding which features drive model decisions is crucial for trust and debugging in misinformation detection applications
- Evidence anchors:
  - [abstract] "Additionally, the use of Shapley values provides explainability by identifying key features used for classification"
  - [section] "In Figure 3a, an image of a speech at a presidential debate is observed. The image consists of a man speaking in a presidential debate. The model is able to focus and identify the man..."
  - [corpus] Weak - corpus contains related explainability papers but not specifically Shapley value applications
- Break condition: If Shapley value computation is too expensive or if explanations don't align with human judgment, the explainability component may not be practically useful

## Foundational Learning

- Concept: Transformer architecture and self-attention mechanism
  - Why needed here: Understanding how transformer encoder processes concatenated text and image embeddings through self-attention is crucial for grasping early fusion component
  - Quick check question: How does self-attention allow the transformer to focus on different parts of the input data simultaneously when processing multimodal inputs?

- Concept: Graph Neural Networks and message passing
  - Why needed here: GNN processes scene graphs by propagating information through nodes and edges, which is essential for understanding late fusion component
  - Quick check question: How do GCN layers update node representations based on their neighbors in the scene graph?

- Concept: Scene graph representation and generation
  - Why needed here: Understanding how scene graphs are structured (objects, attributes, relationships) and generated from text/images is key to the model's approach
  - Quick check question: What are the components of a scene graph and how are they extracted from different modalities?

## Architecture Onboarding

- Component map: Input → TEM → GSGM → Fusion → FFN → Classification
- Critical path: The transformer encoder and GNN modules operate in parallel, then their outputs are fused for final classification
- Design tradeoffs:
  - Early fusion (TEM) captures cross-modal interactions but requires careful handling of different input types
  - Late fusion (GSGM) preserves modality-specific information but may miss cross-modal relationships
  - Using both provides complementary information but increases computational cost
- Failure signatures:
  - Poor performance on samples with minimal visual content suggests TEM underutilizes text-only information
  - Performance drops when scene graphs are sparse indicate GSGM relies heavily on rich graph structure
  - Inconsistent results across datasets suggest model may overfit to specific dataset characteristics
- First 3 experiments:
  1. Remove TSG from model (Full SceneGraMMi w/o TSG) to verify contribution of textual scene graphs
  2. Remove VSG from model (Full SceneGraMMi w/o VSG) to verify contribution of visual scene graphs
  3. Remove entire GSGM module to measure impact of late fusion through scene graphs

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Reliance on pre-trained scene graph generators with unspecified model versions and hyperparameters
- Ablation studies remove entire modules rather than individual components, limiting understanding of specific contributions
- Explainability analysis lacks quantitative metrics to evaluate the quality and reliability of Shapley value attributions

## Confidence
- High confidence: The hybrid fusion architecture combining transformer and GNN modules is technically sound and well-implemented
- Medium confidence: The experimental results show consistent improvements over baselines, but the specific contribution of scene graphs versus other architectural choices remains unclear
- Low confidence: The explainability claims lack rigorous validation and quantitative evaluation of the Shapley value attributions

## Next Checks
1. Conduct ablation studies removing individual components (objects, attributes, relationships) from scene graphs rather than entire modules to better understand their specific contributions
2. Implement a controlled experiment comparing SceneGraMMi against a transformer-only baseline with identical training procedures to isolate the impact of the GNN components
3. Develop quantitative metrics for evaluating the quality of Shapley value explanations, such as alignment with human annotations or consistency across similar samples