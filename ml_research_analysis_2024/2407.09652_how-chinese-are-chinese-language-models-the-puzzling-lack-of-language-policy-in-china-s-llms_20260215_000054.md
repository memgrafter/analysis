---
ver: rpa2
title: How Chinese are Chinese Language Models? The Puzzling Lack of Language Policy
  in China's LLMs
arxiv_id: '2407.09652'
source_url: https://arxiv.org/abs/2407.09652
tags:
- language
- languages
- chinese
- mandarin
- china
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether Chinese-developed large language
  models (LLMs) reflect China's language policy toward linguistic diversity. Researchers
  evaluated six Chinese open-source multilingual models (Qwen1.5-7B, Yi-6B, DeepSeek-LLM-7B,
  InternLM2-7B, XVERSE-7B, Baichuan2-7B) and compared them with international models
  (Llama3-8B, Mistral-7B) on 18 languages including Mandarin, English, Japanese, Korean,
  Southeast Asian languages, and Chinese ethnic minority languages.
---

# How Chinese are Chinese Language Models? The Puzzling Lack of Language Policy in China's LLMs

## Quick Facts
- arXiv ID: 2407.09652
- Source URL: https://arxiv.org/abs/2407.09652
- Authors: Andrea W Wen-Yi; Unso Eun Seo Jo; Lu Jia Lin; David Mimno
- Reference count: 19
- One-line primary result: Chinese open-source LLMs show no evidence of prioritizing or deprioritizing minority languages despite China's official assimilationist language policy

## Executive Summary
This study investigates whether Chinese-developed large language models (LLMs) reflect China's language policy toward linguistic diversity. Researchers evaluated six Chinese open-source multilingual models and compared them with international models on 18 languages including Mandarin, English, Japanese, Korean, Southeast Asian languages, and Chinese ethnic minority languages. Through two experiments measuring language modeling perplexity and zero-shot reading comprehension, the study found no significant performance differences between Chinese and international models. Both groups showed similar patterns: best performance on Mandarin and European languages, followed by Northeast Asian languages, and worst on Chinese minority languages.

The analysis revealed that model performance strongly correlates with the number of language speakers and national GDP, but not with any deliberate Chinese policy intervention. Despite China's assimilationist language policies and AI regulations, no evidence was found of Chinese AI companies prioritizing or deprioritizing minority languages in their models. The lack of minority language performance appears to be driven by data availability rather than intentional policy choices.

## Method Summary
The study evaluates eight LLMs (six Chinese and two international) on 18 languages using two complementary experiments. Experiment 1 measures language modeling perplexity on FLORES+ dataset with 997 parallel sentences across all languages. Experiment 2 evaluates zero-shot reading comprehension using Belebele benchmark with 900 multiple-choice questions per language. The researchers calculate unnormalized negative log likelihood instead of perplexity to account for varying tokenization rates across languages. They then analyze correlation patterns between model performance and external demographic data including language speaker populations and national GDPs.

## Key Results
- Chinese and international models show similar performance patterns across all 18 languages tested
- Both model groups perform best on Mandarin and European languages, followed by Northeast Asian languages, with worst performance on Chinese minority languages
- Model performance correlates strongly with language speaker population (correlation -0.845 for Chinese models, -0.883 for international models on perplexity) and national GDP
- No evidence found of deliberate Chinese policy intervention in model training data composition regarding minority languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chinese LLMs do not show policy-driven prioritization or deprioritization of minority languages despite China's official assimilationist language policy.
- Mechanism: The models' performance across 18 languages correlates strongly with language speaker population and national GDP, but not with any deliberate Chinese language policy intervention.
- Core assumption: The lack of minority language performance is due to data availability rather than intentional policy choices.
- Evidence anchors:
  - [abstract] "we find no evidence of PRC priorities for minority languages — either for or against — in open-source LLMs"
  - [section] "Despite China's assimilationist language policies and AI regulations, no evidence was found of Chinese AI companies prioritizing or deprioritizing minority languages in their models"
  - [corpus] Weak - the corpus contains related papers but none directly showing policy mechanisms affecting model training data composition
- Break condition: If future audits reveal systematic exclusion of minority language data from training corpora, this mechanism would break.

### Mechanism 2
- Claim: Both Chinese and international models show similar performance patterns across languages, with best performance on Mandarin and European languages, followed by Northeast Asian languages, and worst on Chinese minority languages.
- Mechanism: Model performance is driven primarily by data availability patterns rather than national origin of the model developers.
- Core assumption: Training data sources (like Common Crawl) have similar language distributions regardless of model origin.
- Evidence anchors:
  - [abstract] "Both groups showed similar patterns: best performance on Mandarin and European languages, followed by Northeast Asian languages, and worst on Chinese minority languages"
  - [section] "We find no clear distinctions between Chinese and international models across languages"
  - [corpus] Weak - no corpus evidence directly linking training data sources to performance patterns
- Break condition: If analysis shows Chinese models deliberately under-represent minority languages in training data compared to international models, this mechanism would break.

### Mechanism 3
- Claim: Technical reports from Chinese AI companies show lack of consideration for pretraining data language coverage except for English and Mandarin Chinese.
- Mechanism: Chinese companies follow similar data collection practices as international companies, focusing on web data without explicit multilingual diversity strategies.
- Core assumption: Companies prioritize languages based on data availability rather than policy requirements.
- Evidence anchors:
  - [section] "Similarly, the models' technical reports also show lack of consideration for pretraining data language coverage except for English and Mandarin Chinese"
  - [section] "sources of pretrained data rely heavily on web pages, with three reports specifically mentioning Common Crawl as their primary data source"
  - [corpus] Weak - corpus contains related papers but no direct evidence about Chinese companies' data collection practices
- Break condition: If technical reports reveal explicit strategies to limit minority language representation, this mechanism would break.

## Foundational Learning

- Concept: Language model perplexity and its limitations across different tokenization schemes
  - Why needed here: The study uses unnormalized negative log likelihood instead of perplexity to account for varying tokenization rates across languages
  - Quick check question: Why can't we directly compare perplexity scores across languages with different tokenization rates?

- Concept: Zero-shot reading comprehension evaluation
  - Why needed here: The study uses Belebele benchmark for zero-shot MRC to complement perplexity measurements
  - Quick check question: What is the advantage of using zero-shot MRC over perplexity for evaluating language understanding?

- Concept: Correlation analysis and its interpretation
  - Why needed here: The study finds strong correlations between model performance and language speaker population/GDP
  - Quick check question: What does a correlation coefficient of -0.845 between language speaker population and NLL indicate about the relationship?

## Architecture Onboarding

- Component map: Data preprocessing (tokenization) -> Model evaluation (perplexity calculation, MRC evaluation) -> Result aggregation -> Statistical analysis (correlation with demographic data)
- Critical path: Data preprocessing → Model evaluation → Result aggregation → Statistical analysis
- Design tradeoffs: Using unnormalized NLL instead of perplexity trades interpretability for cross-language comparability; zero-shot evaluation trades precision for generalizability
- Failure signatures: If tokenization leads to highly variable fragmentations across languages, or if correlation analysis reveals policy-driven patterns rather than data-driven ones
- First 3 experiments:
  1. Replicate the tokenization analysis to confirm varying segmentation rates across languages
  2. Test model performance on additional Chinese Han dialects if data becomes available
  3. Compare training data composition between Chinese and international models to identify any systematic differences in language representation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do Chinese AI companies intentionally deprioritize Chinese ethnic minority languages in their model training, or is the lack of performance purely driven by data availability constraints?
- Basis in paper: Explicit - The paper explicitly states "we find no evidence of PRC priorities for minority languages — either for or against — in open-source LLMs" and "we find no sign of any consistent policy, either for or against, language diversity in China's LLM development"
- Why unresolved: The study found no evidence of deliberate policy either supporting or deprioritizing minority languages, but couldn't determine if the poor performance is due to intentional neglect or simply lack of available training data
- What evidence would resolve it: Detailed analysis of training data sources showing whether companies actively avoided minority language data or simply didn't have access to it, or interviews with developers about their data collection priorities

### Open Question 2
- Question: Would closed-source Chinese LLMs show different performance patterns on minority languages compared to the open-source models studied?
- Basis in paper: Explicit - The paper states "we do not evaluate closed-source LLMs in this study. It is possible that closed-source LLMs' development and capabilities differ from open-source ones"
- Why unresolved: The study only examined open-source models and acknowledges this limitation, leaving uncertainty about whether companies might prioritize minority languages in closed models for government use
- What evidence would resolve it: Performance testing of closed-source Chinese LLMs on the same benchmark languages, or access to their training data composition

### Open Question 3
- Question: How would Chinese LLMs perform on Chinese Han dialects like Cantonese or Shanghainese if standardized written forms were available?
- Basis in paper: Explicit - The paper states "we do not evaluate Chinese Han dialects" and "The difficulty in evaluating Han dialects is that, except for Cantonese in Hong Kong, these dialects often do not have standardized writing forms"
- Why unresolved: The study excluded Han dialects due to lack of standardized written forms, but these dialects are widely spoken and their performance could reveal different patterns than ethnic minority languages
- What evidence would resolve it: Creation of standardized written forms for major Han dialects and evaluation of Chinese LLMs on these, or development of speech-based evaluation methods for dialect performance

## Limitations
- The study only examines open-source models, which may not represent the full landscape of Chinese AI development including proprietary models
- Analysis assumes similar training data sources across model origins but cannot verify this assumption
- Focus on 18 languages may miss nuanced differences in how models handle linguistic variations within those categories

## Confidence

- **High confidence**: Chinese and international models show similar performance patterns across languages, with strong correlations to speaker population and GDP
- **Medium confidence**: No deliberate Chinese policy intervention is evident in the models based on available metrics
- **Low confidence**: Claims about specific mechanisms of data collection and training practices in Chinese AI companies due to limited public documentation

## Next Checks

1. **Training Data Audit**: Conduct a comprehensive audit of the actual training data composition for both Chinese and international models to verify whether language distribution patterns align with the observed performance patterns.

2. **Expanded Language Coverage**: Test model performance on additional Chinese minority languages and dialects not included in the current evaluation to determine if patterns hold across a broader linguistic spectrum.

3. **Proprietary Model Analysis**: If possible, include evaluation of Chinese proprietary models to determine whether open-source models are representative of China's broader AI landscape and language policy implementation.