---
ver: rpa2
title: Finetuning Generative Large Language Models with Discrimination Instructions
  for Knowledge Graph Completion
arxiv_id: '2407.16127'
source_url: https://arxiv.org/abs/2407.16127
tags:
- dift
- knowledge
- entity
- entities
- completion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DIFT, a framework that finetunes generative
  large language models (LLMs) with discrimination instructions for knowledge graph
  (KG) completion. The key idea is to avoid grounding errors by having LLMs select
  entities from a given candidate list rather than generating unconstrained text.
---

# Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion

## Quick Facts
- **arXiv ID**: 2407.16127
- **Source URL**: https://arxiv.org/abs/2407.16127
- **Reference count**: 39
- **Primary result**: Achieves 0.364 Hits@1 on FB15K-237 and 0.616 on WN18RR

## Executive Summary
This paper introduces DIFT, a framework that finetunes generative large language models (LLMs) for knowledge graph completion by using discrimination instructions. The key innovation is to avoid grounding errors by having LLMs select entities from a given candidate list rather than generating unconstrained text. DIFT employs a lightweight embedding-based model to provide top candidates, then finetunes an LLM using parameter-efficient methods (e.g., LoRA) with discrimination instructions. The framework demonstrates state-of-the-art performance on benchmark datasets FB15K-237 and WN18RR, achieving significant improvements in entity prediction accuracy.

## Method Summary
DIFT addresses grounding errors in generative KG completion by using discrimination instructions where LLMs select from candidate lists rather than generating free text. The framework uses a lightweight embedding-based model to generate top entity candidates, then finetunes the LLM using parameter-efficient methods like LoRA with discrimination instructions. To improve efficiency, DIFT employs truncated sampling to select useful training samples and injects KG embeddings into the LLM. The two-stage approach combines the precision of discriminative methods with the flexibility of generative models, achieving superior performance on standard KG completion benchmarks.

## Key Results
- Achieves 0.364 Hits@1 on FB15K-237, outperforming previous state-of-the-art methods
- Achieves 0.616 Hits@1 on WN18RR, setting new benchmark records
- Demonstrates significant performance improvements over both traditional embedding-based methods and direct generative approaches

## Why This Works (Mechanism)
DIFT works by converting the generative KG completion task into a discriminative selection problem. By providing LLMs with candidate lists rather than requiring free-form generation, the framework eliminates grounding errors where models hallucinate non-existent entities. The discrimination instructions guide the LLM to evaluate and select the most appropriate entity from the candidate set. This approach leverages the strong reasoning capabilities of LLMs while constraining their output to valid knowledge graph entities, combining the best aspects of both generative and discriminative approaches.

## Foundational Learning
- **Knowledge Graph Completion**: Predicting missing links in knowledge graphs; needed to understand the core problem being solved, quick check: can you explain what a triple (head, relation, tail) represents?
- **Discrimination Instructions**: Prompts that guide models to select from options rather than generate; needed to grasp DIFT's key innovation, quick check: can you formulate a discrimination instruction for entity selection?
- **Parameter-Efficient Fine-tuning (LoRA)**: Methods that update only a small subset of model parameters during finetuning; needed to understand how DIFT adapts large LLMs efficiently, quick check: can you contrast LoRA with full model fine-tuning?
- **KG Embeddings**: Vector representations of knowledge graph entities and relations; needed to understand how candidate lists are generated, quick check: can you describe how TransE or DistMult generate entity embeddings?
- **Truncated Sampling**: Selecting a subset of training samples based on some criterion; needed to understand DIFT's efficiency optimization, quick check: can you explain why sampling might improve training efficiency?

## Architecture Onboarding

**Component Map**: Embedding Model -> Candidate Generation -> LLM Fine-tuning -> KG Completion

**Critical Path**: The core workflow flows from lightweight embedding model generating candidate lists, which are then used to train the LLM with discrimination instructions. The LLM fine-tuning with LoRA is the most critical component as it determines final performance.

**Design Tradeoffs**: The framework trades off some of the flexibility of free-form generation for the reliability of candidate selection. This eliminates grounding errors but may miss novel or rare entities not in the candidate list. The two-stage approach adds computational overhead compared to end-to-end methods but provides better control and interpretability.

**Failure Signatures**: Poor candidate generation from the embedding model will directly degrade LLM performance regardless of fine-tuning quality. If the discrimination instructions are poorly formulated, the LLM may still produce incorrect selections. Over-reliance on truncated sampling might miss important edge cases in the training data.

**3 First Experiments**:
1. Verify that discrimination instructions consistently outperform free-form generation on a small subset of FB15K-237
2. Test the impact of different candidate list sizes on LLM selection accuracy
3. Measure the contribution of KG embedding injection by comparing with and without this component

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Performance validated only on two relatively small benchmark datasets (FB15K-237 and WN18RR), not tested on larger-scale knowledge graphs
- Truncated sampling strategy uses a fixed 0.5 threshold without extensive justification for optimality
- KG embedding injection mechanism lacks ablation studies to isolate its individual contribution
- Does not address potential biases or error propagation from the lightweight embedding model's candidate generation
- Computational overhead of the two-stage approach versus end-to-end alternatives is not thoroughly analyzed

## Confidence
- **High confidence** in core methodology and benchmark results: The experimental setup is well-defined, reproducible, and demonstrates clear performance improvements
- **Medium confidence** in generalizability to larger knowledge graphs and real-world applications: Limited dataset scope and missing robustness analyses for diverse entity distributions

## Next Checks
1. Evaluate DIFT on larger-scale knowledge graphs (e.g., Wikidata, YAGO) to test scalability and performance on more diverse entity distributions
2. Conduct ablation studies to quantify the individual contributions of discrimination instructions, truncated sampling, and KG embedding injection to overall performance gains
3. Test framework robustness to noisy or incomplete candidate lists generated by the embedding model to assess error propagation and mitigation strategies