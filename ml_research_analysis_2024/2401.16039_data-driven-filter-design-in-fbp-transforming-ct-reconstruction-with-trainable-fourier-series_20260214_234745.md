---
ver: rpa2
title: 'Data-Driven Filter Design in FBP: Transforming CT Reconstruction with Trainable
  Fourier Series'
arxiv_id: '2401.16039'
source_url: https://arxiv.org/abs/2401.16039
tags:
- filter
- fourier
- loss
- image
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Fourier series-based trainable filter for
  CT reconstruction within the FBP framework, addressing noise reduction and image
  blurring issues in traditional methods. The approach constructs a data-driven filter
  by optimizing Fourier series coefficients, maintaining computational efficiency
  with minimal trainable parameters.
---

# Data-Driven Filter Design in FBP: Transforming CT Reconstruction with Trainable Fourier Series

## Quick Facts
- arXiv ID: 2401.16039
- Source URL: https://arxiv.org/abs/2401.16039
- Reference count: 11
- Key outcome: Superior CT reconstruction performance with SSIM of 0.9379 ± 0.0718, MSE of 0.0009 ± 0.0005, and PSNR of 31.2365 ± 2.0532 dB compared to traditional FBP

## Executive Summary
This paper introduces a Fourier series-based trainable filter for CT reconstruction within the FBP framework, addressing noise reduction and image blurring issues in traditional methods. The approach constructs a data-driven filter by optimizing Fourier series coefficients, maintaining computational efficiency with minimal trainable parameters. A Gaussian edge-enhanced (GEE) loss function is proposed, focusing on the L1 norm of high-frequency magnitudes to preserve image details and sharpness. The method demonstrates superior performance in terms of SSIM, MSE, and PSNR compared to traditional FBP. The research presents a robust, scalable, and interpretable solution for CT reconstruction, suitable for a wide range of practical applications in medical and scientific imaging.

## Method Summary
The method introduces a data-driven filter for CT reconstruction by optimizing Fourier series coefficients within the FBP framework. The filter kernel is constructed in the Fourier domain using 101 trainable parameters (50 orders of Fourier series coefficients), ensuring computational efficiency while maintaining resolution adaptability. A hybrid loss function combining MSE, GEE loss, and GV loss is employed to preserve high-frequency details and suppress noise. The model is trained using the LoDoPaB-CT dataset with 35,802 training samples, 3,522 validation samples, and 3,553 test samples. The training procedure utilizes the Adam optimizer with a OneCycle learning rate policy for 20 epochs on NVIDIA RTX A4000 GPU hardware.

## Key Results
- Achieved SSIM of 0.9379 ± 0.0718, demonstrating superior structural preservation compared to traditional FBP
- Attained MSE of 0.0009 ± 0.0005, indicating significant noise reduction in reconstructed images
- Obtained PSNR of 31.2365 ± 2.0532 dB, showing improved image quality and detail preservation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Fourier series-based trainable filter improves noise reduction by learning optimal frequency domain filter coefficients.
- Mechanism: The method constructs a filter kernel in the Fourier domain using trainable Fourier series coefficients. By optimizing these coefficients, the filter adapts to the specific frequency characteristics of the input sinogram data, effectively suppressing noise while preserving important features.
- Core assumption: Noise in CT reconstruction manifests primarily as unwanted frequency components that can be attenuated by appropriate filtering in the Fourier domain.
- Evidence anchors:
  - [abstract] "This method overcomes the limitation in noise reduction by optimizing Fourier series coefficients to construct the filter"
  - [section] "This method overcomes the limitation in noise reduction, inherent in conventional FBP methods, by optimizing Fourier series coefficients to construct the filter"
  - [corpus] Weak evidence - corpus neighbors do not directly address noise reduction through Fourier series optimization in CT reconstruction
- Break condition: If the noise characteristics do not align with frequency domain representation, or if the optimization of Fourier coefficients fails to converge to meaningful values, the noise reduction benefit would be lost.

### Mechanism 2
- Claim: The GEE loss function preserves high-frequency details and sharpness by prioritizing L1 norm of high-frequency magnitudes.
- Mechanism: The GEE loss focuses on the L1 distance between high-frequency amplitudes of the target and output images. This approach emphasizes preserving edge details and fine structures that are typically lost when using traditional MSE loss functions.
- Core assumption: High-frequency components in CT images correspond to important structural details and edges that should be preserved during reconstruction.
- Evidence anchors:
  - [abstract] "we propose Gaussian edge-enhanced (GEE) loss function that prioritizes the L1 norm of high-frequency magnitudes, effectively countering the blurring problems prevalent in mean squared error (MSE) approaches"
  - [section] "GEE emphasizes high-frequency components to enhance edges and details, leading to clearer images"
  - [corpus] Weak evidence - corpus neighbors do not specifically address high-frequency preservation through L1 norm-based loss functions in CT reconstruction
- Break condition: If the high-frequency components are dominated by noise rather than true image features, the GEE loss might amplify noise instead of preserving meaningful details.

### Mechanism 3
- Claim: The fixed number of trainable parameters (101) ensures computational efficiency while maintaining reconstruction quality across different resolution scales.
- Mechanism: By constraining the Fourier series to 50 orders, the model maintains a fixed set of 101 trainable parameters regardless of input sinogram resolution. This allows the method to handle varying resolution scales without increasing computational complexity.
- Core assumption: A limited number of well-optimized Fourier coefficients can effectively represent the filter kernel across different resolution scales without sacrificing reconstruction quality.
- Evidence anchors:
  - [section] "We restrict the Fourier series to its initial 50 orders to form Krec, with L = 50. This constraint guarantees that the model maintains a fixed set of 101 trainable parameters, regardless of the resolution of the input sinogram"
  - [corpus] Weak evidence - corpus neighbors do not specifically address parameter efficiency through Fourier series truncation in CT reconstruction
- Break condition: If the limited number of parameters proves insufficient to capture the necessary filter characteristics for high-quality reconstruction, or if the fixed parameter set cannot adapt to diverse sinogram characteristics.

## Foundational Learning

- Concept: Fourier series representation of signals
  - Why needed here: The entire filter construction relies on representing the filter kernel as a Fourier series, requiring understanding of how periodic functions can be decomposed into sinusoidal components.
  - Quick check question: How would you represent a simple periodic function like a square wave using a Fourier series, and what would be the first three non-zero terms?

- Concept: Filtered Backprojection algorithm
  - Why needed here: The method builds upon the FBP framework, requiring understanding of how projections are filtered and backprojected to reconstruct images.
  - Quick check question: In FBP, what is the purpose of the ramp filter, and how does it affect the frequency components of the projection data?

- Concept: Loss function design in deep learning
  - Why needed here: The GEE loss function is a novel component that requires understanding of how different loss formulations affect learning outcomes, particularly for preserving high-frequency details.
  - Quick check question: How does L1 loss differ from MSE in terms of gradient behavior, and why might L1 be more suitable for preserving sharp edges in images?

## Architecture Onboarding

- Component map:
  - Input: Sinogram data (M × N matrix)
  - Fourier Transform: Applied along detector position axis
  - Trainable Fourier Series Filter: 101 parameters (a0 + 50 al + 50 bl)
  - Inverse Fourier Transform: Applied along detector position axis
  - Backprojection: Using differentiable backprojection operator
  - Loss Function: Hybrid (MSE + GEE + GV)
  - Output: Reconstructed CT image

- Critical path:
  1. Sinogram → Fourier domain (1D along detector axis)
  2. Element-wise multiplication with trainable filter
  3. Inverse Fourier transform
  4. Backprojection to image domain
  5. Loss computation and backpropagation

- Design tradeoffs:
  - Fixed 101 parameters vs. resolution adaptability: Ensures computational efficiency but may limit filter complexity
  - GEE loss vs. MSE: Better edge preservation but potentially more sensitive to noise
  - Plug-and-play design vs. end-to-end optimization: Easier integration but may miss global optimization opportunities

- Failure signatures:
  - Loss plateaus early: May indicate insufficient filter complexity or learning rate issues
  - High-frequency noise amplification: GEE loss may be overemphasizing noise components
  - Resolution-dependent performance: Fixed parameter set may not generalize well across all scales

- First 3 experiments:
  1. Train with only MSE loss (no GEE or GV) to establish baseline performance
  2. Train with GEE loss only (no MSE or GV) to isolate high-frequency preservation effects
  3. Train with varying Fourier series orders (L=10, 25, 50, 100) to study parameter efficiency vs. reconstruction quality tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Fourier series-based trainable filter perform in 3D CT reconstruction compared to its 2D performance, and what modifications are necessary to extend the method?
- Basis in paper: [explicit] The paper explicitly states "Future work will further refine this trainable filter to enhance its support for resolution invariance in FBP. Additionally, we plan to extend our method from 2D to 3D reconstruction."
- Why unresolved: The current study is limited to 2D reconstruction, and no experimental data or methodology for 3D extension is provided.
- What evidence would resolve it: Implementation and evaluation of the method in 3D CT reconstruction, including performance metrics and comparison with 2D results.

### Open Question 2
- Question: What is the optimal number of Fourier series orders (L) for balancing reconstruction quality and computational efficiency across different CT imaging scenarios?
- Basis in paper: [explicit] The paper mentions "We restrict the Fourier series to its initial 50 orders to form Krec, with L = 50" but does not explore the impact of varying this parameter.
- Why unresolved: The choice of L=50 appears arbitrary, and the sensitivity of reconstruction quality to this parameter is not investigated.
- What evidence would resolve it: Systematic experiments varying L and measuring reconstruction quality metrics (SSIM, PSNR, MSE) across different noise levels and image complexities.

### Open Question 3
- Question: How does the proposed GEE loss function compare to other high-frequency preservation loss functions (e.g., gradient-based losses, frequency-domain losses) in terms of reconstruction quality and computational cost?
- Basis in paper: [inferred] The paper introduces GEE loss as superior to MSE for edge preservation but does not compare it to other advanced loss functions designed for high-frequency detail preservation.
- Why unresolved: The comparative effectiveness of GEE loss versus other modern loss functions is not evaluated.
- What evidence would resolve it: Direct comparison of reconstruction quality using GEE loss versus alternative loss functions (e.g., gradient-domain losses, adversarial losses) on the same datasets with identical network architectures.

## Limitations

- Large confidence intervals in performance metrics (SSIM ± 0.0718, MSE ± 0.0005, PSNR ± 2.0532 dB) suggest potential variability in performance across different test cases
- Limited comparison with state-of-the-art deep learning methods like U-Nets or other learned reconstruction approaches
- Effectiveness of GEE loss function depends heavily on choice of high-pass filter parameters (κ and σ) which are not fully specified

## Confidence

- **High confidence**: The fundamental approach of using Fourier series-based trainable filters within FBP framework is sound and well-established in signal processing theory
- **Medium confidence**: The specific implementation details and performance claims, particularly the GEE loss function's contribution, require careful validation due to limited specification
- **Low confidence**: The generalizability of the method across different CT acquisition geometries and patient anatomies without retraining

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically vary the Fourier series order L (10, 25, 50, 100) and GEE loss weights (α, β) to understand their impact on reconstruction quality and identify optimal configurations
2. **Cross-Dataset Validation**: Test the trained model on different CT datasets (e.g., AAPM Low-Dose CT Grand Challenge) to evaluate generalizability beyond the LoDoPaB dataset
3. **Ablation Study**: Compare performance when using only MSE loss, only GEE loss, and the full hybrid loss to quantify each component's contribution to the overall reconstruction quality