---
ver: rpa2
title: 'Noisy Ostracods: A Fine-Grained, Imbalanced Real-World Dataset for Benchmarking
  Robust Machine Learning and Label Correction Methods'
arxiv_id: '2412.02313'
source_url: https://arxiv.org/abs/2412.02313
tags:
- dataset
- noisy
- label
- learning
- ostracods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the Noisy Ostracods dataset, a real-world\
  \ fine-grained classification benchmark containing 71,466 ostracod specimens with\
  \ label noise. The dataset features 5.58% noise at genus level and extreme class\
  \ imbalance (\u03C1 = 22,429)."
---

# Noisy Ostracods: A Fine-Grained, Imbalanced Real-World Dataset for Benchmarking Robust Machine Learning and Label Correction Methods

## Quick Facts
- arXiv ID: 2412.02313
- Source URL: https://arxiv.org/abs/2412.02313
- Reference count: 40
- Primary result: Cross-entropy training with ImageNet pre-training outperforms sophisticated learning-with-noisy-labels methods on real-world noise

## Executive Summary
This paper introduces the Noisy Ostracods dataset, a real-world fine-grained classification benchmark containing 71,466 ostracod specimens with 5.58% label noise at the genus level and extreme class imbalance (ρ = 22,429). The dataset features diverse noise types including open-set noise and pseudo-classes that differ fundamentally from synthetic noise patterns. Experiments reveal that simple cross-entropy training with ImageNet pre-training outperforms sophisticated learning-with-noisy-labels methods, suggesting inherent robustness in modern architectures. The dataset highlights the gap between synthetic and real-world noise and provides a valuable benchmark for developing more robust fine-grained classification methods.

## Method Summary
The study introduces the Noisy Ostracods dataset with 71,466 ostracod specimens containing 5.58% label noise at genus level and extreme class imbalance (ρ = 22,429). Researchers trained ResNet-50 and ViT-B-16 models with cross-entropy loss using ImageNet pre-trained weights, comparing performance against various learning-with-noisy-labels (LNL) methods (Loss-Clip, Co-teaching, DivideMix, SAM, PLM, SDN, LabelWave) and label correction methods (NECV, Confident Learning, SimiFeat, AUM, CINCER). Manual validation of 250 samples established ground truth for error detection evaluation. Models were trained for 300 epochs with SGD optimization, learning rate schedules, and batch size adjustments.

## Key Results
- Cross-entropy training with ImageNet pre-training outperformed sophisticated LNL methods across most metrics
- NECV ensemble baseline achieved 71.19% hit-rate, outperforming other label correction methods
- Transition matrix-based methods performed poorly despite using ground truth transition matrix
- Real-world noise patterns proved more complex than synthetic noise assumptions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Cross-entropy training with ImageNet pre-training provides inherent robustness to real-world noise without specialized LNL methods.
- **Mechanism**: Pre-trained models have learned robust feature representations that generalize well even when fine-tuning on noisy data, reducing the need for explicit noise-handling strategies.
- **Core assumption**: ImageNet pre-training provides features that are robust to real-world noise patterns.
- **Evidence anchors**:
  - [abstract]: "Experiments reveal that sophisticated learning-with-noisy-labels methods fail to outperform simple cross-entropy training with ImageNet pre-training"
  - [section 4.1]: "the naive cross-entropy (CE) training outperformed other methods in the majority of metrics"
  - [corpus]: Weak - no direct evidence, but related works mention pre-training benefits

### Mechanism 2
- **Claim**: Ensemble cross-validation baseline outperforms sophisticated label correction methods for real-world noise detection.
- **Mechanism**: Multiple diverse models trained on different data subsets provide complementary views, making it easier to identify samples where predictions disagree with true labels.
- **Core assumption**: Model disagreement correlates with label noise in fine-grained classification tasks.
- **Evidence anchors**:
  - [section 4.2]: "NECV proves to be the most reliable method for detecting label errors in fine-grained taxonomic datasets"
  - [section 4.2]: "NECV achieved the highest Hit-rate of 71.19%"
  - [corpus]: Weak - no direct evidence in corpus, but ensemble methods are commonly cited in label correction literature

### Mechanism 3
- **Claim**: Real-world noise patterns differ fundamentally from synthetic noise, making LNL methods designed for synthetic noise ineffective.
- **Mechanism**: Real-world noise includes complex patterns like open-set noise, pseudo-classes, and mixed classes that don't match synthetic noise assumptions.
- **Core assumption**: Synthetic noise models (class-dependent, symmetric) don't capture real-world noise complexity.
- **Evidence anchors**:
  - [abstract]: "The dataset has diverse noises from multiple sources" including "open-set" and "pseudo-classes"
  - [section 3.2]: Detailed description of complex noise types not captured by synthetic models
  - [corpus]: Weak - corpus doesn't discuss synthetic vs real noise differences

## Foundational Learning

- **Concept**: Fine-grained classification challenges
  - **Why needed here**: Ostracods have subtle morphological differences between species that are difficult to capture even with high-quality images
  - **Quick check question**: What makes ostracod species identification particularly challenging compared to general object classification?

- **Concept**: Label noise types and their implications
  - **Why needed here**: The dataset contains multiple noise types (feature errors, pseudo-classes, mixed classes) requiring different handling strategies
  - **Quick check question**: How would you distinguish between a feature error and a label error in this dataset?

- **Concept**: Class imbalance effects on learning
  - **Why needed here**: Extreme imbalance (ρ = 22,429) can bias models toward frequent classes and affect noise detection
  - **Quick check question**: Why might class imbalance make it harder to detect label noise in minority classes?

## Architecture Onboarding

- **Component map**: Dataset → Preprocessing → Model Training → Evaluation → Error Analysis
- **Critical path**: Data preprocessing → Model training → Error detection → Manual validation
- **Design tradeoffs**: Using pre-trained models trades model size and training time for robustness; ensemble methods trade computational cost for better error detection
- **Failure signatures**: Poor performance on minority classes, high false positive rates in error detection, failure to detect open-set noise
- **First 3 experiments**:
  1. Compare cross-entropy vs LNL methods on balanced vs imbalanced subsets
  2. Test different ensemble sizes for error detection
  3. Evaluate noise detection performance on synthetic vs real noise patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why did transition matrix-based methods perform poorly despite using the ground truth transition matrix?
- Basis in paper: [explicit] The paper states that "the class-dependent noise assumption may not hold for the Noisy Ostracods dataset, indicating more complex noise patterns than traditional class-dependent noise models can capture."
- Why unresolved: The exact nature of the complex noise patterns that violate the class-dependent assumption is not fully characterized.
- What evidence would resolve it: Detailed analysis of noise patterns showing specific examples where class-dependent assumptions fail, or development of a more accurate noise model that better fits the observed patterns.

### Open Question 2
- Question: What specific characteristics of fine-grained classification make label correction methods like SimiFeat underperform compared to the simple cross-validation ensemble?
- Basis in paper: [explicit] The paper notes that "k-NN classifier based on features extracted by the CLIP-ViT-L14 and MAE models performed poorly" and attributes this to "low clusterability of the dataset features."
- Why unresolved: While the paper identifies low clusterability as an issue, it doesn't fully explain why fine-grained features specifically lead to this problem or how to overcome it.
- What evidence would resolve it: Comparative studies of feature representations across different levels of granularity, and development of feature extraction methods specifically optimized for fine-grained classification.

### Open Question 3
- Question: How does the performance of LNL methods change when applied to larger, more diverse fine-grained classification datasets?
- Basis in paper: [inferred] The paper suggests that "the gap between synthetic and real-world scenarios highlights the importance of including more real-world noise benchmarks" and that "the fine-grained, imbalanced nature, and complex noise characteristics of the dataset present considerable challenges for existing noise-robust algorithms."
- Why unresolved: The current dataset, while valuable, is limited in size and scope. Testing LNL methods on larger, more diverse datasets would provide stronger evidence about their generalizability.
- What evidence would resolve it: Systematic testing of LNL methods across multiple fine-grained classification datasets of varying sizes and characteristics, with comparative analysis of performance trends.

## Limitations
- Limited manual validation sample size (250 samples) may not fully capture true noise distribution
- Findings based on single domain (ostracod taxonomy) may not generalize to other domains
- Effectiveness of ImageNet pre-training robustness may not extend to datasets with different noise characteristics

## Confidence
- **High confidence**: The dataset construction methodology and basic performance comparisons between cross-entropy and LNL methods
- **Medium confidence**: The generalizability of ImageNet pre-training benefits to other real-world noisy datasets
- **Medium confidence**: The superiority of NECV over other label correction methods for this specific dataset

## Next Checks
1. Test the cross-entropy vs LNL comparison on additional real-world noisy datasets from different domains to validate generalizability
2. Expand manual validation to a larger sample size (e.g., 1000 samples) to better estimate true noise rates and improve error detection method evaluation
3. Conduct ablation studies on the impact of class imbalance by creating balanced subsets to isolate its effect on noise detection performance