---
ver: rpa2
title: Can LLMs be Good Graph Judge for Knowledge Graph Construction?
arxiv_id: '2411.17388'
source_url: https://arxiv.org/abs/2411.17388
tags:
- graph
- knowledge
- triples
- arxiv
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'GraphJudge addresses three key challenges in knowledge graph (KG)
  construction using large language models (LLMs): noise in real-world documents,
  domain-specific knowledge gaps, and LLM hallucinations. It introduces an Entity-Centric
  Text Denoising (ECTD) module to filter irrelevant content, a Knowledge Aware Supervised
  Fine-Tuning (KASFT) module to train an LLM as a graph judge, and a Graph Judgement
  (GJ) module to filter incorrect triples.'
---

# Can LLMs be Good Graph Judge for Knowledge Graph Construction?

## Quick Facts
- arXiv ID: 2411.17388
- Source URL: https://arxiv.org/abs/2411.17388
- Authors: Haoyu Huang; Chong Chen; Zeang Sheng; Yang Li; Wentao Zhang
- Reference count: 40
- Primary result: GraphJudge achieves SOTA performance in KG construction using a 7B LLM, outperforming larger models

## Executive Summary
GraphJudge is a novel framework designed to address critical challenges in knowledge graph (KG) construction using large language models (LLMs). The framework tackles three main issues: noise in real-world documents, domain-specific knowledge gaps, and LLM hallucinations. By introducing specialized modules for entity-centric text denoising, knowledge-aware supervised fine-tuning, and graph judgment, GraphJudge demonstrates state-of-the-art performance across general and domain-specific datasets while maintaining efficiency through a 7B LLM model.

## Method Summary
GraphJudge introduces a three-module approach to improve KG construction quality. The Entity-Centric Text Denoising (ECTD) module filters irrelevant content from input documents, while the Knowledge Aware Supervised Fine-Tuning (KASFT) module trains an LLM to act as a graph judge. Finally, the Graph Judgement (GJ) module evaluates and filters incorrect triples. The framework was tested on two general and one domain-specific dataset, showing superior accuracy, recall, and F1 scores compared to baseline methods, with the added benefit of computational efficiency through the use of a 7B LLM rather than larger models.

## Key Results
- Achieves state-of-the-art performance in KG construction accuracy, recall, and F1 scores
- Demonstrates superior efficiency by using only a 7B LLM compared to larger models
- Shows strong generalization across multiple datasets, including domain-specific applications

## Why This Works (Mechanism)
The framework's effectiveness stems from its multi-stage approach to addressing KG construction challenges. By first denoising input text through entity-centric filtering, the model reduces noise before it can propagate through subsequent stages. The knowledge-aware fine-tuning ensures the LLM has domain-specific understanding, while the graph judgment module provides a final quality control layer. This systematic approach allows the model to handle the complexities of real-world data while maintaining high accuracy and efficiency.

## Foundational Learning
- **Entity-Centric Text Denoising**: Removes irrelevant content from documents to improve input quality
  - Why needed: Real-world documents contain significant noise that can degrade KG construction accuracy
  - Quick check: Measure reduction in irrelevant content before and after denoising

- **Knowledge-Aware Supervised Fine-Tuning**: Trains LLM with domain-specific knowledge for better graph judgment
  - Why needed: General LLMs lack the specialized knowledge required for accurate KG construction
  - Quick check: Compare performance with and without fine-tuning on domain-specific datasets

- **Graph Judgment Module**: Final evaluation layer that filters incorrect triples
  - Why needed: LLMs are prone to hallucinations that can introduce errors into the KG
  - Quick check: Measure false positive rate reduction with the judgment module enabled

## Architecture Onboarding

**Component Map**: ECTD -> KASFT -> GJ

**Critical Path**: Document input → Entity-Centric Text Denoising → Knowledge-Aware Supervised Fine-Tuning → Graph Judgment → Output KG

**Design Tradeoffs**: Uses 7B LLM for efficiency vs. larger models for potential accuracy gains; balances denoising aggressiveness with information preservation

**Failure Signatures**: 
- Poor entity extraction leading to insufficient denoising
- Over-aggressive filtering removing relevant information
- Hallucinations persisting through the judgment module
- Domain-specific knowledge gaps in fine-tuning

**First Experiments**:
1. Test denoising effectiveness with varying noise levels in input documents
2. Evaluate fine-tuning impact on domain-specific vs. general knowledge tasks
3. Measure judgment module performance with controlled hallucination injection

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited dataset diversity may not capture all real-world KG construction scenarios
- Entity extraction quality heavily impacts denoising module effectiveness
- Potential biases in fine-tuning process not thoroughly addressed
- Performance with unseen entities or relationships not fully evaluated

## Confidence

**High confidence in**: Core architecture's ability to filter noisy triples and improve KG construction accuracy, as evidenced by consistent performance improvements across all three datasets and comparison with established baselines.

**Medium confidence in**: Efficiency claims regarding the 7B LLM model, as the computational cost analysis is limited and does not provide detailed comparisons with alternative approaches using different model sizes or inference optimizations.

**Medium confidence in**: Generalization capability of GraphJudge across different domains, as the three datasets, while diverse, may not capture all potential edge cases or domain-specific challenges in knowledge graph construction.

## Next Checks
1. Conduct extensive testing on additional domain-specific datasets, particularly in biomedical and legal domains, to evaluate the model's performance with highly specialized terminology and complex relationship structures.

2. Perform ablation studies to quantify the individual contributions of each module (ECTD, KASFT, and GJ) to the overall performance, and test the model's behavior when one or more modules are disabled.

3. Evaluate the model's performance under different entity extraction methods and noise levels to assess the robustness of the denoising module and identify potential failure modes in real-world applications.