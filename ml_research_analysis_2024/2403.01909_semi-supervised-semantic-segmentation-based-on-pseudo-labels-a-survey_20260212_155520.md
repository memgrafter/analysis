---
ver: rpa2
title: 'Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey'
arxiv_id: '2403.01909'
source_url: https://arxiv.org/abs/2403.01909
tags:
- segmentation
- pseudo-labels
- semi-supervised
- semantic
- pseudo-label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey comprehensively reviews pseudo-label methods for semi-supervised
  semantic segmentation, categorizing them into three main perspectives: model-based
  approaches (single-model vs. multi-model), pseudo-label refinement techniques (update
  vs.'
---

# Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey

## Quick Facts
- arXiv ID: 2403.01909
- Source URL: https://arxiv.org/abs/2403.01909
- Reference count: 15
- Authors: Lingyan Ran; Yali Li; Guoqiang Liang; Yanning Zhang
- One-line primary result: Comprehensive survey categorizing pseudo-label methods into model-based, refinement, and optimization strategies for semi-supervised semantic segmentation

## Executive Summary
This survey comprehensively reviews pseudo-label methods for semi-supervised semantic segmentation, categorizing them into three main perspectives: model-based approaches (single-model vs. multi-model), pseudo-label refinement techniques (update vs. filter-only), and optimization strategies. The survey examines 50+ papers, highlighting key methods like GIST/RIST for iterative self-training, CPS for cross-pseudo-supervision, and DST for de-biased training. Applications in medical and remote-sensing image segmentation are also discussed. Key challenges include pseudo-label quality enhancement, integration of foundation models like SAM, and expanding to complex real-world scenarios.

## Method Summary
The survey focuses on pseudo-label methods for semi-supervised semantic segmentation, where a model is trained on labeled data (Dl) and generates pseudo-labels for unlabeled data (Du). These pseudo-labels are filtered or refined based on confidence and used to augment the training set. The methods are categorized into model-based approaches (single vs. multi-model), refinement techniques (update vs. filter-only), and optimization strategies. Key methods include iterative self-training (GIST/RIST), cross-pseudo-supervision (CPS), and de-biased training (DST). The survey evaluates these methods on standard benchmarks like PASCAL VOC and Cityscapes, using metrics such as Pixel Accuracy, Mean Accuracy, Mean IoU, and Weighted IoU.

## Key Results
- Pseudo-label methods are categorized into model-based, refinement, and optimization strategies
- Multi-model mutual training (e.g., CPS) improves pseudo-label quality by cross-supervision
- Confidence-based filtering and refinement strategies reduce the impact of noisy pseudo-labels
- Applications in medical and remote-sensing image segmentation show domain-specific adaptations
- Key challenges include integrating foundation models like SAM and expanding to complex real-world scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pseudo-labels enable training with limited labeled data by using high-confidence predictions from a model as training targets for unlabeled images.
- Mechanism: A model is first trained on labeled data. It then generates pseudo-labels for unlabeled images, which are filtered by confidence and used to augment the training set, reducing the need for manual labeling.
- Core assumption: The model can generate high-confidence predictions that are mostly correct and representative of the true data distribution.
- Evidence anchors:
  - [abstract] "The process is depicted in Figure 1. In semantic segmentation, the pseudo-label method is considered to be a more dependable option than consistent regularization, which may be affected by different levels of data augmentation."
  - [section] "The plainest pseudo-label method would be: First, we train the initial model M0 on the labeled dataset Dl using the cross-entropy loss Ll. This training process generates a pseudo-labeled dataset ˜Du = {(xu, M0(xu))}q for the unlabeled dataset Du, where M0(xu) represents the pseudo-label of xu."
  - [corpus] Weak evidence for mechanism effectiveness in specialized domains like medical images; more research needed.
- Break condition: If the initial model's predictions are highly inaccurate or the unlabeled data distribution is too different from the labeled data, the pseudo-labels will be unreliable and degrade performance.

### Mechanism 2
- Claim: Multi-model mutual training improves pseudo-label quality by allowing models to cross-supervise and correct each other's errors.
- Mechanism: Two or more models with different initializations are trained simultaneously. Each model generates pseudo-labels for the other, and the cross-supervision helps identify and correct errors that a single model might miss.
- Core assumption: Models with different initializations will make different types of errors, and cross-supervision can effectively localize and correct these errors.
- Evidence anchors:
  - [section] "The dual-model mutual-training method aims at the problems inherent in the single-model self-training method, i.e., a single model is unable to detect and correct its errors... mutual-training [Zhang et al. , 2018] by which two or more models train each other according to their differences, localize their errors, and correct each other is proposed."
  - [corpus] Limited direct evidence in corpus; assumed based on general mutual training principles.
- Break condition: If the models' errors are highly correlated or if the cross-supervision process amplifies rather than corrects errors, the method will fail to improve pseudo-label quality.

### Mechanism 3
- Claim: Confidence-based filtering and refinement strategies reduce the impact of noisy pseudo-labels on training.
- Mechanism: Pseudo-labels are filtered based on confidence thresholds or refined through additional modules that correct errors. This ensures that only high-quality pseudo-labels are used for training, improving model performance.
- Core assumption: Confidence scores are reliable indicators of pseudo-label quality, and refinement modules can effectively correct errors without introducing new ones.
- Evidence anchors:
  - [section] "In addition, some researchers have proposed to enhance the segmentation effect by filtering the noisy pseudo-labels, and such methods do not perform the update of the noisy labels. Confidence Filtering... Ju et al. [2023] propose a class-adaptive semi-supervised framework (CAFS) for semi-supervised semantic segmentation, which allows the construction of a validation set on the labeled dataset to take advantage of the calibration performance of each class."
  - [corpus] Moderate evidence from CAFS and related filtering methods; effectiveness varies by dataset and confidence calibration quality.
- Break condition: If confidence scores are poorly calibrated or if the refinement process introduces bias, the filtering strategy may discard useful data or retain noisy labels, harming performance.

## Foundational Learning

- Concept: Semi-supervised learning
  - Why needed here: This survey focuses on methods that use both labeled and unlabeled data to train segmentation models, which is the core of semi-supervised learning.
  - Quick check question: What is the main advantage of using unlabeled data in semi-supervised learning compared to purely supervised learning?
- Concept: Semantic segmentation
  - Why needed here: The survey reviews methods for pixel-level classification in images, which is the task of semantic segmentation.
  - Quick check question: How does semantic segmentation differ from object detection in terms of output granularity?
- Concept: Pseudo-label generation and filtering
  - Why needed here: The quality of pseudo-labels directly impacts the performance of semi-supervised segmentation models, and filtering is crucial to avoid propagating errors.
  - Quick check question: What is a common strategy to filter out low-quality pseudo-labels during training?

## Architecture Onboarding

- Component map: Initial model → Generate pseudo-labels → Filter/refine pseudo-labels → Final segmentation model
- Critical path: Train initial model → Generate pseudo-labels → Filter/refine pseudo-labels → Train final model on combined dataset
- Design tradeoffs: Balancing confidence thresholds (too high loses data, too low includes noise), choosing between single-model vs. multi-model approaches, and deciding whether to update or filter pseudo-labels
- Failure signatures: Poor segmentation performance due to noisy pseudo-labels, overfitting to pseudo-labels, or underutilization of unlabeled data
- First 3 experiments:
  1. Implement a basic single-model self-training pipeline on a small labeled dataset and evaluate segmentation performance.
  2. Add confidence-based filtering to the pipeline and measure the impact on pseudo-label quality and final performance.
  3. Compare single-model vs. multi-model mutual training on the same dataset to assess improvements in pseudo-label quality and segmentation accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can foundation models like SAM be effectively integrated with pseudo-label methods to improve semi-supervised semantic segmentation?
- Basis in paper: [explicit] The paper discusses the potential of leveraging SAM's prompt functionality to enhance pseudo-label efficiency and effectiveness.
- Why unresolved: While SAM shows promise, specific strategies for integrating its interactive segmentation capabilities with pseudo-label generation and refinement processes remain underexplored.
- What evidence would resolve it: Empirical studies demonstrating improved segmentation accuracy and efficiency when combining SAM with pseudo-label methods, along with analysis of optimal integration strategies.

### Open Question 2
- Question: What strategies can be employed to effectively utilize additional supervisory signals beyond single-type pseudo-labels in semi-supervised semantic segmentation?
- Basis in paper: [explicit] The paper suggests that current methods often ignore valuable information present in other pixels by using only low-quality pseudo-labels as a single type of supervised signal.
- Why unresolved: The paper highlights this limitation but does not propose specific methods for integrating alternative supervisory signals into the model.
- What evidence would resolve it: Development and validation of new models that successfully incorporate multiple types of supervisory signals, showing improved segmentation performance compared to single-type pseudo-label approaches.

### Open Question 3
- Question: How can active selection and refinement strategies be incorporated into pseudo-label techniques to address the problem of noisy data in semi-supervised semantic segmentation?
- Basis in paper: [explicit] The paper mentions that pseudo-label techniques struggle with noisy data and suggests incorporating active selection and refinement strategies as a future direction.
- Why unresolved: While the concept of active learning is mentioned, specific methods for selecting and refining the most informative data points in the context of pseudo-label generation are not explored.
- What evidence would resolve it: Empirical results showing improved segmentation accuracy and reduced noise when using active selection and refinement strategies in conjunction with pseudo-label methods, along with analysis of the most effective selection criteria.

## Limitations

- The review focuses primarily on methods published before mid-2024, potentially missing recent developments in foundation model integration and advanced refinement techniques.
- Confidence in the survey's categorization of methods is high for well-established approaches but moderate for emerging techniques and specialized applications due to limited comparative studies in the corpus.
- The survey's claim that pseudo-label methods are more dependable than consistent regularization requires further validation across diverse datasets and scenarios.

## Confidence

- Pseudo-label methods are more dependable than consistent regularization: Low
- Multi-model mutual training improves pseudo-label quality: Medium
- Confidence-based filtering effectively reduces noisy pseudo-labels: Medium
- Integration of foundation models like SAM will improve performance: Low

## Next Checks

1. Conduct a controlled experiment comparing single-model self-training with multi-model mutual training on a standard dataset (e.g., Cityscapes) to quantify the impact of cross-supervision on pseudo-label quality and final segmentation performance.
2. Implement and evaluate confidence-based filtering strategies (e.g., CAFS) on a medical imaging dataset to assess their effectiveness in specialized domains and validate the survey's claims about domain-specific adaptations.
3. Test the integration of foundation models like SAM into pseudo-label workflows to determine if they improve pseudo-label quality and segmentation accuracy compared to traditional CNN-based approaches.