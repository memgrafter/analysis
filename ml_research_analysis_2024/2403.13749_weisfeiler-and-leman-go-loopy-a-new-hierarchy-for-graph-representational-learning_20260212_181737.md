---
ver: rpa2
title: 'Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational
  Learning'
arxiv_id: '2403.13749'
source_url: https://arxiv.org/abs/2403.13749
tags:
- graph
- graphs
- tree
- definition
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces r-loopy Weisfeiler-Leman (r-\u2113WL), a\
  \ novel hierarchy of graph isomorphism tests that can count cycles up to length\
  \ r+2. The key innovation is to collect messages not only from neighboring nodes\
  \ but also from paths connecting neighboring nodes, enabling the model to capture\
  \ cyclic substructures more effectively."
---

# Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning

## Quick Facts
- arXiv ID: 2403.13749
- Source URL: https://arxiv.org/abs/2403.13749
- Reference count: 40
- Key outcome: Introduces r-loopy Weisfeiler-Leman (r-ℓWL) hierarchy that counts cycles up to length r+2 by aggregating messages from paths between neighbors

## Executive Summary
This paper introduces r-loopy Weisfeiler-Leman (r-ℓWL), a novel hierarchy of graph isomorphism tests that can count cycles up to length r+2. The key innovation is to collect messages not only from neighboring nodes but also from paths connecting neighboring nodes, enabling the model to capture cyclic substructures more effectively. The authors show that r-ℓWL can count homomorphisms of cactus graphs, which strictly extends the capabilities of classical 1-WL and is incomparable to k-WL for any fixed k. They implement this idea as r-ℓMPNN, a corresponding GNN framework with local computations that scales efficiently to large datasets, especially sparse graphs. Empirical results demonstrate strong performance on synthetic datasets, particularly in distinguishing non-isomorphic graph pairs that other models fail to separate, and competitive results on real-world molecular datasets.

## Method Summary
The method introduces r-loopy Weisfeiler-Leman (r-ℓWL) which extends classical 1-WL by aggregating messages from both neighboring nodes and paths connecting these neighbors. The r-ℓMPNN architecture implements this by first extracting r-neighborhoods for each node, then applying GIN layers to process paths within these neighborhoods, aggregating node and path features using MLPs, and finally pooling to obtain graph embeddings. The framework is trained with Adam optimizer and early stopping based on validation performance, with hyperparameters tuned via grid search for real-world datasets.

## Key Results
- r-ℓWL extends 1-WL's expressive power by counting cycles up to length r+2 through path-based message aggregation
- r-ℓWL can homomorphism-count cactus graphs, providing a strict extension over 1-WL that is incomparable to k-WL for any fixed k
- r-ℓMPNN demonstrates competitive performance on real-world molecular datasets (ZINC12K, QM9) while excelling at distinguishing non-isomorphic graph pairs on synthetic datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: r-loopy Weisfeiler-Leman (r-ℓWL) extends classical 1-WL by counting cycles up to length r+2.
- Mechanism: r-ℓWL collects messages not only from neighboring nodes but also from paths connecting any two distinct neighboring nodes, thereby encoding cyclic substructures into the node color refinement process.
- Core assumption: The paths between neighbors provide sufficient structural context to distinguish graphs that differ by cycles of length ≤ r+2.
- Evidence anchors:
  - [abstract]: "The key innovation is to collect messages not only from neighboring nodes but also from paths connecting neighboring nodes, enabling the model to capture cyclic substructures more effectively."
  - [section 4]: Definition 6 introduces r-neighborhoods as paths between neighbors, and Definition 7 formalizes the color update rule using these paths.
  - [corpus]: Weak. Only one neighbor paper (173994) directly discusses homomorphism counting, but does not explicitly confirm r-ℓWL's cycle-counting mechanism.
- Break condition: If the graph contains cycles longer than r+2 or if paths between neighbors do not uniquely encode the cyclic structure, the mechanism fails to distinguish such graphs.

### Mechanism 2
- Claim: r-ℓWL can homomorphism-count cactus graphs, which strictly extends the capabilities of 1-WL and is incomparable to k-WL for any fixed k.
- Mechanism: By using the unfolding tree construction and canonical tree decompositions, r-ℓWL encodes homomorphism counts of cactus graphs into its color refinement process, enabling quantitative expressiveness beyond subgraph counting.
- Core assumption: Cactus graphs can be decomposed into a tree structure where homomorphism counts are preserved by the r-ℓWL color refinement.
- Evidence anchors:
  - [abstract]: "Most notably, we show that r-ℓWL can count homomorphisms of cactus graphs."
  - [section 5.3]: Theorem 2 proves r-ℓWL can homomorphism-count Mr+2, the set of cactus graphs with cycles up to length r+2.
  - [section G]: Detailed proofs show how unfolding trees and tree decompositions enable homomorphism counting.
  - [corpus]: Missing. No neighbor papers directly confirm cactus graph homomorphism counting by r-ℓWL.
- Break condition: If the cactus graph contains cycles longer than r+2 or if the unfolding tree construction fails to preserve homomorphism counts, the mechanism fails.

### Mechanism 3
- Claim: r-ℓMPNN (the GNN framework) matches the expressive power of r-ℓWL under injective functions.
- Mechanism: r-ℓMPNN implements the r-ℓWL color update rule using neural network layers, ensuring that if the functions are injective, the GNN can distinguish the same graphs as r-ℓWL.
- Core assumption: The neural network functions used in r-ℓMPNN (e.g., MLPs, GIN layers) are sufficiently expressive to approximate the injective functions required for r-ℓWL.
- Evidence anchors:
  - [section 6]: Definition 9 and Theorem 3 state that r-ℓMPNN with injective functions is at least as powerful as r-ℓWL.
  - [section 6]: Implementation details show the use of GIN layers for path processing, justified by Xu et al. (2019) Lemma 5.
  - [corpus]: Weak. Only one neighbor paper (147950) discusses aligning transformers with WL, but does not confirm the injective function requirement for r-ℓMPNN.
- Break condition: If the neural network functions are not injective or not expressive enough to approximate the required injective functions, the mechanism fails to match r-ℓWL's expressive power.

## Foundational Learning

- Concept: Weisfeiler-Leman (WL) graph isomorphism test
  - Why needed here: r-ℓWL is a generalization of WL, so understanding WL's mechanism and limitations is crucial for grasping r-ℓWL's innovations.
  - Quick check question: What is the key limitation of 1-WL that r-ℓWL aims to overcome?

- Concept: Graph homomorphism counting
  - Why needed here: r-ℓWL's expressivity is quantified by its ability to count homomorphisms of cactus graphs, which is a more nuanced measure than simple graph isomorphism.
  - Quick check question: How does homomorphism counting differ from subgraph isomorphism counting, and why is it relevant for measuring GNN expressivity?

- Concept: Cactus graphs
  - Why needed here: Cactus graphs are the class of graphs that r-ℓWL can homomorphism-count, and understanding their structure is key to appreciating the significance of this result.
  - Quick check question: What structural properties make cactus graphs a useful class for testing GNN expressivity?

## Architecture Onboarding

- Component map: Input Graph -> r-neighborhood Extraction -> Path Processing (GIN layers) -> Message Aggregation (MLPs) -> Graph Embedding (Pooling)

- Critical path:
  1. Preprocess graph to extract r-neighborhoods
  2. Apply GIN layers to paths within each r-neighborhood
  3. Aggregate node and path features using MLPs
  4. Pool to obtain graph embedding

- Design tradeoffs:
  - Higher r increases expressive power but also computational complexity
  - Using GIN for path processing is simple but may not be optimal; other path-processing layers could be used
  - The injective function requirement for matching r-ℓWL's power is strong but may be relaxed in practice

- Failure signatures:
  - If r is too small, the model cannot distinguish graphs differing by cycles longer than r+2
  - If the neural network functions are not injective, the model may fail to match r-ℓWL's expressive power
  - If the graph is dense, preprocessing r-neighborhoods may become computationally infeasible

- First 3 experiments:
  1. Train r-ℓGIN on synthetic datasets (e.g., GRAPH8C, EXP_ISO) with increasing r to verify cycle-counting ability
  2. Compare r-ℓGIN's performance on real-world molecular datasets (e.g., ZINC12K) against standard GNNs and Subgraph GNNs
  3. Analyze the effect of r on r-ℓGIN's expressive power using ablation studies on the synthetic datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise homomorphism-expressivity of r-ℓWL? Can we determine the exact maximal class of graphs that r-ℓWL can homomorphism-count?
- Basis in paper: [explicit] The authors state that Theorem 2 provides a "loose lower bound" on homomorphism-expressivity and opens the avenue for future research to explore "tight lower bounds, or upper bounds" on homomorphism-expressivity.
- Why unresolved: The current results show r-ℓWL can count cactus graphs, but the authors acknowledge this is not the complete characterization. The relationship between r-ℓWL and other WL variants regarding homomorphism counting remains quantitatively unclear.
- What evidence would resolve it: A proof that identifies the exact maximal class of graphs that r-ℓWL can homomorphism-count, or a counterexample showing a graph that r-ℓWL cannot count but other WL variants can.

### Open Question 2
- Question: How do the generalization capabilities of GNNs with provable homomorphism-counting properties compare to standard GNNs on real-world datasets?
- Basis in paper: [inferred] The authors mention "exploring the generalization capabilities of GNNs with provable homomorphism-counting properties" as a promising direction and observed "improved generalization experimentally" in their ablation study on ZINC12K.
- Why unresolved: While the paper shows r-ℓGIN is competitive on molecular datasets, the authors suggest the ability to homomorphism-count relevant features "may improve generalization" but don't provide comprehensive comparative studies across diverse datasets and tasks.
- What evidence would resolve it: Systematic experiments comparing r-ℓGIN and other GNNs across multiple real-world datasets, measuring both performance and generalization (e.g., via cross-validation, out-of-distribution testing).

### Open Question 3
- Question: Does r-ℓWL with atomic types provide strictly more expressive power than standard r-ℓWL?
- Basis in paper: [explicit] The authors note that the version of r-ℓWL incorporating atomic types "is more powerful than the standard version" but state "it is unclear whether r-ℓWL with atomic types is strictly more powerful than standard r-ℓWL."
- Why unresolved: The authors acknowledge the increased expressivity from atomic types but don't provide a formal proof or counterexample to determine if this enhancement is strict.
- What evidence would resolve it: A proof demonstrating that r-ℓWL with atomic types can distinguish at least one pair of graphs that standard r-ℓWL cannot, or a proof showing they have equivalent expressive power.

## Limitations

- The injective function requirement for matching r-ℓWL's power may be difficult to satisfy in practice with standard neural network architectures
- The cactus graph homomorphism counting result, while theoretically elegant, has unclear practical significance for real-world graphs
- Higher r values increase expressive power but also computational complexity, potentially limiting scalability

## Confidence

- **High**: r-ℓWL extends 1-WL's expressive power and can distinguish more graph pairs
- **Medium**: r-ℓWL's cycle-counting ability translates to improved performance on real-world datasets
- **Low**: The cactus graph homomorphism counting result has clear practical implications for molecular graph learning

## Next Checks

1. **Empirical cycle-counting validation**: Test r-ℓMPNN on a suite of carefully constructed graph pairs that differ only by cycles of length r+2 to verify the mechanism's effectiveness
2. **Ablation study on path processing**: Compare GIN-based path processing against alternative approaches (e.g., transformers, attention mechanisms) to assess whether the current implementation is optimal
3. **Scaling analysis**: Evaluate r-ℓMPNN's performance and computational efficiency on large-scale sparse graphs to determine practical limitations of the r parameter