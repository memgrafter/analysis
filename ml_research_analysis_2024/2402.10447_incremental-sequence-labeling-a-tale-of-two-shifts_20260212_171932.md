---
ver: rpa2
title: 'Incremental Sequence Labeling: A Tale of Two Shifts'
arxiv_id: '2402.10447'
source_url: https://arxiv.org/abs/2402.10447
tags:
- entities
- entity
- learning
- incremental
- labeling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies two key semantic shift problems in incremental
  sequence labeling: E2O (old entity to non-entity) and O2E (non-entity or old entity
  to new entity). The proposed IS3 framework addresses these shifts using knowledge
  distillation to preserve old entity discrimination and a debiased loss function
  plus prototype-based learning to mitigate bias towards new entities.'
---

# Incremental Sequence Labeling: A Tale of Two Shifts

## Quick Facts
- arXiv ID: 2402.10447
- Source URL: https://arxiv.org/abs/2402.10447
- Reference count: 21
- This paper identifies two key semantic shift problems in incremental sequence labeling and proposes the IS3 framework to address them.

## Executive Summary
This paper addresses two critical semantic shift problems in incremental sequence labeling: E2O (old entity to non-entity) and O2E (non-entity or old entity to new entity). The authors propose the IS3 framework which uses knowledge distillation to preserve old entity discrimination and a debiased loss function plus prototype-based learning to mitigate bias towards new entities. Experiments across three datasets and nine incremental learning settings demonstrate significant improvements over previous state-of-the-art methods.

## Method Summary
The IS3 framework addresses incremental sequence labeling through three main components: knowledge distillation to maintain old entity discrimination (addressing E2O problem), debiased cross-entropy loss to reduce bias towards new entities (addressing O2E problem), and prototype-based learning to balance optimization between old and new entities. The method uses BERT-base or RoBERTa-base as backbone with AdamW optimizer, and evaluates performance using macro F1 score across multiple incremental learning settings.

## Key Results
- IS3 outperforms previous state-of-the-art methods across three datasets
- Achieves up to 10.52% improvement in macro F1 score compared to baselines
- Demonstrates effectiveness across nine different incremental learning settings (FG-1-PG-1, FG-2-PG-2, FG-8-PG-1, FG-8-PG-2)
- Shows consistent performance improvements in both AT (last step) and A (average across all steps)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge distillation maintains the discriminative ability for old entities (E2O problem).
- Mechanism: The method uses knowledge distillation to preserve prior knowledge by distilling output probabilities from the old model Mt-1 to the current model Mt, helping correct mislabeling of old entities as non-entities during incremental learning.
- Core assumption: The old model has learned optimal representations for old entities that can guide the new model.
- Evidence anchors: [abstract] "As for the E2O problem, we use knowledge distillation (Hinton et al., 2015). This method preserves the prior knowledge by distilling the output probabilities from the old Mt−1 to the current model Mt."
- Break condition: If the old model's predictions are noisy or biased, knowledge distillation could propagate errors to the new model.

### Mechanism 2
- Claim: Debiased cross-entropy loss reduces the model's bias towards new entities (O2E problem).
- Mechanism: The proposed debiased cross-entropy loss introduces a correction factor δ to reduce the penalizing effect on old entity weights during learning, preventing overfitting to new entity distributions.
- Core assumption: The standard cross-entropy loss excessively penalizes old entity classifiers when learning new entities, causing bias.
- Evidence anchors: [abstract] "to tackle the O2E problem, we alleviate the model's bias towards new entities through debiased loss and optimization levels."
- Break condition: If δ is set too low, the model may not learn new entities effectively; if too high, bias towards new entities persists.

### Mechanism 3
- Claim: Prototype-based learning balances optimization between old and new entities at the feature level.
- Mechanism: Class feature centers (prototypes) of old entities are computed after each task and used during subsequent task training, participating in batch updates alongside new entity features to ensure balanced optimization.
- Core assumption: Including old entity prototypes in training batches helps maintain their feature representations while learning new entities.
- Evidence anchors: [abstract] "At the optimization level, we introduce a prototype-based approach to balance the imbalanced contributions of old and new entities during batch updates."
- Break condition: If prototypes become stale or unrepresentative of the current feature space, they may not effectively balance optimization.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: Understanding why models lose performance on old tasks when learning new ones is fundamental to grasping the problem this paper addresses
  - Quick check question: What happens to a neural network's weights when it's trained on new data without any mechanism to preserve old knowledge?

- Concept: Knowledge distillation
  - Why needed here: The paper uses knowledge distillation as a key mechanism to preserve old entity discrimination
  - Quick check question: How does knowledge distillation work to transfer knowledge from an old model to a new model?

- Concept: Cross-entropy loss and its gradient behavior
  - Why needed here: The paper modifies cross-entropy loss to address bias, requiring understanding of how standard cross-entropy affects model parameters
  - Quick check question: What is the gradient update for a classifier weight in standard cross-entropy loss when the true label is y and the model predicts y'?

## Architecture Onboarding

- Component map: BERT backbone -> Knowledge distillation module (E2O) -> Debiased cross-entropy loss (O2E loss level) -> Prototype-based learning (O2E optimization level) -> Linear classifier
- Critical path: Compute old entity prototypes after each task → Apply knowledge distillation during training → Use debiased loss function → Incorporate prototypes in batch optimization
- Design tradeoffs: The method trades increased computation (prototypes, modified loss) for better incremental learning performance. It avoids storing old samples (unlike rehearsal methods) but requires storing prototypes and relying on old model predictions.
- Failure signatures: Poor performance on old entities indicates E2O issues; poor performance on new entities or confusion between old and new entities indicates O2E issues. If prototypes are inaccurate, both problems may occur.
- First 3 experiments:
  1. Implement basic knowledge distillation alone on i2b2 dataset with FG-1-PG-1 setting to verify E2O mitigation
  2. Add debiased cross-entropy loss to the knowledge distillation setup to test O2E reduction at loss level
  3. Incorporate prototype-based learning to the previous setup to evaluate O2E mitigation at optimization level

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed IS3 framework handle catastrophic forgetting when the number of incremental steps is very large (e.g., 50+ steps) and the accumulation of prediction errors from old models becomes significant?
- Basis in paper: [inferred] The paper acknowledges that the method relies on predictions of old models for preserving existing knowledge, which can result in accumulated prediction errors leading to poor performance in more incremental steps.
- Why unresolved: The paper does not provide experiments or theoretical analysis on the performance degradation of IS3 when the number of incremental steps is very large. The experiments only cover up to 16 incremental steps.
- What evidence would resolve it: Extensive experiments evaluating IS3's performance on datasets with a large number of incremental steps (e.g., 50+) would help determine if the accumulated prediction errors from old models significantly impact the framework's effectiveness.

### Open Question 2
- Question: What is the optimal value of the correction factor δ in the debiased cross-entropy loss function for different datasets and incremental learning settings?
- Basis in paper: [explicit] The paper mentions that δ around 0.5 reaches the best result on OntoNotes5 with the FG-1-PG-1 setting, but it does not explore the optimal value of δ for other datasets and settings.
- Why unresolved: The paper only provides results for a single dataset and setting, leaving the optimal value of δ for other scenarios unexplored. The choice of δ may depend on the dataset characteristics and the specific incremental learning setting.
- What evidence would resolve it: Conducting a comprehensive hyperparameter search for δ across different datasets and incremental learning settings would help identify the optimal values and provide insights into the factors influencing the choice of δ.

### Open Question 3
- Question: How does the IS3 framework perform when using larger pre-trained language models, such as BERT-large or RoBERTa-large, compared to the base models used in the experiments?
- Basis in paper: [inferred] The paper uses BERT-base-cased and RoBERTa-base models in the experiments, but it does not explore the performance of IS3 with larger pre-trained models.
- Why unresolved: The paper does not provide any results or analysis on the performance of IS3 with larger pre-trained models. The choice of the base model may impact the framework's effectiveness, and it is unclear how IS3 would scale to larger models.
- What evidence would resolve it: Experiments comparing the performance of IS3 using base models (BERT-base, RoBERTa-base) and larger models (BERT-large, RoBERTa-large) on the same datasets and incremental learning settings would help determine the impact of model size on IS3's effectiveness.

## Limitations

- The paper lacks detailed information on dataset splitting methodology, making exact reproduction challenging
- The hyper-parameter tuning process for δ and β is not fully specified
- The effectiveness of prototype-based learning depends on the representativeness of prototypes over time

## Confidence

- **High Confidence**: The existence of two semantic shift problems (E2O and O2E) in incremental sequence labeling, and the general effectiveness of IS3 framework in improving performance over baselines.
- **Medium Confidence**: The specific mechanisms of knowledge distillation for E2O and debiased loss for O2E, as the evidence is primarily from the paper's claims without extensive external validation.
- **Low Confidence**: The long-term stability of prototype-based learning and the scalability of the approach to very large numbers of entity types or extremely long sequences.

## Next Checks

1. Implement ablation studies to isolate the contribution of each component (knowledge distillation, debiased loss, prototypes) and verify their individual effectiveness on the E2O and O2E problems.
2. Test the method on a fourth dataset with different characteristics (e.g., more entity types, longer sequences) to assess generalizability beyond the three reported datasets.
3. Evaluate the impact of different δ values in the debiased loss function through a comprehensive sensitivity analysis to determine optimal settings for various incremental learning scenarios.