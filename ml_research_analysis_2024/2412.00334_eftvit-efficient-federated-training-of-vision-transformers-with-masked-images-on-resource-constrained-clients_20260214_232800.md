---
ver: rpa2
title: 'EFTViT: Efficient Federated Training of Vision Transformers with Masked Images
  on Resource-Constrained Clients'
arxiv_id: '2412.00334'
source_url: https://arxiv.org/abs/2412.00334
tags:
- training
- eftvit
- client
- data
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training Vision Transformers
  (ViTs) on resource-constrained edge devices in federated learning scenarios. The
  authors propose EFTViT, a hierarchical federated learning framework that leverages
  masked images to reduce computational costs while maintaining model performance
  and enhancing data privacy.
---

# EFTViT: Efficient Federated Training of Vision Transformers with Masked Images on Resource-Constrained Clients

## Quick Facts
- **arXiv ID:** 2412.00334
- **Source URL:** https://arxiv.org/abs/2412.00334
- **Reference count:** 40
- **Primary result:** EFTViT achieves up to 28.17% accuracy improvement, 2.8× reduction in computational cost, and 4.4× reduction in training time for federated ViT training on resource-constrained devices

## Executive Summary
This paper addresses the challenge of training Vision Transformers (ViTs) on resource-constrained edge devices in federated learning scenarios. The authors propose EFTViT, a hierarchical federated learning framework that leverages masked images to reduce computational costs while maintaining model performance and enhancing data privacy. The core idea involves dividing the ViT into lightweight local modules on clients and a larger global module on the server, with clients training on masked images and uploading patch features. A median sampling strategy is used to balance patch features before uploading, protecting client data distribution privacy. Extensive experiments on CIFAR-10, CIFAR-100, and UC Merced Land-Use datasets demonstrate that EFTViT achieves up to 28.17% accuracy improvement, reduces local training computational cost by up to 2.8×, and cuts local training time by up to 4.4× compared to existing methods, while showing strong performance in handling data heterogeneity.

## Method Summary
EFTViT is a hierarchical federated learning framework that splits a Vision Transformer into lightweight local modules (M Transformer layers) on resource-constrained clients and a larger global module (N Transformer layers) on a central server. Clients process masked images by randomly masking a portion of image patches during training, reducing the number of patches processed while maintaining model accuracy. The framework uses a median sampling strategy to balance the number of patch features per class before uploading to the server, protecting client data distribution privacy. The method employs AdamW optimizer with learning rate 5×10^-5, weight decay 0.05, and cosine annealing learning rate schedule with warm-up, training for 200 rounds with 100 clients and client selection ratio P = 0.1.

## Key Results
- Achieved up to 28.17% accuracy improvement compared to baseline methods
- Reduced local training computational cost by up to 2.8× (GFLOPs)
- Cut local training time by up to 4.4× while maintaining strong performance under data heterogeneity
- Demonstrated effectiveness across CIFAR-10, CIFAR-100, and UC Merced Land-Use datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masked images enable efficient ViT training by exploiting redundancy in visual data.
- Mechanism: Randomly masking a portion of image patches during training reduces the number of patches processed while maintaining model accuracy.
- Core assumption: A significant portion of image patches contain redundant or non-essential information for the classification task.
- Evidence anchors:
  - [abstract] "excluding them from training has minimal impact on performance while substantially reducing computation costs"
  - [section] "we patchify images and randomly mask a portion of the patches, observing that excluding them from training has minimal impact on performance while substantially reducing computation costs"
- Break condition: If the masking ratio becomes too high (above 75% in experiments), accuracy deteriorates significantly.

### Mechanism 2
- Claim: Hierarchical training structure balances computational load between clients and server.
- Mechanism: Lightweight local modules process masked images on clients, while a larger global module on the server processes intermediate features, distributing computational complexity.
- Core assumption: Splitting the model into client-side and server-side components allows resource-constrained devices to participate in training without sacrificing performance.
- Evidence anchors:
  - [abstract] "EFTViT comprises a series of lightweight local modules and a larger global module, updated independently on clients and the central server"
  - [section] "EFTViT comprises lightweight local modules on edge clients and a larger global module on the central server"
- Break condition: If the communication overhead of uploading features outweighs the computational savings, the hierarchical approach becomes inefficient.

### Mechanism 3
- Claim: Median sampling strategy protects client data distribution privacy while maintaining performance.
- Mechanism: Balancing the number of patch features per class to the median count across all classes before uploading obscures individual client data distributions.
- Core assumption: Equalizing feature counts across classes prevents the server from inferring client-specific data characteristics.
- Evidence anchors:
  - [abstract] "balanced through a proposed median sampling strategy to erase client data distribution privacy"
  - [section] "we propose a median sampling strategy that adjusts the patch feature count for each class to the median across all classes prior to uploading, enhancing both performance and training efficiency"
- Break condition: If the median sampling threshold is set too high, it increases computational cost on the server without significant performance gains.

## Foundational Learning

- Concept: Vision Transformers and self-attention mechanisms
  - Why needed here: Understanding ViTs is crucial because EFTViT specifically addresses their computational challenges in federated learning
  - Quick check question: What is the computational complexity of self-attention in ViTs, and why does it create challenges for resource-constrained devices?

- Concept: Federated learning principles and data heterogeneity
  - Why needed here: EFTViT operates in federated learning environments with heterogeneous data across clients, requiring understanding of how to handle non-IID data distributions
  - Quick check question: How does the Dirichlet distribution with parameter β model data heterogeneity in federated learning scenarios?

- Concept: Parameter-efficient fine-tuning techniques
  - Why needed here: EFTViT uses a hierarchical approach similar to parameter-efficient methods but applies it in a federated context with full-parameter training
  - Quick check question: What is the difference between training only the head layer versus training all parameters in a transformer model?

## Architecture Onboarding

- Component map:
  - Client-side: Local module (M Transformer layers), Classification head
  - Server-side: Global module (N Transformer layers), Classification head
  - Communication: Patch features with median sampling protection

- Critical path:
  1. Client processes masked images through local module
  2. Client generates and balances patch features using median sampling
  3. Client uploads balanced features to server
  4. Server processes features through global module
  5. Server updates global parameters and sends back to clients

- Design tradeoffs:
  - Masking ratio vs. accuracy: Higher masking reduces computation but may hurt performance
  - Layer division (M vs N): More layers on client increases computation but may improve local feature quality
  - Median sampling threshold: Higher thresholds increase server computation without significant gains

- Failure signatures:
  - Accuracy degradation: Likely due to excessive masking or poor layer division
  - Communication bottlenecks: If feature upload becomes too large or frequent
  - Convergence issues: May indicate problems with median sampling or hierarchical training coordination

- First 3 experiments:
  1. Test masking ratio impact: Run with rm = 0.0, 0.25, 0.5, 0.75, 0.95 on CIFAR-10 to find optimal balance between computation and accuracy
  2. Validate layer division: Compare performance with different M values (2, 4, 6) while keeping N fixed to find optimal client/server split
  3. Assess median sampling: Compare accuracy with median sampling vs. no sampling vs. other thresholds to verify privacy-protection effectiveness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas remain unexplored based on the analysis of the paper's content and limitations.

## Limitations
- The privacy protection mechanism through median sampling lacks rigorous privacy analysis (e.g., differential privacy guarantees)
- The hierarchical architecture's effectiveness depends heavily on the specific layer division (M=2, N=10), which may not generalize across different ViT variants or tasks
- The method assumes visual data contains substantial redundancy that can be exploited through masking, which may not hold for all types of image data

## Confidence
- **High confidence**: The computational efficiency gains (2.8× reduction in GFLOPs, 4.4× reduction in training time) are well-supported by experimental results across multiple datasets
- **Medium confidence**: The accuracy improvements (28.17% reported) are promising but require independent validation, particularly on larger-scale datasets
- **Medium confidence**: The privacy protection mechanism through median sampling is conceptually sound but lacks formal privacy metrics or threat model analysis

## Next Checks
1. **Generalization Test**: Evaluate EFTViT on larger, more complex datasets (ImageNet-1K, Places365) to assess whether the computational savings and accuracy improvements scale beyond small benchmarks like CIFAR-10/100.

2. **Privacy Analysis**: Conduct formal differential privacy analysis of the median sampling strategy to quantify the actual privacy guarantees and compare against baseline privacy-preserving federated learning methods.

3. **Robustness to Heterogeneity**: Test EFTViT under extreme data heterogeneity conditions (β → 0 in Dirichlet distribution) and with varying client compute capabilities to determine the method's robustness limits.