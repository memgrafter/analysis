---
ver: rpa2
title: 'ApproxDARTS: Differentiable Neural Architecture Search with Approximate Multipliers'
arxiv_id: '2404.08002'
source_url: https://arxiv.org/abs/2404.08002
tags:
- architecture
- search
- approximate
- cell
- multipliers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ApproxDARTS is a hardware-aware neural architecture search method
  that extends DARTS to employ approximate multipliers in convolutional neural networks
  (CNNs). It uses TFApprox4IL to emulate approximate multipliers in the DARTS search
  space, enabling CNNs to be optimized for accuracy, hardware efficiency, and energy
  consumption.
---

# ApproxDARTS: Differentiable Neural Architecture Search with Approximate Multipliers

## Quick Facts
- arXiv ID: 2404.08002
- Source URL: https://arxiv.org/abs/2404.08002
- Reference count: 37
- ApproxDARTS integrates approximate multipliers into DARTS for energy-efficient CNNs

## Executive Summary
ApproxDARTS extends differentiable architecture search (DARTS) to incorporate approximate multipliers in convolutional neural networks, enabling simultaneous optimization of accuracy and hardware efficiency. The method uses TFApprox4IL to emulate approximate multipliers within the DARTS search space, discovering architectures that maintain accuracy while significantly reducing energy consumption in arithmetic operations. Experiments on CIFAR-10 demonstrate that ApproxDARTS can find CNN architectures with up to 53.84% energy savings compared to exact multipliers, while being 2.3× faster than evolutionary approaches like EvoApproxNAS.

## Method Summary
ApproxDARTS modifies the standard DARTS framework by incorporating approximate multipliers into the search space through TFApprox4IL emulation. During the architecture search process, the method evaluates different combinations of approximate multipliers alongside standard architectural decisions like kernel sizes and connections. The search optimizes a joint objective that balances classification accuracy against hardware metrics including energy consumption and latency. After search completion, the discovered architectures are trained to convergence and evaluated on CIFAR-10, with energy savings estimated through the TFApprox4IL tool that models the behavior of approximate multipliers.

## Key Results
- Discovered CNNs achieve similar accuracy to exact multipliers while saving up to 53.84% energy on CIFAR-10
- ApproxDARTS is 2.3× faster than EvoApproxNAS while achieving higher accuracy
- Successfully integrates approximate computing into differentiable architecture search framework

## Why This Works (Mechanism)
ApproxDARTS works by extending the DARTS search space to include approximate multiplier options, allowing the optimization process to discover architectures that strategically place approximate operations where accuracy degradation is minimal. The TFApprox4IL emulation enables differentiable search by providing continuous approximations of discrete approximate multiplier behaviors, making it compatible with gradient-based optimization. By jointly optimizing for accuracy and hardware metrics during the search phase rather than as a post-processing step, ApproxDARTS finds architectures that naturally balance computational efficiency with task performance.

## Foundational Learning
- Differentiable Architecture Search (DARTS): A gradient-based method for neural architecture search that relaxes discrete architecture choices into continuous parameters
  - Why needed: Provides the foundation for efficient, differentiable optimization of neural architectures
  - Quick check: Verify understanding of continuous relaxation in DARTS and how it enables gradient-based search

- Approximate Computing: Computing techniques that allow controlled errors in exchange for efficiency gains in energy, performance, or area
  - Why needed: Enables the exploration of energy-efficient architectures that trade minimal accuracy for significant hardware savings
  - Quick check: Understand the error-energy tradeoff curve for approximate multipliers

- TFApprox4IL: A TensorFlow tool for emulating approximate multipliers in neural networks
  - Why needed: Provides differentiable approximation of discrete approximate multiplier behaviors for integration into DARTS
  - Quick check: Review how TFApprox4IL models approximate multiplier behavior and its impact on gradient flow

## Architecture Onboarding
- Component map: Input -> Convolutional layers (with exact/approximate multipliers) -> Pooling -> Classification head
- Critical path: Search phase (architecture optimization) → Training phase (parameter optimization) → Evaluation phase (accuracy and energy assessment)
- Design tradeoffs: Accuracy vs energy consumption, search time vs solution quality, hardware emulation accuracy vs search efficiency
- Failure signatures: Architectures that overuse approximate multipliers leading to accuracy collapse, search instability due to poor gradient estimates, energy overestimation from emulation inaccuracies
- First experiments: 1) Validate TFApprox4IL emulation accuracy against actual hardware measurements, 2) Test ApproxDARTS on a small CNN search space to verify basic functionality, 3) Compare search convergence with and without approximate multiplier options

## Open Questions the Paper Calls Out
None

## Limitations
- Energy savings estimates rely on TFApprox4IL emulation rather than actual hardware measurements, potentially introducing inaccuracies
- Experiments are limited to CIFAR-10 classification, leaving uncertainty about performance on more complex tasks
- The method remains constrained by DARTS framework limitations, potentially missing optimal approximate computing architectures

## Confidence
- High: Approximate multipliers can be integrated into DARTS and achieve energy savings with minimal accuracy loss
- Medium: Specific energy savings percentages and comparison to EvoApproxNAS due to potential emulation inaccuracies
- Low: Broader applicability to domains beyond CIFAR-10 classification

## Next Checks
1) Implement and measure actual hardware energy consumption of the discovered architectures to verify TFApprox4IL emulation accuracy
2) Test ApproxDARTS on larger-scale vision tasks (e.g., ImageNet) and non-vision tasks to assess generalizability
3) Compare against a broader range of approximate computing neural architecture search methods to establish relative performance