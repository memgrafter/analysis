---
ver: rpa2
title: '3M: Multi-modal Multi-task Multi-teacher Learning for Game Event Detection'
arxiv_id: '2406.09076'
source_url: https://arxiv.org/abs/2406.09076
tags:
- game
- teacher
- event
- other
- chat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes 3M, a multi-modal multi-task multi-teacher learning
  framework for game event detection in esports livestreams. The method addresses
  the challenge of understanding complex gameplay by integrating chat, audio, and
  transcript modalities from the livestream platform.
---

# 3M: Multi-modal Multi-task Multi-teacher Learning for Game Event Detection

## Quick Facts
- arXiv ID: 2406.09076
- Source URL: https://arxiv.org/abs/2406.09076
- Authors: Thye Shan Ng; Feiqi Cao; Soyeon Caren Han
- Reference count: 25
- Primary result: 3M outperforms Game-MUG baseline with macro-averaged F1 of 0.601 vs 0.257

## Executive Summary
This paper proposes 3M, a multi-modal multi-task multi-teacher learning framework for detecting game events in esports livestreams. The framework integrates chat, audio, and transcript modalities from League of Legends esports data to identify four event types: KILL, DRAGON, TOWER, and OTHER. By employing three teacher models fine-tuned on different tasks and distilling their knowledge into a unified student model, 3M achieves significant improvements over existing baselines, particularly for challenging event types.

## Method Summary
3M uses a multi-teacher distillation framework where three teacher models are independently fine-tuned on different modality-specific tasks: audio-based action detection, chat-based emotion tagging, and transcript-based game entity tagging. These teachers then transfer their knowledge to a student model through two distillation losses - hidden state alignment and soft label distillation. The framework processes segmented livestream data through the teacher models, with the student model learning to integrate complementary information across modalities to detect game events.

## Key Results
- 3M achieves macro-averaged precision of 0.638, recall of 0.595, and F1-score of 0.601
- Significant improvement over Game-MUG baseline (F1 0.257) for all event types
- Best performance on KILL events (F1 0.691), lower performance on TOWER (F1 0.397) and DRAGON (F1 0.345) events
- Ablation study shows effectiveness of combining multiple teacher modalities

## Why This Works (Mechanism)

### Mechanism 1
The multi-teacher distillation framework transfers task-specific expertise from separate models trained on chat, audio, and transcript modalities into a unified student model. Each teacher model is fine-tuned on a different modality-specific task, and the student model receives knowledge from all three teachers via two distillation losses, enabling it to learn complementary information across modalities. The core assumption is that independently fine-tuned teachers capture essential modality-specific features that can be meaningfully transferred to a single student model. This is supported by the abstract stating the framework "leverages multiple teachers trained independently on different tasks" and the section describing separate teacher fine-tuning for emotion tagging, action detection, and entity recognition.

### Mechanism 2
The multi-teacher hidden loss aligns corresponding hidden states between teachers and student, enabling effective knowledge transfer of intermediate representations. For each teacher layer, the corresponding student layer is aligned via MSE loss, while remaining teacher layers map to the final student layer. This preserves the teacher's learned intermediate representations while adapting them to the student's architecture. The core assumption is that teacher hidden state representations contain transferable knowledge that can be aligned with student representations through simple transformation matrices. This is evidenced by the mathematical formulation showing how each student hidden layer is directly aligned with a corresponding teacher layer.

### Mechanism 3
The multi-teacher distillation loss transfers modality-related information through soft label comparison, allowing the student to learn from the ensemble of teacher predictions. Teacher output logits are compared with student output logits and ground truth labels via cross entropy, enabling the student to learn from uncertainty and complementarity in teacher predictions rather than just hard labels. The core assumption is that soft label distributions from multiple teachers contain valuable information about relationships between different modalities and game events. This is supported by the mathematical formulation showing comparison between teacher outputs, student outputs, and ground truth.

## Foundational Learning

- Concept: Knowledge distillation fundamentals
  - Why needed here: Understanding how teacher models transfer knowledge to student models is essential for implementing and debugging the 3M framework
  - Quick check question: What is the difference between hidden state distillation and output distillation in knowledge distillation?

- Concept: Multi-modal learning integration
  - Why needed here: The framework combines chat, audio, and transcript modalities, requiring understanding of how different data types can be effectively integrated
  - Quick check question: How does the model handle the different time resolutions and feature representations across chat, audio, and transcript modalities?

- Concept: Fine-tuning vs. pre-training
  - Why needed here: The framework uses pre-trained models that are fine-tuned for specific tasks, requiring understanding of when and how to fine-tune versus training from scratch
  - Quick check question: What are the key differences in hyperparameter tuning between pre-training and fine-tuning stages?

## Architecture Onboarding

- Component map: Segmented livestream inputs → Three modality streams (audio, chat, transcript) → Three teacher models (AST, XLM-RoBERTa, RoBERTa) → Knowledge distillation via hidden state and distillation losses → Student RoBERTa model → Game event classification
- Critical path: Raw livestream audio → Whisper transcription → Data segmentation → Three modality streams → Teacher fine-tuning → Knowledge distillation → Student model → Game event classification
- Design tradeoffs: The framework trades off complexity (three teachers plus student) for potentially better performance through specialized expertise. Alternative would be single model with joint training, which might be simpler but miss modality-specific nuances.
- Failure signatures: Poor performance on specific event types (TOWER, DRAGON) suggests modality-specific issues. Complete failure on OTHER label indicates catastrophic forgetting or class imbalance problems. Inconsistent results across teacher combinations suggest modality noise or conflicting information.
- First 3 experiments:
  1. Train each teacher independently on its task and evaluate performance to establish baseline expertise
  2. Implement and test the hidden state distillation loss with one teacher to verify alignment works
  3. Add soft label distillation with multiple teachers and compare against single-teacher baseline

## Open Questions the Paper Calls Out

### Open Question 1
How does the 3M framework perform on datasets with different class distributions or when trained on a more balanced dataset? The paper notes that classification accuracy is associated with dataset distribution, with more frequent data corresponding to higher classification scores, even with sample weighting. This remains unresolved as experiments only use the existing dataset distribution without exploring balanced or differently distributed datasets.

### Open Question 2
What is the impact of using different teacher-student model architectures on the 3M framework's performance? The paper uses a specific configuration (12-layer teachers distilling to an 8-layer student) but doesn't explore other architectural configurations. This remains unresolved as the paper only tests one specific teacher-student architecture configuration and doesn't explore how different configurations might affect performance.

### Open Question 3
How does the 3M framework generalize to other esports games or different types of livestream content beyond League of Legends? The framework was only tested on one specific game and content type, so its generalizability to other domains remains unknown. This remains unresolved as the paper focuses specifically on League of Legends esports data and doesn't discuss generalization to other games or content types.

## Limitations
- No ablation studies for individual modalities or teacher combinations, making it difficult to assess which components contribute most to performance gains
- Significant variation in performance across event types, with TOWER and DRAGON events having notably lower F1-scores than KILL events
- Dataset composition and class balance are not fully specified, which is critical for understanding performance differences across event types

## Confidence
- High Confidence: The core multi-teacher distillation mechanism is well-specified with clear mathematical formulations and reasonable experimental validation
- Medium Confidence: The effectiveness of hidden state alignment and soft label distillation is supported by ablation studies, but the lack of individual modality ablation studies reduces confidence in understanding the specific contribution of each mechanism
- Low Confidence: The generalizability of the approach to other esports or game types remains uncertain due to the single-game focus and limited discussion of domain transfer

## Next Checks
1. Perform ablation study on modality combinations to quantify the contribution of each modality to overall performance
2. Analyze dataset distribution across event types and evaluate model performance under different class balance scenarios
3. Test the framework on a different esports game to evaluate whether the multi-teacher distillation approach generalizes beyond League of Legends