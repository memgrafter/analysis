---
ver: rpa2
title: 'Navigating Brain Language Representations: A Comparative Analysis of Neural
  Language Models and Psychologically Plausible Models'
arxiv_id: '2404.19364'
source_url: https://arxiv.org/abs/2404.19364
tags:
- brain
- language
- word
- neural
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compared neural language models (NLMs) and psychologically
  plausible models (PPMs) on multi-modal cognitive datasets in Chinese and English,
  examining both word and discourse levels. PPMs significantly outperformed NLMs across
  different modalities (fMRI, eye-tracking) and languages, particularly those incorporating
  embodied and network-topological information.
---

# Navigating Brain Language Representations: A Comparative Analysis of Neural Language Models and Psychologically Plausible Models

## Quick Facts
- arXiv ID: 2404.19364
- Source URL: https://arxiv.org/abs/2404.19364
- Reference count: 9
- Primary result: Psychologically plausible models outperform neural language models in predicting brain activation across modalities and languages

## Executive Summary
This paper conducts a comprehensive comparison of neural language models (NLMs) and psychologically plausible models (PPMs) on multi-modal cognitive datasets in both Chinese and English. The study examines both word and discourse levels, analyzing fMRI and eye-tracking data to determine which computational approaches best predict brain activation patterns. PPMs, particularly those incorporating embodied and network-topological information, significantly outperformed NLMs across different modalities and languages. The findings suggest that PPMs are more effective at capturing brain-relevant semantic information than NLMs trained on language prediction tasks.

## Method Summary
The study employs an encoding model approach where representations from NLMs (GloVe, Word2Vec, GPT2, BERT) and PPMs (LSM, NTM, EBM) are mapped to brain activation patterns using ridge regression with 10-fold cross-validation. fMRI data is preprocessed using fMRIPrep and HCP pipelines, while eye-tracking features are extracted from fixation data. Model representations are convolved with the hemodynamic response function and down-sampled to match fMRI sampling rates. Performance is evaluated using Pearson correlation coefficients between predicted and actual brain activation, with statistical significance assessed using group-level paired t-tests with false discovery rate correction.

## Key Results
- PPMs significantly outperformed NLMs across both fMRI and eye-tracking modalities in Chinese and English
- Embodied-based models showed exceptional performance at both word and discourse levels
- Context-aware NLMs performed better at discourse level than word level
- Eye-tracking results showed distinct patterns from fMRI, with local-statistical models excelling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Psychologically plausible models outperform neural language models in predicting brain activation because they encode brain-relevant semantic information through computational principles that mirror human cognitive processes.
- Mechanism: PPMs leverage three distinct computational principles—local-statistical, network-topological, and embodied-based—that directly capture aspects of human semantic representation through co-occurrence statistics, topological properties of semantic networks, and multi-modal experiential information.
- Core assumption: The semantic representations in the human brain are structured according to these computational principles, making PPMs more aligned with neural processing than NLMs trained on language prediction tasks.
- Evidence anchors: Abstract highlights embodied model's superior performance; section explains the three computational principles; corpus analysis shows limited related research.
- Break condition: If PPM computational principles do not align with actual neural semantic representation mechanisms, or if NLMs develop architectures that explicitly model brain-like processing.

### Mechanism 2
- Claim: Context-aware NLMs perform better at discourse level than word level because they can capture contextual meaning of words within their surrounding text.
- Mechanism: Context-aware models like BERT and GPT2 use bidirectional or autoregressive training to encode word representations that depend on surrounding context, which is particularly valuable for understanding complex language units like discourse that require integration of multiple words' meanings.
- Core assumption: Brain activation patterns for discourse processing depend more on contextual integration than isolated word processing, making context-aware models more suitable for discourse-level prediction.
- Evidence anchors: Abstract notes context-aware NLMs perform better at discourse level; section shows PPMs outperform NLMs across brain networks with less language processing emphasis.
- Break condition: If brain activation patterns for discourse processing rely more on other factors than contextual word meaning, or if PPMs develop mechanisms to effectively incorporate context.

### Mechanism 3
- Claim: Eye-tracking patterns show distinct predictive patterns from fMRI because they capture different aspects of language processing—behavioral responses versus neural activation.
- Mechanism: Eye-tracking measures observable behavioral responses during reading (fixation duration, number of fixations, etc.) that reflect processing effort and timing, while fMRI captures underlying neural activation patterns. These different measurement types are best predicted by different model types—local-statistical models excel at predicting eye-tracking, while embodied and network-topological models better predict fMRI.
- Core assumption: Behavioral responses during language processing reflect different cognitive mechanisms than neural activation patterns, requiring different computational approaches for accurate prediction.
- Evidence anchors: Abstract notes eye-tracking shows distinct patterns from fMRI; section shows LSM outperforms other PPMs on nearly all eye-tracking features.
- Break condition: If eye-tracking and fMRI actually capture the same underlying cognitive processes, or if models can be developed that effectively predict both measurement types.

## Foundational Learning

- Concept: Hemodynamic Response Function (HRF)
  - Why needed here: The paper mentions that word representations are "convolved with the hemodynamic response function (HRF) and down-sampled to the discourse-fMRI sampling rate." Understanding HRF is crucial for interpreting how neural activity is measured in fMRI studies.
  - Quick check question: What is the hemodynamic response function and why is it necessary to convolve neural representations with it when predicting fMRI data?

- Concept: False Discovery Rate (FDR) correction
  - Why needed here: The paper uses "group-level paired t-test with false discovery rate (FDR) correction to assess the significance of comparison results." This statistical method is essential for understanding how the authors determine whether their results are statistically significant.
  - Quick check question: What is FDR correction and why is it important when conducting multiple statistical comparisons in neuroimaging studies?

- Concept: Semantic feature dimensions
  - Why needed here: The Embodied-Based Model (EBM) uses "Word representations with six semantic dimensions" including vision, motor, socialness, emotion, time, and space. Understanding these semantic features is crucial for interpreting how the EBM captures brain-relevant information.
  - Quick check question: What are the six semantic dimensions used in the Embodied-Based Model and how do they relate to human conceptual representation?

## Architecture Onboarding

- Component map: Model representation extraction -> Data preprocessing (fMRI, eye-tracking) -> HRF convolution and downsampling -> Encoding model training (ridge regression, 10-fold CV) -> Evaluation and analysis (Pearson correlation, t-tests with FDR correction)
- Critical path: The most critical path is the complete cycle from representation extraction through encoding model training to evaluation. Any failure in representation quality, preprocessing alignment, or encoding model performance will propagate through the entire analysis. The HRF convolution and sampling rate alignment between representations and fMRI data is particularly critical.
- Design tradeoffs: The choice between context-independent vs context-aware models involves a tradeoff between capturing general semantic information (context-independent) versus specific contextual meaning (context-aware). Similarly, the choice of PPM type involves tradeoffs between capturing local statistical patterns, network topology, or embodied information.
- Failure signatures: Poor encoding performance across all models suggests issues with data preprocessing or alignment. If context-aware models consistently underperform context-independent models, this may indicate problems with the context extraction methodology. If PPMs fail to outperform NLMs despite theoretical advantages, this suggests either the PPM implementation is flawed or the core assumptions about brain-relevant computational principles are incorrect.
- First 3 experiments:
  1. Verify HRF convolution and sampling rate alignment by predicting a simple baseline (e.g., mean activation) and ensuring the encoding pipeline produces reasonable results before testing actual models.
  2. Test context-independent models (GloVe, Word2Vec) on both English and Chinese word-level fMRI to confirm the expected language-dependent performance differences before moving to more complex models.
  3. Compare a single PPM type (e.g., LSM) against a single NLM type (e.g., Word2Vec) on eye-tracking data to validate the core finding that local-statistical models excel at predicting behavioral signals before conducting comprehensive model comparisons.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural or training differences in neural language models cause their inconsistent performance across Chinese and English word-level fMRI encoding?
- Basis in paper: [explicit] The paper observes that context-independent models (Word2Vec) outperform context-aware models (BERT, GPT2) in Chinese, while the opposite is true for English at the word level.
- Why unresolved: The paper attributes this to linguistic differences like homographic/homophonic morphemes in Chinese requiring holistic processing, but does not empirically test whether architectural changes or training paradigms could bridge this gap.
- What evidence would resolve it: Systematic experiments varying training objectives, tokenization strategies, and model depth specifically for Chinese vs. English to identify which factors drive the performance discrepancy.

### Open Question 2
- Question: How do embodied-based models achieve superior discourse-level encoding performance compared to other psychologically plausible models, and can this mechanism be incorporated into neural language models?
- Basis in paper: [explicit] The paper shows that the embodied-based model (EBM) consistently outperforms other PPMs at discourse level by incorporating sensory-motor and abstract semantic dimensions.
- Why unresolved: The paper demonstrates EBM's superiority but doesn't investigate which specific semantic dimensions or integration mechanisms are most critical, nor whether these could enhance neural models.
- What evidence would resolve it: Ablation studies identifying the most predictive semantic dimensions in EBM, followed by experiments incorporating these dimensions into neural model architectures.

### Open Question 3
- Question: Why do local-statistical models excel at predicting eye-tracking patterns but perform poorly at fMRI encoding, and what does this reveal about the relationship between behavioral and neural data?
- Basis in paper: [explicit] The paper observes that local-statistical models (LSM) outperform other PPMs on eye-tracking features while underperforming on fMRI data.
- Why unresolved: The paper notes this discrepancy but doesn't explore whether it reflects fundamental differences in the cognitive processes measured by these modalities or limitations in how models capture temporal dynamics.
- What evidence would resolve it: Comparative analysis of temporal resolution, spatial specificity, and cognitive processes captured by eye-tracking versus fMRI, along with models specifically designed to capture these differences.

## Limitations
- Limited corpus evidence with average FMR of 0.463 suggests this is a relatively novel comparison area
- Does not address potential confounds such as individual differences in brain anatomy or language proficiency
- Cross-linguistic comparison between Chinese and English based on limited datasets may not capture full complexity of typological differences

## Confidence
- PPMs significantly outperform NLMs across modalities and languages: **High**
- Context-aware NLMs perform better at discourse than word level: **Medium**
- Eye-tracking patterns are distinctly predicted by local-statistical models: **Medium**

## Next Checks
1. **Replication across diverse languages**: Test the same model comparison framework on typologically diverse languages (e.g., agglutinative languages like Turkish or morphologically rich languages like Arabic) to determine if the English/Chinese performance patterns generalize.
2. **Ablation study of PPM components**: Systematically remove individual components from the Embodied-Based Model (e.g., sensory dimensions, social dimensions) to quantify the contribution of each semantic feature to brain encoding performance.
3. **Temporal dynamics analysis**: Examine how encoding performance varies across different time windows during discourse processing to determine whether PPM advantages are consistent throughout or specific to particular processing stages.