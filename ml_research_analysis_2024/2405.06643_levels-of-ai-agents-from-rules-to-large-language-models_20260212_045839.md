---
ver: rpa2
title: 'Levels of AI Agents: from Rules to Large Language Models'
arxiv_id: '2405.06643'
source_url: https://arxiv.org/abs/2405.06643
tags:
- agents
- llms
- language
- learning
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a five-level categorization of AI agents inspired
  by SAE's autonomous driving levels. L0 includes tools for perception and action
  without AI; L1 uses rule-based AI; L2 replaces rules with IL/RL-based AI and adds
  reasoning and decision-making; L3 applies LLM-based AI with memory and reflection;
  L4 adds autonomous learning and generalization; L5 includes personality (emotion
  + character) and collaborative behavior among multi-agents.
---

# Levels of AI Agents: from Rules to Large Language Models

## Quick Facts
- arXiv ID: 2405.06643
- Source URL: https://arxiv.org/abs/2405.06643
- Authors: Yu Huang
- Reference count: 0
- Proposes a five-level categorization of AI agents inspired by SAE's autonomous driving levels

## Executive Summary
This paper introduces a systematic framework for classifying AI agents across five levels, from basic tool-assisted systems to sophisticated multi-agent collaborative environments. The framework draws inspiration from autonomous vehicle classification standards to provide a structured progression path for agent development. Each level represents a meaningful advancement in capabilities, moving from simple perception tools to agents with personality and emotional intelligence.

The proposed levels create a taxonomy that helps researchers and developers understand the current state of AI agent technology and identify pathways for advancement. By establishing clear distinctions between levels based on underlying AI approaches (rules, reinforcement learning, LLMs) and capabilities (reasoning, memory, learning, personality), the framework provides a roadmap for future agent development.

## Method Summary
The paper presents a conceptual framework that categorizes AI agents into five levels based on their underlying technology and capabilities. The classification system progresses from L0 (basic tools without AI) through L1 (rule-based AI) to L2 (IL/RL-based AI with reasoning), L3 (LLM-based AI with memory and reflection), L4 (autonomous learning and generalization), and L5 (personality and collaborative behavior). The framework serves as a theoretical structure for understanding agent capabilities rather than presenting empirical validation.

## Key Results
- Establishes a five-level framework for AI agent classification from basic tools to personality-driven multi-agent systems
- L0-L2 focus on traditional AI approaches (rules, IL/RL) with increasing complexity in reasoning and decision-making
- L3-L5 transition to LLM-based architectures with memory, autonomous learning, and social capabilities
- Provides a systematic progression path for agent development and capability enhancement

## Why This Works (Mechanism)
The framework works by establishing clear progression criteria based on the sophistication of AI techniques and the complexity of agent capabilities. Each level builds upon the previous one by incorporating more advanced AI approaches and expanding the agent's functional repertoire. The transition from rule-based to learning-based to LLM-based systems represents genuine technological advancements, while the addition of memory, reflection, autonomous learning, and personality reflects increasing agent autonomy and social intelligence.

## Foundational Learning
- SAE autonomy levels - why needed: Provides established precedent for multi-level classification systems; quick check: verify alignment with SAE Level 0-5 structure
- Rule-based vs learning-based AI - why needed: Establishes fundamental distinction between L1 and L2; quick check: compare performance on rule-following vs adaptive tasks
- LLM capabilities and limitations - why needed: Critical for understanding L3+ distinctions; quick check: evaluate LLM performance on reasoning vs simple pattern matching
- Memory systems in AI - why needed: Essential for L3+ reflection and learning; quick check: test agent performance with and without persistent memory
- Multi-agent coordination - why needed: Foundation for L5 collaborative behavior; quick check: measure performance of single vs multi-agent systems
- Personality modeling in AI - why needed: Core concept for L5 emotional intelligence; quick check: assess consistency of agent behavior across different contexts

## Architecture Onboarding

Component map: Perception/Acquisition -> Processing/Reasoning -> Memory/Storage -> Action/Response -> Learning/Adaptation

Critical path: The progression from perception through reasoning to action forms the core agent loop, with learning and adaptation mechanisms enhancing performance over time.

Design tradeoffs: Traditional vs LLM-based approaches balance interpretability and control against flexibility and capability; memory systems trade storage overhead against improved performance; personality modeling increases engagement but may reduce task efficiency.

Failure signatures: Rule-based systems fail on edge cases outside predefined parameters; learning-based systems may overfit or show unexpected behavior; LLM-based systems may hallucinate or lack consistency; personality-driven agents may prioritize social interaction over task completion.

First experiments:
1. Implement a rule-based agent (L1) and measure performance on structured vs unstructured tasks
2. Compare IL/RL-based agent (L2) performance against rule-based approach on adaptive scenarios
3. Evaluate LLM-based agent (L3) reasoning capabilities against traditional approaches on complex problem-solving

## Open Questions the Paper Calls Out
None

## Limitations
- Framework lacks empirical validation against existing agent architectures
- Distinctions between levels, particularly L3-L4, remain somewhat arbitrary without concrete benchmarks
- L5 concepts of personality and collaboration are highly speculative with limited implementation research
- Framework does not address failure modes or safety considerations at each level

## Confidence

High: Conceptual framework structure - The five-level progression from tools to sophisticated agents follows a logical pattern aligned with observed developments in AI agent technology

Medium: Level definitions and distinctions - While descriptions are clear, boundaries between levels are not rigorously defined or empirically validated

Low: L5 personality and collaboration claims - These concepts remain largely theoretical with limited research on implementation or measurement

## Next Checks

1. Implement and benchmark at least three different agents at different levels (e.g., rule-based L1, RL-based L2, and LLM-based L3) to test the practical distinctions between levels

2. Develop specific evaluation metrics and tests for each level, particularly focusing on the transition points between levels to ensure they represent meaningful advances rather than arbitrary distinctions

3. Conduct a systematic literature review to identify existing agent architectures and map them to the proposed levels, testing the framework's coverage and explanatory power across the current state of the field