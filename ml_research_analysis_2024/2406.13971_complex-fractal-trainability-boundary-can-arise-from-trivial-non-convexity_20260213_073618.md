---
ver: rpa2
title: Complex fractal trainability boundary can arise from trivial non-convexity
arxiv_id: '2406.13971'
source_url: https://arxiv.org/abs/2406.13971
tags:
- fractal
- loss
- boundary
- trainability
- dimension
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the origin of fractal boundaries in hyperparameter
  space that separate convergent and divergent training outcomes in neural network
  optimization. The author hypothesizes that simple non-convexity in the loss function
  can generate such fractal boundaries through sensitive dependence of gradient descent
  dynamics on learning rate.
---

# Complex fractal trainability boundary can arise from trivial non-convexity

## Quick Facts
- arXiv ID: 2406.13971
- Source URL: https://arxiv.org/abs/2406.13971
- Reference count: 0
- Key outcome: Simple non-convexity in loss functions generates fractal boundaries in hyperparameter space through gradient sensitivity

## Executive Summary
This study investigates the origin of fractal boundaries in hyperparameter space that separate convergent and divergent training outcomes in neural network optimization. The author hypothesizes that simple non-convexity in the loss function can generate such fractal boundaries through sensitive dependence of gradient descent dynamics on learning rate. To test this hypothesis, the author constructs simple loss functions by perturbing convex quadratic functions with cosine terms and demonstrates that even these simple non-convex functions exhibit fractal trainability boundaries. The analysis identifies "roughness" - a measure of gradient sensitivity to parameter changes - as the key factor controlling fractal dimensions.

## Method Summary
The author constructs simple loss functions by perturbing convex quadratic functions with cosine terms (either additive or multiplicative). Using gradient descent with varying learning rates, the author numerically identifies boundaries between bounded and divergent training. The analysis reveals that even these simple non-convex functions exhibit fractal trainability boundaries, with fractal dimensions influenced by perturbation type, wavelength, amplitude, and parameter dimension. A key insight is that the fractal dimension is determined by "roughness," which quantifies gradient sensitivity to parameter changes. The author shows that fractal behavior emerges precisely when the perturbed loss function becomes non-convex.

## Key Results
- Fractal trainability boundaries arise from trivial non-convexity in loss functions
- Roughness of perturbation determines fractal dimension of trainability boundaries
- Clear transition from non-fractal to fractal behavior occurs when perturbed loss function becomes non-convex

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Non-convexity in loss functions creates gradient sensitivity to parameters, which transforms into sensitive dependence on learning rate, generating fractal boundaries.
- Mechanism: When the loss function has non-convex perturbations, small changes in parameters cause large changes in the gradient. During gradient descent, these large gradient changes amplify small differences in learning rate, causing nearby learning rates to follow divergent optimization trajectories.
- Core assumption: The gradient's sensitivity to parameter changes is sufficient to create sensitive dependence on hyperparameters without requiring inherent chaos in the optimization dynamics.
- Evidence anchors:
  - [abstract] "the author hypothesizes that simple non-convexity in the loss function can generate such fractal boundaries through sensitive dependence of gradient descent dynamics on learning rate"
  - [section] "We denote the loss function as f(x) where x is the parameter to optimize to minimize f(x). GD can be described as iterating the function x(k+1) = x(k+1)(x(k); s) = x(k) − s∇f(x(k)). If non-convexity can make the gradient ∇f(x) sensitive to parameter x, after we shift learning rate s a little at the kth step, x(k+1) will be a little different from the one obtained with the unchanged learning rate. However, the gradient at the new x(k+1) will be very different, leading to very different subsequent iterations."
- Break condition: If the loss function is convex or the perturbations are too small to create significant gradient sensitivity, fractal boundaries will not form.

### Mechanism 2
- Claim: "Roughness" of perturbation controls the fractal dimension of trainability boundaries.
- Mechanism: Roughness quantifies how sensitive the gradient is to parameter changes. Higher roughness leads to more sensitive gradients, which creates more complex fractal structures. The author shows this through renormalization analysis where roughness is the invariant quantity controlling fractal dimension.
- Core assumption: Fractal dimension depends primarily on loss function properties rather than initial conditions or other factors.
- Evidence anchors:
  - [abstract] "Our analysis identifies 'roughness of perturbation', which measures the gradient's sensitivity to parameter changes, as the factor controlling fractal dimensions of trainability boundaries"
  - [section] "We found that for the additive perturbation case, the fractal dimension increases with decreasing wavelength and increasing amplitude... For the multiplicative perturbation case, the fractal dimension has no clear dependence on amplitude or wavelength... The renormalization can only say ϵ1/λ2 1 and ϵ2/λ2 2 determine the fractal dimension"
- Break condition: If roughness is below a critical threshold, the loss function becomes convex and fractal behavior disappears.

### Mechanism 3
- Claim: The transition from non-fractal to fractal behavior occurs precisely when the perturbed loss function becomes non-convex.
- Mechanism: Convex loss functions have well-behaved gradients that don't amplify small changes in learning rate. When perturbations make the loss non-convex, the gradient can change direction rapidly, creating the sensitive dependence needed for fractal boundaries.
- Core assumption: Non-convexity is necessary for fractal trainability boundaries to emerge.
- Evidence anchors:
  - [abstract] "We observed a clear transition from non-fractal to fractal trainability boundaries as roughness increases, with the critical roughness causing the perturbed loss function non-convex"
  - [section] "We therefore offer a perspective to explain the fractal trainability boundaries observed in real neural networks as a result of non-convexity, emphasizing 'roughness' as the factor controlling fractal dimensions"
- Break condition: If the loss function remains convex despite perturbations, fractal boundaries will not form regardless of roughness value.

## Foundational Learning

- Concept: Gradient descent optimization and loss landscape analysis
  - Why needed here: Understanding how gradient descent interacts with loss function geometry is fundamental to grasping why fractal boundaries emerge from non-convex perturbations
  - Quick check question: What happens to gradient descent trajectories when the loss function has multiple local minima versus being convex?

- Concept: Fractal geometry and box dimension
- Why needed here: The paper uses fractal dimension to quantify the complexity of trainability boundaries, requiring understanding of how fractal dimensions are measured and interpreted
  - Quick check question: How does the box-counting method estimate fractal dimension from discrete data points?

- Concept: Renormalization and scale invariance
  - Why needed here: The author uses renormalization to identify invariant quantities (like roughness) that determine fractal dimension across different scales
  - Quick check question: What does it mean for a quantity to be invariant under renormalization transformations?

## Architecture Onboarding

- Component map:
  - Loss function construction module -> Gradient descent simulator -> Boundary detection system -> Fractal analysis pipeline -> Roughness calculation module

- Critical path:
  1. Construct loss function with specified perturbations
  2. Run gradient descent across range of learning rates
  3. Classify each learning rate as producing bounded or divergent training
  4. Identify boundary segments between different classifications
  5. Count boundary segments at increasing resolutions
  6. Fit scaling law to determine fractal dimension
  7. Calculate roughness and analyze its relationship to fractal dimension

- Design tradeoffs:
  - Resolution vs. computational cost: Higher N values provide better fractal dimension estimates but require exponentially more computation
  - Upper loss bound selection: Affects classification accuracy between slowly diverging and bounded training
  - Initial condition sensitivity: May influence boundary detection but appears less critical than loss function properties

- Failure signatures:
  - Linear scaling of boundary segments with N indicates no fractal behavior
  - Inconsistent fractal dimensions across different initial conditions suggest sensitivity to initialization
  - Missing fractal transitions at expected roughness thresholds may indicate numerical artifacts

- First 3 experiments:
  1. Verify basic setup by testing on pure quadratic function f(x) = x², which should show no fractal behavior with single trainability boundary at s = 1.0
  2. Test additive perturbation case with moderate roughness (e.g., ε = 0.2, λ = 0.1) to confirm fractal boundary emergence and measure fractal dimension
  3. Vary perturbation wavelength while keeping amplitude constant to verify roughness relationship and critical transition point

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the fractal dimension of trainability boundaries depend on the initial parameter value x(0) for higher-dimensional cases?
- Basis in paper: [explicit] The paper states "Our renormalization procedure cannot connect two functions with different dimensions d, and therefore roughness values for functions with different dimensions d are not comparable. Future works are needed to analyze the impact of parameter dimensions d, e.g., defining a generalized roughness that can determine fractal dimension of trainability boundaries across different d."
- Why unresolved: The paper only tested initial conditions for 1D cases and found no significant effect, but the impact for higher dimensions remains unexplored.
- What evidence would resolve it: Numerical experiments systematically varying x(0) across different dimensionalities (d > 1) to measure changes in fractal dimension.

### Open Question 2
- Question: Can the renormalization procedure be generalized to connect loss functions with different parameter dimensions d?
- Basis in paper: [explicit] "Our renormalization procedure cannot connect two functions with different dimensions d, and therefore roughness values for functions with different dimensions d are not comparable."
- Why unresolved: The current renormalization approach only works within the same dimensionality and fails to establish connections across different dimensions.
- What evidence would resolve it: Development of a mathematical framework that extends renormalization to handle functions with varying parameter dimensions, with validation on test functions.

### Open Question 3
- Question: What is the precise mathematical relationship between roughness and fractal dimension for general loss functions beyond the simple quadratic perturbations studied?
- Basis in paper: [explicit] "Our renormalization analysis, while effective in identifying roughness as a key parameter, exhibits limited generalizability. This analysis is restricted to simple functions with explicitly defined parameters, making our conclusions highly specific to the cases studied."
- Why unresolved: The current analysis only covers specific forms of non-convexity (additive and multiplicative cosine perturbations) and cannot be directly applied to more complex loss landscapes.
- What evidence would resolve it: Theoretical derivation of a general formula relating roughness to fractal dimension that applies to arbitrary non-convex loss functions, verified through numerical experiments.

## Limitations
- Analysis relies on simplified toy loss functions that may not fully capture real neural network training landscapes
- Quantitative predictions for actual neural networks remain to be validated
- Critical roughness thresholds are specific to the simple cosine perturbations studied and may not generalize to more complex loss geometries

## Confidence
- **High confidence**: Fractal boundaries arise from trivial non-convexity; roughness determines fractal dimension; clear transition from non-fractal to fractal behavior at convexity threshold
- **Medium confidence**: Quantitative relationship between roughness and fractal dimension; renormalization analysis correctly identifies invariant quantities
- **Low confidence**: Direct applicability of toy model predictions to real neural network training dynamics

## Next Checks
1. Test the framework on loss functions with different perturbation types (e.g., polynomial, exponential) to verify the generality of the roughness-fractal dimension relationship
2. Apply the analysis to simple neural network architectures with small parameter counts to bridge the gap between toy models and practical training
3. Investigate whether similar fractal behavior emerges in other hyperparameter boundaries (e.g., batch size, momentum) using the same mechanistic framework