---
ver: rpa2
title: Few-Shot Class-Incremental Learning with Prior Knowledge
arxiv_id: '2402.01201'
source_url: https://arxiv.org/abs/2402.01201
tags:
- data
- learning
- class
- incremental
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting and overfitting in
  few-shot class-incremental learning (FSCIL) by introducing prior knowledge from
  unlabeled data. The authors propose Learning with Prior Knowledge (LwPK), which
  leverages clustering to assign pseudo-labels to unlabeled incremental class samples
  and jointly trains them with labeled base class samples.
---

# Few-Shot Class-Incremental Learning with Prior Knowledge

## Quick Facts
- arXiv ID: 2402.01201
- Source URL: https://arxiv.org/abs/2402.01201
- Authors: Wenhao Jiang; Duo Li; Menghan Hu; Guangtao Zhai; Xiaokang Yang; Xiao-Ping Zhang
- Reference count: 40
- Primary result: Introduces Learning with Prior Knowledge (LwPK) method that outperforms state-of-the-art FSCIL approaches on CIFAR100, CUB200, and miniImageNet datasets

## Executive Summary
This paper addresses catastrophic forgetting and overfitting in few-shot class-incremental learning (FSCIL) by introducing prior knowledge from unlabeled data. The authors propose Learning with Prior Knowledge (LwPK), which leverages clustering to assign pseudo-labels to unlabeled incremental class samples and jointly trains them with labeled base class samples. This approach constructs a hybrid embedding space that improves the model's ability to generalize to new classes while preserving old knowledge. The method was evaluated on CIFAR100, CUB200, and miniImageNet datasets, showing superior performance compared to state-of-the-art FSCIL methods. Theoretical analysis based on empirical risk minimization and class distance measurement supports the effectiveness of LwPK.

## Method Summary
The proposed LwPK method addresses FSCIL challenges by incorporating prior knowledge from unlabeled data into the learning process. The approach uses clustering algorithms to assign pseudo-labels to unlabeled incremental class samples, which are then jointly trained with labeled base class samples. This hybrid training strategy creates an embedding space that simultaneously learns to recognize base classes with strong supervision while building representations for new classes using the structural information from unlabeled data. The method leverages the intuition that unlabeled data from new classes can provide valuable distributional information that helps the model better generalize when few-shot samples become available. By combining supervised learning from base classes with semi-supervised learning from unlabeled incremental class samples, LwPK mitigates catastrophic forgetting while reducing overfitting to limited few-shot examples.

## Key Results
- LwPK achieves state-of-the-art performance on CIFAR100, CUB200, and miniImageNet datasets for FSCIL tasks
- The method demonstrates improved ability to generalize to new classes while preserving knowledge of base classes
- Theoretical analysis shows that incorporating prior knowledge through unlabeled data improves empirical risk minimization and class separation in the embedding space

## Why This Works (Mechanism)
The effectiveness of LwPK stems from its ability to leverage structural information from unlabeled data to guide the learning of new class representations. By clustering unlabeled incremental class samples and using the resulting pseudo-labels for training, the model gains early exposure to the distributional characteristics of new classes before receiving few-shot examples. This prior knowledge acts as a regularizer that prevents the model from overfitting to the limited labeled samples while also providing a smoother optimization landscape for incorporating new classes. The hybrid embedding space created through joint training with both labeled base classes and pseudo-labeled incremental samples allows the model to maintain discriminative boundaries for known classes while simultaneously building representations that can accommodate new classes. This dual optimization objective addresses the fundamental tension in FSCIL between stability (preserving old knowledge) and plasticity (learning new classes).

## Foundational Learning
- **Catastrophic forgetting**: Why needed - the tendency of neural networks to rapidly forget previously learned information when trained on new tasks; Quick check - measure performance degradation on base classes after incremental learning
- **Empirical risk minimization**: Why needed - fundamental framework for machine learning that LwPK builds upon; Quick check - verify that the total risk is reduced by incorporating prior knowledge
- **Semi-supervised learning**: Why needed - LwPK uses pseudo-labeled data from clustering to augment supervised learning; Quick check - assess performance improvement when varying the amount of unlabeled data
- **Clustering algorithms**: Why needed - used to assign pseudo-labels to unlabeled incremental class samples; Quick check - evaluate different clustering methods (k-means, hierarchical) for pseudo-label quality
- **Embedding space optimization**: Why needed - LwPK constructs a hybrid space balancing old and new class representations; Quick check - visualize embedding space before and after incremental learning
- **Class distance measurement**: Why needed - theoretical analysis of LwPK's effectiveness relies on quantifying inter-class separation; Quick check - measure class separability metrics in the embedding space

## Architecture Onboarding

**Component Map**
Base Classifier -> Feature Extractor -> Clustering Module -> Pseudo-label Generator -> Joint Training Module -> Incremental Classifier

**Critical Path**
Base Classifier (pre-trained) -> Feature Extractor (frozen/partially frozen) -> Clustering Module (unlabeled data) -> Pseudo-label Generator -> Joint Training (base + pseudo-labeled data) -> Incremental Classifier (fine-tuned)

**Design Tradeoffs**
The primary tradeoff involves the quality of pseudo-labels from clustering versus the quantity of unlabeled data used. Higher-quality clustering improves the effectiveness of prior knowledge incorporation but may be computationally expensive or require careful parameter tuning. The method must balance the influence of pseudo-labeled data against labeled base class data to prevent degradation of base class performance. Another tradeoff exists between the granularity of clustering (number of clusters) and the risk of incorrect pseudo-label assignment, which could introduce noise that propagates through the model.

**Failure Signatures**
Poor clustering quality leading to noisy pseudo-labels will manifest as degraded performance on both base and incremental classes, particularly evident when few-shot samples become available. Over-reliance on pseudo-labeled data may cause catastrophic forgetting of base classes, observable as significant performance drops on base class recognition tasks. If the clustering algorithm creates too few or too many clusters relative to the true class structure, the model may fail to learn discriminative features for new classes or create unnecessary complexity in the embedding space.

**First 3 Experiments**
1. Ablation study varying the amount of unlabeled data used for clustering to quantify the impact of prior knowledge quantity on FSCIL performance
2. Comparison of different clustering algorithms (k-means, hierarchical clustering, DBSCAN) for pseudo-label assignment quality and downstream task performance
3. Analysis of base class performance retention after incremental learning with varying proportions of pseudo-labeled versus supervised training data

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the text provided. However, the methodology raises implicit questions about the optimal balance between supervised and semi-supervised learning in FSCIL scenarios, the generalizability of clustering-based pseudo-labeling across diverse datasets, and the scalability of the approach to larger numbers of incremental classes.

## Limitations
- Reliance on clustering for pseudo-label assignment may introduce noise and errors that could propagate through the model
- Effectiveness may be dataset-dependent, particularly for datasets with subtle class distinctions
- Scalability to very large numbers of incremental classes remains untested
- Does not address potential biases introduced by unlabeled data quality or distribution differences between base and incremental classes

## Confidence
- **High Confidence**: The proposed method's effectiveness on CIFAR100, CUB200, and miniImageNet datasets, as demonstrated by empirical results
- **Medium Confidence**: The theoretical justification based on empirical risk minimization and class distance measurement
- **Medium Confidence**: The claim that the hybrid embedding space construction improves generalization while preserving old knowledge

## Next Checks
1. Test the method's performance on datasets with more fine-grained class distinctions and varying data distributions between base and incremental classes
2. Conduct ablation studies to quantify the impact of pseudo-label noise on final performance and evaluate different clustering algorithms
3. Evaluate the method's scalability by testing on scenarios with larger numbers of incremental classes (e.g., 100+ classes) to assess long-term class-incremental learning capability