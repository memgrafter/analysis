---
ver: rpa2
title: 'Feature learning as alignment: a structural property of gradient descent in
  non-linear neural networks'
arxiv_id: '2402.05271'
source_url: https://arxiv.org/abs/2402.05271
tags:
- neural
- networks
- initialization
- learning
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper establishes that the neural feature ansatz (NFA), a key
  empirical observation in deep learning, arises from alignment between the left singular
  structure of weight matrices and the pre-activation tangent kernel (PTK) feature
  covariance. Through the centered NFA, the authors isolate the weight-PTK alignment
  and show that this alignment is driven by gradient-based training, with its strength
  predictable analytically at early times via simple data and label statistics.
---

# Feature learning as alignment: a structural property of gradient descent in non-linear neural networks

## Quick Facts
- arXiv ID: 2402.05271
- Source URL: https://arxiv.org/abs/2402.05271
- Reference count: 40
- Key outcome: The neural feature ansatz (NFA) arises from alignment between weight matrix singular structure and pre-activation tangent kernel (PTK) feature covariance during gradient descent.

## Executive Summary
This paper establishes that the neural feature ansatz (NFA), a key empirical observation in deep learning, arises from alignment between the left singular structure of weight matrices and the pre-activation tangent kernel (PTK) feature covariance. Through the centered NFA, the authors isolate the weight-PTK alignment and show that this alignment is driven by gradient-based training, with its strength predictable analytically at early times via simple data and label statistics. The work introduces Speed Limited Optimization (SLO), a layerwise gradient normalization scheme that increases NFA correlation and improves feature quality without requiring small initialization. Experiments demonstrate that SLO enhances feature learning in both synthetic chain-monomial tasks and real datasets (SVHN, CelebA), leading to higher UC-NFA correlations and better generalization.

## Method Summary
The paper investigates how gradient descent induces alignment between weight matrices and PTK feature covariance through the neural feature ansatz (NFA). The method involves training MLPs with ReLU activations on synthetic and real datasets while computing NFA correlations throughout training. The centered NFA isolates the weight-PTK alignment effect by separating it from initialization effects. Speed Limited Optimization (SLO) is introduced as a layerwise gradient normalization scheme that forces large weight changes to strengthen alignment. Theoretical predictions for early-time NFA correlations are derived using random matrix theory, while experiments validate these predictions across different initialization scales and training regimes.

## Key Results
- NFA arises from alignment between left singular vectors of weight matrices and eigenvectors of PTK feature covariance
- Small initialization increases NFA correlation by making weight updates dominate initialization effects
- SLO dramatically improves feature quality by forcing centered weight changes to dominate uncentered weights
- NFA strength correlates with generalization performance across synthetic and real datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The neural feature ansatz (NFA) arises because the left singular structure of weight matrices aligns with the pre-activation tangent kernel (PTK) feature covariance during gradient descent.
- Mechanism: Gradient descent updates cause the weight matrix W to change in a direction that aligns with the current PTK K. Early in training, the centered NFA (C-NFA) isolates this effect, showing that the second derivatives of the centered NFM and AGOP are driven by the product X⊤YKYX and X⊤YK²YX respectively. When these share eigenvectors (high correlation), the alignment strengthens.
- Core assumption: At initialization, the weight matrices are small enough that their change dominates the uncentered NFA, and the PTK K is non-trivial but not fully random relative to W.
- Evidence anchors:
  - [abstract] "Through the centered NFA, the authors isolate the weight-PTK alignment and show that this alignment is driven by gradient-based training..."
  - [section 2.2] "the NFA is equivalent to PTK-weight alignment... we demonstrate that the original NFA is driven by alignment of the left singular vectors of the weight matrices to with the PTK"
  - [corpus] Weak: neighboring papers discuss NTK and alignment but not the centered NFA specifically.
- Break condition: If K becomes independent of W (e.g., replaced by a random matrix with same spectrum), alignment drops sharply, as shown in chain-monomial experiments.

### Mechanism 2
- Claim: Speed Limited Optimization (SLO) increases NFA correlation by forcing large, layerwise-controlled changes in weight matrices.
- Mechanism: SLO sets the norm of the gradient for each layer to a constant Cℓ, making the centered weight change ¯W dominate the uncentered W. This pushes the C-NFA contribution toward 1, making C-NFA ≈ UC-NFA, which dramatically improves feature quality.
- Core assumption: The learning dynamics of deeper layers are slow enough that the first layer can align to the initial PTK without K changing much.
- Evidence anchors:
  - [abstract] "introduces Speed Limited Optimization (SLO), a layerwise gradient normalization scheme that increases NFA correlation..."
  - [section 4.2] "fixing the learning speed the be high in the first layer and low in the remaining layers causes the ratio of the unnormalized C-NFA to the UC-NFA to become close to 1"
  - [corpus] Weak: neighboring works mention adaptive learning rates but not the specific SLO scheme or its effect on NFA.
- Break condition: If the PTK changes rapidly (e.g., with very large learning rates or deep networks), alignment may break because W tries to align to a moving target.

### Mechanism 3
- Claim: Small initialization improves feature learning by increasing the relative magnitude of weight updates relative to initial weights.
- Mechanism: When initial weights are small, the change ¯W is large relative to W, making the centered NFA dominate the uncentered NFA. This forces the NFM to encode task structure early, improving generalization.
- Core assumption: Activation functions are homogeneous (e.g., ReLU) so that scaling weights is equivalent to scaling outputs/labels.
- Evidence anchors:
  - [abstract] "small initialization... increases NFA correlation and improves feature quality..."
  - [section 4.1] "decreasing initialization forces the weights to change more in order to fit the labels, leading to more change in F from its initialization"
  - [corpus] Weak: no direct mention of small initialization in neighbors, though NTK literature is cited.
- Break condition: If the activation is smooth at zero (e.g., tanh), small initialization may make the network nearly linear, reducing expressivity unless dynamics increase weight magnitude.

## Foundational Learning

- Concept: Neural Tangent Kernel (NTK) and its relation to feature learning
  - Why needed here: The paper builds on NTK theory but shows that feature learning (beyond lazy training) is essential. Understanding NTK helps explain why the PTK (pre-activation NTK) matters for alignment.
  - Quick check question: In the NTK regime, do networks learn features or just fit labels via kernel regression? (Answer: Just kernel regression; feature learning is absent.)

- Concept: Singular value decomposition (SVD) and eigenstructure of matrices
  - Why needed here: The NFA is about alignment of left singular vectors of W with eigenvectors of K. SVD is the tool to analyze and quantify this alignment.
  - Quick check question: If W = UΣV⊤ and K has eigenvectors Q, what does high correlation ρ(F, ¯G) imply about U and Q? (Answer: Their columns are aligned.)

- Concept: Random matrix theory (RMT) and free probability
  - Why needed here: The paper uses RMT to predict NFA correlations analytically in high dimensions, assuming asymptotic freeness of data and parameter matrices.
  - Quick check question: In free probability, if A and B are freely independent, what is E[tr(¯A R ¯B)]? (Answer: Zero, because alternating products vanish.)

## Architecture Onboarding

- Component map: X (input) -> MLP with L hidden layers (ReLU) -> y (output) -> gradient descent/SLO -> weight updates -> NFM F, AGOP ¯G, PTK K -> NFA correlation

- Critical path:
  1. Initialize weights (scale matters)
  2. Forward pass to compute pre-activations and gradients
  3. Compute PTK from gradients
  4. Update weights (standard GD or SLO)
  5. Measure NFA correlation at intervals
  6. (Optional) Compare NFM to EGOP for feature quality

- Design tradeoffs:
  - Initialization scale: Small → stronger C-NFA but risk of linear regime; Large → lazy training dominates, weak feature learning
  - SLO hyperparameters (Cℓ): High Cℓ in target layers forces alignment but may destabilize training if too large
  - Activation choice: Homogeneous (ReLU) simplifies scaling effects; smooth activations at zero may break small-init benefits

- Failure signatures:
  - NFA correlation stays near zero → PTK and W are misaligned (e.g., random K)
  - C-NFA >> UC-NFA throughout → initialization too large, lazy regime
  - UC-NFA high but feature quality low → alignment exists but not with task structure (e.g., wrong K)

- First 3 experiments:
  1. Train a 2-layer ReLU MLP on isotropic Gaussian data (chain-monomial task) with varying initialization scales; plot NFA correlations over time.
  2. Apply SLO with C₀=500, C₁=C₂=0.002 to the same task; compare NFA correlations and feature quality to standard training.
  3. Replace K with a random matrix of same spectrum; verify NFA correlation drops, confirming alignment is not just spectral.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Neural Feature Ansatz (NFA) develop with depth in more complex architectures like CNNs and transformers?
- Basis in paper: [explicit] The authors note that more research is needed to understand how PTK-weight alignment relates to generalization and trainability in deep networks, particularly for architectures like CNNs and transformers.
- Why unresolved: The paper focuses on fully-connected networks and provides theoretical predictions for one and two hidden layer networks with quadratic and ReLU activations. However, the behavior of NFA in deeper and more complex architectures remains unexplored.
- What evidence would resolve it: Experimental studies analyzing NFA in CNNs and transformers, along with theoretical models extending the current analysis to these architectures.

### Open Question 2
- Question: What is the role of gradient batch size and adaptive gradient methods in generalization, as measured by the NFA?
- Basis in paper: [explicit] The authors suggest that analyzing the NFA may clarify the role of gradient batch size and adaptive gradient methods in generalization, citing prior work on the topic.
- Why unresolved: While the paper demonstrates that dataset and optimizer choices affect NFA strength, it does not specifically investigate the impact of gradient batch size and adaptive methods on NFA and generalization.
- What evidence would resolve it: Empirical studies varying gradient batch size and using adaptive optimizers like Adam, while measuring NFA correlations and generalization performance.

### Open Question 3
- Question: How does the change in the pre-activation tangent kernel (PTK) feature covariance over time affect the development of NFA?
- Basis in paper: [explicit] The authors discuss the need to account for changes in the PTK feature covariance over time to predict NFA later in training, suggesting that eigenvectors of the Hessian change slowly during training.
- Why unresolved: The paper provides initial theoretical predictions for NFA at early times but does not fully explore how the evolving PTK feature covariance impacts NFA development throughout training.
- What evidence would resolve it: Theoretical models tracking the evolution of PTK feature covariance and its alignment with weights over training time, validated by experimental data.

## Limitations
- Theoretical analysis limited to two-layer networks and Gaussian data, with empirical validation on small-scale vision tasks
- Random matrix theory predictions provide only asymptotic results without rigorous error bounds for finite samples
- SLO effectiveness not extensively tested across diverse architectures and tasks beyond basic MLPs

## Confidence
- High: Centered NFA mechanism and weight-PTK alignment relationship
- Medium: Initialization effects and SLO performance on small-scale tasks
- Low: Random matrix theory predictions for finite-sample settings

## Next Checks
1. Test SLO on deeper architectures (5+ layers) and non-ReLU activations to assess generalization of the alignment mechanism.
2. Conduct a systematic ablation study of SLO hyperparameters (Cℓ values) across multiple tasks to identify optimal settings and failure modes.
3. Implement the random matrix theory predictions for finite-sample settings and compare against empirical NFA correlations to quantify approximation quality.