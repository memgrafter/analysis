---
ver: rpa2
title: Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large
  Language Models
arxiv_id: '2412.10257'
source_url: https://arxiv.org/abs/2412.10257
tags:
- knowledge
- vector
- concept
- tars
- removal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Targeted Angular Reversal of Weights (TARS),
  a novel method for removing specific knowledge from large language models (LLMs)
  without retraining. TARS identifies weight vectors in feedforward networks that
  strongly align with a concept's internal representation and replaces them with reversed
  vectors, reducing the concept's propagation through the model.
---

# Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in Large Language Models

## Quick Facts
- arXiv ID: 2412.10257
- Source URL: https://arxiv.org/abs/2412.10257
- Reference count: 7
- Primary result: Successfully removed specific knowledge from Llama 3.1 8B with minimal edits while maintaining general model performance

## Executive Summary
This paper introduces Targeted Angular Reversal of Weights (TARS), a novel method for removing specific knowledge from large language models without retraining. TARS identifies weight vectors in feedforward networks that strongly align with a concept's internal representation and replaces them with reversed vectors, reducing the concept's propagation through the model. Applied to Llama 3.1 8B, TARS successfully removed concepts like Sherlock Holmes and Saturn with as few as one edit, achieving 0.00 probability for target tokens while maintaining general model performance (median KL divergence of 0.0015 on Wikipedia text). The method works bidirectionally and across languages despite only being targeted in English, demonstrating its effectiveness for practical knowledge removal applications.

## Method Summary
TARS works by first creating a targeting vector for a specific concept through noise perturbation and filtering of an approximate concept vector. The method then identifies weight vectors in the up-projection and gate-projection layers of feedforward blocks that have high cosine similarity to this targeting vector. These high-similarity weight vectors are replaced with reversed and normalized versions of the targeting vector, effectively "repelling" the concept information through negative element-wise products. The process is iterative, gradually lowering the similarity threshold while monitoring both concept removal effectiveness and general model performance to determine the optimal number of edits.

## Key Results
- Successfully removed Sherlock Holmes and Saturn concepts with as few as one edit each
- Achieved 0.00 probability for target tokens while maintaining median KL divergence of 0.0015 on Wikipedia text
- Demonstrated bidirectional knowledge removal and cross-lingual effectiveness despite only being targeted in English

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feedforward weight vectors in LLMs directly operate on internal representation space, so aligning these weights with concept vectors determines concept propagation strength.
- Mechanism: The TARS method identifies weight vectors in feedforward networks with high cosine similarity to a refined concept vector and replaces them with reversed vectors to reduce concept propagation.
- Core assumption: Knowledge is stored in feedforward networks of LLMs, and residual connections preserve consistent internal representation space throughout the model.

### Mechanism 2
- Claim: Refining an approximate concept vector through noise perturbation and filtering creates a targeting vector that exclusively triggers the specific concept with high probability.
- Mechanism: The method adds Gaussian noise to an approximate concept vector, tests resulting vectors through the LM head, and averages those that achieve 95%+ probability for the target concept.

### Mechanism 3
- Claim: Reversing and normalizing targeting vectors in high-similarity weight positions effectively "repels" concept information through negative element-wise products.
- Mechanism: Weight vectors above a similarity threshold are replaced with -∥vtarget∥3, creating negative activation that prevents concept propagation.

## Foundational Learning

- Concept: Cosine similarity as measure of vector alignment
  - Why needed here: TARS uses cosine similarity to identify weight vectors most aligned with concept vectors
  - Quick check question: What does a cosine similarity of 1, 0, and -1 represent for two vectors?

- Concept: Feedforward neural network operations
  - Why needed here: TARS operates on feedforward weight matrices that perform element-wise products with internal representations
  - Quick check question: How does a feedforward layer transform its input using weight matrices?

- Concept: Internal representation space in transformers
  - Why needed here: TARS assumes consistent internal representation space across layers due to residual connections
  - Quick check question: What role do residual connections play in maintaining internal representation consistency?

## Architecture Onboarding

- Component map: Llama 3.1 8B architecture with attention blocks → post-attention projection → feedforward blocks (gated linear unit with up-projection and gate-projection weights) → LM head
- Critical path: Approximate concept vector → refine through noise perturbation → compute cosine similarities → edit high-similarity weights → test concept removal
- Design tradeoffs: Minimal edits vs. complete knowledge removal, computational efficiency vs. thorough concept isolation, English-only targeting vs. multilingual effectiveness
- Failure signatures: Residual concept activation despite edits, degradation in unrelated knowledge, incomplete concept removal in multilingual contexts
- First 3 experiments:
  1. Test single-concept removal with varying edit thresholds on simple concepts (dog, cat)
  2. Verify bi-directionality by testing concept description and classification removal
  3. Test multilingual effectiveness by removing English concepts and testing in French/German

## Open Questions the Paper Calls Out

1. What is the optimal amplitude for the reversed target vector in the TARS method to maximize concept removal effectiveness while minimizing impact on general model capabilities?

2. How does TARS perform on concepts with multiple common tokens (polysemy) across different languages, and can it effectively remove all meanings simultaneously?

3. Does the TARS method scale effectively to larger models and more complex concepts that require multi-token representations?

4. What is the relationship between the number of TARS edits and the threshold for cosine similarity, and how can this be optimized for different concepts and model sizes?

## Limitations

- Limited experimental scope to only 4-5 specific concepts in a single model architecture
- Threshold selection ambiguity without systematic criteria or sensitivity analysis
- Correlation vs. causation uncertainty regarding whether identified weight vectors actually store the knowledge

## Confidence

**High Confidence (Likelihood >80%)**:
- The TARS method can successfully reduce specific concept probabilities to near-zero levels with minimal edits
- The method preserves general model performance when removing simple concepts
- Bidirectional knowledge removal works for concepts with clear positive/negative descriptions

**Medium Confidence (Likelihood 50-80%)**:
- The mechanism of replacing aligned weight vectors with reversed vectors effectively reduces concept propagation
- The method works across multiple languages despite only being targeted in English
- More complex concepts require editing more weight vectors than simple concepts

**Low Confidence (Likelihood <50%)**:
- The specific weight vectors identified are the actual storage locations for the target knowledge
- The method generalizes to arbitrary concepts beyond the tested examples
- The 95% probability threshold for targeting vector refinement is optimal or necessary

## Next Checks

1. Apply TARS to 20+ diverse concepts spanning different domains and measure removal success rates, required number of edits, and impact on model performance for each.

2. Systematically ablate (zero out) the identified high-similarity weight vectors rather than replacing them with reversed vectors to determine if the editing mechanism specifically requires vector reversal.

3. After applying TARS edits, measure concept removal effectiveness immediately after editing, after 100 sequential prompts, and after fine-tuning on unrelated tasks to assess stability and permanence.