---
ver: rpa2
title: Online Planning in POMDPs with State-Requests
arxiv_id: '2407.18812'
source_url: https://arxiv.org/abs/2407.18812
tags:
- state
- aems-sr
- aems
- action
- beliefs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of online planning in Partially
  Observable Markov Decision Processes (POMDPs) where agents can request full state
  information at a cost. The authors propose AEMS-SR, a novel algorithm that adapts
  Anytime Error Minimization Search (AEMS) to handle state requests by representing
  the search space as a graph rather than a tree, thereby avoiding exponential growth
  in search space.
---

# Online Planning in POMDPs with State-Requests

## Quick Facts
- **arXiv ID:** 2407.18812
- **Source URL:** https://arxiv.org/abs/2407.18812
- **Reference count:** 13
- **Primary result:** AEMS-SR algorithm achieves up to two orders of magnitude more expansions and significant performance gains over AEMS and POMCP in POMDPs with state requests

## Executive Summary
This paper introduces AEMS-SR, a novel online planning algorithm for Partially Observable Markov Decision Processes with State Requests (POMDP-SR), where agents can request full state information at a cost. The key innovation is representing the search space as a graph rather than a tree, allowing corner beliefs (deterministic states) to have multiple parents and avoiding exponential growth from state requests. The algorithm is proven to be ε-optimal and demonstrates superior performance on the new RobotDelivery benchmark and Tag environment, particularly when online bounds are updated during planning.

## Method Summary
AEMS-SR extends Anytime Error Minimization Search (AEMS) to handle state requests by building a cyclic graph of beliefs instead of a tree. When expanding a belief, the algorithm adds children for both state requests (collapsing to corner beliefs) and environmental actions, with corner beliefs allowing multiple parents for reuse. The algorithm uses a heuristic combining discounted reach probability under the current policy with error gap to select which fringe belief to expand next. Bounds are computed offline but updated online at corner beliefs for tighter estimates. The method maintains ε-optimality guarantees while significantly improving expansion efficiency.

## Key Results
- AEMS-SR achieves up to two orders of magnitude more expansions than AEMS and POMCP
- In RobotDelivery R-7 environment, AEMS-SR obtains average return over 2 with at least 0.5s planning time
- Online bound improvements provide significant performance gains without additional memory overhead

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Representing the search space as a graph rather than a tree avoids exponential growth from state requests by reusing corner belief nodes.
- **Mechanism:** When a state request is made, the belief collapses to a corner belief. In AEMS-SR, these corner beliefs can have multiple parents, allowing the algorithm to reuse the same subtree for multiple parent beliefs that lead to the same corner state. This avoids duplicating work across different belief paths that converge to the same state.
- **Core assumption:** Corner beliefs (deterministic states) are sufficient reuse points; non-corner beliefs are expanded normally.
- **Evidence anchors:**
  - [abstract]: "By representing the search space as a graph instead of a tree, AEMS-SR avoids the exponential growth of the search space originating from state requests."
  - [section 4]: "we restrict the capacity for multiple parents to corner beliefs."
- **Break condition:** If the state space is continuous or very large, the assumption that corner beliefs can be stored and reused may break due to memory constraints.

### Mechanism 2
- **Claim:** AEMS-SR's heuristic for selecting the next belief to expand accounts for the probability of reaching that belief under the current policy, weighted by the error reduction potential.
- **Mechanism:** The heuristic ΨˆπG(pb0,b)ˆepbq combines the discounted probability of reaching fringe belief b from the root under the current policy (ΨˆπG) with the estimated error gap (ˆepbq). This prioritizes expanding beliefs that are both likely to be reached and have large error contributions, leading to faster convergence.
- **Core assumption:** The policy approximationˆπG selecting the action maximizing the upper bound is effective for weighting paths.
- **Evidence anchors:**
  - [section 4.1]: "we employ the following two approximations: ˆπGpb,a q " 1 ta " arg max a1UGpb,a1uq and ˆepbq " U pbq ´Lpbq ě epbq."
  - [section 4.1]: "This theorem provides a robust method for choosing the next belief to expand to rapidly minimize root error: prioritize expanding the belief with the greatest estimated contribution arg maxbPF pGq Ψπ˚pb0,b qepbq."
- **Break condition:** If the upper bound is very loose or the belief space is extremely large, the approximation may mislead the heuristic.

### Mechanism 3
- **Claim:** Improving bounds online using corner beliefs during planning significantly boosts performance without extra memory.
- **Mechanism:** At corner beliefs, the upper bound UG(ps,a) is tighter than the offline upper bound α(ps,a) because it reflects the actual value after exploring the graph. AEMS-SR updates the offline bounds with these tighter values during planning, which reduces the error gap faster in subsequent expansions.
- **Core assumption:** Corner beliefs are reached frequently enough during planning for bound updates to matter.
- **Evidence anchors:**
  - [section 5]: "For every corner beliefs in the graphG and actiona, UGps,a q provides a tighter bound thanαapsq computed offline. Therefore, by replacingαapsq with the value ofUGps,a q, we can update the upper bound without requiring additional memory."
  - [section 6]: "In contrast, AEMS-SR displays notable performance gains in RobotDelivery. Particularly in the R-7 environment, moving beyond the exit-immediately strategy it delivers packages and obtains an average return over 2 if given at least 0.5s and 1.84 otherwise."
- **Break condition:** If corner beliefs are rarely reached, bound updates provide negligible benefit.

## Foundational Learning

- **Concept:** POMDP-SR (Partially Observable Markov Decision Process with State Requests)
  - Why needed here: AEMS-SR is designed specifically for this setting where the agent can request full state information at a cost before each action. Understanding the POMDP-SR model is essential to grasp why the graph representation is needed and how the algorithm handles state requests.
  - Quick check question: In POMDP-SR, does the agent always have to request the state before acting?
    - Answer: No, the agent chooses whether to request the state or not before each action; requesting costs c.

- **Concept:** Belief updates and corner beliefs in POMDPs
  - Why needed here: The algorithm relies on belief updates to compute the next belief after an action and observation, and corner beliefs (deterministic states) are the key reuse points in the graph. Understanding these concepts is critical to follow the expansion and backtracking logic.
  - Quick check question: What is a corner belief?
    - Answer: A belief where one state has probability 1 and all others have probability 0.

- **Concept:** Heuristic search in POMDPs (e.g., AEMS)
  - Why needed here: AEMS-SR extends AEMS, so understanding how AEMS selects fringe nodes using upper/lower bounds and the error gap is foundational. The main novelty is adapting this to a graph structure with state requests.
  - Quick check question: In AEMS, how is the next belief to expand chosen?
    - Answer: By maximizing a heuristic that weights the error gap by the discounted probability of reaching that belief.

## Architecture Onboarding

- **Component map:** Root belief b0 -> Graph G (cyclic) -> Fringe beliefs F(G) -> Selected belief b -> Children (state request ι and environmental actions) -> Corner beliefs (multiple parents allowed)

- **Critical path:**
  1. Initialize G with root belief b0
  2. While time remains and not solved:
     a. Compute Ψ for all fringe beliefs using Algorithm 3
     b. Select fringe belief maximizing ΨˆπG(pb0,b)ˆepbq
     c. Expand selected belief, adding children and updating graph
     d. Update bounds for ancestors via dynamic programming
  3. Choose action (request or not) maximizing lower bound
  4. Execute action, observe, reset G with new belief

- **Design tradeoffs:**
  - Graph vs tree: Graph avoids exponential growth but requires handling cycles and computing Ψ
  - Corner belief reuse: Saves computation but may increase memory if many corner beliefs
  - Online bound updates: Improves performance but adds overhead per expansion

- **Failure signatures:**
  - Poor performance: Likely due to loose bounds, infrequent corner belief visits, or incorrect belief updates
  - High memory usage: Too many corner beliefs stored; consider limiting reuse or pruning
  - Slow expansion: Ψ computation expensive; optimize matrix operations or limit fringe nodes

- **First 3 experiments:**
  1. Run AEMS-SR on a simple POMDP-SR (e.g., 2x2 grid) with known optimal policy; verify it matches
  2. Compare AEMS-SR vs AEMS on RobotDelivery with small n (e.g., 3 corridors) to observe expansion counts and return
  3. Test bound improvement by running with and without online updates on R-7; check if return increases and expansions decrease

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of AEMS-SR scale with increasing state space size and complexity in RobotDelivery beyond 7 corridors?
- **Basis in paper:** [explicit] The paper evaluates AEMS-SR on RobotDelivery environments with 3, 5, and 7 corridors, showing superior performance over AEMS and POMCP. It mentions potential areas for further enhancement in the more complex R-7 scenario.
- **Why unresolved:** The paper does not provide results for environments with more than 7 corridors, leaving the scalability of AEMS-SR to larger and more complex state spaces untested.
- **What evidence would resolve it:** Experimental results evaluating AEMS-SR on RobotDelivery environments with more than 7 corridors, demonstrating its performance and scalability as the state space size increases.

### Open Question 2
- **Question:** Can the theoretical guarantees of ε-optimality for AEMS-SR be extended to other subclasses of POMDPs beyond POMDP-SRs?
- **Basis in paper:** [explicit] The paper proves that AEMS-SR is complete and ε-optimal for POMDP-SRs and mentions plans to investigate the potential application of AEMS-Loop to other subclasses of POMDPs in future work.
- **Why unresolved:** The theoretical analysis in the paper is specific to POMDP-SRs, and the extension of these guarantees to other POMDP subclasses is not explored or proven.
- **What evidence would resolve it:** A formal theoretical analysis extending the ε-optimality guarantees of AEMS-SR to other subclasses of POMDPs, supported by proofs and experimental validation.

### Open Question 3
- **Question:** How does the choice of policy ˆπG impact the empirical performance of AEMS-SR in practice, and can it be tuned specifically for POMDP-SR settings?
- **Basis in paper:** [explicit] The paper mentions that other approximations ˆπG are possible and that they selected the one presented in Equation 5 because of its empirical performance in AEMS and its simplicity. It also aims to develop policies ˆπG tuned to the specificity of POMDP-SR in future work.
- **Why unresolved:** The paper does not explore the impact of different policy choices on AEMS-SR's performance or provide insights into how policies can be specifically tailored for POMDP-SR settings.
- **What evidence would resolve it:** Experimental results comparing the performance of AEMS-SR using different policies ˆπG, including policies specifically designed for POMDP-SR settings, demonstrating the impact of policy choice on algorithm efficiency and solution quality.

## Limitations
- Scalability to very large or continuous state spaces may be limited due to memory constraints for storing corner beliefs
- Computational overhead of online bound updates during planning is not fully characterized
- Empirical evaluation limited to two environments, raising questions about generalizability

## Confidence

- **High confidence**: The core mechanism of representing the search space as a graph to avoid exponential growth is well-supported by the theoretical analysis and empirical results. The claim that AEMS-SR can achieve up to two orders of magnitude more expansions is directly evidenced by the reported results.
- **Medium confidence**: The heuristic for selecting beliefs to expand (ΨˆπG) is theoretically justified, but its practical effectiveness depends on the quality of the policy approximationˆπG, which is only briefly described. The claim about significant performance gains from online bound updates is supported by results but could be more thoroughly analyzed.
- **Medium confidence**: The comparison with AEMS and POMCP shows AEMS-SR outperforming both, but the analysis could be more comprehensive in exploring different cost parameters and time limits to fully characterize the trade-offs.

## Next Checks

1. **Scalability test**: Evaluate AEMS-SR on a POMDP-SR with a larger state space (e.g., 10x10 grid or continuous approximation) to verify that the graph representation and corner belief reuse remain effective without excessive memory usage.

2. **Heuristic sensitivity analysis**: Systematically vary the parameters of the policy approximationˆπG and measure the impact on belief selection quality and overall performance to quantify how sensitive the algorithm is to this approximation.

3. **Bound update overhead measurement**: Profile the computational cost of online bound updates during planning and measure the trade-off between the overhead and the performance gains across different environments and time limits.