---
ver: rpa2
title: 'Masked Clinical Modelling: A Framework for Synthetic and Augmented Survival
  Data Generation'
arxiv_id: '2410.16811'
source_url: https://arxiv.org/abs/2410.16811
tags: []
core_contribution: This paper introduces Masked Clinical Modelling (MCM), a novel
  framework for generating synthetic clinical datasets that preserves both data realism
  and utility for survival analysis. MCM adapts masked language modeling to clinical
  data by masking random patient features and reconstructing them using an attention-based
  neural network, enabling both data synthesis and conditional augmentation.
---

# Masked Clinical Modelling: A Framework for Synthetic and Augmented Survival Data Generation

## Quick Facts
- arXiv ID: 2410.16811
- Source URL: https://arxiv.org/abs/2410.16811
- Authors: Nicholas I-Hsien Kuo; Blanca Gallego; Louisa Jorm
- Reference count: 15
- One-line primary result: MCM-generated data closely matched real data distributions and preserved hazard ratios for Cox Proportional Hazards models, with C-index improving from 0.7609 to 0.7662 when augmenting training data.

## Executive Summary
This paper introduces Masked Clinical Modelling (MCM), a novel framework for generating synthetic clinical datasets that preserves both data realism and utility for survival analysis. MCM adapts masked language modeling to clinical data by masking random patient features and reconstructing them using an attention-based neural network, enabling both data synthesis and conditional augmentation. Evaluated on the WHAS500 dataset, MCM-generated data closely matched real data distributions and preserved hazard ratios for Cox Proportional Hazards models. When augmenting training data, MCM improved model discrimination (C-index increased from 0.7609 to 0.7662) and calibration, particularly for high-risk patient subgroups. Compared to SMOTE, VAE, and MICE methods, MCM demonstrated superior performance in maintaining clinical utility while generating realistic synthetic data, addressing privacy concerns in healthcare research.

## Method Summary
The MCM framework uses an attention-based neural network architecture with a two-layer Multi-Layer Perceptron (MLP) with 64 hidden dimensions. The model is trained to minimize mean squared error between predicted and actual values. Clinical features are first Box-Cox transformed and rescaled to [0,1]. A masking layer randomly sets selected features to zero, and an Attention Filter (AF) applies a linear layer with softmax to generate attention values that weight the observed features. These weighted features are then processed by the MLP to reconstruct the masked values. The framework can generate synthetic data through high-masking ratios (75%) or augment existing data through lower ratios (50%).

## Key Results
- MCM-generated data closely matched real data distributions and preserved hazard ratios for Cox Proportional Hazards models
- When augmenting training data, MCM improved model discrimination (C-index increased from 0.7609 to 0.7662) and calibration
- MCM demonstrated superior performance compared to SMOTE, VAE, and MICE methods in maintaining clinical utility while generating realistic synthetic data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masked Clinical Modelling (MCM) preserves clinical utility by maintaining hazard ratios (HRs) through reconstruction-based learning.
- Mechanism: MCM uses masked language modeling adapted to clinical data: random features are masked, and the model learns to reconstruct them using context from the remaining features via attention-based neural networks. This forces the model to learn and preserve the statistical dependencies between variables that underpin hazard ratios.
- Core assumption: The feature dependencies that determine HRs in CoxPH models can be faithfully captured and reconstructed by a neural network trained with masked reconstruction loss.
- Evidence anchors:
  - [abstract] "MCM-generated data closely matched real data distributions and preserved hazard ratios for Cox Proportional Hazards models."
  - [section] "Subfigure (b) demonstrates strong HR alignment, indicating that the synthetic data conserves meaningful correlations for downstream analysis."
- Break condition: If the masked reconstruction task fails to capture non-linear or rare feature interactions critical to HR estimation, utility will degrade despite visual realism.

### Mechanism 2
- Claim: MCM improves both discrimination and calibration of survival models when synthetic data augments training sets.
- Mechanism: By generating synthetic patients conditionally (e.g., specific age ranges or comorbidities), MCM enriches the training distribution, especially for underrepresented subgroups. This augmentation reduces variance and improves model generalization, reflected in higher C-index and better calibration slopes.
- Core assumption: Conditional data augmentation can effectively balance the training distribution without introducing bias, and the augmented synthetic samples are sufficiently realistic for model training.
- Evidence anchors:
  - [abstract] "When augmenting training data, MCM improved model discrimination (C-index increased from 0.7609 to 0.7662) and calibration, particularly for high-risk patient subgroups."
  - [section] "MCM significantly reduced misalignments to 0.36 and 0.33, respectively. At the 75th percentile, where CoxPH performed well, MCM further improved calibration."
- Break condition: If synthetic samples introduce artifacts or mismatch real-world covariate distributions, calibration can degrade even if discrimination improves.

### Mechanism 3
- Claim: MCM reduces privacy risk by enriching datasets with synthetic individuals having uncommon combinations of characteristics, mitigating identity disclosure.
- Mechanism: Instead of relying solely on subsampling or noise injection, MCM generates entirely new synthetic patients conditioned on rare feature combinations. This increases the anonymity set without distorting the underlying statistical structure.
- Core assumption: Synthetic patients generated via MCM are statistically indistinguishable from real patients for model training purposes, while being independent draws not linked to real identities.
- Evidence anchors:
  - [abstract] "Its conditional generation capability presents potential to minimise risks of identity disclosure and attribution... by enriching datasets with more individuals having uncommon combinations of characteristics."
  - [section] No direct quantitative evidence provided; claim is prospective.
- Break condition: If synthetic samples are too close to real individuals in feature space, re-identification risk persists despite augmentation.

## Foundational Learning

- Concept: Masked Language Modeling (MLM)
  - Why needed here: MLM provides the conceptual framework for MCM's reconstruction task, enabling the model to learn bidirectional context from partial data.
  - Quick check question: In BERT-style MLM, what proportion of input tokens are typically masked during training?

- Concept: Cox Proportional Hazards (CoxPH) models and hazard ratios
  - Why needed here: MCM is evaluated on its ability to preserve HRs, the key clinical metric from CoxPH models, ensuring synthetic data utility.
  - Quick check question: What does a hazard ratio greater than 1 signify in survival analysis?

- Concept: Attention mechanisms and multi-layer perceptrons
  - Why needed here: MCM's architecture uses an attention filter to weight observed features and an MLP to reconstruct masked ones; understanding both is essential to modify or extend the model.
  - Quick check question: How does the softmax operation in the attention filter enforce the sum-to-one constraint?

## Architecture Onboarding

- Component map:
  Input (Box-Cox transformed, rescaled to [0,1]) -> Masking layer (randomly sets features to zero) -> Attention Filter (AF: linear layer + softmax) -> Weighted features (element-wise product) -> Multi-Layer Perceptron (MLP: two-layer with ReLU and sigmoid) -> Output (reconstructed features, post-processed to original scale)

- Critical path:
  1. Preprocess -> Mask -> AF -> Weighted features -> MLP -> Reconstruct -> Postprocess
  2. Training loop: forward pass -> MSE loss -> backprop

- Design tradeoffs:
  - Masking ratio (e.g., 50% for augmentation, 75% for synthesis) vs. reconstruction fidelity
  - Attention filter complexity vs. interpretability of feature importance
  - MLP depth/size vs. overfitting on small clinical datasets

- Failure signatures:
  - High MSE loss but poor HR preservation -> model learns superficial patterns
  - Low MSE loss but degraded discrimination -> overfitting to training data
  - Synthetic feature distributions drift from real -> post-processing or masking strategy needs adjustment

- First 3 experiments:
  1. Train MCM on WHAS500 with 50% masking; evaluate MSE and HR preservation vs. real data.
  2. Generate synthetic patients conditioned on rare comorbidity combinations; test for identity disclosure risk via nearest-neighbor analysis.
  3. Augment training data with MCM-generated samples; compare CoxPH C-index and calibration slopes to baseline.

## Open Questions the Paper Calls Out
No open questions were explicitly called out in the paper.

## Limitations
- The paper lacks detailed hyperparameter specifications and implementation details, making exact reproduction challenging.
- There is no quantitative evaluation of re-identification risk or formal privacy guarantees to validate privacy preservation claims.
- Validation is conducted on a single dataset (WHAS500), limiting generalizability across different clinical contexts and data distributions.

## Confidence

- **High Confidence**: The MCM framework's ability to preserve hazard ratios and improve C-index through data augmentation. These claims are directly supported by quantitative results showing HR preservation and C-index improvement from 0.7609 to 0.7662.
- **Medium Confidence**: The claim that MCM outperforms existing methods (SMOTE, VAE, MICE) in maintaining clinical utility. While comparative results are presented, the evaluation framework and baseline implementations are not fully detailed.
- **Low Confidence**: The prospective claim about privacy preservation through synthetic data enrichment. This claim lacks empirical validation and quantitative privacy metrics, making it primarily theoretical at this stage.

## Next Checks
1. **Privacy Risk Assessment**: Conduct formal re-identification risk analysis on MCM-generated synthetic data using metrics such as k-anonymity, l-diversity, or membership inference attacks to empirically validate the privacy preservation claims.

2. **Cross-Dataset Generalization**: Evaluate MCM on multiple clinical datasets with varying characteristics (e.g., different patient populations, feature sets, and sample sizes) to assess the framework's robustness and generalizability beyond WHAS500.

3. **Baseline Implementation Transparency**: Provide complete implementation details for SMOTE, VAE, and MICE baselines, including hyperparameter configurations and evaluation protocols, to enable fair comparison and independent verification of the claimed performance advantages.