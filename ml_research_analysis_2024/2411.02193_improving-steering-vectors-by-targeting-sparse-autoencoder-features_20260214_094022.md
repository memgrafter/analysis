---
ver: rpa2
title: Improving Steering Vectors by Targeting Sparse Autoencoder Features
arxiv_id: '2411.02193'
source_url: https://arxiv.org/abs/2411.02193
tags:
- steering
- feature
- effects
- features
- vectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to quantify and improve steering
  vector effectiveness in language models using sparse autoencoders (SAEs). The authors
  develop SAE-Targeted Steering (SAE-TS), which constructs steering vectors to target
  specific SAE features while minimizing side effects.
---

# Improving Steering Vectors by Targeting Sparse Autoencoder Features

## Quick Facts
- arXiv ID: 2411.02193
- Source URL: https://arxiv.org/abs/2411.02193
- Reference count: 40
- This paper introduces a method to quantify and improve steering vector effectiveness in language models using sparse autoencoders (SAEs)

## Executive Summary
This paper addresses the challenge of controlling language model behavior through steering vectors while maintaining text quality and coherence. The authors introduce SAE-Targeted Steering (SAE-TS), a method that uses sparse autoencoders to measure the causal effects of steering interventions and construct vectors that target specific model behaviors while minimizing side effects. By learning a linear mapping between steering vectors and their measured effects on SAE features, SAE-TS achieves better alignment with intended behaviors while maintaining semantic coherence compared to existing methods like Contrastive Activation Addition (CAA) and direct SAE feature steering.

## Method Summary
SAE-TS constructs steering vectors by first measuring the effects of various steering interventions on SAE feature activations. The method generates a dataset of steering vectors and their corresponding feature effects by comparing SAE activations between steered and unsteered model outputs. A linear effect approximator is then trained to predict feature changes from steering vectors. For targeted steering, the method constructs vectors that maximize activation of target features while minimizing unintended changes using the learned mapping. The approach is evaluated on Gemma-2-2B across 9 steering tasks, measuring both behavioral alignment and output coherence.

## Key Results
- SAE-TS outperforms existing methods on 7 of 9 steering tasks when evaluated on Gemma-2-2B
- Achieves better balance between steering effects and output coherence compared to CAA and direct SAE feature steering
- Successfully demonstrates the utility of SAEs for measuring causal effects of steering interventions

## Why This Works (Mechanism)

### Mechanism 1
SAEs can measure the causal effects of steering interventions on model behavior. By comparing SAE feature activations between steered and unsteered model outputs, we can quantify how steering vectors change the model's internal representations and predict the resulting behavioral changes. The core assumption is that the difference in SAE feature activations accurately reflects the causal impact of the steering intervention. This could break if SAE features don't capture relevant behavioral dimensions or if steering effects are mediated through pathways not reflected in the SAE activations.

### Mechanism 2
A linear relationship exists between steering vectors and their effects on SAE features. The effect approximator learns a mapping from steering vectors to their measured effects, allowing prediction of feature changes for new steering vectors. The core assumption is that this relationship is approximately linear within the tested range of steering vectors. This could break if the relationship becomes highly non-linear for certain steering directions or magnitudes.

### Mechanism 3
SAE-targeted steering vectors can achieve specific behavioral goals while maintaining coherence better than existing methods. By using the linear effect approximator to find steering vectors that maximize target feature activation while minimizing other changes, we can achieve precise control over model behavior. The core assumption is that the linear effect approximator accurately captures the relationship between steering vectors and their behavioral effects. This could break if the effect approximator fails to generalize beyond training data or if SAE features don't correspond to meaningful behavioral dimensions.

## Foundational Learning

- **Concept**: Sparse Autoencoders (SAEs)
  - Why needed here: SAEs are the core tool for decomposing model activations into interpretable features and measuring steering effects
  - Quick check question: How do SAEs differ from traditional autoencoders, and why are they particularly useful for interpretability in LLMs?

- **Concept**: Steering vectors in transformer models
  - Why needed here: Understanding how steering vectors modify model behavior is essential for developing and evaluating SAE-TS
  - Quick check question: What is the mathematical operation for adding a steering vector to a transformer's hidden state, and at what point in the forward pass does this typically occur?

- **Concept**: Causal inference in neural networks
  - Why needed here: The method relies on measuring causal effects of interventions, which requires understanding the difference between correlation and causation in model behavior
  - Quick check question: Why is comparing steered vs. unsteered model outputs a valid approach for measuring causal effects of steering interventions?

## Architecture Onboarding

- **Component map**: SAE training -> Steering vector generation -> Effect measurement -> Linear effect approximator training -> Targeted steering vector construction -> Behavioral evaluation
- **Critical path**: 1) Generate dataset of steering vectors and their measured effects, 2) Train linear effect approximator on this dataset, 3) Use approximator to find targeted steering vectors for specific features, 4) Evaluate steering vectors on behavioral tasks
- **Design tradeoffs**: Linear vs. non-linear effect approximator (simplicity vs. accuracy), dataset size for training effect approximator (coverage vs. computational cost), choice of SAE architecture (feature quality vs. reconstruction fidelity)
- **Failure signatures**: Poor generalization of effect approximator to new steering vectors, steering vectors that achieve target behavior but destroy coherence, effect approximator that predicts effects poorly for certain feature directions
- **First 3 experiments**: 1) Verify that steering with a single SAE feature's decoder vector produces predictable effects on that feature, 2) Test whether the linear effect approximator can accurately predict effects of new steering vectors not in the training set, 3) Compare SAE-TS performance against baseline methods on a simple steering task with clear success criteria

## Open Questions the Paper Calls Out

### Open Question 1
Why does SAE-TS sometimes achieve higher coherence scores than the unsteered baseline at optimal steering scales? The authors observe this phenomenon noting that steering with the bias term increases proper noun frequency and appears to improve coherence scores, but lack a mechanistic explanation for why steering would improve coherence rather than degrade it.

### Open Question 2
How do feature effects measured at layer 12 SAE relate to downstream model behavior and feature interactions in later layers? The paper focuses on layer 12 SAE effects without examining whether these local measurements predict global model behavior changes, which could be crucial for understanding steering effectiveness.

### Open Question 3
Why does the pseudoinverse approach to targeted steering perform significantly worse than the SAE-TS method that normalizes the target feature column and subtracts normalized bias effects? Table 3 shows SAE-TS outperforms pseudoinverse across all tasks, but the paper only provides intuitive explanations about implicit bias handling rather than rigorous justification.

## Limitations
- The linear effect approximator assumption may break down for steering vectors that significantly perturb the model's behavior
- Evaluation relies on GPT-4o-mini scoring, introducing potential subjectivity and model-dependent biases
- Method's performance on larger, more capable models remains untested

## Confidence

**High Confidence**: The core methodology of using SAEs to measure steering effects and construct targeted steering vectors is technically sound and well-supported by the experimental results.

**Medium Confidence**: The claim that SAE-TS achieves better balance between steering effects and output coherence than existing methods is supported by the presented results, but the evaluation methodology introduces some uncertainty.

**Low Confidence**: The paper's assertions about the method's scalability to larger models and its applicability to safety-critical steering tasks are largely speculative.

## Next Checks

1. **Cross-model validation**: Test SAE-TS on at least two additional model architectures (different sizes and training approaches) to verify the method's generalizability beyond Gemma-2-2B and identify any model-specific limitations.

2. **Effect approximator robustness test**: Systematically evaluate the linear effect approximator's performance on steering vectors that significantly exceed the magnitude of those used in training, to determine the breaking point where the linear assumption fails and identify potential non-linear alternatives.

3. **Long-term steering stability analysis**: Generate multiple generations of text using SAE-TS vectors and measure how steering effects accumulate or decay over time, particularly for behaviors that may compound versus those that should remain stable.