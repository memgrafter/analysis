---
ver: rpa2
title: 'The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy
  of Risks From Artificial Intelligence'
arxiv_id: '2408.12622'
source_url: https://arxiv.org/abs/2408.12622
tags:
- risks
- risk
- taxonomy
- systems
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The AI Risk Repository is a comprehensive, publicly accessible
  database of 1,612 AI-related risks extracted from 65 taxonomies. Using systematic
  literature review and expert consultation, the authors developed two taxonomies:
  a high-level Causal Taxonomy (classifying risks by Entity, Intent, and Timing) and
  a mid-level Domain Taxonomy (organizing risks into 7 domains and 24 subdomains).'
---

# The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence

## Quick Facts
- arXiv ID: 2408.12622
- Source URL: https://arxiv.org/abs/2408.12622
- Reference count: 40
- Primary result: First rigorous consolidation of AI risk frameworks into a categorized, publicly accessible database with 1,612 risks and two taxonomies

## Executive Summary
The AI Risk Repository addresses the fragmented landscape of AI risk assessment by systematically reviewing 65 documents containing 1,612 AI-related risks. Using systematic literature review and expert consultation, the authors developed two comprehensive taxonomies - a high-level Causal Taxonomy and a mid-level Domain Taxonomy - to classify these risks. The repository is designed as a living, publicly accessible database that can be filtered, updated, and accessed via website and online spreadsheets. This work represents the first rigorous attempt to consolidate diverse AI risk frameworks into a categorized, extensible database that provides a common frame of reference for researchers, policymakers, and industry stakeholders.

## Method Summary
The authors conducted a systematic literature search using Scopus and preprint databases with a comprehensive search string, followed by title/abstract screening using ASReview with active learning and the SAFE procedure. They then performed full-text screening and extracted individual risks from included documents into a living AI Risk Database. Using best-fit framework synthesis, they developed two taxonomies by selecting initial frameworks (Yampolskiy 2016 for Causal, Weidinger 2022 for Domain), coding risks, identifying themes that didn't fit, updating categories until stable, and combining taxonomies to analyze intersections. Ongoing expert consultation was used to identify additional relevant documents and risks beyond the initial systematic search.

## Key Results
- Created a comprehensive database containing 1,612 AI-related risks extracted from 65 taxonomies
- Developed two novel taxonomies: a high-level Causal Taxonomy (Entity, Intent, Timing) and mid-level Domain Taxonomy (7 domains, 24 subdomains)
- Established a living, publicly accessible repository that can be filtered and updated via website and online spreadsheets
- First rigorous consolidation of AI risk frameworks into a categorized, extensible database

## Why This Works (Mechanism)
The repository works by providing a systematic, categorized framework for understanding AI risks that overcomes the fragmentation in existing literature. By extracting individual risks from diverse sources and classifying them using two complementary taxonomies, it creates a common language for discussing AI risks across different stakeholders. The living database approach allows continuous updates as new risks emerge, while the filtering capabilities enable users to analyze risks based on specific causal factors or domains of concern.

## Foundational Learning
**Systematic Literature Review**: Why needed - to ensure comprehensive coverage of existing AI risk frameworks; Quick check - verify search string captures relevant terminology across disciplines
**Best-fit Framework Synthesis**: Why needed - to develop taxonomies that accommodate diverse risk perspectives; Quick check - assess whether all extracted risks can be classified within the taxonomies
**Active Learning Screening**: Why needed - to efficiently process large numbers of documents; Quick check - evaluate screening agreement rates between human reviewers and ASReview predictions
**Expert Consultation**: Why needed - to capture emerging risks not yet published in academic literature; Quick check - track number of additional risks identified through expert input
**Living Database Design**: Why needed - to maintain relevance as AI technology and associated risks evolve; Quick check - establish update frequency and contribution mechanisms
**Taxonomy Intersection Analysis**: Why needed - to understand how different risk classifications relate to each other; Quick check - validate cross-taxonomy mappings with domain experts

## Architecture Onboarding
**Component Map**: Search Database -> ASReview Screening -> Risk Extraction -> Taxonomy Development -> Living Repository -> Website Interface
**Critical Path**: Systematic search → risk extraction → taxonomy development → database population → public access
**Design Tradeoffs**: Comprehensive coverage vs. manageability (choosing 65 documents from potentially thousands), detail level vs. usability (balancing granularity of taxonomies), academic rigor vs. practical accessibility (making complex frameworks usable for non-researchers)
**Failure Signatures**: Incomplete risk coverage (gaps in search methodology), inconsistent risk classification (poor taxonomy definitions), outdated risk information (infrequent updates), technical barriers to access (poor website design)
**3 First Experiments**: 1) Filter risks by "Future" timing and "Technical" domain to identify emerging technical risks, 2) Cross-reference "Malicious" intent risks with "Human-Computer Interaction" domain to analyze security vulnerabilities, 3) Analyze intersection of "Present" timing with "Economic" domain to assess current financial impacts

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does the AI Risk Repository evolve over time as new AI risks are identified and classified?
- Basis in paper: [explicit] The paper mentions that the repository is a "living" database that can be updated over time and that ongoing expert consultation is used to identify additional relevant documents and risks.
- Why unresolved: The paper does not provide a detailed description of how the repository is maintained and updated, or how often it is expected to be updated.
- What evidence would resolve it: A detailed description of the update process, including the frequency of updates, the criteria for adding new risks, and the mechanisms for incorporating expert feedback.

### Open Question 2
- Question: How can the AI Risk Repository be used to prioritize risks and develop effective mitigation strategies?
- Basis in paper: [inferred] The paper mentions that the repository can be used to identify underrepresented areas and to filter risks based on causal factors and domains, but it does not provide specific guidance on how to prioritize risks or develop mitigation strategies.
- Why unresolved: The paper does not provide a framework for risk prioritization or mitigation strategy development, which would require additional research and analysis.
- What evidence would resolve it: A framework for risk prioritization and mitigation strategy development, including criteria for assessing the severity and likelihood of risks, and a process for selecting and implementing mitigation measures.

### Open Question 3
- Question: How can the AI Risk Repository be used to assess the effectiveness of AI risk management policies and regulations?
- Basis in paper: [inferred] The paper mentions that the repository can be used by policymakers and auditors to develop regulations and standards, but it does not provide specific guidance on how to assess the effectiveness of these policies and regulations.
- Why unresolved: The paper does not provide a framework for evaluating the effectiveness of AI risk management policies and regulations, which would require additional research and analysis.
- What evidence would resolve it: A framework for evaluating the effectiveness of AI risk management policies and regulations, including metrics for assessing the impact of these policies on risk reduction and compliance, and a process for monitoring and evaluating policy implementation.

## Limitations
- Potential coverage gaps due to search string limitations and reliance on indexed publications
- Subjective decisions in taxonomy development may lead to inconsistent risk classification
- Dependence on expert network composition introduces potential selection bias
- Unknown update frequency and mechanisms for maintaining repository relevance over time

## Confidence
- High confidence in the methodological approach and systematic review process
- Medium confidence in the comprehensiveness of risk coverage
- Medium confidence in the reliability of taxonomy classifications
- Medium confidence in the practical utility for risk assessment and mitigation

## Next Checks
1. Conduct inter-rater reliability testing on a stratified random sample of 100 risks from the database, having multiple researchers independently code them against both taxonomies to establish consistency metrics and identify ambiguous classifications.
2. Perform an update search using the same methodology in 3 months to assess the rate of new risk frameworks emerging and evaluate the living database's ability to capture evolving AI risk landscapes.
3. Execute a focused search on the 43 excluded documents to analyze patterns of missed content, determining whether systematic search limitations or content mismatches drove exclusions, and adjust future search strategies accordingly.