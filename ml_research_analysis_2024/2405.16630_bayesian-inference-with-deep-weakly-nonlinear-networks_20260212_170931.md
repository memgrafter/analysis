---
ver: rpa2
title: Bayesian Inference with Deep Weakly Nonlinear Networks
arxiv_id: '2405.16630'
source_url: https://arxiv.org/abs/2405.16630
tags:
- bxbx
- network
- bayesian
- evidence
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies Bayesian inference with deep fully connected
  neural networks with a cubic shaped nonlinearity in the limit where network width,
  depth, training set size, and input dimension are all large. The authors develop
  a new combinatorial model for computing prior moments over network outputs, which
  allows them to compute the partition function and characterize the posterior to
  arbitrary order in 1/N.
---

# Bayesian Inference with Deep Weakly Nonlinear Networks

## Quick Facts
- arXiv ID: 2405.16630
- Source URL: https://arxiv.org/abs/2405.16630
- Reference count: 35
- Key outcome: This paper studies Bayesian inference with deep fully connected neural networks with a cubic shaped nonlinearity in the limit where network width, depth, training set size, and input dimension are all large.

## Executive Summary
This paper develops a theoretical framework for understanding Bayesian inference in deep neural networks with shaped cubic nonlinearities in the proportional large-width, large-depth, large-data limit. The authors introduce a novel combinatorial model for computing prior moments that allows them to characterize the posterior distribution to arbitrary order in 1/N. Their analysis reveals when Bayesian inference reduces to a kernel method versus when the network learns features, and how depth affects both evidence and generalization error.

## Method Summary
The authors analyze Bayesian inference with deep fully connected networks with shaped cubic nonlinearities ϕ(t) = t + ψt³/3L in the proportional limit where width N, depth L, training set size P, and input dimension N₀ all grow large with fixed ratios. They develop a combinatorial model using random graph processes to compute prior moments over network outputs, then use perturbative expansion in 1/N to derive the partition function and characterize the posterior. The analysis assumes Gaussian priors over weights and mean-squared error likelihood.

## Key Results
- When N ≫ L, P, Bayesian inference coincides with a kernel method where ψ determines the curvature of an implicit data manifold
- LP/N acts as an effective depth controlling the extent of feature learning beyond the kernel regime
- For "nice" data generating processes, at zero temperature the posterior is equivalent to a data-dependent kernel method
- In deep linear networks with noisy data, depth improves both evidence and generalization error, demonstrating benign overfitting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: When width N is much larger than depth L and training set size P, Bayesian inference with shaped MLPs reduces to a kernel method.
- Mechanism: In the large width limit, the network output field becomes a Gaussian process. The cubic shaping term scales as 1/L, so at each layer the nonlinearity is nearly linear, but over L layers the cumulative effect is order 1. When N ≫ L, P, the prior over network outputs is dominated by the leading-order Gaussian term, and the cubic correction is suppressed by 1/N.
- Core assumption: N, L, P → ∞ with N ≫ L, P; shaped activation ϕ(t) = t + ψt³/3L.
- Evidence anchors:
  - [abstract] states "When the width N is much larger than the depth L and training set size P, neural network Bayesian inference coincides with Bayesian inference using a kernel."
  - [section 2.2.1] provides the explicit kernel formula K_ψ(x_µ, x_ν) = ⟨(x_µ)_ψ, (x_ν)_ψ⟩ and explains it as an embedding into a sphere/hyperbola/plane.
  - [corpus] includes "Depth-induced NTK: Bridging Over-parameterized Neural Networks and Deep Neural Kernels" and "Information-theoretic reduction of deep neural networks to linear models in the overparametrized proportional regime," both directly relevant to kernel regimes.
- Break condition: If N ≲ L or N ≲ P, the 1/N suppression of the cubic term fails and the posterior deviates from the kernel form.

### Mechanism 2
- Claim: The nonlinearity strength ψ determines the curvature of an implicit data manifold under the feature map.
- Mechanism: The shaped activation can be written as ϕ(t) = t + ψt³/3L. In the infinite depth limit, this produces a feature map (x)_ψ that embeds inputs into a manifold whose curvature is controlled by ψ. For ψ > 0 the manifold is hyperbolic, for ψ < 0 it is spherical, and for ψ = 0 it is flat. The curvature determines the kernel's geometry.
- Core assumption: L → ∞ with N, P large; shaped activation with ψ ≠ 0.
- Evidence anchors:
  - [abstract] notes "The value of ψ determines the curvature of a sphere, hyperbola, or plane into which the training data is implicitly embedded under the feature map."
  - [section 2.2.1] gives the explicit geometric construction: radial projection onto HN₀ for ψ > 0, orthogonal projection onto S⁺_N₀ for ψ < 0, and the flat Euclidean case for ψ = 0.
  - [corpus] includes "Deep Learning without shortcuts: Shaping the kernel with tailored rectifiers" which discusses shaped nonlinearities and kernel geometry.
- Break condition: If ψ = 0 or if the manifold embedding is degenerate (e.g., inputs lie in a lower-dimensional subspace), the curvature effect vanishes.

### Mechanism 3
- Claim: LP/N acts as an effective depth that controls the extent of feature learning beyond the kernel regime.
- Mechanism: The first-order correction to the partition function scales like LP/N. This term arises from the cumulative effect of the cubic nonlinearity over L layers with P training points. When LP/N is small, the posterior stays close to the kernel method; as LP/N grows, the correction becomes significant and the network learns features beyond the kernel.
- Core assumption: N, L, P large; perturbative expansion in 1/N valid.
- Evidence anchors:
  - [abstract] states "LP/N serves as an effective depth that controls the extent of feature learning."
  - [section 2.2.2] explains "Whenever the 1/N correction increases the Bayesian model evidence, we have that the strength of this correction scales like LP/N."
  - [corpus] includes "VIKING: Deep variational inference with stochastic projections" which discusses depth and effective depth in Bayesian settings.
- Break condition: If LP/N is too large, higher-order terms in 1/N may become important and the first-order perturbative description breaks down.

## Foundational Learning

- Concept: Gaussian process priors at infinite width.
  - Why needed here: The paper builds on the fact that wide neural networks with Gaussian weights have asymptotically Gaussian output distributions, which is the foundation for connecting Bayesian inference to kernel methods.
  - Quick check question: What is the limiting distribution of a fully connected network's output when width → ∞ and weights are i.i.d. Gaussian?

- Concept: Stochastic differential equations for layer-wise overlaps.
  - Why needed here: The paper uses SDEs to characterize how the covariance of activations evolves with depth in shaped networks, which is essential for deriving the kernel limit.
  - Quick check question: How does the matrix of pairwise activations V^(ℓ) evolve as a function of the layer index in a shaped network?

- Concept: Bayesian model evidence and its maximization.
  - Why needed here: The paper uses the partition function (model evidence) to compare different network architectures and to study when depth improves inference.
  - Quick check question: In Bayesian model selection, what quantity is maximized to choose between models?

## Architecture Onboarding

- Component map:
  - Input → Hidden layers (width N, depth L) → Output
  - Shaped activation: ϕ(t) = t + ψt³/3L
  - Weights: i.i.d. N(0, 1 + η/L)
  - Data: P examples in RN₀, with P < N₀
  - Inference: Bayesian with Gaussian prior and MSE likelihood
  - Analysis: Perturbative expansion in 1/N

- Critical path:
  1. Compute prior moments over final-layer activations
  2. Build combinatorial model for those moments (random graph process)
  3. Evaluate self-loop process expectations analytically
  4. Derive partition function perturbatively
  5. Extract evidence and posterior to leading orders

- Design tradeoffs:
  - Shaped vs. general nonlinearities: shaping ensures well-behaved priors at large depth but limits expressiveness
  - Width vs. depth: wide networks → kernel regime; deep networks → feature learning, but requires careful scaling
  - Exact vs. perturbative: exact analysis possible only for linear networks; shaped networks require truncation

- Failure signatures:
  - If N ≲ L or N ≲ P, the kernel approximation fails and the 1/N expansion breaks down
  - If ψ is too large, the cubic term dominates and the perturbative approach is invalid
  - If P ≥ N₀, the minimal-norm interpolant is not unique and the analysis framework collapses

- First 3 experiments:
  1. Verify kernel equivalence: Train a shaped MLP with N ≫ L, P and compare its predictive posterior to the kernel method K_ψ; check that they match within statistical error
  2. Test effective depth: Vary LP/N while keeping N, L, P large; measure how the posterior mean and variance deviate from the kernel prediction as LP/N increases
  3. Measure curvature effect: Fix L, N, P and vary ψ; confirm that the predictive performance changes according to the geometry (sphere vs. hyperbola vs. plane) predicted by the theory

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the perturbative expansion behave beyond first order in 1/N for deep nonlinear networks with shaped activations?
- Basis in paper: [explicit] "In principle, one can use our formalism to compute the partition function to any order in 1/N. In the present article, we work it out explicitly to zeroth and first order in 1/N"
- Why unresolved: The authors only compute the partition function to first order in 1/N, noting that higher order corrections could be computed but are not pursued in this work.
- What evidence would resolve it: Explicit computation of the partition function to second or third order in 1/N, and analysis of how the higher order terms modify the kernel regime conditions and the LP/N effective depth relationship.

### Open Question 2
- Question: Can the self-averaging assumption be relaxed or proven for specific data-generating processes beyond the power law model?
- Basis in paper: [explicit] "While assumptions (ii) and (iii) are rather mild, assumption (i) is a significant restriction, which we do not know how to remove" and the self-averaging assumption is used to simplify computations
- Why unresolved: The self-averaging assumption is critical for obtaining explicit formulas but is not proven to hold for general data distributions, limiting the generality of the results.
- What evidence would resolve it: Proof that the self-averaging property holds for broad classes of data distributions (e.g., sub-Gaussian inputs with bounded moments), or explicit computation showing how the results change without this assumption.

### Open Question 3
- Question: How does the Bayesian inference behavior change when the number of datapoints P exceeds the input dimension N₀?
- Basis in paper: [explicit] "The results in the present article assume that the number of datapoints P is strictly less than N₀. Without this assumption, it is not clear how to define a suitable analog for the minimal norm interpolant θ* of the training data"
- Why unresolved: The assumption P < N₀ is crucial for defining the minimal norm interpolant and computing the partition function, but this is a significant limitation for many practical scenarios.
- What evidence would resolve it: Extension of the combinatorial model and partition function computation to the overparameterized regime P ≥ N₀, potentially using different interpolation schemes or regularization approaches.

### Open Question 4
- Question: Does the LP/N effective depth relationship hold for other shaped nonlinearities beyond the cubic form t + ψt³/L?
- Basis in paper: [explicit] "The nonlinearity (1.2) can be thought of as a generic odd shaped nonlinearity since the leading order contribution in 1/L is obtained by 'shaping' √L · σ(t/√L) for a smooth odd function σ"
- Why unresolved: The authors suggest their techniques could generalize to other monomials but note it's unclear how to extend to general shaped nonlinearities, leaving open whether LP/N remains the relevant scaling parameter.
- What evidence would resolve it: Computation of the partition function for shaped nonlinearities with different polynomial exponents (e.g., t + ψt⁵/L or t + ψt⁷/L) and verification that LP/N still controls the departure from the kernel regime.

### Open Question 5
- Question: What is the exact nature of the posterior distribution in the regime where the first order correction is small but non-negligible (i.e., LP/N is small but non-zero)?
- Basis in paper: [explicit] "When LP/N is a small constant, neural network Bayesian inference departs from the kernel regime" and the analysis focuses on LP/N being either 0 (kernel regime) or large enough for the first order correction to dominate
- Why unresolved: The analysis provides conditions for entering and exiting the kernel regime but does not characterize the precise nature of the posterior in the intermediate regime where LP/N is small but non-zero.
- What evidence would resolve it: Derivation of the exact posterior distribution for small but non-zero LP/N, potentially involving higher order terms in the 1/N expansion or alternative approximation schemes.

## Limitations
- The perturbative 1/N expansion requires LP/N to remain small; its validity regime for practical network sizes is unclear
- The shaped activation assumption (cubic nonlinearity) is restrictive and may not generalize to other nonlinearities
- The analysis assumes self-averaging of data points, which may not hold for highly structured or correlated datasets

## Confidence
- High: Kernel equivalence when N ≫ L, P; curvature of implicit data manifold determined by ψ
- Medium: LP/N as effective depth controlling feature learning; zero-temperature equivalence to data-dependent kernel
- Low: Generalization of results to non-shaped activations; behavior beyond first-order 1/N corrections

## Next Checks
1. **Finite-width validation**: Numerically verify the kernel equivalence prediction by training shaped MLPs with varying N, L, P ratios and comparing to the analytical kernel predictions
2. **Effective depth scaling**: Systematically vary LP/N across several orders of magnitude while keeping N, L, P large, measuring the deviation from kernel behavior to confirm LP/N as the relevant scaling parameter
3. **Curvature dependence**: Fix all parameters except ψ and measure how predictive performance changes across the hyperbolic/spherical/flat regimes to validate the geometric interpretation