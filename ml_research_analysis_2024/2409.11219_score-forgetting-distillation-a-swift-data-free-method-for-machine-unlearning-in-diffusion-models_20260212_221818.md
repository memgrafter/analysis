---
ver: rpa2
title: 'Score Forgetting Distillation: A Swift, Data-Free Method for Machine Unlearning
  in Diffusion Models'
arxiv_id: '2409.11219'
source_url: https://arxiv.org/abs/2409.11219
tags:
- diffusion
- forgetting
- score
- data
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Score Forgetting Distillation (SFD), a data-free
  method for machine unlearning (MU) in diffusion models that achieves both effective
  forgetting and fast one-step generation. SFD aligns the conditional scores of "unsafe"
  concepts with "safe" ones via cross-class score distillation, integrated as a regularization
  term in the distillation objective.
---

# Score Forgetting Distillation: A Swift, Data-Free Method for Machine Unlearning in Diffusion Models

## Quick Facts
- **arXiv ID:** 2409.11219
- **Source URL:** https://arxiv.org/abs/2409.11219
- **Reference count:** 40
- **Key outcome:** Introduces Score Forgetting Distillation (SFD), a data-free method for machine unlearning in diffusion models that achieves effective forgetting and fast one-step generation.

## Executive Summary
This paper presents Score Forgetting Distillation (SFD), the first data-free method for machine unlearning (MU) in diffusion models that achieves both effective forgetting and fast one-step generation. SFD aligns the conditional scores of "unsafe" concepts with "safe" ones via cross-class score distillation, integrated as a regularization term in the distillation objective. The method trains a generator and score network using a pre-trained diffusion model as the teacher, eliminating the need for real data. Experiments on CIFAR-10, STL-10, and Stable Diffusion demonstrate that SFD effectively forgets target classes or concepts while preserving quality for other classes. On CIFAR-10, SFD achieves 99.64% unlearning accuracy (UA) and 5.35 FID, outperforming baselines. The method is 1,000x faster than standard diffusion sampling, marking the first accelerated MU for diffusion models.

## Method Summary
SFD is a data-free machine unlearning method that aligns conditional scores of "unsafe" concepts with "safe" ones through cross-class score distillation. The approach trains a generator and score network using a pre-trained diffusion model as the teacher. The SFD loss measures the discrepancy between the teacher model's score for a "safe" concept and the student model's score for the "unsafe" concept, encouraging the student to produce similar scores. An alternating optimization strategy between the generator and score network reduces computational cost while maintaining effective distillation. The total loss combines a distillation loss that preserves remaining classes and a forgetting loss that overrides the target class, with coefficients balancing these competing objectives.

## Key Results
- On CIFAR-10, SFD achieves 99.64% unlearning accuracy (UA) and 5.35 FID, outperforming baseline methods
- On STL-10, SFD reaches 99.02% UA and 18.82 FID for single-class forgetting
- For celebrity forgetting, SFD reduces detection rates from 82.95% to 1.87% for gender and from 90.74% to 1.88% for identity
- SFD enables 1,000x faster generation compared to standard diffusion sampling, marking the first accelerated MU method for diffusion models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SFD achieves data-free machine unlearning by aligning conditional scores of "unsafe" concepts with "safe" ones through cross-class score distillation.
- Mechanism: The SFD loss measures the discrepancy between the teacher model's score for a "safe" concept and the student model's score for the "unsafe" concept, encouraging the student to produce similar scores. This alignment effectively makes the model "forget" the unsafe concept while preserving capabilities for safe concepts.
- Core assumption: The conditional score alignment is sufficient to change the model's behavior without requiring access to real data.
- Evidence anchors:
  - [abstract]: "SFD aligns the conditional scores of 'unsafe' concepts with 'safe' ones via cross-class score distillation"
  - [section 2.2]: "our goal is to align the conditional distributions... by adapting the concept of data-free score distillation"
  - [corpus]: No direct evidence found - weak signal for this specific mechanism

### Mechanism 2
- Claim: The alternating optimization between generator and score network reduces computational cost while maintaining effective distillation.
- Mechanism: Instead of computing the optimal score estimator for each generator state, SFD alternates between updating the generator and its approximate score estimator. This approach approximates the optimal solution while being computationally tractable.
- Core assumption: The alternating updates converge to a good enough solution without requiring the exact optimal score estimator.
- Evidence anchors:
  - [section 2.2]: "we implement an alternating update strategy between θ and ψ... simplifies the computational process"
  - [section 2.2]: "This approach mitigates the need to obtain the optimal score estimator ψ∗(θ) for each θ"
  - [corpus]: No direct evidence found - weak signal for this specific mechanism

### Mechanism 3
- Claim: The hybrid loss formulation (combining distillation and forgetting terms) enables simultaneous forgetting and preservation of other concepts.
- Mechanism: The total loss combines a distillation loss (Lsfd(θ; ϕ, cr, cr)) that preserves the remaining classes and a forgetting loss (Lsfd(θ; ϕ, co, cf)) that overrides the target class. The coefficients λ and μ balance these competing objectives.
- Core assumption: The weighted combination of distillation and forgetting losses can effectively achieve both objectives without compromising either.
- Evidence anchors:
  - [section 2.2]: "minimizing a score forgetting distillation loss... eliminates the need for real data"
  - [section 2.2]: "We implement an alternating update strategy... This approach mitigates the need to obtain the optimal score estimator"
  - [corpus]: No direct evidence found - weak signal for this specific mechanism

## Foundational Learning

- Concept: Diffusion models and score matching
  - Why needed here: SFD builds directly on diffusion model principles and score matching techniques
  - Quick check question: How does the relationship between score estimators and conditional mean estimators enable SFD's approach?

- Concept: Machine unlearning objectives and evaluation
  - Why needed here: Understanding unlearning requirements (forgetting specific concepts while preserving others) is crucial for evaluating SFD
  - Quick check question: What metrics would you use to verify that SFD has successfully forgotten a target concept?

- Concept: Data-free distillation methods
  - Why needed here: SFD's innovation is in achieving unlearning without real data, relying on score distillation
  - Quick check question: Why is data-free distillation particularly challenging for unlearning compared to standard distillation?

## Architecture Onboarding

- Component map:
  - Pre-trained teacher score network (sϕ) - frozen
  - Generator network (gθ) - learnable
  - Fake score network (sψ) - learnable, approximates generator's score
  - Loss computation module - calculates SFD, distillation, and forgetting losses

- Critical path:
  1. Sample noise and class labels
  2. Generate synthetic data through generator
  3. Compute forward diffusion process
  4. Calculate SFD loss using teacher and fake score networks
  5. Update generator and fake score network parameters

- Design tradeoffs:
  - Data-free approach vs. potential performance vs. data-requiring methods
  - Single-step generation vs. potentially higher quality from multi-step methods
  - Alternating optimization vs. computational efficiency vs. potential convergence issues

- Failure signatures:
  - Generator produces low-quality images (high FID, low IS)
  - Forgetting doesn't occur (high UA for target class)
  - Other concepts degrade (increased FID for non-target classes)
  - Training instability or non-convergence

- First 3 experiments:
  1. Train SFD on CIFAR-10 with class 0 as target for forgetting - verify single-step generation works
  2. Measure UA and FID before/after training - confirm forgetting occurs while maintaining quality
  3. Test with different λ and μ values - find optimal balance between forgetting and preservation

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several remain unaddressed based on the experimental scope and methodology.

## Limitations
- Evaluation focuses on forgetting randomly selected classes rather than responding to actual data removal requests, limiting real-world applicability assessment
- The method requires access to a pre-trained diffusion model and a text encoder (for Stable Diffusion experiments), raising questions about whether this constitutes "data-free" in the strictest sense
- No analysis of potential biases introduced by the forgetting process or whether certain concepts are more susceptible to forgetting than others

## Confidence
- **High confidence** in the core technical approach and its novelty as the first data-free, accelerated MU method for diffusion models
- **Medium confidence** in the practical effectiveness due to the artificial nature of the "unlearning" task
- **Medium confidence** in the 1,000x speedup claim, as this appears to be comparing single-step SFD generation against typical 1,000-step DDPM sampling

## Next Checks
1. **Real-world scenario testing**: Apply SFD to remove specific images/classes requested for unlearning by actual users, measuring both forgetting effectiveness and impact on model utility
2. **Robustness analysis**: Test SFD's performance when the pre-trained teacher model has knowledge gaps or when unlearning targets concepts not well-represented in the safe concept set
3. **Bias and fairness audit**: Systematically evaluate whether SFD introduces or amplifies biases during the unlearning process, particularly for sensitive attributes