---
ver: rpa2
title: 'Executing Natural Language-Described Algorithms with Large Language Models:
  An Investigation'
arxiv_id: '2403.00795'
source_url: https://arxiv.org/abs/2403.00795
tags:
- step
- increment
- last
- prev
- color
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether current large language models (LLMs)
  can execute algorithms described in natural language. The authors construct a benchmark
  of 30 algorithms from the textbook "Introduction to Algorithms," including sorting,
  searching, graph algorithms, and dynamic programming, with 300 randomly generated
  instances.
---

# Executing Natural Language-Described Algorithms with Large Language Models: An Investigation

## Quick Facts
- arXiv ID: 2403.00795
- Source URL: https://arxiv.org/abs/2403.00795
- Reference count: 40
- Primary result: GPT-4 achieves 100% accuracy on natural language-described algorithms, demonstrating strong capabilities in following control flow, precise calculations, and variable state maintenance.

## Executive Summary
This paper investigates whether current large language models (LLMs) can execute algorithms described in natural language. The authors construct a benchmark of 30 algorithms from the textbook "Introduction to Algorithms," including sorting, searching, graph algorithms, and dynamic programming, with 300 randomly generated instances. They design natural language prompts for each algorithm and evaluate three popular LLMs: GPT-3.5-Turbo, Text-Davinci-003, and GPT-4. Results show that GPT-4 achieves 100% accuracy across all tasks, demonstrating strong capabilities in following control flow, performing precise calculations, and maintaining variable states. In contrast, GPT-3.5 models perform significantly worse, especially on complex graph algorithms. The study also finds that GPT-4 struggles with heavy numeric computations involving floating-point operations. Overall, the findings suggest that modern LLMs, particularly GPT-4, can effectively interpret and execute natural language-described algorithms, mimicking core functions of the von Neumann machine.

## Method Summary
The authors constructed a benchmark of 30 algorithms from "Introduction to Algorithms" textbook, generating 300 random instances (10 per algorithm). They designed detailed natural language prompts for each algorithm following step-by-step execution format with explicit variable states. The study evaluated GPT-3.5-Turbo, Text-Davinci-003, and GPT-4 on these instances, measuring final output accuracy and intermediate result correctness. The methodology systematically compared performance across different algorithm types and prompt formats, analyzing how well LLMs could follow control flow, perform calculations, and maintain state throughout execution.

## Key Results
- GPT-4 achieved 100% accuracy across all 30 algorithm tasks, while GPT-3.5 models performed significantly worse
- Detailed natural language prompts outperformed Python code alone for algorithm execution
- GPT-4 demonstrated perfect execution of control flow structures (sequential, selection, iteration) and variable state maintenance
- All models struggled with heavy numeric computations involving floating-point operations, achieving 0% accuracy on numeric-intensive tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can execute natural language-described algorithms by simulating a von Neumann machine.
- Mechanism: The model interprets control flow (sequential, selection, iteration), performs precise calculations, and maintains variable states through text output.
- Core assumption: Natural language instructions can be parsed and executed step-by-step without external tools.
- Evidence anchors:
  - [abstract]: "GPT-4 achieves 100% accuracy across all tasks, demonstrating strong capabilities in following control flow, performing precise calculations, and maintaining variable states."
  - [section]: "They can accurately follow the control flow of the algorithm as per the prompt description, precisely execute each step, and perform the calculation."
  - [corpus]: Weak; corpus contains related but not directly equivalent mechanisms.
- Break condition: Heavy numeric computations involving floating-point operations cause failure.

### Mechanism 2
- Claim: Detailed natural language prompts are more effective than Python code for algorithm execution.
- Mechanism: Detailed natural language instructions provide clarity and force step-by-step reasoning, while Python code alone lacks explicit step-by-step guidance.
- Core assumption: LLMs can interpret and follow detailed natural language instructions better than uninterpreted code.
- Evidence anchors:
  - [section]: "Compared with detailed instruction, under Python Code only, the average performance of all three models declines."
  - [section]: "Under detailed instruction, GPT-4 did not make any mistakes in computing intermediate results."
  - [corpus]: Weak; corpus contains related but not directly equivalent mechanisms.
- Break condition: Ambiguous or repetitive natural language prompts cause confusion.

### Mechanism 3
- Claim: Intermediate result accuracy is strongly correlated with final answer correctness.
- Mechanism: Correct intermediate computations lead to correct final answers; a single error typically results in a wrong final answer.
- Core assumption: Each step's output depends on the correctness of previous steps.
- Evidence anchors:
  - [section]: "We find that by replacing detailed instruction with 'uninterpreted' Python code, the Intermediate Accuracy and Process Accuracy drop noticeably together with the Final Accuracy."
  - [section]: "Process Accuracy and Intermediate Accuracy may not be smaller than Final accuracy, indicating that correct intermediate computation would be much more likely to lead to the correct final answer."
  - [corpus]: Weak; corpus contains related but not directly equivalent mechanisms.
- Break condition: Random guessing or memorization could bypass the step dependency.

## Foundational Learning

- Concept: Control flow structures (sequential, selection, iteration)
  - Why needed here: These structures are essential for executing algorithms as they define the order and conditions of operations.
  - Quick check question: Can you write a simple algorithm using if/else and loops in natural language?

- Concept: Variable state maintenance
  - Why needed here: LLMs must track and update variable values throughout execution to produce correct results.
  - Quick check question: How would you explain keeping track of a variable's value through multiple steps in an algorithm?

- Concept: Step-by-step reasoning
  - Why needed here: Forcing the model to think step-by-step prevents jumping to conclusions and ensures accurate execution.
  - Quick check question: Can you break down a simple calculation into explicit, numbered steps?

## Architecture Onboarding

- Component map: Prompt generation -> LLM execution -> Output parsing -> Result validation
- Critical path: Natural language prompt -> LLM step-by-step execution -> Intermediate results -> Final answer
- Design tradeoffs: Detailed prompts vs. brevity; Python code vs. natural language; accuracy vs. context length
- Failure signatures: Incorrect intermediate results; skipped steps; incorrect final answers; context overflow
- First 3 experiments:
  1. Test simple algorithm (e.g., bubble sort) with detailed natural language prompt vs. Python code.
  2. Evaluate intermediate result accuracy for a dynamic programming algorithm.
  3. Test algorithm execution with increasing complexity to identify context length limits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can modern LLMs reliably execute algorithms involving heavy numeric computations, such as floating-point operations, exponentiation, and trigonometric functions?
- Basis in paper: [explicit] The paper found that GPT-4 and other LLMs performed poorly on algorithms requiring complex numeric computations (CLRS-Numeric tasks), achieving 0% accuracy. The authors suggest that external tools like Python interpreters may be needed for such tasks.
- Why unresolved: The paper only tested a limited set of numeric algorithms and did not explore hybrid approaches combining LLMs with external computation tools. It remains unclear whether LLMs can be effectively augmented to handle such computations.
- What evidence would resolve it: Experiments testing LLMs augmented with external tools (e.g., Python interpreters) on a broader range of numeric algorithms, comparing their performance to standalone LLMs.

### Open Question 2
- Question: How does the performance of LLMs on natural language-described algorithms scale with algorithm complexity and input size?
- Basis in paper: [inferred] The paper tested algorithms of varying complexity (CLRS-mini and CLRS-Numeric) but did not systematically analyze performance scaling with input size or algorithmic depth. GPT-4 performed perfectly on simpler tasks but struggled with more complex numeric operations.
- Why unresolved: The study focused on fixed input sizes and did not explore how LLMs handle larger or more intricate algorithmic problems. This leaves open questions about their practical limits.
- What evidence would resolve it: Systematic testing of LLMs on algorithms with progressively larger input sizes and deeper recursion, measuring accuracy, step-by-step correctness, and computational efficiency.

### Open Question 3
- Question: Can LLMs execute algorithms described in natural language without requiring detailed, step-by-step instructions?
- Basis in paper: [explicit] The paper demonstrated that detailed, unambiguous natural language prompts were necessary for accurate execution, as simpler prompts (e.g., Python code alone) led to significant performance drops. GPT-4 struggled with uninterpreted Python code compared to detailed instructions.
- Why unresolved: The study did not explore whether LLMs could generalize from fewer examples or learn to execute algorithms with less explicit guidance. This limits understanding of their true interpretive capabilities.
- What evidence would resolve it: Experiments comparing LLM performance on algorithms with varying levels of instruction detail, including few-shot learning or zero-shot scenarios, to determine the minimum guidance required for accurate execution.

## Limitations
- Benchmark limited to 30 algorithms from single textbook, may not represent full complexity of real-world algorithms
- Natural language prompts were carefully crafted by researchers, performance may degrade with less structured or more ambiguous instructions
- Study does not address computational efficiency or time complexity of LLM-based algorithm execution

## Confidence
- High Confidence: GPT-4's perfect accuracy on benchmark tasks and demonstrated ability to follow control flow and maintain variable states
- Medium Confidence: Claim that GPT-4 simulates a von Neumann machine, as this is interpretive conclusion rather than directly measured capability
- Medium Confidence: Superiority of detailed natural language prompts over Python code, based on specific prompt design used in study

## Next Checks
1. **Generalization Test**: Apply the same evaluation methodology to algorithms from different sources (research papers, online coding platforms) to assess whether GPT-4's perfect accuracy generalizes beyond the textbook benchmark.

2. **Prompt Robustness**: Systematically vary the detail level and structure of natural language prompts to determine the minimum requirements for accurate execution and identify failure modes with less structured inputs.

3. **Computational Complexity Analysis**: Measure the token usage and response time for executing algorithms of varying complexity to establish practical limits on algorithm size and determine the computational overhead of LLM-based execution compared to traditional interpreters.