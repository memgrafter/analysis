---
ver: rpa2
title: 'Upsample Guidance: Scale Up Diffusion Models without Training'
arxiv_id: '2404.01709'
source_url: https://arxiv.org/abs/2404.01709
tags:
- diffusion
- guidance
- resolution
- images
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Upsample guidance is a technique for generating high-resolution
  images with diffusion models without additional training or external models. It
  adapts pretrained models (e.g., 512^2) to generate higher-resolution images (e.g.,
  1536^2) by adding a single term in the sampling process.
---

# Upsample Guidance: Scale Up Diffusion Models without Training

## Quick Facts
- **arXiv ID**: 2404.01709
- **Source URL**: https://arxiv.org/abs/2404.01709
- **Authors**: Juno Hwang; Yong-Hyun Park; Junghyo Jo
- **Reference count**: 16
- **Primary result**: Generates high-resolution images with diffusion models without additional training or external models by adding a single term in the sampling process

## Executive Summary
Upsample guidance is a novel technique that enables diffusion models to generate high-resolution images without additional training or external models. The method works by decomposing the predicted noise at the target resolution into a component from the trained resolution and a residual part. It then adjusts the time and power of the trained resolution component to match the signal-to-noise ratio of the target resolution. The adjusted component is combined with the residual part using a guidance scale, allowing for controlled trade-off between fidelity and detail.

## Method Summary
Upsample guidance modifies the sampling process of pretrained diffusion models to generate higher-resolution images. It decomposes the target-resolution noise prediction into a lower-resolution component and a residual term. The lower-resolution component is adjusted in time (τ) and power (1/P) to match the signal-to-noise ratio of the target resolution. The final noise prediction is a weighted combination of the target-resolution prediction and the adjusted lower-resolution prediction, with the weight acting as a guidance scale. This approach can be applied to various diffusion model architectures, including pixel-space, latent-space, and video models.

## Key Results
- Successfully generates high-resolution images (e.g., 1536²) from pretrained models trained on lower resolutions (e.g., 512²)
- Improves image quality, fidelity, and prompt alignment compared to standard sampling methods
- Applicable to various diffusion model architectures, including pixel-space, latent-space, and video models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Upsample guidance preserves signal-to-noise ratio consistency across different resolutions by adjusting time and power.
- **Mechanism**: The predicted noise at the target resolution is decomposed into a component from the trained resolution and a residual part. The trained resolution component is adjusted in time (τ) to match the SNR of the target resolution, and power is adjusted to normalize the overall signal energy.
- **Core assumption**: The noise predictor's output is sensitive to both the time parameter and the overall variance of the input, and that downsampling affects both SNR and power in predictable ways.
- **Evidence anchors**:
  - [abstract]: "It then adjusts the time and power of the trained resolution component to match the signal-to-noise ratio of the target resolution."
  - [section 4.1]: "we can find the adjusted time τ such that SNRlow(τ) = m · SNR(t). Furthermore, by multiplying by 1/P, we can make the overall power equivalent to that of the target resolution."
  - [corpus]: No direct evidence in corpus papers about SNR matching across resolutions; this is a novel contribution.
- **Break condition**: If the noise predictor is not sensitive to time or variance, or if the downsampling process introduces nonlinearities that break the SNR and power relationships.

### Mechanism 2
- **Claim**: The residual noise at the target resolution captures high-frequency details not present in the lower-resolution component.
- **Mechanism**: By subtracting the upsampled lower-resolution noise prediction from the target-resolution prediction, the residual term isolates the part of the noise that represents higher-frequency information unique to the target resolution.
- **Core assumption**: The noise prediction at the target resolution can be linearly decomposed into a lower-resolution component and a residual, and that this residual represents meaningful high-frequency information.
- **Evidence anchors**:
  - [section 4.2]: "Now, recognizing the need for adjustments to ensure consistency among noise predictors at various resolutions, we substitute the term about trained resolution with the adjusted noise predictor in Equation (7)."
  - [corpus]: No direct evidence in corpus papers about decomposing noise predictions into lower and higher resolution components; this is a novel contribution.
- **Break condition**: If the noise prediction is not linearly decomposable, or if the residual does not capture meaningful high-frequency information.

### Mechanism 3
- **Claim**: Interpolating between the target-resolution and adjusted lower-resolution predictions allows for controlled trade-off between fidelity and detail.
- **Mechanism**: The final noise prediction is a weighted combination of the naive target-resolution prediction and the adjusted lower-resolution prediction, with the weight (wt) acting as a guidance scale that controls the influence of the lower-resolution component.
- **Core assumption**: A weighted combination of noise predictions can effectively blend the strengths of both resolutions, and that the guidance scale can be tuned to optimize image quality.
- **Evidence anchors**:
  - [abstract]: "The adjusted component is then combined with the residual part using a guidance scale."
  - [section 4.2]: "Finally, we consider interpolation between the naive sampling at the target resolution with the parallel sampling at the trained resolution."
  - [corpus]: Some evidence in corpus papers about guidance scales in diffusion models (e.g., classifier-free guidance), but not specifically about combining predictions from different resolutions.
- **Break condition**: If the interpolation does not effectively blend the predictions, or if the guidance scale is not well-calibrated for the specific model and resolution.

## Foundational Learning

- **Concept**: Signal-to-noise ratio (SNR) and its relationship to time in diffusion models.
  - **Why needed here**: Understanding how SNR changes with time is crucial for adjusting the time parameter (τ) to match the SNR of the target resolution.
  - **Quick check question**: In a diffusion model, how does the SNR change as the time parameter increases?

- **Concept**: Linear operations and their preservation under downsampling and upsampling.
  - **Why needed here**: The method relies on the linearity of downsampling and upsampling operations to decompose and recombine noise predictions across resolutions.
  - **Quick check question**: What are the conditions under which linear operations like downsampling and upsampling preserve the properties of the signals they operate on?

- **Concept**: Variational autoencoders (VAEs) and their impact on latent space transformations.
  - **Why needed here**: Understanding how VAEs introduce nonlinearities is crucial for adapting the method to latent diffusion models (LDMs) and avoiding artifacts.
  - **Quick check question**: How do the nonlinearities introduced by VAEs affect the linearity assumptions of the upsample guidance method?

## Architecture Onboarding

- **Component map**: Input noised image -> Downsample -> Noise prediction at trained resolution with adjusted time and power -> Upsample adjusted noise -> Noise prediction at target resolution -> Compute residual -> Interpolate using guidance scale -> Final noise prediction

- **Critical path**:
  1. Input noised image at target resolution.
  2. Downsample image and predict noise at trained resolution with adjusted time and power.
  3. Upsample the adjusted noise prediction.
  4. Predict noise at target resolution.
  5. Compute residual noise.
  6. Interpolate between target and adjusted predictions using guidance scale.
  7. Output final noise prediction.

- **Design tradeoffs**:
  - Resolution vs. computational cost: Higher resolution increases computational cost, but upsample guidance minimizes additional cost by only adjusting a single term.
  - Guidance scale (wt) vs. image quality: Higher guidance scale improves alignment with prompt but may reduce photorealism; lower guidance scale improves photorealism but may reduce alignment.
  - Time adjustment (τ) vs. SNR matching: Accurate time adjustment is crucial for SNR matching, but numerical approximation may be necessary for integer time encoding.

- **Failure signatures**:
  - Residual noise patterns: If the decomposition into lower and higher resolution components is not accurate, residual noise patterns may appear in the generated images.
  - Artifacts at low time: If the guidance scale is not reduced near t=0 in LDMs, artifacts may appear due to the nonlinearities introduced by VAEs.
  - Mismatched SNR: If the time adjustment is not accurate, the SNR of the generated images may not match the target resolution, leading to blurry or noisy images.

- **First 3 experiments**:
  1. Implement upsample guidance on a simple unconditional diffusion model trained on CIFAR-10 and generate images at twice the resolution. Compare the results with and without upsample guidance.
  2. Implement upsample guidance on a text-to-image model based on Stable Diffusion v1.5 and generate images at higher resolutions. Evaluate the impact of the guidance scale on image quality and prompt alignment.
  3. Implement upsample guidance on a video generation model (e.g., AnimateDiff) and generate videos with spatial and temporal upsampling. Evaluate the consistency and quality of the generated videos.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the choice of time threshold η in the guidance scale affect the quality and consistency of generated images across different diffusion model architectures (pixel-space vs latent-space)?
- **Basis in paper**: [explicit] The paper discusses the importance of reducing the guidance scale to zero during mid-stages of sampling for LDMs to prevent artifacts, but a constant guidance scale is effective for pixel-space models. It recommends (θ, η) ≈ (1, 0.6) as a balanced setting for LDMs.
- **Why unresolved**: While the paper provides a recommended setting for LDMs, it does not explore the impact of different η values on the generated image quality across various model architectures or provide a comprehensive analysis of how η interacts with other factors like the noise schedule or model depth.
- **What evidence would resolve it**: Systematic experiments varying η across different diffusion model architectures (pixel-space, latent-space, video) and noise schedules, measuring image quality metrics like FID, CLIP score, and NIQE, would provide insights into the optimal η settings for different scenarios.

### Open Question 2
- **Question**: Can upsample guidance be extended to handle more complex upsampling scenarios, such as generating images with aspect ratios significantly different from the trained model, or generating images with non-integer scale factors?
- **Basis in paper**: [inferred] The paper demonstrates the effectiveness of upsample guidance for spatial and temporal upsampling in video generation models, but does not explore more complex scenarios like generating images with significantly different aspect ratios or non-integer scale factors. The current implementation relies on the linearity of upsampling and downsampling operators, which might not hold for more complex transformations.
- **Why unresolved**: The paper focuses on demonstrating the core concept of upsample guidance and its effectiveness for simple upsampling scenarios. Exploring more complex transformations would require addressing the challenges of maintaining consistency and quality when the upsampling process deviates significantly from the trained resolution.
- **What evidence would resolve it**: Experiments generating images with varying aspect ratios and non-integer scale factors using upsample guidance, comparing the results with other upsampling methods, and analyzing the impact on image quality and consistency, would provide insights into the limitations and potential extensions of the method.

### Open Question 3
- **Question**: How does upsample guidance perform when applied to diffusion models trained on different types of data distributions, such as natural images, medical images, or artistic styles?
- **Basis in paper**: [explicit] The paper demonstrates the effectiveness of upsample guidance across various models, including pixel-space, latent-space, and video diffusion models, but does not explore its performance on different data distributions. The method is derived from the diffusion process and is not dependent on the specific data distribution.
- **Why unresolved**: While the paper shows that upsample guidance is generally applicable to different model architectures, it does not provide evidence of its effectiveness across diverse data distributions. The quality of generated images might be affected by the characteristics of the underlying data distribution, such as the complexity of textures, the presence of fine details, or the adherence to specific artistic styles.
- **What evidence would resolve it**: Experiments applying upsample guidance to diffusion models trained on different datasets, such as natural images (e.g., ImageNet), medical images (e.g., CT scans), or artistic styles (e.g., paintings), and evaluating the quality of generated images using domain-specific metrics, would provide insights into the generalizability of the method across diverse data distributions.

## Limitations
- The method assumes linearity of downsampling and upsampling operations, which may not hold for complex transformations.
- Optimal guidance scale values may be model-specific and require further tuning for different architectures and resolutions.
- The effectiveness of upsample guidance on diffusion models trained on diverse data distributions has not been thoroughly explored.

## Confidence
- **High**: The core claim that adding a single term to the sampling process can generate higher-resolution images without training is well-supported by the theoretical framework and experimental results.
- **Medium**: The effectiveness of the guidance scale for balancing fidelity and detail is supported by experiments, but the optimal values may be model-specific and require further tuning.
- **Medium**: The assumption that the noise prediction can be linearly decomposed into lower and higher resolution components is plausible but requires further validation on diverse models and resolutions.

## Next Checks
1. **Ablation study on time and power adjustments**: Remove the time and power adjustments and observe the impact on image quality and SNR matching across different resolutions.
2. **Cross-model guidance scale optimization**: Systematically vary the guidance scale (wt) for different pretrained models and resolutions to identify optimal values and assess generalizability.
3. **Residual analysis**: Visualize and analyze the residual noise patterns to understand their relationship to high-frequency details and identify potential artifacts.