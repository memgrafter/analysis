---
ver: rpa2
title: Argumentation and Machine Learning
arxiv_id: '2410.23724'
source_url: https://arxiv.org/abs/2410.23724
tags:
- argumentation
- learning
- classi
- arguments
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a comprehensive survey of research works that
  combine Computational Argumentation and Machine Learning. The review identifies
  two broad themes: argumentation for machine learning and machine learning for argumentation.'
---

# Argumentation and Machine Learning

## Quick Facts
- arXiv ID: 2410.23724
- Source URL: https://arxiv.org/abs/2410.23724
- Authors: Antonio Rago; Kristijonas Čyras; Jack Mumford; Oana Cocarascu
- Reference count: 28
- Primary result: Comprehensive survey identifying two broad themes - argumentation for ML and ML for argumentation - across 28 papers

## Executive Summary
This paper provides a systematic survey of research combining Computational Argumentation and Machine Learning, identifying two main themes: argumentation for machine learning and machine learning for argumentation. The review categorizes works across various dimensions including type of learning, form of argumentation framework, and three types of interactions: synergistic, segmented, and approximated approaches. The study concludes that certain forms of argumentation are better suited for supporting specific types of machine learning, and vice versa, while highlighting limitations and challenges that need addressing for continued success in this cross-disciplinary research area.

## Method Summary
The authors conducted a systematic literature review of 28 papers combining argumentation and machine learning, categorizing them across multiple dimensions including the type of learning employed, the form of argumentation framework used, and the nature of interaction between the two fields. Papers were evaluated based on their approach (synergistic, segmented, or approximated) and the specific tasks they addressed. The review methodology involved extracting key characteristics from each paper and analyzing patterns across the corpus to identify trends, limitations, and areas for future research.

## Key Results
- Two broad themes identified: argumentation for machine learning and machine learning for argumentation
- Three types of interactions found: synergistic (joint reasoning), segmented (parallel but separate), and approximated (ML approximating argumentation)
- Clear patterns identified showing suitability of certain argumentation forms for specific ML types
- Highlighted limitations including scalability concerns and lack of user studies for explainability benefits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Argumentation frameworks can be used to inject domain knowledge into ML models to improve their inference accuracy.
- Mechanism: By constructing argumentation frameworks from rules or preferences, conflicting classifications can be resolved through argumentative reasoning (e.g., DeLP-style dialectical analysis). This allows the incorporation of expert knowledge that is not captured by the ML model alone.
- Core assumption: The argumentation framework can accurately represent the domain knowledge and the conflicts between different classifications.
- Evidence anchors:
  - [abstract]: "SA is proposed to improve ML-based classification, often via rule-based/premise-conclusion kind of arguments constructed using rule learning, typically via segmented or synergistic approaches."
  - [section]: "Carstens and Toni (2015) define a segmented approach for sentiment polarity classification via supervised learning. They leverage on the reasoning contained in QBAFs with gradual semantics to make improvements in classifier accuracy in tasks with textual data."
  - [corpus]: Weak - corpus papers are about computational aspects of argumentation frameworks, not ML applications.

### Mechanism 2
- Claim: Argumentation frameworks can provide interpretable explanations for ML model predictions.
- Mechanism: By constructing an argumentation framework that approximates the ML model, the reasons for a particular classification can be traced back to specific features, rules, or data points. This provides a more intuitive and understandable explanation than typical feature importance measures.
- Core assumption: The argumentation framework can accurately approximate the ML model and capture the relevant relationships between features and predictions.
- Evidence anchors:
  - [abstract]: "argumentation is often meant to explain ML-based systems, purportedly because of argumentative relations (especially in synergistic and segmented approaches) that are particularly analytical and interpretable."
  - [section]: "Cocarascu et al. (2020) take a segmented/synergistic approach to develop a model for classification of tabular, annotated image and textual data by leveraging ML's capability to compactly represent data and the argumentative reasoning to make and explain decisions."
  - [corpus]: Weak - corpus papers are about computational aspects of argumentation frameworks, not ML applications.

### Mechanism 3
- Claim: ML models can be used to learn argumentation frameworks from data, enabling automated reasoning.
- Mechanism: By using supervised learning techniques, such as inductive ML or GNNs, argumentation frameworks can be automatically generated from data. This allows for the creation of reasoning systems that are tailored to specific domains and tasks.
- Core assumption: The data contains sufficient information to learn meaningful argumentation frameworks, and the ML models can accurately capture the relevant relationships between arguments and attacks.
- Evidence anchors:
  - [abstract]: "One is that of using ML to generate argumentation frameworks. This can be achieved by means of rule learning, particularly using Inductive ML, purely for constructing rule-based argumentation frameworks in a segmented fashion to reason with."
  - [section]: "Ontañón et al. (2012) argue that inductive generalization in ML is a form of defeasible reasoning, and define a logical model to characterize and generate hypotheses from sets of examples from tabular data in a supervised manner."
  - [corpus]: Weak - corpus papers are about computational aspects of argumentation frameworks, not ML applications.

## Foundational Learning

- Concept: Argumentation frameworks and their semantics (e.g., grounded, preferred, stable).
  - Why needed here: To understand how argumentative reasoning can be used to improve ML models and provide explanations.
  - Quick check question: What is the difference between the grounded and preferred semantics in abstract argumentation?

- Concept: Machine learning models and algorithms (e.g., neural networks, decision trees, rule learning).
  - Why needed here: To understand how ML models can be used to generate argumentation frameworks and approximate reasoning.
  - Quick check question: What is the difference between supervised and unsupervised learning in ML?

- Concept: Graph neural networks and their applications.
  - Why needed here: To understand how GNNs can be used to approximate reasoning in argumentation frameworks and learn from data.
  - Quick check question: What is the key advantage of using GNNs over traditional neural networks for graph-structured data?

## Architecture Onboarding

- Component map: Data preprocessing -> ML model training -> Argumentation framework generation -> Argumentative reasoning -> Explanation generation

- Critical path:
  1. Data preprocessing
  2. ML model training
  3. Argumentation framework generation
  4. Argumentative reasoning
  5. Explanation generation

- Design tradeoffs:
  - Accuracy vs. interpretability: More complex ML models may be more accurate but less interpretable
  - Scalability vs. expressiveness: Larger argumentation frameworks may be more expressive but harder to scale
  - Automation vs. control: More automated approaches may be easier to use but offer less control over the reasoning process

- Failure signatures:
  - Poor ML model performance: Indicates issues with data quality, model selection, or training process
  - Inaccurate argumentation framework generation: Indicates issues with the ML model's ability to capture relevant relationships in the data
  - Ineffective argumentative reasoning: Indicates issues with the argumentation framework's semantics or the reasoning algorithm

- First 3 experiments:
  1. Train a simple ML model (e.g., decision tree) on a small dataset and generate an argumentation framework to resolve conflicts in the predictions
  2. Use a GNN to approximate reasoning in an abstract argumentation framework and compare the results to a traditional argumentation solver
  3. Generate an argumentation framework from text data using topic modeling and supervised learning, and use it to provide explanations for the text's sentiment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can argumentation frameworks effectively scale to support large-scale machine learning models and datasets, or are they inherently limited to smaller, simpler problems?
- Basis in paper: [inferred] The paper discusses the trend of using simpler ML techniques and smaller datasets in argumentation-ML research, and questions whether these approaches can be replicated at scale with modern large-scale models and datasets.
- Why unresolved: The paper acknowledges the lack of evidence for argumentation's effectiveness at scale, noting that modern ML inference resolves conflicts probabilistically and large-scale datasets allow for capturing exceptions and particular contexts using larger models.
- What evidence would resolve it: Empirical studies comparing the performance of argumentation-ML approaches with large-scale ML models and datasets, demonstrating the effectiveness or limitations of argumentation in these settings.

### Open Question 2
- Question: Does the use of argumentation frameworks genuinely improve user trust and model transparency compared to state-of-the-art explainability methods, or is this benefit largely speculative?
- Basis in paper: [explicit] The paper highlights the lack of user studies supporting the presumed benefits of argumentation in explaining ML models, and calls for more objective metrics and subjective experimental evaluation with users to assess the explanatory power of argumentation.
- Why unresolved: The paper acknowledges the intuitive relationship-based structure of argumentation explanations but notes the absence of widely-employed and convincingly useful systems for ML model explainability via argumentation, and the need for more studies to demonstrate its benefits.
- What evidence would resolve it: User studies comparing the effectiveness of argumentation-based explanations with other explainability methods in terms of user trust, model transparency, and understanding of model decisions.

### Open Question 3
- Question: Can argumentation frameworks effectively model and predict human behavior in real-world argumentation scenarios, or are they fundamentally limited in capturing the nuances of human deliberation?
- Basis in paper: [explicit] The paper discusses works that suggest bipolar argumentation is not well-suited to select arguments that people choose in real-world deliberation scenarios and instead proposes using ML for recommending arguments in human discussions.
- Why unresolved: The paper presents empirical evidence showing that ML models can outperform argumentation-based models in predicting human choices of arguments in deliberation tasks, but acknowledges the need for further research to fully understand the limitations and potential of argumentation in modeling human behavior.
- What evidence would resolve it: Empirical studies comparing the performance of argumentation frameworks with ML models in predicting human behavior in various real-world argumentation scenarios, and analyzing the strengths and weaknesses of each approach in capturing the nuances of human deliberation.

## Limitations

- Limited scope: Survey covers only 28 papers, potentially missing emerging approaches or alternative frameworks
- Potential misclassification: Interaction mode boundaries (synergistic, segmented, approximated) may be fuzzy in practice
- Lack of empirical validation: No quantitative analysis or experiments conducted to validate identified patterns across the corpus

## Confidence

- High confidence in methodological approach to categorizing argumentation-ML interactions
- Medium confidence in generalizability of conclusions due to limited corpus size
- Medium confidence in the clarity of interaction mode definitions and boundaries

## Next Checks

1. Validate the categorization of papers across interaction modes by having multiple reviewers independently classify a subset of papers
2. Conduct a citation network analysis to identify additional relevant papers that may have been missed in the literature search
3. Perform quantitative analysis on the relationship between argumentation framework types and ML task success rates across the surveyed papers