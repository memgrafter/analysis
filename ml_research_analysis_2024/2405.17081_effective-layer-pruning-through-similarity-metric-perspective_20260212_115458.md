---
ver: rpa2
title: Effective Layer Pruning Through Similarity Metric Perspective
arxiv_id: '2405.17081'
source_url: https://arxiv.org/abs/2405.17081
tags:
- pruning
- layer
- layers
- accuracy
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an effective layer pruning strategy for deep
  neural networks that leverages the Centered Kernel Alignment (CKA) similarity metric
  to identify and remove unimportant layers without compromising predictive ability.
  The method works by measuring the similarity between feature representations of
  the original network and temporary pruned candidates, then selecting layers whose
  removal preserves the most similarity.
---

# Effective Layer Pruning Through Similarity Metric Perspective

## Quick Facts
- arXiv ID: 2405.17081
- Source URL: https://arxiv.org/abs/2405.17081
- Authors: Ian Pons; Bruno Yamamoto; Anna H. Reali Costa; Artur Jordao
- Reference count: 40
- One-line primary result: Layer pruning method using CKA similarity removes 75%+ of computations while maintaining or improving accuracy.

## Executive Summary
This paper proposes an effective layer pruning strategy for deep neural networks that leverages the Centered Kernel Alignment (CKA) similarity metric to identify and remove unimportant layers without compromising predictive ability. The method works by measuring the similarity between feature representations of the original network and temporary pruned candidates, then selecting layers whose removal preserves the most similarity. Extensive experiments on standard architectures (ResNet56/110/50) and datasets (CIFAR-10/100, ImageNet) demonstrate that the approach outperforms state-of-the-art pruning techniques, removing more than 75% of computations while maintaining or even improving accuracy.

## Method Summary
The proposed method estimates layer importance using the Centered Kernel Alignment (CKA) metric, which measures similarity between feature representations of the unpruned model and candidate pruned models. The process involves iteratively evaluating each layer by temporarily removing it, computing feature maps, and measuring CKA similarity to the original model. The layer with the lowest similarity score is permanently removed, and the process repeats until a target computational reduction is achieved. Pruned models are then fine-tuned to recover any lost accuracy. The method scales linearly with network depth and is particularly effective for residual architectures with skip connections.

## Key Results
- Removes more than 75% of computations while maintaining or improving accuracy across multiple architectures and datasets
- Demonstrates improved robustness to adversarial attacks and out-of-distribution samples in pruned models
- Reduces carbon emissions during training and fine-tuning by up to 80.85%, contributing to Green AI goals
- Achieves consistent performance across both deep (ResNet110) and shallow (ResNet56) architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layers with high CKA similarity to the original model's representations are less important and can be removed without significant accuracy loss.
- Mechanism: The CKA metric measures representational similarity between feature maps. When a candidate pruned model (with a layer removed) produces feature maps similar to the original model, it indicates that the removed layer was redundant for preserving the model's representational capacity.
- Core assumption: Representational similarity as measured by CKA correlates with functional importance - layers that can be removed while maintaining representational similarity are less critical to the model's performance.
- Evidence anchors:
  - [abstract] "Our method estimates the relative importance of a layer using the Centered Kernel Alignment (CKA) metric, employed to measure the similarity between the representations of the unpruned model and a candidate layer for pruning."
  - [section 3] "We employ Centered Kernel Alignment (CKA) due to its effectiveness and flexibility in measuring similarity between two networks"

### Mechanism 2
- Claim: Layer pruning provides more direct computational benefits than filter pruning because it reduces network depth, which directly translates to latency improvements.
- Mechanism: Removing entire layers eliminates all computations associated with those layers, including convolutions, activations, and batch normalization, resulting in reduced FLOPs and faster inference times.
- Core assumption: Network depth is a primary driver of latency, and removing layers provides more substantial speedups than removing individual filters within layers.
- Evidence anchors:
  - [section 4] "layer pruning yields a higher speed-up than filter removal. For example, in ResNet110, with both methods eliminating around a thousand filters, layer pruning achieves an 11 pp speedup over filter pruning."
  - [section 1] "layer pruning reduces network depth, which directly addresses model latency while also providing all the benefits of filter pruning"

### Mechanism 3
- Claim: The proposed method's linear complexity (O(|L|)) makes it scalable for deep networks, unlike evolutionary or optimization-based approaches.
- Mechanism: By evaluating each layer candidate once through forward passes and CKA computation, the method avoids expensive iterative optimization or population-based search methods.
- Core assumption: Single-pass evaluation of layer importance is sufficient to identify optimal pruning candidates without requiring iterative refinement or complex optimization.
- Evidence anchors:
  - [section 3] "In terms of computational cost, compared to Zhou et al. [54], our method is more cost-friendly... our approach requires |L| forwards and CKA comparisons, scaling linearly"
  - [section 4] "Compared to Zhou et al. [54], our method is more cost-friendly... our approach requires |L| forwards and CKA comparisons, scaling linearly (see Algorithm 1)"

## Foundational Learning

- Concept: Centered Kernel Alignment (CKA) similarity metric
  - Why needed here: CKA provides a normalized measure of representational similarity between neural network layers that is invariant to isotropic scaling and orthogonal transformations, making it suitable for comparing feature maps across different network architectures.
  - Quick check question: What is the range of CKA values and what does a value of 1 indicate?

- Concept: Residual network architecture and skip connections
  - Why needed here: The method relies on residual connections to propagate information when layers are removed, as skip connections allow the network to bypass pruned layers while maintaining information flow.
  - Quick check question: How do residual connections enable layer pruning without completely breaking the network's forward pass?

- Concept: Pruning as regularization
  - Why needed here: The paper demonstrates that pruned models can achieve improved robustness and generalization, suggesting that pruning acts as a form of regularization that can enhance model performance beyond just reducing computational cost.
  - Quick check question: How does removing redundant layers potentially improve a model's generalization ability?

## Architecture Onboarding

- Component map: Data preprocessing -> Trained baseline model -> CKA similarity computation -> Layer removal and weight transfer -> Fine-tuning -> Evaluation
- Critical path: Data → Feature extraction → CKA computation → Layer selection → Model modification → Fine-tuning → Evaluation
- Design tradeoffs:
  - Single-pass vs. iterative evaluation: Single-pass is faster but may miss interactions between layers
  - Layer-level vs. block-level pruning: Layer pruning is simpler but may be constrained by architectural boundaries
  - CKA-based vs. other similarity metrics: CKA is well-established but other metrics might capture different aspects of representational similarity
- Failure signatures:
  - Accuracy degradation exceeding acceptable thresholds
  - CKA scores not correlating with actual importance (high CKA but high importance, or vice versa)
  - Computational savings not matching theoretical expectations
  - Robustness metrics degrading despite accuracy being maintained
- First 3 experiments:
  1. Implement CKA computation on feature maps from a small ResNet and verify similarity scores between different layers
  2. Create a layer removal mechanism that preserves skip connections and verify the modified network architecture
  3. Run the full pipeline on a small dataset (e.g., CIFAR-10 with ResNet20) to validate the pruning process and measure accuracy/FLOPs reduction

## Open Questions the Paper Calls Out

### Open Question 1  
- Question: What is the optimal number of layers to remove from Transformer architectures for tabular data to maximize accuracy improvement while minimizing computational cost?
- Basis in paper: [explicit] The paper shows that the layer-pruning technique operated as a strong regularization mechanism on tabular data Transformer architectures, with most pruned models exhibiting no accuracy drop even on high compression regimes.
- Why unresolved: The paper only presents results for Transformer architectures on tabular data, and the optimal number of layers to remove may vary depending on the specific architecture and dataset.
- What evidence would resolve it: Experiments comparing the performance of Transformer architectures with different numbers of removed layers on various tabular datasets, measuring both accuracy and computational cost.

### Open Question 2  
- Question: How does the effectiveness of the proposed CKA criterion compare to other similarity metrics for layer pruning, such as cosine similarity or Euclidean distance?
- Basis in paper: [explicit] The paper proposes using the Centered Kernel Alignment (CKA) metric for layer pruning and demonstrates its effectiveness compared to existing layer-pruning strategies.
- Why unresolved: The paper does not compare the CKA criterion to other similarity metrics for layer pruning.
- What evidence would resolve it: Experiments comparing the performance of layer pruning methods using different similarity metrics, such as CKA, cosine similarity, and Euclidean distance, on various architectures and datasets.

### Open Question 3  
- Question: What is the impact of combining the proposed layer pruning method with other pruning techniques, such as filter pruning or weight pruning, on the overall performance and computational efficiency of the pruned models?
- Basis in paper: [explicit] The paper mentions that the proposed method can be combined with other pruning techniques, such as ℓ1-norm filter pruning, to achieve even higher computational reduction.
- Why unresolved: The paper does not provide a comprehensive analysis of the impact of combining the proposed layer pruning method with other pruning techniques.
- What evidence would resolve it: Experiments comparing the performance and computational efficiency of models pruned using the proposed layer pruning method alone, in combination with filter pruning, and in combination with weight pruning, on various architectures and datasets.

## Limitations

- The method's effectiveness depends heavily on residual connections, making it less applicable to architectures without skip connections
- Computational savings claims are based on theoretical FLOPs rather than measured hardware-specific latency
- The analysis focuses primarily on specific adversarial attack methods and distribution shifts, leaving uncertainty about performance under other stress conditions

## Confidence

- **High Confidence**: The core mechanism of using CKA similarity for layer importance estimation is well-supported by the experimental results across multiple architectures and datasets. The computational complexity claims (linear scaling) are clearly demonstrated.
- **Medium Confidence**: The robustness improvements and Green AI benefits are promising but evaluated on a limited set of attack methods and datasets. The generalizability to other domains (e.g., NLP, vision transformers) requires further validation.
- **Low Confidence**: The claim that layer pruning provides more direct computational benefits than filter pruning may not hold for all hardware configurations and network architectures, as the evidence is based on theoretical FLOPs rather than measured latency.

## Next Checks

1. **Hardware Validation**: Measure actual inference latency on target hardware (GPU/CPU) for pruned models to verify that theoretical FLOPs reduction translates to real speedups, accounting for hardware-specific optimizations.
2. **Architecture Generalization**: Test the method on non-residual architectures (e.g., VGG, Vision Transformers) to assess whether CKA-based layer importance estimation works effectively without skip connections.
3. **Adversarial Robustness Extension**: Evaluate the pruned models against a broader range of adversarial attacks (e.g., PGD, AutoAttack) and out-of-distribution datasets to comprehensively validate the robustness claims.