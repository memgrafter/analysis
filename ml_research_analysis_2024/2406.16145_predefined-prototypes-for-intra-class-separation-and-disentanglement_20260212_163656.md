---
ver: rpa2
title: Predefined Prototypes for Intra-Class Separation and Disentanglement
arxiv_id: '2406.16145'
source_url: https://arxiv.org/abs/2406.16145
tags:
- embeddings
- which
- factors
- prototypes
- pitch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a method for defining prototypes before training
  prototypical learning systems, aiming to improve inter-class separation and enable
  disentanglement of embeddings with respect to specific variation factors. Unlike
  traditional approaches that compute prototypes as averages or train them, this method
  predefines prototypes based on human-specified criteria, simplifying the training
  pipeline.
---

# Predefined Prototypes for Intra-Class Separation and Disentanglement

## Quick Facts
- arXiv ID: 2406.16145
- Source URL: https://arxiv.org/abs/2406.16145
- Authors: Antonio Almudévar; Théo Mariotte; Alfonso Ortega; Marie Tahon; Luis Vicente; Antonio Miguel; Eduardo Lleida
- Reference count: 0
- Primary result: Predefined prototypes improve classification accuracy and enable disentanglement of embeddings with respect to known variation factors

## Executive Summary
This paper introduces a novel approach to prototypical learning where prototypes are predefined rather than learned during training. The method defines prototypes based on human-specified criteria to improve inter-class separation and enable disentanglement of embeddings with respect to specific variation factors. Unlike traditional approaches that compute prototypes as averages or train them, this method predefines prototypes using orthogonal vectors for class separation and factor-dependent vectors for interpretability. Experiments on audio classification tasks demonstrate improved accuracy compared to standard loss functions, while a case study on emotion recognition shows interpretable predictions through disentangled embeddings.

## Method Summary
The method defines prototypes before training using two approaches: orthogonal prototypes for inter-class separation and factor-dependent prototypes for disentanglement. For orthogonal prototypes, an orthogonal basis is constructed (using SVD when embedding dimension is sufficient), ensuring classes are well-separated in embedding space. For disentanglement, prototypes are defined as P(y,α) = (P'α(α), 0), splitting embeddings into factor-dependent and residual components. The loss function combines cross-entropy with prototype reconstruction, and only the embedding extractor and classifier are trained while prototypes remain fixed. This simplifies the training pipeline by removing prototype optimization while enabling interpretable predictions when factors are known.

## Key Results
- ESC-50 audio classification accuracy reaches 94.52% with predefined prototypes versus baseline cross-entropy
- The method outperforms standard losses (Focal Loss, Orthogonal Projection Loss) on both ESC-50 and KS2 datasets
- Emotion recognition on IEMOCAP shows disentangled embeddings with respect to pitch median, pitch std, and loudness
- Predefined prototypes simplify training by eliminating the need to optimize prototype parameters

## Why This Works (Mechanism)

### Mechanism 1
Predefined orthogonal prototypes force embeddings from different classes to spread into distinct, non-overlapping regions of the embedding space. By initializing prototypes as orthogonal vectors, the distance-based loss pushes each class's embeddings toward its respective prototype. Since prototypes are far apart, embeddings must also be far apart to minimize the loss, improving inter-class separability and classification accuracy. This assumes the embedding space has enough dimensions to allow orthogonal placement without overlap.

### Mechanism 2
Predefining prototypes based on known factors disentangles embeddings so specific dimensions encode interpretable variation factors. The prototype extractor splits the embedding into a factor-dependent part and a remainder, with the loss forcing the factor-dependent part to track the known variation while the remainder captures residual variation. This yields interpretable, factor-aligned embeddings, assuming the factors are informative enough to contribute meaningfully to classification.

### Mechanism 3
Predefining prototypes simplifies training by removing the need to learn prototypes, allowing the model to focus on mapping inputs to predefined targets. The prototype extractor is a fixed, non-trainable function, so the loss only needs to update the embedding extractor and classifier, removing optimization overhead and stabilizing training dynamics. This assumes fixed prototypes are well-chosen and do not need adaptation.

## Foundational Learning

- Concept: Orthogonal basis construction and Johnson-Lindenstrauss transforms
  - Why needed here: To ensure prototypes are well-separated when the number of classes C exceeds or is close to the embedding dimension k
  - Quick check question: Given k=16 and C=50, what dimensionality reduction technique would you use to preserve distances while fitting all prototypes orthogonally?

- Concept: Multilinear maps and soft label handling
  - Why needed here: The prototype extractor must accept soft labels (e.g., from mixup) without breaking the predefined structure
  - Quick check question: How does the prototype extractor behave when given a convex combination of two class one-hot vectors?

- Concept: Factor discretization and one-hot coding for interpretability
  - Why needed here: In the emotion recognition example, continuous acoustic factors are discretized into levels to create a fixed prototype mapping
  - Quick check question: If pitch median is discretized into three levels (low, medium, high), how many prototype vectors are needed per class?

## Architecture Onboarding

- Component map: Input preprocessing → ECAPA-TDNN/BEATs/AST backbone (Fθ) → Embedding (z) → Fixed prototype extractor P → Prototype (p) → Linear classifier Gϕ → Prediction (ŷ) → Loss = CE(y, ŷ) + λp||z - p||²
- Critical path: Fθ → z → P → p → ||z - p||² loss term; also Fθ → z → Gϕ → ŷ → CE loss
- Design tradeoffs:
  - Predefining prototypes simplifies training but locks in the geometric layout of classes; any poor choice is irreversible
  - Disentangling prototypes via factor encoding adds interpretability but may reduce accuracy if factors are incomplete
  - Using high-dimensional embeddings helps preserve separation but increases compute
- Failure signatures:
  - Loss plateaus early → prototypes too far or too restrictive for data manifold
  - Accuracy drops vs baseline → predefined prototypes misaligned with true data structure
  - Component parts of embeddings remain zero → factors not informative for task
- First 3 experiments:
  1. Replace predefined prototypes with learned prototypes and compare accuracy on ESC-50
  2. Vary the number of discretization levels for acoustic factors in emotion recognition and measure interpretability vs accuracy
  3. Test embedding orthogonality (e.g., cosine similarity between class means) to confirm separation benefit

## Open Questions the Paper Calls Out

### Open Question 1
How do predefined prototypes compare to trainable prototypes in terms of generalization to unseen data or new classes? The paper focuses on predefined prototypes for inter-class separation and disentanglement but does not directly compare their generalization capabilities to trainable prototypes. Experiments comparing predefined prototypes versus trainable prototypes on datasets with unseen classes or in few-shot learning scenarios would resolve this.

### Open Question 2
Can the proposed method be extended to multi-modal data (e.g., audio-visual or text-audio) while maintaining interpretability? The paper demonstrates disentanglement for audio features with respect to acoustic parameters but does not explore multi-modal extensions or their interpretability. Applying the predefined prototype method to multi-modal datasets and analyzing whether disentanglement and interpretability are preserved across modalities would resolve this.

### Open Question 3
How sensitive is the performance of predefined prototypes to the choice of variation factors in disentanglement tasks? The paper uses specific acoustic parameters (pitch median, pitch std, loudness) for disentanglement in emotion recognition but does not analyze how sensitive the results are to the choice of factors. Systematic ablation studies varying the number, type, and granularity of disentanglement factors would determine their impact on performance and interpretability.

## Limitations
- The disentanglement claims rely heavily on a single case study without systematic ablation or quantitative measures of interpretability
- Training pipeline simplification is claimed but not empirically validated through comparisons to learned prototype methods
- Method's performance depends critically on having informative factors for disentanglement, which may not generalize across all domains

## Confidence
- Mechanism 1 (Orthogonal prototypes for inter-class separation): High confidence - well-supported by theory and experimental results
- Mechanism 2 (Disentanglement via factor-dependent prototypes): Medium confidence - demonstrated in case study but lacks systematic validation
- Mechanism 3 (Training simplification): Low confidence - claimed but not empirically validated

## Next Checks
1. Conduct ablation studies comparing predefined orthogonal prototypes against learned prototypes on multiple datasets to quantify the separation benefit
2. Implement quantitative metrics for interpretability (e.g., factor predictability from embeddings) to systematically evaluate the disentanglement mechanism
3. Compare training dynamics and convergence speed between predefined and learned prototype approaches to validate the training simplification claim