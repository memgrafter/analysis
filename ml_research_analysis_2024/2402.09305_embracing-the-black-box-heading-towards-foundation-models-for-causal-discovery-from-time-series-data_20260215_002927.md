---
ver: rpa2
title: 'Embracing the black box: Heading towards foundation models for causal discovery
  from time series data'
arxiv_id: '2402.09305'
source_url: https://arxiv.org/abs/2402.09305
tags:
- causal
- data
- learning
- time
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Causal Pretraining, a supervised deep learning
  approach for causal discovery from time series data. The method learns an end-to-end
  mapping from multivariate time series to causal graphs, without relying on predefined
  causal discovery frameworks.
---

# Embracing the black box: Heading towards foundation models for causal discovery from time series data

## Quick Facts
- arXiv ID: 2402.09305
- Source URL: https://arxiv.org/abs/2402.09305
- Authors: Gideon Stein; Maha Shadaydeh; Joachim Denzler
- Reference count: 18
- Primary result: Introduces Causal Pretraining, a supervised deep learning approach that learns direct mapping from multivariate time series to causal graphs, with performance scaling with model size and data complexity.

## Executive Summary
This paper presents Causal Pretraining, a novel supervised deep learning methodology for causal discovery from time series data that bypasses traditional causal discovery frameworks. The approach learns an end-to-end mapping from multivariate time series to causal graphs without requiring parameter fitting during inference. Experiments on synthetic data demonstrate that performance scales with model size and data complexity, even when training and test distributions differ, suggesting the potential for foundation models in causal discovery.

## Method Summary
Causal Pretraining is a supervised deep learning approach that trains neural networks to directly map multivariate time series data to causal graphs represented as adjacency tensors. The method uses synthetic data generation with known causal structures to train models that can then be applied to real-world data in zero-shot settings. Multiple neural architectures (MLP, GRU variants, ConvMixer, Transformer) are evaluated, with performance measured using AUROC scores for causal link detection. The approach includes optional techniques like regression outputs and correlation regularization to stabilize learning and prevent trivial solutions.

## Key Results
- Causal Pretraining achieves strong performance on synthetic data when training and test data share similar dynamics
- Performance scales with both model size and data complexity, with extrapolation capabilities increasing even when keeping the same number of samples
- Outperforms baseline methods including correlation thresholding, VAR, and PCMCI on synthetic datasets
- Successfully applies to real-world river discharge and aerosol-cloud interaction datasets in zero-shot settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal Pretraining can learn to map multivariate time series to causal graphs without fitting parameters during inference.
- Mechanism: Supervised learning of a neural network that directly outputs a causal adjacency tensor, bypassing traditional causal discovery frameworks like Granger causality or score-based methods.
- Core assumption: The training and test time series share most of their underlying dynamics, and the structural equations follow a stable, directed acyclic graph (DAG) without instantaneous effects.
- Evidence anchors:
  - [abstract]: "A methodology that aims to learn a direct mapping from multivariate time series to the underlying causal graphs in a supervised manner."
  - [section]: "Causal Pretraining is not concerned with directly uncovering any causal graph G, but rather with producing a causally pretrained neural network (CPNN) in a supervised manner that can be applied in zero-shot settings."
  - [corpus]: Weak. Nearest neighbors discuss domain adaptation and causal discovery but do not directly address end-to-end supervised learning for causal discovery from time series.

### Mechanism 2
- Claim: Performance improves with model size and data complexity, even when training data extends beyond the test distribution.
- Mechanism: Scaling model parameters allows learning more complex and diverse causal relationships, improving generalization and robustness to out-of-distribution samples.
- Core assumption: The relationship between model capacity and data complexity is balanced; simply increasing parameters without increasing data complexity leads to overfitting.
- Evidence anchors:
  - [abstract]: "we found evidence that the performance of Causal Pretraining can increase with data and model size, even if the additional data do not share the same dynamics."
  - [section]: "We find that the parameter count of the model determines the ability to perform causal discovery properly... the extrapolation capabilities increase even when keeping the same number of data samples."
  - [corpus]: Weak. No direct evidence in corpus about scaling laws for causal discovery models.

### Mechanism 3
- Claim: Training with additional techniques (regression output, correlation regularization, correlation injection) stabilizes learning and encourages discovery of true causal links.
- Mechanism: Auxiliary tasks and regularization guide the network away from trivial solutions (e.g., predicting no edges) and help encode prior knowledge that correlation often implies causation.
- Core assumption: The regularization terms and auxiliary outputs are properly tuned and do not dominate the main task loss.
- Evidence anchors:
  - [section]: "We add an optional regression output that predicts the number of non-zero elements in A... To discourage this solution, we add an optional regression output... We introduce a regularization term called correlation regularization (CR)."
  - [abstract]: No direct mention, but implied by "we introduce and evaluate several helper techniques to support the performance of Causal Pretraining."
  - [corpus]: Weak. No direct mention of these specific techniques in related works.

## Foundational Learning

- Concept: Structural Equation Models (SEMs) for time series
  - Why needed here: The paper models causal relationships using time-invariant SEMs, where each variable is a function of past variables and noise.
  - Quick check question: In Equation 1, what does the tensor A represent, and how does it relate to the causal graph G?

- Concept: Directed Acyclic Graphs (DAGs) and causal sufficiency
  - Why needed here: The method assumes the causal graph is a DAG and all relevant causes are observed (causal sufficiency).
  - Quick check question: Why is the assumption of causal sufficiency important for the identifiability of the causal graph?

- Concept: Granger causality and score-based causal discovery
  - Why needed here: These are common baselines and frameworks that Causal Pretraining aims to bypass with end-to-end learning.
  - Quick check question: How does Granger causality differ from the direct mapping approach used in Causal Pretraining?

## Architecture Onboarding

- Component map:
  Input -> Neural Network (MLP, GRU, Transformer, ConvMixer) -> Causal adjacency tensor output (with optional regression head and correlation regularization)

- Critical path:
  1. Generate synthetic data with known causal graphs
  2. Train neural network to map time series to causal graphs
  3. Evaluate on in-distribution and out-of-distribution test sets
  4. Apply to real-world data in zero-shot setting

- Design tradeoffs:
  - Model size vs. data complexity: Larger models can capture more complex relationships but risk overfitting if data is not complex enough
  - Regularization strength: Too much regularization can hinder learning; too little can lead to trivial solutions
  - Architecture choice: Different architectures may perform better on different data distributions

- Failure signatures:
  - AUROC scores close to 0.5 (random guessing)
  - High variance in performance across runs
  - Degradation in performance on out-of-distribution data
  - Convergence to predicting no edges (trivial solution)

- First 3 experiments:
  1. Train on synthetic linear and nonlinear datasets with varying complexity; evaluate in-distribution and out-of-distribution performance
  2. Vary model size on a fixed dataset to identify scaling effects
  3. Apply pretrained models to real-world datasets (rivers, aerosol-cloud) in zero-shot setting

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the text provided.

## Limitations
- The method relies on strong assumptions including causal sufficiency and DAG structure, which may not hold in real-world systems with feedback loops or latent confounders
- Performance on real-world data remains preliminary with limited testing on just two datasets, raising questions about generalization to diverse domains
- The correlation between correlation and causation assumption embedded in regularization may fail in complex systems with multiple confounders

## Confidence
**High Confidence**: The end-to-end supervised learning framework is well-specified and in-distribution performance claims are supported by experimental results.

**Medium Confidence**: Scaling laws showing improved performance with larger models and more complex data are demonstrated but limited to synthetic domains.

**Low Confidence**: Regularization techniques and their effectiveness in preventing trivial solutions are described but not thoroughly validated.

## Next Checks
1. **Robustness to Assumption Violations**: Test Causal Pretraining on synthetic data where causal sufficiency is violated (latent confounders present) and where the DAG assumption is broken (feedback loops exist). Measure performance degradation and identify breaking points for each assumption.

2. **Scaling Law Validation**: Conduct systematic experiments varying both model size and data complexity independently to quantify their individual contributions to performance. Test whether the scaling relationships hold when the training data distribution differs substantially from the test distribution in terms of functional forms and variable interactions.

3. **Real-World Transfer Evaluation**: Apply Causal Pretraining to diverse real-world time series datasets with known or partially known causal structures (e.g., climate data, economic indicators, biological systems). Compare performance against established causal discovery methods across multiple domains and quantify the gap between synthetic and real-world performance.