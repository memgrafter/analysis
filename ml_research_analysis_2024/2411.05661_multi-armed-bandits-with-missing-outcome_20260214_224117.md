---
ver: rpa2
title: Multi-armed Bandits with Missing Outcome
arxiv_id: '2411.05661'
source_url: https://arxiv.org/abs/2411.05661
tags:
- missing
- regret
- reward
- have
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of missing outcomes in multi-armed
  bandits, a critical issue in real-world decision-making scenarios like clinical
  trials and online recommendations. The authors formalize different missing data
  mechanisms, including Missing Completely At Random (MCAR), Missing At Random (MAR),
  and Missing Not At Random (MNAR), and provide regret analysis and algorithms for
  each setting.
---

# Multi-armed Bandits with Missing Outcome

## Quick Facts
- arXiv ID: 2411.05661
- Source URL: https://arxiv.org/abs/2411.05661
- Authors: Ilia Mahrooghi; Mahshad Moradi; Sina Akbari; Negar Kiyavash
- Reference count: 40
- One-line primary result: This paper addresses the challenge of missing outcomes in multi-armed bandits, providing regret analysis and algorithms for MCAR, MAR, and MNAR settings with near-optimal bounds.

## Executive Summary
This paper tackles the critical challenge of missing outcomes in multi-armed bandit settings, which frequently arise in real-world applications like clinical trials and online recommendations. The authors formalize three missing data mechanisms - MCAR (Missing Completely At Random), MAR (Missing At Random), and MNAR (Missing Not At Random) - and develop corresponding upper confidence bound (UCB) algorithms that explicitly account for these mechanisms. Their approach provides theoretically grounded methods for unbiased reward estimation despite missing observations.

The work demonstrates that standard bandit algorithms perform poorly when outcomes are missing, showing linear regret growth compared to the sublinear growth achieved by the proposed methods. Through both theoretical analysis and empirical evaluation, the paper establishes that their algorithms achieve near-optimal regret bounds while maintaining computational feasibility, making them practical for real-world deployment in domains where data incompleteness is a fundamental challenge.

## Method Summary
The core method involves developing specialized UCB algorithms that incorporate missingness mechanisms into the reward estimation process. For MCAR, the algorithm uses simple empirical averages while accounting for the probability of missingness. For MAR, the approach leverages auxiliary variables (mediators) to compute conditional expectations of rewards, effectively reconstructing expected values despite missing outcomes. The most sophisticated approach addresses MNAR through a completeness assumption and integral equation solving to identify reward distributions. The algorithms are designed to provide unbiased estimates by explicitly modeling the missingness mechanism rather than treating missing data as censoring or ignoring it entirely.

## Key Results
- The proposed algorithms achieve O(√(nT log(T))) regret bounds for MCAR and MAR settings, matching near-optimal minimax lower bounds
- For MNAR settings, the algorithm achieves O(√(nT log(T)/S²a)) regret bounds under completeness assumptions
- Empirical evaluations show significant performance improvements over naive UCB algorithms, with regret curves demonstrating linear growth for UCB versus sublinear growth for the proposed methods
- The algorithms are extended to handle missing mediators, broadening applicability to more complex real-world scenarios

## Why This Works (Mechanism)
The algorithms work by explicitly modeling the missingness mechanism rather than treating missing data as censoring or ignoring it. In MCAR, the probability of missingness is independent of rewards, allowing straightforward adjustment of estimates. For MAR, auxiliary variables provide information about the missingness pattern, enabling conditional expectation calculations to recover expected rewards. The MNAR approach leverages completeness assumptions and integral equations to identify the underlying reward distributions despite the missingness being dependent on unobserved rewards themselves.

## Foundational Learning
**Multi-armed Bandit Regret**: The cumulative loss from not always selecting the optimal arm. Needed because performance in bandit problems is measured by how quickly algorithms identify the best arm. Quick check: Compare cumulative reward of proposed algorithm versus oracle that always selects optimal arm.

**Missing Data Mechanisms**: MCAR, MAR, and MNAR represent different ways data can be missing. MCAR means missingness is independent of all variables; MAR means missingness depends only on observed variables; MNAR means missingness depends on unobserved values. Quick check: Verify which mechanism applies by testing whether missingness correlates with observed or unobserved variables.

**Completeness Assumption**: In MNAR settings, this assumption ensures that auxiliary variables contain sufficient information to identify the underlying reward distributions. Needed because without it, the integral equations cannot be uniquely solved. Quick check: Test whether auxiliary variables have sufficient variation and correlation with rewards to satisfy completeness.

**Upper Confidence Bounds**: A bandit algorithm framework that balances exploration and exploitation by maintaining confidence intervals around reward estimates. Needed to provide theoretical guarantees on regret bounds. Quick check: Verify confidence bounds shrink appropriately with sample size.

**Integral Equation Solving**: The mathematical technique used to identify reward distributions in MNAR settings by solving Fredholm equations of the first kind. Needed because direct estimation is impossible when missingness depends on unobserved rewards. Quick check: Test numerical stability and convergence of the integral equation solver.

## Architecture Onboarding

**Component Map**: UCB Estimator -> Missingness Model -> Reward Estimator -> Arm Selector -> Environment Feedback -> Data Storage

**Critical Path**: The algorithm receives arm pulls and observed rewards (with missingness), updates the missingness model, computes adjusted reward estimates using the appropriate mechanism (MCAR/MAR/MNAR), maintains UCB statistics, and selects the next arm based on optimistic estimates.

**Design Tradeoffs**: The main tradeoff is between theoretical guarantees and computational complexity. MCAR and MAR algorithms are computationally efficient with simple updates, while MNAR requires solving integral equations which is computationally intensive but necessary for the general case. The completeness assumption in MNAR represents a theoretical convenience that may not hold in practice.

**Failure Signatures**: Poor performance manifests as linear regret growth similar to naive UCB, indicating the algorithm fails to properly account for missingness. For MAR, failure occurs when auxiliary variables are insufficient or noisy. For MNAR, failure indicates violation of completeness assumptions or numerical instability in integral equation solving.

**First 3 Experiments**: 1) Test MCAR algorithm on synthetic data with known missingness probability to verify O(√(nT log(T))) regret bound. 2) Evaluate MAR algorithm with varying levels of mediator noise to assess robustness. 3) Implement MNAR algorithm on simulated clinical trial data to validate completeness assumption and integral equation solving.

## Open Questions the Paper Calls Out
None

## Limitations
- The MNAR setting requires strong completeness assumptions that may not hold in many real-world scenarios
- Algorithm performance heavily depends on the accuracy and availability of mediator variables in MAR settings
- Theoretical regret bounds may not translate perfectly to practical settings due to computational complexity of solving integral equations
- Limited experimental scope focused primarily on synthetic scenarios rather than diverse real-world applications

## Confidence
- MCAR/MAR regret bounds: High - The theoretical analysis is rigorous and supported by established techniques in bandit literature
- MNAR completeness assumption: Medium - While theoretically sound, this assumption may be violated in practice
- Empirical performance claims: Medium - Limited experimental scope with focus on synthetic scenarios

## Next Checks
1. Test algorithm performance with varying levels of mediator noise to assess robustness in MAR setting
2. Implement the MNAR algorithm on real-world clinical trial data to validate the completeness assumption
3. Compare computational efficiency and runtime performance against naive UCB baseline across different problem scales