---
ver: rpa2
title: 'Counterfactual contrastive learning: robust representations via causal image
  synthesis'
arxiv_id: '2403.09605'
source_url: https://arxiv.org/abs/2403.09605
tags:
- counterfactual
- training
- image
- learning
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces CF-SimCLR, a method that combines counterfactual\
  \ image generation with contrastive learning to improve robustness to domain shifts\
  \ in medical imaging. Instead of using standard augmentation techniques, CF-SimCLR\
  \ leverages counterfactual images\u2014realistic \u201Cwhat-if\u201D versions of\
  \ scans from different scanners\u2014to create cross-domain positive pairs during\
  \ pretraining."
---

# Counterfactual contrastive learning: robust representations via causal image synthesis

## Quick Facts
- arXiv ID: 2403.09605
- Source URL: https://arxiv.org/abs/2403.09605
- Authors: Melanie Roschewitz; Fabio De Sousa Ribeiro; Tian Xia; Galvin Khara; Ben Glocker
- Reference count: 33
- Key outcome: CF-SimCLR improves robustness to domain shifts in medical imaging by using counterfactual image generation for cross-domain positive pairs in contrastive learning

## Executive Summary
This paper introduces CF-SimCLR, a method that combines counterfactual image generation with contrastive learning to improve robustness to domain shifts in medical imaging. Instead of using standard augmentation techniques, CF-SimCLR leverages counterfactual images—realistic "what-if" versions of scans from different scanners—to create cross-domain positive pairs during pretraining. This approach teaches models to focus on semantic content while ignoring domain-specific variations. Experiments across chest radiography and mammography datasets show that CF-SimCLR consistently outperforms standard SimCLR and SimCLR+ (which simply adds counterfactuals without explicit pairing) in both in-distribution and out-of-distribution settings. Gains are especially strong for under-represented scanners and limited label scenarios. Qualitative analysis confirms CF-SimCLR produces more domain-invariant embeddings. The method is efficient, requiring only modest computational overhead compared to standard contrastive pretraining.

## Method Summary
CF-SimCLR is a contrastive learning framework that uses counterfactual image generation to create cross-domain positive pairs. The method trains a counterfactual image generation model using a Deep Structural Causal Model (DSCM) with a Hierarchical Variational Autoencoder (HVAE) backbone, conditioned on scanner variables. During contrastive pretraining, each original image is paired with its counterfactual counterpart as positive pairs, while the contrastive loss encourages the encoder to align representations across scanner domains. The approach builds on SimCLR's framework but modifies the positive pair generation to explicitly create domain-invariant representations. The method is evaluated through linear probing and finetuning on downstream classification tasks including pneumonia detection and breast density classification across multiple medical imaging datasets.

## Key Results
- CF-SimCLR consistently outperforms standard SimCLR and SimCLR+ in both in-distribution and out-of-distribution settings across chest radiography and mammography datasets
- Performance gains are especially strong for under-represented scanners and limited label scenarios
- Qualitative analysis shows CF-SimCLR produces more domain-invariant embeddings with less domain clustering compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CF-SimCLR improves robustness by explicitly aligning representations across scanner domains through counterfactual-based positive pairs.
- Mechanism: The counterfactual image generation model creates realistic "what-if" versions of images from different scanners. By pairing each original image with its domain counterfactual during contrastive learning, the model is trained to minimize the distance between these cross-domain views while maximizing distance from unrelated samples. This explicit pairing forces the encoder to learn features invariant to scanner-specific characteristics.
- Core assumption: The counterfactual generation model can produce realistic images that fool domain classifiers and preserve semantic content while changing only scanner-related attributes.
- Evidence anchors:
  - [abstract] "leverages approximate counterfactual inference for positive pair creation" and "substantially improves robustness to acquisition shift"
  - [section] "the counterfactual contrastive objective encourages explicit alignment of domains in the learned representation"
  - [corpus] Weak - related work on counterfactual contrastive learning exists but focuses on different domains (vision-language, graphs)

### Mechanism 2
- Claim: Adding counterfactuals to training without explicit pairing (SimCLR+) provides inconsistent benefits compared to CF-SimCLR.
- Mechanism: Simply augmenting the training set with counterfactual images treats them as independent samples rather than as paired views of the same underlying content. Without explicit pairing, the model may not learn to align representations across domains effectively, resulting in domain clusters in the embedding space.
- Core assumption: The contrastive loss requires explicit pairing to enforce domain invariance; random sampling of positive pairs is insufficient for cross-domain alignment.
- Evidence anchors:
  - [section] "CF-SimCLR performed consistently better than SimCLR+ where the model is trained on the augmented training set" and "performance gains are not consistent and not as large as for models trained with CF-SimCLR"
  - [section] "models trained with SimCLR as well as SimCLR+ depict very clear domain separation in their t-SNE plots, whereas for CF-SimCLR embeddings appear much less domain-separated"
  - [corpus] Missing - no direct evidence in corpus about pairing vs non-pairing approaches

### Mechanism 3
- Claim: CF-SimCLR is particularly effective for under-represented scanners and limited label scenarios.
- Mechanism: The explicit cross-domain pairing helps the model learn robust features that generalize across scanners, especially when some scanners have limited training data. This prevents the model from overfitting to dominant scanner characteristics and improves transfer learning performance.
- Core assumption: Domain-specific variations are the primary source of domain shift in medical imaging, and learning invariant features is more beneficial than learning scanner-specific ones when some domains are under-represented.
- Evidence anchors:
  - [abstract] "particularly for domains which are under-represented during training" and "improves robustness to acquisition shift"
  - [section] "Performance gains are especially strong for under-represented scanners and limited label scenarios" and "on the under-represented OOD scanner (PlanMed Nuance) CF-SimCLR performs better by a substantial margin"
  - [corpus] Weak - related work exists on robustness and under-representation but not specifically through counterfactual contrastive learning

## Foundational Learning

- Concept: Causal inference and structural causal models (SCMs)
  - Why needed here: The paper relies on counterfactual image generation based on causal graphs, specifically using Deep Structural Causal Models (DSCM) to generate realistic "what-if" images by intervening on scanner variables.
  - Quick check question: What is the difference between a causal intervention and a simple data augmentation, and why does this matter for generating counterfactual images?

- Concept: Contrastive learning and the InfoNCE loss
  - Why needed here: CF-SimCLR builds upon SimCLR's framework, using positive pairs (original images and their counterfactuals) and negative pairs to learn representations that preserve semantic information while discarding domain-specific details.
  - Quick check question: How does the contrastive loss function encourage the model to learn domain-invariant features when positive pairs come from different scanners?

- Concept: Domain adaptation and generalization
  - Why needed here: The paper addresses acquisition shift - differences in images due to different scanners - which is a form of domain shift. Understanding how models generalize across domains is crucial for interpreting the results.
  - Quick check question: What makes acquisition shift particularly challenging in medical imaging compared to natural image domains?

## Architecture Onboarding

- Component map:
  - Counterfactual image generation (DSCM with HVAE) -> Contrastive learning framework (SimCLR) -> Encoder (ResNet-50) -> Downstream evaluation (linear probing and finetuning)

- Critical path:
  1. Train counterfactual generation model on pretraining dataset with scanner labels
  2. Generate counterfactual images for each training sample
  3. During contrastive pretraining, pair each original image with its counterfactual as positive pairs
  4. Train encoder using SimCLR loss with these cross-domain positive pairs
  5. Evaluate on downstream tasks with linear probing and finetuning

- Design tradeoffs:
  - Computational cost: Training counterfactual generation adds overhead but is offset by faster pretraining convergence
  - Generation quality vs. faithfulness: Higher quality generation may trade off with faithfulness to counterfactual conditioning
  - Scanner coverage: Need sufficient diversity in scanners during pretraining to generate meaningful counterfactuals

- Failure signatures:
  - Poor generation quality: Counterfactual images don't look realistic or don't fool domain classifiers
  - Domain clustering: t-SNE plots show clear separation by scanner despite CF-SimCLR training
  - Limited improvement: No significant difference between CF-SimCLR and SimCLR+ performance
  - Overfitting: Model performs well on pretraining scanners but poorly on OOD datasets

- First 3 experiments:
  1. Train counterfactual generation model on PadChest dataset and qualitatively evaluate generated images across scanner pairs
  2. Run CF-SimCLR pretraining with linear evaluation on in-distribution test set to verify improvement over SimCLR
  3. Test transfer learning performance on external datasets (RSNA, CheXpert, VinDR) to confirm OOD generalization benefits

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out specific open questions, but based on the limitations section, several avenues for future research are implied.

## Limitations
- Counterfactual generation quality depends heavily on training data diversity and may produce unrealistic images for underrepresented scanner combinations
- Method requires additional computational resources for training the counterfactual generation model
- Uncertain scalability to extremely large-scale pretraining scenarios and generalizability beyond medical imaging domains

## Confidence
- High confidence in the core mechanism of using counterfactual pairs for domain alignment
- Medium confidence in the consistent performance improvements across all datasets
- Medium confidence in the specific advantages for under-represented scanners
- Low confidence in the scalability to extremely large-scale pretraining scenarios

## Next Checks
1. **Generation Quality Validation**: Systematically evaluate counterfactual image quality using both quantitative metrics (domain classifier fooling rate) and qualitative assessments across all scanner pairs to ensure realistic domain simulation.

2. **Ablation Studies**: Conduct controlled experiments removing the counterfactual generation step entirely vs. keeping it to isolate the specific contribution of counterfactuals versus other SimCLR components.

3. **Cross-Domain Generalization**: Test the pretrained models on entirely different medical imaging modalities or natural image datasets to assess the broader applicability of the domain invariance learned through CF-SimCLR.