---
ver: rpa2
title: Online Posterior Sampling with a Diffusion Prior
arxiv_id: '2410.03919'
source_url: https://arxiv.org/abs/2410.03919
tags:
- prior
- diffusion
- posterior
- sampling
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of posterior sampling in contextual
  bandits with complex priors, specifically using diffusion models. The authors propose
  an efficient algorithm, LaplaceDPS, that approximates the posterior by sampling
  from a chain of conditional posteriors, one for each stage of the reverse diffusion
  process.
---

# Online Posterior Sampling with a Diffusion Prior

## Quick Facts
- **arXiv ID**: 2410.03919
- **Source URL**: https://arxiv.org/abs/2410.03919
- **Reference count**: 40
- **Primary result**: LaplaceDPS uses diffusion models as priors in contextual bandits, achieving asymptotically consistent posterior sampling through Laplace approximations of conditional posteriors

## Executive Summary
This paper addresses the challenge of posterior sampling in contextual bandits when using complex priors, specifically diffusion models. The authors propose LaplaceDPS, an algorithm that efficiently approximates the posterior by sampling from a chain of conditional posteriors across the reverse diffusion process stages. Each conditional is estimated using the Laplace approximation, combining prior knowledge with empirical evidence. The method is asymptotically consistent and demonstrates superior performance compared to baselines like Thompson Sampling and DPS, particularly in scenarios with complex or multimodal priors.

## Method Summary
LaplaceDPS addresses posterior sampling in contextual bandits with diffusion model priors by approximating the posterior through a chain of conditional distributions across T stages of the reverse diffusion process. The algorithm uses the Laplace approximation to estimate each conditional posterior, mixing prior knowledge with empirical evidence. This approach avoids the instability issues of gradient-based methods while maintaining computational efficiency. The method is applied to both linear and generalized linear models, with IRLS used for the GLM case.

## Key Results
- LaplaceDPS achieves asymptotically consistent posterior sampling, with conditional posteriors concentrating around true parameters as observations increase
- Outperforms baselines (TS, TunedTS, MixTS, DPS) on synthetic 2D problems and MovieLens dataset
- Maintains stable performance across different levels of uncertainty, unlike DPS which diverges with increasing observations
- Computational cost is T times higher than Gaussian prior sampling but provides better representation of complex prior distributions

## Why This Works (Mechanism)

### Mechanism 1
LaplaceDPS maintains asymptotic consistency by ensuring conditional posteriors concentrate around the true parameter as observations increase. The algorithm samples from a chain of approximate conditional posteriors, each estimated using Laplace approximation. As observations grow, empirical evidence dominates, causing concentration. This relies on the assumption that λd(Σ̄⁻¹) → ∞ as N → ∞.

### Mechanism 2
The algorithm approximates the posterior by treating the diffusion model prior as a product of conditional distributions. Each stage t involves sampling St-1 from N(μ̂t(st,h), Σ̂t(h)), mixing conditional prior and diffused evidence. This approximation ∫s0 p(h|s0)p(s0|st)ds0 ≈ p(h|st/√ᾱt) allows incorporation of complex priors while maintaining efficiency.

### Mechanism 3
LaplaceDPS outperforms DPS by avoiding instability from the likelihood score ∇log p(h|θ) growing with observations. Instead of adding the score to the diffusion model posterior, LaplaceDPS uses the product of prior and evidence distributions, providing a gradient-free approach that ensures stability across uncertainty levels without requiring problematic hyper-parameter tuning.

## Foundational Learning

- **Diffusion models and reverse process**: Needed to understand how LaplaceDPS samples from the diffusion model prior by reversing the forward process. Quick check: What's the key difference between forward and reverse processes in diffusion models?
- **Laplace approximation for posterior inference**: Essential for estimating each conditional posterior efficiently in the reverse process. Quick check: How does Laplace approximation work and what are its key assumptions?
- **Thompson sampling in contextual bandits**: Crucial for understanding how LaplaceDPS applies posterior sampling to balance exploration and exploitation. Quick check: What's the key idea behind Thompson sampling?

## Architecture Onboarding

- **Component map**: Diffusion model prior -> Reverse process -> Conditional posteriors -> Laplace approximation -> Thompson sampling
- **Critical path**: Forward process → Learn reverse process → Sample from reverse process → Apply Laplace approximation → Sample from conditional posteriors → Thompson sampling
- **Design tradeoffs**: Computational cost vs. accuracy (more stages T improves quality but increases cost); Prior complexity vs. sample efficiency (complex priors improve performance but require more samples); Laplace approximation vs. other methods (computationally efficient but may not capture all posterior aspects)
- **Failure signatures**: Algorithm divergence if conditional posteriors fail to concentrate; Poor performance on simple problems if prior is too complex; Sensitivity to hyper-parameters T and others
- **First 3 experiments**: 1) Implement LaplaceDPS for simple linear bandit with Gaussian prior vs. standard Thompson sampling; 2) Extend to contextual bandit with complex prior and evaluate against existing methods; 3) Investigate impact of T on computational cost and performance by varying T and measuring regret/runtime

## Open Questions the Paper Calls Out

### Open Question 1
How does computational cost scale with T and d? The paper states LaplaceDPS should be T times more costly than Gaussian prior sampling but only provides a single data point without exploring scaling with different T and d values.

### Open Question 2
What's the impact of learned prior quality on DiffTS performance and how many training samples are needed? The ablation study varies training samples from 100 to 10,000 on one problem and metric, leaving generalization unclear.

### Open Question 3
How does DiffTS compare to other diffusion model posterior sampling methods like sequential Monte Carlo and pseudo-inverse approximations? The paper mentions these methods become unstable but doesn't provide direct comparison.

### Open Question 4
Can the approach extend to observation models beyond GLMs like deep neural networks? The paper suggests it can be applied to any model where likelihood can be approximated by a single Gaussian but provides no experiments or analysis beyond GLMs.

## Limitations
- Effectiveness depends on Laplace approximation quality, which may break down for highly non-Gaussian posteriors or insufficient data
- Computational cost scales linearly with diffusion stages T, potentially prohibitive for very complex priors
- Asymptotic consistency proof assumes λd(Σ̄⁻¹) → ∞, which may not hold in practice for all parameter directions

## Confidence

- **High confidence**: Asymptotic consistency result and core algorithmic framework; empirical superiority over baselines on synthetic and real-world datasets
- **Medium confidence**: Laplace approximation quality for each conditional posterior may vary depending on problem structure and data availability
- **Low confidence**: Computational complexity claims are vague - stated to be "significantly higher" but exact scaling and practical implications not thoroughly characterized

## Next Checks

1. Test algorithm's robustness to initialization and hyper-parameter choices (T, αt) across diverse problem settings
2. Quantify Laplace approximation error for different conditional posteriors and assess impact on final performance
3. Conduct ablation studies to isolate contribution of diffusion model prior versus Laplace approximation to performance gains