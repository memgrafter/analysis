---
ver: rpa2
title: 'Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual
  Embedding Inversion Attacks'
arxiv_id: '2408.11749'
source_url: https://arxiv.org/abs/2408.11749
tags:
- language
- languages
- inversion
- corrector
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates embedding inversion attacks on multilingual
  LLMs across 20 languages from 8 families and 12 scripts. The core method uses a
  text-to-text generation approach to reconstruct original text from embeddings, with
  progressive refinement through corrector steps.
---

# Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks

## Quick Facts
- **arXiv ID**: 2408.11749
- **Source URL**: https://arxiv.org/abs/2408.11749
- **Reference count**: 13
- **Primary result**: Arabic and Cyrillic scripts, and Indo-Aryan languages, are most vulnerable to embedding inversion attacks; language confusion is predictable using linguistic features, enabling attackers to improve success rates.

## Executive Summary
This study investigates embedding inversion attacks on multilingual LLMs across 20 languages from 8 families and 12 scripts. The core method uses a text-to-text generation approach to reconstruct original text from embeddings, with progressive refinement through corrector steps. Results show Arabic and Cyrillic scripts, and Indo-Aryan languages, are most vulnerable. Language confusion is identified as a key bottleneck, but is predictable using linguistic features, enabling attackers to improve success rates. Multilingual embeddings are generally more vulnerable than monolingual ones, and in-script/in-family training boosts attack performance. The study emphasizes that multilingual LLM security requires diverse language coverage to protect low-resource and marginalized language communities.

## Method Summary
The study employs a text-to-text generation approach to reconstruct original text from embeddings, using a base model trained for 100 epochs followed by corrector steps with iterative refinement. The methodology evaluates inversion attack success using BLEU, ROUGE, Token F1 (TF1), and cosine similarity metrics. Language confusion is analyzed using off-the-shelf LID tools at word and line levels. Random Forest regression is used to predict language confusion patterns based on linguistic features. The experiments compare monolingual versus multilingual models, in-script versus in-family training, and control group combinations using the CulturaX dataset with 600K-1M samples per language.

## Key Results
- Arabic and Cyrillic scripts, and Indo-Aryan languages, show highest vulnerability to embedding inversion attacks
- Language confusion can be predicted using linguistic features, enabling attackers to improve success rates
- Multilingual embeddings are generally more vulnerable than monolingual ones
- In-script training significantly boosts attack performance (e.g., doubling BLEU score for Urdu)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Embedding inversion attacks are more successful when training data shares script or language family with the target language.
- Mechanism: Shared script/language family increases the model's ability to generate coherent text in the target language by leveraging shared subword patterns and structural similarities.
- Core assumption: The inversion model benefits from cross-linguistic transfer, which is stronger within the same script or family.
- Evidence anchors:
  - [abstract] "In-script training boosts Urdu inversion attack performance, doubling the BLEU score."
  - [section] "Training the embedding inversion model with languages from the same language family significantly enhances performance."
  - [corpus] Found 25 related papers; strongest evidence from "Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis" (FMR=0.674) suggests typological factors matter.
- Break condition: If the shared script/family provides no meaningful subword overlap or structural similarity, transfer gains diminish.

### Mechanism 2
- Claim: Language confusion can be predicted and controlled by attackers using linguistic features.
- Mechanism: Linguistic features such as script directionality, word order, and family membership allow attackers to anticipate which languages the inversion model will confuse and adjust training accordingly.
- Core assumption: The inversion model's language confusion behavior is systematic and correlates with linguistic characteristics.
- Evidence anchors:
  - [abstract] "Language confusion can be predicted using linguistic features...enabling attackers to improve success rates."
  - [section] "Using Random Forest Regression, we predict the probabilities of the languages in which the inverted embeddings are decoded based on linguistic features."
  - [corpus] "Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation" (FMR=0.637) supports that confusion is controllable.
- Break condition: If the inversion model's behavior is dominated by noise or idiosyncratic training effects, prediction accuracy drops.

### Mechanism 3
- Claim: Multilingual embeddings are generally more vulnerable to inversion attacks than monolingual embeddings.
- Mechanism: Multilingual embeddings lack language-specific subspaces, making them more susceptible to cross-lingual confusion and reconstruction errors.
- Core assumption: The absence of strict language separation in multilingual embeddings increases inversion success.
- Evidence anchors:
  - [abstract] "Multilingual embeddings are generally more vulnerable than monolingual ones."
  - [section] "While the performance improve steadily across languages...ME5 is more vulnerable compared to MONO LLMs."
  - [corpus] No strong direct evidence; corpus search returned mostly unrelated papers (average FMR=0.499, zero citations).
- Break condition: If the multilingual model uses strict language separation or strong language-specific regularization, vulnerability decreases.

## Foundational Learning

- Concept: Cross-lingual transfer learning
  - Why needed here: Inversion attacks exploit shared linguistic patterns across languages; understanding transfer helps predict success.
  - Quick check question: What is the difference between positive and negative transfer in cross-lingual settings?

- Concept: Language confusion in LLMs
  - Why needed here: Confusion determines attack success; predicting it is key to effective exploitation.
  - Quick check question: How does word order differ between SOV and SVO languages, and why does this matter for generation?

- Concept: Subword tokenization and script uniformity
  - Why needed here: Subword allocation across scripts affects model's ability to generalize or confuse languages.
  - Quick check question: Why might languages sharing a script (e.g., Arabic vs. Urdu) have higher transfer rates?

## Architecture Onboarding

- Component map:
  - Text-to-text inversion model (T5/MT5) → base + corrector steps → hypothesis embeddings → reconstruction
  - Black-box encoder (ME5/GTR) → embeddings → inversion input
  - Linguistic feature extractor → Random Forest predictor → confusion probabilities
- Critical path:
  1. Train inversion model on paired languages (same script/family)
  2. Use corrector steps to refine output
  3. Predict confusion probabilities using linguistic features
  4. Adjust training data based on predictions
- Design tradeoffs:
  - More paired languages → better transfer but higher compute cost
  - Deeper corrector steps → better reconstruction but slower inference
  - Feature-rich confusion model → better predictions but more engineering overhead
- Failure signatures:
  - Low BLEU/TF1 scores despite same-script training → subword overlap insufficient
  - High variance in confusion predictions → linguistic features not capturing behavior
  - No improvement from corrector steps → model stuck in local minima
- First 3 experiments:
  1. Train inversion model on German + Turkish (same script, different families) and evaluate confusion.
  2. Compare inversion success on Urdu with and without Arabic script training data.
  3. Train a Random Forest predictor using script directionality and word order to forecast confusion for Hindi inversion.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic features (beyond script and family) most strongly predict language confusion in embedding inversion attacks?
- Basis in paper: [explicit] The paper states that features like script-directionality (LR) and word order (WO) were used as control variables in predicting language confusion, and Fig. 2 shows these features consistently rendered better predictions across LLMs and levels.
- Why unresolved: While the paper identifies several linguistic features used in prediction, it doesn't provide a detailed analysis of which features are most predictive or how they interact with each other.
- What evidence would resolve it: A systematic ablation study showing the predictive power of individual linguistic features, or a machine learning model that quantifies feature importance for predicting language confusion.

### Open Question 2
- Question: How does the vulnerability of multilingual LLMs to embedding inversion attacks compare when using real-world, non-parallel text data versus curated parallel datasets?
- Basis in paper: [explicit] The paper mentions that previous studies on embedding inversion have relied on parallel data, which precludes studying information leakage across languages. The authors use CulturaX dataset which contains clean and deduplicated data from 167 languages.
- Why unresolved: The paper uses CulturaX dataset but doesn't explicitly compare the vulnerability of multilingual LLMs using parallel versus non-parallel data.
- What evidence would resolve it: Experiments comparing attack success rates using both parallel and non-parallel datasets across the same set of languages.

### Open Question 3
- Question: What is the trade-off between LLM performance and vulnerability to embedding inversion attacks when training on diverse language combinations?
- Basis in paper: [inferred] The paper discusses how training on language pairs from different scripts and families makes LLMs more robust against inversion attacks, but mentions that the trade-off between vulnerabilities and performance still needs investigation.
- Why unresolved: The paper identifies a potential trade-off but doesn't provide empirical evidence or analysis of how model performance is affected by increased security through diverse training data.
- What evidence would resolve it: Performance benchmarks comparing multilingual LLMs trained on homogeneous versus diverse language sets, measuring both task performance and vulnerability to inversion attacks.

## Limitations
- Data availability constraints for low-resource languages may limit generalizability of results
- Assumes linguistic features alone can predict language confusion patterns, potentially missing model-specific idiosyncrasies
- Focus on text-to-text inversion may not generalize to other embedding architectures or attack vectors

## Confidence

- **High confidence**: Multilingual embeddings show greater vulnerability than monolingual ones; shared script/language family training improves attack success
- **Medium confidence**: Language confusion is predictable using linguistic features; in-script/in-family training boosts performance
- **Low confidence**: The exact relationship between specific linguistic features and confusion patterns; generalizability to other embedding models

## Next Checks
1. Test inversion success rates when training on German + Turkish (same script, different families) to validate transfer learning predictions
2. Compare inversion performance on Urdu with and without Arabic script training data to verify in-script benefits
3. Train and evaluate a Random Forest predictor using script directionality and word order to forecast Hindi inversion confusion patterns