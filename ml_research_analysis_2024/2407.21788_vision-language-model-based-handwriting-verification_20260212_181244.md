---
ver: rpa2
title: Vision-Language Model Based Handwriting Verification
arxiv_id: '2407.21788'
source_url: https://arxiv.org/abs/2407.21788
tags:
- handwriting
- cedar
- verification
- paligemma
- gpt-4o
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the application of Vision-Language Models
  (VLMs) for handwriting verification in document forensics, addressing the interpretability
  limitations of traditional deep learning approaches. The authors compare 0-shot
  Chain-of-Thought (CoT) prompt engineering with GPT-4o and supervised fine-tuned
  PaliGemma against CNN-based ResNet-18 baselines on the CEDAR handwriting dataset.
---

# Vision-Language Model Based Handwriting Verification

## Quick Facts
- arXiv ID: 2407.21788
- Source URL: https://arxiv.org/abs/2407.21788
- Authors: Mihir Chauhan; Abhishek Satbhai; Mohammad Abuzar Hashemi; Mir Basheer Ali; Bina Ramamurthy; Mingchen Gao; Siwei Lyu; Sargur Srihari
- Reference count: 2
- Key outcome: VLMs show promise for generating human-interpretable decisions in handwriting verification but require further refinement to match the performance of task-specific deep learning architectures.

## Executive Summary
This study investigates Vision-Language Models (VLMs) for handwriting verification in document forensics, addressing the interpretability limitations of traditional deep learning approaches. The authors compare 0-shot Chain-of-Thought (CoT) prompt engineering with GPT-4o and supervised fine-tuned PaliGemma against CNN-based ResNet-18 baselines on the CEDAR handwriting dataset. While VLMs demonstrate enhanced interpretability and adaptability to diverse handwriting styles, they underperform compared to specialized deep learning models, with GPT-4o achieving 70% accuracy and PaliGemma 71%, versus ResNet-18's 84% accuracy. These results indicate that VLMs show promise for generating human-interpretable decisions but require further refinement to match the performance of task-specific deep learning architectures in handwriting verification tasks.

## Method Summary
The study compares VLMs (GPT-4o with 0-shot CoT prompt engineering and PaliGemma with 0-shot and supervised fine-tuning on 100 examples) against CNN baselines (ResNet-18, GSC features, ViT) on the CEDAR handwriting dataset. The VLMs are evaluated for their ability to perform handwriting verification while providing human-interpretable explanations and identifying coordinates of similarities and dissimilarities in handwriting samples. The CNN baselines are trained on 10% and 100% of training pairs using categorical cross-entropy loss.

## Key Results
- VLMs achieve 70% (GPT-4o) and 71% (PaliGemma) accuracy on CEDAR AND dataset, compared to ResNet-18's 84% accuracy
- VLMs provide human-interpretable explanations through Chain-of-Thought reasoning, though their accuracy lags behind specialized CNNs
- Fine-tuning PaliGemma on 100 curated examples shows potential for performance improvement over zero-shot baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VLMs can generate human-interpretable explanations for handwriting verification decisions.
- Mechanism: VLMs leverage their Visual Question Answering (VQA) capabilities and Chain-of-Thought (CoT) reasoning to produce natural language explanations that describe the similarities and differences between questioned and known handwriting samples.
- Core assumption: The pre-training of VLMs on diverse handwritten images and natural language understanding enables them to effectively transfer this knowledge to forensic handwriting verification tasks without extensive task-specific training.
- Evidence anchors:
  - [abstract] "VLMs offer enhanced interpretability, reduce the need for large training datasets, and adapt better to diverse handwriting styles"
  - [section] "Using their API, we prompt GPT-4o [gpt, 2024] with 0-shot Chain-of-Thought (CoT) reasoning. This approach allows us to first generate human-interpretable explanations and then determine whether the given questioned and known handwritten samples were written by the same person or by different writers"
  - [corpus] Weak evidence - corpus contains related work on VLMs for educational assessment and handwriting recognition, but no direct evidence of interpretability mechanisms in forensics
- Break condition: If the VLM fails to identify relevant visual features in handwriting samples, the generated explanations will be meaningless or incorrect, breaking the interpretability chain.

### Mechanism 2
- Claim: VLMs can adapt to handwriting verification tasks through transfer learning without extensive training data.
- Mechanism: VLMs leverage their pre-training on multimodal data to understand the relationships between visual features in handwriting and their linguistic descriptions, allowing them to perform verification tasks with minimal or zero-shot examples.
- Core assumption: The multimodal pre-training of VLMs has exposed them to sufficient handwritten text and image-text pairs that they can generalize to forensic handwriting verification without task-specific training.
- Evidence anchors:
  - [abstract] "VLMs offer enhanced interpretability, reduce the need for large training datasets, and adapt better to diverse handwriting styles"
  - [section] "Fine-tuning them with forensic-specific datasets further enhances their performance and applicability in real-world forensic use-cases"
  - [corpus] Moderate evidence - the corpus shows VLMs being used for label-efficient learning in oncology and educational assessment, supporting the transfer learning claim
- Break condition: If the VLM's pre-training did not adequately cover the diversity of handwriting styles and forensic scenarios, transfer learning will fail and performance will be poor.

### Mechanism 3
- Claim: VLMs can identify and mark coordinates of similarities and dissimilarities in handwriting samples.
- Mechanism: VLMs use their visual understanding capabilities to pinpoint specific areas of interest in handwriting samples, such as matching or differing stroke patterns, and provide coordinates for these features.
- Core assumption: The VLM's vision encoder can effectively process handwriting images and extract meaningful visual features that correspond to writer-specific characteristics.
- Evidence anchors:
  - [section] "Additionally, we utilized prompt engineered both VLMs to identify and mark coordinates of similarities and dissimilarities within the two images"
  - [abstract] "By leveraging their Visual Question Answering capabilities and 0-shot Chain-of-Thought (CoT) reasoning"
  - [corpus] Weak evidence - no direct evidence in corpus for coordinate marking capabilities in handwriting verification, though related work exists on VLMs for document understanding
- Break condition: If the VLM cannot accurately localize visual features in handwriting images, the coordinate marking feature will fail, reducing interpretability.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) reasoning
  - Why needed here: CoT provides a structured reasoning process that guides the VLM through step-by-step analysis of handwriting features, improving consistency and reliability of explanations
  - Quick check question: How does CoT reasoning improve the consistency of VLM explanations compared to direct prompting?

- Concept: Vision-Language Model (VLM) architecture
  - Why needed here: Understanding how VLMs integrate visual and linguistic information is crucial for designing effective prompts and interpreting model outputs in handwriting verification
  - Quick check question: What are the key components of a VLM and how do they work together to process image-text pairs?

- Concept: Forensic handwriting verification principles
  - Why needed here: Knowledge of what features forensic examiners look for (stroke patterns, letter spacing, slant) is essential for designing effective VLM prompts and interpreting results
  - Quick check question: What are the primary visual features forensic document examiners use to determine if handwriting samples are from the same writer?

## Architecture Onboarding

- Component map:
  Vision encoder (e.g., SigLIP in PaliGemma) -> Multimodal projector -> Language model (e.g., Gemma in PaliGemma) -> Prompt template system -> Fine-tuning module (optional)

- Critical path:
  1. Input: Questioned and known handwriting sample images
  2. Vision encoder extracts visual features from both images
  3. Multimodal projector aligns visual features with prompt context
  4. Language model generates Chain-of-Thought reasoning
  5. Output: Verification decision + human-interpretable explanation with coordinates

- Design tradeoffs:
  - Zero-shot vs. few-shot vs. full fine-tuning: Balance between generalization and task-specific performance
  - Prompt engineering complexity vs. model performance: More structured prompts may yield better results but require more design effort
  - Model size vs. inference efficiency: Larger models may perform better but are slower and more expensive

- Failure signatures:
  - Inconsistent explanations across similar samples indicate prompt instability
  - Poor accuracy despite good explanations suggests the model understands features but cannot effectively use them for verification
  - Failure to identify writer-specific features indicates inadequate visual feature extraction

- First 3 experiments:
  1. Test zero-shot CoT prompting on a small subset of samples to evaluate baseline interpretability and accuracy
  2. Compare different prompt structures (feature-specific vs. holistic vs. coordinate-focused) on the same sample set
  3. Fine-tune PaliGemma on 100 curated examples and evaluate performance improvement over zero-shot baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can VLMs be further improved to match the performance of specialized deep learning models like ResNet-18 in handwriting verification tasks?
- Basis in paper: [explicit] The paper explicitly states that VLMs lag behind CNN-based architectures in terms of performance, with ResNet-18 achieving 84% accuracy compared to GPT-4o's 70% and PaliGemma's 71% on the CEDAR AND dataset.
- Why unresolved: The paper highlights the need for further advancements in the fine-tuning regimes of VLMs to enhance their effectiveness and reliability for specialized tasks like handwriting verification, but does not provide specific solutions or methodologies to achieve this.
- What evidence would resolve it: Conducting experiments with different fine-tuning strategies, larger and more diverse datasets, or hybrid models combining VLMs with CNNs could provide insights into improving VLM performance.

### Open Question 2
- Question: What specific features or aspects of handwriting do VLMs struggle to accurately identify compared to CNNs?
- Basis in paper: [inferred] The paper suggests that VLMs, while offering enhanced interpretability, underperform compared to CNNs, implying potential difficulties in identifying specific handwriting features.
- Why unresolved: The paper does not detail which specific handwriting features (e.g., stroke width, slant, letter spacing) are more challenging for VLMs to accurately assess compared to CNNs.
- What evidence would resolve it: A detailed analysis of the types of errors made by VLMs versus CNNs in identifying various handwriting features would clarify their respective strengths and weaknesses.

### Open Question 3
- Question: How does the variability in performance metrics for VLMs on the CEDAR Letter dataset affect their reliability in real-world forensic applications?
- Basis in paper: [explicit] The paper notes high variability in performance metrics for VLMs on the CEDAR Letter dataset due to the low sample size, raising concerns about their reliability.
- Why unresolved: The paper does not explore the implications of this variability on the practical use of VLMs in forensic settings or suggest methods to mitigate these issues.
- What evidence would resolve it: Testing VLMs on larger, more diverse datasets and analyzing their consistency across different handwriting styles and forensic scenarios would provide insights into their reliability.

## Limitations
- VLMs significantly underperform specialized deep learning models like ResNet-18 in handwriting verification tasks, with accuracy gaps of 14-19 percentage points
- The study's generalizability is limited as it only tested on CEDAR datasets without validation on other handwriting databases or real-world forensic casework
- High variability in VLM performance metrics on the CEDAR Letter dataset due to low sample size raises reliability concerns for forensic applications

## Confidence

**Confidence Labels:**
- VLM interpretability mechanisms: Medium-High
- Transfer learning effectiveness: Medium
- Comparative performance conclusions: High
- Generalizability to forensic practice: Low-Medium

## Next Checks
1. Conduct cross-dataset validation by testing the same VLM approaches on the IAM and Firemaker handwriting datasets to assess generalization beyond CEDAR.
2. Perform blind evaluation with forensic document examiners to assess whether VLM-generated explanations meet professional standards for interpretability and reliability.
3. Implement ablation studies varying prompt complexity and fine-tuning sample sizes to identify optimal configurations that balance accuracy with interpretability.