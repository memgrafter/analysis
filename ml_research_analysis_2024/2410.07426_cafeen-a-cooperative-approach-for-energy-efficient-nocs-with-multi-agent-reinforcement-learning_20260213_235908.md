---
ver: rpa2
title: 'CAFEEN: A Cooperative Approach for Energy Efficient NoCs with Multi-Agent
  Reinforcement Learning'
arxiv_id: '2410.07426'
source_url: https://arxiv.org/abs/2410.07426
tags:
- routing
- router
- power
- cafeen
- grained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of energy consumption in high-performance
  Network-on-Chip (NoC) architectures, which is crucial to minimize energy usage in
  emerging many-core Systems-on-Chip (SoCs). The proposed framework, CAFEEN, employs
  both heuristic-based fine-grained and machine learning-based coarse-grained power-gating
  for energy-efficient NoCs.
---

# CAFEEN: A Cooperative Approach for Energy Efficient NoCs with Multi-Agent Reinforcement Learning

## Quick Facts
- arXiv ID: 2410.07426
- Source URL: https://arxiv.org/abs/2410.07426
- Reference count: 11
- Key outcome: Reduces total energy by 2.60x for single application workloads and 4.37x for multi-application workloads compared to state-of-the-art NoC power-gating frameworks

## Executive Summary
CAFEEN addresses energy consumption in high-performance Network-on-Chip architectures through a hybrid power-gating approach. The framework uses fine-grained power-gating for low network loads, selectively powering down unused router buffers, and switches to coarse-grained power-gating at peak loads using multi-agent reinforcement learning. This adaptive strategy balances power efficiency with performance, achieving significant energy reductions while maintaining low latency overhead.

## Method Summary
CAFEEN employs a hybrid approach combining fine-grained and coarse-grained power-gating in NoC architectures. For low traffic loads, it uses fine-grained gating to power down individual input buffers when idle for a threshold of 2 cycles. At high traffic loads, it switches to coarse-grained gating that powers entire routers simultaneously. The framework incorporates a multi-agent reinforcement learning system where each router runs an RL agent that selects between XY and YX routing paths to maximize power efficiency through cooperative behavior and shared rewards.

## Key Results
- Achieves 2.60x energy reduction for single application workloads
- Achieves 4.37x energy reduction for multi-application workloads
- Maintains latency overhead below 8% compared to baseline

## Why This Works (Mechanism)

### Mechanism 1
Fine-grained power-gating reduces leakage power by selectively powering down unused router buffers during low traffic. The framework tracks buffer utilization per input port and gates buffers idle for threshold cycles. Under low load, 94% of the time only one out of four input buffers is required by turning packets. As traffic increases, multiple turning packets may require more buffers, making cumulative wake-up latency outweigh leakage savings.

### Mechanism 2
Coarse-grained power-gating under high load avoids compounding wake-up delays by powering entire routers simultaneously. When traffic exceeds threshold, routers switch to coarse-grained mode and MARL routes packets to reuse already-active routers. Router wake-up latency dominates performance at high load, making it better to pay once per router than multiple times per buffer. If RL policy fails or traffic is highly bursty, coarse-grained mode may still incur unnecessary activations.

### Mechanism 3
Cooperative MARL routing maximizes power efficiency by sharing reward information among routers to reuse active routers. Each router hosts an RL agent selecting between XY and YX paths, with shared reward epochs counting packets turned while routers are active. Agents update Q-values to prefer routes that reuse active routers, reducing wake-ups. If traffic has no predictable structure, learned policy may not outperform simple deterministic routing.

## Foundational Learning

- Concept: Power-gating granularity tradeoffs
  - Why needed here: Understanding when fine-grained vs coarse-grained gating is beneficial is central to the framework's adaptive strategy
  - Quick check question: What is the break-even time (BET) and how does it influence the choice of t_idle for buffer gating?

- Concept: Multi-agent reinforcement learning basics
  - Why needed here: The routing decision policy relies on cooperative Q-learning with shared rewards
  - Quick check question: In this MARL setup, why is the standard Q-learning update simplified to exclude the future Q term?

- Concept: XY vs YX routing in mesh NoCs
  - Why needed here: The routing policy space is limited to these two deterministic paths for tractability
  - Quick check question: How does restricting to XY/YX routing reduce the state-action space compared to fully adaptive routing?

## Architecture Onboarding

- Component map: Router (input buffers, output buffers, crossbar, route computation, switch allocation, bypass latch, Q-value table, power-gating controller) -> MARL network (RL agents, reward flits via dedicated channel) -> Power manager (controls fine-grained buffer gating and coarse-grained router gating)

- Critical path: Packet arrival → buffer check → if turning packet and in fine-grained mode, gate only needed buffer; if in coarse-grained mode, wake entire router → RL agent lookup Q-table → route decision → packet injection → reward epoch completion → broadcast reward → Q-value update

- Design tradeoffs: Fine-grained gating saves leakage but incurs multiple wake-ups at high load; coarse-grained gating reduces wake-up latency but can waste power if router is only partially used; limiting routing to XY/YX simplifies learning but may miss some optimal paths

- Failure signatures: High packet latency spike (likely coarse-grained mode with poor RL policy); energy use remains high under low load (fine-grained gating not triggering or t_idle too large); deadlock (possible if adaptive routing lacks proper virtual channel partitioning)

- First 3 experiments: 1) Run a low-load PARSEC workload; measure buffer idle times to verify fine-grained gating triggers correctly; 2) Run a high-load synthetic workload; verify router wake-up counts drop when switching to coarse-grained mode; 3) Inject a bursty traffic pattern; check that Q-values converge to favor XY/YX paths that reuse active routers

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- MARL routing performance under bursty or adversarial traffic patterns is not validated
- Framework assumes predictable traffic patterns that correlate with efficient router reuse
- Implementation details for reward broadcast mechanism are incomplete

## Confidence
- High Confidence: Fundamental tradeoff between fine-grained and coarse-grained power-gating is well-established
- Medium Confidence: Adaptive switching threshold between modes is not explicitly validated through sensitivity analysis
- Low Confidence: MARL routing component's effectiveness depends heavily on traffic patterns without diverse pattern testing

## Next Checks
1. Run MARL component with synthetic adversarial traffic (e.g., targeted hot-spot injection) to verify routing adaptability and check for policy degradation
2. Perform sensitivity analysis on fine-grained gating threshold (t_idle) to identify optimal value across different traffic intensities
3. Test framework on traffic patterns with no predictable structure (e.g., uniform random) to assess whether XY/YX restriction limits performance compared to fully adaptive routing