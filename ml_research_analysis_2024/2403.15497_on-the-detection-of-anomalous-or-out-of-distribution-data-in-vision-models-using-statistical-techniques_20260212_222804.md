---
ver: rpa2
title: On the Detection of Anomalous or Out-Of-Distribution Data in Vision Models
  Using Statistical Techniques
arxiv_id: '2403.15497'
source_url: https://arxiv.org/abs/2403.15497
tags:
- data
- images
- image
- distribution
- out-of-distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores the application of Benford's law as a tool for
  detecting out-of-distribution data and anomalies in computer vision models. The
  authors propose using the divergence of image DCT coefficient distributions from
  the theoretical Benford's law distribution as a measure of data distribution shifts.
---

# On the Detection of Anomalous or Out-Of-Distribution Data in Vision Models Using Statistical Techniques

## Quick Facts
- arXiv ID: 2403.15497
- Source URL: https://arxiv.org/abs/2403.15497
- Authors: Laura O'Mahony; David JP O'Sullivan; Nikola S. Nikolov
- Reference count: 39
- Primary result: Benford's law divergence from DCT coefficients can detect corrupted images as OOD data, with varying correlation to model performance degradation

## Executive Summary
This paper explores using Benford's law as a statistical tool for detecting out-of-distribution data and anomalies in computer vision models. The authors propose measuring the divergence of image DCT coefficient distributions from the theoretical Benford's law distribution as an indicator of data distribution shifts. Tested on ImageNet-C with various corruption types and severity levels, the approach shows that corrupted images generally deviate more from Benford's law compared to clean images. When evaluated on a pretrained AlexNet model, the method sometimes reflects model performance degradation on corrupted data, though not consistently across all corruption types. The authors conclude this technique could serve as a complementary method for anomaly detection but should not replace existing approaches.

## Method Summary
The method applies the discrete cosine transform (DCT) to 8x8 non-overlapping blocks of images, extracts the leading digit distribution of DCT coefficients, and computes the Jensen-Shannon divergence between this empirical distribution and the theoretical Benford's law distribution. This divergence is used as a measure of how much an image deviates from the expected statistical properties of natural images. The approach is tested on the ImageNet-C dataset containing 15 corruption types at 5 severity levels, comparing clean and corrupted images. A pretrained AlexNet model is also evaluated to examine the correlation between BFL divergence and model performance degradation.

## Key Results
- Corrupted images generally show higher median Jensen-Shannon divergence from Benford's law compared to clean images
- Higher severity levels of corruption lead to larger median divergences from the BFL benchmark
- The approach reflects model performance degradation on corrupted data in some cases, but not consistently across all corruption types
- Gaussian noise corruption shows the largest difference in divergence between clean and corrupted images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DCT coefficient leading digit distributions shift when images are corrupted.
- Mechanism: The DCT transforms spatial image data into frequency components. Natural images have DCT coefficients that follow a Laplacian-like distribution, which empirically follows Benford's Law (BFL). When corruption is applied, the statistical properties of the DCT coefficients change, causing deviation from the expected BFL distribution.
- Core assumption: The DCT coefficients of natural images follow BFL, and this property is disrupted by image corruptions.
- Evidence anchors:
  - [abstract] "corrupted images generally deviate more from Benford's law compared to clean images"
  - [section] "images mapped into the DCT domain typically follow BFL [28]"
  - [corpus] Weak - corpus focuses on OOD detection methods rather than DCT/BFL specifically
- Break condition: If corruption types do not significantly alter DCT coefficient distributions, or if certain corruptions preserve the Laplacian-like distribution, this mechanism would fail.

### Mechanism 2
- Claim: Jensen-Shannon divergence effectively measures distribution shift from BFL.
- Mechanism: The Jensen-Shannon divergence provides a symmetric, bounded metric to quantify the difference between the empirical leading digit distribution of DCT coefficients and the theoretical BFL distribution. Larger divergences indicate greater deviation from natural image statistics.
- Core assumption: Jensen-Shannon divergence is an appropriate and sensitive metric for detecting changes in leading digit distributions.
- Evidence anchors:
  - [section] "A statistical metric, the Jensen-Shannon divergence [23], is employed to investigate the difference between these distributions"
  - [section] "Fig. 4... typically, across all corruption types... corrupted images show an increase in the median divergence from the BFL benchmark"
  - [corpus] Weak - corpus doesn't specifically discuss Jensen-Shannon divergence applications
- Break condition: If Jensen-Shannon divergence is not sensitive enough to detect subtle distribution shifts, or if it produces false positives/negatives for certain corruption types.

### Mechanism 3
- Claim: Model performance degradation correlates with increased BFL divergence in some cases.
- Mechanism: When images are corrupted, they become out-of-distribution for models trained on clean ImageNet data. The increased BFL divergence indicates this distributional shift, which sometimes corresponds to decreased model accuracy.
- Core assumption: Distributional shifts in input data can be detected through BFL divergence and correlate with model performance degradation.
- Evidence anchors:
  - [abstract] "When evaluated on a pretrained AlexNet model, the approach reflects model performance degradation on corrupted data in some cases"
  - [section] "Fig. 5 shows that, as expected, the baseline ImageNet validation accuracy of AlexNet... decreased as the level of corruption increased"
  - [corpus] Weak - corpus doesn't establish direct correlation between statistical divergence and model performance
- Break condition: If model performance degradation doesn't consistently correlate with BFL divergence, this mechanism fails to provide reliable OOD detection.

## Foundational Learning

- Concept: Benford's Law and its application to image data
  - Why needed here: Understanding the theoretical foundation that DCT coefficients of natural images follow BFL is crucial for interpreting why deviations indicate anomalies
  - Quick check question: Why do DCT coefficients of natural images typically follow Benford's Law?

- Concept: Discrete Cosine Transform (DCT) and its properties
  - Why needed here: The DCT is the key transformation that converts spatial image data into frequency domain where BFL applies
  - Quick check question: How does the DCT transformation help in extracting statistical properties that follow Benford's Law?

- Concept: Jensen-Shannon divergence and statistical hypothesis testing
  - Why needed here: This metric quantifies the difference between observed and theoretical distributions, forming the core measurement of the approach
  - Quick check question: What properties make Jensen-Shannon divergence suitable for comparing leading digit distributions?

## Architecture Onboarding

- Component map: Image preprocessing → 8x8 DCT blocks → Leading digit extraction → Probability mass function calculation → Jensen-Shannon divergence computation → BFL comparison
- Critical path: DCT coefficient extraction → leading digit distribution calculation → divergence computation → decision threshold application
- Design tradeoffs: Simplicity and computational efficiency vs. sensitivity to subtle corruption types; statistical method vs. learned approaches
- Failure signatures: High false positive rate for certain natural image types; inability to detect semantic anomalies; inconsistent correlation with model performance
- First 3 experiments:
  1. Apply the pipeline to clean ImageNet validation set to establish baseline BFL divergence distribution
  2. Test on single corruption type (e.g., Gaussian noise) at increasing severity levels to verify divergence increases
  3. Compare BFL divergence results with model accuracy degradation on corrupted images to establish correlation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the generalized Benford's equation improve detection performance for Gaussian noise and other corruption types compared to the standard Benford's law?
- Basis in paper: [explicit] The authors suggest this as a potential extension, noting that a generalized Benford's equation has been shown to better fit natural images due to DCT properties.
- Why unresolved: The authors only tested the standard Benford's law in their experiments and did not evaluate the generalized version.
- What evidence would resolve it: Experimental results comparing the detection performance of both the standard and generalized Benford's law approaches on various corruption types, including Gaussian noise.

### Open Question 2
- Question: How well does the divergence from Benford's law correlate with model performance degradation across different corruption types and severity levels?
- Basis in paper: [inferred] The authors note that in some cases, a considerable jump in the median divergence from the BFL benchmark reflected a large model performance degradation, but this was not consistent across all corruption types.
- Why unresolved: The authors only provide a limited analysis of the correlation between the divergence statistic and model performance, focusing on a few corruption types and severity levels.
- What evidence would resolve it: A comprehensive analysis of the correlation between the divergence from Benford's law and model performance degradation across all corruption types and severity levels in the ImageNet-C dataset.

### Open Question 3
- Question: Can the Benford's law-based approach be effectively used for semantic anomaly detection (detecting changes in the label space) in addition to sensory anomaly detection (detecting changes in the input space)?
- Basis in paper: [explicit] The authors mention that a limitation of their approach is that it may be useful for sensory anomaly detection but not semantic anomaly detection.
- Why unresolved: The authors did not test the approach on data with label space shifts or new classes, focusing only on input space corruptions.
- What evidence would resolve it: Experiments applying the Benford's law-based approach to datasets with semantic anomalies, such as out-of-distribution classes or label noise, and evaluating its effectiveness in detecting these anomalies.

## Limitations

- Inconsistent correlation between BFL divergence and model performance degradation across different corruption types
- Limited testing to only 4 out of 15 available corruption types in ImageNet-C and only one model architecture (AlexNet)
- Heavy reliance on the assumption that natural images follow Benford's law in the DCT domain, which lacks strong theoretical justification

## Confidence

- Medium confidence: The core claim that corrupted images deviate more from BFL than clean images is supported by empirical results, but the inconsistent correlation with model performance reduces confidence in practical utility.
- Low confidence: The mechanism by which DCT coefficients follow Benford's law is not well-established theoretically, and the method's effectiveness on other corruption types and models is unknown.
- Medium confidence: The use of Jensen-Shannon divergence as a measurement tool is standard, but its sensitivity to subtle distribution shifts in this specific application context is uncertain.

## Next Checks

1. **Theoretical validation**: Investigate why DCT coefficients of natural images follow Benford's law through mathematical analysis of the DCT transformation and image statistics.

2. **Broader corruption testing**: Evaluate the approach on all 15 corruption types in ImageNet-C to identify which types the method can reliably detect.

3. **Model generalization**: Test the correlation between BFL divergence and model performance across multiple architectures (ResNet, EfficientNet) to establish if the effect is model-specific or generalizable.