---
ver: rpa2
title: Deep Reinforcement Learning for Picker Routing Problem in Warehousing
arxiv_id: '2402.03525'
source_url: https://arxiv.org/abs/2402.03525
tags:
- problem
- routing
- aisle
- learning
- picker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a deep reinforcement learning approach for
  the Picker Routing Problem in warehouse operations management. The problem is formulated
  as a Markov Decision Process, where the goal is to find an optimal sequence of items
  to minimize the total travel distance for a picker.
---

# Deep Reinforcement Learning for Picker Routing Problem in Warehousing

## Quick Facts
- arXiv ID: 2402.03525
- Source URL: https://arxiv.org/abs/2402.03525
- Authors: George Dunn; Hadi Charkhgard; Ali Eshragh; Sasan Mahmoudinazlou; Elizabeth Stojanovski
- Reference count: 37
- Primary result: Attention-based neural network trained with REINFORCE achieves 2.68% optimality gap vs 4.89% for simplified model compared to optimal solutions

## Executive Summary
This paper presents a deep reinforcement learning approach for the Picker Routing Problem in warehouse operations management. The problem is formulated as a Markov Decision Process, where the goal is to find an optimal sequence of items to minimize the total travel distance for a picker. The authors propose a neural network architecture based on attention mechanisms and the Transformer model to approximate the policy, which is trained using the REINFORCE algorithm with a greedy baseline. The model is evaluated against existing heuristics across a range of problem parameters, including the number of aisles and the size of pick lists.

## Method Summary
The authors formulate the Picker Routing Problem as a Markov Decision Process and propose an attention-based neural network for modeling picker tours. The network architecture includes transformer layers with masked self-attention, and the model is trained using the REINFORCE algorithm with a greedy baseline. The method uses aisle-level abstraction, where each aisle is represented as a binary vector indicating item presence, and self-attention layers capture inter-aisle relationships. The model is trained on warehouses with 5-30 aisles and pick lists of 30-90 items, and evaluated against existing heuristics.

## Key Results
- The proposed method consistently outperforms existing heuristics, with an average optimality gap of 2.68% for the standard model and 4.89% for the simplified model.
- The model demonstrates strong generalization across different warehouse sizes and pick list lengths.
- The simplified tour model reduces perceived complexity while maintaining competitive performance.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The attention-based neural network can model warehouse-specific routing by representing aisles as binary vectors and using self-attention to capture inter-aisle relationships.
- Mechanism: Each aisle is encoded as a binary vector indicating item presence; self-attention layers allow the model to dynamically focus on relevant aisles without being constrained by a fixed input order, matching the geometric nature of warehouse routing.
- Core assumption: Aisle-level abstraction preserves sufficient information for near-optimal routing while reducing problem complexity compared to item-level models.
- Evidence anchors:
  - [abstract]: "We introduce an attention based neural network for modeling picker tours, which is trained using Reinforcement Learning."
  - [section]: "The inputs are not a sequence of two-dimensional coordinates, but a sequence of binary vectors representing each aisle... attention-based encoders are invariant to the input order."
  - [corpus]: No direct evidence; this is a novel architectural choice not yet validated in the corpus.
- Break condition: If item-to-item proximity effects dominate routing decisions, aisle-level abstraction may miss critical short-range optimizations.

### Mechanism 2
- Claim: Training with REINFORCE with a greedy baseline and loss normalization stabilizes learning across varying warehouse sizes and pick-list lengths.
- Mechanism: The policy gradient estimator is adjusted by dividing by the baseline tour length, which normalizes reward signals across problem instances and improves generalization.
- Core assumption: Baseline normalization compensates for the wide variation in tour lengths caused by different warehouse dimensions and pick-list sizes.
- Evidence anchors:
  - [section]: "The loss used in Kool et al. (2018) is divided by the baseline cost as the tour lengths for this problem are larger than a TSP within a unit square... allowed better generalization of the loss across different sized problems."
  - [corpus]: No explicit validation in corpus; this is inferred from the methodology description.
- Break condition: If the greedy baseline becomes too loose (e.g., on highly irregular pick patterns), normalization may destabilize learning.

### Mechanism 3
- Claim: Masking the "gap" action during training and inference produces simpler, more human-implementable routes without sacrificing too much optimality.
- Mechanism: The model excludes the largest-gap decision, which is the only action that causes multiple aisle entries; this enforces single-entry-per-aisle tours, aligning with human operator preferences.
- Core assumption: Removing the largest-gap action reduces route complexity enough to improve human usability while retaining competitive performance.
- Evidence anchors:
  - [abstract]: "A key advantage of our proposed method is its ability to offer an option to reduce the perceived complexity of routes."
  - [section]: "One characteristic that is considered to produce complex tours is entering an aisle more than once... excluding this would guarantee a simple solution that enters each aisle at most once."
  - [corpus]: No direct evidence; this is a design choice unique to the paper.
- Break condition: If the optimal solution frequently requires multiple aisle entries, simplification may lead to large optimality gaps.

## Foundational Learning

- Concept: Markov Decision Process formulation of routing as aisle-by-aisle edge selection.
  - Why needed here: Provides a tractable state and action space that matches the warehouse geometry and allows policy gradient methods to learn directly from warehouse layouts.
  - Quick check question: What are the two types of actions in the proposed MDP and how do they correspond to warehouse traversal?

- Concept: Self-attention and multi-head attention mechanisms in transformers.
  - Why needed here: Enables the model to capture complex dependencies between aisles without being constrained by input order, essential for generalizing across different warehouse configurations.
  - Quick check question: How does the attention mask prevent attending to previous aisles, and why is that important for this problem?

- Concept: REINFORCE with baseline normalization.
  - Why needed here: Allows policy gradient training on combinatorial problems where optimal labels are unavailable, with normalization helping generalization across varying problem scales.
  - Quick check question: Why is the baseline updated using a greedy rollout of the best model so far?

## Architecture Onboarding

- Component map: Input -> Embedding -> N Encoder Layers -> Output Projection -> Per-Aisle Action Selection -> Tour Graph Construction
- Critical path: Input → Embedding → N Encoder Layers → Output Projection → Per-Aisle Action Selection → Tour Graph Construction
- Design tradeoffs:
  - Aisle-level vs item-level representation: reduces complexity but may lose fine-grained proximity information
  - Masking largest-gap action: simplifies routes for human use but increases optimality gap
  - Using transformer encoder (vs decoder): enables set-based processing but requires careful masking
- Failure signatures:
  - Large optimality gap on small warehouses: may indicate insufficient model capacity or poor learning signal
  - Degraded performance on larger warehouses: could signal overfitting or poor generalization
  - Erratic training loss: may indicate issues with baseline normalization or learning rate
- First 3 experiments:
  1. Train on small warehouses (5 aisles, 30 items) and evaluate against heuristics to confirm basic learning.
  2. Test generalization by evaluating on larger warehouses not seen during training.
  3. Compare standard vs simplified tour models to quantify the tradeoff between route simplicity and optimality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model perform with non-standard warehouse layouts, such as U-shaped or L-shaped configurations?
- Basis in paper: [inferred] The paper evaluates the model on standard rectangular warehouses with a block layout. There is no mention of testing on alternative warehouse geometries.
- Why unresolved: The current model's architecture and attention mechanisms are specifically tailored to rectangular layouts with parallel aisles. Extending to non-standard geometries would require architectural modifications and retraining.
- What evidence would resolve it: Numerical experiments comparing the model's performance on U-shaped, L-shaped, and other non-rectangular warehouses against existing heuristics and optimal solutions.

### Open Question 2
- Question: How sensitive is the model's performance to the number of storage locations per aisle (h) and the horizontal distance between aisles?
- Basis in paper: [inferred] The paper uses a fixed warehouse configuration with 90 storage locations per aisle and 5 LU between aisles. The impact of varying these parameters is not explored.
- Why unresolved: The model's input representation and attention mechanisms are designed for a specific warehouse geometry. Different storage densities or aisle spacings could affect the model's ability to learn effective routing policies.
- What evidence would resolve it: Ablation studies testing the model's performance across a range of storage densities (e.g., 60, 120 locations per aisle) and aisle spacings (e.g., 3 LU, 7 LU), compared to baseline heuristics.

### Open Question 3
- Question: How does the model scale to warehouses with more than 30 aisles or pick lists with more than 90 items?
- Basis in paper: [explicit] The paper evaluates the model on warehouses with 5-30 aisles and pick lists of 30-90 items. The authors note that the optimal algorithm in Ratliff and Rosenthal (1983) does not scale well to larger problems.
- Why unresolved: The model's attention mechanism and encoder layers are designed to handle sequences up to the tested sizes. Scaling to larger problems may require architectural changes or training strategies to maintain performance.
- What evidence would resolve it: Experiments testing the model's performance on warehouses with 35-50 aisles and pick lists of 100-150 items, comparing against existing heuristics and optimal solutions where feasible.

## Limitations

- Architectural novelty uncertainty: The interaction between aisle-level abstraction and optimal routing performance remains incompletely validated.
- Baseline methodology ambiguity: The OneSidedPairedTTest procedure for baseline updates is not fully detailed.
- Simplified tour tradeoff: The performance gap between standard and simplified tour models may not represent the optimal tradeoff.

## Confidence

- **High Confidence**: The fundamental approach of using attention mechanisms with masked self-attention for warehouse routing is well-supported by the results.
- **Medium Confidence**: The specific performance metrics (optimality gaps) are reliable within the tested parameter ranges.
- **Low Confidence**: The baseline update methodology and its impact on learning stability is not fully transparent.

## Next Checks

1. **Architecture Ablation Study**: Systematically remove the attention mechanism or masking components to quantify their individual contributions to performance.
2. **Baseline Methodology Audit**: Implement and test alternative baseline update strategies to assess sensitivity of learning stability.
3. **Complexity-Optimality Frontier Analysis**: Conduct a systematic evaluation of the simplified tour model across different warehouse densities.