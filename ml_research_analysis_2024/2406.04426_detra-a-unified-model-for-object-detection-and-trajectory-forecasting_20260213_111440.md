---
ver: rpa2
title: 'DeTra: A Unified Model for Object Detection and Trajectory Forecasting'
arxiv_id: '2406.04426'
source_url: https://arxiv.org/abs/2406.04426
tags:
- object
- detection
- forecasting
- attention
- lidar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DeTra is a single-stage model that unifies object detection and
  trajectory forecasting by reformulating them as a trajectory refinement task. It
  uses a refinement transformer that iteratively refines learnable object queries
  and poses over time using attention mechanisms to LiDAR point clouds and HD maps.
---

# DeTra: A Unified Model for Object Detection and Trajectory Forecasting

## Quick Facts
- arXiv ID: 2406.04426
- Source URL: https://arxiv.org/abs/2406.04426
- Reference count: 40
- Key outcome: Single-stage model that unifies object detection and trajectory forecasting through trajectory refinement, outperforming state-of-the-art methods on Argoverse 2 and Waymo datasets.

## Executive Summary
DeTra is a unified model that reformulates object detection and trajectory forecasting as a trajectory refinement task. It uses a refinement transformer with learnable object queries and poses that iteratively refine over multiple blocks using attention mechanisms to LiDAR point clouds and HD maps. The model predicts object detections and multiple future trajectories directly from sensor inputs in Bird's-Eye-View. Experiments show DeTra outperforms state-of-the-art methods in both detection, forecasting, and joint metrics.

## Method Summary
DeTra unifies object detection and trajectory forecasting by treating them as a trajectory refinement task. The model uses a refinement transformer that iteratively refines learnable object queries and poses over time using attention mechanisms to LiDAR point clouds and HD maps. It predicts object detections and multiple future trajectories in Bird's-Eye-View directly from sensor inputs. The architecture includes a LiDAR encoder, map encoder, and refinement transformer with deformable LiDAR attention, k-NN map attention, and factorized self-attention.

## Key Results
- DeTra achieves state-of-the-art performance on joint detection and forecasting metrics (OccAP, TrajAP) on Argoverse 2 Sensor and Waymo Open Dataset
- The refinement approach shows consistent improvement over baselines in both detection and forecasting tasks
- Ablation studies demonstrate the effectiveness of the refinement approach and contribution of each component (deformable attention, k-NN map attention, factorized self-attention)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DeTra unifies detection and forecasting by treating them as trajectory refinement.
- Mechanism: The model uses learnable object queries and poses refined over multiple transformer blocks. Each query attends to LiDAR and map tokens to iteratively improve both detection (current pose) and forecasting (future poses).
- Core assumption: Treating detection as the special case of the first pose in a trajectory allows joint optimization and avoids cascading errors.
- Evidence anchors:
  - [abstract] "our approach formulates the union of the two tasks as a trajectory refinement problem, where the first pose is the detection (current time), and the subsequent poses are the waypoints of the multiple forecasts (future time)."
  - [section] "we design a refinement transformer that infers the presence, pose, and multi-modal future behaviors of objects directly from LiDAR point clouds and high-definition (HD) maps."
- Break condition: If pose initialization is inaccurate, refinement may not converge to correct detections or trajectories.

### Mechanism 2
- Claim: DeTra uses factorized self-attention to efficiently handle 3D queries (object, mode, time).
- Mechanism: Self-attention is decomposed into object self-attention, mode self-attention, and time self-attention, allowing each dimension to propagate information independently while reducing computational cost.
- Core assumption: Factorizing self-attention across object, mode, and time dimensions preserves essential relational reasoning without prohibitive computation.
- Evidence anchors:
  - [section] "we factorize self-attention into object, time, and mode attention."
  - [section] "over different transformer blocks, these operations are repeated, enabling D ETRA to learn complex dependencies across the query volume efficiently."
- Break condition: If factorization omits critical cross-dimension dependencies, trajectory consistency could degrade.

### Mechanism 3
- Claim: Local attention to LiDAR and map tokens improves learning efficiency and accuracy.
- Mechanism: DeTra employs deformable attention to LiDAR (limited to a neighborhood around object poses) and k-nearest neighbor attention to map tokens, avoiding global attention over all tokens.
- Core assumption: Relevant information for each object is concentrated near its current pose, making local attention sufficient and more efficient.
- Evidence anchors:
  - [section] "we pair each of the queries with a pose that represents our belief about the BEV position of a particular object... and perform local attention in a neighborhood instead."
  - [section] "attending to the map tokens far from the object poses is unnecessary, so we limit the cross-attention to the k nearest map tokens from the object pose."
- Break condition: If relevant information lies outside the local neighborhood, local attention may miss it.

## Foundational Learning

- Concept: Bird's-Eye-View (BEV) representation
  - Why needed here: DeTra operates in BEV space to represent object positions and trajectories, matching downstream planning requirements.
  - Quick check question: Why is BEV preferred over camera view for trajectory forecasting in autonomous driving?

- Concept: Transformer attention mechanisms
  - Why needed here: DeTra uses multi-head attention for cross-attention to sensors and self-attention across queries to refine poses.
  - Quick check question: What is the difference between cross-attention and self-attention in the context of DeTra?

- Concept: Multi-modal trajectory forecasting
  - Why needed here: DeTra predicts multiple future trajectories per object to capture uncertainty and diverse possible futures.
  - Quick check question: How does DeTra represent multiple future modes in its query volume?

## Architecture Onboarding

- Component map:
  LiDAR point clouds → LiDAR encoder → Multi-resolution tokens → Refinement transformer (with pose initialization) → Pose update → Detections + Forecasts

- Critical path:
  LiDAR → LiDAR encoder → Multi-resolution tokens → Refinement transformer (with pose initialization) → Pose update → Detections + Forecasts

- Design tradeoffs:
  - Local vs global attention: Local attention reduces computation but risks missing distant context.
  - Factorized self-attention: Reduces complexity but may miss cross-dimension interactions.
  - Number of refinement blocks: More blocks allow better refinement but increase latency.

- Failure signatures:
  - Poor detection at high IoU: Likely due to inaccurate pose initialization or insufficient refinement.
  - Forecasting errors off the lane graph: Likely due to inadequate map attention or temporal reasoning.
  - Slow convergence: Likely due to suboptimal attention ordering or insufficient transformer depth.

- First 3 experiments:
  1. Evaluate detection and forecasting metrics after each refinement block to observe self-improvement.
  2. Test with different local attention radii (k, ℓ) to find optimal balance between accuracy and efficiency.
  3. Compare with and without factorized self-attention to measure impact on trajectory consistency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DeTra's performance scale with the number of refinement blocks, and what is the optimal number for balancing accuracy and computational cost?
- Basis in paper: [explicit] The paper mentions that DeTra's performance improves from 1 to 3 refinement blocks but plateaus after that. It also suggests that different training recipes, hyperparameters, and amounts of data would be necessary to scale DeTra further.
- Why unresolved: The paper only tests up to 5 refinement blocks and suggests that scaling DeTra might require additional tuning. The optimal number of refinement blocks for a given trade-off between accuracy and computational cost remains an open question.
- What evidence would resolve it: Experiments varying the number of refinement blocks while keeping other hyperparameters constant, and measuring the trade-off between accuracy and computational cost, would help determine the optimal number of refinement blocks.

### Open Question 2
- Question: How does the ordering of attention layers within the refinement transformer affect DeTra's performance?
- Basis in paper: [explicit] The paper shows that the ordering of self-attention modules (time, mode, object) matters, with better performance when they come after cross-attention modules (lidar and map). However, the ordering within cross-attention or self-attention seems to have less impact.
- Why unresolved: The paper only tests a few specific orderings of attention layers and does not exhaustively explore all possible permutations. The optimal ordering of attention layers for different datasets or tasks remains an open question.
- What evidence would resolve it: Systematic experiments testing different orderings of attention layers within the refinement transformer, while keeping other hyperparameters constant, would help determine the optimal ordering for different scenarios.

### Open Question 3
- Question: How does DeTra's performance change with different query volume dimensions, such as the number of modes and time steps?
- Basis in paper: [explicit] The paper shows that having more modes (F = 6) and time steps (T = 10) in the query volume improves trajectory forecasting performance, particularly at K = 6. However, detection performance slightly degrades at high IoUs with multiple modes or time steps.
- Why unresolved: The paper only tests a few specific query volume dimensions and does not explore the full range of possible configurations. The optimal query volume dimensions for balancing detection and trajectory forecasting performance remain an open question.
- What evidence would resolve it: Experiments varying the number of modes and time steps in the query volume, while keeping other hyperparameters constant, would help determine the optimal configuration for different datasets or tasks.

## Limitations

- Computational efficiency concerns: The paper doesn't adequately discuss the computational cost of multiple attention mechanisms across B blocks, and the iterative refinement process may offset efficiency gains from local attention.
- Limited dataset generalization: While showing strong results on Argoverse 2 and Waymo datasets, there's limited discussion of how well the model generalizes to different driving environments, weather conditions, or sensor configurations.
- Multi-modal forecasting quality: The paper mentions predicting multiple future trajectories but provides limited analysis of how well the model captures the true diversity of possible futures, with no quantitative assessment of mode coverage or quality.

## Confidence

**High Confidence**: The core mechanism of unifying detection and forecasting through trajectory refinement is well-supported by the architectural description and ablation studies. The factorized self-attention approach and local attention to sensors are clearly explained with appropriate mathematical formulation.

**Medium Confidence**: The claim of superior performance over state-of-the-art methods is supported by benchmark results, but the comparison would benefit from more detailed analysis of different traffic scenarios and failure cases. The effectiveness of the refinement approach is demonstrated but could be more thoroughly validated.

**Low Confidence**: The paper's claims about computational efficiency are not fully substantiated with runtime comparisons or FLOPs analysis. The impact of specific hyperparameter choices (attention radii, number of refinement blocks) on both accuracy and efficiency remains unclear.

## Next Checks

1. **Ablation Study on Refinement Depth**: Conduct experiments varying the number of refinement blocks (B) to quantify the relationship between refinement depth and performance gains, including both accuracy metrics and inference latency.

2. **Cross-Dataset Generalization Test**: Evaluate DeTra on a third, independent autonomous driving dataset with different characteristics (e.g., nuScenes or KITTI) to assess how well the refinement approach generalizes beyond the two training datasets mentioned.

3. **Mode Quality Analysis**: Implement and report metrics that specifically measure the quality and diversity of the predicted multi-modal trajectories, such as mode coverage (how well the predicted modes span the space of possible futures) and mode accuracy (how often the ground truth future is captured by one of the predicted modes).