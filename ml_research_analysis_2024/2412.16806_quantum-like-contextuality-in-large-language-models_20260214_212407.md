---
ver: rpa2
title: Quantum-Like Contextuality in Large Language Models
arxiv_id: '2412.16806'
source_url: https://arxiv.org/abs/2412.16806
tags:
- contextuality
- contextual
- bert
- schema
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first large-scale evidence for quantum-like
  contextuality in natural language using BERT. The authors constructed a linguistic
  schema modeled after a quantum contextual scenario, instantiated it using adjective-noun
  phrases from the Simple English Wikipedia, and extracted probability distributions
  using BERT's masked language modeling.
---

# Quantum-Like Contextuality in Large Language Models

## Quick Facts
- arXiv ID: 2412.16806
- Source URL: https://arxiv.org/abs/2412.16806
- Reference count: 40
- Primary result: First large-scale evidence for quantum-like contextuality in natural language using BERT, finding 77,118 sheaf-contextual and 36,938,948 CbD contextual instances among 51,966,480 total instances

## Executive Summary
This paper presents the first large-scale evidence for quantum-like contextuality in natural language using BERT. The authors constructed a linguistic schema modeled after a quantum contextual scenario, instantiated it using adjective-noun phrases from the Simple English Wikipedia, and extracted probability distributions using BERT's masked language modeling. They discovered 77,118 sheaf-contextual and 36,938,948 CbD contextual instances among 51,966,480 total instances. The findings suggest quantum methods may be advantageous for language tasks, particularly those involving anaphoric ambiguity resolution.

## Method Summary
The authors constructed a PR-anaphora schema based on the minimal quantum contextual scenario (PR prism) and instantiated it using adjective-noun phrases extracted from Simple English Wikipedia. They used BERT's masked language modeling to generate probability distributions for pronoun referents in different contexts. These distributions were analyzed using sheaf-theoretic and Contextuality-by-Default frameworks to detect contextuality. The study also performed polynomial regression analysis to examine correlations between contextuality degrees and BERT embedding features.

## Key Results
- Found 77,118 sheaf-contextual and 36,938,948 CbD contextual instances out of 51,966,480 total instances
- Derived equation showing contextuality degrees relate to Euclidean distances between BERT embedding vectors for noun pairs
- Euclidean distance was the best statistical predictor of contextuality in polynomial regression analysis

## Why This Works (Mechanism)

### Mechanism 1
BERT's masked language modeling captures contextual word probabilities that align with quantum-like measurement contexts. The schema instantiates pronoun-noun ambiguity scenarios where BERT's predictions for masked pronouns form probability distributions over referent nouns. These distributions are contextual because they cannot be explained by pre-existing values—similar to quantum measurements where outcomes depend on the context (other simultaneous measurements).

### Mechanism 2
Semantic similarity between noun pairs correlates with contextuality due to geometric properties of BERT's embedding space. The paper derives an equation showing that contextuality degrees relate to Euclidean distances between BERT's embedding vectors for noun pairs. When noun pairs are semantically similar (small Euclidean distance), BERT's uncertainty about masked pronouns increases, leading to higher contextuality.

### Mechanism 3
The PR-anaphora schema creates measurement scenarios structurally capable of exhibiting quantum contextuality. The schema is designed as a 3-cyclic measurement scenario where three pronouns (observables) each refer to two nouns (outcomes) across three contexts. This structure mirrors the PR prism, a known minimal contextual quantum scenario, ensuring the potential for contextuality.

## Foundational Learning

- **Sheaf-theoretic framework for contextuality**: Provides mathematical formalism to detect and measure contextuality in systems with signalling, essential for analyzing natural language data where no-signalling doesn't hold.
  - Quick check: What distinguishes sheaf-theoretic contextuality from traditional Bell-type contextuality?

- **Contextuality-by-Default (CbD) framework**: Offers alternative approach to measure contextuality in signalling systems, providing complementary validation of sheaf-theoretic results.
  - Quick check: How does CbD's treatment of joint distributions differ from the sheaf approach?

- **Masked language modeling in transformers**: Core mechanism for extracting probability distributions from BERT that serve as empirical data for contextuality analysis.
  - Quick check: How does BERT's prediction for a masked token differ from a simple lookup in the embedding space?

## Architecture Onboarding

- **Component map**: Wikipedia corpus → adjective-noun phrase extraction → noun pair filtering → PR-anaphora schema instantiation → BERT (masked language modeling) → logit score extraction → probability normalization → probability tables → sheaf-theoretic and CbD contextuality measures → correlation analysis with embedding features
- **Critical path**: Wikipedia → BERT predictions → Contextuality measures → Correlation analysis
- **Design tradeoffs**: Larger datasets increase statistical power but require more computation; simpler schemas are easier to analyze but may miss complex contextual phenomena
- **Failure signatures**: Low contextuality percentages might indicate poor schema design, insufficient semantic similarity in noun pairs, or BERT's predictions being too deterministic
- **First 3 experiments**:
  1. Verify BERT produces varying probabilities for different pronoun contexts with controlled noun pairs
  2. Test contextuality measures on synthetic data with known contextual structure
  3. Analyze correlation between semantic similarity and contextuality on a small, manually verified dataset

## Open Questions the Paper Calls Out

- **Does quantum-like contextuality in natural language actually lead to computational advantage for language tasks?**
  - Basis: The authors state "Contextuality leads to quantum advantage. It remains to show whether quantum-like contextuality also leads to advantage, and if so what kind of advantage will it be and how can it be obtained."
  - Why unresolved: The paper establishes contextuality exists but doesn't demonstrate actual performance benefits in specific language tasks
  - What evidence would resolve it: Empirical studies comparing language task performance between quantum-inspired methods and classical baselines

- **What is the relationship between sheaf-theoretic and CbD notions of contextuality in natural language data?**
  - Basis: The authors note "The fact that there are overwhelmingly more CbD-contextual models than sheaf-contextual models in our results is intriguing"
  - Why unresolved: The paper finds a large discrepancy between the two frameworks' measurements but doesn't explain why this occurs
  - What evidence would resolve it: Theoretical analysis explaining the mathematical relationship between the frameworks

- **How does human performance on coreference resolution tasks compare to BERT's contextuality-based approach?**
  - Basis: The authors mention their schema relates to the Winograd Schema Challenge and state "It remains to collect human judgements and compare their performances"
  - Why unresolved: The paper demonstrates BERT can model contextuality but doesn't compare this approach to actual human performance
  - What evidence would resolve it: Experimental data comparing human and BERT performance on coreference resolution tasks

## Limitations

- Findings may not generalize beyond the specific PR-anaphora schema used
- Results are based on a single BERT model without exploring variations across model architectures or sizes
- Correlation between semantic similarity and contextuality doesn't establish causal mechanism

## Confidence

- **High Confidence**: Identification of contextual instances using both sheaf-theoretic and CbD frameworks; correlation analysis showing Euclidean distance as best predictor
- **Medium Confidence**: Interpretation that BERT's masked language modeling captures genuinely quantum-like contextuality in language
- **Low Confidence**: Claim that quantum methods may be advantageous for language tasks remains speculative

## Next Checks

1. Replicate analysis using different transformer architectures (RoBERTa, GPT-2, T5) and model sizes to determine whether contextuality is specific to BERT or a general property of masked language models

2. Design and conduct experiments testing whether incorporating quantum-inspired models or contextuality measures improves performance on anaphoric ambiguity resolution tasks compared to standard NLP approaches

3. Apply the same methodology to different linguistic schemas beyond PR-anaphora (e.g., quantifier scope ambiguity, metaphor interpretation) to assess the breadth of contextuality in natural language