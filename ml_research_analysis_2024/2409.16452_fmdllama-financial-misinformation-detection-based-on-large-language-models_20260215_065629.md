---
ver: rpa2
title: 'FMDLlama: Financial Misinformation Detection based on Large Language Models'
arxiv_id: '2409.16452'
source_url: https://arxiv.org/abs/2409.16452
tags:
- financial
- llms
- arxiv
- misinformation
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses financial misinformation detection (FMD) using
  large language models (LLMs). The authors introduce FMDLlama, the first open-sourced
  LLM fine-tuned for FMD tasks, along with the first multi-task FMD instruction-tuning
  dataset (FMDID) and a comprehensive FMD evaluation benchmark (FMD-B).
---

# FMDLlama: Financial Misinformation Detection based on Large Language Models

## Quick Facts
- arXiv ID: 2409.16452
- Source URL: https://arxiv.org/abs/2409.16452
- Reference count: 8
- Primary result: FMDLlama3 (8B parameters) outperforms ChatGPT (170B parameters) on financial misinformation detection tasks

## Executive Summary
This paper introduces FMDLlama, the first open-sourced large language model fine-tuned specifically for financial misinformation detection (FMD). The authors create FMDID, a multi-task instruction-tuning dataset combining classification and explanation generation, and FMD-B, a comprehensive evaluation benchmark. By fine-tuning Llama3.1 with FMDID, FMDLlama3 achieves state-of-the-art performance on FMD-B, demonstrating that domain-specific instruction tuning can enable smaller models (8B parameters) to surpass larger closed-source models (170B parameters) on specialized tasks.

## Method Summary
The authors fine-tuned Llama3.1-8B-Instruct using the FMDID dataset, which combines classification and explanation generation tasks from FinFact and FinGuard datasets. The training used AdamW optimizer for 3 epochs with batch size 128 and learning rate 1e-6 (5% warm-up), requiring two Nvidia Tesla A100 GPUs with 80GB memory each. The model was evaluated on FMD-B benchmark using classification metrics (accuracy, precision, recall, F1) and generation metrics (ROUGE, BERTScore).

## Key Results
- FMDLlama3 (8B parameters) outperforms ChatGPT (170B parameters) on FMD tasks
- Instruction-tuned Llama3.1 achieves state-of-the-art performance on FMD-B benchmark
- Multi-task learning approach successfully handles both classification and explanation generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific instruction tuning improves LLM performance on financial misinformation detection tasks
- Mechanism: Fine-tuning Llama3.1 on a custom multi-task instruction dataset (FMDID) enables the model to specialize in detecting and explaining financial misinformation patterns that general LLMs may miss
- Core assumption: The structure and content of FMDID captures the specific characteristics of financial misinformation that differ from general misinformation
- Break condition: If FMDID doesn't capture domain-specific patterns or if the financial misinformation characteristics don't differ significantly from general misinformation patterns

### Mechanism 2
- Claim: Using a multi-task instruction dataset enables simultaneous classification and explanation generation for financial misinformation
- Mechanism: The FMDID combines both FinFact (classification + explanation) and FinGuard (classification only) datasets, allowing the model to learn both tasks in parallel
- Core assumption: Multi-task learning improves generalization across related financial misinformation detection subtasks
- Break condition: If the tasks interfere with each other during training or if the model prioritizes one task over the other

### Mechanism 3
- Claim: Fine-tuning smaller LLMs (8B parameters) can outperform larger closed-source models (170B parameters) on domain-specific tasks
- Mechanism: Domain-specific fine-tuning allows smaller models to develop specialized knowledge that larger general models lack, compensating for parameter differences
- Core assumption: Domain expertise is more valuable than model size for specialized tasks
- Break condition: If the domain-specific patterns change rapidly or if the tasks require general knowledge that the smaller model lacks

## Foundational Learning

- Concept: Instruction tuning methodology for LLMs
  - Why needed here: The paper's approach relies on creating and using instruction-tuned datasets rather than traditional fine-tuning approaches
  - Quick check question: What distinguishes instruction tuning from standard fine-tuning in LLM training?

- Concept: Financial misinformation detection as a multi-task problem
  - Why needed here: The system handles both classification (detecting misinformation) and explanation generation (providing reasoning)
  - Quick check question: How do classification and explanation generation tasks complement each other in misinformation detection?

- Concept: Evaluation metrics for generative models in misinformation detection
  - Why needed here: The paper uses a combination of classification metrics (accuracy, precision, recall, F1) and generation metrics (ROUGE, BERTScore)
  - Quick check question: Why are both classification and generation metrics necessary for evaluating financial misinformation detection models?

## Architecture Onboarding

- Component map: Raw datasets (FinFact, FinGuard) → Instruction template processing → FMDID (instruction-tuning dataset) → FMDID → LLM fine-tuning (Llama2, Llama3.1) → FMDLlama models → FMDLlama models + FMD-B benchmark → Performance evaluation

- Critical path: Raw data collection → Instruction dataset creation → LLM fine-tuning → Benchmark evaluation → Performance analysis

- Design tradeoffs: The choice of Llama3.1-8B over larger models balances computational efficiency with performance, while the multi-task approach trades potential task interference for broader capability

- Failure signatures: Poor performance on longer texts (as seen with smaller PLMs), inability to generate coherent explanations, overfitting to specific dataset patterns

- First 3 experiments:
  1. Fine-tune Llama3.1-8B on FMDID and evaluate on FMD-B benchmark
  2. Compare FMDLlama3 performance against zero-shot prompting of Llama3.1-8B on FMD-B
  3. Test ablation study by training on only classification tasks vs. only explanation tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would larger language models (beyond 8B parameters) perform on financial misinformation detection tasks?
- Basis in paper: [explicit] The paper mentions "Due to restricted computational resources, we only carried out instruction-tuning/evaluation of financial misinformation detection tasks using 7b/13b LLMs. As such, we have not considered the impact of using larger models on the FMD tasks."
- Why unresolved: The study was limited by computational resources, preventing evaluation of larger models that might achieve even better performance.
- What evidence would resolve it: Experimental results comparing FMDLlama models with larger parameter sizes (e.g., 30B, 65B, 175B) on the FMD-B benchmark would provide conclusive evidence.

### Open Question 2
- Question: How generalizable is FMDLlama across different financial domains and languages?
- Basis in paper: [inferred] The paper states future work will "augment the FMDID and FMD-B datasets with further FMD datasets, including data from multiple platforms, sources, domains and languages" suggesting current limitations.
- Why unresolved: The current dataset and benchmark are based on only two datasets covering limited domains, making it unclear how well the model performs on other financial subdomains or non-English text.
- What evidence would resolve it: Testing FMDLlama on diverse financial domains (cryptocurrency, banking, insurance) and multiple languages would demonstrate its generalizability.

### Open Question 3
- Question: What is the optimal balance between classification accuracy and explanation quality in FMDLlama?
- Basis in paper: [inferred] The model handles both classification and explanation generation tasks, but the paper doesn't discuss potential trade-offs between these objectives.
- Why unresolved: The paper evaluates both tasks but doesn't analyze whether optimizing for both simultaneously leads to compromises in either classification accuracy or explanation quality.
- What evidence would resolve it: Ablation studies varying the emphasis on classification versus explanation generation during training would reveal optimal parameter balances for different use cases.

## Limitations
- Dataset representativeness: The FMDID dataset combines FinFact and FinGuard datasets, but the relative contributions and potential biases from each source are not fully characterized.
- Evaluation scope: The paper does not address multilingual scenarios or domain-specific jargon that may vary across financial sectors.
- Model efficiency considerations: The computational requirements for fine-tuning and inference are not fully detailed beyond the initial training setup.

## Confidence
- High confidence: The claim that FMDLlama3 (8B parameters) outperforms ChatGPT (170B parameters) on FMD tasks is supported by direct quantitative evidence from the evaluation benchmark.
- Medium confidence: The assertion that domain-specific instruction tuning is the primary mechanism for improved performance lacks ablation studies to definitively isolate this factor.
- Low confidence: The claim that FMDLlama represents the first open-sourced LLM fine-tuned specifically for FMD tasks is difficult to verify definitively.

## Next Checks
1. Conduct ablation study comparing FMDLlama3 fine-tuned on FMDID against the same model architecture trained with standard fine-tuning on the same data.
2. Evaluate FMDLlama3 on financial misinformation datasets from different time periods or financial sectors not represented in the training data to assess real-world robustness.
3. Perform comprehensive analysis of computational requirements for fine-tuning FMDLlama3 on various hardware configurations to understand practical deployment scenarios.