---
ver: rpa2
title: Deep Reinforcement Learning for Adverse Garage Scenario Generation
arxiv_id: '2407.01333'
source_url: https://arxiv.org/abs/2407.01333
tags:
- garage
- road
- parking
- learning
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a deep reinforcement learning-based procedural
  generation framework for creating diverse and challenging 3D underground parking
  garage scenarios to test autonomous driving algorithms. The framework generates
  2D encoding matrices using reinforcement learning, which are then transformed into
  3D models and road network files compatible with the Carla simulator.
---

# Deep Reinforcement Learning for Adverse Garage Scenario Generation

## Quick Facts
- arXiv ID: 2407.01333
- Source URL: https://arxiv.org/abs/2407.01333
- Reference count: 34
- Key outcome: Deep reinforcement learning framework generates diverse 3D underground parking garage scenarios to test autonomous driving algorithms, with coverage primarily above 0.4 and varying difficulty levels

## Executive Summary
This paper presents a deep reinforcement learning-based procedural generation framework for creating diverse and challenging 3D underground parking garage scenarios to test autonomous driving algorithms. The framework generates 2D encoding matrices using reinforcement learning, which are then transformed into 3D models and road network files compatible with the Carla simulator. Two evaluation metrics, coverage and difficulty, are introduced to assess the diversity and complexity of generated garages. Experimental results show that the framework can produce garages with coverage primarily above 0.4 and varying difficulty levels.

## Method Summary
The framework uses deep reinforcement learning to generate diverse 2D encoding matrices representing parking garage structures, which are then converted into 3D models and road networks compatible with Carla. The parking garage generation is modeled as a Markov Decision Process where an agent "colors" blocks in a grid, following constraints and utility rules to maximize rewards. The Deep Q-Network (DQN) algorithm is employed to train the agent. Two evaluation metrics, coverage (percentage of occupied blocks) and difficulty (based on expected road length and intersection count), are introduced to assess the diversity and complexity of generated garages.

## Key Results
- Generated garages achieve coverage primarily above 0.4
- Varying difficulty levels successfully created
- Significant negative correlation between garage difficulty and autonomous driving algorithm success rate in Carla

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The procedural generation framework uses deep reinforcement learning to automatically create diverse 2D encoding matrices that are then transformed into 3D underground parking garage scenarios.
- Mechanism: The framework models the parking garage generation as a Markov Decision Process where an agent "colors" blocks in a grid, following constraints and utility rules to maximize rewards. The encoding matrix represents the planar structure, which is then converted into 3D models and road networks compatible with Carla.
- Core assumption: The MDP formulation accurately captures the constraints and utility rules needed for generating realistic and usable parking garages.
- Evidence anchors:
  - [abstract] "This paper presents a deep reinforcement learning-based procedural generation framework for creating diverse and challenging 3D underground parking garage scenarios"
  - [section] "This study employs the deep reinforcement learning approach to generate the encoding matrix, necessitating the definition of various metrics within the reinforcement learning framework for this problem"
  - [corpus] Weak evidence for deep RL procedural generation in underground parking scenarios

### Mechanism 2
- Claim: The framework introduces two evaluation metrics, coverage and difficulty, to assess the diversity and complexity of generated garages.
- Mechanism: Coverage measures the percentage of occupied blocks relative to the initial free blocks, indicating how much of the garage space is utilized. Difficulty approximates the expected road length and intersection count, with longer roads and more intersections considered more challenging.
- Core assumption: Coverage and difficulty metrics accurately reflect the diversity and complexity of parking garages relevant for testing autonomous driving algorithms.
- Evidence anchors:
  - [abstract] "Two evaluation metrics, coverage and difficulty, are introduced to assess the diversity and complexity of generated garages"
  - [section] "We establish two metrics to evaluate the diversity of generated parking lots: coverage δ and difficulty λ"
  - [corpus] Limited evidence on the effectiveness of coverage and difficulty metrics for parking garage evaluation

### Mechanism 3
- Claim: The framework validates the difficulty metric by testing autonomous driving algorithms in Carla, demonstrating a negative correlation between garage difficulty and algorithm success rate.
- Mechanism: Autonomous driving algorithms are tested in the generated garages, with their success rates measured. The correlation between success rate and difficulty is analyzed to validate the difficulty metric.
- Core assumption: The autonomous driving algorithms and testing setup in Carla accurately reflect real-world autonomous driving challenges in underground parking scenarios.
- Evidence anchors:
  - [abstract] "Autonomous driving algorithm tests in Carla demonstrate a significant negative correlation between garage difficulty and algorithm success rate, validating the effectiveness of the difficulty metric"
  - [section] "We plan to use the pre-trained model to test on 50 different difficulty garages generated from garage Figure 11c. We will statistically measure the success rate of testing on each garage and verify and analyze the correlation between the success rate of testing and the difficulty of the garage"
  - [corpus] Limited evidence on the correlation between garage difficulty and autonomous driving algorithm success rates

## Foundational Learning

- Concept: Markov Decision Processes (MDPs)
  - Why needed here: The framework models parking garage generation as an MDP, where an agent takes actions to maximize rewards based on the current state and transitions to new states.
  - Quick check question: What are the four components of an MDP, and how do they relate to the parking garage generation problem?

- Concept: Deep Reinforcement Learning (DRL)
  - Why needed here: The framework uses DRL, specifically the Deep Q-Network (DQN) algorithm, to train the agent to generate diverse and usable parking garages based on the MDP formulation.
  - Quick check question: How does DRL differ from traditional reinforcement learning, and why is it suitable for the parking garage generation problem?

- Concept: Procedural Content Generation (PCG)
  - Why needed here: The framework generates parking garage scenarios using algorithms, rather than manual design, to create diverse and challenging scenarios for testing autonomous driving algorithms.
  - Quick check question: What are the advantages and challenges of using PCG for generating testing scenarios in autonomous driving?

## Architecture Onboarding

- Component map:
  Initial map and parameters -> MDP Formulation -> Deep Reinforcement Learning (DQN) -> Encoding Matrix Generation -> 3D Model and Road Network Generation -> Carla Simulator -> Evaluation

- Critical path:
  1. Define MDP formulation based on parking garage constraints and utility rules
  2. Train DQN agent to generate diverse encoding matrices
  3. Convert encoding matrices to 3D models and road networks
  4. Import into Carla and test autonomous driving algorithms
  5. Evaluate generated scenarios using coverage and difficulty metrics
  6. Analyze correlation between difficulty and algorithm success rates

- Design tradeoffs:
  - Balancing diversity and usability of generated garages
  - Tradeoff between training time and quality of generated scenarios
  - Complexity of MDP formulation vs. computational efficiency

- Failure signatures:
  - Generated garages that are unrealistic or unusable
  - Lack of diversity in generated scenarios
  - Weak correlation between difficulty and algorithm success rates

- First 3 experiments:
  1. Train DQN agent on a simple initial map and evaluate the diversity and usability of generated garages
  2. Test the correlation between difficulty and algorithm success rates using a set of generated garages
  3. Analyze the impact of different MDP formulations or reward functions on the quality of generated scenarios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed framework's coverage metric correlate with real-world parking lot efficiency and usability?
- Basis in paper: [explicit] The paper defines coverage as a function of remaining vacant blocks in the parking lot.
- Why unresolved: While the paper validates the coverage metric through experiments, it doesn't establish a direct correlation between coverage and real-world parking lot efficiency.
- What evidence would resolve it: Empirical studies comparing parking lot usage data from generated garages with actual parking lot data.

### Open Question 2
- Question: Can the difficulty metric be improved to better reflect the actual test routes and real-world driving challenges?
- Basis in paper: [explicit] The paper acknowledges that the current difficulty metric may not intuitively reflect actual test routes.
- Why unresolved: The paper identifies this as a limitation but doesn't propose specific improvements or alternative formulations.
- What evidence would resolve it: Comparative analysis of different difficulty metric formulations and their correlation with autonomous driving algorithm performance.

### Open Question 3
- Question: How does the framework's performance scale with increasing parking lot size and complexity?
- Basis in paper: [inferred] The paper tests the framework on parking lots of varying sizes but doesn't extensively explore the upper limits of scalability.
- Why unresolved: The experiments focus on relatively small to medium-sized parking lots, leaving questions about performance on larger, more complex structures.
- What evidence would resolve it: Systematic testing of the framework on progressively larger and more complex parking lot configurations, analyzing performance metrics such as training time and generation quality.

## Limitations

- The framework's reliance on specific reward function parameters and pre-built 3D models introduces significant reproducibility challenges
- Limited evaluation of only five initial map types may not capture the full diversity of real-world underground parking garages
- The correlation between difficulty metrics and autonomous driving success rates may not generalize across different algorithms or real-world conditions

## Confidence

- High Confidence: The basic MDP formulation for parking garage generation and the conversion process from 2D matrices to 3D Carla-compatible files are well-established.
- Medium Confidence: The DQN implementation for generating diverse scenarios is theoretically sound, but the specific reward function parameters significantly impact outcomes.
- Low Confidence: The validation of difficulty metrics through correlation with autonomous driving success rates requires more extensive testing across diverse algorithms and scenarios.

## Next Checks

1. Conduct ablation studies on reward function parameters (kc, ku, ws, wr, wc, wXt_i, wYt_i) to determine their impact on coverage and difficulty metrics.
2. Test the generated scenarios with multiple autonomous driving algorithms to verify the consistency of difficulty metric correlation with success rates.
3. Expand the initial map diversity to include more realistic underground parking garage configurations and evaluate the framework's performance across this expanded set.