---
ver: rpa2
title: Gradient Estimation and Variance Reduction in Stochastic and Deterministic
  Models
arxiv_id: '2405.08661'
source_url: https://arxiv.org/abs/2405.08661
tags:
- gradient
- which
- page
- vehicle
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This dissertation develops a new gradient estimation method for
  unconstrained nonlinear optimization problems involving stochastic or piecewise
  continuous models. The core method, reverse differentiation, efficiently computes
  gradients in the same time complexity as evaluating the objective function, even
  for large models.
---

# Gradient Estimation and Variance Reduction in Stochastic and Deterministic Models

## Quick Facts
- arXiv ID: 2405.08661
- Source URL: https://arxiv.org/abs/2405.08661
- Authors: Ronan Keane
- Reference count: 0
- Primary result: New reverse differentiation method computes gradients in O(T(n)) time for unconstrained nonlinear optimization problems with stochastic and deterministic models

## Executive Summary
This dissertation develops a new gradient estimation method called reverse differentiation that efficiently computes gradients for unconstrained nonlinear optimization problems involving both stochastic and deterministic models. The method combines deterministic techniques like the adjoint method with stochastic approaches like score functions to handle both types of model components. It is validated through applications in traffic flow modeling, including car-following and lane-changing models, and shown to be more efficient than existing gradient-free methods. The work addresses three major pitfalls of differentiable models - piecewise functions with parameter-dependent switching conditions, discrete variables, and parameters controlling model duration - by introducing stochasticity to enable gradient-based optimization.

## Method Summary
The reverse differentiation method combines deterministic pathwise derivatives with score functions to compute unbiased gradient estimates for models containing both stochastic and deterministic components. For deterministic parts, the adjoint method efficiently computes gradients by solving a reverse-time system of equations. For stochastic parts, score functions provide gradient estimates using conditional distributions of random variables. The method reformulates piecewise continuous models with parameter-dependent switching conditions by introducing stochastic variables that encode which branch to use, making the switching condition learnable via score functions. This approach enables gradient-based optimization for a broader class of problems that were previously difficult to optimize.

## Key Results
- Reverse differentiation achieves O(T(n)) gradient computation time complexity versus O(mT(n)) for finite differences
- The method successfully calibrates car-following models to trajectory data with higher efficiency than gradient-free methods
- Reformulation of piecewise continuous models with stochastic variables resolves three major pitfalls: parameter-dependent switching, discrete variables, and model duration parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The reverse differentiation estimator combines deterministic pathwise derivatives with score functions to handle both stochastic and deterministic model components.
- Mechanism: When a model element depends on parameters (θ), it is reformulated using a random variable (y) with a known conditional distribution. Score functions ∂ log p(y|·)/∂θ then provide gradient estimates for those parameters, while pathwise derivatives handle deterministic parts.
- Core assumption: The conditional distribution of y must not depend on θ or on the random variables z used for pathwise derivatives.
- Evidence anchors:
  - [abstract] "combining deterministic techniques (like the adjoint method) with stochastic approaches (like score functions)"
  - [section 1.4] Formal theorem 1.1 derives unbiased gradient estimator using both deterministic and stochastic elements
  - [corpus] Neighbor paper "Multi-level Monte-Carlo Gradient Methods for Stochastic Optimization with Biased Oracles" supports variance reduction for stochastic components
- Break condition: If the conditional distribution of y depends on θ or z, the estimator becomes biased or undefined.

### Mechanism 2
- Claim: Piecewise continuous models with parameter-dependent switching conditions can be reformulated to be learnable via gradient descent.
- Mechanism: Replace explicit switching conditions (γ(·) > 0) with stochastic variables (y) that encode which branch to use. The probability distribution of y depends on the switching condition, making it learnable via score functions.
- Core assumption: The support of y does not depend on θ, ensuring unbiased gradient estimates.
- Evidence anchors:
  - [section 1.5.3] "introducing stochasticity, these issues are resolved, enabling the use of gradient-based optimization for a broader class of problems"
  - [section 3.3] Example shows recovery of deterministic behavior while learning switching condition
  - [corpus] Neighbor paper "Double Variance Reduction" supports variance reduction for complex objective structures
- Break condition: If the switching condition depends on parameters in a way that creates discontinuities, the reformulation fails unless additional stochasticity is introduced.

### Mechanism 3
- Claim: The adjoint method efficiently computes gradients for large models by solving a reverse-time system of equations.
- Mechanism: Introduce adjoint variables λ(t) that satisfy a reverse-time ODE derived from the original model. The gradient is then computed as a sum of vector-Jacobian products involving λ and model derivatives.
- Core assumption: The model and its partial derivatives must be piecewise continuous, and the number of discontinuities must be finite.
- Evidence anchors:
  - [section 5.4.1] Detailed derivation of adjoint system for car-following models
  - [section 5.4.3] Comparison shows adjoint method scales as O(T(n)) vs O(mT(n)) for finite differences
  - [corpus] Neighbor paper "Variance-reduced first-order methods" supports gradient computation for large-scale problems
- Break condition: If the model has infinite discontinuities or non-piecewise continuous components, the adjoint method cannot be applied.

## Foundational Learning

- Concept: Vector-Jacobian products (vjp) and their constant-time complexity
  - Why needed here: vjp is the core operation enabling efficient gradient computation in reverse differentiation
  - Quick check question: What is the time complexity of computing vjp(u, F, x) relative to evaluating F?

- Concept: Lipschitz continuity and its role in convergence guarantees
  - Why needed here: Lipschitz continuity of the expected gradient is required for SGD convergence in non-convex settings
  - Quick check question: How does unbiasedness of the gradient estimator relate to Lipschitz continuity of the expected objective?

- Concept: Score functions and their variance properties
  - Why needed here: Score functions provide unbiased gradient estimates for discrete variables but have higher variance than pathwise derivatives
  - Quick check question: When would you choose score functions over pathwise derivatives for a given model component?

## Architecture Onboarding

- Component map: Forward pass -> Reverse pass -> Variance reduction -> Parameter update
- Critical path: Forward pass → Reverse pass → Variance reduction → Parameter update
- Design tradeoffs:
  - Memory vs. computation: Storing intermediate values enables efficient reverse pass but increases memory usage
  - Bias vs. variance: Score functions are unbiased but higher variance; pathwise derivatives have lower variance but require differentiability
  - Model complexity vs. tractability: More complex models require more sophisticated gradient estimation techniques

- Failure signatures:
  - High variance in gradient estimates: Indicates need for better variance reduction or reformulation using pathwise derivatives
  - Biased gradient estimates: Suggests conditional distributions depend on forbidden variables
  - Slow convergence: May indicate Lipschitz continuity assumptions not satisfied or poor learning rate choice

- First 3 experiments:
  1. Implement reverse differentiation on a simple piecewise linear model to verify unbiased gradient estimates
  2. Apply adjoint method to a small car-following model and compare gradient computation time to finite differences
  3. Test variance reduction on a stochastic differential equation with both continuous and discrete components

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the reverse differentiation method be effectively extended to handle stochastic differential equations (SDEs) with more complex noise structures beyond Brownian motion?
- Basis in paper: [explicit] The paper demonstrates the method's application to SDEs with Brownian motion noise, but mentions the possibility of extending it to other noise types like Poisson point processes.
- Why unresolved: The paper does not provide a detailed analysis or implementation of the method for SDEs with more complex noise structures.
- What evidence would resolve it: A rigorous mathematical proof of the method's validity for a broader class of SDEs, along with numerical experiments demonstrating its effectiveness on real-world problems involving complex noise.

### Open Question 2
- Question: How can the proposed gradient estimation method be applied to optimize control policies in reinforcement learning problems with high-dimensional state and action spaces?
- Basis in paper: [explicit] The paper applies the method to a simple reinforcement learning example, but the scalability and effectiveness for high-dimensional problems remain unexplored.
- Why unresolved: The paper does not provide a detailed analysis of the method's performance on large-scale reinforcement learning problems.
- What evidence would resolve it: A comprehensive study comparing the proposed method to existing reinforcement learning algorithms on benchmark problems with high-dimensional state and action spaces.

### Open Question 3
- Question: What are the theoretical guarantees for the convergence of stochastic gradient descent (SGD) when using the proposed gradient estimation method with piecewise continuous models?
- Basis in paper: [inferred] The paper analyzes the convergence of SGD for the proposed method, but the analysis assumes differentiability of the model, which may not hold for piecewise continuous models.
- Why unresolved: The paper does not provide a rigorous analysis of the convergence properties of SGD for piecewise continuous models.
- What evidence would resolve it: A mathematical proof of the convergence of SGD for piecewise continuous models using the proposed method, along with numerical experiments demonstrating its effectiveness.

## Limitations
- The method's efficiency guarantees may not hold for highly complex models with many discontinuities or unknown distributions
- The unbiasedness of the combined gradient estimator depends on strict distributional assumptions that may not always be satisfied
- Limited empirical validation across diverse model classes beyond traffic flow modeling

## Confidence
- High confidence: The adjoint method's O(T(n)) complexity compared to O(mT(n)) for finite differences
- Medium confidence: The unbiasedness of the combined gradient estimator
- Medium confidence: The reformulation approach for piecewise continuous models

## Next Checks
1. Test the reverse differentiation method on a model with parameter-dependent switching conditions where the conditional distribution of the stochastic variable explicitly depends on parameters, to verify the unbiasedness claim under violated assumptions.

2. Implement the method on a non-traffic model (e.g., epidemiological compartmental model with discrete state transitions) to assess generalizability beyond the primary application domain.

3. Conduct systematic variance analysis comparing score function and pathwise derivative components across different levels of model stochasticity to quantify the practical impact of the variance reduction techniques.