---
ver: rpa2
title: Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction
  Using EHR Data
arxiv_id: '2403.04785'
source_url: https://arxiv.org/abs/2403.04785
tags:
- laboratory
- test
- data
- values
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes Large Language Multimodal Models (LLMMs) to
  predict chronic disease risk using EHR data. LLMMs combine text embeddings from
  clinical notes with laboratory test values using multi-head attention fusion.
---

# Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data

## Quick Facts
- arXiv ID: 2403.04785
- Source URL: https://arxiv.org/abs/2403.04785
- Reference count: 34
- Primary result: LLMMs achieve 73% accuracy for chronic disease prediction and 76% AUC for early-stage diabetes prediction

## Executive Summary
This study introduces Large Language Multimodal Models (LLMMs) for predicting chronic disease risk using Electronic Health Record (EHR) data. The approach combines clinical notes with laboratory test values through multi-head attention fusion, addressing the challenge of modeling both tabular and textual EHR data. By converting numerical laboratory values into textual descriptions, the method improves large language models' ability to learn contextual relationships. The research demonstrates superior performance over traditional machine learning methods, achieving 73% accuracy in multiclass chronic disease prediction and 76% AUC for early-stage diabetes prediction.

## Method Summary
The method involves pre-training large language models on clinical notes and converting laboratory test values into textual descriptions for LLM input. ClinicalBERT and BiomedBERT are used with attention fusion to achieve 73% accuracy in multiclass chronic disease prediction. For early-stage diabetes prediction, laboratory test values are transformed into text and processed using Flan T5, achieving 76% AUC. The approach employs multi-head attention fusion to combine text embeddings with laboratory value features, creating a multimodal learning framework that captures both clinical narrative and quantitative test data.

## Key Results
- ClinicalBERT and BiomedBERT with attention fusion achieve 73% accuracy for multiclass chronic disease prediction
- Flan T5 with textual laboratory test values achieves 76% AUC for early-stage diabetes prediction
- Superior performance compared to traditional machine learning methods
- Interpretable risk factors identified through Shapley value analysis

## Why This Works (Mechanism)
The approach works by addressing the fundamental challenge of combining heterogeneous EHR data types. Large language models excel at processing textual clinical notes but struggle with numerical laboratory values. By converting lab values to text descriptions, the method enables LLMs to leverage their contextual learning capabilities. Multi-head attention fusion then integrates these text embeddings with numerical features, allowing the model to capture complex relationships between clinical narratives and quantitative test results. This multimodal approach preserves the rich context of clinical notes while incorporating objective laboratory measurements.

## Foundational Learning

**EHR Data Structure**: Understanding the format and content of clinical notes versus laboratory test values is crucial. Quick check: Verify that clinical notes contain narrative descriptions while lab values are structured numerical data.

**Attention Mechanisms**: Multi-head attention allows the model to focus on relevant parts of the input. Quick check: Ensure the attention weights can be visualized and interpreted for debugging.

**Textual Conversion of Numerical Data**: Converting lab values to text descriptions enables LLM processing. Quick check: Compare model performance with raw numerical vs. textual lab inputs.

**Shapley Value Analysis**: Used for interpreting model predictions and identifying important features. Quick check: Validate that top features align with clinical knowledge.

## Architecture Onboarding

**Component Map**: Clinical Notes -> ClinicalBERT/BiomedBERT -> Text Embeddings -> Multi-head Attention Fusion -> Combined Features -> Prediction
Laboratory Values -> Text Conversion -> Flan T5 -> Text Embeddings -> Multi-head Attention Fusion -> Combined Features -> Prediction

**Critical Path**: The most critical components are the text conversion of lab values and the multi-head attention fusion mechanism. Without proper text conversion, LLMs cannot process numerical data effectively, and without attention fusion, the model cannot integrate multimodal information.

**Design Tradeoffs**: The study trades numerical precision for textual context by converting lab values to text. While this enables LLM processing, it may lose some quantitative information. The tradeoff appears worthwhile given the performance gains.

**Failure Signatures**: Models may underperform if clinical notes are sparse or laboratory values are missing. The textual conversion process may introduce noise if not properly implemented. Imbalanced datasets can lead to biased predictions.

**First Experiments**:
1. Train ClinicalBERT on clinical notes alone and evaluate baseline performance
2. Convert laboratory values to text and process with Flan T5 alone, comparing to numerical processing
3. Implement multi-head attention fusion and test on combined clinical note and lab value inputs

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Specific laboratory test items used for prediction are not fully detailed
- DNN architecture for encoding lab values is unspecified
- Clinical note preprocessing pipeline lacks sufficient detail for exact replication
- Computational resource requirements and training time are not reported

## Confidence

**High Confidence**: The core methodology of combining clinical notes with laboratory test values using attention fusion is well-established and the reported performance metrics are plausible.

**Medium Confidence**: Superiority over traditional ML methods is claimed but comparative analysis details are limited.

**Low Confidence**: Exact reproducibility of the Flan T5-based approach is uncertain due to incomplete specification of the textual lab value conversion process.

## Next Checks
1. Obtain the exact list of laboratory test items used for chronic disease prediction and verify their distribution across the dataset
2. Implement the DNN architecture for lab value encoding based on standard practices and test different configurations
3. Conduct ablation studies comparing model performance with raw numerical versus textual lab inputs