---
ver: rpa2
title: Leveraging Model Guidance to Extract Training Data from Personalized Diffusion
  Models
arxiv_id: '2410.03039'
source_url: https://arxiv.org/abs/2410.03039
tags:
- training
- data
- fine-tuning
- fine-tuned
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that fine-tuning data can be extracted
  from publicly shared diffusion model checkpoints by exploiting the shift in model
  distribution during fine-tuning. The authors propose FineXtract, which extrapolates
  between the pretrained and fine-tuned models' score functions to guide generation
  toward high-probability regions of the fine-tuned data distribution, followed by
  clustering to identify likely training images.
---

# Leveraging Model Guidance to Extract Training Data from Personalized Diffusion Models

## Quick Facts
- arXiv ID: 2410.03039
- Source URL: https://arxiv.org/abs/2410.03039
- Reference count: 40
- Primary result: FineXtract extracts ~20% of fine-tuning data with 0.45-0.55 similarity from public diffusion checkpoints

## Executive Summary
This paper demonstrates a novel method for extracting fine-tuning data from publicly shared diffusion model checkpoints by exploiting the distributional shift that occurs during fine-tuning. The authors propose FineXtract, which uses a combination of model guidance and clustering to generate images that closely match the fine-tuning data distribution. Through extensive experiments across multiple datasets and fine-tuning methods, they show that their approach significantly outperforms existing baselines in both extraction success rate and similarity metrics.

## Method Summary
FineXtract works by approximating fine-tuning as a gradual shift in the model's learned distribution and extrapolating between the pretrained and fine-tuned models' score functions to guide generation toward high-probability regions of the fine-tuning data distribution. The method first models the fine-tuned distribution as an interpolation between the pretrained and fine-tuning distributions, then uses this parametric approximation to guide sampling. Generated images are clustered to identify central images that closely match training samples. The approach works across different fine-tuning methods (DreamBooth, LoRA) and can handle scenarios with partial caption leakage.

## Key Results
- Extracts approximately 20% of training images with average similarity of 0.45-0.55 across multiple datasets
- Significantly outperforms baselines including classifier-free guidance and direct text-to-image generation
- Remains effective even with partial caption leakage and various diffusion model architectures
- Works across different fine-tuning methods (DreamBooth and LoRA) with appropriate guidance scale adjustments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FineXtract leverages the parametric shift in diffusion model distributions during fine-tuning to guide generation toward high-probability regions of the fine-tuning data distribution.
- Mechanism: The method models the fine-tuned model's distribution as an interpolation between the pretrained and fine-tuned data distributions, then extrapolates the score functions to guide sampling toward the fine-tuned data's high-density regions.
- Core assumption: Fine-tuning can be approximated as a gradual shift from the pretrained distribution toward the fine-tuning data distribution, allowing parametric modeling of this shift.
- Evidence anchors:
  - [abstract] "Our method approximates fine-tuning as a gradual shift in the model's learned distribution -- from the original pretrained DM toward the fine-tuning data"
  - [section 4.1] "we parametrically approximate that the learned distribution of the fine-tuned DMs, denoted as pθ′(x), satisfies: pθ′(x)∝p1−λθ(x)qλ(x)"
  - [corpus] Weak evidence - the corpus doesn't directly address this parametric approximation mechanism
- Break condition: If fine-tuning doesn't follow a smooth distributional shift (e.g., catastrophic forgetting or sudden distribution changes), the parametric approximation would fail.

### Mechanism 2
- Claim: Classifier-free guidance combined with model guidance enables conditional generation that targets the fine-tuned data distribution conditioned on specific prompts.
- Mechanism: By extrapolating from unconditional pretrained denoising predictions to conditional fine-tuned predictions, while adding a correction term, the method guides generation toward the conditional fine-tuned data distribution.
- Core assumption: The conditional fine-tuned data distribution is more concentrated than the unconditional one, allowing the correction term to compensate for the mismatch between CFG and model guidance.
- Evidence anchors:
  - [section 4.2] "We can adopt a similar approximation to the one presented in Sec. 4.1: pθ(x|c)∝p1−λ′θ(x)qλ′0(x|c)"
  - [section 4.2] "This implies that: ϵθ′(xt, t, c)≈(1−λ)(1−λ′)ϵθ(xt, t)+λ′(1−λ′)ϵq(xt, t)+λ′ϵq(xt, t, c)"
  - [corpus] Weak evidence - the corpus doesn't discuss conditional generation mechanisms in detail
- Break condition: If the conditional distribution isn't more concentrated than unconditional, or if the correction term calculation is inaccurate, the guidance would fail.

### Mechanism 3
- Claim: Clustering algorithm applied to generated images identifies central images that closely match training data samples.
- Mechanism: The method generates many images in high-probability regions, constructs a similarity graph, finds cliques corresponding to training images, and selects central images within each clique as extracted samples.
- Core assumption: Generated images in high-probability regions will cluster around training data samples, allowing clique detection to identify corresponding image groups.
- Evidence anchors:
  - [section 4.3] "we take inspiration from previous work (Carlini et al., 2023), sampling N images and applying a clustering algorithm to identify the images with the highest probability"
  - [section 4.3] "we connect two vertices when the similarity between the corresponding images exceeds a threshold ϕ"
  - [corpus] Weak evidence - the corpus doesn't discuss clustering approaches for data extraction
- Break condition: If generated images don't cluster appropriately around training samples (e.g., due to poor guidance or insufficient generation), the clustering would fail to identify training images.

## Foundational Learning

- Concept: Diffusion models and score matching
  - Why needed here: Understanding how diffusion models denoise images and the relationship between denoisers and score functions is crucial for implementing the model guidance mechanism
  - Quick check question: Can you explain how the predicted noise ϵθ(xt, t) relates to the score ∇x log q(x) in diffusion models?

- Concept: Classifier-free guidance (CFG)
  - Why needed here: CFG is the baseline method being compared against and understanding its mechanism is necessary for implementing the combined guidance approach
  - Quick check question: How does classifier-free guidance modify the denoising process compared to standard diffusion sampling?

- Concept: Few-shot fine-tuning techniques (DreamBooth, LoRA)
  - Why needed here: The method must work across different fine-tuning approaches, requiring understanding of how each modifies the model
  - Quick check question: What are the key differences between DreamBooth and LoRA in terms of how they modify the pretrained model?

## Architecture Onboarding

- Component map: Pretrained diffusion model (θ) -> Fine-tuned diffusion model (θ′) -> Score function extrapolation module -> Sampling loop with guidance -> Image clustering module -> Similarity computation module

- Critical path: Load models → Compute guidance extrapolation → Generate images → Cluster and select central images → Output extracted dataset

- Design tradeoffs:
  - Generation count N vs. clustering accuracy (higher N improves accuracy but increases computation)
  - Guidance scale w' vs. generation quality (higher w' provides stronger guidance but may cause failures)
  - Clustering threshold ϕ vs. clique detection (lower thresholds create more connections, higher thresholds may miss matches)

- Failure signatures:
  - Generated images are unrealistic or low quality → Check guidance scale and model loading
  - Clustering fails to converge → Increase generation count or adjust similarity threshold
  - Low extraction success rate → Verify models are correctly loaded and guidance is properly computed

- First 3 experiments:
  1. Verify model loading: Load pretrained and fine-tuned models, check they produce reasonable outputs separately
  2. Test guidance mechanism: Implement score extrapolation and verify it modifies generation direction as expected
  3. Validate clustering: Generate a small set of images and verify the clustering algorithm can identify central images correctly

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal guidance scale w' for FineXtract when extracting training data from diffusion models fine-tuned with different methods (DreamBooth vs LoRA)?
- Basis in paper: [explicit] The paper mentions that different guidance scales are needed for different fine-tuning methods, with w' = 3.0 for DreamBooth and w' = 5.0 for LoRA in the main experiments.
- Why unresolved: The paper only provides empirical guidance scale values that worked well in their experiments. There is no theoretical justification for why these specific values are optimal, nor is there a systematic exploration of how w' should be chosen based on fine-tuning method, model architecture, or dataset characteristics.
- What evidence would resolve it: A comprehensive ablation study showing extraction performance across a wide range of w' values for different fine-tuning methods, model architectures, and dataset sizes, along with theoretical analysis of the relationship between w' and the interpolation parameter λ in the fine-tuning process.

### Open Question 2
- Question: How does the performance of FineXtract degrade under more sophisticated defense mechanisms beyond Cutout and RandAugment?
- Basis in paper: [explicit] The paper only tests FineXtract against two defenses: Cutout and RandAugment, finding partial effectiveness at the cost of generation quality.
- Why unresolved: The paper only explores simple preprocessing defenses. More advanced defenses could include adversarial training during fine-tuning, differential privacy, data augmentation techniques specifically designed to prevent memorization, or architectural modifications to diffusion models.
- What evidence would resolve it: Experiments testing FineXtract against a comprehensive suite of defense mechanisms, including membership inference defenses, differential privacy fine-tuning, adversarial training, and architectural modifications, measuring both extraction success rates and generation quality trade-offs.

### Open Question 3
- Question: Can the caption extraction algorithm reliably recover training captions for longer prompts beyond 7 words?
- Basis in paper: [explicit] The paper shows that the caption extraction algorithm works well for prompts up to 7 words, but mentions that longer prompts become more challenging to extract.
- Why unresolved: The paper only provides limited results for longer prompts and doesn't establish the maximum prompt length for which reliable extraction is possible, nor does it analyze how extraction accuracy degrades with increasing prompt length.
- What evidence would resolve it: Systematic experiments testing the caption extraction algorithm on prompts of varying lengths (e.g., 3, 7, 15, 30 words), measuring extraction accuracy and identifying at what prompt length the algorithm fails to recover meaningful information.

## Limitations

- Core assumption uncertainty: The parametric approximation of fine-tuning as a gradual distributional shift remains largely theoretical without extensive empirical validation across diverse fine-tuning scenarios.
- Guidance mechanism fragility: The combined classifier-free and model guidance approach relies on precise calibration of guidance scale and correction terms, which may be difficult to optimize across different scenarios.
- Computational scalability: The clustering approach requires generating large numbers of images and performing quadratic similarity computations, limiting practical applicability for large-scale extraction.

## Confidence

**High Confidence**: The core extraction methodology and its general effectiveness across multiple datasets and fine-tuning methods are well-supported by experimental results.

**Medium Confidence**: The theoretical foundations of the parametric approximation and guidance mechanisms are reasonable but require more rigorous mathematical justification.

**Low Confidence**: The method's performance with partial caption leakage, diverse diffusion model architectures, and real-world checkpoints shows promise but lacks comprehensive evaluation across the full range of potential deployment scenarios.

## Next Checks

**Validation Check 1**: Test the extraction method across a broader range of fine-tuning datasets and model architectures, particularly focusing on scenarios with limited training data and different fine-tuning approaches beyond DreamBooth and LoRA.

**Validation Check 2**: Conduct a systematic ablation study varying the guidance scale w′, generation count N, and clustering parameters to determine optimal configurations for different fine-tuning scenarios.

**Validation Check 3**: Evaluate the method's effectiveness when fine-tuning uses data augmentation techniques and when training data contains significant redundancy or near-duplicates, which could affect the clustering and extraction process.