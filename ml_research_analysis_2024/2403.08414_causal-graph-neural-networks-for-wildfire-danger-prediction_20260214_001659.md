---
ver: rpa2
title: Causal Graph Neural Networks for Wildfire Danger Prediction
arxiv_id: '2403.08414'
source_url: https://arxiv.org/abs/2403.08414
tags:
- causal
- learning
- graph
- variables
- wildfire
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a Causal Graph Neural Network (GNN) for wildfire
  danger prediction, addressing the challenge of modeling complex interactions between
  weather, vegetation, and human activities. The method integrates causality with
  GNNs to explicitly model causal mechanisms among variables using graph learning.
---

# Causal Graph Neural Networks for Wildfire Danger Prediction

## Quick Facts
- arXiv ID: 2403.08414
- Source URL: https://arxiv.org/abs/2403.08414
- Authors: Shan Zhao; Ioannis Prapas; Ilektra Karasante; Zhitong Xiong; Ioannis Papoutsis; Gustau Camps-Valls; Xiao Xiang Zhu
- Reference count: 12
- One-line primary result: Causal GNN outperforms baselines on wildfire danger prediction, especially on imbalanced datasets, by modeling true causal relationships and revealing teleconnection memory effects.

## Executive Summary
This paper introduces a Causal Graph Neural Network (GNN) for wildfire danger prediction, addressing the challenge of modeling complex interactions between weather, vegetation, and human activities. The method integrates causality with GNNs to explicitly model causal mechanisms among variables using graph learning. By computing a causal adjacency matrix through the PCMCI method, the approach captures synergistic effects and removes spurious links from highly correlated variables. Experiments on European boreal and Mediterranean biomes demonstrate superior performance compared to baselines, especially on highly imbalanced datasets, with enhanced robustness to regime shifts.

## Method Summary
The method combines causal graph discovery with Graph Neural Networks for wildfire danger prediction. Local weather variables (temperature, precipitation, vapor pressure deficit) and Oceanic and Climatic Indices (NAO, AO, Nino3.4) are processed through an LSTM to extract temporal node features. The PCMCI method computes a causal adjacency matrix representing true causal relationships among variables. A GNN with LayerNorm and LeakyReLU layers performs message passing along causal links, followed by graph pooling to aggregate global information. The model outputs binary classification via softmax, trained to predict burned areas from the SeasFire Datacube dataset spanning 21 years with 8-day temporal and 0.25-degree spatial resolution.

## Key Results
- Causal GNN outperforms LSTM, GRU, correlation-based GNN, and fully connected GNN baselines on AUPRC and AUROC metrics
- Superior performance particularly evident on highly imbalanced datasets (10% positive samples)
- SHAP analysis reveals memory effects of teleconnections, with increased importance for OCIs at large time lags
- Model demonstrates enhanced robustness to regime shifts compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal adjacency matrix removes spurious links and captures synergistic effects
- Mechanism: PCMCI causal discovery identifies true causal parents while filtering out non-causal correlations, encoding only true causal links in the adjacency matrix to avoid over-smoothing from redundant edges
- Core assumption: Causal stationarity holds after preprocessing (mean removal, monthly resampling)
- Evidence anchors: Abstract mentions "synergistic effect among variables and removes the spurious links"; section describes PCMCI as selection algorithm
- Break condition: If causal stationarity is violated, spurious links may remain or true links may be missed

### Mechanism 2
- Claim: Graph pooling aggregates global information from the entire causal graph
- Mechanism: After node features are updated through message passing along causal links, graph pooling averages these features to produce a global representation capturing overall system state
- Core assumption: Average of node features meaningfully summarizes causal graph state
- Evidence anchors: Section states "graph pooling at the last layer of GNN gathers the global information from the whole graph"
- Break condition: If causal graph is too sparse or important nodes are excluded, global aggregation may lose critical information

### Mechanism 3
- Claim: SHAP values reveal memory effect of teleconnections in driving wildfire danger
- Mechanism: SHAP values quantify feature contributions to predictions; high values for OCIs at large lags indicate delayed teleconnection impacts reflecting atmospheric memory effects
- Core assumption: SHAP values accurately attribute feature importance in this model
- Evidence anchors: Abstract mentions "SHAP analysis reveals the memory effect of teleconnections"; section notes "increased value on large lags signifies memory effects"
- Break condition: If model has learned spurious relationships, SHAP attributions may highlight misleading features

## Foundational Learning

- Concept: Causal inference and graph-based modeling
  - Why needed here: To model complex interactions between weather, vegetation, and human activities driving wildfires, and to distinguish true causal relationships from spurious correlations
  - Quick check question: What is the difference between correlation and causation, and why is it important for wildfire prediction?

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: To process causal graph structure and perform message passing along causal links to update node features representing temporal patterns of variables
  - Quick check question: How do GNNs differ from standard neural networks in handling structured data?

- Concept: Teleconnections and atmospheric memory effects
  - Why needed here: To understand how large-scale climate patterns like El Niño influence wildfire danger over extended time lags, critical for accurate forecasting
  - Quick check question: What is a teleconnection, and how can it affect local weather conditions relevant to wildfires?

## Architecture Onboarding

- Component map: Input (local variables + OCI variables with temporal lags) -> LSTM (extract node features) -> Node feature update (GNN with causal adjacency) -> Graph pooling (global aggregation) -> Classification (softmax)
- Critical path: Input → LSTM → Node feature update (GNN) → Graph pooling → Classification
- Design tradeoffs:
  - Static causal graph vs. learnable causal graph that adapts over time
  - Fully connected graph (more information but more noise) vs. causal graph (less noise but may miss some links)
  - Complex temporal features vs. simpler features for faster computation
- Failure signatures:
  - Overfitting on training data but poor performance on imbalanced test data
  - SHAP values highlighting features that don't align with domain knowledge
  - Performance degradation with increasing forecasting horizons
- First 3 experiments:
  1. Replace causal adjacency matrix with fully connected one and compare AUPRC/AUROC
  2. Use correlation-based adjacency matrix instead of causal and evaluate performance
  3. Test model on balanced dataset to see if performance improves

## Open Questions the Paper Calls Out
- How would performance change with a learnable causal graph instead of static one derived from PCMCI?
- What is the impact of different preprocessing methods on causal discovery and subsequent model performance?
- How well does the Causal-GNN generalize to regions outside of Europe's boreal and Mediterranean biomes?

## Limitations
- Methodology relies heavily on PCMCI causal discovery with sparse implementation details
- Preprocessing steps to ensure causal stationarity remain underspecified
- Absence of domain-specific validation for causal graph structure
- SHAP-based interpretation of teleconnection memory effects lacks direct empirical support

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Causal adjacency matrix improves performance on imbalanced datasets | High |
| PCMCI removes spurious links and captures synergistic effects | Medium |
| SHAP reveals teleconnection memory effects | Low |

## Next Checks

1. Perform domain expert review of causal graph structure to verify identified links align with established wildfire science and atmospheric dynamics
2. Conduct ablation study varying significance threshold in PCMCI and maximum time delay to assess sensitivity of model performance to these parameters
3. Compare SHAP attributions with feature importance rankings from permutation tests to validate that identified teleconnection memory effects are not artifacts of model architecture