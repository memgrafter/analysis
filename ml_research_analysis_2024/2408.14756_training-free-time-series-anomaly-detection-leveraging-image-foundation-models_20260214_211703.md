---
ver: rpa2
title: 'Training-Free Time-Series Anomaly Detection: Leveraging Image Foundation Models'
arxiv_id: '2408.14756'
source_url: https://arxiv.org/abs/2408.14756
tags:
- anomaly
- time
- detection
- series
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ITF-TAD, a training-free approach for time-series
  anomaly detection that leverages image foundation models. ITF-TAD converts time-series
  data into images using wavelet transform and compresses them into a single representation,
  allowing the use of pre-trained image foundation models for anomaly detection without
  additional neural network training or hyperparameter tuning.
---

# Training-Free Time-Series Anomaly Detection: Leveraging Image Foundation Models

## Quick Facts
- **arXiv ID**: 2408.14756
- **Source URL**: https://arxiv.org/abs/2408.14756
- **Reference count**: 40
- **Primary result**: ITF-TAD achieves training-free time-series anomaly detection by converting data to images using wavelet transform and leveraging pre-trained image foundation models, outperforming or matching deep models on five benchmark datasets

## Executive Summary
This paper introduces ITF-TAD, a novel training-free approach for time-series anomaly detection that converts time-series data into images using wavelet transform and leverages pre-trained image foundation models. By aggregating scalograms generated from complex Morlet and Ricker wavelets into RGB images, ITF-TAD enables anomaly detection without additional neural network training or hyperparameter tuning. The method demonstrates high performance across five benchmark datasets, including both univariate and multivariate time series, while providing detailed visualization of anomalies and their corresponding frequencies.

## Method Summary
ITF-TAD converts multivariate time-series data into images through continuous wavelet transform (CWT) using complex Morlet and Ricker wavelets to generate scalograms. These scalograms are aggregated via PCA or random matrix mapping and embedded into RGB images with frequency encoding. The method then applies PatchCore, a semi-supervised image anomaly detection model using a pre-trained Wide ResNet-50-2, to compute anomaly scores. The entire process requires no neural network training or hyperparameter tuning, making it both efficient and accessible for practical deployment.

## Key Results
- ITF-TAD outperforms or matches deep learning baselines on five benchmark datasets (UCR, PSM, SMAP, MSL, SMD)
- Achieves F1-score with score partitioning (F1*-SP) of 0.821 on UCR, 0.830 on PSM, and 0.759 on SMAP
- Demonstrates computational efficiency by leveraging pre-trained image foundation models without requiring additional training
- Provides detailed visualization of anomalies across different frequency bands through dual wavelet approach

## Why This Works (Mechanism)

### Mechanism 1
ITF-TAD achieves training-free anomaly detection by converting time-series data into images that pre-trained image foundation models can process. Time-series data is transformed into scalograms using continuous wavelet transform (CWT) with dual mother wavelets (complex Morlet and Ricker). These scalograms are aggregated into RGB images compatible with pre-trained image foundation models. PatchCore then identifies anomalies by computing distances from nearest points in the coreset. The core assumption is that scalograms retain sufficient temporal and frequency information to represent anomalies, and image foundation models can effectively detect anomalies in these representations.

### Mechanism 2
Dual mother wavelets (complex Morlet and Ricker) improve anomaly detection sensitivity across different frequency characteristics and phase shifts. Complex Morlet wavelet captures frequency characteristics with high sensitivity but loses temporal accuracy, while Ricker wavelet captures phase shifts with high sensitivity but has lower frequency sensitivity. Combining both provides complementary information. The core assumption is that anomalies manifest differently in frequency characteristics versus phase shifts, and combining both perspectives captures a broader range of anomaly types.

### Mechanism 3
Frequency encoding in channel embedding prevents false positives by maintaining positional information in frequency bands. During channel embedding, one RGB channel encodes frequency indexes, which serves as positional encoding similar to transformers. This ensures that image anomaly detection models can differentiate where learned normal image patches are located within a test image across different frequency bands. The core assumption is that most image anomaly detection models ignore positional information, leading to false positives when similar patches appear in different frequency bands.

## Foundational Learning

- **Continuous Wavelet Transform (CWT)**: Transforms time-series data into scalograms that capture both temporal and frequency information, essential for representing anomalies in a form suitable for image-based detection. *Quick check: What is the primary difference between CWT and Fourier Transform in terms of time-frequency representation?*

- **Principal Component Analysis (PCA)**: Used for component-wise mapping to compress aggregated scalograms while minimizing information loss, making them compatible with image foundation models that require fewer channels. *Quick check: How does PCA differ from random matrix mapping in terms of information preservation during dimensionality reduction?*

- **Semi-supervised anomaly detection**: ITF-TAD uses PatchCore, which learns from normal data without requiring anomaly labels, making it suitable for real-world scenarios where anomaly data is scarce. *Quick check: What is the key difference between semi-supervised and unsupervised anomaly detection in terms of training data requirements?*

## Architecture Onboarding

- **Component map**: Input: Multivariate time-series data (Xd) -> CWT processing: Scalogram generation using complex Morlet and Ricker wavelets -> Aggregation: PCA or random matrix mapping with channel embedding (RGB + frequency encoding) -> Detection: PatchCore with pre-trained image foundation model (Wide ResNet-50-2) -> Output: Anomaly scores and visualizations

- **Critical path**: 1. CWT generation for each dimension and mother wavelet 2. Aggregation and channel embedding to create RGB images 3. PatchCore anomaly detection on aggregated images 4. Anomaly score computation and post-processing

- **Design tradeoffs**: PCA mapping vs. random mapping: PCA preserves more structured information but is computationally expensive; random mapping is faster but may lose some information. Scalogram resolution vs. computational efficiency: Higher resolution captures more detail but increases computation time. Frequency encoding vs. simpler RGB images: Frequency encoding improves accuracy but adds complexity.

- **Failure signatures**: Poor anomaly localization indicates issues with scalogram generation or frequency encoding. High false positive rate suggests problems with channel embedding or foundation model generalization. Slow processing points to inefficiencies in CWT computation or image processing pipeline.

- **First 3 experiments**: 1. Verify scalogram generation: Test CWT output for known anomalies to ensure frequency-time characteristics are captured 2. Test channel embedding: Compare anomaly detection with and without frequency encoding to quantify its impact 3. Evaluate mapping methods: Compare PCA vs. random mapping performance and computational costs on a small dataset

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice of wavelet transform parameters (e.g., frequency resolution Ω) affect the performance of ITF-TAD? The paper mentions that Ω is set to min(n, T/D) for PCA mapping and n for random mapping, but does not explore the impact of varying these values.

- **Open Question 2**: How does ITF-TAD's performance compare to other image-based anomaly detection methods that do not use foundation models? The paper focuses on leveraging image foundation models but does not compare its approach to other image-based TAD methods.

- **Open Question 3**: How does ITF-TAD handle multivariate time series with different scales and units across dimensions? The paper mentions normalization of scalograms but does not discuss handling of different scales across dimensions in multivariate time series.

- **Open Question 4**: What is the impact of using different image foundation models (e.g., other than ResNet-type classifiers) on ITF-TAD's performance? The paper mentions using a pretrained ResNet-type classifier as the foundation model but does not explore other options.

## Limitations

- The dual wavelet approach lacks direct validation showing why both complex Morlet and Ricker are necessary versus using either alone
- Computational efficiency claims need scrutiny as CWT computation and image processing may introduce overhead for large-scale applications
- Performance may not generalize to all time-series anomaly detection scenarios, particularly those with very short or very long anomalies

## Confidence

- **High Confidence**: The core claim that time-series can be converted to images for anomaly detection using existing foundation models is well-supported by the methodology and experimental results.
- **Medium Confidence**: The specific dual wavelet mechanism and frequency encoding contributions to performance improvements, as these lack direct ablation studies.
- **Medium Confidence**: The claim of "outperforming or matching deep models" is supported on benchmark datasets, but may not generalize to all time-series anomaly detection scenarios.

## Next Checks

1. **Ablation Study on Wavelet Selection**: Run ITF-TAD with only complex Morlet wavelet, only Ricker wavelet, and the dual approach on all five datasets to quantify the specific contribution of each wavelet type.

2. **Frequency Encoding Impact Test**: Implement a simplified version without frequency encoding in the channel embedding and compare performance metrics (F1*-SP, AUCPR-SP) to measure the actual impact of this design choice.

3. **Computational Efficiency Benchmark**: Measure end-to-end processing time for ITF-TAD including CWT computation, image generation, and anomaly detection on large datasets, comparing against traditional deep learning approaches to validate efficiency claims.