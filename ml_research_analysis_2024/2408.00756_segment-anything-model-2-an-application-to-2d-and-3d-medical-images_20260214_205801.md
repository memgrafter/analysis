---
ver: rpa2
title: 'Segment anything model 2: an application to 2D and 3D medical images'
arxiv_id: '2408.00756'
source_url: https://arxiv.org/abs/2408.00756
tags:
- segmentation
- medical
- slice
- images
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the Segment Anything Model 2 (SAM 2) for medical
  image segmentation tasks. The authors assess SAM 2's performance on both 2D and
  3D medical images across 18 diverse datasets, including MRI, CT, PET, X-ray, and
  ultrasound modalities.
---

# Segment anything model 2: an application to 2D and 3D medical images

## Quick Facts
- arXiv ID: 2408.00756
- Source URL: https://arxiv.org/abs/2408.00756
- Reference count: 37
- Primary result: SAM 2 shows comparable 2D medical segmentation to SAM but poor 3D performance (IoU 0.19) due to memory mechanism limitations

## Executive Summary
This paper evaluates Segment Anything Model 2 (SAM 2) for medical image segmentation tasks across 18 diverse datasets spanning MRI, CT, PET, X-ray, and ultrasound modalities. The authors assess SAM 2's performance on both single-frame 2D segmentation and multi-frame 3D segmentation tasks. While SAM 2 performs comparably to the original SAM for 2D medical image segmentation with box prompts outperforming point prompts, its 3D segmentation capabilities are severely limited by the memory attention mechanism's inability to handle large inter-slice variations in medical volumes.

## Method Summary
The study evaluates SAM 2 across 18 medical imaging datasets using two settings: single-frame 2D segmentation and multi-frame 3D segmentation. For 2D segmentation, SAM 2 is tested with four prompt modes combining point/box prompts and single/multiple prompts. For 3D segmentation, the authors explore three frame selection modes, two prompt modes, two propagation directions, and two mask selection strategies, creating 24 experimental designs. Performance is measured using Intersection over Union (IoU) on non-empty slices.

## Key Results
- SAM 2 achieves IoU scores comparable to original SAM for 2D medical image segmentation
- Box prompts consistently outperform point prompts across all datasets (p < 0.001)
- Multi-frame 3D segmentation performance is significantly worse with average IoU of 0.19
- Selecting the first predicted mask channel performs better than highest-confidence selection for medical segmentation tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAM 2's memory attention mechanism improves video segmentation but fails for medical volumes due to insufficient temporal coherence.
- Mechanism: SAM 2 uses a memory bank that retains information from past predictions and conditions current slice features on previously predicted slices. This works well for videos where consecutive frames are similar, but medical volumes have large inter-slice variations that break this assumption.
- Core assumption: The memory attention can effectively propagate segmentation information across slices when the change between consecutive slices is small.
- Evidence anchors:
  - [abstract]: "SAM 2 proposes a memory bank that retains information from past predictions and allows it to make predictions on slices without prompts based on the information."
  - [section]: "This feature motivates us to examine SAM 2's ability to segment 3D medical images since video segmentation can be transferred to 3D segmentation seamlessly, i.e., each slice is treated as a frame."
  - [corpus]: Weak - no direct evidence about memory mechanism failure in medical volumes found in corpus.
- Break condition: When inter-slice differences exceed the memory mechanism's ability to bridge the gap, typically in deep volumes with non-linear object changes.

### Mechanism 2
- Claim: Box prompts outperform point prompts because they provide more spatial context for the model to infer object boundaries.
- Mechanism: The mask decoder in SAM 2 uses the prompt information to generate multiple mask candidates. Box prompts provide bounding box coordinates that give the model explicit spatial constraints, while point prompts only give single coordinate locations, requiring the model to infer boundaries from minimal information.
- Core assumption: The mask decoder can effectively utilize spatial constraints from box prompts to generate more accurate masks than from single point locations.
- Evidence anchors:
  - [section]: "Comparing the performance for different prompting modes, both the results on SAM and SAM 2 highlight the superiority of box prompts over point prompts."
  - [corpus]: Weak - no direct evidence about box vs point prompt performance found in corpus.
- Break condition: When the object shape is highly irregular or when the box prompt covers multiple disconnected regions.

### Mechanism 3
- Claim: Selecting the first predicted mask channel yields better results than highest confidence mask because the confidence metric doesn't align with medical annotation preferences.
- Mechanism: SAM 2's mask predictor generates multiple mask outputs with associated confidence scores. The paper finds that selecting the first channel (which tends to represent the smallest area) performs better than selecting the mask with highest confidence for medical segmentation tasks.
- Core assumption: The confidence metric used by SAM 2 doesn't accurately reflect the quality of segmentation for medical objects, which often require precise boundary delineation rather than coverage of the entire object.
- Evidence anchors:
  - [section]: "We observe that for the annotated slice, choosing the first channel's prediction achieves comparable or better performance than SAM 2's default method of choosing the most confident slice."
  - [corpus]: Weak - no direct evidence about mask selection strategies found in corpus.
- Break condition: When the smallest predicted mask is too conservative and misses important portions of the medical structure.

## Foundational Learning

- Concept: Intersection over Union (IoU) metric
  - Why needed here: The paper uses IoU as the primary evaluation metric for segmentation performance, so understanding how it's calculated and interpreted is crucial.
  - Quick check question: If a predicted mask covers 80% of the ground truth area and has 20% false positive area, what is the IoU score?

- Concept: Zero-shot segmentation
  - Why needed here: SAM 2 is a foundation model that performs zero-shot segmentation, meaning it can segment objects without being specifically trained on those objects.
  - Quick check question: What's the key difference between zero-shot and few-shot segmentation in terms of training data requirements?

- Concept: Prompt engineering in vision models
  - Why needed here: The paper extensively evaluates different prompting strategies (point vs box, single vs multiple prompts) and their impact on segmentation performance.
  - Quick check question: How does providing multiple prompts for disconnected regions of an object typically affect segmentation accuracy compared to a single prompt?

## Architecture Onboarding

- Component map: Input image → Image encoder → Prompt encoder → Memory attention (conditions on memory bank) → Mask decoder → Output masks
- Critical path: The memory bank stores compressed embeddings of previous predictions and conditions current slice features on previously predicted slices through memory attention
- Design tradeoffs: SAM 2 trades increased computational complexity and memory usage for the ability to segment videos without re-prompting each frame. The memory mechanism adds latency but enables temporal coherence.
- Failure signatures: Low IoU scores in 3D medical segmentation despite good 2D performance, particularly when propagating through deep volumes. Performance degradation when slice-to-slice changes are large.
- First 3 experiments:
  1. Run single-frame 2D segmentation on a 3D medical volume to establish baseline SAM 2 performance before testing 3D capabilities.
  2. Test bidirectional propagation starting from the center slice to verify the memory mechanism works in both directions.
  3. Compare first-channel selection vs highest-confidence selection on the annotated slice to confirm the optimal mask selection strategy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the depth of 3D medical volumes affect SAM 2's performance during propagation, and what is the optimal memory attention window size?
- Basis in paper: [explicit] The authors hypothesize that SAM 2's training on a frame width of 8 frames makes it most effective within this range, while medical volumes range from 10 to hundreds of slices.
- Why unresolved: The paper does not experimentally test different memory attention window sizes or investigate the relationship between volume depth and performance degradation.
- What evidence would resolve it: Experiments varying the memory attention window size and measuring performance on volumes of different depths would determine the optimal configuration.

### Open Question 2
- Question: Would fine-tuning SAM 2 specifically on medical imaging data improve its 3D segmentation performance compared to direct application?
- Basis in paper: [explicit] The authors conclude that "further fine-tuning and redesigning of the memory strategy are needed" for SAM 2 to be feasible for 3D medical imaging segmentation tasks.
- Why unresolved: The paper only evaluates SAM 2 without any domain-specific fine-tuning or architectural modifications.
- What evidence would resolve it: Fine-tuning SAM 2 on medical imaging datasets and comparing its 3D segmentation performance to the baseline results presented in the paper.

### Open Question 3
- Question: How does the large variation between consecutive slices in medical volumes impact SAM 2's propagation performance compared to natural video data?
- Basis in paper: [explicit] The authors note that "the change between consecutive slices can be large for medical volumes due to the nature of medical imaging technology," unlike video data where consecutive frames are similar.
- Why unresolved: The paper identifies this as a potential issue but does not quantify the impact or test mitigation strategies.
- What evidence would resolve it: Experiments comparing SAM 2's performance on medical volumes with varying inter-slice similarity, and testing whether pre-processing techniques to increase slice similarity improve results.

## Limitations

- SAM 2's memory attention mechanism fails for 3D medical volumes due to insufficient temporal coherence when handling large inter-slice variations
- The evaluation is constrained by SAM 2's limited training on 8-frame widths, preventing effective propagation through deeper medical volumes
- The study focuses primarily on single-slice annotations, leaving sparsely annotated volume performance largely unexplored

## Confidence

**High Confidence**: Box prompts outperform point prompts across all datasets (p < 0.001)

**Medium Confidence**: SAM 2's memory mechanism fails for 3D medical images due to insufficient temporal coherence

**Low Confidence**: First predicted mask channel selection yields better results than highest-confidence selection for medical segmentation tasks

## Next Checks

1. Evaluate SAM 2's 3D segmentation performance on volumes with varying depths (10-50 slices) to determine the exact point where memory accumulation causes performance degradation.

2. Compare memory attention effectiveness across different medical imaging modalities to identify which specific types of inter-slice variations most severely impact the propagation mechanism.

3. Test the mask selection strategy (first channel vs highest confidence) on volumes with sparsely distributed annotations to validate whether the observed pattern holds when most slices lack ground truth.