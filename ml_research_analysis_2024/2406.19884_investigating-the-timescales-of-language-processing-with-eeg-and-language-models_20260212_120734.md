---
ver: rpa2
title: Investigating the Timescales of Language Processing with EEG and Language Models
arxiv_id: '2406.19884'
source_url: https://arxiv.org/abs/2406.19884
tags:
- language
- representations
- processing
- word
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study maps word representations from GPT-2 to EEG signals
  recorded during story listening, using Temporal Response Functions (TRFs) to examine
  how different layers of the language model relate to neural activity. Results show
  distinct TRF patterns between the embedding layer (lexical encoding) and a deep
  layer (compositional encoding), with the deep layer displaying a P600-like pattern
  around 600 ms.
---

# Investigating the Timescales of Language Processing with EEG and Language Models

## Quick Facts
- arXiv ID: 2406.19884
- Source URL: https://arxiv.org/abs/2406.19884
- Authors: Davide Turco; Conor Houghton
- Reference count: 10
- Primary result: Distinct TRF patterns between embedding layer (lexical encoding) and deep layer (compositional encoding) map to EEG signals during story listening

## Executive Summary
This study investigates how different layers of a transformer language model (GPT-2) map to neural activity recorded via EEG during story listening. Using Temporal Response Functions (TRFs), the authors examine how lexical and compositional representations in the language model relate to brain signals. The results show that different transformer layers produce distinct TRF patterns, with the deep layer displaying a P600-like pattern around 600 ms, and that syntactic representations negatively correlate with EEG activity post 200 ms.

## Method Summary
The study uses a time-lagged linear regression model (TRF) to map word representations from GPT-2 to EEG signals. EEG data was recorded from subjects listening to stories, then segmented and aligned with corresponding word tokens. Language model activations were extracted from specific layers (l=0 for embedding, l=8 for deep layer). The TRF model was trained using L2 regularization with cross-validation. Linear Discriminant Analysis was applied to isolate part-of-speech representations. Model performance was evaluated using Pearson correlation between predicted and actual EEG signals.

## Key Results
- Distinct TRF patterns observed between embedding layer (l=0) and deep layer (l=8)
- Deep layer TRF shows P600-like pattern around 600 ms
- Correlation between reconstructed and original EEG signals: 0.03 (p ≪ 10⁻⁵)
- Syntactic representations negatively correlate with EEG activity post 200 ms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal Response Functions (TRFs) can linearly map word representations to EEG signals because the brain's response to language unfolds predictably over time.
- Mechanism: TRF models convolve stimulus representations with learned temporal kernels to predict neural responses, capturing how different time lags of word representations relate to EEG amplitudes.
- Core assumption: The relationship between language model activations and EEG signals is approximately linear and time-invariant.
- Evidence anchors:
  - [abstract] "Using a Temporal Response Function (TRF) model, we investigate how neural activity corresponds to model representations across different layers"
  - [section] "We use a time-lagged linear regression model (Crosse et al., 2016): rt,e = ∑i∑τ wτ,e,i st−τ,i"
- Break condition: If neural responses show strong non-linear dynamics or if language processing involves significant feedback loops that violate time-invariance assumptions.

### Mechanism 2
- Claim: Different transformer layers capture distinct aspects of language processing that map to different neural signatures in EEG.
- Mechanism: The embedding layer encodes primarily lexical information while deeper layers encode compositional/syntactic features, each producing distinct TRF patterns.
- Core assumption: Language model layers progressively transform representations from surface form to deeper semantic/syntactic content, mirroring cortical processing hierarchies.
- Evidence anchors:
  - [abstract] "Results show distinct TRF patterns between the embedding layer (lexical encoding) and a deep layer (compositional encoding)"
  - [section] "Our results show that mapping embedding (l=0) and deep layer (l=8) activations to EEG data lead to noticeably different TRFs"
- Break condition: If all layers produce similar TRF patterns or if layer selection doesn't systematically affect model performance.

### Mechanism 3
- Claim: Linear Discriminant Analysis can isolate syntactic features from language model representations that correlate with specific EEG patterns.
- Mechanism: LDA reduces high-dimensional word representations to dimensions corresponding to part-of-speech categories, revealing how syntactic information in the model relates to neural activity.
- Core assumption: Language models encode syntactic information in a linearly separable manner that can be extracted through dimensionality reduction.
- Evidence anchors:
  - [abstract] "we used linear discriminant analysis (LDA) to isolate part-of-speech (POS) representations, offering insights into their influence on neural responses"
  - [section] "we used linear discriminant analysis (LDA), motivated by previous work showing that language models encode linguistic features in a linear manner (Linzen & Baroni, 2021)"
- Break condition: If POS representations don't show clear clustering or if LDA reduction doesn't improve EEG prediction compared to raw representations.

## Foundational Learning

- Concept: Temporal Response Functions and linear convolution models
  - Why needed here: TRFs are the core method for aligning continuous language representations with high-temporal-resolution EEG data
  - Quick check question: What is the mathematical relationship between stimulus representations, temporal kernels, and predicted EEG signals in a TRF model?

- Concept: Transformer architecture and layer-wise processing
  - Why needed here: Understanding how different transformer layers capture different linguistic features (lexical vs compositional) is essential for interpreting results
  - Quick check question: How do transformer embeddings differ from deeper layer representations in terms of linguistic information captured?

- Concept: Part-of-Speech tagging and syntactic feature extraction
  - Why needed here: POS tagging is used to isolate syntactic representations from language model activations to study their neural correlates
  - Quick check question: Why might content words (NOUN, VERB, ADV) cluster together differently from function words (CONJ, PRON) in the reduced representation space?

## Architecture Onboarding

- Component map: EEG preprocessing -> segmentation -> alignment with language model tokens -> GPT-2 layer-specific activation extraction -> optional LDA reduction -> PyTorch TRF implementation with L2 regularization -> Pearson correlation evaluation

- Critical path:
  1. Load and preprocess EEG data (segmentation, filtering)
  2. Align EEG segments with corresponding word tokens
  3. Extract language model activations for selected layers
  4. Train TRF model with cross-validation for regularization
  5. Evaluate correlation and analyze TRF patterns
  6. (Optional) Apply LDA for syntactic feature isolation

- Design tradeoffs:
  - Linear vs non-linear mapping: Current model assumes linearity for interpretability but may miss complex relationships
  - Layer selection: Layer 8 chosen based on prior work but other layers might yield different insights
  - Regularization strength: Balance between overfitting prevention and capturing genuine signal
  - Window size and overlap: Affects temporal resolution vs computational efficiency

- Failure signatures:
  - Low correlations across all subjects despite clean EEG data
  - TRF patterns that don't align with known ERP components
  - LDA-reduced space that doesn't show clear POS clustering
  - Model performance that doesn't improve with layer depth

- First 3 experiments:
  1. Baseline TRF model using embedding layer (l=0) activations only
  2. Compare TRF patterns between embedding layer and deep layer (l=8)
  3. Implement and evaluate LDA-reduced representations for POS isolation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do non-linear components improve the mapping between language model representations and EEG signals compared to the current linear TRF model?
- Basis in paper: [explicit] The authors state "In future work, we plan to improve the mapping model by adding non-linear components to the architecture."
- Why unresolved: The current study uses a linear convolution model (TRF) which may not capture complex non-linear relationships between language representations and neural responses.
- What evidence would resolve it: Comparative analysis showing correlation scores and TRF patterns between linear and non-linear models (e.g., neural networks with non-linear activation functions) applied to the same EEG-language model alignment task.

### Open Question 2
- Question: How do semantic representations from language models relate to EEG signals compared to syntactic (POS) representations?
- Basis in paper: [explicit] The authors mention "we plan to extend the analysis to other aspects of language, like semantics."
- Why unresolved: The study focused on isolating POS representations but did not investigate how semantic information in language models maps to neural activity.
- What evidence would resolve it: TRF analysis and correlation scores comparing semantic embeddings (e.g., word meaning vectors) versus syntactic representations against EEG data.

### Open Question 3
- Question: Do different transformer layers beyond layer 8 show distinct temporal patterns in their relationship to EEG signals?
- Basis in paper: [inferred] The study analyzed only layers 0 and 8, with layer 8 selected based on prior research, but did not explore the full range of layers.
- Why unresolved: The paper only examined two specific layers (embedding and layer 8) without investigating whether intermediate or other deep layers show unique TRF patterns.
- What evidence would resolve it: Comprehensive TRF analysis across all GPT-2 layers (0-11) showing temporal patterns and correlation scores for each layer's mapping to EEG signals.

## Limitations

- Linear mapping assumption may not capture non-linear neural dynamics and feedback mechanisms
- Relatively low correlation coefficient (0.03) suggests substantial unexplained variance in neural responses
- Layer selection (l=0 and l=8) is based on prior work without systematic exploration of intermediate layers

## Confidence

- High confidence: Layer-specific TRF patterns differ between embedding and deep layers (direct empirical observation)
- Medium confidence: P600-like pattern interpretation at deep layer (based on temporal similarity to known ERP components)
- Medium confidence: Syntactic representations negatively correlate with EEG activity post 200 ms (statistically significant but requires careful interpretation)
- Low confidence: Direct causal relationship between language model layer processing and cortical hierarchies (largely correlational evidence)

## Next Checks

1. Test non-linear mapping approaches (e.g., deep neural networks) to determine if they capture additional variance beyond linear TRF models
2. Conduct systematic ablation studies across all GPT-2 layers to identify optimal layer selection and potential intermediate layer contributions
3. Implement stimulus-matched control conditions to validate that observed TRF patterns specifically reflect language processing rather than general acoustic or attention-related neural responses