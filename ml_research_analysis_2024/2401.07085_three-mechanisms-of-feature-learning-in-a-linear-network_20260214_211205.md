---
ver: rpa2
title: Three Mechanisms of Feature Learning in a Linear Network
arxiv_id: '2401.07085'
source_url: https://arxiv.org/abs/2401.07085
tags:
- learning
- kernel
- phase
- initialization
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies the training dynamics of a two-layer linear
  network, revealing three distinct mechanisms of feature learning: (1) learning by
  alignment, (2) learning by disalignment, and (3) learning by rescaling. The authors
  provide an exact solution for the evolution of the network parameters under gradient
  descent, showing how the alignment between the two layers and the output scale change
  during training.'
---

# Three Mechanisms of Feature Learning in a Linear Network

## Quick Facts
- arXiv ID: 2401.07085
- Source URL: https://arxiv.org/abs/2401.07085
- Authors: Yizhou Xu; Liu Ziyin
- Reference count: 19
- Key outcome: Three distinct mechanisms of feature learning (alignment, disalignment, rescaling) identified in two-layer linear networks, with exact analytical solutions for training dynamics

## Executive Summary
This paper presents a rigorous mathematical analysis of feature learning in two-layer linear networks, identifying three distinct mechanisms through which networks evolve during training. The authors derive exact solutions for parameter evolution under gradient descent, demonstrating when networks exhibit feature learning versus remaining in the kernel regime. Their work provides new theoretical insights into neural network training dynamics and offers practical guidance for initialization and learning rate selection to promote beneficial alignment.

## Method Summary
The authors study a two-layer linear network with one-dimensional data, deriving exact analytical solutions for the evolution of network parameters under gradient descent. They identify conserved quantities and phase transitions between kernel and feature learning regimes, providing conditions for when alignment, disalignment, or rescaling mechanisms dominate. The theoretical framework is validated through experiments on CIFAR-10 using two-layer ReLU networks, demonstrating that the identified mechanisms persist in nonlinear settings.

## Key Results
- Three distinct mechanisms of feature learning identified: alignment, disalignment, and rescaling
- Exact analytical solutions provided for parameter evolution in two-layer linear networks
- Conditions derived for kernel vs. feature learning regimes based on initialization and learning rates
- Empirical validation showing mechanisms persist in nonlinear networks on real-world datasets

## Why This Works (Mechanism)

### Mechanism 1: Learning by Alignment
The alignment between layers u and w changes monotonically during training based on the ratio Q/P and asymptotic scale factor α+. When α+ > 1, alignment increases; when α+ < 1, disalignment occurs. This mechanism dominates when the model is in the feature learning regime rather than kernel regime.

### Mechanism 2: Learning by Disalignment
Disalignment occurs when initial predictions are incorrect (uT(0)w(0) < 0) or when learning rates are imbalanced. This forces the network to increase layer norms to maintain output, potentially leading to overfitting. The mechanism is triggered by Q ≥ P or significant learning rate imbalances.

### Mechanism 3: Learning by Rescaling
The network output magnitude (∥u∥ and ∥w∥) changes monotonically with alignment: increasing during alignment and decreasing during disalignment. This rescaling effect is specific to the feature learning regime and vanishes in the kernel regime where NTK remains constant.

## Foundational Learning

- Neural Tangent Kernel (NTK) and kernel vs feature learning regimes: Needed to understand when network parameters change vs remain static during training. Quick check: What happens to NTK when transitioning from kernel to feature learning regime?

- Conservation laws in gradient flow dynamics: Essential for deriving exact solutions as they constrain parameter evolution. Quick check: How many independent conservation laws exist and what do they represent?

- Phase diagrams and scaling limits in infinite-width networks: Critical for understanding how width, learning rates, and initialization affect learning behavior. Quick check: What condition must be satisfied for kernel phase as width approaches infinity?

## Architecture Onboarding

- Component map: Input -> Linear Layer w (d0×d) -> Linear Layer u (d) -> Output
- Critical path: 1) Initialize weights u and w 2) Compute P and Q from initialization 3) Calculate tc and α+ 4) Evolve parameters using Theorem 1 5) Monitor alignment and output scale
- Design tradeoffs: Width vs initialization scale affects kernel vs feature learning; learning rate balance affects alignment; output scale γ controls relative contributions
- Failure signatures: tc → ∞ indicates frozen learning; P = Q = 0 indicates saddle point; lim κ→∞P/Q ≠ 1 prevents kernel phase
- First 3 experiments: 1) Vary initialization scale σ from 0.1 to 10, measure alignment and accuracy 2) Train with different learning rate ratios, observe alignment evolution 3) Compare Kaiming vs Xavier initialization under kernel and feature learning scalings

## Open Questions the Paper Calls Out
- How do dynamics change when input data lies in higher-dimensional subspaces rather than one-dimensional?
- What is the precise relationship between layer alignment/disalignment and generalization performance?
- How do feature learning dynamics differ between gradient flow and stochastic gradient descent in finite-width models?

## Limitations
- Analysis restricted to one-dimensional input subspaces, limiting generalizability
- Empirical validation limited to CIFAR-10 dataset with two-layer ReLU networks
- Does not explore deeper architectures or alternative activation functions
- SGD vs GF differences acknowledged but not thoroughly analyzed

## Confidence
- Theoretical framework for linear networks: High
- Empirical validation on CIFAR-10: Medium
- Generalization to arbitrary deep nonlinear networks: Low-Medium

## Next Checks
1. Test alignment/disalignment patterns in deeper networks (3+ layers) with varying widths
2. Evaluate performance across diverse datasets (ImageNet, tabular data) beyond CIFAR-10
3. Compare results with different activation functions (GELU, Swish) to determine activation dependence