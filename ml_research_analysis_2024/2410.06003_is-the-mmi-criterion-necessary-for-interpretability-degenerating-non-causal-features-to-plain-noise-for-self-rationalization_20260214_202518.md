---
ver: rpa2
title: Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal
  Features to Plain Noise for Self-Rationalization
arxiv_id: '2410.06003'
source_url: https://arxiv.org/abs/2410.06003
tags:
- features
- spurious
- rationale
- datasets
- extractor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of extracting causal rationales
  in the presence of spurious features, which can interfere with the widely used Maximum
  Mutual Information (MMI) criterion in rationalization. The authors propose a new
  criterion called Maximizing the Remaining Discrepancy (MRD) that treats spurious
  features as equivalent to plain noise, simplifying the rationale extraction process.
---

# Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal Features to Plain Noise for Self-Rationalization

## Quick Facts
- arXiv ID: 2410.06003
- Source URL: https://arxiv.org/abs/2410.06003
- Reference count: 40
- This paper proposes a new criterion called Maximizing the Remaining Discrepancy (MRD) that improves rationale quality by up to 10.4% compared to MMI variants

## Executive Summary
This paper challenges the necessity of the Maximum Mutual Information (MMI) criterion in self-rationalization models, which traditionally requires modeling the joint distribution of input features and targets. The authors identify that MMI struggles with spurious features that create complex joint distributions, making optimization difficult. Their solution, Maximizing the Remaining Discrepancy (MRD), treats spurious features as equivalent to plain noise and instead focuses on the remaining input after removing rationale candidates. This simpler approach achieves better rationale quality while being more computationally tractable.

## Method Summary
The paper introduces a novel approach to rationalization that addresses the limitations of the Maximum Mutual Information (MMI) criterion in the presence of spurious features. The proposed Maximizing the Remaining Discrepancy (MRD) criterion simplifies the rationalization process by treating spurious features as plain noise rather than modeling complex joint distributions. The method works by focusing on the remaining part of the input after removing the rationale candidate, rather than the candidate itself. Implementation involves approximating input distributions and updating both the predictor and extractor components iteratively. Experiments across six datasets demonstrate that MRD achieves up to 10.4% improvement in rationale quality compared to several recent competitive MMI variants.

## Key Results
- MRD improves rationale quality (measured by overlap with human-annotated rationales) by up to 10.4% compared to MMI variants
- The method achieves state-of-the-art performance on six widely used datasets
- MRD provides a simpler computational approach while maintaining or improving performance

## Why This Works (Mechanism)
The MRD criterion works by fundamentally changing how spurious features are handled in rationalization. Instead of modeling the complex joint distribution of input features and targets (which becomes intractable with spurious features), MRD treats spurious features as plain noise. This allows the model to focus on the remaining discrepancy after removing the rationale candidate, rather than trying to capture the full joint distribution. By simplifying the optimization target in this way, the method avoids the computational complexity and potential pitfalls of MMI while achieving better performance.

## Foundational Learning

**Mutual Information (MI)**: Measures the statistical dependence between two random variables. Needed to understand the MMI criterion being challenged. Quick check: MI = 0 implies independence, MI = H(X) implies perfect correlation.

**Spurious Features**: Input features that correlate with the target but are not causally related. Needed to understand why MMI fails in practice. Quick check: Spurious features should be removable without affecting the true causal relationship.

**Plain Noise Assumption**: Treating non-causal features as equivalent to random noise. Needed to understand the core simplification in MRD. Quick check: Noise should have no predictive power for the target.

**Joint Distribution**: The probability distribution over multiple random variables simultaneously. Needed to understand why MMI is computationally challenging. Quick check: Joint distributions grow exponentially with the number of variables.

## Architecture Onboarding

**Component Map**: Input Text -> Spurious Feature Detector -> Rationale Extractor -> Predictor -> Output

**Critical Path**: The rationale extractor must identify and remove spurious features while preserving causal features, then the predictor makes predictions based on the remaining input.

**Design Tradeoffs**: MRD sacrifices modeling the full joint distribution for computational simplicity and robustness to spurious features. This trade-off proves beneficial in practice.

**Failure Signatures**: The method may struggle when spurious features are not truly equivalent to noise or when the plain noise assumption breaks down.

**First Experiments**:
1. Test MRD on synthetic data with known spurious correlations to verify the plain noise assumption
2. Compare MRD against MMI variants on datasets with varying levels of spurious feature contamination
3. Evaluate the method's sensitivity to different approximations of input distributions

## Open Questions the Paper Calls Out

None

## Limitations

- The theoretical foundation assumes spurious features are truly equivalent to plain noise, which may not hold in all real-world scenarios
- MRD's effectiveness relies on approximations of input distributions, introducing potential errors
- The method focuses primarily on text-based datasets, with uncertain generalizability to other modalities

## Confidence

- High confidence in experimental methodology and comparative analysis across six datasets
- Medium confidence in theoretical justification for treating spurious features as plain noise
- Medium confidence in scalability to more complex, real-world scenarios

## Next Checks

1. Test the MRD approach on datasets with known complex spurious correlations to evaluate robustness beyond current experimental setup
2. Conduct ablation studies to quantify the impact of the plain noise assumption versus alternative treatments of spurious features
3. Implement and evaluate the method on non-text modalities (e.g., images or tabular data) to assess cross-domain applicability