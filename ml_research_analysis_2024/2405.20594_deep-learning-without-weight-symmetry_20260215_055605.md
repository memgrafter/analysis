---
ver: rpa2
title: Deep Learning without Weight Symmetry
arxiv_id: '2405.20594'
source_url: https://arxiv.org/abs/2405.20594
tags:
- weight
- feedback
- alignment
- weights
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the Product Feedback Alignment (PFA) algorithm
  to address the weight symmetry problem in biological neural networks. Traditional
  backpropagation requires symmetric feedforward and feedback weights, which contradicts
  experimental evidence in the brain.
---

# Deep Learning without Weight Symmetry

## Quick Facts
- arXiv ID: 2405.20594
- Source URL: https://arxiv.org/abs/2405.20594
- Authors: Li Ji-An; Marcus K. Benna
- Reference count: 29
- This work introduces Product Feedback Alignment (PFA) to eliminate weight symmetry requirements in deep learning

## Executive Summary
This paper addresses the weight symmetry problem in biological neural networks by introducing the Product Feedback Alignment (PFA) algorithm. Traditional backpropagation requires symmetric feedforward and feedback weights, contradicting experimental evidence that biological neurons lack such symmetry. PFA eliminates explicit weight symmetry by introducing an intermediate neuronal population and aligning feedforward weights with the product of two feedback weight matrices. The algorithm achieves backpropagation-level performance in deep convolutional networks on MNIST, CIFAR-10, and ImageNet while completely avoiding weight symmetry.

## Method Summary
PFA introduces an intermediate neuronal population that receives error signals through a fixed random feedback matrix, while feedforward weights align with the product of this feedback matrix and a plastic feedback matrix. The algorithm maintains two key metrics during training: path alignment (angle between feedforward and feedback pathways) and path norm ratio (ratio of pathway norms). By keeping these metrics near their ideal values, PFA ensures stable error propagation and weight updates that closely approximate backpropagation gradients. The method uses an expansion ratio of 10 for the intermediate population and applies weight decay to both feedforward and feedback weights to maintain alignment.

## Key Results
- Achieves BP-level performance on MNIST, CIFAR-10, and ImageNet without weight symmetry
- Outperforms other algorithms under sparse feedback connectivity conditions
- Maintains stable alignment metrics throughout training with path alignment angles below 10° and path norm ratios near 1

## Why This Works (Mechanism)

### Mechanism 1
PFA eliminates explicit weight symmetry by using an intermediate neuronal population and aligning feedforward weights with the product of two feedback weight matrices. The algorithm introduces an intermediate population of neurons that receives error signals from the output layer through a fixed random feedback matrix. The feedforward weights then align with the product of this feedback matrix and a plastic feedback matrix, creating implicit alignment between forward and backward pathways without requiring symmetric weights. This mechanism breaks down if BTBl fails to approximate an identity matrix.

### Mechanism 2
PFA achieves BP-level performance by ensuring backward-forward path alignment and maintaining appropriate weight norm ratios. The algorithm maintains path alignment (angle between W and RB) and path norm ratio (||RB||2/||W||2) during training. By keeping these metrics close to their ideal values (near 0° for alignment and near 1 for norm ratio), PFA ensures stable error propagation and weight updates that closely approximate backpropagation. The approximation breaks down if either the path alignment angle becomes too large or the path norm ratio deviates significantly from 1.

### Mechanism 3
PFA's use of an expanded intermediate population provides robustness under sparse feedback connectivity conditions. By introducing an intermediate population with expansion ratio (1/λ = ¯Nl/Nl+1), PFA creates redundancy in the error transmission pathway. This redundancy allows the algorithm to maintain performance even when feedback connections are sparse, as demonstrated by the slower degradation of performance compared to other algorithms under sparse connectivity conditions. The mechanism fails if the expansion ratio is too small to provide sufficient redundancy.

## Foundational Learning

- Concept: Credit assignment problem in deep networks
  - Why needed here: The paper addresses how error signals propagate through deep networks to assign credit to individual weights, which is the core problem that backpropagation solves but requires weight symmetry
  - Quick check question: Why is credit assignment particularly challenging in deep networks compared to shallow networks?

- Concept: Feedback alignment and its variants
  - Why needed here: Understanding FA, DFA, SF, KP, WM, and PAL provides context for why PFA was developed and how it improves upon existing solutions to the weight symmetry problem
  - Quick check question: What is the key limitation of feedback alignment that prevents it from achieving BP-level performance?

- Concept: Weight transport problem and biological plausibility
  - Why needed here: The paper's motivation stems from the discrepancy between backpropagation's weight symmetry requirement and biological neural networks, which lack symmetric connections
  - Quick check question: What experimental evidence contradicts the weight symmetry assumption in biological neural networks?

## Architecture Onboarding

- Component map: Input → Forward pass through W → Intermediate population through B → Plastic feedback through R → Error back to update W and R
- Critical path: Input layer → Feedforward weight matrix → Intermediate population → Plastic feedback matrix → Error signal → Weight updates
- Design tradeoffs: Expansion ratio vs. computational cost; fixed vs. plastic feedback weights; weight decay schedules
- Failure signatures: Large path alignment angle (>30°); path norm ratio deviating from 1; performance plateauing below BP-level; high variance across seeds
- First 3 experiments:
  1. Implement PFA on MNIST with a simple two-hidden-layer network to verify basic functionality and compare against BP, FA, and SF
  2. Test PFA on CIFAR-10 with ResNet-20 to evaluate performance on deeper convolutional architectures
  3. Evaluate PFA under sparse feedback connectivity conditions to assess robustness compared to other algorithms

## Open Questions the Paper Calls Out

### Open Question 1
Can biologically plausible plasticity rules for feedback weights B be discovered that would reduce the expansion ratio requirement in PFA? The authors state exploring biologically plausible plasticity rules for B that could reduce the expansion ratio requirement is a future research direction. Current PFA implementations require large expansion ratios (1/λ = 10) to approximate BP well, which may be biologically implausible. Demonstrating a biologically plausible learning rule for B that maintains good performance with expansion ratios closer to 1 would make PFA more biologically realistic.

### Open Question 2
How does sparse feedback connectivity in PFA compare to BP performance across different network architectures and tasks? The authors show PFA outperforms FA, DFA, and SF under sparse feedback connectivity on MNIST, but acknowledge addressing these limitations is a future direction. The study only examined sparse connectivity on MNIST, so performance on deeper networks, convolutional architectures, and more complex datasets remains untested.

### Open Question 3
Can the additional neuronal population introduced in PFA be implemented using existing biological mechanisms without requiring dedicated populations? The authors note this is broadly consistent with the brain's diverse neuronal population structure but acknowledge the need for additional populations. The biological plausibility of dedicated intermediate populations is questionable, and while the authors suggest this could be achieved through dendritic segregation or burst-dependent plasticity, this remains speculative.

## Limitations

- Scalability concerns to very deep networks beyond tested architectures
- Reliance on weight decay to maintain alignment creates potential instability in long training runs
- Large expansion ratios (1/λ = 10) required for good performance may be biologically implausible

## Confidence

- **High**: PFA's ability to eliminate explicit weight symmetry while maintaining BP-level performance on standard benchmarks
- **Medium**: Claims about PFA's superiority under sparse feedback connectivity conditions
- **Medium**: The assertion that PFA is the first algorithm to achieve BP-level performance without weight symmetry in deep convolutional networks

## Next Checks

1. Test PFA on architectures deeper than ResNet-20 (e.g., ResNet-50 or ResNet-101) to verify scalability to very deep networks
2. Conduct ablation studies varying the expansion ratio λ to determine optimal values for different network depths
3. Evaluate PFA's performance with learned (plastic) feedback matrices instead of fixed random B matrices to assess potential improvements