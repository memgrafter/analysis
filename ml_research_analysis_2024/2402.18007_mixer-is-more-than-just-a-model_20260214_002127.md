---
ver: rpa2
title: Mixer is more than just a model
arxiv_id: '2402.18007'
source_url: https://arxiv.org/abs/2402.18007
tags:
- audio
- mixer
- data
- spectrogram
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ASM-RH, an MLP-based audio classification
  model that extends the Mixer architecture beyond traditional channel and token perspectives.
  It incorporates Roll-Time-mixing and Hermit-Frequency-mixing modules to capture
  time and frequency domain information from spectrograms.
---

# Mixer is more than just a model

## Quick Facts
- arXiv ID: 2402.18007
- Source URL: https://arxiv.org/abs/2402.18007
- Authors: Qingfeng Ji; Yuxin Wang; Letong Sun
- Reference count: 29
- Key outcome: ASM-RH achieves state-of-the-art performance on RA VDESS (75.4% accuracy, 94.98% AUC) and strong results on UrbanSound8K and SpeechCommands

## Executive Summary
This paper introduces ASM-RH, an MLP-based audio classification model that extends the Mixer architecture by incorporating Roll-Time-mixing and Hermit-Frequency-mixing modules. The model achieves state-of-the-art performance on the RA VDESS dataset and competitive results on UrbanSound8K and SpeechCommands, demonstrating that MLP-Mixer architectures can be effectively adapted for audio tasks beyond traditional channel and token mixing perspectives.

## Method Summary
ASM-RH uses a spectrogram-based approach with 12 RH-MixerBlocks that integrate Roll-Time-mixing (spatial shifting of patches) and Hermit-Frequency-mixing (Hermitian FFT and IRFFT operations). The model processes 600x768 spectrograms through patch extraction, linear projection, and sequential mixing layers before producing classification logits. Training uses a learning rate of 2.5e-4 with decay after epoch 5, and the architecture removes traditional positional embeddings in favor of implicit ordering through mixing operations.

## Key Results
- Achieves 75.4% accuracy and 94.98% AUC on RA VDESS dataset, outperforming ERANNs
- Reaches 97.96% average accuracy (98.63% best) on UrbanSound8K in 10-fold cross-validation
- Obtains 96.62% validation accuracy and 96.51% test accuracy on SpeechCommands
- Ablation study confirms effectiveness of both Roll-Time-mixing and Hermit-Frequency-mixing modules

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Roll-Time-mixing captures temporal information by spatially shifting spectrogram patches without losing data.
- Mechanism: The RollBlock operation shifts feature patches in four directions (left, right, up, down) and fills vacated regions with rolled-over data, preserving temporal continuity while exposing the model to shifted contexts.
- Core assumption: Local time-domain patterns in spectrograms benefit from spatially adjacent feature shifts, and zero-padding would degrade performance.
- Evidence anchors:
  - [section] "As every segment of time-domain information in the spectrogram is crucial, to maintain the integrity of the time-domain data, the discarded data from the Shift operation is reinstated in the empty positions."
  - [abstract] "incorporates insights from both time and frequency domains"

### Mechanism 2
- Claim: Hermit-Frequency-mixing extracts frequency-domain structure via Hermitian FFT and reconstructs with IRFFT.
- Mechanism: Applying Hermitian FFT to the token dimension converts local frequency components into real-valued embeddings; IRFFT returns to the time domain while preserving Hermit symmetry, allowing the model to process both domains in the same latent space.
- Core assumption: Audio spectrograms exhibit Hermitian symmetry and that capturing both domains jointly improves classification.
- Evidence anchors:
  - [section] "The Hermit Fast Fourier Transform (HFFT) enables the model to capture frequency domain characteristics and Hermit properties of the data."
  - [corpus] No direct supporting citations found in neighbor papers; this is an original architectural claim.

### Mechanism 3
- Claim: Removing positional embeddings (cls-token, dist-token) is viable because Mixer's token-mixing layers implicitly encode order.
- Mechanism: Pure MLP-Mixer without explicit positional embeddings relies on learned channel-mixing and token-mixing weights to infer structure; Roll-Time-mixing further strengthens temporal ordering.
- Core assumption: MLP-Mixer's mixing layers can substitute for positional encodings in audio spectrograms.
- Evidence anchors:
  - [section] "Ilya Tolstikhin et al., when introducing the MLP-Mixer [5], emphasized that the Mixer architecture eliminates the need for positional embedding."
  - [corpus] No neighbor papers explicitly validate this removal for audio tasks.

## Foundational Learning

- Concept: Spectrogram representation and axis semantics
  - Why needed here: Understanding that height=channels, width=time allows correct design of roll and frequency operations.
  - Quick check question: In a spectrogram of shape (B, H, W), which axis represents time and which represents frequency bins?

- Concept: Hermitian symmetry in real-valued FFT
  - Why needed here: Justifies use of Hermit FFT (real inputs → real outputs) and IRFFT to preserve signal integrity.
  - Quick check question: Why does applying FFT to real audio data produce conjugate-symmetric output?

- Concept: MLP-Mixer layer mechanics
  - Why needed here: Clarifies that token-mixing operates across time/frequency patches and channel-mixing across feature dimensions, so roll and FFT target the right mixing stage.
  - Quick check question: In MLP-Mixer, what is the difference between token-mixing and channel-mixing operations?

## Architecture Onboarding

- Component map: Input → Patch extraction (600x768 → tokens) → Linear projection → RH-MixerBlocks (12 layers) → Roll-Time-mixing (in each block) → Hermit-Frequency-mixing (in each block) → MLP output → Logits
- Critical path: Forward pass through RH-MixerBlocks; RollBlock and Hermit FFT operations dominate compute in each block
- Design tradeoffs:
  - RollBlock vs. convolution: Similar receptive field growth but zero extra parameters; higher memory for rolled-over regions
  - Hermitian FFT vs. standard FFT: Avoids complex numbers (halves memory/compute) but only works for real inputs
  - No positional embeddings: Reduces parameters but relies on implicit order encoding
- Failure signatures:
  - RollBlock: If step size is too large, local context is destroyed; if too small, benefit is negligible
  - Hermit-Frequency-mixing: Incorrect axis selection leads to mixing frequency bins as tokens, harming performance
  - Missing embeddings: Sequence ordering errors manifest as random confusion across classes
- First 3 experiments:
  1. Verify RollBlock by feeding a simple sine wave spectrogram and checking that shifted patches still contain the signal after roll-back
  2. Compare training loss with/without Hermit-Frequency-mixing on a small subset to confirm frequency features add value
  3. Ablate the RollBlock step parameter from {1, 2, 4} on UrbanSound8K validation to find optimal shift range

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the RollBlock's fixed scroll distance and range (C=16, C_a=4) affect the model's ability to capture diverse temporal patterns across different audio classification tasks?
- Basis in paper: [explicit] The paper specifies fixed parameters for RollBlock (C=16, C_a=4) and limits scroll range based on model depth
- Why unresolved: The paper does not explore how varying these parameters affects performance across different datasets or whether they are optimal for all audio tasks
- What evidence would resolve it: Systematic ablation studies varying C and C_a values, testing on multiple audio datasets to determine optimal parameter ranges

### Open Question 2
- Question: What is the theoretical relationship between the Hermit-Frequency-mixing module and traditional frequency-domain analysis techniques like Short-Time Fourier Transform or Mel-frequency cepstral coefficients?
- Basis in paper: [explicit] The paper introduces Hermit-Frequency-mixing as inspired by ActiveMLP and Adaptive Frequency Filters, but doesn't provide theoretical analysis of its relationship to established audio processing methods
- Why unresolved: The paper demonstrates empirical effectiveness but lacks theoretical grounding explaining how this module relates to or improves upon classical frequency-domain audio analysis approaches
- What evidence would resolve it: Mathematical analysis comparing Hermit-Frequency-mixing to traditional frequency-domain transforms, explaining the theoretical advantages

### Open Question 3
- Question: Does the ASM-RH architecture's performance advantage over AST models indicate that MLP-based approaches are fundamentally better suited for audio classification, or are there specific architectural features driving the improvement?
- Basis in paper: [explicit] The paper claims ASM-RH "outperforms AST models" and suggests MLP approaches may be "fundamentally better" for audio, but doesn't isolate which specific architectural elements drive this advantage
- Why unresolved: The paper combines multiple novel elements (RollBlock, Hermit-Frequency-mixing) with the existing ASM architecture without systematic isolation of which components contribute most to performance gains
- What evidence would resolve it: Controlled experiments testing each novel component independently against equivalent AST-based implementations, or direct comparisons with AST variants using similar time/frequency mixing approaches

## Limitations

- The paper demonstrates strong performance on fixed-size spectrograms but doesn't explore robustness to different input resolutions or audio types
- The architectural choices for RollBlock parameters and Hermit-Frequency-mixing are fixed without systematic exploration of optimal values across datasets
- Claims about MLP-Mixer being "more than just a model" for audio tasks are based on limited comparisons without comprehensive ablation of individual architectural innovations

## Confidence

- **High Confidence**: The empirical results showing state-of-the-art performance on RA VDESS (75.4% ACC, 94.98% AUC) and competitive results on UrbanSound8K (97.96% average ACC) are directly measurable and reproducible metrics.
- **Medium Confidence**: The architectural design of combining Roll-Time-mixing and Hermit-Frequency-mixing is plausible and well-motivated, but the specific parameter choices and their optimality across datasets are not thoroughly explored.
- **Low Confidence**: The claim that this demonstrates "Mixer is more than just a model" for audio tasks is more of an interpretation than a proven mechanism, as the paper doesn't compare against all possible audio architectures or demonstrate the approach generalizes beyond the tested datasets.

## Next Checks

1. **Mechanism Isolation Test**: Create controlled experiments that separately measure the contribution of temporal vs frequency information by comparing models with only Roll-Time-mixing, only Hermit-Frequency-mixing, and both together on a simple audio classification task where temporal and frequency cues can be manipulated independently.

2. **Resolution Robustness Test**: Evaluate ASM-RH on spectrograms of varying resolutions (e.g., [300, 384], [600, 768], [1200, 1536]) to determine whether the architectural choices (RollBlock step size, Hermit FFT axis selection) generalize across input dimensions.

3. **Positional Embedding Ablation**: Systematically compare ASM-RH with and without positional embeddings on a phoneme recognition task where absolute position matters, to test whether the implicit encoding is truly sufficient for all audio classification scenarios.