---
ver: rpa2
title: In-Context Example Ordering Guided by Label Distributions
arxiv_id: '2402.11447'
source_url: https://arxiv.org/abs/2402.11447
tags:
- in-context
- label
- examples
- fewshotup
- fewshotu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work tackles the problem of optimizing in-context example
  ordering for improved in-context learning (ICL) performance. The authors propose
  two principles for ordering selection: (1) minimizing the KL divergence between
  the model''s probability distribution on a null input and a uniform distribution
  when no unlabeled data is available, and (2) minimizing the KL divergence between
  the model''s observed label distribution on unlabeled data and a prior label distribution
  when prior knowledge exists.'
---

# In-Context Example Ordering Guided by Label Distributions

## Quick Facts
- arXiv ID: 2402.11447
- Source URL: https://arxiv.org/abs/2402.11447
- Authors: Zhichao Xu; Daniel Cohen; Bei Wang; Vivek Srikumar
- Reference count: 17
- Primary result: PDO improves classification accuracy, reduces variance, and enhances model calibration compared to baselines without requiring labeled development data

## Executive Summary
This paper addresses the challenge of optimizing in-context example ordering for improved in-context learning (ICL) performance. The authors propose Probability Distribution Ordering (PDO), which leverages the model's output probability distributions to select orderings that minimize bias and align with prior label distributions. PDO is agnostic to the choice of scoring function and can select high-quality in-context examples at the task level without requiring labeled development data. Experiments on 13 text classification datasets and 9 autoregressive language models demonstrate that PDO outperforms baseline methods in classification accuracy, variance reduction, and model calibration.

## Method Summary
PDO selects in-context example orderings based on two principles: () minimizing KL divergence between the model's probability distribution on a null input and a uniform distribution when no unlabeled data is available, and (2) minimizing KL divergence between the model's observed label distribution on unlabeled data and a prior label distribution when prior knowledge exists. The method samples 24 permutations from all possible k! permutations, ranks them using PDO, and selects the top-4 orderings. PDO can be combined with Direct and PMI approaches, and experiments demonstrate improvements across 13 text classification datasets using 9 autoregressive language models (700M-13B parameters).

## Key Results
- PDO improves classification accuracy compared to baseline methods across 13 text classification datasets
- PDO reduces variance in ICL performance while maintaining or improving accuracy
- PDO enhances model calibration, reducing Expected Calibration Error (ECE) compared to baselines
- PDO-Direct can select high-quality in-context examples without requiring labeled development data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Minimizing KL divergence between the model's probability distribution on a null input and a uniform distribution reduces bias in the model's predictions.
- Mechanism: When the model sees no input, a less biased model should have a probability distribution closer to uniform across all possible labels. By selecting orderings that minimize this KL divergence, we are effectively selecting orderings that make the model less biased.
- Core assumption: The KL divergence between the model's null input distribution and uniform distribution is a reliable proxy for the model's overall bias.
- Evidence anchors:
  - [abstract] "We propose to select the best ordering that, on the corpus level, has a probability distribution over candidate labels, such that it is (a) less biased towards certain labels"
  - [section 3.1] "PRINCIPLE I: When unlabeled examples are not available, well-ordered in-context examples should lead to the probability distribution of a null input having the minimum KL divergence to a uniform distribution."
  - [corpus] Found 25 related papers. Average neighbor FMR=0.498. This suggests moderate relatedness to other in-context learning ordering works.
- Break condition: If the model's bias doesn't manifest in the null input distribution, or if other factors dominate the model's bias more than the in-context examples.

### Mechanism 2
- Claim: Matching the model's observed label distribution on unlabeled examples to a prior label distribution improves calibration and accuracy.
- Mechanism: By selecting orderings that minimize the KL divergence between the observed label distribution on unlabeled examples and a prior distribution, we are selecting orderings that make the model's predictions align with our expectations about the data distribution.
- Core assumption: The prior label distribution is a good representation of the true data distribution.
- Evidence anchors:
  - [abstract] "We consider two cases: (a) when we only have in-context examples (FewShot), and (b) when we also have unlabeled examples ( FewShotU) and additionally know the prior label distributions (FewShotUP)."
  - [section 3.2] "PRINCIPLE II: Given an unlabeled set of examples and the prior label distribution, well-ordered in-context examples should produce an observed label distribution that matches the prior label distribution."
  - [corpus] Found 25 related papers. Average neighbor FMR=0.498. This suggests moderate relatedness to other in-context learning ordering works.
- Break condition: If the prior label distribution is inaccurate, or if the unlabeled examples are not representative of the true data distribution.

### Mechanism 3
- Claim: The PMI scoring function can lead to over-confident predictions, and using PDO with PMI mitigates this issue.
- Mechanism: The PMI scoring function can magnify skewness in the model's output probability distribution, leading to over-confident predictions. By selecting orderings that minimize bias and align with prior distributions, PDO can counteract this effect.
- Core assumption: The over-confidence from PMI is primarily due to the skewness it introduces in the model's output distribution.
- Evidence anchors:
  - [section 2.2] "PMI skews the output probability distribution, leading to miscalibrated model outputs."
  - [section 4.4] "PDO reduces in-context learning miscalibration."
  - [corpus] Found 25 related papers. Average neighbor FMR=0.498. This suggests moderate relatedness to other in-context learning ordering works.
- Break condition: If the over-confidence from PMI is due to factors other than distribution skewness, or if PDO's bias reduction isn't sufficient to counteract PMI's effects.

## Foundational Learning

- Concept: KL divergence as a measure of difference between probability distributions
  - Why needed here: KL divergence is the core metric used to evaluate both bias in the null input distribution and alignment with prior distributions.
  - Quick check question: What does a KL divergence of 0 between two distributions mean?

- Concept: In-context learning and few-shot learning
  - Why needed here: The entire approach is built on optimizing in-context learning performance by selecting better orderings of in-context examples.
  - Quick check question: How does in-context learning differ from traditional fine-tuning?

- Concept: Expected Calibration Error (ECE) as a measure of model calibration
  - Why needed here: ECE is used to evaluate whether PDO improves model calibration in addition to accuracy.
  - Quick check question: What does an ECE value of 0 indicate about a model's predictions?

## Architecture Onboarding

**Component Map**: In-context examples → Permutation sampling → KL divergence computation → Ordering selection → Model inference → Accuracy/ECE evaluation

**Critical Path**: The core pipeline involves sampling permutations of in-context examples, computing their probability distributions using the language model, evaluating KL divergence metrics, and selecting the top-ranked orderings for final evaluation.

**Design Tradeoffs**: PDO trades computational efficiency (sampling 24 permutations instead of all k!) for practical feasibility while maintaining effectiveness. The method also trades explicit use of labeled development data for performance comparable to influence-based methods.

**Failure Signatures**: Poor performance may result from inaccurate prior distributions in FewShotUP, insufficient permutation sampling that misses optimal orderings, or models where output probability distributions don't reliably reflect label bias.

**First 3 Experiments**:
1. Implement PDO with FewShot setting on a simple binary classification dataset to verify basic functionality
2. Compare PDO-Direct against Direct baseline on multi-class classification to validate improvements
3. Test PDO-PMI on an imbalanced dataset to evaluate calibration improvements

## Open Questions the Paper Calls Out

1. **Cross-task generalization**: How do the proposed principles (minimizing KL divergence to uniform distribution or prior) generalize to tasks beyond text classification, such as generation tasks (summarization, QA)? The paper notes this is a potential future direction.

2. **Large model scaling**: How does PDO performance scale with model size beyond 13B parameters, particularly for commercial models like GPT-4? The authors acknowledge this requires further experiments.

3. **Parameterized ordering**: Can the computational complexity of PDO be reduced by parameterizing the ordering selection process instead of sampling permutations? The authors suggest this as an alternative approach for future work.

## Limitations

- **Generalizability uncertainty**: While PDO shows improvements on 13 text classification datasets, its effectiveness across different NLP tasks (e.g., generation, question answering) and non-text domains remains unknown.

- **Prior distribution dependency**: The FewShotUP variant's performance depends heavily on the quality of prior label distributions, but the paper doesn't address how to obtain reliable priors when such knowledge is unavailable.

- **Permutation sampling strategy**: The paper samples only 24 permutations from all possible k! permutations, and it's unclear whether this sampling approach captures the full optimization landscape effectively.

## Confidence

**High Confidence**: PDO improves classification accuracy and reduces variance compared to baselines across extensive experiments on 13 datasets and 9 models.

**Medium Confidence**: PDO improves model calibration (reduces ECE), though calibration improvements may be sensitive to specific model architectures and dataset characteristics.

**Medium Confidence**: PDO-Direct outperforms baseline methods without requiring labeled development data, though generalizability depends on specific baseline selection and dataset distribution.

## Next Checks

1. **Cross-task validation**: Test PDO on non-classification tasks (e.g., text generation, summarization) to evaluate whether the probability distribution-based ordering principles generalize beyond classification.

2. **Prior sensitivity analysis**: Systematically vary the quality and accuracy of prior label distributions to quantify their impact on FewShotUP performance, particularly examining cases where priors are significantly mismatched from true distributions.

3. **Permutation space completeness**: Compare results using the 24-sample strategy against results using larger sample sizes or deterministic ranking methods to determine whether the sampling approach captures the full optimization landscape effectively.