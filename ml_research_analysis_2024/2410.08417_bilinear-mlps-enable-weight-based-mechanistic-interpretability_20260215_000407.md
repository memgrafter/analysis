---
ver: rpa2
title: Bilinear MLPs enable weight-based mechanistic interpretability
arxiv_id: '2410.08417'
source_url: https://arxiv.org/abs/2410.08417
tags:
- eigenvectors
- features
- bilinear
- input
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper shows that bilinear multi-layer perceptrons (MLPs),
  which use a simple element-wise product activation without nonlinearities, can be
  analyzed through weight-based methods. By expressing bilinear layers as a third-order
  tensor, the authors decompose them into interpretable components via eigendecomposition,
  revealing low-rank structure across tasks.
---

# Bilinear MLPs enable weight-based mechanistic interpretability

## Quick Facts
- arXiv ID: 2410.08417
- Source URL: https://arxiv.org/abs/2410.08417
- Authors: Michael T. Pearce; Thomas Dooms; Alice Rigg; Jose M. Oramas; Lee Sharkey
- Reference count: 40
- Key outcome: This paper shows that bilinear multi-layer perceptrons (MLPs), which use a simple element-wise product activation without nonlinearities, can be analyzed through weight-based methods. By expressing bilinear layers as a third-order tensor, the authors decompose them into interpretable components via eigendecomposition, revealing low-rank structure across tasks. On image classification (MNIST, Fashion-MNIST), the top eigenvectors capture meaningful patterns like digit strokes and edge detectors, with truncation preserving accuracy. On language modeling, low-rank approximations explain output feature activations, and a sentiment negation circuit is identified through nonlinear feature interactions. The results demonstrate that bilinear layers serve as an interpretable replacement for standard MLPs and that weight-based interpretability is viable for deep models.

## Executive Summary
This paper introduces bilinear multi-layer perceptrons (MLPs) as an interpretable alternative to conventional MLPs. By replacing the standard nonlinearity with an element-wise product activation, bilinear layers can be fully expressed as linear operations using a third-order tensor. The authors demonstrate that eigendecomposition of these tensors reveals interpretable low-rank structure across different tasks. On image classification, the top eigenvectors capture meaningful visual patterns, while on language modeling, they explain feature interactions and identify specific circuits like sentiment negation. The approach provides a principled method for understanding how neural networks compute through weight analysis rather than just input-output behavior.

## Method Summary
The authors propose bilinear MLPs that use element-wise product activations instead of nonlinearities. These layers can be expressed as third-order tensors constructed from two weight matrices W and V. For any given output direction, the interaction matrix Q can be decomposed into eigenvectors and eigenvalues using the spectral theorem. The top eigenvectors by magnitude provide the best low-rank approximation to the interaction matrix. The method is applied to both image classification tasks (MNIST, Fashion-MNIST) and language modeling (TinyStories), where sparse autoencoders extract input and output features that are then analyzed through the bilinear tensor decomposition.

## Key Results
- Top eigenvectors of bilinear weights reveal interpretable low-rank structure across tasks, with visual patterns like digit strokes and edge detectors on MNIST
- Low-rank approximations preserve model performance while capturing meaningful computational patterns
- A sentiment negation circuit is identified in language models through nonlinear feature interactions revealed by the bilinear decomposition
- Bilinear layers provide intrinsic interpretability that aids in feature and circuit extraction compared to conventional MLPs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Bilinear MLPs can be fully expressed as linear operations via a third-order tensor.
- **Mechanism:** The element-wise product in a bilinear layer, $(W\mathbf{x}) \odot (V\mathbf{x})$, can be rewritten as $\mathbf{x}^T B \mathbf{x}$ where $B$ is a third-order tensor with entries $b_{aij} = w_{ai}v_{aj}$.
- **Core assumption:** The bilinear layer has no element-wise nonlinearity, preserving the quadratic form.
- **Evidence anchors:**
  - [abstract] "Bilinear MLPs can be fully expressed in terms of linear operations using a third-order tensor"
  - [section] "A bilinear MLP parameterizes the pairwise interactions between inputs... The collection of interaction matrices across the output axis can be organized into the third-order bilinear tensor, B, with elements $b_{aij} = w_{ai}v_{aj}$"
  - [corpus] Weak - no direct evidence found in related papers
- **Break condition:** Introducing any element-wise nonlinearity destroys the quadratic form and breaks the tensor representation.

### Mechanism 2
- **Claim:** The eigenvector decomposition of bilinear weights reveals interpretable low-rank structure.
- **Mechanism:** For a given output direction $u$, the interaction matrix $Q = u \cdot_{out} B$ can be decomposed into eigenvectors $v_i$ and eigenvalues $\lambda_i$, where the output is $\sum_i \lambda_i (v_i^T \mathbf{x})^2$.
- **Core assumption:** The interaction matrix is symmetric (by construction), allowing real eigenvalues and orthogonal eigenvectors.
- **Evidence anchors:**
  - [abstract] "Analyzing the spectra of bilinear MLP weights using eigendecomposition reveals interpretable low-rank structure"
  - [section] "The interaction matrix, $Q = u \cdot_{out} B$ for a given output feature $u$ can be decomposed into a set of eigenvectors... the spectral theorem gives $Q = \sum_i \lambda_i v_i v_i^T$"
  - [corpus] Weak - no direct evidence found in related papers
- **Break condition:** If the interaction matrix has high rank or lacks structure, eigenvectors may not be interpretable.

### Mechanism 3
- **Claim:** Low-rank approximations of bilinear weights can preserve model performance while revealing computation.
- **Mechanism:** Truncating the eigenvector decomposition to top components provides a low-rank approximation that maintains accuracy while capturing the most important computational patterns.
- **Core assumption:** The model's computations rely on low-rank structure that can be captured by top eigenvectors.
- **Evidence anchors:**
  - [abstract] "Smaller eigenvalue terms can be truncated while preserving performance"
  - [section] "The top eigenvectors by eigenvalue magnitude give the best low-rank approximation to the interaction matrix Q for a given rank"
  - [corpus] Weak - no direct evidence found in related papers
- **Break condition:** If the model relies on high-frequency or complex interactions not captured by low-rank approximations, performance will degrade.

## Foundational Learning

- **Concept: Third-order tensor representation**
  - Why needed here: This is the fundamental mathematical structure that enables weight-based interpretability of bilinear layers
  - Quick check question: How would you construct a third-order tensor from two weight matrices W and V?

- **Concept: Eigendecomposition of symmetric matrices**
  - Why needed here: The interaction matrices are symmetric, allowing real eigenvalues and orthogonal eigenvectors that reveal computational structure
  - Quick check question: What guarantees that the eigenvectors of a symmetric matrix are orthogonal?

- **Concept: Low-rank approximation**
  - Why needed here: Many model computations can be captured by top eigenvectors, enabling both interpretability and efficiency
  - Quick check question: What mathematical property ensures that truncating small eigenvalues gives the best low-rank approximation?

## Architecture Onboarding

- **Component map:**
  Input layer → Bilinear MLP (W, V matrices) → Output layer

- **Critical path:**
  1. Forward pass through bilinear layer: $(W\mathbf{x}) \odot (V\mathbf{x})$
  2. Construct interaction matrix: $Q = u \cdot_{out} B$
  3. Eigendecomposition: $Q = \sum_i \lambda_i v_i v_i^T$
  4. Compute output: $\sum_i \lambda_i (v_i^T \mathbf{x})^2$

- **Design tradeoffs:**
  - Bilinear layers vs SwiGLU: Slightly worse performance but much better interpretability
  - Sparse vs dense eigenvectors: Sparse eigenvectors are more interpretable but may miss important interactions
  - Low-rank vs full-rank: Lower rank improves interpretability but may reduce accuracy

- **Failure signatures:**
  - High-rank eigenvalue spectra with no clear structure
  - Eigenvectors that don't correspond to interpretable features
  - Performance degradation when using low-rank approximations
  - Unstable eigendecompositions during training

- **First 3 experiments:**
  1. Implement a simple bilinear MLP on MNIST and visualize top eigenvectors for each digit
  2. Compare performance of bilinear vs SwiGLU on TinyStories language modeling
  3. Apply eigenvector truncation to a trained bilinear model and measure accuracy degradation

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas for future research are implied:

- Applying sparse dictionary learning approaches to decompose the bilinear tensor while relaxing the orthogonality constraint of eigenvectors to find more interpretable features from model weights
- Extending the interpretability techniques to analyze conventional MLPs by approximating their nonlinear computations with bilinear or low-rank approximations
- Investigating how bilinear layers perform compared to conventional MLPs in large-scale language models beyond the 6-layer model tested in this paper

## Limitations
- The analysis relies on symmetric interaction matrices by construction, and the paper doesn't fully address how non-symmetric bilinear layers would affect interpretability
- The low-rank approximation claims are supported by empirical results but lack theoretical guarantees about how much rank reduction is possible
- The language modeling experiments focus on a single small-scale model and one specific circuit, limiting generalizability to larger models and other circuit types

## Confidence

**High confidence**: The mathematical framework for representing bilinear layers as third-order tensors and the resulting eigendecomposition approach are well-established and correctly applied. The MNIST and Fashion-MNIST visualizations of interpretable eigenvectors are compelling and reproducible.

**Medium confidence**: The claim that low-rank approximations can preserve model performance while improving interpretability is supported by the presented results but would benefit from more systematic ablation studies across different tasks and rank thresholds.

**Low confidence**: The generalizability of the interpretability findings to complex language model circuits beyond the demonstrated sentiment negation example, and the claim that bilinear MLPs are universally "better" for interpretability than other architectures.

## Next Checks

1. **Systematic rank reduction study**: Systematically vary the rank of eigenvector truncation across multiple tasks (MNIST, CIFAR-10, TinyStories) and measure the accuracy-performance tradeoff curve to determine how much compression is possible while maintaining acceptable performance.

2. **Cross-circuit validation**: Apply the bilinear interpretability framework to identify and validate multiple circuit types in the TinyStories model beyond sentiment negation, such as syntax processing, coreference resolution, or multi-hop reasoning patterns.

3. **Architecture comparison scaling**: Compare bilinear MLPs against SwiGLU and other interpretable architectures across a range of model scales (from TinyStories up to medium-sized LMs) to determine if the interpretability-performance tradeoff remains favorable as model complexity increases.