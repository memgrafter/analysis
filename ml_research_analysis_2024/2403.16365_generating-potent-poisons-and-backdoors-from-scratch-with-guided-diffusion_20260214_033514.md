---
ver: rpa2
title: Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion
arxiv_id: '2403.16365'
source_url: https://arxiv.org/abs/2403.16365
tags:
- samples
- poisoning
- attacks
- base
- backdoor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Guided Diffusion Poisoning (GDP), a novel
  approach for crafting potent data poisoning and backdoor attacks. GDP synthesizes
  base samples from scratch using guided diffusion, optimizing them specifically for
  the poisoning objective.
---

# Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion

## Quick Facts
- arXiv ID: 2403.16365
- Source URL: https://arxiv.org/abs/2403.16365
- Reference count: 26
- Key outcome: GDP outperforms state-of-the-art attacks, achieving higher success rates even with smaller perturbation budgets and fewer poison samples

## Executive Summary
This paper introduces Guided Diffusion Poisoning (GDP), a novel approach for crafting potent data poisoning and backdoor attacks. The method synthesizes base samples from scratch using guided diffusion, optimizing them specifically for the poisoning objective. These generated base samples are then used as initialization for existing data poisoning and backdoor attack algorithms, significantly boosting their effectiveness. Experiments on CIFAR-10 and ImageNet demonstrate that GDP achieves higher success rates compared to state-of-the-art attacks while requiring smaller perturbation budgets and fewer poison samples.

## Method Summary
GDP uses guided diffusion to generate base samples from scratch, with weak guidance toward the poisoning objective while maintaining strong classifier guidance for clean-label appearance. These base samples serve as initialization for downstream poisoning or backdoor attacks. The method employs universal guidance to steer the diffusion process, combining the poison class label with the poisoning objective. Generated base samples are then used with existing attack algorithms (Witches' Brew or Sleeper Agent) and filtered by objective value before deployment.

## Key Results
- GDP base samples achieve higher poison success rates than random initialization, even with smaller perturbation budgets
- The method maintains clean-label appearance as confirmed by human evaluation
- GDP enables effective attacks with fewer poison samples (as few as 25-50 samples)
- The approach remains effective against various defense mechanisms

## Why This Works (Mechanism)

### Mechanism 1
Diffusion-generated base samples lie near potent poisons while maintaining clean-label appearance. GDP weakly guides the diffusion process using a low-strength gradient-matching poisoning loss while also using strong classifier guidance to maintain the poison class label. The optimization landscape allows simultaneous alignment with poisoning objectives and natural image appearance.

### Mechanism 2
GDP base samples enable more effective downstream poisoning attacks. By starting from base samples already aligned with the poisoning objective, the downstream optimization has less distance to travel and achieves better alignment with a smaller perturbation budget.

### Mechanism 3
GDP enables effective attacks with fewer poison samples. GDP generates more potent poisons per sample, so fewer samples are needed to achieve the same attack success rate.

## Foundational Learning

- **Diffusion models and denoising process**: Needed to understand how GDP uses diffusion to generate base samples from scratch. Quick check: What are the forward and reverse phases in a diffusion model, and how does the denoising network estimate noise?

- **Universal guidance for diffusion models**: Needed to understand how GDP steers the diffusion process toward both the poison class and poisoning objective. Quick check: How does universal guidance differ from classifier guidance and classifier-free guidance?

- **Gradient alignment in poisoning attacks**: Needed to understand the mathematical formulation of gradient-matching objectives used in GDP. Quick check: What is the mathematical formulation of gradient alignment in targeted poisoning attacks?

## Architecture Onboarding

- **Component map**: Pretrained diffusion model -> Universal guidance algorithm -> Generated base samples -> Downstream poisoning attack -> Filtered poisons

- **Critical path**: 1) Generate GDP base samples using guided diffusion, 2) Apply downstream poisoning attack with ℓ∞ constraints, 3) Filter poisons by objective value, 4) Replace random training samples with selected poisons

- **Design tradeoffs**: Guidance strength vs. image quality, base sample quantity vs. generation cost, perturbation budget vs. stealthiness

- **Failure signatures**: Human evaluation shows GDP base samples are misclassified, downstream poisoning attack fails to improve over random initialization, validation accuracy drops significantly

- **First 3 experiments**: 1) Generate GDP base samples for CIFAR-10 with weak Witches' Brew guidance and verify clean-label via human evaluation, 2) Apply Witches' Brew poisoning to GDP base samples and compare success rate to random initialization, 3) Test GDP backdoor attack with Sleeper Agent on CIFAR-10 and measure attack success vs. baseline

## Open Questions the Paper Calls Out

### Open Question 1
Can diffusion-generated base samples be created without requiring a diffusion model trained specifically on the target dataset? The paper notes this as a limitation but does not explore alternatives. Evidence would require experiments showing general-purpose text-to-image diffusion models achieve similar effectiveness.

### Open Question 2
How does the effectiveness of GDP change when the poison budget is extremely small (fewer than 25 poisoned samples)? The paper focuses on 25-50 samples but leaves the lower bound unexplored. Evidence would require experiments showing success rates with budgets below 25 samples.

### Open Question 3
What is the impact of different diffusion guidance strengths on the quality and effectiveness of GDP base samples? The paper uses a fixed guidance strength without exploring the trade-off. Evidence would require a sensitivity analysis showing how different strengths affect success rates and sample quality.

## Limitations

- Human evaluation was conducted only on CIFAR-10 base samples with limited participant numbers
- ImageNet results are less thoroughly validated with human evaluation
- The work assumes access to pre-trained diffusion models and classifiers
- The approach requires significant computational resources for generating base samples

## Confidence

- **High Confidence**: The core mechanism of using guided diffusion to generate base samples for poisoning attacks is technically sound and well-supported by experimental results
- **Medium Confidence**: The effectiveness of GDP base samples against various defense mechanisms needs more extensive validation
- **Medium Confidence**: The claim about generating high-quality base samples that maintain clean-label appearance is supported by human evaluation but could benefit from larger-scale validation

## Next Checks

1. Conduct a larger-scale human evaluation study with more participants and diverse demographic representation to validate the clean-label quality of GDP base samples

2. Test GDP against additional state-of-the-art defense mechanisms not covered in the current evaluation

3. Evaluate the computational efficiency and resource requirements of the guided diffusion process compared to existing poisoning approaches