---
ver: rpa2
title: Empirical Study of Symmetrical Reasoning in Conversational Chatbots
arxiv_id: '2407.05734'
source_url: https://arxiv.org/abs/2407.05734
tags:
- chatbots
- symmetry
- gemini
- sentences
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper examines whether large language models (LLMs) used\
  \ in conversational chatbots can reason about predicate symmetry\u2014a cognitive\
  \ linguistic function thought to be uniquely human. The study uses in-context learning\
  \ (ICL) to test five chatbots (ChatGPT 4, HuggingChat, Copilot, LLaMA via Perplexity,\
  \ and Gemini Advanced) on the Symmetry Inference Sentence (SIS) dataset."
---

# Empirical Study of Symmetrical Reasoning in Conversational Chatbots

## Quick Facts
- arXiv ID: 2407.05734
- Source URL: https://arxiv.org/abs/2407.05734
- Authors: Daniela N. Rim; Heeyoul Choi
- Reference count: 31
- Five chatbots tested on predicate symmetry reasoning using in-context learning achieved correlation scores up to 0.85 with human evaluations

## Executive Summary
This paper examines whether large language models used in conversational chatbots can reason about predicate symmetryâ€”a cognitive linguistic function thought to be uniquely human. The study uses in-context learning (ICL) to test five chatbots (ChatGPT 4, HuggingChat, Copilot, LLaMA via Perplexity, and Gemini Advanced) on the Symmetry Inference Sentence (SIS) dataset. Chatbots were prompted to rate how similar the meaning of two syntactically-alternated sentences was, using a 1-5 scale, without any fine-tuning. Results showed that Gemini performed best, achieving a correlation of 0.85 with human scores, and provided reasoned justifications for its evaluations.

## Method Summary
The study evaluated five conversational chatbots using in-context learning on the Symmetry Inference Sentence (SIS) dataset containing 400 sentence pairs. Chatbots received identical prompts based on human evaluator instructions and rated sentence pair similarity on a 1-5 scale. Performance was measured by correlation with human evaluation scores. Gemini achieved the highest correlation (0.85) while also providing justifications for its symmetry evaluations.

## Key Results
- Gemini achieved correlation of 0.85 with human symmetry scores, the highest among tested models
- HuggingChat and Gemini showed ICL capabilities comparable to fine-tuned language models like BERT
- Some LLMs can capture predicate symmetry through in-context learning without explicit training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gemini's strong symmetry reasoning arises from superior internal representation of predicate-argument relations through ICL.
- Mechanism: Gemini's architecture allows it to capture structural patterns in predicate-argument relations from the training corpus, enabling it to generalize symmetry judgments during ICL without fine-tuning.
- Core assumption: Symmetry understanding is encoded implicitly in the model's weights and can be activated through appropriate prompting.
- Evidence anchors:
  - [abstract] "Gemini, for example, reaches a correlation of 0.85 with human scores, while providing a sounding justification for each symmetry evaluation"
  - [section] "HuggingChat and Gemini exhibited ICL capabilities comparable to fine-tuned language models like BERT, even without explicit training on symmetry features"
  - [corpus] Weak - no direct evidence in corpus about model internals or training data composition

### Mechanism 2
- Claim: The combination of prompt design and model architecture enables Gemini to produce consistent symmetry judgments across multiple trials.
- Mechanism: Gemini's architecture includes mechanisms for maintaining reasoning consistency across prompts, and the structured prompt format helps the model access relevant internal representations.
- Core assumption: The model's architecture includes components that support reasoning consistency and that prompt structure influences how the model accesses these components.
- Evidence anchors:
  - [section] "While we do not have access to the individual answers of each human evaluator, we have the vote count for each score (1-5) given each SIS sentence pair. This made it possible to calculate the majority vote (M.V.), i.e., scoring the sentence pair symmetry with the most elected integer out of the five"
  - [section] "The correlation falls within a threshold of 0.7 and 0.84, showing consistency in Gemini's judgment"
  - [corpus] Weak - no evidence about Gemini's specific architectural components that support reasoning consistency

### Mechanism 3
- Claim: Gemini's justification capability indicates deeper semantic understanding of symmetry beyond surface-level pattern matching.
- Mechanism: Gemini's architecture includes components that enable it to generate coherent explanations by accessing semantic relationships between predicates and their arguments.
- Core assumption: The ability to generate justifications requires access to semantic representations beyond those needed for classification.
- Evidence anchors:
  - [abstract] "Gemini, for example, reaches a correlation of 0.85 with human scores, while providing a sounding justification for each symmetry evaluation"
  - [section] "The first example is for a sentence pair case judged as a 1 for most human voters and received an average of 1.43"
  - [corpus] Weak - no evidence about the relationship between justification generation and semantic understanding in the corpus

## Foundational Learning

- Concept: Predicate-argument relations in natural language
  - Why needed here: Understanding how verbs relate multiple entities is fundamental to symmetry reasoning
  - Quick check question: What distinguishes symmetric from asymmetric predicates in terms of their argument structure?

- Concept: In-context learning mechanisms
  - Why needed here: ICL is the method used to test symmetry reasoning without fine-tuning
  - Quick check question: How does ICL differ from traditional fine-tuning in terms of model adaptation?

- Concept: Correlation metrics for model evaluation
  - Why needed here: Performance is measured against human evaluations using correlation scores
  - Quick check question: What does a correlation of 0.85 between model and human scores indicate about model performance?

## Architecture Onboarding

- Component map: Input prompt processing -> Semantic representation layer -> Symmetry reasoning module -> Output generation -> Justification generation
- Critical path: Prompt -> Semantic parsing -> Symmetry judgment -> Correlation with human scores
- Design tradeoffs: Balance between model size (parameter count) and reasoning capability; trade-off between prompt engineering effort and model performance
- Failure signatures: Low correlation with human scores; inconsistent judgments across trials; inability to provide coherent justifications
- First 3 experiments:
  1. Test symmetry reasoning on a held-out subset of the SIS dataset to validate generalization
  2. Modify prompt structure to see how it affects Gemini's performance and consistency
  3. Compare Gemini's symmetry reasoning with other models on the same dataset using identical prompts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific linguistic features that contribute to symmetrical reasoning in LLMs, and how do they differ across models?
- Basis in paper: [explicit] The paper mentions that certain models like Gemini and HuggingChat perform comparably to fine-tuned BERT models, suggesting they capture linguistic features related to symmetry without explicit training.
- Why unresolved: While the paper shows correlation scores, it does not delve into the specific linguistic features or mechanisms that enable certain models to perform better in symmetrical reasoning tasks.
- What evidence would resolve it: Detailed analysis of the linguistic features and mechanisms used by different models, possibly through feature attribution methods or linguistic feature extraction.

### Open Question 2
- Question: How does the stochastic nature of conversational chatbots impact their reliability in symmetrical reasoning tasks?
- Basis in paper: [explicit] The paper notes that Gemini was tested multiple times to assess stability, showing strong correlation within its answers, but acknowledges the need to understand the degree of randomness.
- Why unresolved: The paper hints at stochasticity but does not provide a comprehensive analysis of its impact on reliability and consistency across different models.
- What evidence would resolve it: Comparative studies of multiple trials across various models, analyzing the variance in their responses to the same prompts.

### Open Question 3
- Question: Can LLMs be further optimized to improve their understanding of nuanced linguistic patterns beyond symmetry, such as diathesis alternations or other complex syntactic structures?
- Basis in paper: [inferred] The paper discusses symmetry as a fundamental linguistic property and suggests that understanding it could aid in systematic generalization, implying potential for further optimization.
- Why unresolved: While the paper shows LLMs can handle symmetry, it does not explore their capability to generalize to other complex linguistic patterns.
- What evidence would resolve it: Experiments testing LLMs on a broader range of linguistic patterns, evaluating their performance and identifying areas for improvement.

## Limitations

- Exact prompt formats for each chatbot are not specified, which could significantly impact performance
- Study relies on correlation with human scores rather than direct validation of semantic understanding
- Stability of performance across different symmetry types and prompt variations remains unclear

## Confidence

- **High Confidence**: Gemini's superior performance (0.85 correlation) and its ability to provide reasoned justifications is well-supported by the results
- **Medium Confidence**: The claim that HuggingChat performs competitively is supported but could benefit from more detailed comparison metrics
- **Low Confidence**: The assertion that symmetry understanding is implicitly encoded in model weights through ICL is speculative

## Next Checks

1. **Prompt Sensitivity Analysis**: Systematically vary prompt structure, wording, and example selection to quantify how much performance depends on prompt engineering versus model capability.

2. **Cross-Dataset Generalization**: Test Gemini and other top-performing models on a held-out symmetry dataset with different predicate-argument structures to validate generalization beyond the SIS dataset.

3. **Temporal Consistency Study**: Conduct multiple trials over an extended period to measure performance stability and identify any degradation or improvement patterns in symmetry reasoning capabilities.