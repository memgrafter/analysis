---
ver: rpa2
title: Items or Relations -- what do Artificial Neural Networks learn?
arxiv_id: '2404.12401'
source_url: https://arxiv.org/abs/2404.12401
tags:
- training
- network
- items
- networks
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines what auto-associative neural networks learn
  by training simple two-layer networks on small binary input sets with known symmetry
  properties. Using both analytical and numerical methods, the authors compare linear
  and non-linear networks (with tanh and sigmoid activations) to determine whether
  they learn training items or the relations between them.
---

# Items or Relations -- what do Artificial Neural Networks learn?

## Quick Facts
- **arXiv ID**: 2404.12401
- **Source URL**: https://arxiv.org/abs/2404.12401
- **Reference count**: 15
- **Primary result**: Linear networks learn relations through plane attractors enabling generalization, while non-linear networks learn individual training items through stable fixed points

## Executive Summary
This study investigates what auto-associative neural networks learn by training simple two-layer networks on small binary input sets with known symmetry properties. Using both analytical and numerical methods, the authors compare linear and non-linear networks (with tanh and sigmoid activations) to determine whether they learn training items or the relations between them. The key finding is that linear networks implement plane attractors that generalize to all inputs within the symmetry group of the training set, while non-linear networks primarily learn individual training items through stable fixed points.

## Method Summary
The authors train 2-layer auto-associative neural networks on small binary input sets with known symmetry properties. They use three activation functions: linear (identity), tanh, and sigmoid. Networks are trained using SGD and ADAM optimizers with various weight initializations (0, 1, or random from uniform/Gaussian distributions). The analysis combines analytical solutions for simple cases with numerical experiments, examining weight matrices, training loss, and generalization to unseen patterns consistent with the symmetry group.

## Key Results
- Linear networks implement plane attractors that generalize to all linear combinations of training items within the symmetry group
- Non-linear networks (sigmoid and tanh) primarily learn individual training items through stable fixed points, limiting generalization
- The weight structure inherently represents the symmetry group of the training set regardless of activation function, but only linear networks exploit this for generalization
- Tanh networks partially generalize when operating in their linear regime around zero, while sigmoid networks show no generalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear networks learn relations through plane attractors, enabling generalization to unseen patterns within the symmetry group
- Mechanism: When the activation function is linear (φ(x) = x), the network implements a linear mapping that preserves the structure of the symmetry group. The resulting fixed points form a plane attractor where any linear combination of training items remains stable, allowing the network to generalize to patterns not explicitly in the training set but consistent with the symmetry structure
- Core assumption: The training set has a well-defined symmetry group and the network architecture can represent this symmetry structure
- Evidence anchors:
  - [abstract] "linear networks generalize, i.e., reproduce items that were not part of the training set but are consistent with the symmetry of the training set"
  - [section] "In this case, the plane spanned by the elements in the training set X is invariant under W"
  - [corpus] Weak - corpus lacks direct discussion of plane attractors or symmetry group generalization
- Break condition: If the activation function becomes strongly non-linear, or if the training set lacks a meaningful symmetry group, the plane attractor structure breaks down and generalization fails

### Mechanism 2
- Claim: Non-linear networks learn individual training items through stable fixed points, limiting generalization
- Mechanism: When activation functions like sigmoid or tanh are used, the non-linearity creates discrete stable fixed points at specific locations in state space. These fixed points correspond to the training items themselves, and the network dynamics drive inputs toward these specific points rather than maintaining the continuous structure needed for generalization
- Core assumption: The non-linearity dominates the network behavior, creating strong attractors at specific locations rather than maintaining continuous symmetry structure
- Evidence anchors:
  - [abstract] "non-linear networks tend to learn individual training items and show associative memory. At the same time, their ability to generalize is limited"
  - [section] "non-linear auto-associators resemble more associative memory and have learned to represent the training items using stable fixed points"
  - [corpus] Missing - corpus does not discuss associative memory or fixed point dynamics
- Break condition: If the activation function operates in a linear regime (e.g., tanh near zero), some generalization may be possible, but the fundamental discrete fixed point structure remains

### Mechanism 3
- Claim: The network weight structure inherently represents the symmetry group of the training set regardless of activation function
- Mechanism: The requirement that the network must reproduce the training set exactly constrains the weight matrix to have a specific structure that reflects the symmetries present in the training data. This structural constraint exists even in non-linear networks, though the dynamics exploit it differently than in linear networks
- Core assumption: The auto-associative task imposes constraints on the weight matrix that align with the symmetry properties of the training set
- Evidence anchors:
  - [abstract] "the general structure of the network weights represents the training set's symmetry group"
  - [section] "The structure of the auto-associator network and the structure of the training set are closely related: The connectivity matrix of the auto-associator network represents the symmetry group of the training set"
  - [corpus] Weak - corpus mentions symmetry but not the specific constraint relationship between weight structure and training set symmetry
- Break condition: If the network architecture or task constraints change significantly, the direct relationship between weight structure and symmetry group may break down

## Foundational Learning

- Concept: Symmetry groups and their action on sets
  - Why needed here: Understanding how symmetry groups partition training sets into orbits is fundamental to distinguishing between learning items (individual elements) versus relations (symmetry structure)
  - Quick check question: If a training set has symmetry group Σ = {e, (23)} where e is identity and (23) swaps positions 2 and 3, what are the orbits of the set {{1,0,1}, {1,1,0}}?

- Concept: Linear versus non-linear dynamics in neural networks
  - Why needed here: The key distinction between generalization and item learning depends on whether the network implements continuous (linear) or discrete (non-linear) dynamics
  - Quick check question: In a 3D space, what geometric structure do linear networks create when they generalize to linear combinations of training items?

- Concept: Auto-associative memory and fixed point analysis
  - Why needed here: Understanding how networks implement auto-associative memory through fixed points is essential for interpreting whether they learn items or relations
  - Quick check question: What type of attractor (point, plane, or other) would you expect in a linear network trained on two linearly independent training vectors?

## Architecture Onboarding

- Component map:
  - Input layer: Receives binary sequences of fixed length
  - Weight matrix W: Square matrix constrained by symmetry group structure
  - Activation function φ: Determines linearity properties (identity, tanh, sigmoid)
  - Output layer: Produces reconstructed patterns
  - Symmetry group Σ: Mathematical structure representing relations between training items

- Critical path:
  1. Define training set and identify its symmetry group
  2. Construct weight matrix structure consistent with symmetry group
  3. Choose activation function based on desired generalization behavior
  4. Train or analytically solve for weight parameters
  5. Analyze fixed points and dynamics to determine what is learned

- Design tradeoffs:
  - Linear activation: Enables generalization but may be less biologically plausible
  - Non-linear activation: More realistic but limits generalization to learned items
  - Training complexity: Analytical solutions possible for simple cases but require computational methods for larger networks
  - Biological relevance: Balance between mathematical tractability and neural plausibility

- Failure signatures:
  - If network only reproduces training items with loss > 0 on test patterns: likely non-linear dynamics with item learning
  - If network weights don't reflect symmetry structure: possible implementation error or inappropriate training algorithm
  - If generalization fails despite linear activation: likely insufficient training or incorrect weight parameterization

- First 3 experiments:
  1. Train linear network on training set {{1,0,1}, {1,1,0}} with identity activation; verify it generalizes to {{0,0,0}, {0,1,1}}
  2. Train sigmoid network on same set; verify it only learns the two training items as fixed points
  3. Train tanh network on same set; verify partial generalization with slightly higher loss than linear case

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- The analytical framework relies on idealized symmetry groups and binary inputs that may not generalize to continuous or noisy real-world data
- The distinction between learning items versus relations depends critically on activation function properties, but the paper doesn't fully explore intermediate non-linearities or multi-layer architectures
- The empirical validation is limited to small binary datasets, leaving questions about scalability to larger, more complex problems

## Confidence
- **High confidence**: The linear network generalization mechanism (plane attractors) is well-supported by the mathematical analysis and consistent with linear algebra principles
- **Medium confidence**: The claim that non-linear networks primarily learn individual items is supported by numerical results but relies on specific assumptions about activation function behavior
- **Medium confidence**: The relationship between weight structure and symmetry group is analytically derived but the empirical validation is limited to simple cases

## Next Checks
1. Test networks on training sets with varying symmetry group complexity to verify whether generalization scales with symmetry structure complexity
2. Implement intermediate activation functions (e.g., piecewise linear with different slopes) to map the transition between item learning and relation learning
3. Apply the methodology to continuous-valued datasets to assess whether the symmetry-based analysis extends beyond binary inputs