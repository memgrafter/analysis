---
ver: rpa2
title: Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition
arxiv_id: '2406.02925'
source_url: https://arxiv.org/abs/2406.02925
tags:
- task
- syn2real
- speech
- vector
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of synthetic-to-real gap in
  automatic speech recognition (ASR), where models trained on synthetic data underperform
  on real speech due to acoustic mismatches. The proposed SYN2REAL task vector method
  bridges this gap by leveraging task arithmetic - creating a vector representation
  of the difference between models fine-tuned on real and synthetic data, then applying
  this vector to models trained on synthetic target domain data.
---

# Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition

## Quick Facts
- arXiv ID: 2406.02925
- Source URL: https://arxiv.org/abs/2406.02925
- Authors: Hsuan Su; Hua Farn; Fan-Yun Sun; Shang-Tse Chen; Hung-yi Lee
- Reference count: 14
- Primary result: SYN2REAL task vector achieves 10.03% average WER improvement over baselines on SLURP dataset

## Executive Summary
This paper addresses the synthetic-to-real gap in automatic speech recognition (ASR), where models trained on synthetic data underperform on real speech due to acoustic mismatches. The proposed SYN2REAL task vector method bridges this gap by leveraging task arithmetic - creating a vector representation of the difference between models fine-tuned on real and synthetic data, then applying this vector to models trained on synthetic target domain data. Experiments on the SLURP dataset show the SYN2REAL task vector achieves an average 10.03% improvement in word error rate (WER) over baseline methods. The approach is validated across different model sizes (Whisper Tiny, Base, Small) and ASR architectures (Whisper and Wav2Vec2-Conformer), demonstrating consistent improvements. Additional experiments show the method's flexibility by applying it to synthetic data from different TTS models (Speech T5, XTTS). An ensemble variant of the SYN2REAL approach, which combines task vectors from multiple source domains, achieves even better performance (18.25% WER reduction) when domain labels are available. The SYN2REAL task vector proves effective at capturing domain-specific acoustic information, making it a promising solution for improving ASR performance with synthetic data.

## Method Summary
The SYN2REAL method employs task arithmetic to bridge the synthetic-to-real gap in ASR. It first fine-tunes a pre-trained model on real speech data (Real model) and separately on synthetic speech data (Synthetic model). The difference between these two fine-tuned models is computed to create a task vector that captures the acoustic domain shift from synthetic to real speech. This task vector is then applied to models trained on synthetic data from target domains, effectively transferring the real speech characteristics to improve performance. The method is evaluated across different model sizes (Whisper Tiny, Base, Small) and ASR architectures (Whisper and Wav2Vec2-Conformer) on the SLURP dataset. An ensemble variant combines task vectors from multiple source domains for improved performance when domain labels are available. The approach demonstrates flexibility by working with synthetic data generated from different TTS models (Speech T5, XTTS).

## Key Results
- SYN2REAL task vector achieves 10.03% average WER improvement over baseline methods on SLURP dataset
- Consistent improvements across Whisper model sizes (Tiny, Base, Small) and ASR architectures (Whisper, Wav2Vec2-Conformer)
- Ensemble variant with multiple source domains achieves 18.25% WER reduction when domain labels available
- Method successfully transfers knowledge from various source domains to target domains

## Why This Works (Mechanism)
The SYN2REAL method works by leveraging task arithmetic to capture and transfer domain-specific acoustic information between synthetic and real speech domains. By computing the difference between models fine-tuned on real and synthetic data, the task vector encodes the acoustic characteristics that distinguish real speech from synthetic speech. When this vector is applied to models trained on synthetic target domain data, it effectively injects the real speech domain knowledge, mitigating the synthetic-to-real gap. The method exploits the continuity assumption in the task space, where the difference between two fine-tuned models represents a meaningful transformation that can be transferred to related tasks. The ensemble variant further enhances this by combining multiple source domain vectors, creating a more comprehensive representation of the acoustic space. This approach proves effective because it directly addresses the acoustic mismatch between synthetic and real speech through a learnable transformation rather than attempting to generate more realistic synthetic data.

## Foundational Learning
**Automatic Speech Recognition (ASR)**: Converts spoken language into text; needed for understanding the core application domain and evaluation metrics like WER.
Quick check: Verify the paper defines WER and explains its significance in ASR evaluation.

**Synthetic-to-Real Gap**: Performance degradation when models trained on synthetic data are applied to real speech due to acoustic mismatches; central problem being addressed.
Quick check: Confirm the paper provides evidence of performance degradation with synthetic data.

**Task Arithmetic**: Technique of computing vector differences between fine-tuned models to represent task transformations; the core methodology enabling SYN2REAL.
Quick check: Verify the paper explains how task arithmetic is applied to ASR models specifically.

**Fine-tuning**: Adapting pre-trained models to specific domains or tasks by continuing training on domain-specific data; essential for creating Real and Synthetic models.
Quick check: Confirm the paper details the fine-tuning process and hyperparameters used.

**Word Error Rate (WER)**: Standard ASR evaluation metric measuring the edit distance between predicted and reference transcriptions; primary performance metric.
Quick check: Verify WER calculation methodology and baseline comparisons.

## Architecture Onboarding

**Component Map**: Pre-trained ASR Model -> Fine-tune on Real Data (Real Model) -> Fine-tune on Synthetic Data (Synthetic Model) -> Compute Task Vector (Real - Synthetic) -> Apply to Target Domain Models -> Improved ASR Performance

**Critical Path**: The critical path involves creating the task vector by fine-tuning on both real and synthetic data, then applying this vector to target domain models. This requires access to real speech data for the source domain and synthetic data for both source and target domains.

**Design Tradeoffs**: The method requires additional fine-tuning steps (real and synthetic) to generate task vectors, increasing computational overhead. However, this is offset by improved performance without requiring complex synthetic data generation or domain adaptation techniques. The approach trades storage/memory (for storing task vectors) against performance gains.

**Failure Signatures**: The method may fail when the acoustic characteristics of source and target domains are too dissimilar, making the task vector ineffective at bridging the gap. Additionally, if the synthetic data quality is extremely poor or unrepresentative, the task vector may capture noise rather than meaningful domain differences.

**First Experiments**: 
1. Validate task vector computation by applying it to the Synthetic model itself and checking for recovery of the Real model
2. Test task vector transfer between different model sizes (e.g., from Whisper Base to Whisper Tiny)
3. Evaluate ensemble variant performance with varying numbers of source domains

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental scope limited to single dataset (SLURP), raising questions about generalizability across different ASR tasks and domains
- Computational overhead of fine-tuning multiple models to generate task vectors may limit practical applicability, especially for resource-constrained scenarios
- Performance highly dependent on the specific characteristics of the SLURP dataset, with potential variability across different speech recognition scenarios

## Confidence
- SYN2REAL effectiveness in bridging synthetic-to-real gap: **High** confidence (consistent WER improvements across multiple experiments and architectures)
- Task arithmetic capturing domain-specific acoustic information: **High** confidence (demonstrated ability to transfer knowledge from various source domains)
- Ensemble variants achieving superior performance: **Medium** confidence (relies on availability of domain labels which may not always be practical)

## Next Checks
1. Test SYN2REAL task vectors across diverse ASR datasets including telephony speech, conversational speech, and noisy environments to assess generalizability beyond SLURP
2. Evaluate the computational efficiency and memory requirements of generating and applying task vectors at scale, comparing against simpler adaptation methods
3. Investigate whether task vectors can be effectively transferred across different languages and accents, determining if acoustic characteristics are language-dependent or universal