---
ver: rpa2
title: 'FurniScene: A Large-scale 3D Room Dataset with Intricate Furnishing Scenes'
arxiv_id: '2401.03470'
source_url: https://arxiv.org/abs/2401.03470
tags:
- scene
- indoor
- furniture
- room
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FurniScene, a large-scale 3D indoor scene
  dataset with 111,698 rooms and 39,691 high-quality furniture CAD models across 89
  categories. It addresses the limitation of existing datasets that lack small furnishings
  and realism.
---

# FurniScene: A Large-scale 3D Room Dataset with Intricate Furnishing Scenes

## Quick Facts
- arXiv ID: 2401.03470
- Source URL: https://arxiv.org/abs/2401.03470
- Reference count: 40
- Key outcome: Introduces FurniScene (111,698 rooms, 39,691 CAD models across 89 categories) and TSDSM model achieving FID 44.45/36.54 and KID 22.65/19.31 for living room generation

## Executive Summary
This paper introduces FurniScene, a large-scale 3D indoor scene dataset containing 111,698 rooms with 39,691 high-quality furniture CAD models across 89 categories. The dataset addresses limitations of existing datasets by including intricate furnishings and small decorative objects. The authors also propose a Two-Stage Diffusion Scene Model (TSDSM) that first generates furniture lists and then retrieves models and layouts, improving scene generation quality. Experiments demonstrate TSDSM outperforms baselines like SceneFormer, ATISS, and DiffuScene on realism and diversity metrics.

## Method Summary
The authors propose a Two-Stage Diffusion Scene Model (TSDSM) for indoor scene generation. In the first stage, a Furniture List Generation Model (FLGM) uses a diffusion model to generate comprehensive furniture lists (categories and sizes) conditioned on text prompts. In the second stage, a Layout Generation Model (LGM) generates positions and orientations for the retrieved furniture models. The model uses transformers with cross-attention for text conditioning and is trained on the FurniScene dataset using DDPM settings with batch size 64 for 1000 epochs on NVIDIA A40 GPU.

## Key Results
- TSDSM achieves FID of 44.45/36.54 and KID of 22.65/19.31 for living room generation with/without text prompts
- Outperforms baselines SceneFormer, ATISS, and DiffuScene on realism and diversity metrics
- FurniScene contains 111,698 rooms with 39,691 unique furniture CAD models across 89 categories
- Average of 14.4 objects per room in FurniScene vs 6.9 in 3D-FRONT

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TSDSM's two-stage design separates furniture type/size generation from layout positioning, reducing the optimization complexity of the layout network.
- Mechanism: The first stage generates a furniture list (categories and sizes) using a diffusion model conditioned on text prompts, providing a fixed prior for the second stage which only needs to predict positions and orientations. This avoids the combinatorial explosion of predicting all attributes simultaneously.
- Core assumption: Realistic furniture lists can be generated from text prompts and reliably retrieved from a large CAD database.
- Evidence anchors: Abstract mentions TSDSM introduction; Section 4.2 describes the two-stage process with FLGM and FRS components.

### Mechanism 2
- Claim: Using diffusion models in both stages allows TSDSM to handle stochasticity and produce diverse, realistic results.
- Mechanism: Diffusion models progressively denoise noise into realistic samples. TSDSM uses separate denoising networks for furniture list generation and layout generation, allowing specialization in respective tasks.
- Core assumption: Diffusion models can effectively model furniture list and layout distributions in FurniScene dataset.
- Evidence anchors: Abstract mentions TSDSM; Section 4.2 describes the denoising process with furniture denoising network.

### Mechanism 3
- Claim: The furniture retrieval system ensures generated layouts use high-quality, textured CAD models from the dataset.
- Mechanism: After the first stage generates a furniture list, the FRS retrieves corresponding CAD models from FurniScene based on this list, ensuring real, high-quality furniture models with accurate textures and geometries.
- Core assumption: FurniScene dataset contains sufficient CAD models to cover generated furniture lists.
- Evidence anchors: Abstract mentions 39,691 unique furniture CAD models; Section 4.2 describes FRS retrieving furniture objects from the database.

## Foundational Learning

- Concept: Diffusion Models
  - Why needed here: TSDSM relies on diffusion models for both stages of furniture list and layout generation. Understanding forward noising and reverse denoising is crucial for grasping the architecture.
  - Quick check question: What is the key difference between the forward and reverse processes in a diffusion model?

- Concept: Scene Graphs and Object Representations
  - Why needed here: The paper represents rooms as sequences of objects with attributes (size, category, location, rotation). Understanding scene graphs is important for data preparation and model inputs.
  - Quick check question: How would you represent a 3D scene as a scene graph, and what information would each node contain?

- Concept: Transformer Networks
  - Why needed here: The paper uses transformers in denoising networks to model relationships between furniture items. Understanding transformers and attention mechanisms is crucial for capturing spatial and categorical dependencies.
  - Quick check question: What is the role of self-attention in a transformer network, and how does it help in modeling relationships between objects in a scene?

## Architecture Onboarding

- Component map: Text prompt → FLGM → FRS → LGM → 3D room
- Critical path: Text prompt → Furniture List Generation Model → Furniture Retrieval System → Layout Generation Model → 3D room
- Design tradeoffs:
  - Two-stage vs. single-stage: Two-stage allows focused optimization but introduces complexity and potential FRS failure points
  - Diffusion vs. other generative models: Diffusion models handle complex distributions well but are computationally expensive
  - Text conditioning: Allows controllable generation but adds model and data preparation complexity
- Failure signatures:
  - FLGM failure: Unrealistic furniture lists (wrong categories, sizes, or quantities)
  - FRS failure: Missing or incorrect CAD model retrieval
  - LGM failure: Overlapping furniture, impossible layouts, or lack of diversity
- First 3 experiments:
  1. Ablation study: Remove text conditioning from FLGM and observe impact on generated scenes
  2. Stress test: Generate scenes with extreme text prompts (e.g., "a room with 100 chairs") and analyze model behavior
  3. Robustness test: Intentionally corrupt the furniture list and observe LGM's ability to handle inconsistencies

## Open Questions the Paper Calls Out

- How does the inclusion of numerous small decorative objects (e.g., teacups, books, vases) in FurniScene affect the performance of existing indoor scene generation methods compared to methods trained on datasets with fewer object categories?

- What is the optimal number of furniture items per room type for achieving high realism in generated scenes, and how does this optimal number vary across different room types?

- How does the Two-Stage Diffusion Scene Model (TSDSM) handle the trade-off between diversity and realism in generated scenes, and what are the limitations of this approach?

## Limitations

- The paper's central claim about TSDSM's two-stage design reducing optimization complexity lacks ablation studies comparing against single-stage alternatives on the same dataset
- FurniScene dataset construction relies heavily on automated pipelines without quantitative validation of annotation quality or geometric accuracy
- The paper doesn't specify the exact size and diversity metrics of the furniture database used for retrieval, nor how FRS handles cases where generated lists don't match available models

## Confidence

**High confidence**: The architectural description of TSDSM is clearly specified with explicit stage separation and diffusion model usage. The quantitative evaluation methodology (FID, KID, SCA, CKL metrics) is standard and reproducible.

**Medium confidence**: The claim that TSDSM outperforms baselines is supported by reported metrics, but without access to baseline implementations or detailed experimental protocols, we cannot verify whether the comparison is fair or whether differences stem from the two-stage design specifically.

**Low confidence**: The assertion that FurniScene contains "intricate furnishings" and superior realism compared to existing datasets lacks objective benchmarks or user studies demonstrating perceptual quality improvements beyond the quantitative metrics reported.

## Next Checks

1. **Ablation study**: Train a single-stage diffusion model on FurniScene that generates all furniture attributes simultaneously, then compare its performance and training dynamics against TSDSM to isolate the benefits of the two-stage approach.

2. **Retrieval robustness analysis**: Systematically generate furniture lists with rare or edge-case combinations (e.g., very large furniture, unusual category combinations) and measure the FRS success rate and quality of fallback handling when exact matches aren't available.

3. **Human perceptual validation**: Conduct a randomized user study where participants compare TSDSM-generated scenes against baseline methods without knowing which model produced which scene, collecting both preference scores and qualitative feedback on realism and plausibility.