---
ver: rpa2
title: 'Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas'
arxiv_id: '2402.17270'
source_url: https://arxiv.org/abs/2402.17270
tags:
- cooperation
- agents
- social
- human
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey examines cooperation in social dilemmas across three
  domains: multi-agent cooperation, human-agent cooperation, and leveraging AI agents
  to enhance human-human cooperation. The authors identify key mechanisms that support
  cooperation, including intrinsic motivations (inequity aversion, altruism, social
  value orientation, social influence, reputation) and external motivations (peer
  rewarding, agreements).'
---

# Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas

## Quick Facts
- arXiv ID: 2402.17270
- Source URL: https://arxiv.org/abs/2402.17270
- Authors: Chunjiang Mu; Hao Guo; Yang Chen; Chen Shen; Shuyue Hu; Zhen Wang
- Reference count: 40
- Primary result: Comprehensive survey examining cooperation mechanisms across multi-agent systems, human-agent interaction, and AI-enhanced human-human cooperation in social dilemmas

## Executive Summary
This survey provides a systematic examination of cooperation mechanisms across three domains: multi-agent cooperation, human-agent cooperation, and leveraging AI to enhance human-human cooperation. The authors identify and categorize key mechanisms supporting cooperation, including intrinsic motivations like inequity aversion and altruism, as well as external motivations such as peer rewarding and agreements. The survey also explores adaptive policy adoption and opponent shaping strategies for diverse opponent scenarios, while highlighting the role of large language models as emerging tools for facilitating cooperation.

## Method Summary
The survey employs a comprehensive literature review methodology, systematically examining research across multiple domains including game theory, multi-agent systems, human-computer interaction, and social psychology. The authors synthesize findings from 40 key references to identify common patterns, mechanisms, and research gaps in cooperation within social dilemmas. The analysis spans theoretical frameworks, algorithmic approaches, and empirical studies, providing a multi-faceted perspective on how cooperation can be fostered and maintained across different agent types and contexts.

## Key Results
- Identified key cooperation mechanisms including intrinsic motivations (inequity aversion, altruism, social value orientation, social influence, reputation) and external motivations (peer rewarding, agreements)
- Explored adaptive policy adoption and opponent shaping as strategies for multi-agent cooperation against diverse opponents
- Discussed human biases toward AI agents and methods to mitigate these biases in human-agent cooperation
- Reviewed AI applications for enhancing human-human cooperation through network engineering, evolutionary dynamics influence, and decision delegation
- Highlighted future research directions including LLM integration, theoretical framework development, and real-world SSD applications

## Why This Works (Mechanism)

## Foundational Learning
- Social dilemmas framework: Provides theoretical foundation for understanding conflict between individual and collective interests; needed to analyze cooperation challenges across different agent types
- Intrinsic vs. external motivations: Categorizes different drivers of cooperative behavior; needed to systematically identify and compare cooperation mechanisms
- Opponent modeling: Enables prediction of other agents' behaviors; needed for adaptive policy adoption and effective cooperation strategies
- Reputation systems: Facilitates trust building and accountability; needed for sustaining long-term cooperation in repeated interactions
- Network engineering: Influences interaction patterns and information flow; needed for designing environments that promote cooperation

## Architecture Onboarding
Component map: Theoretical frameworks -> Cooperation mechanisms -> Agent types (multi-agent, human-agent, human-human) -> Applications and future directions

Critical path: Understanding social dilemmas → Identifying cooperation mechanisms → Matching mechanisms to agent types → Developing applications → Addressing research gaps

Design tradeoffs: Comprehensive coverage vs. depth of analysis; theoretical rigor vs. practical applicability; human-centered vs. AI-centric approaches

Failure signatures: Oversimplification of complex human motivations; assumptions of rational agents with perfect information; limited empirical validation of proposed frameworks

First experiments:
1. Empirical validation of intrinsic vs. external motivation effectiveness in controlled social dilemma experiments
2. Comparative analysis of different opponent modeling approaches in multi-agent cooperation scenarios
3. Evaluation of LLM-based facilitation tools for human-human cooperation in social dilemma contexts

## Open Questions the Paper Calls Out
The survey highlights several open questions for future research, including how to effectively incorporate large language models into cooperation frameworks, how to establish more comprehensive theoretical foundations for human-agent cooperation, and how to bridge the gap between human-agent cooperation research and social science theories of human cooperation. The authors also call for more real-world applications of social dilemmas and revisiting existing theories of human cooperation in light of AI advancements.

## Limitations
- Human-agent cooperation coverage is less developed compared to multi-agent systems
- Many claims rely on theoretical arguments rather than systematic experimental validation
- LLM applications for cooperation are speculative given limited published research
- Categorization of mechanisms may oversimplify complex motivational interplay
- Assumptions of rational agents with perfect information may not hold in practical applications

## Confidence
- Multi-agent cooperation mechanisms: High
- Human-agent cooperation frameworks: Medium
- AI for enhancing human-human cooperation: Medium
- Theoretical foundations and future directions: Medium

## Next Checks
1. Conduct systematic experiments testing the effectiveness of proposed human-agent cooperation frameworks across different social dilemma games and participant populations
2. Validate the proposed categorization of cooperation mechanisms through empirical studies measuring the relative impact of intrinsic versus external motivations in controlled settings
3. Develop and test benchmark scenarios for evaluating large language models' ability to facilitate cooperation in social dilemmas, comparing their performance against established multi-agent algorithms