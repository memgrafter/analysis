---
ver: rpa2
title: 'Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved
  ROCKET Algorithm for Multivariate Time Series Analysis'
arxiv_id: '2408.02760'
source_url: https://arxiv.org/abs/2408.02760
tags:
- classification
- ensemble
- channel
- channels
- detach-rocket
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Detach-Rocket Ensemble, a ROCKET-based algorithm
  designed to address scalability and interpretability challenges in multivariate
  time series classification (MTSC) for neuroscience data like EEG and MEG. The model
  leverages pruning to estimate channel importance and uses ensembles for improved
  accuracy and label probability.
---

# Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis

## Quick Facts
- arXiv ID: 2408.02760
- Source URL: https://arxiv.org/abs/2408.02760
- Authors: Adrià Solana; Erik Fransén; Gonzalo Uribarri
- Reference count: 31
- Achieves 79.86% accuracy on EEG Alzheimer's disease classification, outperforming raw EEG classifiers and approaching engineered feature performance

## Executive Summary
This paper introduces Detach-Rocket Ensemble, a ROCKET-based algorithm designed to address scalability and interpretability challenges in multivariate time series classification (MTSC) for neuroscience data like EEG and MEG. The model leverages pruning to provide integrated channel importance estimation and uses ensembles to improve accuracy and label probability. The authors demonstrate that Detach-Rocket Ensemble correctly identifies relevant channels in synthetic datasets and achieves competitive classification accuracy on real-world MEG and EEG datasets without requiring feature engineering.

## Method Summary
Detach-Rocket Ensemble is an ensemble of Detach-MiniRocket models that uses Sequential Feature Detachment (SFD) pruning to select relevant kernels and estimate channel importance. The algorithm generates MiniRocket kernels with deterministic parameters, applies SFD to iteratively remove the least important features based on ridge regression coefficients, and aggregates predictions across ensemble members. Channel relevance is calculated by distributing kernel weights proportionally to participating channels. The ensemble mitigates model variability and provides more reliable channel relevance estimates than single models.

## Key Results
- Achieves 64.3% accuracy on MEG face detection task, outperforming previous ROCKET-based models
- Achieves 79.86% accuracy on EEG Alzheimer's disease classification task, significantly outperforming other raw EEG classifiers
- Correctly identifies relevant channels in synthetic dataset validation experiments
- Provides interpretable channel relevance estimates without requiring manual feature engineering

## Why This Works (Mechanism)

### Mechanism 1
Pruning via Sequential Feature Detachment (SFD) effectively reduces feature dimensionality while maintaining or improving classification accuracy. SFD iteratively fits a ridge classifier, removes the least important features (those with smallest coefficients), and refits. This process eliminates irrelevant random convolutional kernels generated by MiniRocket, which were originally introduced to compensate for the lack of a learned kernel. The magnitude of ridge regression coefficients is used as a reliable indicator of feature importance for classification.

### Mechanism 2
Ensemble averaging of multiple Detach-MiniRocket models reduces variance and improves both classification accuracy and channel relevance estimation. Multiple independent Detach-MiniRocket models are trained with different random channel subsets for each kernel. By averaging predictions and channel relevance estimates across the ensemble, the model mitigates individual model variability and provides more robust results. The variability between Detach-MiniRocket models is primarily due to different random channel subsets, and this variability is unbiased around the true solution.

### Mechanism 3
The weighted channel importance calculation (kernel weight divided by number of channels in kernel) provides a more accurate estimate of individual channel relevance than simple counting. For each selected kernel, each participating channel receives importance proportional to the kernel's ridge regression coefficient divided by the number of channels in that kernel. This accounts for the fact that kernels mixing many channels dilute individual channel contributions. The ridge regression coefficient for a kernel is used as a proxy for its overall importance, and dividing by channel count appropriately distributes this importance.

## Foundational Learning

- **Ridge regression and coefficient interpretation**: Used to determine feature (kernel) importance during pruning and channel relevance estimation. Quick check: How does ridge regression handle multicollinearity, and why is this beneficial for time series feature selection?
- **Ensemble methods and variance reduction**: The Detach-Rocket Ensemble uses multiple models to reduce variance in both predictions and channel relevance estimates. Quick check: What is the relationship between ensemble size and variance reduction, assuming independent errors?
- **Convolutional neural networks and random kernels**: ROCKET variants use random convolutional kernels instead of learned ones, which is the foundation for understanding why pruning is effective. Quick check: Why might random convolutional kernels still capture useful patterns in time series data?

## Architecture Onboarding

- **Component map**: Input preprocessing (normalization) -> MiniRocket kernel generation (deterministic parameters, random biases and channel selection) -> PPV feature extraction (percentage of positive values) -> Sequential Feature Detachment (iterative pruning based on ridge coefficients) -> Ensemble aggregation (weighted voting for predictions, median for channel relevance) -> Channel relevance estimation (kernel weighting by coefficient/channel count)
- **Critical path**: 1. Generate MiniRocket kernels and extract PPV features 2. Apply SFD pruning to select most relevant kernels 3. Train ensemble of Detach-MiniRocket models 4. Aggregate predictions and compute channel relevance
- **Design tradeoffs**: More kernels initially → better coverage but slower training/pruning; More ensemble members → better variance reduction but increased computational cost; More aggressive pruning → smaller model but risk of losing useful features; Channel relevance estimation accuracy vs. computational overhead
- **Failure signatures**: High variance in channel relevance estimates across ensemble members suggests insufficient exploration of kernel space; Poor classification accuracy despite pruning indicates relevant features are being removed; Slow inference despite pruning suggests kernel selection isn't effective
- **First 3 experiments**: 1. Run Detach-MiniRocket with varying numbers of initial kernels (1000, 5000, 10000) on a small dataset to observe pruning effectiveness and accuracy 2. Create a 2-model ensemble vs. single model comparison on synthetic data with known channel importance to verify ensemble benefits 3. Test channel relevance estimation on the synthetic dataset with theta=45° to confirm equal importance is detected for channels 1 and 2

## Open Questions the Paper Calls Out

### Open Question 1
How does Detach-Rocket Ensemble's performance scale with increasing numbers of channels, and what is the upper limit of channels it can effectively handle before performance degrades? The paper discusses the challenge of scalability with number of channels in ROCKET-based models, noting that the probability of meaningful multichannel information decays rapidly as the number of interacting channels increases. Testing Detach-Rocket Ensemble on synthetic datasets with varying numbers of channels (e.g., 100, 500, 1000) and reporting classification accuracy and computational time would provide insights into scalability limits.

### Open Question 2
Can the iterative application of Detach-Rocket Ensemble for channel pruning significantly improve classification accuracy on real-world datasets, and how does this compare to the performance of models using engineered features? The authors mention that they plan to explore the iterative application of Detach-Rocket Ensemble for channel pruning in future work, which could improve model performance by providing better coverage of relevant channels. Conducting experiments where Detach-Rocket Ensemble is applied iteratively to prune channels and retrain the model, comparing the final accuracy to both the original model and models using engineered features, would provide a direct answer.

### Open Question 3
How does the choice of base classifier (Detach-MiniRocket vs. Detach-MultiRocket) affect the performance of Detach-Rocket Ensemble on high-dimensional multivariate time series datasets? The authors state that they chose Detach-MiniRocket as the base classifier for their ensemble but note that the same methodology can be applied using Detach-MultiRocket, which may yield even better results for some datasets. Implementing and evaluating Detach-Rocket Ensemble with both Detach-MiniRocket and Detach-MultiRocket as base classifiers on the same high-dimensional datasets (e.g., MEG and EEG datasets) and comparing their classification accuracy, training time, and channel relevance estimation would clarify the effect of this choice.

## Limitations

- Computational constraints prevented implementing the full proposed ensemble with all optimizations, requiring use of smaller kernel subsets
- Synthetic dataset validation may not fully capture the complexity of real EEG/MEG data, particularly regarding nonlinear channel interactions
- Assumption that ridge regression coefficients reliably indicate feature importance may not hold for all types of time series patterns

## Confidence

- **High**: Classification accuracy improvements over baseline ROCKET models (64.3% MEG, 79.86% EEG)
- **Medium**: Channel relevance estimation on synthetic data showing correct identification of relevant channels
- **Low**: Generalization of channel relevance findings to complex real-world EEG/MEG datasets

## Next Checks

1. **Scalability validation**: Test the full Detach-Rocket Ensemble implementation (10,000 kernels, all 306 MEG channels, N=25) on a smaller benchmark dataset to verify that computational limitations are the only barrier to achieving reported performance.

2. **Channel interaction validation**: Apply the model to a dataset where channel interactions are known to be nonlinear (e.g., sensorimotor rhythms in EEG) and compare channel relevance estimates against ground truth spatial patterns.

3. **Cross-dataset generalization**: Train the model on one EEG/MEG dataset and test on another with similar tasks but different acquisition parameters to assess whether the learned channel relevances transfer across datasets.