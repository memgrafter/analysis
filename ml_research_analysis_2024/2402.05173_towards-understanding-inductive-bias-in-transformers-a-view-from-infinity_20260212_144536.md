---
ver: rpa2
title: 'Towards Understanding Inductive Bias in Transformers: A View From Infinity'
arxiv_id: '2402.05173'
source_url: https://arxiv.org/abs/2402.05173
tags:
- bias
- arxiv
- group
- learning
- symmetry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies the inductive bias of transformer networks in
  the infinitely wide limit, where they can be analyzed using Gaussian processes.
  By leveraging the representation theory of the symmetric group, the authors show
  that transformers are biased towards learning more permutation-symmetric functions.
---

# Towards Understanding Inductive Bias in Transformers: A View From Infinity

## Quick Facts
- arXiv ID: 2402.05173
- Source URL: https://arxiv.org/abs/2402.05173
- Authors: Itay Lavie; Guy Gur-Ari; Zohar Ringel
- Reference count: 40
- Primary result: Transformers in the infinitely wide limit are biased towards learning more permutation-symmetric functions, with learnability determined by the kernel spectrum.

## Executive Summary
This paper analyzes the inductive bias of transformer networks by studying them in the infinitely wide limit, where they can be described as Gaussian processes. The authors leverage representation theory of the symmetric group to show that transformers are inherently biased towards learning more permutation-symmetric functions in sequence space. By deriving analytical predictions for learning curves and network outputs, they establish a scaling law relating the number of samples needed to learn a target function to its degree of permutation symmetry. Experiments on WikiText-2 suggest that natural language data exhibits approximate permutation symmetry at leading order, validating the relevance of the theoretical framework for real-world applications.

## Method Summary
The authors analyze transformers in the infinite width limit using Gaussian process theory. They develop a simplified transformer architecture with linear attention and linear MLP, trained with MSE loss and weight decay using uncorrected Langevin dynamics. The key analytical tool is the kernel operator, whose eigenvalues determine function learnability. By exploiting permutation symmetry through representation theory of the symmetric group, they decompose the function space into irreducible representations and derive scaling laws for sample complexity. The framework is validated through experiments on synthetic datasets (mixture of HMMs) and natural language data (WikiText-2).

## Key Results
- Transformers in the infinite width limit are equivalent to Gaussian processes with a specific kernel encoding permutation symmetry
- The learnability of functions is determined by the kernel spectrum, with more symmetric functions having higher eigenvalues and being easier to learn
- Natural language data exhibits approximate permutation symmetry at leading order, making the theoretical framework relevant for practical applications
- A scaling law relates the number of samples needed to learn a target function to its degree of permutation symmetry

## Why This Works (Mechanism)

### Mechanism 1
- Claim: In the infinitely wide limit, transformer networks become equivalent to Gaussian processes with a specific kernel that encodes the model's inductive bias.
- Mechanism: As the network width goes to infinity, the distribution of network outputs converges to a Gaussian process. The kernel of this process captures the model's prior beliefs about function space, determining which functions are more likely to be learned.
- Core assumption: The network initialization follows a specific distribution (LeCun initialization) and the training protocol (uncorrected Langevin dynamics) preserves the Gaussian process structure.
- Evidence anchors:
  - [abstract]: "We study inductive bias in Transformers in the infinitely over-parameterized Gaussian process limit and argue transformers tend to be biased towards more permutation symmetric functions in sequence space."
  - [section 2.1.1]: "As shown in Hron et al. (2020) when dk, Nheads → ∞ the distribution of NN outputs induced by the initialization distribution converges to a GP f(x) ∼ GP (0, k) with k being the kernel of the NN."
  - [corpus]: Weak - no direct evidence about Gaussian process equivalence in corpus.
- Break condition: If the network width is finite, or if the initialization or training deviates significantly from the assumed distributions.

### Mechanism 2
- Claim: The inductive bias of transformers can be quantified by the spectrum of the kernel operator, with more symmetric functions being more learnable.
- Mechanism: The kernel operator's eigenfunctions correspond to different function components. Eigenvalues determine learnability - higher eigenvalues mean functions are easier to learn. Permutation symmetry causes degeneracy in the spectrum, creating blocks of equally learnable functions.
- Core assumption: The dataset possesses some permutation symmetry, and the kernel respects this symmetry.
- Evidence anchors:
  - [abstract]: "We show that the representation theory of the symmetric group can be used to give quantitative analytical predictions when the dataset is symmetric to permutations between tokens."
  - [section 2.2]: "Symmetries can greatly simplify the eigenvalue problems like equation 9 above. We say an operator like ˆK is symmetric under the action of a group G if ∀g ∈ G, k (⃗ xg, ⃗ yg) = k(⃗ x, ⃗ y) & pdata(⃗ xg) = pdata(⃗ x)"
  - [corpus]: Weak - no direct evidence about spectrum-based learnability in corpus.
- Break condition: If the dataset lacks permutation symmetry, or if the kernel doesn't respect the symmetry.

### Mechanism 3
- Claim: Natural language data exhibits approximate permutation symmetry at leading order, making the theoretical framework relevant for real-world applications.
- Mechanism: The first-order correlations in natural language data are similar across different positions in the sequence, indicating approximate symmetry. This allows the theoretical predictions to be approximately valid.
- Core assumption: The approximation of permutation symmetry holds well enough for practical purposes.
- Evidence anchors:
  - [abstract]: "Finally, we argue WikiText dataset, does indeed possess a degree of permutation symmetry."
  - [section 3.2]: "We analyze WikiText-2 and show that at leading order correlations the dataset does indeed appear to be permutation symmetric to a good approximation."
  - [corpus]: Moderate - related papers discuss permutation invariance and symmetry in transformers.
- Break condition: If higher-order correlations break the symmetry significantly, or if the approximation fails for specific tasks.

## Foundational Learning

- Concept: Gaussian Processes and Neural Network Gaussian Process Correspondence
  - Why needed here: The entire theoretical framework relies on the equivalence between infinitely wide neural networks and Gaussian processes to make analytical predictions.
  - Quick check question: What is the relationship between the kernel of a Gaussian process and the neural network architecture?

- Concept: Representation Theory of the Symmetric Group
  - Why needed here: The theory provides tools to decompose the function space into irreducible representations, which correspond to different levels of symmetry and learnability.
  - Quick check question: How do irreducible representations of the symmetric group relate to the eigenvalues of the kernel operator?

- Concept: Eigenvalue Problems and Spectral Bias
  - Why needed here: The spectrum of the kernel operator determines which functions are learnable and how many samples are needed, providing a quantitative measure of inductive bias.
  - Quick check question: How does the eigenvalue spectrum relate to the number of samples needed to learn a function?

## Architecture Onboarding

- Component map: Embedding layer with positional encoding -> Multi-head self-attention layer (MHA) -> MLP with one hidden layer -> Final linear readout layer
- Critical path:
  1. Calculate the kernel matrix for the network
  2. Analyze the symmetry properties of the kernel
  3. Decompose the kernel operator into irreducible representations
  4. Calculate the spectrum and determine learnability
  5. Predict performance on training and test data
- Design tradeoffs:
  - Linear vs. non-linear activations: Linear activations allow for analytical solutions but may not capture all aspects of real networks
  - Exact vs. approximate symmetry: Exact symmetry simplifies analysis but may not reflect real data
  - Finite vs. infinite width: Infinite width allows for Gaussian process analysis but may not capture finite-size effects
- Failure signatures:
  - Poor performance on data with broken symmetry
  - Discrepancy between theoretical predictions and experimental results for finite networks
  - Unexpected scaling laws that don't match theoretical predictions
- First 3 experiments:
  1. Verify the Gaussian process correspondence by comparing network outputs to GP predictions for increasing width
  2. Test the symmetry properties by analyzing the kernel spectrum for datasets with known symmetries
  3. Validate the learnability predictions by training networks on functions with different levels of symmetry and measuring sample complexity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the permutation symmetry of natural language data extend beyond first-order correlations? Specifically, what is the structure of higher-order correlations (e.g., third-order) in datasets like WikiText-2, and do they exhibit approximate permutation symmetry?
- Basis in paper: [explicit] The paper analyzes first-order correlations in WikiText-2 and finds evidence of approximate permutation symmetry, but explicitly suggests examining second-order correlations as a next step, as they could contain mechanisms for in-context learning.
- Why unresolved: The analysis presented is limited to first-order correlations, and the authors explicitly leave the examination of higher-order correlations for future work. The potential for in-context learning mechanisms to appear at higher orders is suggested but not investigated.
- What evidence would resolve it: Analyzing third-order (or higher) correlation matrices in natural language datasets and comparing their spectral properties and symmetries to those of first-order correlations. Demonstrating whether higher-order correlations also exhibit approximate permutation symmetry or follow a different symmetry structure would clarify the extent and nature of symmetry in natural language data.

### Open Question 2
- Question: How do finite-size effects and non-zero learning rates impact the inductive bias of transformers, and can the theoretical predictions from the infinite-width limit be extended to capture these effects?
- Basis in paper: [inferred] The paper acknowledges that while the Gaussian process (GP) limit provides a good starting point, it does not address finite learning rates and finite-size corrections. The authors cite recent works that have studied such corrections and suggest studying them as future work.
- Why unresolved: The theoretical framework presented relies on the infinite-width GP limit, which may not fully capture the behavior of finite neural networks trained with finite learning rates. The paper explicitly states that studying finite-size corrections is left for future work.
- What evidence would resolve it: Developing theoretical models that incorporate finite learning rates and finite-size effects into the analysis of transformer inductive bias. Comparing the predictions of these models with experimental results on finite networks trained with various learning rates would validate their accuracy and provide a more complete understanding of inductive bias.

### Open Question 3
- Question: Can the representation theory tools developed for analyzing permutation symmetry in transformers be extended to other types of symmetries or structured data, such as graphs or sets, and what insights would this provide about the inductive bias of models designed for such data?
- Basis in paper: [inferred] The paper focuses on permutation symmetry in transformers and uses representation theory of the symmetric group. While the authors mention that transformers for sets or in-context learning settings have exact symmetry, they do not explore the extension of their methods to other symmetries or data structures.
- Why unresolved: The paper's analysis is specific to permutation symmetry in sequence data. The potential for applying similar representation theory techniques to other types of symmetries or structured data is not explored, leaving open the question of how broadly applicable these methods are.
- What evidence would resolve it: Applying the representation theory framework to analyze the inductive bias of models designed for other structured data types, such as graphs or sets. Investigating whether similar symmetry-based simplifications and bounds on learnability can be derived for these models would demonstrate the broader applicability of the approach and provide insights into the inductive biases of different model architectures.

## Limitations

- Finite-width effects: The theoretical framework relies on the infinitely wide limit, but practical transformers are finite, potentially introducing non-trivial corrections
- Symmetry approximation: The claim that natural language exhibits approximate permutation symmetry is based on first-order correlations in WikiText-2, which may not generalize to all language tasks or datasets
- Linear activation assumption: The analysis uses linear activations to enable analytical solutions, and the inductive bias could differ substantially with non-linear activations

## Confidence

- High Confidence: The Gaussian process correspondence in the infinite width limit and the eigenvalue-based learnability analysis
- Medium Confidence: The claim about natural language's approximate permutation symmetry and the extrapolation from theory to practical finite networks
- Low Confidence: The generalization of results from linear to non-linear activations, and the quantitative predictions for specific learning curves in practical settings

## Next Checks

1. **Finite-width scaling study:** Systematically vary transformer width and head count to map out the transition from theoretical predictions to empirical behavior. Quantify deviations from the infinite-width limit.

2. **Cross-dataset symmetry analysis:** Apply the permutation symmetry analysis to diverse NLP datasets (e.g., different domains, languages, and task types) to assess the generality of the approximate symmetry claim.

3. **Non-linear activation comparison:** Implement the full theoretical framework with ReLU (or other non-linear) activations using numerical methods, and compare the resulting learnability spectra and predictions to the linear case.