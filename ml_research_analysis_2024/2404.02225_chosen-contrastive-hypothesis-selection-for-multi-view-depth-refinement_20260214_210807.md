---
ver: rpa2
title: 'CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement'
arxiv_id: '2404.02225'
source_url: https://arxiv.org/abs/2404.02225
tags:
- depth
- cost
- multi-view
- hypothesis
- stereo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CHOSEN, a contrastive learning-based framework
  for multi-view depth refinement that addresses the limitations of traditional depth
  averaging methods in multi-view stereo (MVS) pipelines. The key innovation is transforming
  depth hypotheses into a "pseudo disparity" space that accounts for different camera
  setups and scales, enabling robust contrastive learning across diverse capture systems.
---

# CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement

## Quick Facts
- arXiv ID: 2404.02225
- Source URL: https://arxiv.org/abs/2404.02225
- Reference count: 18
- 70.16% of pixels with <1mm depth error on DTU dataset

## Executive Summary
This paper introduces CHOSEN, a contrastive learning-based framework for multi-view depth refinement that addresses limitations of traditional depth averaging methods in multi-view stereo (MVS) pipelines. The key innovation is transforming depth hypotheses into a "pseudo disparity" space that accounts for different camera setups and scales, enabling robust contrastive learning across diverse capture systems. CHOSEN significantly outperforms state-of-the-art deep learning MVS methods on the DTU dataset, achieving 70.16% of pixels with <1mm depth error and 45.53% with <5° normal error, compared to 61.92% and 18.96% respectively for the previous best method (MVSFormer).

## Method Summary
CHOSEN operates by transforming depth hypotheses into a pseudo disparity space that enables contrastive learning across different camera setups and scales. The framework iteratively refines depth estimates by resampling hypotheses and selecting the best ones using a carefully designed feature representation that combines matching costs, geometric consistency, and learned context features. The method operates independently on each hypothesis, making it robust to noisy initial estimates, and can be integrated into simple baseline MVS pipelines to achieve state-of-the-art performance without requiring hyperparameter tuning.

## Key Results
- 70.16% of pixels with <1mm depth error on DTU dataset (vs 61.92% for MVSFormer)
- 45.53% of pixels with <5° normal error on DTU dataset (vs 18.96% for MVSFormer)
- Outperforms state-of-the-art deep learning MVS methods when integrated into simple baseline pipeline

## Why This Works (Mechanism)
CHOSEN's effectiveness stems from its ability to leverage contrastive learning in a carefully designed feature space that combines geometric consistency with learned contextual information. By transforming depth hypotheses into pseudo disparity space, the method can effectively compare and select between different depth estimates regardless of the underlying camera geometry. The iterative resampling strategy allows the framework to progressively improve depth estimates by exploring the hypothesis space more thoroughly, while the feature representation ensures that selection is based on both local matching quality and global geometric consistency.

## Foundational Learning

**Pseudo Disparity Space** - A transformed representation that normalizes depth hypotheses across different camera setups and scales. Needed to enable contrastive learning across diverse capture systems. Quick check: Verify transformation preserves depth relationships while enabling cross-camera comparison.

**Multi-View Stereo Matching** - The process of estimating depth from multiple calibrated camera views. Needed as the underlying problem CHOSEN addresses. Quick check: Confirm understanding of matching cost computation and camera calibration fundamentals.

**Contrastive Learning Framework** - A machine learning approach that learns representations by contrasting similar and dissimilar examples. Needed to select between depth hypotheses based on learned features. Quick check: Review contrastive loss formulations and their application to depth estimation.

## Architecture Onboarding

**Component Map**: Depth Hypotheses -> Pseudo Disparity Transform -> Feature Extraction -> Contrastive Selection -> Resampled Hypotheses -> Refined Depth

**Critical Path**: The core pipeline processes each depth hypothesis independently through feature extraction and selection, with iterative resampling enabling progressive refinement.

**Design Tradeoffs**: 
- Independence of hypothesis processing enables parallelization but requires careful feature design to capture inter-hypothesis relationships
- Pseudo disparity transformation adds computational overhead but enables cross-camera learning
- Iterative resampling improves refinement quality but increases runtime

**Failure Signatures**: Poor initial hypothesis quality, insufficient hypothesis diversity, or inadequate feature representation can lead to suboptimal refinement results.

**Three First Experiments**:
1. Test contrastive selection with ground truth features to establish upper performance bounds
2. Evaluate pseudo disparity transformation with synthetic camera setups
3. Assess feature representation effectiveness with varying levels of noise in initial hypotheses

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends on quality of initial depth hypotheses, as refinement can only improve within provided range
- Limited evaluation on outdoor scenes and datasets with significant textureless regions
- Effectiveness relies on sufficient diversity in hypothesis pool, potentially limiting performance with few initial hypotheses

## Confidence

**High Confidence**: Core claims about CHOSEN's effectiveness on DTU dataset benchmarks, particularly quantitative improvements over MVSFormer and other state-of-the-art methods.

**Medium Confidence**: Generalization claims to new datasets and camera setups, as evaluation on Tanks and Temples is less comprehensive than DTU experiments.

**Low Confidence**: Claims about not requiring hyperparameter tuning across diverse datasets and camera configurations, which needs broader validation.

## Next Checks

1. Evaluate CHOSEN on outdoor datasets like ETH3D or Tanks and Temples with detailed per-scene analysis to assess performance across different environments and lighting conditions.

2. Test the framework with varying numbers of initial hypotheses (fewer than 16) to determine minimum hypothesis diversity required for effective refinement.

3. Conduct ablation studies specifically examining the impact of iterative resampling strategy versus alternative refinement approaches like depth map fusion or filtering-based methods.