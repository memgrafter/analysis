---
ver: rpa2
title: Superposition through Active Learning lens
arxiv_id: '2412.16168'
source_url: https://arxiv.org/abs/2412.16168
tags:
- learning
- active
- superposition
- more
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether active learning can reduce feature
  superposition in neural networks. The study compares a baseline ResNet-18 model
  trained on CIFAR-10 and Tiny ImageNet with an active learning model using uncertainty-based
  sampling.
---

# Superposition through Active Learning lens

## Quick Facts
- arXiv ID: 2412.16168
- Source URL: https://arxiv.org/abs/2412.16168
- Authors: Akanksha Devkar
- Reference count: 11
- Key outcome: Active learning model exhibited more superposition than baseline, with higher feature overlap and worse clustering quality

## Executive Summary
This paper investigates whether active learning can reduce feature superposition in neural networks. The study compares a baseline ResNet-18 model trained on CIFAR-10 and Tiny ImageNet with an active learning model using uncertainty-based sampling. The active learning model was trained on least confident samples across multiple loops. Results showed that contrary to expectations, the active learning model exhibited more superposition than the baseline, with higher feature overlap, worse clustering quality, and less distinct class separation. These findings suggest that non-informative sample selection and potential overfitting to uncertain samples may have hindered the active learning model's ability to generalize better, indicating more sophisticated approaches might be needed to decode and potentially reduce superposition.

## Method Summary
The study uses ResNet-18 CNN models trained on CIFAR-10 (50,000 training images, 10 classes) and Tiny ImageNet (100,000 training images, 200 classes). A baseline model is trained for 20 epochs with cross-entropy loss. The active learning model uses least confidence-based uncertainty sampling across 10 loops, selecting 5,000 samples per loop for CIFAR-10 and 10,000 samples per loop for Tiny ImageNet. Results are compared using t-SNE visualizations, cosine similarity histograms, silhouette scores, and Davies-Bouldin indexes.

## Key Results
- Active learning model shows higher mean cosine similarity (0.927) compared to baseline (0.885), indicating more similar features
- Active learning model has lower silhouette scores, indicating worse clustering quality
- t-SNE visualizations reveal more overlap between clusters in active learning model, with cat class particularly scattered

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Active learning with uncertainty-based sampling increases superposition by concentrating model capacity on ambiguous samples rather than maximizing class separation.
- Mechanism: When training on least-confident samples, the model adapts to noisy or overlapping decision boundaries, which encourages neurons to represent multiple related features simultaneously (polysemanticity).
- Core assumption: Uncertain samples correspond to regions of feature space where class boundaries are unclear, and repeated training on these samples reinforces mixed representations.
- Evidence anchors:
  - [abstract] "contrary to our expectations, the active learning model did not significantly outperform the baseline...suggests that non-informative sample selection and potential overfitting to uncertain samples may have hindered..."
  - [section] "the active learning model shows more overlap between clusters...the cat class cluster is the weakest and seems to be scattered across other classes."
  - [corpus] Weak - no direct corpus neighbors mention superposition with active learning specifically.
- Break condition: If uncertain samples were instead used for targeted clarification (e.g., query-by-committee) rather than repeated training, superposition might decrease.

### Mechanism 2
- Claim: Non-informative sample selection biases the learned feature space toward uniform distributions, increasing mean cosine similarity between neurons.
- Mechanism: By repeatedly sampling uncertain or ambiguous examples, the model learns representations that cover a narrower, more uniform region of feature space, reducing diversity in feature directions.
- Core assumption: Uniform sampling of uncertain samples leads to more homogeneous activation patterns across neurons.
- Evidence anchors:
  - [section] "Active Learning model has a higher mean cosine similarity of 0.927 compared to the Baseline at 0.885 indicating features in Active Learning are more similar to each other."
  - [section] "Active Learning model has a lower silhouette score... indicating worse clustering quality."
  - [corpus] Weak - no corpus support for uniformity bias from uncertainty sampling.
- Break condition: If sample selection prioritized diversity or uncertainty diversity, feature space uniformity might decrease.

### Mechanism 3
- Claim: Limited training loops (10 loops, 5000 images per loop) cause underfitting to the broader class distribution, reinforcing superposition.
- Mechanism: The model focuses on refining uncertain regions while missing broader class-representative features, leading to less distinct, more overlapping class representations.
- Core assumption: Fewer training iterations with limited data per loop prevent the model from exploring the full feature space.
- Evidence anchors:
  - [section] "Active Learning model in certain cases seems to have more uniform distribution but that does not reflect in its ability to better distinguish between classes."
  - [section] "the cat class cluster is the weakest and seems to be scattered across other classes. Interestingly, the cat class was the most picked class during the active learning loops..."
  - [corpus] Weak - no corpus neighbors discuss loop count effects on superposition.
- Break condition: Increasing loop count or batch size might allow better exploration of feature space and reduce superposition.

## Foundational Learning

- Concept: **Superposition (polysemanticity)**
  - Why needed here: Core phenomenon being investigated; understanding how neurons can represent multiple features simultaneously is essential to interpret results.
  - Quick check question: What is the key difference between superposition and feature orthogonality in neural representations?
- Concept: **Active Learning (uncertainty-based sampling)**
  - Why needed here: The experimental intervention; knowing how uncertainty sampling selects samples is key to understanding why superposition increased.
  - Quick check question: How does least confidence sampling differ from entropy-based uncertainty sampling?
- Concept: **Feature clustering metrics (Silhouette score, Davies-Bouldin index)**
  - Why needed here: Primary evaluation tools; interpreting whether feature clusters are distinct or overlapping depends on understanding these metrics.
  - Quick check question: What does a negative silhouette score indicate about cluster separation?

## Architecture Onboarding

- Component map: ResNet-18 CNN -> final fully connected layer (10/200 classes) -> feature extraction -> t-SNE + cosine similarity + clustering metrics -> comparison
- Critical path: Data sampling -> model training (baseline vs active learning) -> feature extraction -> statistical/visual analysis -> interpretation
- Design tradeoffs: Small datasets (CIFAR-10/Tiny ImageNet) for computational feasibility vs. limited feature complexity; 10-loop active learning vs. full dataset training; uncertainty sampling vs. diversity-based sampling
- Failure signatures: Higher mean cosine similarity + lower silhouette score + overlapping t-SNE clusters = increased superposition; negative silhouette scores = severe cluster overlap
- First 3 experiments:
  1. Compare baseline vs active learning using entropy-based uncertainty sampling instead of least-confidence sampling.
  2. Increase number of active learning loops (e.g., 20 loops with smaller batches) to test overfitting hypothesis.
  3. Apply diversity-maximizing active learning (e.g., core-set selection) to see if superposition decreases compared to uncertainty-based sampling.

## Open Questions the Paper Calls Out
None

## Limitations
- Unknown implementation details of least confidence sampling and specific parameters for t-SNE visualization
- Limited training iterations with uncertainty sampling may have biased results toward increased superposition
- Results based on synthetic experiments without extensive real-world validation

## Confidence

- **High confidence**: The observation that the active learning model exhibited more superposition than the baseline, as evidenced by higher feature overlap, worse clustering quality, and less distinct class separation.
- **Medium confidence**: The hypothesis that non-informative sample selection and potential overfitting to uncertain samples contributed to the increased superposition, based on the observed results and the discussion of these factors.
- **Low confidence**: The claim that more sophisticated approaches might be needed to decode and potentially reduce superposition, as this is a broader suggestion without specific evidence or proposed solutions in the current study.

## Next Checks

1. Test different uncertainty sampling strategies (e.g., entropy-based vs. least confidence) to determine their impact on superposition.
2. Increase the number of active learning loops and vary batch sizes to investigate the effects of training duration and data exposure on superposition.
3. Apply diversity-maximizing active learning methods (e.g., core-set selection) and compare their performance with uncertainty-based sampling in reducing superposition.