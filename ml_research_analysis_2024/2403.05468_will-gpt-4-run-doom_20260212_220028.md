---
ver: rpa2
title: Will GPT-4 Run DOOM?
arxiv_id: '2403.05468'
source_url: https://arxiv.org/abs/2403.05468
tags:
- available
- https
- online
- game
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that GPT-4, without any training, can play
  the 1993 first-person shooter game Doom to a passable degree using only its reasoning
  and observational capabilities. The authors developed a system where one GPT-4 model
  (Vision) processes screenshots to describe the game state, while another (Agent)
  decides actions based on this description and game history.
---

# Will GPT-4 Run DOOM?

## Quick Facts
- arXiv ID: 2403.05468
- Source URL: https://arxiv.org/abs/2403.05468
- Authors: Adrian de Wynter
- Reference count: 40
- Primary result: GPT-4 can play Doom without training using Vision and Agent components

## Executive Summary
This paper demonstrates that GPT-4 can play the 1993 first-person shooter game Doom to a passable degree using only its reasoning and observational capabilities, without any training. The authors developed a system where one GPT-4 model (Vision) processes screenshots to describe the game state, while another (Agent) decides actions based on this description and game history. More complex prompting strategies, including walkthroughs and multi-agent planning, significantly improved performance. While GPT-4 could open doors, combat enemies, and perform basic pathing, it struggled with long-term planning, frequently overlooked enemies, had poor aim, and ignored environmental hazards.

## Method Summary
The study uses two GPT-4 models: Vision (with image processing capabilities) to interpret screenshots and generate structured game state descriptions, and Agent (text-only) to make gameplay decisions based on Vision's output and game history. The system tests different prompting strategies including naïve, walkthrough-enabled, plan-generating, and k-level reasoning approaches. Performance is measured using modified Passed Maps' Average Time (PMAT) and Death-Weighted PMAT (D-PMAT) metrics across different rooms in the E1M1 level of Doom.

## Key Results
- GPT-4 successfully navigates Doom levels, opening doors and defeating enemies without any training
- Complex prompting strategies (walkthroughs, multi-agent planning) significantly outperform naïve approaches
- The system achieves passable performance but struggles with long-term planning and environmental awareness
- Inference time of approximately one minute per frame makes real-time gameplay impossible

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can act as a game engine proxy by interpreting visual game states into structured text descriptions.
- Mechanism: The Vision component processes screenshots using GPT-4V to generate structured descriptions of the game environment, enemies, and UI. This textual representation replaces direct engine interaction, allowing the Agent to make decisions based on interpreted game states.
- Core assumption: GPT-4V can accurately parse game screenshots into consistent, structured outputs that capture relevant game state information.
- Evidence anchors: [abstract] "a textual description–generated by the model itself from screenshots–about the state of the game being observed", [section 3.1] "GPT-4V accepts images and textual input, and returns text"
- Break condition: If Vision cannot consistently generate structured outputs from screenshots, the entire proxy system fails as Agent would lack reliable game state information.

### Mechanism 2
- Claim: Chain-of-thought prompting with structured variables enables GPT-4 to make sequential game decisions.
- Mechanism: The Agent component uses chain-of-thought prompting where it must fill out variables describing the current state, history, and reasoning before selecting an action. This structured reasoning approach helps maintain consistency in decision-making.
- Core assumption: Chain-of-thought prompting improves reasoning consistency in dynamic game environments.
- Evidence anchors: [section 3.4] "All prompts are symbolic chain-of-thought, which was shown to provide good results in complex scenarios with multiple referents and long-term dependencies", [section 4.1] "GPT-4 generally output the correct actions in context, but the rationale behind these was poor and fraught with hallucinations"
- Break condition: If chain-of-thought prompting leads to excessive hallucinations or fails to maintain context across frames, Agent decisions become unreliable.

### Mechanism 3
- Claim: Multiple context sources (walkthroughs, plans, expert advice) enhance GPT-4's planning capabilities in game navigation.
- Mechanism: The system employs walkthrough prompts, plan-generating components, and k-level reasoning with expert calls. These multiple context sources provide hierarchical planning and richer environmental understanding for the Agent.
- Core assumption: GPT-4 can effectively integrate multiple context sources to improve long-term planning and decision-making.
- Evidence anchors: [section 3.4] "More complex prompting strategies involving multiple model calls provide better results", [section 4.1] "walkthrough-enabled prompts were noticeably better at traversing the map, and the addition of exemplars to improve traversal... was effective"
- Break condition: If integrating multiple context sources introduces too much noise or conflicts, Agent performance degrades rather than improves.

## Foundational Learning

- Concept: Chain-of-thought prompting
  - Why needed here: Helps GPT-4 maintain reasoning consistency across sequential game decisions by structuring the thought process
  - Quick check question: How does chain-of-thought prompting differ from standard prompting in maintaining context across multiple decision steps?

- Concept: Multimodal input processing
  - Why needed here: Vision component must convert visual game states into structured text for the text-only Agent component to process
  - Quick check question: What challenges arise when converting visual game information into textual descriptions for language model processing?

- Concept: Hierarchical planning
  - Why needed here: Game navigation requires both immediate tactical decisions and longer-term strategic planning that multiple context sources can provide
  - Quick check question: How does hierarchical planning differ from flat planning in complex environments like video games?

## Architecture Onboarding

- Component map: Screenshot → Vision → Agent → Action → Game State Update → Repeat
- Critical path: Vision processes screenshots into structured descriptions, Agent makes decisions based on Vision output and history, Manager coordinates execution
- Design tradeoffs:
  - Using text-based game state representation vs. direct engine integration
  - Chain-of-thought prompting for consistency vs. potential verbosity
  - Multiple context sources for richer planning vs. increased complexity and potential conflicts
  - Frame rate reduction for cost vs. potential loss of temporal precision
- Failure signatures:
  - Vision: Inconsistent or missing game state descriptions
  - Agent: Actions not in allowed set or nonsensical decisions
  - Planner/Experts: Hallucinations or contradictory advice
  - Overall: Frequent timeouts or inability to progress through game
- First 3 experiments:
  1. Test Vision component with sample screenshots to verify structured output generation
  2. Test Agent with pre-generated Vision outputs to verify action selection
  3. Test full pipeline with simple game scenarios to verify end-to-end functionality before attempting full gameplay

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would fine-tuning GPT-4 on Doom gameplay data impact its performance compared to in-context learning?
- Basis in paper: [inferred] The paper discusses that GPT-4 was not trained on Doom and that fine-tuning could improve planning performance, as mentioned in the limitations section.
- Why unresolved: The authors did not explore fine-tuning due to GPT-4's infeasibility for this approach and focused on in-context learning instead.
- What evidence would resolve it: Experiments comparing GPT-4's performance with and without fine-tuning on Doom gameplay data, measuring metrics like PMAT and D-PMAT.

### Open Question 2
- Question: Would using a smaller, more efficient language model like Llama 2 with fine-tuning capabilities outperform GPT-4 in playing Doom?
- Basis in paper: [explicit] The paper suggests that smaller models like Llama 2 could be better candidates for fine-tuning-based strategies due to their proximity to GPT-4's capabilities.
- Why unresolved: The authors did not test smaller models and focused on GPT-4's performance using in-context learning.
- What evidence would resolve it: Comparative studies between GPT-4 and Llama 2 (or similar models) fine-tuned on Doom data, evaluating their performance in terms of gameplay success and efficiency.

### Open Question 3
- Question: How would the addition of multimodal knowledge, such as visual or spatial reasoning, enhance GPT-4's ability to play Doom?
- Basis in paper: [explicit] The paper references related work showing that multimodal knowledge improves problem-solving and planning in spatial reasoning tasks.
- Why unresolved: The authors used only textual descriptions generated from screenshots and did not explore direct multimodal input integration.
- What evidence would resolve it: Experiments comparing GPT-4's performance with and without multimodal inputs (e.g., direct image processing alongside textual descriptions) in playing Doom.

## Limitations
- The system's inference time of approximately one minute per frame makes real-time gameplay impossible
- GPT-4 struggles with long-term planning, frequently overlooks enemies, and exhibits poor aiming accuracy
- The Vision-Agent architecture ignores environmental hazards like acid pools, limiting generalizability
- Reliance on Azure OpenAI API introduces reproducibility concerns and cost barriers

## Confidence
- High confidence: GPT-4 can interpret game screenshots and generate passable game state descriptions
- Medium confidence: Chain-of-thought prompting improves decision consistency
- Low confidence: The system can handle complex game scenarios requiring rapid decision-making

## Next Checks
1. Test Vision component's consistency across different lighting conditions and enemy types to verify robustness of game state interpretation beyond the E1M1 level
2. Implement a timing analysis to measure the exact overhead introduced by each prompting strategy and identify bottlenecks in the Vision-Agent pipeline
3. Create a controlled experiment comparing GPT-4's performance against a rule-based agent using the same visual inputs to isolate LLM-specific advantages and disadvantages