---
ver: rpa2
title: 'Arithmetic Reasoning with LLM: Prolog Generation & Permutation'
arxiv_id: '2405.17893'
source_url: https://arxiv.org/abs/2405.17893
tags:
- prolog
- reasoning
- language
- generation
- total
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores using Prolog code generation for arithmetic
  reasoning in large language models. Instead of generating natural language Chain-of-Thought
  reasoning, the method extracts predicates and symbolic formulas from math problems
  and uses an external Prolog interpreter for calculation.
---

# Arithmetic Reasoning with LLM: Prolog Generation & Permutation

## Quick Facts
- arXiv ID: 2405.17893
- Source URL: https://arxiv.org/abs/2405.17893
- Reference count: 7
- Primary result: Prolog generation outperforms Chain-of-Thought by 10.9% on GSM8K and 22.6% on GSM-HARD

## Executive Summary
This work proposes a novel approach to arithmetic reasoning in LLMs by generating Prolog code instead of natural language Chain-of-Thought reasoning. The method extracts predicates and symbolic formulas from math problems and delegates computation to an external Prolog interpreter, achieving significant accuracy improvements over traditional approaches. The authors create GSM8K-Prolog dataset and introduce PROPER, a permutation-based data augmentation technique that leverages Prolog's non-sequential predicate structure to improve model robustness.

## Method Summary
The method involves supervised fine-tuning of 7B models (Llama-2, CodeLlama, Mistral) on GSM8K-Prolog dataset using LoRA (rank 32, alpha 64). Instead of generating natural language reasoning, models generate Prolog code which is evaluated by an external interpreter (PySwip). PROPER data augmentation permutes predicates in Prolog code during training. Models are evaluated using beam search (size 4) on GSM8K and GSM-HARD test sets, with validation accuracy used for checkpoint selection rather than loss.

## Key Results
- Prolog generation outperforms Chain-of-Thought reasoning by 10.9% on GSM8K and 22.6% on GSM-HARD
- PROPER data augmentation provides consistent improvements across all three 7B models
- Validation accuracy is more effective than loss for checkpoint selection due to observed metric divergence
- The approach is limited to integer answers due to PySwip library constraints

## Why This Works (Mechanism)

### Mechanism 1: Predicate Extraction + External Computation
- Claim: Prolog generation separates predicate extraction from computation, delegating calculation to a deterministic interpreter
- Mechanism: LLMs translate natural language problems into Prolog facts and rules, which are then solved by an external interpreter without intermediate reasoning steps
- Core assumption: LLMs can reliably extract correct predicates and the Prolog interpreter will compute correct answers if predicates are correct
- Evidence anchors: 22.6% accuracy gain on GSM-HARD for large number calculations, FMR=0.600 relevance to related work

### Mechanism 2: PROPER Data Augmentation
- Claim: PROPER improves robustness by leveraging Prolog's non-sequential predicate structure through permutation-based data augmentation
- Mechanism: Permuting order of facts and goals in Prolog code helps models learn to extract predicates regardless of ordering
- Core assumption: Permuting Prolog predicates doesn't change program semantics and models can generalize from permutations
- Evidence anchors: PROPER takes advantage of permutative property, FMR=0.636 relevance to reasoning enhancements

### Mechanism 3: Validation Accuracy Over Loss
- Claim: Validation accuracy is more effective than loss for checkpoint selection due to metric divergence
- Mechanism: Cross-entropy loss may not align with accuracy metric, especially in binary predicate extraction tasks
- Core assumption: Validation accuracy better reflects model's ability to extract correct predicates
- Evidence anchors: Authors observed divergence between loss and accuracy metrics

## Foundational Learning

1. **Prolog Predicate Structure**
   - Why needed: Understanding how Prolog programs are structured with facts, rules, and goals is crucial for predicate extraction
   - Quick check: Verify you can distinguish between Prolog facts (assertions) and rules (implications)

2. **LoRA Fine-tuning Parameters**
   - Why needed: LoRA (Low-Rank Adaptation) is used for efficient fine-tuning of large models with specific rank and alpha parameters
   - Quick check: Confirm you understand rank 32 and alpha 64 settings and their impact on model adaptation

3. **Data Augmentation via Permutation**
   - Why needed: PROPER relies on permuting Prolog predicates while maintaining semantic equivalence
   - Quick check: Ensure you can generate valid permutations of Prolog facts without changing program meaning

4. **Beam Search in Code Generation**
   - Why needed: Beam search (size 4) is used for generating Prolog code with multiple candidate solutions
   - Quick check: Verify understanding of how beam search balances exploration and exploitation in code generation

5. **External Interpreter Integration**
   - Why needed: PySwip serves as the Prolog interpreter that evaluates generated code
   - Quick check: Confirm you can set up and use PySwip for Prolog code execution

## Architecture Onboarding

**Component Map**: GSM8K Problems -> Prolog Generation -> PySwip Interpreter -> Accuracy Evaluation

**Critical Path**: Problem input → LLM Prolog generation → Code validation → PySwip execution → Answer extraction → Accuracy calculation

**Design Tradeoffs**:
- Prolog vs Natural Language: Separates reasoning from computation but requires Prolog expertise
- PROPER vs Standard Training: Improves robustness but may introduce permutation-specific artifacts
- Validation Accuracy vs Loss: Better reflects final performance but may slow convergence

**Failure Signatures**:
- Syntax errors in generated Prolog code indicate model generation issues
- Interpreter errors suggest semantic problems in predicate extraction
- Low accuracy despite high validation loss indicates metric misalignment

**3 First Experiments**:
1. Generate Prolog code for simple GSM8K problems and verify interpreter execution
2. Apply PROPER augmentation to training data and measure impact on validation accuracy
3. Compare checkpoint selection using validation accuracy vs validation loss

## Open Questions the Paper Calls Out

### Open Question 1: Model Scaling Impact
- Question: How does Prolog generation performance scale with larger language models (beyond 7B parameters)?
- Basis: Authors explicitly state they didn't test scaling beyond 7B parameters
- Why unresolved: Only tested three 7B parameter models (Llama-2, CodeLlama, Mistral)
- Resolution evidence: Experiments with larger models (13B, 30B, 70B) on GSM8K-Prolog showing accuracy comparisons

### Open Question 2: Handling Non-Integer Answers
- Question: Can Prolog generation handle non-integer answers and more complex mathematical domains?
- Basis: Current approach restricted to integer answers due to PySwip limitations
- Why unresolved: PySwip cannot handle decimal answers, limiting scope to integer solutions
- Resolution evidence: Implementation using different interpreter that handles floating-point arithmetic

### Open Question 3: PROPER Generalization
- Question: Does PROPER benefit other code generation tasks beyond Prolog?
- Basis: PROPER specifically designed for Prolog's non-sequential structure with mixed results
- Why unresolved: Only tested on Prolog generation with varying effectiveness across models
- Resolution evidence: Applying PROPER-style augmentation to other non-sequential programming languages

## Limitations

- Narrow model scope: Only tested three 7B parameter models (Llama-2, CodeLlama, Mistral)
- Limited datasets: Only evaluated on GSM8K and GSM-HARD, leaving uncertainty about other domains
- Integer-only answers: PySwip library constraints restrict problems to those with integer solutions
- Manual dataset correction: GSM8K-Prolog creation involved manual correction which could introduce bias

## Confidence

- High confidence: Prolog generation outperforms Chain-of-Thought (10.9% on GSM8K, 22.6% on GSM-HARD)
- Medium confidence: PROPER effectiveness shows consistent improvements but generalizability unclear
- Medium confidence: Validation accuracy recommendation based on observed metric divergence

## Next Checks

1. Evaluate on diverse mathematical reasoning datasets beyond GSM8K and GSM-HARD, such as MATH or other benchmarks, to assess generalizability across different problem types and difficulty levels.

2. Test with larger and different model architectures (13B, 34B, GPT-3.5, Claude) to determine if performance gains scale with model size and are architecture-agnostic.

3. Conduct detailed error analysis to identify specific failure modes in predicate extraction, particularly for problems involving complex relationships, implicit information, or non-standard mathematical operations not well-handled by Prolog interpreters.