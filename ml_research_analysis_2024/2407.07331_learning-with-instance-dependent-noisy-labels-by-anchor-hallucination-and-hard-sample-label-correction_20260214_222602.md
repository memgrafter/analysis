---
ver: rpa2
title: Learning with Instance-Dependent Noisy Labels by Anchor Hallucination and Hard
  Sample Label Correction
arxiv_id: '2407.07331'
source_url: https://arxiv.org/abs/2407.07331
tags:
- samples
- hard
- training
- noise
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of learning with instance-dependent
  noisy labels in image classification. The authors propose a novel approach that
  distinguishes between easy and hard samples, using cleanly-labeled easy samples
  to identify and correct labels of hard samples through anchor hallucination.
---

# Learning with Instance-Dependent Noisy Labels by Anchor Hallucination and Hard Sample Label Correction

## Quick Facts
- arXiv ID: 2407.07331
- Source URL: https://arxiv.org/abs/2407.07331
- Reference count: 0
- Primary result: Proposes anchor hallucination method that achieves state-of-the-art performance on instance-dependent noisy label datasets

## Executive Summary
This paper addresses the challenging problem of learning with instance-dependent noisy labels in image classification. The authors propose a novel approach that distinguishes between easy and hard samples, using cleanly-labeled easy samples to identify and correct labels of hard samples through anchor hallucination. The method involves three main steps: easy sample selection using the small-loss criterion, hard anchor hallucination by synthesizing feature vectors from easy samples, and hard sample selection via majority voting of hallucinated anchors. Experiments on synthetic and real-world instance-dependent noisy datasets demonstrate the superiority of the proposed method over state-of-the-art noisy label learning approaches.

## Method Summary
The proposed method employs a two-phase iterative training framework that first identifies easy samples with small losses using a Gaussian Mixture Model, then uses these easy samples to hallucinate anchors representing hard samples between different classes. For each easy sample, anchors are generated by concatenating its feature with another easy sample from a different class and passing through a hallucinator network. Hard samples are selected based on their proximity to these hallucinated anchors using cosine similarity, and their labels are corrected through majority voting among nearby anchors. The corrected hard samples are then used in semi-supervised learning with the easy samples, iteratively improving the model's ability to handle noisy labels.

## Key Results
- Achieves state-of-the-art performance on CIFAR-10, CIFAR-10N/100N, and Clothing1M with instance-dependent noise
- Significant improvements in classification accuracy compared to baseline methods like DivideMix and TSCSI
- Ablation study confirms effectiveness of each design component, particularly the importance of incorporating hard sample information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Easy samples are selected using small-loss criterion, assuming they have correct labels and simple patterns.
- Mechanism: Initial training computes cross-entropy loss for each sample, fits a two-component Gaussian Mixture Model (GMM) to the loss distribution, and selects samples with the smallest losses (easiest) to form the easy sample set.
- Core assumption: DNNs learn simple patterns faster than complex ones, so samples with small loss are more likely to have clean labels and simple visual patterns.
- Evidence anchors:
  - [abstract] "We identify training samples with small losses, assuming they have simple patterns and correct labels."
  - [section] "Drawing on the insight that DNNs tend to learn simple patterns faster than complex ones [6], we identify easy samples by analyzing the distribution of classification losses during initial training."
- Break condition: If loss distribution is bimodal due to other factors (e.g., batch effects), GMM may misidentify easy samples, leading to inclusion of noisy samples or exclusion of hard clean samples.

### Mechanism 2
- Claim: Anchor hallucination generates synthetic features that represent hard samples between two easy samples from different classes.
- Mechanism: For each easy sample feature, randomly pair with another easy sample from a different class, concatenate their features, and pass through a hallucinator network to generate an anchor feature. The anchor is regularized to be between the two input features in feature space while belonging to the first class.
- Core assumption: Complex visual patterns can be represented as combinations of simpler patterns from different classes, and the hallucinator can learn to generate plausible hard sample features.
- Evidence anchors:
  - [abstract] "Utilizing these easy samples, we hallucinate multiple anchors to select hard samples for label correction."
  - [section] "We introduce a novel anchor hallucination technique that synthesizes feature vectors in the feature space. These hallucinated features, called anchors, are generated from easy samples to simulate hard samples that are with complex visual compositions."
- Break condition: If the hallucinator overfits to the easy samples and cannot generate diverse enough anchors, or if the feature space does not support linear interpolation between classes, the anchors may not represent realistic hard samples.

### Mechanism 3
- Claim: Hard samples are selected by finding real samples near hallucinated anchors using cosine similarity, then corrected using majority voting among nearby anchors.
- Mechanism: For each hallucinated anchor, find the nearest hard sample in feature space. If similarity exceeds threshold, consider the anchor a valid representative. For each hard sample, collect up to K valid anchors and use majority voting of their pseudo-labels to correct the hard sample's label.
- Core assumption: Hard samples with correct labels are positioned near the decision boundary and will be close to hallucinated anchors representing that region, while noisy hard samples will be farther away or surrounded by anchors of different classes.
- Evidence anchors:
  - [abstract] "Utilizing these easy samples, we hallucinate multiple anchors to select hard samples for label correction."
  - [section] "The hallucinated anchors extend throughout the feature space... We measure this proximity between sa and sh using cosine similarity."
- Break condition: If the feature space is not well-structured (e.g., classes are not linearly separable or have complex manifolds), cosine similarity may not accurately identify which hard samples are near which anchors, leading to incorrect label corrections.

## Foundational Learning

- Concept: Gaussian Mixture Models (GMM) for fitting loss distributions
  - Why needed here: To identify the low-loss Gaussian component representing easy samples, distinguishing it from the high-loss component representing hard samples
  - Quick check question: How does fitting a two-component GMM to the loss distribution help identify easy samples, and what would happen if the loss distribution is not well-separated?

- Concept: Cosine similarity in feature space for nearest neighbor search
  - Why needed here: To measure proximity between hallucinated anchors and real hard samples in the learned feature space, enabling selection of hard samples based on their spatial relationship to anchors
  - Quick check question: Why is cosine similarity preferred over Euclidean distance in high-dimensional feature spaces, and what are the implications if the feature space is not normalized?

- Concept: Semi-supervised learning with pseudo-label refinement
  - Why needed here: To leverage both the corrected hard samples and easy samples as labeled data, while using the remaining hard samples as unlabeled data for SSL, maximizing data utilization
  - Quick check question: How does the weighting of given labels by easiness scores in the SSL loss function balance trust in initial labels versus model predictions, and what would happen if this weighting is too aggressive?

## Architecture Onboarding

- Component map: Classification module (Feature extractor + Linear classifier) -> Anchor hallucinator (2-layer MLP) -> GMM model -> Semi-supervised learning framework (MixMatch)

- Critical path: Easy sample selection -> Anchor hallucination -> Hard sample selection -> Label correction -> Semi-supervised learning

- Design tradeoffs:
  - Using a single network instead of co-training two networks reduces computational cost but may have slightly lower performance
  - Anchor hallucination versus direct hard sample identification trades off complexity for potentially better coverage of the feature space
  - Class-balanced easy sample selection ensures all classes are represented but may exclude some informative samples

- Failure signatures:
  - Poor performance on hard samples: Indicates issues with anchor hallucination or hard sample selection
  - Overfitting to easy samples: Suggests insufficient hard sample correction or SSL
  - Degenerate hallucinator: Produces identical anchors regardless of input, indicating insufficient diversity in easy samples or model capacity issues

- First 3 experiments:
  1. Implement easy sample selection with GMM on CIFAR-10 with synthetic noise, verify that selected easy samples have higher accuracy than random samples
  2. Implement anchor hallucination with a simple hallucinator, visualize hallucinated anchors in t-SNE to verify they are positioned between classes
  3. Implement hard sample selection using cosine similarity, measure the accuracy of label corrections on a validation set with known ground truth

## Open Questions the Paper Calls Out

- Question: How does the proposed anchor hallucination method perform on highly imbalanced datasets where the easy sample set may not adequately span the feature space?
  - Basis in paper: [explicit] The paper states: "Our framework identifies hard samples and corrects their labels through hard anchor hallucination, with the assumption that the selected easy feature set Se (and hence the hallucinated anchor set Shal) span the class of interest. As a result, the proposed hallucination process might not work well for highly imbalanced datasets."
  - Why unresolved: The paper acknowledges this limitation but does not provide experimental evidence or solutions for imbalanced datasets.
  - What evidence would resolve it: Experiments on highly imbalanced datasets demonstrating the method's performance, or proposed modifications to handle imbalance.

- Question: Can the hallucinator model hφ be generalized to domains beyond image classification, such as text or audio classification?
  - Basis in paper: [inferred] The method relies on feature extraction and hallucination, which could potentially be applied to other data modalities. However, the paper only demonstrates results on image datasets.
  - Why unresolved: The paper focuses exclusively on image classification and does not explore other data types.
  - What evidence would resolve it: Experiments applying the method to text or audio classification tasks with comparable performance improvements.

- Question: How does the choice of λp in the similarity loss Lsim affect the quality of hallucinated anchors and overall model performance?
  - Basis in paper: [explicit] The paper mentions λp as a hyperparameter controlling the difficulty level of hallucinated anchors: "λp ∈ [0.5, 1.0] is a hyperparameter controlling the difficulty level of sa."
  - Why unresolved: The paper does not provide an ablation study or sensitivity analysis for λp.
  - What evidence would resolve it: A detailed analysis showing how different λp values impact anchor quality and classification accuracy.

## Limitations

- The method assumes that small-loss samples are clean and represent simple patterns, which may not hold in cases where noise is structured or the model initially memorizes noisy patterns
- Anchor hallucination introduces additional complexity and may struggle to generate diverse enough anchors if the easy sample set is limited or the feature space does not support meaningful interpolation between classes
- The effectiveness of majority voting for label correction depends on the density and distribution of hallucinated anchors in the feature space, which may not adequately cover regions with complex noise patterns

## Confidence

- High confidence: The overall framework design and experimental methodology are well-defined, with clear evaluation metrics and comparison to state-of-the-art methods
- Medium confidence: The effectiveness of individual components (easy sample selection, anchor hallucination, hard sample selection) relies on specific assumptions about data structure and model behavior that may not generalize across all IDN scenarios
- Medium confidence: The claim of superiority over existing methods is supported by experiments on multiple datasets, but the exact hyperparameter values and implementation details are not fully specified

## Next Checks

1. Conduct ablation studies on the anchor hallucination component by varying the number of hallucinated anchors per easy sample and measuring the impact on hard sample correction accuracy
2. Evaluate the method's robustness to different noise types and levels by testing on synthetic datasets with varying noise rates and comparing performance degradation to baseline methods
3. Analyze the feature space distribution of hard samples before and after label correction using t-SNE visualizations to verify that corrected samples are repositioned closer to their true class regions