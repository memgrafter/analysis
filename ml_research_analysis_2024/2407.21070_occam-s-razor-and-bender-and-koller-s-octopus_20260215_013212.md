---
ver: rpa2
title: Occam's Razor and Bender and Koller's Octopus
arxiv_id: '2407.21070'
source_url: https://arxiv.org/abs/2407.21070
tags:
- octopus
- koller
- bender
- data
- argument
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a teaching approach for critically analyzing
  Bender and Koller's 2020 argument about language models' inability to truly understand
  language (the "Octopus" thought experiment). The author provides classroom materials
  including slides and guided questions that challenge the original paper's claim
  that LLMs cannot learn meaning from form alone.
---

# Occam's Razor and Bender and Koller's Octopus

## Quick Facts
- arXiv ID: 2407.21070
- Source URL: https://arxiv.org/abs/2407.21070
- Authors: Michael Guerzhoy
- Reference count: 1
- Primary result: Teaching materials challenge Bender and Koller's claim that LLMs cannot learn meaning from form alone using guided questions and scientific analogies

## Executive Summary
This paper presents a teaching approach for critically analyzing Bender and Koller's 2020 argument about language models' inability to truly understand language. The author provides classroom materials including slides and guided questions that challenge the original paper's claim that LLMs cannot learn meaning from form alone. The approach draws parallels between scientific theory building and LLM learning, using principles like Occam's razor to show how an intelligent observer might build world models from observational data.

## Method Summary
The teaching approach involves presenting Bender and Koller's "Octopus" thought experiment alongside counterarguments using scientific analogies, particularly astronomical theory building. Students engage with guided questions that prompt critical analysis of whether meaning can be inferred from patterns and form alone. The method includes classroom lectures, video materials, and structured discussion prompts designed to help students develop their own conclusions about the debate.

## Key Results
- Students find the debate engaging and structured questions helpful for analysis
- Teaching materials are available online with slides and video lecture
- Approach successfully challenges original Bender and Koller claims about LLM capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Students can build theoretical understanding from observational data using inductive biases and simplicity principles
- Mechanism: Draws analogy between scientific theory building and LLM learning, showing how both processes involve inferring patterns from observations and using Occam's razor
- Core assumption: Students can transfer understanding of scientific theory building to understanding how LLMs might learn meaning from form alone
- Evidence anchors: [abstract] Teaching materials challenge claim LLMs cannot learn meaning from form alone; [section] Scientific process analogized to B&K octopus observing data
- Break condition: If students cannot grasp the analogy or reject that simplicity principles can guide meaning inference

### Mechanism 2
- Claim: Guided questions help students critically analyze complex arguments by breaking them down into manageable components
- Mechanism: Provides specific questions prompting students to explore different aspects of the Bender and Koller argument and counterarguments
- Core assumption: Structured questioning helps students engage more deeply with complex philosophical arguments about AI and language understanding
- Evidence anchors: [abstract] Author provides classroom materials including slides and guided questions; [section] "We also provide the following guiding questions"
- Break condition: If questions are too leading or don't adequately capture debate complexity

### Mechanism 3
- Claim: Presenting both sides of a debate increases student engagement and critical thinking
- Mechanism: Presents Bender and Koller's original argument alongside counterarguments, encouraging students to form their own conclusions
- Core assumption: Students benefit from examining multiple perspectives on controversial topics in AI and language understanding
- Evidence anchors: [abstract] Recommend students engage with natural counter-arguments; [section] Students will engage with argument and counterargument
- Break condition: If students become confused by conflicting viewpoints or if debate format leads to polarization

## Foundational Learning

- Concept: Occam's Razor
  - Why needed here: Central to understanding how both scientists and LLMs might select simpler theories from observational data
  - Quick check question: If two theories explain the same data equally well, which should we prefer and why?

- Concept: Inductive Biases
  - Why needed here: Key to understanding how LLMs might build world models from form alone, despite Bender and Koller's claims
  - Quick check question: How might an LLM's architecture provide inductive biases that help it infer meaning from language patterns?

- Concept: Scientific Theory Building Process
  - Why needed here: Provides the analogy for how LLMs might learn meaning through observation and pattern recognition
  - Quick check question: What role did epicycles play in astronomical theory building, and how does this relate to LLM learning?

## Architecture Onboarding

- Component map: Teaching materials -> Slides, guided questions, video lecture -> Scientific analogies (astronomy, octopus) -> Key concepts (Occam's Razor, inductive biases, form vs. meaning)

- Critical path: 1) Present Bender and Koller's argument, 2) Introduce counterarguments using scientific analogies, 3) Guide students through specific questions about meaning inference, 4) Encourage students to form their own conclusions

- Design tradeoffs: Balancing depth of philosophical argument with accessibility for undergraduates, choosing between presenting more counterarguments versus focusing on most compelling ones, deciding how much background in linguistics or AI to assume

- Failure signatures: Students struggling to see connection between scientific theory building and LLM learning, confusion about role of simplicity principles in meaning inference, difficulty engaging with debate format or forming independent conclusions

- First 3 experiments: 1) Test guided questions with small student group to assess clarity and effectiveness, 2) Compare student engagement between debate-based and lecture-based presentations, 3) Evaluate whether students can apply Occam's Razor reasoning to new AI-related arguments beyond Bender and Koller debate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific inductive biases might enable an LLM to build world models from observational data, and how do these biases differ from traditional scientific methods?
- Basis in paper: [explicit] Paper mentions Bender and Koller's prediction about LLMs not being able to learn arithmetic was due to "insufficiently accounting for the possibility of using inductive biases to build a model of the data"
- Why unresolved: While paper suggests inductive biases could be key, it doesn't specify what these biases are or how they might work in practice
- What evidence would resolve it: Empirical studies demonstrating specific inductive biases in LLMs and their role in world model building, or theoretical frameworks explaining how these biases operate in language model learning

### Open Question 2
- Question: What are the fundamental limitations of the octopus analogy when applied to modern LLMs, particularly regarding the ability to interact with and test hypotheses about the world?
- Basis in paper: [explicit] Paper notes that "unlike the astronomers, the octopus cannot interact with the world – he cannot influence what observations are made" and asks students to consider how this limitation might affect learning speed
- Why unresolved: Paper presents the octopus analogy but doesn't fully explore how inability to interact with world fundamentally differs between octopus and modern LLMs
- What evidence would resolve it: Comparative studies of learning efficiency between observational-only and interactive learning scenarios in LLMs, or theoretical analysis of how interaction capabilities might bridge gap identified in octopus analogy

### Open Question 3
- Question: How does the role of simplicity (Occam's razor) in scientific theory building compare to the way LLMs might use simplicity principles in their learning processes?
- Basis in paper: [explicit] Paper discusses how "Occam's razor – the principle that, all things being equal, we should prefer the simpler theory – can help select the better scientific theory" and asks how this might apply to the octopus
- Why unresolved: While paper draws parallels between scientific theory building and LLM learning, it doesn't explore how concept of simplicity might manifest differently in these two contexts
- What evidence would resolve it: Empirical studies comparing simplicity of theories generated by humans versus LLMs, or analysis of how LLMs weight simplicity in their learning processes compared to other factors

## Limitations
- Lack of empirical evidence demonstrating teaching approach effectiveness
- Analogies may not transfer effectively to all students, particularly those without strong backgrounds in philosophy of science or machine learning
- Claims about student engagement and learning outcomes are based on anecdotal observations rather than systematic evaluation

## Confidence
- High Confidence: Paper clearly presents structured teaching approach with specific materials and well-defined pedagogical framework
- Medium Confidence: Analogies between scientific theory building and LLM learning are conceptually sound but may not resonate with all student audiences
- Low Confidence: Claims about student engagement and learning outcomes are based on anecdotal observations rather than systematic evaluation

## Next Checks
1. Conduct pre- and post-tests measuring students' ability to critically analyze arguments about AI capabilities, comparing groups taught with this approach versus traditional lecture-based instruction
2. Implement think-aloud protocols during guided question sessions to assess how students are actually reasoning through counterarguments and whether they're engaging with core philosophical issues
3. Survey students about their prior knowledge of philosophy of science and machine learning to determine whether teaching approach needs adaptation for different academic backgrounds and experience levels