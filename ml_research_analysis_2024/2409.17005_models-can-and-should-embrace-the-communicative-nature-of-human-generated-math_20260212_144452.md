---
ver: rpa2
title: Models Can and Should Embrace the Communicative Nature of Human-Generated Math
arxiv_id: '2409.17005'
source_url: https://arxiv.org/abs/2409.17005
tags:
- math
- equation
- language
- rule
- mathematical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The authors investigated whether language models (LLMs) treat\
  \ math as situated linguistic communication, not just symbolic reasoning. They conducted\
  \ two experiments: (1) given equivalent equations in different orders, GPT-4o generated\
  \ word problems with consistent differences and almost never recovered the reverse\
  \ order, showing sensitivity to communicative asymmetry in math notation; (2) LLMs\
  \ preferred natural orderings of proofs and rules, matching human mathematicians\u2019\
  \ expectations, even after modifying variables or wording to prevent memorization."
---

# Models Can and Should Embrace the Communicative Nature of Human-Generated Math

## Quick Facts
- arXiv ID: 2409.17005
- Source URL: https://arxiv.org/abs/2409.17005
- Reference count: 40
- Models recover original equation orderings 52% of the time but reverse orderings only 0.2% of the time, showing sensitivity to communicative asymmetry

## Executive Summary
Language models (LLMs) interpret mathematical notation not as pure symbolic reasoning but as situated linguistic communication, mirroring human communicative intentions. The authors demonstrate that GPT-4o generates systematically different word problems for mathematically equivalent equations arranged in different orders, and almost never recovers the reverse ordering. Additionally, LLMs show clear preferences for natural orderings of proofs and rules that align with human mathematicians' expectations, even after modifying variables or wording to prevent memorization.

## Method Summary
The study conducted two experiments: (1) GPT-4o generated word problems from paired forward/reverse equations and attempted recovery, measuring the asymmetric success rates; (2) four different LLMs (LLaMa 3.1 8B, Mistral 7B v0.3, Mathstral 7B, and Qwen2-Math 7B) calculated surprisal scores for natural vs. counterfactual equation orderings from Mirin and Dawkins [29]. The authors also tested reworded and emoji-substituted variants to control for memorization effects.

## Key Results
- GPT-4o recovered original equation orderings 52% of the time but reverse orderings only 0.2% of the time
- LLMs preferred natural orderings of proofs in nine out of ten equations tested
- Even with variable names changed or replaced with emojis, LLMs maintained preferences for natural orderings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs interpret math equations asymmetrically, mirroring human communicative intentions.
- Mechanism: The model learns that left-to-right presentation of equivalent equations conveys different contextual meaning, influencing generated word problems and recovery rates.
- Core assumption: The training data encodes human communicative preferences that associate left-side structure with specific real-world interpretations.
- Evidence anchors:
  - [abstract] "language models interpret the equals sign in a humanlike way—generating systematically different word problems for the same underlying equation arranged in different ways"
  - [section 2] "We found that the original equation was recovered on average 52% of the time... The reverse equation was nearly never recovered: 0.2%"
  - [corpus] FMR=0.492 suggests some topical overlap with math communication literature, though cited_by_count=0 indicates limited academic citation.

### Mechanism 2
- Claim: LLMs prefer natural orderings of mathematical proofs, reflecting human communicative intent.
- Mechanism: The model learns that certain proof orderings are more probable based on how humans write proofs for comprehension, not just logical correctness.
- Core assumption: Training data contains enough naturally-ordered proofs that the model can distinguish them from logically-equivalent but unnatural orderings.
- Evidence anchors:
  - [abstract] "language models prefer proofs to be ordered in naturalistic ways, even though other orders would be logically equivalent"
  - [section 3] "the evaluated models display clear and consistent preferences for the natural ordering in nine of ten equations"
  - [corpus] FMR=0.492 indicates moderate topical relevance, but lack of citations suggests this area needs more empirical work.

### Mechanism 3
- Claim: LLMs capture communicative signals in variable naming and notation choices.
- Mechanism: The model associates specific naming conventions (f, g for functions) with communicative intent, affecting how it interprets and generates mathematical content.
- Core assumption: Training data preserves not just mathematical correctness but also human stylistic preferences in notation.
- Evidence anchors:
  - [section 4] "Even though they don't matter logically, variable names matter for communicating math (e.g., functions are often f and g)"
  - [section 3] "mathematicians expressed surprise at seeing f and g instead of f (x) and g(x)"
  - [corpus] FMR=0.492 suggests some connection to math communication, but no direct evidence for variable naming patterns.

## Foundational Learning

- Concept: Communicative asymmetry in mathematical notation
  - Why needed here: Understanding that equivalent mathematical expressions can carry different communicative meanings is crucial for interpreting why LLMs show recovery biases
  - Quick check question: If 3x + 9 and 9 + 3x are mathematically equivalent, why would an LLM generate different word problems for them?

- Concept: Proof structure and human comprehension
  - Why needed here: The preference for natural proof orderings isn't about logical correctness but about how humans understand and internalize mathematical arguments
  - Quick check question: What distinguishes a "natural" proof ordering from a logically-equivalent but unnatural one?

- Concept: Mathematical notation as communicative choice
  - Why needed here: Variable naming and notation selection convey pragmatic information beyond pure semantics, which LLMs learn to recognize
  - Quick check question: How might using emojis instead of traditional variable names affect an LLM's interpretation of a proof?

## Architecture Onboarding

- Component map: Input -> Pattern recognition -> Contextual interpretation -> Output generation
- Critical path: Input → Pattern recognition → Contextual interpretation → Output generation
- Design tradeoffs: Pure symbolic solvers vs. LLM-based approaches; interpretability vs. raw computational power; generalization vs. communicative fidelity
- Failure signatures: Equal recovery rates for forward/reverse equations (loss of asymmetry), uniform surprisal across proof orderings (loss of communicative preference), random variable naming acceptance (loss of notation sensitivity)
- First 3 experiments:
  1. Test recovery rates for mathematically equivalent equations with varied formatting to confirm asymmetry persists
  2. Measure surprisal scores for proof orderings with and without explanatory text to isolate communicative vs. logical components
  3. Replace all variables with emojis in proofs and measure impact on natural ordering preferences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can models consistently recover the reverse ordering of equations from word problems?
- Basis in paper: [explicit] The paper shows that GPT-4o recovered the original equation ordering 52% of the time but the reverse ordering only 0.2% of the time across 1000 samples.
- Why unresolved: The experiment was one-directional - testing recovery from word problems back to equations. It's unknown if models could be prompted differently to recover reverse orderings.
- What evidence would resolve it: Testing different prompting strategies and model architectures on the same equation-word problem pairs to see if reverse recovery rates can be improved.

### Open Question 2
- Question: Do math-fine-tuned models perform significantly better than general models on proof ordering preferences?
- Basis in paper: [explicit] The paper compared four models (two general, two math-fine-tuned) and found no significant performance differences (paired t = 0.606, p = 0.548).
- Why unresolved: While no significant difference was found in this specific experiment, the sample size may have been too small to detect smaller but meaningful differences. The authors suggest this is an area for further investigation.
- What evidence would resolve it: Larger scale experiments with more diverse proof types and model architectures to detect potential performance differences between fine-tuned and general models.

### Open Question 3
- Question: How robust are these communicative patterns across different mathematical domains?
- Basis in paper: [inferred] The experiments focused on basic algebra equations and undergraduate-level proofs. The authors suggest these principles "encompass a much broader class of phenomena" but don't test this.
- Why unresolved: The study is limited to specific mathematical contexts. It's unclear if similar communicative asymmetries and ordering preferences exist in other domains like geometry, topology, or advanced analysis.
- What evidence would resolve it: Testing the same experimental paradigms across diverse mathematical domains to identify which communicative patterns generalize and which are domain-specific.

## Limitations
- Limited model diversity with only four LLM architectures tested in Experiment 2
- Potential cultural bias in mathematical communication patterns not accounted for
- Reliance on English-language mathematical notation may not capture cross-cultural communication patterns

## Confidence
- **High confidence**: The asymmetric recovery rates in Experiment 1 (52% vs 0.2%) are robust and well-supported by the data
- **Medium confidence**: The proof ordering preferences in Experiment 2 show consistent patterns but the interpretation remains somewhat speculative
- **Medium confidence**: The variable naming and notation findings are suggestive but rely on indirect evidence

## Next Checks
1. **Cross-cultural validation**: Test the same experiments with LLMs trained on non-English mathematical corpora to determine if communicative patterns are universal or culturally specific

2. **Controlled variable manipulation**: Systematically randomize variable names and equation orderings in both training and inference phases to quantify how much communicative preference depends on learned patterns versus inherent model architecture

3. **Expert human comparison**: Conduct controlled studies where professional mathematicians rate the "naturalness" of different proof orderings and equation presentations, then compare these ratings directly with LLM preferences to validate the claimed alignment with human communicative intent