---
ver: rpa2
title: Image captioning in different languages
arxiv_id: '2407.09495'
source_url: https://arxiv.org/abs/2407.09495
tags:
- image
- captioning
- language
- dataset
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a manually curated list of non-English image
  captioning datasets, revealing a significant lack of diversity: only 23 languages
  are represented. Most datasets rely on translation from English, perpetuating Western
  perspectives.'
---

# Image captioning in different languages

## Quick Facts
- arXiv ID: 2407.09495
- Source URL: https://arxiv.org/abs/2407.09495
- Authors: Emiel van Miltenburg
- Reference count: 32
- Primary result: Only 23 non-English languages represented in image captioning datasets, with most relying on English translations

## Executive Summary
This paper presents a manually curated inventory of non-English image captioning datasets, revealing a concerning lack of linguistic diversity in Vision & Language research. The study found that only 23 languages are represented across all available datasets, with most relying on translation from English captions. This creates a significant bias toward Western perspectives and limits the applicability of image captioning technology for global users. The research calls for urgent action to develop more inclusive datasets and build community around multilingual vision-language research.

## Method Summary
The author conducted a systematic search for non-English image captioning datasets, manually curating and verifying each entry. The methodology involved examining existing dataset repositories, academic papers, and related resources to identify all available multilingual captioning datasets. Each dataset was evaluated for its language coverage, data collection methodology, and potential biases in representation. The analysis focused on identifying the source languages of captions and the translation methods used, if applicable.

## Key Results
- Only 23 non-English languages have dedicated image captioning datasets
- Most datasets use English as a source language and translate captions
- Translation-based approaches perpetuate Western cultural perspectives
- Significant gaps exist for languages from Asia, Africa, and indigenous communities

## Why This Works (Mechanism)
The study's findings reveal how language-dependent biases in image captioning datasets create systematic limitations in Vision & Language models. When captions are translated from English rather than generated natively, cultural context, local idioms, and region-specific references are often lost or misinterpreted. This mechanism of translation-based dataset creation inherently privileges English-speaking perspectives and fails to capture the diverse ways different cultures describe visual scenes. The limited language coverage means that most of the world's population cannot benefit from image captioning technology that reflects their linguistic and cultural context.

## Foundational Learning
- **Multilingual dataset curation** - Why needed: To understand how language representation affects model performance across cultures; Quick check: Compare dataset sizes and quality across different language families
- **Cross-cultural image description patterns** - Why needed: To identify how different cultures focus on different visual elements; Quick check: Analyze caption content for cultural-specific references
- **Translation methodology impact** - Why needed: To assess how translation quality affects caption accuracy; Quick check: Compare human vs machine translation results
- **Vision-Language model bias propagation** - Why needed: To understand how training data biases affect model outputs; Quick check: Evaluate model performance across different language groups
- **Dataset representativeness metrics** - Why needed: To quantify how well datasets serve global populations; Quick check: Compare language coverage to global speaker demographics
- **Cultural context preservation** - Why needed: To maintain meaning across language boundaries; Quick check: Validate cultural appropriateness with native speakers

## Architecture Onboarding
**Component Map:** Dataset Curation -> Language Coverage Analysis -> Cultural Bias Assessment -> Community Building Initiative
**Critical Path:** Identify languages -> Collect/verify datasets -> Analyze translation methods -> Propose solutions
**Design Tradeoffs:** Manual curation ensures accuracy but limits scalability; Translation-based datasets are faster to create but less culturally authentic
**Failure Signatures:** Over-reliance on English creates blind spots; Translation errors propagate through training; Underrepresentation of certain language families
**First Experiments:**
1. Survey native speakers from 5 underrepresented languages about image description needs
2. Compare caption quality between translated and native-generated captions for the same images
3. Build a small pilot dataset for one critically underrepresented language using native speakers

## Open Questions the Paper Calls Out
None

## Limitations
- Manual curation approach may miss datasets or contain selection bias
- Translation quality and cultural representativeness were not systematically validated
- The 23-language count may not reflect the full scope of available but difficult-to-find resources
- No quantitative analysis of how translation affects caption quality or model performance

## Confidence
- High confidence in the finding that only 23 non-English languages are represented in image captioning datasets, as this is a verifiable count
- Medium confidence in the claim about Western perspective dominance, as this requires subjective cultural interpretation
- Medium confidence in the assessment of translation dependency, pending verification of source methodologies

## Next Checks
1. Conduct a systematic audit of the translation methodologies used in the 23 datasets, verifying whether machine or human translation was employed and assessing quality through independent evaluation
2. Perform linguistic diversity analysis comparing the 23 represented languages against global language demographics and digital resource availability
3. Validate the cultural representativeness claim by having native speakers from different language groups evaluate sample captions for cultural appropriateness and local context relevance