---
ver: rpa2
title: 'Belief sharing: a blessing or a curse'
arxiv_id: '2407.02465'
source_url: https://arxiv.org/abs/2407.02465
tags:
- agents
- belief
- beliefs
- sharing
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study examines belief-sharing dynamics in multi-agent active
  inference systems, identifying echo chamber and self-doubt phenomena that arise
  when agents share posterior beliefs. Through simulations in an object-finding task,
  the authors demonstrate that naive belief sharing can lead to agents reinforcing
  incorrect beliefs or discounting their observations, resulting in poor collaborative
  performance.
---

# Belief sharing: a blessing or a curse

## Quick Facts
- arXiv ID: 2407.02465
- Source URL: https://arxiv.org/abs/2407.02465
- Reference count: 18
- Key outcome: Likelihood-sharing strategy outperforms naive belief-sharing in preventing echo chambers and self-doubt in multi-agent active inference systems

## Executive Summary
This paper investigates belief-sharing dynamics in multi-agent active inference systems, identifying two problematic phenomena: echo chambers where agents reinforce incorrect beliefs without new evidence, and self-doubt where agents discount their observations in favor of shared beliefs. The authors propose a novel likelihood-sharing strategy that communicates interpreted observations rather than posterior beliefs, treating other agents as independent observers. Through simulations in an object-finding task, they demonstrate that likelihood-sharing agents achieve comparable performance to naive belief-sharing agents while avoiding the negative social dynamics of echo chambers and self-doubt.

## Method Summary
The study employs active inference agents operating in a graph-based environment with N locations, where agents must find a static object. Each agent has a POMDP generative model with location and object location state factors, three observation modalities (self-location, object visibility, and belief-sharing), and selects actions by minimizing expected free energy. The paper compares three communication strategies: no communication, naive belief sharing (directly sharing posterior beliefs with identity likelihood mapping), and likelihood sharing (communicating interpreted observations as additional independent evidence).

## Key Results
- Naive belief sharing leads to echo chambers where agents reinforce incorrect beliefs without new evidence
- Agents discount their own observations in favor of incorrect shared beliefs (self-doubt)
- Likelihood-sharing agents perform on par with naive belief-sharing agents while avoiding echo chambers and self-doubt
- Likelihood-sharing outperforms both random agents and non-communicating agents in object-finding tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sharing posterior beliefs in multi-agent active inference systems leads to echo chambers where agents reinforce incorrect beliefs without new evidence.
- Mechanism: Bayesian model updating doubles down on shared priors when agents directly share their posterior beliefs, causing the prior beliefs to be reinforced through repeated communication.
- Core assumption: Agents have similar generative models and can interpret each other's beliefs directly.
- Evidence anchors:
  - [abstract] "naive belief sharing can give rise to the negative social dynamics of echo chambers and self-doubt"
  - [section] "When agents share a common world and world model, they can benefit from sharing beliefs among each other"
  - [corpus] Weak evidence - only 0 citations found in related papers
- Break condition: When agents receive contradictory evidence that their shared belief is incorrect, but self-doubt prevents them from updating appropriately.

### Mechanism 2
- Claim: Sharing posterior beliefs can cause self-doubt where agents discount their own observations in favor of incorrect shared beliefs.
- Mechanism: When agents' observations contradict strongly reinforced shared beliefs, the shared belief signal overpowers the observation signal in the variational message passing update equation.
- Core assumption: The likelihood mapping between shared beliefs and observations is direct (identity mapping).
- Evidence anchors:
  - [abstract] "agents discount their observations to favor shared, yet incorrect, beliefs"
  - [section] "agents 'doubt' their observations originating from the environment"
  - [corpus] Weak evidence - no relevant citations found in related papers
- Break condition: When the observation likelihood becomes strong enough to overcome the reinforced shared belief signal.

### Mechanism 3
- Claim: Sharing likelihood information rather than posterior beliefs treats other agents as independent observers, preventing echo chambers and self-doubt.
- Mechanism: By sharing only the likelihood message (interpreted observations) rather than full posterior beliefs, agents integrate information as additional evidence rather than reinforcing priors.
- Core assumption: Other agents can be treated as additional independent observers of the same latent state.
- Evidence anchors:
  - [abstract] "likelihood-sharing agents perform on par with naive belief-sharing agents while avoiding echo chambers and self-doubt"
  - [section] "we advocate for sharing likelihood information rather than posterior beliefs, treating other agents' observations as additional independent sources of information"
  - [corpus] Weak evidence - only 0 citations found in related papers
- Break condition: When agents have fundamentally different generative models that cannot be reconciled as independent observations.

## Foundational Learning

- Concept: Variational Free Energy and its relationship to Bayesian inference
  - Why needed here: The entire communication mechanism relies on minimizing variational free energy during belief updating
  - Quick check question: What are the two components of variational free energy and how do they trade off against each other?

- Concept: Message passing in probabilistic graphical models
  - Why needed here: The paper explicitly uses variational message passing notation to describe how beliefs are updated
  - Quick check question: In the update equation for shared observations, what are the three components that contribute to the final belief?

- Concept: Active inference planning as inference
  - Why needed here: Understanding how agents select policies based on expected free energy is crucial for interpreting the experimental results
  - Quick check question: How does the expected free energy balance information gain against utility in policy selection?

## Architecture Onboarding

- Component map: Agent observation → likelihood computation → belief updating → action selection → observation sharing with other agents
- Critical path: The core communication mechanism flows through agent observation → likelihood computation → belief updating → action selection → observation sharing with other agents. The bottleneck is in the belief-sharing observation modality that connects agents.
- Design tradeoffs: Direct posterior belief sharing is simple but creates echo chambers; likelihood sharing is more robust but requires additional computation to convert observations to likelihood messages; no communication is safe but suboptimal.
- Failure signatures: Echo chambers manifest as agents reinforcing incorrect beliefs without new evidence; self-doubt manifests as agents ignoring their own observations when they contradict shared beliefs; both show up as poor object-finding performance.
- First 3 experiments:
  1. Replicate the echo chamber simulation by initializing agents with small priors on specific locations and measuring belief reinforcement over time
  2. Replicate the self-doubt simulation by initializing agents with strong incorrect beliefs and measuring whether they can update based on observations
  3. Test the likelihood-sharing mechanism by comparing performance against naive belief sharing and no communication across all possible object locations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the theoretical limits of likelihood-sharing versus posterior-sharing in terms of communication efficiency and robustness across different types of generative models and environmental complexities?
- Basis in paper: [explicit] The paper compares these two strategies but does not provide a comprehensive theoretical analysis of their relative strengths and weaknesses.
- Why unresolved: The paper focuses on a specific graph-based object-finding task and does not explore the generalizability of the findings to more complex or diverse environments.
- What evidence would resolve it: A systematic comparison of belief-sharing and likelihood-sharing strategies across a range of generative models and environmental complexities, including theoretical analysis and empirical validation.

### Open Question 2
- Question: How can active inference agents be designed to detect and mitigate the formation of echo chambers or self-doubt in real-time, without requiring a priori knowledge of the environment or other agents' beliefs?
- Basis in paper: [inferred] The paper demonstrates the existence of echo chambers and self-doubt but does not provide a mechanism for detecting or mitigating these phenomena in real-time.
- Why unresolved: The paper focuses on a specific communication strategy (likelihood-sharing) to prevent echo chambers and self-doubt, but does not address the problem of detecting and mitigating these phenomena once they have formed.
- What evidence would resolve it: The development and validation of a real-time detection and mitigation mechanism for echo chambers and self-doubt in active inference agents, applicable to a range of environments and agent configurations.

### Open Question 3
- Question: How do belief-sharing dynamics change when agents have different generative models or when the environment is non-stationary, and what strategies can be employed to maintain effective collaboration under these conditions?
- Basis in paper: [explicit] The paper assumes that all agents share a common world and world model, but does not explore the implications of model heterogeneity or environmental non-stationarity.
- Why unresolved: The paper's analysis is limited to a specific scenario where agents have identical generative models and operate in a static environment.
- What evidence would resolve it: An investigation of belief-sharing dynamics in active inference agents with heterogeneous generative models and non-stationary environments, including the development and validation of strategies to maintain effective collaboration under these conditions.

## Limitations

- Limited empirical validation beyond synthetic simulations in a single task domain
- Echo chamber and self-doubt mechanisms lack direct experimental demonstration with measurable metrics beyond object-finding success rates
- Theoretical framework relies on specific assumptions about shared generative models that may not generalize

## Confidence

- High confidence: The likelihood-sharing mechanism as an alternative to posterior belief sharing is technically sound and theoretically justified within the active inference framework.
- Medium confidence: The proposed solution effectively prevents echo chambers and self-doubt in the specific object-finding task, though this may not generalize to other domains.
- Low confidence: The characterization of self-doubt as a distinct phenomenon separate from echo chambers, and the claim that these are fundamental problems requiring the proposed solution.

## Next Checks

1. Test the likelihood-sharing mechanism in a task with dynamic or moving objects to assess robustness to changing environments and temporal dependencies.
2. Implement an ablation study where agents can selectively share different components of their beliefs (priors, posteriors, likelihoods) to isolate the specific contribution of each sharing strategy.
3. Evaluate performance when agents have heterogeneous generative models or partially observable environments to test the assumption that agents can be treated as independent observers.