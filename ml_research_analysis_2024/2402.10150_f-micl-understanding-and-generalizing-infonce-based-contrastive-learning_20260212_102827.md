---
ver: rpa2
title: '$f$-MICL: Understanding and Generalizing InfoNCE-based Contrastive Learning'
arxiv_id: '2402.10150'
source_url: https://arxiv.org/abs/2402.10150
tags:
- learning
- similarity
- contrastive
- objective
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces $f$-MICL, a framework that generalizes InfoNCE-based
  contrastive learning by extending the KL-based mutual information to the broader
  $f$-divergence family. The authors propose a novel $f$-Gaussian similarity function
  derived under the assumption that the joint feature distribution follows a Gaussian
  kernel.
---

# $f$-MICL: Understanding and Generalizing InfoNCE-based Contrastive Learning

## Quick Facts
- arXiv ID: 2402.10150
- Source URL: https://arxiv.org/abs/2402.10150
- Reference count: 40
- Primary result: f-MICL framework improves MoCo v3 by 2.1% on ImageNet (73.2%→76.5% accuracy)

## Executive Summary
This paper introduces f-MICL, a framework that generalizes InfoNCE-based contrastive learning by extending the KL-based mutual information to the broader f-divergence family. The authors propose a novel f-Gaussian similarity function derived under the assumption that the joint feature distribution follows a Gaussian kernel. Empirically, f-MICL consistently outperforms baseline methods across vision and language datasets, with the best-performing f-divergence being task and dataset dependent.

## Method Summary
The f-MICL framework extends contrastive learning by using f-divergences instead of KL divergence for mutual information estimation. It employs a variational lower bound of f-mutual information combined with the convex conjugate to derive the objective function. The method uses an f-Gaussian similarity function that assumes the joint feature distribution follows a Gaussian kernel. The framework connects to existing methods like InfoNCE and Alignment & Uniformity, providing a unified theoretical foundation. Training involves optimizing the f-MICL objective with standard contrastive learning procedures using batch-based negative sampling.

## Key Results
- f-MICL with JS divergence improves MoCo v3 by 2.1% on ImageNet (73.2%→76.5% accuracy)
- Best-performing f-divergence is task and dataset dependent across KL, JS, Pearson, Squared Hellinger, Tsallis, and Vincze-Le Cam divergences
- f-Gaussian similarity consistently outperforms cosine similarity across various f-divergences and datasets

## Why This Works (Mechanism)

### Mechanism 1
The f-MICL framework generalizes InfoNCE by extending the KL-based mutual information to the f-divergence family, allowing for better objective selection depending on task and dataset. By using the variational lower bound of f-mutual information and the convex conjugate, f-MICL provides a family of objectives that preserve the alignment and uniformity properties of InfoNCE while offering flexibility in the choice of f-divergence. Core assumption: The convex conjugate of f provides a valid lower bound for the f-divergence, and the optimal similarity function under this framework is derived from the joint feature distribution.

### Mechanism 2
The proposed f-Gaussian similarity function, derived under the assumption that the joint feature distribution follows a Gaussian kernel, provides better interpretability and empirical performance compared to the heuristic cosine similarity. By assuming the joint feature density is proportional to a Gaussian kernel, the f-Gaussian similarity function s_f(x_g,y_g) = f' ∘ G_σ(‖x_g - y_g‖²) is derived, which aligns with the theoretical foundation of f-MICL and outperforms the cosine similarity in practice. Core assumption: The joint feature distribution of positive pairs is proportional to a Gaussian kernel.

### Mechanism 3
The f-MICL framework establishes connections between its objective and several popular InfoNCE-based objectives, such as SimCLR, MoCo, and Alignment & Uniformity, providing a unified understanding of these methods. By showing that InfoNCE is an upper bound of f-MICL, and that Alignment & Uniformity is a special case of f-MICL with the KL divergence and f-Gaussian similarity, the framework unifies these objectives under a common theoretical foundation. Core assumption: The f-MICL objective can be transformed into InfoNCE and Alignment & Uniformity by appropriate choices of f-divergence and similarity function.

## Foundational Learning

- Concept: Mutual Information (MI)
  - Why needed here: The paper generalizes the KL-based MI to the f-divergence family, making a clear understanding of MI crucial for grasping the f-MICL framework.
  - Quick check question: What is the relationship between mutual information and KL divergence?

- Concept: f-divergences
  - Why needed here: The paper introduces the f-MICL framework by extending the KL-based MI to the broader f-divergence family, making a solid understanding of f-divergences essential.
  - Quick check question: What are some common examples of f-divergences, and how do they differ from the KL divergence?

- Concept: Convex conjugates
  - Why needed here: The paper uses the convex conjugate of f to derive the variational lower bound of f-MI and the optimal similarity function, making a clear understanding of convex conjugates necessary.
  - Quick check question: What is the relationship between a function and its convex conjugate, and how is the convex conjugate used in variational bounds?

## Architecture Onboarding

- Component map: Feature encoder (g) -> f-divergence function (f) -> Similarity function (s) -> Objective function
- Critical path:
  1. Sample a batch of data and create positive pairs using data augmentation
  2. Encode the data using the feature encoder to obtain hypersphere embeddings
  3. Compute the similarity between positive and negative pairs using the f-Gaussian similarity function
  4. Maximize the f-MICL objective to update the feature encoder
- Design tradeoffs:
  - Choice of f-divergence: Different f-divergences may lead to varying performance depending on the task and dataset
  - Choice of similarity function: The f-Gaussian similarity is derived from the f-MICL framework, but other similarity functions may be used
  - Hyperparameters: The weighting parameter α and the variance σ² in the Gaussian kernel need to be tuned for optimal performance
- Failure signatures:
  - Poor downstream performance: May indicate an inappropriate choice of f-divergence or similarity function
  - Unstable training: May suggest issues with the weighting parameter α or the variance σ²
  - Feature collapse: May occur when using non-satisfying f-divergences, such as the RKL or Neyman χ² divergences
- First 3 experiments:
  1. Implement the f-MICL framework with a simple f-divergence (e.g., KL) and the f-Gaussian similarity function on a small vision dataset (e.g., CIFAR-10)
  2. Compare the performance of different f-divergences (e.g., JS, Pearson, SH) on the same dataset to identify the best-performing divergence
  3. Evaluate the impact of the weighting parameter α and the variance σ² on the downstream performance and training stability

## Open Questions the Paper Calls Out

### Open Question 1
Is there a theoretical framework to determine the optimal f-divergence for a given task and dataset? The paper states that while how to derive an optimal f-divergence deserves more study in theory, in practice we can select the best f among several common f-divergences on a validation set. This remains unresolved because the paper empirically demonstrates that the best-performing f-divergence is task and dataset dependent, but does not provide a theoretical method for selecting the optimal f-divergence.

### Open Question 2
How does the choice of similarity function (e.g., f-Gaussian vs. cosine) affect the alignment and uniformity properties of the learned representations? While the paper demonstrates the superiority of the f-Gaussian similarity, it does not investigate the specific effects of different similarity functions on the alignment and uniformity of the learned representations.

### Open Question 3
Can the f-MICL framework be extended to other types of divergences beyond the f-divergence family? The paper focuses on extending the KL-based mutual information to the f-divergence family, but does not explore the possibility of incorporating other types of divergences, such as the Wasserstein distance or the Jensen-Shannon divergence.

## Limitations

- The Gaussian kernel assumption for joint feature distributions may not hold universally across all datasets and modalities
- Limited ablation studies on the impact of different f-divergences for specific downstream tasks
- The f-Gaussian similarity function, while showing empirical benefits, lacks theoretical justification beyond the Gaussian assumption

## Confidence

- High Confidence: The theoretical framework connecting f-MICL to InfoNCE and Alignment & Uniformity objectives
- Medium Confidence: The empirical superiority of f-MICL over baselines, given the consistent improvements across datasets
- Medium Confidence: The choice of optimal f-divergence being task and dataset dependent, based on limited ablation studies

## Next Checks

1. Conduct systematic ablation studies across more diverse tasks and datasets to validate the claim that optimal f-divergence is task-dependent
2. Test the framework with non-Gaussian feature distributions to assess robustness of the f-Gaussian similarity assumption
3. Implement theoretical proofs or bounds on the approximation error when using the f-Gaussian similarity versus the optimal similarity function derived from the f-divergence's convex conjugate