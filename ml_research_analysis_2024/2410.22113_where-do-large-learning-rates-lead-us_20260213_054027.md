---
ver: rpa2
title: Where Do Large Learning Rates Lead Us?
arxiv_id: '2410.22113'
source_url: https://arxiv.org/abs/2410.22113
tags:
- training
- learning
- fine-tuning
- regime
- pre-training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how initial learning rate (LR) values affect
  final model quality and feature learning. Using a controlled scale-invariant training
  setup, the authors analyze three LR regimes: convergence, chaotic equilibrium, and
  divergence.'
---

# Where Do Large Learning Rates Lead Us?

## Quick Facts
- **arXiv ID:** 2410.22113
- **Source URL:** https://arxiv.org/abs/2410.22113
- **Reference count:** 40
- **Primary result:** Only a narrow range of initial learning rates just above the convergence threshold consistently yields optimal generalization after fine-tuning or weight averaging.

## Executive Summary
This paper investigates how initial learning rate (LR) values affect final model quality and feature learning in neural networks. Using a controlled scale-invariant training setup, the authors identify three distinct regimes of training behavior: convergence, chaotic equilibrium, and divergence. They find that only initial learning rates in a narrow "optimal range" (subregime 2A) consistently lead to high-quality minima that are linearly connected and easily reachable via fine-tuning or weight averaging. The paper also demonstrates that these optimal LRs induce sparse feature learning, focusing the model on the most relevant features for the task, while other LR values fail to show such specialization. These findings transfer to practical settings with standard architectures and datasets.

## Method Summary
The paper uses scale-invariant ResNet-18 and ConvNet architectures trained on CIFAR-10 and synthetic data with fixed learning rates to study three distinct training regimes. Models are pre-trained with different initial learning rates (PLRs) for 200 epochs, then fine-tuned with small fine-tuning learning rates (FLRs) or processed with stochastic weight averaging (SWA). The authors analyze generalization performance, loss landscape geometry (angular distance and error barriers between minima), and feature learning properties (sparsity and relevance). Scale-invariant training is implemented by fixing the last layer, removing affine parameters from normalization layers, and projecting weights to a unit sphere.

## Key Results
- Only initial learning rates in subregime 2A (just above convergence threshold) consistently yield optimal generalization after fine-tuning or weight averaging
- Optimal LRs locate a basin in the loss landscape containing only high-quality minima that are linearly connected
- Training with optimal initial LRs induces sparse feature learning, focusing on the most relevant features (e.g., mid-frequencies in images)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Initial learning rates in subregime 2A locate a basin containing only high-quality minima that are linearly connected
- Mechanism: Training with these LRs causes the optimizer to "bounce between walls" of the basin, preventing convergence to poor local minima
- Core assumption: The loss landscape around these minima is sufficiently smooth and convex to form a connected basin
- Evidence anchors: Abstract states LRs from optimal range locate basin of high-quality minima; section describes bouncing between walls of bowl-shaped basin

### Mechanism 2
- Claim: Optimal initial LRs induce sparse feature learning, focusing on most relevant features
- Mechanism: Large LRs create optimization noise that prevents fitting all features equally, favoring subset of most useful features
- Core assumption: Task-relevant features are sparse and distinguishable from irrelevant features
- Evidence anchors: Abstract mentions sparse set of learned features; section notes NNs learn sparser set of most relevant features as LR increases

### Mechanism 3
- Claim: Too-small LRs lead to unstable minima escapable by increasing LR during fine-tuning; too-large LRs fail to locate good basins
- Mechanism: Small LRs converge to sharp, poor-quality minima; very large LRs cause optimizer to wander without finding useful patterns
- Core assumption: Optimization dynamics are sensitive to initial LR and basin structure is not uniform
- Evidence anchors: Abstract states small LRs lead to unstable minima; section mentions pre-training with small PLRs ends up in unstable minima

## Foundational Learning

- Concept: Scale-invariance in neural networks
  - Why needed here: Controlled scale-invariant training allows accurate control of effective learning rate for studying different initial LR impacts
  - Quick check question: What is the difference between learning rate (LR) and effective learning rate (ELR) in scale-invariant models?

- Concept: Three regimes of training with fixed learning rates
  - Why needed here: Taxonomy categorizes behavior of models trained with different initial LR values and identifies optimal range
  - Quick check question: What are the three regimes of training with fixed learning rates, and how do they differ in model behavior?

- Concept: Feature learning and sparsity
  - Why needed here: Studies how different initial LR values affect sparsity of learned features and their relevance to task
  - Quick check question: How does feature sparsity relate to model generalization, and why might sparse feature learning be beneficial?

## Architecture Onboarding

- Component map: Scale-invariant ResNet-18/ConvNet -> 3-layer MLP (synthetic) -> Vision Transformer (practical) -> Scale-invariant weight constraints -> Fixed LR schedules -> Pre-training/fine-tuning stages

- Critical path:
  1. Choose dataset and architecture
  2. Implement scale-invariant training setup (fix last layer, remove affine params, project weights to unit sphere)
  3. Define learning rate ranges for three regimes
  4. Pre-train models with different initial learning rates
  5. Fine-tune or perform weight averaging on pre-trained models
  6. Analyze generalization, loss landscape geometry, and feature learning properties

- Design tradeoffs:
  - Scale-invariant vs. standard training: Scale-invariant allows more accurate LR control but may not directly translate to standard settings
  - Fixed vs. scheduled LRs: Fixed LRs allow clearer analysis of regimes but may not be optimal for practical training
  - Pre-training vs. training from scratch: Pre-training with optimal initial LRs can lead to better solutions but requires additional stage

- Failure signatures:
  - Poor generalization after fine-tuning: Initial LR may not be in optimal range (subregime 2A)
  - Unstable training dynamics: Initial LR may be too large (subregime 2B or regime 3)
  - Inability to converge: Initial LR may be too small (regime 1)

- First 3 experiments:
  1. Train scale-invariant ResNet-18 on CIFAR-10 with different fixed initial learning rates, observe three regimes
  2. Fine-tune models pre-trained with different initial learning rates, compare generalization performance
  3. Analyze loss landscape geometry and feature learning properties of models trained with different initial learning rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How exactly do properties of learned features relate to characteristics of the basin of solutions found during pre-training?
- Basis in paper: Paper conjectures learning subset of features corresponds to localizing specific region in loss landscape but lacks concrete theoretical framework or empirical evidence
- Why unresolved: While paper observes correlation between feature sparsity and basin quality, it does not establish causal relationship or explain mechanism
- What evidence would resolve it: Experiments manipulating feature properties during pre-training and showing effects on basin shape, size, and solution quality; theoretical analysis connecting feature learning dynamics to loss landscape geometry

### Open Question 2
- Question: Can observed feature sparsity bias towards mid-frequencies in image classification be generalized to other types of features or tasks?
- Basis in paper: Paper shows optimal LRs induce feature sparsity focusing on mid-frequencies in image classification but acknowledges this may not always be the case
- Why unresolved: Paper only explores feature sparsity in context of image classification and synthetic examples, leaving question of generalization to other feature types or tasks
- What evidence would resolve it: Experiments applying methodology to different feature types (temporal in time series, semantic in NLP) and tasks to determine if feature sparsity consistently improves generalization across domains

### Open Question 3
- Question: How does choice of initial learning rate affect model robustness to adversarial attacks or out-of-distribution data?
- Basis in paper: Paper discusses impact of initial LRs on generalization and feature learning but does not explore model robustness to adversarial attacks or out-of-distribution data
- Why unresolved: While paper shows optimal LRs lead to better generalization on training data, it does not investigate whether this translates to improved robustness
- What evidence would resolve it: Experiments evaluating robustness of models trained with different initial LRs to adversarial attacks and out-of-distribution data, comparing performance to models trained with standard LR schedules

## Limitations

- Findings based on controlled scale-invariant training setup may not directly translate to standard training settings with non-invariant architectures
- Optimal initial LR range is narrow, and results may be sensitive to small deviations from this range
- Study focuses on specific architectures (ResNet-18, ConvNet, ViT) and datasets (CIFAR-10, synthetic), generalizability to other settings not fully explored

## Confidence

- High confidence: Existence of three distinct training regimes and observation that optimal initial LRs lead to better generalization after fine-tuning
- Medium confidence: Claim that optimal initial LRs induce sparse feature learning focusing on relevant features - supported by experiments but mechanism needs investigation
- Low confidence: Assertion that loss landscape around optimal minima forms connected basin of high-quality solutions - based on geometric observations but lacks rigorous theoretical foundation

## Next Checks

1. **Transfer to Standard Training Settings**: Validate findings by training standard, non-scale-invariant architectures (ResNet-50, EfficientNet) with different initial learning rates on various datasets (ImageNet, COCO) and comparing generalization performance after fine-tuning.

2. **Robustness to Hyperparameter Variations**: Investigate sensitivity of optimal initial LR range to changes in batch size, optimizer choice, and learning rate schedules to determine if findings hold across wider range of training configurations.

3. **Feature Learning Analysis**: Conduct detailed analysis of features learned with different initial learning rates using feature visualization, ablation studies, and comparison to known feature importance metrics to validate claim that optimal LRs induce sparse, task-relevant feature learning.