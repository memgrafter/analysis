---
ver: rpa2
title: 'One STEP at a time: Language Agents are Stepwise Planners'
arxiv_id: '2411.08432'
source_url: https://arxiv.org/abs/2411.08432
tags:
- step
- task
- language
- agent
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces STEP, a novel framework designed to enhance
  the planning capabilities of language agents through stepwise planning. STEP consists
  of four interconnected components: a Planner that decomposes tasks into subtasks
  and retrieves relevant insights, an Executor that generates action candidates, an
  Evaluator that ensures actions align with learned rules, and a Memory that stores
  experiences for future decisions.'
---

# One STEP at a time: Language Agents are Stepwise Planners

## Quick Facts
- arXiv ID: 2411.08432
- Source URL: https://arxiv.org/abs/2411.08432
- Reference count: 13
- Overall score: 67.4, successfully completing 12 out of 18 tasks

## Executive Summary
This paper introduces STEP, a novel framework designed to enhance the planning capabilities of language agents through stepwise planning. STEP consists of four interconnected components: a Planner that decomposes tasks into subtasks and retrieves relevant insights, an Executor that generates action candidates, an Evaluator that ensures actions align with learned rules, and a Memory that stores experiences for future decisions. The framework was evaluated on the ScienceWorld benchmark, a dynamic, text-based environment for scientific tasks. Results show that STEP consistently outperforms state-of-the-art models, achieving an overall score of 67.4 and successfully completing 12 out of 18 tasks. Notably, STEP achieved first place in 11 tasks, demonstrating its potential as a robust framework for enhancing planning capabilities in language agents within dynamic environments.

## Method Summary
STEP is a four-component framework that enhances language agents' planning capabilities in dynamic environments. The Planner decomposes tasks into subtasks while retrieving relevant insights from memory, the Executor generates action candidates based on these subtasks, the Evaluator ensures actions align with learned rules from previous experiences, and the Memory stores causal abstraction insights and suggested strategies. The framework was evaluated on the ScienceWorld benchmark using gpt-4o-mini as the base LLM, with 5 episodes per task and step limits of 37 for short tasks and 70 for long tasks.

## Key Results
- Achieved an overall score of 67.4 on the ScienceWorld benchmark
- Successfully completed 12 out of 18 tasks
- Ranked first in 11 individual tasks, demonstrating superior performance over state-of-the-art models

## Why This Works (Mechanism)

### Mechanism 1
STEP improves task performance by isolating the Planner's role in high-level task decomposition while keeping the Executor focused on immediate subtasks. The Planner receives the full task context and generates the next subtask, ensuring the Executor does not access irrelevant information (e.g., object locations outside the current subtask scope). This reduces distraction and enforces task sequence. The core assumption is that the Executor's effectiveness depends on receiving distilled, task-relevant subtasks rather than the full task trace. Evidence shows that this isolation prevents the Executor from prematurely interacting with substance B and helps STEP avoid penalties.

### Mechanism 2
STEP's Evaluator enforces action alignment with learned rules from memory, preventing critical errors that cause task resets. The Evaluator compares action candidates against stored causal rules (e.g., "X is necessary for Y") before execution. Actions violating these rules are rejected and sent back for refinement. The core assumption is that memory-stored causal rules from previous trials are sufficient to identify and prevent critical mistakes in future trials. Evidence shows that while the dynamic nature of the environment makes it nearly impossible to construct a world model upfront, the "plan-on-the-go" strategy takes advantage of this flexibility.

### Mechanism 3
STEP's memory system enables continual learning by storing causal abstraction insights, which inform future planning without updating model parameters. After each trial, STEP generates causal abstraction insights (e.g., "X is necessary for Y") and stores them in memory. The Planner retrieves relevant insights for the current subtask, ensuring the Executor benefits from past experiences. The core assumption is that causal abstraction insights derived from trial outcomes are generalizable and improve future task performance. Evidence shows that the notion of insights is well-established in recent research and can encompass pairs of actions and observations, causal verbal reflections, or human feedback.

## Foundational Learning

- Concept: Task decomposition in dynamic environments
  - Why needed here: STEP's Planner must break down complex tasks into manageable subtasks while adapting to environmental changes
  - Quick check question: How does STEP ensure the Executor only focuses on the current subtask without accessing irrelevant information?

- Concept: Memory-based continual learning
  - Why needed here: STEP stores causal abstraction insights from previous trials to inform future decisions without updating model parameters
  - Quick check question: What type of insights does STEP store in memory, and how does the Planner retrieve relevant ones?

- Concept: Rule-based action evaluation
  - Why needed here: STEP's Evaluator prevents critical errors by enforcing alignment between action candidates and learned rules from memory
  - Quick check question: How does the Evaluator determine whether an action candidate violates stored causal rules?

## Architecture Onboarding

- Component map: Planner -> Memory (retrieve insights) -> Executor (generate actions) -> Evaluator (check alignment) -> Memory (store experiences)

- Critical path:
  1. Planner receives task and generates subtask + relevant insights
  2. Executor generates action candidates based on subtask + insights
  3. Evaluator assesses action candidates against learned rules
  4. If approved, action is executed; if not, Executor refines action
  5. After trial completion, Memory updates with new insights and strategy

- Design tradeoffs:
  - Isolating Planner and Executor roles reduces distraction but may delay task completion if subtasks are poorly generated
  - Storing causal abstraction insights enables continual learning but may introduce noise if insights are too abstract or context-specific

- Failure signatures:
  - Poor subtask generation: Agent deviates from intended task sequence, leading to failure
  - Poor strategy generation: Memory stores redundant or unachievable strategies, causing future agents to replicate past mistakes
  - Evaluator errors: Critical mistakes are not caught, leading to large penalties or task resets

- First 3 experiments:
  1. Test Planner isolation: Remove Planner and observe Executor's performance without task decomposition
  2. Test Evaluator rule enforcement: Remove Evaluator and observe agent's ability to avoid critical errors
  3. Test Memory continual learning: Remove Memory and observe agent's performance without access to past insights

## Open Questions the Paper Calls Out

### Open Question 1
How does STEP's Planner component specifically handle task decomposition in environments with hidden or ambiguous goals? The paper mentions that STEP's Planner breaks down tasks into subtasks and retrieves relevant insights, but does not detail the mechanisms for handling hidden or ambiguous goals.

### Open Question 2
What are the limitations of STEP's Evaluator in assessing action candidates that involve complex reasoning or require multi-step planning? The paper describes the Evaluator as ensuring actions align with learned rules but does not specify its limitations in handling complex reasoning tasks.

### Open Question 3
How does STEP's Memory component ensure the retrieval of relevant insights without causing information overload, especially in long-term tasks? The paper mentions that Memory stores experiences for future decisions but does not elaborate on how it manages information overload.

## Limitations

- Evaluation relies heavily on a single benchmark (ScienceWorld) without ablation studies isolating individual component contributions
- Causal abstraction framework for generating insights is referenced but not fully specified
- Paper lacks quantitative comparisons showing how much each component contributes to overall performance improvements

## Confidence

- High confidence: STEP achieves superior performance on ScienceWorld benchmark compared to state-of-the-art models (67.4 overall score, 12/18 tasks completed)
- Medium confidence: The stepwise planning approach with isolated components improves task performance by reducing distraction and enforcing task sequence
- Medium confidence: The Evaluator's rule-based approach prevents critical errors, though the specific rules and their effectiveness are not fully detailed
- Low confidence: The generalizability of causal abstraction insights across different environments and tasks

## Next Checks

1. Conduct ablation studies removing each STEP component individually to quantify their individual contributions to performance improvements
2. Test STEP's performance on alternative dynamic environments beyond ScienceWorld to assess generalizability
3. Implement the causal abstraction framework explicitly and evaluate whether the claimed benefits persist with different insight generation methods