---
ver: rpa2
title: 'Into the crossfire: evaluating the use of a language model to crowdsource
  gun violence reports'
arxiv_id: '2401.12989'
source_url: https://arxiv.org/abs/2401.12989
tags:
- violence
- reports
- human
- rights
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates a BERT-based language model for identifying
  gun violence reports in Brazilian Portuguese Twitter data, partnering with a human
  rights organization. The model, trained on semi-supervised data, achieves 93% accuracy
  and 0.97 AUC score.
---

# Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports

## Quick Facts
- arXiv ID: 2401.12989
- Source URL: https://arxiv.org/abs/2401.12989
- Reference count: 40
- A BERT-based model achieves 93% accuracy in identifying gun violence reports in Brazilian Portuguese Twitter data, improving human rights monitoring efficiency.

## Executive Summary
This study evaluates a BERT-based language model for identifying gun violence reports in Brazilian Portuguese Twitter data, partnering with the human rights organization Fogo Cruzado. The model, trained on semi-supervised data, achieves 93% accuracy and 0.97 AUC score. Integrated into a web application, it was tested in a live intervention with analysts who monitor gun violence events. Qualitative feedback showed improved efficiency and expanded search capabilities, while quantitative analysis revealed increased analyst interactions with online users reporting gun violence. The findings demonstrate that NLP techniques can significantly augment human rights organizations' ability to monitor social media for firearm-related incidents.

## Method Summary
The study fine-tuned BERTimbau, a BERT model for Brazilian Portuguese, using semi-supervised learning with a combination of labeled Twitter messages from Fogo Cruzado and pseudo-labeled data from unlabeled tweets. The model was deployed in a web application that classifies tweets in real-time, allowing analysts to efficiently identify and respond to gun violence reports. A difference-in-differences analysis measured the impact on analyst interactions, while qualitative interviews assessed user experience and trust in the system.

## Key Results
- BERT model achieves 93% accuracy and 0.97 AUC score in classifying gun violence reports
- Analysts report improved efficiency and expanded search capabilities using the web application
- Quantitative analysis shows increased analyst interactions with online users reporting gun violence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuned BERT models can accurately classify gun violence reports in Portuguese Twitter data.
- Mechanism: The model learns semantic patterns in text that distinguish firearm-related events from unrelated posts by training on semi-supervised data.
- Core assumption: Twitter data with geo-filtering and keyword-based labeling contains sufficient signal to train the model.
- Evidence anchors:
  - [abstract] Model achieves 93% accuracy and 0.97 AUC score.
  - [section 4.2] Fine-tuned BERTimbau on Brazilian Portuguese text with semi-supervised learning techniques.
  - [corpus] Average neighbor FMR=0.466 suggests moderate semantic similarity to related NLP framing and violence detection papers.
- Break condition: If training data contains significant false positives (e.g., posts about "tiro" meaning "to take" rather than "shot"), model performance degrades.

### Mechanism 2
- Claim: Real-time web application with BERT model increases analysts' efficiency in monitoring gun violence reports.
- Mechanism: Automated filtering reduces noise, allowing analysts to focus on relevant messages and expand search capabilities beyond geo-restrictions.
- Core assumption: Analysts trust model predictions and adopt the interface for routine monitoring.
- Evidence anchors:
  - [abstract] Qualitative feedback shows improved efficiency and expanded search capabilities.
  - [section 5.2] All analysts adopted the prototype and found it useful for discovering new cases.
  - [corpus] Weak similarity to AR-based narrative change and LLM neutrality papers suggests limited prior work in this domain.
- Break condition: If model latency exceeds 5 minutes or if frequent misclassification erodes trust, adoption drops.

### Mechanism 3
- Claim: Semi-supervised self-training improves model performance on imbalanced Twitter data.
- Mechanism: Pseudo-labels from initial model fine-tuning augment the training set, enhancing recall for rare positive cases.
- Core assumption: Pseudo-labels are mostly correct and do not introduce harmful noise.
- Evidence anchors:
  - [section 4.2] Self-training improved BERTimbau recall by 2 percentage points.
  - [section 4.2] Validation sample of 80 messages confirmed pseudo-label quality.
  - [corpus] No direct evidence; weak analog to general NLP semi-supervised methods.
- Break condition: If pseudo-labels contain >20% errors, the iterative retraining loop can degrade performance.

## Foundational Learning

- Concept: BERT pre-training and fine-tuning
  - Why needed here: Understanding how BERTimbau was adapted from general Portuguese text to gun violence detection task.
  - Quick check question: What is the difference between pre-training and fine-tuning in BERT?

- Concept: Semi-supervised learning and self-training
  - Why needed here: Explaining how the model leverages unlabeled Twitter data to improve performance.
  - Quick check question: How does self-training generate pseudo-labels and use them to augment training data?

- Concept: Difference-in-differences regression design
  - Why needed here: Interpreting the statistical evidence that the intervention increased analyst interactions.
  - Quick check question: What assumptions must hold for difference-in-differences to produce valid causal estimates?

## Architecture Onboarding

- Component map:
  - Twitter API v1 search -> preprocessing (tokenization, emoji conversion) -> BERT model -> web app
  - Web interface: Tabbed view (positive geo, negative geo, positive non-geo) -> tables with text, timestamp, location, bio -> action buttons (view, reply)
  - Backend: Python script runs every 5 minutes -> classifies new tweets -> updates web app

- Critical path:
  1. Collect tweets via API search endpoint
  2. Preprocess text and tokenize
  3. Run BERT classification
  4. Upload results to web interface
  5. Analysts review and interact with users

- Design tradeoffs:
  - 5-minute update interval vs. real-time monitoring needs
  - Fixed keyword set vs. dynamic search flexibility
  - Web app table view vs. TweetDeck column-based interface

- Failure signatures:
  - High false positive rate -> analysts ignore model suggestions
  - Frequent API failures -> data gaps
  - Long text or emoji-heavy posts -> model misclassification

- First 3 experiments:
  1. Validate BERT model on holdout dataset Hreports to confirm 93% accuracy
  2. Deploy prototype to Fogo Cruzado analysts and monitor adoption rate
  3. Run difference-in-differences regression to measure impact on analyst interactions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the BERT model perform on tweets with emojis compared to tweets without emojis?
- Basis in paper: [explicit] The paper mentions that emojis are present in 23% of misclassified messages and that the best-performing model struggles with long text and emojis.
- Why unresolved: The paper does not provide a detailed breakdown of model performance on tweets with and without emojis.
- What evidence would resolve it: A detailed analysis comparing the model's performance on tweets with and without emojis, including precision, recall, and F1-score for each category.

### Open Question 2
- Question: What is the impact of the model on the quality of interactions (e.g., relevance, depth of information) rather than just the quantity?
- Basis in paper: [inferred] The paper mentions an increase in the number of interactions but does not discuss the quality of these interactions.
- Why unresolved: The paper focuses on quantitative metrics but does not explore the qualitative aspects of the interactions.
- What evidence would resolve it: An analysis of the content and quality of interactions before and after the model's implementation, possibly through manual review or user feedback.

### Open Question 3
- Question: How does the model's performance vary across different Brazilian regions with varying levels of gun violence?
- Basis in paper: [explicit] The paper mentions that the model was tested in Rio de Janeiro and Bahia, but does not provide a detailed comparison of performance across regions.
- Why unresolved: The paper does not provide a comprehensive analysis of the model's performance across different regions.
- What evidence would resolve it: A comparative analysis of the model's performance across different regions, including precision, recall, and F1-score for each region.

## Limitations
- Limited generalizability to other human rights organizations or geographic contexts
- Reliance on qualitative feedback from a small sample of analysts
- Potential biases in classification around regional dialects or slang variations within Brazilian Portuguese

## Confidence

- **High confidence**: Model performance metrics (93% accuracy, 0.97 AUC score) - based on clear validation procedures and holdout datasets
- **Medium confidence**: Qualitative feedback about improved analyst efficiency - based on small sample (3 analysts) with potential confirmation bias
- **Medium confidence**: Quantitative analysis showing increased analyst interactions - difference-in-differences design is appropriate but relies on assumptions about parallel trends

## Next Checks

1. Conduct systematic user testing with a larger sample of human rights analysts across different organizations to validate the qualitative findings about improved efficiency and trust in the model.

2. Test the model's performance on Twitter data from other Portuguese-speaking regions (e.g., Portugal, Angola) to assess generalizability and identify potential geographic or dialect-specific biases.

3. Implement bias auditing procedures to examine whether the model systematically misclassifies posts from certain demographic groups or regions within Brazil, particularly those from marginalized communities most affected by gun violence.