---
ver: rpa2
title: 'Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step
  Defences'
arxiv_id: '2406.10427'
source_url: https://arxiv.org/abs/2406.10427
tags:
- accuracy
- input
- standard
- noise
- certified
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes Adaptive Randomized Smoothing (ARS), a framework\
  \ that leverages the composition properties of f-Differential Privacy to provide\
  \ a rigorous analysis of multi-step adaptive models. ARS is applied to image classification\
  \ tasks, specifically targeting L\u221E-bounded adversarial examples."
---

# Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences

## Quick Facts
- arXiv ID: 2406.10427
- Source URL: https://arxiv.org/abs/2406.10427
- Authors: Saiyue Lyu; Shadab Shaikh; Frederick Shpilevskiy; Evan Shelhamer; Mathias Lécuyer
- Reference count: 40
- Key outcome: ARS improves certified accuracy by up to 15 percentage points on CIFAR-10, 30 percentage points on CelebA, and 1.6 percentage points on ImageNet over standard Randomized Smoothing

## Executive Summary
Adaptive Randomized Smoothing (ARS) introduces a novel framework for certified adversarial robustness by leveraging f-Differential Privacy to analyze multi-step adaptive defenses. The key innovation is an adaptive masking step that reduces effective input dimensionality, allowing subsequent noise injection to use lower variance while maintaining the same privacy guarantee. This approach specifically targets L∞-bounded adversarial examples and consistently improves both standard and certified accuracy across multiple image classification datasets.

## Method Summary
ARS is a two-step defense mechanism that combines Gaussian noise injection with adaptive masking. The first step (M1) adds Gaussian noise to the input and produces a mask that weights input pixels based on their relevance. The second step (M2) applies Gaussian noise to the masked input with reduced variance proportional to the mask weights. The final prediction is a weighted average of M1 and M2 outputs. The theoretical foundation relies on f-Differential Privacy composition properties to certify that the multi-step adaptive computation maintains the same privacy guarantee as a single Gaussian mechanism with equivalent total noise.

## Key Results
- On CIFAR-10 with distractor backgrounds, ARS improves certified accuracy by up to 15 percentage points
- On CelebA with spatial variation, ARS improves certified accuracy by up to 30 percentage points at small radii
- On ImageNet, ARS improves certified accuracy by up to 1.6 percentage points over standard RS

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive masking reduces effective input dimension, enabling noise variance reduction in subsequent steps while maintaining the same privacy guarantee.
- Mechanism: The first step adds Gaussian noise and produces a mask that weights input pixels. This mask reduces the effective dimensionality seen by the second step, allowing it to use lower noise variance while preserving the same f-DP privacy bound.
- Core assumption: The mask function w(.) can effectively identify and suppress irrelevant input dimensions without harming classification accuracy.
- Evidence anchors:
  - [abstract] "The key idea is to introduce an adaptive masking step that reduces the effective input dimension, thereby reducing noise variance in subsequent steps"
  - [section] "w(.) is a masking function, adaptively reducing (if wi(m1) ≪ 1) the value of Xi and thereby the attack surface of an L∞ attacker"
  - [corpus] Weak evidence - no direct comparison of dimension reduction effects in related work
- Break condition: If the mask cannot effectively distinguish relevant from irrelevant dimensions, or if the base classifier cannot handle the masked inputs effectively.

### Mechanism 2
- Claim: The composition of multiple Gaussian mechanisms preserves the same overall privacy guarantee as a single Gaussian mechanism with equivalent total noise.
- Mechanism: By leveraging f-DP composition properties, multiple adaptive steps can be composed such that their combined privacy guarantee equals that of a single step with variance equal to the harmonic mean of individual variances.
- Core assumption: f-DP composition is sound and the composition formula accurately captures the privacy loss across adaptive steps.
- Evidence anchors:
  - [abstract] "ARS extends the analysis of randomized smoothing using f-Differential Privacy to certify the adaptive composition of multiple steps"
  - [section] "Applying Theorem 2.3 with q(r∞)2d σ2 1 + (r∞)2d σ2 2 = r∞ q d 1 σ2 1 + 1 σ2 2 concludes the proof"
  - [corpus] Moderate evidence - composition properties are well-established in DP literature but specific to Gaussian mechanisms
- Break condition: If the composition formula doesn't accurately capture privacy loss, or if the adaptive steps introduce dependencies that break the composition assumptions.

### Mechanism 3
- Claim: Test-time adaptivity through input-dependent masking improves both standard and certified accuracy compared to static methods.
- Mechanism: The mask model learns to predict task-relevant regions at test time, reducing noise in those regions while maintaining noise elsewhere. This improves prediction accuracy and increases the separation between most probable and runner-up classes, leading to larger certification radii.
- Core assumption: Input-dependent masking can be learned effectively during training and generalizes to test inputs.
- Evidence anchors:
  - [abstract] "ARS consistently improves certified accuracy over standard Randomized Smoothing and other adaptive baselines, particularly in high-dimensional settings where masking is beneficial"
  - [section] "ARS outperforms all the baselines under distractor backgrounds (k > 32). Static mask is slightly better at k = 32, probably because CIFAR-10 images lack enough 'irrelevant' information for ARS to discard"
  - [corpus] Strong evidence - multiple experiments show consistent improvements across different datasets and noise levels
- Break condition: If the mask model overfits to training data, or if the adaptation introduces instability that harms accuracy.

## Foundational Learning

- Concept: Differential Privacy (DP) and f-Differential Privacy (f-DP)
  - Why needed here: The entire theoretical foundation of ARS relies on DP composition properties to analyze multi-step adaptive defenses while maintaining provable robustness guarantees.
  - Quick check question: What is the key difference between (ϵ, δ)-DP and f-DP in terms of how they quantify privacy?

- Concept: Randomized Smoothing and its connection to DP
  - Why needed here: ARS builds on Randomized Smoothing by reinterpreting it through the lens of DP, enabling the analysis of adaptive multi-step defenses.
  - Quick check question: How does the Gaussian mechanism relate to both Randomized Smoothing and DP?

- Concept: L∞ threat model and its challenges
  - Why needed here: ARS specifically targets L∞-bounded adversarial examples, which present unique challenges due to the √d dependency in traditional RS certification.
  - Quick check question: Why does the L∞ threat model create more challenges for certification in high-dimensional settings compared to L2?

## Architecture Onboarding

- Component map: Input → M1 (noise + mask) → M2 (masked input + noise) → weighted average → base classifier → smoothed prediction
- Critical path: Input → M1 (noise + mask) → M2 (masked input + noise) → weighted average → base classifier → smoothed prediction
- Design tradeoffs:
  - Fixed vs. learned noise budget split: Fixed provides stability but learned could optimize per-dataset
  - Mask model complexity: More complex masks could better identify relevant regions but increase computation
  - Number of noise samples: More samples improve certification accuracy but increase inference time
- Failure signatures:
  - Low standard accuracy with high certified accuracy: Mask model failing to identify relevant regions
  - High standard accuracy with low certified accuracy: Insufficient noise reduction or poor separation between classes
  - Instability across seeds: Mask model overfitting or insufficient training
- First 3 experiments:
  1. Verify baseline RS performance on CIFAR-10 with different noise levels
  2. Implement and test static masking baseline to establish improvement baseline
  3. Add adaptive masking and measure improvement in both standard and certified accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ARS perform on other norms beyond L∞? The paper focuses on L∞-bounded adversaries, but what about L2 or other norms?
- Basis in paper: [inferred] The paper states "Lastly, our adaptive masking technique provides improved certificates for the L∞ norm, but does not have the same effect for other norms such as L2" and suggests that "It is plausible that ARS' adaptivity can lead to improvements under alternative norms, by leveraging different DP mechanisms and updates."
- Why unresolved: The paper explicitly leaves this exploration for future work and does not provide any experimental results or theoretical analysis for norms other than L∞.
- What evidence would resolve it: Experimental results comparing ARS performance on L2 and other norms to standard RS, or theoretical analysis showing how ARS could be adapted for different norms.

### Open Question 2
- Question: What is the optimal noise budget split between M1 and M2 steps in ARS? The paper uses a fixed split of σ1 = σ2 = √2σ, but is this optimal?
- Basis in paper: [explicit] The paper states "In practice, we assign σ1 ≥ σ to M1, and then σ2 = 1/√(1/σ2 − 1/σ1^2). We set σ1 by either fixing it to a constant or learning it end-to-end."
- Why unresolved: The paper only explores a fixed budget split and does not investigate other allocation strategies or compare different splits.
- What evidence would resolve it: Comparative experiments showing ARS performance with different noise budget splits, or an analysis of how the optimal split varies with dataset characteristics or noise levels.

### Open Question 3
- Question: How does ARS combine with other RS improvements like adversarial training, consistency regularization, or denoising by diffusion?
- Basis in paper: [explicit] The paper states "While we empirically show improvement by ARS, it would be interesting and important to investigate how it combines with other RS improvements such as adversarial training (Salman et al., 2019), consistency regularization (Jeong and Shin, 2020), higher order certification (Mohapatra et al., 2020), double sampling (Li et al., 2022b), and denoising by diffusion (Carlini et al., 2022)."
- Why unresolved: The paper does not explore combinations with these other techniques and leaves this as a direction for future work.
- What evidence would resolve it: Experimental results showing ARS performance when combined with one or more of these techniques, compared to each technique individually and to standard RS.

## Limitations

- Limited evaluation scope to L∞ threat model, with no exploration of other norms like L2 or L0
- Focus on relatively standard datasets (CIFAR-10, CelebA, ImageNet) without testing on more challenging or diverse real-world scenarios
- Theoretical analysis relies on f-DP composition properties that may not capture all practical failure modes in multi-step adaptive defenses

## Confidence

- High confidence: The core mechanism of adaptive masking reducing effective dimensionality and the theoretical foundation using f-DP composition
- Medium confidence: The empirical improvements across datasets, as results are consistent but limited to specific experimental setups
- Low confidence: The generalizability of ARS to other threat models (L2, L0) and real-world deployment scenarios

## Next Checks

1. Test ARS performance under L2 threat model to verify if the adaptive masking approach generalizes beyond L∞
2. Evaluate on a dataset with more complex spatial variation (e.g., TinyImageNet or ImageNet-21k subset) to assess scalability
3. Implement and test a multi-step variant with more than two adaptive steps to verify if the composition benefits extend to deeper adaptive pipelines