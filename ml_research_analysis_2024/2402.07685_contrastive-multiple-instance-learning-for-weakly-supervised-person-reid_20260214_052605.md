---
ver: rpa2
title: Contrastive Multiple Instance Learning for Weakly Supervised Person ReID
arxiv_id: '2402.07685'
source_url: https://arxiv.org/abs/2402.07685
tags:
- learning
- person
- dataset
- re-identification
- cmil
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Contrastive Multiple Instance Learning (CMIL),
  a novel framework for weakly supervised person re-identification (ReID) that leverages
  contrastive learning without requiring pseudo labels or multiple models. CMIL addresses
  the challenge of learning from weakly labeled bags of images where only group-level
  identity information is available.
---

# Contrastive Multiple Instance Learning for Weakly Supervised Person ReID

## Quick Facts
- arXiv ID: 2402.07685
- Source URL: https://arxiv.org/abs/2402.07685
- Authors: Jacob Tyo; Zachary C. Lipton
- Reference count: 40
- Key outcome: Introduces CMIL framework achieving state-of-the-art performance on weakly labeled ReID datasets with a single model and no pseudo labels

## Executive Summary
This paper introduces Contrastive Multiple Instance Learning (CMIL), a novel framework for weakly supervised person re-identification (ReID) that leverages contrastive learning without requiring pseudo labels or multiple models. CMIL addresses the challenge of learning from weakly labeled bags of images where only group-level identity information is available. The method optimizes bag representations using contrastive losses while maintaining effective individual image representations through an accumulation network. Extensive experiments demonstrate that CMIL achieves state-of-the-art performance on the WL-market1501 and WL-MUDD datasets, and matches top performance on the large-scale SYSU-30k dataset. Notably, CMIL requires fewer modeling assumptions than competing methods.

## Method Summary
CMIL introduces a framework for weakly supervised person ReID where bags of images contain only group-level identity labels. The method uses a feature extraction network (ResNet-50) to encode individual crops into feature vectors, followed by an accumulation network (set transformer or simpler alternatives like average pooling) to aggregate crop representations into bag representations. Contrastive losses (triplet loss) and identity loss (cross-entropy) optimize bag representations, with an optional alignment loss to encourage similarity between bag and crop representations. The framework requires only a single model and no pseudo labels, distinguishing it from prior work. Mini-bag sampling creates batches from larger bags for training, and the accumulation network must be permutation-invariant to handle variable numbers of crops per bag.

## Key Results
- CMIL achieves state-of-the-art performance on WL-market1501 and WL-MUDD datasets
- CMIL matches top performance on the large-scale SYSU-30k dataset
- Ablation studies reveal average pooling performs nearly as well as set transformer for image aggregation
- Alignment loss does not improve accuracy despite theoretically encouraging closer bag and crop representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimizing bag representations using contrastive losses indirectly optimizes individual crop representations even without explicit alignment.
- Mechanism: The bag representation is a function of crop representations, so minimizing bag-level contrastive loss forces the model to produce crop features that, when aggregated, distinguish between different identities.
- Core assumption: The accumulation function (e.g., average, set transformer) preserves discriminative information from individual crops when forming the bag representation.
- Evidence anchors:
  - [abstract] "CMIL distinguishes itself by requiring only a single model and no pseudo labels while leveraging contrastive losses"
  - [section] "This shift in perspective, of optimizing for bag representations instead of representations of a single image within that bag, is not obvious, mainly because at test time, the goal is still to produce a high-performing ReID model"
  - [corpus] Weak - corpus neighbors focus on person ReID datasets and methods, but do not directly discuss MIL or contrastive learning for weak supervision
- Break condition: If the accumulation function destroys discriminative information from individual crops (e.g., extreme noise or uniform averaging without selection).

### Mechanism 2
- Claim: The alignment loss is ineffective because the model learns to separate bag and crop representations during training, yet crop representations remain discriminative.
- Mechanism: During training, the bag representation and crop representations can diverge while still maintaining good discriminative power at the crop level, as shown by improved rank-1 accuracy even when alignment loss decreases.
- Core assumption: The model can learn useful crop representations without them being close to the bag representation.
- Evidence anchors:
  - [abstract] "Surprisingly, we find that even without the alignment loss, optimizing for high-quality bag representations implicitly leads to high-quality image representations"
  - [section] "Interestingly, the performance of the model (therefore the crop embedding model) continues to improve, even while their embeddings diverge from bag embeddings"
  - [corpus] Weak - no direct corpus evidence on alignment loss behavior in MIL settings
- Break condition: If crop representations become non-discriminative when bag and crop representations diverge significantly.

### Mechanism 3
- Claim: Average pooling for image aggregation performs nearly as well as the set transformer because non-representative crops cancel each other out, leaving a representation close to the representative crops.
- Mechanism: The noise in bags (non-representative crops) is roughly symmetric, so averaging cancels out the noise and preserves the signal from representative crops.
- Core assumption: The non-representative crops are diverse enough that their features average toward zero or a neutral representation.
- Evidence anchors:
  - [section] "Interestingly, the average does well, matching, or nearly matching, the performance of the set transformer. This is surprising as the crops within a representative bag of the bag label are the minority of samples, typically representing less than half of the samples within each bag"
  - [abstract] "Ablation studies reveal the effectiveness of average pooling for image aggregation"
  - [corpus] Weak - no corpus evidence on averaging behavior in MIL settings
- Break condition: If non-representative crops are correlated or biased in a way that prevents cancellation.

## Foundational Learning

- Concept: Multiple Instance Learning (MIL)
  - Why needed here: The problem provides only bag-level labels (presence of a shared identity) without individual crop labels, requiring MIL to learn from weak supervision.
  - Quick check question: In MIL, what is the relationship between the label of a bag and the labels of its instances?

- Concept: Contrastive Learning
  - Why needed here: Re-identification is inherently a contrastive task (matching the same person across different images), and contrastive losses can learn discriminative representations without requiring individual labels.
  - Quick check question: How does contrastive learning differ from classification in terms of the information it uses to update model parameters?

- Concept: Set Transformers and Permutation Invariance
  - Why needed here: The accumulation function must handle variable numbers of crops per bag in any order, requiring permutation-invariant operations.
  - Quick check question: Why must the accumulation function be permutation invariant in this MIL framework?

## Architecture Onboarding

- Component map: Feature extractor (ResNet-50) -> Accumulation network (Set Transformer or pooling) -> Distance metric (cosine/Euclidean) -> Loss functions (Triplet, Cross-entropy, optional alignment)
- Critical path:
  1. Extract features for each crop in a bag
  2. Aggregate crop features into bag representation
  3. Compute contrastive and classification losses on bag representations
  4. Backpropagate gradients to update feature extractor and accumulation network
- Design tradeoffs:
  - Set transformer vs. average pooling: Set transformer is more expressive but computationally heavier; average pooling is simpler and surprisingly effective
  - Bag size: Larger bags provide more diverse crops but may require more computation and careful sampling
  - Alignment loss: Attempts to align crop and bag representations but empirically doesn't improve performance
- Failure signatures:
  - Poor rank-1 accuracy despite good bag-level classification: Indicates the accumulation function isn't preserving discriminative information
  - Alignment loss decreases while accuracy increases: Normal behavior indicating bag and crop representations can diverge while maintaining performance
  - Performance drops significantly with larger bag sizes: May indicate the accumulation function can't handle increased noise
- First 3 experiments:
  1. Compare set transformer vs. average pooling as accumulation functions on WL-Market1501
  2. Test different bag sizes (5, 10, 20 crops) on the same dataset to find optimal noise-to-signal ratio
  3. Evaluate the effect of the alignment loss coefficient (gamma) on both bag and crop representation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the alignment loss fail to improve model performance despite theoretically encouraging closer bag and crop representations?
- Basis in paper: [explicit] The paper states "Surprisingly, in every case, the alignment loss does not improve accuracy" and provides experimental evidence in Table 2 showing gamma=0 for all datasets.
- Why unresolved: The paper observes that bag and crop representations start similar but diverge during training, yet model performance continues to improve. This counterintuitive behavior is consistent across experiments but lacks explanation.
- What evidence would resolve it: Analysis of the relationship between alignment loss values and model accuracy throughout training, investigation of whether specific crop features dominate bag representations, or comparison of crop-to-bag distance distributions between models with and without alignment loss.

### Open Question 2
- Question: What specific mechanism causes average pooling to perform nearly as well as the set transformer for instance aggregation despite non-representative crops being the majority in most bags?
- Basis in paper: [explicit] The ablation study shows "Interestingly, the average does well, matching, or nearly matching, the performance of the set transformer" and suggests non-representative crops might "cancel one another out."
- Why unresolved: The paper proposes a hypothesis about feature cancellation but doesn't verify this mechanism or explore why this mathematical property would consistently emerge across different noise levels and datasets.
- What evidence would resolve it: Empirical analysis of crop feature distributions showing cancellation effects, comparison of feature variance between representative and non-representative crops, or testing alternative aggregation methods that explicitly exploit this cancellation property.

### Open Question 3
- Question: How does the bag sampling strategy (oversampling smaller bags, ensuring multiple bags per label per batch) affect the convergence and final performance of CMIL compared to alternative sampling approaches?
- Basis in paper: [explicit] The implementation details section describes specific bag sampling requirements including oversampling bags smaller than batch size and ensuring valid triplets can always be constructed.
- Why unresolved: The paper presents these sampling requirements as practical necessities but doesn't investigate whether different sampling strategies (e.g., stratified sampling, importance sampling) might yield better performance or faster convergence.
- What evidence would resolve it: Systematic comparison of CMIL performance using different bag sampling strategies, analysis of convergence speed under different sampling regimes, or investigation of how sampling affects the quality of learned bag representations.

## Limitations
- The paper lacks rigorous ablation studies on set transformer architecture, not exploring whether simpler permutation-invariant operations might suffice
- Analysis of why alignment loss doesn't help is limited to observation without deeper theoretical justification
- The WL-MUDD dataset may have limited generalizability due to its specific domain (motorcycle racing) and potential bias from crowd-sourced labeling

## Confidence
- **High confidence**: The core empirical results showing CMIL's state-of-the-art performance on the three benchmark datasets
- **Medium confidence**: The claim that average pooling works nearly as well as the set transformer
- **Medium confidence**: The explanation for why the alignment loss doesn't help

## Next Checks
1. Conduct systematic ablation comparing average pooling, max pooling, sum pooling, and set transformer on all three datasets
2. Perform controlled experiments varying alignment loss coefficient while monitoring both alignment loss values and rank-1 accuracy
3. Test CMIL trained on WL-Market1501 on culturally-diverse ReID benchmarks to assess cross-domain generalization