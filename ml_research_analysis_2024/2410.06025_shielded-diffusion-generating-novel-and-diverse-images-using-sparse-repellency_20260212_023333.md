---
ver: rpa2
title: 'Shielded Diffusion: Generating Novel and Diverse Images using Sparse Repellency'
arxiv_id: '2410.06025'
source_url: https://arxiv.org/abs/2410.06025
tags:
- diffusion
- images
- spell
- repellency
- guidance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SPELL, a training-free method to increase diversity
  of diffusion models while ensuring generated images avoid a reference set. SPELL
  works by sparsely adding repulsive terms to the diffusion SDE trajectory whenever
  the expected output falls within a shield radius around protected images.
---

# Shielded Diffusion: Generating Novel and Diverse Images using Sparse Repellency

## Quick Facts
- **arXiv ID:** 2410.06025
- **Source URL:** https://arxiv.org/abs/2410.06025
- **Reference count:** 40
- **Primary result:** SPELL improves diversity of diffusion model outputs while ensuring generated images avoid reference sets, scaling to protect all 1.2M ImageNet images

## Executive Summary
This paper introduces SPELL, a training-free method to enhance diversity in diffusion models while preventing generated images from overlapping with protected reference sets. The approach works by adding sparse repulsive terms to the diffusion SDE trajectory whenever the expected output falls within a shield radius around protected images. SPELL is demonstrated to significantly improve diversity metrics across multiple state-of-the-art diffusion models while only marginally impacting precision and FID. The method scales to protect all 1.2M ImageNet images, reducing image proximity to training data from 7.6% to 0.16%.

## Method Summary
SPELL modifies the backward diffusion trajectory by adding corrective repulsive terms that activate only when the expected denoised output would fall within a shield radius around protected images. The method uses the diffusion model's denoising network to predict expected outputs at each timestep, then applies sparse corrections based on proximity to the protection set. SPELL can operate with either static reference sets (like ImageNet training data) or dynamically, by updating the protection set at each timestep with expected outputs from concurrently generated images. The approach is both sparse (minimal perturbations, mostly early in generation) and scalable, making it practical for large-scale deployment.

## Key Results
- Improves diversity metrics (recall, Vendi score) by up to 8% while maintaining quality (precision, FID)
- Scales to protect all 1.2M ImageNet training images, reducing protected image proximity from 7.6% to 0.16%
- Outperforms other diversity-inducing methods in quality-diversity tradeoffs
- Dynamic intra-batch repellency creates blue-noise-like coverage of the distribution

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sparse repellency interventions push diffusion trajectories away from shielded images only when the expected output would fall within a radius r of a protected image.
- **Mechanism:** The method computes the expected denoised image at each timestep using the diffusion model's denoising network and checks if it lies within the shield radius of any protected image. If so, it adds a correction vector that pushes the trajectory outward, ensuring the final output lands outside the shielded region.
- **Core assumption:** The shield radius r is small enough that shielded regions do not overlap, allowing independent corrections for each protected image.
- **Evidence anchors:**
  - [abstract] "SPELL works by sparsely adding repulsive terms to the diffusion SDE trajectory whenever the expected output falls within a shield radius around protected images."
  - [section] "We modify the trajectory only for those k that ˆx0 is too close to, giving ∆ = ∑k 1Bk(ˆx0) · δk(ˆx0)"
- **Break condition:** If shields overlap significantly, the correction terms may interfere with each other, potentially failing to guarantee outputs remain outside all shields.

### Mechanism 2
- **Claim:** Repellency interventions are sparse in both time and reference set size, mostly occurring early in generation and affecting few images per timestep.
- **Mechanism:** The ReLU weighting in the correction term ensures it is zero unless the expected output is within radius r of a protected image. Empirically, this happens rarely and mostly early in the backward diffusion process when the trajectory is still exploring.
- **Core assumption:** The diffusion model's trajectory naturally avoids protected images unless they are very close to the expected output, making interventions infrequent.
- **Evidence anchors:**
  - [abstract] "Our method is sparse in the sense that these repellency terms are zero and inactive most of the time, and even more so towards the end of the generation trajectory."
  - [section] "The set of indices k that the ReLU is non-zero for at each individual timestep is usually very small."
- **Break condition:** If the protection set is extremely large or if the diffusion model frequently generates outputs near protected images, sparsity may decrease and computational overhead may increase.

### Mechanism 3
- **Claim:** Dynamic repellency from previously and concurrently generated images increases diversity within batches without requiring retraining.
- **Mechanism:** At each timestep, the expected outputs of all images in the current batch are added to the protection set, and the generation of each image repels from all others in the batch plus previously generated images. This creates a blue-noise-like coverage of the distribution.
- **Core assumption:** The expected outputs from the diffusion model provide a good approximation of where trajectories will land, making dynamic shielding effective.
- **Evidence anchors:**
  - [abstract] "Our method... can be used either with a static reference set... or dynamically, by updating the set at each timestep with the expected images concurrently generated within a batch."
  - [section] "This batch generation produces B samples... and its repellency mechanism uses a time-evolving set of repellency points zk,t = E[X0 | Xt = x(k)t]"
- **Break condition:** If the diffusion model's expected outputs are poor predictors of final outputs, dynamic shielding may fail to prevent collisions effectively.

## Foundational Learning

- **Concept:** Diffusion models and stochastic differential equations (SDEs)
  - Why needed here: SPELL modifies the SDE trajectory by adding corrective terms, so understanding the forward and reverse diffusion processes is essential.
  - Quick check question: What is the relationship between the forward diffusion process and the reverse SDE used for generation?

- **Concept:** Denoising score matching and Tweedie's formula
  - Why needed here: SPELL relies on the denoising network to predict the expected clean image from noisy latents, which is used to determine when to apply repellency.
  - Quick check question: How does Tweedie's formula relate the denoising network output to the expected clean image?

- **Concept:** Classifier-free guidance and conditional diffusion
  - Why needed here: SPELL can be applied to both unconditional and classifier-free guided diffusion models, so understanding how guidance modifies the score function is important.
  - Quick check question: How does classifier-free guidance modify the unconditional score function in text-to-image diffusion models?

## Architecture Onboarding

- **Component map:**
  Diffusion model checkpoint -> Denoising network -> Repellency module -> Neighbor search index -> Scheduler

- **Critical path:**
  1. Initialize noise latents
  2. At each timestep, predict expected clean image using denoising network
  3. Check proximity to protection set
  4. Compute and apply repellency correction if needed
  5. Step backward in diffusion process
  6. Output final image

- **Design tradeoffs:**
  - Sparsity vs protection strength: Larger shield radius provides better protection but may require more frequent interventions
  - Static vs dynamic protection: Static sets are simpler but dynamic sets provide better diversity
  - Runtime vs accuracy: Approximate nearest neighbor search speeds up large set protection but may miss some collisions

- **Failure signatures:**
  - Images falling within shield radius of protected images
  - Excessive runtime due to frequent interventions
  - Visual artifacts from overcompensation
  - Reduced image quality from too strong repellency

- **First 3 experiments:**
  1. Apply SPELL with small radius to a pre-trained diffusion model and verify diversity metrics improve while quality remains stable
  2. Test dynamic intra-batch repellency on a small batch size and verify outputs are diverse within the batch
  3. Scale to a large protection set (e.g., ImageNet training set) and measure protection rate and runtime overhead

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the optimal trade-off between repellency radius and overcompensation factor to maximize diversity while maintaining image quality?
- **Basis in paper:** [explicit] The paper shows that increasing the repellency radius increases diversity but may impact precision, and mentions overcompensation can help finish repellency earlier with stronger effects.
- **Why unresolved:** The paper provides empirical results showing trends but does not systematically explore the full hyperparameter space of repellency radius and overcompensation factor combinations to find optimal Pareto fronts.
- **What evidence would resolve it:** A comprehensive grid search or Bayesian optimization over both parameters, measuring diversity metrics (recall, Vendi score, coverage) against quality metrics (precision, FID, FDDINOv2, CLIP score) to identify optimal parameter combinations for different use cases.

### Open Question 2
- **Question:** How does SPELL's performance compare when using semantic distance measures (e.g., DINOv2 embeddings) instead of L2 distance in latent space?
- **Basis in paper:** [explicit] The paper mentions that "SPELL could also create shields in semantic spaces, e.g., by comparing the DINOv2 embeddings of expected image outputs" and suggests this for future work.
- **Why unresolved:** The paper only implements and evaluates SPELL using L2 distance in the diffusion models' latent spaces, leaving the potential benefits of semantic distance measures unexplored.
- **What evidence would resolve it:** Implementing SPELL with semantic distance measures and comparing diversity and quality metrics against the current L2-based approach across multiple models and datasets.

### Open Question 3
- **Question:** What is the theoretical guarantee for SPELL when shields overlap, and how can the algorithm be improved to handle this case?
- **Basis in paper:** [explicit] The paper acknowledges that "While more complicated projection operators might still yield exact updates in that case, they would involve the resolution of quadratic program" and notes this as a theoretical limitation.
- **Why unresolved:** The paper uses a simple sum of non-overlapping shield corrections that doesn't guarantee exact protection when shields overlap, and the authors haven't developed or tested more sophisticated approaches.
- **What evidence would resolve it:** Mathematical proofs showing either (1) conditions under which the current approach provides exact guarantees even with overlapping shields, or (2) demonstration of a computationally tractable algorithm (e.g., convex hull-based approach) that provides exact guarantees for overlapping shields with acceptable runtime overhead.

## Limitations

- The method's sparsity guarantees depend on shield radius not overlapping, but the paper doesn't quantify how often this occurs in practice
- Dynamic intra-batch repellency effectiveness relies on the denoising network's expected output being a good predictor of final outputs, which isn't empirically validated
- The trade-off between shield radius and generation quality isn't systematically studied across different types of protected content

## Confidence

- **High confidence:** Diversity improvement claims (supported by multiple metrics across several models)
- **Medium confidence:** Shield effectiveness (protection rate measured but spatial distribution of failures not analyzed)
- **Low confidence:** Runtime claims for large protection sets (only one extreme case reported without systematic scaling analysis)

## Next Checks

1. Measure shield overlap frequency empirically across different radii and protection set compositions to validate the sparsity assumption
2. Compare dynamic intra-batch repellency diversity gains against alternative batch sampling strategies like determinantal point processes
3. Profile runtime overhead scaling with protection set size using smaller datasets to extrapolate expected performance for different use cases