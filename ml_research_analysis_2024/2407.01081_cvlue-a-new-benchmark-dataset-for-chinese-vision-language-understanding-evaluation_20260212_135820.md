---
ver: rpa2
title: 'CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation'
arxiv_id: '2407.01081'
source_url: https://arxiv.org/abs/2407.01081
tags:
- uni00000048
- uni00000052
- uni00000044
- uni00000051
- uni0000004c
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces CVLUE, a new Chinese vision-language benchmark\
  \ designed to evaluate models in Chinese cultural contexts, addressing the Western\
  \ bias in existing datasets. CVLUE includes four tasks\u2014image-text retrieval,\
  \ visual question answering, visual grounding, and visual dialogue\u2014using images\
  \ representative of Chinese culture."
---

# CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation

## Quick Facts
- arXiv ID: 2407.01081
- Source URL: https://arxiv.org/abs/2407.01081
- Reference count: 34
- Primary result: CVLUE reveals significant performance gaps for VLMs on Chinese cultural images, which can be improved through fine-tuning on culturally-specific data.

## Executive Summary
This paper introduces CVLUE, a new Chinese vision-language benchmark designed to evaluate models in Chinese cultural contexts, addressing the Western bias in existing datasets. CVLUE includes four tasks—image-text retrieval, visual question answering, visual grounding, and visual dialogue—using images representative of Chinese culture. Experiments reveal that current multilingual vision-language models perform significantly worse on CVLUE compared to English datasets, with poor performance on categories closely tied to Chinese culture. Fine-tuning on Chinese cultural data improves performance, demonstrating the dataset's effectiveness for assessing and enhancing models' understanding of Chinese culture.

## Method Summary
CVLUE is a benchmark dataset for Chinese vision-language understanding that includes four tasks: image-text retrieval, visual question answering, visual grounding, and visual dialogue. The dataset uses images representative of Chinese culture across 92 categories, with separate training, validation, and test splits for each task. The methodology involves evaluating multilingual VLMs in both zero-shot and fine-tuned settings on CVLUE and English counterpart datasets (COCO, VQA-v2, RefCOCOg, Visdial 1.0). The benchmark is constructed by selecting culturally specific images, annotating them for each task, and then using these annotations to create evaluation metrics that compare model performance across cultural contexts.

## Key Results
- Current multilingual VLMs perform significantly worse on CVLUE compared to English datasets, revealing Western bias in training data
- Fine-tuning on Chinese cultural data effectively improves VLM performance on CVLUE tasks
- Category-level analysis shows specific cultural knowledge gaps, with poorest performance on categories most closely tied to Chinese culture

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Chinese vision-language models perform worse on CVLUE because the images are culturally specific and not present in Western-centric pre-training data.
- **Mechanism**: The dataset uses images selected by Chinese native speakers that reflect daily life and cultural elements not found in existing English datasets. When VLMs are evaluated on these images, their performance drops significantly compared to English benchmarks because they lack exposure to these culturally specific visual concepts during pre-training.
- **Core assumption**: Visual concepts tied to Chinese culture are underrepresented or absent in Western-centric image datasets used for pre-training VLMs.
- **Evidence anchors**:
  - [abstract]: "CVLUE includes four tasks... using images representative of Chinese culture. Experiments reveal that current multilingual vision-language models perform significantly worse on CVLUE compared to English datasets"
  - [section]: "Our in-depth category-level analysis reveals a lack of Chinese cultural knowledge in existing VLMs"
  - [corpus]: Found 25 related papers on Chinese vision-language benchmarks, suggesting this is a recognized gap
- **Break condition**: If Chinese cultural concepts are already well-represented in Western datasets, or if VLMs can generalize cultural knowledge without direct exposure.

### Mechanism 2
- **Claim**: Fine-tuning on Chinese cultural data improves VLM performance because it adds culturally specific visual-linguistic associations.
- **Mechanism**: When VLMs are fine-tuned on datasets containing Chinese cultural images and annotations, they learn new mappings between visual features and Chinese language descriptions that were missing from their original training. This targeted learning fills the cultural knowledge gap.
- **Core assumption**: VLMs can effectively learn new visual-linguistic associations through fine-tuning, even if these associations weren't present in original pre-training.
- **Evidence anchors**:
  - [abstract]: "We also find that fine-tuning on Chinese culture-related VL datasets effectively enhances VLMs' understanding of Chinese culture"
  - [section]: "Our in-depth category-level analysis reveals a lack of Chinese culture-related knowledge in existing VLMs and shows that fine-tuning on Chinese culture-related VL datasets can effectively enhance VLMs' VLU capabilities"
  - [corpus]: Related work on Chinese ancient documents and multicultural benchmarks suggests targeted cultural fine-tuning is effective
- **Break condition**: If VLMs cannot learn new cultural associations through fine-tuning, or if the cultural gap is too large to bridge with available fine-tuning data.

### Mechanism 3
- **Claim**: The performance gap between English and Chinese tasks reveals the Western bias in existing VLM training data.
- **Mechanism**: By comparing VLM performance on equivalent tasks in English and Chinese using culturally appropriate images, we can measure the extent of Western bias in the training data. Large performance gaps indicate that the models have learned representations that are heavily skewed toward Western visual concepts.
- **Core assumption**: Equivalent tasks in different languages with culturally appropriate images provide a fair comparison of VLM capabilities across cultures.
- **Evidence anchors**:
  - [abstract]: "Our in-depth category-level analysis reveals a lack of Chinese cultural knowledge in existing VLMs"
  - [section]: "The three large-scale VLMs under the zero-shot setting yield strong performance on the English datasets they are evaluated on... On the other hand, all five models' performance on CVLUE is much lower than that on the English VL dataset"
  - [corpus]: PISA-Bench and VULCA-Bench also evaluate cultural understanding, supporting this mechanism
- **Break condition**: If the tasks are not truly equivalent across languages, or if other factors (like language differences) dominate the performance gap.

## Foundational Learning

- **Concept**: Cultural bias in vision datasets
  - Why needed here: Understanding how dataset composition affects model performance is crucial for interpreting CVLUE results
  - Quick check question: Why do models trained on Western-centric datasets perform poorly on Chinese cultural images?

- **Concept**: Fine-tuning vs zero-shot evaluation
  - Why needed here: The paper compares both approaches to understand how VLMs handle cultural knowledge
  - Quick check question: What's the key difference between evaluating a model in zero-shot vs fine-tuned settings?

- **Concept**: Multimodal representation learning
  - Why needed here: VLMs learn joint representations of vision and language, and cultural gaps affect both modalities
  - Quick check question: How do vision-language models learn to associate visual features with language descriptions?

## Architecture Onboarding

- **Component map**: Image collection → category selection → annotation for each task → benchmark creation → model evaluation → analysis of cultural knowledge gaps
- **Critical path**: Image collection → category selection → annotation for each task → benchmark creation → model evaluation → analysis of cultural knowledge gaps
- **Design tradeoffs**: Balanced coverage of Chinese culture vs dataset size, real photos vs synthetic data, comprehensive tasks vs annotation cost
- **Failure signatures**: Poor performance on culturally-specific categories, inconsistent results across tasks, models failing to recognize common Chinese objects
- **First 3 experiments**:
  1. Evaluate baseline VLMs on CVLUE to establish performance gaps
  2. Fine-tune models on CVLUE data and re-evaluate to measure improvement
  3. Compare performance on translated English versions of CVLUE to test knowledge transfer

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specific types of Chinese cultural knowledge (e.g., traditional festivals, historical artifacts, regional customs) differentially impact the performance of VLMs across different tasks?
- Basis in paper: [explicit] The paper identifies categories "closely related to Chinese culture" versus those with "weakest association with Chinese culture" and shows performance gaps, but doesn't analyze which specific cultural knowledge types are most challenging.
- Why unresolved: The paper only broadly categorizes cultural relevance but doesn't drill down to identify which specific cultural elements cause the most difficulty for VLMs.
- What evidence would resolve it: Detailed performance analysis broken down by specific cultural knowledge types (festivals, historical periods, regional cuisines, etc.) rather than just broad cultural association categories.

### Open Question 2
- Question: What is the minimum amount and type of culturally-specific training data needed to substantially improve VLM performance on Chinese cultural understanding?
- Basis in paper: [inferred] The paper shows that fine-tuning on Chinese cultural data improves performance, but doesn't explore optimal training data size, diversity, or specific data characteristics needed.
- Why unresolved: The paper demonstrates that fine-tuning helps but doesn't establish efficiency thresholds or optimal training data composition.
- What evidence would resolve it: Systematic experiments varying training data quantity, diversity of cultural elements, and cultural specificity to identify minimal effective training requirements.

### Open Question 3
- Question: How do VLMs' cultural understanding capabilities in Chinese compare to their understanding of other non-Western cultures, and what factors drive these differences?
- Basis in paper: [explicit] The paper focuses specifically on Chinese cultural understanding and notes the Western bias in existing datasets, but doesn't compare Chinese performance to other non-Western cultures.
- Why unresolved: The paper establishes a benchmark for Chinese culture but doesn't contextualize this within broader cross-cultural VLM performance patterns.
- What evidence would resolve it: Comparative studies of VLM performance across multiple non-Western cultures with similarly constructed benchmarks to identify common challenges and culture-specific factors.

## Limitations
- The dataset construction process details are not fully specified, particularly how images were selected to represent "Chinese culture" and whether this selection introduces cultural bias
- The exact methodology for category-level analysis and how performance gaps are attributed to cultural knowledge vs other factors remains unclear
- The paper does not provide detailed ablations on the importance of different cultural categories or the minimum dataset size needed to capture cultural concepts

## Confidence

- **High confidence**: The empirical finding that current VLMs perform significantly worse on CVLUE compared to English datasets is well-supported by the experimental results presented
- **Medium confidence**: The claim that this performance gap is primarily due to Western bias in pre-training data, as alternative explanations (language differences, task formulation) are not fully ruled out
- **Medium confidence**: The effectiveness of fine-tuning on Chinese cultural data, as the paper shows improvement but doesn't establish the minimum effective dose or compare against other fine-tuning strategies

## Next Checks
1. Conduct controlled experiments varying the proportion of Chinese cultural images in fine-tuning data to determine the minimum effective dataset size and identify which cultural categories are most critical for performance improvement
2. Implement cross-cultural transfer learning experiments where models trained on CVLUE are evaluated on Western datasets to test bidirectional cultural knowledge transfer
3. Perform ablation studies on the task formulations to ensure that observed performance differences are not due to task-specific factors rather than cultural knowledge gaps