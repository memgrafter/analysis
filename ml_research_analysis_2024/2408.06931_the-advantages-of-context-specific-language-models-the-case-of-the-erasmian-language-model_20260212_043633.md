---
ver: rpa2
title: 'The advantages of context specific language models: the case of the Erasmian
  Language Model'
arxiv_id: '2408.06931'
source_url: https://arxiv.org/abs/2408.06931
tags:
- language
- data
- non-eur
- training
- other
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Erasmian Language Model (ELM) demonstrates that context-specific
  language models can achieve adequate performance for academic use with significantly
  lower computational resources than large-scale models. ELM, a 900M parameter model
  trained exclusively on Erasmus University data, achieved 26% accuracy on MMLU benchmark
  subjects relevant to the university (social sciences, humanities, medicine) compared
  to 23% on unrelated subjects.
---

# The advantages of context specific language models: the case of the Erasmian Language Model

## Quick Facts
- arXiv ID: 2408.06931
- Source URL: https://arxiv.org/abs/2408.06931
- Authors: João Gonçalves; Nick Jelicic; Michele Murgia; Evert Stamhuis
- Reference count: 9
- Primary result: Context-specific 900M parameter model trained on Erasmus University data achieves adequate academic performance at significantly lower cost than large-scale models

## Executive Summary
The Erasmian Language Model (ELM) demonstrates that context-specific language models can achieve adequate performance for academic use with significantly lower computational resources than large-scale models. ELM, a 900M parameter model trained exclusively on Erasmus University data, achieved 26% accuracy on MMLU benchmark subjects relevant to the university (social sciences, humanities, medicine) compared to 23% on unrelated subjects. In a classroom pilot with 23 students, ELM produced coherent academic text that students found aligned with their writing style. The model was trained on a single A10 GPU for 30 days at a cost under €4000, proving that resource-constrained organizations can develop effective, privacy-preserving language models tailored to their specific needs without requiring massive computational infrastructure or external training data.

## Method Summary
ELM uses a scaled-down Llama-2 architecture (900M parameters) trained exclusively on Erasmus University research output and theses (2.7B tokens). The model was pretrained on a single A10 GPU for 30 days at 3 epochs, then fine-tuned with LoRA using Alpaca dataset and English/Dutch instruction pairs. Reinforcement learning from human feedback with direct preference optimization was applied using student-generated preference data. A custom tokenizer with 32K vocabulary was developed, and text was truncated to 256-token chunks during processing.

## Key Results
- ELM achieved 26% accuracy on MMLU benchmark subjects relevant to Erasmus University (social sciences, humanities, medicine) versus 23% on unrelated subjects
- Trained on single A10 GPU for 30 days at under €4000, demonstrating resource-efficient model development
- 23 students in classroom pilot found ELM produced coherent academic text aligned with their writing style

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Context-specific pretraining on domain data enables specialization without massive parameter scaling.
- Mechanism: ELM achieved 26% accuracy on EUR-relevant subjects versus 23% on unrelated subjects by pretraining on exclusively Erasmus University data, allowing the model to develop stronger representations for its target domain.
- Core assumption: Quality of domain-specific training data is more important than quantity for achieving adequate performance in narrow contexts.
- Evidence anchors: [abstract] "ELM, a 900M parameter model trained exclusively on Erasmus University data, achieved 26% accuracy on MMLU benchmark subjects relevant to the university"; [section] "the model specializes in topics related to the social sciences and especially the humanities, in line with the profile of Erasmus university"; [corpus] Found 25 related papers with average FMR=0.491, suggesting moderate relevance to ELM's focus on privacy and efficiency

### Mechanism 2
- Claim: Resource constraints can be overcome through architectural optimization and efficient training strategies.
- Mechanism: ELM was trained on a single A10 GPU for 30 days at under €4000 by using Llama-2 architecture with scaled-down parameters (900M vs 1.7T for GPT-4) and efficient training practices.
- Core assumption: Architectural efficiency gains and focused training objectives can compensate for smaller parameter counts when training data is highly relevant.
- Evidence anchors: [abstract] "ELM was trained on a single A10 GPU for 30 days at a cost under €4000"; [section] "Pretraining of ELM-medium was also conducted on a single Nvidia A10 GPU for 3 epochs, taking a total of 720 hours (30 days) of training"; [corpus] Evidence weak - corpus doesn't directly address training efficiency comparisons

### Mechanism 3
- Claim: Iterative development with end-user feedback ensures model alignment with domain-specific needs.
- Mechanism: ELM-small was tested in classroom settings with 23 students who provided feedback that the model produced coherent academic text aligned with their writing style, informing subsequent development decisions.
- Core assumption: Direct involvement of the target user community in model evaluation and iteration leads to better alignment than generic benchmark optimization.
- Evidence anchors: [abstract] "In a classroom pilot with 23 students, ELM produced coherent academic text that students found aligned with their writing style"; [section] "ELM-small was presented in a public event where participants could interact with the model"; [corpus] Found 25 related papers with average citations=0.0, suggesting limited external validation of this approach

## Foundational Learning

- Concept: Transfer learning and fine-tuning limitations
  - Why needed here: ELM chose to pretrain from scratch on domain data rather than fine-tuning existing models because "the model performed inadequately for academic purposes, resorting to general information more frequently than domain specific information required for Erasmus University"
  - Quick check question: Why did ELM developers choose pretraining from scratch instead of fine-tuning existing models like Llama-2?

- Concept: Context-specific vs general-purpose model tradeoffs
  - Why needed here: ELM demonstrated that context-specific models can achieve adequate performance for specific use cases while being more resource-efficient than general-purpose models
  - Quick check question: What are the key performance differences between ELM and general-purpose models on domain-relevant versus domain-irrelevant tasks?

- Concept: Privacy-preserving model development
  - Why needed here: ELM used only Erasmus University data to avoid privacy risks associated with training on external data sources
  - Quick check question: How does using only institution-specific data impact both model performance and privacy considerations?

## Architecture Onboarding

- Component map: Data collection → Custom tokenizer → Pretraining on domain corpus → LoRA-based fine-tuning → RLHF with DPO → User validation → Deployment
- Critical path: Data collection → Custom tokenizer → Pretraining on domain corpus → LoRA-based fine-tuning → RLHF with DPO → User validation → Deployment
- Design tradeoffs: Smaller parameter count (900M vs 1.7T) for resource efficiency vs reduced general capabilities; exclusive domain data for privacy vs limited generalizability; single GPU training for cost control vs longer training time
- Failure signatures: Poor performance on domain-irrelevant tasks (23% vs 26% accuracy); tendency to go off-topic when prompts are outside training domain; inability to generate coherent long texts due to 256-token chunk truncation
- First 3 experiments:
  1. Compare ELM performance on EUR vs non-EUR MMLU subjects to verify domain specialization
  2. Test different max_length and temperature parameters to optimize text coherence
  3. Evaluate privacy compliance by verifying no external data leakage in model outputs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does ELM's performance generalize to other academic institutions with similar domain focus but different institutional contexts?
- Basis in paper: [explicit] The paper states ELM was specifically trained on Erasmus University data and tested within that context, but questions remain about transferability to other institutions with similar social sciences/humanities focus
- Why unresolved: The paper only tested ELM within one specific institutional context (Erasmus University), making it unclear whether the approach would work equally well at other universities with similar disciplinary focus but different data, cultures, or academic traditions
- What evidence would resolve it: Testing ELM or similar context-specific models at multiple universities with comparable social sciences/humanities orientations, comparing performance across institutions, and analyzing how institutional differences affect model effectiveness

### Open Question 2
- Question: What is the optimal trade-off between model size, training data volume, and computational resources for achieving context-specific academic performance?
- Basis in paper: [inferred] The paper presents ELM with 900M parameters trained on 2.7B tokens from one institution, but doesn't systematically explore how different parameter sizes or data volumes would affect performance in academic contexts
- Why unresolved: The study only presents one configuration (900M parameters, 2.7B tokens) without comparing it to alternatives like smaller models with more focused data, or larger models with broader but still context-specific data
- What evidence would resolve it: Systematic experimentation varying model sizes (e.g., 100M, 500M, 900M, 1.5B parameters) and training data volumes while maintaining context-specificity, measuring performance trade-offs and computational costs

### Open Question 3
- Question: How does ELM's context-specific approach affect long-term knowledge retention and update capabilities compared to general-purpose models?
- Basis in paper: [explicit] The paper notes ELM's limitation in generating coherent long texts and making up words/references, suggesting potential issues with knowledge completeness that could worsen over time
- Why unresolved: The paper only evaluates ELM's current state without examining how its context-specific nature might make it harder to update with new information or maintain accuracy as academic knowledge evolves
- What evidence would resolve it: Longitudinal studies tracking ELM's performance over time, comparing its update mechanisms and knowledge retention to general-purpose models, and testing how easily new academic information can be incorporated into the context-specific framework

## Limitations

- The 3-percentage-point improvement in MMLU accuracy (26% vs 23%) on domain-relevant tasks is modest and may not justify the development effort for all institutions
- The qualitative assessment from 23 students in a single pilot session is insufficient to establish reliability or generalizability of the findings
- The resource efficiency claims require more rigorous cost-benefit analysis to determine practical significance, as 17,000 GPU-hours still represents substantial computational investment

## Confidence

**High Confidence**: The technical implementation details are well-documented and verifiable. The use of Llama-2 architecture with 900M parameters, training on a single A10 GPU for 30 days, and the overall resource consumption figures appear accurate based on the methodology described.

**Medium Confidence**: The performance claims on MMLU benchmarks are credible but limited in scope. The 26% vs 23% accuracy difference on relevant vs unrelated subjects demonstrates domain specialization, but the absolute performance levels are relatively low.

**Low Confidence**: The claims about ELM being "adequate for academic use" and producing "coherent academic text aligned with student writing style" are not well-supported by the evidence provided. The privacy preservation claims, while aligned with the methodology, lack specific security audits or privacy impact assessments.

## Next Checks

1. **Comprehensive Academic Task Evaluation**: Conduct systematic testing of ELM across diverse academic tasks including literature review generation, research paper summarization, statistical analysis explanation, and academic writing assistance. Compare performance against both general-purpose models (fine-tuned on academic data) and other context-specific models using standardized rubrics for factual accuracy, coherence, and task completion.

2. **Extended User Study with Diverse Participants**: Expand the classroom pilot to include multiple institutions, diverse academic disciplines, and extended usage periods. Implement pre/post surveys measuring perceived usefulness, integration with existing workflows, and actual impact on academic productivity.

3. **Privacy and Security Audit**: Conduct a comprehensive privacy impact assessment including differential privacy analysis, membership inference testing, and security vulnerability assessment. Compare ELM's privacy guarantees against both API-based solutions with appropriate data handling agreements and other privacy-preserving model development approaches.