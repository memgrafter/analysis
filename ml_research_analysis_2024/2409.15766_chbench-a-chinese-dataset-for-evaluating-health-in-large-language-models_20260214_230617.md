---
ver: rpa2
title: 'CHBench: A Chinese Dataset for Evaluating Health in Large Language Models'
arxiv_id: '2409.15766'
source_url: https://arxiv.org/abs/2409.15766
tags:
- uni00000013
- uni00000011
- health
- similarity
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CHBench, the first Chinese dataset designed
  to evaluate large language models (LLMs) on health-related tasks, addressing the
  gap in health-focused benchmarks for Chinese LLMs. CHBench includes 6,493 mental
  health entries and 2,999 physical health entries, covering diverse scenarios.
---

# CHBench: A Chinese Dataset for Evaluating Health in Large Language Models

## Quick Facts
- arXiv ID: 2409.15766
- Source URL: https://arxiv.org/abs/2409.15766
- Reference count: 7
- One-line primary result: CHBench is the first Chinese dataset designed to evaluate LLMs on health-related tasks, revealing significant room for improvement in model performance on health queries.

## Executive Summary
This paper introduces CHBench, the first Chinese dataset designed to evaluate large language models (LLMs) on health-related tasks. The dataset addresses the gap in health-focused benchmarks for Chinese LLMs by providing 9,492 entries covering both mental and physical health scenarios. The evaluation uses multiple metrics including cosine similarity and Jaccard similarity to assess response quality against gold-standard responses generated by ERNIE Bot. Experiments with four Chinese LLMs reveal significant performance gaps, particularly in handling complex or sensitive health-related queries.

## Method Summary
The CHBench dataset was constructed from diverse sources including web posts, exams, and existing datasets, resulting in 6,493 mental health entries and 2,999 physical health entries. ERNIE Bot was used to generate gold-standard responses for all entries, which were then scored using multiple metrics including accuracy, safety, practicality, and morality. Four Chinese LLMs (ChatGLM, Qwen, Baichuan, and SparkDesk) were evaluated by comparing their responses to the gold standards using cosine and Jaccard similarity coefficients.

## Key Results
- All four evaluated Chinese LLMs showed significant room for improvement in handling health-related queries
- Models struggled particularly with complex or sensitive topics, often misinterpreting questions or providing inaccurate information
- Qwen model was especially prone to flagging benign queries as toxic
- The evaluation framework revealed gaps in how LLMs manage practical and ethical aspects of health communication

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** ERNIE Bot generates more reliable gold-standard responses than crowdsourced human labels because it is trained on diverse cultural contexts and large-scale text data, reducing subjective bias.
- **Mechanism:** By using ERNIE Bot to evaluate and score prompt-response pairs, the dataset achieves higher consistency and objectivity compared to manual annotations influenced by individual ideologies and cultural backgrounds.
- **Core assumption:** ERNIE Bot's training data sufficiently covers the range of cultural and ethical perspectives needed to evaluate health-related prompts fairly.
- **Evidence anchors:** [abstract] states the dataset uses "powerful Chinese LLM Ernie Bot to generate responses for all entries" and "multiple metrics are employed to assess the quality of the generated responses." [section 3.4.1] explains that differences in cultural backgrounds among annotators pose a challenge, and ERNIE Bot offers "more objective and consistent scoring outcomes." [corpus] shows related work on evaluating LLM safety in Chinese mental health dialogues, supporting the need for culturally grounded evaluation.
- **Break condition:** If ERNIE Bot's training corpus lacks sufficient diversity in health-related cultural contexts, its evaluations may still reflect bias or miss nuanced ethical considerations.

### Mechanism 2
- **Claim:** The use of cosine similarity and Jaccard similarity coefficients provides complementary measures of response quality by capturing both semantic direction and set-based overlap.
- **Mechanism:** Cosine similarity emphasizes the directional relationship between vectors in multidimensional space, while Jaccard similarity focuses on co-occurrence of words, together offering a comprehensive similarity assessment.
- **Core assumption:** The embedding space used for cosine similarity adequately represents semantic meaning for health-related Chinese text.
- **Evidence anchors:** [section 4.2] explains that "cosine similarity is a dimensionless metric frequently used in text data analysis" and "Jaccard similarity coefficient is a set-based metric that calculates the ratio of the intersection to the union of two sets." [section 5] applies these metrics to evaluate responses, showing their use in the experimental design. [corpus] includes studies on LLM evaluation in health contexts, implying the relevance of robust similarity metrics.
- **Break condition:** If the embedding model does not capture domain-specific terminology or cultural nuances in Chinese health language, similarity scores may misrepresent response quality.

### Mechanism 3
- **Claim:** The dataset's construction from diverse sources (web posts, exams, existing datasets) ensures comprehensive coverage of health-related scenarios, improving model evaluation.
- **Mechanism:** By collecting data across multiple domains and sources, the dataset captures a wide range of physical and mental health issues, enabling robust assessment of LLM capabilities.
- **Core assumption:** The selected sources (Zhihu, exams, Ruozhiba) adequately represent the diversity of health-related queries in Chinese contexts.
- **Evidence anchors:** [section 3.2] describes data collection from "web posts, exams, and existing datasets," specifying the domains covered for physical and mental health. [abstract] states the dataset "covers diverse scenarios" and includes "2,999 entries focused on physical health" and "6,493 entries related to mental health." [corpus] references related benchmarks like SafeText and PsychoBench, supporting the importance of diverse data sources.
- **Break condition:** If the sources underrepresent certain health conditions or cultural contexts, the dataset may fail to evaluate LLMs adequately on those scenarios.

## Foundational Learning

- **Concept:** Cultural context in health communication
  - **Why needed here:** Health-related queries often involve culturally specific idioms, expressions, and ethical norms, especially in Chinese contexts, which affect how models interpret and respond.
  - **Quick check question:** How might a Chinese idiom in a health query affect an LLM's response if it lacks cultural context training?

- **Concept:** Similarity metrics in NLP (cosine and Jaccard)
  - **Why needed here:** These metrics quantify how closely model responses align with gold-standard answers, critical for evaluating response quality in open-ended health queries.
  - **Quick check question:** What is the key difference between cosine similarity and Jaccard similarity when applied to text responses?

- **Concept:** Ethical evaluation criteria in AI
  - **Why needed here:** The dataset uses multi-dimensional criteria (accuracy, safety, morality, practicality) to assess responses, ensuring comprehensive evaluation beyond factual correctness.
  - **Quick check question:** Why is it important to include morality and practicality as evaluation criteria for health-related LLM responses?

## Architecture Onboarding

- **Component map:** Data Collection Module -> Gold-Standard Generation -> Evaluation Metrics -> Model Evaluation -> Annotation Pipeline
- **Critical path:**
  1. Collect diverse health-related prompts from multiple sources
  2. Generate gold-standard responses using ERNIE Bot
  3. Score prompt-response pairs using ERNIE Bot with multi-dimensional criteria
  4. Evaluate other models by comparing their responses to gold standards using similarity metrics
  5. Analyze results to identify model strengths and weaknesses
- **Design tradeoffs:** Using ERNIE Bot for gold standards ensures consistency but may inherit its biases or training limitations. Relying on similarity metrics may not capture nuanced differences in response quality, especially for open-ended health queries. Focusing on Chinese health contexts limits generalizability to other languages or cultures.
- **Failure signatures:** High similarity scores but low quality responses due to superficial matching of terms without understanding context. ERNIE Bot generating inappropriate gold standards due to gaps in its training data on rare health conditions. Models flagging benign queries as toxic due to over-sensitivity, as seen with Qwen in the results.
- **First 3 experiments:**
  1. Test ERNIE Bot's gold-standard generation on a small subset of prompts with manual verification to assess consistency and quality.
  2. Compare cosine and Jaccard similarity results on a sample of responses to validate their complementary use.
  3. Evaluate a new Chinese LLM on the dataset to benchmark its performance against the four models studied.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How would CHBench perform if expanded to include multilingual health-related queries beyond Chinese?
- **Basis in paper:** [inferred] The paper explicitly states that CHBench is limited to Chinese health data and does not include other languages, restricting its applicability to multilingual models.
- **Why unresolved:** The dataset's current design focuses solely on Chinese, and the authors acknowledge this as a limitation, suggesting the need for broader language coverage.
- **What evidence would resolve it:** Conducting evaluations using CHBench with multilingual models or extending the dataset to include non-Chinese health-related queries would provide insights into its performance across languages.

### Open Question 2
- **Question:** What are the potential impacts of incorporating rare or emerging health issues into CHBench?
- **Basis in paper:** [inferred] The paper mentions that CHBench primarily focuses on common health scenarios, which may not fully reflect the complexity and diversity of real-world medical situations, especially rare or emerging health issues.
- **Why unresolved:** The dataset's current scope does not address rare or emerging health concerns, leaving a gap in evaluating models' ability to handle such scenarios.
- **What evidence would resolve it:** Expanding CHBench to include rare or emerging health issues and evaluating model performance on these additions would clarify their impact.

### Open Question 3
- **Question:** How would the evaluation results differ if gold-standard responses were generated by a different LLM or human annotators instead of ERNIE Bot?
- **Basis in paper:** [explicit] The paper states that ERNIE Bot was used to generate gold-standard responses, and manual reviews were conducted to verify its assessments, but the authors do not explore alternative methods.
- **Why unresolved:** The reliance on ERNIE Bot as the sole source for gold-standard responses may introduce biases or limitations not addressed in the study.
- **What evidence would resolve it:** Comparing evaluation results using gold-standard responses generated by different LLMs or human annotators would highlight potential differences and biases.

### Open Question 4
- **Question:** What are the specific challenges LLMs face in addressing complex or sensitive health-related queries, as identified in the study?
- **Basis in paper:** [explicit] The paper mentions that models struggle with misinterpreting questions, providing inaccurate information, or failing to effectively manage complex queries, but does not detail specific challenges.
- **Why unresolved:** The study identifies general issues but does not provide a detailed breakdown of the specific challenges encountered by LLMs in health-related contexts.
- **What evidence would resolve it:** A detailed analysis of model responses to complex or sensitive queries, identifying recurring patterns or errors, would clarify the specific challenges faced.

## Limitations
- The use of ERNIE Bot as both evaluator and gold-standard generator introduces potential circular validation
- Limited manual verification raises questions about consistency and appropriateness of generated responses
- The dataset focuses exclusively on Chinese health contexts, limiting generalizability
- Similarity metrics may not fully capture quality of nuanced health advice

## Confidence
- **High confidence** in dataset construction methodology and data diversity
- **Medium confidence** in evaluation framework based on similarity metrics
- **Low confidence** in generalizability to real-world health applications

## Next Checks
1. Conduct manual evaluation of a larger random sample (at least 100 entries) to verify ERNIE Bot's gold-standard responses and assess consistency with human judgment.
2. Test the evaluation framework with a different gold-standard generation method (e.g., human expert consensus) to compare results and validate the similarity metrics' effectiveness.
3. Evaluate the dataset's performance with models from other language families to assess the framework's generalizability beyond Chinese health contexts.