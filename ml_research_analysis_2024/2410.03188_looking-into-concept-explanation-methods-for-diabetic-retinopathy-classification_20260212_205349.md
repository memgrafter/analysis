---
ver: rpa2
title: Looking into Concept Explanation Methods for Diabetic Retinopathy Classification
arxiv_id: '2410.03188'
source_url: https://arxiv.org/abs/2410.03188
tags:
- concepts
- concept
- images
- were
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates two concept-based explanation techniques,
  Testing with Concept Activation Vectors (TCAV) and Concept Bottleneck Models (CBMs),
  for explaining deep neural networks developed for automatic diagnosis of diabetic
  retinopathy (DR) from fundus images. The authors compare the methods using a combination
  of seven open access datasets and evaluate their performance on DR grading and concept
  detection.
---

# Looking into Concept Explanation Methods for Diabetic Retinopathy Classification

## Quick Facts
- arXiv ID: 2410.03188
- Source URL: https://arxiv.org/abs/2410.03188
- Authors: Andrea M. Storås; Josefine V. Sundgaard
- Reference count: 11
- Key outcome: Concept-based explanation techniques (TCAV and CBMs) show promise for explaining diabetic retinopathy classification models, with TCAV outperforming CBMs due to limited concept annotations in available datasets.

## Executive Summary
This paper investigates two concept-based explanation techniques, Testing with Concept Activation Vectors (TCAV) and Concept Bottleneck Models (CBMs), for explaining deep neural networks developed for automatic diagnosis of diabetic retinopathy (DR) from fundus images. The authors compare the methods using seven open access datasets and evaluate their performance on DR grading and concept detection. TCAV and CBMs both show promise in explaining DR grading models, with TCAV outperforming CBMs on DR grading due to the lack of publicly available medical datasets annotated with both concepts and target labels. The authors find that the concept-based explanations align with established medical knowledge about DR, and test time intervention in CBMs results in more accurate model predictions.

## Method Summary
The study combines seven open access datasets (APTOS, DR Detection, Messidor-2, FGADR, DDR, DIARETDB1, IDRiD) containing fundus images annotated with DR grades and segmentation masks for six retinal abnormalities. Inception V3 and DenseNet-121 models are fine-tuned for DR grading, then concept activation vectors are generated using positive and negative example sets. TCAV scores are calculated to measure concept importance, while CBMs are trained with a bottleneck layer predicting concepts before final predictions. The methods are evaluated using accuracy, balanced accuracy, F1 score, Matthews correlation coefficient, and precision metrics.

## Key Results
- TCAV outperforms CBMs on DR grading due to limited concept annotations in available datasets
- Both methods show promise in explaining DR grading models and align with established medical knowledge
- Test time intervention in CBMs leads to more accurate model predictions when concept values are manually corrected
- CBMs perform better on concept detection tasks compared to DR grading

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TCAV provides interpretable explanations by measuring model sensitivity to concept directions
- Mechanism: TCAV trains linear classifiers to separate features from positive/negative concept examples, creating CAVs orthogonal to classification boundaries. TCAV scores measure directional derivatives of model output with respect to CAVs
- Core assumption: Concepts are linearly separable in feature space
- Evidence anchors: Abstract describes TCAV as measuring "relative concept importance" through "sensitivity to changes in input image toward the direction of the concept"
- Break condition: If concepts aren't linearly separable, CAVs won't accurately represent concept directions

### Mechanism 2
- Claim: CBMs provide interpretable explanations by learning to predict target labels from concepts
- Mechanism: CBMs modify deep neural networks to include a bottleneck layer that predicts concepts before the final prediction layer, allowing inspection of concept probabilities
- Core assumption: Target labels can be accurately predicted from concepts alone
- Evidence anchors: Abstract explains CBMs learn concepts together with target labels during training
- Break condition: If concepts don't capture sufficient information for accurate predictions

### Mechanism 3
- Claim: Test time intervention in CBMs improves predictions through manual concept correction
- Mechanism: Predicted concepts are manually adjusted based on training data percentiles (1st and 99th) as surrogates for true concept values
- Core assumption: Training data percentiles accurately represent true concept values
- Evidence anchors: Abstract highlights manual correction of predicted concepts at test time
- Break condition: If training percentiles don't accurately represent true concept values

## Foundational Learning

- Concept: Diabetic Retinopathy (DR) Grading
  - Why needed here: Essential for interpreting results and ensuring explanations align with medical knowledge
  - Quick check question: What are the five levels of DR severity according to Wilkinson et al. (2003) grading system?

- Concept: Concept Activation Vectors (CAVs)
  - Why needed here: Core mechanism behind TCAV for measuring concept importance
  - Quick check question: How are CAVs estimated from positive and negative example sets of images?

- Concept: Bottleneck Models
  - Why needed here: CBMs rely on bottleneck layers to predict concepts before final predictions
  - Quick check question: How does the bottleneck layer in a CBM differ from a standard deep neural network layer?

## Architecture Onboarding

- Component map: Data preparation → Model training → Concept generation → Explanation generation → Test time intervention
- Critical path: Fundus image preprocessing → Model fine-tuning → Concept generation (TCAV/CBM) → Performance evaluation
- Design tradeoffs:
  - TCAV: Requires additional concept data but applicable post-hoc to any trained model
  - CBM: Requires concept annotations in training data but allows test time intervention
- Failure signatures:
  - Low TCAV scores: Poor linear separability of concepts in feature space
  - Poor CBM performance: Insufficient information captured by concepts
  - Ineffective test time intervention: Training percentiles don't represent true concept values
- First 3 experiments:
  1. Train baseline DR grading model (Inception V3 or DenseNet-121) on combined dataset
  2. Generate TCAV concepts using full and masked images focusing on medical findings
  3. Train CBM using FGADR dataset with all six concepts and evaluate on test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TCAV performance compare to CBMs with datasets having limited concept annotations?
- Basis in paper: [explicit] TCAV outperforms CBMs due to lack of datasets annotated with both concepts and target labels
- Why unresolved: Paper doesn't explore TCAV performance with varying levels of concept annotations
- What evidence would resolve it: Experimental results comparing TCAV across datasets with different annotation levels

### Open Question 2
- Question: Can concept-based explanations be validated by medical professionals for clinical relevance?
- Basis in paper: [inferred] Explanations align with medical knowledge but lack medical professional feedback
- Why unresolved: Study focuses on technical performance without clinical validation
- What evidence would resolve it: Feedback from ophthalmologists on explanation relevance and accuracy

### Open Question 3
- Question: How do TCAV and CBMs perform on other medical imaging tasks beyond DR grading?
- Basis in paper: [inferred] Study limited to DR grading without exploration of other medical applications
- Why unresolved: No investigation of generalizability to other medical imaging tasks
- What evidence would resolve it: Application to other medical imaging tasks with performance comparison

## Limitations

- Performance gap between TCAV and CBMs attributed to limited concept annotations in available datasets
- CBMs require more training data and concept annotations to achieve optimal performance
- Test time intervention effectiveness may be limited by accuracy of training data percentiles as concept value surrogates
- Small size and non-uniform distribution of retinal abnormalities pose challenges for concept generation

## Confidence

- High: Concept-based explanations align with established medical knowledge about DR
- Medium: TCAV outperforms CBMs on DR grading due to limited concept annotations
- Low: Test time intervention in CBMs consistently improves model predictions

## Next Checks

1. Collect additional datasets with both concept and target label annotations to train CBMs on larger scale
2. Investigate alternative methods for estimating concept values, such as expert annotations or unsupervised learning techniques
3. Evaluate robustness of TCAV and CBMs to domain shift by testing on datasets from different sources or with different image characteristics