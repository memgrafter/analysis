---
ver: rpa2
title: Deep evolving semi-supervised anomaly detection
arxiv_id: '2412.00860'
source_url: https://arxiv.org/abs/2412.00860
tags:
- data
- learning
- mnist
- continual
- labelled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper formalizes the task of continual semi-supervised anomaly
  detection (CSAD), integrating continual learning, semi-supervised learning, and
  anomaly detection. The authors propose a Variational Autoencoder (VAE) based approach
  enhanced with outlier rejection, using extreme value theory (EVT) to improve data
  generation quality in continual learning.
---

# Deep evolving semi-supervised anomaly detection

## Quick Facts
- arXiv ID: 2412.00860
- Source URL: https://arxiv.org/abs/2412.00860
- Authors: Jack Belham; Aryan Bhosale; Samrat Mukherjee; Biplab Banerjee; Fabio Cuzzolin
- Reference count: 40
- Primary result: Proposes EVT-based outlier rejection for VAE continual semi-supervised anomaly detection, outperforming EWC baselines on MNIST (0.690 AUC) and Fashion-MNIST (0.581 AUC)

## Executive Summary
This paper introduces continual semi-supervised anomaly detection (CSAD), integrating continual learning, semi-supervised learning, and anomaly detection. The authors propose a VAE-based approach enhanced with outlier rejection using extreme value theory (EVT) to improve data generation quality in continual learning. Experiments on MNIST, Fashion-MNIST, and CIFAR-10 demonstrate that the outlier rejection method outperforms baseline approaches like Elastic Weight Consolidation (EWC) and naive training, with ablation studies highlighting the impact of labeled data percentage, distribution, and anomaly inclusion on model performance.

## Method Summary
The approach uses a VAE with classifier loss for semi-supervised anomaly detection, enhanced with outlier rejection in the latent space using Weibull distribution modeling. The method generates representative normal class samples through VAE replay across experiences, filtering low-quality samples before decoding. Experiments compare this approach against EWC, joint training, and naive methods using AUC-ROC scores across MNIST, Fashion-MNIST, and CIFAR-10 datasets with varying labeled data parameters.

## Key Results
- Outlier rejection method achieves 0.690 AUC-ROC on MNIST and 0.581 on Fashion-MNIST, outperforming EWC baselines
- Performance degrades on CIFAR-10, indicating limitations with complex high-dimensional data
- Ablation studies show labeled data percentage, distribution across experiences, and anomaly inclusion significantly impact model performance

## Why This Works (Mechanism)

### Mechanism 1
Outlier rejection improves generative replay quality by filtering low-quality samples before decoding. In the latent space, samples are evaluated against a Weibull distribution fitted to normal class distances from their latent mean. Samples with low outlier probability are rejected before decoding, ensuring only representative data is replayed. Core assumption: Normal class has a coherent latent structure that can be modeled with Weibull distribution.

### Mechanism 2
VAE with classifier loss improves semi-supervised anomaly detection by leveraging limited labeled data. The M2 model uses labeled data to train a classifier alongside the VAE encoder, creating better separation between normal and anomalous classes in latent space. Core assumption: Labeled anomalies are representative of the true anomaly distribution.

### Mechanism 3
Continual learning with generative replay mitigates catastrophic forgetting better than EWC for CSAD. By generating representative normal class samples through VAE with outlier rejection, the model can replay normal distribution patterns across experiences without storing original data. Core assumption: Generated samples accurately represent the normal class distribution.

## Foundational Learning

- **Variational Autoencoder architecture and training**: The core model is a VAE with classifier component, requiring understanding of ELBO, reconstruction loss, and KL divergence. Quick check: What are the three components of VAE loss function and how do they balance?

- **Extreme Value Theory and Weibull distribution**: Outlier rejection uses Weibull distribution to model distances from latent mean for anomaly detection. Quick check: How does fitting a Weibull distribution to distance metrics enable outlier rejection?

- **Catastrophic forgetting in continual learning**: The paper compares generative replay with EWC for mitigating forgetting across experiences. Quick check: What is the fundamental difference between replay-based and regularization-based approaches to catastrophic forgetting?

## Architecture Onboarding

- **Component map**: Input → Encoder → Classifier (if labeled) → Latent space → Outlier rejection → Decoder → Reconstruction
- **Critical path**: Input flows through encoder, optional classifier, latent space with outlier rejection, then decoder for reconstruction
- **Design tradeoffs**: Dense vs convolutional architectures for different dataset complexities; trade-off between computational cost and reconstruction quality
- **Failure signatures**: Low AUC scores indicate poor normal class reconstruction; sudden performance drops suggest catastrophic forgetting
- **First 3 experiments**:
  1. Train VAE on MNIST with varying labeled data percentages to establish baseline performance
  2. Implement outlier rejection on CIFAR-10 to test effectiveness on more complex datasets
  3. Compare generative replay with EWC across Fashion-MNIST experiences to validate continual learning benefits

## Open Questions the Paper Calls Out

1. How does the performance of Outlier Rejection (OR) compare to other continual learning methods on more complex, high-dimensional datasets beyond MNIST and Fashion MNIST? The paper notes OR performs poorly on CIFAR-10 compared to EWC, suggesting the need for enhanced encoder-decoder architectures like convolutional layers.

2. What is the optimal balance between labelled and unlabelled anomalies in each experience to maximize CSAD performance without violating the cluster assumption of semi-supervised learning? Ablation studies show that varying the percentage of unlabelled anomalies affects model performance, with an initial increase followed by a decrease, likely due to violation of the cluster assumption.

3. How does the choice of anomaly detection metric (e.g., reconstruction probability, ELBO, outlier rejection probability) affect CSAD performance, and can combining multiple metrics improve results? The paper uses ELBO as the anomaly detection metric and notes that the outlier rejection probability could not be used due to implementation choices in the probabilistic encoder.

## Limitations

- The EVT-based outlier rejection mechanism lacks rigorous theoretical grounding for its application to VAE latent spaces, and the Weibull distribution assumption may not hold for complex, multi-modal distributions
- Scalability to high-dimensional data like CIFAR-10 is limited, with the proposed method underperforming compared to simpler datasets
- The paper does not adequately address why the model struggles with more complex image data or provide evidence for robustness across different dataset characteristics

## Confidence

- **High Confidence**: Formalization of CSAD as novel task integrating continual learning, semi-supervised learning, and anomaly detection; experimental methodology using AUC-ROC and ablation studies
- **Medium Confidence**: Comparative performance against baseline methods on MNIST and Fashion-MNIST; results show consistent improvement but may not generalize to more complex datasets
- **Low Confidence**: Scalability to high-dimensional data like CIFAR-10; paper lacks adequate explanation for performance degradation on complex images

## Next Checks

1. **Distribution Validation**: Conduct experiments to test the Weibull distribution assumption by comparing outlier rejection performance with alternative distribution models (e.g., Gaussian Mixture Models) on the same latent space distances

2. **Cross-Dataset Robustness**: Evaluate the model on additional datasets with varying characteristics (e.g., medical imaging, industrial sensor data) to assess generalizability beyond standard image benchmarks

3. **Theoretical Analysis**: Develop a mathematical framework connecting EVT properties to VAE latent space geometry, establishing formal guarantees for when outlier rejection will improve anomaly detection performance