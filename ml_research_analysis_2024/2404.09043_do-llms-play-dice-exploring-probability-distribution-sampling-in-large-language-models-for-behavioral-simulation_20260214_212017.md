---
ver: rpa2
title: Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language
  Models for Behavioral Simulation
arxiv_id: '2404.09043'
source_url: https://arxiv.org/abs/2404.09043
tags:
- probability
- distribution
- agents
- distributions
- behavior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether large language models (LLMs) can
  accurately simulate human behavioral sequences that follow specific probability
  distributions, which is crucial for their use as agents in Markov decision processes
  (MDPs). The authors explore this by examining LLM agents' abilities to understand
  and sample from both explicit and implicit probability distributions.
---

# Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation

## Quick Facts
- arXiv ID: 2404.09043
- Source URL: https://arxiv.org/abs/2404.09043
- Reference count: 22
- Primary result: LLMs struggle to reliably simulate human behavior through probability distribution sampling, with limited accuracy especially for implicit distributions

## Executive Summary
This paper investigates whether large language models (LLMs) can accurately simulate human behavioral sequences that follow specific probability distributions, a capability crucial for their use as agents in Markov decision processes (MDPs). The authors systematically evaluate LLM performance in understanding and sampling from both explicit and implicit probability distributions. They find that while LLMs can identify probability distributions when explicitly stated, their ability to generate sequences that match target distributions is limited, particularly for implicit distributions where the distribution must be inferred from examples. The integration of programming tools shows promise for explicit distributions but fails to improve performance on implicit ones.

## Method Summary
The authors conduct experiments across multiple LLMs (including GPT-3.5, GPT-4, and Claude) using a series of carefully designed tasks to evaluate probability distribution sampling capabilities. They employ both synthetic datasets with known distributions and human-generated behavioral sequences. The evaluation framework includes tasks for identifying probability distributions from textual descriptions, sampling from explicit distributions (where probabilities are directly stated), and sampling from implicit distributions (where the model must infer the distribution from examples). The study also tests whether integrating programming tools (like Python code execution) can improve sampling accuracy. Performance is measured using statistical metrics comparing generated sequences to target distributions.

## Key Results
- LLMs can identify probability distributions when explicitly stated in prompts but struggle with sampling accuracy
- Performance on explicit distribution sampling improves with programming tool integration, but remains imperfect
- LLMs show significant limitations in sampling from implicit probability distributions, failing to accurately infer distributions from examples
- Sampling accuracy decreases as sequence length and distribution complexity increase

## Why This Works (Mechanism)
Assumption: The observed limitations in LLM distribution sampling likely stem from their training objective of next-token prediction, which does not explicitly optimize for generating sequences that match specific probability distributions. While LLMs can learn statistical patterns from training data, their ability to deliberately generate sequences conforming to user-specified distributions appears to be an emergent capability that varies in reliability. The integration of programming tools helps with explicit distributions by providing deterministic sampling algorithms, but cannot compensate for the fundamental challenge of inferring distributions from limited examples in implicit cases.

## Foundational Learning
- **Probability distributions**: Understanding different types of distributions (uniform, Bernoulli, etc.) and their properties is essential for evaluating whether LLM-generated sequences match target distributions
- **Markov decision processes (MDPs)**: MDPs provide the framework for behavioral simulation, where agents must make decisions based on state transitions and probability distributions
- **Sequence generation**: The ability to generate coherent sequences that follow specific statistical properties is fundamental to behavioral simulation
- **Statistical testing**: Metrics for comparing generated sequences to target distributions (e.g., chi-square tests, KL divergence) are needed to quantitatively assess sampling accuracy
- **Implicit vs explicit learning**: Distinguishing between distributions that are directly stated versus those that must be inferred from examples is crucial for understanding LLM limitations

## Architecture Onboarding
**Component Map**: LLM Core -> Prompt Processing -> Distribution Identification -> Sequence Generation -> Output Validation

**Critical Path**: The study follows a path from prompt engineering through distribution identification to sequence generation, with evaluation at each stage. The critical limitation appears in the transition from distribution identification to accurate sampling, particularly for implicit distributions.

**Design Tradeoffs**: The choice between explicit and implicit distribution representation creates a fundamental tradeoff - explicit distributions allow for direct sampling but may not reflect real-world scenarios, while implicit distributions are more realistic but significantly harder for LLMs to handle accurately.

**Failure Signatures**: The paper identifies several failure modes: (1) systematic bias in generated sequences that deviates from target distributions, (2) inability to maintain distribution characteristics over longer sequences, and (3) complete failure to infer implicit distributions from limited examples.

**3 First Experiments**:
1. Test basic distribution identification capabilities with varied prompt formulations
2. Evaluate explicit distribution sampling with and without programming tool integration
3. Assess implicit distribution sampling performance using synthetic and human-generated sequences

## Open Questions the Paper Calls Out
Unknown: The paper does not explicitly call out specific open questions, but several emerge from the findings. How can LLM architecture or training approaches be modified to improve implicit distribution sampling? What is the relationship between model size, training data composition, and distribution sampling capabilities? How do these findings generalize to continuous and multimodal distributions that better represent real-world scenarios?

## Limitations
- The study focuses on relatively simple discrete probability distributions, limiting generalizability to more complex real-world scenarios
- Evaluation relies heavily on synthetic data, raising questions about external validity when applied to naturalistic behavioral contexts
- Limited exploration of different prompting strategies and their impact on implicit distribution sampling performance
- The study does not investigate the role of model size or training data composition on distribution sampling capabilities

## Confidence
- **High Confidence**: LLMs can identify probability distributions when explicitly stated in prompts (Section 4.1 findings)
- **Medium Confidence**: Integration of programming tools improves explicit distribution sampling, though the magnitude and generalizability of improvement requires further validation
- **Low Confidence**: Claims about LLMs' inability to sample implicit distributions are based on limited test cases and may not represent broader capabilities

## Next Checks
1. Test LLM sampling performance across a wider range of probability distributions (continuous, multimodal, time-varying) to assess generalizability beyond the current discrete uniform and Bernoulli distributions
2. Conduct human-subject experiments to compare LLM-generated sequences against authentic human behavioral data in real-world decision-making tasks
3. Evaluate the impact of different prompting strategies and few-shot examples on implicit distribution sampling performance, including systematic variation of prompt engineering techniques