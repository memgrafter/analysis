---
ver: rpa2
title: How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model
  Collapse
arxiv_id: '2404.05090'
source_url: https://arxiv.org/abs/2404.05090
tags:
- data
- synthetic
- collapse
- training
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies model collapse, a phenomenon where generative
  models degrade over recursive training on synthetic data. The authors propose a
  statistical framework to characterize the effects of recursive training on language
  models, focusing on statistical approximation error.
---

# How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse

## Quick Facts
- **arXiv ID:** 2404.05090
- **Source URL:** https://arxiv.org/abs/2404.05090
- **Reference count:** 40
- **Primary result:** Model collapse always occurs in fully synthetic training; can be avoided in partially synthetic training with sufficient real data

## Executive Summary
This paper presents a rigorous statistical framework for understanding model collapse in language models trained recursively on synthetic data. The authors prove that when models are trained solely on synthetic data from previous generations, the estimated distributions inevitably converge to degenerate Dirac masses, causing collapse. Through theoretical analysis and empirical validation, they demonstrate that mixing real data with synthetic data can prevent collapse if the real data dominates sufficiently. The framework quantifies the relationship between collapse rates and factors like sample size, initial distribution diversity, and the ratio of real to synthetic data.

## Method Summary
The authors analyze model collapse through recursive training of linear Softmax classifiers on synthetic data. They consider two settings: fully synthetic training (only synthetic data from previous generations) and partially synthetic training (mixture of real and synthetic data). The statistical framework tracks how the estimated conditional probabilities evolve across generations, measuring dispersion and distribution shift. Empirical validation uses both the statistical model and transformer-based experiments on the tiny Shakespeare dataset, tracking metrics like σₘ (dispersion), ∥p(m) - p(1)∥₁ (distribution drift), and validation loss.

## Key Results
- Model collapse always occurs in fully synthetic training due to exponentially decreasing variance of conditional probability estimates
- Partially synthetic training can avoid collapse if the ratio of real to synthetic data exceeds a threshold determined by sample sizes
- The rate of collapse depends on initial distribution diversity (S₀) and sample size (n), with lower diversity and smaller samples accelerating collapse

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model collapse always occurs in fully synthetic training because the variance of the conditional probability estimate decreases exponentially with each generation.
- Mechanism: Each generation model is trained only on synthetic data from the previous generation, creating a Markov chain where variance decreases by factor (1 - 1/n) at each step, driving distribution toward Dirac mass.
- Core assumption: Initial distribution is nontrivial (S₀ < 1 and ∥p(0)∥∞ < 1) and sample size n is finite.
- Evidence anchors: Abstract states collapse cannot be avoided with solely synthetic data; Theorem 1 shows Sm = 1 - (1 - 1/n)ᵐ(1 - S₀).
- Break condition: If n → ∞ or model has infinite capacity to capture true distribution exactly.

### Mechanism 2
- Claim: Partially synthetic training can avoid model collapse if ratio of real to synthetic data is sufficiently large.
- Mechanism: Real data dominates weighted averages of estimated conditional probabilities, bounding variance by 1/N (real data sample size) plus decreasing term.
- Core assumption: Real data is available with large sample size N compared to synthetic sample size n.
- Evidence anchors: Abstract provides estimate for maximal synthetic data below which collapse is avoided; Theorem 2 bounds Sm ≈ S₀ when n ≪ N.
- Break condition: If n/N exceeds bound in Theorem 3, synthetic data dominates and collapse occurs.

### Mechanism 3
- Claim: Rate of collapse depends on diversity of initial distribution and sample size.
- Mechanism: Lower entropy initial distributions (smaller S₀) or smaller support size (smaller s̃) collapse faster; smaller n accelerates collapse by increasing variance.
- Core assumption: Initial distribution has finite support and sample size is finite.
- Evidence anchors: Theorem 1 describes p(m) behavior as function of m, n, and S₀; smaller S₀ corresponds to faster collapse.
- Break condition: If S₀ → 1 (uniform) or n → ∞, collapse rate approaches zero.

## Foundational Learning

- **Concept: Markov chains and absorbing states**
  - Why needed here: Explains why fully synthetic training creates Markov chain where all states converge to absorbing Dirac masses
  - Quick check question: In a Markov chain with absorbing states, what happens to probability of being in transient states as time goes to infinity?

- **Concept: Law of total variance and recursive estimation**
  - Why needed here: Proof relies on recursively applying law of total variance to show how variance decreases across generations
  - Quick check question: If X|Y ~ Binomial(n,Y) and Y ~ Bernoulli(p), what is E[X²]?

- **Concept: Concentration inequalities for multinomial distributions**
  - Why needed here: Theorem 3 uses concentration results to bound deviation between generations in partially synthetic case
  - Quick check question: For multinomial distribution with parameter p and n trials, what is typical scale of ∥p̂ - p∥₁?

## Architecture Onboarding

- **Component map:** Ground truth model p(0) → Recursive generation → Next generation models
- **Critical path:** Ground truth model → Recursive generation → Training with mixture → Evaluation of σₘ and ∥p(m) - p(1)∥₁
- **Design tradeoffs:**
  - Small n speeds up experiments but accelerates collapse in fully synthetic setting
  - Large vocabulary size increases computational cost but better represents real language models
  - One-hot embeddings simplify analysis but differ from transformer embeddings
- **Failure signatures:**
  - σₘ → 1 indicates total collapse (Dirac mass)
  - ∥p(m) - p(1)∥₁ → 0 in fully synthetic indicates convergence to same collapsed distribution
  - Validation loss degradation in fully synthetic indicates functional approximation issues
- **First 3 experiments:**
  1. Implement statistical model with s=3, ℓ=4, verify Theorem 1 by plotting Sm and ρₘ for various n
  2. Implement partially synthetic training, verify Theorem 2 by plotting σₘ for different n/N ratios
  3. Implement transformer-based experiments with tiny Shakespeare, verify distribution drift from Figure 5

## Open Questions the Paper Calls Out

- **Open Question 1:** What is precise relationship between sample size n and expected total collapse time E[T] in fully synthetic setting?
  - Basis in paper: [explicit] Theorem 1 provides bounds on E[T] at least of order n and at most of order n²
  - Why unresolved: Bounds are not sharp; experiments suggest E[T] might be closer to O(n) than O(n²)
  - What evidence would resolve it: More extensive experiments with varying n and initial distributions p(0) to empirically determine relationship

- **Open Question 2:** How does functional approximation error affect model collapse in language models?
  - Basis in paper: [inferred] Paper acknowledges theoretical analysis focuses on statistical approximation error and suggests extending framework to account for functional approximation error
  - Why unresolved: Current framework doesn't incorporate functional approximation error, significant factor in real-world LLMs
  - What evidence would resolve it: Theoretical analysis incorporating functional approximation error, potentially by considering high-dimensional Gaussian vectors as context embeddings

- **Open Question 3:** What is effect of in-context learning on model collapse in transformer-based language models?
  - Basis in paper: [inferred] Paper mentions investigating effect of in-context learning on model collapse could be future extension
  - Why unresolved: Current theoretical framework doesn't account for in-context learning, key feature of transformer models
  - What evidence would resolve it: Theoretical analysis incorporating in-context learning, potentially by considering impact on distribution of synthetic data

## Limitations
- Theoretical framework uses linear Softmax classifier with one-hot embeddings, differing significantly from modern transformer architectures
- Assumes finite support distributions and exact sampling from conditional probabilities, which may not hold for natural language
- Empirical validation uses tiny Shakespeare with limited vocabulary, raising scalability questions to larger models and datasets
- Bounds in Theorem 3 assume independent sampling, not accounting for complex data augmentation and curriculum learning strategies

## Confidence
- **High confidence:** Fully synthetic training inevitably leads to model collapse under stated conditions (rigorous theoretical analysis and consistent empirical results)
- **Medium confidence:** Specific bounds and rates of collapse provided by Theorems 1-3 (mathematical derivations appear sound but practical relevance uncertain)
- **Medium confidence:** Mitigation strategy of mixing real and synthetic data (theoretical upper bound is precise but practical implementation may require additional considerations)

## Next Checks
1. **Scale validation:** Implement experiments with larger transformer models (e.g., GPT-2 small) and larger datasets to verify whether theoretical bounds on synthetic data mixing scale appropriately with model capacity and data diversity
2. **Distribution diversity testing:** Systematically vary initial distribution diversity (S₀) and support size (s̃) in linear model to quantify their precise impact on collapse rates, testing predictions of Theorem 1 beyond specific values reported
3. **Real-world sampling validation:** Compare theoretical predictions with empirical results when synthetic data is generated through actual model sampling (with temperature, top-k, etc.) rather than exact conditional probability sampling, to assess robustness to realistic sampling procedures