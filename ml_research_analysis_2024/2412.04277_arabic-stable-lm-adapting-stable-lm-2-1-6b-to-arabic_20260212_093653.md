---
ver: rpa2
title: 'Arabic Stable LM: Adapting Stable LM 2 1.6B to Arabic'
arxiv_id: '2412.04277'
source_url: https://arxiv.org/abs/2412.04277
tags:
- arabic
- arxiv
- data
- https
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Arabic Stable LM 1.6B, a compact Arabic-centric
  language model with a base and chat version, developed by fine-tuning Stable LM
  2 1.6B on 100 billion Arabic tokens. The chat model achieves state-of-the-art results
  on Arabic cultural alignment and language understanding benchmarks, outperforming
  models with up to 8x more parameters.
---

# Arabic Stable LM: Adapting Stable LM 2 1.6B to Arabic

## Quick Facts
- arXiv ID: 2412.04277
- Source URL: https://arxiv.org/abs/2412.04277
- Reference count: 17
- One-line primary result: Arabic Stable LM 1.6B achieves state-of-the-art results on Arabic cultural alignment and language understanding benchmarks, outperforming models with up to 8x more parameters.

## Executive Summary
This paper introduces Arabic Stable LM 1.6B, a compact Arabic-centric language model developed by fine-tuning Stable LM 2 1.6B on 100 billion Arabic tokens. The model comes in both base and chat versions, with the chat model achieving impressive results on multiple Arabic benchmarks. Key innovations include optimizing tokenization for Arabic text and incorporating synthetic instruction-tuning data via a rephrasing pipeline. The model excels in cloze-format evaluations and demonstrates robustness while maintaining efficiency despite the challenges of overtokization.

## Method Summary
The authors fine-tune Stable LM 2 1.6B on a mixture of Arabic datasets (CulturaX, SANAD, and Arabic E-book corpus) combined with the English training mixture from Bellagente et al. (2024). They employ an early cool down learning rate scheduler and batch size of 96 for base model fine-tuning over 500k steps. For the chat model, they instruction tune on 677,746 samples using ChatML templates, combining rephrased synthetic dialogue data with Instar-500k and Aya Dataset. Evaluation uses ArabicMMLU, CIDAR-MCQ-100, ACV A, and AlGhafa benchmarks with a focus on cloze format for reliability.

## Key Results
- Arabic Stable LM 1.6B chat model outperforms multiple models with up to 8x the parameters on Arabic benchmarks
- Cloze format evaluation proves more robust than multiple-choice format for Arabic LLM assessment
- Synthetic instruction-tuning data mixing improves cultural alignment and language understanding performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Overtokenization in the Stable LM 2 tokenizer reduces Arabic inference throughput, but fine-tuning on 100B+ Arabic tokens compensates by improving model understanding.
- Mechanism: The tokenizer's high fertility score (tokens per word) means more subword tokens are used for Arabic words, increasing inference cost. However, the extensive fine-tuning on large Arabic datasets helps the model learn robust representations despite the suboptimal tokenization.
- Core assumption: The model can learn meaningful Arabic representations even with overtokenization, given sufficient training data.
- Evidence anchors:
  - [abstract]: "Our Arabic Stable LM 1.6B chat model achieves impressive results on several benchmarks beating multiple models with up to 8x the parameters."
  - [section 3.1]: "The Stable LM 2 tokenizer achieves the second-highest fertility after the AceGPT models."
  - [corpus]: Weak evidence; no direct mention of how overtokenization affects downstream performance.
- Break condition: If the tokenizer's fertility score is so high that the model cannot form coherent Arabic representations even after extensive fine-tuning.

### Mechanism 2
- Claim: Mixing synthetic instruction-tuning data improves chat model performance on cultural alignment and language understanding tasks.
- Mechanism: The rephrasing pipeline generates diverse question-answer pairs from Arabic text, augmenting the training data with varied instruction formats. This synthetic data helps the model learn to follow instructions and understand cultural nuances.
- Core assumption: Synthetic data generated via LLM-based rephrasing is diverse and high-quality enough to improve model performance.
- Evidence anchors:
  - [abstract]: "In addition, we show the benefit of mixing in synthetic instruction tuning data by augmenting our fine-tuning data with a large synthetic dialogue dataset."
  - [section 4]: "We create an Arabic instruction-tuning dataset using LLM-based text rephrasing to train our Arabic Stable LM 1.6B chat model."
  - [corpus]: Weak evidence; no direct mention of the quality or diversity of the synthetic data.
- Break condition: If the synthetic data is too repetitive or low-quality, it could introduce noise and degrade performance.

### Mechanism 3
- Claim: The cloze format (CF) is more robust than the multiple-choice format (MCF) for evaluating Arabic LLMs.
- Mechanism: CF requires the model to generate the full answer, reducing the impact of choice randomization and letter symbols that can affect MCF performance.
- Core assumption: CF provides a more accurate measure of the model's understanding than MCF.
- Evidence anchors:
  - [abstract]: "Our fine-tuned models can achieve results on par with models using up to 8x the parameters. In particular, we show that our Arabic Stable LM 1.6B chat model achieves better results on multiple benchmarks in cloze format (CF)."
  - [section 5]: "We use the cloze format (CF) to predict the probability of the correct answer and use the normalized accuracy metric for the final score."
  - [corpus]: Weak evidence; no direct mention of CF vs MCF performance in other studies.
- Break condition: If CF is not a reliable evaluation metric for Arabic LLMs, it could lead to overestimation of model performance.

## Foundational Learning

- Concept: Tokenization and its impact on model performance
  - Why needed here: Understanding how tokenization affects model efficiency and understanding is crucial for optimizing Arabic LLMs.
  - Quick check question: What is the fertility score, and how does it relate to tokenization efficiency?

- Concept: Instruction tuning and its role in improving model performance
  - Why needed here: Instruction tuning helps the model learn to follow instructions and understand cultural nuances, which is essential for Arabic LLMs.
  - Quick check question: What is the difference between base and chat models, and why is instruction tuning important for chat models?

- Concept: Evaluation metrics and their significance in assessing model performance
  - Why needed here: Choosing the right evaluation metrics is crucial for accurately measuring the model's performance on Arabic tasks.
  - Quick check question: What are the advantages of using cloze format (CF) over multiple-choice format (MCF) for evaluating Arabic LLMs?

## Architecture Onboarding

- Component map: Tokenizer -> Pre-training -> Fine-tuning -> Instruction-tuning -> Evaluation
- Critical path: Tokenizer → Pre-training → Fine-tuning → Instruction-tuning → Evaluation
- Design tradeoffs: Tokenization efficiency vs. model understanding, synthetic data quality vs. diversity, evaluation metric robustness vs. simplicity
- Failure signatures: Overtokenization leading to poor inference throughput, synthetic data introducing noise, evaluation metrics not accurately reflecting model performance
- First 3 experiments:
  1. Evaluate the impact of different tokenization strategies on Arabic model performance.
  2. Test the effectiveness of synthetic data in improving model performance on cultural alignment tasks.
  3. Compare the performance of cloze format (CF) and multiple-choice format (MCF) for evaluating Arabic LLMs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does overtokization affect the model's performance and inference efficiency, and can tokenizer transfer mitigate these issues?
- Basis in paper: [explicit] The paper discusses overtokization due to the high fertility rate of the Stable LM 2 tokenizer for Arabic text and suggests tokenizer transfer as a potential solution.
- Why unresolved: The paper acknowledges overtokization as a limitation but does not provide empirical evidence or experiments to quantify its impact on performance or demonstrate the effectiveness of tokenizer transfer.
- What evidence would resolve it: Conducting experiments comparing the model's performance and inference speed with and without tokenizer transfer would provide concrete evidence of the impact of overtokization and the effectiveness of the proposed solution.

### Open Question 2
- Question: How does the synthetic instruction-tuning data affect the model's cultural alignment and understanding, and what are the potential risks of relying on synthetic data?
- Basis in paper: [explicit] The paper introduces a synthetic dialogue pipeline to create instruction-tuning data and mentions the potential risks of synthetic data, such as safety concerns.
- Why unresolved: While the paper demonstrates the effectiveness of synthetic data in improving performance, it does not explore the potential biases or safety issues that might arise from using synthetic data, nor does it provide a thorough evaluation of the model's cultural alignment.
- What evidence would resolve it: Conducting a detailed analysis of the synthetic data's impact on the model's cultural alignment, including bias detection and safety evaluations, would provide insights into the risks and benefits of using synthetic data.

### Open Question 3
- Question: How does the choice of learning rate scheduler (early vs. late cool down) affect the model's performance, and what is the optimal configuration for Arabic language models?
- Basis in paper: [explicit] The paper ablates two different learning rate schedulers (early and late cool down) and observes that the early cool down setup achieves better downstream benchmark performance.
- Why unresolved: The paper does not provide a comprehensive analysis of the impact of learning rate schedulers on the model's performance or explore other potential configurations that might yield better results.
- What evidence would resolve it: Conducting experiments with various learning rate scheduler configurations and analyzing their impact on the model's performance would help identify the optimal setup for Arabic language models.

## Limitations

- Overtokization due to high fertility rate of Stable LM 2 tokenizer for Arabic text reduces inference throughput
- Reliance on synthetic data for instruction tuning introduces potential safety and quality concerns
- Limited empirical validation of cloze format superiority over multiple-choice format for Arabic LLM evaluation

## Confidence

**High Confidence Claims**:
- The model achieves state-of-the-art results on Arabic cultural alignment and language understanding benchmarks
- Fine-tuning on 100B+ Arabic tokens significantly improves performance compared to the base model
- The model outperforms larger models (up to 8x parameters) on several benchmarks

**Medium Confidence Claims**:
- Overtokenization reduces inference throughput but is compensated by extensive fine-tuning
- Synthetic instruction-tuning data improves chat model performance
- Cloze format is more robust than multiple-choice format for Arabic LLM evaluation

**Low Confidence Claims**:
- The quality and diversity of synthetic data generated via rephrasing pipeline
- The long-term stability and safety of the model given reliance on synthetic data
- The generalizability of results across different Arabic dialects and domains

## Next Checks

1. **Tokenization Efficiency Analysis**: Conduct a quantitative comparison of inference throughput between the adapted model and other Arabic models using different tokenization strategies. Measure tokens per second and tokens per word to quantify the impact of overtokenization on practical deployment.

2. **Synthetic Data Quality Audit**: Perform a comprehensive analysis of the synthetic data including diversity metrics, repetition analysis, and human evaluation of data quality. Test model performance with and without synthetic data to isolate its contribution and identify potential noise or bias.

3. **Evaluation Format Robustness Study**: Conduct head-to-head comparisons of cloze format versus multiple-choice format across all Arabic benchmarks used in the paper. Include randomization tests and analyze whether CF consistently provides more reliable results than MCF across different model sizes and datasets.