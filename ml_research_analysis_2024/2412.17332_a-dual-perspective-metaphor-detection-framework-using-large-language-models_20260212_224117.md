---
ver: rpa2
title: A Dual-Perspective Metaphor Detection Framework Using Large Language Models
arxiv_id: '2412.17332'
source_url: https://arxiv.org/abs/2412.17332
tags:
- metaphor
- detection
- guidance
- theories
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a dual-perspective framework for metaphor detection
  using large language models (LLMs). The core idea is to leverage both implicit and
  explicit guidance based on metaphor theories (MIP and SPV) to improve the reliability
  and transparency of LLM-based metaphor detection.
---

# A Dual-Perspective Metaphor Detection Framework Using Large Language Models

## Quick Facts
- arXiv ID: 2412.17332
- Source URL: https://arxiv.org/abs/2412.17332
- Reference count: 34
- Primary result: Achieves state-of-the-art performance on metaphor detection with up to 91.71% accuracy on MOH-X and 73.73% on TroFi datasets

## Executive Summary
This paper introduces a dual-perspective framework for metaphor detection that leverages large language models (LLMs) with both implicit and explicit guidance based on metaphor theories. The framework combines in-context learning through similarity-based retrieval with structured theory-guided reasoning to improve detection reliability and transparency. Experiments demonstrate state-of-the-art performance across widely-used datasets, with significant improvements over previous methods.

## Method Summary
The framework consists of three main components: Implicit Theory-Driven Guidance using a datastore of pre-trained model features for in-context learning, Explicit Theory-Driven Guidance retrieving dictionary information and generating multi-step thoughts, and Self-Judgment validating responses from both perspectives. The approach uses MelBERT representations based on MIP and SPV metaphor theories to create embeddings for similarity retrieval, while also employing dictionary definitions and structured reasoning to guide LLM predictions. The final answer is synthesized through joint consideration of both implicit and explicit perspectives.

## Key Results
- Achieves 91.71% accuracy on MOH-X dataset, outperforming previous LLM-based approaches
- Reaches 73.73% accuracy on TroFi dataset, demonstrating effectiveness on longer, more complex sentences
- Shows consistent improvements across both accuracy and F1-score metrics compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual-perspective retrieval improves LLM reasoning by combining implicit feature similarity with explicit theory-guided reasoning
- Mechanism: The framework retrieves k nearest neighbors from a datastore built using MIP and SPV theory-based embeddings. These retrieved samples are combined with explicit theory-based multi-step thoughts and dictionary information to form prompts for the LLM. The self-judgment mechanism then synthesizes responses from both perspectives to produce a final answer
- Core assumption: LLM reasoning benefits from both similarity-based in-context learning and structured theory-based reasoning
- Evidence anchors: [abstract] "The framework consists of three parts: Implicit Theory-Driven Guidance (using a datastore of pre-trained model features for in-context learning), Explicit Theory-Driven Guidance (retrieving dictionary information and generating multi-step thoughts), and Self-Judgment (validating responses from both perspectives)"

### Mechanism 2
- Claim: The datastore built using MIP and SPV theory-based embeddings provides effective implicit guidance for LLM reasoning
- Mechanism: The datastore is created offline using a pre-trained MelBERT model. For each sample, the MIP theory learns representations by concatenating the target word embedding with its context embedding, while SPV theory learns representations by concatenating the sentence representation with the target word's context embedding
- Core assumption: The MIP and SPV theory-based embeddings capture meaningful semantic relationships that can guide LLM reasoning through similarity-based retrieval
- Evidence anchors: [section II.B.1] "In detail, given a sentence s and a target word wt, we first utilize NLTK to obtain the lemma of wt. Next, we search for definitions and relevant usage examples of the lemma from the Oxford Dictionary."

### Mechanism 3
- Claim: The self-judgment mechanism improves prediction reliability by synthesizing responses from both implicit and explicit perspectives
- Mechanism: After obtaining responses from both implicit theory-driven guidance and explicit theory-driven guidance, the LLM acts as a judge to evaluate these responses and provide a final answer
- Core assumption: LLM reasoning can effectively evaluate and synthesize responses from different perspectives to produce more reliable predictions
- Evidence anchors: [section II.D] "With the responses Rim and Rex, the final outputs are derived through a joint consideration of these two perspectives"

## Foundational Learning

- Concept: Metaphor detection and metaphor theories (MIP and SPV)
  - Why needed here: The framework is built specifically to leverage metaphor theories for guiding LLM reasoning in metaphor detection tasks
  - Quick check question: Can you explain the difference between MIP theory (target word's basic meaning conflicts with contextual meaning) and SPV theory (statistical anomalies in word combinations)?

- Concept: In-context learning and retrieval-augmented generation
  - Why needed here: The framework uses in-context learning by retrieving similar samples from a datastore, and retrieval-augmented generation by retrieving dictionary information to guide LLM reasoning
  - Quick check question: How does in-context learning differ from fine-tuning, and why might it be beneficial for metaphor detection tasks?

- Concept: Large language model reasoning and chain-of-thought prompting
  - Why needed here: The framework relies on LLMs to perform reasoning tasks, including generating multi-step thoughts based on metaphor theories and acting as a judge to synthesize responses
  - Quick check question: What is chain-of-thought prompting, and how might it help LLMs perform better on reasoning tasks like metaphor detection?

## Architecture Onboarding

- Component map: Datastore creation -> Implicit theory-driven guidance -> Explicit theory-driven guidance -> Self-judgment -> Final output

- Critical path:
  1. Create datastore offline using MelBERT embeddings based on MIP and SPV theories
  2. During inference, compute MelBERT embeddings for input sample
  3. Retrieve k nearest neighbors from datastore
  4. Retrieve dictionary information for target word
  5. Generate multi-step thoughts based on metaphor theories
  6. Form prompts combining retrieved samples, dictionary information, and multi-step thoughts
  7. Obtain responses from LLM using both implicit and explicit guidance
  8. LLM judge evaluates and synthesizes responses to produce final answer

- Design tradeoffs:
  - Datastore size vs. retrieval accuracy: Larger datastores may provide more relevant samples but increase retrieval time
  - k value selection: Higher k values provide more in-context examples but may include less relevant samples
  - Dictionary source selection: Oxford Dictionary provides comprehensive definitions but may have licensing restrictions
  - LLM model selection: GPT-4o provides better reasoning capabilities but at higher cost compared to GPT-3.5 turbo

- Failure signatures:
  - Poor metaphor detection performance: May indicate issues with datastore embeddings, retrieval parameters, or LLM reasoning capabilities
  - Inconsistent self-judgment results: May indicate conflicts between implicit and explicit guidance that the LLM judge cannot effectively resolve
  - High inference latency: May indicate inefficient datastore queries or overly complex prompts

- First 3 experiments:
  1. Test datastore retrieval effectiveness by checking if retrieved samples are semantically similar to input samples using human evaluation
  2. Evaluate the impact of k value on metaphor detection performance by testing different k values (e.g., 4, 8, 16) on a validation set
  3. Compare performance of different LLM models (GPT-3.5 turbo vs. GPT-4o) on the same framework to assess the impact of model reasoning capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DMD scale with different values of k in the Implicit Theory-Driven Guidance, and is there an optimal value that balances computational efficiency with detection accuracy?
- Basis in paper: [explicit] The paper mentions that the value of k is set to 8 in Implicit Theory-Driven Guidance but does not explore how different values of k might affect performance
- Why unresolved: The paper does not provide experimental results or analysis on how varying k impacts the framework's effectiveness, leaving uncertainty about the optimal trade-off between accuracy and efficiency
- What evidence would resolve it: Conducting experiments with different k values and analyzing their impact on both accuracy and computational resources would provide insights into the optimal configuration for the framework

### Open Question 2
- Question: How does DMD perform on metaphor detection tasks involving less common or domain-specific metaphors, such as those found in scientific or technical texts?
- Basis in paper: [inferred] The paper focuses on general metaphor detection using widely-used datasets like MOH-X and TroFi, but does not address the framework's adaptability to specialized domains
- Why unresolved: The current evaluation does not cover domain-specific metaphor detection, which may involve different linguistic patterns and require additional fine-tuning of the model
- What evidence would resolve it: Testing DMD on domain-specific datasets and analyzing its performance and adaptability would clarify its effectiveness in specialized contexts

### Open Question 3
- Question: Can DMD be extended to detect metaphors in languages other than English, and what challenges might arise in adapting the framework for multilingual metaphor detection?
- Basis in paper: [inferred] The paper focuses on English datasets and does not discuss the potential for multilingual applications or the challenges involved in such an extension
- Why unresolved: The current framework relies on English-specific resources like the Oxford Dictionary and pre-trained models, which may not be directly applicable to other languages without significant modifications
- What evidence would resolve it: Developing and testing a multilingual version of DMD, along with an analysis of the challenges and solutions for adapting the framework, would provide insights into its potential for broader linguistic applications

## Limitations
- Limited evaluation scope: Tested only on two metaphor detection datasets (MOH-X and TroFi) with relatively clean annotations
- Implementation details missing: Critical details about datastore construction, prompt templates, and self-judgment mechanism are underspecified
- Computational cost unclear: The framework requires multiple LLM calls and datastore operations, but inference time and cost implications are not discussed

## Confidence
- High: The general architecture and dual-perspective approach is sound and theoretically justified
- Medium: The experimental results showing state-of-the-art performance are credible but limited in scope
- Low: Specific implementation details required for faithful reproduction are missing

## Next Checks
1. Conduct human evaluation of retrieved samples to verify they are semantically relevant and capture the intended metaphor theory relationships
2. Systematically remove either the implicit or explicit guidance components and measure performance degradation to quantify each perspective's contribution
3. Evaluate the framework on a held-out metaphor detection dataset not used in the original experiments to assess generalization beyond training domains