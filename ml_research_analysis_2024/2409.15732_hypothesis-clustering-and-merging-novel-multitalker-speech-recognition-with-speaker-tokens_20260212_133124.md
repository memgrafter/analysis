---
ver: rpa2
title: 'Hypothesis Clustering and Merging: Novel MultiTalker Speech Recognition with
  Speaker Tokens'
arxiv_id: '2409.15732'
source_url: https://arxiv.org/abs/2409.15732
tags:
- speaker
- speech
- speakers
- recognition
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses overlapped speech recognition in multi-speaker
  environments using a novel method called Hypothesis Clustering and Merging (HCM).
  The core idea is to use speaker clustering to generate special speaker tokens, which
  are then used to condition recognition hypotheses during decoding.
---

# Hypothesis Clustering and Merging: Novel MultiTalker Speech Recognition with Speaker Tokens

## Quick Facts
- arXiv ID: 2409.15732
- Source URL: https://arxiv.org/abs/2409.15732
- Reference count: 40
- Primary result: 55% relative WER reduction on clean data and 36% on noisy data for 3-speaker overlapped speech recognition

## Executive Summary
This paper introduces Hypothesis Clustering and Merging (HCM), a novel approach for overlapped speech recognition that eliminates the need for explicit speaker enumeration. The method uses k-means clustering of speaker embeddings to generate speaker tokens, which are then used to condition multiple recognition hypotheses during decoding. These hypotheses are clustered using agglomerative hierarchical clustering based on normalized edit distance and merged using ROVER. Experiments on LibriMix show significant improvements over serialized output training, particularly in clean conditions, while maintaining reasonable performance in noisy environments.

## Method Summary
HCM addresses overlapped speech recognition by first clustering speaker embeddings from TitaNet-large using k-means to create discrete speaker tokens. During training, these tokens are prepended to transcriptions, allowing the model to learn speaker-conditioned representations. An attention-based encoder-decoder model with Conformer encoder and joint CTC/attention training is used. At inference, multiple hypotheses are generated using different speaker tokens, clustered using AHC based on normalized edit distance, and merged using ROVER. This approach eliminates the need for prior speaker count knowledge while improving recognition accuracy through multiple hypothesis generation and intelligent merging.

## Key Results
- Achieved 55% relative WER reduction on clean 3-speaker LibriMix data compared to SOT baseline
- Demonstrated 36% relative WER reduction on noisy 3-speaker conditions
- Showed strong speaker counting accuracy, particularly for 1- and 2-speaker scenarios
- Maintained competitive performance with only 32 speaker clusters versus 1024 clusters

## Why This Works (Mechanism)

### Mechanism 1
Speaker tokens derived from k-means clustering reduce permutation ambiguity during multi-speaker recognition by transforming the permutation-invariant problem into a fixed mapping problem. By clustering speaker embeddings into discrete classes and prepending these tokens to transcriptions during training, the model learns to associate each speaker cluster with its corresponding text.

### Mechanism 2
Multiple hypothesis generation followed by agglomerative hierarchical clustering (AHC) resolves speaker count ambiguity without prior knowledge. The model generates multiple recognition hypotheses conditioned on different speaker tokens, and AHC groups similar transcriptions based on normalized edit distance, allowing the number of speakers to emerge from clustering.

### Mechanism 3
ROVER-based merging improves transcription accuracy by resolving word-level ambiguities through majority voting. Within each AHC cluster, multiple recognition hypotheses are aligned and merged using ROVER, where the most frequent word at each position is selected, effectively reducing recognition errors.

## Foundational Learning

- **K-means clustering of speaker embeddings**: Creates discrete speaker tokens that can be predicted and used as prompts during decoding. *Quick check: How does the number of k-means clusters affect the granularity of speaker differentiation and model performance?*
- **Normalized edit distance for text comparison**: Provides a metric to cluster recognition hypotheses based on transcription similarity rather than speaker identity. *Quick check: What happens to AHC clustering if the normalized edit distance threshold is set too high or too low?*
- **ROVER (Recognizer Output Voting Error Reduction)**: Merges multiple recognition hypotheses within each speaker cluster to improve final transcription accuracy. *Quick check: How does ROVER handle cases where no single word appears more than once at a given position across hypotheses?*

## Architecture Onboarding

- **Component map**: Conformer encoder (12 layers) â†’ Attention