---
ver: rpa2
title: 'QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou'
arxiv_id: '2411.11739'
source_url: https://arxiv.org/abs/2411.11739
tags:
- item
- code
- multi-modal
- representation
- qarm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents QARM, a quantitative alignment multi-modal
  recommendation framework that addresses two key challenges in industrial recommendation
  systems: representation unmatching between pre-trained multi-modal models and downstream
  tasks, and representation unlearning where multi-modal features cannot be updated
  during training. The proposed framework consists of an item alignment mechanism
  that fine-tunes multi-modal representations using business-specific interaction
  data, and a quantitative code mechanism that converts aligned representations into
  learnable semantic IDs using vector quantization and residual quantization techniques.'
---

# QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou

## Quick Facts
- arXiv ID: 2411.11739
- Source URL: https://arxiv.org/abs/2411.11739
- Reference count: 37
- Primary result: Achieved 9.704% revenue increase in advertising and 2.296% GMV increase in online shopping at Kuaishou

## Executive Summary
This paper presents QARM, a quantitative alignment multi-modal recommendation framework that addresses two key challenges in industrial recommendation systems: representation unmatching between pre-trained multi-modal models and downstream tasks, and representation unlearning where multi-modal features cannot be updated during training. The proposed framework consists of an item alignment mechanism that fine-tunes multi-modal representations using business-specific interaction data, and a quantitative code mechanism that converts aligned representations into learnable semantic IDs using vector quantization and residual quantization techniques. When deployed at Kuaishou, QARM achieved significant improvements including 9.704% revenue increase in advertising and 2.296% GMV increase in online shopping, while showing particular effectiveness for cold-start and long-tail items.

## Method Summary
QARM addresses industrial recommendation challenges through two key mechanisms. The item alignment mechanism fine-tunes pre-trained multi-modal models using business-specific interaction data via a pre-order alignment model that generates item-to-item pairs from existing retrieval models, then applies batch contrastive loss to align representations with real user-item interaction patterns. The quantitative code mechanism converts these aligned representations into learnable semantic IDs through vector quantization (VQ) and residual quantization (RQ) techniques, creating discrete codes that can be updated during downstream training. The framework uses VQ codes to capture local neighborhood relationships through top-k similar item neighbors, while RQ codes encode hierarchical residual paths representing the entire representation structure. The downstream recommendation model then uses these semantic IDs as learnable features in a multi-task prediction module.

## Key Results
- Achieved 9.704% revenue increase in advertising and 2.296% GMV increase in online shopping
- Showed particular effectiveness for cold-start and long-tail items
- Improved AUC, UAUC, and GAUC metrics in offline evaluation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The item alignment mechanism resolves representation unmatching by fine-tuning the pre-trained multi-modal model using downstream business interaction data.
- Mechanism: A pre-order alignment model is trained to generate item-to-item pairs from existing retrieval models, then uses batch contrastive loss to align multi-modal representations with real business user-item interaction patterns.
- Core assumption: The real-time user-item interaction data from downstream tasks contains sufficient business-specific signal to guide meaningful representation alignment.
- Evidence anchors:
  - [abstract] "The pre-trained multi-modal model is always supervised by the classic NLP/CV tasks, while the recommendation models are supervised by real user-item interaction."
  - [section 2.2] "we consider fine-tuning the pre-trained multi-modal model in a customized manner... we insert a pre-order item alignment mechanism to fine-tune the multi-modal model with corresponding business data"
  - [corpus] Weak - no direct neighbor papers discuss fine-tuning alignment for business-specific signals
- Break condition: If downstream interaction data is sparse or unrepresentative of true user preferences, the alignment may degrade rather than improve representations.

### Mechanism 2
- Claim: The quantitative code mechanism overcomes representation unlearning by converting aligned representations into learnable semantic IDs.
- Mechanism: After fine-tuning, multi-modal representations are quantized using vector quantization (VQ) and residual quantization (RQ) techniques, creating discrete code IDs that can be updated during downstream training.
- Core assumption: Discrete quantization can preserve semantic information while enabling gradient-based updates through the recommendation model.
- Evidence anchors:
  - [abstract] "the quantitative code mechanism that converts aligned representations into learnable semantic IDs using vector quantization and residual quantization techniques"
  - [section 2.3] "we consider generating the Semantic IDs for the down-stream tasks... we propose a simple-but-effective heuristics residual K-means algorithm to obtain a quantization codebook"
  - [corpus] Weak - neighbor papers discuss semantic IDs but don't validate the quantization-to-learnableness transition
- Break condition: If quantization introduces too much information loss, the semantic IDs may not capture sufficient signal for accurate recommendations.

### Mechanism 3
- Claim: The combination of VQ and RQ codes captures different aspects of multi-modal knowledge, improving recommendation performance.
- Mechanism: VQ codes capture local neighborhood relationships through top-k similar item neighbors, while RQ codes encode hierarchical residual paths representing the entire representation structure.
- Core assumption: Different quantization strategies encode complementary information that enhances model expressiveness when combined.
- Evidence anchors:
  - [section 2.3] "the VQ code aims to utilize the TopK similar item neighbors to represent target item information, while the RQ code focuses on encoding the entire MLLM representation into a hierarchical residual path"
  - [section 4.2] "incorporating the VQ and RQ codes at same time could further enhance model performance"
  - [corpus] Missing - no neighbor papers validate complementary quantization strategies
- Break condition: If the two code types encode highly redundant information, combining them may add computational cost without performance benefit.

## Foundational Learning

- Concept: Contrastive learning and batch contrastive loss
  - Why needed here: The item alignment mechanism uses batch contrastive loss to align representations based on item-to-item pairs from retrieval models
  - Quick check question: What is the difference between instance-level and batch-level contrastive learning, and why is batch-level appropriate for this alignment task?

- Concept: Vector quantization and residual quantization
  - Why needed here: These techniques convert continuous multi-modal representations into discrete semantic IDs that can be learned during downstream training
  - Quick check question: How do VQ and RQ differ in their approach to quantization, and what are the trade-offs between reconstruction quality and codebook size?

- Concept: Multi-task learning in recommendation systems
  - Why needed here: The downstream recommendation model uses a multi-task prediction module (MoE) that combines user-side, item-side, and target item-aware features
  - Quick check question: What are the benefits and challenges of multi-task learning for recommendation systems, particularly when incorporating multi-modal features?

## Architecture Onboarding

- Component map: Pre-trained MLLM → Item Alignment Model → Quantization Codebooks → Downstream Recommendation Model (Retrieval + Ranking stages)
- Critical path: User-item interaction data → Item alignment training → Quantization codebook generation → Feature engineering → Model training → Online serving
- Design tradeoffs: End-to-end training vs. computational efficiency (fine-tuning vs. frozen representations), quantization granularity vs. information retention, VQ vs. RQ encoding strategies
- Failure signatures: Decreased AUC/GAUC metrics, increased cold-start item exposure but reduced overall engagement, model convergence issues with semantic IDs
- First 3 experiments:
  1. Validate alignment effectiveness: Compare pre-trained vs. aligned representations using retrieval model similarity metrics
  2. Test quantization impact: Measure information loss through reconstruction error and downstream performance degradation
  3. Ablation study: Evaluate individual and combined effects of VQ and RQ codes on recommendation metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the fine-tuning of the pre-trained multi-modal model with business-specific interaction data affect the performance of QARM across different types of downstream tasks (e.g., advertising vs. shopping)?
- Basis in paper: [explicit] The paper mentions that the item alignment mechanism fine-tunes the multi-modal model with corresponding business data to reflect real business characteristics, but does not provide a detailed comparison of performance across different types of tasks.
- Why unresolved: The paper focuses on the overall effectiveness of QARM but does not delve into the nuances of how the fine-tuning process impacts different types of tasks differently.
- What evidence would resolve it: Detailed experimental results comparing the performance of QARM across various types of downstream tasks, with and without fine-tuning, would provide insights into the impact of business-specific fine-tuning.

### Open Question 2
- Question: What is the impact of the choice of quantization code length (K) and code embedding dimension (d) on the performance and efficiency of QARM?
- Basis in paper: [explicit] The paper mentions that the VQ code length K and code embedding dimension d are set to 25 and 64, respectively, by default, and conducts experiments on different values of K and d, but does not provide a comprehensive analysis of their impact.
- Why unresolved: The paper provides some insights into the impact of these parameters but does not explore the full range of possible values or their trade-offs in terms of performance and efficiency.
- What evidence would resolve it: A systematic study of the impact of different values of K and d on the performance and efficiency of QARM, including trade-offs between accuracy and computational cost, would provide a clearer understanding of the optimal settings.

### Open Question 3
- Question: How does the use of quantitative codes (VQ and RQ) compare to other methods of representing multi-modal information in recommendation systems, such as direct use of pre-trained representations or contrastive learning approaches?
- Basis in paper: [explicit] The paper highlights the benefits of using quantitative codes to represent multi-modal information and compares them to direct use of pre-trained representations, but does not provide a detailed comparison with other methods like contrastive learning.
- Why unresolved: The paper focuses on the effectiveness of quantitative codes but does not explore how they compare to other representation methods in terms of performance, scalability, and adaptability to different tasks.
- What evidence would resolve it: A comparative study of quantitative codes, direct use of pre-trained representations, and contrastive learning approaches in various recommendation tasks would provide insights into the relative strengths and weaknesses of each method.

## Limitations
- The framework's effectiveness depends heavily on business-specific interaction patterns that may not transfer to other platforms
- The quantitative code mechanism lacks theoretical grounding for why VQ and RQ together capture complementary information better than either alone
- Computational overhead of generating and maintaining quantization codebooks at industrial scale is not fully addressed

## Confidence

- **High confidence**: Representation unmatching and representation unlearning are valid industrial challenges - this is well-established in recommendation literature and supported by the authors' observations of frozen multi-modal features.
- **Medium confidence**: The item alignment mechanism effectively resolves representation unmatching - while the contrastive learning approach is sound, the paper lacks ablation studies comparing different alignment strategies or evaluating alignment quality directly.
- **Low confidence**: The quantitative code mechanism fully resolves representation unlearning - the paper demonstrates learnable semantic IDs work in practice, but doesn't establish whether quantization preserves sufficient semantic information or if simpler approaches could achieve similar results.

## Next Checks

1. **Alignment quality validation**: Conduct controlled experiments measuring the semantic similarity between aligned and unaligned representations using external benchmarks, not just downstream recommendation metrics, to isolate the alignment effect from other improvements.

2. **Quantization information preservation**: Systematically evaluate information loss by measuring reconstruction error, downstream performance degradation with varying quantization levels, and comparing against baseline approaches that use continuous representations with gradient updates.

3. **Cold-start generalizability**: Test the framework's effectiveness on cold-start items that lack sufficient interaction data for alignment, using synthetic cold-start scenarios to understand when the alignment mechanism fails and whether the quantitative code mechanism compensates.