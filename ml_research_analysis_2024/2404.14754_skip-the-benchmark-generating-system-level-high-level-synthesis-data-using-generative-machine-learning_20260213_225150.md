---
ver: rpa2
title: 'Skip the Benchmark: Generating System-Level High-Level Synthesis Data using
  Generative Machine Learning'
arxiv_id: '2404.14754'
source_url: https://arxiv.org/abs/2404.14754
tags:
- data
- synthetic
- design
- directives
- dcgan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Vaegan, a novel approach for generating high-fidelity
  synthetic High-Level Synthesis (HLS) data using generative machine learning. The
  primary challenge addressed is the scarcity of real-world, system-level HLS data
  for complex multi-component embedded systems, which limits the effectiveness of
  Design Space Exploration (DSE) methodologies.
---

# Skip the Benchmark: Generating System-Level High-Level Synthesis Data using Generative Machine Learning

## Quick Facts
- **arXiv ID**: 2404.14754
- **Source URL**: https://arxiv.org/abs/2404.14754
- **Reference count**: 22
- **Primary result**: Vaegan achieves 44.05% improvement in MMD scores compared to prior synthetic HLS data generation methods

## Executive Summary
This paper introduces Vaegan, a novel approach for generating high-fidelity synthetic High-Level Synthesis (HLS) data using generative machine learning. The work addresses the critical challenge of scarce real-world, system-level HLS data for complex multi-component embedded systems, which limits Design Space Exploration (DSE) effectiveness. By transforming diverse real HLS data into binary fixed-point format and employing VAE and GAN models, Vaegan generates synthetic data that closely matches real data distributions. The approach is validated through multiple metrics including MMD, SSD, PRD, and COSS, demonstrating significant improvements over prior methods and expanding Pareto frontiers in case studies.

## Method Summary
Vaegan converts HLS directives and metrics into 32-bit fixed-point binary format, with directives using 4-bit option codes padded to 32 bits. The approach employs a VAE model with two hidden layers and ReLU activation to learn the latent distribution of HLS design spaces. A weighted loss function emphasizes MSB changes to improve fidelity for binary HLS data. The method is evaluated using metrics like MMD, SSD, PRD, and COSS, with experimental results showing 44.05% improvement in MMD scores compared to prior work. A wearable pregnancy monitoring system case study demonstrates that Vaegan-generated data expands the Pareto frontier, uncovering new Pareto-optimal solutions.

## Key Results
- Achieves 44.05% improvement in Maximum Mean Discrepancy (MMD) scores compared to prior synthetic data generation methods
- Expands Pareto frontier in case study, uncovering new Pareto-optimal solutions not present in original dataset
- Outperforms Gaussian and ABC synthetic data generation methods across multiple evaluation metrics (MMD, SSD, PRD, COSS)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Binary fixed-point transformation preserves both continuous and discrete HLS data characteristics while enabling ML model input compatibility
- Mechanism: HLS directives and metrics are converted into 32-bit fixed-point binary format, with directives represented using 4-bit option codes padded to 32 bits
- Core assumption: Binary fixed-point representation can accurately encode the full range and precision of HLS directive and metric values without information loss
- Evidence anchors:
  - "We propose converting each input variable to a binary fixed-point format, with the precision determined by the real data."
  - "Advantages of using a fixed-point binary representation include seamlessly handling both continuous and discrete data types and achieving high precision while maintaining a dynamic range."

### Mechanism 2
- Claim: VAE model learns the latent distribution of HLS design spaces more effectively than GAN for this binary input format
- Mechanism: VAE encoder maps binary HLS data to a latent Gaussian distribution, and decoder reconstructs synthetic data
- Core assumption: Latent space learned by VAE can capture essential structure of HLS design configurations for meaningful synthesis
- Evidence anchors:
  - "MLPVAE has two hidden layers and uses a ReLU activation function to provide non-linearity and symmetry for the VAE."
  - "Experimental results show that, compared to prior work, Vaegan effectively generates high-fidelity synthetic data that improves the Maximum Mean Discrepancy (MMD) score from real HLS data by 44.05%."

### Mechanism 3
- Claim: Weighted loss function that emphasizes MSB changes improves fidelity for binary HLS data
- Mechanism: Loss function assigns higher weight to errors in most significant bit, recognizing MSB changes cause larger value variations in fixed-point representation
- Core assumption: Preserving MSB accuracy is more critical than lower-bit accuracy for maintaining overall data distribution fidelity
- Evidence anchors:
  - "A unique feature of the fixed-point input format used here is that we modified the loss function to place additional weight on changes to the most significant bit (MSB)."

## Foundational Learning

- Concept: High-Level Synthesis (HLS) design space exploration fundamentals
  - Why needed here: Understanding how HLS directives affect hardware metrics is essential for interpreting what synthetic data represents
  - Quick check question: What are primary design metrics that HLS DSE optimizes for, and how do directives like loop unrolling affect them?

- Concept: Generative adversarial networks (GAN) and variational autoencoders (VAE)
  - Why needed here: Paper adapts these models for HLS data, so understanding their standard operation is crucial
  - Quick check question: How does VAE's probabilistic latent space differ from GAN's deterministic generator, and what implications does this have for synthetic data generation?

- Concept: Fixed-point binary representation and quantization
  - Why needed here: Input transformation relies on fixed-point binary format, which affects both data encoding and model training
  - Quick check question: How does separation of integer and fractional portions in fixed-point representation enable handling both discrete directives and continuous metrics?

## Architecture Onboarding

- Component map:
  Data Transformation Layer -> VAE Model -> Evaluation Layer -> Input Pipeline

- Critical path:
  1. Load and transform real HLS data from HLSDataset
  2. Train VAE model on transformed data
  3. Generate synthetic data using trained VAE
  4. Evaluate synthetic data against real data using multiple metrics

- Design tradeoffs:
  - Fixed-point precision vs. model complexity: Higher precision requires more bits but may not improve results proportionally
  - VAE depth vs. training time: Deeper networks may capture more complex patterns but increase training time significantly
  - MSB weighting in loss vs. overall distribution matching: Aggressive MSB weighting may improve some metrics but harm others

- Failure signatures:
  - High MMD scores indicate synthetic data distribution differs significantly from real data
  - High SSD and PRD scores suggest synthetic data values are far from real data values
  - Low COSS scores indicate poor cosine similarity between synthetic and real data distributions
  - Training instability in VAE (reconstruction loss not decreasing) suggests poor data transformation or model architecture issues

- First 3 experiments:
  1. Run VAE training on small subset of HLSDataset (100 samples) to verify data transformation correctness and basic model functionality
  2. Compare VAE vs DCGAN performance on same small dataset to validate paper's claim about VAE superiority
  3. Test effect of different fixed-point precisions (e.g., 16-bit vs 32-bit) on synthetic data fidelity metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Vaegan's performance compare when using different generative models like diffusion models instead of VAE and GAN?
- Basis in paper: The paper mentions exploring additional models like diffusion models in future work
- Why unresolved: Current study only evaluates MLPVAE and DCGAN, leaving potential of other models unexplored
- What evidence would resolve it: Comparative experiments using diffusion models or other generative models to assess their effectiveness in generating high-fidelity synthetic HLS data

### Open Question 2
- Question: Can Vaegan be effectively extended to generate synthetic data for early-stage HLS exploration using inputs like data flow graphs?
- Basis in paper: Conclusion mentions extending Vaegan to accommodate various inputs such as data flow graphs for early-stage HLS exploration
- Why unresolved: Current implementation focuses on HLS directives and post-implementation data, not early-stage exploration inputs
- What evidence would resolve it: Successful adaptation of Vaegan to generate synthetic data using data flow graphs or similar early-stage inputs, validated against real data

### Open Question 3
- Question: How does fidelity of synthetic data generated by Vaegan impact accuracy of ML-based HLS DSE predictors when bypassing HLS process?
- Basis in paper: Conclusion suggests exploring Vaegan as machine learning predictor to bypass HLS process
- Why unresolved: Study does not investigate direct use of synthetic data for ML prediction in HLS DSE
- What evidence would resolve it: Experiments demonstrating effectiveness of Vaegan-generated synthetic data in training ML models that accurately predict HLS outcomes, validated against real data

### Open Question 4
- Question: What are limitations of Vaegan in handling benchmarks with highly variable loop structures and directive options?
- Basis in paper: Results section notes that MLPVAE's performance is benchmark-dependent due to variabilities in loop structures and directive options
- Why unresolved: Paper does not provide detailed analysis of Vaegan's limitations with complex benchmarks
- What evidence would resolve it: Comprehensive study evaluating Vaegan's performance across diverse set of benchmarks with varying loop structures and directive complexities, identifying specific limitations and potential solutions

## Limitations

- Binary fixed-point transformation's impact on preserving discrete HLS directive semantics remains unclear
- Case study's wearable pregnancy monitoring system evaluation lacks detail on how synthetic data actually improves system-level DSE outcomes
- Performance claims may be benchmark-dependent due to differences in loop structures and directive options

## Confidence

- **High Confidence**: Comparative performance claims against prior synthetic data methods (44.05% MMD improvement) are well-supported by quantitative metrics across multiple benchmarks
- **Medium Confidence**: VAE superiority claim is supported by results but paper acknowledges DCGAN performance depends heavily on hyperparameters and architecture choices that aren't fully specified
- **Medium Confidence**: Fixed-point binary transformation methodology is clearly specified, but preservation of discrete directive semantics requires additional validation

## Next Checks

1. Verify that synthetic HLS directives generated by Vaegan produce valid, compilable HLS code when processed through actual HLS tools
2. Test Vaegan's performance on additional HLS benchmarks beyond Polybench to assess generalizability
3. Conduct ablation studies to quantify individual contributions of binary transformation, VAE architecture, and MSB-weighted loss to overall performance improvements