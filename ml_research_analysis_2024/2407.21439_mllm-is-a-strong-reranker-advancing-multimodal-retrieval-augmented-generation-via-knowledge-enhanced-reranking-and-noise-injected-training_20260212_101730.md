---
ver: rpa2
title: 'MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation
  via Knowledge-enhanced Reranking and Noise-injected Training'
arxiv_id: '2407.21439'
source_url: https://arxiv.org/abs/2407.21439
tags:
- image
- reranker
- images
- multimodal
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-granularity noisy correspondence
  (MNC) in multimodal retrieval-augmented generation (RAG), where retrieval and generation
  stages are hindered by noisy text-image correspondences. To tackle this, the authors
  propose RagVL, a framework that leverages knowledge-enhanced reranking and noise-injected
  training.
---

# MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training

## Quick Facts
- **arXiv ID:** 2407.21439
- **Source URL:** https://arxiv.org/abs/2407.21439
- **Reference count:** 28
- **Primary result:** Up to 64.25% overall accuracy on WebQA, outperforming baselines by 15–29 percentage points

## Executive Summary
This paper addresses the challenge of multi-granularity noisy correspondence (MNC) in multimodal retrieval-augmented generation (RAG), where retrieval and generation stages are hindered by noisy text-image correspondences. The authors propose RagVL, a framework that leverages knowledge-enhanced reranking and noise-injected training to improve both retrieval filtering and generation robustness. By instruction-tuning multimodal large language models (MLLMs) to act as rerankers and introducing visual noise during training, the framework achieves significant performance gains on WebQA and MultimodalQA benchmarks.

## Method Summary
The paper introduces RagVL, a framework that tackles noisy correspondences in multimodal RAG by employing two key strategies. First, MLLMs are instruction-tuned to serve as rerankers that filter retrieved image-text pairs, improving the quality of inputs for the generation stage. Second, noise injection is applied during training at both data and token levels to enhance the generation model's robustness to visual noise. The framework is evaluated on WebQA and MultimodalQA, demonstrating substantial improvements over baseline approaches, with up to 64.25% overall accuracy on WebQA.

## Key Results
- RagVL achieves up to 64.25% overall accuracy on WebQA, outperforming baselines by 15–29 percentage points.
- The framework generalizes well to low-resource settings and traditional caption-to-image retrieval tasks.
- Noise-injected training and knowledge-enhanced reranking together contribute to significant gains in robustness and accuracy.

## Why This Works (Mechanism)
The core mechanism relies on leveraging MLLMs as strong rerankers to filter noisy image-text pairs retrieved during the RAG pipeline. By instruction-tuning these models, they can effectively discern relevant correspondences and suppress irrelevant or misleading ones. The noise injection at both data and token levels during training further strengthens the generation model's resilience to real-world visual noise, ensuring more reliable outputs even when inputs are imperfect.

## Foundational Learning
- **Multimodal Retrieval-augmented Generation (RAG):** Combines retrieval and generation to answer questions using external knowledge; needed to contextualize the problem of noisy correspondences.
- **Multimodal Large Language Models (MLLMs):** Models capable of processing both text and images; needed as rerankers and generators in the framework.
- **Noise Injection in Training:** Technique to improve model robustness by exposing it to noisy inputs during training; needed to handle real-world imperfect data.
- **Knowledge-enhanced Reranking:** Uses instruction-tuned models to filter and rank retrieved content; needed to improve input quality for downstream generation.
- **Multi-granularity Noisy Correspondence (MNC):** Describes noise at different levels (e.g., image, text, token); needed to understand the scope of the challenge.

## Architecture Onboarding
**Component Map:** Retriever -> Reranker (MLLM) -> Generator (MLLM) -> Output

**Critical Path:** The reranking step is critical, as it directly filters noisy image-text pairs before generation, significantly impacting final output quality.

**Design Tradeoffs:** Reranking introduces computational overhead but improves accuracy; noise injection improves robustness but may affect model interpretability.

**Failure Signatures:** Poor reranking can propagate noise to the generator, leading to incorrect answers; excessive noise injection may degrade model calibration.

**First Experiments:**
1. Evaluate reranker-only performance on a held-out noisy retrieval set.
2. Test noise injection impact by varying noise intensity during training.
3. Assess generalization by applying RagVL to a new multimodal QA dataset.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is limited to two benchmark datasets, which may not reflect real-world diversity.
- Computational overhead from reranking and noise injection is not quantified.
- No ablation studies on different noise types or their relative importance.

## Confidence
- **High confidence:** Core methodology and primary experimental results on WebQA and MultimodalQA.
- **Medium confidence:** Contribution of noise injection to robustness; generalizability to low-resource and retrieval tasks.

## Next Checks
1. Conduct cross-domain evaluation on specialized domains (e.g., medical, scientific, or technical documentation) to assess RagVL's performance beyond general web-based QA.
2. Perform systematic ablation studies on different noise injection strategies (data-level vs token-level, varying noise intensities) to quantify their individual contributions to overall performance.
3. Measure and report the computational overhead introduced by the reranking step and noise injection training, including inference time increases and memory requirements compared to baseline models.