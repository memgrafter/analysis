---
ver: rpa2
title: How Do Training Methods Influence the Utilization of Vision Models?
arxiv_id: '2410.14470'
source_url: https://arxiv.org/abs/2410.14470
tags:
- training
- adversarial
- conv2
- conv1
- conv3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how different training methods affect the
  utilization of neural network layers in vision models. The authors conduct experiments
  on ResNet-50 models trained on ImageNet-1k, keeping the architecture and data constant
  but varying the training pipeline.
---

# How Do Training Methods Influence the Utilization of Vision Models?

## Quick Facts
- arXiv ID: 2410.14470
- Source URL: https://arxiv.org/abs/2410.14470
- Reference count: 15
- Key outcome: Training methods significantly influence which neural network layers become critical to decision-making, with adversarial training increasing overall layer criticality while SSL methods strengthen early layers.

## Executive Summary
This paper investigates how different training methods affect the utilization of neural network layers in vision models. Through experiments on ResNet-50 models trained on ImageNet-1k with varying training pipelines, the authors measure layer criticality by randomizing individual layers and assessing changes in prediction consistency. They find that training methods dramatically influence which layers become critical to the decision function, with improved training regimes and self-supervised learning increasing early layer importance while under-utilizing deeper layers, and adversarial training showing the opposite trend. These findings provide insights into how training methodology shapes the internal mechanics of neural networks.

## Method Summary
The study employs a randomization-based approach to measure layer criticality in ResNet-50 models. For each model, individual layers' parameters are systematically randomized and the resulting change in prediction consistency is measured using cosine distance between probability vectors before and after randomization. This is performed on 10,000 random ImageNet validation images. The analysis compares 50 different ResNet-50 models with identical architecture and data but varying training methods including standard training, adversarial training with different attack budgets, data augmentation strategies, and self-supervised learning approaches.

## Key Results
- Training methods significantly influence which layers become critical to the decision function, with no layer being consistently auxiliary across all methods
- Adversarial training increases layer criticality proportionally to attack budget strength, particularly in early and middle stages
- Self-supervised learning methods (DINO, MoCo v3, SwAV) create shorter decision functions by strengthening early operations while relaxing deeper ones
- Improved training recipes (Touvron