---
ver: rpa2
title: Interpreting Neurons in Deep Vision Networks with Language Models
arxiv_id: '2403.13771'
source_url: https://arxiv.org/abs/2403.13771
tags:
- concept
- neurons
- layer
- neuron
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Describe-and-Dissect (DnD), a training-free
  method for automatically describing hidden neurons in vision networks using multimodal
  deep learning. DnD leverages image-to-text models, large language models, and text-to-image
  models to generate complex natural language descriptions of neuron concepts without
  labeled training data or predefined concept sets.
---

# Interpreting Neurons in Deep Vision Networks with Language Models

## Quick Facts
- arXiv ID: 2403.13771
- Source URL: https://arxiv.org/abs/2403.13771
- Reference count: 40
- This paper introduces a training-free method for automatically describing hidden neurons in vision networks using multimodal deep learning.

## Executive Summary
This paper introduces Describe-and-Dissect (DnD), a training-free method for automatically describing hidden neurons in vision networks using multimodal deep learning. DnD leverages image-to-text models, large language models, and text-to-image models to generate complex natural language descriptions of neuron concepts without labeled training data or predefined concept sets. Extensive qualitative and quantitative evaluations demonstrate that DnD outperforms existing methods in producing higher-quality neuron descriptions. In crowdsourced studies, DnD was selected as the best explanation more than twice as often as the best baseline and achieved an average rating over 4.1 out of 5 on ResNet models. The method also identified uninterpretable neurons and spurious correlations in land cover prediction models, demonstrating practical utility for sustainability applications.

## Method Summary
DnD is a three-step pipeline that uses recent advancements in multimodal deep learning to describe neuron functionality. First, it augments a probing dataset with attention cropping to collect highly activating images for target neurons. Second, it generates candidate concepts by producing descriptive captions using BLIP and summarizing similarities between captions using GPT-3.5 Turbo. Third, it selects the best concept by generating synthetic images and scoring them based on neuron activation and image similarity. The method requires no labeled training data or predefined concept sets, making it training-free and highly flexible.

## Key Results
- DnD was selected as the best explanation more than twice as often as the best baseline in crowdsourced studies
- Achieved average rating over 4.1 out of 5 on ResNet models in human evaluation
- Successfully identified uninterpretable neurons and spurious correlations in land cover prediction models

## Why This Works (Mechanism)

### Mechanism 1
DnD produces higher quality neuron descriptions than baseline methods by leveraging generative image-to-text models. DnD uses BLIP to generate descriptive captions for highly activating images, which captures complex concepts better than fixed concept sets used by CLIP-Dissect and Network Dissection. Core assumption: Generative image-to-text models can produce more expressive and accurate descriptions than static concept sets.

### Mechanism 2
DnD's candidate concept generation through GPT summarization produces more accurate descriptions than training from scratch. DnD uses GPT to summarize similarities between multiple image captions, creating candidate concepts that better represent the neuron's functionality. Core assumption: GPT can effectively identify and summarize conceptual similarities between image captions.

### Mechanism 3
DnD's concept selection through synthetic image generation and scoring functions improves accuracy over baseline methods. DnD generates synthetic images based on candidate concepts and selects the concept whose generated images activate the neuron most highly. Core assumption: The synthetic images generated from the true concept will cause the neuron to activate highly.

## Foundational Learning

- Concept: Multimodal deep learning (image-to-text, text-to-image models)
  - Why needed here: DnD relies on these models for generating and refining neuron descriptions
  - Quick check question: What are the key components of a multimodal deep learning pipeline?

- Concept: Neuron interpretability methods (Network Dissection, CLIP-Dissect, MILAN)
  - Why needed here: Understanding baseline methods helps contextualize DnD's improvements
  - Quick check question: How do Network Dissection and CLIP-Dissect differ in their approach to neuron labeling?

- Concept: Large language models (GPT-3.5 Turbo)
  - Why needed here: GPT is used for summarizing image captions and identifying conceptual similarities
  - Quick check question: What are the key capabilities of GPT-3.5 Turbo that make it suitable for concept summarization?

## Architecture Onboarding

- Component map: Probing dataset augmentation (attention cropping) -> Candidate concept generation (BLIP image captioning + GPT summarization) -> Best concept selection (synthetic image generation + scoring function) -> Evaluation framework (crowdsourced human ratings)

- Critical path: 1. Collect highly activating images for target neuron 2. Generate image captions using BLIP 3. Summarize captions using GPT to create candidate concepts 4. Generate synthetic images for each candidate concept 5. Score concepts based on neuron activation and image similarity 6. Select best concept as neuron description

- Design tradeoffs:
  - Using generative models vs. fixed concept sets: Generative models provide more expressive descriptions but require more computational resources
  - Single label vs. multiple labels: Single labels are simpler but may not capture polysemantic neurons
  - Probing dataset size: Larger datasets provide more diverse images but increase computational cost

- Failure signatures:
  - Inaccurate descriptions: May indicate issues with image captioning, concept summarization, or scoring function
  - Generic/vague labels: Could suggest the neuron is polysemantic or the concept is difficult to express
  - Poor performance on specific layers: May indicate the method is less effective for certain types of neurons

- First 3 experiments:
  1. Compare DnD descriptions to baseline methods on a small set of randomly selected neurons
  2. Evaluate the impact of attention cropping on description accuracy
  3. Test different scoring functions for concept selection and compare their performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the quality of DnD-generated neuron descriptions vary across different layers of deep vision networks, and what architectural properties of the network contribute to this variation? While the paper shows DnD performs well across layers, it doesn't deeply analyze the architectural reasons why certain layers might be easier or harder to describe.

### Open Question 2
To what extent does the choice of image-to-text model (BLIP vs. BLIP-2 vs. GPT-4o) impact the accuracy and specificity of DnD-generated neuron descriptions? The paper shows performance differences but doesn't establish which model is optimal for different types of neurons or network architectures.

### Open Question 3
How does DnD perform when applied to vision networks trained on specialized domains (medical imaging, satellite imagery, etc.) compared to general-purpose ImageNet-trained models? The paper focuses on general vision networks and one sustainability use case, leaving open whether DnD generalizes to domain-specific applications.

## Limitations

- Dependence on the quality of underlying multimodal models, with inaccuracies propagating directly to final descriptions
- Computational intensity requiring significant resources for image generation and processing
- Potential limitations in handling polysemantic neurons with single-label descriptions

## Confidence

- **High Confidence**: The core mechanism of using multimodal models for neuron description is technically sound and well-supported by empirical evidence
- **Medium Confidence**: The superiority over baseline methods is demonstrated, but results depend heavily on the quality of human evaluation studies
- **Low Confidence**: The method's generalizability to very different network architectures or domains beyond image classification remains untested

## Next Checks

1. Cross-architecture validation: Test DnD on transformer-based vision models (like ViT) and convolutional architectures beyond ResNet to verify generalizability

2. Concept polysemy analysis: Systematically evaluate how DnD handles polysemantic neurons by comparing single-label vs. multi-label descriptions and their accuracy

3. Computational efficiency study: Profile the computational cost across different neuron types and explore optimization strategies to reduce the ~38.8 seconds per neuron processing time