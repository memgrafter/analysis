---
ver: rpa2
title: Can GNN be Good Adapter for LLMs?
arxiv_id: '2402.12984'
source_url: https://arxiv.org/abs/2402.12984
tags:
- graphadapter
- graph
- arxiv
- language
- pre-training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores using graph neural networks (GNNs) as efficient
  adapters for large language models (LLMs) to model text-attributed graphs (TAGs).
  TAGs are graphs where nodes have both textual features and structural information.
---

# Can GNN be Good Adapter for LLMs?

## Quick Facts
- arXiv ID: 2402.12984
- Source URL: https://arxiv.org/abs/2402.12984
- Authors: Xuanwen Huang; Kaiqiao Han; Yang Yang; Dezheng Bao; Quanjin Tao; Ziwei Chai; Qi Zhu
- Reference count: 40
- One-line primary result: GraphAdapter improves node classification accuracy by 4.7-5.4% over baselines while using 30x fewer parameters

## Executive Summary
This paper proposes GraphAdapter, a framework that uses graph neural networks (GNNs) as lightweight adapters for large language models (LLMs) to model text-attributed graphs (TAGs). The approach leverages a frozen LLM and trains a GNN adapter to combine graph structure with text, enabling efficient pre-training and fine-tuning. Experimental results on real-world TAG datasets demonstrate that GraphAdapter significantly outperforms state-of-the-art baselines while maintaining computational efficiency through parameter-efficient tuning.

## Method Summary
GraphAdapter employs a frozen LLM with a trained GNN adapter to model text-attributed graphs. The framework is pre-trained using auto-regression on node text (next token prediction) where the GNN learns to predict masked tokens by combining node structure with context. For downstream tasks, GraphAdapter uses task-specific prompts to transform the problem into a next-token prediction task, allowing fine-tuning with a new head while keeping the LLM frozen. The GNN and LLM predictions are combined through residual learning, averaging the original LLM prediction with the GNN-fused prediction.

## Key Results
- GraphAdapter improves node classification accuracy by 4.7-5.4% over state-of-the-art baselines
- Uses 30x fewer parameters compared to fine-tuning the entire LLM
- Particularly effective on smaller datasets (Instagram/Reddit) where pre-training provides significant benefits
- Residual connections between GNN and LLM predictions are crucial for performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GraphAdapter improves LLM predictions by leveraging graph structure to correct errors on structure-relevant tokens
- Mechanism: The residual learning approach averages the original LLM prediction with the GNN-fused prediction, allowing the GNN to "rescue" tokens that the LLM struggles with based on structural context
- Core assumption: Tokens that the LLM predicts poorly are the ones that benefit most from structural information
- Evidence anchors:
  - [abstract]: "GraphAdapter offers several advantages: â€¢ Lightweight: A GNN adapter introduces a few trainable parameters and low computational costs. â€¢ Language-aware graph pre-training: Using language to supervise the modeling of graph structure, which can help LLMs comprehend both textual and structural information."
  - [section]: "Intuitively, words related to graph structure should be difficult for the language model to predict based on context. Therefore, the results of pre-trained language models are reused."
  - [corpus]: Weak - corpus neighbors discuss GNN adapters and knowledge distillation but don't specifically address token-level error correction through residual learning
- Break condition: If the GNN cannot identify which tokens are "structure-relevant" or if the residual averaging actually degrades predictions for tokens the LLM handles well

### Mechanism 2
- Claim: Pre-training on node text enables the GNN adapter to learn structural patterns that correlate with textual semantics
- Mechanism: During pre-training, the GNN learns to predict masked tokens by combining node structure with context, creating a learned mapping between structural features and semantic information
- Core assumption: There exists a learnable correlation between graph structure and textual content that can be discovered through next-token prediction
- Evidence anchors:
  - [abstract]: "The entire framework is trained using auto-regression on node text (next token prediction). Once trained, GraphAdapter can be seamlessly fine-tuned with task-specific prompts for various downstream tasks."
  - [section]: "To capture the data distribution of the graph, we employ parameter-efficient tuning of LLMs on node texts. This approach is similar to the continual training of language models except GNN is the tuning parameter, which helps reduce the distribution discrepancy between the pre-training corpus and target data."
  - [corpus]: Weak - corpus neighbors mention pre-training for TAGs but don't specifically address the structural-semantic correlation learning mechanism
- Break condition: If the graph structure is too noisy or the textual data is too sparse for meaningful structural-semantic correlations to emerge

### Mechanism 3
- Claim: Task-specific prompts allow GraphAdapter to extract semantic information relevant to downstream tasks without additional fine-tuning of the LLM
- Mechanism: Prompts transform the downstream task into a next-token prediction problem, allowing GraphAdapter to leverage its pre-trained ability to combine structural and textual information
- Core assumption: The semantic information learned during pre-training generalizes to different downstream tasks when the input is properly framed with prompts
- Evidence anchors:
  - [abstract]: "Once trained, GraphAdapter can be seamlessly fine-tuned with task-specific prompts for various downstream tasks."
  - [section]: "We use the hidden state of the last token as the sentence representation, denoted as ð‘Šð‘– |P. Since the last token is used to predict the next token distribution in the pre-training stage, it can naturally combine the inserted prompt information into the original sentence and extract the prompt-related semantics."
  - [corpus]: Weak - corpus neighbors discuss prompts for LLMs but don't specifically address task-specific prompt adaptation in the GraphAdapter context
- Break condition: If prompts are poorly designed or the downstream task requires information not present in the pre-training phase

## Foundational Learning

- Concept: Graph Neural Networks and Message Passing
  - Why needed here: Understanding how GNNs aggregate neighbor information is crucial for understanding how GraphAdapter incorporates structural information
  - Quick check question: What is the key operation that distinguishes GNNs from standard neural networks in processing graph data?

- Concept: Prompt Engineering for LLMs
  - Why needed here: GraphAdapter relies on carefully designed prompts to transform downstream tasks into next-token prediction problems
  - Quick check question: How do prompts help bridge the gap between pre-training tasks and downstream tasks in LLMs?

- Concept: Parameter-Efficient Fine-Tuning
  - Why needed here: GraphAdapter uses a GNN adapter rather than fine-tuning the entire LLM, making it computationally efficient
  - Quick check question: What are the advantages of using adapter modules instead of full fine-tuning for large language models?

## Architecture Onboarding

- Component map: Frozen LLM -> Tokenization -> GNN Adapter (GraphSAGE) -> Fusion Layer (MLP) -> Residual Connection -> Prediction

- Critical path:
  1. Node text is tokenized and processed by frozen LLM
  2. GNN computes structural representation from node features and adjacency matrix
  3. Fusion layer combines LLM hidden states with GNN representation
  4. Residual connection averages GNN-fused prediction with original LLM prediction
  5. For downstream tasks, prompts are added and new head is trained

- Design tradeoffs:
  - GNN depth vs. computational cost: Deeper GNNs capture more complex structure but increase computation
  - Fusion layer complexity vs. expressiveness: More complex fusion layers may capture better interactions but risk overfitting
  - Prompt specificity vs. generalization: Highly specific prompts may work better for individual tasks but reduce reusability

- Failure signatures:
  - No improvement over baseline LLM: GNN adapter may not be learning meaningful structural features
  - Performance degradation: Residual connection may be harmful, or prompts may be mis-specified
  - Training instability: Learning rate or architecture may need adjustment

- First 3 experiments:
  1. Compare GraphAdapter with frozen LLM only on a small dataset to verify GNN adapter adds value
  2. Test different GNN architectures (GAT, GraphSAGE) to find optimal structural modeling approach
  3. Experiment with prompt variations to identify optimal prompt design for downstream tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the pre-training process of GraphAdapter scale with increasing graph size and complexity?
- Basis in paper: [explicit] The paper mentions that GraphAdapter uses parameter-efficient tuning of LLMs on node texts and performs mean-pooling on predicted logits from a GNN adapter and LLMs. However, it does not provide specific details on how the pre-training process scales with larger graphs.
- Why unresolved: The paper does not provide experiments or analysis on the scalability of the pre-training process with respect to graph size and complexity. This is an important aspect to consider for practical applications of GraphAdapter on real-world datasets with billions of nodes and edges.
- What evidence would resolve it: Experiments comparing the performance and efficiency of GraphAdapter on graphs of varying sizes and complexities, including benchmarks on large-scale datasets, would provide insights into the scalability of the pre-training process.

### Open Question 2
- Question: Can GraphAdapter be extended to handle multi-modal text-attributed graphs where nodes have additional types of features beyond text?
- Basis in paper: [inferred] The paper focuses on text-attributed graphs where nodes have textual features and structural information. However, real-world graphs often have additional types of features, such as images, videos, or numerical attributes. The paper does not discuss how GraphAdapter can be adapted to handle these multi-modal graphs.
- Why unresolved: The current framework of GraphAdapter is specifically designed for text-attributed graphs, and it is unclear how it can be extended to incorporate other types of features. This limitation may restrict the applicability of GraphAdapter in domains where multi-modal graphs are prevalent.
- What evidence would resolve it: Research exploring the integration of GraphAdapter with other types of features, such as images or numerical attributes, and experiments demonstrating its performance on multi-modal text-attributed graphs would provide insights into the potential extension of the framework.

### Open Question 3
- Question: How does the choice of GNN architecture impact the performance of GraphAdapter, and are there specific GNN designs that are more suitable for different types of text-attributed graphs?
- Basis in paper: [explicit] The paper uses GraphSAGE as the GNN architecture in the experiments but does not explore the impact of different GNN designs on the performance of GraphAdapter. It also does not discuss whether certain GNN architectures are more suitable for specific types of text-attributed graphs.
- Why unresolved: The choice of GNN architecture can significantly influence the performance of GraphAdapter, as different GNNs have varying capabilities in capturing graph structural information. Understanding the relationship between GNN design and performance on different types of text-attributed graphs is crucial for optimizing the framework.
- What evidence would resolve it: Experiments comparing the performance of GraphAdapter with various GNN architectures, such as Graph Attention Networks (GAT), Graph Convolutional Networks (GCN), or Graph Isomorphism Networks (GIN), on different types of text-attributed graphs would provide insights into the impact of GNN design on the framework's performance.

## Limitations
- Limited to social network datasets, with unknown generalizability to other graph types like knowledge graphs or molecular graphs
- Heavy dependency on prompt engineering without comprehensive guidelines for different task types
- Focus on GraphSAGE architecture without thorough exploration of how different GNN designs impact performance

## Confidence
- High confidence: Computational efficiency claims (30x fewer parameters) are well-supported by parameter counts and transparent methodology
- Medium confidence: Performance improvement claims (4.7-5.4% accuracy gains) are based on specific datasets and tasks, limiting generalizability
- Low confidence: Theoretical claims about residual learning mechanism correcting LLM errors lack direct empirical validation

## Next Checks
1. Test GraphAdapter on non-social network TAG datasets (e.g., citation networks like Cora, molecular graphs) to assess generalizability beyond social media contexts
2. Implement a version that doesn't use residual averaging (pure GNN prediction) and compare performance to understand whether the residual connection is essential to the reported gains
3. Systematically vary prompt formulations across multiple tasks to quantify how sensitive performance is to prompt design, establishing guidelines for optimal prompt engineering