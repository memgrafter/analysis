---
ver: rpa2
title: Automated legal reasoning with discretion to act using s(LAW)
arxiv_id: '2401.14511'
source_url: https://arxiv.org/abs/2401.14511
tags:
- legal
- discretion
- student
- place
- automated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the challenge of modeling and automating legal\
  \ reasoning in contexts involving discretion, ambiguity, and incomplete information\u2014\
  concepts central to legal texts but difficult to formalize computationally. The\
  \ authors propose s(LAW), a framework built on s(CASP), a goal-directed Answer Set\
  \ Programming system, which allows for the representation of vague legal concepts\
  \ like \"force majeure\" and discretionary decision-making."
---

# Automated legal reasoning with discretion to act using s(LAW)

## Quick Facts
- arXiv ID: 2401.14511
- Source URL: https://arxiv.org/abs/2401.14511
- Reference count: 22
- Primary result: s(LAW) framework enables automated legal reasoning with discretion and ambiguity through multi-model generation and natural language justifications

## Executive Summary
This paper addresses the challenge of modeling and automating legal reasoning in contexts involving discretion, ambiguity, and incomplete information—concepts central to legal texts but difficult to formalize computationally. The authors propose s(LAW), a framework built on s(CASP), a goal-directed Answer Set Programming system, which allows for the representation of vague legal concepts like "force majeure" and discretionary decision-making. They demonstrate their approach using a real-world case: the Spanish "Comunidad de Madrid" school admissions process, encoding both deterministic rules and discretionary criteria. The system supports multiple models and provides human-readable justifications in natural language for its conclusions. The evaluation shows that s(LAW) can handle complex legal reasoning tasks with transparency, scalability, and the ability to explain decisions—addressing key limitations of existing ASP systems. This work represents a significant advance in automating legal reasoning while preserving the interpretability and nuance of legal decision-making.

## Method Summary
The authors developed s(LAW), a framework built on s(CASP), a goal-directed Answer Set Programming system that generates partial stable models instead of requiring grounding. They encoded the Spanish "Comunidad de Madrid" school admissions process using ArticleESO.pl for legislation rules, ArticleESO.pred.pl for natural language patterns, and Students.pl for evidence data. The system uses predicates like evidence/2 and -evidence/2 to generate different models based on available information, allowing exploration of multiple interpretations for ambiguous concepts like "force majeure" and discretionary criteria. Natural language justifications are generated through directive-based patterns that translate predicates into readable explanations, making the system interpretable to legal experts without programming background.

## Key Results
- Successfully encoded Spanish school admissions rules with both deterministic requirements and discretionary criteria
- Generated multiple partial models representing different interpretations of ambiguous concepts like "force majeure"
- Provided human-readable natural language justifications for all conclusions and reasoning paths
- Demonstrated scalability advantages of s(CASP)'s top-down execution over traditional ASP systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: s(CASP) enables handling of legal ambiguity and discretion by generating multiple partial models instead of a single canonical one.
- Mechanism: Unlike traditional ASP systems that require grounding and produce a single model, s(CASP)'s top-down query-driven execution generates partial stable models that represent different possible interpretations of vague legal concepts like "force majeure" or discretionary criteria.
- Core assumption: Legal reasoning often involves incomplete information and multiple valid interpretations that need to be explored rather than resolved to a single answer.
- Evidence anchors:
  - [abstract] states "The system supports multiple models and provides human-readable justifications in natural language for its conclusions."
  - [section] explains "The discretion to act can be considered as a ground or an exception following the previous patterns" and "This feature allows us to reuse some of the clauses without repeating them."

### Mechanism 2
- Claim: Natural language justification generation makes the system interpretable to legal experts without programming background.
- Mechanism: s(CASP) provides directive-based patterns that translate predicates into natural language explanations, allowing experts to understand both the program logic and reasoning results.
- Core assumption: Legal experts need to understand not just what decision was made, but why, including the chain of reasoning and evidence considered.
- Evidence anchors:
  - [abstract] mentions "provides human-readable justifications in natural language for its conclusions"
  - [section] shows the directive pattern "#pred obtain_place(St) :: '@(St) may obtain a school place'" and states "These patterns can be used with the program text itself, thereby making it easier for experts without a programming background to understand both the program and the results"

### Mechanism 3
- Claim: The system can reason both with and without specific evidence, generating different models based on available information.
- Mechanism: By using predicates like evidence/2 and -evidence/2, the system can generate models assuming different truth values for unknown information, allowing exploration of "what if" scenarios.
- Core assumption: In legal cases, evidence is often incomplete, and decision-makers need to understand how different evidence scenarios would affect outcomes.
- Evidence anchors:
  - [section] describes "the desirable behavior should capture the absence of information by generating different models depending on the relevant information" and provides the example of "it may be unclear whether the documents we have to certify that we are a large_family are valid or not"
  - [section] shows the encoding pattern where "the partial model returned assumes that the truth values for these pieces of information are true"

## Foundational Learning

- Concept: Answer Set Programming (ASP) and stable models
  - Why needed here: The system is built on ASP foundations, and understanding how stable models work is crucial for understanding how s(CASP) differs from traditional ASP
  - Quick check question: What is the key difference between traditional ASP systems and s(CASP) in terms of execution strategy?

- Concept: Non-monotonic reasoning and negation as failure
  - Why needed here: Legal reasoning often involves exceptions and default assumptions, which are captured through negation as failure in the logic programming framework
  - Quick check question: How does the system represent "force majeure" as an ambiguous concept using negation as failure?

- Concept: Goal-directed execution vs bottom-up grounding
  - Why needed here: s(CASP)'s top-down approach avoids the grounding phase, which is crucial for scalability and handling uninterpreted functions
  - Quick check question: What are the three major advantages of s(CASP)'s top-down query-driven execution strategy over traditional ASP systems?

## Architecture Onboarding

- Component map: ArticleESO.pl -> ArticleESO.pred.pl -> Students.pl -> s(CASP) core
- Critical path:
  1. Load legislation rules (ArticleESO.pl)
  2. Load natural language patterns (ArticleESO.pred.pl)
  3. Load student evidence (Students.pl)
  4. Process query through s(CASP)
  5. Generate partial models and justifications
- Design tradeoffs:
  - Multiple models vs single deterministic outcome: The system prioritizes exploring ambiguity over forcing a single answer
  - Interpretability vs computational efficiency: Natural language justifications add overhead but are essential for legal domain
  - Generality vs specificity: Generic patterns allow reuse but may not capture all legal nuances
- Failure signatures:
  - No models returned when evidence is insufficient but some decision is legally required
  - Too many models returned, making it difficult to reach a decision
  - Natural language justifications become too complex or fail to capture reasoning chain
- First 3 experiments:
  1. Run a simple query with complete evidence to verify basic functionality and justification generation
  2. Run a query with missing evidence to test the system's ability to generate multiple models based on assumptions
  3. Test the system's handling of exceptions by creating a case where a requirement is met but an exception applies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can s(LAW) be extended to handle more complex legal scenarios involving multiple competing discretionary criteria beyond the Spanish school admissions case?
- Basis in paper: [inferred] The paper mentions this is a future research direction: "Second, we want to explore the combination of different rule-based techniques to create a hybrid model where (i) the legislation is modeled as rules, (ii) previous sentences are stored in databases..."
- Why unresolved: The current implementation focuses on a specific case study. Scaling to more complex, real-world legal scenarios with multiple competing criteria would require additional research.
- What evidence would resolve it: A study demonstrating s(LAW)'s effectiveness in handling a more complex legal case involving multiple competing discretionary criteria, with a comparison to other approaches.

### Open Question 2
- Question: How can s(LAW) be integrated with machine learning techniques to improve its ability to handle ambiguous and incomplete information in legal reasoning?
- Basis in paper: [inferred] The paper mentions the need for "inductive logic programming (instead of machine learning) to 'learn' rules from reduced number of landmark cases" as a future research direction.
- Why unresolved: While s(LAW) can handle ambiguity and incomplete information, incorporating machine learning techniques could potentially improve its performance in these areas.
- What evidence would resolve it: A study demonstrating how s(LAW) can be integrated with machine learning techniques to improve its ability to handle ambiguous and incomplete information, with a comparison to other approaches.

### Open Question 3
- Question: How can s(LAW) be used to model and reason about legal concepts that are not explicitly defined in the legislation, such as "unjust enrichment" or "good faith"?
- Basis in paper: [inferred] The paper mentions the need to "complete the modeling of the legislation by tabulation for each of the criteria used in the procedure for adjudication of school places" as a future research direction. This suggests that s(LAW) could potentially be used to model and reason about legal concepts that are not explicitly defined in the legislation.
- Why unresolved: The current implementation focuses on explicitly defined legal concepts. Modeling and reasoning about legal concepts that are not explicitly defined would require additional research.
- What evidence would resolve it: A study demonstrating how s(LAW) can be used to model and reason about legal concepts that are not explicitly defined in the legislation, with a comparison to other approaches.

## Limitations
- Evaluation relies on a single case study (Spanish school admissions), limiting generalizability to other legal domains
- Framework assumes legal experts can effectively interpret multiple partial models, but decision paralysis could occur with too many interpretations
- Natural language justification system depends on manually crafted patterns, which may not scale to complex legal reasoning without significant maintenance overhead

## Confidence

- High confidence: The core claim that s(CASP) can generate multiple partial models for ambiguous legal concepts is well-supported by the demonstrated encoding of "force majeure" and discretionary criteria.
- Medium confidence: The claim about natural language justification interpretability is supported by examples but lacks evaluation with actual legal experts.
- Medium confidence: The scalability advantage over traditional ASP systems is theoretically justified but not empirically validated against large-scale legal datasets.

## Next Checks

1. Test the system with a larger, more complex legal dataset (e.g., full Spanish civil code or multiple jurisdictions) to evaluate scalability and grounding avoidance claims.
2. Conduct user studies with legal practitioners to assess whether the natural language justifications are sufficiently clear and useful for real-world decision-making.
3. Measure the system's behavior when processing cases with high ambiguity where multiple interpretations could lead to significantly different outcomes, evaluating whether the multi-model approach aids or hinders legal reasoning.