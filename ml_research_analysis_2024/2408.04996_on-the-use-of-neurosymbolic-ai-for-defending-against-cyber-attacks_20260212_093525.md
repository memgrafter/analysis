---
ver: rpa2
title: On the use of neurosymbolic AI for defending against cyber attacks
arxiv_id: '2408.04996'
source_url: https://arxiv.org/abs/2408.04996
tags:
- knowledge
- cyber
- symbolic
- alerts
- nesy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper makes the case for combining connectionist and symbolic
  AI (neurosymbolic AI) to address key challenges in defending against cyber attacks.
  The authors identify a set of challenges faced by security practitioners using AI
  today, including improving ML model accuracy under real-world conditions, learning
  from small labelled datasets, integrating knowledge into ML models, automating threat
  hunting, handling alert fatigue, combining observations with knowledge for analysis,
  understanding incident risk and impact, generating explainable response actions,
  and producing tailored incident reports.
---

# On the use of neurosymbolic AI for defending against cyber attacks

## Quick Facts
- arXiv ID: 2408.04996
- Source URL: https://arxiv.org/abs/2408.04996
- Reference count: 40
- This paper proposes neurosymbolic AI approaches to address key challenges in defending against cyber attacks

## Executive Summary
This paper argues for combining connectionist and symbolic AI approaches to overcome limitations in current AI-based cyber defense systems. The authors identify key challenges faced by security practitioners including improving ML model accuracy under real-world conditions, learning from small labeled datasets, integrating knowledge into ML models, automating threat hunting, handling alert fatigue, combining observations with knowledge for analysis, understanding incident risk and impact, generating explainable response actions, and producing tailored incident reports. Through two proof-of-concept experiments using Logic Tensor Networks for intrusion detection and LLMs with temporal logic for attack plan recognition, the paper demonstrates the potential of neurosymbolic approaches to address these real-world challenges.

## Method Summary
The paper proposes two neurosymbolic approaches to improve cyber defense: (1) using Logic Tensor Networks to improve intrusion detection by incorporating domain knowledge through logical axioms that constrain neural network predictions, and (2) using LLMs combined with temporal logic and Answer Set Programming to relate phases of cyber attacks by mapping observed alerts to attack patterns extracted from CTI reports. The first experiment involves training a neural network on the CICIDS2017 dataset and then extending it with LTN incorporating domain knowledge axioms. The second experiment uses an LLM to extract LTL representations from CTI reports, which are then processed by telingo to postdict possible attacks from observed alert sequences.

## Key Results
- Logic Tensor Networks improved intrusion detection precision from 0.70 to 0.91 and recall from 0.92 to 0.98 by incorporating domain knowledge
- LLMs combined with ASP successfully extracted attack patterns from CTI reports and related them to observed alerts
- Neurosymbolic approaches showed promise for addressing multiple SOC challenges including detection accuracy, explainability, and automated analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Logic Tensor Networks improve intrusion detection accuracy by encoding domain knowledge as logical axioms that constrain the neural network's predictions
- Mechanism: LTN defines a membership predicate as a neural network and uses logical axioms to enforce relationships between classes, training maximizes accumulated truth value of axioms
- Core assumption: The logical axioms correctly represent domain knowledge that reduces false positives without significantly increasing false negatives
- Evidence anchors: [abstract] "using Logic Tensor Networks to improve intrusion detection by incorporating domain knowledge"; [section] "we define the following axioms... ∀x∈ NWS : ¬(P(x, Brute force)∨ P(x, XSS))"
- Break condition: If the domain knowledge axioms are incorrect or incomplete, the LTN may incorrectly filter legitimate traffic or fail to improve accuracy

### Mechanism 2
- Claim: LLMs combined with temporal logic and ASP can relate phases of cyber attacks by mapping observed alerts to attack patterns extracted from CTI reports
- Mechanism: LLMs extract formal representations of attack patterns from CTI reports in natural language, while ASP reasons about sequences of observed alerts to determine if they match known attack patterns
- Core assumption: The LLM can accurately extract attack patterns from natural language CTI reports and the ASP solver can correctly reason about temporal relationships between alerts
- Evidence anchors: [abstract] "using LLMs with temporal logic and ASP to relate phases of cyber attacks from alerts and CTI"; [section] "The experiment is inspired by existing work such as: neurosymbolic plan recognition [6], attack plan recognition [7], and the use of LLMs to extract both LTL [32]"
- Break condition: If the LLM fails to accurately extract attack patterns or the temporal reasoning in ASP is too restrictive/permissive, the system may miss attack phases or generate false correlations

### Mechanism 3
- Claim: Neurosymbolic RL combines the sample efficiency of planning with the adaptability of RL, making it suitable for generating timely, risk-aware response actions in SOCs
- Mechanism: Neurosymbolic RL uses symbolic knowledge to guide exploration and planning, reducing the number of interactions needed compared to pure RL while maintaining adaptability to changing environments
- Core assumption: Symbolic knowledge about the environment and attack patterns can effectively guide the RL agent to learn appropriate response policies without extensive exploration
- Evidence anchors: [abstract] "generating explainable response actions" and "in a timely manner"; [section] "Neurosymbolic reinforcement learning (NeuroRL) [3] combines the respective advantages of reinforcement learning and AI planning"
- Break condition: If the symbolic knowledge is incomplete or the environment is too complex for the planning component, the NeuroRL agent may fail to generate effective responses or require extensive retraining

## Foundational Learning

- Concept: MAPE-K reference model (Monitor-Analyze-Plan-Execute over shared Knowledge)
  - Why needed here: The paper structures all challenges and use cases around this model, showing how neurosymbolic AI can be applied across different phases of incident management
  - Quick check question: What are the four phases of the MAPE-K model and what is the role of the shared Knowledge component?

- Concept: Logic Tensor Networks (LTNs)
  - Why needed here: LTN is used in the first experiment to demonstrate how symbolic knowledge can be embedded into neural networks for improved detection
  - Quick check question: How does LTN combine neural networks with first-order logic, and what is the role of the Real Logic language?

- Concept: Temporal Logic (LTLf) and Answer Set Programming (ASP)
  - Why needed here: These are combined in the second experiment to reason about sequences of alerts and relate them to attack phases
  - Quick check question: What is the difference between LTL and LTLf, and how does telingo use ASP to reason about temporal programs?

## Architecture Onboarding

- Component map: NetFlow entries → ML model → Alerts → LTN reasoning → Filtered alerts; Alerts + CTI → LLM extraction → LTLf patterns → ASP reasoning → Attack phase correlation; Incident context → NeuroRL agent → Response action → Execution
- Critical path: For detection: Events → ML model → Alerts → LTN reasoning → Filtered alerts. For analysis: Alerts + CTI → LLM extraction → LTLf patterns → ASP reasoning → Attack phase correlation. For response: Incident context → NeuroRL agent → Response action → Execution
- Design tradeoffs: Accuracy vs. explainability (pure ML vs. neurosymbolic), real-time performance vs. complex reasoning (simple models vs. LTN/ASP), generalization vs. specialization (broad detection vs. domain-specific knowledge)
- Failure signatures: High false positive rates (knowledge axioms too restrictive), missed attack phases (temporal reasoning too strict), slow response generation (NeuroRL requires too much planning), model drift (concept drift not handled)
- First 3 experiments:
  1. Implement a simple LTN with domain knowledge axioms on a small network traffic dataset and measure precision/recall improvement
  2. Use an LLM to extract LTL patterns from CTI reports and validate against known attack descriptions
  3. Implement a NeuroRL agent with symbolic guidance for a simple cyber defense scenario and compare sample efficiency to pure RL

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific improvements in detection accuracy can be achieved when combining symbolic knowledge with ML models in real-world SOC environments?
- Basis in paper: [explicit] The paper discusses using LTN to improve intrusion detection by incorporating domain knowledge, showing nearly doubled precision in a simplified experiment
- Why unresolved: The experiment was conducted in a simplified setting with a limited dataset and a basic neural network architecture. Real-world SOC environments involve more complex data, noise, and evolving threats
- What evidence would resolve it: Conducting experiments with state-of-the-art detectors, using realistic datasets with concept drift, and evaluating performance in live SOC environments would provide evidence of the actual improvements achievable

### Open Question 2
- Question: How can LLMs be effectively integrated with symbolic reasoning techniques to support automated threat hunting in SOCs?
- Basis in paper: [explicit] The paper proposes using LLMs for hypothesis generation in threat hunting and combining them with symbolic knowledge and reasoning capabilities
- Why unresolved: While the paper suggests potential integration methods, it does not provide concrete implementations or evaluate the effectiveness of such integrations in real SOC scenarios
- What evidence would resolve it: Developing and testing LLM-driven threat hunting systems that integrate with existing SOC tools and knowledge bases, and evaluating their performance in identifying and validating hypotheses would provide evidence of their effectiveness

### Open Question 3
- Question: What are the most effective ways to represent and reason about knowledge in cyber threat intelligence to support situational awareness and decision-making in SOCs?
- Basis in paper: [explicit] The paper discusses the challenges of combining observations with knowledge for analysis and proposes using knowledge graphs and probabilistic reasoning
- Why unresolved: The paper does not provide specific methodologies for representing and reasoning about CTI knowledge, nor does it evaluate the effectiveness of different approaches in supporting SOC decision-making
- What evidence would resolve it: Developing and testing different knowledge representation and reasoning frameworks, such as probabilistic attack graphs or temporal logic-based systems, and evaluating their impact on SOC situational awareness and response times would provide evidence of their effectiveness

## Limitations

- The effectiveness of knowledge integration depends heavily on the quality and completeness of domain axioms and threat intelligence, which may not always be available or accurate in real-world SOC environments
- The computational overhead of neurosymbolic reasoning could impact real-time performance, particularly for complex ASP-based attack correlation
- The experiments presented are proof-of-concept demonstrations rather than comprehensive evaluations across diverse attack scenarios and datasets

## Confidence

- **High**: The identification of specific challenges in current AI-based cyber defense (alert fatigue, explainability, sample efficiency)
- **Medium**: The feasibility of LTN for intrusion detection improvement based on limited experimental results
- **Low**: The practical scalability of LLM+ASP approaches for real-time attack plan recognition across diverse CTI sources

## Next Checks

1. Conduct extensive evaluation of LTN performance across multiple intrusion detection datasets with varying domain knowledge completeness
2. Test LLM+ASP attack correlation with diverse, real-world CTI reports and measure accuracy against ground truth attack sequences
3. Benchmark computational overhead and latency of neurosymbolic components compared to pure ML approaches in real-time SOC environments