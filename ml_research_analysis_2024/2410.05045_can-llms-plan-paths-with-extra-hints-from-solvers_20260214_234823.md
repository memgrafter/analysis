---
ver: rpa2
title: Can LLMs plan paths with extra hints from solvers?
arxiv_id: '2410.05045'
source_url: https://arxiv.org/abs/2410.05045
tags:
- planning
- problems
- llms
- hints
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the capabilities of large language models
  (LLMs) in solving 2D path planning problems with solver-generated feedback. The
  authors evaluate three LLMs (GPT-4o, Gemini Pro 1.5, and Claude 3.5 Sonnet) on a
  benchmark of 10 handcrafted and 100 randomly generated planning problems.
---

# Can LLMs plan paths with extra hints from solvers?

## Quick Facts
- arXiv ID: 2410.05045
- Source URL: https://arxiv.org/abs/2410.05045
- Authors: Erik Wu; Sayan Mitra
- Reference count: 40
- Large language models significantly improve path planning performance when provided with solver-generated feedback

## Executive Summary
This paper investigates whether large language models can solve 2D path planning problems when provided with feedback from SMT solvers. The authors evaluate three prominent LLMs (GPT-4o, Gemini Pro 1.5, and Claude 3.5 Sonnet) on a benchmark of 10 handcrafted and 100 randomly generated planning problems. They implement a closed-loop prompting framework that iteratively provides solver-generated hints to improve LLM-generated paths, testing four different hint types: collision detection, free space suggestions, correct prefix validation, and image-based hints.

The results demonstrate that solver-generated feedback substantially improves LLM performance on moderately difficult problems, with success rates reaching 90% for problems with 1-3 obstacles. However, the hardest problems requiring 25-segment paths remained unsolvable even with maximum hints. The study also reveals that different LLMs exhibit distinct planning tendencies, with GPT-4o generating diagonal paths while Gemini and Claude produce primarily orthogonal paths. Fine-tuning the models on path planning tasks further enhanced their performance, while image hints provided no additional benefit despite LLMs' strong image comprehension in other contexts.

## Method Summary
The authors implement a closed-loop prompting framework where LLMs generate path planning solutions that are evaluated by an SMT solver (Z3). Based on solver analysis, targeted hints are generated and provided to the LLM in subsequent iterations. The framework tests four hint strategies: collision hints (identifying where paths intersect obstacles), free space hints (suggesting obstacle-free waypoints), correct prefix hints (affirming valid path segments), and image hints (visual problem representations). The LLMs are evaluated on 10 handcrafted and 100 randomly generated 2D path planning problems with quadrilateral obstacles. Additionally, the models are fine-tuned on 200 randomly generated problem-solution pairs to assess performance improvements.

## Key Results
- Solver-generated feedback significantly improves LLM performance on moderately difficult problems, with 90% success rates for 1-3 obstacle problems
- The hardest problems requiring 25-segment paths remained unsolvable even with maximum hints
- Different LLMs exhibit distinct planning tendencies: GPT-4o generates diagonal paths while Gemini and Claude produce primarily orthogonal paths
- Fine-tuning substantially enhances performance on both moderate and hard problems
- Image hints provide no additional benefit despite LLMs' strong image comprehension in other contexts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Solver-generated feedback significantly improves LLM performance on moderately difficult path planning problems.
- Mechanism: The closed-loop prompting framework provides the LLM with iterative, targeted hints generated by an SMT solver that identifies specific errors in the proposed paths (e.g., collisions, incorrect prefixes, free space opportunities).
- Core assumption: LLMs can effectively incorporate and act on precise, problem-specific feedback to iteratively refine their solutions.
- Evidence anchors:
  - [abstract] "solver-generated feedback improves the LLM's ability to solve the moderately difficult problems"
  - [section III-C.1] "With collision hints, Claude 3.5 Sonnet consistently achieves a success rate of 90% for problems involving 1, 2, and 3 obstacles"
  - [corpus] Weak evidence - the related papers focus on planning with LLMs but don't directly address solver-generated feedback mechanisms
- Break condition: If the solver feedback becomes too generic or the LLM cannot interpret the hints correctly, the iterative improvement loop fails.

### Mechanism 2
- Claim: Different LLMs exhibit distinct planning tendencies that affect their problem-solving approaches.
- Mechanism: The architectural and training differences between LLMs lead to systematic variations in how they generate paths - some favor orthogonal movements while others generate diagonal paths.
- Core assumption: LLM architectures and training data create inherent biases in path generation strategies.
- Evidence anchors:
  - [section III-C.5] "Gemini and Claude tend to generate axis-aligned paths, while GPT-4o frequently produces paths with diagonal segments"
  - [section III-C.5] "GPT-4o consistently outperformed Gemini and Claude on the Canyon problem but was completely unable to solve Diagonal Wall"
  - [corpus] Weak evidence - the related papers don't discuss architectural differences in planning strategies
- Break condition: If problem requirements change (e.g., requiring diagonal movement) and the LLM's tendency doesn't match, performance degrades significantly.

### Mechanism 3
- Claim: Fine-tuning LLMs on path planning tasks substantially enhances their performance on both moderate and hard problems.
- Mechanism: Supervised training on application-specific datasets allows LLMs to develop task-specific reasoning patterns and solution strategies.
- Core assumption: LLMs can effectively learn from task-specific examples to improve their planning capabilities beyond general prompting strategies.
- Evidence anchors:
  - [abstract] "Fine-tuning the models on path planning tasks substantially enhanced their performance"
  - [section III-C.4] "Fine-tuning (see Section II-C) led to a noticeable improvement in the length of the paths found"
  - [corpus] Weak evidence - the related papers don't discuss fine-tuning for path planning specifically
- Break condition: If the fine-tuning dataset is too small or not representative of the problem space, improvements may be limited or inconsistent.

## Foundational Learning

- Concept: Satisfiability Modulo Theory (SMT) solvers
  - Why needed here: SMT solvers are used to generate precise, verifiable hints about path validity (collisions, prefixes, free spaces) that guide LLM improvements
  - Quick check question: How does an SMT solver verify that a path segment intersects with a convex obstacle?

- Concept: Closed-loop feedback systems
  - Why needed here: The iterative prompting framework relies on a feedback loop where the LLM's output is analyzed and used to generate targeted hints for the next iteration
  - Quick check question: What are the three main components of the closed-loop prompting system described in the paper?

- Concept: Path planning problem formulation
  - Why needed here: Understanding how path planning problems are formalized (initial/goal positions, obstacle sets) is essential for implementing the hint generation system
  - Quick check question: What makes a path "correct" in the context of this 2D path planning problem?

## Architecture Onboarding

- Component map: LLM API interface -> Prompt generator with hint strategies -> SMT solver (Z3) for constraint verification -> Problem generator -> Evaluation metrics collector

- Critical path: Prompt → LLM solution → SMT analysis → Hint generation → Updated prompt → Repeat until success or iteration limit

- Design tradeoffs:
  - Hint specificity vs. computational cost (more detailed hints require more solver time)
  - Iteration limits vs. solution quality (longer iterations may find better solutions)
  - LLM choice vs. problem type (some LLMs perform better on specific problem characteristics)

- Failure signatures:
  - LLM generates identical incorrect paths across iterations (hint misinterpretation)
  - Solver timeouts during hint generation (computational bottleneck)
  - Success rate plateaus below 100% for problems with X obstacles (architectural limitation)

- First 3 experiments:
  1. Test collision hints on Easy problem with all three LLMs to verify basic feedback loop functionality
  2. Compare orthogonal vs. diagonal path generation on Canyon problem to observe LLM tendencies
  3. Run fine-tuning on a small dataset and measure improvement on Box problem

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do image hints fail to improve LLM performance in path planning when LLMs demonstrate strong image comprehension in other contexts?
- Basis in paper: [explicit] "image hints, did not appear to enhance the LLM’s path-planning performance" and "This outcome is surprising, given that LLMs have demonstrated strong image comprehension in other contexts"
- Why unresolved: The paper notes the surprising ineffectiveness of image hints but does not investigate the underlying reasons for this discrepancy.
- What evidence would resolve it: Comparative analysis of how LLMs process spatial information in textual vs. visual formats for path planning tasks, and experiments testing whether the format of visual representation affects performance.

### Open Question 2
- Question: Would incorporating dynamic constraints and agent geometry into path planning tasks improve LLM performance on harder problems?
- Basis in paper: [explicit] "For planned paths to be useful, the should be path dynamically feasible... Such dynamic or nonholonomic constraints are currently not included in our framework"
- Why unresolved: The paper acknowledges this limitation but does not test whether adding these constraints would help or hinder LLM performance.
- What evidence would resolve it: Experiments comparing LLM performance on path planning tasks with and without dynamic constraints and agent geometry considerations.

### Open Question 3
- Question: Would presenting path planning problems in real-world contexts with geographical data and realistic maps improve LLM performance compared to abstract obstacles and free-space?
- Basis in paper: [explicit] "we conjecture that attaching the planning problems to real world data that is supposedly embedded in the LLM will improve their performance"
- Why unresolved: The paper only speculates about this potential improvement without testing it empirically.
- What evidence would resolve it: Experiments comparing LLM performance on abstract path planning problems versus equivalent problems presented in real-world geographical contexts.

## Limitations
- The evaluation focuses on a relatively small benchmark of 10 handcrafted and 100 randomly generated problems, which may not capture the full diversity of real-world scenarios
- The closed-loop framework shows promising results for moderately difficult problems but fails to solve the hardest problems requiring 25-segment paths
- The study lacks baseline comparisons against traditional planning algorithms to establish relative effectiveness
- The finding that image hints provide no additional benefit is surprising and warrants further investigation

## Confidence
- Medium: The improvement from solver-generated feedback is well-documented with specific success rates, but the lack of baseline comparisons and limited problem diversity reduce confidence in generalizing these results

## Next Checks
1. Test the closed-loop framework on problems with mixed obstacle shapes (circles, irregular polygons) to assess generalization beyond quadrilateral obstacles
2. Compare LLM performance with traditional graph-based planners on the same benchmark to establish relative effectiveness
3. Conduct ablation studies on hint specificity levels to determine the optimal balance between hint detail and computational cost