---
ver: rpa2
title: 'ADAM: An Embodied Causal Agent in Open-World Environments'
arxiv_id: '2410.22194'
source_url: https://arxiv.org/abs/2410.22194
tags:
- items
- arxiv
- causal
- adam
- iron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents ADAM, an embodied causal agent designed for
  open-world environments like Minecraft. The core idea is to integrate causal methods
  with embodied agents to enable continuous learning of structured knowledge, particularly
  causality, from scratch.
---

# ADAM: An Embodied Causal Agent in Open-World Environments

## Quick Facts
- arXiv ID: 2410.22194
- Source URL: https://arxiv.org/abs/2410.22194
- Authors: Shu Yu; Chaochao Lu
- Reference count: 32
- Primary result: ADAM constructs causal graphs from scratch, achieving 4.6× speedup in obtaining raw iron in modified Minecraft environments

## Executive Summary
ADAM introduces an embodied causal agent designed for open-world environments like Minecraft. The agent integrates causal methods with embodied exploration to enable continuous learning of structured knowledge, particularly causality, from scratch. Unlike existing agents that rely on prior knowledge and black-box models, ADAM constructs an ever-growing causal graph through interaction and intervention-based causal discovery, enabling efficient task decomposition and execution with strong interpretability.

The paper demonstrates that ADAM maintains performance in modified Minecraft environments where prior knowledge is invalid, showing remarkable robustness and generalization capability. By learning causal relationships from scratch rather than relying on pre-existing knowledge, ADAM adapts to changes in game dynamics and achieves significant speedups compared to state-of-the-art methods. The approach pioneers a novel paradigm that synergistically integrates causal methods and embodied agents.

## Method Summary
ADAM comprises four modules: interaction, causal model, controller, and perception. The interaction module executes actions and records observable information from the environment. The causal model module contains LLM-based causal discovery (CD) and intervention-based CD for constructing causal graphs. The controller module includes a planner that decomposes tasks using the learned causal graph and an actor that executes actions, with memory tracking long-term context. The perception module uses multimodal large language models (MLLMs) to convert game images to text descriptions. ADAM learns causal relationships from scratch through embodied exploration and intervention-based causal discovery, enabling task decomposition and execution in modified Minecraft environments.

## Key Results
- ADAM constructs an almost perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability
- In modified Minecraft games where no prior knowledge is available, ADAM maintains performance and shows remarkable robustness
- ADAM achieves a 4.6× speedup in obtaining raw iron compared to the state-of-the-art

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ADAM constructs an almost perfect causal graph from scratch through embodied exploration and intervention-based causal discovery
- Mechanism: The agent interacts with the environment, collecting data on action-item dependencies. LLM-based causal discovery makes initial assumptions, which are refined through intervention-based causal discovery by systematically removing items and observing effects
- Core assumption: The causal relationships between items and actions in Minecraft are stable and repeatable across different runs
- Evidence anchors:
  - [abstract] "ADAM constructs an almost perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability"
  - [section] "Intervention-based CD performs sampling(a, C \ {c}, I1) for each item c ∈ C. For each item e ∈ E, if there is always e ∉ I1 within a maximum number of samplings, then c is the cause of e, and the edge c → e is retained"
  - [corpus] Weak evidence - The related work focuses on Minecraft agents with knowledge graphs or causal reasoning but doesn't directly address causal graph construction from scratch through embodied exploration
- Break condition: If the causal relationships in the environment are non-stationary or context-dependent, the intervention-based refinement would fail to identify stable causal edges

### Mechanism 2
- Claim: ADAM maintains performance in modified Minecraft environments where prior knowledge is invalid
- Mechanism: By learning causal relationships from scratch rather than relying on prior knowledge, ADAM can adapt to changes in the game dynamics. The intervention-based causal discovery identifies the actual dependencies in the modified environment
- Core assumption: The LLM-based causal assumptions can be corrected through intervention-based discovery even when initial assumptions are based on invalid prior knowledge
- Evidence anchors:
  - [abstract] "in our modified Minecraft games where no prior knowledge is available, ADAM maintains its performance and shows remarkable robustness and generalization capability"
  - [section] "Intervention-based CD will verify each item in {c1, c2}. When removing c1 from the inventory and executing action a, c1 cannot be obtained, proving that c1 is a dependency of c2, and this edge (c1 → c2) is retained in the causal graph"
  - [corpus] Weak evidence - Related work discusses causal reasoning in Minecraft but doesn't specifically address adaptation to modified game rules
- Break condition: If the modifications are too extensive or the intervention-based discovery is computationally infeasible within the step limit, ADAM would fail to learn the new causal graph

### Mechanism 3
- Claim: ADAM achieves 4.6× speedup in obtaining raw iron compared to state-of-the-art by leveraging causal knowledge for efficient task decomposition
- Mechanism: The learned causal graph enables the planner to decompose complex tasks into subtasks that follow the causal dependencies. The actor executes actions in an order that respects these dependencies, avoiding redundant exploration
- Core assumption: The causal graph accurately represents the true dependencies in the environment, enabling optimal task decomposition
- Evidence anchors:
  - [abstract] "ADAM maintains its performance and shows remarkable robustness and generalization capability, achieving a 4.6× speedup in obtaining raw iron compared to the state-of-the-art"
  - [section] "The Planner utilizes LLMs to decompose the task with current inventory It at step t and the learned causal graph"
  - [corpus] Weak evidence - Related work mentions task decomposition but doesn't specifically quantify speedups achieved through causal knowledge
- Break condition: If the causal graph contains errors or omissions, the task decomposition would be suboptimal, leading to inefficient exploration

## Foundational Learning

- Concept: Causal Discovery
  - Why needed here: ADAM needs to learn the causal relationships between items and actions from scratch without prior knowledge
  - Quick check question: How does intervention-based causal discovery differ from observational causal discovery in terms of identifying causal relationships?

- Concept: Embodied Exploration
  - Why needed here: ADAM learns causal relationships through interaction with the Minecraft environment rather than from pre-existing knowledge
  - Quick check question: What are the advantages of learning causal relationships through embodied exploration compared to learning from pre-collected datasets?

- Concept: Multimodal Perception
  - Why needed here: ADAM uses visual information from the environment rather than relying on omniscient metadata, aligning its behavior with human gameplay
  - Quick check question: How does using only observable information (pixels and inventory) rather than metadata affect the agent's ability to perform tasks that require environmental awareness?

## Architecture Onboarding

- Component map: Interaction Module -> Causal Model Module -> Controller Module -> Perception Module -> Task Execution -> New Items -> Interaction
- Critical path: Interaction → Causal Model → Controller → Task Execution → New Items → Interaction (lifelong learning loop)
- Design tradeoffs:
  - LLM-based CD vs direct causal discovery: LLM-based CD reduces complexity but introduces potential errors
  - Intervention-based CD sampling: More samples increase accuracy but slow down learning
  - MLLM perception vs metadata: MLLMs align with human gameplay but may miss environmental details
- Failure signatures:
  - Causal graph construction fails: SHD (Structural Hamming Distance) between learned and target graph is high
  - Task execution fails: Agent cannot complete tasks within step limits despite having required items in causal graph
  - Exploration inefficiency: Agent takes many redundant steps exploring known areas
- First 3 experiments:
  1. Test causal graph construction on a simple crafting chain (e.g., log → planks → sticks → crafting_table)
  2. Evaluate task execution efficiency on obtaining wooden tools using the learned causal graph
  3. Assess adaptation to modified recipes by changing one dependency and measuring recovery time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ADAM change when deployed in Minecraft environments with significantly different game dynamics, such as custom crafting recipes or altered resource distributions?
- Basis in paper: [explicit] The paper mentions that ADAM maintains performance in modified Minecraft games where crafting recipes are altered, but it does not provide detailed results for other types of modifications
- Why unresolved: The experiments in the paper focus on a specific type of modification (crafting recipes), and there is limited information on how ADAM performs with other environmental changes
- What evidence would resolve it: Conducting experiments with various types of modifications in Minecraft, such as different resource distributions or game rules, and comparing ADAM's performance to other methods would provide insights into its adaptability and robustness

### Open Question 2
- Question: How does the integration of additional sensory inputs, such as sound or touch, affect the performance and interpretability of ADAM in open-world environments?
- Basis in paper: [inferred] The paper discusses the use of multimodal LLMs for visual perception in ADAM but does not explore the integration of other sensory modalities
- Why unresolved: The current implementation focuses on visual input, and the potential benefits or challenges of incorporating additional sensory data are not addressed
- What evidence would resolve it: Implementing and testing ADAM with additional sensory inputs, such as audio or haptic feedback, and evaluating its performance and interpretability in tasks that require these modalities would clarify their impact

### Open Question 3
- Question: What are the limitations of the causal discovery methods used in ADAM when dealing with highly dynamic or stochastic environments, and how can they be addressed?
- Basis in paper: [explicit] The paper mentions that ADAM uses LLM-based and intervention-based causal discovery methods, but it does not discuss their limitations in dynamic or stochastic settings
- Why unresolved: The paper does not explore scenarios where the environment's dynamics change rapidly or introduce high levels of uncertainty, which could challenge the causal discovery process
- What evidence would resolve it: Conducting experiments in environments with high variability or stochastic elements and analyzing the accuracy and efficiency of ADAM's causal discovery methods would highlight their limitations and potential improvements

## Limitations
- Reliance on LLM-based causal discovery introduces potential errors that are refined through intervention-based methods
- Limited evidence for scalability to environments with more complex causal structures
- Computational overhead of intervention-based sampling may impact real-time decision-making

## Confidence
- **High Confidence**: ADAM's ability to learn causal graphs from scratch and maintain performance in modified environments
- **Medium Confidence**: The 4.6× speedup claim (based on comparison with specific baselines in controlled settings)
- **Medium Confidence**: The claim that LLM-based CD combined with intervention-based CD produces "almost perfect" causal graphs (requires more extensive validation across diverse scenarios)

## Next Checks
1. **Stress Test Causal Graph Accuracy**: Evaluate ADAM's causal graph construction accuracy across a wider range of crafting recipes and environmental modifications, measuring SHD (Structural Hamming Distance) against ground truth in progressively more complex scenarios
2. **Computational Efficiency Analysis**: Measure the computational overhead of intervention-based causal discovery compared to pure LLM-based approaches, particularly in environments requiring rapid decision-making under time constraints
3. **Cross-Environment Transferability**: Test ADAM in multiple open-world environments beyond Minecraft (e.g., virtual robotics simulators, different game engines) to assess the generalizability of the causal learning approach and identify environment-specific limitations