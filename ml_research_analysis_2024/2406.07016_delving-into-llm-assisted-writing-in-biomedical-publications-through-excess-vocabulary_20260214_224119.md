---
ver: rpa2
title: Delving into LLM-assisted writing in biomedical publications through excess
  vocabulary
arxiv_id: '2406.07016'
source_url: https://arxiv.org/abs/2406.07016
tags:
- frequency
- words
- excess
- usage
- writing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study addresses the growing use of LLMs like ChatGPT in academic\
  \ writing by introducing an unbiased, large-scale approach to quantify their prevalence.\
  \ The researchers analyzed over 14 million PubMed abstracts from 2010\u20132024,\
  \ tracking changes in vocabulary after ChatGPT's release."
---

# Delving into LLM-assisted writing in biomedical publications through excess vocabulary

## Quick Facts
- **arXiv ID:** 2406.07016
- **Source URL:** https://arxiv.org/abs/2406.07016
- **Authors:** Dmitry Kobak; Rita González-Márquez; Emőke-Ágnes Horvát; Jan Lause
- **Reference count:** 40
- **Primary result:** At least 13.5% of 2024 biomedical abstracts show signs of LLM processing, marking unprecedented linguistic change

## Executive Summary
This study addresses the growing use of LLMs like ChatGPT in academic writing by introducing an unbiased, large-scale approach to quantify their prevalence. The researchers analyzed over 14 million PubMed abstracts from 2010–2024, tracking changes in vocabulary after ChatGPT's release. They identified "excess words" that showed a significant increase in usage, finding that at least 13.5% of 2024 abstracts were processed with LLMs. This LLM-induced change in scientific writing was unprecedented, surpassing even the impact of the COVID-19 pandemic. The study revealed significant heterogeneity across disciplines, countries, and journals, with some reaching 40% LLM usage. This data-driven approach provides a valuable tool for monitoring LLM adoption in academia and informing future policies.

## Method Summary
The researchers analyzed over 14 million PubMed abstracts from 2010–2024 using a novel "excess words" methodology. They tracked vocabulary changes by identifying words that showed statistically significant increases in usage frequency after ChatGPT's release in late 2022. The approach compared post-2022 linguistic patterns against historical baselines from 2010–2022, accounting for normal linguistic evolution. By focusing on words that exceeded expected frequency increases, they created a quantitative measure of LLM influence on scientific writing that could be applied at scale across different disciplines and publication venues.

## Key Results
- At least 13.5% of 2024 biomedical abstracts show evidence of LLM processing
- LLM-induced linguistic change in scientific writing was unprecedented, exceeding even COVID-19's impact
- Significant heterogeneity in LLM usage across disciplines, countries, and journals, with some reaching 40% usage

## Why This Works (Mechanism)
The study's approach works by exploiting the characteristic linguistic patterns introduced by LLMs into academic writing. Large language models tend to favor certain phrases and word choices that differ from traditional scientific writing conventions, creating a detectable statistical signature in text corpora. By establishing pre-2022 baselines of normal linguistic evolution and then measuring deviations that exceed these patterns, the researchers could identify the "excess words" that correlate with LLM adoption. This methodology effectively captures the quantitative impact of LLM usage without requiring direct detection of the models themselves.

## Foundational Learning
- **Excess words identification**: Statistical detection of vocabulary anomalies beyond normal linguistic evolution - needed to isolate LLM-specific linguistic patterns; quick check: verify words exceed historical growth rates
- **Corpus-scale analysis**: Processing millions of abstracts to establish reliable baselines - needed for statistical power across disciplines; quick check: ensure sample size maintains significance
- **Temporal pattern recognition**: Comparing pre- and post-2022 vocabulary changes - needed to attribute changes specifically to LLM adoption; quick check: confirm patterns differ from historical trends
- **Cross-disciplinary validation**: Testing methodology across different biomedical fields - needed to ensure generalizability; quick check: verify consistent excess word detection across specialties
- **Country-level heterogeneity analysis**: Examining geographic variations in LLM usage - needed to understand adoption patterns; quick check: confirm statistical significance of regional differences

## Architecture Onboarding
- **Component map**: PubMed abstracts (2010-2024) -> Vocabulary frequency analysis -> Excess word identification -> LLM usage estimation
- **Critical path**: Text preprocessing → Historical baseline establishment → Post-2022 comparison → Statistical significance testing → Prevalence calculation
- **Design tradeoffs**: Sensitivity vs. specificity balance - favoring conservative estimates to avoid false positives; scalability vs. granularity - choosing corpus-wide analysis over individual paper verification
- **Failure signatures**: False positives from genuine linguistic evolution, false negatives from subtle LLM editing, bias from disciplinary writing conventions
- **Three first experiments**: 1) Validate excess word detection on known LLM-generated abstracts, 2) Test method sensitivity with controlled vocabulary variations, 3) Compare results across different biomedical subfields

## Open Questions the Paper Calls Out
None

## Limitations
- The method cannot definitively prove LLM usage, only identify statistical anomalies in word frequency patterns
- The 13.5% figure represents a conservative lower bound estimate
- The approach may have false positives from genuine linguistic evolution or other text-generation tools

## Confidence
- **High confidence**: The methodology for identifying excess vocabulary is sound and reproducible
- **Medium confidence**: The 13.5% prevalence estimate is reasonable but represents a conservative lower bound
- **Low confidence**: The claim about LLMs' impact being "unprecedented" lacks historical comparison to other technological writing aids

## Next Checks
1. Conduct manual verification on a random sample of high-scoring abstracts to confirm LLM usage patterns
2. Replicate the analysis using abstracts from journals with known LLM usage policies to validate classification accuracy
3. Compare excess word patterns with submissions to preprint servers where LLM usage is explicitly documented