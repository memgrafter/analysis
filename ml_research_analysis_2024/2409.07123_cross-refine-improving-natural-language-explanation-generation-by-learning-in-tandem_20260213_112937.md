---
ver: rpa2
title: 'Cross-Refine: Improving Natural Language Explanation Generation by Learning
  in Tandem'
arxiv_id: '2409.07123'
source_url: https://arxiv.org/abs/2409.07123
tags:
- cross-refine
- explanations
- language
- association
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'CROSS-REFINE improves natural language explanations by using two
  LLMs: one as a generator and another as a critic. The critic provides feedback and
  suggestions to refine the generator''s initial explanations.'
---

# Cross-Refine: Improving Natural Language Explanation Generation by Learning in Tandem

## Quick Facts
- arXiv ID: 2409.07123
- Source URL: https://arxiv.org/abs/2409.07123
- Authors: Qianli Wang; Tatiana Anikina; Nils Feldhus; Simon Ostermann; Sebastian MÃ¶ller; Vera Schmitt
- Reference count: 30
- Primary result: CROSS-REFINE outperforms SELF-REFINE in explanation quality, especially with less powerful LLMs, by using separate generator and critic roles

## Executive Summary
CROSS-REFINE introduces a novel approach to improving natural language explanations by deploying two large language models (LLMs) in tandem: one as a generator and another as a critic. The critic evaluates the generator's initial explanation, provides corrective feedback, and suggests an improved alternative. The generator then refines its explanation using both inputs. This approach outperforms the SELF-REFINE baseline, particularly when using less powerful LLMs, and demonstrates effectiveness in both English and German. The method shows that cross-referencing feedback and suggestions leads to better refinement than single-source feedback.

## Method Summary
CROSS-REFINE uses two LLMs - a generator and a critic - to iteratively refine natural language explanations. The generator creates an initial explanation, which the critic evaluates and responds to with both feedback and a suggested explanation. The generator then refines its output using this dual input. This approach leverages in-context learning through few-shot prompting with FiXer demonstrations and is evaluated across three datasets (ECQA, eSNLI, and HealthFC) in English and German using automated metrics (BLEURT, BARTScore, TIGERScore) and human evaluation.

## Key Results
- CROSS-REFINE consistently outperforms SELF-REFINE across multiple datasets and LLM combinations
- The approach shows particular advantage when using less powerful LLMs as generators
- Both feedback and suggestions are crucial components - ablation studies show removing either degrades performance
- CROSS-REFINE excels when LLMs have domain knowledge but struggles with specialized medical knowledge tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The critic's feedback and suggested explanations enable the generator to correct errors it cannot self-identify
- Core assumption: The critic can identify errors that the generator misses and provide meaningful guidance for improvement
- Evidence anchors: [abstract] LLMs struggle to identify reasoning errors; [section 6.1] CROSS-REFINE with same LLM outperforms SELF-REFINE

### Mechanism 2
- Claim: Role modeling with separate generator and critic LLMs creates specialized focus that improves refinement quality
- Core assumption: Specialization through role separation produces better results than a single model performing both tasks
- Evidence anchors: [abstract] CROSS-REFINE involves deploying separate LLMs for generator and critic roles; [section 6.3] suggestions are as crucial as feedback

### Mechanism 3
- Claim: Cross-referencing feedback and suggestions provides multiple perspectives that lead to better refinement than single-source feedback
- Core assumption: Multiple perspectives (feedback + suggestion) are more effective than single-source feedback for improvement
- Evidence anchors: [section 6.3] Removing suggestions causes sharp reduction in BLEURT and TIGERScore; [section 6.1] CROSS-REFINE outperforms SELF-REFINE

## Foundational Learning

- Concept: In-context learning through demonstration-based prompting
  - Why needed here: CROSS-REFINE relies on few-shot prompting to guide both generator and critic roles without requiring fine-tuning
  - Quick check question: How many demonstrations are typically used in CROSS-REFINE's FiXer collection for effective few-shot prompting?

- Concept: Chain-of-Thought reasoning for explanation generation
  - Why needed here: Both generator and critic need to produce step-by-step reasoning to create coherent explanations and meaningful feedback
  - Quick check question: What template does CROSS-REFINE follow for its explanation generation prompts?

- Concept: Semantic similarity measurement for evaluation
  - Why needed here: Automatic evaluation metrics like BLEURT, BARTScore, and TIGERScore are used to assess explanation quality objectively
  - Quick check question: Which three automated metrics are used to evaluate CROSS-REFINE's refined explanations?

## Architecture Onboarding

- Component map: Input -> Generator LLM -> Initial Explanation -> Critic LLM -> Feedback & Suggestion -> Generator LLM -> Refined Explanation -> Evaluation Metrics

- Critical path:
  1. Input processed by generator to create initial explanation
  2. Initial explanation sent to critic for quality assessment
  3. Critic generates feedback and suggested explanation
  4. Generator refines initial explanation using both feedback and suggestion
  5. Refined explanation evaluated using automated metrics and/or human assessment

- Design tradeoffs:
  - Using two separate LLMs increases computational cost but provides specialized expertise
  - Cross-referencing requires more context length but produces better refinement
  - German language support requires different evaluation metrics due to limited multilingual support

- Failure signatures:
  - Explanations remain unchanged between initial and refined versions (feedback/suggestions ineffective)
  - Refined explanations are shorter or less coherent than initial versions (over-correction)
  - Generator repeats its initial explanation without incorporating feedback (poor cross-referencing)
  - Critic provides generic feedback that doesn't address specific errors

- First 3 experiments:
  1. Test CROSS-REFINE with same LLM as both generator and critic ("self CROSS-REFINE") vs. SELF-REFINE baseline to measure impact of explicit suggestions
  2. Run ablation study removing feedback vs. removing suggestions to quantify each component's contribution
  3. Evaluate CROSS-REFINE on German HealthFC dataset vs. English datasets to assess multilingual performance

## Open Questions the Paper Calls Out

- Question: How does CROSS-REFINE perform when using human-crafted feedback and suggestions instead of LLM-generated ones?
  - Basis in paper: The paper discusses using LLMs as critics but doesn't explore human-generated feedback
  - Why unresolved: The study relies entirely on automated feedback from LLMs
  - What evidence would resolve it: A controlled experiment comparing CROSS-REFINE with human-crafted vs. LLM-generated feedback

- Question: What is the optimal number of demonstrations needed for effective in-context learning in CROSS-REFINE?
  - Basis in paper: The paper mentions using 3-20 shots but doesn't systematically study the optimal number
  - Why unresolved: The demonstration count appears to be chosen based on practical constraints
  - What evidence would resolve it: A study varying the number of demonstrations and measuring impact on explanation quality

- Question: How does CROSS-REFINE scale to languages other than English and German?
  - Basis in paper: The paper only evaluates on English and German datasets
  - Why unresolved: The study is limited to two languages
  - What evidence would resolve it: Systematic evaluation across multiple language families using appropriate datasets

## Limitations

- Domain Knowledge Gap: CROSS-REFINE struggles with tasks requiring specialized knowledge, particularly medical fact-checking
- Limited Multilingual Support: Automatic evaluation metrics are primarily designed for English, with TIGERScore being the only German-specific metric
- Resource Intensiveness: The approach requires two separate LLM invocations plus additional processing, significantly increasing computational costs

## Confidence

- **High Confidence**: The core mechanism of using separate generator and critic roles is well-supported by experimental results showing consistent improvements across multiple datasets and LLM combinations
- **Medium Confidence**: The claim that cross-referencing feedback and suggestions is superior to self-refinement is supported but limited by the relatively small number of datasets tested
- **Low Confidence**: The effectiveness of CROSS-REFINE in domains requiring specialized knowledge (like medical fact-checking) is questionable, as evidenced by poor performance on HealthFC

## Next Checks

1. **Domain Transfer Test**: Evaluate CROSS-REFINE on additional specialized domains (legal reasoning, technical documentation) to determine if performance degradation is consistent across knowledge-intensive tasks or specific to medical content

2. **Single LLM Generalization**: Test whether a single LLM with role-switching (generating then critiquing its own output) can achieve similar improvements to using two separate LLMs

3. **Cost-Benefit Analysis**: Measure the marginal improvement in explanation quality against the increased computational cost of using two LLMs versus single LLM approaches across different model sizes and task complexities