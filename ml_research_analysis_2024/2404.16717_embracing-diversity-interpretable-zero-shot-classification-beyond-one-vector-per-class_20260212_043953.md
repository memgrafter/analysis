---
ver: rpa2
title: 'Embracing Diversity: Interpretable Zero-shot classification beyond one vector
  per class'
arxiv_id: '2404.16717'
source_url: https://arxiv.org/abs/2404.16717
tags:
- class
- classification
- accuracy
- diversity
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a limitation of the one-vector-per-class
  paradigm in zero-shot classification: it fails to adequately represent classes with
  diverse instances, leading to poor performance on atypical examples. The authors
  propose a method to go beyond one vector per class by leveraging the open-vocabulary
  capabilities of vision-language models (VLMs) to explicitly account for intra-class
  diversity.'
---

# Embracing Diversity: Interpretable Zero-shot classification beyond one vector per class

## Quick Facts
- arXiv ID: 2404.16717
- Source URL: https://arxiv.org/abs/2404.16717
- Reference count: 40
- This paper proposes a method to improve zero-shot classification by explicitly accounting for intra-class diversity using vision-language models and attribute-enriched text embeddings.

## Executive Summary
This paper identifies a critical limitation in standard zero-shot classification: representing each class with a single vector fails to capture intra-class diversity, leading to poor performance on atypical instances. The authors propose a method that leverages large language models to infer diverse attributes for each class and uses a non-linear consolidation mechanism to combine similarities between images and multiple attribute-enriched class vectors. Extensive experiments demonstrate that the proposed method consistently matches or exceeds existing approaches, with particularly strong gains on the hardest classes and subpopulations. The method also offers enhanced interpretability by providing fine-grained, faithful explanations for each inference.

## Method Summary
The proposed method consists of three main steps: (1) using a large language model to infer diverse attributes for each class across multiple axes of diversity, (2) encoding both images and attribute-enriched text descriptions using a vision-language model, and (3) consolidating the similarities between each image and the multiple class-specific vectors using a non-linear mechanism that averages the top-k most similar attribute vectors per class. This approach allows the method to capture intra-class diversity without requiring additional training or labeled data.

## Key Results
- The proposed method consistently matches or exceeds existing zero-shot classification approaches in overall accuracy
- Larger gains are observed on the hardest classes and subpopulations, with up to 66% improvement on worst-class accuracy
- The method provides enhanced interpretability by offering fine-grained, faithful explanations for each inference through attribute-based scoring

## Why This Works (Mechanism)

### Mechanism 1
- Claim: One vector per class inadequately represents diverse subpopulations because class embeddings are too diffuse to align well with all image embeddings within that class.
- Mechanism: When class instances vary widely (e.g., whole vs. diced pears), their image embeddings become dispersed. A single vector cannot simultaneously be close to all dispersed embeddings, so atypical instances fall outside the effective decision boundary.
- Core assumption: Image embeddings from the same class but different subpopulations are farther apart than embeddings from different classes in typical cases.
- Evidence anchors:
  - [abstract] "standard VLM classifiers map all instances of a class to a single vector based on the class label" and the drop from 97.3% to 30.3% for peeled vs. typical pears shows this misalignment.
  - [section 3.1] "classes with higher diversity have lower accuracy in the one vector per class paradigm."
- Break condition: If the VLM's embedding space is highly non-linear or if the classifier uses a large margin that tolerates intra-class variance, the single vector may still capture diversity.

### Mechanism 2
- Claim: VLMs can recognize diverse subpopulations when attributes are explicitly provided because the open-vocabulary encoder can embed any descriptive text.
- Mechanism: Instead of mapping only the class name, the method embeds multiple attribute-enriched descriptions (e.g., "diced pear"). The image embedding aligns better with these more specific subpopulation vectors than with the generic class vector.
- Core assumption: The LLM can generate meaningful, accurate attributes that correspond to real subpopulations in the data.
- Evidence anchors:
  - [abstract] "VLMs can enrich the single per-class vector with attributes to more faithfully capture the variety with which a class can appear."
  - [section 3.2] Empirical test shows average precision increases when adding attributes (e.g., molten cake +40 points).
- Break condition: If LLM-generated attributes are irrelevant or incorrect, or if the VLM cannot embed those attributes accurately, performance may degrade.

### Mechanism 3
- Claim: Non-linear consolidation over top-k subpopulations improves atypical instance classification by focusing on only the most relevant attribute vectors.
- Mechanism: For each class, compute similarity to all subpopulation embeddings, then average only the top-k similarities. This avoids diluting the score with irrelevant attributes and allows high scores for images close to just one subpopulation.
- Core assumption: Atypical instances are only close to a small subset of subpopulation embeddings, so including more than k would reduce their scores.
- Evidence anchors:
  - [abstract] "we non-linearly consolidate these similarities to obtain one score per class" and the observation of larger gains on hardest classes and subpopulations.
  - [section 6.2] Sweeping k shows improved accuracy on worst classes when k is small.
- Break condition: If k is too small, the method may overfit to noisy subpopulation embeddings, causing incorrect classifications.

## Foundational Learning

- Concept: Cosine similarity in normalized embedding space
  - Why needed here: The method relies on comparing image embeddings to text embeddings via cosine similarity, which is standard for CLIP-like VLMs.
  - Quick check question: What is the range of cosine similarity values, and how does normalization affect the dot product?
- Concept: Zero-shot classification paradigm
  - Why needed here: The paper contrasts standard zero-shot (classname only) with the proposed multi-attribute approach.
  - Quick check question: How does CLIP compute class scores in zero-shot mode?
- Concept: Embedding variance as diversity proxy
  - Why needed here: The paper measures class diversity as variance of image embeddings to correlate with accuracy.
  - Quick check question: How do you compute variance of embeddings for a class, and why is high variance problematic for a single vector?

## Architecture Onboarding

- Component map:
  LLM (Vicuna-13b-v1.5) -> VLM (CLIP/BLIP-2) -> Consolidator -> Output
- Critical path:
  1. Run LLM to infer attributes per class (once per dataset)
  2. Embed image and all subpopulation texts
  3. Compute cosine similarities
  4. Select top-k and average for each class
  5. Predict highest scoring class
- Design tradeoffs:
  - Larger k -> better coverage but more noise; smaller k -> better for outliers but risk of noise
  - More attribute types -> broader diversity coverage but more computation and potential irrelevance
  - LLM temperature -> diversity of attributes vs. coherence
- Failure signatures:
  - Drop in overall accuracy with high k or many irrelevant attributes
  - LLM outputs generic attributes that do not match data subpopulations
  - VLM fails to embed certain complex attribute phrases accurately
- First 3 experiments:
  1. Verify that adding a single meaningful attribute improves AP on subpopulations (e.g., "diced pear" vs. "pear").
  2. Sweep k on a small dataset to find optimal tradeoff point between overall and worst-class accuracy.
  3. Replace LLM with a fixed attribute set and compare to baseline to isolate consolidation effect.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the LLM attribute inference process be made more reliable to reduce the small percentage of uninformative or inaccurate outputs?
- Basis in paper: [explicit] The paper notes only 2.7% of 300 randomly sampled LLM outputs were uninformative and none were inaccurate, but acknowledges LLMs can provide unreliable outputs.
- Why unresolved: While the flexible consolidation scheme provides some robustness to irrelevant outputs, there is no systematic way to automatically detect and remove unreliable LLM outputs.
- What evidence would resolve it: A method that reliably detects and removes unreliable LLM outputs, validated on a diverse set of classification tasks.

### Open Question 2
- Question: Can uncertainty estimation techniques be incorporated to automatically flag and remove subpopulations that the VLM cannot reliably detect?
- Basis in paper: [explicit] The paper mentions that VLMs can fail to recognize certain subpopulations, especially composite concepts, and suggests uncertainty estimation as a potential avenue for future work.
- Why unresolved: The paper does not explore specific uncertainty estimation techniques or their effectiveness in this context.
- What evidence would resolve it: A method that uses uncertainty estimation to identify and exclude unreliable subpopulations, resulting in improved classification accuracy.

### Open Question 3
- Question: How does the proposed method perform on datasets with different levels of intra-class diversity compared to datasets with known diversity?
- Basis in paper: [explicit] The paper shows the method generalizes well to finer-grained datasets without attributes, but these datasets are less likely to have high intra-class diversity.
- Why unresolved: The paper does not provide a systematic study of performance across datasets with varying levels of intra-class diversity.
- What evidence would resolve it: A comprehensive evaluation of the method's performance on a range of datasets with varying levels of intra-class diversity, including both labeled and unlabeled diversity.

## Limitations
- The method relies heavily on the LLM's ability to generate meaningful and accurate attributes, which may vary across datasets and domains
- The non-linear consolidation mechanism introduces hyperparameters (k and Î») that require careful tuning and may not generalize well across all datasets
- The method assumes that the VLM can accurately embed complex attribute phrases, which may not always hold true for certain types of descriptions

## Confidence

- High confidence: The core observation that single-vector-per-class representation struggles with diverse subpopulations is well-supported by empirical evidence (e.g., the 97.3% to 30.3% accuracy drop for peeled pears).
- Medium confidence: The effectiveness of the non-linear consolidation mechanism depends on the quality of LLM-generated attributes and the choice of hyperparameters, which may vary across datasets.
- Medium confidence: The method's interpretability is promising but may be limited by the LLM's ability to generate coherent and faithful attribute explanations.

## Next Checks

1. Test the method on a dataset with known subpopulation labels to quantify the improvement on atypical instances versus typical ones.
2. Evaluate the sensitivity of performance to different LLM prompts and hyperparameters (e.g., temperature, repetition penalty) for attribute generation.
3. Assess the method's robustness to noisy or irrelevant attributes by artificially injecting incorrect attributes and measuring the impact on accuracy.