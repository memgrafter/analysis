---
ver: rpa2
title: 'ETSCL: An Evidence Theory-Based Supervised Contrastive Learning Framework
  for Multi-modal Glaucoma Grading'
arxiv_id: '2407.14230'
source_url: https://arxiv.org/abs/2407.14230
tags:
- glaucoma
- contrastive
- loss
- dirichlet
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses glaucoma grading using multi-modal imaging
  (color fundus photography and optical coherence tomography). The authors propose
  ETSCL, a novel framework that integrates supervised contrastive learning with evidence
  theory-based decision fusion.
---

# ETSCL: An Evidence Theory-Based Supervised Contrastive Learning Framework for Multi-modal Glaucoma Grading

## Quick Facts
- arXiv ID: 2407.14230
- Source URL: https://arxiv.org/abs/2407.14230
- Reference count: 28
- Key outcome: State-of-the-art performance on GAMMA dataset with kappa 0.8844 and accuracy 0.84, outperforming existing methods by over 3%

## Executive Summary
This paper presents ETSCL, a novel framework for multi-modal glaucoma grading that integrates supervised contrastive learning with evidence theory-based decision fusion. The method leverages color fundus photography (CFP), optical coherence tomography (OCT), and vessel information extracted via Frangi vesselness algorithm to improve diagnostic accuracy. By incorporating supervised contrastive loss for feature extraction and uncertainty-aware evidence theory fusion for decision making, ETSCL achieves superior performance on the GAMMA dataset compared to existing approaches.

## Method Summary
ETSCL is a two-stage framework that first extracts discriminative features using supervised contrastive learning, then fuses multi-modal information with uncertainty estimation. Three parallel ResNet50 encoders process CFP, OCT, and vessel images, with supervised contrastive loss pulling same-class features together and pushing different-class features apart. An evidence theory-based classifier quantifies uncertainty for each modality using Dirichlet distributions and belief functions, then combines them via Dempster's rule. The framework is trained in two stages: feature extraction with contrastive loss, followed by decision fusion training.

## Key Results
- Achieved kappa coefficient of 0.8844 and accuracy of 0.84 on GAMMA dataset
- Outperformed existing methods by over 3% in both kappa and accuracy metrics
- Demonstrated effectiveness of combining supervised contrastive learning with evidence theory-based uncertainty estimation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Supervised contrastive loss improves feature discrimination in multi-modal glaucoma grading by grouping same-class features and separating different-class features.
- Mechanism: The supervised contrastive loss uses label information to create positive pairs from the same class, forcing the model to pull these embeddings closer while pushing apart embeddings from different classes.
- Core assumption: Label information is reliable and semantic similarity within classes is meaningful for glaucoma grading.
- Evidence anchors:
  - [abstract] "the supervised contrastive loss is employed to enhance the discriminative power in the feature extraction process, resulting in more effective features"
  - [section] "The supervised contrastive loss leverages label information to generate the positives, making it more effective at grouping features of the same class closely together and separating those of different classes"

### Mechanism 2
- Claim: Evidence theory-based classifier provides uncertainty estimation for each modality, enabling reliable decision fusion.
- Mechanism: The framework uses Dirichlet distributions to model class probabilities, with evidence values derived from feature embeddings. Belief masses and uncertainty masses are calculated for each modality, then combined using Dempster's rule.
- Core assumption: Evidence from each modality can be meaningfully quantified and combined using belief functions, with higher uncertainty modalities having less influence on final decision.
- Evidence anchors:
  - [abstract] "an evidence theory-based multi-modality classifier is employed to combine multi-source information with uncertainty estimation"
  - [section] "The proposed classifier uses the belief functions to quantitatively estimate the uncertainty of information from different modalities, and combines the information based on Dempster's rule of combination"

### Mechanism 3
- Claim: Vessel information as a third modality provides complementary diagnostic information that improves glaucoma grading accuracy.
- Mechanism: The Frangi vesselness algorithm extracts vessel structures from CFP images, creating a third branch alongside CFP and OCT. This addresses the limitation that existing methods overlook vessel information, which is considered a key triggering factor in glaucoma development.
- Core assumption: Vessel structure changes are indicative of glaucoma progression and can be reliably extracted from CFP images to provide complementary information.
- Evidence anchors:
  - [abstract] "we utilize the Frangi vesselness algorithm as a preprocessing step to incorporate vessel information to assist in the prediction"
  - [section] "Vascular genesis is considered a key triggering factor in the development of glaucoma"

## Foundational Learning

- Concept: Contrastive learning and supervised contrastive loss
  - Why needed here: Standard supervised learning often produces sub-optimal feature representations in medical imaging due to high image similarity and limited labeled data. Contrastive learning leverages semantic similarity to create more stable representations.
  - Quick check question: How does supervised contrastive loss differ from self-supervised contrastive loss in terms of positive pair creation?

- Concept: Evidence theory and Dempster-Shafer Theory
  - Why needed here: Multi-modal systems need to handle uncertainty in predictions from different sources. Evidence theory provides a mathematical framework for quantifying belief and uncertainty, enabling more reliable fusion than simple weighted averaging.
  - Quick check question: What is the relationship between belief masses, uncertainty mass, and Dirichlet distribution parameters in this framework?

- Concept: Vessel segmentation and Frangi filter
  - Why needed here: Vessel information is a novel third modality that provides complementary diagnostic information. The Frangi filter is specifically designed to enhance vessel-like structures in images.
  - Quick check question: How does the Frangi filter detect vessels based on their geometric properties?

## Architecture Onboarding

- Component map: CFP ResNet50 -> MLP -> Evidence theory classifier; OCT ResNet50 -> MLP -> Evidence theory classifier; Vessel ResNet50 -> MLP -> Evidence theory classifier -> Dempster's rule -> Final prediction
- Critical path: Feature extraction (contrastive learning) -> Uncertainty estimation (evidence theory) -> Decision fusion (Dempster's combination) -> Final prediction
- Design tradeoffs: Using three separate ResNet50 encoders increases computational cost but allows modality-specific feature learning. Evidence theory adds complexity but provides principled uncertainty handling. The vessel branch adds a third modality but depends on reliable vessel extraction.
- Failure signatures: Poor kappa/accuracy scores indicate feature extraction issues; overconfident predictions despite contradictory modalities suggest evidence theory implementation problems; vessel branch underperforms suggests vessel extraction or modality relevance issues.
- First 3 experiments:
  1. Baseline comparison: Run with only CFP branch (Softmax classifier) to establish single-modality performance
  2. Dual modality test: Add OCT branch with evidence theory fusion to verify multi-modal improvement
  3. Vessel integration test: Add vessel branch to confirm complementary information contribution

## Open Questions the Paper Calls Out

- Open Question 1: How would the ETSCL framework perform on datasets with larger sample sizes and different distributions?
  - Basis in paper: [inferred] The authors note that the limited size of the GAMMA dataset constrains method choices and restricts generalizability testing.
  - Why unresolved: The study only evaluated on the relatively small GAMMA dataset (300 pairs), limiting the ability to test robustness and generalizability to other datasets.
  - What evidence would resolve it: Performance evaluation on larger, private datasets with different patient populations and imaging conditions would demonstrate the framework's robustness and generalizability.

- Open Question 2: Would alternative vessel extraction methods (beyond Frangi filter) improve glaucoma grading performance?
  - Basis in paper: [explicit] The authors mention using the Frangi vesselness algorithm as a preprocessing step to incorporate vessel information, but acknowledge this as a preprocessing choice without comparing alternatives.
  - Why unresolved: The paper does not explore or compare different vessel extraction algorithms that might capture vascular information more effectively for glaucoma grading.
  - What evidence would resolve it: Comparative experiments using different vessel extraction methods (e.g., Hessian-based filters, deep learning approaches) alongside the ETSCL framework would reveal whether the Frangi filter is optimal.

- Open Question 3: How does the uncertainty estimation from the evidence theory-based classifier translate to clinical decision-making in glaucoma diagnosis?
  - Basis in paper: [explicit] The authors highlight that existing methods overlook uncertainty estimation of different modalities, leading to unreliable predictions, and propose their evidence theory-based classifier to address this.
  - Why unresolved: The paper focuses on technical implementation but does not demonstrate how the uncertainty estimates would be interpreted or used by clinicians in practice.
  - What evidence would resolve it: Clinical validation studies showing how uncertainty estimates correlate with diagnostic confidence, inter-observer variability, or influence clinical decision-making would bridge the gap between technical performance and clinical utility.

## Limitations
- Performance constrained by relatively small dataset size (300 samples) which may limit generalization
- Vessel extraction using Frangi filter may not capture all pathological vessel changes specific to glaucoma
- Evidence theory fusion assumes conditional independence between modalities, which may not hold in practice

## Confidence

- Mechanism 1 (Supervised Contrastive Learning): High confidence - strong theoretical foundation and empirical evidence support effectiveness
- Mechanism 2 (Evidence Theory Fusion): Medium confidence - principled framework but specific implementation details for medical imaging fusion not fully specified
- Mechanism 3 (Vessel Modality): Medium confidence - vessel information is theoretically relevant but practical contribution depends on reliable extraction

## Next Checks

1. Conduct ablation studies on the GAMMA dataset to quantify the individual and combined contributions of supervised contrastive loss and evidence theory fusion to performance gains
2. Test the framework on external glaucoma datasets to evaluate generalization beyond the training population and assess robustness to different imaging protocols
3. Perform uncertainty calibration analysis to verify that the evidence theory-based uncertainty estimates correlate with actual prediction reliability across different patient subgroups