---
ver: rpa2
title: 'Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis
  of Fine-Tuning Strategies'
arxiv_id: '2402.15337'
source_url: https://arxiv.org/abs/2402.15337
tags:
- entities
- pairwise
- features
- language
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies ranking entities along conceptual space dimensions
  with LLMs. The core problem is that ground truth rankings for perceptual and subjective
  features are rare, making direct fine-tuning difficult.
---

# Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies

## Quick Facts
- **arXiv ID:** 2402.15337
- **Source URL:** https://arxiv.org/abs/2402.15337
- **Reference count:** 19
- **Primary result:** Fine-tuning LLMs on numerical features from one domain improves ranking performance in perceptual domains when training data includes some perceptual or subjective features.

## Executive Summary
This paper addresses the challenge of ranking entities along conceptual space dimensions, particularly for perceptual and subjective features where ground truth rankings are rare. The authors propose using numerical attributes from Wikidata as training data to fine-tune LLMs, then analyze whether these models can transfer their ranking capabilities to perceptual and subjective features. Through extensive experiments with multiple models (Llama2, Llama3, Mistral) and datasets (rocks, movies, taste, etc.), they find that fine-tuning on numerical data can indeed improve perceptual ranking, but the presence of perceptual or subjective features in training is crucial for optimal performance. The study compares pointwise and pairwise ranking approaches, finding the pointwise approach highly effective, though pairwise models combined with SVM-based aggregation yield the best overall results.

## Method Summary
The method involves fine-tuning pre-trained LLMs on ranking tasks using either pointwise or pairwise approaches. For pairwise fine-tuning, the model learns to classify entity pairs using prompts like "Is X longer than Y?" with a linear layer and sigmoid activation. For pointwise fine-tuning, entities are scored individually using prompts like "Is X among the longest?" and trained via pairwise comparisons. The pairwise judgments are then aggregated into final rankings using either SVM-based weight learning or simple counting methods. The training uses QLoRa 4-bit quantization, batch size 8, and validation split of 20% from Wikidata (WD1 dataset). The models are evaluated on multiple test datasets including taste, rocks, movies, books, and physical properties, measuring accuracy on pairwise judgments and Spearman correlation for ranking quality.

## Key Results
- Fine-tuning on numerical features from Wikidata improves LLM ranking performance in perceptual domains, but requires at least some perceptual/subjective features in training data
- Pointwise fine-tuning is highly effective and comparable to pairwise for pairwise judgments, but pairwise with SVM aggregation achieves the best overall ranking performance
- Models outperform GPT-3.5 and GPT-4 baselines on many perceptual and subjective ranking tasks
- The best results are obtained using pairwise models combined with SVM-based aggregation of pairwise judgments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning on numerical features from one domain improves LLM ranking performance in unrelated perceptual domains.
- Mechanism: Pre-trained LLMs contain latent perceptual knowledge, which can be unlocked by fine-tuning on numerical data, enabling generalization to perceptual features.
- Core assumption: The latent knowledge captured during pre-training is sufficient to model perceptual relationships once properly activated through fine-tuning.
- Evidence anchors:
  - [abstract]: "We therefore use more readily available features as training data and analyse whether the ranking capabilities of the resulting models transfer to perceptual and subjective features. We find that this is indeed the case, to some extent, but having at least some perceptual and subjective features in the training data seems essential for achieving the best results."
  - [section]: "We find this indeed largely to be the case, as long as the training data also contains perceptual or subjective features."
  - [corpus]: Weak evidence; no direct studies on cross-domain transfer from numerical to perceptual features.
- Break condition: If training data lacks any perceptual or subjective features, performance on perceptual domains degrades significantly.

### Mechanism 2
- Claim: Pairwise comparison models outperform pointwise models when rankings are aggregated using SVM-based strategies.
- Mechanism: Pairwise models generate noisy but consistent relative judgments that, when aggregated via SVM margin maximization, produce more accurate rankings than pointwise scoring.
- Core assumption: Aggregating pairwise judgments with SVM-based methods effectively resolves inconsistencies and noise in relative comparisons.
- Evidence anchors:
  - [abstract]: "the best results overall are still obtained using a pairwise model combined with an SVM-based strategy for aggregating pairwise judgments into a single ranking."
  - [section]: "The SVM method generally performs better than the Count method, especially in the case where 30 judgments per entity are obtained."
  - [corpus]: Weak evidence; SVM-based aggregation is established in other domains but not previously validated for LLM pairwise judgments.
- Break condition: If the number of pairwise samples per entity is too low, the SVM method may not outperform simpler aggregation strategies.

### Mechanism 3
- Claim: LLMs can rank entities based on commonsense properties despite limited direct training on such features.
- Mechanism: The pre-trained knowledge in LLMs includes commonsense associations that can be leveraged through structured prompting and fine-tuning, even without explicit commonsense examples.
- Core assumption: Pre-trained LLMs already encode sufficient commonsense knowledge to rank entities on novel properties, given appropriate fine-tuning and prompting.
- Evidence anchors:
  - [abstract]: "We find that this is indeed the case, to some extent, but having at least some perceptual and subjective features in the training data seems essential for achieving the best results."
  - [section]: "The model sometimes struggles with commonsense features" and "spaceship is listed as the most suitable vehicle for long-distance travel with a family."
  - [corpus]: Weak evidence; no direct studies on commonsense ranking performance of LLMs post-fine-tuning.
- Break condition: If the commonsense property involves culturally or contextually specific knowledge not captured in pre-training, performance degrades.

## Foundational Learning

- Concept: Conceptual spaces and quality dimensions
  - Why needed here: The task requires understanding how entities are represented along perceptual and subjective features, which is formalized using conceptual spaces.
  - Quick check question: Can you explain the difference between a conceptual space dimension and a traditional feature in a knowledge graph?

- Concept: Pairwise vs pointwise ranking models
  - Why needed here: The paper compares these two strategies for ranking entities, and understanding their tradeoffs is critical for implementation.
  - Quick check question: What are the main advantages and disadvantages of pairwise ranking compared to pointwise ranking in terms of sample complexity and ranking accuracy?

- Concept: SVM-based aggregation of pairwise judgments
  - Why needed here: The paper uses SVM to aggregate pairwise judgments into a single ranking, which is key to the proposed approach.
  - Quick check question: How does the SVM-based aggregation method ensure that the resulting ranking respects the pairwise judgments while maximizing the margin between entities?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> Aggregation module -> Evaluation pipeline

- Critical path:
  1. Prepare training data from numerical and perceptual features.
  2. Fine-tune LLMs using pointwise and pairwise strategies.
  3. Aggregate pairwise judgments using SVM or Count methods.
  4. Evaluate ranking performance on held-out perceptual and subjective datasets.

- Design tradeoffs:
  - Pointwise vs pairwise: Pointwise is faster but may be less accurate; pairwise is more accurate but requires more computation for aggregation.
  - Training data diversity: Including perceptual features in training improves generalization but may reduce the size of the numerical training set.
  - Aggregation method: SVM-based methods are more accurate but computationally heavier than Count-based methods.

- Failure signatures:
  - Poor generalization to perceptual domains: Indicates insufficient perceptual features in training data.
  - High variance in pairwise judgments: Suggests the need for more pairwise samples or better prompting.
  - Low accuracy on commonsense properties: May indicate gaps in pre-trained knowledge or need for targeted fine-tuning.

- First 3 experiments:
  1. Fine-tune an LLM on numerical features from Wikidata and evaluate on taste rankings.
  2. Compare pointwise and pairwise models on a small perceptual dataset (e.g., rocks).
  3. Implement and test SVM-based aggregation on pairwise judgments from a movie dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well can fine-tuning LLMs on features from one domain (e.g., taste) generalize to extracting rankings in completely unrelated domains (e.g., movies) when there are no perceptual or subjective features in the training data?
- Basis in paper: [explicit] The authors found that fine-tuning on WD alone (numerical features) led to worse results on Taste and Rocks datasets, suggesting the need for perceptual/subjective features in training data for generalization.
- Why unresolved: The paper only tested WD (numerical) vs. WD+TG+Taste (perceptual/subjective). It did not test a purely numerical training set without any perceptual features.
- What evidence would resolve it: Experiments comparing models trained on purely numerical features (e.g., WD) versus models trained on a mix of numerical and perceptual features when tested on a domain with only perceptual features (e.g., movies).

### Open Question 2
- Question: Is the pointwise approach for ranking entities with LLMs as effective as the pairwise approach when evaluated on tasks beyond pairwise judgments, such as ranking entities along a single dimension?
- Basis in paper: [explicit] The authors found that pointwise methods were as successful as pairwise methods for making pairwise judgments, but pairwise methods still had the advantage when aggregating judgments into a single ranking.
- Why unresolved: The paper only compared pointwise and pairwise methods on pairwise judgment tasks. It did not directly compare their effectiveness on the original ranking task (ranking entities along a single dimension).
- What evidence would resolve it: Experiments comparing the Spearman correlation between predicted rankings and ground truth rankings using pointwise and pairwise methods on the same datasets.

### Open Question 3
- Question: To what extent does the popularity of entities in the training data affect the reliability of LLMs when extracting conceptual space representations?
- Basis in paper: [inferred] The authors analyzed the correlation between entity popularity and prediction error for the countries population feature, finding no clear correlation. However, they only tested one feature and one model.
- Why unresolved: The analysis was limited to one feature and one model. It is unclear if the lack of correlation generalizes to other features, models, and datasets.
- What evidence would resolve it: Experiments analyzing the correlation between entity popularity and prediction error across multiple features, models, and datasets, and investigating potential factors influencing the relationship (e.g., feature type, model size).

## Limitations

- The cross-domain transfer from numerical to perceptual features is limited and requires at least some perceptual features in training data
- The pairwise approach with SVM aggregation is computationally intensive and may not scale well to very large entity sets
- The evaluation is limited to English-language datasets and models, raising questions about generalization to other languages and cultural contexts

## Confidence

**High Confidence:** The relative performance comparison between pointwise and pairwise fine-tuning approaches is well-supported by the experimental results across multiple datasets and model sizes. The claim that SVM-based aggregation outperforms simple counting methods for pairwise judgments is also strongly supported by the presented evidence.

**Medium Confidence:** The claim that pre-trained LLMs contain latent perceptual knowledge that can be unlocked through fine-tuning on numerical data is plausible but not definitively proven. While the experimental results show transfer effects, the exact mechanism and limits of this knowledge transfer remain uncertain.

**Low Confidence:** The assertion that LLMs can reliably rank entities on commonsense properties without explicit training examples is weakly supported. The paper acknowledges several instances where commonsense judgments fail, and the underlying knowledge appears inconsistent across different feature types.

## Next Checks

1. **Transfer Threshold Analysis:** Systematically vary the proportion of perceptual features in training data (0%, 25%, 50%, 75%, 100%) and measure the impact on downstream performance across different domains to identify the minimum perceptual content required for effective transfer.

2. **Cultural Context Evaluation:** Test the fine-tuned models on perceptual ranking tasks from non-Western cultural contexts (e.g., Chinese taste preferences, Indian movie genres) to assess the cultural specificity of the learned ranking capabilities.

3. **Commonsense Knowledge Audit:** Create a benchmark of commonsense properties with known ground truth rankings and systematically evaluate model performance, documenting specific failure patterns to better understand the limits of pre-trained commonsense knowledge.