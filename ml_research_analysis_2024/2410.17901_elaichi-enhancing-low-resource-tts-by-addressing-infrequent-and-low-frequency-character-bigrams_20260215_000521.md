---
ver: rpa2
title: 'ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency
  Character Bigrams'
arxiv_id: '2410.17901'
source_url: https://arxiv.org/abs/2410.17901
tags:
- speech
- data
- bigrams
- corpus
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of intelligibility in low-resource
  TTS systems, particularly for Hindi, which struggles with synthesizing low-frequency
  character bigrams due to limited training data. The authors propose three methods:
  leveraging high-quality data from related languages, using denoised ASR data, and
  applying knowledge distillation from large-scale models using synthetic data.'
---

# ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams

## Quick Facts
- arXiv ID: 2410.17901
- Source URL: https://arxiv.org/abs/2410.17901
- Reference count: 11
- Primary result: Multilingual training with Hindi and Chhattisgarhi data yields highest intelligibility rates (IR: 0.85) and mean opinion scores (MOS: 4.42) for low-resource TTS systems.

## Executive Summary
This paper addresses the critical challenge of intelligibility in low-resource TTS systems, particularly for Hindi, which struggles with synthesizing low-frequency character bigrams due to limited training data. The authors propose three innovative methods to improve coverage of these underrepresented patterns: leveraging high-quality data from related languages, utilizing denoised ASR data, and applying knowledge distillation from large-scale models using synthetic data. Their experiments demonstrate that multilingual training with Hindi and Chhattisgarhi data achieves the best performance, with significant improvements in both intelligibility rates and speech quality metrics. The results highlight the importance of both coverage and relative growth of low-frequency bigrams for improving TTS performance in resource-constrained settings.

## Method Summary
The authors employ a VITS-based TTS model trained on multiple data augmentation strategies to improve low-frequency character bigram coverage. They use four augmentation approaches: adding proximal language data (Chhattisgarhi), scaling with multilingual corpora, incorporating denoised ASR data, and generating synthetic data through knowledge distillation from a large pre-trained model (VoiceCraft). The training pipeline involves preprocessing each dataset type, training VITS models on 8 NVIDIA A100 GPUs with default hyperparameters, and evaluating intelligibility through human assessment of low-frequency bigram recognition rates and MOS scores. The synthetic data generation specifically targets low-frequency character bigrams to improve their representation in the training corpus.

## Key Results
- Multilingual training with Hindi and Chhattisgarhi data achieves highest intelligibility (IR: 0.85) and MOS scores (4.42)
- Scaling multilingual data further improves performance to IR: 0.90 and MOS: 4.51
- Synthetic data generation achieves IR: 0.71 and MOS: 4.08
- Coverage and relative growth of low-frequency bigrams are crucial for improving TTS intelligibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Augmenting TTS training data with related languages improves low-frequency character bigram coverage and intelligibility.
- Mechanism: Related languages share scripts and phonemes, so adding their data increases the frequency of bigrams that are rare in the target language.
- Core assumption: Shared script and phoneme sets between languages mean that bigrams underrepresented in the target language will be more frequent in related languages.
- Evidence anchors: [abstract] leveraging high-quality data from linguistically related languages; [section] shared vocabulary and phoneme sets; [corpus] Chhattisgarhi as proximal language example.
- Break condition: If related language has significantly different phoneme sets or script, the benefit would diminish.

### Mechanism 2
- Claim: Using ASR-enhanced data improves TTS intelligibility by increasing low-frequency bigram coverage with additional speakers.
- Mechanism: ASR data, though noisy, can be cleaned and provides diverse speaker data that increases the frequency of rare bigrams in the target language.
- Core assumption: Cleaning ASR data produces usable TTS training data that improves bigram coverage without degrading overall speech quality.
- Evidence anchors: [abstract] refined using denoising and speech enhancement models; [section] increase frequency counts of low-frequency bigrams; [corpus] cleaned IndicVoices-R data.
- Break condition: If denoising process fails to sufficiently improve audio quality, the added data could harm TTS performance.

### Mechanism 3
- Claim: Knowledge distillation from large-scale TTS models using synthetic data improves TTS intelligibility for low-frequency bigrams.
- Mechanism: A large pre-trained model can generate high-quality speech for rare bigrams, and augmenting training data with these synthetic samples improves the smaller model's performance.
- Core assumption: The large model has learned robust representations of low-frequency bigrams from its diverse training data, and synthetic samples are of sufficient quality to be useful for training.
- Evidence anchors: [abstract] knowledge distillation from large-scale models using synthetic data; [section] augmenting high-quality TTS dataset with synthetic speech; [corpus] VoiceCraft trained on 1704+ hours of data.
- Break condition: If the large model performs poorly on rare bigrams, the synthetic data would not be beneficial.

## Foundational Learning

- Concept: Character bigram frequency analysis
  - Why needed here: The core problem is that certain character bigrams are underrepresented in training data, leading to intelligibility issues. Understanding how to measure and improve bigram frequency is crucial.
  - Quick check question: If a bigram appears 5 times in a 10-hour corpus and 50 times in a 100-hour corpus, has its relative frequency changed?

- Concept: Multilingual data augmentation
  - Why needed here: The paper proposes using data from related languages to improve coverage of rare bigrams. Understanding how to combine and leverage multilingual data is essential.
  - Quick check question: If Language A has 1000 occurrences of bigram "xy" and Language B has 50, what happens to the frequency of "xy" when we combine the datasets?

- Concept: Knowledge distillation
  - Why needed here: The paper uses a large TTS model to generate synthetic data for training a smaller model. Understanding how distillation works is important for implementing this approach.
  - Quick check question: In knowledge distillation, what is the teacher model and what is the student model?

## Architecture Onboarding

- Component map: VITS model (posterior encoder, prior encoder, decoder, discriminator, duration predictor) -> Data augmentation modules (proximal language, ASR-enhanced, synthetic data generation) -> Evaluation pipeline (human intelligibility tests, MOS scores, automated speech quality metrics)

- Critical path: 1. Prepare training corpora (baseline + augmented data) -> 2. Train VITS model on augmented corpus -> 3. Generate synthetic data using VoiceCraft -> 4. Evaluate intelligibility and speech quality

- Design tradeoffs: Data quality vs. quantity (ASR data is abundant but noisy); Computational cost (generating synthetic data is expensive but can significantly improve coverage); Language relatedness (closely related languages improve bigram coverage but may limit data diversity)

- Failure signatures: Intelligibility does not improve despite increased coverage (model may not be learning new bigrams effectively); Speech quality degrades (augmented data may be introducing noise or inconsistencies); Speaker identity is lost (adding too many speakers without proper conditioning may affect speaker consistency)

- First 3 experiments: 1. Train baseline VITS model on Hindi data only and measure intelligibility on low-frequency bigrams -> 2. Add Chhattisgarhi data and retrain, comparing intelligibility improvements -> 3. Generate synthetic data using VoiceCraft for low-frequency bigrams and retrain, measuring impact on both intelligibility and speech quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of synthetic data augmentation vary with different pre-trained models beyond VoiceCraft?
- Basis in paper: [explicit] The paper discusses using VoiceCraft but acknowledges the need to explore other models and their impact on relative growth and coverage.
- Why unresolved: The study focused on VoiceCraft due to computational constraints and did not explore alternative pre-trained models.
- What evidence would resolve it: Experiments comparing TTS performance using synthetic data generated by various large-scale models would reveal differences in coverage, relative growth, and intelligibility rates.

### Open Question 2
- Question: To what extent do the proposed methods generalize to other low-resource languages with different phonetic structures or cultural contexts?
- Basis in paper: [explicit] The paper focuses on Hindi as a case study and acknowledges the need to explore other languages with varying phonetic structures.
- Why unresolved: The study's focus on Hindi limits generalizability to other low-resource languages.
- What evidence would resolve it: Conducting similar experiments on other low-resource languages with diverse phonetic structures would provide insights into the generalizability and adaptability of the proposed methods.

### Open Question 3
- Question: What is the optimal balance between coverage and relative growth of low-frequency character bigrams when using synthetic data?
- Basis in paper: [explicit] The paper highlights that both coverage and relative growth are crucial, but synthetic data approach prioritized coverage over relative growth due to computational constraints.
- Why unresolved: The study did not explore the optimal balance between coverage and relative growth in synthetic data generation.
- What evidence would resolve it: Experiments varying the emphasis on coverage versus relative growth in synthetic data generation and evaluating their impact on TTS intelligibility would help determine the optimal balance.

## Limitations
- The paper does not provide detailed quality metrics for denoised ASR data or synthetic data, making it difficult to assess the reliability of the augmented training data.
- Critical implementation details such as exact training duration, learning rate schedules, and stopping criteria for VITS models are not specified.
- Results are demonstrated specifically for Hindi and Chhattisgarhi, limiting generalizability to languages with less orthographic and phonetic similarity.

## Confidence

**High Confidence**: The core methodology of using multilingual data to improve coverage of underrepresented patterns is well-established, and observed improvements in intelligibility rates (0.51 to 0.85) and MOS scores (3.97 to 4.42) with proximal language augmentation are consistent with expectations based on shared linguistic features.

**Medium Confidence**: The effectiveness of ASR-enhanced data and synthetic data generation shows promise but lacks rigorous validation, as the absence of detailed quality metrics for augmented data sources introduces uncertainty about the reliability and reproducibility of these results.

**Low Confidence**: The scalability claims and specific contributions of each augmentation method are difficult to verify due to the lack of ablation studies to isolate individual contributions, and the claim that scaling multilingual data further improves results (IR: 0.90, MOS: 4.51) needs independent verification.

## Next Checks

1. **Ablation Study Implementation**: Conduct controlled experiments to isolate the contribution of each augmentation method by training models with only one type of augmented data at a time, then systematically combining them to verify the additive effects claimed in the paper.

2. **Quality Metrics Analysis**: Generate detailed quality assessments for the denoised ASR data and synthetic speech, including SNR measurements, spectrograms, and specific evaluations of how well the large-scale model (VoiceCraft) handles the target low-frequency bigrams before using its output for training.

3. **Cross-Linguistic Generalization Test**: Apply the proposed methodology to a different language pair with less linguistic similarity than Hindi-Chhattisgarhi to evaluate whether the approach generalizes beyond closely related languages, and measure whether the same relative improvements in intelligibility and MOS scores are achievable.