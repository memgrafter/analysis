---
ver: rpa2
title: 'DiagESC: Dialogue Synthesis for Integrating Depression Diagnosis into Emotional
  Support Conversation'
arxiv_id: '2408.06044'
source_url: https://arxiv.org/abs/2408.06044
tags:
- depression
- dialogue
- user
- utterance
- desc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces DiagESC, a novel task for dialogue systems
  in mental health care that integrates emotional support with depression diagnosis.
  The authors develop the DESC dataset to support this task, which involves generating
  diagnostic conversations based on the PHQ-9 questionnaire while maintaining a positive
  user experience.
---

# DiagESC: Dialogue Synthesis for Integrating Depression Diagnosis into Emotional Support Conversation

## Quick Facts
- arXiv ID: 2408.06044
- Source URL: https://arxiv.org/abs/2408.06044
- Authors: Seungyeon Seo; Gary Geunbae Lee
- Reference count: 12
- Primary result: Novel dialogue synthesis task integrating emotional support with depression diagnosis using PHQ-9 questionnaire

## Executive Summary
This work introduces DiagESC, a novel task for dialogue systems in mental health care that integrates emotional support with depression diagnosis. The authors develop the DESC dataset to support this task, which involves generating diagnostic conversations based on the PHQ-9 questionnaire while maintaining a positive user experience. The dataset is synthesized using task-specific prompts and strict filtering algorithms to ensure data quality. Professional psychological counselors validate the diagnostic ability and conversational quality of DESC. The results show that DESC has superior diagnostic performance compared to existing datasets and maintains fluent, consistent, and coherent dialogues.

## Method Summary
The DESC dataset is synthesized through a four-step process: pre-processing PESConv dataset to match persona sentences with seeker utterances, PHQ-9-based dialogue generation using GPT-4 with task-specific prompts and Chain-of-Thought technique, diagnostic dialogue generation with model filtering and expert validation, and post-processing to finalize the dataset. The process employs keyword filtering to ensure medical accuracy, pre-assigned PHQ-9 severity labels for balanced data distribution, and expert filtering by professional psychologists to validate symptom scores and re-label seeker utterances when necessary.

## Key Results
- DESC achieves a QWK score of 0.476 for depression severity prediction, superior to existing datasets
- Human evaluation scores for conversational quality: Fluency (4.45), Consistency (4.18), Coherence (4.14) on a 5-point scale
- DESC outperforms baselines (Llama-2-7b-chat-hf) on BLEU score (9.97) and accuracy (0.55) for depression detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task-specific prompt engineering combined with strict filtering enables generation of clinically meaningful depression assessment dialogues.
- Mechanism: The prompts guide the LLM through a Chain-of-Thought process that first analyzes user context, then plans appropriate questioning, and finally generates symptom inquiries. This structure ensures that questions are contextually relevant and emotionally appropriate.
- Core assumption: LLMs can follow structured reasoning patterns to generate medically accurate and psychologically sensitive content when given explicit step-by-step instructions.
- Evidence anchors:
  - "The both prompts involve the three-step Chain-of-Thought technique... In the initial turn, it is essential to formulate questions with caution to maintain a positive user experience."
  - "Keyword Filtering... ensures that the PHQ-9 maintains its medical meaning... The generated utterance must contain at least one of the keywords."

### Mechanism 2
- Claim: Pre-assigning PHQ-9 severity labels creates a balanced dataset that enables reliable depression severity prediction.
- Mechanism: By assigning depression severity labels before dialogue generation, the synthesis process ensures even distribution across severity levels, allowing the model to learn robust patterns for classification.
- Core assumption: The LLM can generate coherent dialogues that align with predetermined severity levels without creating inconsistencies in symptom reporting.
- Evidence anchors:
  - "To achieve an even distribution of the final severity level within the generated conversational data, the PHQ-9 labels are pre-assigned."
  - "The DESC comprises 976 dialogues... Figure 4 illustrates the distribution of dialogue samples across five levels of depression severity."

### Mechanism 3
- Claim: Expert filtering validates and corrects LLM-generated labels, ensuring clinical accuracy of the dataset.
- Mechanism: Professional psychologists evaluate symptom scores for validation and test sets, and re-label based on consensus, reducing errors from LLM hallucination.
- Core assumption: Expert human judgment can identify and correct subtle inaccuracies in symptom frequency reporting that automated filtering might miss.
- Evidence anchors:
  - "To ensure the reliability of the PHQ-9 labels, Expert Filtering is conducted on the validation and test datasets... Three psychologists... assessed scores for each symptom."
  - "The seeker utterances are then re-labeled to the mode value of the three scores."

## Foundational Learning

- Concept: Chain-of-Thought prompting
  - Why needed here: Enables structured generation of medically appropriate questions by breaking down the task into analysis, planning, and response generation stages
  - Quick check question: Can you describe the three stages of Chain-of-Thought prompting used for generating supporter utterances?

- Concept: Keyword-based medical content filtering
  - Why needed here: Ensures that generated symptom inquiries maintain clinical accuracy by requiring specific medical terminology
  - Quick check question: How does keyword filtering prevent the LLM from distorting the medical meaning of PHQ-9 symptoms?

- Concept: Expert validation of machine learning datasets
  - Why needed here: Provides ground truth labels for critical healthcare applications where automated filtering may be insufficient
  - Quick check question: Why is expert filtering particularly important for validation and test sets in clinical datasets?

## Architecture Onboarding

- Component map: PESConv dataset -> LLM (GPT-4) -> Task-specific prompts -> Keyword filtering -> Model filtering -> Expert validation -> DESC dataset
- Critical path: Prompt generation -> LLM response -> Filtering -> Validation
- Design tradeoffs: Pre-assigned labels ensure balanced data but may constrain natural symptom progression; expert filtering adds reliability but reduces scalability
- Failure signatures: Low QWK scores indicate poor symptom frequency prediction; inconsistent expert scores suggest LLM hallucination issues
- First 3 experiments:
  1. Generate 10 dialogues with different prompt variations and measure keyword inclusion rate
  2. Test model filtering threshold sensitivity on symptom frequency classification accuracy
  3. Compare expert agreement rates with and without prompt engineering variations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DiagESC change when using different LLM architectures for dialogue generation?
- Basis in paper: [inferred] The paper uses GPT-4 for utterance generation but does not explore the impact of different LLM architectures on the quality and diagnostic accuracy of the generated dialogues.
- Why unresolved: The study focuses on synthesizing a dataset using a specific LLM (GPT-4) without comparing its performance against other architectures like smaller or specialized models.
- What evidence would resolve it: Comparative experiments using multiple LLM architectures to generate dialogues and evaluate their diagnostic accuracy and conversational quality.

### Open Question 2
- Question: What is the impact of cultural and linguistic differences on the effectiveness of the DiagESC system in diverse populations?
- Basis in paper: [explicit] The paper mentions that psychological counselors used are native English speakers or bilingual, but does not address how the system performs across different cultures or languages.
- Why unresolved: The dataset and evaluations are conducted within a specific linguistic and cultural context, leaving the generalizability of the system to other populations untested.
- What evidence would resolve it: Cross-cultural studies evaluating the system's performance and diagnostic accuracy in populations with different languages and cultural backgrounds.

### Open Question 3
- Question: How does the inclusion of multimodal data (e.g., audio or video features) enhance the diagnostic accuracy of DiagESC compared to text-only interactions?
- Basis in paper: [inferred] The paper focuses on text-based interactions and does not explore the potential benefits of incorporating multimodal data, which could provide additional context for depression detection.
- Why unresolved: The study does not investigate the integration of audio or video features that could capture non-verbal cues indicative of depression, limiting the assessment to text-based symptoms.
- What evidence would resolve it: Experiments comparing the diagnostic accuracy of text-only interactions with those incorporating multimodal data, such as audio cues or facial expressions.

## Limitations

- Expert validation relies on three psychologists without reporting inter-rater reliability statistics, creating uncertainty about validation consistency
- No direct comparison with human-generated depression assessment dialogues to establish clinical representativeness
- Pre-assigned PHQ-9 labels may introduce label-data misalignment if LLM struggles to generate coherent symptom reports

## Confidence

- **High confidence**: Technical approach of using task-specific prompts and filtering algorithms to generate clinically relevant dialogues is well-specified and grounded in established methods
- **Medium confidence**: Claim that DESC achieves superior diagnostic performance compared to existing datasets is supported by QWK scores but lacks direct human baseline comparisons
- **Low confidence**: Assertion that DESC maintains fluent, consistent, and coherent dialogues is based on human evaluation scores but evaluation criteria and rater agreement are not fully detailed

## Next Checks

1. Calculate and report Fleiss' kappa or similar statistics for expert filtering on validation and test sets to quantify agreement among psychologists and establish reliability of the validation process

2. Conduct controlled study comparing DESC-generated dialogues with human-generated depression assessment conversations on both diagnostic accuracy (QWK) and conversational quality metrics

3. Perform systematic analysis of dialogue-content consistency by checking whether symptom descriptions in generated seeker utterances align with their pre-assigned PHQ-9 severity labels, identifying and quantifying instances of potential misalignment