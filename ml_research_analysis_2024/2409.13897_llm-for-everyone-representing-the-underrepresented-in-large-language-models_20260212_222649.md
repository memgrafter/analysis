---
ver: rpa2
title: 'LLM for Everyone: Representing the Underrepresented in Large Language Models'
arxiv_id: '2409.13897'
source_url: https://arxiv.org/abs/2409.13897
tags:
- language
- languages
- llms
- alignment
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis evaluates multilingual large language models (LLMs)
  on underrepresented languages and cultures, focusing on Austronesian languages spoken
  in Indonesia. Evaluations reveal that while LLMs perform well on Indonesian, they
  struggle with local indigenous languages and cultural understanding.
---

# LLM for Everyone: Representing the Underrepresented in Large Language Models

## Quick Facts
- arXiv ID: 2409.13897
- Source URL: https://arxiv.org/abs/2409.13897
- Authors: Samuel Cahyawijaya
- Reference count: 0
- Primary result: Introduces cross-lingual alignment methods and UniVaR to improve LLM performance on underrepresented languages without sacrificing high-resource language capability.

## Executive Summary
This thesis addresses the multilingual generalization gap in large language models (LLMs) by focusing on underrepresented languages, particularly Austronesian languages spoken in Indonesia. It reveals that while LLMs perform well on Indonesian, they struggle with local indigenous languages and cultural understanding. The research proposes three cross-lingual alignment methods—InstructAlign, semantic cross-lingual in-context learning, and in-context query alignment—that significantly improve LLM performance on underrepresented languages without degrading performance on high-resource languages. Additionally, a novel high-dimensional value representation called UniVaR is introduced to measure and compare cultural values across different LLMs and languages.

## Method Summary
The research evaluates multilingual LLMs on 18 languages spoken in Indonesia, including Indonesian and 17 local indigenous languages. It introduces three cross-lingual alignment methods: InstructAlign for continual instruction tuning, semantic cross-lingual in-context learning, and in-context query alignment. These methods are designed to improve LLM performance on underrepresented languages by aligning their representations with high-resource languages through parallel data and in-context learning techniques. Additionally, the thesis proposes UniVaR, a high-dimensional value representation that captures human value distributions in LLMs, enabling comparison and alignment across languages and cultures. The methods are evaluated using various datasets and metrics, including F1-score, SacreBLEU, and ROUGEL, and compared with pre-trained language models and statistical baselines.

## Key Results
- Cross-lingual alignment methods significantly improve LLM performance on underrepresented languages without sacrificing performance on high-resource languages.
- InstructAlign, semantic cross-lingual in-context learning, and in-context query alignment demonstrate effectiveness in improving language understanding and generation tasks.
- UniVaR successfully captures high-dimensional human value distributions, enabling comparison and alignment of cultural values across different LLMs and languages.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual alignment improves LLM performance on underrepresented languages without harming high-resource language capability.
- Mechanism: By incorporating cross-lingual alignment objectives (TLM, XSS, MT) into continual instruction tuning, LLMs learn to align the representations of underrepresented languages with high-resource languages, enabling better zero-shot generalization.
- Core assumption: Parallel data between underrepresented and high-resource languages exists and is sufficient for alignment learning.
- Evidence anchors:
  - [abstract] "Addressing the multilingual generalization gap, this thesis proposes data-and-compute-efficient methods to mitigate the disparity in LLM ability in underrepresented languages, allowing better generalization on underrepresented languages without the loss of task generalization ability."
  - [section] "InstructAlign compels multilingual LLMs to perform crosslingual alignments between pre-trained and novel languages through alignment-based crosslingual instruction tuning, enabling the model to graspL2with only a limited amount of parallel data."
  - [corpus] Weak evidence; corpus includes NusaX, NusaTranslation, and FLORES-200 datasets, but no explicit mention of their size or coverage for all language pairs.
- Break condition: If parallel data is unavailable or insufficient, cross-lingual alignment fails.

### Mechanism 2
- Claim: In-context query alignment improves cross-lingual understanding without requiring task-specific data.
- Mechanism: By providing in-context dictionary lookups for similar sentences in the target language, LLMs can align the query to the source language, enabling better task understanding in the target language.
- Core assumption: LLMs possess inherent dictionary lookup capabilities that can be exploited for cross-lingual alignment.
- Evidence anchors:
  - [abstract] "These methods significantly improve LLM performance on underrepresented languages without sacrificing performance on high-resource languages."
  - [section] "We introduce in-context query alignment, which enables better cross-lingual alignment through in-context learning without the needs of any task-relevant information in any languages."
  - [corpus] Weak evidence; case study in Table 5.4 shows dictionary lookup in an artificial language, but no explicit mention of its effectiveness on real underrepresented languages.
- Break condition: If LLMs lack inherent dictionary lookup capabilities, in-context query alignment fails.

### Mechanism 3
- Claim: UniVaR captures high-dimensional human value distributions in LLMs, enabling comparison and alignment across languages and cultures.
- Mechanism: By eliciting value-relevant information through QA pairs and applying multi-view learning, UniVaR learns a compact representation of value-decisive factors while discarding value-agnostic information.
- Core assumption: Value-relevant information can be elicited through QA pairs and captured by a high-dimensional representation.
- Evidence anchors:
  - [abstract] "Furthermore, a novel method to measure cultural values alignment between LLMs operating in different languages is proposed, ensuring cultural sensitivity and inclusivity."
  - [section] "We propose UniVaR, a high-dimensional representation, alike word and sentence embedding models, for capturing human value distributions in LLMs."
  - [corpus] Weak evidence; UniVaR is trained on 8 multilingual LLMs and tested on various open-source and commercial LLMs, but no explicit mention of the size or diversity of the training data.
- Break condition: If value-relevant information cannot be effectively elicited or captured by a high-dimensional representation, UniVaR fails.

## Foundational Learning

- Concept: Cross-lingual alignment
  - Why needed here: To improve LLM performance on underrepresented languages by aligning their representations with high-resource languages.
  - Quick check question: What are the three cross-lingual alignment objectives used in InstructAlign?

- Concept: In-context learning
  - Why needed here: To enable cross-lingual understanding without requiring task-specific data by leveraging LLMs' inherent dictionary lookup capabilities.
  - Quick check question: How does in-context query alignment differ from in-context label alignment?

- Concept: Value alignment
  - Why needed here: To ensure LLMs are aligned with human values and preferences across different languages and cultures.
  - Quick check question: What are the three major goals of value alignment in LLMs?

## Architecture Onboarding

- Component map: InstructAlign consists of cross-lingual alignment through instruction tuning and continual instruction tuning through experience replay. UniVaR consists of value-eliciting QA generation and multi-view value embedding learning. X-ICL consists of retrieval-based cross-lingual in-context learning and in-context alignment.
- Critical path: For InstructAlign, the critical path is cross-lingual alignment through instruction tuning. For UniVaR, the critical path is value-eliciting QA generation. For X-ICL, the critical path is retrieval-based cross-lingual in-context learning.
- Design tradeoffs: InstructAlign trades data efficiency for computational cost. UniVaR trades interpretability for expressiveness. X-ICL trades task-specificity for generalization.
- Failure signatures: InstructAlign fails if parallel data is unavailable or insufficient. UniVaR fails if value-relevant information cannot be effectively elicited or captured. X-ICL fails if LLMs lack inherent dictionary lookup capabilities or if the retrieval quality is poor.
- First 3 experiments:
  1. Evaluate InstructAlign on a small parallel dataset between an underrepresented and a high-resource language.
  2. Evaluate UniVaR on a small set of value-eliciting QA pairs across multiple languages.
  3. Evaluate X-ICL on a small set of underrepresented languages with and without in-context alignment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed cross-lingual alignment methods scale when applied to extremely low-resource languages with minimal parallel data?
- Basis in paper: [explicit]
- Why unresolved: The paper only evaluates the methods on 18 languages spoken in Indonesia, which may not represent the full spectrum of low-resource languages. The effectiveness of the methods on languages with even fewer speakers and less available data remains unclear.
- What evidence would resolve it: Experiments on a wider range of low-resource languages, including those with minimal parallel data, would provide insights into the scalability and limitations of the proposed methods.

### Open Question 2
- Question: Can the UniVaR representation be used to measure the degree of cultural value alignment between a language model and a specific target culture?
- Basis in paper: [explicit]
- Why unresolved: While the paper demonstrates the effectiveness of UniVaR in comparing cultural values across different languages and models, it does not explore its potential as a metric for measuring alignment with a specific target culture.
- What evidence would resolve it: Experiments that use UniVaR to measure the alignment of language models with predefined cultural values of specific target cultures would provide evidence for its applicability as an alignment metric.

### Open Question 3
- Question: How does the choice of semantic similarity model impact the effectiveness of semantic X-ICL for underrepresented languages?
- Basis in paper: [explicit]
- Why unresolved: The paper explores the use of different semantic similarity models for cross-lingual retrieval in X-ICL, but the impact of the choice of model on underrepresented languages is not fully investigated.
- What evidence would resolve it: Comparative experiments using different semantic similarity models on a diverse set of underrepresented languages would reveal the optimal choice for maximizing the effectiveness of semantic X-ICL.

## Limitations

- The effectiveness of cross-lingual alignment methods depends on the availability and quality of parallel data, which may vary across language pairs.
- UniVaR's ability to capture high-dimensional value distributions is promising but requires further validation with diverse and extensive training data.
- The in-context query alignment method's reliance on LLMs' inherent dictionary lookup capabilities is a potential weakness, as this may not be consistent across different models.

## Confidence

- **High Confidence**: The overall framework for evaluating multilingual LLMs on underrepresented languages is well-established, and the proposed methods (InstructAlign, UniVaR, X-ICL) are grounded in existing research.
- **Medium Confidence**: The effectiveness of the proposed methods depends on the availability and quality of parallel data, which may vary across language pairs. The UniVaR method's ability to capture high-dimensional value distributions is promising but requires further validation.
- **Low Confidence**: The in-context query alignment method's reliance on LLMs' inherent dictionary lookup capabilities is a potential weakness, as this may not be consistent across different models.

## Next Checks

1. Evaluate InstructAlign on a small parallel dataset between an underrepresented and a high-resource language to assess its ability to improve LLM performance without requiring large amounts of task-specific data.
2. Assess UniVaR's value-eliciting capabilities by testing it on a diverse set of value-eliciting QA pairs across multiple languages and cultures.
3. Investigate in-context query alignment's reliance on dictionary lookup by comparing its performance on underrepresented languages with and without in-context alignment, and assess its dependence on LLMs' inherent dictionary lookup capabilities.