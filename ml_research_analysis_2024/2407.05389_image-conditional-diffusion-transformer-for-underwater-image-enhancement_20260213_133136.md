---
ver: rpa2
title: Image-Conditional Diffusion Transformer for Underwater Image Enhancement
arxiv_id: '2407.05389'
source_url: https://arxiv.org/abs/2407.05389
tags:
- image
- underwater
- diffusion
- images
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel image-conditional diffusion transformer
  (ICDT) for underwater image enhancement (UIE). The method uses a degraded underwater
  image as conditional input and employs a transformer-based architecture in the denoising
  diffusion probabilistic model (DDPM) framework, replacing the conventional U-Net
  backbone.
---

# Image-Conditional Diffusion Transformer for Underwater Image Enhancement

## Quick Facts
- arXiv ID: 2407.05389
- Source URL: https://arxiv.org/abs/2407.05389
- Reference count: 40
- Key outcome: ICDT-XL/2 achieves PSNR of 28.17, SSIM of 0.87, and LPIPS of 0.14 on Underwater ImageNet dataset

## Executive Summary
This paper introduces a novel image-conditional diffusion transformer (ICDT) for underwater image enhancement (UIE). The method uses a degraded underwater image as conditional input and employs a transformer-based architecture in the denoising diffusion probabilistic model (DDPM) framework, replacing the conventional U-Net backbone. The authors train ICDT with a hybrid loss function involving variances, achieving better log-likelihoods and accelerating the sampling process. Experiments demonstrate the scalability of ICDTs and show that the largest model, ICDT-XL/2, outperforms all comparison methods on the Underwater ImageNet dataset, achieving state-of-the-art quality in image enhancement.

## Method Summary
The authors propose ICDT as a conditional diffusion model that takes degraded underwater images as input and transforms them into enhanced outputs. The architecture replaces the U-Net backbone in DDPM with a transformer, using pre-trained VAE encoder/decoder for latent space conversion. The model employs patch embeddings, diffusion transformer blocks with adaptive layer normalization, and a linear decoder for noise and covariance prediction. Training uses a hybrid loss function with learned variances to achieve better log-likelihoods while accelerating sampling. The model is trained on the Underwater ImageNet dataset with 3,700 paired images, split into 3,328 training and 372 testing samples.

## Key Results
- ICDT-XL/2 achieves PSNR of 28.17, SSIM of 0.87, and LPIPS of 0.14 on Underwater ImageNet dataset
- The method outperforms all comparison methods including CNN and GAN-based approaches
- Transformer-based architecture demonstrates superior scalability compared to traditional U-Net approaches

## Why This Works (Mechanism)

### Mechanism 1: Transformer Backbone Scalability
Replacing U-Net with transformer backbone in DDPM improves scalability and sample quality by processing sequences of image patches with self-attention, allowing long-range dependency modeling and parallel computation. This is more scalable than CNNs' fixed receptive field.

### Mechanism 2: Hybrid Loss with Learned Variances
The hybrid loss function with learned variances accelerates sampling while maintaining quality by allowing diffusion to proceed in fewer steps through dynamic noise schedule adaptation, while the hybrid objective preserves training stability.

### Mechanism 3: Conditional Input for Content Fidelity
Using the degraded image as conditional input improves fidelity to target content by concatenating degraded image latent with noised latent at every denoising step, guiding restoration toward correct content.

## Foundational Learning

- **Concept**: Denoising Diffusion Probabilistic Models (DDPM)
  - Why needed: Core generative framework that ICDT extends; understanding forward/reverse processes is essential
  - Quick check: What are the two main processes in a DDPM, and how do they interact during sampling?

- **Concept**: Vision Transformers (ViT) and patch embeddings
  - Why needed: ICDT replaces U-Net with transformer; understanding patchifying and positional embeddings is critical
  - Quick check: How does the number of patches relate to computational cost in ViT, and what hyperparameter controls this?

- **Concept**: Hybrid loss functions and learned variances
  - Why needed: ICDT uses a hybrid loss to learn variance parameters; understanding this balance is key to grasping speedup claims
  - Quick check: What is the role of the variance term in the loss, and how does it affect the number of sampling steps?

## Architecture Onboarding

- **Component map**: Degraded image → VAE encoder → Conditional latent → Channel-wise concat → Transformer → Denoised latent → VAE decoder → Output image
- **Critical path**: Pre-trained VAE encoder/decoder → Patch embed layer → N diffusion transformer blocks with adaLN → Linear decoder → Hybrid loss training
- **Design tradeoffs**: Larger patch size reduces tokens but loses detail; deeper/wider transformer improves quality but increases compute; more sampling steps improve fidelity but slow inference
- **Failure signatures**: Blurry outputs suggest underfitting or aggressive variance learning; color artifacts indicate conditioning mismatch or VAE reconstruction error; slow convergence points to poor initialization or learning rate issues
- **First 3 experiments**: 1) Train ICDT-S/8 on tiny subset to verify PSNR improvement over U-Net DDPM; 2) Vary patch size (8→4→2) with ICDT-S to plot FLOPs vs PSNR; 3) Compare sampling speed with/without learned variances and measure quality drop

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the limitations and scope, several important questions remain unanswered regarding scalability to larger datasets, performance with different transformer architectures, and the impact of latent space dimensionality on image quality.

## Limitations

- **Dataset size constraints**: The Underwater ImageNet dataset contains only 3,700 paired images, which is relatively small for diffusion models, limiting generalization assessment
- **Computational resource requirements**: Transformer-based approaches require significantly more computational resources than U-Net, but detailed FLOPs comparisons and inference time measurements are not provided
- **Lack of ablation studies**: The paper lacks direct comparisons isolating transformer vs U-Net benefits, making it difficult to attribute performance gains specifically to the transformer architecture

## Confidence

- **High confidence**: Transformer architecture provides better scalability than U-Net (supported by broader literature)
- **Medium confidence**: Learned variances accelerate sampling without quality loss (mechanism plausible but no direct ablation)
- **Low confidence**: ICDT-XL/2 achieves state-of-the-art quality on Underwater ImageNet (only tested on one dataset, no comparison to most recent methods)

## Next Checks

1. **Ablation study**: Train ICDT with and without learned variances on the same dataset, measuring both sampling speed and quality to directly verify the acceleration claim.

2. **Cross-dataset evaluation**: Test ICDT-XL/2 on additional underwater datasets (e.g., UIEB, UFO-120) to assess generalization beyond the Underwater ImageNet.

3. **Computational efficiency analysis**: Measure and compare FLOPs, parameters, and inference time between ICDT-XL/2 and the strongest U-Net baseline to quantify the scalability advantage.