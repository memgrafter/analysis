---
ver: rpa2
title: Federated Communication-Efficient Multi-Objective Optimization
arxiv_id: '2410.16398'
source_url: https://arxiv.org/abs/2410.16398
tags:
- learning
- fedcmoo
- server
- objectives
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses federated multi-objective optimization (FMOO),
  where a single model must be trained to optimize multiple objective functions in
  a distributed, privacy-preserving setting. Existing approaches suffer from high
  communication costs that scale with the number of objectives and suffer from local
  training drift across objectives.
---

# Federated Communication-Efficient Multi-Objective Optimization

## Quick Facts
- arXiv ID: 2410.16398
- Source URL: https://arxiv.org/abs/2410.16398
- Authors: Baris Askin; Pranay Sharma; Gauri Joshi; Carlee Joe-Wong
- Reference count: 40
- One-line primary result: FedCMOO achieves communication cost independent of the number of objectives (O(d) instead of O(Md)) while converging to Pareto stationary solutions in federated multi-objective optimization.

## Executive Summary
This paper addresses federated multi-objective optimization (FMOO) where a single model must be trained to optimize multiple objective functions across distributed clients. Existing approaches suffer from high communication costs that scale linearly with the number of objectives and experience local training drift across objectives. The proposed FedCMOO algorithm introduces a communication-efficient approach using randomized SVD-based compression of the Gram matrix of stochastic Jacobians, reducing per-client communication from O(Md) to O(d). The method also mitigates local drift by using aggregated stochastic gradients for local training, achieving theoretical convergence to Pareto stationary solutions under milder assumptions than prior work. Experiments demonstrate faster convergence and superior accuracy compared to baseline approaches on diverse datasets including MultiMNIST, CIFAR10+FMNIST, CelebA, and QM9.

## Method Summary
FedCMOO is a federated learning algorithm for multi-objective optimization that addresses communication inefficiency and local drift. The server sends the current model to participating clients, who compute the stochastic Jacobian matrix and reshape it into a square matrix. Using randomized SVD, clients compress this matrix and send only the top r components (keeping upload budget at d). The server reconstructs an approximate Gram matrix from these compressed matrices, computes aggregation weights to maximize total gradient descent while satisfying compression constraints, and sends these weights back to clients. Clients perform τ local SGD steps on the weighted aggregate loss P_k w_k f_i,k and send updates to the server, which aggregates them into the global model. A preference-based variant FedCMOO-Pref uses KL divergence minimization to align solutions with user-specified objective value ratios.

## Key Results
- FedCMOO reduces per-client communication cost from O(Md) to O(d) using randomized SVD-based compression
- Theoretical convergence to Pareto stationary solutions with sample complexity O(Mn/ϵ²), improving upon existing methods
- Experiments show faster convergence and superior accuracy compared to baseline FSMGDA on MultiMNIST, CIFAR10+FMNIST, CelebA, and QM9 datasets
- FedCMOO-Pref variant successfully aligns solutions with user-specified objective value ratios

## Why This Works (Mechanism)

### Mechanism 1
FedCMOO reduces per-client communication cost from O(Md) to O(d) using randomized SVD-based compression of the Gram matrix. Instead of sending M separate gradient updates for each objective, clients compute the stochastic Jacobian matrix, reshape it to a square matrix, apply randomized SVD to compress it, and send only the top r components. The server reconstructs an approximate Gram matrix from these compressed matrices. This works because the Gram matrix of the Jacobian can be well-approximated by the compressed versions while maintaining sufficient fidelity for weight computation. If the approximation error becomes too large relative to the true Gram matrix, the computed weights will be inaccurate, degrading convergence.

### Mechanism 2
FedCMOO mitigates local training drift by using aggregated stochastic gradients for local training instead of separate objective-specific updates. Unlike FSMGDA which performs independent local updates for each objective and fuses gradients only at the server, FedCMOO clients perform τ local SGD steps on the weighted aggregate loss P_k w_k f_i,k, maintaining better alignment with the global optimization direction. This works because aggregating gradients during local training preserves the descent direction more effectively than separate objective updates. If the weighted aggregation doesn't properly balance conflicting gradients across objectives, local training could still diverge from the Pareto stationary solution.

### Mechanism 3
The preference-based variant FedCMOO-Pref can find Pareto solutions aligned with user-specified objective value ratios. It uses KL divergence minimization to measure deviation from desired objective ratios, computes weights that either reduce KL divergence or maximize total descent, and constrains weights to prevent increasing losses of preferred objectives. This works because KL divergence between normalized scaled losses and uniform distribution provides a good measure of preference satisfaction. If the difficulty gap between objectives is too large, the method may fail to satisfy strongly imbalanced preferences, defaulting to more balanced solutions.

## Foundational Learning

- **Multi-objective optimization and Pareto stationarity**: Understanding why we can't minimize all objectives simultaneously and need to find Pareto stationary solutions. Quick check: What is the difference between a Pareto optimal solution and a Pareto stationary solution in non-convex problems?

- **Federated learning with partial client participation and local training**: Understanding the challenges of data heterogeneity, communication bottlenecks, and local drift in federated settings. Quick check: How does partial client participation affect convergence in federated optimization compared to centralized optimization?

- **Stochastic gradient descent with compression techniques**: Understanding how compression affects gradient fidelity and convergence, especially with randomized SVD. Quick check: What is the trade-off between compression ratio and approximation error in gradient compression?

## Architecture Onboarding

- **Component map**: Server -> Model distribution -> Clients (Jacobian computation -> SVD compression -> Update training) -> Server (Gram matrix reconstruction -> Weight computation -> Model aggregation)
- **Critical path**: Server sends model → Clients compute compressed Jacobians → Server reconstructs Gram matrix → Server computes weights → Server sends weights → Clients perform local training → Clients send updates → Server aggregates updates
- **Design tradeoffs**: Communication efficiency vs approximation accuracy, local drift mitigation vs convergence speed, preference satisfaction vs feasibility
- **Failure signatures**: Poor convergence indicated by objective values not improving, weight oscillations, or divergence; communication bottlenecks if compression is insufficient
- **First 3 experiments**:
  1. Run FedCMOO on MultiMNIST with N=100, M=2, compare communication cost vs FSMGDA
  2. Test local drift by varying τ in FedCMOO vs FSMGDA on MNIST+FMNIST
  3. Validate preference satisfaction by running FedCMOO-Pref with different r vectors on MultiMNIST

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of FedCMOO scale when the number of objectives M becomes very large (e.g., hundreds or thousands)? The paper shows that FedCMOO's communication cost is O(d) independent of M, and its sample complexity is O(Mn/ϵ²). However, the theoretical analysis assumes a fixed small M, and the paper only experiments with up to 40 objectives (CelebA dataset). The paper does not provide theoretical analysis or empirical results for very large M scenarios, which would be important for real-world applications with many objectives. Experiments with datasets having hundreds of objectives and theoretical analysis of convergence rates for large M would clarify scalability limitations.

### Open Question 2
How sensitive is FedCMOO to the choice of hyperparameters like learning rates and compression rank r? The paper mentions that learning rates are selected via validation and compression rank r is chosen to keep upload budget at d×1, but doesn't provide sensitivity analysis or guidelines for hyperparameter selection. The paper doesn't explore the robustness of FedCMOO to hyperparameter choices or provide practical guidance for tuning these parameters in different scenarios. Sensitivity analysis experiments varying learning rates, compression rank, and other hyperparameters across different datasets would reveal robustness characteristics and tuning guidelines.

### Open Question 3
How does FedCMOO perform under highly heterogeneous data distributions where clients have very different objective functions? The paper assumes each client has data for all tasks and uses Dirichlet distribution with α=0.3 for data partitioning, but doesn't explore extreme heterogeneity cases where clients have disjoint or very different objective data. The paper's analysis and experiments focus on moderate heterogeneity, leaving open questions about performance in extreme cases like clients having completely different objective functions. Experiments with extreme data heterogeneity scenarios (e.g., clients having disjoint objectives) and theoretical analysis of convergence under such conditions would clarify performance boundaries.

### Open Question 4
Can the preference-based FedCMOO-Pref algorithm handle conflicting preferences where user-specified ratios are mathematically impossible to achieve? The paper shows FedCMOO-Pref can find solutions aligned with user preferences in most cases, but notes that "imbalanced preferences or differences in the difficulty levels of objectives may cause misalignment." The paper doesn't provide a formal framework for detecting or handling impossible preference specifications, nor does it explore what happens when users request contradictory objectives. Experiments with deliberately conflicting preference specifications and theoretical analysis of the feasible preference space would clarify the algorithm's behavior under impossible constraints.

## Limitations

- The randomized SVD compression method's approximation quality depends on Gram matrix structure, which may vary across datasets and objectives
- Generalization to non-image domains (text, time series) remains untested despite success on image and molecular datasets
- Preference-based variant's performance with highly imbalanced objectives is not fully characterized

## Confidence

**High Confidence**: Claims about communication complexity reduction from O(Md) to O(d) and the sample complexity bound O(Mn/ϵ²) are well-supported by theoretical analysis and direct comparisons to baseline methods.

**Medium Confidence**: Claims about local drift mitigation and preference-based alignment are supported by experimental evidence but rely on assumptions about objective function characteristics and preference distributions that may not hold universally.

**Low Confidence**: Claims about generalizability to arbitrary multi-objective federated learning scenarios, particularly with non-convex objectives or extreme data heterogeneity, lack comprehensive validation.

## Next Checks

1. **Compression Fidelity Test**: Systematically vary the rank parameter r in the randomized SVD compression and measure the resulting approximation error in the Gram matrix reconstruction, then correlate this with convergence performance across different objective combinations.

2. **Drift Analysis Under Varying τ**: Conduct controlled experiments varying the number of local training steps τ across a wider range (1-50) to identify the exact point where local drift begins to dominate and whether FedCMOO maintains superiority throughout.

3. **Preference Sensitivity Analysis**: Test FedCMOO-Pref with extreme preference ratios (e.g., r = [0.99, 0.01]) on objectives with large difficulty gaps to determine the method's limits in satisfying strongly imbalanced preferences.