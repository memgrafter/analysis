---
ver: rpa2
title: 'ShapG: new feature importance method based on the Shapley value'
arxiv_id: '2407.00506'
source_url: https://arxiv.org/abs/2407.00506
tags:
- shapg
- features
- h1n1
- feature
- importance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ShapG, a new model-agnostic Explainable AI
  (XAI) method based on Shapley values for graphs. The method constructs an undirected
  graph of features using Pearson correlation coefficients and calculates approximated
  Shapley values by sampling coalitions between each feature and its neighbors.
---

# ShapG: new feature importance method based on the Shapley value

## Quick Facts
- arXiv ID: 2407.00506
- Source URL: https://arxiv.org/abs/2407.00506
- Authors: Chi Zhao; Jing Liu; Elena Parilina
- Reference count: 40
- Primary result: Introduces ShapG, a model-agnostic XAI method using Shapley values for graphs, achieving 4.8-161x speedup over KernelSHAP while improving feature importance accuracy

## Executive Summary
This paper introduces ShapG, a novel model-agnostic Explainable AI (XAI) method based on Shapley values for graphs. The method constructs an undirected graph of features using Pearson correlation coefficients and calculates approximated Shapley values by sampling coalitions between each feature and its neighbors. This approach significantly reduces computational complexity compared to traditional methods. Evaluation on two datasets shows ShapG provides more accurate feature importance rankings than existing methods like SHAP, LIME, and Feature Importance, while demonstrating significant computational advantages.

## Method Summary
ShapG introduces a novel approach to feature importance using Shapley values for graphs. The method constructs an undirected graph where nodes represent features and edges represent Pearson correlation coefficients between features. Instead of computing exact Shapley values by evaluating all possible feature coalitions (exponential complexity), ShapG approximates these values by sampling coalitions between each feature and its neighboring features in the graph. This approximation strategy significantly reduces computational complexity while maintaining accuracy in feature importance rankings. The method is model-agnostic and can handle complex hybrid models where traditional game-theory-based methods fail.

## Key Results
- ShapG achieves 4.8-161x faster computation compared to KernelSHAP and SamplingSHAP depending on dataset and model
- For housing price dataset, ShapG achieves better RÂ² values after feature removal compared to SHAP, LIME, and Feature Importance methods
- For H1N1 dataset, ShapG demonstrates superior accuracy preservation when features are removed based on importance rankings
- Successfully explains complex hybrid models where other game-theory-based methods fail

## Why This Works (Mechanism)
ShapG leverages the structure of feature relationships through correlation-based graphs to approximate Shapley values efficiently. By focusing only on coalitions between features and their neighbors rather than all possible coalitions, the method drastically reduces computational complexity from exponential to polynomial time. The graph structure captures feature dependencies, allowing the method to account for interactions without explicitly computing all combinations. The sampling approach provides a practical trade-off between computational efficiency and approximation accuracy.

## Foundational Learning
1. Shapley Value Theory (why needed: foundation for fair feature attribution)
   - Quick check: Verify understanding of marginal contribution concept and symmetry axiom

2. Graph Theory for Feature Relationships (why needed: efficient approximation strategy)
   - Quick check: Confirm understanding of correlation-based graph construction and neighbor relationships

3. Model-Agnostic Explainability (why needed: broad applicability across model types)
   - Quick check: Understand how feature importance can be extracted without model internals

## Architecture Onboarding

Component Map:
Features -> Correlation Matrix -> Undirected Graph -> Coalition Sampling -> Shapley Value Approximation -> Feature Importance Rankings

Critical Path:
1. Compute Pearson correlation coefficients between all feature pairs
2. Construct undirected graph based on correlation thresholds
3. For each feature, sample coalitions with neighboring features
4. Approximate Shapley values from sampled coalitions
5. Generate feature importance rankings

Design Tradeoffs:
- Computational efficiency vs. approximation accuracy in coalition sampling
- Correlation threshold selection balancing graph sparsity and feature relationship capture
- Sampling strategy affecting the stability and reliability of Shapley value approximations

Failure Signatures:
- Poor correlation threshold selection leading to disconnected graphs or overly dense connections
- Insufficient sampling resulting in unstable importance rankings
- Violation of Pearson correlation assumptions for non-linear feature relationships

First Experiments:
1. Run ShapG on a simple linear regression with correlated features to verify basic functionality
2. Compare runtime and importance rankings against exact Shapley computation on a small dataset
3. Test sensitivity to correlation threshold parameter on a dataset with known feature relationships

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to only two datasets (housing prices and H1N1), limiting generalizability
- Assumes linear relationships through Pearson correlation coefficients, potentially missing non-linear feature interactions
- Approximation of Shapley values through sampling may introduce uncertainty not thoroughly quantified

## Confidence
- High confidence: Computational complexity claims and runtime comparisons are well-supported by methodology and results
- Medium confidence: Accuracy improvements over other methods, as evaluation is limited to two datasets
- Medium confidence: The claim about explaining hybrid models where other game-theory methods fail, as specific examples and detailed comparisons are not provided

## Next Checks
1. Test ShapG on diverse datasets with different characteristics (non-linear relationships, high-dimensional features, time series) to assess generalizability
2. Quantify the variance in feature importance rankings when using different sampling strategies for coalition approximation
3. Compare ShapG's performance with other graph-based feature importance methods that use different correlation measures or handle non-linear relationships