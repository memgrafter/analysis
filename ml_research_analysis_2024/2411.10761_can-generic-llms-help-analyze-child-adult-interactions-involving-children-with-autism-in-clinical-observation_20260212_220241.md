---
ver: rpa2
title: Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with
  Autism in Clinical Observation?
arxiv_id: '2411.10761'
source_url: https://arxiv.org/abs/2411.10761
tags:
- language
- adult
- child
- llms
- children
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluates the ability of generic Large Language Models
  (LLMs) to analyze child-adult interactions involving children with autism in clinical
  observation settings. Four tasks were designed: classifying child-adult utterances,
  recognizing engaged activities, predicting language skills, and understanding relevant
  traits.'
---

# Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with Autism in Clinical Observation?

## Quick Facts
- arXiv ID: 2411.10761
- Source URL: https://arxiv.org/abs/2411.10761
- Authors: Tiantian Feng; Anfeng Xu; Rimita Lahiri; Helen Tager-Flusberg; So Hyun Kim; Somer Bishop; Catherine Lord; Shrikanth Narayanan
- Reference count: 23
- One-line primary result: LLMs demonstrate strong capability in analyzing child-adult interactions involving children with autism, often surpassing non-expert human evaluators in clinical observation settings

## Executive Summary
This study evaluates the ability of generic Large Language Models (LLMs) to analyze child-adult interactions involving children with autism in clinical observation settings. The research focuses on four key tasks: classifying child-adult utterances, recognizing engaged activities, predicting language skills, and understanding relevant traits. Using two datasets (Remote-NLS and ADOSMod3) with expert-annotated transcripts, the study compares multiple open-source LLMs against non-expert human evaluators. Results demonstrate that LLMs can effectively segment interactions, assist in language skills evaluation, identify engaged activities, and provide clinically relevant context for assessments, highlighting their potential to support clinicians in autism diagnosis and intervention.

## Method Summary
The study employs local open-source LLMs (Mistral-7B, LLaMa2-7B/13B, LLaMa3-8B, Qwen1.5-7B/14B) with 0-shot and 5-shot prompting on two datasets: Remote-NLS (89 sessions of 15-minute child-adult interactions at home) and ADOSMod3 (164 children in child-clinician interactions following ADOS-2 protocol). Four tasks are evaluated: utterance classification (F1 score), activity recognition (multilabel F1), language skill prediction (binary F1), and trait prediction (binary F1). Performance is compared against non-expert human evaluations and a fine-tuned RoBERTa baseline for utterance classification. The study measures LLM effectiveness in analyzing complex conversations in clinical observation sessions.

## Key Results
- LLMs demonstrate strong capability in segmenting child-adult interactions of interest in clinical observation sessions
- Models show potential to assist in language skills evaluation and identify engaged activities with reasonable accuracy
- LLMs often surpass the performance of non-expert human evaluators across multiple tasks
- The study highlights promise for LLMs in understanding child-inclusive interactions in clinical settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can segment child-adult utterances by leveraging contextual cues from surrounding dialogue
- Mechanism: The models use 5-shot prompting to provide historical context, enabling them to distinguish between child and adult speech patterns based on linguistic markers and conversational flow
- Core assumption: Sufficient context from surrounding utterances allows the model to infer speaker identity even in noisy, unstructured conversations
- Evidence anchors: [abstract] "Specifically, we explore LLMs in performing four tasks: classifying child-adult utterances..."; [section] "However, adding more context does not consistently improve performance, as seen with the LLaMa3-8B's decrease with 5-shot across both datasets"

### Mechanism 2
- Claim: LLMs can predict engaged activities by recognizing patterns in dialogue transcripts that correspond to specific activities
- Mechanism: The models analyze the entire session transcript to identify keywords, phrases, and interaction patterns that match predefined activity categories, even in complex multi-label scenarios
- Core assumption: Activity patterns are sufficiently distinct in transcripts to be recognizable by language models trained on general text
- Evidence anchors: [abstract] "Results show their potential to segment interactions of interest, assist in language skills evaluation, identify engaged activities..."; [section] "Activity recognition is a multilabel task in the Remote-NLS dataset"

### Mechanism 3
- Claim: LLMs can evaluate language skills by analyzing linguistic complexity and developmental markers in child speech
- Mechanism: The models assess vocabulary complexity, sentence structure, and grammatical patterns against established developmental benchmarks to categorize language proficiency levels
- Core assumption: Language skill indicators are reliably encoded in transcripts and can be detected by pattern-matching in LLMs
- Evidence anchors: [abstract] "predicting the child's language skills" and "evaluating the child's language skills"; [section] "Language Skill. Two unique codes evaluate language skills in the Remote-NLS and ADOSMod3 datasets"

## Foundational Learning

- Concept: Speaker diarization
  - Why needed here: Essential for distinguishing between child and adult utterances in transcripts before analysis
  - Quick check question: What are the key acoustic and linguistic features that distinguish child speech from adult speech?

- Concept: Activity pattern recognition
  - Why needed here: Required to map dialogue content to specific activities like play, reading, or art
  - Quick check question: How do different activities manifest linguistically in child-adult interactions?

- Concept: Language development milestones
  - Why needed here: Critical for evaluating language skills against established benchmarks
  - Quick check question: What are the key linguistic markers that distinguish pre-verbal, first words, and word combinations stages?

## Architecture Onboarding

- Component map: Transcript preprocessing -> Speaker classification -> Activity recognition -> Language skill assessment -> Age prediction
- Critical path: The sequence flows from utterance-level understanding to session-level comprehension, with each task building on previous classifications
- Design tradeoffs: Using smaller models (7B-15B parameters) balances computational efficiency with performance, but may limit complex reasoning capabilities
- Failure signatures: Hallucinations in language skill predictions, confusion in activity recognition, inconsistent speaker classification
- First 3 experiments:
  1. Test speaker classification accuracy with varying context window sizes (1-shot to 10-shot)
  2. Evaluate activity recognition performance on transcripts with different activity densities
  3. Assess language skill prediction accuracy across different age ranges and developmental stages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can multi-modal approaches combining LLMs with speech foundation models and vision language models (VLMs) improve the accuracy of analyzing child-adult interactions involving children with autism?
- Basis in paper: [explicit] The authors explicitly mention plans to use speech foundation models and VLMs to provide multi-modal evaluations along with LLMs in the future
- Why unresolved: The current study only uses text transcripts and does not explore how combining multiple modalities might enhance performance
- What evidence would resolve it: Conducting experiments that integrate speech recognition, speaker diarization, and visual analysis with LLM predictions and comparing performance against the current text-only approach

### Open Question 2
- Question: How do hallucinations in LLM outputs affect expert assessments in clinical and diagnostic settings involving children with autism?
- Basis in paper: [explicit] The authors observe hallucinations in LLM responses and acknowledge the need for systematic study on how these hallucinated outputs would impact expert assessments
- Why unresolved: The study identifies hallucinations as a concern but does not investigate their specific impact on clinical decision-making
- What evidence would resolve it: Conducting controlled studies where experts evaluate LLM outputs with varying levels of hallucination to determine how they affect diagnostic accuracy and clinical judgments

### Open Question 3
- Question: What biases exist in LLMs when performing tasks related to understanding child-adult interactions involving children with autism?
- Basis in paper: [explicit] The authors acknowledge that LLMs are known to have biased outputs and note the lack of analysis of biases in their work
- Why unresolved: The study does not include any systematic analysis of potential biases in the LLMs' predictions across the four designed tasks
- What evidence would resolve it: Performing comprehensive bias analysis by testing LLMs on diverse datasets and examining predictions across different demographic groups, language abilities, and cultural contexts to identify systematic biases

## Limitations
- The study relies on two specific datasets with limited sample sizes (89 and 164 sessions), which may not generalize to other clinical settings or cultural contexts
- Performance shows high sensitivity to prompt engineering, with 5-shot prompting improving some tasks while degrading others, particularly with LLaMa3-8B
- The study lacks comparison with expert clinicians who would typically use these assessments in practice, making claims about surpassing non-expert evaluators less clinically meaningful

## Confidence
- High Confidence: LLMs can perform basic utterance classification and activity recognition tasks with reasonable accuracy across multiple models and datasets
- Medium Confidence: LLMs demonstrate potential for language skill evaluation and trait prediction, though results vary significantly by model and task complexity with reliability concerns
- Low Confidence: Claims that LLMs can fully replace or significantly augment clinical expertise in autism assessment are premature without clinical validation and real-world workflow integration

## Next Checks
1. **Expert Clinician Validation Study** - Conduct a head-to-head comparison of LLM outputs against expert clinician assessments using the same transcripts, measuring inter-rater reliability and clinical agreement to establish whether LLM performance translates to clinical utility

2. **Cross-Dataset Generalization Test** - Evaluate the best-performing models from this study on an independent, held-out dataset from a different clinical setting or population to assess robustness and generalizability beyond the original training data

3. **Prompt Engineering Optimization** - Systematically vary prompt structures, context window sizes, and shot counts across all four tasks to identify optimal prompting strategies for each model-task combination, addressing the observed inconsistencies in performance