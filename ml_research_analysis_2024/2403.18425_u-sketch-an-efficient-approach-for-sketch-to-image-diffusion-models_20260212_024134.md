---
ver: rpa2
title: 'U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models'
arxiv_id: '2403.18425'
source_url: https://arxiv.org/abs/2403.18425
tags:
- edge
- image
- sketch
- images
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: U-Sketch introduces a U-Net-based latent edge predictor for sketch-to-image
  diffusion synthesis, replacing the per-pixel MLP approach to better capture spatial
  correlations. The framework enables users to optionally preprocess sketches via
  a simplification network and uses the edge predictor to guide image synthesis during
  inference without retraining.
---

# U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models

## Quick Facts
- arXiv ID: 2403.18425
- Source URL: https://arxiv.org/abs/2403.18425
- Authors: Ilias Mitsouras; Eleftherios Tsonis; Paraskevi Tzouveli; Athanasios Voulodimos
- Reference count: 38
- Primary result: U-Net-based latent edge predictor replaces per-pixel MLP approach for sketch-to-image diffusion, improving realism and reducing denoising steps by ~80%

## Executive Summary
U-Sketch introduces a U-Net-based latent edge predictor to guide sketch-to-image diffusion synthesis, replacing the traditional per-pixel MLP approach. The framework enables users to optionally preprocess sketches via a simplification network and uses the edge predictor to guide image synthesis during inference without retraining. Qualitative results show improved realism and edge fidelity over the MLP baseline, with reduced denoising steps by approximately 80%, leading to significant time savings. User studies confirm preference for U-Sketch in realism (60.9%), edge fidelity (70.5%), and structural coherence (70.7%), with higher mean opinion scores (MOS) and lower variance.

## Method Summary
U-Sketch replaces the per-pixel MLP edge predictor in sketch-to-image diffusion with a U-Net architecture that captures spatial correlations more effectively. The method involves extracting intermediate activations from Stable Diffusion's denoising U-Net, processing them through the U-Net edge predictor, and using the resulting edge maps to guide the denoising process via gradient-based optimization. A sketch simplification network is optionally applied to preprocess rough sketches. The framework uses 50 total denoising steps with sketch guidance applied to the first 25 steps, achieving an 80% reduction in required steps compared to traditional approaches.

## Key Results
- User studies show U-Sketch preferred over MLP baseline for realism (60.9%), edge fidelity (70.5%), and structural coherence (70.7%)
- Recall metric demonstrates better alignment between generated images and input sketches (0.645 vs 0.595)
- Reduced denoising steps by ~80%, significantly decreasing execution time
- MOS values higher for U-Sketch with lower variance, indicating more consistent quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The U-Net latent edge predictor captures spatial correlations between pixels more effectively than a per-pixel MLP approach.
- Mechanism: The U-Net architecture uses convolutional layers that process spatial neighborhoods, allowing it to model relationships between adjacent pixels. This is crucial for edge detection because edges are defined by discontinuities in pixel values across spatial regions.
- Core assumption: The spatial structure of edges can be better represented through convolutional feature extraction rather than treating each pixel independently.
- Evidence anchors:
  - [abstract]: "which is capable of efficiently capturing both local and global features, as well as spatial correlations between pixels"
  - [section]: "it is reasonable to utilize architectures that are capable of processing the input tensors as whole and not in a per-pixel way"
  - [corpus]: No direct evidence found in corpus about U-Net vs MLP for edge detection; this is a novel contribution

### Mechanism 2
- Claim: The U-Net predictor provides better edge estimations at earlier denoising steps, reducing total denoising iterations by ~80%.
- Mechanism: By capturing spatial correlations, the U-Net can estimate edge maps more accurately from intermediate activations, allowing the sketch-guidance process to be effective with fewer steps. The gradient-based guidance (equation 6) works more effectively when edge predictions are accurate.
- Core assumption: Better early edge predictions translate to fewer denoising steps needed for satisfactory results.
- Evidence anchors:
  - [abstract]: "drastically reducing the number of required denoising steps and, consequently, the overall execution time"
  - [section]: "Our framework tends to prioritize the preservation of realism over attaining absolute spatial precision"
  - [corpus]: No direct evidence found about 80% reduction; this is a key quantitative claim from the paper

### Mechanism 3
- Claim: The sketch simplification network improves edge fidelity for rough or poorly drawn sketches by preprocessing them before the diffusion process.
- Mechanism: The simplification network uses convolutional layers trained with adversarial loss to refine sketch edges, removing overlapping lines and smoothing transitions. This creates cleaner edge maps that the U-Net predictor can work with more effectively.
- Core assumption: Preprocessing sketches to remove noise and ambiguity improves the subsequent edge guidance process.
- Evidence anchors:
  - [section]: "This network is particularly useful in cases of rough and poorly drawn sketches, where it is used to alleviate the impact of the overlapping and indistinct lines"
  - [section]: "examples 4c and 4d demonstrate an overall improvement after simplifying the input sketches"
  - [corpus]: No direct evidence found about sketch simplification networks in corpus; this appears to be a novel component

## Foundational Learning

- Concept: Diffusion models and the reverse diffusion process
  - Why needed here: Understanding how U-Sketch integrates with Stable Diffusion's denoising U-Net and modifies the latent space during inference
  - Quick check question: What is the role of the denoising U-Net in Stable Diffusion, and how does U-Sketch modify its output?

- Concept: Convolutional neural networks and spatial feature extraction
  - Why needed here: Understanding why U-Net architecture is better suited for edge detection than MLPs, and how intermediate activations are extracted and processed
  - Quick check question: How do convolutional layers in U-Net capture spatial correlations that MLPs miss?

- Concept: Gradient-based optimization and guidance in generative models
  - Why needed here: Understanding how the edge similarity measure is used to modify the denoising process through gradient descent
  - Quick check question: How does the guidance strength parameter α balance between edge fidelity and realism in the generated images?

## Architecture Onboarding

- Component map:
  Input Sketch -> Optional Sketch Simplification Network -> Stable Diffusion VAE Encoder -> Stable Diffusion denoising U-Net -> U-Net Latent Edge Predictor (ULEP) -> Guidance Mechanism with Gradient Modification -> Stable Diffusion VAE Decoder -> Output Image

- Critical path:
  1. Encode sketch and text to latent space
  2. Initialize random noise
  3. Iteratively denoise with U-Net guidance for first S steps
  4. Complete denoising without guidance for remaining steps
  5. Decode to image space

- Design tradeoffs:
  - U-Net vs MLP: Better spatial correlation capture vs simpler architecture
  - Guidance strength β: Higher values improve edge fidelity but may reduce realism
  - Number of guided steps S: More steps improve adherence but increase computation
  - Sketch simplification: Optional preprocessing improves rough sketches but may over-smooth detailed ones

- Failure signatures:
  - Blurry edges or loss of sketch structure: Guidance strength too low or U-Net predictions inaccurate
  - Unrealistic images or poor text adherence: Guidance too strong or too many guided steps
  - Slow generation: Too many guided steps or inefficient U-Net architecture
  - Sketch simplification artifacts: Network over-smooths or introduces distortions

- First 3 experiments:
  1. Baseline comparison: Generate images with MLP predictor vs U-Net predictor using same seed and parameters
  2. Step reduction test: Measure quality degradation when reducing guided steps from 25 to 10, 15, 20
  3. Sketch simplification impact: Compare outputs with and without sketch preprocessing on rough vs clean sketches

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several unresolved issues emerge from the analysis:
- The scalability of the U-Net approach to larger, more diverse datasets remains untested
- Alternative edge detection methods (Canny, Sobel) could potentially improve performance
- The systematic impact of noise initialization across varying sketch complexities requires deeper analysis

## Limitations
- Lack of rigorous ablation studies for key hyperparameters like guidance strength β and number of guided steps S
- No systematic validation of the claimed 80% reduction in denoising steps across different image types
- Limited exploration of alternative edge detection methods beyond PiDiNet

## Confidence
- **High confidence**: The architectural choice of U-Net over MLP for spatial correlation capture is well-justified theoretically and supported by visual results
- **Medium confidence**: The qualitative improvements in realism and edge fidelity are convincing, but lack rigorous quantitative metrics beyond recall and user studies
- **Low confidence**: The claimed 80% reduction in denoising steps and its consistency across different image types requires further validation

## Next Checks
1. Conduct systematic ablation studies varying β (0.5 to 2.5) and S (10 to 40) to quantify the trade-off between edge fidelity and realism
2. Implement quantitative metrics comparing structural similarity (SSIM) and edge preservation scores against baseline methods
3. Test the method on diverse sketch qualities and image categories to validate generalizability beyond the Sketchy Dataset and ImageNet classes used in training