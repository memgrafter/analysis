---
ver: rpa2
title: 'EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication
  with Cloud-based LLMs'
arxiv_id: '2402.05868'
source_url: https://arxiv.org/abs/2402.05868
tags:
- user
- encryption
- encrypted
- data
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PromptCrypt, a simple yet effective encryption
  method designed to protect user privacy when interacting with cloud-based LLMs like
  ChatGPT. The core idea is to convert user input from natural language into sequences
  of emojis, emoticons, and operators, effectively masking sensitive data from both
  humans and the LLM itself.
---

# EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs

## Quick Facts
- arXiv ID: 2402.05868
- Source URL: https://arxiv.org/abs/2402.05868
- Authors: Sam Lin; Wenyue Hua; Zhenting Wang; Mingyu Jin; Lizhou Fan; Yongfeng Zhang
- Reference count: 26
- Primary result: A simple encryption method that converts user input into emojis to protect privacy when interacting with cloud-based LLMs

## Executive Summary
This paper presents PromptCrypt, a simple yet effective encryption method designed to protect user privacy when interacting with cloud-based LLMs like ChatGPT. The core idea is to convert user input from natural language into sequences of emojis, emoticons, and operators, effectively masking sensitive data from both humans and the LLM itself. The proposed system employs two LLMs: one for encryption (LLMenc) and another for task-specific inference (LLMinf), ensuring that sensitive data remains obfuscated while retaining its informativeness for the LLM to process. Experiments conducted on three real-world datasets demonstrate that PromptCrypt can maintain or even improve task performance compared to unencrypted prompts.

## Method Summary
PromptCrypt uses two separate LLMs - LLMenc for encryption and LLMinf for inference. The system converts natural language text into emoji sequences that preserve semantic meaning while obscuring sensitive information. The encryption process can be either reusable (for fixed entities like product names) or non-reusable (for variable text like reviews). The encrypted prompts are then processed by LLMinf for task completion. The approach was evaluated on three datasets: Amazon Beauty for product recommendations, IMDB reviews for sentiment analysis, and Census Income for tabular data analysis.

## Key Results
- On Amazon Beauty dataset, HR@10 was 0.277 with encrypted prompts versus 0.292 with unencrypted prompts
- The encryption effectively prevents recovery of original data with cosine similarity scores significantly below optimal safety thresholds
- PromptCrypt demonstrates potential as a practical solution for enhancing data security in cloud-based LLM applications

## Why This Works (Mechanism)
PromptCrypt works by transforming natural language into emoji sequences that maintain semantic relationships while obscuring literal content. The dual-LLM architecture separates the encryption process from task inference, ensuring that sensitive data is never directly exposed to the inference LLM. By using standardized emoji representations, the system creates a symbolic vocabulary that is both human-readable and machine-processable while providing privacy protection.

## Foundational Learning
1. **LLM-based Encryption** - Using LLMs to transform text into emoji sequences
   - Why needed: To create a privacy-preserving transformation that maintains semantic meaning
   - Quick check: Verify emoji sequences retain task-relevant information through similarity metrics

2. **Dual-LLM Architecture** - Separating encryption and inference into different models
   - Why needed: To prevent exposure of sensitive data to the inference model
   - Quick check: Ensure encrypted prompts can be processed independently by the inference LLM

3. **Cosine Similarity for Privacy Assessment** - Measuring encryption effectiveness
   - Why needed: To quantify how well the original data is obscured
   - Quick check: Compare similarity scores against established safety thresholds

## Architecture Onboarding
**Component Map**: User Input -> LLMenc (Encryption) -> Emoji Sequence -> LLMinf (Inference) -> Task Output

**Critical Path**: The encryption process must successfully preserve semantic meaning while obscuring sensitive information. The inference model must be able to process emoji sequences effectively without access to the original text.

**Design Tradeoffs**: 
- Simplicity vs. security: Simple emoji transformations are easy to implement but may be vulnerable to certain attacks
- Performance vs. privacy: More complex encryption may provide better privacy but could reduce task performance
- Reusability vs. flexibility: Reusable encryption is efficient but may be less adaptable to variable content

**Failure Signatures**: 
- Poor task performance indicating loss of semantic meaning during encryption
- High cosine similarity scores suggesting inadequate privacy protection
- Inconsistent results across different LLM combinations

**3 First Experiments**:
1. Test encryption on a small sample of product names to verify emoji representation maintains searchability
2. Evaluate sentiment preservation by encrypting positive and negative reviews and comparing inference results
3. Measure cosine similarity between original and encrypted prompts to assess privacy protection

## Open Questions the Paper Calls Out
### Open Question 1
How does the performance of PromptCrypt vary with different LLM architectures for LLMenc and LLMinf, and what are the implications for practical deployment?
- Basis in paper: The paper evaluates the performance of using the same LLM (GPT-4) for both encryption and inference, as well as using different LLMs (Gemini for encryption and GPT-4 for inference), noting a decrease in performance when using different LLMs.
- Why unresolved: The paper does not explore a wide range of LLM architectures for LLMenc and LLMinf, nor does it provide a comprehensive analysis of the trade-offs between using the same vs. different LLMs for these tasks in terms of performance, security, and computational efficiency.
- What evidence would resolve it: Systematic experiments comparing the performance, security, and computational efficiency of various combinations of LLM architectures for LLMenc and LLMinf, along with an analysis of the trade-offs involved in choosing different architectures for these tasks.

### Open Question 2
What is the impact of the symbolic vocabulary size and diversity on the effectiveness of PromptCrypt's encryption and its ability to maintain task performance?
- Basis in paper: The paper mentions the limited symbolic vocabulary as a potential concern, noting that the restricted set of symbols may lead to oversimplification or omission of intricate details in the encrypted version.
- Why unresolved: The paper does not provide a detailed analysis of how the size and diversity of the symbolic vocabulary used in PromptCrypt's encryption affect the encryption's effectiveness in protecting privacy and maintaining task performance.
- What evidence would resolve it: Experiments varying the size and diversity of the symbolic vocabulary used in PromptCrypt's encryption, along with an analysis of how these variations impact the encryption's effectiveness in protecting privacy and maintaining task performance.

### Open Question 3
How does the performance of PromptCrypt compare to other privacy-preserving methods, such as homomorphic encryption and differential privacy, in terms of accuracy, privacy, and computational efficiency?
- Basis in paper: The paper discusses other privacy-preserving methods, such as homomorphic encryption and differential privacy, but does not provide a direct comparison of their performance with PromptCrypt.
- Why unresolved: The paper does not include a comprehensive comparison of PromptCrypt with other privacy-preserving methods, making it difficult to assess its relative strengths and weaknesses.
- What evidence would resolve it: A systematic comparison of PromptCrypt with other privacy-preserving methods, such as homomorphic encryption and differential privacy, in terms of accuracy, privacy, and computational efficiency, along with an analysis of the trade-offs involved in choosing different methods for privacy-preserving communication with cloud-based LLMs.

## Limitations
- Evaluation limited to three specific datasets (Amazon Beauty, IMDB reviews, and Census Income)
- Does not address potential adversarial attacks beyond cosine similarity analysis
- Additional computational overhead and latency introduced by encryption-decryption process not quantified

## Confidence
**High confidence**: Claims about PromptCrypt's ability to maintain or improve task performance on the tested datasets. The experimental methodology is clear, and results are reproducible with access to the same datasets and LLM APIs.

**Medium confidence**: Claims about encryption robustness and privacy preservation. While cosine similarity metrics support these claims, the study lacks comprehensive adversarial testing and real-world deployment scenarios.

**Low confidence**: Claims about generalizability across diverse domains and languages. The evaluation is limited to English text and specific task types (recommendation, sentiment analysis, tabular data), making broader applicability uncertain.

## Next Checks
1. **Adversarial robustness testing**: Evaluate PromptCrypt's resistance to common adversarial attacks, including prompt injection, semantic reconstruction, and brute-force decryption attempts across varying dataset sizes and complexity levels.

2. **Cross-LLM performance consistency**: Test encryption and inference across multiple LLM combinations (e.g., Claude, LLaMA, Mistral) to assess performance stability and identify potential model-specific vulnerabilities or optimization requirements.

3. **Computational overhead and latency analysis**: Measure the end-to-end processing time and computational resources required for PromptCrypt compared to unencrypted prompts, including both encryption and decryption phases, to evaluate practical deployment feasibility in real-time applications.