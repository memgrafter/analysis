---
ver: rpa2
title: 'No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations'
arxiv_id: '2407.10964'
source_url: https://arxiv.org/abs/2407.10964
tags:
- features
- fungi
- gradients
- image
- vit-b
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces FUNGI, a method that enhances the features
  of transformer encoders by leveraging self-supervised gradients. FUNGI is simple:
  given any pretrained model, it computes gradients from various self-supervised objectives
  for each input, projects these gradients to a lower dimension, and then concatenates
  them with the model''s output embedding.'
---

# No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations

## Quick Facts
- arXiv ID: 2407.10964
- Source URL: https://arxiv.org/abs/2407.10964
- Reference count: 40
- Primary result: FUNGI improves ImageNet-1K kNN accuracy from 65.3% to 70.1% using self-supervised gradients

## Executive Summary
FUNGI is a simple yet effective method that enhances frozen model representations by incorporating self-supervised gradients. The approach takes any pretrained model and computes gradients from various self-supervised objectives for each input, projects these gradients to a lower dimension, and concatenates them with the model's output embedding. This creates enriched features that consistently outperform standard embeddings across vision, NLP, and audio domains. The method demonstrates significant improvements on tasks ranging from k-nearest neighbor classification to semantic segmentation, image retrieval, and in-context scene understanding, all without requiring any additional training.

## Method Summary
FUNGI works by leveraging self-supervised gradients as a form of implicit supervision to enhance frozen representations. For each input, the method computes gradients from self-supervised objectives (such as those used in DINO, MAE, or SimCLR) with respect to the model parameters, while keeping the model frozen. These gradients are then projected to a lower dimension (128D) and concatenated with the original embedding. The resulting enriched features capture complementary information that gradients from self-supervised losses encode, providing improved performance across various downstream tasks. The method is modality-agnostic and works with any pretrained encoder, requiring only the ability to compute gradients through the frozen model.

## Key Results
- ImageNet-1K kNN accuracy improves from 65.3% to 70.1% with FUNGI
- Semantic segmentation mIoU improves by 17% on DINO without any training
- Consistent performance gains across 11 vision, 5 NLP, and 2 audio datasets
- FUNGI features improve linear classification, clustering, and image retrieval tasks

## Why This Works (Mechanism)
FUNGI works by exploiting the information encoded in self-supervised gradients that is complementary to the model's learned embeddings. When a frozen model processes an input, the gradients from self-supervised objectives capture how the model's parameters would need to change to better satisfy those objectives. These gradients contain rich information about the input's relationship to the self-supervised task, effectively encoding additional semantic and structural details that the original embedding might miss. By projecting and concatenating these gradients with the embeddings, FUNGI creates a more informative representation that captures both the model's learned features and the implicit supervision from self-supervised learning signals.

## Foundational Learning
- Self-supervised learning objectives (why needed: understanding the gradient sources; quick check: familiarity with DINO, MAE, SimCLR losses)
- Gradient computation through frozen models (why needed: core mechanism of FUNGI; quick check: ability to compute ∂L/∂θ for frozen θ)
- Feature concatenation and dimensionality reduction (why needed: combining gradient and embedding information; quick check: experience with embedding fusion techniques)
- k-nearest neighbor classification (why needed: primary evaluation metric; quick check: understanding of non-parametric evaluation methods)
- Frozen model evaluation (why needed: method assumes frozen backbones; quick check: experience with feature extraction from pretrained models)

## Architecture Onboarding

### Component Map
Input → Frozen Model → Embedding + Gradient Computation → Gradient Projection (128D) → Concatenation → FUNGI Features → Downstream Tasks

### Critical Path
The critical path is Input → Frozen Model → Gradient Computation → Gradient Projection → Concatenation. The method requires the ability to backpropagate through the frozen model to compute self-supervised gradients, project them to a fixed dimension, and concatenate with embeddings. The downstream task performance depends entirely on this enriched representation.

### Design Tradeoffs
The primary tradeoff is computational overhead from gradient computation versus performance gains. Computing gradients through a frozen model requires backpropagation, which adds processing time compared to simple feature extraction. The method also assumes the availability of self-supervised loss functions compatible with the frozen model's architecture. The fixed 128D projection may not be optimal for all modalities or dataset sizes.

### Failure Signatures
Performance degradation occurs when: (1) self-supervised objectives are poorly matched to the pretrained model's training objective, (2) gradient computation is numerically unstable, (3) the projection dimension is too small to capture gradient information, or (4) concatenation destroys the original embedding's structure for certain tasks.

### First Experiments
1. Verify gradient computation stability by checking gradient norms across different inputs and batch sizes
2. Test kNN performance improvement on a single dataset (e.g., ImageNet-1K) with a well-established backbone (e.g., DINO-ResNet50)
3. Compare FUNGI features against original embeddings on a simple downstream task (e.g., linear classification) to validate performance gains

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided content.

## Limitations
- Computational overhead from backpropagation through frozen models is not fully characterized
- Fixed 128D gradient projection may not be optimal across all modalities and dataset sizes
- Limited evaluation of models from diverse research communities beyond established architectures
- Theoretical explanation for why gradients encode complementary information lacks rigorous proof

## Confidence
- High confidence: quantitative improvements on standard benchmarks (ImageNet kNN, semantic segmentation)
- Medium confidence: generalizability across modalities (vision/NLP/audio)
- Medium confidence: improvements on downstream tasks without fine-tuning

## Next Checks
1. Characterize the computational overhead of gradient computation across different model sizes and batch configurations
2. Test FUNGI with models from different research communities (e.g., CLIP, BEiT, speech models) not mentioned in the current evaluation
3. Compare the concatenation approach with learned fusion methods to assess whether the simple concatenation is optimal or if more sophisticated integration could yield better results