---
ver: rpa2
title: 'Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses'
arxiv_id: '2408.00584'
source_url: https://arxiv.org/abs/2408.00584
tags:
- solution
- first
- words
- test
- pass
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new benchmark for evaluating large language
  models on Italian rebus puzzles, which require multi-step reasoning to decode hidden
  phrases from images and letters. The authors create a dataset of over 80,000 verbalized
  rebuses by combining rebus transcriptions with crossword definitions, then test
  state-of-the-art models including GPT-4o, Claude-3.5 Sonnet, and fine-tuned Phi-3
  Mini.
---

# Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses

## Quick Facts
- arXiv ID: 2408.00584
- Source URL: https://arxiv.org/abs/2408.00584
- Reference count: 40
- Primary result: Even best prompted models solve only 24% of Italian rebus puzzles, while fine-tuned models memorize training examples rather than generalize

## Executive Summary
This paper introduces a benchmark for evaluating large language models on Italian rebus puzzles, which require multi-step reasoning to decode hidden phrases from images and letters. The authors create a dataset of over 80,000 verbalized rebuses by combining rebus transcriptions with crossword definitions, then test state-of-the-art models including GPT-4o, Claude-3.5 Sonnet, and fine-tuned Phi-3 Mini. Results show that even the best prompted models solve only 24% of puzzles correctly, while the fine-tuned Phi-3 Mini achieves 51% accuracy. However, detailed analysis reveals that this performance gain is primarily due to memorization of training examples rather than genuine reasoning ability, as accuracy drops significantly on out-of-distribution test cases. The findings suggest that rebus solving remains a challenging test for evaluating language models' linguistic proficiency and sequential reasoning skills.

## Method Summary
The paper creates a verbalized rebus dataset by combining 223k rebuses from Eureka5 with crossword definitions from ItaCW, filtering to 83k examples for training and testing. Models are evaluated using few-shot prompting and chain-of-thought reasoning for prompted approaches, while Phi-3 Mini is fine-tuned using QLoRA on the verbalized dataset. Performance is measured across multiple metrics including definition accuracy, first pass word accuracy, and solution exact match. The study employs out-of-distribution testing to distinguish between memorization and genuine reasoning capabilities, revealing that fine-tuned models perform significantly worse on unseen word combinations.

## Key Results
- Prompted state-of-the-art models (GPT-4o, Claude-3.5 Sonnet) solve only 24% of Italian rebuses correctly
- Fine-tuned Phi-3 Mini achieves 51% accuracy but shows strong evidence of memorization rather than reasoning
- Out-of-distribution testing reveals performance drops from 96% to 20% for first pass words when unseen words are introduced
- Length constraints are crucial for rebus solving but often ignored by prompted models prioritizing grammatical correctness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning improves model performance by increasing word coverage in training data
- Mechanism: The fine-tuned Phi-3 model achieves higher accuracy because it has seen more first-pass words during training, allowing it to better predict them
- Core assumption: Model performance is directly correlated with the frequency of word occurrences in training data
- Evidence anchors:
  - [section] "We find a significant positive correlation (ùúå = 0.44) between first pass word prediction accuracy and training frequency for the fine-tuned Phi-3 model"
  - [section] "Word Complexity and Frequency Affects LLM Fine-tuning Performance"
  - [corpus] Weak - corpus contains related work on visual rebuses but no direct evidence about word frequency effects
- Break condition: If model encounters out-of-distribution words not seen during training, performance drops significantly

### Mechanism 2
- Claim: Memorization of training examples drives fine-tuned model performance
- Mechanism: The Phi-3 model's strong performance comes from memorizing specific rebus patterns rather than developing general reasoning abilities
- Core assumption: The model doesn't generalize well to unseen words or patterns
- Evidence anchors:
  - [section] "we evaluate our fine-tuned model in out-of-distribution settings... introducing OOD words should produce a significant drop in model performances"
  - [section] "Results shown in Table 3 confirm that this is indeed the case"
  - [section] "These results strongly suggest that memorization is the main factor behind the strong rebus-solving performance of our fine-tuned LLM"
- Break condition: When tested on examples containing at least one out-of-distribution word, performance drops dramatically (from 0.96 to 0.20 for first pass words)

### Mechanism 3
- Claim: Length constraints are crucial for rebus solving but often ignored by prompted models
- Mechanism: Successful rebus solving requires strict adherence to solution key length constraints, which prompted models struggle with
- Core assumption: Length constraints significantly narrow the solution space and guide correct answers
- Evidence anchors:
  - [section] "we note that D1 and D2 incorrect predictions for Claude 3.5S satisfy the provided definitions, suggesting that access to more explicit information about the given constraints could further boost LLMs' performance on this task"
  - [section] "In particular, GPT-4o appears to prioritize grammatically correct solutions at the cost of ignoring first pass words and solution key length constraints"
  - [table 2] "Fine-tuning strongly improves the constraint-following abilities of our system, with prompted systems being less strict with applying length and letter-choice constraints"
- Break condition: If models prioritize grammatical correctness or semantic plausibility over strict length matching, they may produce incorrect solutions

## Foundational Learning

- Concept: Multi-step reasoning
  - Why needed here: Rebus solving requires sequential processing - first decoding definitions, then constructing first pass, then re-segmenting according to solution key
  - Quick check question: Can you describe the three distinct reasoning stages in rebus solving?

- Concept: Out-of-distribution generalization
  - Why needed here: The paper distinguishes between in-domain and out-of-domain word performance to assess whether models truly understand or just memorize
  - Quick check question: What performance difference would you expect between ID and OOD test cases for a model that memorizes rather than generalizes?

- Concept: Constraint satisfaction in language tasks
  - Why needed here: Rebus solving imposes strict constraints (word lengths, letter usage) that must be satisfied simultaneously with semantic correctness
  - Quick check question: How might a model balance between satisfying length constraints and producing semantically plausible words?

## Architecture Onboarding

- Component map: EurekaRebus (223k rebuses) ‚Üí filtered to 83k verbalized examples ‚Üí split into training (81k) and test (2k) ‚Üí Phi-3 Mini 3.8B with QLoRA fine-tuning ‚Üí evaluation metrics (Definition Accuracy, First Pass Words/Letter Accuracy, Solution Exact Match)
- Critical path: Data preprocessing ‚Üí model fine-tuning ‚Üí few-shot prompting baseline ‚Üí comprehensive evaluation ‚Üí analysis of memorization vs generalization
- Design tradeoffs: Small model (3.8B) with fine-tuning vs larger prompted models; verbalized format vs visual rebuses; ID vs OOD evaluation
- Failure signatures: High ID performance but low OOD performance indicates memorization; poor constraint satisfaction indicates reasoning gaps
- First 3 experiments:
  1. Test Phi-3 fine-tuned model on both ID and OOD splits to confirm memorization pattern
  2. Compare constraint satisfaction (solution key matching) between prompted and fine-tuned models
  3. Correlate word frequency in training data with prediction accuracy to quantify memorization effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would performance differ with full-weight fine-tuning versus low-rank adaptation for rebus-solving LLMs?
- Basis in paper: [explicit] The paper states "Further experiments are needed to verify that memorization patterns after fine-tuning remain relevant for other model sizes, prompt formats, and training regimes, particularly for full-weight training approaches."
- Why unresolved: The paper only evaluated QLoRA (low-rank adaptation) for fine-tuning Phi-3 Mini, not comparing it to full-weight fine-tuning approaches.
- What evidence would resolve it: Comparative experiments showing performance, memorization patterns, and generalization capabilities between QLoRA and full-weight fine-tuned models on the same dataset.

### Open Question 2
- Question: What is the upper limit of performance achievable on verbalized rebuses without memorization, and how can it be measured?
- Basis in paper: [inferred] The paper demonstrates that current LLMs achieve 24% accuracy through prompting but 51% through fine-tuning that appears to rely heavily on memorization, suggesting a gap between genuine reasoning and memorization-based performance.
- Why unresolved: The paper doesn't establish a baseline for non-memorization performance or propose methods to distinguish between genuine reasoning and memorization in rebus solving.
- What evidence would resolve it: Experiments using out-of-distribution test sets, controlled training data, or ablation studies that isolate reasoning components from memorization effects.

### Open Question 3
- Question: How would multimodal models perform on visual rebuses compared to text-only verbalized versions?
- Basis in paper: [explicit] The paper states "Importantly, the task of solving visual rebuses and their more convoluted variants remains far beyond the current capabilities of vision-language models."
- Why unresolved: The paper only evaluated text-based verbalized rebuses and did not test any vision-language models on the visual versions of the same puzzles.
- What evidence would resolve it: Direct comparison of performance between text-only and multimodal models on identical rebus puzzles presented in both visual and verbalized formats.

## Limitations

- The study focuses exclusively on Italian rebuses, limiting generalizability to other languages or puzzle types
- Sample sizes for out-of-distribution testing are relatively small, potentially affecting statistical robustness
- The analysis relies heavily on the assumption that word frequency in training data directly correlates with memorization rather than legitimate generalization

## Confidence

- High Confidence: The finding that even state-of-the-art prompted models solve only 24% of Italian rebuses correctly is well-supported by comprehensive evaluation across multiple model architectures
- Medium Confidence: The conclusion that memorization drives the fine-tuned model's performance is supported by OOD testing but could benefit from additional ablation studies
- Medium Confidence: The claim that length constraints are crucial but often ignored by prompted models is supported by qualitative analysis but would benefit from more systematic metrics

## Next Checks

1. Conduct ablation studies on the fine-tuning process by varying the amount of training data and measuring the correlation between training data size and out-of-distribution performance to better isolate memorization effects

2. Implement a systematic constraint-satisfaction evaluation framework that quantifies how often models satisfy length constraints, letter usage requirements, and semantic coherence simultaneously, rather than relying on qualitative observations

3. Test the same models and methodologies on English rebuses or other puzzle types to evaluate whether the observed memorization patterns generalize across different languages and puzzle structures