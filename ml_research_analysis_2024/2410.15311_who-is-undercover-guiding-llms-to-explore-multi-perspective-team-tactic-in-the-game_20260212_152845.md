---
ver: rpa2
title: Who is Undercover? Guiding LLMs to Explore Multi-Perspective Team Tactic in
  the Game
arxiv_id: '2410.15311'
source_url: https://arxiv.org/abs/2410.15311
tags:
- game
- mptt
- team
- undercover
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Multi-Perspective Team Tactic (MPTT), a framework
  to improve Large Language Models' (LLMs) decision-making in complex scenarios by
  simulating human-like reasoning in the game "Who is Undercover?" (WIU). MPTT uses
  alternating speaking and voting sessions with techniques like self-perspective,
  identity-determination, self-reflection, self-summary, and multi-round find-teammates.
---

# Who is Undercover? Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game

## Quick Facts
- arXiv ID: 2410.15311
- Source URL: https://arxiv.org/abs/2410.15311
- Authors: Ruiqi Dong; Zhixuan Liao; Guangwei Lai; Yuhan Ma; Danni Ma; Chenyou Fan
- Reference count: 33
- One-line primary result: MPTT framework improves LLM performance in WIU game, increasing undercovers' victory rate from 0.25 to 0.60

## Executive Summary
This paper introduces Multi-Perspective Team Tactic (MPTT), a framework that enhances Large Language Models' decision-making in the social deduction game "Who is Undercover?" (WIU). MPTT simulates human-like reasoning through alternating speaking and voting sessions, incorporating techniques like self-perspective, identity-determination, self-reflection, self-summary, and multi-round find-teammates. The framework significantly improves undercovers' performance, with victory rates increasing from 0.25 to 0.60 and successfully assessing enemy team accuracy improving from 0.88 to 0.92.

## Method Summary
The MPTT framework implements alternating speaking and voting sessions where agents privately reflect on their roles using self-perspective, identity-determination, self-reflection, and self-summary techniques, then publicly speak (Word-Speak) and vote based on accumulated evidence. The method divides gameplay into two phases: private reflection and public interaction, allowing agents to iteratively refine their understanding of hidden identities while maintaining strategic coherence. The framework is implemented using ChatGPT (gpt-3.5-turbo) with 5 agents (3 civilians, 2 undercovers) playing multiple rounds with common life topics.

## Key Results
- Victory rate (VR) increased from 0.25 to 0.60 for undercovers
- Successfully assessing enemy team accuracy (PSA) improved from 0.88 to 0.92
- Human-in-the-loop experiments showed LLMs aligning with human behaviors, improving comprehension capability and voting success rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Alternating speaking and voting sessions enable iterative refinement of understanding hidden identities
- Mechanism: Each round includes private reflection, public speaking, and voting, allowing agents to progressively build trust relationships while concealing private information
- Core assumption: Agents can maintain coherent private state across rounds while producing strategically consistent public outputs
- Evidence anchors: Abstract mentions alternating sessions; section describes dividing game into speaking and voting phases

### Mechanism 2
- Claim: Multi-perspective techniques create richer internal representations for distinguishing teammates from opponents
- Mechanism: Self-perspective forces diverse descriptions even with identical words; identity-determination uses historical records; self-reflection finds common features to avoid exposure
- Core assumption: Diverse self-perspective descriptions provide meaningful differentiation between team members
- Evidence anchors: Abstract mentions cultivating human-like language expression; section describes self-perspective stage

### Mechanism 3
- Claim: Continuous self-summary and multi-round find-teammates maintain strategic narratives over time
- Mechanism: Agents create summaries after each reflection phase and reassess identities as new information accumulates
- Core assumption: Agents can maintain coherent strategic narratives across multiple rounds while adapting to new information
- Evidence anchors: Abstract mentions self-summary and multi-round find-teammates; section shows summary order calculation

## Foundational Learning

- Concept: Chain-of-Thought (CoT) reasoning
  - Why needed here: Provides foundational step-by-step reasoning framework that MPTT builds upon for complex multi-agent decision making
  - Quick check question: Can you explain how CoT helps LLMs break down complex reasoning tasks into manageable steps?

- Concept: Game theory and incomplete information games
  - Why needed here: WIU is fundamentally an incomplete information game where agents must make decisions based on partial knowledge of others' identities
  - Quick check question: How does the voting mechanism in WIU create a dynamic where undercovers must strategically conceal their identity?

- Concept: Theory of Mind and social identity
  - Why needed here: MPTT simulates human-like social reasoning by having agents understand and predict others' mental states and group affiliations
- Quick check question: Why is the ability to maintain private state while producing public outputs crucial for undercover agents in WIU?

## Architecture Onboarding

- Component map: Game Engine -> Reflection Module -> Communication Module -> Decision Module -> State Manager
- Critical path: Round initialization → Private reflection → Public speaking → Vote collection → State update → Next round
- Design tradeoffs: More sophisticated reflection techniques improve performance but increase computational cost and prompt complexity
- Failure signatures: Inconsistent voting patterns, inability to distinguish teammates from opponents, premature exposure of undercover identities
- First 3 experiments:
  1. Implement basic CoT baseline with only game rules and speaking/voting mechanics
  2. Add self-perspective and identity-determination to test impact on teammate recognition
  3. Integrate self-summary and multi-round find-teammates to evaluate strategic narrative maintenance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MPTT effectiveness change when applied to different types of social deduction games beyond WIU?
- Basis in paper: Paper mentions exploring advanced strategies and diverse scenarios as future research directions
- Why unresolved: Only tested on WIU, not on other games with different rules and dynamics
- What evidence would resolve it: Testing MPTT on various social deduction games like Werewolf or Avalon and comparing performance across games

### Open Question 2
- Question: What are the specific mechanisms by which human players influence LLM agents' decision-making in Human-in-the-loop experiments?
- Basis in paper: Paper notes human players enhance their team's CCAP and VSR but does not detail underlying mechanisms
- Why unresolved: Paper identifies impact but does not explore how human and LLM reasoning interact
- What evidence would resolve it: Analyzing specific ways human language and reasoning styles affect LLM agents' strategies during gameplay

### Open Question 3
- Question: How can MPTT be adapted to improve minority group representation and decision-making in real-world scenarios outside of games?
- Basis in paper: Paper suggests MPTT can aid minority groups in communication and expression
- Why unresolved: Demonstrates effectiveness in game setting but does not explore practical application to real-world scenarios
- What evidence would resolve it: Implementing MPTT in real-world decision-making platforms and evaluating impact on minority group representation

## Limitations

- Implementation details of MPTT techniques remain underspecified, making exact replication difficult
- Results may not generalize beyond ChatGPT (gpt-3.5-turbo) and the specific WIU game configuration tested
- Some performance metrics like "Influence" and "Comprehension Capability" lack clear measurement methodology definitions

## Confidence

- High confidence: Claims about performance improvements (VR, PSA, PST increases) supported by experimental data
- Medium confidence: Claims about mechanism effectiveness due to implementation details being underspecified
- Low confidence: Claims about generalizability to other contexts, models, or game variations

## Next Checks

1. **Implementation replication test**: Implement MPTT with the same prompts and parameters as described, then systematically vary one component (e.g., remove self-summary) to measure its individual contribution to overall performance.

2. **Cross-model validation**: Test MPTT across multiple LLM architectures (GPT-4, Claude, Llama) to verify that improvements are not model-specific and to identify which components work universally versus model-dependently.

3. **Vocabulary complexity stress test**: Evaluate MPTT performance with increasingly obscure or technical vocabulary to determine the limits of the self-perspective technique's effectiveness and identify when the approach breaks down.