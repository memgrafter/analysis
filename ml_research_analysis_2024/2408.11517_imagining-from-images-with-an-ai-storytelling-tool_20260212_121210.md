---
ver: rpa2
title: Imagining from Images with an AI Storytelling Tool
arxiv_id: '2408.11517'
source_url: https://arxiv.org/abs/2408.11517
tags:
- narrative
- story
- images
- image
- storytelling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ImageTeller, a novel AI-powered storytelling
  tool that generates narratives from single images or image sequences. The system
  leverages multimodal AI capabilities of GPT-4o for visual analysis and narrative
  generation, combined with Stable Diffusion XL for illustration creation.
---

# Imagining from Images with an AI Storytelling Tool

## Quick Facts
- arXiv ID: 2408.11517
- Source URL: https://arxiv.org/abs/2408.11517
- Reference count: 37
- Key outcome: ImageTeller generates narratives from single images or image sequences using GPT-4o for visual analysis and narrative generation, combined with Stable Diffusion XL for illustrations

## Executive Summary
ImageTeller is a novel AI-powered storytelling tool that transforms single images or image sequences into engaging narratives with accompanying illustrations. The system leverages the multimodal capabilities of GPT-4o for visual analysis and story generation, while using Stable Diffusion XL to create chapter illustrations. Users can guide the narrative through genre selection (comedy, romance, tragedy, satire, mystery) or data storytelling, and interact with the generation process through iterative refinement. The prototype demonstrates promising results in automated narrative generation while maintaining user interaction and creative control throughout the process.

## Method Summary
ImageTeller employs a multi-AI-agent architecture with three main components: a Visual Analyzer using GPT-4o Vision for image interpretation, a Storywriter using GPT-4o for narrative generation, and an Illustrator using Stable Diffusion XL for creating chapter illustrations. The system accepts images from various sources and allows users to guide the narrative through genre selection or data storytelling options. A modular prompt system (Pgeneral, Pstory, Pgenre, Pdata, Pimage) coordinates the different AI agents, while a Plot Manager orchestrates the overall generation process. User interaction is integrated throughout, enabling refinement of both narrative and visual elements through iterative feedback.

## Key Results
- Successfully generates coherent narratives from single images and image sequences
- Supports multiple genres (comedy, romance, tragedy, satire, mystery) through prompt engineering
- Enables user interaction through iterative refinement of chapters and illustrations
- Demonstrates versatility across various input types including classic literature scenes, comic strips, and data visualizations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ImageTeller generates coherent stories by chaining visual analysis → structured narrative generation → illustration creation
- Mechanism: GPT-4o Vision produces image descriptions, GPT-4o Storywriter converts them into chapter narratives using modular prompts, and Stable Diffusion XL generates chapter illustrations
- Core assumption: The modular prompt system can consistently convert visual descriptions into engaging, genre-appropriate narratives
- Evidence anchors: The proposed method explores the multimodal capabilities of GPT-4o to interpret visual content and create engaging stories, which are illustrated by a Stable Diffusion XL model

### Mechanism 2
- Claim: User guidance through genre selection and optional captions enables controlled narrative direction
- Mechanism: Genre specification modifies the Storywriter prompt to include genre-specific conventions, while captions are integrated into image analysis to influence interpretation
- Core assumption: Genre conventions can be effectively encoded as prompt modifications that consistently produce genre-appropriate narratives
- Evidence anchors: Users can guide the narrative's development according to the conventions of fundamental genres, and when a caption is provided by the user, this additional context is incorporated directly into the analysis

### Mechanism 3
- Claim: Iterative user interaction allows refinement of both narrative and visual elements throughout the generation process
- Mechanism: Users can request alternative chapters or illustrations, restart the generation process with the same input, and save stories to their personal library
- Core assumption: User feedback loops improve the quality of generated content and increase user satisfaction
- Evidence anchors: User interaction is provided along the generation process, allowing the user to request alternative chapters or illustrations, and even reject and restart the story generation based on the same input

## Foundational Learning

- Concept: Multimodal AI systems and their component models (vision, language, image generation)
  - Why needed here: Understanding how GPT-4o Vision, GPT-4o, and Stable Diffusion XL work together is crucial for maintaining and extending ImageTeller
  - Quick check question: What are the three main AI models used in ImageTeller and what specific role does each play in the narrative generation pipeline?

- Concept: Narrative genre conventions and their structural elements
  - Why needed here: The system relies on genre-specific prompt modifications to guide story generation, requiring understanding of what makes each genre distinct
  - Quick check question: How does the Tragedy genre definition influence the story generation process?

- Concept: Prompt engineering for large language models
  - Why needed here: The system uses a complex modular prompt system with specific components (Pgeneral, Pstory, Pgenre, Pdata, Pimage) that must be carefully constructed
  - Quick check question: What are the five components of the prompt system and how do they combine differently for story-driven vs data-driven narratives?

## Architecture Onboarding

- Component map: Image upload → Visual Analyzer (GPT-4o Vision) → Storywriter (GPT-4o) → Illustrator (Stable Diffusion XL) → User Interface → Story Library
- Critical path: Image upload → Visual analysis → Story generation (with optional genre selection) → Illustration generation → User interaction/iteration → Story saving
- Design tradeoffs: Modular architecture provides flexibility for future AI model updates but adds complexity; user interaction increases satisfaction but may slow down the generation process
- Failure signatures: Incomplete image descriptions lead to weak narratives; genre conflicts with visual content create incoherent stories; model API failures break the generation pipeline
- First 3 experiments:
  1. Test with simple single-image input to verify basic functionality of the three-agent pipeline
  2. Test with genre selection to ensure genre-specific conventions are properly applied
  3. Test the iterative refinement features by requesting alternative chapters and illustrations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do users with different personality traits or preferences respond to the genre-based narrative generation in ImageTeller?
- Basis in paper: The paper mentions plans to explore personality and preference modeling for adaptive storytelling in future work, citing previous research on personality modeling in interactive storytelling
- Why unresolved: The current system allows users to select genres but does not adapt the narrative generation based on individual user characteristics or preferences
- What evidence would resolve it: User studies comparing narrative preferences and engagement across different personality types when using genre-based vs. non-genre-based narrative generation

### Open Question 2
- Question: How can the consistency of character traits be maintained across multiple chapters in ImageTeller's generated narratives?
- Basis in paper: The paper identifies this as a future research direction, noting that character traits should remain consistent with textual descriptions across successive chapters
- Why unresolved: The current implementation does not explicitly track or enforce character consistency throughout the narrative, potentially leading to inconsistencies in character portrayal
- What evidence would resolve it: Comparative analysis of character consistency in narratives generated with and without explicit character tracking mechanisms across multiple chapters

### Open Question 3
- Question: What is the optimal balance between data-driven insights and creative storytelling elements in ImageTeller's data storytelling capabilities?
- Basis in paper: The paper presents experiments with data-driven narratives but acknowledges this as an area requiring further exploration to bridge the gap between traditional narrative forms and modern data communication needs
- Why unresolved: The current implementation combines data insights with storytelling elements, but the optimal balance for different types of data visualizations and audiences remains unclear
- What evidence would resolve it: User studies comparing comprehension and engagement levels across narratives with varying ratios of data insights to creative storytelling elements for different types of data visualizations

## Limitations

- Generated narratives may not maintain consistency with input images or genre conventions
- Illustrations may not accurately represent story content or maintain character consistency across chapters
- System's reliance on GPT-4o API introduces potential variability in performance and availability

## Confidence

- **High confidence**: The technical architecture using three AI agents (GPT-4o Vision, GPT-4o Storywriter, Stable Diffusion XL) is clearly specified and functional
- **Medium confidence**: The user interaction features (genre selection, iterative refinement, story saving) are implemented but their impact on user satisfaction is not measured
- **Low confidence**: The quality of generated narratives and illustrations across diverse inputs and genres is not systematically evaluated

## Next Checks

1. Conduct a user study with diverse participants to assess narrative quality, engagement, and ease of use across different genres and input types
2. Test the system's robustness with varied visual inputs (photographs, abstract art, technical diagrams) to evaluate generalization beyond the presented use cases
3. Implement automated metrics for narrative coherence and illustration consistency, then validate them through human evaluation studies