---
ver: rpa2
title: 'Transforming Scholarly Landscapes: Influence of Large Language Models on Academic
  Fields beyond Computer Science'
arxiv_id: '2409.19508'
source_url: https://arxiv.org/abs/2409.19508
tags:
- llms
- fields
- papers
- non-cs
- science
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a systematic analysis of the influence and
  usage of Large Language Models (LLMs) in academic fields beyond Computer Science.
  The authors curate a dataset of 106 well-cited LLMs and analyze ~148k papers citing
  LLMs to quantify their influence and reveal trends in their usage patterns.
---

# Transforming Scholarly Landscapes: Influence of Large Language Models on Academic Fields beyond Computer Science

## Quick Facts
- arXiv ID: 2409.19508
- Source URL: https://arxiv.org/abs/2409.19508
- Reference count: 40
- Key outcome: This paper presents a systematic analysis of the influence and usage of Large Language Models (LLMs) in academic fields beyond Computer Science.

## Executive Summary
This study systematically analyzes the influence and usage of Large Language Models (LLMs) in academic fields beyond Computer Science. The authors curate a dataset of 106 well-cited LLMs and analyze ~148k papers citing LLMs to quantify their influence and reveal trends in usage patterns. Key findings include the dominance of Linguistics, Engineering, and Medicine in LLM citations, the continued popularity of BERT and task-agnostic models like GPT-3 and LLaMA, and the predominant use of LLMs to solve domain-specific problems rather than analyzing the models themselves.

## Method Summary
The authors curate a dataset of 106 well-cited LLMs and analyze ~148k papers citing these models from the Semantic Scholar dataset. They use quantitative analysis of citation patterns and metadata to identify which non-CS fields are most impacted by LLMs, analyze how usage patterns evolve over time, and understand the contexts in which LLMs are applied. Qualitative analysis of paper content identifies tasks and applications, while keyword searches assess mentions of ethical risks.

## Key Results
- Linguistics, Engineering, and Medicine are the top three fields citing LLMs, with Linguistics and Engineering together accounting for ~45% of LLM citations.
- BERT remains the most popular LLM among non-CS fields, followed by task-agnostic models like GPT-3 and LLaMA.
- Most non-CS fields predominantly use LLMs to solve their domain-specific problems rather than focusing on analyzing the models themselves.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Citations from non-CS fields to LLM papers serve as a quantifiable proxy for the influence of NLP technologies on those fields.
- Mechanism: By aggregating citation counts and analyzing their distribution across fields, we can infer the relative adoption and impact of LLMs in diverse academic domains.
- Core assumption: Citation frequency correlates with research impact and adoption, and the Semantic Scholar field-of-study classifier is sufficiently accurate (86% reported).
- Evidence anchors:
  - [abstract]: "One notable marker of this inter-field influence is citation... we propose that the degree to which a source field cites the works of a target field can serve as a rough indicator of their mutual influence."
  - [section]: "We examine the citations in non-CS papers referencing LLM papers. If a citing paper is labeled to be in multiple fields, then it contributes to the citation count in each field."
  - [corpus]: Found related work on citation-based influence analysis (e.g., "Large Language Models Penetration in Scholarly Writing and Peer Review"), suggesting the corpus supports this mechanism, though specific citation distribution data is not directly shown.
- Break condition: Citation practices vary widely by field, and high citation counts may reflect trends other than genuine adoption (e.g., critique, comparison, or commentary rather than practical use).

### Mechanism 2
- Claim: The age of LLM citations (AoC) in a field reflects its stage of LLM adoption, with low AoC indicating recent uptake and high AoC suggesting reliance on older models.
- Mechanism: By calculating the average difference between publication years of citing papers and cited LLM papers, we can identify which fields are early adopters, which are late adopters, and which maintain a mix.
- Core assumption: The age of citations is a meaningful proxy for the recency of technology adoption and the field's comfort with newer models.
- Evidence anchors:
  - [abstract]: "The LLM citation age represents the average age of the LLMs that papers in a particular field are citing."
  - [section]: "We calculate the mean Age of LLM Citation (mAoCc) for a field c as: mAoCc = 1/MN sum_i sum_j AoC(xi, yj), ∀xi ∈ c."
  - [corpus]: Weak/no direct evidence; the corpus contains related work on LLM usage patterns but not specifically on citation age analysis.
- Break condition: Citation age may be influenced by factors unrelated to adoption (e.g., a field's citation norms, or continued reliance on established, well-understood models regardless of age).

### Mechanism 3
- Claim: Task-specific trigrams in LLM-citing papers reveal the practical applications of LLMs in non-CS fields, distinguishing use for domain problem-solving from model analysis.
- Mechanism: By extracting and filtering trigrams from titles, abstracts, and citation contexts, we can categorize the types of tasks non-CS fields address with LLMs.
- Core assumption: Task-trigrams extracted from these sources accurately represent the dominant applications of LLMs in each field.
- Evidence anchors:
  - [abstract]: "We examine LLM usage in various non-CS fields using trigrams in paper titles, abstracts, and citation contexts."
  - [section]: "By citation contexts, we precisely mean sentences that explicitly mention LLMs by name or citation... We further process them to identify trigrams indicative of tasks using regex-based heuristics."
  - [corpus]: No direct evidence; the corpus contains papers on LLM usage but not specifically on task-trigram analysis.
- Break condition: Trigram extraction may miss nuanced or multi-word tasks, and the focus on explicit LLM mentions may exclude papers that use LLMs without naming them.

## Foundational Learning

- Concept: Citation analysis and scientometrics
  - Why needed here: The paper's core methodology relies on interpreting citation patterns to measure cross-disciplinary influence; understanding this field is crucial for evaluating the validity of its claims.
  - Quick check question: What are some limitations of using citation counts as a measure of influence, and how might these affect the conclusions drawn in this paper?

- Concept: Transformer-based LLMs and their capabilities
  - Why needed here: The paper focuses on the impact of transformer-based LLMs; understanding their architecture, training, and typical use cases is essential for interpreting the results.
  - Quick check question: What distinguishes task-agnostic LLMs from fine-tuned models, and why might non-CS fields prefer the former?

- Concept: Text mining and natural language processing for scholarly data
  - Why needed here: The paper uses NLP techniques (trigram extraction, keyword filtering) to analyze the content of LLM-citing papers; understanding these methods is necessary to assess the robustness of the findings.
  - Quick check question: How might the choice of stopword removal or regex heuristics affect the accuracy of task identification via trigrams?

## Architecture Onboarding

- Component map: Data ingestion (Semantic Scholar) -> field-of-study classification -> citation counting -> trigram extraction -> keyword filtering -> manual annotation -> visualization (Sankey plots, bar charts, Gini indices)
- Critical path: Curate LLM papers -> extract citing papers -> classify by field -> count citations -> analyze trends over time -> extract task trigrams -> filter for ethical discussions -> manual annotation -> visualize and interpret
- Design tradeoffs: Broad field coverage vs. classification accuracy; automated text analysis vs. manual verification; focus on explicit LLM mentions vs. implicit usage; use of citation proxies vs. direct measures of adoption
- Failure signatures: High Gini index may indicate concentration in a few fields rather than broad adoption; low percentage of papers discussing LLM risks may reflect lack of awareness rather than absence of concerns; discrepancies between citation counts and task-trigram analysis may suggest mixed usage patterns
- First 3 experiments:
  1. Validate field-of-study classifier accuracy on a sample of LLM-citing papers from known fields.
  2. Test trigram extraction and filtering pipeline on a small set of papers to ensure relevant tasks are captured.
  3. Manually annotate a subset of papers discussing LLM risks to calibrate keyword filtering and ensure high recall and precision.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Which non-CS fields are most likely to develop and use LLMs specifically tailored to their domain needs?
- Basis in paper: [inferred] The paper notes that fields like Linguistics, Engineering, and Medicine cite LLMs most, but use task-agnostic models rather than developing field-specific ones.
- Why unresolved: The study focuses on citation patterns and usage contexts, not on whether fields are actively developing their own LLMs.
- What evidence would resolve it: A survey or dataset tracking which non-CS fields are developing or fine-tuning LLMs for domain-specific applications.

### Open Question 2
- Question: How does the diversity of LLM adoption across non-CS fields change over time, and what factors drive this evolution?
- Basis in paper: [explicit] The paper shows increasing adoption over time (2018-2023) and uses Gini index to measure diversity, but doesn't deeply analyze drivers.
- Why unresolved: The study identifies trends but doesn't explore underlying causes like technological barriers, funding, or field-specific needs.
- What evidence would resolve it: Longitudinal analysis of non-CS fields' LLM adoption, including qualitative interviews or case studies on adoption barriers and enablers.

### Open Question 3
- Question: What is the impact of LLM citation diversity on interdisciplinary collaboration and innovation in non-CS fields?
- Basis in paper: [inferred] The paper notes that fields with more CS collaborators are more likely to cite LLMs, but doesn't examine the impact on collaboration or innovation.
- Why unresolved: The study focuses on citation patterns and doesn't assess the downstream effects on research outcomes or cross-field collaboration.
- What evidence would resolve it: Analysis of collaborative research outputs, patents, or breakthroughs in non-CS fields that frequently cite LLMs versus those that don't.

## Limitations
- Potential bias in citation-based influence measures, as high citation counts may reflect critique or comparison rather than adoption.
- The analysis relies on the accuracy of the Semantic Scholar field-of-study classifier (reported at 86%).
- Task identification via trigrams may not capture nuanced or multi-word tasks, and the focus on explicit LLM mentions may miss implicit usage.

## Confidence
- Confidence in the claim that citation frequency correlates with research impact and adoption is **Low**, given the acknowledged variability in citation practices across fields and the possibility of alternative explanations for high citation counts.
- Confidence in the use of citation age as a proxy for adoption recency is **Medium**, as this is a reasonable assumption but may be influenced by factors unrelated to actual adoption.
- Confidence in the ability of task-specific trigrams to accurately reveal LLM applications in non-CS fields is **Medium**, as the method is plausible but may miss nuanced or implicit uses.

## Next Checks
1. Validate the field-of-study classifier accuracy on a sample of LLM-citing papers from known fields.
2. Test the trigram extraction and filtering pipeline on a small set of papers to ensure relevant tasks are captured.
3. Manually annotate a subset of papers discussing LLM risks to calibrate keyword filtering and ensure high recall and precision.