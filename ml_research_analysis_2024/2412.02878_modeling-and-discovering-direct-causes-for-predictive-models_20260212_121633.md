---
ver: rpa2
title: Modeling and Discovering Direct Causes for Predictive Models
arxiv_id: '2412.02878'
source_url: https://arxiv.org/abs/2412.02878
tags:
- direct
- causal
- causes
- independence
- predictive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a causal modeling framework to identify direct
  causes of predictions in predictive models treated as black boxes. The core idea
  is to represent predictive models as causal graphs (predictive graphs), where direct
  causes of an outcome correspond to the parents of the outcome node.
---

# Modeling and Discovering Direct Causes for Predictive Models

## Quick Facts
- arXiv ID: 2412.02878
- Source URL: https://arxiv.org/abs/2412.02878
- Authors: Yizuo Chen; Amit Bhatia
- Reference count: 17
- Primary result: Framework identifies direct causes of predictions as Markov boundary of outcome, with 2x speedup using I-decomposability rule

## Executive Summary
This paper introduces a causal modeling framework to identify direct causes of predictions in predictive models treated as black boxes. The core innovation is representing predictive models as causal graphs where direct causes correspond to parents of the outcome node. Under canonicity or weak faithfulness assumptions, direct causes form a unique Markov boundary, enabling discovery via Markov blanket algorithms. The paper also proposes a novel I-decomposability rule that accelerates discovery by skipping independence tests, achieving significant runtime improvements while maintaining accuracy.

## Method Summary
The framework treats predictive models as black boxes and represents them as causal graphs (predictive graphs). Under canonicity assumption, the induced distribution is a perfect map of some causal graph, making direct causes equivalent to the Markov boundary of the outcome. Under weak faithfulness, direct causes always depend on the outcome regardless of conditioning. The method uses adjacency search algorithms (M3B, HITON variants) to discover neighbors of the outcome, then applies the I-decomposability rule to skip independence tests when possible, reducing computational complexity from exponential to polynomial in some cases.

## Key Results
- Direct causes form a unique Markov boundary under canonicity and weak faithfulness assumptions
- I-decomposability rule achieves up to 2x speedup by skipping independence tests
- Framework maintains accuracy while significantly reducing runtime compared to existing algorithms
- Computational complexity reduced from O(n·exp(n)) to O(n³) in specific cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Under canonicity assumption, direct causes form a unique Markov boundary
- Mechanism: When distribution is a perfect map of some causal graph, parents of outcome variable are exactly its Markov boundary
- Core assumption: Data distribution must be canonical (P-MAP of some causal graph)
- Evidence anchors: Abstract states direct causes form unique Markov boundary under canonicity; Theorem 8 formalizes this relationship
- Break condition: Distribution not a perfect map of any causal graph, or contains cycles not representable in ADMGs

### Mechanism 2
- Claim: Weak faithfulness assumption enables both discovery and computational efficiency
- Mechanism: When direct causes always depend on outcome regardless of conditioning, direct causes equal neighbors of outcome
- Core assumption: Distribution must be weakly faithful (direct causes always depend on outcome)
- Evidence anchors: Abstract mentions weak faithfulness enables discovery; Theorem 10 formalizes equivalence
- Break condition: Direct causes can be independent of outcome under certain conditioning sets

### Mechanism 3
- Claim: I-decomposability rule skips independence tests, reducing computational complexity
- Mechanism: When a set is I-decomposable, certain independence tests can be skipped by theorem inference
- Core assumption: Distribution must be canonical for I-decomposability rule to preserve correctness
- Evidence anchors: Abstract proposes I-decomposability rule for acceleration; Proposition 15 shows complexity reduction
- Break condition: Distribution not canonical, or graph structure prevents effective I-decomposability

## Foundational Learning

- Concept: Causal graphs and ADMGs
  - Why needed here: Framework represents predictive models as causal graphs to identify direct causes as parents of outcome node
  - Quick check question: What distinguishes an ADMG from a DAG in this context?

- Concept: Markov boundaries and Markov blankets
  - Why needed here: Under both assumptions, direct causes are equivalent to Markov boundary of outcome
  - Quick check question: How does a Markov boundary differ from a Markov blanket in ADMGs?

- Concept: Independence testing and conditional independence
  - Why needed here: Discovery algorithms rely on testing conditional independences to identify neighbors and parents
  - Quick check question: What are the computational bottlenecks of independence testing mentioned in the paper?

## Architecture Onboarding

- Component map: Data → Independence tests → Markov boundary discovery → Direct causes identification
- Critical path: Independence testing → Markov blanket algorithms → Direct causes identification
- Design tradeoffs:
  - Canonicity vs Weak faithfulness: Canonicity more general but weak faithfulness more computationally efficient
  - Independence test selection: χ² vs G-tests trade accuracy for speed
  - Anytime vs complete algorithms: Bounded depth for resource constraints
- Failure signatures:
  - Algorithm returns superset of true direct causes (non-uniqueness)
  - Runtime explodes with feature count (exponential independence tests)
  - Accuracy degrades with sample size (sample inefficiency)
- First 3 experiments:
  1. Test ADJ_SEARCH vs M3B on synthetic data with known ground truth under canonicity assumption
  2. Compare I-HITON-DEC vs I-HITON on data with weak faithfulness to measure speedup
  3. Vary sample size from 1000 to 200000 instances to assess sample efficiency of I-decomposability rule

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we efficiently test whether a set V is I-decomposable in practice without relying on caching pairwise independencies?
- Basis in paper: Paper mentions procedure for checking I-decomposability but notes it requires caching pairwise independencies
- Why unresolved: Implementation details and efficiency analysis of caching mechanism not provided
- What evidence would resolve it: Detailed implementation study showing memory overhead and runtime of caching approach

### Open Question 2
- Question: Can the I-decomposability rule be extended to distributions that are not canonical but satisfy weaker conditions?
- Basis in paper: Rule preserves adjacency search behavior under canonicity, but extension to non-canonical distributions unexplored
- Why unresolved: Theoretical analysis only covers canonical case
- What evidence would resolve it: Formal proofs or counterexamples for non-canonical distributions

### Open Question 3
- Question: How does the I-decomposability rule perform in high-dimensional settings with n > 1000 features?
- Basis in paper: Demonstrates exponential speedup in specific examples but doesn't analyze very large n
- Why unresolved: Scalability analysis limited; overhead of maintaining pairwise independence cache could be prohibitive
- What evidence would resolve it: Empirical studies across wide range of n including very large values

### Open Question 4
- Question: Can methods be extended to identify indirect causes or hierarchical causal relationships?
- Basis in paper: Focuses exclusively on direct causes (parents of Y), broader causal structure unaddressed
- Why unresolved: While direct causes are useful, understanding indirect pathways requires different algorithms
- What evidence would resolve it: Development and validation of algorithms for indirect cause discovery

## Limitations
- Framework effectiveness depends critically on canonicity or weak faithfulness assumptions that may not hold in real-world models
- Empirical validation limited to synthetic data, may not generalize to complex real-world datasets
- I-decomposability rule's performance varies with graph structure and may not provide uniform benefits

## Confidence
- **High confidence**: Theoretical foundation linking direct causes to Markov boundaries under canonicity and weak faithfulness assumptions
- **Medium confidence**: Computational efficiency gains from I-decomposability rule based on empirical evidence
- **Medium confidence**: Framework's applicability to real-world predictive models, primarily validated on synthetic data

## Next Checks
1. Apply framework to high-dimensional, real-world predictive models (e.g., deep neural networks) to assess practical utility beyond synthetic datasets
2. Systematically test framework's performance when canonicity or weak faithfulness assumptions are violated, quantifying degradation in accuracy and runtime
3. Evaluate framework's performance on datasets with thousands of features to identify computational bottlenecks and scalability limits of I-decomposability optimization