---
ver: rpa2
title: 'On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness:
  Impact of Interactions and Systematic Choices'
arxiv_id: '2402.12817'
source_url: https://arxiv.org/abs/2402.12817
tags:
- randomness
- factors
- importance
- data
- effects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a method to systematically investigate the effects
  of randomness factors (e.g., varying data order) on learning with limited labeled
  data. The method explicitly addresses interactions between factors by mitigating
  the effects of non-investigated factors and measuring the relative importance of
  each factor's contribution to overall performance variance.
---

# On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices

## Quick Facts
- **arXiv ID:** 2402.12817
- **Source URL:** https://arxiv.org/abs/2402.12817
- **Reference count:** 40
- **Primary result:** Disregarding interactions between randomness factors in learning with limited labeled data causes inconsistent findings; effects of randomness factors are also dependent on systematic choices like number of classes and prompt format

## Executive Summary
This work proposes a method to systematically investigate the effects of randomness factors (e.g., varying data order) on learning with limited labeled data. The method explicitly addresses interactions between factors by mitigating the effects of non-investigated factors and measuring the relative importance of each factor's contribution to overall performance variance. Applying the method to in-context learning, fine-tuning, and meta-learning across 7 text classification tasks, the study finds that existing works' inconsistent findings stem from ignoring factor interactions, and that randomness effects depend on systematic choices beyond the randomness factors themselves.

## Method Summary
The proposed method systematically investigates the effects of randomness factors by isolating each factor's impact while mitigating interactions with other factors. For each investigated randomness factor, multiple investigation runs are performed with fixed configurations of non-investigated factors. The method calculates standard deviations across runs to measure the factor's contribution to overall performance variance, then computes importance scores by comparing this contributed deviation to the total variance captured by a golden model. This approach allows ranking randomness factors by their impact on model stability while accounting for non-additive interactions between factors.

## Key Results
- Disregarding interactions between randomness factors in existing works caused inconsistent findings due to incorrect attribution of effects
- The proposed method reveals that sample order sensitivity varies significantly with systematic choices like number of samples per class and prompt format
- Besides mutual interactions, randomness factor effects are dependent on more systematic choices unexplored in existing works

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Randomness factors interact in non-additive ways, causing misleading attributions when factors are studied in isolation.
- **Mechanism:** When multiple randomness factors are varied simultaneously, their combined effect on model performance is not the sum of their individual effects. This interaction means that attributing performance variance to a single factor without accounting for others leads to incorrect conclusions about which factors are truly important.
- **Core assumption:** Interactions between randomness factors exist and are significant enough to affect performance attribution.
- **Evidence anchors:**
  - [abstract] "disregarding interactions between randomness factors in existing works caused inconsistent findings due to incorrect attribution of the effects of randomness factors"
  - [section 1] "we argue that such observed inconsistencies are caused by disregarding the interactions between randomness factors"
  - [corpus] Weak evidence - corpus contains general sensitivity analysis papers but not specific to NLP learning with limited data
- **Break condition:** If randomness factors operate independently with no interaction effects, the method's complexity would be unnecessary and simpler approaches would suffice.

### Mechanism 2
- **Claim:** The proposed method isolates individual randomness factor effects by systematically mitigating interactions through repeated investigation runs.
- **Mechanism:** By running multiple investigation runs with different fixed configurations of non-investigated factors, the method averages out the interaction effects. This allows measurement of the true contribution of the investigated factor to overall performance variance.
- **Core assumption:** Multiple mitigation runs with varied configurations can sufficiently cover the state space of non-investigated factors to average out their interactions.
- **Evidence anchors:**
  - [abstract] "our method mitigates the effects of other factors and observes how the performance varies across multiple runs"
  - [section 3] "the investigation run is repeated multiple (M) times with different fixed configurations of the non-investigated randomness factors"
  - [corpus] Moderate evidence - corpus includes papers on sensitivity analysis and variance reduction, supporting the general approach
- **Break condition:** If the state space of non-investigated factors is too large or complex to be adequately covered by the chosen number of mitigation runs, residual interactions may bias the results.

### Mechanism 3
- **Claim:** Importance scores provide a relative measure of randomness factor impact by comparing contributed deviation to overall model variance.
- **Mechanism:** The importance score calculates what fraction of the golden model's standard deviation (representing total performance variance) is contributed by the investigated factor over all non-investigated factors. This relative measure allows ranking factors by their impact on stability.
- **Core assumption:** Golden model standard deviation accurately represents the total performance variance that should be attributed to all randomness factors.
- **Evidence anchors:**
  - [abstract] "measures the relative importance of the effects of randomness factors by calculating what fraction of the overall deviation in the model's performance (estimated by a golden model) the investigated factor contributes"
  - [section 3] "The importance score of the factor is defined as the portion of the golden model standard deviation the investigated factors contribute over the non-investigated ones"
  - [corpus] Weak evidence - corpus lacks specific papers on importance scoring in the context of learning with limited labeled data
- **Break condition:** If the golden model doesn't accurately capture all sources of variance (e.g., missing systematic choices), importance scores may be misleading.

## Foundational Learning

- **Concept: Statistical significance and standard deviation**
  - Why needed here: The method relies on calculating standard deviations across multiple runs to quantify the effects of randomness factors and their importance.
  - Quick check question: If you run an experiment 10 times and get F1 scores of [0.78, 0.79, 0.77, 0.78, 0.79, 0.78, 0.77, 0.78, 0.79, 0.78], what is the standard deviation of these results?

- **Concept: Experimental design with controlled variables**
  - Why needed here: The method requires systematically varying one factor while controlling others, similar to scientific experiments with independent and dependent variables.
  - Quick check question: In a study testing how sample order affects model performance, what should remain constant across all runs to properly isolate the effect of sample order?

- **Concept: Cross-validation and data splitting strategies**
  - Why needed here: Data Split is one of the randomness factors investigated, and understanding how different splits affect model performance is crucial for interpreting results.
  - Quick check question: If you have 1000 training samples and use an 80-20 split, how many samples go to training and how many to validation in each fold of 5-fold cross-validation?

## Architecture Onboarding

- **Component map:**
  - Randomness Factor Investigation Engine -> Mitigation Run Manager -> Performance Analyzer -> Golden Model Generator -> Configuration Space Explorer

- **Critical path:**
  1. Select randomness factor to investigate
  2. Generate configurations for investigated and non-investigated factors
  3. Execute investigation runs with fixed non-investigated configurations
  4. Calculate partial standard deviations and means
  5. Aggregate results across mitigation runs
  6. Compare contributed deviation to mitigated and golden model deviations
  7. Calculate and report importance score

- **Design tradeoffs:**
  - Number of investigation runs (N) vs. precision: More runs provide better coverage but increase computation cost
  - Number of mitigation runs (M) vs. interaction mitigation: More mitigation runs better average out interactions but increase computation cost
  - Sample size for evaluation vs. reliability: More test samples provide more reliable performance estimates but increase computation cost

- **Failure signatures:**
  - Importance scores consistently near zero for all factors: May indicate insufficient investigation runs or that factors have negligible impact
  - Large variance in importance scores across repeated experiments: Suggests inadequate mitigation of interactions or unstable experimental conditions
  - Contributed standard deviation larger than golden model standard deviation: Indicates potential calculation error or that investigated factor dominates all others

- **First 3 experiments:**
  1. Investigate Data Order on SST2 dataset with Flan-T5 using N=10, M=20 to verify the method works and produces expected results
  2. Investigate Sample Choice on SST2 dataset with Flan-T5 to compare with existing literature findings
  3. Investigate Model Initialization on SST2 dataset with BERT to validate the method on fine-tuning approaches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed investigation method's mitigation strategy compare to using more sophisticated sample selection strategies for randomness factors?
- Basis in paper: The paper mentions that using a sample selection strategy could replace the repeated training runs for mitigating effects of other factors, but does not explore this comparison.
- Why unresolved: The paper uses repeated training runs for mitigation, but does not investigate whether more sophisticated sample selection strategies could provide more effective or efficient mitigation.
- What evidence would resolve it: A direct comparison of the proposed method's mitigation approach versus using advanced sample selection strategies for the same randomness factors, measuring both effectiveness in mitigating interactions and computational efficiency.

### Open Question 2
- Question: How do the effects of randomness factors change when using larger models (e.g., GPT-4, PaLM) compared to the smaller models investigated in this study?
- Basis in paper: The paper explicitly acknowledges that the effects may not be as representative for larger models and that larger models were observed to be more susceptible to randomness effects in related work.
- Why unresolved: The study focused on smaller models due to computational constraints, but the actual impact on larger models remains unknown.
- What evidence would resolve it: Replicating the investigation using the same method on larger language models while measuring both the contributed standard deviation and importance scores for each randomness factor.

### Open Question 3
- Question: What is the relationship between the number of mitigation runs needed and the complexity/computation cost of the specific randomness factor being investigated?
- Basis in paper: The paper discusses the trade-off between computation costs and reliability but does not explore how this varies by randomness factor type.
- Why unresolved: The study used fixed numbers of investigation and mitigation runs across all factors, without examining whether different factors require different numbers of runs for reliable estimation.
- What evidence would resolve it: A systematic study varying the number of mitigation runs for each randomness factor type, measuring how the reliability of contributed standard deviation estimates changes with different run counts.

## Limitations
- The method's mitigation strategy requires many repeated training runs, making it computationally expensive for large models
- The choice of N=10 investigation runs and M=20-100 mitigation runs appears arbitrary without theoretical justification
- The importance score interpretation depends on the golden model accurately capturing all variance sources, including systematic choices not explicitly investigated

## Confidence
- **Medium:** The method's theoretical foundation for isolating randomness factor effects is sound, but the assumption that M mitigation runs sufficiently cover the state space of non-investigated factors remains unverified for complex interactions
- **Medium:** While the importance score calculation provides a systematic way to rank randomness factors, the interpretation depends heavily on the golden model accurately representing total variance
- **Low:** The claim that disregarding interactions caused inconsistent findings in existing works is based on re-analysis of previously published results without access to original experimental setups

## Next Checks
1. **Coverage analysis:** Systematically vary M (number of mitigation runs) and measure how stability of importance scores changes to validate whether chosen M values provide sufficient coverage of non-investigated factor state space
2. **Interaction strength quantification:** Design controlled experiments with artificially introduced known interaction effects between randomness factors to measure the method's ability to detect and correctly attribute these interactions
3. **Golden model variance decomposition:** Perform ablation studies on the golden model by systematically including/excluding systematic choices to quantify how much variance they contribute and whether this affects importance score interpretations