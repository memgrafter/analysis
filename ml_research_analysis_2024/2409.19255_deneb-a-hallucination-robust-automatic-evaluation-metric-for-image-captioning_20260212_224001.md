---
ver: rpa2
title: 'DENEB: A Hallucination-Robust Automatic Evaluation Metric for Image Captioning'
arxiv_id: '2409.19255'
source_url: https://arxiv.org/abs/2409.19255
tags:
- image
- metrics
- deneb
- metric
- captions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Deneb, a supervised automatic evaluation metric
  specifically robust against hallucinations in image captioning. Deneb incorporates
  the Sim-Vec Transformer to process multiple reference captions simultaneously, capturing
  the similarity between an image, a candidate caption, and reference captions.
---

# DENEB: A Hallucination-Robust Automatic Evaluation Metric for Image Captioning

## Quick Facts
- arXiv ID: 2409.19255
- Source URL: https://arxiv.org/abs/2409.19255
- Authors: Kazuki Matsuda; Yuiga Wada; Komei Sugiura
- Reference count: 40
- Primary result: Deneb achieves 95.4% and 96.5% accuracy on FOIL benchmark in single-reference and four-reference settings

## Executive Summary
This paper introduces DENEB, a supervised automatic evaluation metric designed specifically to be robust against hallucinations in image captioning. Hallucinations occur when generated captions contain words or concepts not depicted in the input image. DENEB employs a Sim-Vec Transformer architecture that processes multiple reference captions simultaneously, capturing the similarity between an image, a candidate caption, and reference captions. The authors construct the Nebula dataset comprising 32,978 images with human judgments to train the model.

## Method Summary
DENEB processes an image, candidate caption, and multiple reference captions through CLIP and RoBERTa encoders to extract features. A Sim-Vec Extraction (SVE) module uses Hadamard products and element-wise differences to capture similarity features. These features are then processed by an N-layer transformer encoder (N=3) to handle multiple references simultaneously. The model is trained with Huber loss on the Nebula dataset and evaluated on multiple benchmarks including FOIL, Composite, and PASCAL-50S.

## Key Results
- Deneb achieves 95.4% accuracy on FOIL in single-reference setting, outperforming existing LLM-free metrics by 1.7 points
- Deneb achieves 96.5% accuracy on FOIL in four-reference setting, outperforming existing LLM-free metrics by 1.4 points
- Deneb demonstrates state-of-the-art performance across multiple hallucination detection benchmarks

## Why This Works (Mechanism)

### Mechanism 1
The Sim-Vec Transformer effectively captures similarity between image, candidate, and multiple references by processing them simultaneously using transformer architecture instead of aggregating independent scores. This approach assumes transformer-based processing can better capture vector-form similarities than simple MLP aggregation. Evidence shows the transformer architecture is explicitly designed for this purpose in section 3.2, though direct corpus evidence for its superiority in this specific task is weak.

### Mechanism 2
The Sim-Vec Extraction (SVE) module enhances feature extraction for evaluation by using Hadamard product and element-wise differences to extract features capturing similarity between image and text embeddings. The core assumption is that element-wise operations on embeddings can better capture nuanced similarity relationships than simple concatenation. The approach is designed to allow the model to focus more on vector-form similarity, though direct corpus evidence for effectiveness is weak.

### Mechanism 3
Construction of the diverse Nebula dataset enables effective training for hallucination-robust metrics by extending the Polaris dataset with three times more images to address imbalance issues and improve visual diversity. The core assumption is that a more diverse and balanced dataset leads to better generalization and robustness against hallucinations. While the dataset construction is explicitly described in section 4.1, direct corpus evidence for dataset diversity's impact on hallucination robustness is weak.

## Foundational Learning

- **Concept: Transformer architectures for sequence processing**
  - Why needed here: To handle multiple reference captions simultaneously and capture complex relationships between image, candidate, and references
  - Quick check question: How does a transformer encoder differ from a simple RNN in handling multiple input sequences?

- **Concept: Vision-language pretraining and embedding spaces**
  - Why needed here: To extract meaningful features from both images and text that can be compared for evaluation
  - Quick check question: What are the key differences between CLIP's image encoder and RoBERTa's text encoder in terms of architecture and training objectives?

- **Concept: Supervised metric learning and loss functions**
  - Why needed here: To train the metric to align with human judgments using the Nebula dataset
  - Quick check question: Why might the Huber loss be preferred over standard L2 loss for training metrics that need to handle outliers in human judgments?

## Architecture Onboarding

- **Component map**: Image, candidate caption, multiple reference captions -> CLIP and RoBERTa encoders -> Sim-Vec Extraction (SVE) -> Sim-Vec Transformer (N=3 layers) -> MLP -> Evaluation score
- **Critical path**: Feature extraction → Sim-Vec Extraction → Sim-Vec Transformer → MLP → Score
- **Design tradeoffs**: Using frozen CLIP and RoBERTa vs. fine-tuning for task-specific features; choosing transformer depth (N=3) for balancing performance and efficiency; using Huber loss vs. other loss functions for robustness to outliers
- **Failure signatures**: Low accuracy on FOIL benchmark indicates poor hallucination detection; poor Kendall's tau correlation indicates misalignment with human judgments; high inference time may indicate inefficiency in transformer layers
- **First 3 experiments**: 1) Ablation study removing Sim-Vec Transformer to confirm its contribution; 2) Test with different transformer depths (N=1, 2, 3, 4) to find optimal balance; 3) Evaluate on a small subset of Nebula with manual inspection of failure cases

## Open Questions the Paper Calls Out
The paper identifies that Deneb's main limitation is its inability to capture the relationship between candidate captions and local regions of the image. The authors suggest extending Deneb with a mechanism to extract this relationship, though they do not implement or evaluate such an extension.

## Limitations
- The metric relies on the newly constructed Nebula dataset, which may introduce dataset-specific biases that could limit generalizability to other captioning domains or languages
- Evaluation primarily focuses on hallucination detection rather than broader aspects of caption quality like grammar, fluency, or relevance beyond hallucination
- Use of frozen CLIP and RoBERTa encoders may limit the model's ability to adapt to task-specific nuances compared to fine-tuned alternatives

## Confidence
- **High Confidence**: The FOIL benchmark results (95.4% and 96.5% accuracy) are well-established metrics in the hallucination detection literature, and performance gains over existing LLM-free metrics are statistically significant
- **Medium Confidence**: The claim of "state-of-the-art" performance across all evaluated datasets assumes fair comparison conditions, but differences in dataset preprocessing and evaluation protocols may affect direct comparability
- **Low Confidence**: The long-term robustness of the metric against emerging types of hallucinations or in domains outside the training distribution (e.g., medical imaging) remains untested

## Next Checks
1. **Cross-domain validation**: Evaluate Deneb on image captioning datasets from different domains (medical, technical, or multilingual) to assess generalization beyond the training distribution
2. **Temporal stability test**: Re-evaluate Deneb's performance on the same benchmarks after 6-12 months using updated versions of CLIP/RoBERTa or newer vision-language models to assess sensitivity to underlying embedding changes
3. **Human-in-the-loop verification**: Conduct a small-scale user study where human annotators compare Deneb's scores against their own judgments on edge cases, particularly focusing on borderline hallucinations that may be context-dependent