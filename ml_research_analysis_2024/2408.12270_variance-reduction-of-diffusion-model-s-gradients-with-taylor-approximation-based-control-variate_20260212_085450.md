---
ver: rpa2
title: Variance reduction of diffusion model's gradients with Taylor approximation-based
  control variate
arxiv_id: '2408.12270'
source_url: https://arxiv.org/abs/2408.12270
tags:
- control
- variate
- variance
- gradients
- reduction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the high variance in denoising score matching
  objectives for training score-based generative models, which hinders optimization.
  The authors propose using a control variate derived from a k-th order Taylor expansion
  of the training objective and its gradient to reduce this variance.
---

# Variance reduction of diffusion model's gradients with Taylor approximation-based control variate

## Quick Facts
- arXiv ID: 2408.12270
- Source URL: https://arxiv.org/abs/2408.12270
- Reference count: 40
- Key outcome: Taylor expansion-based control variates reduce variance in denoising score matching, but effectiveness diminishes with network complexity and doesn't improve training loss on MNIST with U-Net.

## Executive Summary
This paper addresses high variance in denoising score matching objectives for training score-based generative models. The authors propose using control variates derived from k-th order Taylor expansions of the training objective and its gradients to reduce this variance. They prove an equivalence between controlling the objective and its gradient, and demonstrate empirically that the regression coefficient is crucial for variance reduction. While effective on low-dimensional toy problems, the approach shows only marginal variance reduction on MNIST with U-Net architectures, suggesting limitations for complex diffusion models.

## Method Summary
The method uses control variates based on k-th order Taylor expansions of the score network to reduce variance in denoising score matching. The control variate C_k is constructed by approximating the score function s(x) around a point a using Taylor series. A regression coefficient β is computed to optimally scale the control variate, minimizing the variance of the adjusted estimator. The approach can target either the training objective or directly the gradients, with the latter shown to be more effective due to the regression coefficient's impact on gradient variance.

## Key Results
- On 2D toy datasets, variance reduction enabled convergence in small batch size regimes with higher-order expansions (k=1,2) outperforming k=0
- For MNIST with U-Net (2M parameters), variance reduction was marginal (1.4x for k=2) and did not improve training loss
- MLPs of varying width and depth showed decreased variance reduction effectiveness as network complexity increased, suggesting Taylor approximation quality degrades with irregular architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Control variate reduces variance by exploiting correlation between the original Monte Carlo estimator and an auxiliary problem.
- Mechanism: The control variate C(z) is chosen to correlate with the original function L(z), and the optimal regression coefficient βopt = Cov(L(z), C(z)) / Var(C(z)) maximizes variance reduction.
- Core assumption: The auxiliary problem C(z) must be chosen such that it correlates with L(z), and the regression coefficient β must be set optimally.
- Evidence anchors:
  - [abstract] "Control variate reduces the variance by leveraging an auxiliary Monte Carlo integration problem that correlates with the original one."
  - [section] "Control variate (Owen, 2013) is a technique to reduce the variance of an estimator..."
  - [corpus] Weak correlation - no direct citations on control variate variance reduction in diffusion models found.
- Break condition: If the control variate is poorly chosen or the regression coefficient is not set optimally, variance reduction may not occur or may even increase variance.

### Mechanism 2
- Claim: Taylor expansion of the score network provides a polynomial approximation that serves as a control variate.
- Mechanism: The k-th order Taylor expansion T_k s, a(x) approximates the score function s(x) around a point a, and this approximation is used to construct the control variate.
- Core assumption: The Taylor expansion provides a good approximation of the score function, especially for small perturbations.
- Evidence anchors:
  - [abstract] "We propose to use a popular variance reduction method, control variate (Owen, 2013), to address this high variance. Control variate for score-based model has been originally introduced by Wang et al. (2020) through a linearisation of the training objective for small noise level. We propose to generalise their method to k-th order Taylor approximation..."
  - [section] "We extend that approach by finding a suitable polynomial approximation of L. Various polynomial approximations exist (Cody, 1970), but one that makes sense when using automatic differentiation mechanism is the Taylor series (Duistermaat & Kolk, 2010)."
  - [corpus] Weak correlation - no direct citations on Taylor expansion in diffusion model variance reduction found.
- Break condition: For complex networks like U-Nets, the Taylor approximation may be poor, limiting the effectiveness of the control variate.

### Mechanism 3
- Claim: Controlling the gradients directly is more effective than controlling the training objective due to the regression coefficient issue.
- Mechanism: The control variate on the gradients C_g,θ is derived from the Taylor expansion of the score network and its gradient, and this is applied directly to the gradient computation.
- Core assumption: The gradients are more sensitive to variance than the training objective itself, and controlling them directly yields better results.
- Evidence anchors:
  - [abstract] "We prove an equivalence between the two and demonstrate empirically the effectiveness of our approach..."
  - [section] "However, the regression coefficient of the objective's control variate is unrelated to that of the gradients. Since this coefficient is decisive for the quality of the control variate, we cannot expect to control the variance of the gradient through the objective alone."
  - [corpus] Weak correlation - no direct citations on gradient variance control in diffusion models found.
- Break condition: Computing the optimal regression coefficient for gradients is memory-intensive and may not be feasible for large models.

## Foundational Learning

- Concept: Denoising Score Matching
  - Why needed here: The paper builds on denoising score matching as the training objective for score-based models, which suffers from high variance.
  - Quick check question: What is the relationship between denoising score matching and the training objective L_θ(z, x, σ)?

- Concept: Control Variate
  - Why needed here: Control variate is the variance reduction technique used to address the high variance in denoising score matching.
  - Quick check question: How does the regression coefficient β affect the variance reduction in control variate?

- Concept: Taylor Series
  - Why needed here: Taylor series is used to approximate the score network and construct the control variate.
  - Quick check question: What is the impact of the order k of the Taylor expansion on the quality of the control variate?

## Architecture Onboarding

- Component map: Score network s_θ -> Training objective L_θ -> Control variate C_k -> Regression coefficient β -> Optimizer

- Critical path:
  1. Compute the training objective L_θ(z, x, σ)
  2. Compute the control variate C_k(z, x, σ) using Taylor expansion
  3. Compute the optimal regression coefficient β
  4. Update the score network parameters using the control variate-adjusted gradient

- Design tradeoffs:
  - Higher-order Taylor expansions (k > 0) provide better variance reduction but are more computationally expensive
  - Controlling gradients directly is more effective but requires computing the optimal regression coefficient for gradients, which is memory-intensive
  - The effectiveness of the control variate decreases with network complexity, limiting its use for large models like U-Nets

- Failure signatures:
  - Variance reduction is marginal or negative when using high-order Taylor expansions for complex networks
  - The training loss does not improve despite variance reduction, indicating that variance may not be the primary bottleneck
  - Memory issues when computing the optimal regression coefficient for gradients in large models

- First 3 experiments:
  1. Implement the control variate on a simple 2D toy dataset with an MLP to verify variance reduction and convergence
  2. Test the control variate on MNIST with a U-Net to evaluate its effectiveness on a more complex dataset and model
  3. Study the impact of network complexity (width and depth) on the effectiveness of the control variate by training MLPs with varying architectures

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but the results raise several important unresolved issues:

### Open Question 1
- Question: How does the effectiveness of Taylor-based control variates scale with network depth and width in practical diffusion models?
- Basis in paper: [explicit] The paper experimentally demonstrates that variance reduction decreases as MLP complexity (depth and width) increases, hypothesizing this is due to the Taylor approximation becoming poorer for irregular networks.
- Why unresolved: The experiments only tested MLPs of limited size. Real diffusion models use very deep, wide networks (e.g., U-Nets) where this relationship might differ or have different implications.
- What evidence would resolve it: Systematic experiments varying depth and width on a range of network architectures (including U-Nets) while measuring variance reduction and training performance.

### Open Question 2
- Question: Does variance reduction through control variates provide tangible benefits for training stability or sample quality in high-dimensional diffusion models?
- Basis in paper: [explicit] On MNIST with a U-Net, variance reduction was marginal and did not improve training loss, raising the question of whether the inherent variance in diffusion models is actually harmful or potentially beneficial.
- Why unresolved: The experiments only tested one dataset (MNIST) and one model type (U-Net). The role of variance in training dynamics and its impact on final model quality remains unclear.
- What evidence would resolve it: Comparative training experiments on multiple datasets and architectures measuring not just training loss but also sample quality metrics (FID, Inception Score) and training stability indicators.

### Open Question 3
- Question: What is the optimal order k of Taylor expansion for variance reduction across different network architectures and noise levels?
- Basis in paper: [inferred] The paper shows k=1 provides better variance reduction than k=0 on toy problems, with marginal improvement from k=1 to k=2, but doesn't systematically explore this relationship across architectures or analyze the theoretical properties.
- Why unresolved: The relationship between Taylor expansion order and effectiveness across different network types, architectures, and noise regimes is not characterized. The computational cost of higher-order expansions also needs consideration.
- What evidence would resolve it: Systematic experiments varying k across multiple architectures and noise levels, coupled with theoretical analysis of approximation quality and computational complexity trade-offs.

## Limitations

- The effectiveness of variance reduction is strongly dependent on Taylor approximation quality, which degrades for complex networks like U-Nets
- Even when variance is reduced, this doesn't necessarily translate to improved training loss or sample quality
- Computing optimal regression coefficients for gradient control is memory-intensive and may not scale to large models

## Confidence

- Theoretical foundations: High confidence - clear proofs showing equivalence between controlling objective and gradients
- Toy experiments: Medium confidence - convincing variance reduction and convergence results
- MNIST U-Net results: Low confidence - marginal variance reduction with no improvement in training loss

## Next Checks

1. **Gradient correlation analysis**: Systematically measure the correlation between L_θ and C_k for different network architectures to quantify how Taylor approximation quality degrades with model complexity. This would validate the hypothesis about why variance reduction fails for larger models.

2. **Sample quality evaluation**: Beyond training loss, evaluate the impact of variance reduction on sample quality metrics (FID, Inception Score) on MNIST and CIFAR-10 to determine if any benefits manifest in generation quality rather than just optimization metrics.

3. **Alternative control variates**: Test whether other polynomial approximations beyond Taylor series (Chebyshev, Legendre) provide better control variates for complex networks, or whether different auxiliary problems might correlate better with the diffusion model objective.