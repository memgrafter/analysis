---
ver: rpa2
title: 'HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance'
arxiv_id: '2401.08772'
source_url: https://arxiv.org/abs/2401.08772
tags:
- group
- chat
- assistant
- questions
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents HuixiangDou, a large language model-based
  technical assistant designed to help algorithm developers with questions about open-source
  projects in group chat scenarios. The system uses a three-stage approach: first,
  it filters out non-technical content using text2vec models; then it retrieves relevant
  documents from domain-specific sources; and finally, it generates responses using
  LLM with long context capabilities.'
---

# HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance

## Quick Facts
- arXiv ID: 2401.08772
- Source URL: https://arxiv.org/abs/2401.08772
- Authors: Huanjun Kong; Songyang Zhang; Jiaying Li; Min Xiao; Jun Xu; Kai Chen
- Reference count: 3
- Primary result: HuixiangDou achieves 0.99 precision and 0.92 recall in filtering non-technical content while providing LLM-based technical assistance in group chats

## Executive Summary
This paper presents HuixiangDou, a large language model-based technical assistant designed to help algorithm developers with questions about open-source projects in group chat scenarios. The system addresses the challenges of hallucination and message flooding in group chats by implementing a three-stage approach: filtering out non-technical content using text2vec models, retrieving relevant documents from domain-specific sources, and generating responses using LLM with long context capabilities. The authors verify that text2vec models are reliable for task rejection and identify three critical requirements for LLMs in technical assistant products: scoring ability, In-Context Learning, and long context support.

## Method Summary
HuixiangDou implements a three-stage pipeline to provide technical assistance in group chat scenarios. First, a text2vec-based rejection pipeline filters out non-technical content using semantic similarity to the knowledge base, achieving 0.99 precision and 0.92 recall. Second, the system retrieves relevant documents through a hybrid search approach combining web search and repository-specific search (Score Board). Third, an LLM with long context capabilities (optimized with ReRoPE and Triton) generates responses after scoring retrieved documents for relevance. The system was trained on 28,000 QA pairs from cleaned group chat data and OpenMMLab project documents, with a fine-tuned 7B/13B base LLM using XTuner's qLoRA method.

## Key Results
- Text2vec models achieve 0.99 precision and 0.92 recall in filtering non-technical content
- The system successfully addresses hallucination and message flooding challenges in group chat technical assistance
- Three critical LLM requirements identified: scoring ability, In-Context Learning, and long context support
- Context length up to 40k tokens provides relatively good results for complex technical queries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Text2vec models reliably filter out non-technical content in group chats.
- Mechanism: Text2vec models use semantic similarity to determine if messages relate to domain-specific knowledge, enabling effective task rejection.
- Core assumption: Text2vec models can accurately distinguish between technical and non-technical content based on semantic similarity to the knowledge base.
- Evidence anchors:
  - [abstract] "We verify that text2vec models are reliable for task rejection, achieving 0.99 precision and 0.92 recall."
  - [section] "We manually annotated hundreds of user contents... We then used different text2vec models to construct a database and test the accuracy of refusal to answer."
  - [corpus] Weak evidence - related papers focus on LLM applications but don't specifically validate text2vec for task rejection in group chats.
- Break condition: Text2vec models fail when non-technical content uses terminology similar to the domain knowledge base, or when technical content uses domain-specific terms in non-technical contexts.

### Mechanism 2
- Claim: LLM scoring improves retrieval relevance by filtering search results.
- Mechanism: LLMs evaluate the relevance between queries and retrieved documents/snippets, removing irrelevant results before response generation.
- Core assumption: LLMs can accurately judge the semantic relevance between a query and potential response candidates better than text2vec alone.
- Evidence anchors:
  - [abstract] "They also identify three critical requirements for LLMs in technical assistant products: scoring ability, In-Context Learning, and long context support."
  - [section] "We also employ LLM scoring to judge the relevance between the query and the document."
  - [corpus] Weak evidence - no direct corpus evidence for LLM scoring in retrieval pipelines, though related work on RAG exists.
- Break condition: LLM scoring becomes unreliable when queries are ambiguous, when documents are too short to provide meaningful context, or when the scoring prompt is poorly constructed.

### Mechanism 3
- Claim: Long context support enables processing of extended technical documentation.
- Mechanism: Extended context windows allow LLMs to process multiple document snippets and search results simultaneously, improving response accuracy.
- Core assumption: Technical questions require sufficient context from multiple sources to generate accurate responses.
- Evidence anchors:
  - [abstract] "They also identify three critical requirements for LLMs in technical assistant products: ... Long Context."
  - [section] "Considering the prohibitive training cost of YaRN Peng et al. (2023), we optimized ReRoPE's inference performance using Triton Contributors (2019), also introducing dynamic quantization."
  - [corpus] Weak evidence - related papers mention long context but don't specifically address technical documentation processing.
- Break condition: Long context support fails when the combined token count of all relevant documents exceeds even the extended context window, or when processing efficiency degrades with very long contexts.

## Foundational Learning

- Concept: Semantic similarity and text embeddings
  - Why needed here: Text2vec models rely on embedding similarity to determine if content is relevant to the technical domain.
  - Quick check question: How does text2vec measure similarity between a user message and the knowledge base?

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: The system uses RAG to find relevant documents before generating responses, reducing hallucination.
  - Quick check question: What are the two main components of a RAG pipeline and how do they interact?

- Concept: In-Context Learning (ICL)
  - Why needed here: LLMs use ICL to process retrieved documents without fine-tuning, enabling adaptation to new information.
  - Quick check question: How does In-Context Learning differ from traditional fine-tuning in terms of knowledge integration?

## Architecture Onboarding

- Component map:
  Input Layer -> Preprocessor -> Reject Pipeline -> Keyword Extraction -> Document Retrieval -> LLM Scoring -> Response Generation -> Security Check -> Output Layer

- Critical path: Message → Preprocessor → Reject Pipeline → Keyword Extraction → Document Retrieval → LLM Scoring → Response Generation → Security Check → Output

- Design tradeoffs:
  - Precision vs Recall in task rejection (high precision prevents flooding but may miss technical questions)
  - Context length vs Processing speed (longer contexts improve accuracy but increase computational cost)
  - Single model vs Hybrid service (single model simplifies architecture but hybrid service offers better capability coverage)

- Failure signatures:
  - High reject rate with few responses: Text2vec model too strict or knowledge base too narrow
  - Incorrect technical answers: Retrieval quality poor or LLM scoring unreliable
  - System crashes: Context length exceeded or memory allocation insufficient

- First 3 experiments:
  1. Test reject pipeline with annotated dataset to measure precision/recall and adjust thresholds
  2. Compare different text2vec models and text splitting methods on sample technical vs non-technical messages
  3. Evaluate LLM scoring effectiveness by measuring relevance scores between queries and retrieved documents with human evaluation baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal method for integrating multimodal capabilities (like OCR) to process user-submitted images and screenshots in group chat technical assistant systems?
- Basis in paper: [explicit] The authors mention that users frequently send log screenshots before asking questions, and these images contain valuable context. They tried various open-source and commercial OCR methods but found the results unsatisfactory.
- Why unresolved: The paper acknowledges this limitation but doesn't provide a solution or evaluate different OCR approaches systematically. The multimodal integration challenge remains open for group chat technical assistants.
- What evidence would resolve it: Comparative evaluation of different OCR models specifically tested on technical documentation and error logs from open-source projects, measuring accuracy and relevance of extracted information for technical assistance tasks.

### Open Question 2
- Question: How can we develop more accurate domain-specific part-of-speech tagging models that work effectively for bilingual technical content (Chinese-English)?
- Basis in paper: [explicit] The authors note that domain-specific POS tagging lacks precision, particularly for terms like "deploy" in deep learning contexts. They also mention that HanLP performs poorly on English, and translation APIs introduce significant misinterpretations for technical terms.
- Why unresolved: Current NLP tools fail to capture the nuanced meaning of technical terms that vary by context, and there's no effective solution for bilingual technical content processing in the paper.
- What evidence would resolve it: Development and evaluation of a POS tagging model specifically trained on bilingual technical documentation from open-source projects, with metrics showing improved accuracy over general-purpose models.

### Open Question 3
- Question: What is the minimum context length required for technical assistants to effectively handle complex queries involving multiple knowledge points from large code repositories?
- Basis in paper: [explicit] The authors experimented with context lengths up to 40k tokens and found that even 32k tokens provided relatively good results. They mention that complex queries involving multiple knowledge points remain challenging.
- Why unresolved: While the paper identifies context length as important, it doesn't establish a clear threshold for when additional context stops providing meaningful improvements for technical assistance.
- What evidence would resolve it: Systematic testing of context lengths (16k, 32k, 64k, 128k) on increasingly complex technical queries, measuring precision and recall to identify the point of diminishing returns for technical assistance tasks.

## Limitations

- The system's hybrid search implementation (Score Board) lacks detailed specifications, making faithful reproduction challenging
- LLM scoring mechanism effectiveness is not comprehensively validated against human evaluation baselines
- No comprehensive evaluation of end-to-end system performance and user satisfaction in realistic group chat scenarios

## Confidence

- **High Confidence**: The effectiveness of text2vec models for task rejection (0.99 precision, 0.92 recall) based on direct experimental validation
- **Medium Confidence**: The three identified LLM requirements (scoring ability, In-Context Learning, long context) as critical for technical assistant products, based on the authors' analysis but limited external validation
- **Low Confidence**: The overall system performance and user satisfaction metrics, as the paper lacks comprehensive evaluation of end-to-end functionality

## Next Checks

1. Implement and test the task rejection pipeline with annotated datasets to verify the reported precision and recall metrics across different text2vec models
2. Evaluate the LLM scoring mechanism's effectiveness by comparing its relevance judgments against human evaluations on a held-out test set
3. Conduct an end-to-end system evaluation measuring response accuracy, hallucination rates, and user satisfaction in realistic group chat scenarios with domain experts