---
ver: rpa2
title: Quantifying Memorization and Detecting Training Data of Pre-trained Language
  Models using Japanese Newspaper
arxiv_id: '2404.17143'
source_url: https://arxiv.org/abs/2404.17143
tags:
- memorization
- data
- training
- language
- plms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study quantified the memorization of domain-specific pre-trained
  language models using a limited corpus of Japanese newspaper articles and detected
  training data from them. The experiments replicated empirical findings from English
  studies that memorization increases with training data duplication, model size,
  and prompt length, and demonstrated that training data can be detected in Japanese
  with AUC scores of approximately 0.6 using membership inference attacks.
---

# Quantifying Memorization and Detecting Training Data of Pre-trained Language Models using Japanese Newspaper

## Quick Facts
- **arXiv ID:** 2404.17143
- **Source URL:** https://arxiv.org/abs/2404.17143
- **Authors:** Shotaro Ishihara; Hiromu Takahashi
- **Reference count:** 40
- **Primary result:** Domain-specific Japanese GPT-2 models exhibit memorization scaling with duplication, model size, and prompt length, with training data detection possible at AUC ~0.6

## Executive Summary
This study investigates memorization in domain-specific pre-trained language models using Japanese newspaper articles, replicating findings from English studies that memorization scales with training data duplication, model size, and prompt length. The researchers demonstrate that training data can be detected in Japanese PLMs using membership inference attacks, achieving AUC scores of approximately 0.6. By leveraging newspaper paywalls to create natural public/private splits in articles, the study provides a novel framework for evaluating privacy risks in domain-specific models trained on private data.

## Method Summary
The researchers pre-trained GPT-2 models (0.1B parameters) on Japanese newspaper articles from Nikkei Inc, varying training epochs from 1 to 60. They constructed evaluation sets using 1,000 articles from 2021, splitting each at the paywall boundary into public prompts and private references. Memorization was quantified using eidetic (character matching) and approximate (normalized Levenshtein distance) metrics. Training data detection employed membership inference attacks using Min-k% Prob scoring based on log-likelihood values. Negative examples from January 2023 articles ensured detection methods were not exploiting language model biases.

## Key Results
- Memorization increases with training data duplication, model size, and prompt length, replicating English study findings in Japanese
- Training data detection is feasible in Japanese PLMs with AUC scores around 0.6 using membership inference attacks
- The paywall-based experimental design effectively separates public and private content for evaluation purposes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Memorization of Japanese PLMs scales with training data duplication, model size, and prompt length, replicating prior English findings.
- **Mechanism:** Increased data duplication (multiple epochs) and larger model parameters provide more capacity for exact and approximate memorization of training data fragments.
- **Core assumption:** The relationship between duplication, model size, and memorization observed in English is transferable to Japanese due to shared underlying model architectures and training dynamics.
- **Evidence anchors:**
  - [abstract] "Experiments replicated the empirical finding that memorization of PLMs is related to the duplication in the training data, model size, and prompt length, in Japanese the same as in previous English studies."
  - [section] "Memorization enhances along with epochs. This phenomenon replicates the empirical finding that memorization is associated with duplication within a training set, even in Japanese."
  - [corpus] Weak. The corpus evidence only lists related papers but does not directly support the transferability claim.
- **Break condition:** If Japanese tokenization or language structure fundamentally alters the memorization dynamics (e.g., different sparsity patterns), the English findings may not replicate.

### Mechanism 2
- **Claim:** Training data detection via membership inference attacks is feasible in Japanese PLMs using log-likelihood scoring.
- **Mechanism:** Higher log-likelihood for memorized tokens signals likely training data membership, enabling detection even without reference comparison.
- **Core assumption:** The statistical signature of memorization (elevated log-likelihood for memorized tokens) is language-agnostic and detectable in Japanese.
- **Evidence anchors:**
  - [abstract] "we attempted membership inference attacks, demonstrating that the training data can be detected even in Japanese, which is the same trend as in English."
  - [section] "The performance (AUC and TPR@10%FPR) of Min-k% Prob... exceeded the value of the random prediction (0.50) in almost all cases."
  - [corpus] Weak. Corpus neighbors are unrelated to membership inference methodology.
- **Break condition:** If Japanese tokenization or vocabulary size disrupts the statistical distribution of memorized tokens, log-likelihood-based detection may fail.

### Mechanism 3
- **Claim:** Newspaper paywalls enable realistic data splitting into public prompts and private references, mirroring real-world access restrictions.
- **Mechanism:** Public article beginnings serve as prompts; private continuations act as references, creating a natural separation between accessible and protected content.
- **Core assumption:** Paywall structures in Japanese newspapers align with the experimental need for controlled prompt-reference pairs.
- **Evidence anchors:**
  - [section] "We propose to use the beginning of the newspaper article (the public part) as a prompt and the continuation in the paywall (the private part) as a reference."
  - [section] "Using private parts as references can achieve the splitting in which publishers hide important information that they want to preserve."
  - [corpus] Weak. No corpus evidence directly supports paywall structure relevance.
- **Break condition:** If paywall policies change or articles lack clear public/private demarcation, the experimental design collapses.

## Foundational Learning

- **Concept:** Differential privacy and its role in mitigating memorization.
  - **Why needed here:** Understanding differential privacy helps explain why some training methods reduce memorization risk.
  - **Quick check question:** How does adding noise during training reduce the likelihood of exact memorization?

- **Concept:** Tokenization and its impact on memorization metrics.
  - **Why needed here:** Japanese lacks explicit word boundaries; tokenization choices affect similarity and memorization measurements.
  - **Quick check question:** Why might unigram language models be preferred for Japanese tokenization in memorization studies?

- **Concept:** Membership inference attack metrics (AUC, TPR@10%FPR).
  - **Why needed here:** These metrics quantify detection performance and are central to evaluating the feasibility of detecting memorized training data.
  - **Quick check question:** What does an AUC of 0.6 indicate about the detection capability in this context?

## Architecture Onboarding

- **Component map:** Japanese newspaper corpus → paywall splitting → public prompts + private references → GPT-2 training (varying epochs) → greedy decoding → memorization metrics + detection scores

- **Critical path:**
  1. Prepare corpus with paywall metadata
  2. Train GPT-2 models for specified epochs
  3. Generate continuations for public prompts
  4. Compute memorization metrics and detection scores

- **Design tradeoffs:**
  - Smaller models reduce computational cost but may underrepresent memorization dynamics
  - Greedy decoding is simple but may miss diverse memorized outputs
  - Fixed prompt lengths limit exploration of context-length effects

- **Failure signatures:**
  - Low AUC scores indicate detection failure (e.g., AUC ≈ 0.5 suggests random guessing)
  - No correlation between epochs and memorization suggests experimental setup issues
  - High variance in metrics may indicate unstable training or data quality problems

- **First 3 experiments:**
  1. Compare eidetic vs. approximate memorization across epochs to validate metric sensitivity
  2. Vary prompt length systematically to confirm scaling effects
  3. Test detection performance across k values in Min-k% Prob to identify optimal configuration

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the choice of decoding strategy (e.g., greedy vs. top-k sampling) impact the quantity and quality of memorized content in domain-specific PLMs trained on Japanese newspaper articles?
- **Basis in paper:** [explicit] The paper mentions that previous studies used various decoding strategies and that Carlini et al. (2023) reported minimal effects, but Lee et al. (2023) observed more training data extraction with top-k and top-p sampling. The paper itself only used a greedy method.
- **Why unresolved:** The paper only used a greedy decoding method and did not explore the impact of different decoding strategies on memorization.
- **What evidence would resolve it:** Conducting experiments with various decoding strategies (e.g., top-k sampling, temperature tuning) and comparing the amount and nature of memorized content generated under each strategy.

### Open Question 2
- **Question:** What is the relationship between model size and memorization in domain-specific PLMs trained on Japanese newspaper articles, and how does this compare to general PLMs?
- **Basis in paper:** [explicit] The paper notes that general GPT-2 models showed increased memorization with larger parameter sizes, but the domain-specific GPT-2 models were only of one size (0.1 B).
- **Why unresolved:** The study only used domain-specific GPT-2 models of one size (0.1 B), preventing a direct comparison of memorization across different model sizes in the domain-specific context.
- **What evidence would resolve it:** Pre-training domain-specific GPT-2 models with varying parameter sizes and comparing their memorization levels under controlled conditions.

### Open Question 3
- **Question:** How effective are different methods for mitigating memorization (e.g., data deduplication, differential privacy, confidence masking) when applied to domain-specific PLMs trained on Japanese newspaper articles?
- **Basis in paper:** [explicit] The paper lists several defensive approaches (pre-processing, training, post-processing) but does not evaluate their effectiveness in the Japanese context.
- **Why unresolved:** The study focuses on quantifying memorization and detecting training data but does not explore the effectiveness of existing mitigation techniques in the Japanese domain-specific setting.
- **What evidence would resolve it:** Applying different memorization mitigation techniques during pre-training and evaluating their impact on memorization levels using the framework established in the paper.

## Limitations
- Paywall-based experimental design may not generalize across different Japanese publications or evolve over time
- Detection performance (AUC ≈ 0.6) indicates modest capability with limited practical reliability
- Focus on greedy decoding may underestimate diversity of memorized outputs
- Limited parameter scale (0.1B) may not capture memorization behaviors of larger deployed models

## Confidence
- **Memorization scaling with duplication, model size, and prompt length:** High
- **Feasibility of training data detection in Japanese:** Medium
- **Paywall-based experimental design:** Medium

## Next Checks
1. **Validate detection robustness:** Test the Min-k% Prob detection method across different k values (k=5, 15, 20) and evaluate whether performance scales consistently or if 0.6 AUC represents a ceiling for this approach.
2. **Assess tokenization impact:** Compare memorization metrics using different Japanese tokenization approaches (unigram vs. alternative methods) to determine if tokenization choices systematically affect detection performance or memorization measurements.
3. **Test cross-publication generalization:** Apply the paywall-based experimental design to Japanese newspaper articles from multiple publishers with different paywall policies to verify the approach's generalizability beyond the Nikkei corpus.