---
ver: rpa2
title: Replay Consolidation with Label Propagation for Continual Object Detection
arxiv_id: '2409.05650'
source_url: https://arxiv.org/abs/2409.05650
tags:
- replay
- task
- memory
- object
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles catastrophic forgetting in continual object
  detection by introducing Replay Consolidation with Label Propagation for Object
  Detection (RCLPOD). The method addresses the missing annotations problem, where
  unlabeled objects in earlier tasks reappear as new classes in later tasks, causing
  task interference.
---

# Replay Consolidation with Label Propagation for Continual Object Detection

## Quick Facts
- arXiv ID: 2409.05650
- Source URL: https://arxiv.org/abs/2409.05650
- Authors: Riccardo De Monte; Davide Dalle Pezze; Marina Ceccon; Francesco Pasti; Francesco Paissan; Elisabetta Farella; Gian Antonio Susto; Nicola Bellotto
- Reference count: 40
- Primary result: RCLPOD achieves 56.1 mAP on VOC 15p1 and 20.0 mAP50-95 on COCO 40p10, outperforming existing replay and distillation-based methods

## Executive Summary
This paper addresses catastrophic forgetting in continual object detection by introducing Replay Consolidation with Label Propagation for Object Detection (RCLPOD). The method tackles the missing annotations problem where unlabeled objects in earlier tasks reappear as new classes in later tasks, causing task interference. RCLPOD enhances replay memory through two mechanisms: Label Propagation enriches stored samples with pseudo-labels for previously learned classes, and OCDM promotes class balance in the memory buffer. Additionally, a masking loss prevents interference during training, and feature distillation reduces drift in intermediate representations.

## Method Summary
RCLPOD is a continual learning method for object detection that combines replay memory with label propagation and class-balanced selection. During each task, the method uses the previously trained model to generate pseudo-labels for previously learned classes on new task samples, then trains with a masking loss that prevents interference from new classes on replay samples. After training, the method applies backward label propagation to enrich replay memory with new class knowledge. OCDM maintains balanced class distribution in the memory buffer through a greedy selection mechanism. Feature distillation stabilizes intermediate representations by reducing drift during task transitions.

## Key Results
- Achieves 56.1 mAP on VOC 15p1 and 20.0 mAP50-95 on COCO 40p10 benchmarks
- Outperforms existing replay-based methods and distillation-based approaches on both VOC and COCO datasets
- Demonstrates effectiveness across different YOLOv8 architectures (YOLOv8n and YOLOv8m)
- Shows improved stability-plasticity balance compared to state-of-the-art continual learning methods

## Why This Works (Mechanism)

### Mechanism 1: Label Propagation for Replay Memory Enrichment
- Claim: RCLPOD improves replay memory quality by enriching stored samples with pseudo-labels for previously learned classes, reducing task interference.
- Mechanism: The Label Propagation (LP) mechanism adds pseudo-labels for old classes to new task samples during training, then consolidates new class knowledge into old samples post-training.
- Core assumption: Pseudo-labels generated by the old model for previously learned classes are accurate enough to prevent interference when learning new classes.
- Evidence anchors:
  - [abstract]: "RCLPOD enhances the replay memory by improving the quality of the stored samples through a technique that promotes class balance while also improving the quality of the ground truth associated with these samples through a technique called label propagation."
  - [section]: "During the training of task t, for a sample (x, y) ∈ Dt, the forward step modifies the ground truth y adding pseudo-labels of the classes C1, . . . , Ct−1 by leveraging the knowledge of the previously trained model fθt−1."
  - [corpus]: Weak - the corpus contains multi-label continual learning work but no direct evidence for object detection LP efficacy.
- Break condition: Pseudo-label accuracy degrades when old model confidence is low, causing incorrect pseudo-labels that harm performance.

### Mechanism 2: OCDM for Class-Balanced Memory Selection
- Claim: Class-balanced memory selection through OCDM improves sample diversity and reduces redundancy compared to random selection.
- Mechanism: OCDM uses a greedy approach to remove samples that contribute least to uniform class distribution, prioritizing underrepresented classes.
- Core assumption: Maintaining balanced class representation in replay memory improves overall detection performance across all classes.
- Evidence anchors:
  - [abstract]: "RCLPOD enhances the replay memory by improving the quality of the stored samples through a technique that promotes class balance"
  - [section]: "OCDM works in synergy to optimize the replay memory, as demonstrated by the conducted ablation study"
  - [corpus]: Missing - no corpus papers directly address OCDM for object detection, only general continual learning.
- Break condition: When dataset is already balanced or memory is too small to maintain diversity, OCDM provides minimal benefit.

### Mechanism 3: Masking Loss for New Classes
- Claim: Masking loss for new classes in replay samples prevents task interference when objects overlap in YOLO architectures.
- Mechanism: During training on new tasks, classification loss contributions from new classes are ignored for predictions on replay samples.
- Core assumption: New-class objects in replay samples don't need to be detected during new task training, only old classes matter.
- Evidence anchors:
  - [abstract]: "Additionally, a masking loss prevents interference during training"
  - [section]: "we propose a custom masking loss approach for YOLOv8. In particular, we propose to ignore the contribution of new classes for the classification loss computation for every prediction associated to any sample saved in the memory buffer"
  - [corpus]: Weak - only one corpus paper mentions masking, but not specifically for overlapping objects in object detection.
- Break condition: When new-class objects rarely overlap with old ones, masking provides negligible improvement.

## Foundational Learning

- Concept: Catastrophic Forgetting
  - Why needed here: The paper explicitly addresses catastrophic forgetting as the core problem RCLPOD solves.
  - Quick check question: What happens to model performance on previous tasks when training on new tasks without continual learning techniques?

- Concept: Label Propagation
  - Why needed here: RCLPOD's main innovation relies on label propagation to enrich replay memory with pseudo-labels.
  - Quick check question: How does label propagation differ from standard pseudo-labeling approaches in continual learning?

- Concept: Object Detection vs Image Classification
  - Why needed here: The paper contrasts CL challenges between these domains, particularly the missing annotations problem.
  - Quick check question: Why does continual learning for object detection face additional challenges compared to image classification?

## Architecture Onboarding

- Component map: Backbone -> Label Propagation Module -> Masking Loss -> Feature Distillation -> OCDM Selector -> Replay Memory
- Critical path: New task → Forward LP → Training with masking + distillation → Backward LP → Memory update with OCDM
- Design tradeoffs:
  - Memory vs Performance: Larger replay buffer improves performance but increases resource usage
  - Label Quality vs Computation: Better pseudo-labels improve performance but require more computation
  - Balance vs Diversity: Strict class balancing may reduce sample diversity
- Failure signatures:
  - Performance degradation on old classes indicates insufficient replay quality
  - Performance degradation on new classes suggests masking is too aggressive
  - Memory inefficiency shows OCDM not selecting optimal samples
- First 3 experiments:
  1. Compare RCLPOD with and without Label Propagation on VOC 15p1
  2. Test different memory sizes (400 vs 800) for OCDM selection
  3. Evaluate masking loss impact by disabling it on COCO 40p10

## Open Questions the Paper Calls Out
The paper does not explicitly call out any open questions.

## Limitations
- Effectiveness depends heavily on pseudo-label quality, which degrades when old model confidence is low
- OCDM performance is sensitive to memory buffer size, with diminishing returns for larger buffers
- Masking loss assumes new-class objects rarely need detection in replay samples, which may not hold for all scenarios

## Confidence
- High confidence in replay memory enhancement claims: Supported by quantitative results showing RCLPOD outperforms baselines on both VOC and COCO benchmarks
- Medium confidence in label propagation efficacy: The mechanism is well-defined but relies on pseudo-label quality that varies with model confidence and class distribution
- Medium confidence in OCDM effectiveness: The mechanism is theoretically sound but lacks ablation studies isolating its individual contribution
- Low confidence in masking loss impact: Limited discussion of when this mechanism provides significant benefits versus baseline approaches

## Next Checks
1. Perform sensitivity analysis on pseudo-label generation thresholds and IoU criteria to determine optimal parameters for different class distributions
2. Conduct ablation study isolating OCDM's contribution by comparing with random memory selection across multiple memory buffer sizes
3. Test masking loss effectiveness on datasets with varying degrees of object overlap between old and new classes to identify scenarios where it provides maximum benefit