---
ver: rpa2
title: 'SoMeLVLM: A Large Vision Language Model for Social Media Processing'
arxiv_id: '2402.13022'
source_url: https://arxiv.org/abs/2402.13022
tags:
- social
- text
- language
- media
- hate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The authors introduce SoMeLVLM, a large vision-language model\
  \ designed to address social media processing tasks. To enhance the model\u2019\
  s capabilities, they develop a comprehensive cognitive framework inspired by Bloom\u2019\
  s Taxonomy, consisting of five levels: Knowledge & Comprehension, Application, Analysis,\
  \ Evaluation, and Creation."
---

# SoMeLVLM: A Large Vision Language Model for Social Media Processing

## Quick Facts
- arXiv ID: 2402.13022
- Source URL: https://arxiv.org/abs/2402.13022
- Authors: Xinnong Zhang; Haoyu Kuang; Xinyi Mou; Hanjia Lyu; Kun Wu; Siming Chen; Jiebo Luo; Xuanjing Huang; Zhongyu Wei
- Reference count: 40
- Primary result: SoMeLVLM achieves state-of-the-art performance across 12 social media tasks using a Bloom's Taxonomy-based cognitive framework

## Executive Summary
SoMeLVLM addresses the challenge of applying large vision-language models to social media processing by introducing a cognitive framework inspired by Bloom's Taxonomy. The authors construct a 654k-instance multimodal dataset spanning 12 social media tasks organized into five cognitive levels. Through systematic instruction tuning, SoMeLVLM demonstrates superior performance compared to existing models, particularly excelling at higher-level cognitive tasks like evaluation and creation. The model's design specifically targets the informal language and multimodal nature of social media content that typically confounds general-purpose LVLMs.

## Method Summary
The authors develop SoMeLVLM through a two-step instruction tuning process. First, they fine-tune the Vicuna-7b-v1.1 base model on 654k textual instruction data covering social media tasks organized into five Bloom's Taxonomy-derived cognitive levels. Second, they tune the connection module between the vision encoder and language model using multimodal data. The dataset encompasses 12 social media tasks including sentiment analysis, misinformation detection, humor classification, and content creation. Evaluation employs both classification accuracy metrics (Acc, Acc*) and generative metrics (BLEU, ROUGE, GPT-Score) across zero-shot settings.

## Key Results
- SoMeLVLM achieves state-of-the-art performance across all 12 evaluated social media tasks
- The model demonstrates particular strength in higher cognitive levels (Analysis, Evaluation, Creation) compared to baseline models
- Zero-shot accuracy (Acc*) shows strong generalization capability without task-specific fine-tuning
- Multimodal tasks show significant improvement over text-only baselines, validating the visual-text integration approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cognitive-level instruction tuning enables systematic handling of social media's multifaceted tasks.
- Mechanism: The authors structure training data across five Bloom's Taxonomy-derived cognitive levels (Knowledge & Comprehension, Application, Analysis, Evaluation, Creation). Each level addresses a different depth of understanding and task type, allowing the model to progressively build from basic recognition to complex generation.
- Core assumption: Social media tasks can be decomposed into cognitive levels that map to specific learning objectives and data types.
- Evidence anchors:
  - [abstract] "cognitive framework equipped with five key capabilities including knowledge & comprehension, application, analysis, evaluation, and creation."
  - [section 3] "We begin by designing a cognitive pyramid according to Bloom's Taxonomy... which is a classic teaching theory proposed by Benjamin Bloom in 1956."
- Break condition: If social media tasks do not align neatly into cognitive-level categories, the model may struggle with ambiguous or mixed-demand inputs.

### Mechanism 2
- Claim: Multimodal instruction tuning with curated social media data closes the gap between general-domain LVLMs and the informal, nuanced language of social media.
- Mechanism: By fine-tuning on a 654k multimodal dataset constructed from both open-source and collected social media sources, the model learns informal expressions, visual-text integration, and domain-specific context absent in general models.
- Core assumption: General-domain models fail on social media due to lack of exposure to informal language and multimodal context.
- Evidence anchors:
  - [abstract] "general domain models often fall short in aligning with the unique speaking style and context of social media tasks."
  - [section 1] "we discover three major challenges faced by general domain models in addressing the nuances of social media: Limitations in social multimedia understanding, Challenges in informal language understanding, Complex cognitive demands in social media tasks."
- Break condition: If the curated dataset does not adequately represent the diversity and evolving nature of social media language and content, model performance will degrade on unseen posts.

### Mechanism 3
- Claim: Zero-shot performance is improved by explicit instruction-following design and cognitive-level scaffolding.
- Mechanism: The authors design five prompts per dataset, enforce instruction-following output formats, and organize tasks by cognitive level. This structured approach allows the model to generalize without task-specific examples.
- Core assumption: Zero-shot generalization improves when training data is highly structured and prompts enforce explicit output formats.
- Evidence anchors:
  - [abstract] "We have developed a 654k multimodal social media instruction-tuning dataset to support our cognitive framework and fine-tune our model."
  - [section 4.3] "Considering the zero-shot setting and the overall instruction-following ability of LVLMs, we report both the accuracy over the whole test set and the accuracy when only valid answers are counted (Acc*)."
- Break condition: If the instruction-following format is too rigid, the model may fail to adapt to novel task formats not covered by the training prompts.

## Foundational Learning

- Concept: Bloom's Taxonomy cognitive levels
  - Why needed here: Provides a principled framework to organize social media tasks by cognitive demand, ensuring the model learns from simple recognition to complex creation.
  - Quick check question: Which cognitive level focuses on generating new content (e.g., hashtags) based on a given multimodal post?
- Concept: Multimodal instruction tuning
  - Why needed here: Enables the model to integrate visual and textual information, essential for understanding social media posts that combine images and captions.
  - Quick check question: What type of data format does the model expect for multimodal inputs during instruction tuning?
- Concept: Zero-shot generalization in LLMs
  - Why needed here: The goal is to handle unseen social media tasks without additional fine-tuning; the model must interpret and execute tasks based on prompt instructions alone.
  - Quick check question: How does the model differentiate between valid and invalid answers when evaluating zero-shot performance?

## Architecture Onboarding

- Component map: CLIP visual encoder -> Q-former projection layer -> Vicuna-7b-v1.1 language model
- Critical path:
  1. Load base language model and visual encoder.
  2. Apply QLoRA fine-tuning on textual instruction data (2 epochs).
  3. Tune connection module with multimodal data (3 epochs).
  4. Evaluate zero-shot on held-out datasets.
- Design tradeoffs:
  - Using Vicuna-7b limits model capacity but keeps fine-tuning tractable; larger models could improve performance but increase cost.
  - Separate tuning of connection module allows reuse of base model weights but may introduce misalignment if not carefully aligned.
  - Zero-shot focus avoids need for per-task fine-tuning but relies heavily on prompt quality and dataset coverage.
- Failure signatures:
  - Degraded instruction-following: Base model produces outputs that do not match the requested format (e.g., generating prose instead of single-word answers).
  - Multimodal misalignment: Generated text ignores image context or misinterprets visual cues.
  - Poor zero-shot transfer: Model fails on tasks or domains not represented in the training set.
- First 3 experiments:
  1. Test instruction-following on a small set of labeled emotion classification prompts; verify output format compliance.
  2. Evaluate multimodal understanding on a held-out image-text pair task; check if image context is correctly incorporated.
  3. Run zero-shot classification on a novel misinformation dataset; measure accuracy and Acc* to assess generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SoMeLVLM perform on multilingual social media tasks beyond English?
- Basis in paper: [explicit] The authors explicitly state that "Our work currently focuses on English, and the performances shown in this paper may not be well reproduced in other languages."
- Why unresolved: The paper does not provide any experimental results or analysis on multilingual social media tasks, leaving the model's performance in this area unknown.
- What evidence would resolve it: Conducting experiments on multilingual social media datasets and comparing SoMeLVLM's performance with other models in different languages would provide evidence to answer this question.

### Open Question 2
- Question: How does SoMeLVLM handle emerging neologisms and culturally-specific phrases in social media?
- Basis in paper: [inferred] The authors mention that "these neologisms and phrases are often driven by specific cultures, communities, or events, and their meanings may vary across different groups," suggesting potential interpretive biases in the model.
- Why unresolved: The paper does not provide any specific examples or analysis of how SoMeLVLM handles emerging or culturally-specific phrases in social media.
- What evidence would resolve it: Testing SoMeLVLM on social media data containing emerging neologisms and culturally-specific phrases, and analyzing its ability to correctly interpret and generate relevant responses, would provide evidence to answer this question.

### Open Question 3
- Question: How does SoMeLVLM's performance compare to human performance on social media tasks?
- Basis in paper: [explicit] The authors mention that "at the multimodal Creation level, all of the models perform poorly as they are required to generate three hashtags that best describe the post, which is not an easy task even for human beings."
- Why unresolved: The paper does not provide any direct comparison between SoMeLVLM's performance and human performance on social media tasks.
- What evidence would resolve it: Conducting human evaluations on social media tasks and comparing the results with SoMeLVLM's performance would provide evidence to answer this question.

## Limitations

- The cognitive framework's effectiveness depends on whether social media tasks can be meaningfully decomposed into Bloom's Taxonomy levels, which has not been independently validated for this domain
- The 654k dataset size, while substantial, may not fully capture the evolving and diverse nature of social media language and content
- Evaluation focuses on zero-shot performance without comparing against few-shot or full fine-tuning baselines, leaving open whether instruction tuning is optimal

## Confidence

**High confidence** in the model's superior performance on the reported tasks, as evidenced by multiple quantitative metrics and direct comparisons with established baselines. The technical implementation details (Vicuna base, CLIP visual encoder, QLoRA fine-tuning) are standard and well-documented in the LVLM literature.

**Medium confidence** in the cognitive framework's practical utility, as the paper provides theoretical justification but limited empirical evidence showing that organizing data by cognitive level actually improves performance versus other organizational schemes. The connection between Bloom's Taxonomy and social media task performance needs further validation.

**Low confidence** in the zero-shot generalization claims without broader domain testing. The model was evaluated on tasks similar to its training data, and its performance on truly novel social media phenomena (new slang, emerging misinformation patterns, platform-specific features) remains untested.

## Next Checks

1. **Cross-platform generalization test**: Evaluate SoMeLVLM on social media posts from platforms not represented in the training data (e.g., TikTok, Reddit, LinkedIn) to assess whether the cognitive framework enables true zero-shot transfer across social media domains.

2. **Cognitive level ablation study**: Re-train the model with scrambled cognitive-level assignments while keeping the same data distribution, then compare performance to determine if the specific organization by Bloom's Taxonomy levels provides measurable benefits.

3. **Dynamic content adaptation test**: Measure performance degradation over time as social media language evolves, comparing SoMeLVLM against a periodically updated model to quantify the framework's resilience to changing communication patterns.