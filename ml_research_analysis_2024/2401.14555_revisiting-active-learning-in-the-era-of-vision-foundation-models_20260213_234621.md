---
ver: rpa2
title: Revisiting Active Learning in the Era of Vision Foundation Models
arxiv_id: '2401.14555'
source_url: https://arxiv.org/abs/2401.14555
tags:
- learning
- active
- query
- foundation
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how vision foundation models impact active
  learning (AL) strategies, particularly in the low-budget regime. The authors identify
  four critical components of effective AL: initial labeled pool selection, ensuring
  diverse sampling, the trade-off between representative and uncertainty sampling,
  and leveraging unlabeled data.'
---

# Revisiting Active Learning in the Era of Vision Foundation Models

## Quick Facts
- arXiv ID: 2401.14555
- Source URL: https://arxiv.org/abs/2401.14555
- Reference count: 40
- Key outcome: DropQuery outperforms state-of-the-art AL methods by leveraging foundation models' robust representations through dropout-based uncertainty estimation and clustering-based diversity

## Executive Summary
This paper challenges fundamental assumptions about active learning (AL) in the era of vision foundation models. The authors systematically investigate four critical components of effective AL: initial pool selection, diversity sampling, the uncertainty-representative sampling trade-off, and unlabeled data utilization. They demonstrate that foundation models' semantically organized latent spaces fundamentally alter AL dynamics, particularly in low-budget regimes. Based on these insights, they propose DropQuery, a simple yet effective AL strategy that uses dropout for uncertainty estimation and K-means clustering for diversity, achieving state-of-the-art performance across diverse image classification benchmarks including challenging biomedical datasets.

## Method Summary
The authors use frozen vision foundation models (DINOv2 ViT-g14, OpenCLIP ViT-G14) as feature extractors, training linear classifiers on top. For AL, they employ dropout perturbations at inference time to estimate uncertainty, selecting candidates where prediction inconsistency exceeds a threshold. These uncertain candidates are then clustered using K-means into B groups, with centroids selected as final queries. The method operates in a low-budget regime (1 sample per class per iteration) across 20 AL iterations, evaluating on both natural and out-of-domain biomedical image datasets. Experiments use 5 random seeds with mean accuracy and standard deviation reported.

## Key Results
- DropQuery achieves state-of-the-art performance across 13 diverse image classification benchmarks
- Uncertainty sampling outperforms representative sampling in early AL iterations when using foundation models
- Intelligent initial pool selection significantly improves AL performance in the low-budget regime
- Foundation model representations reduce the need for complex diversity sampling methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Foundation models' robust representations challenge existing active learning (AL) assumptions in the low-budget regime.
- Mechanism: Vision foundation models (DINOv2, OpenCLIP) create semantically organized latent spaces that reduce the need for uncertainty sampling early in AL.
- Core assumption: Semantic clustering in foundation model embeddings is sufficient to establish good decision boundaries with minimal labeled data.
- Evidence anchors:
  - [abstract] "The advent of large vision and vision-language models, pretrained on web-scale data corpora, has led to the significant enhancement of visual representation spaces."
  - [section 3.1] "Our experimental results in Section 3.1 demonstrated the utility of intelligently selecting the initial pool of candidates to label. Informed by these results and given the semantic clusters characteristic to the latent spaces of foundation models, DropQuery employs a centroid-based initial pool selection strategy to overcome the cold-start problem."
- Break condition: If the dataset distribution significantly deviates from the pretraining data, semantic clustering may fail and uncertainty sampling becomes necessary again.

### Mechanism 2
- Claim: Dropout perturbations effectively estimate uncertainty for AL candidate selection.
- Mechanism: Applying dropout at inference time creates stochastic perturbations in feature space; samples near decision boundaries show inconsistent predictions across perturbations.
- Core assumption: Dropout-induced feature perturbations are meaningful indicators of classifier uncertainty.
- Evidence anchors:
  - [section 4] "We experiment using dropout perturbations to measure uncertainty and select candidates for annotation."
  - [section 4] "Since label propagation does not help queries in our experiments, we do not consider it a core component."
- Break condition: If dropout perturbations are too coarse (high dropout ratio) or too subtle (low ratio), uncertainty estimation becomes unreliable.

### Mechanism 3
- Claim: K-means clustering of uncertainty candidates enforces diversity without explicit diversity metrics.
- Mechanism: After shortlisting uncertain candidates, clustering into B groups and selecting centroids ensures diverse coverage of the representation space.
- Core assumption: Feature space is Euclidean-like enough for K-means to capture meaningful diversity.
- Evidence anchors:
  - [section 3.2] "Our results show that by imposing simple diversity measures, uncertainty-based queries like Uncertainty, Entropy, Margins, and BALD surpass the performance of AL strategies that explicitly incorporate diversity in their queries."
  - [section 4] "Candidate clustering ensures the diversity of selected points, as shown in Table 3."
- Break condition: If feature space is highly non-linear or clusters are poorly separated, K-means may fail to capture true diversity.

## Foundational Learning

- Concept: Semantic clustering in pretrained representation spaces
  - Why needed here: Foundation models organize features into meaningful clusters, reducing the need for complex diversity sampling methods.
  - Quick check question: Can you explain why a centroid-based initial pool selection works better with foundation model embeddings than with randomly initialized models?

- Concept: Dropout as uncertainty estimator
  - Why needed here: Dropout simulates an ensemble of models, and prediction inconsistency indicates uncertainty in candidate selection.
  - Quick check question: How does dropout at inference time differ from traditional Bayesian dropout uncertainty estimation?

- Concept: K-means for diversity enforcement
  - Why needed here: Simple clustering can enforce diversity without explicit diversity metrics, leveraging the structure of the representation space.
  - Quick check question: Why might K-means clustering fail in highly non-linear or poorly separated feature spaces?

## Architecture Onboarding

- Component map: Frozen foundation model -> Linear classifier -> Dropout uncertainty module -> K-means clustering -> Label propagation (optional)
- Critical path:
  1. Extract features from unlabeled pool using frozen backbone
  2. Apply dropout perturbations to measure prediction consistency
  3. Select uncertain candidates where inconsistency > 0.5M
  4. Cluster candidates into B groups and select centroids
  5. Query selected points for labels
  6. Retrain linear classifier on updated labeled pool
- Design tradeoffs:
  - Dropout ratio vs. number of candidates: Higher dropout increases uncertainty signal but reduces candidate pool size
  - M (number of dropout iterations) vs. computational cost: More iterations improve uncertainty estimation but increase compute
  - Clustering granularity vs. diversity: More clusters improve diversity but may reduce uncertainty signal
- Failure signatures:
  - High dropout ratio → Very few candidates selected → Poor model performance
  - Too few M iterations → Unreliable uncertainty estimates → Poor candidate selection
  - Poor initial pool → Slow convergence → Suboptimal final accuracy
  - Non-Euclidean feature space → K-means fails → Loss of diversity
- First 3 experiments:
  1. Verify dropout uncertainty estimation: Compare prediction consistency with and without dropout on a small labeled set
  2. Test K-means diversity: Cluster a diverse set of samples and check if centroids capture representative points
  3. Ablation study: Run AL with and without initial pool selection to measure cold-start impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do foundation models perform on active learning in scenarios with heavily imbalanced class distributions, particularly in biomedical imaging where class imbalances are widespread?
- Basis in paper: [inferred] The paper acknowledges the limitation of their experiments focusing on datasets with relatively even label distributions and notes that long-tailed datasets are common in real-world scenarios, particularly in biomedical domains.
- Why unresolved: The current study primarily used balanced datasets and did not thoroughly investigate performance on imbalanced data, which is a common challenge in practical applications.
- What evidence would resolve it: Conducting experiments on various imbalanced datasets, particularly in biomedical imaging, and comparing performance metrics such as accuracy, F1-score, and area under the ROC curve across different active learning strategies.

### Open Question 2
- Question: What is the impact of different dropout ratios and the number of dropout iterations on the performance and diversity of selected samples in DropQuery?
- Basis in paper: [explicit] The paper conducted ablation studies on the dropout ratio and the number of dropout iterations, showing that higher dropout ratios slightly improved model performance but resulted in fewer samples added to the candidate set. The number of dropout iterations had minimal impact on performance.
- Why unresolved: While the study provided initial insights, the exact relationship between dropout parameters and the trade-off between model performance and candidate diversity remains unclear.
- What evidence would resolve it: Further systematic experiments varying dropout ratios and iteration counts across different datasets and analyzing the resulting candidate diversity and model performance metrics.

### Open Question 3
- Question: How does the performance of DropQuery and other active learning strategies change when using different types of foundation models, such as those trained on domain-specific data or with different pretraining objectives?
- Basis in paper: [explicit] The paper used DINOv2 and OpenCLIP models but acknowledged that the efficacy of foundation models in active learning might vary based on the model's pretraining data and objectives.
- Why unresolved: The study focused on general-purpose foundation models and did not explore the impact of domain-specific or differently trained models on active learning performance.
- What evidence would resolve it: Evaluating active learning strategies using a variety of foundation models, including those pretrained on domain-specific data and with different objectives, and comparing their performance on relevant tasks.

## Limitations
- The paper does not provide detailed ablation studies on dropout perturbation parameters (dropout ratio, number of iterations M)
- Limited discussion of computational overhead compared to other AL methods, particularly regarding feature extraction costs for large foundation models
- No theoretical analysis of why dropout perturbations work well for uncertainty estimation in this specific context

## Confidence
- **High Confidence**: Claims about foundation models' robust representations challenging existing AL assumptions (well-supported by experiments)
- **Medium Confidence**: Effectiveness of DropQuery across diverse datasets (extensive experiments but limited ablation on hyperparameters)
- **Low Confidence**: Generalizability to non-vision domains (only tested on image classification tasks)

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary dropout ratio and M iterations to determine optimal ranges and sensitivity of DropQuery performance
2. **Computational Efficiency Comparison**: Measure wall-clock time and resource usage of DropQuery vs. state-of-the-art methods across different dataset scales
3. **Domain Transferability Test**: Evaluate DropQuery on non-image modalities (text, audio) using corresponding foundation models to assess generalizability beyond vision tasks