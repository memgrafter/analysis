---
ver: rpa2
title: A Modified Word Saliency-Based Adversarial Attack on Text Classification Models
arxiv_id: '2403.11297'
source_url: https://arxiv.org/abs/2403.11297
tags:
- adversarial
- text
- word
- attack
- bert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a modified word saliency-based adversarial
  attack (MWSAA) for text classification models that integrates contextual embeddings
  and semantic consistency constraints into the probability-weighted word saliency
  (PWWS) framework. The method first identifies salient words through saliency estimation,
  then uses BERT embeddings to find contextually appropriate replacements, and finally
  applies cosine similarity to ensure semantic coherence.
---

# A Modified Word Saliency-Based Adversarial Attack on Text Classification Models

## Quick Facts
- arXiv ID: 2403.11297
- Source URL: https://arxiv.org/abs/2403.11297
- Reference count: 22
- Primary result: MWSAA achieves 42.50%-95.50% attack success rates with 3.27%-16.24% word replacement rates across three models and datasets

## Executive Summary
This paper presents a modified word saliency-based adversarial attack (MWSAA) that enhances the probability-weighted word saliency (PWWS) framework by integrating contextual embeddings and semantic consistency constraints. The method identifies salient words, uses BERT embeddings to find contextually appropriate replacements, and applies cosine similarity to ensure semantic coherence. Evaluated on BERT, ALBERT, and RoBERTa models using IMDB, AG News, and SST datasets, MWSAA demonstrates superior performance with higher attack success rates and lower word replacement rates compared to PWWS while maintaining semantic coherence in adversarial examples.

## Method Summary
MWSAA modifies the PWWS framework by incorporating two key enhancements: contextual embedding guidance and semantic consistency constraints. The approach first identifies salient words through saliency estimation, then uses BERT embeddings to find contextually appropriate replacements by calculating cosine similarity between original and candidate words in the embedding space. Finally, it applies cosine similarity between original and perturbed text embeddings to ensure semantic coherence, accepting only substitutions that maintain high similarity scores. This two-stage filtering process creates more efficient optimization that identifies high-impact, low-cost perturbations.

## Key Results
- Attack success rates ranging from 42.50% to 95.50% across different model-dataset combinations
- Lower word replacement rates (3.27%-16.24%) compared to PWWS (3.38%-18.93%)
- Maintained higher classification accuracy degradation while preserving semantic coherence
- Demonstrated effectiveness across three large language models (BERT, ALBERT, ROBERTa) and three datasets (IMDB, AG News, SST)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating contextual embeddings (BERT) into PWWS enables more semantically coherent word substitutions than word-level saliency alone.
- Mechanism: BERT's contextual embeddings capture richer semantic and contextual information by pre-training on masked language modeling and next-sentence prediction tasks. This allows the model to dynamically adjust word representations based on surrounding context, leading to more appropriate replacement words.
- Core assumption: BERT embeddings provide meaningful contextual representations that can guide word substitution choices better than static word embeddings or saliency scores alone.
- Evidence anchors:
  - [abstract]: "The method first identifies salient words through saliency estimation, then uses BERT embeddings to find contextually appropriate replacements"
  - [section 3.1]: "BERT embeddings can provide PWWS with a more nuanced understanding of word importance within the context of the entire sentence"
  - [corpus]: Weak - no direct corpus evidence found supporting this specific mechanism
- Break condition: If BERT embeddings fail to capture domain-specific context or if the target model is not sensitive to semantic coherence, the contextual guidance may not improve attack success.

### Mechanism 2
- Claim: Imposing semantic consistency constraints using cosine similarity ensures adversarial examples remain semantically similar to original text.
- Mechanism: After candidate words are identified through PWWS, cosine similarity between original and perturbed text embeddings is calculated. Only substitutions yielding high similarity scores are accepted, ensuring semantic coherence.
- Core assumption: Cosine similarity between text embeddings effectively measures semantic similarity in a way that correlates with human perception of meaning preservation.
- Evidence anchors:
  - [abstract]: "finally applies cosine similarity to ensure semantic coherence"
  - [section 3.2]: "cosine similarity measure to compute the semantic similarity between the original text and its adversarial counterpart"
  - [corpus]: Weak - no direct corpus evidence found supporting this specific mechanism
- Break condition: If cosine similarity does not align with actual semantic preservation (e.g., synonyms with different connotations), or if the model is insensitive to semantic changes, this constraint may not improve attack effectiveness.

### Mechanism 3
- Claim: Combining contextual embedding guidance with semantic consistency constraints produces adversarial examples requiring fewer word replacements while maintaining higher attack success.
- Mechanism: The two-stage filtering process (contextual appropriateness → semantic similarity) creates a more efficient optimization that identifies the most impactful word substitutions with minimal perturbations.
- Core assumption: The combination of contextual and semantic filtering is more effective than either approach alone in identifying high-impact, low-cost perturbations.
- Evidence anchors:
  - [abstract]: "with lower word replacement rates (3.27%-16.24%) compared to PWWS (3.38%-18.93%) while maintaining higher classification accuracy degradation"
  - [section 4]: "the percentage of word replacement involved in MWSAA is lower than that of PWWS"
  - [corpus]: Weak - no direct corpus evidence found supporting this specific mechanism
- Break condition: If the computational overhead of the two-stage process outweighs the benefits, or if the target model is not sensitive to the types of perturbations selected, the approach may not be advantageous.

## Foundational Learning

- Concept: Word saliency estimation
  - Why needed here: Identifies which words in the input text are most influential to the model's decision-making process, prioritizing them for potential replacement
  - Quick check question: How does word saliency differ from simple frequency-based word importance measures?

- Concept: Contextual embeddings and BERT architecture
  - Why needed here: Provides rich semantic representations that capture word meaning based on surrounding context, enabling more appropriate word substitutions
  - Quick check question: What is the key difference between BERT's bidirectional context understanding and traditional left-to-right language models?

- Concept: Cosine similarity for semantic comparison
  - Why needed here: Measures the semantic similarity between original and perturbed text to ensure the adversarial example remains coherent and retains original meaning
  - Quick check question: Why might cosine similarity between embeddings be preferred over simple word overlap metrics for measuring semantic similarity?

## Architecture Onboarding

- Component map: Saliency estimation module → Word candidate generation (PWWS) → BERT embedding contextualization → Cosine similarity filtering → Word substitution
- Critical path: Saliency estimation → BERT embedding generation → Cosine similarity calculation → Final word substitution
  - Bottleneck: BERT embedding generation for each candidate word can be computationally expensive
- Design tradeoffs:
  - More comprehensive contextual analysis (BERT) vs. computational efficiency
  - Stricter semantic constraints vs. attack success rate
  - Number of candidate words considered vs. runtime
- Failure signatures:
  - High word replacement rate with low attack success → Semantic constraints too strict
  - Low attack success with minimal word changes → Contextual embedding guidance ineffective
  - Excessive runtime → BERT embedding generation bottleneck
- First 3 experiments:
  1. Test saliency estimation alone vs. with BERT embeddings on a small dataset to measure impact on word replacement rate
  2. Compare cosine similarity threshold values (0.8, 0.85, 0.9) to find optimal balance between semantic preservation and attack success
  3. Measure attack success rate on a single model (BERT) with and without semantic consistency constraints to isolate their impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the MWSAA approach perform against text classification models with different architectural designs beyond BERT, ALBERT, and ROBERTa?
- Basis in paper: [explicit] The paper evaluates MWSAA against BERT, ALBERT, and ROBERTa models, suggesting potential for broader applicability.
- Why unresolved: The paper does not explore MWSAA's effectiveness on other types of models or architectures, limiting understanding of its versatility.
- What evidence would resolve it: Testing MWSAA against a wider variety of text classification models, such as GPT or Transformer-based models, would provide insights into its generalizability and performance across different architectures.

### Open Question 2
- Question: What is the impact of varying the semantic similarity metrics on the performance of MWSAA?
- Basis in paper: [explicit] The paper mentions the use of cosine similarity for semantic consistency but does not explore the effects of alternative metrics like word mover's distance or Jaccard similarity.
- Why unresolved: Without comparing different semantic similarity measures, it's unclear if cosine similarity is optimal or if other metrics could enhance MWSAA's performance.
- What evidence would resolve it: Conducting experiments with different semantic similarity metrics and comparing their impact on MWSAA's attack success rate and semantic coherence would clarify the best approach.

### Open Question 3
- Question: How does the MWSAA method scale with larger datasets or more complex language models?
- Basis in paper: [inferred] The paper evaluates MWSAA on three datasets and three language models, implying a need to test scalability and robustness.
- Why unresolved: The paper does not address the performance of MWSAA with larger datasets or more complex models, leaving questions about its scalability and robustness unanswered.
- What evidence would resolve it: Testing MWSAA on larger datasets and more complex language models would provide insights into its scalability and robustness, potentially revealing limitations or areas for improvement.

## Limitations

- The method's effectiveness depends on BERT's ability to capture domain-specific context, which may be limited by pre-training on general corpora
- Computational overhead of generating BERT embeddings for each candidate word substitution may limit scalability to large-scale applications
- The paper lacks ablation studies isolating the individual contributions of contextual embeddings versus semantic consistency constraints

## Confidence

*High Confidence:* The reported improvements in attack success rates (42.50% to 95.50%) and reduced word replacement rates (3.27% to 16.24%) compared to PWWS are well-supported by the experimental results presented.

*Medium Confidence:* The claim that cosine similarity effectively measures semantic coherence between original and adversarial examples assumes this metric aligns with human perception of meaning preservation.

*Low Confidence:* The paper does not provide ablation studies isolating the individual contributions of contextual embeddings versus semantic consistency constraints to the overall performance improvement.

## Next Checks

1. Conduct ablation studies to separately measure the impact of BERT contextual embeddings and cosine similarity constraints on attack success rates and word replacement efficiency.

2. Evaluate the approach on domain-specific text classification tasks (e.g., medical or legal documents) to assess generalization beyond the general domains tested (IMDB, AG News, SST).

3. Measure the computational overhead of BERT embedding generation and analyze whether the performance benefits justify the increased processing time compared to baseline PWWS.