---
ver: rpa2
title: Stabilizing Sharpness-aware Minimization Through A Simple Renormalization Strategy
arxiv_id: '2401.07250'
source_url: https://arxiv.org/abs/2401.07250
tags:
- learning
- training
- wasc
- ssam
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the instability of sharpness-aware minimization
  (SAM) during training, particularly its tendency to get trapped in saddle points,
  which can degrade performance. The authors propose a simple renormalization strategy,
  dubbed Stable SAM (SSAM), that rescales the gradient norm of the descent step to
  match the ascent step, improving training stability without introducing additional
  hyperparameters.
---

# Stabilizing Sharpness-aware Minimization Through A Simple Renormalization Strategy

## Quick Facts
- arXiv ID: 2401.07250
- Source URL: https://arxiv.org/abs/2401.07250
- Reference count: 13
- The paper proposes a simple renormalization strategy (SSAM) to stabilize sharpness-aware minimization (SAM) training by rescaling the gradient norm of the descent step to match the ascent step, improving training stability and generalization without introducing additional hyperparameters.

## Executive Summary
Sharpness-aware minimization (SAM) is a powerful optimization technique that improves generalization by minimizing the loss within a neighborhood ball. However, SAM can be unstable during training, particularly at high learning rates, and is prone to getting trapped in saddle points. This paper introduces a simple renormalization strategy, dubbed Stable SAM (SSAM), which rescales the gradient norm of the descent step to match the ascent step. Theoretical analysis shows that SSAM extends the regime of learning rates where SAM outperforms SGD and achieves better generalization. Empirically, SSAM demonstrates improved stability and comparable or superior performance to SAM across various tasks, including image classification on CIFAR and ImageNet datasets, and convergence on a quadratic loss function.

## Method Summary
SSAM modifies SAM by adding a renormalization step that scales the gradient norm of the descent step to match the ascent step. This is achieved by computing a renormalization factor γt = ∥∇FΩt(wt)∥2 / ∥∇FΩt(wasc t )∥2, where wt is the current weight, wasc t is the perturbed weight, and FΩt is the loss function. The descent gradient is then multiplied by γt before being used for the weight update. This simple modification improves training stability without introducing additional hyperparameters and can be easily integrated with existing SAM variants.

## Key Results
- SSAM improves training stability and reduces the risk of getting trapped in saddle points compared to SAM.
- SSAM achieves comparable or superior performance to SAM across various image classification tasks on CIFAR and ImageNet datasets.
- Theoretical analysis shows that SSAM extends the regime of learning rates where SAM outperforms SGD, enabling larger learning rates without instability.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SSAM improves stability by rescaling the descent gradient to match the ascent gradient norm, reducing step size fluctuations near saddle points.
- Mechanism: When the ascent gradient norm is larger than the descent gradient norm, SSAM downscales the descent step to avoid large fluctuations that can cause divergence or trapping at saddle points. When the ascent gradient norm is smaller, it upscales to maintain sufficient perturbation for escaping saddle points.
- Core assumption: The ratio of ascent to descent gradient norms reflects the local curvature and sharpness, and controlling this ratio stabilizes training.
- Evidence anchors:
  - [abstract] "so that the gradient norm of the descent step maintains the same as that of the ascent step."
  - [section 3] "When ∥∇FΩt(wasc t )∥2 is larger than ∥∇FΩt(wt)∥2, we downscale the norm of ∇FΩt(wasc t )..."
  - [corpus] Weak—no direct evidence from related papers, but the concept of norm matching aligns with broader optimization stability research.
- Break condition: If the renormalized gradient leads to vanishing updates or if the norm ratio is unstable across batches, SSAM could degrade performance.

### Mechanism 2
- Claim: SSAM extends the regime of learning rates where SAM outperforms SGD, enabling larger learning rates without instability.
- Mechanism: By preventing excessive gradient norm growth in the descent step, SSAM reduces the chance of divergence at high learning rates, allowing SAM-like benefits across a wider learning rate range.
- Core assumption: The instability of SAM at high learning rates is primarily due to gradient norm mismatch between ascent and descent steps.
- Evidence anchors:
  - [abstract] "... we also conduct a theoretical analysis of sharpness-aware training, revealing that compared to SGD, the effectiveness of SAM is only assured in a limited regime of learning rate."
  - [section 4.3] Theoretical analysis shows SSAM allows larger learning rates without violating uniform stability bounds.
  - [corpus] Weak—no direct evidence, but the theory aligns with known learning rate sensitivity in sharpness-aware methods.
- Break condition: If the learning rate exceeds the stability bound even with re-normalization, or if the ratio γt becomes unstable, the benefit may vanish.

### Mechanism 3
- Claim: SSAM consistently finds flatter minima with lower Hessian eigenvalues than SAM, improving generalization.
- Mechanism: By stabilizing training and reducing gradient norm mismatches, SSAM can navigate the loss landscape more smoothly toward flatter regions without getting trapped at sharp saddle points.
- Core assumption: Flatter minima correlate with lower dominant Hessian eigenvalues and better generalization, and SSAM's stability enables better navigation toward such regions.
- Evidence anchors:
  - [section 5.4] "we further compare the differences in the sharpness of the minima found by different optimizers, which can be described by the dominant eigenvalue of the Hessian of the loss function."
  - [section 5.4] "it also can be observed that SSAM achieves the lowest eigenvalue, suggesting that the renormalization strategy is indeed beneficial in escaping saddle points and finding flatter regions of the loss landscape."
  - [corpus] Weak—no direct evidence from related papers, but Hessian eigenvalue analysis is standard in sharpness-aware research.
- Break condition: If the minima found by SSAM are not flatter than those found by SAM, or if generalization does not improve, the claim fails.

## Foundational Learning

- Concept: Sharpness-aware minimization (SAM) and its motivation for improving generalization by minimizing loss within a neighborhood ball.
  - Why needed here: Understanding SAM is essential to grasp why SSAM was developed and how it modifies SAM.
  - Quick check question: What is the key difference between SAM and standard SGD in terms of loss minimization?

- Concept: Algorithmic stability and uniform stability in the context of generalization bounds.
  - Why needed here: The paper's theoretical analysis relies on uniform stability to bound generalization error for SAM and SSAM.
  - Quick check question: How does uniform stability relate to the expected generalization error of a learning algorithm?

- Concept: Convex optimization and smoothness/strong convexity assumptions used in theoretical analysis.
  - Why needed here: The proofs of stability and convergence bounds rely on these assumptions to derive growth rates and bounds.
  - Quick check question: What role does strong convexity play in ensuring the contraction of parameter distance in SAM/SSAM?

## Architecture Onboarding

- Component map: SAM -> SSAM (SAM with renormalization step)
- Critical path: Compute ascent gradient → compute descent gradient → renormalize descent gradient → update weights using base optimizer (e.g., SGD)
- Design tradeoffs: Simplicity and compatibility vs. potential slowdown if γt is consistently <1 (as the paper notes SSAM may slow convergence but find better minima)
- Failure signatures: Training instability at high learning rates, failure to converge, or worse generalization than SAM if γt is poorly estimated or if the base optimizer is incompatible
- First 3 experiments:
  1. Verify gradient norm matching on a simple quadratic loss with known saddle point.
  2. Compare training stability curves (loss vs. epoch) for SAM and SSAM at multiple learning rates on CIFAR-10.
  3. Measure Hessian eigenvalue spectra of minima found by SAM and SSAM on CIFAR-10 with ResNet-20.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the renormalization factor γt evolve during training, and what does this imply about the convergence dynamics of SSAM compared to SAM?
  - Basis in paper: [explicit] Figure 3 shows that γt decreases throughout training and is typically smaller than 1, but the paper does not fully explore the implications of this trend.
  - Why unresolved: While the paper notes this observation, it does not provide a theoretical or empirical analysis of how this evolution affects convergence speed, stability, or generalization performance.
  - What evidence would resolve it: A detailed study tracking γt across different architectures, datasets, and training regimes, coupled with analysis of its correlation with convergence metrics (e.g., loss, accuracy, and gradient norms).

- **Open Question 2**: To what extent does the renormalization strategy reshape the optimization trajectory or the parameter space explored by SSAM compared to SAM?
  - Basis in paper: [inferred] The paper suggests SSAM improves stability and generalization, but does not explicitly analyze how the optimization trajectory or parameter space exploration differs from SAM.
  - Why unresolved: The paper focuses on the theoretical and empirical benefits of SSAM but does not provide a detailed comparison of the optimization paths or the regions of parameter space explored by the two methods.
  - What evidence would resolve it: Visualization of optimization trajectories, analysis of parameter space coverage, and comparison of the basins of attraction explored by SAM and SSAM.

- **Open Question 3**: How does the renormalization strategy influence the adversarial robustness of models trained with SSAM?
  - Basis in paper: [explicit] The paper mentions that the influence of the renormalization strategy on adversarial robustness should be investigated, but does not provide any analysis or results.
  - Why unresolved: The paper acknowledges the potential relevance of adversarial robustness but does not explore it, leaving this as an open direction for future research.
  - What evidence would resolve it: Experiments comparing the adversarial robustness of models trained with SSAM, SAM, and other optimizers, using standard adversarial attack benchmarks.

## Limitations
- The theoretical analysis assumes smoothness and strong convexity, which may not hold in practice for deep networks.
- The effectiveness of SSAM depends on the stability of the gradient norm ratio γt, which is not extensively validated across diverse architectures.
- The claim that SSAM finds flatter minima is based on Hessian eigenvalue analysis, but the connection to generalization is not rigorously proven.

## Confidence
- Mechanism 1: Medium
- Mechanism 2: Medium
- Mechanism 3: Low
- Overall claim: Medium

## Next Checks
1. Analyze the stability of γt across different architectures and datasets.
2. Validate the generalization improvement on a broader range of tasks, including non-image domains.
3. Investigate the computational overhead of SSAM compared to SAM.