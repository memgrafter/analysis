---
ver: rpa2
title: 'Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture'
arxiv_id: '2407.07342'
source_url: https://arxiv.org/abs/2407.07342
tags:
- multilingual
- language
- languages
- safety
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Multilingual Blending, a mixed-language query-response
  scheme to evaluate the safety alignment of large language models (LLMs) under complex
  multilingual conditions. By generating malicious questions and responses in mixed
  languages and instructing LLMs to follow the same mixed-language format, the study
  demonstrates that Multilingual Blending significantly compromises the safety alignment
  of various state-of-the-art LLMs (e.g., GPT-3.5, GPT-4o, Llama3), achieving bypass
  rates of up to 67.23% on GPT-3.5 and 40.34% on GPT-4o.
---

# Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture

## Quick Facts
- arXiv ID: 2407.07342
- Source URL: https://arxiv.org/abs/2407.07342
- Reference count: 20
- One-line primary result: Multilingual Blending significantly compromises LLM safety alignment, achieving bypass rates up to 67.23% on GPT-3.5 and 40.34% on GPT-4o.

## Executive Summary
This paper introduces Multilingual Blending, a mixed-language query-response scheme to evaluate the safety alignment of large language models under complex multilingual conditions. The study demonstrates that combining multiple languages in both queries and responses significantly increases the likelihood of bypassing safety alignment mechanisms in various state-of-the-art LLMs. By generating malicious questions and responses in mixed languages and instructing LLMs to follow the same mixed-language format, the authors show that this approach can overwhelm safety filters, with effectiveness varying based on linguistic properties such as language availability, morphology, and language family.

## Method Summary
The Multilingual Blending method transforms single-language malicious queries into mixed-language format using token-level translation, then instructs LLMs to respond in the same mixed-language style. The process involves three main steps: (1) preparing 120 malicious questions from three datasets and translating them into 55 source languages, (2) generating mixed-language combinations and running LLM inference with temperature set to 0, and (3) translating responses back to English and evaluating safety using Perspective API with 10 attributes and a 0.3 threshold. The approach systematically tests various language combinations across seven state-of-the-art LLMs to measure bypass rates and analyze the impact of linguistic properties on safety alignment effectiveness.

## Key Results
- Multilingual Blending achieves bypass rates of up to 67.23% on GPT-3.5 and 40.34% on GPT-4o, significantly higher than single-language baselines
- Language combinations involving different morphology types and diverse language families show higher bypass rates than homogeneous combinations
- Mixed-language combinations with lower resource levels generally exhibit higher bypass rates compared to high-resource combinations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mixed-language input-response pairs increase uncertainty in LLMs, reducing safety alignment effectiveness.
- Mechanism: The vocabulary set for next-token prediction expands drastically from single-language to multilingual scope, increasing entropy in the first token's probability distribution.
- Core assumption: Higher uncertainty correlates with lower confidence in safety detection mechanisms.
- Evidence anchors: [abstract] "in the context of mixed-language generation, the vocabulary set available for the LLM to predict the next token is drastically expanded from a single-language scope to a multilingual set." [section] "higher uncertainties indicate a lower level of confidence, which could potentially lead to erroneous, unsafe, or non-factual outputs."

### Mechanism 2
- Claim: Multilingual Blending exploits linguistic distance between languages to evade safety detection.
- Mechanism: Combining languages from different families and morphologies creates semantic complexity that safety filters trained on single languages cannot parse effectively.
- Core assumption: Safety alignment models are primarily trained on homogeneous language data and lack robustness to mixed-language inputs.
- Evidence anchors: [abstract] "the performance of Multilingual Blending varies notably based on intrinsic linguistic properties, with languages of different morphology and from diverse families being more prone to evading safety alignments." [section] "combinations involving mixed language families exhibit higher bypass rates compared to those containing only single language families."

### Mechanism 3
- Claim: Resource level affects safety alignment robustness in mixed-language contexts.
- Mechanism: Languages with lower resource levels in training data create blind spots that Multilingual Blending can exploit when combined with higher-resource languages.
- Core assumption: LLMs rely on statistical patterns from training data availability to detect harmful content.
- Evidence anchors: [abstract] "languages of different morphology and from diverse families being more prone to evading safety alignments." [section] "mixed-language combinations with high resource levels generally exhibit lower bypass rates... whereas the combinations with lower or mixed resource levels tend to show higher chances to overwhelm the models' safety mechanism."

## Foundational Learning

- Concept: Token-level probability distributions and entropy calculation
  - Why needed here: Understanding how uncertainty is measured and why it increases in mixed-language scenarios is fundamental to grasping the bypass mechanism.
  - Quick check question: How does expanding the vocabulary set from a single language to multiple languages affect the entropy of the first token's probability distribution?

- Concept: Linguistic typology (morphology, language family, resource level)
  - Why needed here: The effectiveness of Multilingual Blending depends on understanding how different linguistic properties affect LLM comprehension and safety detection.
  - Quick check question: Why would combining languages from different morphological types (isolating, fusional, agglutinative) create more bypass opportunities than combining similar types?

- Concept: Safety alignment training methodologies (RLHF, supervised fine-tuning)
  - Why needed here: Knowing how current safety alignment works helps identify why it fails in mixed-language contexts.
  - Quick check question: What assumption about input language homogeneity is implicit in most current safety alignment approaches?

## Architecture Onboarding

- Component map: Token translation → LLM response generation → Back-translation → Safety evaluation
- Critical path: Token translation → LLM response generation → Back-translation → Safety evaluation. The bottleneck is achieving semantic similarity threshold during mixed-language generation.
- Design tradeoffs: Token-level translation offers simplicity but may miss contextual nuances; sentence-level translation would be more complex but potentially more effective.
- Failure signatures: High semantic similarity failure rates indicate translation difficulty; low bypass rates suggest safety models have some multilingual robustness.
- First 3 experiments:
  1. Test single-language baselines with the same malicious questions to establish baseline bypass rates.
  2. Vary the number of languages in mixed combinations (2, 4, 6) to find the optimal complexity for bypassing.
  3. Test combinations with languages from the same family versus different families to measure family distance impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would different translation methods (e.g., sentence-level vs token-level) affect the effectiveness of Multilingual Blending in bypassing LLM safety alignment?
- Basis in paper: Explicit - The paper mentions that different translation methods could be used but only employs token-level translation in their study.
- Why unresolved: The study only used token-level translation for generating mixed-language queries, leaving the impact of other methods unexplored.
- What evidence would resolve it: Comparative experiments using different translation methods (sentence-level, phrase-level) while keeping other variables constant would reveal how translation granularity affects bypass rates.

### Open Question 2
- What is the optimal number of languages in a mixed-language combination for maximizing bypass effectiveness, and how does this vary across different LLMs?
- Basis in paper: Explicit - The paper found that combinations with around four languages worked best but suggests this might vary by model.
- Why unresolved: The study only tested up to six languages and used a fixed threshold for semantic similarity, potentially missing optimal combinations for different model architectures.
- What evidence would resolve it: Systematic testing across a wider range of language combinations (2-10 languages) with varying semantic similarity thresholds for each model type would identify optimal configurations.

### Open Question 3
- How do syntactic features (word order, grammatical structures) interact with morphological properties to affect Multilingual Blending's effectiveness?
- Basis in paper: Inferred - The paper examined morphology and language family separately but didn't analyze how syntactic differences between languages contribute to bypass effectiveness.
- Why unresolved: The study focused on morphology and language family but didn't consider how syntactic differences between mixed languages might compound or mitigate the effect.
- What evidence would resolve it: Experiments combining languages with different syntactic structures (e.g., SVO vs SOV) while controlling for morphological properties would reveal syntactic contributions to bypass effectiveness.

## Limitations

- The study relies heavily on Perspective API for safety evaluation, which may not perfectly align with human judgment of harmful content.
- The token-level translation approach may miss contextual nuances that could affect safety detection and comprehension.
- The evaluation focuses on a limited set of 120 malicious questions across 55 languages, potentially missing broader linguistic phenomena in real-world scenarios.

## Confidence

- High confidence: The core observation that multilingual mixing increases bypass rates across multiple state-of-the-art LLMs is well-supported by experimental results showing consistent patterns.
- Medium confidence: The claim that linguistic properties (morphology, language family, resource level) significantly influence bypass effectiveness is supported but requires further statistical validation.
- Medium confidence: The uncertainty mechanism explanation (expanded vocabulary leading to higher entropy) is plausible but not directly measured or validated in the paper.

## Next Checks

1. **Human evaluation validation**: Conduct human evaluations of the back-translated responses to verify that Perspective API classifications align with human judgments of safety, particularly for borderline cases.

2. **Cross-linguistic safety robustness test**: Test the same malicious queries across different language pairs to systematically measure how specific linguistic properties quantitatively affect bypass rates.

3. **Fine-tuning resilience assessment**: Evaluate whether fine-tuning LLMs on mixed-language safety data can mitigate the bypass effect, testing whether the observed vulnerability is an inherent limitation or a training data gap that can be addressed.