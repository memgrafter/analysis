---
ver: rpa2
title: In-context Contrastive Learning for Event Causality Identification
arxiv_id: '2405.10512'
source_url: https://arxiv.org/abs/2405.10512
tags:
- event
- causal
- demonstrations
- learning
- iccl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an In-Context Contrastive Learning (ICCL) model
  for event causality identification. ICCL reformulates event pairs into in-context
  prompts with retrieved demonstrations, then applies contrastive learning on event
  pairs and demonstrations to enhance semantic distinction between causal and non-causal
  pairs.
---

# In-context Contrastive Learning for Event Causality Identification

## Quick Facts
- arXiv ID: 2405.10512
- Source URL: https://arxiv.org/abs/2405.10512
- Reference count: 18
- F1 scores: 70.4% (intra), 61.3% (cross) on EventStoryLine; 65.4% (intra) on Causal-TimeBank

## Executive Summary
This paper introduces In-Context Contrastive Learning (ICCL), a novel approach for event causality identification that reformulates event pairs into in-context prompts with retrieved demonstrations. The model applies contrastive learning on event pairs and demonstrations to enhance semantic distinction between causal and non-causal relations. ICCL achieves state-of-the-art performance on EventStoryLine and Causal-TimeBank corpora, outperforming previous prompt-based and graph-based methods with significant improvements in F1 scores across intra- and cross-dataset evaluations.

## Method Summary
ICCL reformulates event pairs into in-context prompts by concatenating query instances with retrieved demonstrations and their labels. The model encodes these prompts using a PLM and applies contrastive learning on event pair representations (computed as offset vectors) to pull together representations of event pairs with the same causal label while pushing apart those with different labels. The causality prediction is made by predicting virtual tokens (<causal> or <none>) for the [MASK] position between event mentions. The model is trained using a combination of contrastive loss and prediction loss with a balancing parameter β.

## Key Results
- Achieves 70.4% F1 (intra), 61.3% F1 (cross) on EventStoryLine corpus
- Achieves 65.4% F1 (intra) on Causal-TimeBank corpus
- Outperforms previous prompt-based and graph-based methods on both datasets
- Optimal performance achieved with 4 demonstrations (2 causal, 2 non-causal)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning between event pairs and demonstrations enhances the model's ability to distinguish causal from non-causal relations
- Mechanism: By optimizing the offset vectors (he1 - he2) through contrastive loss, the model learns to pull together representations of event pairs with the same causal label while pushing apart those with different labels
- Core assumption: The offset between event mention embeddings captures the relational semantics necessary for causality prediction
- Evidence anchors:
  - [abstract] "applies contrastive learning on event pairs and demonstrations to enhance semantic distinction between causal and non-causal pairs"
  - [section 3.3] "The in-context contrastive module optimizes the representation of event mention by simultaneously maximizing its agreement with positive demonstrations and minimizing with negative ones, via a contrastive loss"
  - [corpus] Weak - The corpus contains related papers but no direct evidence about this specific mechanism

### Mechanism 2
- Claim: In-context learning with demonstrations provides explicit guidance for label prediction
- Mechanism: By concatenating query instances with retrieved demonstrations and their labels, the model learns patterns from demonstrations that guide its prediction
- Core assumption: Including demonstrations with labels in the prompt provides sufficient context for the model to learn analogical reasoning
- Evidence anchors:
  - [abstract] "The in-context learning paradigm provides explicit guidance for label prediction in the prompt learning paradigm"
  - [section 3.2] "The in-context prompt template T(x) is constructed by concatenating the prediction prompt template Tp(q) and some analogy prompt templates Ta(dk)"
  - [corpus] Weak - No direct evidence in corpus about this specific in-context mechanism

### Mechanism 3
- Claim: Reformulating event pairs into cloze-style prompts enables direct prediction of causality labels
- Mechanism: The model predicts virtual tokens (<causal> or <none>) for the [MASK] position, transforming causality identification into a masked language modeling task
- Core assumption: The PLM's understanding of causal language patterns is sufficient to predict the correct virtual token
- Evidence anchors:
  - [abstract] "reformulates event pairs into in-context prompts with retrieved demonstrations"
  - [section 3.2] "A PLM-specific token [MASK] is inserted between two event mentions for relation prediction"
  - [section 3.4] "We add two virtual words into PLM's vocabulary dictionary as the answer space, viz. <causal> and <none>"
  - [corpus] Weak - No direct evidence in corpus about this specific reformulation mechanism

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: To distinguish between causal and non-causal event pairs by pulling together similar representations and pushing apart dissimilar ones
  - Quick check question: What is the purpose of the temperature parameter τ in the contrastive loss function?

- Concept: In-context learning
  - Why needed here: To provide explicit guidance for label prediction by including demonstrations with known labels in the prompt
  - Quick check question: How does the model determine which demonstrations are positive versus negative samples?

- Concept: Masked language modeling
  - Why needed here: To reformulate causality identification as a prediction task where the model fills in a [MASK] token with the appropriate causality label
  - Quick check question: What are the two virtual tokens added to the vocabulary for causality prediction?

## Architecture Onboarding

- Component map: Prompt Learning Module -> In-context Contrastive Module -> Causality Prediction Module
- Critical path:
  1. Input event pair and retrieve demonstrations
  2. Construct in-context prompt with query and demonstrations
  3. Encode prompt with PLM
  4. Compute contrastive loss on event pair offsets
  5. Compute prediction loss on [MASK] token
  6. Combine losses and update model parameters

- Design tradeoffs:
  - Number of demonstrations: More demonstrations provide better guidance but increase input length
  - Ratio of causal to non-causal demonstrations: Affects precision-recall tradeoff
  - Value of β: Balances importance of contrastive versus prediction loss

- Failure signatures:
  - Performance degrades with too many demonstrations due to input length limitations
  - Model becomes biased toward one label if demonstration ratio is imbalanced
  - Contrastive learning fails if event pair offsets don't capture causal semantics

- First 3 experiments:
  1. Test model performance with different numbers of demonstrations (1-4) to find optimal balance
  2. Compare performance of ICCL with and without contrastive module to validate its effectiveness
  3. Evaluate impact of different β values (0.1, 0.5, 1.0) on model performance to find optimal balance between losses

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several implicit research directions emerge from the work.

## Limitations
- Model effectiveness depends heavily on quality and diversity of retrieved demonstrations
- Fixed ratio of 2 causal to 2 non-causal demonstrations may not generalize across domains
- Demonstration retrieval strategy during training vs testing is not fully specified

## Confidence
- **High Confidence**: The model architecture and training procedure are well-specified, with clear descriptions of the prompt learning, contrastive learning, and causality prediction modules. The reported performance improvements over baseline methods are substantial and consistent across different evaluation settings.
- **Medium Confidence**: The mechanism of how contrastive learning specifically improves causality identification is theoretically sound but lacks direct empirical validation in the paper. The assumption that offset vectors between event mentions capture sufficient relational semantics for causality prediction needs further investigation.
- **Low Confidence**: The demonstration retrieval strategy during training versus testing phases is not fully specified, creating uncertainty about reproducibility. The paper also does not address potential biases introduced by the fixed demonstration ratio or how the model would perform with imbalanced demonstration sets.

## Next Checks
1. **Ablation Study on Contrastive Module**: Systematically evaluate ICCL performance with the contrastive module disabled versus enabled across different demonstration counts to quantify the exact contribution of contrastive learning to overall performance gains.

2. **Demonstration Retrieval Strategy Analysis**: Compare different demonstration retrieval methods (e.g., random sampling, similarity-based retrieval, diversity-based retrieval) to determine which approach yields optimal performance and assess sensitivity to retrieval strategy variations.

3. **Generalization Across Domains**: Test the model on additional event causality datasets from different domains (e.g., biomedical, financial) with varying causal/non-causal distributions to evaluate robustness and identify potential limitations in real-world applications.