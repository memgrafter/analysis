---
ver: rpa2
title: Variational Randomized Smoothing for Sample-Wise Adversarial Robustness
arxiv_id: '2407.11844'
source_url: https://arxiv.org/abs/2407.11844
tags:
- smoothing
- accuracy
- noise
- adversarial
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces variational randomized smoothing, a method
  that selects a suitable noise level for each input image using a neural network
  noise level selector. The approach addresses the challenge of optimizing noise levels
  in randomized smoothing to balance certified accuracy and radius.
---

# Variational Randomized Smoothing for Sample-Wise Adversarial Robustness

## Quick Facts
- arXiv ID: 2407.11844
- Source URL: https://arxiv.org/abs/2407.11844
- Reference count: 14
- Key outcome: Variational randomized smoothing achieves improved empirical robustness against adversarial attacks by selecting sample-wise noise levels for randomized smoothing, with experiments on CIFAR-10 showing better clean and robust accuracy compared to fixed-noise-level approaches.

## Executive Summary
This paper introduces variational randomized smoothing, a method that improves adversarial robustness by selecting a suitable noise level for each input image using a neural network noise level selector. The approach addresses the challenge of optimizing noise levels in randomized smoothing to balance certified accuracy and radius. By training the selector with stochastic regularization and conditional meta learning, the method achieves better empirical robustness against adversarial attacks compared to conventional fixed-noise-level approaches. Experiments on CIFAR-10 demonstrate improved clean and robust accuracy, particularly when using universal training for the base classifier. Additionally, median smoothing is applied to protect the selector from adversarial attacks, further enhancing robustness.

## Method Summary
The method trains a noise level selector h(x) that outputs a per-sample noise level σs for randomized smoothing, replacing the conventional fixed σs approach. The selector is trained using a variational framework with cross-entropy loss for clean accuracy and KL divergence regularization to encourage σs to follow a target distribution. Universal λ training samples λ from Uniform(0,1) during training, forcing the selector to handle the full range of regularization strengths, while conditional meta learning adds λ as an input to h for test-time flexibility. Median smoothing protects the selector from adversarial attacks by taking the median of multiple perturbed outputs. The dual smoothing pipeline first applies median smoothing to h, then uses the selected σs for randomized smoothing of the base classifier.

## Key Results
- Variational randomized smoothing with universal σa training achieves certified accuracy of 70.1% and radius of 0.69 at λ=0.2
- Median smoothing with Nh=100 samples and D=0.25 provides certified accuracy of 69.3% and radius of 0.70 against PGD attacks
- Clean accuracy improves from 78.1% (baseline) to 80.2% (variational with universal training) while maintaining comparable robust accuracy

## Why This Works (Mechanism)

### Mechanism 1
Sample-wise noise selection adapts smoothing to input difficulty, improving clean and robust accuracy. A neural network h(x) learns to predict a noise level σs per input image, replacing the fixed σs in conventional randomized smoothing. The selector is trained to balance clean accuracy (via cross-entropy loss) and robustness (via KL regularization encouraging σs to follow a target distribution). If the selector h is attacked and manipulated to pick inappropriate σs, the smoothing may degrade to or below baseline performance.

### Mechanism 2
Universal λ training and conditional meta learning make the selector adaptable at test time without retraining. During training, λ is sampled uniformly from [0,1], forcing h to learn to handle the full range of regularization strengths. Additionally, λ is added as an input to h so that at test time, the user can adjust the noise strength by specifying λ without retraining. If λ is not properly normalized or if the selector architecture cannot effectively use λ as a conditional input, performance may collapse.

### Mechanism 3
Dual smoothing (median smoothing on h + randomized smoothing on f) defends the selector against adversarial attacks. The selector h itself is protected by median smoothing: multiple perturbed versions of x are passed through h, and the median of the resulting σs values is used. This makes h more robust to small input perturbations, and the selected σs is then used for randomized smoothing of the base classifier f. If the perturbation budget D is too large or Nh (number of samples for median) is too small, the upper and lower bounds of h(x) may be too wide, reducing effectiveness.

## Foundational Learning

- **Randomized smoothing and certification theory**: Understanding the limitations of fixed noise levels (trade-off between accuracy and radius) is essential to grasp why per-sample noise selection helps. Quick check: What is the formula for the certified radius R in standard randomized smoothing, and what parameters does it depend on?

- **KL divergence and variational inference**: The selector is trained using KL divergence to encourage the distribution of selected noise levels to match a target Gaussian distribution, ensuring stability. Quick check: In the context of the selector training, what does the KL divergence term DKL(p||q) encourage regarding the distribution of σs?

- **Median smoothing for regression**: Median smoothing is used to protect the selector h from adversarial attacks; understanding its mechanism and bounds is crucial for analyzing the dual smoothing approach. Quick check: How does median smoothing provide upper and lower bounds on the selector output in the presence of adversarial perturbations?

## Architecture Onboarding

- **Component map**: Input image → Perturb with ε → Pass through h (with σa, λ) → Median over Nh samples → Use median σs to perturb input again → Pass through f with N samples → Majority vote → Output class

- **Critical path**: Input image → Perturb with ε → Pass through h (with σa, λ) → Median over Nh samples → Use median σs to perturb input again → Pass through f with N samples → Majority vote → Output class

- **Design tradeoffs**: Higher Nh for median smoothing increases robustness but also computational cost. Smaller λ favors clean accuracy but may reduce robustness; larger λ encourages robustness but may hurt accuracy. Universal σa training increases flexibility but may reduce peak performance at any single σa compared to fixed σa training.

- **Failure signatures**: Selector h always outputs extreme σs values (likely due to poor regularization or loss imbalance). Certified accuracy drops sharply when D increases (indicates median smoothing bounds are too loose). Clean accuracy drops significantly with dual smoothing (indicates median smoothing is too conservative).

- **First 3 experiments**:
  1. Train base classifier f with fixed σa and evaluate conventional randomized smoothing with swept σs to establish baseline certified accuracy/radius curves.
  2. Train selector h with fixed σa base model, no adversarial attack, evaluate clean and robust accuracy vs λ to find optimal operating point.
  3. Apply PGD attack to f only (weaker attack) and compare clean/robust accuracy of gv vs baseline g to verify selector benefits without h being attacked.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the performance of variational randomized smoothing scale with different architectures for the noise level selector h? The paper only presents results using one specific architecture for h, so the effects of different architectures are unknown.

- **Open Question 2**: What is the impact of the regularization factor λ on the performance of variational randomized smoothing, and how sensitive is the method to its choice? The paper only presents results using a limited set of λ values, and does not explore the sensitivity of the method to this parameter.

- **Open Question 3**: How does the performance of variational randomized smoothing compare to other state-of-the-art methods for adversarial robustness, such as adversarial training or denoising methods? The paper does not include experiments comparing the proposed method to other state-of-the-art techniques for adversarial robustness.

## Limitations

- The proposed method introduces significant complexity through the dual smoothing architecture and variational training framework, potentially limiting practical deployment.

- The paper lacks complete architectural specifications for the noise level selector, making exact reproduction challenging.

- The theoretical analysis of median smoothing bounds for continuous outputs remains heuristic rather than rigorous.

## Confidence

- **Variational selector improves empirical robustness**: Medium confidence - claims are supported by experimental results but lack ablation studies isolating the selector's contribution
- **Universal λ and σa training enhance flexibility**: Low confidence - theoretical motivation is provided but empirical benefits are not thoroughly quantified
- **Dual smoothing protects against adversarial attacks**: Medium confidence - theoretical bounds exist but their practical tightness under attack scenarios is unclear
- **Certified accuracy and radius improvements**: Medium confidence - experimental evidence shows improvements but comparison methodology could be more comprehensive

## Next Checks

1. **Ablation study isolation**: Evaluate the base classifier with optimal fixed noise level versus the selector with fixed λ to quantify the selector's individual contribution to robustness improvements.

2. **Median smoothing parameter sensitivity**: Systematically vary Nh (number of median samples) and D (perturbation budget) to determine the tradeoff between robustness protection and performance degradation.

3. **Theoretical bound verification**: Conduct experiments measuring the empirical gap between certified radii and actual attack success rates across different D values to validate the tightness of the median smoothing bounds.