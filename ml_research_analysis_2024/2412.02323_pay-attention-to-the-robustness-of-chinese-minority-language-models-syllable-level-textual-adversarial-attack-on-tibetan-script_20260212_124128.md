---
ver: rpa2
title: Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level
  Textual Adversarial Attack on Tibetan Script
arxiv_id: '2412.02323'
source_url: https://arxiv.org/abs/2412.02323
tags:
- adversarial
- attack
- chinese
- textual
- minority
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TSAttacker, the first Tibetan syllable-level
  black-box textual adversarial attack method. It leverages syllable cosine distance
  to identify candidate substitution syllables and a scoring mechanism based on word
  saliency to determine substitution order.
---

# Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level Textual Adversarial Attack on Tibetan Script

## Quick Facts
- arXiv ID: 2412.02323
- Source URL: https://arxiv.org/abs/2412.02323
- Reference count: 34
- Key outcome: TSAttacker achieves up to 76% attack success rates on Tibetan language models while maintaining high-quality adversarial samples with low Levenshtein distances.

## Executive Summary
This paper introduces TSAttacker, the first Tibetan syllable-level black-box textual adversarial attack method. It leverages syllable cosine distance to identify candidate substitution syllables and a scoring mechanism based on word saliency to determine substitution order. Experiments on six models derived from two versions of the CINO multilingual PLM for three downstream tasks demonstrate TSAttacker's effectiveness, achieving attack success rates up to 76% while maintaining high-quality adversarial samples with low Levenshtein distances. The results reveal significant vulnerabilities in Chinese minority language models, highlighting the need for improved robustness in NLP systems for these languages.

## Method Summary
TSAttacker is a black-box textual adversarial attack that operates at the Tibetan syllable level. The method uses syllable embeddings from fastText to identify candidate substitutions based on cosine similarity, with a maximum threshold of 0.2929. It employs a scoring mechanism that combines word saliency with probability impact to determine the order of syllable substitutions. The attack iteratively queries the victim model to find substitutions that maximize prediction probability drops, without access to gradients or internal representations. The approach exploits the gap between Tibetan's character-based and word-based linguistic structures by targeting syllables as intermediate units.

## Key Results
- TSAttacker achieves attack success rates up to 76% on Chinese minority language models
- Maintains high-quality adversarial samples with Levenshtein distances indicating minimal perturbations
- Demonstrates significant vulnerabilities in Chinese minority language models, particularly Tibetan NLP systems

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Syllable-level perturbations exploit the gap between Tibetan's character-based and word-based linguistic structures.
- **Mechanism:** The attack substitutes Tibetan syllables with semantically similar syllables based on cosine similarity of their embeddings, causing misclassification while maintaining minimal visual/semantic change.
- **Core assumption:** Tibetan syllable embeddings in the fastText space adequately capture semantic similarity for adversarial substitution.
- **Evidence anchors:** [abstract] "leverages syllable cosine distance to identify candidate substitution syllables"; [section 3.2.1] "we cleaned the result and obtained 7,652 Tibetan syllable embeddings basically containing all commonly used syllables"
- **Break condition:** If syllable embeddings are not semantically meaningful, the substitutions will fail to fool the model.

### Mechanism 2
- **Claim:** The scoring mechanism prioritizes substitutions that maximize both saliency and probability impact.
- **Mechanism:** Syllable saliency (change in prediction probability when syllable is replaced with <UNK>) is weighted by the maximum probability drop achievable by substituting that syllable, determining substitution order.
- **Core assumption:** Syllable saliency correlates with the model's reliance on that syllable for prediction, and this correlation is consistent across models.
- **Evidence anchors:** [section 3.2.2] "We incorporate the scoring formula in the probability weighted word saliency algorithm... to determine the substitution order of syllables"; [abstract] "a scoring mechanism based on word saliency to determine substitution order"
- **Break condition:** If the saliency metric doesn't correlate with importance for the model, the ordering will be suboptimal.

### Mechanism 3
- **Claim:** Black-box setting forces the attack to use only input-output queries, making it practical against real-world models.
- **Mechanism:** The attack iteratively substitutes syllables and queries the model to find substitutions that maximize probability drop, without access to gradients or internal representations.
- **Core assumption:** The victim model's predictions are stable enough across queries to enable effective attack iteration.
- **Evidence anchors:** [abstract] "black-box textual adversarial attack called TSAttacker"; [section 3.2.1] Iterative substitution and probability calculation without mentioning gradient access
- **Break condition:** If the model has strong defenses against repeated queries (e.g., rate limiting, stochastic predictions), the attack becomes impractical.

## Foundational Learning

- **Concept:** Tibetan script structure and syllable composition
  - **Why needed here:** The attack operates at the syllable level, so understanding that Tibetan syllables are intermediate between characters and words is crucial for grasping the attack's granularity choice.
  - **Quick check question:** How does Tibetan syllable structure differ from Chinese characters and English words in terms of linguistic granularity?

- **Concept:** Cosine similarity in embedding space
  - **Why needed here:** The attack uses cosine distance between syllable embeddings to find substitution candidates, so understanding how this metric captures semantic similarity is essential.
  - **Quick check question:** What does a cosine distance of 0.2929 represent in terms of angle between syllable embeddings, and why is this threshold chosen?

- **Concept:** Word saliency and its application to syllables
  - **Why needed here:** The attack adapts word saliency (used in English attacks) to syllables, so understanding how saliency measures feature importance for model predictions is key.
  - **Quick check question:** How does replacing a syllable with <UNK> help measure its importance to the model's prediction?

## Architecture Onboarding

- **Component map:** Syllable embedding database -> Candidate generation module -> Scoring engine -> Black-box query interface -> Substitution orchestrator
- **Critical path:** Syllable → Candidate generation → Scoring → Query → Substitution → Check success
- **Design tradeoffs:**
  - Higher dmax increases attack success but reduces semantic similarity of substitutions
  - Larger candidate sets improve substitution quality but increase computation time
  - Syllable-level granularity provides finer control than word-level but more candidates than character-level
- **Failure signatures:**
  - High Levenshtein distance indicates poor-quality substitutions
  - Low attack success rate suggests embeddings don't capture semantic similarity
  - Inconsistent results across models indicate attack doesn't generalize well
- **First 3 experiments:**
  1. Vary dmax (0.1340, 0.2929, 0.5) and measure impact on ADV, ASR, and LD
  2. Compare syllable-level attack vs. character-level and word-level attacks on same models
  3. Test attack effectiveness across different Tibetan datasets and model architectures

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the effectiveness of TSAttacker vary when using different syllable embedding sources beyond the fastText-trained embeddings?
- **Basis in paper:** The paper relies on pre-trained Tibetan syllable embeddings from fastText, but acknowledges that the training dataset contained unwanted vectors. The authors cleaned the embeddings but did not explore alternative embedding sources.
- **Why unresolved:** The paper does not compare the performance of TSAttacker using different embedding models or training datasets, leaving open whether alternative embeddings could improve attack effectiveness or generate higher-quality adversarial samples.
- **What evidence would resolve it:** Experiments comparing TSAttacker's performance using syllable embeddings from different sources (e.g., GloVe, custom-trained embeddings on larger Tibetan corpora) while measuring attack success rates and Levenshtein distances.

### Open Question 2
- **Question:** Would incorporating linguistic knowledge about Tibetan syllable structure and phonotactics improve the quality and effectiveness of adversarial attacks?
- **Basis in paper:** The paper treats syllables as discrete units without leveraging linguistic knowledge about Tibetan phonology. The substitution relies purely on cosine distance without considering whether substituted syllables form valid or meaningful words in context.
- **Why unresolved:** The current approach may generate substitutions that, while semantically similar at the syllable level, create nonsensical or invalid word combinations that could be easily detected by human readers or more sophisticated models.
- **What evidence would resolve it:** Comparative experiments showing whether attacks that incorporate linguistic constraints (such as valid syllable combinations, semantic coherence, or phonetic similarity) produce more effective or less detectable adversarial examples than the current syllable-level approach.

### Open Question 3
- **Question:** How do Tibetan models trained on different corpus sizes and domain-specific data compare in their robustness to TSAttacker?
- **Basis in paper:** The paper evaluates only CINO models fine-tuned on specific datasets but does not explore how model robustness varies with training data quantity, diversity, or domain specificity. The discussion mentions that Chinese minority NLP models have lower robustness partly due to smaller corpora.
- **Why unresolved:** Without testing models trained on varying amounts and types of data, it remains unclear whether data augmentation, larger training sets, or domain-specific pretraining would significantly improve robustness against syllable-level attacks.
- **What evidence would resolve it:** Experiments comparing TSAttacker's effectiveness on models trained with different corpus sizes, from different domains (news, social media, literature), or with data augmentation techniques, measuring changes in attack success rates and accuracy drops.

## Limitations
- The semantic quality of syllable substitutions is asserted but not directly validated through human evaluation
- The choice of attack parameters (particularly dmax = 0.2929) appears arbitrary rather than empirically optimized
- Limited model diversity in evaluation restricts generalizability of attack effectiveness claims

## Confidence
- **High Confidence:** The attack framework architecture and implementation details are clearly specified, and the experimental results (ASR, ADV, LD metrics) are reproducible given the described methodology.
- **Medium Confidence:** The effectiveness of syllable-level attacks on Chinese minority language models is demonstrated, but the generalizability to other Tibetan models and tasks remains uncertain due to limited model diversity.
- **Low Confidence:** The semantic quality of syllable substitutions is asserted but not directly validated, and the choice of attack parameters appears arbitrary rather than empirically optimized.

## Next Checks
1. **Embedding Quality Validation:** Conduct human evaluation of syllable substitutions to verify semantic similarity and assess whether cosine distance correlates with human-perceived similarity in Tibetan.
2. **Parameter Sensitivity Analysis:** Systematically vary dmax and evaluate its impact on attack success rates, Levenshtein distances, and semantic quality to determine optimal thresholds.
3. **Cross-Model Generalization:** Test TSAttacker against additional Tibetan language models (different architectures, training datasets) to evaluate attack robustness and identify model-specific vulnerabilities.