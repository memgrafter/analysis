---
ver: rpa2
title: Graph-Convolutional Autoencoder Ensembles for the Humanities, Illustrated with
  a Study of the American Slave Trade
arxiv_id: '2401.00824'
source_url: https://arxiv.org/abs/2401.00824
tags:
- autoencoder
- slave
- trade
- learning
- humanities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Starcoder, a framework for graph-convolutional
  autoencoder ensembles designed to make deep learning accessible to humanities scholars.
  The key innovation is composing neural sub-architectures into models isomorphic
  to scholarly domains, maintaining interpretability while enabling collaboration
  between computational and traditional researchers.
---

# Graph-Convolutional Autoencoder Ensembles for the Humanities, Illustrated with a Study of the American Slave Trade

## Quick Facts
- arXiv ID: 2401.00824
- Source URL: https://arxiv.org/abs/2401.00824
- Reference count: 17
- Primary result: Framework automatically generates graph-convolutional autoencoder ensembles from domain schemas for humanities research

## Executive Summary
This paper introduces Starcoder, a framework that automatically generates graph-convolutional autoencoder ensembles from entity-relationship models and associated data. The key innovation is composing neural sub-architectures into models isomorphic to scholarly domains, maintaining interpretability while enabling collaboration between computational and traditional researchers. The framework was applied to study the American post-Atlantic slave trade, successfully reconstructing historical patterns of enslaved people's movements and identifying evidence of leasing practices and sexual exploitation.

## Method Summary
Starcoder takes entity-relationship model schemas in JSON-LD format along with primary source data to automatically generate and train graph-convolutional autoencoder ensembles. The framework parses the schema to identify entity types, properties, and relationships, then composes appropriate neural sub-architectures for each component. Autoencoders are stacked at multiple depths with graph-convolutional connections between related entities to allow information flow. The framework includes automatic generation of exploration interfaces and supports various data formats including CSV, XML, and SQL.

## Key Results
- Successfully reconstructed historical patterns of enslaved people's movements in the American post-Atlantic slave trade
- Identified evidence of leasing practices and sexual exploitation through analysis of reconstructed representations
- Demonstrated framework's effectiveness across two dozen studies in various humanities fields with different data types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-convolutional autoencoders capture relational structure between entities better than independent autoencoders
- Mechanism: The framework stacks autoencoders at multiple depths, where each depth incorporates information from related entities through graph-convolutional operations, allowing information to flow between connected entities
- Core assumption: Relationship structure between entities contains meaningful information that improves representation learning
- Evidence anchors:
  - [abstract]: "combining autoencoding with graph-convolutional mechanisms to capture relational structure"
  - [section 3.5]: "To connect these models and allow information to flow between related entities, we stack additional entity-autoencoders up to depth D"
  - [corpus]: Weak - the corpus contains related work on graph-convolutional autoencoders but lacks direct comparison studies
- Break condition: If relationship structure is random or irrelevant to the task, graph-convolutional mechanisms provide no benefit over independent autoencoders

### Mechanism 2
- Claim: The schema-driven model generation creates interpretable models that bridge computational and traditional research
- Mechanism: By composing neural sub-architectures to produce a model isomorphic to a humanistic domain, the framework maintains interpretability while providing function signatures for each sub-architectural choice
- Core assumption: Humanistic domains can be effectively represented as entity-relationship models that map to neural architectures
- Evidence anchors:
  - [abstract]: "By composing sub-architectures to produce a model isomorphic to a humanistic domain we maintain interpretability"
  - [section 2]: "The linchpin of our approach is a formal specification (schema) of the traditional scholar's domain of interest as an entity-relationship model"
  - [corpus]: Weak - while related work exists on knowledge graphs and representation learning, there's limited evidence on schema-driven interpretability in humanities contexts
- Break condition: If humanistic domains cannot be adequately captured by entity-relationship models, the isomorphism breaks and interpretability is lost

### Mechanism 3
- Claim: The framework enables low-barrier entry to deep learning for humanities scholars
- Mechanism: Automatic generation of models from domain schemas and associated data, plus automatic creation of exploration interfaces, allows scholars to work with deep learning without requiring computational expertise
- Core assumption: Humanities scholars can effectively use and interpret automatically generated interfaces and models
- Evidence anchors:
  - [abstract]: "designed to facilitate deep learning for scholarship in the humanities" and "Low-barrier entry to modern deep learning for bespoke humanistic domains"
  - [section 2]: "Starcoder has algorithms for working with several common formats" and "This flexibility allows, for example, tight control over parameter counts"
  - [corpus]: Weak - the corpus contains related work on human-in-the-loop machine learning but lacks direct evidence of humanities scholar adoption
- Break condition: If scholars cannot effectively use or interpret the generated interfaces, or if the automatic generation produces unusable results

## Foundational Learning

- Concept: Entity-relationship models and JSON-LD schema format
  - Why needed here: The framework uses domain schemas as the foundation for automatic model generation, so understanding how to represent domains as entity-relationship models is crucial
  - Quick check question: What are the three main components of an entity-relationship model, and how are they represented in JSON-LD?

- Concept: Graph-convolutional neural networks
  - Why needed here: The framework uses graph-convolutional mechanisms to capture relational structure, so understanding how GCNs work is essential
  - Quick check question: How do graph-convolutional layers differ from standard convolutional layers, and what information do they incorporate?

- Concept: Autoencoder architecture and training
  - Why needed here: The framework uses autoencoders as the core building block, so understanding autoencoder basics is necessary
  - Quick check question: What is the primary objective function for training autoencoders, and how does it differ from supervised learning?

## Architecture Onboarding

- Component map: Schema parsing -> Model generation -> Training -> Interface generation
- Critical path: Schema parsing (defines model structure), autoencoding mechanism (learns representations), graph-convolutional mechanism (incorporates relationships)
- Design tradeoffs: Depth vs. signal propagation (deeper models capture more complex relationships but suffer from vanishing gradients), property encoder/decoder choices (affect representation quality), batching policies (affect training efficiency and relationship modeling)
- Failure signatures: Vanishing gradients at higher depths (model stops learning), poor reconstruction quality (autoencoder isn't learning effectively), poor relationship modeling (graph-convolutional mechanism isn't incorporating relationship information)
- First 3 experiments:
  1. Test independent autoencoders on a simple domain without relationships to verify basic functionality
  2. Add graph-convolutional connections to the same domain and verify improved performance on relationship-aware tasks
  3. Increase model depth incrementally and monitor for vanishing gradient issues

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are normalizing flows and variational autoencoders compared to vanilla autoencoders for regularizing the latent representation space in Starcoder?
- Basis in paper: [explicit] The paper mentions ongoing work to explore regularizing the latent representation space beyond naive autoencoding using variational autoencoders and normalizing flows.
- Why unresolved: The paper has not yet implemented or tested these regularization methods, only mentioned them as future directions.
- What evidence would resolve it: Implementing and testing Starcoder models with VAEs and normalizing flows, then comparing their performance on reconstruction accuracy and downstream tasks to the current vanilla autoencoder approach.

### Open Question 2
- Question: What is the optimal depth for graph-convolutional autoencoders in Starcoder when dealing with highly structured vs less structured data?
- Basis in paper: [explicit] The paper shows that increasing depth from 0 to 1 improves performance on an arithmetic expression task, but performance degrades at depth 3 due to vanishing gradients. However, it doesn't systematically explore the optimal depth for different types of data.
- Why unresolved: The paper only provides limited experiments on a synthetic dataset and doesn't investigate how optimal depth varies across different domains and data structures.
- What evidence would resolve it: Running extensive experiments on diverse real-world datasets with varying structures (highly connected, hierarchical, sparse) to determine the optimal depth for each case and identify patterns or guidelines.

### Open Question 3
- Question: How does the performance of Starcoder compare to other graph neural network approaches on knowledge base completion tasks?
- Basis in paper: [inferred] The paper mentions that Starcoder's task is similar to representation learning over knowledge bases, but doesn't provide direct comparisons to other methods.
- Why unresolved: The paper focuses on Starcoder's unique approach and applications but doesn't benchmark against existing graph neural network methods on standard knowledge base completion datasets.
- What evidence would resolve it: Conducting experiments comparing Starcoder to state-of-the-art graph neural networks on standard knowledge base completion benchmarks like FB15k-237 or WN18RR.

## Limitations

- The framework's generalizability to diverse humanities domains remains untested beyond demonstrated examples
- The automatic generation of exploration interfaces lacks detailed evaluation of their usability by humanities scholars without computational backgrounds
- The technical contribution of combining autoencoding with graph-convolutional mechanisms needs empirical validation against baselines

## Confidence

- **High Confidence**: The core claim that entity-relationship models can be translated into neural architectures is well-supported by the framework's design and implementation
- **Medium Confidence**: The claim that this approach facilitates collaboration between computational and traditional researchers is plausible but lacks direct evidence from humanities scholars using the framework
- **Low Confidence**: The automatic generation of usable exploration interfaces for humanities scholars is the weakest claim, relying heavily on assumptions about usability without extensive user testing

## Next Checks

1. Conduct a user study with humanities scholars to evaluate the usability and interpretability of automatically generated exploration interfaces, comparing them against traditional analysis methods
2. Perform ablation studies comparing graph-convolutional autoencoders against independent autoencoders and pure graph-convolutional networks on tasks that require both relationship modeling and reconstruction
3. Systematically evaluate the framework's performance across domains with varying complexity to characterize its scalability and identify failure modes