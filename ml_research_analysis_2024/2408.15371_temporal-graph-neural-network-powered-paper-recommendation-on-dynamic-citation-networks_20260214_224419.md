---
ver: rpa2
title: Temporal Graph Neural Network-Powered Paper Recommendation on Dynamic Citation
  Networks
arxiv_id: '2408.15371'
source_url: https://arxiv.org/abs/2408.15371
tags:
- graph
- citation
- node
- networks
- temporal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of paper recommendation in dynamic
  citation networks by introducing a temporal dimension to paper recommendation strategies.
  The core idea is to continuously update a paper's embedding when new citation relationships
  appear, enhancing its relevance for future recommendations.
---

# Temporal Graph Neural Network-Powered Paper Recommendation on Dynamic Citation Networks
## Quick Facts
- arXiv ID: 2408.15371
- Source URL: https://arxiv.org/abs/2408.15371
- Reference count: 28
- Introduces temporal dimension to paper recommendation using TGN for continuous embedding updates

## Executive Summary
This paper addresses the challenge of paper recommendation in dynamic citation networks by introducing a temporal dimension to paper recommendation strategies. The core idea is to continuously update a paper's embedding when new citation relationships appear, enhancing its relevance for future recommendations. A Temporal Graph Neural Network (TGN) is employed to update embeddings of related papers whenever a citation relationship is added to the literature. The proposed approach demonstrates effectiveness in paper recommendation accuracy compared to state-of-the-art approaches, as shown in experiments on an open citation network dataset including 313,278 articles from PaperWithCode.

## Method Summary
The approach leverages TGN to update paper embeddings dynamically as new citation relationships emerge in the citation network. When a new citation is added, the TGN updates embeddings of related papers based on the evolving citation patterns. This continuous updating mechanism allows the model to capture how researchers' perceptions and interest in papers change over time, rather than relying on static embeddings. The TGN-based model learns temporal patterns in how people's views of papers evolve, aiming to guide paper recommendations more precisely based on these dynamics.

## Key Results
- TGN-based approach shows improved paper recommendation accuracy compared to state-of-the-art methods
- Effective performance demonstrated on open citation network dataset with 313,278 articles from PaperWithCode
- Continuous embedding updates enable more precise recommendations by capturing evolving citation patterns

## Why This Works (Mechanism)
The TGN-based approach works by continuously updating paper embeddings as new citation relationships appear in the network. This temporal updating mechanism captures the dynamic nature of how research papers gain relevance and importance over time. By learning patterns in how citations evolve and how researchers' perceptions change, the model can recommend papers that are not only relevant based on current citations but also anticipate future relevance based on temporal citation patterns.

## Foundational Learning
- **Temporal Graph Neural Networks**: Why needed - To capture dynamic changes in citation networks over time. Quick check - Verify TGN implementation correctly handles temporal sequences of citation events.
- **Citation network dynamics**: Why needed - Understanding how paper relevance evolves through citations. Quick check - Analyze citation pattern distributions across different research domains.
- **Paper embedding updates**: Why needed - To maintain current relevance scores as citation patterns change. Quick check - Measure embedding drift over time for papers with varying citation frequencies.
- **Recommendation accuracy metrics**: Why needed - To evaluate how well temporal updates improve recommendations. Quick check - Compare precision@k and recall@k metrics against baseline methods.
- **Graph neural network fundamentals**: Why needed - Core mechanism for learning paper representations. Quick check - Validate GNN message passing correctly aggregates neighborhood information.
- **Temporal pattern learning**: Why needed - To identify how citation behavior changes over time. Quick check - Test model's ability to predict future citation trends from historical patterns.

## Architecture Onboarding
Component Map: Citation Events -> TGN Layer -> Paper Embeddings -> Recommendation Engine
Critical Path: New citation event detection → TGN embedding update → Recommendation recalculation
Design Tradeoffs: Real-time updates vs. computational cost, temporal granularity vs. model complexity
Failure Signatures: Outdated embeddings for papers with burst citations, recommendation lag for emerging topics
First Experiments:
1. Validate TGN correctly updates embeddings for single citation addition
2. Test recommendation quality improvement for papers with recent citation bursts
3. Measure embedding stability for papers with stable citation patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes citation patterns follow predictable temporal dynamics that may not hold across all research fields
- Effectiveness depends on citation frequency, potentially limiting performance for papers in slower-moving disciplines
- Evaluation on single dataset (PaperWithCode) raises questions about generalizability to other citation networks

## Confidence
- Technical implementation: High
- Experimental methodology: High
- Comparative performance claims: Medium
- Generalizability across domains: Low

## Next Checks
1. Test the TGN-based approach on multiple citation datasets from different scientific domains to assess generalizability across fields with varying citation patterns and temporal dynamics.

2. Conduct ablation studies to quantify the specific contribution of temporal updates versus static GNN embeddings, and determine optimal update frequencies for different citation patterns.

3. Evaluate recommendation performance for papers at different stages of their citation lifecycle (pre-publication, early-stage, established) to understand how well the temporal approach handles papers with varying citation histories.