---
ver: rpa2
title: Optimizing Large Language Models for Dynamic Constraints through Human-in-the-Loop
  Discriminators
arxiv_id: '2410.15163'
source_url: https://arxiv.org/abs/2410.15163
tags:
- constraints
- agent
- performance
- discriminator
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework to improve large language models'
  performance on constraint-based problems through a concept-to-optimization approach.
  The method builds initial constraints from system interfaces and iteratively refines
  performance using human and LLM-based discriminators to identify critical cases.
---

# Optimizing Large Language Models for Dynamic Constraints through Human-in-the-Loop Discriminators

## Quick Facts
- **arXiv ID**: 2410.15163
- **Source URL**: https://arxiv.org/abs/2410.15163
- **Reference count**: 23
- **Primary result**: 7.78% pass rate with human discriminators (40.2% improvement over baseline) and 6.11% with LLM discriminators after one iteration in travel planning task

## Executive Summary
This paper introduces a framework to improve large language models' performance on constraint-based problems through a concept-to-optimization approach. The method builds initial constraints from system interfaces and iteratively refines performance using human and LLM-based discriminators to identify critical cases. Applied to travel planning, the framework achieved a 7.78% pass rate with human discriminators (40.2% improvement over baseline) and 6.11% with LLM discriminators after one iteration. The human discriminator outperformed the LLM-based discriminator in ranking plans for optimization, demonstrating the value of human-in-the-loop refinement. The work lays a foundation for applying this approach to other constraint-based domains and future model fine-tuning.

## Method Summary
The framework employs a two-phase learning approach: first extracting constraints from system interfaces (explicit and implicit) to build a conceptual understanding, then using discriminator agents to iteratively optimize performance on critical cases. The planning agent processes user queries and generates travel plans, while discriminators (both human and LLM-based) evaluate plan quality and identify the most challenging cases for refinement. The system focuses on critical constraint violations rather than broad retraining, making it more data-efficient than traditional approaches.

## Key Results
- Human discriminators achieved 7.78% pass rate, outperforming LLM discriminators (6.11%) and baseline (5.55%)
- One iteration of optimization produced a 40.2% improvement over baseline performance
- Human discriminators outperformed LLM discriminators in ranking plans for optimization
- Framework demonstrated effectiveness in travel planning with moderate constraints

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework improves LLM performance by iteratively identifying and focusing on critical constraint violations rather than retraining on all cases.
- Mechanism: The framework uses discriminator agents (human and LLM) to rank data cases by difficulty and selectively incorporate only the most challenging cases into the prompt refinement process, creating a targeted optimization loop.
- Core assumption: Focusing on critical constraint violations is more data-efficient than broad retraining or fine-tuning approaches.
- Evidence anchors:
  - [abstract] "The human discriminator outperformed the LLM-based discriminator in ranking plans for optimization, demonstrating the value of human-in-the-loop refinement."
  - [section 3.2] "Both discriminators review the data cases the initial agent processes and identify critical cases that can improve planning performance."
  - [corpus] Weak - no direct corpus evidence supporting this mechanism specifically
- Break condition: If discriminators fail to accurately identify constraint violations or if constraint violations are too diverse to benefit from targeted optimization.

### Mechanism 2
- Claim: The framework's two-phase approach (concept-to-optimization) mimics human cognitive processes for learning constraints, making it more efficient than traditional methods.
- Mechanism: The initial phase extracts constraints from system interfaces (explicit and implicit) to build a conceptual understanding, while the optimization phase uses discriminators to refine performance on critical cases, mirroring how humans first grasp overall rules then learn exceptions.
- Core assumption: LLMs can effectively extract and formalize constraints from system interfaces in a way that captures the essential constraint concepts.
- Evidence anchors:
  - [abstract] "The essence of this cognitive process lies in distilling rules and identifying minimal cases for refinement rather than depending on the inefficient generation of large datasets"
  - [section 3.1] "To enable LLM-based agents to comprehend application constraints and plan effectively, it is essential to extract and formalize these constraints in natural language (NL) format."
  - [corpus] Weak - no direct corpus evidence supporting this cognitive mimicry mechanism
- Break condition: If constraint extraction from interfaces is incomplete or if LLMs cannot effectively formalize constraints in NL format.

### Mechanism 3
- Claim: The hybrid discriminator model (human + LLM) balances the strengths of human expertise and automated scalability to identify critical cases effectively.
- Mechanism: Human discriminators provide nuanced understanding of application constraints and accurate difficulty ranking, while LLM discriminators offer scalability and can handle complex reasoning tasks, creating a complementary system for identifying critical cases.
- Core assumption: Human discriminators can effectively define metrics for measuring difficulty levels of data cases and provide reference ranking mechanisms.
- Evidence anchors:
  - [abstract] "Given the dynamic nature of system constraints, we do not rely solely on LLMs to evaluate data cases. Instead, we propose leveraging human expertise to define metrics for measuring the difficulty levels of data cases"
  - [section 4.2.1] "The task of the discriminators is to determine an ordering of those 10 plans that corresponded to how useful each plan would be for improving the performance"
  - [section 5.1] "human discriminator quality is still the top tier" while LLM discriminators offer "distinct advantages in complex reasoning tasks"
- Break condition: If human expertise becomes unavailable or if LLM discriminators cannot provide sufficient accuracy to complement human judgment.

## Foundational Learning

- Concept: Constraint classification (explicit vs implicit)
  - Why needed here: Understanding the difference between explicit constraints (directly documented) and implicit constraints (inferred from system behavior) is crucial for effective constraint extraction and formalization.
  - Quick check question: Can you identify whether a given constraint is explicit or implicit based on its source and nature?

- Concept: Discriminator-based ranking systems
  - Why needed here: The framework relies on discriminators to rank data cases by difficulty and select critical cases for optimization, requiring understanding of how ranking systems work and how they can be implemented.
  - Quick check question: How would you design a scoring system to rank plans based on their constraint violation severity?

- Concept: Prompt engineering and refinement
  - Why needed here: The framework improves agent performance through iterative prompt refinement based on discriminator feedback, requiring understanding of how to effectively modify prompts to incorporate constraint information.
  - Quick check question: What strategies would you use to incorporate constraint information from critical cases into the planning agent's prompt?

## Architecture Onboarding

- Component map: User query -> Planning agent -> Constraint extraction module -> Discriminator evaluation (human/LLM) -> Critical case identification -> Prompt refinement -> Improved planning agent

- Critical path: The main workflow follows: user query → planning agent → constraint extraction → discriminator evaluation → critical case identification → prompt refinement → improved planning agent. This loop continues until performance thresholds are met.

- Design tradeoffs: The framework trades computational efficiency for data efficiency by focusing on critical cases rather than retraining on all data. It also trades automation for accuracy by incorporating human expertise in the discriminator component. The constraint extraction approach trades comprehensiveness for simplicity by focusing on NL formalization rather than complex code analysis.

- Failure signatures: Common failure modes include: discriminators failing to identify relevant critical cases, constraint extraction producing incomplete or inaccurate constraint concepts, prompt refinement not effectively incorporating constraint information, and evaluation metrics not accurately measuring constraint satisfaction.

- First 3 experiments:
  1. Test constraint extraction on a simple white-box system with clear intermediate steps to evaluate the framework's ability to handle noise in constraint formalization.
  2. Compare human and LLM discriminator performance on a diverse set of constraint violation cases to quantify their respective strengths and weaknesses.
  3. Evaluate the impact of different constraint classification strategies (explicit vs implicit) on the framework's overall performance and data efficiency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the framework's performance scale with increasing constraint complexity across different domains?
- Basis in paper: [inferred] The paper demonstrates effectiveness on travel planning with moderate constraints but acknowledges the need to test in other domains with distinct features and constraints.
- Why unresolved: The current evaluation is limited to travel planning, and the paper explicitly states that more complex domains with advanced capabilities beyond current constraints need to be tested.
- What evidence would resolve it: Empirical results showing performance across multiple domains (e.g., education planning, logistics) with varying constraint complexity levels.

### Open Question 2
- Question: What is the optimal balance between human and LLM discriminator contributions for maximizing performance while minimizing resource costs?
- Basis in paper: [explicit] The paper identifies that human discriminators outperform LLM discriminators but acknowledges human resources are often limited in practical systems, suggesting a hybrid model.
- Why unresolved: The paper presents preliminary results showing human discriminators perform better but doesn't determine the optimal weighting or allocation strategy between human and LLM discriminators.
- What evidence would resolve it: Comparative studies testing different human/LLM discriminator ratios across various problem domains and constraint complexities.

### Open Question 3
- Question: How can the framework be extended to handle implicit constraints in white-box systems with noisy intermediate computations?
- Basis in paper: [explicit] The paper discusses challenges with extracting constraints from white-box systems where intermediate computations introduce noise, and mentions exploring code analysis technologies but doesn't provide solutions.
- Why unresolved: The paper identifies this as a main focus but doesn't present a complete solution, only suggesting potential approaches like AST analysis and dynamic compilation.
- What evidence would resolve it: Implementation and validation of constraint extraction methods that successfully handle noisy intermediate computations in real white-box systems.

## Limitations
- The framework's effectiveness is currently demonstrated only on travel planning with moderate constraints
- Scalability to more complex constraint domains with advanced capabilities remains untested
- Human-in-the-loop approaches may not be sustainable as constraint complexity increases
- Constraint extraction from white-box systems with noisy intermediate computations presents ongoing challenges

## Confidence
- **High**: Human discriminators outperform LLM discriminators in ranking critical cases for optimization
- **Medium**: Overall effectiveness of the framework for constraint-based optimization
- **Medium**: Two-phase concept-to-optimization methodology generalizability beyond travel planning

## Next Checks
1. Test the framework on a more complex constraint domain (such as medical treatment planning or financial portfolio optimization) to evaluate generalizability and identify domain-specific challenges
2. Conduct a longitudinal study measuring the diminishing returns of human discriminator input over multiple optimization iterations to establish optimal human involvement thresholds
3. Compare the framework's performance against traditional fine-tuning approaches on the same travel planning task using equivalent computational resources