---
ver: rpa2
title: Approximations to the Fisher Information Metric of Deep Generative Models for
  Out-Of-Distribution Detection
arxiv_id: '2403.01485'
source_url: https://arxiv.org/abs/2403.01485
tags:
- detection
- gradient
- data
- which
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of out-of-distribution (OOD)
  detection in deep generative models, where likelihood-based methods often fail due
  to counterintuitive behaviors observed in prior work. The authors propose a novel
  approach that leverages the gradient of the log-likelihood with respect to model
  parameters as a discriminative feature for OOD detection.
---

# Approximations to the Fisher Information Metric of Deep Generative Models for Out-Of-Distribution Detection

## Quick Facts
- arXiv ID: 2403.01485
- Source URL: https://arxiv.org/abs/2403.01485
- Authors: Sam Dauncey; Chris Holmes; Christopher Williams; Fabian Falck
- Reference count: 39
- One-line primary result: Proposed method outperforms typicality test on most OOD detection tasks with high AUROC values up to 0.9997 for Glow models.

## Executive Summary
This paper addresses the challenge of out-of-distribution (OOD) detection in deep generative models, where likelihood-based methods often fail due to counterintuitive behaviors. The authors propose a novel approach that leverages the gradient of the log-likelihood with respect to model parameters as a discriminative feature for OOD detection. By approximating the Fisher information metric and showing that layer-wise gradient norms are chi-square distributed and weakly correlated across layers, they develop a simple, model-agnostic method that estimates the joint density of layer-wise gradient norms. The proposed method is hyperparameter-free and satisfies the principle of representation invariance.

## Method Summary
The proposed method computes layer-wise gradient norms of the log-likelihood with respect to model parameters and uses them as features for OOD detection. It approximates the Fisher information metric as a diagonal matrix (layer-wise L2 norms) and fits Gaussian distributions to the log-transformed gradient norms. The joint density of these layer-wise features is then used as the OOD score. This approach is model-agnostic, requires no additional training, and satisfies representation invariance.

## Key Results
- The proposed method achieves AUROC values up to 0.9997 for Glow models on CIFAR-10 vs SVHN, compared to 0.9999 for the typicality test.
- Outperforms the typicality test in most cases across various image datasets and deep generative models.
- Layer-wise gradient norms are chi-square distributed and weakly correlated across layers, enabling effective combination of information.
- The method is hyperparameter-free and satisfies representation invariance, making it robust to invertible transformations of the input space.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: OOD data induces larger gradient norms because it is more "influential" on model parameters.
- Mechanism: The gradient of the log-likelihood with respect to parameters measures how much a data point would change the model if it were used in an optimization step. OOD data causes larger changes because it lies outside the training manifold, so the model has not learned to handle it well.
- Core assumption: A well-trained model has flat likelihood landscapes for in-distribution data and steep gradients for OOD data.
- Evidence anchors:
  - [abstract] "based on the simple intuition that OOD data should have larger gradient norms than training data"
  - [section 1] "If a neural network converged to a local (or global) minimum, we expect the gradient of the likelihood with respect to the model's parameters to be flat for training data points."
- Break condition: If the model is undertrained or the training data is too small, the gradient landscape may not be flat for in-distribution data, invalidating the assumption.

### Mechanism 2
- Claim: The Fisher information metric (FIM) approximates the size of the gradient in a way that is invariant to parameter scaling.
- Mechanism: The FIM re-scales gradients to give equal weight to parameters that typically have smaller gradients, making it independent of how parameters are scaled. This prevents dependence on representation in the gradient space.
- Core assumption: The FIM has large absolute diagonal values, making a diagonal approximation (layer-wise L2 norms) a good proxy.
- Evidence anchors:
  - [section 3.3] "We observe an interesting pattern of diagonal dominance: The diagonal elements are significantly larger in absolute value, on average approximately five times the size of the off-diagonal elements."
  - [section 3.2] "the Fisher information metric ∥∇θl(x)∥FIM (Radhakrishna Rao, 1948), defined as ∥∇θl(x)∥2FIM =∇θl(x)TF−1θ∇θl(x)"
- Break condition: If the FIM has significant off-diagonal structure or if layers have highly correlated gradients, the diagonal approximation may fail.

### Mechanism 3
- Claim: Layer-wise gradient norms are weakly correlated across layers, making their combination informative for OOD detection.
- Mechanism: Each layer captures different aspects of the model's response to data. If these responses are weakly correlated, combining them provides more information than using the overall gradient norm.
- Core assumption: The scale of the gradient norms differs by orders of magnitude across layers, and layer-wise gradients contain more information than the overall gradient norm.
- Evidence anchors:
  - [section 3.1] "the scale of the gradient norms differs by orders of magnitudes. In particular, taking the norm over the entire score vector would overshadow the signal of layers with a smaller norm by those on much larger magnitudes."
  - [section 3.4] "We observe a good fit of logfθj to a Normal distribution, empirically validating this holds in spite of our approximations."
- Break condition: If gradients across layers become highly correlated (e.g., in very deep or narrow networks), the combined information may not be as informative.

## Foundational Learning

- Concept: Fisher Information Matrix (FIM)
  - Why needed here: The FIM provides a principled way to measure the size of gradients in a representation-invariant manner.
  - Quick check question: What is the relationship between the FIM and the score statistic, and why is this relevant for OOD detection?

- Concept: Representation invariance in deep generative models
  - Why needed here: OOD detection should not depend on how data is represented (e.g., RGB vs HSV color space), so the method must be invariant to such transformations.
  - Quick check question: How does the gradient of the log-likelihood remain invariant under invertible transformations of the input space?

- Concept: Layer-wise gradient norms and their distribution
  - Why needed here: Understanding that layer-wise gradients are chi-square distributed and weakly correlated is key to combining them effectively for OOD detection.
  - Quick check question: Why does the log of the layer-wise gradient norm follow a normal distribution, and how does this enable density estimation?

## Architecture Onboarding

- Component map:
  - Deep generative model (Glow, diffusion, or VAE) -> Gradient computation module (layer-wise L2 norms of log-likelihood gradients) -> Statistical modeling module (fitting Gaussians to log-transformed gradient norms) -> OOD scoring module (joint density estimation from layer-wise features)

- Critical path:
  1. Train a deep generative model on in-distribution data.
  2. Compute layer-wise gradient norms for a held-out fit set.
  3. Fit Gaussian distributions to the log-transformed gradient norms.
  4. For new data, compute layer-wise gradient norms and evaluate the joint density as the OOD score.

- Design tradeoffs:
  - Using the full FIM vs. a diagonal approximation (layer-wise norms) for computational efficiency.
  - Single sample vs. batch gradient norms for robustness vs. noise.
  - Joint density estimation vs. Fisher's method for combining statistics.

- Failure signatures:
  - Poor separation between in-distribution and OOD data in layer-wise gradient norm histograms.
  - High correlation between layer-wise gradient norms, reducing the informativeness of their combination.
  - Model not well-trained, leading to flat gradients for in-distribution data and invalidating the core assumption.

- First 3 experiments:
  1. Replicate the layer-wise gradient norm histograms for a Glow model trained on CIFAR-10, comparing in-distribution vs. OOD data.
  2. Fit Gaussian distributions to the log-transformed layer-wise gradient norms and visualize the fit quality.
  3. Compute the joint density OOD score for a batch of in-distribution and OOD data, and compare the scores to the typicality test.

## Open Questions the Paper Calls Out

- Does the proposed method generalize to large-scale language models or other high-dimensional data modalities beyond images?
  - Basis in paper: [explicit] The authors acknowledge this as a key limitation and state "datasets beyond images and for instance large language models should be tested."
  - Why unresolved: The paper only provides experimental results on image datasets (SVHN, CelebA, GTSRB, CIFAR-10, ImageNet32). No experiments were conducted on language models or other data types like audio or video.
  - What evidence would resolve it: Empirical results showing the method's performance on large language models (e.g., GPT-3, BERT) and other data modalities, with comparisons to existing OOD detection methods for those domains.

- What is the optimal number of gradient features (layers) to use for OOD detection, and how does this scale with model size?
  - Basis in paper: [inferred] The authors observe that gradient norms vary significantly across layers and propose using layer-wise norms. However, they don't investigate the optimal number of layers to use or how this scales with model depth.
  - Why unresolved: The paper uses all available layers but doesn't analyze the trade-off between performance and computational cost as the number of layers increases. The impact of layer selection on performance is also not explored.
  - What evidence would resolve it: Systematic experiments varying the number of layers used, showing performance curves and computational costs, along with analysis of which layers contribute most to OOD detection accuracy.

- How does the method perform on real-world OOD data that may be semantically similar to in-distribution data?
  - Basis in paper: [inferred] The authors note that current evaluations often use "semantically dissimilar surrogate out-distributions" and question whether unsupervised methods should consistently reject images from other natural image datasets.
  - Why unresolved: The paper focuses on detecting semantically distinct OOD datasets (e.g., CIFAR-10 vs. SVHN) but doesn't address the harder problem of detecting subtle distribution shifts or adversarial examples.
  - What evidence would resolve it: Experiments using real-world OOD scenarios like corrupted images, domain-shifted data, or adversarial examples, with analysis of detection rates for these challenging cases.

## Limitations
- The assumption that well-trained models have flat likelihood landscapes for in-distribution data may not hold for under-trained or data-scarce models.
- The diagonal approximation of the Fisher information matrix assumes weak correlations between layer-wise gradients, which may not be valid for all architectures.
- The chi-square distribution of layer-wise gradient norms is an approximation that may not hold in practice.

## Confidence
- Confidence in the core claim that OOD data induces larger gradient norms is High, supported by empirical evidence in the paper.
- Confidence in the effectiveness of the diagonal approximation of the Fisher information matrix is Medium, as it relies on the assumption of weak gradient correlations.
- The claim that the proposed method is hyperparameter-free is Medium, as it depends on the quality of the Gaussian fits to the log-transformed gradient norms.

## Next Checks
1. Evaluate the proposed method on a wider range of deep generative models, including autoregressive models and flow-based models beyond Glow.
2. Investigate the impact of model under-training on the effectiveness of the method by training models with varying numbers of epochs and evaluating OOD detection performance.
3. Explore the use of alternative distributions (e.g., Student's t-distribution) to model the log-transformed gradient norms and compare the OOD detection performance to the Gaussian assumption.