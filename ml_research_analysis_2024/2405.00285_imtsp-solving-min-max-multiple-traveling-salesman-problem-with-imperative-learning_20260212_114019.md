---
ver: rpa2
title: 'iMTSP: Solving Min-Max Multiple Traveling Salesman Problem with Imperative
  Learning'
arxiv_id: '2405.00285'
source_url: https://arxiv.org/abs/2405.00285
tags:
- gradient
- mtsp
- imtsp
- cities
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the Min-Max Multiple Traveling Salesman Problem
  (MTSP), aiming to minimize the longest tour length among multiple agents collectively
  visiting all cities. The core method introduces imperative MTSP (iMTSP), a self-supervised,
  bilevel learning framework that decomposes MTSP into smaller single-agent TSPs.
---

# iMTSP: Solving Min-Max Multiple Traveling Salesman Problem with Imperative Learning

## Quick Facts
- **arXiv ID**: 2405.00285
- **Source URL**: https://arxiv.org/abs/2405.00285
- **Reference count**: 40
- **Primary result**: iMTSP achieves up to 80% shorter tour lengths compared to Google OR-Tools on large-scale MTSP problems (400-1000 cities, 5-15 agents).

## Executive Summary
The paper introduces imperative MTSP (iMTSP), a self-supervised bilevel learning framework that solves the Min-Max Multiple Traveling Salesman Problem by decomposing it into multiple single-agent TSPs. The core innovation lies in using an allocation network to assign cities to agents, combined with a control variate-based optimization technique to handle the non-differentiability and high variance introduced by discrete sampling and black-box TSP solvers. The method demonstrates significant performance improvements over existing solvers on large-scale problems.

## Method Summary
iMTSP reformulates MTSP as a bilevel optimization problem where an allocation network assigns cities to agents (upper level), and a TSP solver finds optimal tours for each agent's assigned cities (lower level). The allocation network uses attention mechanisms to compute agent embeddings and assign cities probabilistically. A surrogate network predicts tour lengths to enable control variate-based gradient estimation, reducing the high variance from discrete sampling. The framework is trained end-to-end using self-supervision from the TSP solver outputs, without requiring ground-truth optimal allocations.

## Key Results
- Achieves up to 80% shorter maximum tour lengths compared to Google OR-Tools on problems with 400-1000 cities and 5-15 agents
- Converges 20 times faster than reinforcement learning baseline [14]
- Demonstrates strong generalization from training on 50-100 cities to testing on 400-1000 cities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The bilevel reformulation enables efficient decomposition of the large-scale MTSP into manageable single-agent TSPs.
- Mechanism: The allocation network assigns cities to agents, converting the global optimization problem into a set of independent local TSP problems, each solvable by a classic TSP solver.
- Core assumption: The allocation quality is strongly correlated with the final objective value (minimizing the longest tour).
- Evidence anchors:
  - [abstract] "This involves introducing an allocation network that decomposes the MTSP into multiple single-agent traveling salesman problems (TSPs)."
  - [section] "The allocation network is to assign each city to an agent, which decomposes the MTSP into multiple single-agent TSPs."
- Break condition: If the TSP solver cannot produce high-quality tours for the assigned subsets, the bilevel decomposition loses its advantage.

### Mechanism 2
- Claim: The control variate-based optimization algorithm reduces gradient variance, enabling stable learning in the presence of non-differentiable lower-level optimization.
- Mechanism: A surrogate network estimates the tour length and its gradient variance; this estimate is used to construct a control variate that corrects the high-variance Monte Carlo gradient estimator from the discrete allocation sampling.
- Evidence anchors:
  - [abstract] "Additionally, to tackle the high-variance gradient issues during the optimization, we introduce a control variate-based gradient estimation algorithm."
  - [section] "To handle this difficulty, we introduce a control variate [28] to reduce the variance of the gradient estimations."
- Break condition: If the surrogate network fails to correlate well with the actual TSP solver output, the control variate correction becomes ineffective.

### Mechanism 3
- Claim: The self-supervised supervision from the TSP solver's output allows end-to-end learning without requiring ground-truth optimal allocations.
- Mechanism: The allocation network is trained to minimize the maximum tour length returned by the TSP solver, creating a differentiable signal from a non-differentiable process via the control variate.
- Evidence anchors:
  - [abstract] "The longest tour from these TSP solutions is then used to self-supervise the allocation network."
  - [section] "The upper-level optimization, namely the training of the allocation network, is supervised by the lower-level TSP solver."
- Break condition: If the TSP solver consistently returns poor-quality solutions, the self-supervision signal becomes unreliable.

## Foundational Learning

- Concept: Bilevel optimization
  - Why needed here: MTSP requires solving a global allocation problem and local TSP subproblems; bilevel formulation naturally captures this nested structure.
  - Quick check question: In bilevel optimization, which level's solution depends on the other's parameters?

- Concept: Control variates in gradient estimation
  - Why needed here: The discrete sampling in allocation introduces high variance in Monte Carlo gradient estimates; control variates reduce this variance.
  - Quick check question: What property must a control variate have relative to the target estimator to guarantee variance reduction?

- Concept: Attention mechanisms for graph-structured data
  - Why needed here: The allocation network must reason about relationships between cities and agents; attention allows flexible, learnable aggregation of these relationships.
  - Quick check question: In the allocation network, what role do the query vectors play when computing agent embeddings?

## Architecture Onboarding

- Component map: Allocation network → discrete sampling → TSP solver(s) → surrogate network → control variate correction → gradient update. The allocation network and surrogate network share the same input (city embeddings).
- Critical path: Allocation → sampling → TSP solving → maximum tour length → surrogate prediction → gradient computation → parameter update. Latency is dominated by TSP solving.
- Design tradeoffs: Using a classic TSP solver provides strong solutions but introduces non-differentiability; replacing it with a learned solver could enable end-to-end differentiability but may sacrifice solution quality.
- Failure signatures: High variance in allocation gradients, allocation collapse (all cities assigned to one agent), or poor generalization to larger problem sizes.
- First 3 experiments:
  1. Verify the allocation network can produce valid probability matrices and that sampling yields diverse agent assignments.
  2. Test the surrogate network's ability to predict tour lengths and correlate with actual TSP outputs.
  3. Measure gradient variance with and without the control variate to confirm variance reduction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the iMTSP framework generalize to unseen problem sizes, especially when the number of cities or agents significantly exceeds the training set?
- Basis in paper: [explicit] The paper mentions that current methods struggle with generalization to problem sizes outside the training set, and that iMTSP is tested on problems with 400 to 1000 cities when trained on 50 to 100 cities.
- Why unresolved: While the paper shows iMTSP performs well on larger problems, it doesn't provide a detailed analysis of how the model's performance degrades as the problem size increases beyond the training range.
- What evidence would resolve it: Conducting experiments with progressively larger problem sizes and reporting the performance metrics (e.g., tour length, computation time) would provide insights into the model's generalization capabilities.

### Open Question 2
- Question: How sensitive is the iMTSP framework to the choice of hyperparameters, such as the learning rates, embedding dimensions, and attention mechanism parameters?
- Basis in paper: [explicit] The paper mentions specific hyperparameter choices (e.g., learning rates, embedding dimensions) but doesn't explore the sensitivity of the model's performance to these choices.
- Why unresolved: The paper doesn't provide a systematic analysis of how different hyperparameter configurations affect the model's performance, making it difficult to assess the robustness of the approach.
- What evidence would resolve it: Performing a hyperparameter sensitivity analysis by varying different parameters and reporting the corresponding performance metrics would help understand the model's robustness and guide the selection of optimal hyperparameters.

### Open Question 3
- Question: How does the iMTSP framework perform in the presence of real-world constraints, such as obstacles, inter-agent collision avoidance, and time windows?
- Basis in paper: [explicit] The paper mentions that future work will consider constraints like environmental obstacles and inter-agent collision, indicating that the current framework doesn't handle these real-world complexities.
- Why unresolved: The current iMTSP framework assumes a simplified problem setting without considering real-world constraints that are crucial for practical applications.
- What evidence would resolve it: Extending the iMTSP framework to incorporate real-world constraints and evaluating its performance on benchmark problems with these constraints would demonstrate its applicability to real-world scenarios.

## Limitations
- Lacks detailed architectural specifications for embedding network and surrogate network, making exact replication difficult
- Critical hyperparameters for control variate optimization (learning rates, clip constants) are not specified
- Impressive performance claims lack statistical significance testing or multiple random seeds

## Confidence
- **High Confidence**: The bilevel decomposition mechanism and its theoretical motivation are well-established and clearly explained
- **Medium Confidence**: The control variate variance reduction technique is plausible given the non-differentiability of the TSP solver, but the specific implementation details are underspecified
- **Low Confidence**: The exact performance claims (80% improvement, 20× faster convergence) cannot be fully verified without knowing the random seeds, statistical tests, or exact architectural parameters used

## Next Checks
1. **Architectural Reproducibility Check**: Implement the allocation network with CMPNN embedding and surrogate network using reasonable defaults, then verify that it can learn to produce valid probability matrices and diverse city-to-agent assignments on small test instances
2. **Variance Reduction Validation**: Measure the variance of allocation network gradients during training with and without the control variate, confirming that the surrogate-based correction achieves meaningful variance reduction as claimed
3. **Generalization Stress Test**: Evaluate the trained model on problem sizes beyond the training distribution (e.g., training on 100 cities, testing on 1000 cities) to verify the claimed scalability and identify any overfitting or performance degradation