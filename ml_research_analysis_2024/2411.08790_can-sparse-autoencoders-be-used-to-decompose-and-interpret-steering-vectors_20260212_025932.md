---
ver: rpa2
title: Can sparse autoencoders be used to decompose and interpret steering vectors?
arxiv_id: '2411.08790'
source_url: https://arxiv.org/abs/2411.08790
tags:
- steering
- vectors
- vector
- negative
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates why directly applying sparse autoencoders
  (SAEs) to steering vectors yields misleading decompositions. The authors identify
  two main reasons: (1) steering vectors fall outside the input distribution for which
  SAEs are designed, and (2) steering vectors can have meaningful negative projections
  in feature directions, which SAEs are not designed to accommodate.'
---

# Can sparse autoencoders be used to decompose and interpret steering vectors?

## Quick Facts
- arXiv ID: 2411.08790
- Source URL: https://arxiv.org/abs/2411.08790
- Reference count: 40
- Primary result: SAE-decomposed steering vectors fail to retain steering properties due to distributional shift and inability to represent negative projections

## Executive Summary
This paper investigates why directly applying sparse autoencoders (SAEs) to steering vectors yields misleading decompositions. The authors identify two main reasons: (1) steering vectors fall outside the input distribution for which SAEs are designed, and (2) steering vectors can have meaningful negative projections in feature directions, which SAEs are not designed to accommodate. Through empirical analysis on Gemma 2 2B, they demonstrate that SAE-decomposed steering vectors fail to retain the steering properties of the original vectors. The paper shows that SAE encoder bias overwhelmingly influences the decomposition, and that meaningful negative projections in feature directions cannot be captured by SAEs' non-negative reconstruction coefficients.

## Method Summary
The authors extract steering vectors from Gemma 2 2B using Contrastive Activation Addition on a corrigibility dataset (340 contrastive prompt pairs). They then decompose these steering vectors using pre-trained Gemma Scope SAEs (layer 14, 16,384 features, L0=173) and analyze the reconstruction coefficients. The method involves comparing steering vector L2-norm distributions with model activation norms, and analyzing feature activation patterns between positive and negative contrastive prompts to identify negative projections.

## Key Results
- Steering vectors have significantly smaller L2-norms than model activations, causing SAE encoder bias to dominate decomposition
- 51.2% of SAE features activate more strongly on negative prompts, indicating meaningful negative projections that SAEs cannot represent
- Feature 14004 has negative cosine similarity (-0.82) with feature 3517, causing spurious positive projections in interpretations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAEs are designed to reconstruct activations, not steering vectors, leading to out-of-distribution inputs.
- Mechanism: Steering vectors have smaller L2-norms than typical model activations, causing the SAE encoder bias to dominate the reconstruction. This bias overwhelms meaningful contributions from the steering vector.
- Core assumption: SAEs assume inputs are drawn from the same distribution as activations they were trained on.
- Evidence anchors:
  - [abstract] "steering vectors fall outside the input distribution for which SAEs are designed"
  - [section 3.1] "One way this out-of-distribution issue materialises, is that steering vectors have significantly smaller L2-norms than model activations"
  - [corpus] Weak evidence; neighboring papers focus on SAE steering but not the distributional shift issue explicitly.
- Break condition: If steering vectors are scaled to match activation norms while preserving default components, the bias dominance might be reduced.

### Mechanism 2
- Claim: SAEs enforce non-negative reconstruction coefficients, but steering vectors can have meaningful negative projections in feature directions.
- Mechanism: When steering vectors are derived from contrastive pairs, some SAE features activate more strongly on negative prompts, implying the steering vector writes negatively in those directions. SAEs cannot represent this, setting such coefficients to zero.
- Core assumption: Negative projections in SAE feature directions are meaningful for steering behavior.
- Evidence anchors:
  - [abstract] "steering vectors can have meaningful negative projections in feature directions, which SAEs are not designed to accommodate"
  - [section 3.2] "We find that 51.2% of the features that activate on either positive or negative prompts in Contrastive Activation Addition activate more strongly on the negative prompts"
  - [corpus] Weak evidence; no direct corpus support for negative projection interpretability.
- Break condition: If SAE features have no meaningful negative alignment or if steering vectors only require positive contributions.

### Mechanism 3
- Claim: Negative projections in one SAE feature direction can appear as spurious positive projections in another direction due to negative cosine similarity between features.
- Mechanism: If feature A has a negative projection and feature B has negative cosine similarity with A, the steering vector's negative projection in A can manifest as a positive projection in B, misleading interpretation.
- Core assumption: SAE features exhibit non-orthogonal relationships (negative cosine similarity) that can conflate negative and positive contributions.
- Evidence anchors:
  - [section 3.2] "feature 14004 has a negative cosine similarity (-0.82) with feature 3517, which rarely activates for either prompt type. This negative alignment causes a spurious positive projection in feature 3517's direction"
  - [corpus] Weak evidence; no corpus discussion of feature alignment effects on steering interpretation.
- Break condition: If SAE features are orthogonal or if negative cosine similarity is negligible in practice.

## Foundational Learning

- Concept: Contrastive Activation Addition
  - Why needed here: Steering vectors are extracted using this method; understanding the subtraction process is crucial to why they differ from activations.
  - Quick check question: What is the mathematical form of a steering vector derived from contrastive pairs?

- Concept: Sparse Autoencoder (SAE) reconstruction
  - Why needed here: SAEs decompose activations into non-negative linear combinations; this assumption fails for steering vectors.
  - Quick check question: What constraint does the SAE activation function impose on reconstruction coefficients?

- Concept: Feature alignment and cosine similarity
  - Why needed here: Negative cosine similarity between SAE features can cause misinterpretation of negative projections.
  - Quick check question: How does negative cosine similarity between features affect the interpretation of steering vector projections?

## Architecture Onboarding

- Component map: Steering vector -> SAE Encoder -> SAE Decoder -> Interpreted feature contributions
- Critical path:
  1. Extract steering vector via Contrastive Activation Addition
  2. Pass through SAE encoder to get coefficients
  3. Decode to reconstruct vector
  4. Analyze feature activations for interpretability
- Design tradeoffs:
  - SAEs provide interpretability but enforce non-negative coefficients, limiting representation of steering vectors.
  - Alternative methods (e.g., gradient pursuit) can handle negative coefficients but may sacrifice sparsity or interpretability.
- Failure signatures:
  - Top activating features in SAE decomposition resemble those for zero vector, indicating encoder bias dominance.
  - High overlap between positive and negative prompt feature activations suggests negative projections are ignored.
- First 3 experiments:
  1. Compare SAE decomposition of zero vector vs. steering vector to quantify encoder bias influence.
  2. Analyze feature activation differences between positive and negative contrastive prompts to detect negative projections.
  3. Test scaled steering vectors to see if distributional shift is mitigated without restoring default components.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can steering vectors be effectively decomposed in the SAE basis by learning them directly within that space rather than applying SAEs to existing steering vectors?
- Basis in paper: [explicit] The authors propose this as a potential solution that would overcome both the out-of-distribution issue and the negative coefficient problem
- Why unresolved: This approach has not been tested or implemented yet, and would require establishing new evaluation metrics to compare it with existing methods
- What evidence would resolve it: Empirical results showing that steering vectors learned in the SAE basis retain their steering properties and provide interpretable decompositions, compared to traditional Contrastive Activation Addition vectors

### Open Question 2
- Question: How does the interpretability of steering vectors depend on the specific model activations they are applied to, rather than being a global property?
- Basis in paper: [inferred] The authors illustrate how the same steering vector can have different effects depending on the model activations it's applied to, due to feature direction alignment
- Why unresolved: The paper only provides an illustrative example without empirical testing across different activation contexts
- What evidence would resolve it: Systematic experiments showing how steering vector effects and interpretations vary when applied to different model activation states, particularly those different from those they were extracted from

### Open Question 3
- Question: Are there alternative sparse approximation methods beyond gradient pursuit and sparse SAE task vector fine-tuning that could better handle the meaningful negative feature coefficients in steering vectors?
- Basis in paper: [explicit] The authors mention these two methods but note that they must still handle the issue of meaningful negative feature coefficients, which is a more fundamental challenge
- Why unresolved: The paper only briefly mentions these existing methods without exploring or testing other potential approaches
- What evidence would resolve it: Development and empirical comparison of new sparse approximation methods that can effectively capture negative projections while maintaining steering properties

### Open Question 4
- Question: How significant is the impact of feature alignment (negative cosine similarity between features) on the interpretability of steering vectors across different behaviors and models?
- Basis in paper: [explicit] The authors provide one example of feature 14004 and 3517 showing how negative cosine similarity can lead to misleading interpretations
- Why unresolved: The paper only explores this phenomenon in depth for one specific feature pair and one behavior
- What evidence would resolve it: Comprehensive analysis of feature alignment effects across multiple behaviors, models, and feature pairs to quantify how often and severely this impacts interpretability

## Limitations
- The distributional shift argument relies heavily on Gemma 2 2B and may not generalize to other model architectures
- The analysis of negative projections lacks direct mechanistic validation of their necessity for steering behavior
- The proposed alternative of learning steering vectors in SAE basis is not extensively validated

## Confidence
- **High confidence**: The distributional shift claim is well-supported by empirical data and encoder bias effect is clearly demonstrated
- **Medium confidence**: The negative projection claim is supported by feature activation analysis but lacks direct mechanistic validation
- **Low confidence**: The negative cosine similarity mechanism is demonstrated for specific feature pairs but not systematically validated

## Next Checks
1. Apply the same SAE decomposition analysis to steering vectors from different models (e.g., Llama, Mistral) and different steering tasks (e.g., sentiment, toxicity) to assess universality of the issues
2. Test whether SAE variants with different activation functions or reconstruction objectives show improved performance on steering vector decomposition
3. Design experiments where steering vectors are explicitly constructed to require negative projections in specific feature directions, then verify whether removing these negative components degrades steering performance