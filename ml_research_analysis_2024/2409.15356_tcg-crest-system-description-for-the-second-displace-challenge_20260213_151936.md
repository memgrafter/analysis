---
ver: rpa2
title: TCG CREST System Description for the Second DISPLACE Challenge
arxiv_id: '2409.15356'
source_url: https://arxiv.org/abs/2409.15356
tags:
- diarization
- track
- speech
- speaker
- challenge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The team developed speaker and language diarization systems for
  the DISPLACE 2024 challenge using the SpeechBrain toolkit. They explored speech
  enhancement, voice activity detection, unsupervised domain categorization, and neural
  embedding extraction, implementing spectral clustering for both tasks.
---

# TCG CREST System Description for the Second DISPLACE Challenge

## Quick Facts
- arXiv ID: 2409.15356
- Source URL: https://arxiv.org/abs/2409.15356
- Reference count: 0
- Primary result: Speaker diarization achieved 32.22% DER, language diarization achieved 43.76% DER on evaluation set

## Executive Summary
TCG CREST participated in the Second DISPLACE Challenge, developing speaker and language diarization systems using the SpeechBrain toolkit. The team explored speech enhancement, voice activity detection, unsupervised domain categorization, and neural embedding extraction. For both tracks, they implemented spectral clustering on fixed 2.0s segments with 0.4s overlap. Track 1 used ECAPA-TDNN embeddings trained on VoxCeleb, achieving a 7% relative improvement over baseline. Track 2 fused ECAPA-TDNN and XLS-R embeddings but did not achieve improvement over baseline. The systems were tested on DISPLACE 2024 challenge dataset using AMD Ryzen 9 7900X CPU and NVIDIA GeForce RTX 4090 GPU.

## Method Summary
The diarization systems used spectral clustering with fixed 2.0s segments and 0.4s overlap for both speaker and language tasks. For speaker diarization (Track 1), ECAPA-TDNN embeddings were extracted using a pre-trained model on VoxCeleb corpus. For language diarization (Track 2), the team fused affinity scores from ECAPA-TDNN (supervised) and XLS-R (self-supervised) embeddings with weights 0.8 and 0.2 respectively. Voice activity detection was performed using Pyannote for both tracks, and speaker diarization included VB-HMM re-segmentation. The spectral clustering approach was chosen for its ability to handle non-convex clusters in the affinity matrix.

## Key Results
- Speaker diarization achieved 32.22% DER on evaluation set, improving 7% relative over baseline
- Language diarization achieved 43.76% DER on evaluation set, no improvement over baseline
- Systems used fixed 2.0s segments with 0.4s overlap for both tracks
- Track 2 fusion used weights 0.8 for ECAPA-TDNN and 0.2 for XLS-R embeddings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Spectral clustering on fixed 2.0s segments with 0.4s overlap yields robust speaker and language clustering in multilingual, multi-speaker audio.
- Mechanism: Fixed-length segmentation with overlap reduces boundary ambiguity; spectral clustering leverages pairwise embedding affinities to group segments by speaker/language identity.
- Core assumption: Overlapping segments preserve contextual continuity and improve affinity estimation between adjacent segments.
- Evidence anchors:
  - [abstract] "Our final submissions use spectral clustering for both the speaker and language diarization."
  - [section] "We have used fixed segmentation of maximum length 2.0s and overlap 0.4s."
  - [corpus] No direct evidence; assumption based on standard diarization literature.
- Break condition: Overlap too small → boundary errors; too large → redundant computation without gain.

### Mechanism 2
- Claim: ECAPA-TDNN embeddings trained on VoxCeleb provide discriminative speaker representations for Track 1, improving over baseline.
- Mechanism: ECAPA-TDNN uses multi-scale feature aggregation and Squeeze-Excitation blocks to capture speaker-specific characteristics; VoxCeleb training ensures generalization to unseen speakers.
- Core assumption: Pre-trained embeddings on VoxCeleb are transferable to multilingual conversational settings.
- Evidence anchors:
  - [abstract] "Our final submission in Track 1 consists of ECAPA-TDNN embeddings extracted with a pre-trained model trained on the VoxCeleb corpus."
  - [section] "Our final submissions use spectral clustering for both the speaker and language diarization."
  - [corpus] No direct evidence; transfer assumption from standard speaker verification literature.
- Break condition: Domain mismatch between VoxCeleb and target domain reduces embedding quality.

### Mechanism 3
- Claim: Fusion of ECAPA-TDNN and XLS-R embeddings (weights 0.8/0.2) attempts to improve language diarization robustness.
- Mechanism: ECAPA-TDNN provides speaker-level features; XLS-R (self-supervised) captures multilingual language patterns; weighted fusion aims to balance speaker and language cues.
- Core assumption: Combining supervised speaker embeddings with self-supervised multilingual embeddings improves language discrimination.
- Evidence anchors:
  - [abstract] "for Track 2, we fused the affinity scores obtained with embeddings from two types of embedding extractors: one trained in a supervised way with ECAPA-TDNN architecture, and another trained in a self-supervised manner with XLS-R architecture."
  - [section] "Track 2 submission as described in Table 2 uses affinity matrix fusion with weight 0.8 for affinity matrix from ECAPA-TDNN embedding and 0.2 for affinity matrix from XLS-R embedding."
  - [corpus] Weak evidence; fusion idea is common in multimodal systems but specific performance not demonstrated.
- Break condition: Poor complementarity between embedding types → fusion degrades rather than improves performance.

## Foundational Learning

- Concept: Speaker diarization and language diarization fundamentals
  - Why needed here: Understanding the distinction and overlap between SD and LD tasks guides model design and evaluation.
  - Quick check question: What is the difference between "who spoke when" and "which language was spoken when"?

- Concept: Spectral clustering mechanics
  - Why needed here: Spectral clustering is the core grouping algorithm; knowing its steps (affinity matrix, eigen-decomposition, k-means) is essential for debugging and tuning.
  - Quick check question: How does spectral clustering differ from hierarchical agglomerative clustering in diarization?

- Concept: Embedding extraction and pooling
  - Why needed here: Track 2 uses frame-level XLS-R embeddings pooled to segment level; understanding pooling strategies affects feature quality.
  - Quick check question: Why use average pooling for frame-level embeddings in language diarization?

## Architecture Onboarding

- Component map:
  - Speech enhancement (explored but not used in final)
  - Voice Activity Detection: Pyannote (SD) / Pyannote (LD)
  - Embedding extraction: ECAPA-TDNN (VoxCeleb) for SD; ECAPA-TDNN + XLS-R fusion for LD
  - Clustering: Spectral clustering (both tracks)
  - Re-segmentation: VB-HMM (SD only)
  - Fixed segmentation: 2.0s max length, 0.4s overlap

- Critical path:
  1. Input audio → VAD → fixed segmentation
  2. Segment embeddings → affinity matrix
  3. Spectral clustering → diarization output
  4. (SD only) VB-HMM re-segmentation

- Design tradeoffs:
  - Fixed vs. variable segmentation: Fixed simplifies processing but may miss short turns.
  - Single vs. fused embeddings: Fusion adds complexity but can improve robustness; here it didn't for LD.
  - Spectral vs. hierarchical clustering: Spectral handles non-convex clusters better; computationally heavier.

- Failure signatures:
  - High DER despite good VAD: likely embedding quality or clustering parameter issues.
  - Over-segmentation: too many clusters; check embedding similarity thresholds.
  - Under-segmentation: too few clusters; check spectral gap or k selection.

- First 3 experiments:
  1. Run the pipeline end-to-end on a short, clean test clip; verify VAD and segmentation outputs.
  2. Visualize the affinity matrix and spectral embedding space; check for clear cluster separation.
  3. Tune spectral clustering parameters (number of clusters, affinity type) on dev set; measure DER impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would fine-tuning the pre-trained ECAPA-TDNN and XLS-R models on the DISPLACE challenge dataset improve performance in both speaker and language diarization tasks?
- Basis in paper: [explicit] The authors mention in their conclusion that they plan to investigate fine-tuning of the pre-trained models in future work.
- Why unresolved: The team used publicly available pre-trained models without fine-tuning due to resource and time constraints, so the impact of adaptation to the specific dataset remains unknown.
- What evidence would resolve it: Conducting experiments with fine-tuned versions of the embedding extractors on the DISPLACE dataset and comparing results to the current system would provide a clear answer.

### Open Question 2
- Question: How would optimizing clustering and re-segmentation parameters affect the performance of the diarization systems?
- Basis in paper: [explicit] The authors used default parameters for clustering and re-segmentation due to resource and time constraints, indicating potential for improvement through parameter tuning.
- Why unresolved: Default parameters may not be optimal for the specific characteristics of the DISPLACE dataset, but the authors did not have time to explore this avenue.
- What evidence would resolve it: Systematic parameter search for spectral clustering and VB-HMM re-segmentation on the development set, followed by evaluation on the test set, would quantify the potential gains from optimization.

### Open Question 3
- Question: Would incorporating speech enhancement techniques improve the performance of the diarization systems when combined with other components like SAD and embedding extraction?
- Basis in paper: [explicit] The authors found that speech enhancement did not significantly improve performance, and attempts to use enhanced speech for SAD also did not help.
- Why unresolved: The experiments were conducted with fixed parameter settings and without exploring the interaction between enhancement and other pipeline components in detail.
- What evidence would resolve it: Comprehensive experiments varying enhancement algorithms, parameters, and their integration points in the pipeline, followed by ablation studies, would clarify the role of enhancement in the overall system.

## Limitations
- Language diarization fusion approach did not yield improvement over baseline
- Fixed segmentation strategy may not optimally handle varying speech rates
- Spectral clustering parameters and embedding dimensionality reductions are not fully specified

## Confidence
- High confidence: Speaker diarization mechanism (ECAPA-TDNN + spectral clustering) and Track 1 results (DER 32.22%)
- Medium confidence: Language diarization fusion approach and Track 2 results (DER 43.76%)
- Medium confidence: Fixed segmentation benefits and spectral clustering efficacy claims

## Next Checks
1. **Embedding Fusion Analysis**: Conduct ablation studies to determine if XLS-R embeddings contribute positively to language diarization when used alone or with different fusion weights (e.g., 0.5/0.5 or 0.6/0.4).
2. **Segmentation Parameter Sweep**: Evaluate the impact of varying segment lengths (1.5s, 2.5s) and overlaps (0.2s, 0.6s) on both speaker and language diarization DER.
3. **Clustering Parameter Tuning**: Systematically test different numbers of clusters and affinity matrix normalization methods to identify optimal spectral clustering settings for both tasks.