---
ver: rpa2
title: 'SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing'
arxiv_id: '2407.02811'
source_url: https://arxiv.org/abs/2407.02811
tags:
- lipschitz
- certified
- splitz
- local
- classifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'SPLITZ introduces a novel approach to certifiable adversarial
  robustness by splitting a neural network into two parts: constraining the Lipschitz
  constant of the first half and applying randomized smoothing to the second half.
  This leverages heterogeneity in Lipschitz constants across layers, where the first
  layers tend to be more stable while latter layers exhibit larger Lipschitz constants.'
---

# SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing

## Quick Facts
- arXiv ID: 2407.02811
- Source URL: https://arxiv.org/abs/2407.02811
- Authors: Meiyu Zhong; Ravi Tandon
- Reference count: 40
- One-line primary result: SPLITZ achieves 43.2% top-1 test accuracy on CIFAR-10 with ℓ2 perturbation budget ε=1, outperforming previous state-of-the-art of 39.8%

## Executive Summary
SPLITZ introduces a novel approach to certifiable adversarial robustness by splitting a neural network into two parts: constraining the Lipschitz constant of the first half and applying randomized smoothing to the second half. This leverages heterogeneity in Lipschitz constants across layers, where early layers tend to be more stable while later layers exhibit larger Lipschitz constants. The method provides theoretical guarantees for certified radius using the local Lipschitz constant of the first half combined with randomized smoothing parameters of the second half.

## Method Summary
SPLITZ trains a classifier by splitting it into two components: fL (first half) and fR (second half). The method constrains the local Lipschitz constant of fL while applying randomized smoothing to fR. During training, SPLITZ minimizes both the standard cross-entropy loss and a smoothing loss that encourages similar predictions for noisy perturbations. The certified radius is computed as the minimum of two terms: the certified radius of the smoothed second half and the ratio of the local Lipschitz constant to the optimal smoothing parameter. The approach is evaluated on MNIST, CIFAR-10, and ImageNet datasets, consistently outperforming state-of-the-art methods.

## Key Results
- SPLITZ achieves 43.2% top-1 test accuracy on CIFAR-10 with ℓ2 perturbation budget ε=1, compared to 39.8% for previous state-of-the-art
- Demonstrates superior performance for larger perturbation values across all tested datasets
- Maintains effectiveness on tabular datasets including Adult Income and Law School datasets
- Shows consistent improvements over randomized smoothing baseline across different network architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Splitting the network allows different robustness strategies for different layers, exploiting layer-wise heterogeneity in Lipschitz constants.
- Mechanism: Constrain the local Lipschitz constant of the first half (stable layers) while applying randomized smoothing to the second half (less stable layers). This reduces overall sensitivity to input perturbations while maintaining accuracy.
- Core assumption: Different layers in a neural network exhibit heterogeneous Lipschitz constants, with early layers being more stable than later ones.
- Evidence anchors: [abstract] "Motivation for SPLITZ comes from the observation that many standard deep networks exhibit heterogeneity in Lipschitz constants across layers." [section] "We observe that the values can vary widely across the layers, and quite often, latter half of the network often shows larger Lipschitz constants."

### Mechanism 2
- Claim: Local Lipschitz constant provides a tighter, input-specific bound compared to global Lipschitz constant.
- Mechanism: During training, SPLITZ minimizes the local Lipschitz constant of the first half of the network, which provides a tighter bound for certified radius computation.
- Core assumption: The local Lipschitz constant at a specific input provides a tighter bound on robustness than the global Lipschitz constant.
- Evidence anchors: [section] "Another line of works utilize the local Lipschitz bound to obtain better robustness guarantees, e.g., [36], [37]." [section] "More importantly, it does not depend on the specific input x as well as the parameter γ."

### Mechanism 3
- Claim: Optimizing over the split location can further improve certified radius.
- Mechanism: By varying where the network is split (after different layers), SPLITZ can find the optimal balance between constrained Lipschitz constants and smoothing effectiveness.
- Core assumption: The optimal split location varies depending on the specific architecture and dataset.
- Evidence anchors: [section] "In principle, we can also optimize over how we split the classifier. If the base classifier is a composition of K functions...then we can find the optimal split s* by varying s from 0, 1, 2, ..., K." [section] "In our experiments (see Section IV), we find that it is sufficient to split after a few layers (e.g., split the classifier after the s = 1st layer, fL = f1) and this alone suffices to outperform the state-of-art methods."

## Foundational Learning

- Concept: Lipschitz constant and its role in robustness
  - Why needed here: Understanding Lipschitz constants is crucial for grasping how SPLITZ constrains network stability and computes certified radii
  - Quick check question: What does it mean for a function to be L-Lipschitz, and why is this property important for adversarial robustness?

- Concept: Randomized smoothing and its theoretical guarantees
  - Why needed here: SPLITZ builds on randomized smoothing for the second half of the network, so understanding the certification mechanism is essential
  - Quick check question: How does adding Gaussian noise to inputs create a smoothed classifier with provable robustness guarantees?

- Concept: Local vs global Lipschitz constants
  - Why needed here: SPLITZ specifically uses local Lipschitz constants for tighter bounds, so understanding the difference is critical
  - Quick check question: What is the key difference between local and global Lipschitz constants, and why might local bounds be tighter?

## Architecture Onboarding

- Component map:
  - Input layer → First half (fL) with constrained local Lipschitz constant → Noise addition (δ) → Second half (fR) with randomized smoothing → Output

- Critical path:
  - Forward pass: x → fL(x) → fL(x) + δ → fR(fL(x) + δ) → prediction
  - Certification: Compute L(γ)fL(x), find optimal γ, calculate RgSPLITZ(x) = min(RfR(fL(x))/L(γ)fL(x), γ)

- Design tradeoffs:
  - Split location vs performance: Earlier splits constrain more layers but may hurt accuracy; later splits preserve accuracy but constrain fewer layers
  - Local Lipschitz bound tightness vs computation: Tighter bounds improve certified radius but increase computation
  - Noise level vs certified radius: Higher noise levels increase certified radius but may reduce accuracy

- Failure signatures:
  - Poor accuracy: Local Lipschitz constraint too tight, noise level too high, or split location suboptimal
  - Low certified radius: Local Lipschitz bound not sufficiently constrained, noise level too low, or split location too late
  - Training instability: Learning rate too high for the combined loss function, or local Lipschitz threshold θ not properly tuned

- First 3 experiments:
  1. Baseline comparison: Implement RS on the same architecture and compare certified accuracy on CIFAR-10 with varying ε values
  2. Split location sensitivity: Test SPLITZ with splits after layer 1, 2, and 3 on CIFAR-10 to find optimal location
  3. Local Lipschitz impact: Compare SPLITZ with and without local Lipschitz constraint on CIFAR-10 to quantify the benefit

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal split location between Lipschitz-constrained and smoothed portions vary across different neural network architectures and datasets?
- Basis in paper: [explicit] The paper mentions that splitting after the first layer consistently outperforms deeper splits on CIFAR-10, but also notes that optimization over split locations is theoretically possible.
- Why unresolved: The paper only tests a limited number of split locations and architectures. The relationship between network depth, architecture type, and optimal split position remains unclear.
- What evidence would resolve it: Systematic experiments varying split locations across diverse architectures (VGG, ResNet, Transformers) and datasets, with analysis of how network properties influence optimal split positioning.

### Open Question 2
- Question: What is the theoretical relationship between the local Lipschitz constant threshold θ and the trade-off between clean accuracy and certified robustness?
- Basis in paper: [explicit] The paper mentions using a learnable threshold θ and observes trade-offs between smaller Lipschitz constants (better robustness) and accuracy, but does not provide theoretical analysis of this relationship.
- Why unresolved: The paper empirically observes this trade-off but lacks theoretical characterization of how θ affects the robustness-accuracy frontier or how to optimally set θ for different scenarios.
- What evidence would resolve it: Theoretical analysis deriving the relationship between θ and the achievable robustness-accuracy trade-off, potentially including optimal selection strategies for different application contexts.

### Open Question 3
- Question: How does SPLITZ's certified robustness scale with input dimensionality and complexity beyond the tested image datasets?
- Basis in paper: [inferred] The paper demonstrates effectiveness on MNIST, CIFAR-10, and ImageNet, and mentions results on tabular datasets, but does not systematically explore scaling behavior with input complexity or dimensionality.
- Why unresolved: The theoretical guarantees and empirical results are limited to specific input domains. The method's performance on high-dimensional or structurally complex data remains unexplored.
- What evidence would resolve it: Extensive evaluation across diverse data types with varying dimensionality (text, graphs, multimodal data), analysis of how SPLITZ's performance scales with input complexity, and theoretical bounds on certified radius as a function of input dimensionality.

## Limitations
- The method relies on the assumption of heterogeneous Lipschitz constants across network layers, which may not hold for all architectures
- Additional computational overhead for local Lipschitz bound estimation during training
- Performance degrades on datasets with larger perturbation budgets where even constrained Lipschitz constants become limiting
- Optimal split location is dataset and architecture dependent, requiring empirical tuning

## Confidence
- Mechanism 1 (Heterogeneous Lipschitz constants): Medium - supported by layer-wise observations but limited corpus evidence
- Mechanism 2 (Local Lipschitz advantages): Medium - theoretical basis established but weak corpus validation
- Mechanism 3 (Optimal split optimization): Low - primarily theoretical contribution with limited empirical exploration

## Next Checks
1. Test SPLITZ across diverse architectures (ResNet, DenseNet, Vision Transformers) to verify the heterogeneous Lipschitz constant assumption
2. Conduct ablation studies comparing SPLITZ with and without local Lipschitz constraints on identical architectures
3. Evaluate SPLITZ performance on out-of-distribution datasets to assess generalization of certified robustness