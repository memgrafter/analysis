---
ver: rpa2
title: When Does Visual Prompting Outperform Linear Probing for Vision-Language Models?
  A Likelihood Perspective
arxiv_id: '2409.01821'
source_url: https://arxiv.org/abs/2409.01821
tags:
- prompts
- visual
- scores
- pre-trained
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a log-likelihood ratio (LLR) method to determine\
  \ whether visual prompting or linear probing is more suitable for a given dataset\
  \ when adapting pre-trained models. The method leverages approximations of visual\
  \ prompts (e.g., Gaussian, gradient-based, mini-finetuning) to compute LLR scores\
  \ efficiently without full training, achieving up to 100\xD7 speedup."
---

# When Does Visual Prompting Outperform Linear Probing for Vision-Language Models? A Likelihood Perspective

## Quick Facts
- arXiv ID: 2409.01821
- Source URL: https://arxiv.org/abs/2409.01821
- Reference count: 12
- Primary result: LLR method predicts whether VP or LP is better for a dataset, achieving up to 100× speedup through prompt approximations

## Executive Summary
This paper addresses the challenge of selecting between visual prompting and linear probing for adapting pre-trained vision-language models to new tasks. The authors propose a log-likelihood ratio (LLR) approach that analyzes the comparative benefits of these two transfer learning methods by decomposing input data into in-distribution (ID) and out-of-distribution (OOD) components. By employing resource-efficient visual prompt approximations (Gaussian noise, gradient-based, and mini-finetuning), the method achieves up to 100-fold runtime reduction compared to full training while maintaining strong predictive accuracy. Experiments across 12 datasets and 5 pre-trained models demonstrate that LLR scores effectively predict which adaptation method will yield better accuracy, with high correlation to actual performance gains.

## Method Summary
The method computes log-likelihood ratios (LLR) to compare visual prompting (VP) and linear probing (LP) by analyzing how each method performs on ID versus OOD data. The LLR score is calculated using LogME evidence estimation on feature matrices extracted from pre-trained models. To make this computationally efficient, the authors develop three visual prompt approximation methods: Gaussian noise injection, gradient-based prompts, and mini-finetuning on small subsets. The approach ranks datasets by their LLR scores, where positive scores indicate VP is better suited for OOD data and negative scores suggest LP is preferable for ID data. The method validates its predictions by comparing LLR rankings with actual accuracy gains between VP and LP using Kendall's τ and Spearman's ρ correlation metrics.

## Key Results
- LLR scores align well with actual accuracy gains between VP and LP across multiple datasets and models
- The method achieves up to 100× speedup through efficient prompt approximations compared to full training
- LLR outperforms traditional OOD detection baselines in ranking datasets for optimal transfer learning method selection
- High correlation (Kendall's τ and Spearman's ρ) between LLR scores and actual accuracy differences validates the predictive capability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The log-likelihood ratio (LLR) score effectively identifies whether visual prompting (VP) or linear probing (LP) is more suitable for a given dataset by comparing the likelihood of VP vs LP on ID vs OOD data.
- Mechanism: LLR decomposes input data into ID and OOD components, then computes the difference in log-likelihoods between VP and LP for each component. Positive LLR indicates VP is better for OOD, negative indicates LP is better for ID.
- Core assumption: Visual prompts contribute differently to ID vs OOD data, with prompts disrupting ID features but enhancing OOD recognition.
- Evidence anchors:
  - [abstract] "We propose a log-likelihood ratio (LLR) approach to analyze the comparative benefits of visual prompting and linear probing"
  - [section 3.1] "By decomposing the input x into components xID and xOOD, we can analyze the distinct impacts of visual prompts on ID and OOD inputs"
  - [corpus] Weak - no direct corpus evidence for this mechanism

### Mechanism 2
- Claim: Visual prompt approximations enable efficient LLR computation without full training, achieving up to 100x speedup.
- Mechanism: Instead of training actual visual prompts, the method uses three approximations: Gaussian noise, gradient-based prompts, and mini-finetuning on small subsets. These approximations are evaluated using LogME evidence.
- Core assumption: Simulated prompts can effectively approximate trained prompts in terms of their impact on model features.
- Evidence anchors:
  - [abstract] "By employing the LLR score alongside resource-efficient visual prompts approximations, our cost-effective measure attains up to a 100-fold reduction in run time compared to full training"
  - [section 3.3] "we explore different methods for simulating prompt distributions" including Gaussian, gradient, and mini-finetuning approaches
  - [corpus] Weak - no direct corpus evidence for this mechanism

### Mechanism 3
- Claim: LLR scores correlate with actual accuracy gains between VP and LP, making them reliable predictors for method selection.
- Mechanism: The method validates that LLR rankings align with Kendall's τ and Spearman's ρ coefficients when compared to actual accuracy differences, achieving high LLR-Acc scores.
- Core assumption: The likelihood-based LLR metric captures the same underlying factors that determine accuracy differences between VP and LP.
- Evidence anchors:
  - [abstract] "LLR scores align well with accuracy gains and outperform OOD detection baselines in ranking datasets for the appropriate transfer learning method"
  - [section 4.1] "we observe a close correlation between LLR scores and actual accuracy gains"
  - [corpus] Weak - no direct corpus evidence for this mechanism

## Foundational Learning

- Concept: Log-likelihood ratio (LLR) and evidence estimation
  - Why needed here: LLR forms the core of the method, comparing VP vs LP performance through likelihood ratios, while evidence estimation enables efficient computation without full training
  - Quick check question: How does the log-likelihood ratio in Equation 3 decompose the input data, and what does a positive vs negative LLR indicate about VP vs LP suitability?

- Concept: Visual prompting vs linear probing mechanisms
  - Why needed here: Understanding how VP adds trainable prompts around images versus LP adjusting only the linear layer is crucial for interpreting LLR results and implementation
  - Quick check question: What are the key architectural differences between VP and LP in terms of parameter updates and feature extraction points?

- Concept: OOD detection and dataset characterization
  - Why needed here: The method relies on distinguishing ID vs OOD data to determine when VP outperforms LP, building on established OOD detection techniques
  - Quick check question: How does the method's approach to ID/OOD characterization differ from traditional OOD detection methods that use confidence scores or Mahalanobis distance?

## Architecture Onboarding

- Component map: Pre-trained model -> Feature extractor -> Log-likelihood calculator -> Visual prompt simulator -> LLR scorer -> Method ranking
- Critical path: 1) Extract features from clean image (LP) and prompted image (VP) using pre-trained model, 2) Compute LogME evidence scores for both VP and LP using feature matrices, 3) Calculate LLR score as difference between VP and LP log-likelihoods, 4) Rank datasets by LLR scores to determine optimal adaptation method
- Design tradeoffs: VP maintains pre-trained model weights frozen but requires prompt training space and can disrupt ID features; LP is simpler but may underperform on OOD data; approximations sacrifice some accuracy for 100x speedup but must balance computational cost with prompt fidelity
- Failure signatures: Low Kendall's τ or Spearman's ρ between LLR scores and actual accuracy gains indicates poor correlation; high KL divergence between simulated and trained prompts suggests approximations are inadequate; negative accuracy gains when LLR suggests VP should win indicates fundamental model mismatch
- First 3 experiments:
  1. Run LLR calculation on a simple dataset pair (SVHN vs DTD) to verify positive LLR for OOD and negative for ID as shown in Figure 4
  2. Compare LLR rankings using different prompt approximations (Gaussian vs gradient vs mini-finetuning) to validate convergence toward trained prompts
  3. Test LLR prediction accuracy on a held-out dataset not used in training to assess generalization of the ranking method

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided text.

## Limitations
- The analysis relies on approximations of visual prompts that may not fully capture trained prompt behavior
- The LLR method assumes visual prompts affect ID and OOD data differently, which may not hold across all dataset distributions
- The evidence for core mechanisms is weak, with no direct corpus validation of theoretical claims

## Confidence
- Mechanism 1 (LLR decomposition): Medium - Theoretical framework is sound but empirical validation is limited
- Mechanism 2 (Prompt approximations): Low - No direct comparison between approximated and fully-trained prompts
- Mechanism 3 (LLR-accuracy correlation): Medium - Shows good correlation in experiments but lacks external validation
- Overall method effectiveness: Medium - Works well on tested datasets but generalization to new scenarios is uncertain

## Next Checks
1. Test LLR predictions on a completely new set of datasets and models not included in the original study to assess generalizability
2. Compare LLR scores computed using fully-trained visual prompts versus approximated prompts to measure approximation error
3. Evaluate the method's performance on datasets with varying degrees of ID/OOD separation to identify boundary conditions where the approach breaks down