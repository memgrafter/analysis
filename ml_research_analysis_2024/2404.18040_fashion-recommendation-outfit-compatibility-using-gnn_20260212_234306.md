---
ver: rpa2
title: 'Fashion Recommendation: Outfit Compatibility using GNN'
arxiv_id: '2404.18040'
source_url: https://arxiv.org/abs/2404.18040
tags:
- outfit
- item
- items
- compatibility
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work addresses the problem of outfit compatibility and fashion\
  \ recommendation using graph neural networks. Two graph-based approaches\u2014Node-wise\
  \ Graph Neural Network (NGNN) and Hypergraph Neural Network (HGNN)\u2014are evaluated\
  \ on Polyvore dataset subsets for Fill-in-the-Blank (FITB) and Compatibility Prediction\
  \ tasks."
---

# Fashion Recommendation: Outfit Compatibility using GNN

## Quick Facts
- **arXiv ID**: 2404.18040
- **Source URL**: https://arxiv.org/abs/2404.18040
- **Reference count**: 3
- **Primary result**: GNN-based fashion recommendation models achieve 39% FITB accuracy and 0.76 AUC for compatibility prediction

## Executive Summary
This work addresses outfit compatibility and fashion recommendation using graph neural networks. Two approaches - Node-wise Graph Neural Network (NGNN) and Hypergraph Neural Network (HGNN) - are evaluated on Polyvore dataset subsets for Fill-in-the-Blank (FITB) and Compatibility Prediction tasks. Both models use node embeddings derived from item categories, with HGNN capturing higher-order interactions via hyperedges. Experiments show HGNN marginally outperforms NGNN: 39% vs 38% FITB accuracy and 0.76 vs 0.65 AUC for compatibility prediction. Multi-modal embeddings improve results over single modalities. Performance is lower than original papers due to reduced dataset size from computational constraints.

## Method Summary
The study implements two graph-based approaches for fashion recommendation. NGNN processes individual node interactions within the outfit graph, while HGNN uses hyperedges to capture higher-order relationships between multiple items simultaneously. Both models generate node embeddings from item categories as input features. The experiments are conducted on Polyvore dataset subsets due to computational limitations, with evaluation on FITB and Compatibility Prediction tasks. Vision Transformer embeddings are incorporated to provide additional visual features alongside text-based embeddings.

## Key Results
- HGNN achieves 39% accuracy on FITB task compared to NGNN's 38%
- Compatibility prediction shows HGNN with 0.76 AUC versus NGNN's 0.65 AUC
- Multi-modal embeddings (text + visual) outperform single modality approaches
- Performance metrics are lower than original papers due to reduced dataset size

## Why This Works (Mechanism)
Graph neural networks excel at capturing relational patterns in fashion outfits by modeling items as nodes and their compatibility relationships as edges. The hypergraph extension allows HGNN to capture complex, higher-order interactions between multiple items that traditional pairwise relationships miss. By incorporating both visual and textual features through multi-modal embeddings, the models can better understand the semantic and visual coherence of outfits. The node-wise processing in NGNN establishes baseline compatibility relationships, while HGNN's hyperedges enable more sophisticated reasoning about outfit composition.

## Foundational Learning
- **Graph Neural Networks**: Needed to model item relationships in outfits; quick check: verify message passing between connected nodes works correctly
- **Hypergraphs**: Required for capturing multi-way item interactions; quick check: ensure hyperedges properly aggregate information from multiple nodes
- **Multi-modal Embeddings**: Essential for combining visual and textual fashion features; quick check: validate embedding dimensions match model requirements
- **Outfit Compatibility**: Core task definition; quick check: confirm ground truth labels are correctly formatted
- **Polyvore Dataset**: Standard benchmark for fashion recommendation; quick check: verify dataset preprocessing maintains item relationships

## Architecture Onboarding
**Component Map**: Input Embeddings -> NGNN/HGNN Layers -> Compatibility Prediction
**Critical Path**: Node embeddings → Graph message passing → Output logits
**Design Tradeoffs**: HGNN adds complexity for potentially better higher-order reasoning vs NGNN's simpler pairwise approach
**Failure Signatures**: Poor performance on both tasks suggests embedding issues; HGNN underperforming NGNN indicates hyperedge construction problems
**First Experiments**: 1) Train NGNN with text embeddings only; 2) Train HGNN with visual embeddings only; 3) Compare single vs multi-modal performance

## Open Questions the Paper Calls Out
None

## Limitations
- Reduced dataset size due to computational constraints impacts result generalizability
- Marginal performance differences between NGNN and HGNN raise questions about practical significance
- Limited to two specific tasks without exploring broader recommendation metrics

## Confidence
- Core methodology and experimental design: **High**
- Reported performance metrics: **Medium** (due to reduced dataset size)
- Comparative analysis between NGNN and HGNN: **Medium** (marginal differences, no significance testing)

## Next Checks
1. Conduct experiments on the full dataset to verify whether the performance gap between NGNN and HGNN remains consistent when computational constraints are removed
2. Perform statistical significance testing (e.g., paired t-tests or McNemar's test) on the model comparisons to determine if observed differences are meaningful
3. Expand evaluation to include additional metrics such as top-k recommendation accuracy and user-centric measures to better assess practical utility