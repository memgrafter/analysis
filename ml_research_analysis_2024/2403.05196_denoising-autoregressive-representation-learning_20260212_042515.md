---
ver: rpa2
title: Denoising Autoregressive Representation Learning
arxiv_id: '2403.05196'
source_url: https://arxiv.org/abs/2403.05196
tags:
- learning
- patch
- image
- diffusion
- denoising
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DARL, a generative approach for learning visual
  representations by employing a decoder-only Transformer to predict image patches
  autoregressively. The authors find that training with Mean Squared Error (MSE) loss
  alone leads to strong representations, and further enhance the image generation
  ability by replacing the MSE loss with a diffusion objective using a denoising patch
  decoder.
---

# Denoising Autoregressive Representation Learning

## Quick Facts
- arXiv ID: 2403.05196
- Source URL: https://arxiv.org/abs/2403.05196
- Authors: Yazhe Li; Jorg Bornschein; Ting Chen
- Reference count: 39
- Primary result: DARL achieves performance remarkably close to state-of-the-art masked prediction models under fine-tuning protocol, with only 1% performance gap.

## Executive Summary
This paper presents DARL, a generative approach for learning visual representations using a decoder-only Transformer to predict image patches autoregressively. The authors find that MSE loss alone yields strong representations comparable to masked prediction models, and further improve image generation by using a diffusion objective with a denoising patch decoder. By employing tailored noise schedules and longer training in larger models, DARL achieves performance remarkably close to state-of-the-art masked prediction models under the fine-tuning protocol, with only a 1% performance gap.

## Method Summary
DARL uses a decoder-only Transformer with causal attention masking to predict image patches autoregressively from fixed raster ordering. The model can be trained with either MSE loss or a diffusion objective using a denoising patch decoder. Key architectural choices include 2D Rotary Position Embedding (RoPE) for spatial encoding and a start token for patch sequence generation. The method employs either standard MSE loss or a diffusion process where patches are gradually corrupted and the model learns to denoise them.

## Key Results
- DARL achieves 84.6% top-1 accuracy on ImageNet with fine-tuning, close to state-of-the-art MAE (85.6%)
- On VTAB benchmark, DARL reaches 76.5% accuracy compared to MAE's 77.1%
- The model performs competitively on COCO object detection and segmentation tasks
- 2D RoPE positional encodings provide significant performance gains for causal Transformers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Autoregressive modeling with MSE loss alone yields strong visual representations comparable to masked prediction models.
- Mechanism: The decoder-only Transformer predicts the next image patch based on previously observed patches, learning spatial and semantic structure through next-token prediction.
- Core assumption: Image patch sequences contain sufficient information for representation learning without explicit reconstruction objectives.
- Evidence anchors:
  - [abstract] "We find that training with Mean Squared Error (MSE) loss alone leads to strong representations."
  - [section] "When trained with MSE loss, the fine-tuning performance of the model is not far away from the state-of-the-art representation methods."
- Break condition: If patch ordering or spatial dependencies are critical for downstream tasks, fixed raster ordering may become a bottleneck.

### Mechanism 2
- Claim: Diffusion denoising with tailored noise schedules improves representation quality in larger models.
- Mechanism: The denoising patch decoder learns to recover corrupted patches, capturing multi-modal patch distributions and enhancing feature learning across spatial frequencies.
- Core assumption: Higher noise levels force the model to learn more abstract representations rather than low-level details.
- Evidence anchors:
  - [abstract] "We show that the learned representation can be improved by using tailored noise schedules and longer training in larger models."
  - [section] "When the noise schedule is more focused on high noise levels, training with diffusion objective leads to an improvement which becomes more pronounced with extended pre-training epochs."
- Break condition: If noise schedule doesn't align with model capacity, performance may degrade rather than improve.

### Mechanism 3
- Claim: 2D Rotary Position Embedding (RoPE) provides significant performance gains for causal Transformers in vision.
- Mechanism: Decomposing RoPE along x and y axes provides better spatial inductive bias compared to absolute or learnable positional encodings.
- Core assumption: Relative positional encodings are more effective for image data than absolute ones, especially for autoregressive models.
- Evidence anchors:
  - [section] "We show that 2D RoPE improves the performance, in particular for causal Transformers."
  - [section] "Table 1 suggests that RoPE, both 1D and 2D versions, outperforms other types of positional encodings with or without causal attention masking."
- Break condition: If model capacity or architecture changes significantly, positional encoding benefits may diminish.

## Foundational Learning

- Concept: Autoregressive modeling and causal attention masking
  - Why needed here: Ensures each patch prediction only uses previous patches, maintaining temporal dependency crucial for next-token prediction
  - Quick check question: What would happen if causal attention masking was removed during pre-training?

- Concept: Diffusion process and variational lower bound
  - Why needed here: Provides the mathematical framework for gradually corrupting and denoising image patches, enabling multi-modal distribution learning
  - Quick check question: How does the noise schedule affect which spatial frequencies the model learns to represent?

- Concept: Relative positional encodings (2D RoPE)
  - Why needed here: Provides spatial inductive bias for image data while maintaining translation equivariance, crucial for visual tasks
  - Quick check question: Why might 2D RoPE outperform 1D RoPE for image data?

## Architecture Onboarding

- Component map: Image patches → Linear projection → Sequence with start token → Decoder-only Transformer with causal attention masking → Predicted next image patch → Loss computation (MSE or diffusion)

- Critical path: Image → Patch embedding → Transformer → Patch prediction → Loss computation

- Design tradeoffs:
  - Causal vs non-causal attention: Causal preserves autoregressive nature but slightly reduces performance
  - MSE vs diffusion: MSE simpler but diffusion enables better generation; diffusion requires careful noise schedule tuning
  - Fixed vs random patch ordering: Fixed raster order works best; random ordering requires architectural changes

- Failure signatures:
  - Poor fine-tuning performance → Check patch ordering, causal masking, or positional encoding
  - Blurry generations → Verify diffusion loss implementation and noise schedule
  - Unstable training → Check learning rate, batch size, or initialization

- First 3 experiments:
  1. Train with MSE loss and evaluate ImageNet fine-tuning accuracy to establish baseline
  2. Switch to diffusion objective with default noise schedule and compare performance
  3. Implement 2D RoPE and measure impact on both MSE and diffusion training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DARL's performance scale with model size beyond the standard ViT family sizes tested?
- Basis in paper: [inferred] The paper mentions observing a correlation between validation loss during pre-training and downstream performance for both MSE and diffusion loss, but notes insufficient datapoints for statistically significant analysis.
- Why unresolved: The paper only tested standard ViT family sizes and didn't conduct a systematic study of larger models.
- What evidence would resolve it: Systematic experiments with larger model sizes, measuring both validation loss and downstream performance, would provide insights into scaling behavior.

### Open Question 2
- Question: Does using a discrete VAE tokenizer improve DARL's performance, and under what conditions?
- Basis in paper: [explicit] The paper provides preliminary results using a dVAE tokenizer, showing that using dVAE to encode image patches negatively impacts performance, but using dVAE as the target is only slightly worse than MSE or denoising.
- Why unresolved: The paper suggests that further investigation is needed for longer training schedules and evaluation on other downstream tasks.
- What evidence would resolve it: Extensive experiments with dVAE tokenization under various conditions (training length, downstream tasks) would determine its effectiveness.

### Open Question 3
- Question: What is the optimal patch ordering strategy for DARL, and does random ordering offer any advantages?
- Basis in paper: [explicit] The paper explores fixed ordering strategies (raster, nested raster, round-robin) and random ordering using a two-stream XLNet architecture, finding that raster ordering is near-optimal and random ordering doesn't offer performance advantages.
- Why unresolved: While the paper provides insights, it doesn't conclusively determine the optimal patch ordering strategy or explore all possible ordering methods.
- What evidence would resolve it: Further experiments comparing various patch ordering strategies (including more complex methods) on larger datasets and with different model architectures would help determine the optimal approach.

## Limitations
- Exact implementation details of the denoising patch decoder are not specified
- Optimal noise schedule parameters (a and b values for Beta distribution) are not provided
- Generalizability to domains beyond ImageNet remains untested
- Computational requirements for longer training schedules in larger models could limit practical applicability

## Confidence
- **High confidence**: DARL achieves competitive representation learning performance using autoregressive modeling with MSE loss, and 2D RoPE provides measurable improvements for causal Transformers in vision tasks
- **Medium confidence**: The diffusion objective with tailored noise schedules improves representation quality in larger models, though specific noise schedule parameters are not provided
- **Low confidence**: The generalizability of DARL's representation learning approach to domains beyond ImageNet and the scalability to significantly larger model sizes remain untested assumptions

## Next Checks
1. **Noise schedule sensitivity analysis**: Systematically vary the noise schedule parameters (a and b) to determine their impact on representation quality and identify the optimal configuration for downstream tasks
2. **Cross-dataset generalization**: Evaluate DARL representations on diverse datasets (e.g., CIFAR, Places, COCO) to assess whether the strong ImageNet performance generalizes beyond curated image classification tasks
3. **Patch ordering ablation**: Compare fixed raster ordering against random patch ordering and learnable permutations to determine whether spatial dependencies captured by DARL are essential for representation quality