---
ver: rpa2
title: Data-dependent and Oracle Bounds on Forgetting in Continual Learning
arxiv_id: '2406.09370'
source_url: https://arxiv.org/abs/2406.09370
tags:
- tasks
- forgetting
- learning
- task
- bounds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides theoretical bounds on forgetting in continual
  learning. The authors derive both data-dependent upper bounds applicable to any
  model and algorithm, and oracle bounds for Gibbs posteriors.
---

# Data-dependent and Oracle Bounds on Forgetting in Continual Learning

## Quick Facts
- arXiv ID: 2406.09370
- Source URL: https://arxiv.org/abs/2406.09370
- Authors: Lior Friedman; Ron Meir
- Reference count: 40
- Primary result: Theoretical bounds on forgetting in continual learning, with data-dependent and oracle bounds showing low forgetting for similar tasks

## Executive Summary
This paper provides theoretical bounds on forgetting in continual learning by deriving both data-dependent upper bounds applicable to any model and algorithm, and oracle bounds for Gibbs posteriors. The authors demonstrate that forgetting can be low when tasks are similar and show that their approach yields tight and practical bounds across several continual learning problems including synthetic Gaussian data, permuted-MNIST, split-MNIST, and split-CIFAR10. The key insight is that the tightness of bounds depends on task similarity and the ability of the shared model to capture knowledge across tasks.

## Method Summary
The method centers on Algorithm 1 (PAC-Bayes Continual Learning), which minimizes an upper bound on backward transfer by balancing task performance with minimal posterior drift through KL-divergence regularization. The algorithm uses variational inference with Gaussian approximations to estimate posteriors and can also be approximated via Elastic Weight Consolidation. The approach derives data-dependent bounds using the Donsker-Varadhan change-of-measure inequality and oracle bounds for Gibbs posteriors when tasks have positively correlated losses.

## Key Results
- Data-dependent bounds hold regardless of model choice through change-of-measure inequality
- Oracle bounds show low forgetting when tasks are similar (positive loss covariance)
- Algorithm yields tight bounds on forgetting across synthetic and vision datasets
- As shared model improves over tasks, forgetting decreases and bounds become tighter

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data-dependent upper bound on backward transfer holds regardless of model choice
- Mechanism: Uses Donsker-Varadhan change-of-measure inequality to isolate task-dependent performance gap from model-agnostic KL-divergence
- Core assumption: Loss is bounded and tasks are sampled independently
- Evidence anchors: Abstract mentions "data-dependent upper bounds that apply regardless of model and algorithm choice"
- Break condition: Unbounded loss or adversarially constructed tasks

### Mechanism 2
- Claim: Oracle bounds for Gibbs posteriors provide tight forgetting bounds for similar tasks
- Mechanism: Gibbs posterior optimizes bound's right-hand side; positive loss covariance ensures hypotheses performing well on one task also perform well on others
- Core assumption: Task similarity measured by positive covariance between exponential loss terms
- Evidence anchors: Corollary 4.2 states "if covλt(P, s, t) ≥ 0"
- Break condition: Orthogonal or negatively correlated tasks

### Mechanism 3
- Claim: Algorithm achieves low forgetting by minimizing upper bound on backward transfer
- Mechanism: Explicitly optimizes bound by minimizing task performance plus KL-divergence between successive posteriors
- Core assumption: KL-divergence can be efficiently estimated via variational inference
- Evidence anchors: Algorithm 1 uses "ˆL(Q1:t, St) + (1/λt)DKL(Q1:t||Q1:t-1)"
- Break condition: Computationally intractable posterior estimation

## Foundational Learning

- Concept: Change-of-measure inequality (Donsker-Varadhan)
  - Why needed here: Forms mathematical foundation for data-dependent bounds on backward transfer
  - Quick check question: What is the role of Eπ[eλt(f(z)-Eπf(z))] in the change-of-measure inequality?

- Concept: KL-divergence and PAC-Bayes bounds
  - Why needed here: Quantifies distance between successive posteriors, controlling forgetting through posterior stability
  - Quick check question: How does KL-divergence term behave as number of tasks increases?

- Concept: Loss covariance as task similarity measure
  - Why needed here: Determines whether knowledge transfer between tasks is beneficial or harmful for forgetting
  - Quick check question: What happens to bound when covλt(P,s,t) < 0 (negative correlation)?

## Architecture Onboarding

- Component map: Task sequence -> Model update -> Posterior estimation -> Bound calculation -> Forgetting measurement
- Critical path: Task sequence → Model update → Posterior estimation → Bound calculation → Forgetting measurement
- Design tradeoffs:
  - Model capacity vs. bound tightness: Larger models may increase KL-divergence, loosening bounds
  - Computational budget vs. posterior accuracy: VI requires more epochs than EWC but may yield tighter bounds
  - Task order vs. forgetting: Gradual vs. orthogonal shifts significantly impact forgetting behavior
- Failure signatures:
  - KL-divergence explosion: Indicates model changing too rapidly between tasks
  - Bound loosening over time: Suggests posterior estimation or model capacity issues
  - Negative forgetting values: May indicate optimization issues or overly optimistic bounds
- First 3 experiments:
  1. Synthetic 10d Gaussian data with similar tasks to validate basic bound tightness
  2. Gradual shift scenario to test bound behavior during smooth distribution changes
  3. Orthogonal shift case to verify bounds remain meaningful when forgetting is desirable

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does tightness of data-dependent bounds scale with model size and complexity?
- Basis in paper: The paper notes that KL-divergence term may become looser for larger models
- Why unresolved: Experiments focused on small neural networks; no theoretical analysis of bound scaling
- What evidence would resolve it: Theoretical analysis of KL-divergence for different model sizes, or empirical results comparing bound tightness across architectures

### Open Question 2
- Question: How do bounds behave under adversarial task constructions where tasks aren't sampled independently?
- Basis in paper: Paper acknowledges bounds assume independent task sampling
- Why unresolved: No analysis or results on non-independent task sampling scenarios
- What evidence would resolve it: Theoretical analysis under different task sampling scenarios, or empirical results comparing different task orderings

### Open Question 3
- Question: Can bounds be extended to other continual learning algorithms beyond VI and EWC?
- Basis in paper: Bounds are applicable regardless of model choice but only demonstrated for VI and EWC
- Why unresolved: No analysis or results on other algorithm classes
- What evidence would resolve it: Theoretical analysis for different algorithm classes, or empirical results comparing various continual learning algorithms

### Open Question 4
- Question: How do bounds behave under different task similarity measures and assumptions?
- Basis in paper: Oracle bounds derived under specific task similarity assumptions
- Why unresolved: No extensive analysis or results on different task similarity measures
- What evidence would resolve it: Theoretical analysis under different task similarity measures, or empirical results comparing different similarity scenarios

## Limitations
- Theoretical assumptions (bounded loss, independent task sampling) may not hold in practical scenarios
- Task similarity requirement for tight oracle bounds may be difficult to verify in complex, heterogeneous task sequences
- Computational tractability of variational inference approximation remains uncertain for high-dimensional problems

## Confidence
**High Confidence**: Data-dependent upper bound on backward transfer - follows directly from established PAC-Bayes theory and Donsker-Varadhan inequality with well-defined assumptions.

**Medium Confidence**: Oracle bounds for Gibbs posteriors - theoretically sound but practical relevance depends heavily on task similarity assumption.

**Medium Confidence**: Algorithm's practical performance - empirical results show promise but computational complexity and scalability remain unclear.

## Next Checks
1. **Stress Test Task Correlation**: Systematically generate task sequences with varying correlation degrees to validate how oracle bounds behave when covλt(P,s,t) ≥ 0 assumption is violated.

2. **Bounded Loss Verification**: Test data-dependent bounds on tasks with known unbounded losses to quantify degradation in bound tightness and identify practical workarounds.

3. **Scalability Assessment**: Implement Algorithm 1 on larger-scale continual learning problems to evaluate computational feasibility of variational inference approximation and practical value of bounds for model selection.