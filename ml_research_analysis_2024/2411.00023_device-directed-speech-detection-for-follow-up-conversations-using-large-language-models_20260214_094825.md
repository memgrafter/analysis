---
ver: rpa2
title: Device-Directed Speech Detection for Follow-up Conversations Using Large Language
  Models
arxiv_id: '2411.00023'
source_url: https://arxiv.org/abs/2411.00023
tags:
- follow-up
- query
- context
- speech
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the use of Large Language Models (LLMs) for
  Device-Directed Speech Detection (DDSD) in follow-up conversations with virtual
  assistants. The key innovation is modeling both the initial and follow-up queries
  together, leveraging ASR uncertainty via n-best hypotheses for the follow-up.
---

# Device-Directed Speech Detection for Follow-up Conversations Using Large Language Models

## Quick Facts
- **arXiv ID**: 2411.00023
- **Source URL**: https://arxiv.org/abs/2411.00023
- **Reference count**: 21
- **Primary result**: Classification-based LLM approach with LoRA adapters achieves 14.9% FRR and 1.8% FAR at 10% FRR for follow-up conversation DDSD

## Executive Summary
This paper addresses the challenge of detecting device-directed speech in follow-up conversations with virtual assistants, where a user's second utterance may be directed to the device or to a human being. The authors propose using Large Language Models (LLMs) to jointly model both the initial device-directed query and the follow-up query, leveraging ASR uncertainty through n-best hypotheses. Two approaches are explored: prompting-based and classification-based, with the latter showing superior performance. The best approach, ClassLoRAHead, achieves significant improvements over modeling follow-ups alone, demonstrating 20-40% reduction in FAR while maintaining low FRR.

## Method Summary
The method involves using LLMs to detect whether follow-up utterances in conversations with virtual assistants are directed to the device or to a human. The approach leverages both the initial device-directed query context and ASR uncertainty through n-best hypotheses for the follow-up. Two implementation strategies are proposed: a prompting-based approach using direct LLM prompting or LoRA finetuning, and a classification-based approach with a classifier head on top of the LLM. The classification-based approach with LoRA adapters (ClassLoRAHead) performs best, achieving 14.9% FRR and 1.8% FAR at 10% FRR. The dataset consists of approximately 245k utterance pairs from 19k audio recordings, with 1.3k participants, split into training (70%), validation (10%), and test (20%) sets.

## Key Results
- Classification-based approach with LoRA adapters (ClassLoRAHead) achieves 14.9% FRR and 1.8% FAR at 10% FRR
- 20-40% reduction in FAR compared to modeling follow-ups alone
- Joint modeling of initial and follow-up queries with n-best hypotheses significantly improves detection accuracy
- LoRA-based approach is 5-10 times faster to train than full fine-tuning while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1: Contextual Disambiguation
Claim: Joint modeling of initial and follow-up queries improves DDSD accuracy by providing contextual disambiguation.
Mechanism: When the LLM processes both the initial query (always device-directed) and the follow-up query together, it can leverage the conversational context to better determine whether the follow-up is also device-directed. This is particularly helpful when the follow-up query content is ambiguous on its own.
Core assumption: The initial query provides sufficient contextual information to disambiguate follow-up queries that would otherwise be difficult to classify correctly.
Evidence anchors:
- [abstract]: "due to the joint modeling of the previous speech context and ASR uncertainty, compared to when follow-ups are modeled alone"
- [section]: "Table 2 (left) compares the prompting- vs. classification-based approaches... By looking at the role of the context, we note that adding the n-best hypothesis for the initial query helps when the n-best hypothesis is used for the follow-up (FAR 16.4% → 2.3%). This shows the importance of the context."
Break condition: If follow-up queries are contextually independent of the initial query, or if the initial query is itself ambiguous or device-undirected, the contextual benefit disappears.

### Mechanism 2: ASR Uncertainty Modeling
Claim: Exposing the LLM to n-best ASR hypotheses reduces information bottleneck and improves detection accuracy.
Mechanism: Instead of using only the 1-best ASR hypothesis, providing n-best hypotheses (with associated costs) gives the LLM access to the ASR uncertainty distribution. This additional information helps the model make more informed decisions about whether the follow-up query is device-directed.
Core assumption: ASR uncertainty contains meaningful signal about device-directedness that is not captured in the 1-best hypothesis alone.
Evidence anchors:
- [abstract]: "we also exploit the ASR uncertainty when designing the LLM prompts"
- [section]: "We expand this information bottleneck by exposing the LLM to an n-best list of ASR hypotheses, and we do so only for the follow-up utterance to prevent confusing the model"
Break condition: If ASR hypotheses are highly correlated (low uncertainty) or if the n-best list becomes too large and introduces noise that overwhelms the signal.

### Mechanism 3: Parameter-Efficient Fine-Tuning
Claim: LoRA-based fine-tuning of classification heads enables efficient adaptation of LLMs for DDSD while preserving performance.
Mechanism: By adding a classification head on top of the frozen LLM and fine-tuning only the LoRA adapters (instead of the entire model), the approach achieves significant parameter efficiency while maintaining or improving accuracy compared to full fine-tuning.
Core assumption: The pretrained LLM has learned general language understanding that can be leveraged for DDSD with minimal task-specific adaptation.
Evidence anchors:
- [section]: "We also showed that the classifier-adapted approaches can achieve high accuracy by tuning a fraction of the LLM parameters (via LoRA), saving the compute time"
- [section]: "the LoRA-based approach has less tunable parameters and is much faster to train (on the used dataset, the reduce in the train time was ∼5-10 times)"
Break condition: If the pretrained LLM lacks sufficient domain knowledge for the DDSD task, or if the classification head architecture is insufficient to capture task-specific patterns.

## Foundational Learning

- **Concept**: Automatic Speech Recognition (ASR) uncertainty modeling
  - Why needed here: The paper leverages n-best hypotheses from ASR systems to capture uncertainty in speech-to-text conversion, which provides additional signal for DDSD
  - Quick check question: What information does the n-best hypothesis list provide that the 1-best hypothesis does not?

- **Concept**: Context modeling in conversational AI
  - Why needed here: The approach relies on using the initial query context to improve follow-up query classification, which is fundamental to understanding how conversational context improves task performance
  - Quick check question: Why might an isolated follow-up query be more difficult to classify than a follow-up query with its preceding context?

- **Concept**: Parameter-efficient fine-tuning (PEFT) methods
  - Why needed here: The paper uses LoRA adapters for efficient model adaptation, which is a key technique for adapting large models to new tasks without full fine-tuning
  - Quick check question: How does LoRA differ from traditional fine-tuning in terms of which parameters are updated?

## Architecture Onboarding

- **Component map**: ASR System → n-best hypotheses generation → Prompt Engineering → LLM Base → Classification Head → Training Pipeline → Inference Pipeline → DDSD decision
- **Critical path**: ASR output → Prompt construction → LLM processing → Classification → DDSD decision
- **Design tradeoffs**:
  - Context vs. Simplicity: Using initial query context improves accuracy but adds complexity to the pipeline
  - ASR uncertainty vs. Noise: n-best hypotheses provide additional signal but may introduce noise if too many hypotheses are included
  - Full fine-tuning vs. LoRA: Full fine-tuning may achieve better accuracy but at significantly higher computational cost
  - Prompt engineering vs. Classification head: Prompt-based approaches are simpler but less tunable than classification-based approaches
- **Failure signatures**:
  - High FAR with low FRR: Model is too permissive, likely overfitting to device-directed patterns
  - High FRR with low FAR: Model is too conservative, likely missing contextual cues
  - Degradation with n-best hypotheses: Model is confused by ASR uncertainty rather than helped by it
  - Performance plateau with additional context: Initial query provides diminishing returns beyond a certain point
- **First 3 experiments**:
  1. Baseline: Test classification accuracy using only 1-best follow-up hypothesis (no context, no ASR uncertainty modeling)
  2. Context addition: Test classification accuracy using both initial and follow-up 1-best hypotheses to measure contextual benefit
  3. ASR uncertainty: Test classification accuracy using n-best follow-up hypotheses (no context) to measure benefit of uncertainty modeling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed DDSD approach perform with multi-turn conversations beyond just pairs of queries?
- Basis in paper: [explicit] The paper mentions that "other signals (e.g. V A's responses, acoustic features, and speaker information) can also be integrated to further improve the system accuracy."
- Why unresolved: The experiments only evaluated on pairs of user queries, not on longer conversation chains.
- What evidence would resolve it: Experiments testing the model's performance on conversations with 3+ turns, comparing accuracy degradation or improvement over multiple exchanges.

### Open Question 2
- Question: What is the optimal number of n-best hypotheses for ASR uncertainty that balances accuracy and computational cost?
- Basis in paper: [explicit] "We also observed diminishing gains as we increase the size of the n-best list beyond n = 8, which can be due to the model overfitting and/or getting more confused by the uncertainty from too many ASR hypotheses."
- Why unresolved: The paper tested n=8 but suggests there might be an optimal point before diminishing returns.
- What evidence would resolve it: Systematic experiments varying n from 1 to 20, measuring accuracy gains against computational overhead.

### Open Question 3
- Question: How does the proposed method compare to traditional acoustic-only DDSD approaches?
- Basis in paper: [inferred] The paper focuses on text-based approaches using LLM, but mentions that previous works used "acoustic and lexical features" for DDSD.
- Why unresolved: The paper only compares different LLM-based approaches, not against traditional acoustic feature-based methods.
- What evidence would resolve it: Head-to-head comparison of the LLM-based approach against acoustic feature-based DDSD systems on the same dataset, measuring both accuracy and resource requirements.

## Limitations

- The results are based on a specific dataset from a single virtual assistant platform, limiting generalizability to other domains or conversational contexts
- The ASR system used is internal and proprietary, making exact replication challenging
- The evaluation focuses primarily on binary classification metrics without exploring the impact on end-user experience or conversational flow

## Confidence

- **High confidence** in the overall superiority of classification-based approaches with LoRA adapters, supported by multiple ablation studies and clear performance improvements
- **Medium confidence** in the contextual benefit mechanism, as the evidence shows correlation but doesn't fully establish causation between context modeling and improved accuracy
- **Low confidence** in the ASR uncertainty modeling claims, as the paper doesn't provide sufficient evidence about why n-best hypotheses specifically help beyond showing improved metrics

## Next Checks

1. **Cross-domain validation**: Test the approach on a different conversational dataset (e.g., customer service interactions or smart home scenarios) to assess generalizability beyond the original virtual assistant context
2. **Ablation on ASR quality**: Systematically vary ASR accuracy levels to determine whether the n-best hypothesis benefit scales with ASR uncertainty or is independent of ASR quality
3. **Human evaluation study**: Conduct user studies to measure whether the improved DDSD accuracy translates to better user experience and reduced conversational friction in real-world usage scenarios