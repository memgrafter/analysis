---
ver: rpa2
title: 'TSDS: Data Selection for Task-Specific Model Finetuning'
arxiv_id: '2410.11303'
source_url: https://arxiv.org/abs/2410.11303
tags:
- data
- examples
- selection
- should
- example
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of selecting training data for
  task-specific finetuning of foundation models. The authors propose TSDS, a framework
  that uses optimal transport to align the distribution of selected data with that
  of a small set of representative examples from the target task, while encouraging
  diversity through regularization.
---

# TSDS: Data Selection for Task-Specific Model Finetuning

## Quick Facts
- arXiv ID: 2410.11303
- Source URL: https://arxiv.org/abs/2410.11303
- Reference count: 40
- Outperforms state-of-the-art data selection methods by up to 6 F1 points

## Executive Summary
This paper addresses the challenge of selecting training data for task-specific finetuning of foundation models. The authors propose TSDS, a framework that uses optimal transport to align the distribution of selected data with that of a small set of representative examples from the target task, while encouraging diversity through regularization. A key innovation is incorporating kernel density estimation to handle near-duplicates in the candidate data, ensuring more robust selection. The framework connects to nearest neighbor search, enabling efficient algorithms using approximate search techniques. Experiments on instruction tuning and domain-specific continued pretraining show that TSDS outperforms state-of-the-art methods by up to 6 F1 points, particularly with small annotated sets.

## Method Summary
TSDS formulates data selection as an optimal transport problem, where the goal is to find a subset of data that matches the distribution of a small representative set of target examples. The method uses a kernel density estimation component to handle near-duplicates in the candidate data, which is critical for datasets with contamination issues. The framework connects to nearest neighbor search, allowing the use of efficient approximate search algorithms. The overall objective balances distribution alignment (via optimal transport) with diversity promotion (via regularization), and can be solved using iterative methods that leverage the nearest neighbor connection.

## Key Results
- TSDS outperforms state-of-the-art data selection methods by up to 6 F1 points
- Particularly effective with small annotated sets (100 examples)
- Robust to data duplication issues, which are common in web-scale datasets

## Why This Works (Mechanism)
The framework's effectiveness stems from its dual objective: aligning the selected data distribution with the target task while maintaining diversity. Optimal transport provides a principled way to measure distributional similarity, while the diversity regularization prevents the selection from collapsing to a few similar examples. The kernel density estimation component is crucial for handling near-duplicates, which are common in web-scale datasets and can otherwise skew the selection process.

## Foundational Learning
- Optimal Transport Theory: Why needed - provides principled measure of distributional similarity. Quick check - verify that the Wasserstein distance is correctly computed between empirical distributions.
- Kernel Density Estimation: Why needed - handles near-duplicates in candidate data. Quick check - validate that KDE bandwidth is appropriately set for the data characteristics.
- Approximate Nearest Neighbor Search: Why needed - enables scalability to large candidate pools. Quick check - benchmark ANNS accuracy vs exact search on a subset of data.

## Architecture Onboarding
**Component Map:** Candidate Data -> Representation Extraction -> KDE + OT Formulation -> Selection via ANNS -> Final Subset
**Critical Path:** The bottleneck is typically the representation extraction and nearest neighbor search phases, which scale with both candidate pool size and representation dimensionality.
**Design Tradeoffs:** The method trades some approximation accuracy (via ANNS) for significant computational efficiency. The KDE component adds robustness but also computational overhead.
**Failure Signatures:** Poor performance when candidate data has very different characteristics than the representative set, or when the representation space doesn't capture task-relevant features.
**First Experiments:** 1) Validate OT-based selection on a small, controlled dataset with known ground truth. 2) Test KDE robustness by injecting synthetic duplicates. 3) Benchmark ANNS accuracy vs exact search on the full candidate pool.

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Scalability to very large candidate pools (>10M examples) remains unproven
- Performance on tasks with fundamentally different data distributions (e.g., code generation) untested
- Assumes access to meaningful representations for optimal transport

## Confidence
- **High Confidence**: Core formulation using optimal transport with diversity regularization is mathematically sound and experimentally validated
- **Medium Confidence**: Efficiency claims via ANNS connection are plausible but not fully validated at scale
- **Low Confidence**: Claims about effectiveness with "very small" annotated sets based on experiments with 100 examples

## Next Checks
1. Evaluate TSDS on candidate pools of 10M+ examples using distributed computing frameworks to verify efficiency benefits hold at web-scale
2. Test framework on non-text tasks (image classification, code generation) where distribution alignment assumption may break down
3. Systematically vary representative set size from 10 to 1000 examples to identify practical lower bound for performance advantage