---
ver: rpa2
title: 'Cross-model Control: Improving Multiple Large Language Models in One-time
  Training'
arxiv_id: '2410.17599'
source_url: https://arxiv.org/abs/2410.17599
tags:
- logits
- delta
- should
- training
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently optimizing multiple
  large language models (LLMs) with varying parameter scales and vocabularies for
  specific tasks like instruction following and unlearning. The authors propose Cross-model
  Control (CMC), a method that trains a portable tiny language model alongside a frozen
  template LLM to learn how to alter the logits output by LLMs.
---

# Cross-model Control: Improving Multiple Large Language Models in One-time Training

## Quick Facts
- arXiv ID: 2410.17599
- Source URL: https://arxiv.org/abs/2410.17599
- Authors: Jiayi Wu; Hao Sun; Hengyi Cai; Lixin Su; Shuaiqiang Wang; Dawei Yin; Xiang Li; Ming Gao
- Reference count: 36
- One-line primary result: A tiny 15-million-parameter model can effectively improve a 70-billion-parameter LLM through logit modification without individual fine-tuning

## Executive Summary
Cross-model Control (CMC) introduces a novel approach to efficiently optimize multiple large language models (LLMs) with varying parameter scales and vocabularies through one-time training. The method trains a portable tiny language model alongside a frozen template LLM to learn how to alter LLM outputs, which can then be shared with other user LLMs to achieve optimization effects without individual fine-tuning. A key innovation is the PM-MinED token mapping strategy that enables the tiny model to work across models with different vocabularies.

## Method Summary
CMC trains a tiny delta model alongside a frozen template LLM, where the delta model learns to modify the logits output by the LLM to achieve desired behaviors like instruction following or unlearning. This trained delta model is then applied to other user LLMs through a novel token mapping strategy called PM-MinED, which combines prefix matching with minimum edit distance to handle different vocabularies. The approach enables multiple LLMs to benefit from the optimization effects without requiring individual fine-tuning, offering significant computational efficiency gains compared to traditional methods like LoRA.

## Key Results
- A tiny 15-million-parameter model can effectively modify a 70-billion-parameter LLM's behavior
- CMC achieves performance comparable to LoRA while offering greater portability and lower computational costs
- The method successfully handles different vocabularies through the PM-MinED token mapping strategy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Fine-tuning effects on logits are similar across models with different parameter scales and vocabularies.
- **Mechanism:** When models are fine-tuned on the same task, the shifts in logits before and after fine-tuning exhibit high similarity across different models. This allows a portable tiny model to learn to modify LLM outputs.
- **Core assumption:** Logit shifts before and after fine-tuning are consistent across different model architectures when trained on the same task.
- **Evidence anchors:**
  - [abstract]: "we have observed that the logit shift before and after fine-tuning is remarkably similar across different models."
  - [section 2]: "We discovered that the shifts in logits across different models exhibit a high degree of similarity."
  - [corpus]: Weak. No direct corpus evidence supporting this claim.
- **Break condition:** If the similarity assumption fails, the portable tiny model cannot effectively transfer fine-tuning outcomes across different models.

### Mechanism 2
- **Claim:** A tiny delta model can effectively modify LLM outputs to achieve desired behaviors.
- **Mechanism:** By training alongside a frozen template LLM, the tiny delta model learns to alter the logits output by the LLM. This modification enables the user LLM to achieve fine-tuning effects without individual fine-tuning.
- **Core assumption:** A small model with significantly fewer parameters can learn to effectively modify LLM outputs.
- **Evidence anchors:**
  - [abstract]: "By training alongside a frozen template LLM, the tiny model gains the capability to alter the logits output by the LLMs."
  - [section 3.1]: "we train the template LLM and delta model together, keeping the template LLM frozen and the delta model tunable."
  - [corpus]: Weak. No direct corpus evidence supporting this claim.
- **Break condition:** If the tiny model cannot learn to effectively modify LLM outputs, the approach fails to achieve the desired fine-tuning effects.

### Mechanism 3
- **Claim:** PM-MinED enables token mapping between models with different vocabularies.
- **Mechanism:** The PM-MinED strategy combines prefix matching with minimum edit distance to map tokens from the delta model's vocabulary to tokens in the user LLM's vocabulary. This allows the delta model to be applied to models with different vocabularies.
- **Core assumption:** Prefix matching combined with minimum edit distance provides sufficient token mapping accuracy.
- **Evidence anchors:**
  - [section 3.3]: "we propose a new mapping strategy: Prefix-Match with Minimal Distance (PM-MinED)."
  - [abstract]: "To make this tiny language model applicable to models with different vocabularies, we propose a novel token mapping strategy named PM-MinED."
  - [corpus]: Weak. No direct corpus evidence supporting this claim.
- **Break condition:** If PM-MinED fails to provide accurate token mapping, the delta model cannot effectively modify user LLM outputs.

## Foundational Learning

- **Concept:** Logits and LogSoftmax
  - **Why needed here:** Understanding how models produce probabilities from logits and why LogSoftmax is applied to project logits into logarithmic space is crucial for grasping how the delta model modifies LLM outputs.
  - **Quick check question:** Why does the delta model apply LogSoftmax to LLM logits but not to its own logits during training?

- **Concept:** Token mapping and edit distance
  - **Why needed here:** Understanding how tokens are mapped between different vocabularies and the concept of edit distance is essential for comprehending the PM-MinED strategy.
  - **Quick check question:** How does prefix matching improve upon minimum edit distance alone in token mapping?

- **Concept:** Fine-tuning and parameter-efficient methods
  - **Why needed here:** Understanding traditional fine-tuning approaches and parameter-efficient methods like LoRA provides context for why CMC is valuable.
  - **Quick check question:** What are the computational advantages of CMC compared to LoRA fine-tuning?

## Architecture Onboarding

- **Component map:** Template LLM (frozen) -> Delta model (trainable) -> PM-MinED token mapping -> User LLM (frozen)
- **Critical path:** 1. Train delta model with template LLM 2. Apply PM-MinED for token mapping 3. Modify user LLM outputs using delta model
- **Design tradeoffs:**
  - Portability vs. performance: Smaller delta models are more portable but may sacrifice some performance
  - Inference cost: CMC has lower inference cost than methods requiring multiple models
  - Vocabulary coverage: Limited by delta model's vocabulary
- **Failure signatures:**
  - Poor performance on token mapping indicates PM-MinED issues
  - No improvement in user LLM behavior suggests delta model learning problems
  - High variance in results may indicate instability in training process
- **First 3 experiments:**
  1. Train delta model with template LLM and verify it can modify outputs
  2. Test PM-MinED token mapping accuracy on a small vocabulary
  3. Apply trained delta model to a user LLM and measure performance improvement on a simple task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Cross-model Control scale when applied to extremely large models (e.g., 100B+ parameters) versus extremely small delta models?
- Basis in paper: [explicit] The paper mentions testing on a 70B parameter model and explores different sizes of delta models (15M, 42M, 110M parameters), noting that smaller delta models may lead to decreased performance but not rapidly.
- Why unresolved: The paper only tests on models up to 70B parameters and delta models down to 15M parameters. The relationship between delta model size and performance for much larger models is not explored.
- What evidence would resolve it: Systematic experiments testing Cross-model Control on models significantly larger than 70B parameters with a range of delta model sizes, particularly very small delta models.

### Open Question 2
- Question: Can Cross-model Control be effectively extended to multilingual models with vocabularies covering multiple languages?
- Basis in paper: [inferred] The paper discusses handling different vocabularies through PM-MinED but does not explicitly test on multilingual models or discuss challenges specific to multilingual vocabularies.
- Why unresolved: The paper focuses on English-centric datasets and models, and the PM-MinED strategy is described but not tested on truly multilingual scenarios where vocabularies may have very different structures or token distributions.
- What evidence would resolve it: Experiments applying Cross-model Control to multilingual models (e.g., BLOOM, mT5) and evaluating performance across different language pairs, particularly those with very different scripts or tokenization strategies.

### Open Question 3
- Question: What is the theoretical limit of how much a delta model can alter the behavior of a base LLM, and are there fundamental constraints on what tasks can be achieved through logit shifting alone?
- Basis in paper: [explicit] The paper demonstrates successful instruction following and unlearning through logit shifting, but acknowledges that the delta model's performance is constrained by the scope of its vocabulary and that some tasks might require more than just logit modification.
- Why unresolved: While the paper shows practical success on specific tasks, it does not establish theoretical bounds on the capabilities of delta models or explore whether certain complex behaviors require architectural changes beyond logit shifting.
- What evidence would resolve it: Formal analysis of the representational capacity of logit-shifting transformations, comparative studies testing delta models on increasingly complex tasks, and exploration of tasks that fail despite reasonable delta model sizes.

## Limitations

- Core assumption about logit shift similarity across architectures remains largely unproven
- PM-MinED token mapping strategy lacks comprehensive evaluation on morphologically complex languages
- Method's generalizability beyond instruction tuning and unlearning tasks remains untested

## Confidence

- Cross-model applicability and portability: Medium
- Computational efficiency gains: High
- Effectiveness of PM-MinED token mapping: Medium
- Generalization across diverse tasks: Low

## Next Checks

1. **Architecture Diversity Test:** Evaluate CMC across LLMs with fundamentally different architectures (transformers, recurrent models, etc.) to verify the logit similarity assumption.

2. **Token Mapping Stress Test:** Create a benchmark of challenging token mapping scenarios including morphologically complex languages and domain-specific terminology to stress-test PM-MinED's limitations.

3. **Task Generalization Study:** Apply CMC to a diverse set of tasks including mathematical reasoning, code generation, and domain-specific applications to assess its broader applicability beyond instruction tuning and unlearning.