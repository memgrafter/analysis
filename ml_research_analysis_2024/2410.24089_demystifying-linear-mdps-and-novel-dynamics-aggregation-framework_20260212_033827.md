---
ver: rpa2
title: Demystifying Linear MDPs and Novel Dynamics Aggregation Framework
arxiv_id: '2410.24089'
source_url: https://arxiv.org/abs/2410.24089
tags:
- state
- linear
- space
- learning
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proves that in linear MDPs, the feature dimension $d$
  is lower bounded by $S/U$, where $S$ is the state space size and $U$ is the maximum
  number of directly reachable states. This implies $d$ can scale with $S$ in most
  real-world environments.
---

# Demystifying Linear MDPs and Novel Dynamics Aggregation Framework

## Quick Facts
- arXiv ID: 2410.24089
- Source URL: https://arxiv.org/abs/2410.24089
- Authors: Joongkyu Lee; Min-hwan Oh
- Reference count: 40
- Key outcome: Proves linear MDPs require feature dimension scaling with state space, then proposes dynamics aggregation framework achieving $\tilde{O}(d_\psi^{3/2}H^{3/2}\sqrt{NT})$ regret

## Executive Summary
This paper addresses a fundamental limitation of linear MDPs where the feature dimension must scale with the state space size, making them impractical for many real-world environments. The authors prove that in linear MDPs, the feature dimension $d$ is lower bounded by $S/U$, where $S$ is the state space size and $U$ is the maximum number of directly reachable states. To overcome this limitation, they propose a novel dynamics aggregation framework that clusters sub-structures based on their dynamics and design a provably efficient hierarchical RL algorithm called UC-HRL.

## Method Summary
The authors propose a two-stage approach: first proving that linear MDPs inherently require feature dimensions that scale with state space size when maximum reachable states are limited, then introducing a dynamics aggregation framework that clusters similar subMDPs to reduce effective complexity. The UC-HRL algorithm learns transition probabilities for each aggregated subMDP using ridge regression with UCB bonuses, enabling optimistic planning that reuses learned dynamics across similar sub-structures. The framework partitions the state space, projects subMDPs into aggregated versions based on dynamics similarity, and achieves improved regret bounds when hierarchical structures exist.

## Key Results
- Proves linear MDPs require $d \geq \lceil S/U \rceil$, showing feature dimension scales with state space when $U$ is small
- UC-HRL achieves $\tilde{O}(d_\psi^{3/2}H^{3/2}\sqrt{NT})$ regret, improving over LSVI-UCB's $\tilde{O}(d^{3/2}H^{3/2}\sqrt{T})$
- Shows $d_\psi^3N \ll d^3$ is readily met in real-world environments with hierarchical structures

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Linear MDPs require feature dimension $d$ to scale with state space size $S$ when maximum reachable states $U$ is small relative to $S$.
- **Mechanism:** The proof shows that $d$ must be at least $\lceil S/U \rceil$ to properly represent transition probabilities in linear MDPs. This occurs because each row of the transition kernel requires linearly independent features to distinguish different reachable states.
- **Core assumption:** Every state is accessible from at least one other state, and the maximum number of directly reachable states $U$ is bounded.
- **Evidence anchors:**
  - [abstract] "we prove that, in linear MDPs, the feature dimension $d$ is lower bounded by $S/U$ in order to aptly represent transition probabilities"
  - [section] "Theorem 1. For an MDP M with a finite state space, the feature dimension d is lower bounded by $d \geq \lceil S/U \rceil$"
  - [corpus] Weak evidence - no direct citations about this specific lower bound relationship
- **Break condition:** If $U$ scales proportionally with $S$ (i.e., $U = \Theta(S)$), then $d$ can remain constant relative to $S$.

### Mechanism 2
- **Claim:** Dynamics aggregation framework enables efficient learning by clustering similar subMDPs and reusing learned dynamics.
- **Mechanism:** The framework partitions the state space into subMDPs, then projects these into aggregated subMDPs based on similar dynamics. This reduces the effective state space size from $S$ to $M \cdot N$ where $M$ is max aggregated subMDP size and $N$ is number of aggregated subMDPs.
- **Core assumption:** MDP has hierarchical structure with repeating sub-structures that can be grouped.
- **Evidence anchors:**
  - [abstract] "we propose a novel structural aggregation framework based on dynamics, named as the dynamics aggregation"
  - [section] "Dynamics aggregation partitions the original MDPs into subMDPs and projects these subMDPs into aggregated subMDPs, while explicitly considering repeating structures"
  - [corpus] Weak evidence - no direct citations about dynamics aggregation framework
- **Break condition:** If MDP lacks hierarchical structure or repeating sub-structures, then $N \approx L$ and no improvement is gained.

### Mechanism 3
- **Claim:** UC-HRL algorithm achieves regret bound of $\tilde{O}(d_\psi^{3/2}H^{3/2}\sqrt{NT})$ by leveraging learned dynamics of aggregated subMDPs.
- **Mechanism:** The algorithm learns transition probabilities for each aggregated subMDP using ridge regression with UCB bonus, then constructs optimistic Q-value functions that can be reused across similar sub-structures.
- **Core assumption:** Transition probabilities of aggregated subMDPs follow linear model (Assumption 1).
- **Evidence anchors:**
  - [abstract] "Our proposed algorithm exhibits statistical efficiency, achieving a regret of $\tilde{O}(d_\psi^{3/2}H^{3/2}\sqrt{NT})$"
  - [section] "Under this newly proposed model, we design a model-based HRL algorithm that leverages the hierarchical structure of MDPs and employs optimistic planning"
  - [corpus] Weak evidence - no direct citations about UC-HRL algorithm performance
- **Break condition:** If aggregation error $\epsilon_p$ is too large, the regret bound degrades to $\tilde{O}(d_\psi^{3/2}H^{3/2}\sqrt{NT} + TH\epsilon_p)$.

## Foundational Learning

- **Concept:** Linear MDPs and function approximation
  - Why needed here: The entire paper builds on understanding how linear function approximation works in MDPs and its limitations
  - Quick check question: What is the relationship between feature dimension $d$ and state space size $S$ in linear MDPs according to Theorem 1?

- **Concept:** Hierarchical reinforcement learning and state aggregation
  - Why needed here: The dynamics aggregation framework extends traditional state aggregation concepts to leverage hierarchical structures
  - Quick check question: How does dynamics aggregation differ from standard state aggregation and equivalence mapping?

- **Concept:** Optimistic planning and UCB algorithms
  - Why needed here: UC-HRL uses optimistic planning with UCB bonuses to efficiently explore and learn optimal policies
  - Quick check question: What is the role of the UCB bonus term $\beta ||\phi(\bar{s}, a)||_{\Lambda^{-1}}$ in the algorithm?

## Architecture Onboarding

- **Component map:** State observation → Aggregation mapping → Transition learning → Optimistic planning → Action selection → Environment feedback → Data update

- **Critical path:** State observation → Aggregation mapping → Transition learning → Optimistic planning → Action selection → Environment feedback → Data update

- **Design tradeoffs:** Model-based approach enables reusability but requires more computation per step vs model-free approaches; aggregation introduces approximation error but reduces learning complexity

- **Failure signatures:** Poor performance when aggregation error $\epsilon_p$ is large; no improvement when hierarchical structure is absent; computational issues when $N$ or $M$ is too large

- **First 3 experiments:**
  1. Implement Block-RiverSwim environment and verify Theorem 1 prediction that $d$ scales with $S$ when $U$ is small
  2. Test UC-HRL on Block-RiverSwim with varying numbers of blocks to demonstrate improvement over LSVI-UCB
  3. Measure aggregation error $\epsilon_p$ on different environments to understand when regret bound degrades

## Open Questions the Paper Calls Out
None

## Limitations
- The theoretical lower bound may not capture all practical scenarios where feature dimensions could be smaller
- Dynamics aggregation assumes strong hierarchical structure which may not exist in many real-world environments
- The regret analysis depends on having optimal aggregation, which is computationally challenging to achieve in practice

## Confidence
- Theorem 1 lower bound (Mechanism 1): High confidence in the proof, Medium confidence in practical relevance
- Dynamics aggregation framework (Mechanism 2): Low confidence due to limited empirical validation
- UC-HRL regret bound (Mechanism 3): Medium confidence in theory, Low confidence in practical implementation

## Next Checks
1. Test Theorem 1 predictions on diverse environments with varying $U/S$ ratios to verify the lower bound relationship holds beyond synthetic examples
2. Systematically measure aggregation error $\epsilon_p$ across multiple real-world hierarchical environments to quantify the practical impact on regret bounds
3. Implement and benchmark UC-HRL against state-of-the-art algorithms on complex hierarchical environments with known sub-structures to assess computational feasibility and actual performance gains