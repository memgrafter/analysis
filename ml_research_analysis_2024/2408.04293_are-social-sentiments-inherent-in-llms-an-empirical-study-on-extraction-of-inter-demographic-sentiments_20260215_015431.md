---
ver: rpa2
title: Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of
  Inter-demographic Sentiments
arxiv_id: '2408.04293'
source_url: https://arxiv.org/abs/2408.04293
tags:
- llms
- sentiment
- sentiments
- social
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether large language models (LLMs) capture
  and can extract inter-demographic sentiments across nationalities, religions, and
  races/ethnicities. Researchers input questions about sentiments from one group to
  another into five representative LLMs (GPT-3.5, GPT-4, Llama 2-Chat 13B, Llama 2-Chat
  70B, and Vicuna 13B) and applied sentiment analysis to the responses.
---

# Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments

## Quick Facts
- arXiv ID: 2408.04293
- Source URL: https://arxiv.org/abs/2408.04293
- Authors: Kunitomo Tanaka; Ryohei Sasano; Koichi Takeda
- Reference count: 15
- One-line primary result: LLMs capture inter-group sentiments with correlation coefficients typically above 0.3 for nationalities and religions

## Executive Summary
This study investigates whether large language models can extract inter-demographic sentiments across nationalities, religions, and races/ethnicities. Researchers input questions about sentiments from one group to another into five representative LLMs and applied sentiment analysis to the responses. The sentiment scores were compared with actual social survey data using Pearson correlation coefficients. Results showed higher correlations (ρ typically above 0.3) with relatively small p-values for nationalities and religions, indicating that LLM responses align well with actual social survey results.

## Method Summary
The researchers used five LLMs (GPT-3.5, GPT-4, Llama 2-Chat 13B, Llama 2-Chat 70B, and Vicuna 13B) to generate responses about inter-group sentiments between various demographic groups. They created question templates asking about sentiments from one group to another for nationalities, religions, and races/ethnicities. Each question was run three times per model to ensure reliability. Sentiment analysis (VADER) was applied to the responses to score sentiments from -1 to +1, and Pearson correlation coefficients were computed between these scores and actual social survey data for each demographic attribute.

## Key Results
- LLMs showed statistically significant correlations (ρ typically above 0.3) with survey data for nationalities and religions
- Correlation strength varied across demographic attributes, with higher correlations for nationalities and religions compared to races/ethnicities
- The results suggest LLMs can capture and express inter-group sentiments, particularly for nationalities and religions

## Why This Works (Mechanism)

### Mechanism 1
LLMs capture inter-group sentiment because their training corpus contains sufficient human-generated text expressing such sentiments. During pretraining, LLMs are exposed to vast amounts of text from diverse sources (social media, news, forums) that often contain discussions about group relationships, stereotypes, and collective opinions. The models learn to associate certain language patterns with positive or negative sentiment toward specific groups.

### Mechanism 2
Sentiment analysis tools can extract measurable sentiment from LLM responses about group relationships. When LLMs generate text about group sentiments, they use language that sentiment analyzers can quantify. Tools like VADER score words based on their valence, allowing researchers to convert qualitative responses into numerical sentiment scores that correlate with survey data.

### Mechanism 3
Correlation between LLM-extracted sentiment and survey data validates that LLMs capture real inter-group sentiments. By comparing sentiment scores extracted from LLM responses with actual survey data using Pearson correlation coefficients, researchers can determine if the LLM outputs align with human-reported sentiments. Higher correlations indicate better capture of real inter-group dynamics.

## Foundational Learning

- **Concept: Sentiment analysis and valence scoring**
  - Why needed here: The study relies on converting LLM responses into numerical sentiment scores using tools like VADER
  - Quick check question: How does a sentiment analyzer like VADER convert text into a score between -1 and +1?

- **Concept: Pearson correlation coefficient**
  - Why needed here: The study uses Pearson correlation to compare LLM-extracted sentiment scores with survey data
  - Quick check question: What does a Pearson correlation coefficient of 0.3 indicate about the relationship between two variables?

- **Concept: Statistical significance and p-values**
  - Why needed here: The study reports p-values alongside correlation coefficients to indicate statistical significance
  - Quick check question: What does a p-value of 0.05 mean in the context of testing whether correlation is significantly different from zero?

## Architecture Onboarding

- **Component map**: Question templates -> LLM inference (5 models, 3 runs each) -> Sentiment analysis (VADER) -> Pearson correlation computation
- **Critical path**: The most time-consuming step is LLM inference, as each question is run three times per model for reliability
- **Design tradeoffs**: Using open-ended questions allows richer sentiment expression but requires sentiment analysis. Multiple question types help validate robustness but increase computational cost. Five different LLMs provide model comparison but multiply the workload.
- **Failure signatures**: Low correlations could indicate either that LLMs don't capture sentiments well, or that the sentiment analysis tool fails to extract them properly. High p-values suggest results aren't statistically significant. Discrepancies between question types might reveal model biases.
- **First 3 experiments**:
  1. Run a single LLM (e.g., GPT-3.5) with a small subset of questions to verify the end-to-end pipeline works
  2. Compare sentiment scores from different sentiment analyzers to ensure consistency
  3. Test with synthetic "ground truth" data to verify the correlation computation works as expected

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but several remain unresolved based on the methodology and findings.

## Limitations
- The study doesn't specify whether social survey questions match the LLM question templates, which could affect correlation interpretation
- VADER sentiment analyzer was designed for short social media text, not LLM-generated responses about demographic groups
- Sample sizes vary significantly across demographic attributes, suggesting results may not be equally reliable across all tested dimensions

## Confidence
- **High Confidence**: LLMs generate text about inter-group relationships that can be processed by sentiment analysis tools to produce numerical scores
- **Medium Confidence**: LLMs show statistically significant correlations with social survey data for nationalities and religions
- **Low Confidence**: The study's implication that LLMs "capture" social sentiments is overstated

## Next Checks
1. Conduct a human evaluation study where independent raters assess the alignment between LLM responses and survey questions directly
2. Test multiple sentiment analysis tools (including more sophisticated models like RoBERTa-based sentiment analyzers) on the same LLM responses
3. Perform a controlled experiment using synthetic ground truth data where LLM responses are generated about known sentiment relationships