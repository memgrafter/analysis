---
ver: rpa2
title: What Is Missing in Multilingual Visual Reasoning and How to Fix It
arxiv_id: '2403.01404'
source_url: https://arxiv.org/abs/2403.01404
tags:
- reasoning
- performance
- gpt-4v
- visual
- open
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates multilingual visual reasoning capabilities
  across both proprietary and open models, revealing that while GPT-4V achieves strong
  performance across all languages, open models lag, especially on low-resource languages.
  Through detailed analysis, the authors identify three main challenges: multilinguality,
  complex reasoning, and multimodality.'
---

# What Is Missing in Multilingual Visual Reasoning and How to Fix It

## Quick Facts
- arXiv ID: 2403.01404
- Source URL: https://arxiv.org/abs/2403.01404
- Authors: Yueqi Song; Simran Khanuja; Graham Neubig
- Reference count: 20
- Primary result: Three interventions—translation to English, visual programming, and caption-based reasoning—significantly improve open model performance on multilingual visual reasoning tasks

## Executive Summary
This paper investigates multilingual visual reasoning capabilities across both proprietary and open models, revealing that while GPT-4V achieves strong performance across all languages, open models lag, especially on low-resource languages. Through detailed analysis, the authors identify three main challenges: multilinguality, complex reasoning, and multimodality. To address these, they propose three interventions: translating statements to English (translate-test), breaking down reasoning into modular visual programs, and reasoning over image captions instead of raw images. These interventions significantly boost open model performance—LLaVA-v1.5-13B improves by 13.4%, LLaVA-v1.6-34B by 20.3%, and Qwen-VL by 16.7%—and also yield minor gains for GPT-4V, achieving state-of-the-art zero-shot results on MaRVL.

## Method Summary
The paper evaluates multilingual visual reasoning using NLVR2 (English) and MaRVL (five languages) datasets. It compares zero-shot and finetuned performance of proprietary models (GPT-4V, Gemini) and open models (mBLIP, LLaVA variants, Qwen-VL). Three interventions are proposed: (1) Translate-test—translating statements to English to leverage stronger English reasoning; (2) Visual programming—decomposing complex reasoning into modular submodules; and (3) Caption-based reasoning—reasoning over image captions instead of raw images. The methods are evaluated across all models to identify performance improvements and challenges.

## Key Results
- Open models show significant performance gaps on low-resource languages compared to English, while GPT-4V maintains strong multilingual performance
- Translation to English improves open model performance but unexpectedly degrades GPT-4V and Gemini performance
- Visual programming and caption-based reasoning interventions improve open model performance by 13.4-20.3% on average
- The caption-based reasoning approach achieves state-of-the-art zero-shot performance on MaRVL

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Translating reasoning statements to English reduces cross-lingual performance gaps for open models but harms GPT-4V and Gemini.
- Mechanism: When statements are translated to English, open models (which are primarily pretrained on English data) can leverage their stronger English reasoning capabilities, leading to performance gains. However, GPT-4V and Gemini already possess strong multilingual reasoning abilities, so translation introduces errors that degrade performance.
- Core assumption: Open models' multilingual reasoning abilities are weaker than their English reasoning capabilities, while GPT-4V and Gemini have comparable multilingual reasoning performance.
- Evidence anchors:
  - [abstract]: "translation leads to a drop in performance for GPT-4V and Gemini-1.5-Pro (which might indicate their advanced multilingual capabilities), but helps improve performance for open models"
  - [section 6.1]: "All models except for GPT-4V and Gemini 1.5 Pro see an increase in accuracy after performing translate test; while surprisingly, GPT-4V and Gemini 1.5 Pro show a sharp decrease in performance"
  - [corpus]: Weak - the corpus neighbors discuss multilingual instruction tuning and African languages but don't directly address translation effects on visual reasoning
- Break condition: If open models receive multilingual pretraining comparable to GPT-4V/Gemini, or if translation quality becomes perfect, this mechanism would break.

### Mechanism 2
- Claim: Breaking down complex reasoning statements into modular visual programs improves performance by addressing reasoning complexity.
- Mechanism: Long, compositional statements require complex reasoning that models struggle with. By decomposing these statements into smaller programmatic submodules that can be executed sequentially, models can handle each reasoning step independently, reducing cognitive load and improving accuracy.
- Core assumption: Complex reasoning tasks can be effectively decomposed into smaller, executable submodules that preserve the original task semantics.
- Evidence anchors:
  - [abstract]: "a visual programming approach to break down complex reasoning"
  - [section 5.2]: "we measure the number of words of the NLVR2 and MaRVL statements (translated to English), and find that model performances drop as the number of words of the statement increases"
  - [section 6.2]: "PAL (Gao et al., 2023) provides significant improvements by decomposing a natural language instruction into multiple programmatic submodules"
  - [corpus]: Weak - corpus discusses multilingual instruction tuning but not visual programming decomposition
- Break condition: If statements cannot be effectively decomposed without losing semantic meaning, or if execution of submodules introduces errors that compound.

### Mechanism 3
- Claim: Reasoning over image captions instead of raw images alleviates multimodal interaction challenges and improves performance.
- Mechanism: Multimodal reasoning is challenging due to the need to align image and text modalities simultaneously. By first generating captions for each image conditioned on the statement, the task becomes purely text-based reasoning, which leverages LLMs' stronger text reasoning capabilities and eliminates the need for direct image-text alignment during reasoning.
- Core assumption: Image captions generated by LLMs can capture sufficient information for the reasoning task, and text-based reasoning is more reliable than multimodal reasoning for these models.
- Evidence anchors:
  - [abstract]: "a method that leverages image captioning to address multimodality"
  - [section 5.3]: "multimodal reasoning is known to be harder than reasoning over text alone" and "GPT-4 reasons as follows: Reasoning - The statement is False"
  - [section 6.3]: "we prompt LLMs to reason whether the statement match caption pairs"
  - [corpus]: Weak - corpus neighbors discuss multilingual multimodal benchmarks but don't specifically address caption-based reasoning
- Break condition: If generated captions omit critical visual details necessary for reasoning, or if text-based reasoning cannot capture multimodal relationships effectively.

## Foundational Learning

- Concept: Chain-of-thought reasoning
  - Why needed here: The paper leverages LLMs' chain-of-thought capabilities to break down complex reasoning tasks and to reason over image captions
  - Quick check question: How does chain-of-thought prompting differ from direct answer prompting, and why might it improve reasoning performance?

- Concept: Cross-lingual transfer
  - Why needed here: The paper examines how models transfer reasoning capabilities from English to other languages, and how translation affects this transfer
  - Quick check question: What factors influence how well a model trained on English data can perform on non-English tasks?

- Concept: Multimodal pretraining objectives
  - Why needed here: Understanding how models are pretrained on image-text pairs helps explain why they struggle with pairs of images and how different interventions address this mismatch
  - Quick check question: What are the common pretraining objectives for vision-language models, and how might they differ from the NLVR2/MaRVL task format?

## Architecture Onboarding

- Component map: Image pair + statement → (optional) Translation module → (optional) Visual programming module → (optional) Captioning module → Text-based reasoning → True/False prediction

- Critical path: For the best-performing approach (captioning pipeline): Image → Caption generation → Statement + Caption pair → Text-based reasoning → Prediction

- Design tradeoffs:
  - Translation adds computational overhead but can improve open model performance; however, it may degrade GPT-4V/Gemini performance
  - Visual programming requires additional inference steps but provides interpretability; may not match end-to-end model performance
  - Captioning pipeline trades raw visual information for text-based reasoning reliability; introduces dependency on caption quality

- Failure signatures:
  - Performance degradation after translation suggests either translation errors or that models already handle multilinguality well
  - Visual programming failures indicate either poor decomposition of statements or errors in executing submodules
  - Captioning failures suggest either inadequate caption generation or that visual details were lost in the captioning process

- First 3 experiments:
  1. Baseline evaluation of open models on NLVR2 and MaRVL to establish performance gaps
  2. Translation test on MaRVL languages to identify cross-lingual transfer issues
  3. Captioning pipeline evaluation with LLaVA-v1.5-13B to measure improvement from multimodal to text-based reasoning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does GPT-4V's performance drop when translating MaRVL statements to English while open models improve?
- Basis in paper: [explicit] The paper notes that GPT-4V and Gemini 1.5 Pro show a sharp decrease in performance across almost all MaRVL languages after translate test, while other models see an increase in accuracy after performing translate test.
- Why unresolved: The paper provides one example where translation loses cultural nuances (青绿色 vs turquoise), but doesn't systematically analyze why GPT-4V's multilingual capabilities appear to degrade with translation when other models benefit.
- What evidence would resolve it: Controlled experiments testing GPT-4V with different translation methods (human vs machine translation, preserving vs replacing cultural terms) while keeping open models constant.

### Open Question 2
- Question: What specific aspects of multilinguality, reasoning, or multimodality are most challenging for open models on MaRVL?
- Basis in paper: [explicit] The authors identify three key challenges (multilinguality, complex reasoning, multimodality) but don't isolate which is most responsible for the performance gap between open models and GPT-4V.
- Why unresolved: The interventions target all three challenges simultaneously, making it difficult to determine which challenge contributes most to the performance gap.
- What evidence would resolve it: Ablation studies where each intervention is applied individually to isolate the impact of addressing each specific challenge.

### Open Question 3
- Question: Can open models achieve equitable performance across all MaRVL languages through targeted training approaches?
- Basis in paper: [explicit] The paper observes that models show significantly better performance on English data and that the gap between English and MaRVL languages increases after finetuning for mBLIP.
- Why unresolved: The paper only evaluates finetuning on English data and doesn't explore alternative training strategies like multilingual finetuning or curriculum learning across languages.
- What evidence would resolve it: Comparative experiments training open models with different data strategies (English-only vs multilingual finetuning, balanced vs imbalanced language sampling) and measuring performance equity across all MaRVL languages.

## Limitations

- The paper doesn't fully explain why translation helps open models but harms GPT-4V/Gemini, suggesting fundamental architectural differences that remain unexplored
- The caption-based reasoning approach introduces information loss by relying on generated captions rather than raw images, potentially masking true model capabilities
- The interventions are evaluated individually but their interactions and combined effects are not systematically studied

## Confidence

- High confidence: The identification of performance gaps across languages and the overall effectiveness of interventions in improving open model performance
- Medium confidence: The mechanism explanations for why each intervention works, particularly the translation effects on different model families
- Low confidence: The claim that caption-based reasoning is more reliable than multimodal reasoning, given the information loss inherent in the approach

## Next Checks

1. **Translation Quality Analysis**: Systematically evaluate how translation errors (semantic drift, cultural nuances, idiomatic expressions) correlate with performance drops in GPT-4V/Gemini to validate the claim that translation harms these models.

2. **Cross-Modal Alignment Evaluation**: Measure the information retention between raw images and generated captions using established image-text alignment metrics to quantify what visual details are lost in the captioning pipeline.

3. **Intervention Interaction Study**: Test combinations of interventions (e.g., visual programming + captioning, or translate-test + visual programming) to determine whether the improvements are additive or whether certain combinations create conflicts or redundancies.