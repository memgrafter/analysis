---
ver: rpa2
title: A two-stage transliteration approach to improve performance of a multilingual
  ASR
arxiv_id: '2410.14709'
source_url: https://arxiv.org/abs/2410.14709
tags:
- speech
- language
- languages
- transliteration
- recognition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving multilingual Automatic
  Speech Recognition (ASR) systems, particularly in code-mixing scenarios where acoustically
  similar units map to different graphemes due to script variations across languages.
  The authors propose a two-stage transliteration approach that projects multilingual
  grapheme data to the script of a more generic target language (Devanagari), reducing
  speech-class confusion and minimizing the need for retraining acoustic models.
---

# A two-stage transliteration approach to improve performance of a multilingual ASR

## Quick Facts
- arXiv ID: 2410.14709
- Source URL: https://arxiv.org/abs/2410.14709
- Reference count: 0
- Primary result: 20% relative reduction in WER and 24% in CER on Nepali and Telugu datasets

## Executive Summary
This paper addresses the challenge of improving multilingual Automatic Speech Recognition (ASR) systems, particularly in code-mixing scenarios where acoustically similar units map to different graphemes due to script variations across languages. The authors propose a two-stage transliteration approach that projects multilingual grapheme data to the script of a more generic target language (Devanagari), reducing speech-class confusion and minimizing the need for retraining acoustic models. The approach operates in two stages: (1) lexical transformation, mapping graphemes to phonemes and then to the target script, and (2) conversion of dependent vowels (matra) to independent forms, further reducing vocabulary size. Experiments on Nepali and Telugu datasets show significant improvements: a relative reduction of 20% in Word Error Rate (WER) and 24% in Character Error Rate (CER) compared to baseline language-dependent models.

## Method Summary
The approach uses a two-stage transliteration process to improve multilingual ASR performance. Stage 1 performs lexical transformation, mapping source language graphemes to phonemes and then to a target script (Devanagari). Stage 2 converts dependent vowels (matras) to independent forms to further reduce vocabulary size. The transliterated text becomes the label for training an end-to-end ASR model (Deepspeech2 CTC-based architecture with 2 CNN layers, 5 RNN layers, and softmax layer). The method claims to reduce speech-class confusion by unifying acoustically similar units under shared graphemes, enabling the same acoustic model to generalize across languages without retraining.

## Key Results
- 20% relative reduction in Word Error Rate (WER) compared to baseline language-dependent models
- 24% relative reduction in Character Error Rate (CER) on test datasets
- Significant improvements observed on both Nepali and Telugu datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Projecting multilingual graphemes to a common script reduces speech-class confusion by unifying acoustically similar units under shared graphemes.
- Mechanism: The two-stage transliteration converts Nepali and Telugu graphemes into Devanagari, collapsing phonetically similar sounds into single grapheme representations, thereby shrinking the vocabulary and reducing ambiguity in the phoneme-to-grapheme mapping.
- Core assumption: Devanagari is sufficiently broad to represent both Nepali and Telugu phonemes without losing critical distinctions.
- Evidence anchors:
  - [abstract] "reducing speech-class confusion and minimizing the need for retraining acoustic models."
  - [section] "The target language (ltgt) here is the language, or a mix of multiple languages that serve as input to the ASR."
  - [corpus] "LAMA-UT: Language Agnostic Multilingual ASR through Orthography Unification and Language-Specific Transliteration" supports orthography unification as a general approach.
- Break condition: If the target languages contain phonemes not representable in Devanagari, critical distinctions are lost and recognition degrades.

### Mechanism 2
- Claim: Converting dependent vowels (matras) to independent forms further reduces vocabulary size and disambiguates acoustically similar vowel sounds.
- Mechanism: In stage-2, matras (dependent vowel signs) are replaced by their independent vowel graphemes, ensuring each vowel sound maps to a unique grapheme and eliminating multiple spellings for the same phonetic content.
- Core assumption: The independent form fully captures the phonetic value of the matra without ambiguity.
- Evidence anchors:
  - [section] "Stage-2 addresses this by focusing on converting the dependent form (matra) of a vowel to the independent form."
  - [corpus] "Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn't" suggests reducing orthographic complexity helps performance.
- Break condition: If independent vowel forms introduce ambiguity or if matras carry grammatical information lost in conversion, model performance suffers.

### Mechanism 3
- Claim: Using a single writing script across languages enables the same acoustic model to generalize without retraining across new languages that share phonetic inventory.
- Mechanism: By unifying the grapheme space, the acoustic model learns a single mapping from acoustic features to graphemes, and new languages with overlapping phoneme sets can be incorporated by transliteration without model retraining.
- Core assumption: Phonetic overlap between source and target languages is sufficient to avoid catastrophic forgetting or degradation.
- Evidence anchors:
  - [abstract] "This approach saves the acoustic model from retraining to span over a larger space and can easily be extended to multiple languages."
  - [section] "The proposed approach hence chooses the Devanagari script as lint to convert the target languages ltgt Nepali, and Telugu."
  - [corpus] "Building Robust and Scalable Multilingual ASR for Indian Languages" shows challenges in multilingual ASR that transliteration can address.
- Break condition: If new languages have phonemes absent from the intermediate script, the transliteration fails and retraining is required.

## Foundational Learning

- Concept: Grapheme-to-phoneme mapping
  - Why needed here: The transliteration approach relies on converting graphemes to phonemes and back; understanding this mapping is essential to implement and debug the process.
  - Quick check question: How would you map the Devanagari vowel 'à¤…' to its phoneme representation, and what happens if a language lacks this vowel?

- Concept: Script unification and its impact on vocabulary size
  - Why needed here: Reducing the number of unique graphemes directly affects the confusion in ASR decoding; grasping this trade-off is key to evaluating the method.
  - Quick check question: If two languages have 50 graphemes each but share 30, how many unique graphemes remain after unification if they are mapped to a common script?

- Concept: End-to-end ASR architecture with CTC loss
  - Why needed here: The transliteration output becomes the label for the ASR model; understanding how CTC handles sequence alignment is crucial for interpreting results.
  - Quick check question: In CTC decoding, how are repeated labels and blanks handled when mapping the network output to the final transcription?

## Architecture Onboarding

- Component map: Data preprocessing -> Transliteration pipeline (Stage-1 and Stage-2) -> Grapheme sequence labeling -> End-to-end ASR model (CNN-RNN-CTC) -> Beam search decoder -> Evaluation (WER/CER)
- Critical path: Transliteration -> ASR training -> Evaluation
- Design tradeoffs:
  - Choosing intermediate script (Devanagari) balances broad phonetic coverage against potential ambiguity.
  - Stage-2 vowel conversion reduces vocabulary but may lose grammatical cues.
  - Avoiding acoustic model retraining trades adaptability for speed of deployment.
- Failure signatures:
  - High WER/CER after transliteration suggests loss of phonetic distinctions or incorrect mapping.
  - Disproportionate degradation on code-mixed data may indicate transliteration errors in English or foreign words.
- First 3 experiments:
  1. Baseline: Train ASR directly on original Nepali and Telugu graphemes (no transliteration).
  2. Stage-1 only: Transliterate to Devanagari with matras retained, train and evaluate.
  3. Full two-stage: Apply both transliteration stages, train and evaluate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the two-stage transliteration approach perform on languages with more complex script variations or larger phoneme sets than Nepali and Telugu?
- Basis in paper: [inferred] The paper demonstrates success with Nepali and Telugu, which have relatively simpler script variations. However, it does not explore more complex languages or scripts.
- Why unresolved: The experiments are limited to two Indic languages, and the scalability of the approach to other language families or scripts is not addressed.
- What evidence would resolve it: Conducting experiments on languages with more complex scripts (e.g., Chinese, Arabic) or larger phoneme sets to evaluate the approach's generalizability and effectiveness.

### Open Question 2
- Question: What is the impact of the two-stage transliteration approach on real-time speech recognition systems in terms of latency and computational overhead?
- Basis in paper: [inferred] The paper focuses on improving accuracy but does not discuss the computational efficiency or latency implications of the transliteration process in real-time systems.
- Why unresolved: The paper does not provide benchmarks or analysis of the approach's performance in terms of speed or resource usage.
- What evidence would resolve it: Benchmarking the transliteration approach in a real-time ASR system to measure latency, computational overhead, and its impact on overall system performance.

### Open Question 3
- Question: How does the two-stage transliteration approach handle languages with no shared phonemes or scripts, such as English and Chinese?
- Basis in paper: [explicit] The paper uses Devanagari as an intermediate script, which shares phonemes with Nepali and Telugu. However, it does not address scenarios where languages have no phonetic or script overlap.
- Why unresolved: The approach relies on shared phonemes for transliteration, and its effectiveness in cases with no overlap is not explored.
- What evidence would resolve it: Testing the approach on language pairs with no shared phonemes or scripts to evaluate its adaptability and identify potential limitations or modifications needed.

### Open Question 4
- Question: What is the long-term impact of the two-stage transliteration approach on the generalization ability of ASR models when trained on transliterated data?
- Basis in paper: [inferred] The paper shows improved performance in transliterated space but does not investigate whether the model's ability to generalize to new, unseen data is affected by the transliteration process.
- Why unresolved: The paper focuses on immediate performance gains but does not explore the broader implications for model robustness and adaptability.
- What evidence would resolve it: Conducting longitudinal studies to assess the model's performance on new data, including out-of-domain or multilingual scenarios, to determine if the transliteration approach enhances or limits generalization.

## Limitations
- The approach's effectiveness for languages with phonemes not representable in Devanagari is not validated.
- The impact of matra-to-independent-vowel conversion on grammatical information is not explored.
- The scalability claim to other languages lacks experimental validation beyond Nepali and Telugu.
- No comparison with alternative multilingual strategies like shared vocabularies or joint models.

## Confidence

- **Confidence: High** for the improvement in WER and CER on Nepali and Telugu datasets using the two-stage transliteration, as these are direct experimental results with measurable outcomes.
- **Confidence: Medium** for the mechanism by which script unification reduces speech-class confusion, since the underlying assumption about Devanagari's coverage is plausible but not empirically validated for all phonemic distinctions.
- **Confidence: Low** for the scalability claim to other languages without retraining, given the absence of experimental validation on languages outside the Nepali-Telugu pair.

## Next Checks

1. **Phoneme Coverage Validation**: Perform a systematic audit of Nepali and Telugu phonemes to ensure every distinct sound maps uniquely and unambiguously to Devanagari; identify and document any phonemes that cannot be represented or are mapped to the same grapheme.

2. **Ablation Study on Stage-2**: Conduct experiments isolating the effect of matra-to-independent-vowel conversion by training and evaluating models with and without this stage, and analyze if any grammatical or semantic information is lost.

3. **Cross-Lingual Generalization Test**: Apply the transliteration pipeline and trained model to a third language (e.g., Hindi or Marathi, which also use Devanagari) and measure degradation in WER/CER to assess the scalability claim.