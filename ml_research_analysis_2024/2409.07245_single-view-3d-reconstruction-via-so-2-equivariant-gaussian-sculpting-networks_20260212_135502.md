---
ver: rpa2
title: Single-View 3D Reconstruction via SO(2)-Equivariant Gaussian Sculpting Networks
arxiv_id: '2409.07245'
source_url: https://arxiv.org/abs/2409.07245
tags:
- gaussian
- reconstruction
- object
- view
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SO(2)-Equivariant Gaussian Sculpting Networks
  (GSNs) for single-view 3D reconstruction, generating Gaussian splat representations
  of object geometry and texture from a single image. The method uses a shared feature
  extractor followed by parallel MLPs to predict Gaussian parameters (color, covariance,
  position, opacity) from a canonical cube representation, achieving real-time inference
  (150FPS).
---

# Single-View 3D Reconstruction via SO(2)-Equivariant Gaussian Sculpting Networks

## Quick Facts
- arXiv ID: 2409.07245
- Source URL: https://arxiv.org/abs/2409.07245
- Reference count: 40
- Single-view 3D reconstruction via SO(2)-equivariant Gaussian splatting achieves >150FPS with competitive quality

## Executive Summary
This paper introduces SO(2)-Equivariant Gaussian Sculpting Networks (GSNs) for single-view 3D reconstruction, generating Gaussian splat representations from a single image. The method achieves real-time inference (>150FPS) while maintaining competitive reconstruction quality with diffusion-based methods. GSNs are validated on ShapeNet benchmarks and demonstrated in robotic grasping applications, showing consistent performance under SO(2) transformations of input views.

## Method Summary
GSNs use a shared ResNet-based feature extractor to encode a single input image into a latent vector, followed by parallel MLPs that decode this vector into Gaussian parameters (color, covariance, position, opacity) as deviations from a canonical cube representation. The model is trained with multi-view rendering loss and Extended Chamfer Distance (ECD) loss to enforce SO(2) equivariance. This architecture enables efficient decoding while maintaining reconstruction quality, making it suitable for robotics applications where only sparse observations are available.

## Key Results
- Achieves real-time inference at >150FPS for single-view 3D reconstruction
- Competitive reconstruction quality (PSNR, SSIM, LPIPS) compared to diffusion-based methods
- Maintains consistent performance under SO(2) transformations of input views
- Demonstrated effectiveness in robotic grasping pipeline on ShapeNet benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GSN achieves high throughput (>150FPS) by predicting deviations from a canonical cube representation rather than direct parameter regression.
- Mechanism: The network encodes a single input image into a latent vector, then uses parallel MLPs to predict deviations (∆µ, ∆s) from predefined Gaussian positions and scales on a unit cube. This decomposition simplifies the optimization landscape and allows for efficient parallel computation of Gaussian parameters.
- Core assumption: The canonical cube provides a reasonable initialization that can be deformed to match most object shapes through learned deviations.
- Evidence anchors:
  - [abstract] "GSNs take a single observation as input to generate a Gaussian splat representation... By using a shared feature extractor before decoding Gaussian colors, covariances, positions, and opacities, GSNs achieve extremely high throughput (>150FPS)."
  - [section III-A] "Instead of letting the neural network directly predict the 5 parameters for each Gaussian, our method predicts a deviation of the parameters from a canonical cube... The final predicted Gaussian Splat has the form Spred = {( ¯µi + ∆µi, ¯si + ∆si, ri, ci, αi), i = 1, . . . , N}"

### Mechanism 2
- Claim: SO(2) equivariance is achieved through input rotation augmentation and Extended Chamfer Distance (ECD) loss.
- Mechanism: The input image is randomly rotated along the camera's principal axis before processing. The network then predicts Gaussian splats for both rotated and unrotated inputs. ECD loss is applied between these splats to enforce equivariance, measuring differences in positions, scales, colors, rotations, and opacities.
- Core assumption: The ECD loss effectively captures the equivariant relationship between rotated input views and their corresponding Gaussian splat representations.
- Evidence anchors:
  - [abstract] "The GSN model is validated on multiple benchmark experiments... Moreover, we demonstrate the potential for GSNs to be used within a robotic manipulation pipeline for object-centric grasping."
  - [section III-C] "To achieve SO(2) invariance regarding the view angle, the input image is rotated along the camera’s principal axis by a random angle T and then processed by the same network to produce a rotated splat. We minimize an Extended Chamfer Distance (ECD) between the rotated splat and the unrotated splat after applying the same rotation around the camera’s principal axis."

### Mechanism 3
- Claim: The shared feature extractor followed by parallel MLPs enables efficient decoding of Gaussian parameters while maintaining reconstruction quality.
- Mechanism: A ResNet-based encoder processes the input image to generate a latent vector. Parallel MLPs then independently decode this latent vector into each Gaussian parameter (∆µ, ∆s, r, c, α), allowing for specialized processing of each parameter type while sharing the initial feature extraction.
- Core assumption: The parallel MLP architecture provides sufficient representational capacity for each parameter type while benefiting from shared feature extraction.
- Evidence anchors:
  - [abstract] "By using a shared feature extractor before decoding Gaussian colors, covariances, positions, and opacities, GSNs achieve extremely high throughput (>150FPS)."
  - [section III-B] "Parallel MLPs are used to decode the latent vector into Gaussian parameters ∆S = {(∆µi, ∆si, ri, ci, αi), i = 1 , . . . , N}. For each of the 5 parameters, we have an independent MLP layer to output N × size of parameter number of values..."

## Foundational Learning

- Concept: Gaussian Splatting
  - Why needed here: Understanding the Gaussian primitive representation (mean, covariance, color, opacity) is fundamental to grasping how GSN generates 3D objects from single images.
  - Quick check question: What are the five parameters that define a Gaussian primitive in Gaussian Splatting, and how do they contribute to the final rendered image?

- Concept: Neural Radiance Fields (NeRF)
  - Why needed here: Comparing GSN to NeRF helps understand the advantages of explicit Gaussian representations over implicit neural representations for robotics applications.
  - Quick check question: What are the key differences between implicit representations (like NeRF) and explicit representations (like Gaussian Splatting) in terms of 3D reconstruction and downstream task integration?

- Concept: SO(2) Equivariance
  - Why needed here: The paper's contribution includes achieving SO(2) equivariance, which is crucial for consistent object understanding across different view angles in robotics.
  - Quick check question: What does SO(2) equivariance mean in the context of 3D object reconstruction, and why is it important for robotic manipulation tasks?

## Architecture Onboarding

- Component map:
  - Input image -> ResNet encoder -> 2352D latent vector -> Parallel MLPs -> Gaussian parameters -> 3D Gaussian Splatting renderer -> Rendered image

- Critical path:
  1. Input image → Encoder → Latent vector
  2. Latent vector → Parallel MLPs → Gaussian parameters
  3. Gaussian parameters → Renderer → Rendered image(s)
  4. Rendered image(s) vs. ground truth → Loss computation → Backpropagation

- Design tradeoffs:
  - Using parallel MLPs allows specialized processing but increases parameter count compared to shared MLP architectures.
  - Canonical cube initialization simplifies the learning task but may limit the model's ability to reconstruct highly irregular shapes.
  - Rotation augmentation and ECD loss enforce equivariance but may slightly reduce reconstruction quality compared to models without these constraints.

- Failure signatures:
  - Poor reconstruction of thin structures or fine details suggests insufficient receptive field or encoder capacity.
  - Inconsistent reconstructions across rotated views indicate issues with the equivariance loss or augmentation strategy.
  - Slow inference or training convergence issues may stem from inefficient encoder architecture or insufficient parallelization.

- First 3 experiments:
  1. Train GSN on a subset of ShapeNet-SRN (e.g., 10 categories) to validate basic reconstruction capability and investigate the impact of the canonical cube initialization.
  2. Compare different encoder architectures (e.g., ResNet50 vs. ResNet152) and latent vector extraction strategies to optimize reconstruction quality and computational efficiency.
  3. Evaluate the effectiveness of the Extended Chamfer Distance loss by training models with and without this loss term, measuring both reconstruction quality and equivariance preservation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice between ResNet50 and ResNet152 impact the quality and speed of single-view 3D reconstruction?
- Basis in paper: [explicit] The paper compares ResNet50 and ResNet152 in the ablation study section, finding that centering the unit cube on the origin has the greatest impact, but the impact of the latent vector and architecture might be due to the small dataset.
- Why unresolved: The study was conducted on a small dataset containing 30 car objects with 150 views each, which may not be representative of the full dataset or real-world scenarios.
- What evidence would resolve it: A comprehensive study on the full dataset with various object categories and views, comparing the performance of ResNet50 and ResNet152 in terms of reconstruction quality and inference speed.

### Open Question 2
- Question: How can the Extended Chamfer Distance (ECD) be improved to achieve both high reconstruction quality and good equivariance preservation?
- Basis in paper: [explicit] The paper discusses the trade-off between reconstruction quality and equivariance preservation when using ECD, suggesting that a better version of ECD could be developed to achieve both goals.
- Why unresolved: The current ECD formulation leads to a decrease in reconstruction quality, as observed in the ablation study.
- What evidence would resolve it: Development and evaluation of alternative ECD formulations or loss functions that maintain high reconstruction quality while preserving equivariance.

### Open Question 3
- Question: How can GSN be extended to handle scene-level tasks and multiple object reconstruction in cluttered scenes with heavy occlusion?
- Basis in paper: [inferred] The paper mentions that GSN is an object-centric model and does not account for noise in input images, making it unsuitable for scene-level tasks. The authors suggest that future directions may include scene-level single-image reconstruction or multiple object reconstruction in cluttered scenes.
- Why unresolved: The current GSN architecture is designed for object-centric reconstruction and does not incorporate mechanisms to handle complex scenes or occlusions.
- What evidence would resolve it: Development and evaluation of GSN extensions or modifications that can handle scene-level tasks, including the ability to reconstruct multiple objects in cluttered scenes and handle occlusions.

## Limitations
- The canonical cube initialization may limit reconstruction of highly irregular or complex object shapes
- The ECD loss constraint may reduce reconstruction quality for objects without rotational symmetry
- The model is object-centric and doesn't handle scene-level tasks or cluttered environments with occlusion

## Confidence

- Reconstruction quality claims (PSNR/SSIM/LPIPS): High - Well-supported by quantitative metrics and ablation studies
- Real-time performance claims (>150FPS): High - Directly measured and compared against baselines
- SO(2) equivariance effectiveness: Medium - Demonstrated but not extensively analyzed across different object categories
- Robotic grasping applicability: Medium - Preliminary results shown but limited to specific scenarios

## Next Checks

1. Conduct extensive ablation studies varying the number of Gaussians (N) in the canonical cube to quantify the trade-off between reconstruction quality and computational efficiency.
2. Evaluate GSN's performance on objects with high rotational symmetry (e.g., vases, bottles) versus asymmetric objects to better understand the impact of the equivariance constraint.
3. Test the model's robustness to extreme viewing angles and occlusion scenarios common in real-world robotic manipulation tasks to validate practical applicability beyond the ShapeNet benchmarks.