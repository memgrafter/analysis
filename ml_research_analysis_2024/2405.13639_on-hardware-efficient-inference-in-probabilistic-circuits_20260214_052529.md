---
ver: rpa2
title: On Hardware-efficient Inference in Probabilistic Circuits
arxiv_id: '2405.13639'
source_url: https://arxiv.org/abs/2405.13639
tags:
- error
- bits
- energy
- hardware
- mantissa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the high energy and resolution requirements
  for probabilistic circuit (PC) inference on hardware. PCs support efficient probabilistic
  reasoning but require high-resolution floating-point computations, which are energy-intensive.
---

# On Hardware-efficient Inference in Probabilistic Circuits

## Quick Facts
- arXiv ID: 2405.13639
- Source URL: https://arxiv.org/abs/2405.13639
- Authors: Lingyun Yao; Martin Trapp; Jelin Leslin; Gaurav Singh; Peng Zhang; Karthekeyan Periasamy; Martin Andraud
- Reference count: 40
- Primary result: Energy reductions of up to 649× for MAP queries and 357× for marginal queries using AAI-based approximate computing

## Executive Summary
This work addresses the high energy and resolution requirements for probabilistic circuit (PC) inference on hardware. PCs support efficient probabilistic reasoning but require high-resolution floating-point computations, which are energy-intensive. The authors propose an approximate computing framework based on Addition-As-Int (AAI), which replaces floating-point multiplications with simple integer additions, reducing energy consumption. The method alternates between logarithmic and linear computations, leveraging Mitchell's approximation for efficient multiplication. Empirical results show energy reductions of up to 649× for MAP queries and 357× for marginal queries, with minimal approximation error.

## Method Summary
The paper proposes a dedicated approximate computing framework for efficient PC inference on hardware. The core approach is based on Addition-As-Int (AAI), which approximates floating-point multiplication by replacing it with integer addition in the logarithmic domain. This leverages Mitchell's approximation to interpret products as logarithmic additions. The method alternates between logarithmic and linear computations using an "exp-sum-log" trick. To minimize accuracy loss, the authors provide theoretical error analysis (using KL divergence) and devise a greedy algorithm for safe multiplier replacement. An error correction mechanism using Monte-Carlo integration further improves accuracy by correcting expected errors based on the circuit's probability distribution.

## Key Results
- Energy reduction of up to 357× for marginal (MAR) queries
- Energy reduction of up to 649× for MAP queries
- Minimal approximation error achieved through safe multiplier replacement
- Error correction mechanism further improves accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing floating-point multipliers with AAI drastically reduces energy consumption
- Mechanism: AAI approximates the product of two floating-point numbers by replacing the multiplication with a simple integer addition in the logarithmic domain using Mitchell's approximation
- Core assumption: The approximation error introduced by AAI is tolerable for probabilistic inference tasks
- Evidence anchors:
  - [abstract]: "The method alternates between logarithmic and linear computations, leveraging Mitchell’s approximation for efficient multiplication"
  - [section]: "We propose a dedicated approximate computing framework to efficiently compute PCs on hardware. It is based on a similar alternation between log and linear computations, which we refer as the "exp-sum-log" trick"

### Mechanism 2
- Claim: Safe multiplier replacement strategies minimize accuracy loss when using AAI
- Mechanism: Theoretical analysis of AAI error (using KL divergence) is used to develop a greedy algorithm that selects multipliers to replace while minimizing overall error
- Core assumption: Theoretical error analysis accurately predicts impact of AAI on PC inference accuracy
- Evidence anchors:
  - [section]: "Based on Eq. (9) and Eq. (10), we devise a greedy algorithm that gradually replaces multiplications with AAI while minimizing the introduced error"

### Mechanism 3
- Claim: Error correction mechanisms further improve accuracy of PCs using AAI
- Mechanism: Proposes computing expected error introduced by AAI (using Monte-Carlo integration) and correcting computed probabilities based on the circuit's probability distribution
- Core assumption: Expected error can be accurately estimated and used to correct computed probabilities
- Evidence anchors:
  - [section]: "To reduce the error caused by AAI, [Saadat et al., 2018] proposed to correct this error by computing an expected error, assuming uniform probability for all possible floating-point numbers"

## Foundational Learning

- **Probabilistic Circuits (PCs)**: Why needed: PCs are the primary focus and understanding their structure is essential for the hardware-efficient inference framework. Quick check: What are the key properties of PCs that enable efficient and exact computation of probabilistic inference tasks?
- **Floating-point arithmetic and hardware implementation**: Why needed: Understanding floating-point multiplication complexity is crucial for appreciating AAI benefits. Quick check: Why is floating-point multiplication more energy-intensive than addition in hardware?
- **Logarithmic and linear domains in probabilistic computation**: Why needed: The "exp-sum-log" trick alternates between these domains. Quick check: Why are computations in PCs typically performed in the log domain, and what are the challenges of performing these computations in hardware?

## Architecture Onboarding

- **Component map**: Probabilistic Circuit structure → Hardware generation (Chisel to Verilog) → AAI multiplier implementation → Error correction mechanism → Hardware blocks for inference
- **Critical path**: Parse PC structure → Generate hardware description → Implement AAI multiplier and error correction → Synthesize to Verilog → Simulate hardware for functionality and energy measurement
- **Design tradeoffs**: Accuracy vs. energy consumption (more mantissa bits = better accuracy but higher energy); Hardware complexity vs. energy consumption (AAI reduces complexity but introduces errors); Error correction vs. computational overhead
- **Failure signatures**: High approximation error compromising accuracy; Incorrect hardware generation from Chisel code; Simulation mismatch with actual hardware implementation
- **First 3 experiments**:
  1. Implement simple tree-shaped PC and verify correct translation from Chisel to Verilog/VHDL
  2. Implement AAI multiplier and compare energy consumption and accuracy against floating-point multiplier
  3. Implement error correction mechanism and verify accuracy improvement for marginal inference task

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the AAI framework perform on PCs with more complex structures beyond tree-shaped non-deterministic PCs?
- **Open Question 2**: Can the safe multiplier replacement strategy be further optimized for higher energy savings while maintaining low error?
- **Open Question 3**: How does the error correction mechanism perform in PCs with continuous variables or non-indicator leaf nodes?

## Limitations

- Theoretical error bounds for AAI in non-deterministic circuits rely on KL divergence approximations that may not capture all practical failure modes
- Hardware implementation details (Chisel code specifics, Verilog translation) are not fully specified, potentially affecting reproducibility
- Monte-Carlo error correction assumes specific probability distributions that may not hold for all PC structures

## Confidence

- **High Confidence**: Energy reduction measurements (357× for MAR, 649× for MAP) based on CMOS technology simulations with clear methodology
- **Medium Confidence**: Theoretical error analysis for AAI - mathematically rigorous but requires further validation on real-world inference tasks
- **Medium Confidence**: Safe multiplier replacement strategy - well-defined greedy algorithm but may not find globally optimal solutions

## Next Checks

1. Reproduce energy measurements by implementing AAI multiplier and comparing energy consumption against floating-point multiplier on FPGA using simple multiplication benchmarks
2. Validate theoretical error bounds empirically by testing KL divergence bounds on deterministic and non-deterministic circuits with known ground truth
3. Test safe replacement algorithm by applying greedy multiplier replacement to different PC structures across multiple benchmark datasets to verify consistent low-error subset selection