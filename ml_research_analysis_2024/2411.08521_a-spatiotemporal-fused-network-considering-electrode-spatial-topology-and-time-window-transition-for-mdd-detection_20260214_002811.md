---
ver: rpa2
title: A spatiotemporal fused network considering electrode spatial topology and time-window
  transition for MDD detection
arxiv_id: '2411.08521'
source_url: https://arxiv.org/abs/2411.08521
tags:
- feature
- time
- features
- spatial
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes SET-TIME, a deep learning framework for detecting
  major depressive disorder (MDD) using EEG signals. The method addresses limitations
  in existing spatiotemporal feature extraction approaches by incorporating electrode
  spatial topology and time-window transition information.
---

# A spatiotemporal fused network considering electrode spatial topology and time-window transition for MDD detection

## Quick Facts
- arXiv ID: 2411.08521
- Source URL: https://arxiv.org/abs/2411.08521
- Reference count: 36
- Primary result: Achieves 92.00% accuracy on PRED+CT and 94.00% on MODMA datasets for MDD detection

## Executive Summary
This paper introduces SET-TIME, a deep learning framework that addresses key limitations in existing spatiotemporal feature extraction approaches for MDD detection using EEG signals. The method innovatively incorporates electrode spatial topology and time-window transition information through three novel modules: a time-window transitional module that captures long-range dependencies between adjacent windows, an electrode spatial topology module that fuses physical and functional connectivity patterns, and a secondary time-correlation feature extractor that enhances temporal feature extraction using both LSTM and Graph Transformer Network. Evaluated on two public MDD datasets with 10-fold cross-validation, SET-TIME achieves state-of-the-art accuracies of 92.00% and 94.00% respectively, demonstrating that incorporating spatial and temporal transition information significantly improves detection performance.

## Method Summary
The SET-TIME framework processes EEG signals by first dividing them into 20 non-overlapping time windows, then extracting features through a common feature extractor that combines multi-scale depth-wise convolution with the time-window transitional and electrode spatial topology modules. The time-window transitional module uses autoencoders to capture features from window transitions, while the electrode spatial topology module fuses physical adjacency matrices with functional connectivity using GCNs. A secondary time-correlation feature extractor further enhances temporal features through LSTM and Graph Transformer Network processing. The model employs domain adaptation via adversarial learning to improve cross-subject generalization and is trained using SGD optimizer with 10-fold cross-validation in cross-subject mode.

## Key Results
- Achieves state-of-the-art accuracy of 92.00% on PRED+CT dataset and 94.00% on MODMA dataset
- Ablation studies demonstrate the effectiveness of the electrode spatial topology module, particularly on the MODMA dataset where its removal causes a 4.33% accuracy drop
- Domain adaptation module improves cross-subject generalization, with PAM scores of 86.00% and 88.00% on respective datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The electrode spatial topology module improves MDD detection by explicitly encoding the physical positions and connectivity patterns of EEG electrodes into the network.
- **Mechanism:** The module fuses a binary physical adjacency matrix (capturing spatial topology) with a functional connectivity matrix (derived from EEG data) using a mask-based approach. This fused connectivity matrix is then used as input to a graph convolutional network (GCN), which aggregates spatial features from neighboring electrodes based on their physical and functional relationships.
- **Core assumption:** MDD pathology manifests as abnormal functional connectivity patterns between specific brain regions, and these patterns can be better captured by combining physical and functional connectivity information.
- **Evidence anchors:**
  - [abstract] "an electrode spatial topology module that contains the spatial location and physical connection information is proposed to mine spatial features of EEG signals"
  - [section] "Previous studies have shown that the connectivity patterns and activity intensity between different regions of the brain in patients with MDD undergo significant changes... automatic weighting to the connection map by means of model training allows the model to learn enhanced spatial location information"
  - [corpus] No direct evidence from corpus papers; this appears to be a novel contribution
- **Break condition:** If the functional connectivity patterns in MDD do not correlate with the physical electrode positions, or if the GCN cannot effectively aggregate features from the fused connectivity matrix, this mechanism would fail.

### Mechanism 2
- **Claim:** The time-window transitional module captures long-range temporal dependencies between adjacent time windows by extracting features from the transitions between windows.
- **Mechanism:** The module uses an autoencoder to extract features from the start and end segments of each time window, then uses a dual-path autoencoder to capture temporal correlations between these segments across consecutive windows. This allows the model to learn dependencies across window boundaries without disrupting the temporal order of the EEG signal.
- **Core assumption:** MDD-related neural activity patterns exhibit temporal continuity and correlations across adjacent time windows, which can be better captured by explicitly modeling the transitions between windows.
- **Evidence anchors:**
  - [abstract] "a time-window transitional module for capturing long-range dependencies between adjacent time windows"
  - [section] "the time-window transitional module uses an auto-encoder to extract features for the start and the end of each time window, and then digs deeper into the time window correlations to establish long-range dependencies"
  - [corpus] No direct evidence from corpus papers; this appears to be a novel contribution
- **Break condition:** If MDD-related patterns do not exhibit temporal continuity across time windows, or if the autoencoder cannot effectively extract meaningful transition features, this mechanism would fail.

### Mechanism 3
- **Claim:** The secondary time-correlation feature extractor enhances temporal feature extraction by capturing deep temporal correlations among multiple time windows using both LSTM and GTN networks.
- **Mechanism:** The module first uses an LSTM network to learn complex long-range dependencies among multiple time windows containing spatial features. It then uses a Graph Transformer Network (GTN) to dynamically construct graph structures and capture longer node connections along the time-window dimension, breaking through LSTM's limitations in extracting fixed temporal patterns.
- **Core assumption:** MDD-related neural activity patterns exhibit complex temporal dynamics that require both recurrent and graph-based modeling approaches to capture effectively.
- **Evidence anchors:**
  - [abstract] "a secondary time-correlation feature extractor further enhances temporal feature extraction"
  - [section] "The secondary time correlation extraction module provides temporal features with high resolution and semantic information. Meanwhile, the long-range temporal dependencies of multiple time windows can be further exploited"
  - [corpus] No direct evidence from corpus papers; this appears to be a novel contribution
- **Break condition:** If the combination of LSTM and GTN does not provide additional temporal information beyond what the common feature extractor captures, or if the temporal patterns in MDD are not complex enough to require this dual approach, this mechanism would fail.

## Foundational Learning

- **Concept: Graph Convolutional Networks (GCNs)**
  - Why needed here: GCNs are essential for processing the spatial connectivity information between EEG electrodes, as they can aggregate features from neighboring nodes based on the graph structure
  - Quick check question: How does a GCN differ from a standard convolutional neural network in terms of the data it can process?

- **Concept: Autoencoders for feature extraction**
  - Why needed here: Autoencoders are used in the time-window transitional module to extract compressed representations of the start and end segments of each time window
  - Quick check question: What is the primary purpose of using an autoencoder in the context of extracting features from EEG time windows?

- **Concept: Domain adaptation using adversarial learning**
  - Why needed here: The domain adaptation module uses gradient reversal to learn features that are invariant across different subjects, improving cross-subject MDD detection performance
  - Quick check question: How does the gradient reversal layer in the domain adaptation module encourage the network to learn domain-invariant features?

## Architecture Onboarding

- **Component map:** Input EEG signals → Common feature extractor (multi-scale depth-wise convolution + time-window transitional module + electrode spatial topology module) → Secondary time-correlation feature extractor (LSTM + Graph Transformer Network) → Domain adaptation module → Classification output

- **Critical path:** Input → Common feature extractor → Secondary time-correlation feature extractor → Domain adaptation → Classification

- **Design tradeoffs:**
  - Spatial vs. temporal feature extraction: The electrode spatial topology module focuses on spatial relationships while the time-window modules focus on temporal dependencies
  - Complexity vs. interpretability: The multi-scale convolutions and dual-path autoencoders add complexity but may capture more nuanced features
  - Cross-subject generalization: The domain adaptation module trades some subject-specific accuracy for improved generalization across subjects

- **Failure signatures:**
  - Poor performance on both datasets: Indicates issues with the overall architecture or training process
  - Good performance on one dataset but poor on another: Suggests overfitting to dataset-specific characteristics or inadequate domain adaptation
  - Degradation when removing specific modules: Confirms the importance of those components but also reveals potential redundancies

- **First 3 experiments:**
  1. Test the common feature extractor alone (without secondary time-correlation or domain adaptation) to establish baseline performance
  2. Add the electrode spatial topology module to the common feature extractor and measure performance improvement
  3. Add the time-window transitional module to the previous configuration and evaluate the impact on temporal feature extraction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of time windows for extracting temporal features from EEG signals for MDD detection?
- Basis in paper: [explicit] The paper uses 20 time windows in experiments but notes that the optimal number may vary based on dataset characteristics.
- Why unresolved: The paper does not conduct experiments to determine the optimal number of time windows, leaving this as a hyperparameter that may need tuning for different datasets.
- What evidence would resolve it: Systematic experiments varying the number of time windows (e.g., 10, 15, 20, 25, 30) on multiple datasets while measuring classification performance would identify the optimal window count.

### Open Question 2
- Question: How does the performance of SET-TIME vary across different electrode channel configurations and what is the minimum number of channels required for effective MDD detection?
- Basis in paper: [explicit] The paper shows significantly different performance between PRED+CT (66 channels) and MODMA (128 channels) datasets, with MODMA showing more dramatic performance drops when electrode topology is removed.
- Why unresolved: While the paper demonstrates that electrode count affects performance, it does not systematically explore how performance scales with different channel configurations or determine the minimum effective channel count.
- What evidence would resolve it: Experiments systematically reducing the number of channels from the full configuration while measuring classification accuracy would establish the relationship between channel count and performance.

### Open Question 3
- Question: What is the relative importance of the secondary time-correlation feature extractor components (LSTM vs. GTN) across different types of temporal patterns in EEG signals?
- Basis in paper: [explicit] The ablation study shows unexpected results where removing the entire secondary time-correlation feature extractor sometimes performs better than removing just one component, suggesting complex interactions between LSTM and GTN.
- Why unresolved: The paper does not analyze which temporal patterns each component is better at capturing or under what conditions one component might be preferable over the other.
- What evidence would resolve it: Detailed analysis of temporal patterns in MDD vs. healthy control EEG signals, combined with component-specific ablation studies on datasets with different temporal characteristics, would clarify the strengths and limitations of each approach.

## Limitations
- Physical adjacency matrix specifications are not fully described, requiring inference from figure references
- Domain adaptation module implementation details, particularly gradient reversal layer configuration, are not specified
- Performance metrics are evaluated using cross-subject validation, but the impact of subject-specific vs. generalized features is not explicitly quantified

## Confidence

- High confidence in the overall architecture design and module integration approach
- Medium confidence in the effectiveness of the time-window transitional module, as this appears to be a novel contribution without direct corpus support
- Medium confidence in the electrode spatial topology module's contribution, given the lack of direct evidence from related papers
- Low confidence in the exact implementation details of the domain adaptation component due to unspecified gradient reversal configuration

## Next Checks

1. Implement ablation studies systematically by removing each proposed module (electrode spatial topology, time-window transitional, secondary time-correlation) to quantify their individual contributions
2. Validate the physical adjacency matrix construction by comparing the model's performance with different spatial topology configurations
3. Test the model's sensitivity to domain adaptation strength by varying the gradient reversal layer's scaling factor and measuring cross-subject generalization performance