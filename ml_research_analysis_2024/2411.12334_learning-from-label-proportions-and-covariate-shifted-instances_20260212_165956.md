---
ver: rpa2
title: Learning from Label Proportions and Covariate-shifted Instances
arxiv_id: '2411.12334'
source_url: https://arxiv.org/abs/2411.12334
tags:
- domain
- target
- source
- loss
- bags
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses learning from label proportions (LLP) in the
  presence of covariate shift, where the source data has instance-level labels and
  the target data has bag-level labels. The authors propose methods that leverage
  both the source instance labels and target bag labels within a domain adaptation
  framework.
---

# Learning from Label Proportions and Covariate-shifted Instances

## Quick Facts
- **arXiv ID**: 2411.12334
- **Source URL**: https://arxiv.org/abs/2411.12334
- **Authors**: Sagalpreet Singh; Navodita Sharma; Shreyas Havaldar; Rishi Saket; Aravindan Raghuveer
- **Reference count**: 40
- **Primary result**: BL-WFA and PL-WFA methods outperform baseline methods on LLP with covariate shift, with improvements of up to 27.9% over best baseline.

## Executive Summary
This paper addresses the challenge of learning from label proportions (LLP) in the presence of covariate shift between source and target domains. The source domain provides instance-level labels while the target domain provides only bag-level labels. The authors propose the BagCSI loss function that combines instance-level loss on source data, bag-level loss on target bags, and a domain adaptation term. Two methods are introduced: Bag Label Weighted Feature Alignment (BL-WFA) and Pseudo-label Weighted Feature Alignment (PL-WFA), both of which leverage both source instance labels and target bag labels within a domain adaptation framework.

## Method Summary
The paper proposes a framework for LLP under covariate shift where source data has instance-level labels and target data has bag-level labels. The core contribution is the BagCSI loss function that combines three terms: instance-level loss on source data, bag-level loss on target bags, and a domain adaptation term that aligns feature representations across domains. Two methods are proposed: BL-WFA assigns bag-labels as pseudo-labels for all instances within bags, while PL-WFA generates pseudo-labels by adding a constant offset to predictions to match bag-labels. The methods are evaluated on synthetic and real-world datasets, showing improvements of up to 27.9% over baseline methods, particularly for larger bag sizes.

## Key Results
- BL-WFA and PL-WFA outperform baseline methods on IPUMS and Wine datasets, with BL-WFA achieving 2.9% and 4.3% improvements over best baselines for bag sizes 256 and 32 respectively.
- On the large-scale Criteo SSCL dataset, BL-WFA and PL-WFA achieve 27.9% and 23.5% improvements over the best baseline (LR) for bag size 128.
- Performance degrades with increasing bag size across all methods, with MSE scores increasing from 0.0026 (bag size 8) to 0.0064 (bag size 256) on IPUMS dataset.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: BagCSI loss provides an upper bound on target generalization error by combining instance-level loss on source data, bag-level loss on target bags, and a domain adaptation term.
- **Mechanism**: The BagCSI loss function includes three components: (1) instance-level loss on source data, (2) bag-level loss on target bags, and (3) a domain adaptation term that aligns feature representations across source and target domains. This alignment leverages both instance labels from the source and bag labels from the target to create a more effective learning signal than using either source or target data alone.
- **Core assumption**: The covariate shift assumption holds (i.e., p(X) differs between source and target distributions while p(Y|X) remains the same), and the regularization term R(h, S, T) is negligible in practice.
- **Evidence anchors**:
  - [abstract]: "Our main methodological novelty is the third term which leverages bag-labels (unlike previous works) from the target domain for domain adaptation, along with instance-labels from the source domain."
  - [section]: "Combining Lemma 3.1 with the implication of Theorem 3.2 we obtain ε(DT, h) ≤ w1¯ε(B, h) + w2ˆε(S, h) + w2 (¯ε(B, h) − ˆε(S, h))"
  - [corpus]: Weak - The corpus doesn't directly discuss BagCSI loss mechanisms, focusing instead on general LLP approaches.
- **Break condition**: If the covariate shift assumption is violated (p(Y|X) differs between domains), the domain adaptation term would be ineffective and the upper bound would no longer hold.

### Mechanism 2
- **Claim**: The PL-WFA method improves performance by generating pseudo-labels for target instances that satisfy bag-label constraints while minimizing prediction error.
- **Mechanism**: PL-WFA computes pseudo-labels by adding a constant offset to each instance prediction within a bag such that the average pseudo-label matches the bag-label. This creates a consistent labeling scheme that can be used for domain adaptation, effectively creating a bridge between the fully supervised source data and weakly supervised target data.
- **Core assumption**: The underlying hypothesis model h can produce reasonable predictions that, when adjusted by a constant offset, yield pseudo-labels close to the true instance labels.
- **Evidence anchors**:
  - [abstract]: "Another approach is to use the following process for pseudo-labeling instances in a bag B using hypothesis model h"
  - [section]: "Compute the predictions {h(x)}x∈B. The pseudo-labels are given by adding to each prediction the same b ∈ R such that average pseudo-label in the bag equals the bag-label."
  - [corpus]: Weak - Corpus neighbors discuss LLP but don't specifically address pseudo-label generation methods.
- **Break condition**: If the hypothesis model h produces highly inaccurate predictions, the pseudo-labels would be poor quality, leading to ineffective domain adaptation and degraded performance.

### Mechanism 3
- **Claim**: The BL-WFA method works by treating bag-labels as instance pseudo-labels for all instances within each bag, creating a domain adaptation signal that aligns source and target feature representations.
- **Mechanism**: BL-WFA assigns the bag-label as the pseudo-label for all instances within a bag, then uses these pseudo-labels in the domain adaptation loss term. This creates a simple but effective way to incorporate target supervision into the feature alignment process.
- **Core assumption**: The bag-label provides a reasonable approximation of the average instance label within the bag, and this approximation is sufficient for effective domain adaptation.
- **Evidence anchors**:
  - [abstract]: "One way is to assign the bag-label as the pseudo-label for all instances within the bag, in which case ψ(S, B) essentially reduces to ξ(S, B)"
  - [section]: "We call this method Bag Label Weighted Feature Alignment (BL-WFA) which involves training using the BagCSI loss."
  - [corpus]: Weak - The corpus doesn't specifically discuss bag-label based pseudo-labeling approaches.
- **Break condition**: If bags contain highly heterogeneous instance labels (e.g., bags with both very high and very low instance labels), the bag-label approximation becomes poor and the domain adaptation signal degrades.

## Foundational Learning

- **Concept: Learning from Label Proportions (LLP)**
  - Why needed here: LLP is the fundamental setting where training data is organized into bags with only aggregate labels available, which is the core challenge addressed by this paper.
  - Quick check question: In LLP, if a bag contains 4 instances with labels [0.2, 0.8, 0.5, 0.3], what is the bag-label?

- **Concept: Domain Adaptation**
  - Why needed here: The paper addresses covariate shift between source (fully supervised) and target (bag-labeled) domains, requiring techniques to align feature distributions across domains.
  - Quick check question: What is the key assumption about label distributions in covariate shift that enables domain adaptation to work?

- **Concept: Generalization Error Bounds**
  - Why needed here: The paper provides theoretical guarantees bounding the target generalization error, which requires understanding how sample complexity and pseudo-dimension affect learning performance.
  - Quick check question: According to the paper's bound, how does the generalization error scale with bag size k?

## Architecture Onboarding

- **Component map**: Feature vectors -> Neural network (128 ReLU nodes) -> Domain classifier (sigmoid) -> Output (linear) -> Loss computation (BagCSI, ξ², pseudo-label generation)
- **Critical path**: 
  1. Forward pass through neural network for both source instances and target bag instances
  2. Compute predictions and pseudo-labels (for PL-WFA/BL-WFA)
  3. Calculate BagCSI loss components (instance loss, bag loss, domain adaptation)
  4. Backward pass and parameter updates
  5. Domain classifier update (for DANN variants)
- **Design tradeoffs**:
  - Using bag-labels as pseudo-labels (BL-WFA) vs. generating pseudo-labels from predictions (PL-WFA): BL-WFA is simpler but less precise; PL-WFA is more sophisticated but computationally heavier
  - Including vs. excluding regularization term R(h, S, T): Including provides theoretical completeness but empirically shows minimal impact
  - Equal vs. proportional sampling of source/target instances in mini-batches: Equal sampling simplifies normalization but may not reflect data distribution
- **Failure signatures**:
  - Poor performance on small bag sizes: May indicate insufficient information from target domain, requiring stronger source domain signal
  - Degraded performance with large bag sizes: Expected due to information loss, but excessive degradation may indicate model capacity issues
  - High variance across runs: May indicate insufficient regularization or unstable pseudo-label generation
- **First 3 experiments**:
  1. Compare BL-WFA vs. Bagged-Target baseline on IPUMS dataset with bag size 256 to verify the claimed 2.9% improvement
  2. Test PL-WFA with different λ values to find optimal trade-off between source instance loss and target bag loss
  3. Evaluate both proposed methods on synthetic dataset with varying covariate shift magnitude to understand robustness to domain shift

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the traditional sense. However, the following questions arise from the limitations and implications of the work:

1. How does the performance of BL-WFA and PL-WFA scale with different levels of covariate shift between source and target distributions?
2. Can the BagCSI loss function be extended to handle multi-class classification tasks in addition to regression?
3. How sensitive are the proposed methods to the choice of hyperparameters, particularly the weights (λ1, λ2, λ3) in the BagCSI loss function?

## Limitations
- Performance degrades significantly with larger bag sizes (up to 50% relative degradation on Criteo SSCL), suggesting fundamental limitations of the approach.
- The pseudo-label generation mechanism relies on the assumption that a constant offset to predictions can produce reasonable pseudo-labels, which is not rigorously validated.
- The theoretical guarantees rely on assumptions about the negligible regularization term R(h, S, T) that are not empirically validated.

## Confidence
- **BagCSI loss provides effective upper bound**: Medium confidence - The theoretical framework is sound, but empirical validation of the bound is limited to observed performance improvements rather than verification of the bound itself.
- **Proposed methods outperform baselines**: High confidence - Experimental results consistently show improvements across multiple datasets and bag sizes, with statistically significant margins.
- **Performance degrades with bag size**: High confidence - This is observed across all methods and datasets, consistent with theoretical expectations about information loss.

## Next Checks
1. Validate the negligible regularization assumption: Conduct experiments that explicitly measure the regularization term R(h, S, T) across different datasets and compare it to the other terms in the bound to empirically verify the assumption that it is negligible.
2. Test PL-WFA robustness to prediction quality: Evaluate the pseudo-label generation mechanism by deliberately introducing noise into the hypothesis predictions and measuring the impact on final performance to understand the sensitivity to prediction quality.
3. Analyze bag-label approximation error: For bags with known heterogeneous instance labels, measure the discrepancy between bag-labels and true average instance labels to quantify how this approximation error affects domain adaptation performance.