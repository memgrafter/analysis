---
ver: rpa2
title: A Collaborative, Human-Centred Taxonomy of AI, Algorithmic, and Automation
  Harms
arxiv_id: '2407.01294'
source_url: https://arxiv.org/abs/2407.01294
tags:
- taxonomy
- harms
- loss
- harm
- technology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a collaborative, human-centred taxonomy of
  AI, algorithmic, and automation harms. The taxonomy addresses the need for a comprehensive,
  understandable classification of harms caused by these technologies, aiming to empower
  citizens, NGOs, policymakers, and product teams to identify, report, and mitigate
  violations.
---

# A Collaborative, Human-Centred Taxonomy of AI, Algorithmic, and Automation Harms

## Quick Facts
- arXiv ID: 2407.01294
- Source URL: https://arxiv.org/abs/2407.01294
- Reference count: 40
- Primary result: Introduces a comprehensive, human-centred taxonomy of AI, algorithmic, and automation harms with 9 top-level categories and 69 sub-categories, developed through iterative expert and crowdsourced annotation testing.

## Executive Summary
This paper presents a collaborative, human-centred taxonomy designed to classify harms caused by AI, algorithmic, and automation technologies. The taxonomy addresses the need for a comprehensive, understandable classification system that can empower diverse stakeholders—citizens, NGOs, policymakers, and product teams—to identify, report, and mitigate technology-related harms. Developed through an iterative process involving literature review, expert outreach, and crowdsourced annotation testing using a custom tool, the taxonomy organizes harms into nine top-level categories and 69 sub-categories. It aims to foster greater understanding of AI-related harms, inform policy discussions, and encourage responsible technology development and deployment.

## Method Summary
The taxonomy was developed through an iterative process combining literature review, expert outreach, and crowdsourced annotation testing. A custom-built tool facilitated incident annotation where multiple annotators classified incidents from the AIAAIC database, computing Krippendorff's alpha for agreement. Definitions were refined through multiple rounds until high consensus was achieved. The approach followed an "outside-in" methodology, starting from documented incidents rather than theoretical risks, and incorporated input from diverse stakeholders including NGOs, policymakers, and industry representatives.

## Key Results
- Taxonomy comprises 9 top-level harm categories and 69 specific sub-categories covering diverse harm types
- Iterative annotation process achieved high inter-annotator agreement (Krippendorff's alpha) through multiple refinement rounds
- Taxonomy designed to be clear, practical, and extensible with definitions provided for each harm type
- Addresses gaps in existing taxonomies by being more comprehensive and accessible to non-technical audiences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The taxonomy enables broader stakeholder engagement by using plain language and relatable categories.
- Mechanism: It replaces technical jargon with nine top-level harm types and 69 sub-categories that map to everyday concerns (e.g., "Loss of life," "Harassment," "Job loss"), making it easier for non-experts to recognize and report harms.
- Core assumption: Stakeholders will find these categories intuitive and actionable.
- Evidence anchors:
  - [abstract]: "clear and understandable to a broad set of audiences"
  - [section 1]: Mentions "teenage addiction to social media platforms" and "loss of fundamental liberties" as relatable examples.
  - [corpus]: Weak; no explicit evidence of usability testing with non-experts in corpus neighbors.
- Break condition: If stakeholder testing reveals categories are still too abstract or misclassified.

### Mechanism 2
- Claim: The iterative annotation testing process ensures consensus and reduces bias in harm classification.
- Mechanism: Using a custom tool, multiple annotators label incidents, compute Krippendorff's alpha for agreement, and refine definitions until high consensus is reached.
- Core assumption: Annotators from diverse backgrounds will converge on consistent classifications.
- Evidence anchors:
  - [section 3.2.4]: Describes "Krippendorff's alpha coefficient, a score measuring agreement among annotators."
  - [abstract]: "iterative refinement with topic experts and crowdsourced annotation testing."
  - [corpus]: Weak; corpus does not mention Krippendorff's alpha or consensus measures.
- Break condition: If alpha scores remain low despite iterations, indicating inherent disagreement or poor definitions.

### Mechanism 3
- Claim: The taxonomy supports both risk management and policy enforcement by linking harms to measurable consequences.
- Mechanism: It organizes harms into actionable categories (e.g., "Financial/earnings loss," "Privacy loss") that can be tied to compliance metrics, audit trails, and impact assessments under regulations like the EU AI Act.
- Core assumption: Regulators and auditors will adopt these categories in formal risk frameworks.
- Evidence anchors:
  - [section 5]: "Risk management: The taxonomy...can also be used for risk management, auditing and impact assessment purposes."
  - [abstract]: "empower NGOs and individuals to identify and report violations, inform policy discussions."
  - [corpus]: No direct evidence; corpus focuses on academic taxonomy projects, not regulatory adoption.
- Break condition: If regulators continue using existing, narrower taxonomies despite this proposal.

## Foundational Learning

- Concept: Harm vs. Risk
  - Why needed here: The paper distinguishes "harms" (actual or potential damages) from "risks" (likelihood of those damages). This is key to understanding the taxonomy's focus.
  - Quick check question: In the taxonomy, what distinguishes an "actual" harm from a "potential" harm?
    - Answer: "Actual" when sources explicitly state the harm occurred; "potential" when it is reasonably likely to occur.

- Concept: Krippendorff's Alpha
  - Why needed here: Used to measure annotator agreement during testing, ensuring the taxonomy is clear and consistently understood.
  - Quick check question: What metric does the paper use to measure agreement among annotators?
    - Answer: Krippendorff's alpha coefficient.

- Concept: Outside-in vs. Inside-out taxonomy development
  - Why needed here: Explains the methodology—starting from documented incidents (outside-in) rather than theoretical risks (inside-out)—ensuring real-world relevance.
  - Quick check question: Does the taxonomy begin with documented incidents or theoretical risks?
    - Answer: Documented incidents (outside-in).

## Architecture Onboarding

- Component map:
  - Core taxonomy data structure: harm types (9) → specific harms (69)
  - Annotation tool: UI for incident selection, harm tagging, comment submission
  - Consensus engine: computes Krippendorff's alpha, generates Sankey diagrams
  - Repository integration: links incidents from AIAAIC database to taxonomy
  - Documentation: definitions, usage guides, open-source tooling

- Critical path:
  1. Load incident from repository
  2. Annotator selects harm types and specific harms
  3. Tool computes agreement scores
  4. If consensus < threshold, iterate definitions
  5. Publish updated taxonomy

- Design tradeoffs:
  - Broad vs. deep: 69 sub-categories balance comprehensiveness with usability
  - Flexibility vs. stability: taxonomy designed to evolve but not change weekly
  - Open vs. controlled: volunteer-driven but requires moderation to maintain quality

- Failure signatures:
  - Low Krippendorff's alpha scores across multiple rounds
  - Annotator confusion reflected in comments or inconsistent tagging
  - Repository incidents remain uncategorized after extended periods

- First 3 experiments:
  1. Load a known incident (e.g., facial recognition wrongful arrest) and tag harms; verify alpha score > 0.6
  2. Attempt to add a new specific harm (e.g., "Deepfake political manipulation") and test categorization flow
  3. Simulate regulator use case: map taxonomy harms to EU AI Act risk categories and check completeness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the taxonomy be made more inclusive of diverse cultural contexts and perspectives on harm?
- Basis in paper: [explicit] The paper states the taxonomy aims to be "inclusive of various differing social, geographical, and cultural contexts."
- Why unresolved: The paper acknowledges this as a goal but does not detail how it will be achieved or tested.
- What evidence would resolve it: A study demonstrating the taxonomy's effectiveness and applicability across diverse cultural contexts.

### Open Question 2
- Question: How can the taxonomy be made more machine-readable and interoperable with existing systems?
- Basis in paper: [explicit] The paper states the taxonomy is designed to be "machine-readable to facilitate further development and encourage adoption."
- Why unresolved: While the goal is stated, the paper does not provide specific details on implementation or testing.
- What evidence would resolve it: A technical specification or prototype demonstrating machine-readability and interoperability.

### Open Question 3
- Question: How can the taxonomy be effectively used to inform risk management and impact assessment practices?
- Basis in paper: [explicit] The paper discusses potential uses of the taxonomy for risk management and impact assessment, but does not provide concrete examples or guidelines.
- Why unresolved: The paper outlines the potential benefits but does not detail how the taxonomy would be integrated into existing risk management frameworks.
- What evidence would resolve it: Case studies or guidelines demonstrating the practical application of the taxonomy in risk management and impact assessment.

## Limitations

- Limited empirical validation with target users (citizens, policymakers, product teams) to confirm usability and effectiveness
- Potential bias in incident selection from AIAAIC repository, which may not represent global AI harms comprehensively
- High inter-annotator agreement (Krippendorff's alpha) does not guarantee taxonomy accuracy or completeness of harm coverage
- 69 sub-categories may create usability challenges despite being designed as a balance between comprehensiveness and practicality

## Confidence

- **High confidence**: The taxonomy's structure (9 top-level categories, 69 sub-categories) is internally consistent and follows established taxonomy development practices. The methodology of using documented incidents and measuring annotator agreement is sound.
- **Medium confidence**: The claim that this taxonomy is "clearer and more understandable to a broad set of audiences" than existing alternatives. While the plain language approach is promising, no comparative usability studies are presented.
- **Low confidence**: The assertion that the taxonomy will "empower NGOs and individuals to identify and report violations" and "inform policy discussions." These claims are aspirational but lack empirical evidence of actual impact or adoption.

## Next Checks

1. **User testing with target audiences**: Conduct structured usability tests with citizens, policymakers, and product teams to measure how effectively they can identify and classify AI-related harms using the taxonomy compared to existing alternatives.

2. **Real-world adoption pilot**: Partner with NGOs or regulatory bodies to pilot the taxonomy in actual harm reporting or risk assessment workflows, measuring completion rates, accuracy, and user satisfaction.

3. **Coverage gap analysis**: Systematically compare the taxonomy against a diverse sample of AI incidents (including those outside the AIAAIC repository) to identify potential gaps or misclassification patterns.