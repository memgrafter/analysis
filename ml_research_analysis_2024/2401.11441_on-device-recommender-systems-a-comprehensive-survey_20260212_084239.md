---
ver: rpa2
title: 'On-Device Recommender Systems: A Comprehensive Survey'
arxiv_id: '2401.11441'
source_url: https://arxiv.org/abs/2401.11441
tags:
- recommendation
- user
- data
- systems
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides the first comprehensive overview of on-device
  recommender systems (DeviceRSs), addressing three critical aspects: deployment/inference,
  training/updating, and security/privacy. The paper systematically categorizes existing
  methods, including binary code-based compression, embedding sparsification, variable-size
  embeddings, compositional embeddings, federated learning approaches, decentralized
  collaborative learning, and privacy-preserving techniques.'
---

# On-Device Recommender Systems: A Comprehensive Survey

## Quick Facts
- arXiv ID: 2401.11441
- Source URL: https://arxiv.org/abs/2401.11441
- Reference count: 40
- Key outcome: First comprehensive survey covering DeviceRSs across deployment, training, and security aspects

## Executive Summary
This survey provides the first comprehensive overview of on-device recommender systems (DeviceRSs), addressing three critical aspects: deployment/inference, training/updating, and security/privacy. The paper systematically categorizes existing methods, including binary code-based compression, embedding sparsification, variable-size embeddings, compositional embeddings, federated learning approaches, decentralized collaborative learning, and privacy-preserving techniques. It also highlights challenges like device heterogeneity, fairness, evolving user dynamics, and model copyright protection. The survey serves as a foundational reference for researchers and practitioners, offering insights into current methodologies, evaluation metrics, and future research directions in the rapidly evolving field of DeviceRSs.

## Method Summary
The survey systematically reviews existing DeviceRS approaches by categorizing them into three main aspects: deployment/inference (model compression techniques), training/updating (federated and decentralized learning), and security/privacy (privacy-preserving mechanisms and attack defenses). The evaluation framework considers recommendation accuracy metrics (HR@K, Recall@K, NDCG@K), on-device efficiency (model size, inference time), training efficiency (communication cost, convergence time), and security/privacy robustness. The minimum viable reproduction plan involves setting up evaluation with standard datasets, implementing methods from each category, and evaluating using specified metrics while focusing on trade-offs between accuracy, efficiency, and privacy.

## Key Results
- DeviceRSs shift computational responsibilities from cloud to edge devices, addressing high resource consumption, latency, and privacy risks
- Embedding compression techniques enable large recommender models to fit within edge device memory constraints
- Federated and decentralized training frameworks enable good performance despite limited local data while preserving privacy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DeviceRSs shift computational and storage responsibilities from centralized cloud to edge devices, directly addressing the three key deficiencies of CloudRSs: high resource consumption, response latency, and privacy/security risks.
- Mechanism: By deploying model inference and/or training on local devices, DeviceRSs eliminate the need for continuous cloud-server communication, reduce centralized data storage, and localize data processing to enhance privacy.
- Core assumption: Edge devices have sufficient computational and storage capabilities to run lightweight or compressed recommendation models effectively.
- Evidence anchors:
  - [abstract] "leverage the capabilities of edge devices to minimize centralized data storage requirements, reduce the response latency caused by communication overheads, and enhance user privacy and security by localizing data processing and model training."
  - [section 2] "a brand new recommendation paradigm, namely on-device recommender systems (DeviceRSs), are proposed to transit all or a bulk part of the computation and storage responsibilities from the cloud server to users’ end-devices"
- Break condition: If edge devices lack the required computational power or storage capacity to handle even compressed models, or if network conditions prevent efficient model updates.

### Mechanism 2
- Claim: Embedding compression techniques (binary code-based, sparsification, variable size, compositional) enable large recommender models to fit within the memory constraints of edge devices while retaining performance.
- Mechanism: These techniques reduce the number of parameters or bit precision of embedding tables, which typically constitute the majority of model size in recommender systems, allowing deployment on resource-constrained devices.
- Core assumption: Most parameters in recommender systems are concentrated in embedding tables, and compressing these embeddings preserves model accuracy sufficiently.
- Evidence anchors:
  - [section 4] "deployment and inference methods for DeviceRSs primarily focus on embedding table compression"
  - [section 4.1] "Binarization compresses an embedding weight from full-precision as binary code of just one bit"
  - [section 4.4] "compositional techniques share embedding weights among embedding tables, effectively reducing the overall parameter count"
- Break condition: If compression leads to unacceptable accuracy degradation or if the specific compression technique is incompatible with the model architecture.

### Mechanism 3
- Claim: Federated and decentralized training frameworks enable DeviceRSs to achieve good performance despite limited local data by coordinating collaborative learning across devices while preserving privacy.
- Mechanism: Federated learning allows multiple devices to train local models on their data and aggregate updates centrally without sharing raw data. Decentralized learning enables peer-to-peer knowledge exchange. Both approaches mitigate data sparsity and enhance privacy.
- Core assumption: The aggregation of updates from multiple devices can compensate for the limited data on each individual device to achieve good model performance.
- Evidence anchors:
  - [section 5.1] "each user u only maintain their own user embedding pu and item embedding table Qu locally" and "goal of FedRSs is to learn the optimal global parameters"
  - [section 5.2] "optimize on-device models through a combination of local training and inter-device communication within specific user groups"
- Break condition: If the non-IID data distribution across devices is too severe for effective aggregation, or if communication costs become prohibitive.

## Foundational Learning

- Concept: Recommender Systems (RSs) fundamentals - collaborative filtering, matrix factorization, deep learning-based methods, and their evaluation metrics (HR@K, Recall@K, NDCG@K, MSE, AUC).
  - Why needed here: DeviceRSs are built upon traditional RS techniques but adapted for edge deployment. Understanding these fundamentals is crucial for grasping the challenges and solutions in DeviceRSs.
  - Quick check question: What are the two main categories of data used in traditional recommender systems, and how do they differ?

- Concept: Federated Learning basics - client selection, local training, model upload, global aggregation, and privacy mechanisms (DP, LDP, HE, MPC).
  - Why needed here: Federated learning is a core component of many DeviceRS training approaches. Understanding its pipeline and privacy mechanisms is essential for implementing and evaluating these systems.
  - Quick check question: In federated learning, what is the purpose of the "client selection" step in each training round?

- Concept: Edge Computing constraints - limited storage, computation, and energy resources compared to cloud servers.
  - Why needed here: DeviceRSs operate under strict resource constraints. Understanding these limitations is key to appreciating the need for model compression and efficient training strategies.
  - Quick check question: Why is model size a critical consideration when deploying recommender systems on edge devices?

## Architecture Onboarding

- Component map: User interaction -> Local data processing -> Model inference/update -> Secure communication (if federated) -> Model aggregation/collaboration -> Updated model on device

- Critical path: User interaction → Local data processing → Model inference/update → Secure communication (if federated) → Model aggregation/collaboration → Updated model on device

- Design tradeoffs:
  - Model accuracy vs. compression level (smaller models may be less accurate)
  - Privacy protection vs. model performance (stronger privacy often reduces accuracy)
  - Communication cost vs. convergence speed (more frequent updates can speed up training but increase costs)
  - Device heterogeneity (varying capabilities) vs. unified model design

- Failure signatures:
  - Poor recommendation accuracy despite compression (compression too aggressive)
  - High latency in recommendations (model too large or inefficient for device)
  - Privacy breaches (inadequate protection mechanisms)
  - Slow convergence or poor performance in federated settings (non-IID data, insufficient aggregation)

- First 3 experiments:
  1. Baseline: Train a standard recommender model (e.g., matrix factorization) on a public dataset (e.g., MovieLens) and evaluate accuracy metrics (HR@K, NDCG@K).
  2. Compression: Apply a simple compression technique (e.g., quantization to 8-bit) to the embedding tables and measure the impact on model size and accuracy.
  3. Federated Learning: Implement a basic federated learning setup with multiple clients, each with non-IID data, and evaluate convergence and final accuracy compared to centralized training.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal trade-off between model accuracy and privacy protection in federated recommender systems, and how does it vary across different user populations and data distributions?
- Basis in paper: [explicit] The paper discusses various privacy protection techniques (differential privacy, homomorphic encryption, etc.) and their impact on model performance, highlighting the need to balance utility and privacy.
- Why unresolved: Different privacy mechanisms have varying levels of effectiveness and computational overhead, and their impact on model accuracy can depend on factors like data sparsity, user heterogeneity, and the specific recommendation task.
- What evidence would resolve it: Comprehensive empirical studies comparing the performance and privacy guarantees of different techniques across diverse datasets and user populations, along with theoretical analysis of the privacy-accuracy trade-off.

### Open Question 2
- Question: How can we effectively handle the cold-start problem in on-device recommender systems, particularly for new users and devices with limited interaction data?
- Basis in paper: [explicit] The paper mentions the cold-start problem as a challenge in DeviceRSs, noting that it is more complex than in traditional CloudRSs due to the dual challenge of providing recommendations for cold-start users and deploying models to new devices.
- Why unresolved: Existing cold-start solutions in CloudRSs may not be directly applicable to DeviceRSs due to the constraints on data sharing and model deployment. Novel approaches are needed to leverage limited local data and incorporate external knowledge sources.
- What evidence would resolve it: Development and evaluation of effective cold-start algorithms specifically designed for DeviceRSs, demonstrating their ability to provide accurate recommendations for new users and devices with minimal data.

### Open Question 3
- Question: What are the most effective defense mechanisms against model poisoning attacks in federated recommender systems, and how can they be deployed without significantly impacting model performance or communication efficiency?
- Basis in paper: [explicit] The paper discusses various model poisoning attacks and their countermeasures, highlighting the vulnerability of DeviceRSs to such attacks due to the exposure of the training process.
- Why unresolved: Existing defense mechanisms, such as Byzantine-robust aggregation, may not be fully effective in the context of non-IID data and can introduce significant computational overhead or communication costs.
- What evidence would resolve it: Rigorous evaluation of defense mechanisms against realistic model poisoning attacks, demonstrating their ability to maintain model robustness while minimizing performance degradation and communication overhead.

## Limitations
- The rapid evolution of this field means some recent advances may not be fully captured
- The survey primarily focuses on technical aspects, with less emphasis on user experience and real-world deployment challenges
- While privacy mechanisms are discussed, the trade-offs between privacy protection and recommendation quality require further empirical validation

## Confidence
- High Confidence: The classification of existing methods into deployment/inference, training/updating, and security/privacy categories is well-founded based on the systematic review of current literature.
- Medium Confidence: The identified challenges and future directions are reasonable extrapolations from current limitations, but their prioritization may vary based on specific application contexts.
- Medium Confidence: The proposed mechanisms for achieving on-device recommendation (compression, federated learning, etc.) are theoretically sound, but their practical effectiveness depends heavily on specific device constraints and data characteristics.

## Next Checks
1. **Empirical Validation**: Implement and benchmark at least three representative DeviceRS approaches (one from each category) on real edge devices with diverse hardware specifications to measure actual performance gains versus theoretical predictions.
2. **Privacy-Performance Trade-off Analysis**: Conduct controlled experiments varying privacy protection mechanisms (DP noise levels, encryption strength) to quantify the exact impact on recommendation accuracy and user privacy across different threat models.
3. **Device Heterogeneity Stress Test**: Design experiments with heterogeneous device populations (varying computational power, memory, network conditions) to identify failure points and develop adaptive strategies for model deployment and federated learning protocols.