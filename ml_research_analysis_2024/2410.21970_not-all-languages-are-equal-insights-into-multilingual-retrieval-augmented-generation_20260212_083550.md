---
ver: rpa2
title: 'Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented
  Generation'
arxiv_id: '2410.21970'
source_url: https://arxiv.org/abs/2410.21970
tags:
- ralms
- languages
- knowledge
- documents
- multilingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of multilingual retrieval-augmented
  generation (RAG), which is critical for leveraging global knowledge across diverse
  languages. The authors propose Futurepedia, a new benchmark designed to evaluate
  multilingual RAG models across three tasks: monolingual knowledge extraction, cross-lingual
  knowledge transfer, and multilingual knowledge selection.'
---

# Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented Generation

## Quick Facts
- **arXiv ID**: 2410.21970
- **Source URL**: https://arxiv.org/abs/2410.21970
- **Reference count**: 40
- **Primary result**: High-resource languages outperform low-resource ones in multilingual RAG; English selection bias dominates multilingual contexts

## Executive Summary
This paper investigates linguistic inequalities in multilingual retrieval-augmented generation (RAG) systems through a new benchmark called Futurepedia. The authors evaluate six multilingual RALMs across eight languages on three tasks: monolingual knowledge extraction, cross-lingual knowledge transfer, and multilingual knowledge selection. They identify three key linguistic inequalities: high-resource languages outperform low-resource ones due to translation errors, Indo-European languages enable better cross-lingual transfer, and English dominates due to selection bias. The study proposes practical strategies to mitigate these inequalities.

## Method Summary
The authors introduce Futurepedia, a benchmark with 197 parallel documents and QA pairs across eight languages (English, French, Spanish, Portuguese, Chinese, Japanese, Korean, and Arabic). They evaluate six multilingual RALMs (Aya-23, Qwen2, GPT-3.5, GPT-4o) on three tasks using gold document retrieval. The evaluation employs Character 3-gram Recall for semantic similarity and Selection Entropy to measure language preference. Experiments compare performance across language families, document positions, and query-response language configurations.

## Key Results
- High-resource languages (English, French, Spanish, Portuguese) consistently outperform low-resource languages (Chinese, Japanese, Korean, Arabic) in monolingual knowledge extraction
- Indo-European languages enable better cross-lingual transfer by allowing direct document-based answers rather than translation-dependent responses
- English exhibits strong selection bias in multilingual knowledge selection, dominating answer generation even when other language documents contain valid information

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Translation errors from low-resource to high-resource languages cascade and degrade RALM performance in monolingual knowledge extraction
- **Mechanism**: When translating low-resource language documents into high-resource languages, subtle misinterpretations of entities or context lead to inaccuracies that propagate through retrieval and generation
- **Core assumption**: Translation quality is inversely correlated with the resource level of the source language
- **Evidence anchors**: [section] "misinterpretations of key entities during translation may lead to cascading errors"; [section] "careful attention must be paid to cascading errors during the translation"
- **Break condition**: If translation quality improves to near-perfect accuracy, cascading errors would diminish

### Mechanism 2
- **Claim**: Indo-European language documents reduce cross-lingual transfer difficulty by enabling RALMs to answer directly from source documents
- **Mechanism**: RALMs can more easily generate accurate answers when the source document is in an Indo-European language compared to non-Indo-European languages due to better internal representation alignment
- **Core assumption**: RALMs have better internal alignment between Indo-European languages due to training data distribution
- **Evidence anchors**: [section] "Indo-European languages lead RALMs to provide answers directly from documents in different languages"; [section] Character 3-gram Recall scores show 58.75 for Indo-European vs 31.94 for other languages when using Arabic queries
- **Break condition**: If RALMs are trained with balanced multilingual data across language families, this advantage may disappear

### Mechanism 3
- **Claim**: RALMs exhibit selection bias toward English documents in multilingual knowledge selection tasks
- **Mechanism**: The model's learned preference for English text causes it to disproportionately select English documents when multiple language options are available
- **Core assumption**: Training data and fine-tuning corpora are heavily English-dominant, creating inherent bias
- **Evidence anchors**: [section] "English benefits from RALMs' selection bias and speaks louder in multilingual contexts"; [section] "RALMs favor query languages" with diagonal dominance in selection matrix
- **Break condition**: If non-English documents are overrepresented in the context or if document position is manipulated, selection bias can be mitigated

## Foundational Learning

- **Concept**: Character 3-gram Recall
  - **Why needed here**: This metric captures semantic similarity in multilingual contexts where exact string matching fails due to translation variations
  - **Quick check question**: If the ground truth answer is "United States" and the model outputs "USA", would Character 3-gram Recall give a higher score than exact match accuracy?

- **Concept**: Cross-lingual transfer
  - **Why needed here**: Understanding how knowledge flows between languages is central to evaluating RALMs' multilingual capabilities
  - **Quick check question**: In a cross-lingual task, if the document is in French and the query is in English, what are the two main failure modes for RALMs?

- **Concept**: Chain-of-thought prompting
  - **Why needed here**: Used to improve cross-lingual performance by splitting the task into document comprehension and language translation steps
  - **Quick check question**: How does chain-of-thought prompting help RALMs avoid the difficulty of expressing answers across languages?

## Architecture Onboarding

- **Component map**: Retriever -> mcontriever-msmarco -> RALMs (Aya-23, Qwen2, GPT-3.5, GPT-4o) -> Context construction (8,192 tokens) -> Generation -> Evaluation
- **Critical path**: Document retrieval → Context construction → RALM generation → Evaluation
- **Design tradeoffs**: Fixed chunk size (200 tokens) vs. variable context length; Gold document retrieval vs. learned retrieval; LLM-based evaluation vs. automated metrics
- **Failure signatures**: Low recall across all languages → Retriever or RALM comprehension issue; High variance across languages → Language-specific bias or capability gap; Diagonal dominance in selection matrix → Query language bias
- **First 3 experiments**: 1) Test translation cascade by translating low-resource docs to high-resource and evaluating performance drop; 2) Compare strict vs flexible language settings in cross-lingual tasks to measure language transformation difficulty; 3) Vary document position of English vs non-English docs to measure selection bias magnitude

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the observed linguistic inequalities in multilingual RAG be mitigated through model architecture changes rather than data-based strategies?
- **Basis in paper**: Inferred from the observation that high-resource languages outperform low-resource ones and that model size can narrow performance gaps
- **Why unresolved**: The paper primarily explores data-based strategies like translation and document positioning, but does not investigate architectural modifications such as language-specific adapters or token embedding adjustments
- **What evidence would resolve it**: Comparative experiments evaluating multilingual RAG performance with and without architectural adaptations like language-specific fine-tuning layers or multilingual token embeddings

### Open Question 2
- **Question**: How do cascading errors from translating low-resource languages into high-resource ones specifically impact the semantic meaning and factual accuracy of retrieved documents?
- **Basis in paper**: Explicit mention of cascading errors during translation and their potential impact on RALMs' performance
- **Why unresolved**: While the paper acknowledges the issue, it does not provide a detailed analysis of the types of errors introduced or their downstream effects on knowledge extraction accuracy
- **What evidence would resolve it**: A systematic error analysis comparing original low-resource documents, their translations, and the final RALMs' outputs to quantify semantic drift and factual inaccuracies

### Open Question 3
- **Question**: To what extent does the chain-of-thought approach in cross-lingual knowledge transfer generalize across different language pairs and model sizes?
- **Basis in paper**: Inferred from the success of refined prompts in encouraging RALMs to provide answers from documents in different languages
- **Why unresolved**: The paper tests this approach on a limited set of languages and models, without exploring its effectiveness across diverse language families or varying model capacities
- **What evidence would resolve it**: Extensive experiments across multiple language pairs (including non-Indo-European languages) and model sizes to assess the robustness and generalizability of the chain-of-thought method

## Limitations
- Translation quality assessment remains qualitative rather than quantitative, making it difficult to precisely measure translation error impact
- The study assumes performance gaps stem primarily from linguistic factors without fully isolating confounding variables like training data distribution
- Cross-lingual transfer mechanisms are inferred from performance patterns rather than through detailed error analysis or ablation studies

## Confidence
- **Medium**: Claims about cascading translation errors affecting monolingual performance (supported by performance gaps but lacking direct error analysis)
- **Medium**: Observations about Indo-European language advantages in cross-lingual transfer (based on performance metrics but without linguistic feature analysis)
- **Medium**: Evidence of English selection bias in multilingual contexts (observed through diagonal dominance but not through controlled experiments)

## Next Checks
1. Conduct controlled experiments comparing RALM performance on original vs professionally translated low-resource language documents to quantify translation error impact
2. Perform detailed linguistic feature analysis (e.g., syntactic complexity, morphological richness) to determine if observed performance gaps correlate with specific language family characteristics
3. Implement controlled document positioning experiments with balanced language representation to measure the magnitude and reversibility of English selection bias