---
ver: rpa2
title: Explainable Multi-Label Classification of MBTI Types
arxiv_id: '2405.02349'
source_url: https://arxiv.org/abs/2405.02349
tags:
- data
- mbti
- label
- best
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study aims to identify the most effective machine learning\
  \ model for classifying Myers-Briggs Type Indicator (MBTI) personality types from\
  \ Reddit posts using explainable multi-label classification. The authors apply the\
  \ Binary Relevance method with glass-box models\u2014k-Nearest Neighbour, Multinomial\
  \ Naive Bayes, and Logistic Regression\u2014and use Explainable AI techniques for\
  \ transparency."
---

# Explainable Multi-Label Classification of MBTI Types

## Quick Facts
- arXiv ID: 2405.02349
- Source URL: https://arxiv.org/abs/2405.02349
- Reference count: 2
- One-line primary result: Logistic Regression with solver=liblinear and penalty=L1 achieves exact match ratio of 0.586 and Hamming loss of 0.178 for MBTI classification from Reddit posts.

## Executive Summary
This study evaluates glass-box machine learning models for multi-label classification of Myers-Briggs Type Indicator (MBTI) personality types from Reddit posts. Using the Binary Relevance method, the authors compare k-Nearest Neighbour, Multinomial Naive Bayes, and Logistic Regression models with Explainable AI techniques for transparency. After preprocessing and feature selection, they find that model performance varies significantly based on class composition, with Logistic Regression achieving the best overall results when all classes have sufficient data entries.

## Method Summary
The authors collect Reddit posts from MBTI-related subreddits and preprocess them through tokenization, stop-word removal, lemmatization, and TF-IDF vectorization. They apply the Binary Relevance method to decompose the 16 MBTI types into four binary classification tasks (one per trait). Three glass-box classifiers are evaluated: k-Nearest Neighbour (k=89), Multinomial Naive Bayes, and Logistic Regression (solver=liblinear, penalty=L1). The models are tested using 5-fold cross-validation with feature selection via SelectKBest and Chi2, and evaluated using Exact Match Ratio, Hamming Loss, and per-label precision/recall/F1 metrics.

## Key Results
- Logistic Regression with solver=liblinear and penalty=L1 achieves the best overall performance (exact match ratio 0.586, Hamming loss 0.178) when all classes have >550 entries.
- Multinomial Naive Bayes and kNN perform better when classes with Observer (S) traits are excluded, with exact match ratio nearly doubling.
- Feature selection (SelectKBest + Chi2) improves performance for some models while degrading others, indicating model-specific feature importance.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multinomial Naive Bayes improves when classes with S traits are excluded because the remaining N-only classes allow the model to perfectly predict the N/S label.
- Mechanism: Binary Relevance treats each MBTI trait as a separate binary label. When only N classes remain, the N/S label becomes trivially predictable with 100% precision/recall, reducing overall Hamming loss and boosting exact match ratio.
- Core assumption: The model assumes feature independence (Naive Bayes assumption), so removing S classes does not distort predictions for other labels.
- Evidence anchors:
  - [abstract] "Multinomial Naive Bayes and k-Nearest Neighbour perform better if classes with Observer (S) traits are excluded"
  - [section 6.1] "When we conducted the experiment with all the classes with the S trait excluded, the exact match ratio almost doubled and the hamming loss went down by 0.07. However, the per-label scores did not improve for the remaining labels"
- Break condition: If real data contains mixed N/S posts, excluding S classes removes useful variability and harms generalization.

### Mechanism 2
- Claim: Logistic Regression performs best when excluding classes with fewer than 550 examples because class imbalance skews decision boundaries toward majority classes.
- Mechanism: Logistic Regression finds linear decision boundaries; with very small classes, the boundary cannot capture the true separation, leading to higher misclassification rates and lower exact match.
- Core assumption: Sufficient sample size per class is needed for the model to learn meaningful patterns; otherwise, the learned weights are unreliable.
- Evidence anchors:
  - [abstract] "Logistic Regression obtains its best results when all classes have > 550 entries"
  - [section 6.3] "For the dataset excluding all MBTI types with less than 550 data... it gave the best overall result so far, with an exact match ratio of 0.586"
- Break condition: If new data has different class size distributions, the threshold of 550 may no longer be optimal.

### Mechanism 3
- Claim: Using TF-IDF vectorization before applying binary relevance improves feature discriminability for MBTI prediction.
- Mechanism: TF-IDF downweights common words and upweights rare but informative terms, giving the classifier sharper signals for personality-related vocabulary.
- Core assumption: MBTI-indicative language tends to be distinctive; common stopwords do not help differentiate types.
- Evidence anchors:
  - [section 5] "We used the result of Step 2 as the baseline result for each classifier experiment, which uses all the data in the dataset" (baseline uses TF-IDF)
  - [section 6.4] Comparison of baseline vs tuned models implicitly relies on TF-IDF as the starting point.
- Break condition: If personality signals are distributed across non-text features (e.g., post timing), TF-IDF alone may miss them.

## Foundational Learning

- Concept: Multi-label classification vs multi-class classification
  - Why needed here: MBTI types are combinations of four binary traits; each trait is a separate label rather than a single class.
  - Quick check question: If we encoded all 16 MBTI types as one class, would we still be able to measure trait-level performance?

- Concept: Binary Relevance method
  - Why needed here: It decomposes the multi-label problem into four independent binary classifiers, one per MBTI trait.
  - Quick check question: What happens to the N/S label precision when only N classes are present?

- Concept: Glass-box models
  - Why needed here: Transparency is required to interpret why certain personality traits are predicted, aligning with XAI goals.
  - Quick check question: How does the interpretability of Logistic Regression differ from that of a black-box ensemble model?

## Architecture Onboarding

- Component map: Data preprocessing -> TF-IDF vectorization -> Binary Relevance wrapper -> Individual classifier (kNN/MultinomialNB/LogisticRegression) -> Evaluation (Exact Match, Hamming Loss, Precision/Recall/F1)
- Critical path: TF-IDF -> Binary Relevance -> Classifier training -> Cross-validation evaluation
- Design tradeoffs: Simpler glass-box models trade some accuracy for interpretability; feature selection (SelectKBest+Chi2) can improve speed but risks discarding useful signals.
- Failure signatures: High Hamming loss with low exact match suggests label imbalance; consistently low N/S precision when S classes present indicates insufficient S data.
- First 3 experiments:
  1. Run all three classifiers with full dataset using default hyperparameters; record baseline metrics.
  2. Repeat with TF-IDF vectorization and 5-fold cross-validation; compare improvements.
  3. Apply feature selection (k_best=50) to the best-performing classifier; observe changes in exact match ratio.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the Reddit dataset contain significantly more data for Intuitive (N) types compared to Observant (S) types?
- Basis in paper: [explicit] The authors note that "most types with Intuitive trait (N) have more than 700+ data and the types with Observant trait (S) have less than 600 data" and speculate this may be due to N types being described as "imaginative, open-minded, and curious" who "make more posts online."
- Why unresolved: This is presented as speculation without empirical evidence. The authors do not test this hypothesis or explore alternative explanations.
- What evidence would resolve it: Analysis of posting frequency patterns across different MBTI subreddits, user surveys about posting behavior, or comparison with other personality-related posting datasets.

### Open Question 2
- Question: Does the superior performance of Logistic Regression over other models persist when using more complex, non-glass-box models?
- Basis in paper: [explicit] The authors conclude that "Logistic Regression with solver = liblinear and penalty = L1" achieved the best results, but they only tested glass-box models for interpretability.
- Why unresolved: The study's XAI focus limited it to glass-box models. No comparison was made with potentially more powerful black-box models.
- What evidence would resolve it: Experiments with complex models (e.g., neural networks, ensemble methods) using the same datasets and evaluation metrics.

### Open Question 3
- Question: How do the results change when using more balanced datasets, either through data augmentation or by excluding imbalanced classes?
- Basis in paper: [explicit] The authors note significant class imbalance in both Reddit and Kaggle datasets and observe that different experimental conditions (excluding S types, excluding small classes) yield different results.
- Why unresolved: The authors acknowledge the imbalance but only partially address it through exclusion criteria rather than balancing techniques.
- What evidence would resolve it: Experiments using balanced datasets created through techniques like SMOTE, undersampling, or stratified sampling, with comparison to the current results.

## Limitations

- The study's conclusions are based on specific dataset sizes and class distributions that may not generalize to new data.
- The binary relevance approach treats MBTI traits as independent, but in reality, traits may have dependencies that the model cannot capture.
- The analysis does not account for potential temporal changes in Reddit language or demographic shifts in MBTI discussions that could affect model performance.

## Confidence

- **High Confidence**: The observation that Logistic Regression performs best with classes having >550 entries, supported by direct experimental results and logical reasoning about class imbalance effects on decision boundaries.
- **Medium Confidence**: The improvement from excluding S trait classes in Multinomial Naive Bayes and kNN, as this relies on the assumption that N/S labels become trivially predictable when only N classes remain.
- **Low Confidence**: The generalizability of the optimal hyperparameters (k=89, solver=liblinear, penalty=L1) across different datasets or personality classification tasks, as these appear to be dataset-specific optimizations.

## Next Checks

1. Test model performance on a temporally separated dataset (e.g., Reddit posts from a different year) to assess temporal generalization and detect potential concept drift in MBTI-related language patterns.

2. Conduct ablation studies on the feature selection step by systematically varying the number of selected features (k_best parameter) and measuring impact on exact match ratio to determine optimal feature count.

3. Evaluate model performance when using multi-class classification (16 MBTI types as single classes) versus the current multi-label approach to quantify the benefits of trait-level decomposition for interpretability and performance.