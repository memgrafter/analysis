---
ver: rpa2
title: Large Language Model Distilling Medication Recommendation Model
arxiv_id: '2402.02803'
source_url: https://arxiv.org/abs/2402.02803
tags:
- medication
- recommendation
- leader
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LEADER, a large language model-based approach
  for medication recommendation in healthcare systems. The method addresses challenges
  of semantic understanding and handling first-time patients by leveraging the semantic
  comprehension and input-agnostic properties of LLMs.
---

# Large Language Model Distilling Medication Recommendation Model

## Quick Facts
- arXiv ID: 2402.02803
- Source URL: https://arxiv.org/abs/2402.02803
- Reference count: 40
- Primary result: LEADER outperforms state-of-the-art baselines in medication recommendation tasks with higher PRAUC, Jaccard, and F1 scores

## Executive Summary
This paper introduces LEADER, a large language model-based approach for medication recommendation in healthcare systems. The method addresses challenges of semantic understanding and handling first-time patients by leveraging the semantic comprehension and input-agnostic properties of LLMs. The authors propose a novel output layer and refined tuning loss function to overcome out-of-corpus issues with drugs, and use feature-level knowledge distillation to transfer LLM capabilities to a more efficient model. Experimental results on MIMIC-III and MIMIC-IV datasets demonstrate that LEADER outperforms state-of-the-art baselines in medication recommendation tasks, achieving higher PRAUC, Jaccard, and F1 scores.

## Method Summary
LEADER employs a two-stage process: first, fine-tuning an LLM (LlaMA-7B) with modified output layer and loss function using prompt templates for EHR data; second, distilling knowledge to a smaller student model using feature-level knowledge distillation. The student model incorporates three encoders (diagnosis, procedure, medication), a visit encoder, and a profile encoder. The approach also includes profile alignment through contrastive learning to improve single-visit patient recommendations. The method is evaluated on MIMIC-III and MIMIC-IV datasets, measuring performance using PRAUC, Jaccard, and F1 scores.

## Key Results
- LEADER achieves higher PRAUC, Jaccard, and F1 scores compared to state-of-the-art baselines on MIMIC-III and MIMIC-IV datasets
- The approach demonstrates significant improvements in handling single-visit patients compared to existing methods
- Feature-level knowledge distillation successfully transfers LLM capabilities to a more efficient model while maintaining performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic understanding from LLMs improves medication recommendation accuracy
- Mechanism: LLMs are trained on vast natural language corpora and can interpret medical terminology and context, enabling richer representations of diagnoses and procedures than identity-based embeddings
- Core assumption: Medical terms carry meaningful semantic relationships that can be captured by LLMs
- Evidence anchors:
  - [abstract] "We harness the powerful semantic comprehension and input-agnostic characteristics of Large Language Models (LLMs)"
  - [section III-B] "We design the proper prompt templates to format the electronic health records into natural language"
  - [corpus] Weak - no direct comparison with identity-based baselines in corpus
- Break condition: If medical terminology lacks consistent semantic patterns or if prompts fail to elicit meaningful medical reasoning

### Mechanism 2
- Claim: Feature-level knowledge distillation transfers LLM capabilities to a compact model
- Mechanism: The hidden states from the LLM contain semantic information that can be projected into the student model's representation space through a learnable projection layer
- Core assumption: Hidden states from LLM contain transferable semantic information relevant to medication recommendation
- Evidence anchors:
  - [section III-C2] "We propose a feature-level knowledge distillation method"
  - [section III-C2] "we design a trainable projector to transform the hidden state into the representation space of LLM"
  - [corpus] Weak - only one related paper on distillation for medication recommendation
- Break condition: If hidden states contain too much task-specific or irrelevant information for the student model

### Mechanism 3
- Claim: Profile alignment enables effective single-visit patient recommendations
- Mechanism: Contrastive learning aligns profile feature representations with medication representations in the same embedding space
- Core assumption: Patient profile features contain predictive information about medication needs
- Evidence anchors:
  - [section III-C3] "we design a profile alignment method"
  - [section III-C3] "we propose a contrastive loss to align profile and medication sets"
  - [corpus] Weak - no direct evidence of profile alignment effectiveness in corpus
- Break condition: If profile features lack predictive power for medication recommendations

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Both LLM teacher and student models use transformer layers for encoding medical information
  - Quick check question: How does multi-head attention enable the model to capture different types of relationships between medical codes?

- Concept: Knowledge distillation techniques
  - Why needed here: The method transfers knowledge from the large LLM to a smaller student model
  - Quick check question: What's the difference between feature-level and output-level knowledge distillation?

- Concept: Contrastive learning
  - Why needed here: Used to align profile feature representations with medication representations
  - Quick check question: How does the contrastive loss encourage the model to learn meaningful similarities between profiles and medications?

## Architecture Onboarding

- Component map:
  Prompt template generator → LLM with modified output layer → Feature projector → Student model (diagnosis encoder, procedure encoder, medication encoder, visit encoder, profile encoder) → Medication recommendations

- Critical path: EHR data → prompt templates → LLM → feature projector → student model → medication recommendations

- Design tradeoffs:
  - LLM size vs. inference efficiency
  - Number of transformer layers in student model vs. model capacity
  - Knowledge distillation weight vs. ground truth loss weight
  - Profile alignment strength vs. model convergence

- Failure signatures:
  - High perplexity in LLM outputs → check prompt templates
  - Student model underperforms on single-visit patients → check profile alignment
  - Distillation fails → check feature projector dimensionality and alignment
  - Poor generalization → check LoRA configuration and fine-tuning

- First 3 experiments:
  1. Validate prompt templates by testing LLM outputs on small EHR samples
  2. Test feature projector by comparing projected states with student model inputs
  3. Validate profile alignment by checking profile-medication similarity scores

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the authors note their work is "the first to explore the integration of medication recommendation and large language models" and call for future work on drug-drug interaction safety.

## Limitations
- Limited evidence of how much semantic information actually transfers from the large LLM to the smaller student model through knowledge distillation
- No systematic evaluation of prompt template quality and its impact on downstream performance
- Claims about handling first-time patients are supported by metrics but lack ablation studies showing exactly how profile alignment contributes

## Confidence
- High confidence: The technical approach of using LLM semantic understanding for medication recommendation is well-grounded
- Medium confidence: The experimental results showing LEADER outperforming baselines on MIMIC datasets are convincing, but the specific contribution of each component to overall performance is difficult to disentangle
- Low confidence: Claims about handling first-time patients are supported by metrics but lack ablation studies showing exactly how profile alignment contributes compared to simply using diagnoses and procedures alone

## Next Checks
1. Ablation study on knowledge distillation: Compare LEADER's performance with and without feature-level knowledge distillation to quantify how much performance gain comes specifically from transferring semantic information from the LLM
2. Prompt template robustness testing: Systematically vary prompt templates and measure their impact on LLM output quality and downstream medication recommendation performance to validate the importance of prompt engineering
3. Single-modality evaluation: Train models using only profile features, only diagnoses, and only procedures to verify the assumption that profile features contain meaningful predictive information for medication recommendations