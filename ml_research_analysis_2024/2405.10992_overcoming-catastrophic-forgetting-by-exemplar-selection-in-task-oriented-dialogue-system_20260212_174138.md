---
ver: rpa2
title: Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue
  System
arxiv_id: '2405.10992'
source_url: https://arxiv.org/abs/2405.10992
tags:
- hesit
- data
- training
- learning
- tods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a continual learning method for task-oriented
  dialogue systems that addresses catastrophic forgetting. The core idea is to use
  a hyper-gradient-based exemplar selection strategy that traces the influence of
  training examples on model performance during the optimization process, avoiding
  the instability of estimating Hessian for large pre-trained models.
---

# Overcoming Catastrophic Forgetting by Exemplar Selection in Task-oriented Dialogue System

## Quick Facts
- arXiv ID: 2405.10992
- Source URL: https://arxiv.org/abs/2405.10992
- Reference count: 11
- Primary result: HESIT achieves state-of-the-art results on 37-domain ToDs benchmark, significantly outperforming other rehearsal-based methods in mitigating catastrophic forgetting

## Executive Summary
This paper introduces HESIT, a hyper-gradient-based exemplar selection strategy for continual learning in task-oriented dialogue systems. The method traces the influence of training examples on model performance during optimization, avoiding the computational instability of Hessian estimation for large pre-trained models. By selecting influential exemplars for periodic retraining, HESIT effectively mitigates catastrophic forgetting across multiple task domains. Experiments on a benchmark of 37 dialogue domains demonstrate superior performance across all metrics compared to existing rehearsal-based methods.

## Method Summary
HESIT is a continual learning method that addresses catastrophic forgetting in task-oriented dialogue systems by selecting influential exemplars for periodic retraining. The method traces hyper-gradients of training examples during the first few epochs to measure their influence on model performance, then selects the top examples based on these influence scores. These exemplars are stored in a memory buffer and used for retraining alongside new task data. The approach is compatible with large pre-trained models as it avoids Hessian estimation, making it computationally efficient while maintaining effectiveness across all dialogue system modules (INTENT, DST, NLG, E2E).

## Key Results
- HESIT achieves state-of-the-art performance across all metrics (INTENT accuracy, JGA, EER, BLEU) on the 37-domain ToDs benchmark
- Significantly outperforms other rehearsal-based methods in mitigating catastrophic forgetting
- Demonstrates effectiveness across all four modules of task-oriented dialogue systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hyper-gradient-based exemplar selection effectively mitigates catastrophic forgetting by tracing data influence during training.
- Mechanism: HESIT traces hyper-gradients of training examples throughout the optimization process, using the influence of these examples on model performance on unseen validation data to select exemplars for periodic retraining.
- Core assumption: The influence of training data on model performance can be effectively captured by hyper-gradient tracing without requiring Hessian estimation.
- Evidence anchors:
  - [abstract]: "HESIT analyzes the training data influence by tracing their hyper-gradient in the optimization process."
  - [section 3.3]: "HESIT traces and analyzes the hyper-gradient of training examples in the complicated optimization process."
  - [corpus]: Weak evidence - the corpus provides related papers but lacks specific evidence supporting this mechanism.
- Break condition: If the hyper-gradient tracing fails to capture the true influence of training data on model performance, or if Hessian estimation becomes necessary for accurate influence measurement.

### Mechanism 2
- Claim: Avoiding Hessian estimation makes HESIT compatible with large pre-trained models used in ToDs.
- Mechanism: By avoiding the need to estimate the Hessian matrix, HESIT reduces computational costs and instability associated with Hessian estimation for large pre-trained models.
- Core assumption: The influence of training data on model performance can be effectively measured without Hessian estimation.
- Evidence anchors:
  - [abstract]: "Furthermore, HESIT avoids estimating Hessian to make it compatible for ToDs with a large pre-trained model."
  - [section 3.3]: "Furthermore, HESIT avoids estimating Hessian to make it compatible for ToDs with a large pre-trained model."
  - [corpus]: Weak evidence - the corpus does not provide specific evidence supporting this mechanism.
- Break condition: If the influence of training data cannot be accurately measured without Hessian estimation, or if the computational benefits are outweighed by reduced performance.

### Mechanism 3
- Claim: Selecting exemplars based on their influence on model performance improves the effectiveness of rehearsal-based continual learning.
- Mechanism: HESIT selects exemplars that have the most positive influence on model performance on unseen data, ensuring that the most informative and representative examples are used for periodic retraining.
- Core assumption: The influence of training data on model performance is a good indicator of its informativeness and representativeness for future tasks.
- Evidence anchors:
  - [abstract]: "HESIT adopts a profound exemplar selection strategy that considers the general performance of the trained model when selecting exemplars for each task domain."
  - [section 3.3]: "HESIT roots in model performance on unseen data to measure the influence of these traced samples."
  - [corpus]: Weak evidence - the corpus does not provide specific evidence supporting this mechanism.
- Break condition: If the selected exemplars do not effectively mitigate catastrophic forgetting, or if their influence on model performance does not correlate with their usefulness for future tasks.

## Foundational Learning

- Concept: Catastrophic Forgetting
  - Why needed here: Understanding catastrophic forgetting is crucial for developing methods to mitigate it in continual learning settings.
  - Quick check question: What is catastrophic forgetting, and why is it a problem in continual learning for task-oriented dialogue systems?

- Concept: Hyper-gradient Tracing
  - Why needed here: Hyper-gradient tracing is the core technique used by HESIT to measure the influence of training data on model performance.
  - Quick check question: How does hyper-gradient tracing differ from traditional gradient descent, and why is it useful for exemplar selection in continual learning?

- Concept: Rehearsal-based Continual Learning
  - Why needed here: HESIT is a rehearsal-based continual learning method, so understanding the basics of this approach is essential for comprehending its effectiveness.
  - Quick check question: What is rehearsal-based continual learning, and how does it differ from other approaches like regularization-based or architecture-based methods?

## Architecture Onboarding

- Component map: Pre-trained GPT-2 model -> Hyper-gradient tracing mechanism -> Exemplar selection strategy -> Memory buffer -> Retraining module
- Critical path: Train on new task data -> Trace hyper-gradients of training examples -> Select top exemplars based on influence scores -> Store in memory buffer -> Retrain on exemplars + current data -> Evaluate performance
- Design tradeoffs: The main tradeoff is between the computational cost of hyper-gradient tracing and the effectiveness of the exemplar selection strategy in mitigating catastrophic forgetting.
- Failure signatures: Potential failures include ineffective exemplar selection leading to persistent catastrophic forgetting, or excessive computational costs due to hyper-gradient tracing.
- First 3 experiments:
  1. Compare the performance of HESIT with and without hyper-gradient tracing on a small-scale continual learning benchmark.
  2. Evaluate the impact of different exemplar selection strategies (e.g., random sampling, influence-based) on the effectiveness of HESIT in mitigating catastrophic forgetting.
  3. Measure the computational cost of hyper-gradient tracing for different model sizes and task complexities, and assess its scalability for large-scale applications.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HESIT vary when using cross-domain validation sets to select exemplars for each task domain?
- Basis in paper: [inferred] The paper mentions that HESIT only evaluates performance on the self-domain validation set when selecting exemplars for the current domain, but suggests that cross-domain influences should be taken into account.
- Why unresolved: The paper does not provide experimental results or analysis on using cross-domain validation sets for exemplar selection.
- What evidence would resolve it: Experiments comparing HESIT's performance when using self-domain vs. cross-domain validation sets for exemplar selection, showing the impact on overall task-oriented dialogue system performance across multiple domains.

### Open Question 2
- Question: How does the exemplar selection strategy of HESIT perform on other NLP tasks beyond task-oriented dialogue systems?
- Basis in paper: [inferred] The paper focuses on task-oriented dialogue systems and demonstrates HESIT's effectiveness in this specific domain. However, the method's potential applicability to other NLP tasks is not explored.
- Why unresolved: The paper does not provide any experiments or analysis on applying HESIT to other NLP tasks.
- What evidence would resolve it: Experiments applying HESIT to other NLP tasks such as text classification, named entity recognition, or machine translation, and comparing its performance to other continual learning methods in these domains.

### Open Question 3
- Question: How does the performance of HESIT scale with the number of task domains and the size of the curriculum?
- Basis in paper: [inferred] The paper demonstrates HESIT's effectiveness on a benchmark of 37 dialogue domains. However, the scalability of the method to larger curricula with more task domains is not explored.
- Why unresolved: The paper does not provide any experiments or analysis on scaling HESIT to larger curricula with more task domains.
- What evidence would resolve it: Experiments scaling HESIT to curricula with varying numbers of task domains (e.g., 50, 100, 200) and analyzing its performance, computational efficiency, and memory requirements as the curriculum size increases.

## Limitations

- The paper lacks sufficient detail on the exact implementation of hyper-gradient tracing, making exact replication challenging.
- The computational complexity and scalability for larger models or more domains remains unclear.
- The method's performance on non-task-oriented dialogue systems or other sequential learning tasks is not evaluated.

## Confidence

- **High Confidence**: The effectiveness of HESIT in mitigating catastrophic forgetting on the tested 37-domain benchmark, supported by comprehensive experimental results across multiple metrics.
- **Medium Confidence**: The claim that avoiding Hessian estimation makes HESIT compatible with large pre-trained models, as this is theoretically sound but not extensively validated across different model architectures.
- **Low Confidence**: The generalizability of the exemplar selection strategy to other continual learning domains beyond task-oriented dialogue systems, due to lack of cross-domain validation.

## Next Checks

1. Implement a simplified version of HESIT with a smaller model (e.g., GPT-2 small) on a reduced dataset to verify the core hyper-gradient tracing mechanism works as described.
2. Conduct ablation studies removing the hyper-gradient tracing component to quantify its specific contribution to performance improvements over baseline rehearsal methods.
3. Test HESIT's scalability by gradually increasing the number of domains and measuring both performance degradation and computational overhead to establish practical limits.