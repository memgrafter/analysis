---
ver: rpa2
title: Training Zero-Shot Generalizable End-to-End Task-Oriented Dialog System Without
  Turn-level Dialog Annotations
arxiv_id: '2407.15055'
source_url: https://arxiv.org/abs/2407.15055
tags:
- dialog
- nl-tod
- system
- chatgpt
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a zero-shot generalizable end-to-end task-oriented
  dialog system, NL-ToD, that removes the need for manual turn-level annotations by
  leveraging dialog history and domain schemas. The approach formulates TOD response
  generation as a conditional sequence generation task and incorporates query generation
  as a core task, allowing the system to autonomously manage external information
  retrieval.
---

# Training Zero-Shot Generalizable End-to-End Task-Oriented Dialog System Without Turn-level Dialog Annotations

## Quick Facts
- arXiv ID: 2407.15055
- Source URL: https://arxiv.org/abs/2407.15055
- Authors: Adib Mosharrof; A. B. Siddique
- Reference count: 27
- Key outcome: Zero-shot TOD system achieves 31.4% BLEU-4 improvement on SGD and 82.1% on KETOD without turn-level annotations

## Executive Summary
This paper introduces NL-ToD, a zero-shot generalizable end-to-end task-oriented dialog system that eliminates the need for manual turn-level annotations by leveraging dialog history and domain schemas. The approach formulates TOD response generation as a conditional sequence generation task and incorporates query generation as a core task, enabling autonomous external information retrieval. Trained using multi-task instruction fine-tuning on a simple prompt without complex templates or examples, NL-ToD demonstrates state-of-the-art performance on three diverse TOD datasets while maintaining strong zero-shot generalization to unseen domains.

## Method Summary
NL-ToD is an end-to-end task-oriented dialog system that uses multi-task instruction fine-tuning on Flan-T5-large with LORA to generate both user responses and API calls from dialog history and domain schemas. The system breaks down outputs into categories (slot filling, retrieval, query generation) and trains on a simple prompt structure without requiring turn-level annotations. The model uses AdamW optimizer (learning rate 0.01), 500 warmup steps, and greedy decoding for inference.

## Key Results
- NL-ToD outperforms state-of-the-art models trained on annotated data, achieving 31.4% BLEU-4 improvement on SGD and 82.1% on KETOD
- Strong zero-shot generalization to unseen domains while maintaining competitive performance in supervised settings
- Evaluation across three diverse TOD datasets (SGD, KETOD, BiToD) with three LLMs of varying sizes shows consistent performance gains

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Multi-task instruction fine-tuning enables zero-shot generalization by teaching the model to handle both response generation and API call generation as distinct but related tasks.
- **Mechanism**: The model learns to interpret domain schemas and dialog history to determine when to generate a user-facing response versus when to make an API call. This is achieved by structuring the output into multiple categories (slot filling, retrieval, query generation) during training.
- **Core assumption**: The model can learn the distinction between different types of system outputs through instruction-based training without requiring turn-level annotations.
- **Evidence anchors**:
  - [abstract]: "we incorporate query generation as a core task of the system, where the output of the system could be a response to the user or an API query to communicate with an external resource."
  - [section]: "The output of these systems can be broadly categorized into two types: responses to the user and API calls to external sources. This duality inherently frames the problem as a multi-task learning problem..."

### Mechanism 2
- **Claim**: Breaking down the system output into specific categories (slot filling, retrieval, general interaction) allows for more granular analysis and targeted improvements.
- **Mechanism**: By categorizing outputs, the system can focus on the most challenging aspects of TOD systems, such as slot filling, which requires extracting specific information from user input.
- **Core assumption**: Categorizing outputs will reveal which aspects of the system need improvement and guide future development efforts.
- **Evidence anchors**:
  - [section]: "Our analysis reveals that slot filling is the most challenging TOD task for all models."
  - [section]: "We also introduce specific metrics to evaluate the performance of the API call task..."

### Mechanism 3
- **Claim**: Using only dialog history and domain schemas, without turn-level annotations, reduces dependency on expensive manual labeling while maintaining performance.
- **Mechanism**: The model learns to generate appropriate responses by understanding the domain context and previous conversation turns, rather than relying on labeled dialog states and policies.
- **Core assumption**: Dialog history and domain schemas contain sufficient information for the model to generate accurate responses without explicit turn-level annotations.
- **Evidence anchors**:
  - [abstract]: "removes the dependency on manually annotated turn wise data by utilizing dialog history and domain schemas"
  - [section]: "NL-ToD requires only the domain schemas and dialog history" (in contrast to existing approaches)

## Foundational Learning

- **Concept**: Conditional sequence generation
  - **Why needed here**: TOD response generation is formulated as predicting the next system utterance given the dialog history and domain schema.
  - **Quick check question**: What are the two main inputs to the conditional generation process in NL-ToD?

- **Concept**: Multi-task learning
  - **Why needed here**: The system must handle both response generation and API call generation, which are different but related tasks.
  - **Quick check question**: How does treating response generation and API call generation as separate tasks improve the system's performance?

- **Concept**: Domain schema understanding
  - **Why needed here**: The model must interpret domain schemas to understand the available intents, slots, and their relationships for each domain.
  - **Quick check question**: What information does a domain schema typically contain in a TOD system?

## Architecture Onboarding

- **Component map**: Dialog history + Domain schema → Flan-T5-large (LORA fine-tuned) → Categorized system responses (slot filling, retrieval, query generation)

- **Critical path**: Dialog history → Domain schema understanding → Response generation/API call decision → Output generation

- **Design tradeoffs**:
  - Simplicity vs. performance: Using only dialog history and domain schemas instead of turn-level annotations reduces complexity but may limit performance in some scenarios
  - Generalization vs. specialization: The zero-shot approach allows for handling new domains but may not match supervised performance on seen domains

- **Failure signatures**:
  - Incorrect API calls: System generates API calls at inappropriate times or with wrong parameters
  - Poor slot filling: System fails to extract necessary information from user input
  - Inappropriate responses: System generates responses that don't match the user's intent or the conversation context

- **First 3 experiments**:
  1. Test the model's ability to generate appropriate responses on seen domains with different levels of dialog complexity
  2. Evaluate the model's zero-shot performance on unseen domains with varying schema complexity
  3. Measure the accuracy of API call generation, including method selection and parameter filling, across different domain types

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the model handle ambiguous or conflicting slot values provided by the user across multiple turns?
- **Basis in paper**: [inferred] The paper discusses slot filling and retrieval tasks but does not address how the model resolves ambiguities or conflicts in slot values.
- **Why unresolved**: The paper focuses on the overall system performance and does not delve into the specifics of conflict resolution mechanisms.
- **What evidence would resolve it**: Detailed analysis of model behavior in scenarios with conflicting slot values, including examples and metrics on conflict resolution accuracy.

### Open Question 2
- **Question**: What is the impact of domain schema complexity on the model's performance in zero-shot settings?
- **Basis in paper**: [inferred] The paper evaluates the model on different datasets with varying domain schemas but does not analyze the relationship between schema complexity and performance.
- **Why unresolved**: The paper does not provide a systematic study on how the complexity of domain schemas affects the model's ability to generalize to new domains.
- **What evidence would resolve it**: Experiments varying schema complexity across different domains and measuring corresponding changes in model performance metrics.

### Open Question 3
- **Question**: How does the model's performance scale with increasing dialog length and complexity?
- **Basis in paper**: [inferred] The paper evaluates the model on dialogs of varying lengths but does not specifically analyze the scaling behavior with respect to dialog complexity.
- **Why unresolved**: The paper provides overall performance metrics but lacks a detailed analysis of how performance degrades or improves with more complex dialogs.
- **What evidence would resolve it**: Performance analysis on dialogs of increasing length and complexity, including metrics such as BLEU-4, GLEU, and API call accuracy, to determine the model's scalability.

## Limitations

- The reported performance gains lack clear baseline comparisons and statistical significance testing
- Zero-shot evaluation methodology is not fully specified regarding truly held-out domains
- Multi-task instruction fine-tuning details are sparse, making it difficult to assess the source of improvements

## Confidence

- **High Confidence**: The core claim that NL-ToD removes dependency on turn-level annotations is well-supported by the methodology description and use of dialog history + domain schemas
- **Medium Confidence**: The claim of outperforming state-of-the-art models trained on annotated data is supported by reported metrics, but lacks sufficient baseline specification
- **Low Confidence**: The zero-shot generalization claims are based on results from three datasets but don't specify the experimental setup for truly unseen domains or provide ablation studies

## Next Checks

1. **Baseline specification audit**: Request detailed specification of comparison models, including their training data requirements, model sizes, and exact performance numbers used for calculating the reported improvement percentages

2. **Zero-shot protocol validation**: Clarify the experimental protocol for unseen domains - were these domains completely held out during any training/fine-tuning, or were they seen during pre-training of the underlying LLM?

3. **Ablation study**: Conduct experiments removing key components (multi-task learning, query generation task, LORA fine-tuning) to quantify their individual contributions to the reported performance gains