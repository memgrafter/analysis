---
ver: rpa2
title: 'Rethinking Self-Distillation: Label Averaging and Enhanced Soft Label Refinement
  with Partial Labels'
arxiv_id: '2402.10482'
source_url: https://arxiv.org/abs/2402.10482
tags:
- label
- distillation
- corruption
- class
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes self-distillation in multi-class classification,
  particularly in linear probing with fixed feature extractors. The authors show that
  multi-round self-distillation effectively performs label averaging among instances
  with high feature correlations, governed by the eigenvectors of the Gram matrix
  derived from input features.
---

# Rethinking Self-Distillation: Label Averaging and Enhanced Soft Label Refinement with Partial Labels

## Quick Facts
- arXiv ID: 2402.10482
- Source URL: https://arxiv.org/abs/2402.10482
- Reference count: 40
- This paper introduces PLL (Partial Label Learning) student model that replicates multi-round self-distillation benefits in a single round through top-2 partial label refinement.

## Executive Summary
This paper provides a comprehensive theoretical and empirical analysis of self-distillation in multi-class classification with linear probing. The authors demonstrate that multi-round self-distillation effectively performs label averaging among instances with high feature correlations, governed by the eigenvectors of the Gram matrix. This mechanism improves robustness to label noise by reducing reliance on potentially corrupted labels. They establish conditions for achieving 100% population accuracy despite label noise. Additionally, the paper introduces a novel, efficient single-round self-distillation method using refined partial labels from the teacher's top two softmax outputs, achieving comparable or superior performance while significantly reducing computational cost.

## Method Summary
The paper analyzes self-distillation using fixed pre-trained feature extractors (ResNet34/ViT-B) with two-layer classifiers (linear + softmax) trained via cross-entropy loss with weight decay. For multi-round distillation, students are iteratively trained using previous student outputs as targets. The novel PLL student method refines teacher outputs into partial labels using the top two predictions with generalized cross-entropy loss. The theoretical analysis reveals that multi-round self-distillation performs label averaging among instances with high feature correlations, governed by eigenvectors of the Gram matrix derived from input features.

## Key Results
- PLL student matches or exceeds multi-round self-distillation performance across six datasets (CIFAR-100, Caltech-101/256, Flowers-102, Food-101, StanfordCars)
- PLL achieves significant improvements in high-noise scenarios while reducing computational cost
- Theoretical conditions established for achieving 100% population accuracy despite label noise through multi-round self-distillation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-round self-distillation performs label averaging among instances with high feature correlations, governed by eigenvectors of the Gram matrix.
- Mechanism: Each distillation round multiplies predictions by a matrix that emphasizes top eigenvectors of the Gram matrix, causing predictions to cluster around instances from the same ground-truth class.
- Core assumption: The softmax outputs can be approximated linearly as 1/K + v/K for small logits.
- Evidence anchors:
  - [abstract] "Our theoretical analysis reveals that multi-round self-distillation effectively performs label averaging among instances with high feature correlations, governed by the eigenvectors of the Gram matrix derived from input features."
  - [section] "Under this approximation, we derive closed-form expressions for {α(t)} in (4) and analyze how the model's outputs change over multiple rounds of self-distillation."
  - [corpus] Weak - neighboring papers discuss pseudo-label refinement and noise mitigation, but none specifically address eigenvector-based label averaging.
- Break condition: If feature correlations between instances from different classes become similar to those within classes, the clustering effect breaks down.

### Mechanism 2
- Claim: Multi-round self-distillation improves robustness to label noise by reducing reliance on corrupted labels through label averaging.
- Mechanism: As distillation rounds progress, predictions increasingly incorporate averaged labels from highly correlated instances, diluting the impact of noisy individual labels.
- Core assumption: The dataset has a block-wise Gram matrix structure where instances from the same class have higher feature correlations than those from different classes.
- Evidence anchors:
  - [abstract] "This process leads to clustered predictions and improved generalization, mitigating the impact of label noise by reducing the model's reliance on potentially corrupted labels."
  - [section] "We establish conditions under which multi-round self-distillation achieves 100% population accuracy despite label noise."
  - [corpus] Weak - neighboring papers address label noise through pseudo-label refinement, but don't specifically discuss multi-round self-distillation's label averaging effect.
- Break condition: If label corruption rate is too high that the majority of instances in a class are corrupted, averaging cannot recover the true label.

### Mechanism 3
- Claim: Single-round PLL student model replicates multi-round self-distillation benefits by refining teacher outputs into partial labels using top two predictions.
- Mechanism: By assigning equal weights to top two predictions, the true label (if present in top two) gets boosted confidence while reducing over-confidence on potentially incorrect predictions.
- Core assumption: The true label consistently appears among the top two predictions in the teacher's softmax output.
- Evidence anchors:
  - [abstract] "Furthermore, we introduce a novel, efficient single-round self-distillation method using refined partial labels from the teacher's top two softmax outputs, referred to as the PLL student model."
  - [section] "The key idea stems from the observation that, under mild conditions on the label corruption rates, the teacher's softmax output at the true label consistently ranks at least second-highest--even for label-noisy samples."
  - [corpus] Weak - neighboring papers discuss pseudo-label refinement but focus on graph-based methods or self-supervised pretraining, not top-two partial label selection.
- Break condition: If the true label falls outside the top two predictions for significant portions of the dataset, the PLL method loses its advantage.

## Foundational Learning

- Concept: Gram matrix and its eigen-decomposition
  - Why needed here: The Gram matrix captures feature correlations between instances, and its eigenvectors determine how label averaging occurs during distillation.
  - Quick check question: Given a dataset of normalized feature vectors, how would you compute the Gram matrix and identify which eigenvectors correspond to within-class correlations?

- Concept: Linear approximation of softmax function
  - Why needed here: The theoretical analysis requires approximating the non-linear softmax to derive closed-form solutions for how predictions evolve.
  - Quick check question: Under what conditions is the linear approximation σ(v) ≈ 1/K + v/K valid, and how does this affect the theoretical guarantees?

- Concept: Label corruption matrix and population accuracy
  - Why needed here: The analysis quantifies when self-distillation can achieve 100% population accuracy despite label noise, requiring understanding of corruption matrices.
  - Quick check question: How would you construct a label corruption matrix from a dataset with noisy labels, and what properties must it satisfy for the PLL method to work?

## Architecture Onboarding

- Component map: Fixed feature extractor -> Two-layer classifier (linear + softmax) -> Cross-entropy loss -> Gram matrix computation -> Label refinement module
- Critical path:
  1. Extract features from pre-trained model
  2. Compute Gram matrix for theoretical analysis
  3. Train teacher model with given labels
  4. Generate student targets from teacher outputs
  5. Train student models with teacher targets
  6. For PLL: refine teacher outputs to top-two partial labels
  7. Evaluate accuracy on test set
- Design tradeoffs:
  - Using fixed feature extractor vs. fine-tuning: Fixed extractor enables theoretical analysis but may limit performance
  - Multi-round vs. single-round distillation: Multi-round provides better noise robustness but higher computational cost
  - Top-2 vs. larger partial label sets: Top-2 balances inclusion of true label with confidence preservation
- Failure signatures:
  - Gram matrix eigenvalues show no clear gap between top-K and remaining eigenvalues (weak clustering)
  - PLL student performance degrades significantly when label corruption exceeds threshold
  - Softmax approximation error increases with sample size or regularization parameter
- First 3 experiments:
  1. Verify Gram matrix structure on real dataset shows block-diagonal pattern for within-class correlations
  2. Test softmax approximation validity by comparing theoretical predictions with numerical solutions
  3. Evaluate PLL student performance vs. multi-round distillation across different label corruption rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the label averaging effect observed in multi-round self-distillation be generalized to scenarios where the feature correlation matrix does not exhibit a block-diagonal structure?
- Basis in paper: [inferred] The paper assumes a specific class-wise feature correlation model (7) with a block-diagonal Gram matrix to derive closed-form solutions and analyze the label averaging effect. The authors validate this assumption empirically on real datasets but acknowledge it as a limitation.
- Why unresolved: The paper's theoretical analysis relies heavily on the block-diagonal structure of the Gram matrix. Extending the analysis to more general feature correlation models, such as those with non-zero inter-superclass correlations or more complex feature correlation patterns, remains an open challenge.
- What evidence would resolve it: Empirical studies on diverse datasets with varying feature correlation structures, combined with theoretical extensions of the analysis to accommodate these structures, would help determine the generalizability of the label averaging effect.

### Open Question 2
- Question: How does the temperature scaling of the softmax function affect the label averaging effect and the performance gains achieved through multi-round self-distillation?
- Basis in paper: [explicit] The paper briefly mentions temperature scaling in Appendix D.3, showing that it does not affect the optimal prediction of the student model. However, the impact of temperature scaling on the label averaging effect and the overall performance of self-distillation is not thoroughly investigated.
- Why unresolved: The analysis in the paper assumes a temperature scaling of τ = 1, and the effect of varying the temperature parameter on the label averaging effect and the resulting performance gains is not explored.
- What evidence would resolve it: Systematic experiments varying the temperature parameter across different datasets and label corruption scenarios, combined with theoretical analysis of the impact of temperature scaling on the label averaging effect, would provide insights into the role of temperature in self-distillation.

### Open Question 3
- Question: Can the label averaging effect of multi-round self-distillation be leveraged to improve the performance of other machine learning tasks beyond multi-class classification, such as regression or unsupervised learning?
- Basis in paper: [inferred] The paper focuses on the application of self-distillation to multi-class classification problems. While the authors mention that self-distillation has been studied in regression settings, the potential benefits of the label averaging effect in other machine learning tasks are not explored.
- Why unresolved: The paper's analysis and experiments are limited to multi-class classification, and the applicability of the label averaging effect to other machine learning tasks remains unexplored.
- What evidence would resolve it: Theoretical analysis and empirical studies extending the label averaging effect to other machine learning tasks, such as regression or unsupervised learning, would help determine the broader applicability of self-distillation and its potential benefits in these domains.

## Limitations

- The theoretical analysis relies heavily on a linear approximation of the softmax function which is only valid for small logits.
- The block-diagonal Gram matrix structure with fixed correlation parameters is a simplifying assumption that may not capture real feature space complexity.
- The PLL method's effectiveness critically depends on the true label consistently appearing in the teacher's top-2 predictions.

## Confidence

- **High confidence**: The empirical demonstration that PLL student matches or exceeds multi-round self-distillation performance across multiple datasets and corruption types.
- **Medium confidence**: The theoretical conditions for 100% population accuracy under label noise, as these depend on specific assumptions about Gram matrix structure and corruption rates.
- **Low confidence**: The exact quantitative relationship between feature correlation parameters and distillation effectiveness in real datasets.

## Next Checks

1. **Gram Matrix Structure Validation**: Compute and visualize the Gram matrix from real dataset features to verify the block-diagonal structure with clear separation between within-class and between-class correlations. Measure the eigenvalue gap between top-K and remaining eigenvalues.

2. **Softmax Approximation Accuracy**: Systematically test the validity of the linear softmax approximation across different datasets and regularization parameters by comparing theoretical predictions with numerical solutions. Quantify approximation error as a function of logit magnitudes.

3. **PLL Candidate Set Analysis**: For each dataset and corruption scenario, measure the frequency with which the true label appears in the teacher's top-2 predictions. Determine the minimum accuracy threshold required for PLL to outperform standard distillation.