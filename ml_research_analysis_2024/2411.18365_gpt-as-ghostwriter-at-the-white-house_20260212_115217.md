---
ver: rpa2
title: GPT as ghostwriter at the White House
arxiv_id: '2411.18365'
source_url: https://arxiv.org/abs/2411.18365
tags:
- table
- presidents
- speeches
- style
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares State of the Union addresses written by recent
  US presidents (Reagan to Obama) with those generated by ChatGPT 3.5. Stylometric
  analysis shows that GPT-generated speeches tend to overuse the lemma "we," nouns,
  and commas, while employing fewer verbs and longer sentences.
---

# GPT as ghostwriter at the White House

## Quick Facts
- arXiv ID: 2411.18365
- Source URL: https://arxiv.org/abs/2411.18365
- Reference count: 0
- GPT-generated State of the Union speeches show distinct stylistic patterns from real presidential addresses

## Executive Summary
This study systematically compares State of the Union addresses written by recent US presidents (Reagan to Obama) with those generated by ChatGPT 3.5. Using comprehensive stylometric analysis, the research reveals that GPT-generated speeches exhibit distinctive patterns: overuse of the lemma "we," nouns, and commas; underuse of verbs; and longer sentences compared to human-authored speeches. Even when GPT attempts to imitate specific presidents, its output remains stylistically distinct from authentic presidential rhetoric. The analysis demonstrates that current AI-generated political texts have identifiable characteristics that differentiate them from human-authored political discourse.

## Method Summary
The study compares stylometric features of GPT-generated State of the Union addresses with real presidential speeches from Reagan through Obama. GPT-3.5-turbo was used with temperature=0.5 and top_p=0.4 to generate speeches for each president based on prompts derived from non-SOTU examples. The corpus includes real SOTU addresses (20K-67K tokens each) and GPT-generated versions (~9K-11K tokens each). Stylistic metrics analyzed include word length, big words percentage, moving average type-token ratio (MATTR), mean sentence length, part-of-speech distribution, characteristic vocabulary, psychological wordlists, and intertextual distance measures. Statistical tests confirm significant differences between GPT and human-authored speeches.

## Key Results
- GPT-generated speeches overuse the lemma "we," nouns, and commas while employing fewer verbs than human-written speeches
- GPT speeches have longer mean sentence length (22.62 vs 19.71) and word length (4.89 vs 4.39) compared to presidential addresses
- Intertextual distance measures confirm GPT speeches differ significantly from actual presidential speeches, with distance values around 0.2-0.3

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: GPT-generated speeches exhibit statistically higher noun and article density compared to human-authored State of the Union addresses.
- **Mechanism**: GPT's training on web-scale text corpus leads to over-reliance on descriptive, noun-heavy constructions rather than action-oriented verb phrases.
- **Core assumption**: GPT's output reflects learned distributional patterns from training data, not human rhetorical intent.
- **Evidence anchors**:
  - [abstract]: "GPT-generated speeches tend to overuse the lemma 'we,' nouns, and commas, while employing fewer verbs..."
  - [section 4]: Table 5 shows POS distribution with GPT using 23.52% nouns vs. 19-20% for presidents, and 8.43% articles vs. 7.7-9.5%.
  - [corpus]: Statistical tests confirm these differences are significant (p<0.01).
- **Break condition**: If GPT's training corpus or fine-tuning objectives explicitly prioritize verb-based constructions, this mechanism fails.

### Mechanism 2
- **Claim**: GPT-generated speeches have longer mean sentence length and word length, indicating higher complexity than human speeches.
- **Mechanism**: GPT's token-level prediction model generates syntactically longer constructions without the rhetorical constraints human writers use.
- **Core assumption**: Longer constructions correlate with reduced audience comprehension and less effective political rhetoric.
- **Evidence anchors**:
  - [abstract]: "...longer sentences. Even when imitating specific presidents, GPT's style remains distinct..."
  - [section 4]: Table 4 shows GPT MSL at 22.62 vs. 19.71 for presidents, word length 4.89 vs. 4.39.
  - [corpus]: Proportion tests confirm these differences are statistically significant.
- **Break condition**: If longer sentences are preferred by the target audience or political context, this mechanism breaks.

### Mechanism 3
- **Claim**: GPT's rhetorical tone is more neutral and positive, avoiding divisive or emotionally charged language used by human presidents.
- **Mechanism**: GPT's training objectives prioritize coherence and grammatical correctness over persuasive emotional impact.
- **Core assumption**: Political speeches require emotional resonance and rhetorical positioning that GPT systematically avoids.
- **Evidence anchors**:
  - [abstract]: "GPT opts for a neutral tone with mainly positive emotional expressions..."
  - [section 6]: Table 7 shows GPT with 4.67% positive emotion vs. 2.78-3.78% for presidents, and 0.95% negative vs. 1.07-1.53%.
  - [corpus]: Wordlist analysis confirms GPT avoids blame-related terms (0.2% vs. 0.39-0.60%).
- **Break condition**: If GPT's training corpus or fine-tuning objectives explicitly include persuasive political rhetoric, this mechanism fails.

## Foundational Learning

- **Concept**: Intertextual distance computation using vocabulary overlap
  - Why needed here: To quantify stylistic differences between GPT and human speeches across entire vocabulary space
  - Quick check question: What mathematical transformation converts raw vocabulary overlap into a distance metric between 0 and 1?

- **Concept**: Part-of-speech (POS) distributional analysis
  - Why needed here: To identify systematic stylistic differences in grammatical construction between GPT and human authors
  - Quick check question: Which POS categories show the largest statistically significant differences between GPT and presidential speeches?

- **Concept**: Characteristic vocabulary analysis using Z-score
  - Why needed here: To identify words that are over/under-used by specific authors relative to corpus baseline
  - Quick check question: How does the Z-score threshold determine whether a word belongs to an author's characteristic vocabulary?

## Architecture Onboarding

- **Component map**: Text preprocessing → POS tagging → Frequency counting → Statistical comparison → Distance matrix computation → Visualization
- **Critical path**: Each analysis stage must complete before next begins
- **Design tradeoffs**: Trade accuracy for speed by using moving average TTR (MATTR) instead of full TTR, and by limiting intertextual distance comparisons to pairs with acceptable length ratios
- **Failure signatures**: High variance in MATTR across small segments indicates poor text segmentation; extreme intertextual distances (>0.4) suggest preprocessing errors or corpus mismatch
- **First 3 experiments**:
  1. Run POS distribution analysis on GPT vs. president pairs to identify statistically significant differences
  2. Compute MATTR on same segments to verify vocabulary richness differences
  3. Generate intertextual distance matrix to visualize overall stylistic similarity patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the overuse of the lemma "we" in GPT-generated speeches indicate an attempt to mimic the inclusive tone of real presidential speeches, or does it suggest a lack of nuance in GPT's language generation?
- Basis in paper: [explicit] The paper notes that GPT tends to overuse the lemma "we" as well as nouns and commas, while employing fewer verbs and longer sentences. Even when imitating specific presidents, GPT's style remains distinct from real presidential addresses.
- Why unresolved: The paper does not delve into the motivations behind GPT's stylistic choices. It is unclear whether the overuse of "we" is a deliberate attempt to mimic the inclusive tone of presidential speeches or a result of the model's training data and algorithms.
- What evidence would resolve it: A comparative analysis of the contexts in which "we" is used in GPT-generated speeches versus real presidential speeches could shed light on this question. Additionally, examining the training data and algorithms used to develop GPT could provide insights into its stylistic choices.

### Open Question 2
- Question: How does the intertextual distance between GPT-generated speeches and real presidential speeches change as GPT is trained on more diverse and representative data?
- Basis in paper: [inferred] The paper uses intertextual distance measures to confirm that GPT speeches differ significantly from actual presidential speeches, demonstrating that current AI-generated political texts have identifiable stylistic characteristics distinct from human-authored ones. This suggests that the training data and algorithms used to develop GPT play a crucial role in shaping its output.
- Why unresolved: The paper does not explore how the intertextual distance between GPT-generated speeches and real presidential speeches changes as GPT is trained on more diverse and representative data. This could provide insights into the model's ability to adapt to different styles and contexts.
- What evidence would resolve it: Conducting experiments where GPT is trained on different subsets of data and comparing the intertextual distance between the generated speeches and real presidential speeches could help answer this question.

### Open Question 3
- Question: To what extent do the stylistic differences between GPT-generated speeches and real presidential speeches impact the perceived authenticity and persuasiveness of the generated texts?
- Basis in paper: [explicit] The paper demonstrates that GPT-generated speeches have identifiable stylistic characteristics distinct from human-authored ones, such as overusing the lemma "we," nouns, and commas, while employing fewer verbs and longer sentences. These differences could impact the perceived authenticity and persuasiveness of the generated texts.
- Why unresolved: The paper does not explore how the stylistic differences between GPT-generated speeches and real presidential speeches impact the perceived authenticity and persuasiveness of the generated texts. This could provide insights into the effectiveness of GPT as a tool for generating political speeches.
- What evidence would resolve it: Conducting experiments where participants evaluate the perceived authenticity and persuasiveness of GPT-generated speeches versus real presidential speeches could help answer this question. Additionally, analyzing the linguistic and rhetorical features that contribute to the perceived authenticity and persuasiveness of political speeches could provide insights into the effectiveness of GPT.

## Limitations

- **Prompt Design Ambiguity**: The study does not provide exact prompts used to generate GPT speeches, only stating they were based on "non-SOTU examples from Miller Center"
- **Corpus Imbalance**: Real presidential speeches (20K-67K tokens) are 3-6x longer than GPT-generated speeches (~9K-11K tokens), potentially biasing statistical comparisons
- **Cross-linguistic Generalization**: Results may not generalize beyond English-language State of the Union addresses from US presidents

## Confidence

**High Confidence**: The finding that GPT-generated speeches show statistically significant differences in POS distribution (overuse of nouns/commas, underuse of verbs) is well-supported by the data and consistent across multiple statistical tests.

**Medium Confidence**: Claims about emotional tone differences (more positive, less negative emotion) are supported by LIWC analysis but may be sensitive to specific word lists used.

**Low Confidence**: The intertextual distance measures showing GPT speeches are "distinct" from human speeches may overstate practical significance, as distance values around 0.2-0.3 indicate some overlap exists.

## Next Checks

1. **Prompt Variation Test**: Generate GPT speeches using multiple prompt formulations (direct imitation vs. style transfer vs. content-focused) to determine if observed stylistic differences persist across prompt strategies or are prompt-dependent artifacts.

2. **Length Normalization Analysis**: Resample or truncate real presidential speeches to match GPT speech lengths and recompute all statistical comparisons to verify that length imbalance doesn't drive the observed differences.

3. **Cross-Generational Comparison**: Compare GPT-3.5 outputs with speeches from newer AI models (GPT-4, Claude, etc.) to assess whether the identified stylistic markers are model-specific or represent broader AI writing patterns.