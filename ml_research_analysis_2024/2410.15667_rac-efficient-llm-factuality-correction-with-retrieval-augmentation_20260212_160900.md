---
ver: rpa2
title: 'RAC: Efficient LLM Factuality Correction with Retrieval Augmentation'
arxiv_id: '2410.15667'
source_url: https://arxiv.org/abs/2410.15667
tags:
- llms
- retrieved
- correction
- retrieval
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Retrieval Augmented Correction (RAC), a post-processing
  method that improves the factual correctness of LLM outputs by decomposing generated
  text into atomic facts, verifying them against retrieved documents, and correcting
  only incorrect statements. RAC is designed to work both with and without Retrieval-Augmented
  Generation (RAG), offering up to 30% improvement in factuality across two datasets.
---

# RAC: Efficient LLM Factuality Correction with Retrieval Augmentation

## Quick Facts
- arXiv ID: 2410.15667
- Source URL: https://arxiv.org/abs/2410.15667
- Reference count: 15
- Key outcome: RAC improves factual correctness of LLM outputs by up to 30% across two datasets using fine-grained verification and selective correction

## Executive Summary
RAC introduces a post-processing method that enhances the factual accuracy of LLM outputs through atomic fact decomposition, verification against retrieved documents, and selective correction. The approach works both with and without RAG, offering significant improvements in factuality while reducing latency compared to prior methods. By verifying each extracted fact individually and only correcting false statements, RAC avoids introducing new hallucinations while preserving correct information. The method demonstrates consistent improvements across multiple models and datasets, with some cases showing better performance without RAG than with it.

## Method Summary
RAC decomposes LLM-generated text into atomic facts, verifies them against retrieved documents, and corrects only false statements while preserving verified truths. The system uses fine-grained verification and correction with retrieval post-processing to ensure high-quality verification documents. It operates in two modes: with RAG (using retrieval data for verification and correction) and without RAG (using only the generated output). The approach is designed to be efficient, reducing latency by 2x to 40x compared to previous methods while maintaining or improving factuality scores on TruthfulQA and Biography datasets.

## Key Results
- Up to 30% improvement in factuality across two datasets (TruthfulQA and Biography)
- Consistent improvements across multiple models: GPT-3.5-Turbo, Llama 2-7B, Llama 3-8B, and Mistral 7B
- Works both with and without RAG, with some cases showing better performance without RAG
- Reduced latency of 2x to 40x compared to previous approaches
- Avoids introducing new hallucinations by selectively correcting only false statements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Atomic fact extraction enables fine-grained verification and correction
- Mechanism: By decomposing LLM-generated content into independent factual statements, the system can verify and correct each fact individually rather than treating the entire output as a single unit. This allows targeted corrections without risking the introduction of new hallucinations in correct statements.
- Core assumption: Breaking down content into atomic facts preserves all necessary information while making verification tractable
- Evidence anchors:
  - [abstract] "RAC decomposes the LLM's output into atomic facts and applies a fine-grained verification and correction process with retrieved content"
  - [section 3.3] "Atomic fact extraction breaks down the original task outputs from LLMs into several independent factual statements"
  - [corpus] Weak - no direct corpus evidence found for this specific mechanism

### Mechanism 2
- Claim: Selective correction with verification reduces hallucination introduction
- Mechanism: Instead of correcting all statements, the system first verifies each atomic fact against retrieved documents. Only false statements are corrected while true statements are preserved, preventing the introduction of new errors in content that is already correct.
- Core assumption: RAG outputs contain mostly correct information that should be preserved rather than overwritten
- Evidence anchors:
  - [section 4.2] "Since many of the extracted statements after using RAG are correct, we find we do not need to correct all statements"
  - [section 4.3] "True statements are always kept, False statements always be corrected, and Not Mentioned statements are kept"
  - [corpus] Weak - no direct corpus evidence found for this specific selective correction approach

### Mechanism 3
- Claim: Retrieval post-processing ensures high-quality verification documents
- Mechanism: The system filters out unrelated documents and truncates content to fit LLM context windows, ensuring that verification operates on relevant, faithful, and concise documents. This improves the reliability of the verification step.
- Core assumption: The quality of retrieved documents directly impacts the success of verification and correction
- Evidence anchors:
  - [section 3.2] "The retrieval post-processing conducts two things: 1. filtering out unrelated documents or reranking and picking up top-k documents; 2. truncating or compressing the documents"
  - [section 7.3] "Without RAG, using gold data as the retrieval data for correction only improves the performance little. RAG using gold data has improved RAG a lot"
  - [corpus] Weak - no direct corpus evidence found for this specific post-processing approach

## Foundational Learning

- Concept: Retrieval Augmented Generation (RAG)
  - Why needed here: Understanding how RAG works is essential to grasp why RAC needs both verification and correction components, and when each is necessary
  - Quick check question: What are the two main stages of RAG, and why does RAG alone not guarantee factual correctness?

- Concept: Atomic fact extraction
  - Why needed here: This is the foundation for RAC's fine-grained approach - understanding how to break down text into independent factual statements is crucial
  - Quick check question: How does atomic fact extraction differ from sentence segmentation, and why is this distinction important for verification?

- Concept: Verification vs. Correction vs. Revision
  - Why needed here: RAC uses three distinct operations with different purposes - understanding their roles prevents confusion during implementation
  - Quick check question: What is the key difference between verification and correction in RAC, and when is each used?

## Architecture Onboarding

- Component map:
  - Input Processing → Atomic Fact Extraction → (Verification →) Correction → Revision → Output
  - Retrieval (with post-processing) → Verification/Verification → Correction → Revision
  - Key components: Extractor, Verifier, Corrector, Reviser, Retriever, Post-processor

- Critical path:
  - For RAG: Extraction → Verification → Correction → Revision
  - For non-RAG: Extraction → Correction → Revision
  - Retrieval and post-processing occur before verification/correction

- Design tradeoffs:
  - Granularity vs. efficiency: Atomic facts enable fine-grained correction but increase processing overhead
  - Verification overhead vs. hallucination prevention: Verification adds latency but reduces hallucination introduction
  - Retrieval quality vs. processing speed: More comprehensive retrieval improves verification but increases latency

- Failure signatures:
  - Degradation in factuality scores indicates verification/correction failures
  - Increased hallucinations in output suggest over-correction or poor verification
  - Latency spikes may indicate inefficient retrieval or processing bottlenecks

- First 3 experiments:
  1. Implement atomic fact extraction and verify it correctly decomposes sample outputs
  2. Test verification component with gold-standard documents to ensure it correctly identifies true/false statements
  3. Implement correction component and verify it only changes false statements while preserving true ones

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact mechanism by which the atomic fact extraction process handles pronouns and maintains factual accuracy when decomposing complex sentences?
- Basis in paper: [explicit] The paper states "Atomic fact extraction breaks down the original task outputs from LLMs into several independent factual statements. This strategy is inspired by Factscore (Min et al., 2023)."
- Why unresolved: While the paper mentions atomic fact extraction and its inspiration, it doesn't provide detailed implementation specifics about pronoun handling or the algorithmic approach to maintaining factual accuracy during decomposition.
- What evidence would resolve it: Implementation details showing how the extraction process identifies and handles pronouns, maintains entity references, and ensures that decomposed facts preserve the original meaning and relationships.

### Open Question 2
- Question: How does the latency reduction of RAC (2x to 40x) compare when scaling to different model sizes and across different hardware configurations?
- Basis in paper: [explicit] The paper states "Table 5 shows the experimentally measured latency on the Biography dataset for our method and previous approaches. Our method has reduced latency of 2x to 40x compared to previous approaches."
- Why unresolved: The paper only reports latency measurements for the Biography dataset using specific models and doesn't explore how these improvements scale with different model sizes or hardware setups.
- What evidence would resolve it: Comprehensive latency benchmarking across various model sizes (from small to large), different hardware configurations (GPU vs CPU, different GPU models), and multiple datasets to establish generalizability of the latency improvements.

### Open Question 3
- Question: How does the performance of RAC vary across different domains (e.g., technical, creative, medical) beyond the two tested datasets?
- Basis in paper: [inferred] The paper evaluates on TruthfulQA and Biography datasets but doesn't explore performance across diverse domains that might have different factuality requirements or knowledge structures.
- Why unresolved: The current evaluation is limited to two specific datasets, leaving questions about how well the approach generalizes to other domains with different factuality challenges.
- What evidence would resolve it: Comprehensive evaluation across multiple domains including technical documentation, creative writing, medical information, and scientific content to establish domain-specific performance characteristics and limitations.

## Limitations

- The evaluation relies heavily on GPT-3.5-Turbo for factuality scoring, which introduces potential bias
- The study does not report human evaluation results, limiting confidence in real-world performance
- The atomic fact extraction method is not detailed, raising questions about its robustness across different domains and languages
- Ablation studies are limited and don't explore different verification strategies or document quality thresholds

## Confidence

**High confidence**: The RAC architecture design and its ability to improve factuality metrics on benchmark datasets. The claim that selective correction prevents hallucination introduction is well-supported by controlled experiments showing up to 30% improvement.

**Medium confidence**: The comparative advantage over state-of-the-art baselines, as this depends on the specific evaluation methodology and may not generalize to all use cases. The claim that RAC without RAG can outperform with RAG in some cases needs further validation across diverse domains.

**Low confidence**: The scalability of the approach to very large documents or highly technical domains where atomic fact extraction may struggle. The latency improvements compared to prior approaches are not quantified in absolute terms.

## Next Checks

1. **Human evaluation study**: Conduct blinded human assessments comparing RAC outputs to original LLM outputs and baseline correction methods to validate automated metrics.

2. **Cross-domain robustness test**: Apply RAC to diverse domains (scientific, legal, technical) to evaluate the generalizability of atomic fact extraction and verification components.

3. **Latency and resource analysis**: Measure absolute latency improvements and compute resource requirements compared to baseline approaches across different document lengths and fact densities.