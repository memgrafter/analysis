---
ver: rpa2
title: Improving self-training under distribution shifts via anchored confidence with
  theoretical guarantees
arxiv_id: '2411.00586'
source_url: https://arxiv.org/abs/2411.00586
tags:
- ancon
- self-training
- distribution
- temporal
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AnCon, a method that improves self-training
  under distribution shifts by promoting selective temporal consistency through uncertainty-aware
  label smoothing. The key innovation is constructing a temporal ensemble that weights
  predictions based on confidence, then using this ensemble to smooth noisy pseudo
  labels during self-training.
---

# Improving self-training under distribution shifts via anchored confidence with theoretical guarantees

## Quick Facts
- arXiv ID: 2411.00586
- Source URL: https://arxiv.org/abs/2411.00586
- Reference count: 40
- This paper introduces AnCon, a method that improves self-training under distribution shifts by promoting selective temporal consistency through uncertainty-aware label smoothing

## Executive Summary
This paper introduces AnCon, a novel method for improving self-training under distribution shifts by promoting selective temporal consistency through uncertainty-aware label smoothing. The key innovation is constructing a temporal ensemble that weights predictions based on confidence, then using this ensemble to smooth noisy pseudo labels during self-training. This approach efficiently mitigates the detrimental effects of incorrect pseudo labels without requiring computationally expensive neighborhood searches or multiple model predictions.

Extensive experiments across diverse distribution shift scenarios demonstrate that AnCon consistently improves self-training performance by 8-16%, outperforming vanilla self-training and showing competitive results to early learning regularization. The method exhibits attractive properties including improved calibration, robustness to hyperparameter choices, and resilience to different model selection criteria.

## Method Summary
AnCon constructs a temporal ensemble by maintaining a history of model predictions over training iterations, with each prediction weighted based on its confidence. The weighting scheme uses relative thresholding, where predictions exceeding a confidence threshold are assigned higher weights. This ensemble is then used to smooth pseudo labels through a label smoothing formulation, which prevents the model from becoming overconfident on potentially incorrect labels. The method operates as an add-on to existing self-training frameworks and can be integrated with state-of-the-art self-training methods like GCE and NRC for further performance gains.

## Key Results
- AnCon improves self-training performance by 8-16% across multiple datasets and distribution shift scenarios
- The method demonstrates competitive results compared to early learning regularization while requiring fewer assumptions
- AnCon shows improved calibration and robustness to hyperparameter choices, with resilience to different model selection criteria

## Why This Works (Mechanism)
AnCon addresses the core challenge in self-training under distribution shifts: incorrect pseudo labels can accumulate errors and degrade performance. By constructing a temporal ensemble that weights predictions based on confidence, the method selectively incorporates reliable predictions while downweighting uncertain ones. The label smoothing formulation prevents overconfidence on potentially incorrect labels, creating a more stable training process. This approach effectively balances the benefits of temporal consistency with the need to filter out noisy predictions, without requiring computationally expensive neighborhood searches or multiple model predictions.

## Foundational Learning
- Temporal ensemble: A history of model predictions over training iterations, weighted by confidence
  - Why needed: To capture the evolution of model predictions and identify reliable patterns
  - Quick check: Verify that ensemble weights decay appropriately over time
- Label smoothing: A regularization technique that prevents overconfidence by softening hard labels
  - Why needed: To prevent the model from becoming overconfident on potentially incorrect pseudo labels
  - Quick check: Confirm that smoothed labels maintain semantic meaning
- Relative thresholding: A weighting scheme that assigns higher weights to predictions exceeding a confidence threshold
  - Why needed: To selectively incorporate reliable predictions while downweighting uncertain ones
  - Quick check: Ensure threshold adapts appropriately to confidence distribution
- Self-training: A semi-supervised learning approach that iteratively generates and uses pseudo labels
  - Why needed: To leverage unlabeled target domain data for improving model performance
  - Quick check: Verify that pseudo label quality improves over training iterations

## Architecture Onboarding
- Component map: Pre-trained model -> Temporal ensemble construction -> Weighted averaging -> Label smoothing -> Self-training loop -> Final model
- Critical path: The temporal ensemble construction and weighted averaging steps are critical for ensuring selective temporal consistency
- Design tradeoffs: AnCon trades computational efficiency for improved performance by avoiding expensive neighborhood searches, while maintaining simplicity through its add-on nature
- Failure signatures: Poor performance due to incorrect implementation of relative thresholding weighting scheme or inappropriate hyperparameter choices
- First experiments: 1) Verify relative thresholding weighting scheme implementation, 2) Conduct sensitivity analysis with different λ and β values, 3) Test integration with GCE and NRC methods

## Open Questions the Paper Calls Out
None

## Limitations
- The method requires careful tuning of hyperparameters (λ and β) for optimal performance
- Performance may degrade if the confidence threshold is set too high or too low
- The method's effectiveness depends on the quality of the initial pre-trained model and the extent of distribution shift

## Confidence
- Performance improvements (8-16% gains): Medium
- Theoretical guarantees: Low
- Calibration improvements: Medium

## Next Checks
1. Implement the relative thresholding weighting scheme correctly and verify that weights are computed as specified.
2. Conduct sensitivity analysis with different values of λ and β to ensure robustness to hyperparameter choices.
3. Test integration with state-of-the-art self-training methods like GCE and NRC to verify further performance gains.