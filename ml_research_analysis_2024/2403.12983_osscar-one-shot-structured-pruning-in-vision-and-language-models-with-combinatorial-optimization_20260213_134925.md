---
ver: rpa2
title: 'OSSCAR: One-Shot Structured Pruning in Vision and Language Models with Combinatorial
  Optimization'
arxiv_id: '2403.12983'
source_url: https://arxiv.org/abs/2403.12983
tags:
- pruning
- structured
- osscar
- time
- matrix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OSSCAR is a one-shot structured pruning framework that reduces
  inference costs of large vision and language models by removing entire subcomponents
  like neurons or attention heads without retraining. The method formulates structured
  pruning as a quadratic optimization problem with combinatorial constraints, reformulated
  to exploit problem structure for scalability.
---

# OSSCAR: One-Shot Structured Pruning in Vision and Language Models with Combinatorial Optimization

## Quick Facts
- arXiv ID: 2403.12983
- Source URL: https://arxiv.org/abs/2403.12983
- Authors: Xiang Meng; Shibal Ibrahim; Kayhan Behdin; Hussein Hazimeh; Natalia Ponomareva; Rahul Mazumder
- Reference count: 40
- Key outcome: Achieves state-of-the-art one-shot structured pruning, notably reducing test perplexity by 125× on WikiText for OPT-2.7B while achieving 2× speedup, and handles models up to 30 billion parameters using only 32GB GPU memory

## Executive Summary
OSSCAR introduces a novel one-shot structured pruning framework that removes entire subcomponents like neurons or attention heads from vision and language models without retraining. By formulating structured pruning as a quadratic optimization problem with combinatorial constraints, the method achieves significant inference cost reductions while maintaining model accuracy. The approach scales to extremely large models (up to 30 billion parameters) and outperforms existing one-shot methods by 6-8× in speed, making it practical for deployment of large language models.

## Method Summary
OSSCAR formulates structured pruning as a mixed-integer quadratic program (MIQP) with combinatorial constraints that identify optimal subcomponents to remove. The method reformulates this problem to exploit its specific structure, enabling scalability to very large models. A novel local combinatorial optimization algorithm with low-rank updates efficiently searches for high-quality solutions. The framework operates in a layer-wise manner, using a reconstruction objective that preserves model performance while removing redundant components. Unlike iterative pruning methods, OSSCAR performs all pruning decisions in a single shot, eliminating the need for computationally expensive fine-tuning.

## Key Results
- Achieves 125× reduction in test perplexity on WikiText for OPT-2.7B while maintaining 2× inference speedup
- Handles models up to 30 billion parameters using only 32GB GPU memory
- Outperforms competing one-shot methods by 6-8× in computational efficiency
- Demonstrates state-of-the-art performance across both vision models (ResNet20, MobileNet, ResNet50) and language models (OPT-1.3B to OPT-30B)

## Why This Works (Mechanism)
OSSCAR works by exploiting the combinatorial structure of structured pruning through an MIQP formulation. The key insight is that structured pruning can be viewed as selecting which entire subcomponents (neurons, attention heads) to keep rather than individual weights to remove. This combinatorial perspective enables the use of specialized optimization techniques that scale efficiently. The local combinatorial optimization algorithm with low-rank updates allows searching through the exponential space of possible pruning configurations without explicitly enumerating them, making the approach tractable for very large models.

## Foundational Learning
- **Mixed-Integer Quadratic Programming (MIQP)**: Optimization framework combining quadratic objectives with integer constraints, essential for modeling the discrete nature of structured pruning decisions
  - Why needed: Provides mathematical formulation for selecting entire subcomponents while optimizing reconstruction error
  - Quick check: Verify MIQP solver can handle the specific constraint structure in pruning problems

- **Low-rank matrix updates**: Technique for efficiently updating matrix factorizations when small changes occur, critical for the local search algorithm
  - Why needed: Enables rapid evaluation of neighboring solutions in the combinatorial search space without recomputing from scratch
  - Quick check: Confirm low-rank updates maintain numerical stability across iterations

- **Layer-wise reconstruction objective**: Method for evaluating the impact of removing subcomponents by measuring reconstruction error at each layer
  - Why needed: Provides a computationally efficient proxy for the true performance impact of pruning decisions
  - Quick check: Validate reconstruction error correlates with actual performance degradation

## Architecture Onboarding
- **Component map**: Input model -> Layer-wise reconstruction objective -> MIQP formulation -> Combinatorial reformulation -> Local search with low-rank updates -> Pruned model
- **Critical path**: The core computational bottleneck lies in constructing and solving the MIQP formulation for each layer, particularly the matrix operations for H and G in the combinatorial reformulation
- **Design tradeoffs**: One-shot approach trades potential optimality of iterative methods for dramatic computational efficiency gains; structured pruning limits achievable sparsity compared to unstructured methods but enables hardware acceleration
- **Failure signatures**: High GPU memory usage indicates problems with low-rank update implementation; poor pruning performance suggests suboptimal hyperparameter choices for ˆt and ˆp; numerical instability in MIQP solver suggests issues with constraint formulation
- **First experiments**: 1) Validate baseline implementations (MP, CHIP, FPGM, Lasso, ThiNet for vision; MP, MP+, ZipLM for language); 2) Test sensitivity to ˆt and ˆp hyperparameters across different model sizes; 3) Verify low-rank update implementation by comparing against full matrix recomputation

## Open Questions the Paper Calls Out
- **Open Question 1**: What is the precise relationship between the size of the calibration dataset and the final perplexity achieved by OSSCAR? Specifically, is there a theoretical bound on the number of samples needed to achieve within ε of the optimal perplexity?
  - Basis in paper: The paper shows experimentally that increasing the calibration dataset from 128 to 2048 samples reduces perplexity by up to 3.5 points for a 2x speedup, with diminishing returns beyond that point
  - Why unresolved: The paper only provides empirical observations without theoretical analysis of the sample complexity
  - What evidence would resolve it: Theoretical analysis establishing sample complexity bounds, or additional experimental results showing the relationship across a wider range of dataset sizes and speedup ratios

- **Open Question 2**: How does the performance of OSSCAR compare to gradual pruning methods that include fine-tuning, particularly for very large models where fine-tuning becomes impractical?
  - Basis in paper: The paper focuses exclusively on one-shot pruning to avoid the computational expense of fine-tuning, but doesn't compare against gradual pruning methods in cases where fine-tuning would be feasible
  - Why unresolved: The paper only benchmarks against other one-shot methods, leaving open the question of how much accuracy is sacrificed compared to gradual pruning approaches
  - What evidence would resolve it: Direct comparison experiments between OSSCAR and gradual pruning methods on models where fine-tuning is computationally feasible

- **Open Question 3**: Can the OSSCAR framework be extended to handle unstructured pruning, or is it fundamentally limited to structured pruning due to its combinatorial optimization formulation?
  - Basis in paper: The paper specifically formulates structured pruning as a mixed-integer quadratic program with combinatorial constraints that exploit problem structure
  - Why unresolved: While the paper demonstrates excellent results for structured pruning, it doesn't explore whether the underlying optimization techniques could be adapted for unstructured pruning
  - What evidence would resolve it: Extension of the OSSCAR framework to unstructured pruning, or theoretical proof that the combinatorial formulation is incompatible with unstructured approaches

## Limitations
- Relies on exact implementations of competing methods (MP, CHIP, FPGM, Lasso, ThiNet, ZipLM) which may not be readily available
- Performance depends critically on hyperparameter choices (ˆt, ˆp) that require careful tuning across different models and speedup targets
- Focuses exclusively on one-shot pruning without exploring potential benefits of gradual pruning approaches with fine-tuning

## Confidence
- **Core technical contributions**: High - The combinatorial optimization framework and local search algorithm are well-described and theoretically sound
- **Empirical results**: Medium - Results are comprehensive but depend on baseline implementations and hyperparameter choices that require verification
- **Scalability claims**: Medium-High - The low-rank optimization approach is detailed, but the 30B parameter result needs independent validation

## Next Checks
1. Implement and validate the exact formulations of competing methods (MP, CHIP, FPGM, Lasso, ThiNet, ZipLM) to ensure fair comparison
2. Systematically test the sensitivity of results to hyperparameter choices (ˆt, ˆp) across different model sizes and speedup targets
3. Reproduce the 30B parameter pruning result to verify the claimed 32GB GPU memory usage and computational efficiency