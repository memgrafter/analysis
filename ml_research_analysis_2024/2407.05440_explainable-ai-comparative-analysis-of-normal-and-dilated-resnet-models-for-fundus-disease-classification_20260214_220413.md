---
ver: rpa2
title: 'Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for
  Fundus Disease Classification'
arxiv_id: '2407.05440'
source_url: https://arxiv.org/abs/2407.05440
tags:
- dilation
- resnet
- dilated
- figure
- normal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the use of dilated convolutional filters
  in ResNet models for classifying retinal fundus images. By replacing normal convolutions
  with dilated convolutions in the higher layers, the receptive field is improved,
  enhancing feature capture and diagnostic accuracy.
---

# Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification

## Quick Facts
- arXiv ID: 2407.05440
- Source URL: https://arxiv.org/abs/2407.05440
- Reference count: 22
- Primary result: Dilated ResNet models achieved average F1 scores of 0.71, 0.70, 0.69, 0.67, and 0.70 for ResNet-18, ResNet-34, ResNet-50, ResNet-101, and ResNet-152 respectively on ODIR dataset

## Executive Summary
This study investigates the application of dilated convolutional filters in ResNet architectures for classifying retinal fundus images. By strategically replacing normal convolutions with dilated convolutions in higher layers, the research demonstrates improved feature capture and diagnostic accuracy. The proposed approach is validated on the ODIR dataset containing eight classes of common retinal diseases. The work also incorporates explainable AI techniques to provide insights into model decision-making processes.

## Method Summary
The research proposes a novel approach to fundus disease classification by modifying standard ResNet architectures with dilated convolutions. Specifically, the study replaces normal convolutions with dilated convolutions in the higher layers of ResNet models (ResNet-18, 34, 50, 101, and 152). This modification aims to improve the receptive field, thereby enhancing the model's ability to capture more comprehensive features from retinal fundus images. The models are trained and evaluated on the ODIR dataset, which includes eight classes of common retinal diseases. The effectiveness of the proposed method is assessed using standard classification metrics, particularly F1 scores.

## Key Results
- Dilated ResNet models achieved average F1 scores ranging from 0.67 to 0.71 across different ResNet architectures
- ResNet-18 with dilated convolutions performed best with an average F1 score of 0.71
- The proposed method outperformed standard ResNet models in fundus disease classification
- Explainable AI techniques (LIME, RISE, and Grad-CAM) were successfully applied to provide insights into model decision-making

## Why This Works (Mechanism)
The mechanism behind the improved performance lies in the enhanced receptive field achieved through dilated convolutions. By increasing the receptive field in higher layers, the models can capture more contextual information from the retinal fundus images, leading to better feature extraction and ultimately improved classification accuracy. The dilated convolutions allow the model to aggregate information from a larger area of the image without increasing the number of parameters, which is crucial for medical image analysis where context and spatial relationships are important for accurate diagnosis.

## Foundational Learning
- **Dilated Convolutions**: A convolution technique that expands the receptive field without increasing parameters. Why needed: To capture larger contextual information in medical images. Quick check: Verify dilation rate and its impact on receptive field size.
- **ResNet Architectures**: Deep residual networks that use skip connections to ease training of deep models. Why needed: To handle complex feature hierarchies in fundus images. Quick check: Confirm number of layers and blocks in each ResNet variant.
- **ODIR Dataset**: A dataset containing eight classes of common retinal diseases. Why needed: To provide a standardized benchmark for fundus disease classification. Quick check: Validate class distribution and image quality in the dataset.
- **Explainable AI Techniques**: Methods like LIME, RISE, and Grad-CAM used to interpret model decisions. Why needed: To validate model behavior against medical knowledge and build trust. Quick check: Ensure visualizations align with known disease characteristics.
- **F1 Score**: A metric combining precision and recall, crucial for imbalanced medical datasets. Why needed: To provide a balanced evaluation of classification performance. Quick check: Compare F1 scores with other metrics like accuracy and AUC-ROC.

## Architecture Onboarding
**Component Map**: Input Image -> Feature Extraction (ResNet with Dilated Convolutions) -> Classification Head -> Output Predictions
**Critical Path**: Image Preprocessing -> Dilated ResNet Feature Extraction -> Global Average Pooling -> Fully Connected Layer -> Softmax Classification
**Design Tradeoffs**: The use of dilated convolutions improves receptive field but may introduce gridding artifacts. The choice of applying dilation only in higher layers balances improved feature capture with computational efficiency.
**Failure Signatures**: Potential overfitting due to limited dataset size, gridding artifacts from dilated convolutions, and misclassification of rare disease classes.
**First Experiments**: 1) Compare F1 scores of dilated vs. normal ResNet models on a held-out validation set. 2) Visualize feature maps to confirm expanded receptive fields. 3) Apply LIME/RISE to random samples to validate explainable AI results.

## Open Questions the Paper Calls Out
None

## Limitations
- The ODIR dataset has been noted for potential quality issues and limited sample sizes per class, affecting generalizability
- The specific configuration of applying dilated convolutions only in higher layers lacks theoretical justification
- Explainable AI methods may introduce artifacts or misinterpretations in the validation process
- Reported F1 scores indicate significant room for improvement before clinical deployment

## Confidence
- **High confidence**: The experimental methodology for comparing dilated vs. normal ResNet models is sound and reproducible
- **Medium confidence**: The claim that dilated convolutions improve feature capture is supported but could benefit from more detailed feature visualization
- **Medium confidence**: The explainable AI validation against medical knowledge is a valuable contribution but requires more rigorous clinical expert validation

## Next Checks
1. Conduct cross-validation across multiple fundus image datasets beyond ODIR to verify model robustness
2. Perform ablation studies testing different dilation configurations (rates, layers, and combinations) to optimize the architectural design
3. Implement expert clinician review of the explainable AI visualizations to validate their clinical relevance and accuracy